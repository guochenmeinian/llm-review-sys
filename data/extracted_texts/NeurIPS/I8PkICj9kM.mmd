# Rethinking Score Distillation as a

Bridge Between Image Distributions

 David McAllister\({}^{1}\)1 Songwei Ge\({}^{2*}\) Jia-Bin Huang\({}^{2}\) David W. Jacobs\({}^{2}\)

Alexei A. Efros\({}^{1}\) Aleksander Holynski\({}^{1}\) Angjoo Kanazawa\({}^{1}\)

\({}^{1}\) UC Berkeley \({}^{2}\) University of Maryland

[https://sds-bridge.github.io/](https://sds-bridge.github.io/)

###### Abstract

Score distillation sampling (SDS) has proven to be an important tool, enabling the use of large-scale diffusion priors for tasks operating in data-poor domains. Unfortunately, SDS has a number of characteristic artifacts that limit its usefulness in general-purpose applications. In this paper, we make progress toward understanding the behavior of SDS and its variants by viewing them as solving an optimal-cost transport path from a source distribution to a target distribution. Under this new interpretation, these methods seek to transport corrupted images (source) to the natural image distribution (target). We argue that current methods' characteristic artifacts are caused by (1) linear approximation of the optimal path and (2) poor estimates of the source distribution. We show that calibrating the text conditioning of the source distribution can produce high-quality generation and translation results with little extra overhead. Our method can be easily applied across many domains, matching or beating the performance of specialized methods. We demonstrate its utility in text-to-2D, text-based NeRF optimization, translating paintings to real images, optical illusion generation, and 3D sketch-to-real. We compare our method to existing approaches for score distillation sampling and show that it can produce high-frequency details with realistic colors.

## 1 Introduction

Diffusion models have shown tremendous success in modeling complex data distributions like images , videos  and robot action policies . In domains where data is plentiful, they produce state-of-the-art results. Many data modalities, however, cannot enjoy the same scaling benefits due to their lack of sufficiently large datasets. In these cases, it is useful to exploit diffusion models trained on domains with rich data sources as a prior in an optimization framework. Score Distillation Sampling (SDS)  and its variants  are a widely adopted way to optimize parametric images, _i.e._, images produced by a model like NeRF, with a pre-trained diffusion model. Despite being applicable to a wide range of applications, SDS is also known to suffer from several significant artifacts, such as oversaturation and oversmoothing. As such, several variants have been proposed to alleviate these artifacts , often at the cost of efficiency, diversity, or other artifacts.

In this paper, we investigate the core issues with SDS by casting the class of score distillation optimization problems as a Schrodinger Bridge (SB) problem , which finds the optimal transport between two distributions. Specifically, given some images from the current optimized distribution (_e.g._, renderings from a NeRF), applying the transport maps them to their pair images in a target distribution (_e.g._, text-conditioned natural image distribution). The density flow formed by these mappings is transport-optimal, as defined in the SB problem. In an optimization framework, the difference between paired source and target samples, computed with an SB, can beused as a gradient to update the source. Su _et al_.  have shown that this path can be explicitly solved using two pre-trained diffusion models. We show that one can also compose these models as an optimizer to approximate transport paths on the fly.

Under this framework, we can understand SDS and its variants as approximating a source-to-target distribution bridge with the difference of two denoising directions. The denoising scores point to the source and target distributions respectively, with the source representing the current optimized image that updates with each optimization step.

This framing reveals two sources of errors. First, these methods are a first-order approximation of the diffusion bridge. Specifically, Gaussian noise is sampled to perturb the current optimized image, and single denoising steps, instead of the full PF-ODE simulation, are used to estimate the transport. This induces error in estimating the desired path. Recent works [34; 41] that use multi-step estimation can be explained as mitigating this error. Second, estimating the denoising direction to the current source distribution is non-trivial, since the current optimized image may not necessarily look like a real image (_e.g._, initializing with Gaussian noise or starting from a render of an untextured 3D model). Our analysis reveals that SDS approximates the current distribution with the unconditional image distribution, which is not accurate and results in a _distribution mismatch error_. We show that recent SDS variants [70; 76; 32] can be seen as proposals to improve this distribution mismatch error.

Finally, our analysis motivates a simple method that rectifies the distribution mismatch issue without additional computational overhead. Our insight is that the large-scale text-to-image diffusion models learn from billions of caption-image pairs , where a breadth of image corruptions are present in their training sets. They are also equipped with powerful pre-trained text encoders, which empower the models with zero-shot capacity in generating unseen concepts [53; 52]. As such, simply describing the current source distribution with text, even if it is not part of the real image manifold, can approximate the distribution of the current optimized image, leading to improved transport paths. Our simple and efficient solution can be easily applied to any existing application that uses SDS. We show that it consistently improves the visual quality in the desired domain. We comprehensively compare our approach with standard distillation sampling methods over several generation tasks, where our approach matches or outperforms the baselines.

Our contributions are as follows:

* We propose to cast the problem of using a pre-trained diffusion model as a prior in an optimization problem as solving the Schrodinger Bridge (SB) problem between two image distributions. Specifically, it can be seen as bridging the distribution of the current optimized image to the target distribution under a dual-bridge framework.
* We analyze recent SDS-based methods under the lens of our framework and explain the pros and cons of the individual methods.
* Our analysis motivates a simple yet effective alternative to SDS by using textual descriptions to specify the current optimized image distribution. It achieves consistently more realistic results than SDS, producing quality comparable with VSD  without its computational overhead. We compare various generation tasks to show its wall-clock efficiency and quality generations against state-of-the-art methods.

## 2 Related Work

Score Distillation SamplingModalities like 3D, 4D, sketch, and vector graphics (SVGs) lack the large-scale, diverse, and high-quality datasets needed to train a domain-specific diffusion model. In these domains, previous works explore exploiting image or video as a proxy modality [26; 16]. By computing the gradient on a proxy representation with a pretrained model, optimization in the target modality is viable with differentiable mappings, e.g. differentiable rasterization  for SVGs or differentiable rendering  for 3D objects and scenes. The seminal method, Score Distillation Sampling (SDS) , first proposed to apply a pretrained text-to-image diffusion model for text-to-3D generation. However, it requires a high classifier-free guidance weight and, therefore, suffers from artifacts such as over-saturation and over-smoothing. Recent works have built upon SDS to adapt it for editing tasks [30; 20; 46; 29] or more broadly improve over the original SDS formulation [28; 1; 70; 77; 76; 78]. NFSD  and LMC-SDS  inspect the individual components of the SDS gradient and propose methods to rectify the high guidance weights. However, the over saturation problem is mitigated but not fully resolved. VSD  formulates the problem as particle-based variational inference and proposes to train a LoRA  on the fly to estimate the score of proxy distribution. We present a new framework that allows rethinking all the variants under the same lens. This framework also motivates a method that improves the quality of SDS without losing efficiency.

Visual Content Generation with SDSSince SDS was developed for text-to-3D generation, it has also been adopted to generate various other visual content such as SVGs [18; 73], sketches , texture [43; 6; 7; 8; 75], typography , 3D bodies , dynamic 4D scenes [2; 60; 37] and illusions . Among these applications, text-to-3D has been the most active research direction. In addition to designing better distillation sampling methods [70; 77; 28], prior work has also studied the underlying 3D neural representations [74; 66; 35; 9] and leveraging multiview data to improve the 3D consistency [57; 40; 39; 78]. We note that these explorations are orthogonal to our study and should be able to work jointly with our method. In this paper, we look into existing applications like text-based NeRF optimization, painting-to-real, and illusion generation. We also propose a new AR application called 3D sketch-to-real.

## 3 Method

In this section, we present an analytical framework that casts the score distillation sampling (SDS) family of methods as instantiations of a Schrodinger Bridge problem. We show that many recent SDS based methods can be interpreted as an online solver for the problem. That is, each SDS optimization step is a first-order approximation of a dual diffusion bridge formed by two probability flow (PF) ODEs . We analyze SDS and its variants under this general framework. Then, we present a simple solution based on the analysis, which leads to significant quality improvement with little extra computational overhead.

### Background

**Diffusion models** define a forward "noising" process that degrades data samples \(\) gradually from the image distribution to noised samples \(_{t}\), and eventually the i.i.d. Gaussian distribution [23; 62]. This process is indexed by timesteps \(t\), where \(t=1\) indexes the full Gaussian noise distribution and \(t=0\) indexes the data distribution. A diffusion model, parameterized by \(\), is then trained to reverse this encoding process, iteratively transforming the noise distribution into the data distribution with the following denoising objective:

\[_{}(,)=_{t(0,1), (,)}[w(t)\|_{ }(_{t}+_{t};y,t)-\|_{2 }^{2}], \]

where \(w(t)\) is a loss weighting function, \(y\) is a conditioning text prompt, and \(_{t}\) and \(_{t}\) are hyperparameters from the predefined noise schedule.

Figure 1: **Optimization with diffusion models as approximation of a Schrödinger Bridge Problem (SBP).** (a) We propose to formulate optimization with diffusion models as bridging the distribution of the current optimized image \(x_{}\) to the target distribution under a dual-bridge framework (a). Current methods can be interpreted as approximating the optimal transport \(_{}^{*}\) between these distributions via the difference between projections of a noised image \(x_{,t}\) onto the two distributions. This analysis reveals two sources of error: (1) these gradients are linear approximations of the optimal path, as illustrated in (a), and (2) the source distribution used for computing this approximation (_e.g._, the unconditional distribution in SDS ) may not be aligned with the current distribution, illustrated in (b).

**Probability Flow ODE.** Denoising score matching [64; 27; 61] shows that the diffusion model denoising prediction can be rewritten as a score vector field:

\[_{} p_{t}()=-}} _{t}. \]

Because of its special connection to marginal probability densities, the resulting ODE is named the probability flow (PF) ODE with the following expression:

\[dx=[f(,t)-g^{2}(t)_{} p_{t}())]dt, \]

where \(f(,t)\) and \(g(t)\) are pre-defined schedule parameters. This PF-ODE can be solved deterministically , mapping a noise sample to its corresponding data sample through the reverse process and the opposite through the forward process (inversion). This cycle-consistent conversion between image and latent representations is important in establishing dual diffusion implicit bridges.

**Dual Diffusion Implicit Bridges.** Dual Diffusion Implicit Bridges (DDIBs)  compose a diffusion inversion and generation process for solving image-to-image translation problems without requiring a paired image dataset. Instead, DDIBs use two diffusion models trained on different domains (or, analogously, one model with two different text conditions). DDIB inverts the source image into a noise latent via the forward PF-ODE and then decodes the latent in the target domain via the reverse PF-ODE. DDIBs can be interpreted as a concatenation of the Schrodinger Bridges from source-to-latent and latent-to-target, hence the dual bridges in its name. DDIBs enable solving transport between two distributions using a single pre-trained diffusion model. We build on this insight in an optimization context.

### Optimization with Diffusion Model Approximates a Dual Schrodinger Bridge

Many generative vision tasks involve optimizing corrupted images to the image manifold. For example, in 3D generation, a 3D representation like NeRF is optimized to render natural images matching a prescribed text prompt. Methods like SDS enable this by using a pre-trained diffusion model as a prior. We propose formulating such optimization problems as solutions to an instantiation of a Schrodinger Bridges Problem (SBP). SBP finds cost-optimal paths between a source image distribution \(p_{}\) and a target image distribution \(p_{}\)[68; 14]. Optimizing a parametrized image toward the natural image distribution can be cast as finding the optimal paths between the current optimized image(s) and the natural image distribution. Instead of solving this problem directly, which would require training a generative model from scratch [38; 14; 10], we show that pre-trained diffusion models can be exploited as an optimizer that approximates the path. Further, the gradient computed by the existing score distillation methods can be viewed as the first-order approximation of this path. This formulation is illustrated in Figure 1.

Let \(_{}^{d}\) represent a parametric image, _i.e._, an image produced differentiably by a model with parameter \(\), such as a NeRF. To leverage the pretrained diffusion model, we add noise \((,)\) to obtain a latent at timestep \(t\):

\[_{,t}=_{t}_{}+_{t} \]

Suppose that \(_{t^{},}\) and \(_{t^{},}\) denote the paths obtained by solving the PF ODE as in Eq. 3 from \(t\) to \(0\), both starting from \(_{,t}\), such that \(_{0,} p_{}\), \(_{0,} p_{}\), \(_{t,}=_{t,}=_{,t}\). This forms a dual diffusion bridge  from \(_{0,}\) to \(_{0,}\). We approximate this path _per-iteration_ using a pretrained diffusion model. We denote the displacement of this path as:

\[^{*}_{}=_{0,}-_{0,}. \]

Fully simulating this bridge involves solving two PF ODEs, which invokes dozens of neural function evaluations (NFEs) to estimate the gradient of each iteration. Instead, one can estimate each half of the bridge with a single-step prediction by computing two denoising directions \(_{,}\) and \(_{,}\). We thus obtain a first-order approximation of a dual diffusion bridge with the difference vector:

\[_{}=_{,}-_{,}, \]which is subject to the following sources of errors.

1. **First-order approximation error**. Instead of performing full PF-ODE simulations, the single-step noising and prediction are less accurate and induce errors. Recent work ISM  can be interpreted as reducing this error with a multi-step simulation to obtain \(_{,t}\).
2. **Source distribution mismatch**. The dual diffusion bridge relies on \(_{,}\) accurately estimating the distribution of the current sample, \(_{}\). A series of works can be viewed as improving this error [70; 28; 76] by computing more accurate \(_{,}\).

We show that \(_{,}-_{,}\) is an effective gradient when both the source and target distribution are well expressed. Next, we discuss the popular score distillation methods under this analysis. We argue that their characteristic artifacts can largely be understood due to the errors above.

### Analyzing Existing Score Distillation Methods

We analyze SDS and its variants through our framework by inspecting each component in the computed gradient. For notation, \(y_{}\) is the text prompt representing the target distribution, and \(\) denotes the unconditional prompt. For each method, we present its gradient update and discuss its implications.

Score Distillation Sampling : \[_{}=_{}(_{,t};, t)+s(_{}(_{,t};y_{},t )-_{}(_{,t};,t) )-,\]

where \(s\) is the strength of classifier-free guidance. When \(s\) is small, the \(\) functions as an averaging term to regress the image to the mean. However, the SDS gradient has been shown to work best with extreme values of classifier-free guidance \(s\) like \(100\). We can rewrite the gradient to emphasize how the conditional-unconditional delta dominates at high CFG scales.

\[_{}=( _{,t};y_{},t)-_{}(_{,t}; ,t))}_{when~{}$s 1$}}+_{}(_{ ,t};,t)-,\]

Experimentally, we produce very similar results at high CFG with or without the non-dominant terms. We argue that SDS should be interpreted through the dominant term, which fits within our analysis. Under this interpretation, the unconditional direction \((_{,t};,t)\) approximates the source distribution of \(_{}\) poorly, instead representing images of any identity with low contrast and geometric artifacts. Figure 1(b) illustrates the effect of a poor approximation. The bridge from the unconditional to conditional distribution leads to the characteristic oversaturation and smoothing of SDS results.

Delta Distillation Sampling : \[_{}=_{}(_{,t};y_{},t)-_{}(_{,t};y_{},t ),\]

where \(_{,t}\) is a noised version of a reference image in the image editing task. As shown in Figure 2 (b), this increases the _source distribution mismatch_ since \(_{,}\) is not calculated based on the current optimized image \(_{,t}\).

Noise Free Score Distillation : \[_{}=(_{}(_{,t};,t)-(t<0.2)_{}(_{,t};y_{},t))+s(_{}(_{,t};y_{},t)-_{}(_{,t};,t )),\]

Figure 2: **Comparision of SDS variants under our analysis. We illustrate the major gradient components of different SDS variants and provide a straightforward comparison with \(_{}\).**

where the strength of classifier-free guidance \(s\) is set to \(7.5\) and \(y_{}=\)"unrealistic, blurry, low quality...". NFSD greatly reduces the guidance strength while it is observed to perform very similarly to SDS in practice. We can better explain this phenomenon since the prompt \(y_{}\) does not accurately describe the source distribution as it omits the image's content. In addition, the second component with weight \(s=7.5\) still forms the major part of the gradient, which is the dominant term in SDS.

**Classifier Score Distillation :**

\[_{}=w_{1}(_{}(_{,t};y_ {},t)-_{}(_{,t};,t ))+w_{2}(_{}(_{,t};,t )-_{}(_{,t};y_{},t)),\]

where \(w_{1}\) and \(w_{2}\) are hyperparameters. As shown in Figure 2 (c), the second term approximates the bridge from the source distribution to the unconditional distribution, which is not ideal since it does not point to the target distribution. It explains the observation made by the authors  that this undermines the alignment with the text prompt. Therefore, the authors always anneal \(w_{2}\) to \(0\) during the optimization. However, we show this often reintroduces the SDS artifacts in practice.

**Variational Score Distillation :**

\[_{}=_{}(_{,t};, t)+s(_{}(_{,t};y_{},t )-_{}(_{,t};,t))- _{LoRA}(_{,t};y_{},t).\]

Out of all the discussed methods, VSD attempts to minimize the _source distribution mismatch_ error most directly by test-time finetuning a copy of the diffusion model with LoRA on the current set of \(_{}\). Note that in the original paper, the use of LoRA was motivated based on a particle-based variational framework. Our analysis enables an alternative understanding of VSD. As shown in Figure 2 a), this approach is well-justified in our dual diffusion bridge framework. However, training a LoRA _every iteration_ is computationally expensive, adds complexity, and introduces its own low-rank approximation errors. Given this insight, we propose a simple yet efficient approach to mitigating source distribution without LoRA.

### Mitigating Source Distribution Mismatch with Textual Descriptions

Our analysis reveals that the LoRA model in VSD most closely approximates the distribution of the current optimized parametrized image, addressing the distribution mismatch error. Unfortunately, it incurs \(200-300\%\) runtime overhead on top of SDS, making it impractical, despite its significant performance gains. With this understanding, we propose a simple approach that better expresses the source distribution. Our insight is that pre-trained diffusion models have learned the distribution of natural and corrupted images through a combination of powerful text representation and enormous image-caption datasets. We find that by simply describing image corruptions with a text prompt, we can improve our estimate of the source distribution.

Specifically, we propose to use the gradient

\[_{}=w(_{}(_{,t};y_{ },t)-_{}(_{,t};y_{ },t)),\]

where we get \(y_{}\) by adding descriptions of the current image distribution to \(y_{}\) (the base prompt). The remaining question is how to set this description. In generation tasks, we propose a simple two-stage solution.

1. We use \(_{}\) to produce a generation with the method's characteristic artifacts:
2. We switch to optimization with our gradient, \(_{}\), to transport the image parameter toward the natural image distribution.

To describe the artifacts produced by SDS, we append the descriptors ", oversaturated, smooth, pixelated, cartoon, foggy, hazy, blurry, bad structure, noisy, malformed" and drop the descriptors of the high-quality generation. This description \(y_{}\) does not require hand-crafting based on problem domains--it is fixed across all shown examples and use cases. As shown in Appendix Figure A5, we explored searching for other prompts but did not find that variations in these descriptions made a big difference.

In editing tasks, we have an initialization that \(y_{}\) describes accurately. In such cases, we omit the first SDS stage and only apply our gradient to optimization. We also append a "domain descriptor." For instance, in painting-to-real, this is simply ", painting" to represent the initial distribution.

While the use of such negative prompting has been explored before, such as in NFSD, our analysis motivates a principled way to incorporate it into score distillation. We find that these simple modifications significantly narrow the quality gap between SDS and resource-intensive methods like VSD. We verify this finding experimentally with qualitative results and quantitative comparisons across applicable tasks.

## 4 Experiments

In this section, we test our proposed method on several generation problems where SDS is adopted. We compare against SDS and other task-specific baselines. Note that our goal is not to show another state-of-the-art text-to-3D generation method, but to verify our findings, where the proposed score distillation approach based on textual description efficiently improves the results by mitigating the source distribution mismatch error. We first perform a thorough experiment in a controlled setting on text-to-image generation. Then, we compare it on text-guided NeRF optimization to SDS and VSD and evaluate the painting-to-real image translation task against image editing baselines. Please see more results in the appendix, including additional qualitative results and comparison, ablation studies and our method's application to optical illusion generation and 3D-sketch-to-real task.

### Zero-Shot Text-to-Image Generation with Score Distillation

To verify our analysis of existing SDS variants and the proposed method, we perform text-to-image generation by optimizing an image of size \(64 64 4\) in the Stable Diffusion latent space [70; 28] (We explore other base models like MVDream  and SDXL  in Appendix Figure A3). The benefit of choosing image generation as the evaluation task is that its generation quality has the least confounding variables among other tasks. (_e.g.,_ in text-to-3D, many designs like regularizations , initialization , 3D representations [9; 67; 74; 66], and 2D prior models [57; 40; 39; 49; 78] could affect the final quality.

    & DDIM (lower bound) & SDS  & NFSD  & CSD  & VSD  & Ours \\  Zero-Shot FID (\(\)) & \(49.12\) & \(86.02\) & \(91.70\) & \(89.96\) & \(\) & \(67.89\) \\ Zero-Shot CLIP FID (\(\)) & \(16.56\) & \(28.39\) & \(29.25\) & \(27.07\) & \(\) & \(\) \\ Time per Sample (mins) & \(0.05\) & \(\) & \(7.20\) & \(6.21\) & \(16.02\) & \(\) \\   

Table 1: **Zero-shot FID comparison with different score distillation methods.** We report FID scores of text-to-image generation using 5K captions randomly sampled from the COCO dataset. The best score distillation result is indicated in **bold**, while the second best is underlined.

Figure 3: **Text-to-image generation results with COCO Captions.** We compare different score distillation methods for generating images with COCO captions by optimizing a randomly initialized image. DDIM sampling indicates the lower bound that the diffusion model can achieve. VSD  and our method generate the least color artifacts while ours is more efficient than VSD.

We use the MS-COCO  dataset for the evaluation. Consistent with the prior study , we randomly sample 5K captions from the COCO validation set as conditions for generating images. For each caption, we optimize a randomly initialized the image with the score distillation gradients. We compare our method with several SDS variants including SDS , NFSD , CSD , and VSD . For all the methods, we use the same learning rate of \(0.01\) and optimize for \(2,500\) steps where we generally observe convergence. We compute the zero-shot FID  and CLIP FID scores  between these generated images and the ground truth images. We also report results generated by DDIM with \(20\) steps as a lower bound for reference.

We report the FID scores and the time to optimize one image in Table 1. Among all the score distillation methods, VSD  achieves the lowest FID scores. However, it requires training a LoRA along the optimization process. Instead, ours achieves a comparable FID score with over \(3\) faster speed. We visualize random examples generated by different score distillation methods in Figure 3. We notice that SDS and NSFD suffer from the over-saturation and over-smoothness issues. CDS has slightly fewer color artifacts. VSD and ours generate the samples that most closely resemble the DDIM sampling.

### Text-guided NeRF Optimization

We now evaluate the text-to-3D generation problem, where we intentionally aim to exclude variables that could affect the generation quality other than the score distillation methods. We use the Three-Studio  repository to optimize a NeRF with settings tuned for ProlificDreamer stage 1 (NeRF optimization) . Note that we do not perform stages 2 and 3, _i.e_. geometry fine-tuning and texture refinement. Specifically, we initialize the NeRF with the method proposed by Magic3D , use the regularization losses on the sparsity and opacity, and optimize for 25K steps. We adopt the native SDS and VSD guidance implementations for comparison. In Appendix Figure A4, we evaluate our methods with additional text-to-3D systems, including Fantasia3D , Magic3D  and CSD .

We first show visual comparisons of different score distillation methods in Figure 4. We notice that SDS tends to generate fewer details, as shown by the rock and chair examples, and sometimes suffers from over-saturation issues, as in 2D, as demonstrated by the cottage and seashell examples. Instead, both VSD and ours can generate highly photo-realistic 3D objects, while ours does not require training a LoRA model and shares a similar computational cost as SDS.

    & ViT-L/14 & ViT-B/16 & ViT-B/32 \\  SDS  & 0.2811 & 0.3196 & 0.3139 \\ VSD  & 0.2837 & 0.3292 & 0.3166 \\ Ours & 0.2848 & 0.3282 & 0.3148 \\   

Table 2: **Quantitative comparisons of NeRF optimization**. We measure the average CLIP similarity of rendered views using SDS, VSD and our.

Figure 4: **Text-guided NeRF optimization with different score distillation methods.** We make a fair comparison of SDS and VSD for text-to-3D generation. For each generation, we show three uniformly sampled views. SDS results like the cottage and pepper mill still suffer from over-saturation problems, while ours and VSD can produce realistic details, color, and texture.

We also perform a quantitative evaluation and user study on the NeRFs optimized based on 31 different text prompts. Note that this number is similar to the choice of existing works on the text-to-3D task [34; 32; 15]. However, different from these works that ignore the confounding 3D variables that contribute to the generation quality, we disentangle this by isolating the score distillation method as the only comparison variable. We follow these works to evaluate the generation quality with CLIP . We report the CLIP similarity in Table 2. Our method consistently outperforms SDS and achieves comparable results with VSD. In addition, in a user study consisting of 37 users, shown pairwise comparisons of rotating 3D renders (_i.e.,_ comparisons of our result and a random choice of VSD or SDS, with the prompt: "For a text-to-3D system, given the prompt _[p]_, which result would you be happiest with?"), our results were chosen in 75.7% of all responses.

### Painting-to-Real

We examine our method's ability to serve as a general-purpose realism prior. Paintings are "near-manifold" images, meaning they do not possess natural image statistics but live near the image distribution in image space. An effective image prior should guide a painting toward a nearby natural image through optimization.

We initialize a latent image by encoding scans of the artwork through Stable Diffusion's encoder. We specify a prompt for each painting to condition the diffusion model and then apply the second optimization stage of our method (SDS stage omitted). We experimented with automatically generating prompts via pretrained vision language models but found the results inconsistent, so we leave this to future work. Since the large image datasets used to train diffusion models contain artwork, we append the domain descriptor ", painting" to \(y_{}\) to optimize away from this distribution.

While SDS is proposed to leverage a pretrained text-to-image diffusion model as an image prior, its artifacts make it ineffective in practice. In comparison, our method realistically synthesizes details and relights the image naturally. We observe that SDS methods diverge more easily in 2D experiments than in 3D but that the issue can be mostly resolved with tuning. A future goal is to formulate a gradient that can be applied idempotently . We compare with image reconstruction baselines in Figure 5 and provide a small gallery of painting-to-real results in Figure 6.

## 5 Discussion on Solving the Linear Approximation Error

As we have shown that reducing the distribution mismatching error can significantly improve the generation quality of the score distillation optimization, it is natural to ask whether one can also reduce the first-order approximation error, induced by linear bridge estimation, to improve the results further. Several recent studies, including SDI  and ISM , can be viewed as mitigating

Figure 5: **Painting-to-Real comparison. We compare our gradient in optimization to image restoration and image-conditional generation baselines. While SDEdit produces convincing textures, it is difficult to find a strength value that balances structure and quality. Other baselines fail to reproduce natural image quality, while our method produces the best combination of quality and faithfulness.**

this error by replacing the single-step estimation with a multi-step estimation to an intermediate timestep. Under our framework, one can estimate the entire dual bridge by solving both PF-ODE paths. Specifically, via inversion, one can solve the PF-ODE path from \(_{0,}\) to \(x_{,T}\), and then walk to the \(_{0,}\) via sampling. In this way, it is possible to obtain the most accurate gradient direction with little approximation error \(^{*}_{}=w(_{0,}-_{0,})\). We refer to this approach as "full path". Note that this resolves the linear approximation error, and it is independent of handling the source approximation error, which could be addressed via the discussed text description or LoRA.

However, solving the inversion ODE is not trivial . We noticed that the inversion can exaggerate the distribution mismatch error and cause the optimization to get stuck at a local optimum at the beginning of the optimization. Instead, the stochasticity of the single-step methods often shows more robustness to the input image. Therefore, we first perform the single-step score distillation optimization to obtain reasonable results and then switch to solving the full bridge. We also anneal the timestep endpoint of the bridge throughout the optimization. With this approach, we can now explore addressing both the first and second sources of error. The first source (linear approximation) has "full-path," and the second source (source distribution mismatch error) has "Bridge" or "LoRA". We find that using the "full-path" multi-step (mitigating linear approximation error) always outperforms the single-step methods, achieving a lower FID, as shown in Table 3. However, the same trend does not fully transfer to the text-to-3D experiments. We observe that solving the entire bridge typically introduces additional artifacts and makes the optimization less stable. We leave the best way of leveraging this gradient for future research exploration.

## 6 Conclusion

We present an analysis that formulates the use of a pre-trained diffusion model in an optimization framework as seeking an optimal transport between two distributions. Under this lens, we analyze SDS variants with a unified framework. We also develop a simple approach based on textual descriptions that work comparably well to the best-performing approach, VSD, without its significant computational burden. However, neither approach has yet to achieve the quality and diversity of images generated by the reverse process. We hope that our analysis enables the development of a more sophisticated solution that can one day achieve the same quality and diversity as the reverse process in an optimization framework. Combining our proposed method with multi-step approximations like ISM  or schedules like DreamFlow  could mitigate the first-order approximation error and further improve the efficiency, which is an interesting future research direction. With the rise of high-quality video diffusion models, we anticipate that the question of how to effectively use such models as a prior in various problems will become even more important.

   Approximate the bridge &  &  \\ Estimate source distribution & Uncond. (SDS) & Bridge & LoRA (VSD) & Uncond. & Bridge & LoRA \\  Zero-Shot COCO FID (\(\)) & 86.02 & 67.89 & 59.22 & 63.31 & 60.07 & 55.65 \\   

Table 3: **Reducing first-order approximation error improves generation quality. Using full PF-ODE simulation (“Full-path”) to replace single-step prediction improves visual quality in all settings.**

Figure 6: **Painting-to-Real results.We show selected Painting-to-Real samples with diverse art styles and subjects. Initialization images are shown on the left, optimized images are shown on the right.**

Acknowledgment.We thank Matthew Tancik, Jiaming Song, Riley Peterlinz, Ayaan Haque, Ethan Weber, Konpat Preechakul, Amit Kohli and Ben Poole for their helpful feedback and discussion. This project is supported in part by a Google research scholar award, IARPA DOI/IBC No. 140D0423C0035, and NSF grant No. IIS-2213335. The views and conclusions contained herein are those of the authors and do not represent the official policies or endorsements of these institutions.