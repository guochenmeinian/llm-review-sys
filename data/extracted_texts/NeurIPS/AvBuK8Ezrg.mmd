# _NeuroPath_: A Neural Pathway Transformer for

Joining the Dots of Human Connectomes

 Ziquan Wei

University of North Carolina at Chapel Hill

Chapel Hill, NC 27599

ziquanw@eamil.unc.edu

&Tingting Dan

University of North Carolina at Chapel Hill

Chapel Hill, NC 27599

tingting_dan@med.unc.edu

&Jiaqi Ding

University of North Carolina at Chapel Hill

Chapel Hill, NC 27599

jiaqid@cs.unc.edu

&Guorong Wu

University of North Carolina at Chapel Hill

Chapel Hill, NC 27599

guorong_wu@med.unc.edu

###### Abstract

Although modern imaging technologies allow us to study connectivity between two distinct brain regions _in-vivo_, an in-depth understanding of how anatomical structure supports brain function and how spontaneous functional fluctuations emerge remarkable cognition is still elusive. Meanwhile, tremendous efforts have been made in the realm of machine learning to establish the nonlinear mapping between neuroimaging data and phenotypic traits. However, the absence of neuroscience insight in the current approaches poses significant challenges in understanding cognitive behavior from transient neural activities. To address this challenge, we put the spotlight on the coupling mechanism of structural connectivity (SC) and functional connectivity (FC) by formulating such network neuroscience question into an expressive graph representation learning problem for high-order topology. Specifically, we introduce the concept of _topological detour_ to characterize how a ubiquitous instance of FC (direct link) is supported by neural pathways (detour) physically wired by SC, which forms a cyclic loop interacted by brain structure and function. In the cliche of machine learning, the multi-hop detour pathway underlying SC-FC coupling allows us to devise a novel multi-head self-attention mechanism within Transformer to capture multi-modal feature representation from paired graphs of SC and FC. Taken together, we propose a biological-inspired deep model, coined as _NeuroPath_, to find putative connectomic feature representations from the unprecedented amount of neuroimages, which can be plugged into various downstream applications such as task recognition and disease diagnosis. We have evaluated _NeuroPath_ on large-scale public datasets including Human Connectome Project (HCP) and UK Biobank (UKB) under different experiment settings of supervised and zero-shot learning, where the state-of-the-art performance by our _NeuroPath_ indicates great potential in network neuroscience.

## 1 Introduction

The seek of meaningful feature representations for graph topology has been extensively investigated , with widespread applications in reasoning path  and cycle basis  for knowledge graph, as well as neural fingerprint , junction tree autoencoder  and cellular Weisfeiler Leman (WL) testing  for molecular substructure encoding. Moreover, graph data in the realm of neuroscience research demands feature representation bearing additional neuroscience insightwhich is supposed to underline particular neurobiological mechanisms of interest. For example, substructure embedding  and snapshot embedding  have been proposed to characterize the phenotypic traits from structural connectivity (SC), which is a static graph and physically wired by neuronal fibers, and functional connectivity (FC) in the brain, which is a dynamic graph and supported by neural circuit overlaid on SC topology . Nevertheless, the graph learning approach of physical neural pathways of SC coupled with FC is rare in related works .

The advancement of diffusion-weighted imaging (DWI) technology enables the _in-vivo_ measurement of physical region-to-region connections through neuronal fibers (aka. SC). Multiple lines of neuroscience finding suggest that high-level cognition and behavior emerge from the remarkable SC-FC coupling mechanism, making the in-depth understanding of the interplay between SC and FC become the gateway to reverse engineering human mind . To that end, a plethora of computational models have been proposed over the past decade, including biophysical models , graph harmonics , network communications , multivariate statistical technique , and deep learning-based structure-function mapping . However, the complex relationship between structural and functional connectivity is still elusive , particularly evidenced by the lack of direct physical pathways (formed by SC in Fig. 1 orange box) between two brain regions that exhibit functional co-activation (indicated by FC in Fig. 1 green box) . Although the topology of SC does not necessarily always aligned with the counterpart of FC motivating previous related works, there is a converging consensus that each FC instance is supported by a sub-graph of SC, as shown in Fig. 1 orange box, where blue links constructing a path sub-graph represent the neural pathway that physically supports the red link.

We strike on this outstanding neuroscience question by lifting the concept of univariate coupling, which is limited to the correspondence between a direct link of SC and another direct link of FC, to a new paradigm of multivariate SC-FC coupling mechanism that models how the ubiquitous FC instance is associated with the detour pathway on SC topology. As shown in green box of Fig. 1, the red line represents the direct FC link between region \(\#1\) and \(\#2\) while the collection of blue lines indicates the corresponding detour pathway of SC. Although the whole-brain topology remains unchanged as brain function evolves, the functional co-activation over time is dynamically supported by different neural pathways of SC. Note, the direct FC link and SC detour form a cyclic loop inherited from both SC and FC topology. Such conceptualization is supported by various neuroscience findings that synchronization of neural activity between two brain regions is fundamentally supported by the underlying neural circuitry established by structural connectivities .

In the perspective of machine learning, as shown in the middle of Fig. 1, the overarching goal is to establish a mapping function between neuroimaging data (SC only, FC only, or both) to the phenotypic traits (such as cognitive tasks). Due to the complex nature of human cognition, however, current deep models encounter several significant challenges. First, it is less common to use the static SC only for the prediction of evolving cognitive states, largely due to the ill-posed setting which boils down to a one-to-many mapping . Alternatively, tremendous efforts have been made to predict cognitive states based on time series of neural activity  and FC topology . However, it has been frequently reported that massive inter-subject variations of FC often predominate the intrinsic task-relevant patterns, such variations in real-world data are demonstrated in Sec. 2.1. Thus, current learning-based approaches have difficulties in scaling up to large-size population data. Furthermore, limiting consideration to either SC or FC alone fails to capture the holistic nature of the brain as a dynamic system, resulting in existing approaches having limited power to uncover new insight of complex relationship between SC and FC . In this regard, it is natural to combine the information of SC and FC in a multi-modality learning scenario . In general, current research focuses on information fusion at node or link level. Few attention has been paid to integrating SC and FC by combining the power of machine learning and insight of cognitive neuroscience.

Taken together, we propose a novel deep model, coined _NeuroPath_, to (1) enhance the machine performance of predicting cognitive status using both SC and FC information and (2) uncover new neuroscience underpinning of SC-FC coupling mechanism. In a nutshell, we conceptualize that the effective way to advance our current understanding of cognitive neuroscience is to characterize the latent SC-FC coupling mechanism from neuroimaging data. To land this conceptualization into an end-to-end deep model, we put the spotlight on devising a new multi-head self-attention (MHSA) component by capitalizing on the multivariate SC-FC coupling mechanism. As shown in Fig. 1 grey box, nodes of multiple paths detouring an FC link on SC are transformed respectively by multiple heads of self-attention in one layer. On top of this, we learn putative feature representations from the cyclic loop capturing complete information on how the underlying functional fluctuations are supported by the neural pathway (aka. SC detour) with different lengths.

Our major contribution has three folds. _First_, we present a novel multivariate SC-FC coupling mechanism that allows us to develop an explainable deep model with great neuroscience insight and guarantee from graph theory. _Second_, we present a Transformer-based deep model that is scalable to utilize existing large population of neuroimaging data. _Third_, we have validated our _NeuroPath_ on large-scale public datasets with a total of 10,886 fMRI scans including Human Connectome Project (HCP), UK Biobank (UKB), Alzheimer's Disease Neuroimaging Initiative (ADNI), and Open Access Series of Imaging Studies (OASIS). We have evaluated (1) the accuracy for predicting phenotypic traits (cognitive status in healthy brains and disease risk for aging brains) (2) model interpretability in identifying latent neural pathways, and (3) the clinical value of our model in terms of robustness and zero-shot learning, where promising results suggests potential application in computational neuroscience field.

## 2 Preliminaries

### Motivations

Massive inter-subject variations of FC often predominate the intrinsic task-relevant patterns. Take the HCP data  as an example in which the data heterogeneity issue has been harmonized by using standardized imaging protocol. As shown in Fig. 2, we first identify a set of brain regions which exhibit significant difference between resting stage and VISMOTOR tasking  in a paired \(t\)-test using detour degree and FC degree1, respectively, where the identified regions are colored based on \(p\)-values. Next, we examine the location of these regions in each functional sub-networks (manually defined using neuroscience domain knowledge). For comparison, we display the overlap ratio (y-axis) between the number identified regions and the total number of regions in each sub-network (x-axis) at the bottom of Fig. 2. Current neuroscience findings suggest that resting state is relevant to default mode network (red circle) while VISMOTOR task is associated with visual (orange circle) and sensorimotor areas (green circle). In this regard, the detour degree achieves

Figure 1: Planting a novel multivariate SC-FC coupling mechanism to explainable deep model. Orange box: The structural connectivity (SC) denoted by grey links represents the strength of neurological fiber that physically connects two brain regions. SC is relatively static given the neural activities are transient, e.g. cognitive tasks. Green box: The functional connectivity (FC) is commonly considered as the brain network topology  since SC is static for different cognitive tasks. The overlapping area of orange and green boxes: the multivariate SC-FC coupling mechanism, where a neural pathway (detour) is constructed by multiple SC links to support one FC link. Grey box: _NeuroPath_ Transformer using a new MHSA module filtered by adjacency matrices emits the representation of multi-hop detours.

overall higher discrimination power than FC to the extent that most of identified regions are aligned with neuroscience finding with much less false positives in other non-relevant regions. The same findings are observed on diverse populations by gender in Appendix Fig. 8. The evidence shown in Fig. 2 underscores the importance of including SC detour in finding putative functional biomarkers, prompting us to further integrate the SC-FC coupling mechanism into the design of _NeuroPath_.

### Relevant Machine Learning Work for Brain Connectomes

Tremendous efforts have been made to perform graph learning on human connectome data. The most representative work includes graph convolutional network (GCN ) and transformer-based deep models . Recently, most of popular GNN models and their application in neuroscience have been reviewed in .

Inspired by the great success of Transform  in NLP and CV, various graph transformer models have been proposed in graph learning. For example, GraphGPS  and TokenGT  models use either a structure encoding or token of graph elements as the initial graph feature representations. Furthermore, a self-attention gating mechanism is proposed in  using an additional branch of edge embedding to implement the augmentation of self-attention. By integrating original node features and structural embeddings into an augmented self-attention module, Graphormer  shows the same expressibility as conventional graph neural networks (GNN), which has been proved in  that such augmented self-attention is strictly more expressive than low-order WL for distinguishing non-isomorphic graphs . In the following, we present our _NeuroPath_ where the novel biological-inspired self-attention mechanism yields more expressive power of graph representation than Graphormer .

## 3 _NeuroPath_ - A Biological-Inspired Transformer for Human Connectomes

Problem formulationGiven that the detour degree can profile nodes highly associated with functional sub-networks, the problem in this work is formulated as how to plant this neuroscience insight of topological detour from SC-FC coupling into deep neural networks.

**Notations.** Assume SC and FC are denoted by adjacency matrices \(}^{N N}\) and \(}^{N N}\), respectively, where \(A^{(i)}_{ij}\) is the connectivity between \(i^{th}\) and \(j^{th}\) region (\(i,j=1,...,N\)). In practice, SC and FC are calculated by the subject-wise normalized water matter (WM) fiber counts and the Pearson's correlation coefficient of neural signals, respectively. Furthermore, we use \(}^{()}\) to denote the binary adjacency matrix after high-pass filtering and adding self-loop for either SC or FC. Node attribute is denoted by \(^{N C}\), where \(C\) is the feature dimension.

**Definition of detour in the context of SC-FC coupling.** To capture multi-scale topology, we employ random walk on graph of SC, yielding a set of multi-hop detour adjacency matrices as follows:

**Definition 3.1** (Detour adjacency matrix).: \(^{h}\), a binary matrix shapes of \(N N\) and stores if a link of FC is associated with a \(h\)-hop topological detour, where a 1-hop detour is equivalent to an edge.

It is obtained by element-wise production between binary matrices \(^{h}:=((}^{})^{h}>0)( }^{})\), where \(1 h H\), and \(H\) is the maximum length of detour.

Figure 2: Motivation of integrating SC-FC coupling in neural networks. Top: Brain regions manifesting significant resting state vs VISMOTOR difference using detour degree and FC degree. Color indicate the \(p\)-values (\(0 p 0.05\)) in paired _t_-test. Bottom: The overlap ratio (y-axis) between the number of identified significant regions and the total number of brain regions in each pre-defined functional sub-networks (x-axis). Specifically, we examine the identified regions in default mode (red circle/box), visual (orange circle/box), and sensorimotor (green circle/box) networks since they are closely associated with resting stage vs VISMOTOR difference.

Note that \(^{h}\) avoids finding all simple paths by our model, it significantly reduces computational costs with sufficient power for the neural pathways representation as discussed in Sec. 3.2.

### Network Architecture of _NeuroPath_

_NeuroPath_ is designed with twin branch as shown in Figure 3, where two branches in the model have identical frameworks of the multi-head self-attention (MHSA) from the Transformer encoder . This twin branch is designed for feature representation to fuse SC and FC information by being consistent between FC link representation and SC detour representation. Given a set of learnable parameters \(},}^{(HC) C}\) and \(}_{h},}_{h},}_{h},}_{h}, }_{h},}_{h}^{C C}\) where \(h=1,,H\), \(H\) is head number of MHSA, and \(C\) denotes feature dimension, the branch TD-MHSA is then defined as

\[f_{TD}()=(}_{1},,}_{H})}, \]

where \(}_{h}=((}_{h})(}_{h})^{T}+f_{mask}(^{h}))(}_{h})\). Similarly, the FC-MHSA branch is defined as

\[f_{FC}()=(}_{1},,}_{H})}, \]

where \(}_{h}=((}_{h})(}_{h})^{T}+f_{mask}(}^{}))(}_{h})\). Adding masks to attention maps is a mature approach for only involving interested nodes in the self-attention mechanism. To achieve this, \(f_{mask}\) here is defined as filling negative infinities to false slots and zeros to true slots of the binary adjacency matrix so that \(\) can ignore false slots in both branches.

Loss function during training is set as the downstream application objective along with the consistency constraint loss \(_{TD}\), which is defined as

\[_{TD}=||f_{TD}()-f_{FC}()||^{2}. \]

Taking classification as an example, the final loss \(=(label,)+_{TD}\), where the logits \(=^{-}}^{} ^{-}f_{TD}()\) with learnable parameters \(^{C n}\), \(n\) is class number and \(\) is degree of brain network adjacency \(}^{}\).

### Neural Pathway Representation by _NeuroPath_

TD-MHSA strictly follows the pathway of topological detour after SC-FC coupling to produce node features hop-by-hop corresponding to each head of self-attention. In fact, the \(i\)-th node feature representation, \(f_{TD}()_{i}\), is the weighted sum of nodes among half of the neural pathways in the range of \(H\)-hop after expanding Eq. 1. Detailed proof can be found in Appendix.

**Fact 3.1**.: _The top pathway representations are obtained by \(*{arg\,max}_{j,h}(_{j}_{ij}}_{h}}_{i j})\), where \(\) denotes the softmax of self-attention, \(_{i}^{H}\) is a set of node index of a path and \(_{i}^{H}\) is the node collection of neural pathways within \(H\)-hop starting at \(i\)-th node._

Fact 3.1 indicates the power of our _NeuroPath_ for high-order graph substructure. PathNN  models all simple paths has \(O(N^{H})\) computational complexity by sorting all paths in advance. In contrast,

Figure 3: Framework of twin branch, topological detour filtered multi-head self-attention (TD-MHSA) and functional connectivity filtered multi-head self-attention (FC-MHSA), for node feature transformation in _NeuroPath_, where training/testing readout indicates different branch is used for training/testing stage.

_NeuroPath_ can model important paths using only \(O(N^{2})\) computational complexity and does not require any pre-computation of high-order topology.

Regarding the neuroscience knowledge that FC is relatively denser than SC with the evidence of significant indirect SC links , FC adjacency is also denser than the TD adjacency according to the Def. 3.1. Meanwhile, the consistency constraint \(_{TD}\) cooperates with the twin branch so that FC-MHSA produces the expressive node feature representation as well. Consequently, existing states of FC-MHSA can hold the same power of TD-MHSA by a consistent feature representation, and hence benefit the prediction by this SC-FC coupling.

## 4 Experimental Results

The experiments are designed for the following four Research Questions (RQ). **RQ1:** How is performance on neural activity recognition and cognition disordering disease diagnosis compared to state-of-the-art (SOTA) brain models and graph transformers? **RQ2:** Can the brain network representation by _NeuroPath_ being consistent on zero-shot learning experiments? **RQ3:** Does performance enhancement by _NeuroPath_ align with intuitions by ablations of model framework and neural pathway length? **RQ4:** What is the pattern of neural pathways contributing to prediction? To thoroughly answer those questions, four public datasets are used in our experiments. Detailed data preprocessing and profiles can be found in Appendix.

**The Lifespan Human Connectome Project Aging (HCPA)** dataset  is instrumental in task recognition research, offering a comprehensive view of the aging process. It includes data from 717 subjects, encompassing both fMRI (\(n\)=4,863) and DWI (\(n\)=716). It includes data from three brain tasks associated with memory and sensory-motor: VISMOTOR, CARIT, and FACENAME, and the resting state. In the related experiments, these tasks are treated as (1) a four-class classification problem and (2) resting/tasking classification for zero-shot learning. We partition brain regions using AAL atlas  in experiments except for ablation studies using Gordon atlas .

**United Kingdom's Biobank (UKB)** dataset is a large-scale dataset with MRI data. There are fMRI (\(n\)=5,483) and DWI (\(n\)=3,162) preprocessed by the same algorithm as HCPA. It includes data from one brain task that engages cognitive and sensory-motor . Data is treated as a two-class classification in the following experiments. Brain regions are partitioned by Gordon atlas .

**Alzheimer's Disease Neuroimaging Initiative (ADNI)** dataset  serves as an invaluable resource, featuring a collection of pre-processed fMRI (\(n\)=138) and DWI (\(n\)=135) with AAL parcellation in our experiment. Additionally, ADNI includes clinical diagnostic labels, encompassing a spectrum of cognitive states: Cognitive Normal (CN), Subjective Memory Complaints (SMC), Early-Stage Mild Cognitive Impairment (EMCI), Late-Stage Mild Cognitive Impairment (LMCI), and Alzheimer's Disease (AD). Considering the data balance issue, we simplified these categories into two broad groups based on disease severity: we combined CN, SMC, and EMCI into 'CN' group, while LMCI and AD were grouped as the 'AD' group.

**Open Access Series of Imaging Studies (OASIS)** dataset  presents a substantial collection of data from 924 subjects, comprising 3,322 fMRI sessions in total. Among the dataset, fMRI (\(n\)=402) and DWI (\(n\)=362) are pre-processed with Destrieux parcellation . Our experiment focused on binary classification: subjects in preclinical stages of AD or those manifesting dementia-related conditions are under the 'AD' group, while healthy individuals are under the 'CN' group.

All datasets are split as train/validation in a 5-fold cross-validation according to the subject index to prevent data leakage. Node attributes of brain network setting as Blood-Oxygen Level Dependent (BOLD) signal or correlation (CORR) between BOLD signals are performing vary on different datasets . Furthermore, the deep model performance is also affected by using a short-length or full-length BOLD which is considered a dynamic or static brain network, respectively . To evaluate _NeuroPath_ under all situations, four combinations of CORR/BOLD and static/dynamic are all tested in our experiments.

Competitive methods, two baselines (MLP and GCN), three SOTA brain models (BrainGNN , BNT , and BoIT ), and two SOTA general graph transformers (Graphormer  and NAG-phormer ) are chosen for comparison with _NeuroPath_, where MLP and GCN both have one layer of the vanilla framework followed by batch normalization and activation for feature representation and one layer of graph convolution for graph prediction. All train/validate settings such as random seed and learning rate are set as the same.

    &  &  &  &  \\   & static & dynamic & static & dynamic & static & dynamic & static & dynamic \\   \\ MLP & 96.01\({}_{ 0.50}\) & 92.57\({}_{ 0.32}\) & 93.42\({}_{ 0.58}\) & 83.64\({}_{ 1.33}\) & 99.00\({}_{ 0.15}\) & 97.70\({}_{ 0.32}\) & 99.05\({}_{ 0.48}\) & 96.42\({}_{ 0.60}\) \\ GCN & 95.85\({}_{ 0.93}\) & 91.95\({}_{ 0.45}\) & 92.94\({}_{ 0.58}\) & 84.60\({}_{ 0.45}\) & 99.00\({}_{ 0.22}\) & 97.54\({}_{ 0.24}\) & 99.31\({}_{ 0.33}\) & 93.39\({}_{ 0.71}\) \\  BrainGNN & 90.85\({}_{ 1.35}\) & 86.06\({}_{ 2.64}\) & 89.38\({}_{ 2.88}\) & 72.62\({}_{ 3.33}\) & 97.54\({}_{ 0.52}\) & 95.32\({}_{ 1.68}\) & 90.33\({}_{ 2.72}\) & 86.11\({}_{ 4.04}\) \\ BNT & 97.92\({}_{ 0.65}\) & 94.18\({}_{ 0.35}\) & 92.57\({}_{ 1.19}\) & 86.55\({}_{ 0.37}\) & 98.71\({}_{ 0.34}\) & 97.15\({}_{ 0.49}\) & 98.64\({}_{ 0.18}\) & 95.98\({}_{ 0.44}\) \\ BoI T & 96.40\({}_{ 0.41}\) & 91.68\({}_{ 0.38}\) & 95.78\({}_{ 0.55}\) & 91.92\({}_{ 0.69}\) & 99.13\({}_{ 0.33}\) & 97.61\({}_{ 0.23}\) & 99.29\({}_{ 0.26}\) & 98.22\({}_{ 0.31}\) \\  Graphormer & 78.80\({}_{ 5.89}\) & 78.73\({}_{ 1.91}\) & 59.63\({}_{ 6.07}\) & 65.01\({}_{ 3.84}\) & 92.76\({}_{ 1.05}\) & 81.98\({}_{ 9.83}\) & 86.82\({}_{ 1.24}\) & 55.56\({}_{ 21.08}\) \\ NAGphormer & 93.67\({}_{ 0.96}\) & 90.73\({}_{ 0.64}\) & 94.76\({}_{ 1.15}\) & 82.02\({}_{ 1.77}\) & 98.79\({}_{ 0.35}\) & 96.83\({}_{ 0.36}\) & 99.22\({}_{ 0.36}\) & 92.90\({}_{ 0.69}\) \\ _NeuronPath_ & 96.69\({}_{ 0.54}\) & 92.76\({}_{ 0.52}\) & 95.03\({}_{ 1.93}\) & 87.54\({}_{ 0.77}\) & 99.22\({}_{ 0.24}\) & 97.77\({}_{ 0.21}\) & 99.59\({}_{ 0.21}\) & 94.12\({}_{ 0.75}\) \\   \\ MLP & 96.01\({}_{ 0.49}\) & 92.52\({}_{ 0.35}\) & 93.42\({}_{ 0.58}\) & 82.86\({}_{ 1.68}\) & 99.00\({}_{ 0.15}\) & 97.69\({}_{ 0.32}\) & 99.05\({}_{ 0.49}\) & 96.42\({}_{ 0.60}\) \\ GCN & 95.85\({}_{ 0.95}\) & 91.90\({}_{ 0.41}\) & 92.98\({}_{ 0.60}\) & 83.95\({}_{ 0.37}\) & 99.00\({}_{ 0.22}\) & 97.53\({}_{ 0.24}\) & 99.31\({}_{ 0.33}\) & 93.36\({}_{ 0.71}\) \\  BrainGNN & 90.92\({}_{ 1.41}\) & 85.43\({}_{ 3.37}\) & 89.38\({}_{ 2.92}\) & 64.40\({}_{ 0.67}\) & 97.54\({}_{ 0.52}\) & 95.30\({}_{ 1.71}\) & 90.35\({}_{ 2.70}\) & 86.09\({}_{ 4.18}\) \\ BNT & 97.92\({}_{ 0.66}\) & 94.16\({}_{ 0.35}\) & 92.57\({}_{ 1.22}\) & 86.45\({}_{ 0.40}\) & 98.71\({}_{ 0.34}\) & 97.15\({}_{ 0.49}\) & 98.64\({}_{ 0.18}\) & 95.97\({}_{ 0.43}\) \\ BoI T & 96.38\({}_{ 0.43}\) & 91.66\({}_{ 0.39}\) & 95.78\({}_{ 0.57}\) & 91.76\({}_{ 0.78}\) & 99.13\({}_{ 0.34}\) & 97.60\({}_{ 0.23}\) & 99.29\({}_{ 0.26}\) & 98.22\({}_{ 0.31}\) \\  Graphormer & 77.29\({}_{ 7.15}\) & 75.26\({}_{ 2.66}\) & 53.05\({}_{ 5.81}\) & 57.04\({}_{ 1.46}\) & 92.67\({}_{ 10.25}\) & 80.19\({}_{ 11.35}\) & 86.54\({}_{ 13.03}\) & 50.12\({}_{ 27.58}\) \\ NAGphormer & 93.69\({}_{ 0.95}\) & 90.64\({}_{ 0.68}\) & 94.76\({}_{ 1.16}\) & 81.06\({}_{ 2.03}\) & 98.79\({}_{ 0.35}\) & 96.82\({}_{ 0.35}\) & 99.22\({}_{ 0.36}\) & 92.88\({}_{ 0.68}\) \\ _NeuroPath_ & 96.70\({}_{ 0.54}\) & 92.72\({}_{ 0.54}\) & 95.09\({}_{ 1.86}\) & 87.03\({}_{ 0.95}\) & 99.22\({}_{ 0.24}\) & 97.77\({}_{ 0.21}\) & 99.59\({}_{ 0.21}\) & 94.11\({}_{ 0.75}\) \\   

Table 1: Performance comparison on HCPA and UKB datasets. Colored numbers indicate ranking in the first, second, and third place.

    &  &  &  &  \\   & static & dynamic & static & dynamic & static & dynamic & static & dynamic \\   \\ MLP & 79.26\({}_{ 10.34}\) & 82.68\({}_{ 5.71}\) & 80.67\({}_{ 7.26}\) & 82.93\({}_{ 6.35}\) & 89.28\({}_{ 3.58}\) & 89.32\({}_{ 3.18}\) & 88.99\({}_{ 3.52}\) & 89.02\({}_{ 3.25}\) \\ GCN & 84.22\({}_

### Performance of Neural Activity Classification

Performance on datasets HCPA and UKB is listed in Table 1. Except for UKB BOLD dynamic, _NeuroPath_ can rank in the top two places under all data settings on the accuracy and the weighted F1 score. The highest accuracy of neural activity classification on all settings of UKB can be achieved by _NeuroPath_ as 99.59%, while the best by other models, 99.31%, is achieved by the GCN rather than other fancy models implying they are rarely capturing features from neuroscience senses. Regarding HCPA dataset, SOTA brain models have more than double the number of parameters than our model as listed in Appendix. Nonetheless, we can hold the second place for all data settings in HCPA since _NeuroPath_ learn from the physical neural pathways, while the general graph transformers can be even worse than the vanilla MLP and GCN since they do not involve neuroscience knowledge.

### Performance of Cognition Disordering Diagnosis

The performance of AD/CN classification on datasets ADNI and OASIS is listed in Table 2. _NeuroPath_ has the top three performance among all datasets with four different data settings except for the F1 score on dynamic OASIS BOLD. The neuroscience insight of SC-FC coupling benefits _NeuroPath_ achieved the best accuracy on \(5/8\) cases and the best F1 score on \(3/8\) cases. It is worth noting that _NeuroPath_ is the only one that has over 90% accuracy in these experiments. Class unbalance in ADNI and OASIS datasets makes the F1 score lower than accuracy. Nevertheless, _NeuroPath_ has top scores on both two datasets, 83.29% and 87.02%, respectively, under all data settings. Given the challenges of more neural pathways present in dynamic graphs that have a higher degree as listed in Appendix, our performance slightly drops to against others. In summary, _NeuroPath_ shows superior performance than existing SOTA models on static graphs of various data with the benefit of our novel multivariate SC-FC coupling.

### Zero-shot Learning

Despite neural activity classification and cognitive disordering diagnosis are two types of experiments usually tested in computational neuroscience research, zero-shot learning by training and validating the model on one dataset and testing on another dataset is rarely present in the field. Since for both resting/tasking and AD/CN classification, we all have two datasets, it is feasible to test our explainable deep model by zero-shot learning to show the clinical value. The experimental setting is consistent as above with a 5-fold cross-validation to choose the best model state on the train-val dataset, and then test it on validating a set of the corresponding fold of another dataset.

Given that the three SOTA brain models are all sensitive to the node number of the graph, they are not compatible with zero-shot learning. Therefore, F1 scores are listed in Table 4 in comparison against two general graph transformers, which are designed for various vertex-cardinality. It is worth highlighting that our model outperforms all competitors under different data settings except for ADNI\(\)OASIS dynamic. Specifically, _NeuroPath_ can surpass the best of others with a 16.8 score for HCPA\(\)UKB static. Although the performance of zero-shot learning by _NeuroPath_ still has an observable gap to the fully supervised version listed in Table 1 and 2, results here show that the neural pathway pattern learned by _NeuroPath_ is more consistent than FC pattern across datasets.

### Ablation of Hyperparameter \(H\)

Since the length of the neural pathway is limited by the head number of two branches in _NeuroPath_, the ablation of the head number in MHSA leads to various performances of our model. As shown in Fig. 4, we set head number \(H\) from 1 to 8 keeping all other settings remain the same. The green

    &  &  \\   & static & dynamic & static & dynamic \\  Graphormer & 77.63\({}_{ 2.89}\) & 77.24\({}_{ 7.34}\) & 79.69\({}_{ 7.71}\) & **83.55\({}_{ 6.90}\)** \\ NAGphormer & 73.11\({}_{ 5.90}\) & 78.09\({}_{ 7.24}\) & 69.63\({}_{ 10.99}\) & 78.09\({}_{ 7.08}\) \\ _NeuroPath_ & **79.78\({}_{ 3.53}\)** & **81.57\({}_{ 7.24}\)** & **80.03\({}_{ 8.50}\)** & 79.65\({}_{ 6.35}\) \\    &  \\   & static & dynamic & static & dynamic \\  Graphormer & 39.09\({}_{ 28.14}\) & 50.97\({}_{ 4.01}\) & 57.78\({}_{ 14.50}\) & 64.36\({}_{ 7.90}\) \\ NAGphormer & 74.49\({}_{ 4.01}\) & 70.17\({}_{ 1.31}\) & 89.77\({}_{ 0.94}\) & 73.44\({}_{ 0.70}\) \\ _NeuroPath_ & **91.29\({}_{ 2.10}\)** & **72.08\({}_{ 2.15}\)** & **90.61\({}_{ 3.65}\)** & **75.62\({}_{ 2.98}\)** \\   

Table 4: Zero-shot learning between four datasets using BOLD as node attributes under different data settings, where resting/tasking state classification is tested for HCPA and UKB datasets, F1 scores are listed, and ‘**bold**’ and ‘**underline**’ denote the first and the second rank, respectively.

curves shown in Fig. 4 demonstrate clear peaks at \(H=7\) on datasets HCPA and UKB that are processed with a finer parcellation of 333 regions. In comparison, for the atlas used on datasets ADNI and OASIS has no more than 200 regions, the peak disappeared with a flat trend of F1 score suggesting longer pathways are less contributing to the prediction under fewer regions. This is aligned with the nature of more hops needed to construct the same neural pathway where regions are more but smaller on HCPA and UKB than ADNI and OASIS.

### Ablation of Model Architecture

Twin branch is a core design of _NeuroPath_ to plant the insight of SC-FC coupling to deep model. The ablation of using none or a single branch can illustrate the effectiveness of our design. As listed in Table 5, _NeuroPath_ with twin branch has the best performance on all datasets except for the F1 score on OASIS. Despite TD-MHSA using the detour adjacency that can detect brain communities as mentioned in Sec. 2.1, SC-FC fused feature representation by using the consistency constraint \(_{TD}\) for twin branch has more contribution to the performance.

### Ablation of Model Depth

Performance comparison between models with different layer numbers is listed in Table 6. Most of competing models dropped on performance when increasing the layer number to 16, e.g., Graphormer dropped under 50 on HCPA and UKB datasets. In contrast, _NeuroPath_ is more stable than others and has the best average ranking.

### Ablation of Graph Building

Performance comparison between models with different edge threshold to construct brain network is listed in Table 7. Similarly, existing methods dropped on performance when graph is too dense or too sparse as the threshold of Pearson coefficient changed, which is an empirical hyperparameter. _NeuroPath_ can keep the best average ranking in this case.

### Pattern of Neural Pathway Contributing to Prediction

As we introduced in Sec. 3.2, _NeuroPath_ is in fact weighting neural pathways to obtain the feature representation of the brain network. Therefore, the neural pathways can be sorted by their weights

    &  &  &  &  \\ Layer \# & 4 & 8 & 16 & 4 & 8 & 16 & & \\  BNT & 91.81 & 93.41 & 93.28 & 3.67 & 88.63 & 96.32 & 97.45 & 3.00 \\ BoIT & 97.01 & 97.81 & 88.23 & 2.33 & 81.36 & 89.20 & 89.84 & 4.00 \\ Graphormer & 64.08 & 47.01 & 50.84 & 5.00 & 43.42 & 43.44 & 59.46 & 5.00 \\ NAGphorner & 96.89 & 97.26 & 97.22 & 2.33 & 99.24 & 98.95 & 99.20 & 2.00 \\ _NeuroPath_ & 97.76 & 97.72 & 96.60 & **1.67** & 99.59 & 99.61 & 99.44 & **1.00** \\   & ADNI &  &  &  \\  BNT & 76.39 & 75.91 & 77.28 & 3.67 & 85.32 & 85.96 & 85.21 & 3.33 \\ BoIT & 75.93 & 78.67 & 78.23 & 2.67 & 85.30 & 84.55 & 85.55 & 3.67 \\ Graphormer & 78.58 & 74.12 & 74.12 & 4.00 & 84.45 & 83.87 & 83.87 & 5.00 \\ NAGphorner & 75.86 & 77.15 & 78.44 & 3.00 & 86.05 & 86.49 & 85.78 & 1.67 \\ _NeuroPath_ & 78.93 & 78.42 & 78.32 & **1.67** & 86.16 & 86.77 & 85.78 & **1.00** \\   

Table 6: F1 scores by models with different layer numbers on four datasets. ‘**Bold**’ and ‘underline’ denote the first and the second place of the average rank, respectively.

Figure 4: Ablation study of various lengths of the neural pathway that is visible to _NeuroPath_. Static BOLD is set as node attributes in this experiment. The blue shade is the range of error bars and the green lines are average F1 scores.

    &  &  &  &  \\   & Accuracy & F1 score & Accuracy & F1 score & Accuracy & F1 score & Accuracy & F1 score \\  None & 82.42\(\)5.58 & 78.65\(\)7.37 & 88.52\(\)3.48 & 86.19\(\)3.81 & 97.53\(\)0.50 & 97.53\(\)0.51 & 99.53\(\)0.22 & 99.53\(\)0.22 \\ w/ TD-MHSA & 82.74\(\)7.88 & 77.51\(\)9.39 & 89.05\(\)3.99 & 86.11\(\)4.32 & 97.33\(\)0.44 & 97.34\(\)0.43 & 99.10\(\)0.13 & 99.10\(\)0.13 \\ w/ FC-MHSA & 81.93\(\)3.25 & 80.97\(\)4.20 & 89.31\(\)4.36 & **86.58\(\)**8.87 & 97.72\(\)0.34 & 97.72\(\)0.34 & 99.25\(\)0.18 & 99.25\(\)0.18 \\ w/ both & **85.56\(\)4.97** & **83.29\(\)**4.45 & **90.01\(\)**3.42 & 86.37\(\)0.03 & **98.23\(produced by our model. As shown in Fig. 5, we visualized three pathways corresponding to the same three functionally connected node pairs (blue nodes in Fig. 5), where links that have the same color are members of the same pathway. To show the neural pathway pattern of diseased brain topology, the three functionally connected node pairs are selected from FC links that exhibit significant difference (\(p 0.05\)) between AD and CN subjects from the OASIS dataset in a \(t\)-test. We exclude the influence of inter-subject variations of FC mentioned in Sec. 2.1 by narrowing FC links in the \(t\)-test solely between regions of the subcortical, entorhinal cortex, occipital lobe, and parietal lobe, where those brain structures are associated with the progression of AD . In comparison of pathway visualization in Fig. 5, it is obvious that the AD subject demands a longer SC detour to support the same direct FC link than CN subjects which only need shorter pathways (within two hops). This observation suggests a diseased human connectome might need a longer detour to support normal brain function since the brain network could rewire neurological fibers from other normal regions to fetch up lesion regions . Therefore, this visualization is neuroscience evidence of the interpretability of _NeuroPath_.

### Computational Costs

The computational costs can be indicated by the practical running time and the learnable parameter amount as listed in Table 8. Although Graphormer and NAGphormer are two models with lower parameter numbers than _NeuroPath_, they have slower training and testing than _NeuroPath_ with pre-processing leading to more computing time. This demonstrates the efficiency of _NeuroPath_.

## 5 Conclusion

In this work, we propose _NeuroPath_, a graph transformer to model the physical neural pathway by our novel multivariate SC-FC coupling mechanism and learn the relationship between neural pathways and brain functions. The framework of _NeuroPath_ driven by the neuroscience insight can effectively produce SC-FC coupled feature representation of multi-hop neural pathways from the twin branch design. Compared to SOTA brain models and graph transformers on large-scale datasets including HCP and UKB under various data settings, our experiments have not only demonstrated the superior performance of _NeuroPath_ in neural activity classification and cognitive disordering diagnosis but also provided great interpretability. Planting the proposed multivariate SC-FC coupling into the design of _NeuroPath_ enables it to be not only applicable for zero-shot learning on unseen datasets but also to a better performance than general SOTA models on resting/tasking classification and AD diagnosis. By visualizing the top-1 neural pathway contributing to the prediction by _NeuroPath_, more interpretability is brought to our performance on AD diagnosis, and the observation of visualization agrees with the hypothesis that it needs a longer structural detour to support a functional but diseased human connectome. Modeling neural pathways shows us a clue of fundamental neuroscience models to decipher the relationship between brain structural and functional topology.

    &  &  &  &  \\  FC threshold & 0.3 & 0.5 & 0.7 & 0.3 & 0.5 & 0.7 & & \\  BNT & 95.73 & 92.57 & 84.51 & 4.00 & 76.41 & 98.64 & 94.46 & 4.33 \\ BoT & 87.02 & 95.78 & 94.68 & 3.00 & 86.98 & 99.29 & 87.04 & 3.67 \\ Graphormer & 90.41 & 53.05 & 88.43 & 4.33 & 97.76 & 86.54 & 96.73 & 3.67 \\ NAGphormer & 96.08 & 94.76 & 96.85 & 2.33 & 97.80 & 99.22 & 98.78 & 2.33 \\ _NeuroPath_ & 97.57 & 95.09 & 97.32 & **1.33** & 99.27 & 99.59 & 99.15 & **1.00** \\    &  &  &  \\  BNT & 77.74 & 80.16 & 77.92 & **1.67** & 85.14 & 85.32 & 86.05 & 3.67 \\ BoT & 74.33 & 76.68 & 76.53 & 4.00 & 84.98 & 84.91 & 84.67 & 4.67 \\ Graphormer & 75.82 & 77.78 & 75.17 & 3.33 & 86.23 & 85.44 & 87.15 & 2.00 \\ NAGphormer & 72.55 & 75.40 & 77.29 & 4.67 & 86.32 & 83.87 & 85.78 & 3.67 \\ _NeuroPath_ & 78.36 & 77.35 & 79.49 & **1.67** & 86.59 & 87.02 & 86.13 & **1.33** \\   

Table 7: F1 scores by models with different FC thresholds to build brain networks. ‘**Bold**’ and ‘underline’ denote the first and the second place of the average rank, respectively.

Figure 5: The visualization of the top-1 neural pathway that corresponds to a significant FC link contributing to the prediction by _NeuroPath_ on OASIS dataset.

    & Param \# & Preproc. & Train & Test \\  BrainGNN & 7.30M & - & 7.24 & 2.61 \\ BNT & 1.57M & - & 1.82 & 0.64 \\ BoT & 1.58M & - & 3.83 & 1.83 \\ Graphormer & 0.30M & 270 & 2.79 & 0.90 \\ NAGphormer & 0.26M & 40 & 3.92 & 1.85 \\ _NeuroPath_ & 0.69M & - & 1.61 & 0.67 \\   

Table 8: Computational complexity in our experiments, where computing time is the average on UKB dataset with unit the millisecond per graph data.

Acknowledgments

Thanks to the Foundation of Hope and NIH grant AG068399.