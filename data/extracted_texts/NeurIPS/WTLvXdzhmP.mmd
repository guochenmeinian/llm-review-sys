# Statistical Estimation in the Spiked Tensor Model via the Quantum Approximate Optimization Algorithm

Statistical Estimation in the Spiked Tensor Model via the Quantum Approximate Optimization Algorithm

 Leo Zhou

Walter Burke Institute for Theoretical Physics and the IQIM

California Institute of Technology, Pasadena, CA 91125

Electrical and Computer Engineering Department

University of California, Los Angeles, CA 90095

leoxzhou@ucla.edu

Joao Basso

Department of Mathematics

University of California, Berkeley, CA 94720

Quantum Artificial Intelligence Lab (QuAIL)

NASA Ames Research Center, Moffett Field, CA 94035

Research Institute for Advanced Computer Science (RIACS)

USRA, Mountain View, CA 94043

joao.basso@berkeley.edu

Song Mei

Department of Statistics and Department of EECS

University of California, Berkeley, CA 94720

songmei@berkeley.edu

###### Abstract

The quantum approximate optimization algorithm (QAOA) is a general-purpose algorithm for combinatorial optimization that has been a promising avenue for near-term quantum advantage. In this paper, we analyze the performance of the QAOA on the spiked tensor model, a statistical estimation problem that exhibits a large computational-statistical gap classically. We prove that the weak recovery threshold of \(1\)-step QAOA matches that of \(1\)-step tensor power iteration. Additional heuristic calculations suggest that the weak recovery threshold of \(p\)-step QAOA matches that of \(p\)-step tensor power iteration when \(p\) is a fixed constant. This further implies that multi-step QAOA with tensor unfolding could achieve, but not surpass, the asymptotic classical computation threshold \((n^{(q-2)/4})\) for spiked \(q\)-tensors. Meanwhile, we characterize the asymptotic overlap distribution for \(p\)-step QAOA, discovering an intriguing sine-Gaussian law verified through simulations. For some \(p\) and \(q\), the QAOA has an effective recovery threshold that is a constant factor better than tensor power iteration. Of independent interest, our proof techniques employ the Fourier transform to handle difficult combinatorial sums, a novel approach differing from prior QAOA analyses on spin-glass models without planted structure.

## 1 Introduction

We study statistical estimation in the spiked tensor model, where we observe a \(q\)-tensor \(^{n^{q}}\) in \(n^{q}\) dimensions given by

\[=(_{n}/n^{q/2})^{ q}+(1/) ^{n^{q}}.\] (1.1)Here \((\{+1,-1\}^{n})\) is some hidden signal,1 and \((^{n})^{ q}\) is a noise tensor whose entries are i.i.d. standard Gaussian \((0,1)\). The parameter \(_{n}>0\) is the _signal-to-noise ratio_ (SNR). The goal is to estimate \(\) given only access to \(\). That is, we seek an estimator \(}(^{n})^{ q}^{n-1}()\) achieving nontrivial overlap with the signal:

\[_{n}[}(), ^{2}/n^{2}]>0.\] (1.2)

This task is known as _weak recovery_ in the spiked tensor model.

The spiked tensor model is a famous problem because it exhibits a huge computational-statistical gap, referring to regimes of SNR where the statistical estimation problem is information-theoretically solvable, but no efficient algorithm has been found. For example, it is known that the Bayes optimal estimator achieves non-trivial overlap with the signal \(\) when \(_{n}>_{}\) for some constant threshold \(_{}=(1)\), whereas the problem is information-theoretically impossible when \(_{n}_{}\). Furthermore, the maximum likelihood estimator also achieves non-trivial overlap with the signal when \(_{n}>_{}\) for some \(_{}=(1)\). However, the best-known polynomial-time classical algorithms for computing a non-trivial estimator require a much higher SNR of \(_{n}=(n^{(q-2)/4})\). These include tensor power iteration, gradient descent, approximate message passing, and spectral methods with tensor unfolding . Indeed, assuming the secret leakage planted clique conjecture, Ref.  proves an \((n^{(q-2)/4})\) lower bound on the SNR needed by any polynomial-time classical algorithm. See Fig. 1 for an illustration of the different SNR thresholds and Section 2.1 for more background.

On the other hand, quantum algorithms are widely believed to have computational advantages over classical algorithms for many problem classes. In particular, we focus on the Quantum Approximate Optimization Algorithm (QAOA) , a general-purpose quantum optimization algorithm that can be applied to optimize any objective function on bit-strings. The QAOA has received an enormous amount of attention in the quantum computing community for several reasons. First, the QAOA is simple and allows efficient implementation on near-term quantum hardware with many applications . Additionally, the QAOA is computationally universal , and its generalization can realize other powerful algorithms such as the quantum singular value transform . Under common complexity-theoretic assumptions, no classical device can efficiently simulate the output distribution of the QAOA even at shallow depth . Furthermore, the QAOA is guaranteed to find optimal solutions when its number of steps (or depth) diverges . Nevertheless, analyzing the asymptotic performance of QAOA remains challenging: classical simulation of the algorithm is limited to small problem dimension \(n\), and analytical computations are often highly non-trivial . Given the enormous \((n^{(q-2)/4})\) computational-statistical gap in the spiked tensor model (compared to e.g., the constant factor gap in spin-glass optimization ), it is an interesting open question whether the QAOA, as a realistic quantum algorithm with asymptotic convergence guarantees, can provide any computational advantages.

In this work, we investigate the performance of QAOA for the spiked tensor model. In particular, we choose the log-likelihood objective of spiked tensor \(C()=,^{ q}/n^{(q-2)/2}\). Its maximizer, the maximum likelihood estimator, achieves non-trivial overlap with the signal whenever \(_{n}>_{}=(1)\). While the infinite-step QAOA could compute the maximizer, we are interested in the performance of QAOA when the depth is polynomial in the problem size, and hope that it can surpass the \((n^{(q-2)/4})\) classical threshold. Although some limitations of the QAOA are known for certain random optimization problems in the low-depth regime , these negative results do not apply to the spiked tensor model since they rely on either sparse connectivity or concentration, both of which are absent in the current setting. Here, as a first attempt to bridge the gap in understanding how well a popular quantum algorithm may perform on a classically hard statistical estimation problem, we study the asymptotic behavior of the QAOA on the spiked tensor model in the constant-depth regime, where we are able to obtain rigorous and analytical results.

Our contribution.In this paper, we analyze the signal-to-noise ratio threshold of \(p\)-step QAOA for weak recovery in the spiked tensor model, in the regime of fixed \(p\) and \(n\) approaching infinity. For \(p=1\), we prove the weak recovery threshold is \(_{n}=(n^{(q-1)/2})\), matching that of 1-step tensor power iteration. For \(p>1\), heuristic calculations suggest the threshold is \(_{n}=(n^{(q-2+_{p})/2})\)where \(_{p}=(q-2)/[(q-1)^{p}-1]\), again matching \(p\)-step tensor power iteration. Additionally, given an initialization vector with \(n^{c}/n\) correlation to the signal for \(1/2<c<1\), we prove the weak recovery threshold for 1-step QAOA is \(_{n}=(n^{(1-c)(q-1)})\), identical to 1-step tensor power iteration. These results indicate that constant-step QAOA has the same asymptotic recovery threshold as tensor power iteration in the spiked tensor model. Meanwhile, further heuristic analysis suggests that QAOA with tensor unfolding could achieve the classical computation threshold \((n^{(q-2)/4})\).

Furthermore, we derive the asymptotic distribution of the overlap for \(p\)-step QAOA, revealing an intriguing sine-Gaussian law distinct from \(p\)-step tensor power iteration. Analyzing the second moment, we see that, for certain \((p,q)\) pairs, the QAOA effectively has a recovery threshold that is a constant factor better than tensor power iteration. Since there are classical algorithms that achieve better recovery thresholds than power iteration, it remains an interesting open question whether quantum advantage over the state-of-the-art classical algorithms may be obtained at larger QAOA depths that grow with system size. To our current knowledge, our work is the first to obtain analytical results using the QAOA for a statistical inference problem.

The proof of the sine-Gaussian distribution adopted novel techniques, including using discrete Fourier transforms and the central limit theorem to handle combinatorial summations. The Fourier transform technique also allows us to replace nonlinear polynomials in the exponents with dual variables, leaving linear exponents that become easy in combinatorial sums. These techniques are of independent interest and could be useful for analyzing the QAOA in other models.

## 2 Background and related work

### Spiked tensor model and prior algorithms

The spiked tensor model (1.1) was first introduced as a statistical model for tensor principal component analysis in , where it was studied with a spherical prior \(^{n-1}()\). The information-theoretic threshold for weak recovery under this model with the spherical prior [3; 7; 8] and the Rademacher prior \(\{ 1\}^{n}\) are both \(_{n}=(1)\).

Tensor power iteration.A well-studied classical algorithm for the spiked tensor model is tensor power iteration [2; 10; 33]. Starting from a uniform random initialization \(}_{0}(^{n-1})\), the \(k\)-th iteration is given by \(}_{k}\), where

\[}_{k}=[}_{k-1}^{(q-1)}]/ [}_{k-1}^{(q-1)}]_{2},\ \ \ \ k 1,\ \ \ }_{0}(^{n-1}).\] (2.1)

Here, \([}^{(q-1)}]^{n}\) denotes contracting the order-\(q\) tensor \(^{n^{q}}\) with the order-\((q-1)\) tensor \(}^{(q-1)}^{n^{q-1}}\). It is shown that with \(( n)\) iterations, weak recovery is possible if the SNR satisfies \(_{n}=(n^{(q-2)/2}/(n))\)[10; 33]. However, tensor power iteration does not match the best-known classical algorithms. Furthermore, we remark that rounding the tensor power iteration to \((}_{k})\{ 1\}^{n}\) does not give a better threshold.

Other classical algorithms and related results. showed that the tensor power iteration and approximate message passing algorithms with random initialization can recover the signal provided \(_{n}=(n^{(q-1)/2})\). This SNR threshold was later improved to \(_{n}=(n^{(q-2)/2})\) by [3; 10; 33] for these same methods. The same threshold \(_{n}=(n^{(q-2)/2})\) could also be achieved by gradient

Figure 1: Different thresholds for the spiked tensor model.

descent and Langevin dynamics as proved in . On maximum likelihood estimation for the spiked tensor model with a spherical prior, [5; 6] studied the loss landscape, providing intuition that it contains many saddle points and local minima near the equator, but no bad critical points off the equator.

The best currently known polynomial-time algorithms can achieve a sharp threshold of \(_{n}=(n^{(q-2)/4})\). These include spectral methods with tensor unfolding [2; 11], sum-of-squares algorithms [34; 35; 36], sophisticated iteration algorithms [37; 38; 39], and gradient descent on the smoothed landscape [40; 41].

Another line of research has attempted to prove computational lower bounds in restricted computational models, including low-degree polynomials and statistical query algorithms [42; 43]. Under the secreted leakage planted clique conjecture,  proved that any classical polynomial-time algorithm requires \(_{n}=(n^{(q-2)/4})\) for weak recovery of the signal.

A quantum algorithm by Ref. .To the best of our knowledge, the only prior quantum algorithm proposed for the spiked tensor model with provable guarantees is by Hastings in Ref. . Hastings' algorithm is based on a spectral method for a Hamiltonian on \(M\) bosons over \(n\) modes, living in a Hilbert space of dimension \(n^{M}\), where \(M[n^{(q-2)/4}/_{n}]^{4/(q-2)}(n)\). Finding the dominant eigenvector of this Hamiltonian allows for weak recovery in the regime where \(_{n}=(n^{(q-2)/4})\). In this regime, where \(M=(\,n)\), the standard classical matrix power iteration algorithm can extract the dominant eigenvector and recover the signal in \((n^{M})\) time. For the proposed quantum algorithm, Ref.  uses a combination of quantum phase estimation, amplitude amplification, and clever state initialization to recover the signal in \((n^{M/4})\) time, achieving a quartic speedup. (A few months after our paper appeared online, a related work  emerged, simplifying Hastings' algorithm and generalizing it to another planted inference problem.)

We remark that Hastings' algorithm runs in superpolynomial time \(n^{(\,n)}\) and does not improve over the asymptotic computational threshold in SNR for recovery (although a constant factor improvement is possible). For comparison, the classical spectral method based on tensor unfolding [2; 11] achieves recovery when \(_{n}>n^{(q-2)/4}\) in polynomial time \(O((n^{q}))\). In this work, we study the QAOA in the constant-step regime, where the gate complexity grows only linearly in the problem size \(O(n^{q})\).

### Quantum approximate optimization algorithm

The quantum approximate optimization algorithm (QAOA) was introduced by  as a quantum algorithm for finding approximate solutions to combinatorial optimization problems. The QAOA can be applied to optimize any cost function on bit-strings, \(C:\{ 1\}^{n}\). In the spiked tensor model, we consider optimizing the log-likelihood function given by

\[}_{}=_{\{ 1\}^{n}}C()=,^{ q}/n^{(q-2)/2}}.\] (2.2)

The maximum likelihood estimator \(}_{}\) achieves non-trivial correlation with the signal when \(_{n}>_{}\) for some constant \(_{}=(1)\). However, classical algorithms cannot efficiently compute the MLE unless \(_{n}=(n^{(q-2)/4})\). This paper investigates whether QAOA could compute \(}_{}\), or an approximate estimator, for smaller values of \(_{n}\).

The inputs to the QAOA algorithm are a cost function \(C:\{ 1\}^{n}\) and parameter vectors \(,^{p}\). The initial QAOA state \(|s=2^{-n/2}_{}|\) is the rescaled all-one vector \(2^{-n/2}_{2^{n}}^{2^{n}}\), assigning equal probability to measuring each possible bit-string upon quantum measurement. See Appendix A.1 for a review of quantum computing terminology, where we also define the Pauli operators \(\{X_{k},Y_{k},Z_{k}\}_{k=1}^{n}\) acting on the \(k\)-th qubit. The cost function \(C\) associates with a \(2^{n} 2^{n}\) diagonal matrix, where the \(||\)'th diagonal gives \(C()\). For the spiked tensor model with cost function \(C()=\,,^{ q}/n^{(q-2)/2}\), this matrix is \(C=_{j_{1},,j_{q}=1}^{n}Y_{j_{1} j_{q}}Z_{1} Z_{q}/n^{(q -2)/2}^{2^{n} 2^{n}}\). Letting \(B=_{j=1}^{n}X_{j}^{2^{n} 2^{n}}\), for any parameter \((,)\), the unitary matrices \(e^{-i C},e^{-i B}^{2^{n} 2^{n}}\) are matrix exponents of \(-i C\) and \(-i B\). Given \(,^{p}\), the \(p\)-step QAOA state is

\[|,=e^{-i_{p}B}e^{-i_{p}C} e^{-i _{1}B}e^{-i_{1}C}|s^{2^{n}}.\] (2.3)One can verify \(|,\) is a unit vector since \(|s^{2^{n}}\) is unit and \(e^{-i_{k}B}^{2^{n} 2^{n}}\) and \(e^{-i_{k}C}^{2^{n} 2^{n}}\) are unitary matrices. After preparing the quantum state \(|,\), QAOA samples a bit string \(|,\) in \(\{ 1\}^{n}\) by quantum measurement. In our main results, we will analyze the distribution of the overlap \(_{}\) of this quantum measurement \(\) with respect to the signal \(\):

\[_{}^{}/n=_{i=1}^ {n}z_{i}u_{i}[-1,1].\] (2.4)

For any function \(f()=_{k=0}^{n}_{\{j_{1},,j_{k}\}}_{j_{1} j_{k }}z_{j_{1}} z_{j_{k}}\), its expectation under the QAOA state \(|,\) is given by \(,|f()|,\), where \(,|^{1 2^{n}}\) is the conjugate transpose of \(|,^{2^{n} 1}\), and \(f()=_{k=0}^{n}_{\{j_{1},,j_{k}\}}_{j_{1} j_{k }}Z_{j_{1}} Z_{j_{k}}^{2^{n} 2^{n}}\) for Pauli-Z matrices \(Z_{j}\). To simplify the notations, we denote \(_{,}\) by the expectation with the quantum measurement from \(|,\), so that

\[ f()_{,}=,|f()|,.\] (2.5)

In the main theorems of this paper, we will focus on the second moment of the overlap of QAOA, denoted as \(_{}^{2}_{,}= ,|}^{2}|,\), where \(}_{i=1}^{n}u_{i}Z_{i}\). We defer further related literature on theoretical analyses of the QAOA to Appendix A.2.

In terms of experimental realizations, the QAOA has been implemented in quantum computing platforms such as trapped ions [16; 19], superconducting qubits , and neutral atoms , for optimization problems with up to 179 bit variables. Implementing the QAOA for the spiked tensor model, however, poses additional challenges due to the all-to-all connectivity in its cost function, leading to a higher overhead in the number of quantum gates and circuit compilation costs. Currently, the largest experimental implementations for problems with dense connectivity include 17-bit Sherrington-Kirkpatrick spin-glass models on superconducting qubits , and an 18-bit LABS problem on trapped-ion quantum processors . We expect larger problems can be implemented as quantum hardware matures, but quantum error-correction is likely necessary to observe any quantum advantage at scale .

## 3 Main results

### Weak recovery threshold and overlap distribution for \(1\)-step QAOA

We first consider the general \(1\)-step QAOA for weak recovery in the spiked tensor model. Consider the spiked tensor model \(\) (1.1) with planted signal \((\{ 1\}^{n})\) and the \(1\)-step QAOA quantum state \(|_{n},_{n}=e^{-i_{n}B}e^{-i_{n}C}|s\) (see Section 2.2) with parameters \((_{n},_{n})_{>0}[0,2]\). The quantum state \(|_{n},_{n}\) depends randomly on \(\) through \(C()=,^{ q}/n^{(q-2)/2}\). Our main results characterize the distribution of the overlap \(_{}=}^{}/n\) between a sample \(}|_{n},_{n}\) and the signal vector \(\).

**Theorem 1** (Weak recovery threshold and overlap distribution for \(1\)-step QAOA).: _Consider the spiked tensor model (1.1) and the \(1\)-step QAOA overlap as defined above. Then the following hold._

1. _Take any sequence of_ \(\{_{n}\}_{n 1}\)_,_ \(\{_{n}\}_{n 1}[0,2]\)_, and any sequence of_ \(\{_{n}\}_{n 1}[0,)\) _with_ \(_{n}_{n}/n^{(q-1)/2}=0\)_. We have_ \[_{n}_{}[_{}^{2}_{_{n},_{n}}]=0.\] (3.1)
2. _Take any sequence of_ \(\{_{n}\}_{n 1}\)_,_ \(\{_{n}\}_{n 1}\)_, and_ \(\{_{n}\}_{n 1}\) _which satisfies_ \[_{n}(_{n},_{n},_{n}/n^{(q-1)/2})=(,, ).\] (3.2) _Then, over the randomness of_ \(\) _and the quantum measurement, the overlap_ \(_{}\) _of the_ \(1\)_-step QAOA converges in distribution to a sine-Gaussian law as_ \[_{}e^{-2q^{2}}(2)(2q  G^{q-1}),G(0,1).\] (3.3)
3. _As a corollary of (b), under the asymptotic limit of (_3.2_) with_ \(>0\)_,_ \(>0\)_, and_ \(\{k/2:k\}\)_, we have_ \[_{n}_{}[_{}^{2}_{_{n},_{n}}]>0.\] (3.4)The full proof of Theorem 1 is contained in Appendix C.

**Remark 3.1** (Weak recovery threshold).: Theorem 1(c) implies that when \(_{n}=(n^{(q-1)/2})\), the overlap will be non-zero with non-trivial probability over both the random draw of the tensor and the quantum randomness. In contrast, Theorem 1(a) shows that when \(_{n}=o(n^{(q-1)/2})\) the overlap will be zero with high probability. This establishes that \(_{n}=(n^{(q-1)/2})\) is the weak recovery threshold of 1-step QAOA in the spiked tensor model.

**Remark 3.2** (Overlap distribution).: Theorem 1 does not show that the overlap distribution for a typical instance \(\) converges to the same sine-Gaussian law. In Section 4, we perform numerical simulations that provide evidence that the overlap distribution will concentrate over the random draw of \(\), which would imply that the overlap distribution is indeed sine-Gaussian for any typical \(\).

Comparison with classical tensor power iteration.The \(1\)-step tensor power iteration estimator (Eq. (2.1)) is redefined here for the reader's convenience: \(}_{1}=[}_{0}^{(q-1)}]/\|[ {}_{0}^{(q-1)}]\|_{2}\), where \(}_{0}(^{n-1})\) is a random initialization vector. In the following proposition, we show that the weak recovery threshold for the \(1\)-step power iteration estimator is also \(_{n}=(n^{(q-1)/2})\), and we provide the distribution of the overlap \(_{}}_{1}^{}/n\) between the power iteration estimator \(}_{1}\) and the signal \(\).

**Proposition 3.3** (Weak recovery threshold for \(1\)-step tensor power iteration).: _Assume that the rescaled signal-to-noise ratio has a limit \(_{n}_{n}/n^{(q-1)/2}=\). Then over the randomness of \(\) and initialization \(}_{0}\), the overlap \(_{}\) of the power iteration estimator with the signal converges in distribution to_

\[_{}}{{}}[ ( G^{q-1})],G(0,1).\] (3.5)

_As a corollary, when \(_{n}_{n}/n^{(q-1)/2}=0\), we have \(_{}}{{}}0\)._

The proof of Proposition 3.3 is contained in Appendix H.1.

**Remark 3.4** (Comparing the overlaps).: Theorem 1 and Proposition 3.3 show that both 1-step QAOA and 1-step power iteration have the same weak recovery threshold \(_{n}=(n^{(q-1)/2})\). To compare the two algorithms more precisely, we take the limit \(_{n}_{n}/n^{(q-1)/2}=\) for some small \(>0\). Eq. (3.3) and Eq. (3.5) give the limiting squared overlap distributions for 1-step QAOA and 1-step power iteration, respectively:

\[_{ 0}^{-2}&_{n }_{}[^{2}_{}_{ ,}]=e^{-4q^{2}}4q^{2}^{2}^{2}(2)\,_{G (0,1)}[G^{2q-2}],\\ &_{ 0}^{-2}\,_{n}_{}[^{2}_{}]=\,_{G(0,1)}[G^{2q -2}].\] (3.6)

This gives

\[_{,}_{ 0+}_{n}_{}[^{2}_{}_{,}]/\,_{}[^{2}_{}]}=e^{-4q_{*}^{2}}4q^{2} _{*}^{2}^{2}(2_{*})=q/e,\] (3.7)

where the maximizer is \((_{},_{*})=(},/4)\). Thus, for \(q>e\), 1-step QAOA gives better overlap than 1-step power iteration.

**Remark 3.5** (Rounding via \((})\) will not improve the overlap).: The readers may wonder whether the overlap of tensor power iteration will be improved by rounding the estimator via \(}_{1}=(}_{1})\{ 1\}^{n}\), outputting an estimator in the signal space. Defining \(}_{}=}_{1}^{}/n\), it is straightforward to show that as \(_{n}_{n}/n^{(q-1)/2}=\),

\[}_{}}{{ }}( G^{q-1}),G(0,1),\ \ (t)=2_{Z (0,1)}(Z t)-1.\] (3.8)

Hence, the computational threshold has the same exponent by rounding, but the overlap becomes smaller:

\[_{ 0}^{-2}_{n}_{}[}_{}^{2}]=(2/)_{G(0,1)}[ G^{2q-2}].\] (3.9)

**Remark 3.6** (Sine-Gaussian law versus sine-arctan-Gaussian law).: The sine-Gaussian law of QAOA is particularly interesting in that the overlap will not concentrate as \(\). Instead, it will satisfy a sine-uniform distribution, i.e., \((2q G^{q-1})}{{}}(U)\) for \(U([0,2])\). In contrast, the sine-arctan-Gaussian law of tensor power iteration will concentrate at \(\{ 1\}\) as \(\).

In Appendix E, we also study the scenario where prior information about the signal may be leveraged to recover the signal with a smaller SNR. There, we rigorously analyzed the 1-step QAOA applied to boost the signal in a weak estimator in Theorem 2, and compared it classical power iteration in Proposition E.2. Our result shows that the 1-step QAOA has the same asymptotic computational efficiency as 1-step power iteration, albeit with a constant-factor better overlap in the \( 1\) regime when \(q>e\).

### Weak recovery threshold and overlap distribution for \(p\)-step QAOA

We next consider the general \(p\)-step QAOA for weak recovery in the spiked tensor model. Although it is known that the QAOA is able to output the MLE that weakly recovers the signal when \(p\) grows unboundedly with \(n\), here we focus on a more analytically tractable regime where \(p\) is an arbitrary fixed constant in the \(n\) limit. Using a physics-style derivation, we show that the \(p\)-step QAOA can achieve weak recovery when the signal-to-noise ratio satisfies

\[_{n}=n^{(q-2+_{p})/2}, _{p}=-1},&q>2,\\ 1/p,&q=2.\] (3.10)

Observe that \(0<_{p} 1\) and \(_{p}_{p}=0\). Hence, the \(p\)-step QAOA can recover the signal with a progressively weaker SNR as \(p\) increases. Moreover, we are able to characterize the overlap distribution \(_{}}^{}/n\) of \(p\)-step QAOA between a sample \(}|,\) (see Eq. (2.3)) and the signal \(\) as follows:

**Claim 3.7** (\(p\)-step QAOA for weak recovery).: _Consider the \(p\)-step QAOA with parameters \(\{(_{n},_{n})\}_{n 1}\) applied to the spiked tensor model (1.1) with signal-to-noise ratio \(\{_{n}\}_{n 1}\). Suppose_

\[_{n}_{n},_{n},_{n}/n^{(q-2+ _{p})/2}=(,,).\] (3.11)

_Then, there are parameter-dependent coefficients \((a_{p}(,),b_{p}(,))\) such that over the randomness of \(\) and the quantum measurement, the overlap \(_{}\) of the \(p\)-step QAOA converges in distribution to a sine-Gaussian law as_

\[_{}}{{}}a_{p }(b_{p}^{1/_{p}}G^{(q-1)^{p}}), G (0,1).\] (3.12)

The derivation of Claim 3.7 is contained in Appendix D. We remark that our derivation uses non-rigorous heuristics from physics such as the Dirac delta function and its Fourier transform to linearize exponents in combinatorial sums (see Appendix D.1 for a sketch). Analytical expressions for the coefficients \(a_{p}(,)\) and \(b_{p}(,)\) can be found in Appendix D.5.

**Remark 3.8** (Weak recovery threshold).: As \( 0\), Eq. (3.12) implies that \(_{}}{{}}0\). Thus, Claim 3.7 implies that \(_{n}=(n^{(q-2+_{p})/2})\) is the weak recovery threshold by the \(p\)-step QAOA in the spiked tensor model in the regime of fixed QAOA parameter. We believe this scaling is also the weak recovery threshold for the QAOA with any sequence of parameters \((_{n},_{n})\), but proving this requires ruling out better performance of the QAOA when \((_{n},_{n})\) is allowed to depend strongly on \(n\) as we have done in Theorem 1(a); we leave this as future work. Since \(_{p} 0\) as \(p\), this means \(_{n}=(n^{(q-2)/2})\) is the recovery threshold given a diverging number of QAOA steps (but constant with respect to \(n\)). However, this does not achieve the \((n^{(q-2)/4})\) computational threshold for classical algorithms.

Comparison with classical tensor power iteration.We now compare the overlap from the \(p\)-step QAOA to that from the classical \(p\)-step tensor power iteration algorithm. We show that the weak recovery threshold for the \(p\)-step power iteration estimator is also \(_{n}=(n^{(q-2+_{p})/2})\), and we provide the distribution of the overlap \(_{}}_{p}^{}/n\) between the \(p\)-step power iteration estimator \(}_{p}\) (see Eq. (2.1)) and the signal \(\).

**Proposition 3.9** (Corollary of Lemma 3.2 of ).: _Consider a random instance of the spiked tensor model with \(_{n}_{n}/n^{(q-2+_{p})/2}=\). The overlap \(_{}\) of the \(p\)-step tensor power iteration algorithm converges in distribution as_

\[_{}}{{}} [(^{1/_{p}}G^{(q-1)^{p}})], G(0,1).\] (3.13)The proof of Proposition 3.9 is contained in Appendix H.3.

**Remark 3.10** (Comparing the overlaps).: In the small \( 1\) regime, we have

\[_{}(|a_{p}b_{p}|^{_{p}})^{1/ _{p}}G^{(q-1)^{p}}_{} ^{1/_{p}}G^{(q-1)^{p}}.\] (3.14)

When \(|a_{p}b_{p}|>1\), the QAOA has a constant factor advantage over the classical power iteration algorithm in the overlap achieved, assuming the conjectured Claim 3.7 based on heuristic derivations. To quantify this advantage, we consider the quantum enhancement factor, \(|a_{p}b_{p}|^{_{p}}\), which is the factor that the signal-to-noise ratio can shrink for the QAOA while maintaining the same overlap as the power iteration algorithm. Effectively, this factor \(|a_{p}b_{p}|^{_{p}}\) corresponds to a quantum improvement in the recovery threshold by the QAOA over classical power iteration. We numerically optimize \(|a_{p}b_{p}|^{_{p}}\) with respect to the QAOA parameters \((,)\), and present the optimized values in Table 1.

**Remark 3.11** (Weak recovery threshold for QAOA with tensor unfolding).: Although neither the constant-step QAOA nor the tensor power iteration matches the \((n^{(q-2)/4})\) recovery threshold for the best polynomial-time classical algorithms, we can achieve this threshold using the idea of tensor unfolding. When \(q\) is even, the tensor \(^{n}\) can be unfolded into a matrix \(}\):

\[}=(_{n}/n^{q/2})}}^{}+( 1/)}^{n^{q/2} n^{q/2}}.\] (3.15)

Here \(_{(j_{1},,j_{q/2}),(j_{q/2+1},,j_{q})}=Y_{j_{1} j _{q}}\), \(_{(j_{1},,j_{q/2}),(j_{q/2+1},,j_{q})}=W_{j_{1} j _{q}}\), and \(}=(^{(q/2)})\{ 1\}^{n^{q/2}}\). Existing work  have demonstrated that the leading eigenvector \(}\) of \(}\) has non-vanishing correlation with the signal \(}\) as soon as \(_{n}>n^{(q-2)/4}\). Furthermore, for the eigenvector \(}\) in such a regime, standard analysis as in  implies that the top singular vector of \((})^{n n^{q/2-1}}\) will have non-trivial overlap with the signal \(\), achieving the \((n^{(q-2)/4})\) weak recovery threshold for the spectral method with tensor-unfolding.

A similar tensor-unfolding pre-processing could be applied to the QAOA to improve the computational threshold. Indeed, the QAOA method could be adopted to maximize the cost function \((})=}^{}} {}/n^{(q-1)/2}\) with decision variable \(}\{ 1\}^{n^{q/2}}\). Notice that such a QAOA method needs to be applied to a \(n^{q/2}\)-qubit system. Effectively, \((})\) could be interpreted as the cost function of a spiked \(2\)-tensor model of size \(=n^{q/2}\) and with a rescaled signal-to-noise ratio \(_{n}=_{n}/n^{(q-2)/4}\). According to Claim 3.7, \(p\)-step QAOA outputs a long bit-string \(}\{ 1\}^{n^{q/2}}\) overlapping with the signal \(}\) as long as \(_{n}=^{_{p}/2}\) for \(_{p}=1/p\). Translating to the scaling of \(_{n}\), the computational threshold for QAOA with tensor unfolding is \(_{n}=(n^{(q-2+_{p}^{})/4})\) where \(_{p}^{}=q/p\). This recovers the classical \((n^{(q-2)/4})\) threshold as \(p\).

## 4 Numerical simulations

We now validate our theoretical results by conducting numerical simulations of the QAOA through classical computers. In this section, we focus on the case of 1-step QAOA (\(p=1\)) for the spiked

 \(p\) & 2 & 3 & 4 & 5 & 6 & 7 \\  
1 & 0.8578 & 1.0505 & 1.2131 & 1.3562 & 1.4857 & 1.6047 \\
2 & 0.9663 & 1.0505 & 1.1916 & 1.2882 & 1.4167 & 1.5162 \\
3 & 1.0204 & 1.0314 & 1.1615 & 1.2555 & 1.3844 & 1.4917 \\
4 & 1.0487 & 1.0144 & 1.1419 & 1.2447 & 1.3795 & 1.4858 \\
5 & 1.0631 & 1.0063 & 1.1327 & 1.2411 & 1.3770 & 1.4845 \\
6 & 1.0697 & 1.0013 & 1.1297 & 1.2399 & 1.3743 & 1.4842 \\
7 & 1.0719 & & & & & \\ 

Table 1: **The quantum enhancement factor \(|a_{p}b_{p}|^{_{p}}\) of the \(p\)-step QAOA over the \(p\)-step tensor power iteration**, for spiked \(q\)-tensors when \(_{n}= n^{(q-2+_{p})/2}\) in the \( 1\) regime. Note in the first row, which corresponds to \(p=1\) with \(_{1}=1\), we know the optimal value \(|a_{1}b_{1}|=\) from Eq. (3.7). The remaining values are optimized via a quasi-Newton method starting with 1000 heuristic initial guesses of \((,)\) and keeping the best value; hence, they currently should be considered as lower bounds on the best possible enhancement factors.

matrix model (\(q=2\)), where we can obtain an explicit formula the expected squared overlap at any finite problem dimension \(n\) (see Appendix F for a derivation):

\[_{}[^{2}_{ }_{{}_{},}]&=e^{-8^{2}(n-2)/n }^{2}(2)[1-^{n-2}(8/n)]\\ &+e^{-4^{2}(n-1)/n}(4)(4 /n)^{n-2}(4/n)+.\] (4.1)

In Fig. 2(a), we report the overlap distribution of 1-step QAOA (\(p=1\)) for the spiked matrix model (\(q=2\)) where the SNR is chosen as \(_{n}=n^{1/2}\). The histogram shows the Monte Carlo simulation results following the predicted sine-Gaussian law. The dashed gray lines are from the simulations of the QAOA using classical algorithms for \(n=26\), each corresponding to one of 40 instances. Note that simulating QAOA classically has complexity \(O(2^{n})\), which limits us to \(n=26\). We see

Figure 3: Example overlap distributions from \(p\)-step QAOA for the spiked tensor model for \(1 p 5\). The top row shows data from 40 random 26-bit instances with \(q=2\) and \(_{n}=n^{1/(2p)}\). The bottom row shows data from 40 random 23-bit instances with \(q=3\) and \(_{n}=n^{[1+1/(2^{p}-1)]/2}\). Different columns correspond to different \(p\), using the QAOA parameters (\(,\)) that optimized \(|a_{p}b_{p}|^{_{p}}\) in Table 1. Dash gray lines connect data from the same instance. Blue histograms are the theoretical sine-Gaussian distributions in the \(n\) limit, where \(_{} a_{p}[b_{p}G^{(q-1)^{p}}]\) according to Claim 3.7. (Note here \(=1\).)

Figure 2: (a) Example overlap distribution from 1-step QAOA for the spiked matrix model (\(q=2\)), where simulation data is collected from 40 random generated instances with \(n=26\) bits. The signal-to-noise ratio is chosen to be \(_{n}=n^{1/2}\), and \((,)=(,/4)\). Dash gray lines connect data from the same instance. (b) Average of squared overlap \(^{2}_{}_{{}_{},}\) from the QAOA output distribution for 40 random instances generated at various problem dimensions.

that, despite some finite sample effects, the predicted sine-Gaussian distribution matches the QAOA simulation.

Fig. 2(b) reports the expected squared overlap from the QAOA simulations. The green dashed line is the theoretical prediction in the \(n\) limit. The blue solid line is the finite \(n\) theoretical prediction from Eq. (4.1). The gray dots are the squared overlaps from individual QAOA instances simulated classically. The average over instances (red crosses) agrees well with the finite \(n\) theory prediction, which converges to the \(n\) limit with order \(1/n\) deviation.

We also perform simulations for \(1 p 5\) and \(q=2,3\). Fig. 3 plots the overlap distribution for \(p\)-step QAOA. The simulation curves follow the shape of the theoretical histograms for \(p 2\). For \(p 3\), the shapes of the simulated and theoretical overlap distributions do not match well, likely due to finite size effects (simulations for large \(n>26\) are computationally challenging).

In Appendix G, we present additional numerical simulation results on higher \((p,q)\) and find the second moment of the QAOA overlap converges to our theoretical predictions up to \(O(1/n)\) deviations. We also describe more details of the simulation methods.

An interesting phenomenon apparent from Fig. 2(a) and Fig. 3 is that the output distribution of the QAOA appears to concentrate over the randomness of instances \(\), but not over the quantum measurements. This is in stark contrast to previous concentration results on the QAOA where concentration over measurements were shown, e.g., for spin-glass models in [24; 26; 32]. We note that such anti-concentration is also expected in the limit of zero noise (\(\)), where it is known the constant-\(p\) QAOA can prepare the GHZ state . Since existing limitations of both classical  and quantum algorithms [30; 26; 31; 32] on various problems over random structures rely heavily on concentration, extending these negative results to the QAOA for the spiked tensor model do not seem possible due to the absence of concentration. Nevertheless, our analysis shows that the constant-\(p\) QAOA is unable to improve the recovery threshold in the spiked tensor model achieved by classical algorithms by more than a constant factor.

## 5 Discussion

In this paper, we have investigated the power of quantum algorithms for the spiked tensor model, a canonical problem in statistical inference with a large computational-statistical gap that has so far eluded classical algorithms. We gave the first rigorous study of a polynomial-time quantum algorithm on this problem by analyzing the performance of the QAOA, a popular variational quantum algorithm that has been implemented on current quantum computing hardware. We showed that \(p\)-step QAOA achieves the same asymptotic SNR threshold for weak recovery as \(p\)-step tensor power iteration. A heuristic analysis showed that multi-step QAOA with tensor unfolding could achieve, but not surpass, the classical computation threshold \((n^{(q-2)/4})\). This implies that achieving a strong quantum advantage via the QAOA requires using a number of steps \(p\) that grows with \(n\). However, we revealed that the asymptotic overlap distribution of QAOA exhibits an intriguing sine-Gaussian law, distinct from tensor power iteration. For certain parameters \((p,q)\), the QAOA effectively has a recovery threshold that is a constant factor better, indicating a modest quantum advantage over the classical power iteration. Overall, while achieving identical scalings as power iteration, the QAOA demonstrates qualitative differences and potential for quantum speedups.

There are many interesting questions that remain open. One worthy challenge would be a rigorous proof for the \(p>1\) analysis without relying on heuristic arguments. Additionally, it would be interesting to prove that the sine-Gaussian distribution is concentrated over problem instances but not over measurements, as suggested by our simulations. This is in contrast to recent results showing that the low-depth QAOA is concentrated over measurements [26; 32], a seemingly essential ingredient for many proofs of algorithmic limitations [26; 29; 30; 31; 32]. Despite the absence of concentration in the spiked tensor setting, our results show that the constant-\(p\) QAOA has limited power, similar to the message of recent works [26; 30; 31; 32; 32; 33; 34; 35; 36; 37; 38; 39; 40; 41; 42; 43; 44; 45; 46; 47; 48; 49; 50; 51] proving limitations up to \(p=O( n)\). This suggests that demonstrating strong quantum advantage requires analyzing super-logarithmic depth QAOA, which remains an outstanding open question. Finally, it would be interesting to study quantum algorithms in other statistical inference models that classically exhibit computational-statistical gaps, including planted clique, Bayesian linear models, and sparse PCA. Overcoming any such gap with a polynomial-time quantum algorithm would be an exciting superpolynomial quantum speedup with practical relevance.