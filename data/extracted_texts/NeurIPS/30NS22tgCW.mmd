# Optimal Scalarizations for Sublinear Hypervolume Regret

Qiuyi (Richard) Zhang

Google Deepmind

qiuyiz@google.com

###### Abstract

Scalarization is a general, parallizable technique that can be deployed in any multi-objective setting to reduce multiple objectives into one, yet some have dismissed this versatile approach because linear scalarizations cannot explore concave regions of the Pareto frontier. To that end, we aim to find simple non-linear scalarizations that provably explore a diverse set of \(k\) objectives on the Pareto frontier, as measured by the dominated hypervolume. We show that hypervolume scalarizations with uniformly random weights achieves an optimal sublinear hypervolume regret bound of \(O(T^{-1/k})\), with matching lower bounds that preclude any algorithm from doing better asymptotically. For the setting of multiobjective stochastic linear bandits, we utilize properties of hypervolume scalarizations to derive a novel non-Euclidean analysis to get regret bounds of \((dT^{-1/2}+T^{-1/k})\), removing unnecessary \((k)\) dependencies. We support our theory with strong empirical performance of using non-linear scalarizations that outperforms both their linear counterparts and other standard multiobjective algorithms in a variety of natural settings.

## 1 Introduction

Optimization objectives in modern AI systems are becoming more complex with many different components that must be combined to perform precise tradeoffs in machine learning models. Starting from standard \(_{p}\) regularization objectives in regression problems (Kutner et al., 2005) to increasingly multi-component losses used in reinforcement learning (Sutton et al., 1998) and deep learning (LeCun et al., 2015), many of these single-objective problems are phrased as a scalarized form of an inherently \(k\)-objective problem.

**Scalarization Method.** Practitioners often vary the weights of the scalarization method, with the main goal of exploring the entire _Pareto frontier_, which is the set of optimal objectives that cannot be simultaneously improved. First, one chooses some weights \(^{k}\) and scalarization functions \(s_{}(y):^{k}\) that convert \(k\) multiple objectives \(F(a):=(f_{1}(a),...,f_{k}(a))\) over some parameter space \(a^{d}\) into a single-objective scalar. Optimization is then applied to this family of single-objective functions \(s_{}(F(x))\) for various \(\) and since we often choose \(s_{}\) to be monotonically increasing in all coordinates, \(x_{}=_{a}s_{}(F(a))\) is on the Pareto frontier and the various choices of \(\) recovers an approximation to the Pareto frontier (Paria et al., 2018).

Due to its simplicity of use, many have turned to a heuristic-based scalarization strategy to pick the family of scalarizer and weights, which efficiently splits the multi-objective optimization into numerous single "scalarized" optimizations (Roijers et al., 2013). Linear scalarizations with varying weights are often used in multi-objective optimization problems, such as in multi-objective reinforcement learning to combine task reward with the negative action norm (Abdolmaleki et al., 2021) or in RLHF to align responses with human preferences Ouyang et al. (2022). However, the appeal ofusing scalarizations in multiobjective optimization declined as linear scalarizations are shown to be provably incapable of exploring the full Pareto frontier (Boyd and Vandenberghe, 2004).

**Beyond Linear Scalarization.** To address this, some works have proposed piecewise linear scalarizations inspired by economics (Busa-Fekete et al., 2017), while for multi-armed bandits, scalarized knowledge gradient methods empirically perform better with non-linear scalarizations (Yahyaa et al., 2014). The classical Chebyshev scalarization has been shown to be effective in many settings, such as evolutionary strategies Qi et al. (2014); Li et al. (2016), general blackbox optimization (Kasimbeyli et al., 2019) or reinforcement learning Van Moffaert et al. (2013). Other works have come up with novel scalarizations that perform better empirically in some settings (Aliano Filho et al., 2019; Schmidt et al., 2019). There also have been specific multi-objective algorithms tailored to specific settings such as ParEgo (Knowles, 2006) and MOEAD (Zhang and Li, 2007) for black-box optimization or multivariate iteration for reinforcement learning (Yang et al., 2019). Furthermore, many adaptive reweighting strategies have been proposed in order to target or explore the full Pareto frontier, which have connections to gradient-based multi-objective optimization (Lin et al., 2019; Abdolmaleki et al., 2021). However these adaptive strategies are heuristic-driven and hard to compare, while understanding simple oblivious scalarizations remain very important especially in batched settings where optimizations are done heavily in parallel Gergel and Kozinov (2019).

**Hypervolume Regret.** To determine optimality, a natural and widely used metric to measure progress of an optimizer is the _hypervolume indicator_, which is the volume of the dominated portion of the Pareto set (Zitzler and Thiele, 1999). The hypervolume metric has become a gold standard because it has strict Pareto compliance meaning that if set \(A\) is a subset of \(B\) and \(B\) has at least one Pareto point not in \(A\), then the hypervolume of \(B\) is greater than that of \(A\). Unsurprisingly, multiobjective optimizers often use hypervolume related metrics for progress tracking or acquisition function, such as the Expected Hypervolume Improvement (EHVI) or its differentiable counterpart (Daulton et al., 2020; Hupkens et al., 2015). Only recently has some works provide sub-linear hypervolume regret bounds which guarantees convergence to the full Pareto frontier; however, they are exponential in \(k\) and its analysis only applies to a specially tailored algorithm that requires an unrealistic classification step (Zuluaga et al., 2013). We draw inspiration on work by (Golovin and Zhang, 2020) that introduces random hypervolume scalarizations but their work does not consider the finite-sample regime and their regret bounds are in the blackbox setting, where the convergence rate quantifies the statistical convergence of the Pareto frontier estimation.

### Our Contributions

We show, perhaps surprisingly, that a simple ensemble of nonlinear scalarizations, known as Hypervolume scalarizations, are theoretically optimal to minimize hypervolume regret and are empirically competitive for general multiobjective optimization. Intuitively, we quantify how fast scalarizations can approximate the Pareto frontier under finite samples even with perfect knowledge of the Pareto frontier, which is the white-box setting. Specifically, as the hypervolume scalarization has sharp level curves, they naturally allow for the targeting of a specific part of the Pareto frontier, without any assumptions on the Pareto set or the need for adaptively changing weights. Additionally, we can oblivously explore the Pareto frontier by choosing \(T\) maximizers of randomly weighted Hypervolume scalarizations and achieve a sublinear hypervolume regret rate of \(O(T^{-1/k})\), where \(T\) is the number of points sampled.

**Sublinear Hypervolume Regret.** Given any set of objectives \(\) that are explicitly provided, our goal is to choose points on the Pareto frontier in a way to maximize the hypervolume. In this white-box setting, we introduce the notion of the hypervolume regret convergence rate, which is both a function of both the scalarization and the weight distribution, and show that the maxima of Hypervolume scalarization with uniform i.i.d. weights enjoy \(O(T^{-1/k})\) hypervolume regret (see Theorem 7). In fact, our derived regret rate of the Hypervolume scalarization holds for all frontiers, regardless of the inherent multiobjective function \(F\) or the underlying optimizer. Therefore, we emphasize that analyzing these model-agnostic rates can be a general theoretical tool to compare and analyze the effectiveness of proposed multiobjective algorithms. Although many scalarizers will search the entire Pareto frontier as \(T\), the rate at which this convergence occurs can differ significantly, implying that this framework paves the road for a theoretical standard by which to judge the effectiveness of advanced strategies, such as adaptively weighted scalarizations.

**Lower bounds.** On the other hand, we show surprisingly that no multiobjective algorithm, whether oblivious or adaptive, can beat the optimal hypervolume regret rates of applying single-objective optimization with the hypervolume scalarization. To accomplish this, we prove novel lower bounds showing one cannot hope for a better convergence rate due to the exponential nature of our regret, for any set of \(T\) points. Specifically, we show that the hypervolume regret of any algorithm after \(T\) actions is at least \((T^{-1/k})\), demonstrating the necessity of the \(O(T^{-1/k})\) term up to small constants in the denominator. As a corollary, we leverage the sublinear regret properties of hypervolume scalarization to transfer our lower bounds to the more general setting of scalarized Bayes regret. Together, we demonstrate that for general multiobjective optimzation, finding maximas of the hypervolume scalarizations with a uniform weight distribution optimally finds the Pareto frontier asymptotically.

**Theorem 1** (Informal Restatement of Theorem 7 and Theorem 8).: _Let \(_{T}=\{y_{1},...,y_{T}\}\) be a set of \(T\) points in \(^{k}\) such that \(y_{i}_{y}s_{_{i}}^{}(y)\) with \(_{i}_{+}\) randomly drawn i.i.d. from an uniform distribution and \(s^{}\) are hypervolume scalarizations. Then, the hypervolume regret satisfies_

\[(^{})-(_{T})=O(T^{-})\]

_where \(^{}\) is the Pareto frontier and \(\) is the hypervolume function. Furthermore, any algorithm for choosing these \(T\) points must suffer hypervolume regret of at least \((T^{-})\)._

**Scalarized Algorithm for Linear Bandit.** Next, we use a novel non-Euclidean analysis to prove improved hypervolume regret bounds for our theoretical toy model: the classic _stochastic linear bandit_ setting. For any scalarization and weight distribution, we propose a new scalarized algorithm (Algorithm 1) for multiobjective stochastic linear bandit that combines uniform exploration and exploitation via an UCB approach to provably obtain scalarized Bayes regret bounds, which we then combine with the hypervolume scalarization to derive optimal hypervolume regret bounds. Specifically, for any scalarization \(s_{}\), we show that our algorithm in the linear bandit setting has a scalarized Bayes regret bound of \((L_{p}k^{1/p}dT^{-1/2}+T^{-1/k})\), where \(L_{p}\) is the Lipschitz constant of the \(s_{}()\) in the \(_{p}\) norm. Finally, by using hypervolume scalarizations and exploiting their \(_{}\)-smoothness, we completely remove the dependence on the number of objectives, \(k\), which had a polynomial dependence in previous regret bound given by Golovin and Zhang (2020).

**Theorem 2** (Informal Restatement of Theorem 11).: _For the multiobjective linear bandit problem, let \(_{T}\) be the actions generated by \(T\) rounds of Algorithm 1, then our hypervolume regret is bounded by:_

\[_{z}(^{})-_{z}(^{} _{T}) O(dT^{-}+T^{-})\]

**Experiments.** Guided by our theoretical analysis, we empirically evaluate a diverse combination of scalarizations and weight distributions in multiple natural settings. First, we consider a synthetic optimization that is inspired by our theoretical derivation of hypervolume regret when the entire Pareto front is known and analytically given. Thus we can explicitly calculate hypervolume regret as a function of the number of Pareto points chosen and compare the regret convergence rates of multiple scalarizations with the uniform \(_{+}\) distribution with \(k=3\) objectives, for easy visualization. This is important since when \(k=2\), we show that the Chebyshev and Hypervolume scalarizations are in fact equivalent.

In our setup, we consider synthetic combinations of concave, convex, and concave/convex Pareto frontiers in each dimension. As expected, non-linear Hypervolume and Chebyshev scalarizations enjoy fast sublinear convergence, while the performance of the Linear scalarization consistently lacks behind, surprisingly even for convex Pareto frontiers. We observe that generally the Hypervolume scalarization does better on concave Pareto frontiers and on some convex-concave frontiers, while the Chebyshev distribution have faster hypervolume convergence in certain convex regimes.

For multiobjective linear bandits, our experiments show that for many settings, despite having a convex Pareto frontier, applying linear or Chebyshev scalarizations naively with various weight distributions leads to suboptimal hypervolume progress, especially when the number of objective increase to exceed \(k 5\). This is because the non-uniform curvature of the Pareto frontier, exaggerated by the curse of dimensionality and combined with a stationary weight distribution, hinders uniform progress in exploring the frontier. Although one can possibly adapt the weight distribution to the varying curvature of the Pareto frontier when it is convex, the use of simple non-linear scalarizations allow for fast parallelization and are theoretically sound.

For general multiobjective optimization, we perform empirical comparisons on BBOB benchmarks for bi-objective functions in a bayesian optimization setting, using classical Gaussian Process models (Williams and Rasmussen, 2006). When comparing EHVI with hypervolume scalarization approaches, we find that EHVI tends to limit its hypervolume gain by over-focusing on the central portion of the Pareto frontier, whereas the hypervolume scalarization encourages a diverse exploration of the extreme ends.

We summarize our contributions as follows:

* Show that hypervolume scalarizations optimizes for the full Pareto frontier and enjoys sublinear hypervolume regret bounds of \(O(T^{-1/k})\), a theoretical measure of characterizing scalarization effectiveness in the white-box setting.
* Establish a tight lower bound on the hypervolume regret for any algorithm and Bayes regret of \((T^{-1/k})\) by a packing argument on the Pareto set.
* Introduce optimization algorithm for multiobjective linear bandits that achieves improved \((dT^{-1/2}+T^{-1/k})\) hypervolume regret via a novel non-Euclidean regret analysis and metric entropy bounds.
* Empirically justify the adoption of hypervolume scalarizations for finding a diverse Pareto frontier in general multiobjective optimization via synthetic, linear bandit, and blackbox optimization benchmarks.

## 2 Problem Setting and Notation

For a scalarization function \(s_{}(x)\), \(s_{}\) is \(L_{p}\)-Lipschitz with respect to \(x\) in the \(_{p}\) norm on \(^{d}\) if for \(x_{1},x_{2}\), \(|s_{}(x_{1})-s_{}(x_{2})| L_{p}\|x_{1}-x_{2}\|_{p}\), and \(L_{}\) analogously for \(\) in the Euclidean norm. We let \(_{+}^{k-1}=\{y^{k}\,|\,\|y\|=1,y>0\}\) be the sphere in the positive orthant and by abuse of notation, we also let \(y_{+}^{k-1}\) denote that \(y\) is drawn uniformly on \(_{+}^{k-1}\). Our usual settings of the weight distribution \(=_{+}^{k-1}\) will be uniform, unless otherwise stated.

For two outputs \(y,z^{k}\), we say that \(y\) is _Pareto-dominated_ by \(z\) if \(y z\) and there exists \(j\) such that \(y_{j}<z_{j}\), where \(y z\) is defined for vectors element-wise. A point is _Pareto-optimal_ if no point in the output space \(\) can dominates it. Let \(^{}\) denote the set of Pareto-optimal points (objectives) in \(\), which is also known as the _Pareto frontier_. Our main progress metrics for multiobjective optimization is given by the standard hypervolume indicator. For \(S^{k}\) compact, let \((S)\) be the regular hypervolume of \(S\) with respect to the standard Lebesgue measure.

**Definition 3**.: _For a set \(\) of points in \(^{k}\), we define the (dominated)_ **hypervolume indicator**_of \(\) with respect to reference point \(z\) as:_

\[_{z}()=(\{x\,|\,x z,xy\})\]

We can formally phrase our optimization objective as trying to rapidly minimize the hypervolume (psuedo-)regret. Let \(\) be our action space and for some general multi-objective function \(F\), let \(\) be the image of \(\) under \(F\). Let \(_{T}^{T d}\) be any matrix of \(T\) actions and let \(_{T}=F(_{T})^{T k}\) be the \(k\) objectives corresponding. Then, the hypervolume regret of actions \(_{T}\), with respect to the reference point \(z\), is given by:

\[(_{T})=_{z}(^{} )-_{z}(_{T})\]

which is \(0\) for all \(z\) if and only if \(_{T}\) contains all unique points in \(^{}\).

For various scalarizations and weight distributions, an related measure of progress that attempts to capture the requirement of diversity in the Pareto front is scalarized Bayes regret for some scalarization function \(s_{}\). For some fixed scalarization with weights \(\), \(s_{}:^{k}\), we can define the instantaneous scalarized (psuedo-)regret as \(r(s_{},a_{t})=_{a}s_{}(F(a))-s_{}(F(a_ {t}))\). To capture diversity and progress, we will vary \(\) according to some distribution of non-negative weight vectors and define regret with respect with respect to all past actions \(_{t}\). Specifically, we define the _(scalarized) Bayes regret_ with respect to a set of actions \(_{t}\) to be \(BR(s_{},_{t})=_{}[_{a }s_{}(F(a))-_{a_{t}}s_{}(F(a))]= _{}[_{a_{t}}r(s_{},a)]\)Unlike previous notions of Bayes regret in literature, we are actually calculating the Bayes regret of a reward function that is maximized with respect to an entire set of actions \(_{t}\). Specifically, by maximizing over all previous actions, this captures the notion that during multi-objective optimization our Pareto set is always expanding. We will see later that this novel definition is the right one, as it generalizes to the multi-objective setting in the form of hypervolume regret.

### Scalarizations for Multiobjective Optimization

For multiobjective optimization, we generally only consider _monotone_ scalarizers that have the property that if \(y>z\), then \(s_{}(y)>s_{}(z)\) for all \(\). Note this guarantees that an optimal solution to the scalarized optimization is on the Pareto frontier. A common scalarization used widely in practice is the linear scalarization: \(s_{}^{}(y)=^{}y\) for some chosen positive weights \(^{k}\). By Lagrange duality and hyperplane separation of convex sets, one can show that any convex Pareto frontier can be characterized fully by an optimal solution for some weight settings.

However, linear scalarizations cannot recover the non-convex regions of Pareto fronts since the linear level curves can only be tangent to the Pareto front in the protruding convex regions (see Figure 1). To overcome this drawback, another scalarization that is proposed is the Chebyshev scalarization: \(s_{}^{}(y)=_{i}_{i}y_{i}\). Indeed, one can show that the sharpness of the scalarization, due to its minimum operator, can discover non-convex Pareto frontiers.

**Proposition 4** (Emmerich and Deutz (2018)).: _For a point \(y^{}^{}\) for convex \(\), there exists \(>0\) such that \(y^{}=_{y}s_{}^{}(y)\). For a point \(y^{}^{}\) for any possibly non-convex set \(\) that lies in the positive orthant, there exists \(>0\) such that \(y^{}=_{y}s_{}^{}(y)\)._

## 3 Hypervolume Scalarizations

In this section, we show the utility and optimality of a related scalarization known as the Hypervolume scalarization, \(s_{}^{}(y)=_{i}(y_{i}/_{i})^{k}\) that was introduced in Golovin and Zhang (2020). To gain intuition, we visualize the non-linear level curves of the scalarization, which shows that our scalarization targets the portion of the Pareto frontier in the direction of \(\) for any \(>0\) (see Figure 1), since the tangent point of the level curves of the scalarization is always on the vector in the direction of \(\). This implies that with an uniform distribution on \(\), we are guaranteed to have a uniform spread of Pareto points in terms of its angular direction.

Figure 1: **Left:** Comparisons of the scalarized minimization solutions with various weights with convex and non-convex Pareto fronts. The colors represent different weights; the dots are scalarized optima and the dotted lines represent level curves. Linear scalarization does not have an optima in the concave region of the Pareto front for any set of weights, but the non-linear scalarization, with its sharper level curves, can discover the whole Pareto front (Figure from (Emmerich and Deutz, 2018)). **Right:** The dotted red lines represent the level curves of the hypervolume scalarization with \(=v\), discovering \(b\), whereas the linear scalarization would prefer \(a\) or \(c\). Furthermore, the optima is exactly the Pareto point that is in the direction of \(v\).

**Lemma 5**.: _For any point \(y^{}\) on the Pareto frontier of any set \(\) that lies in the positive orthant, there exists \(>0\) such that \(y^{}=_{y}s_{}^{}(y)\). Furthermore, for any \(,>0\) such that \(\) is on the Pareto frontier, then \(_{y}s_{}^{}(y)\)._

This scalarization additionally has the special property that the expected maximized scalarized value under a uniform weight distribution on \(_{+}^{k-1}\) gives the dominated hypervolume, up to a constant scaling factor. Thus, the optima of the hypervolume scalarization over some static uniform distribution will be provably sufficiently diverse for any Pareto set in expectation.

**Lemma 6** (Hypervolume in Expectation ).: _Let \(_{T}=\{y_{1},...,y_{T}\}\) be a set of \(T\) points in \(^{k}\). Then, the hypervolume with respect to a reference point \(z\) is given by:_

\[_{z}(_{T})=c_{k}*{}_{ _{+}^{k-1}}[_{y_{T}}s_{}^{}(y-z)]\]

_where \(c_{k}=}{2^{k}\ (k/2+1)}\) is a constant depending only on \(k\)._

While this lemma is useful in the infinite limit, we supplement it by showing that finite-sample bounds on the strongly sublinear hypervolume convergence rate. In fact, many scalarizations will eventually explore the whole Pareto frontier in the infinite limit, but the rate at which the exploration improves the hypervolume is not known, and may be exponentially slow. We show that the optimizing hypervolume scalarizations with a uniform weight distribution enjoys _sublinear hypervolume regret_, specifically \(O(T^{-1/k})\) hypervolume regret convergence rates for any Pareto set \(\). Note that this rate is agnostic of the underlying optimization algorithm or Pareto set, meaning this is a general property of the scalarization.

Our novel proof of convergence uses a generalization argument to connect hypervolume-scalarized Bayes regret and its finite sample form, exploiting the Lipschitz properties of \(s_{}^{}\) to derive metric entropy bounds. Proving smoothness properties of our hypervolume scalarizations for any \(>0\) with \(\) normalized on the unit sphere is non-obvious as \(s_{}^{}(y)\) depends inversely on \(_{i}\) so when \(_{i}\) is small, \(s_{}^{}\) might change wildly.

**Theorem 7** (Sublinear Hypervolume Regret).: _Let \(_{T}=\{y_{1},...,y_{T}\}\) be a set of \(T\) points in \(^{k}\) such that \(y_{i}_{y}s_{_{i}}^{}(y-z)\) with respect to a reference point \(z\) and \(B_{l} y_{i}-z B_{u}\). Then, with probability at least \(1-\) over \(_{i}_{+}\) i.i.d., the hypervolume of \(_{T}\) with respect to \(z\) satisfies

Figure 2: The hypervolume scalarization taken with respect to a direction \(=w\) corresponds to a differential area element within dominated hypervolume and averaging over random directions is analogous to integrating over the dominated hypervolume in polar coordinates. We exploit this fact to show that by choosing the maximizers of \(T\) random hypervolume scalarizers, we quickly converge to the hypervolume of the Pareto frontier at an optimal rate of \(O(T^{-1/k})\). Figure from _sublinear hypervolume regret in \(T\):_

\[_{z}(^{})-_{z}(_{T})=O(T^{- }+T^{-})\]

_where \(O\) hides constant factors in \(k,B_{u},B_{l}\)._

_For \(k=2\), this also holds when Chebyshev scalarization is used: \(y_{i}_{y}s^{}_{_{i}}(y-z)\)._

We note that the distribution of Pareto points selected by the Chebyshev scalarizer is quite similar to the Hypervolume scalarizer as the formulas are almost identical, except for the inverse weights of the latter. In fact, we show that when \(k=2\), both scalarizers behave the same and enjoy strong convergence rates; however for \(k>2\), the Pareto distributions are in fact different under \(_{+}\) and we can empirically observe the suboptimality of the Chebyshev scalarizer. By definition, using the inverse weight distribution with the Chebyshev scalarizer will be equivalent to applying the Hypervolume scalarizer.

### Lower Bounds and Optimality

The dominating factor in our derived convergence rate is the \(O(T^{-1/(k+1)})\) term and we show that this cannot be improved. Over all subsets \(_{T}\) of size \(T\), note that our optimal convergence rate is given by the the subset that maximizes the dominated hypervolume of \(_{T}\), although finding this is in fact a NP-hard problem due to reduction to set cover. By constructing a lower bound via a novel packing argument, we show that even this optimal set would incur at least \((T^{-1/k})\) regret, implying that our convergence rates, derived from generalization rates when empirically approximating the hypervolume, are optimal.

Specifically, we show that for hypervolume regret, any algorithm cannot achieve better than \(O(T^{-1/(k-1)})\) regret even when using linear objectives, and this matches the dominating factor in our algorithm up to a small constant in the denominator. By using hypervolume scalarizations and its connection to hypervolume regret, we conclude that this also implies a \((T^{-1/(k-1)})\) lower bound on the scalarized Bayes regret.

**Theorem 8** (Hypervolume Regret Lower Bound).: _There exists a setting of linear objective parameters \(^{}\) and \(=\{a:\|a\|=1\}\) such that for any actions \(_{T}\), the hypervolume regret at \(z=0\) after \(T\) rounds is_

\[_{z}(^{})-_{z}(^{} _{T})=(T^{-})\]

**Corollary 9**.: _There is a setting of objectives \(^{}\) and \(=\{a:\|a\|=1\}\) such that for any actions \(_{T}\), the scalarized Bayes regret after \(T\) rounds is_

\[BR(s^{}_{},_{T})=(T^{-})\]

## 4 Multiobjective Stochastic Linear Bandits

We propose a simple scalarized algorithm for linear bandits and provide a novel \(_{p}\) analysis of the hypervolume regret that removes the polynomial dependence on \(k\) in the scalarized regret bounds. When combined with the \(_{}\) sharpness of the hypervolume scalarization, this analysis gives an optimal \(O(d/)\) bound on the scalarized regret, up to \((k)\) factors. This \(\) dependence on \(k\) is perhaps surprising but is justified information theoretically since each objective is observed separately. Note that our scalarized algorithm works despite of noise in the observations, which makes it difficult to even statistically infer measures of hypervolume progress. Our setup and algorithm is given in the Appendix (see Section A).

By using the confidence ellipsoids given by the UCB algorithm, we can determine each objective parameter \(^{}_{i}\), up to a small error. To bound the scalarized regret, we utilize the \(_{p}\) smoothness of \(s_{}\), \(L_{p}\), to reduce the dependence on \(k\) to be \(O(k^{1/p})\), which effectively removes the polynomial dependence on \(k\) when \(p\). This is perhaps not surprising, since each objective is observed independently and fully, so the information gain scales with the number of objectives.

**Lemma 10**.: _Consider running ExploreUCB (Algorithm 1) for \(T>(k,d)\) iterations and for \(T\) even, let \(a_{T}\) be the action that maximizes the scalarized UCB in iteration \(T/2\). Then, with probability at least \(1-\), the instantaneous scalarized regret can be bounded by_

\[r(s_{},a_{T}) 10k^{}L_{p}d}\]

_where \(L_{p}\) is the \(_{p}\)-Lipschitz constant for \(s_{}()\)._

Finally, we connect the expected Bayes regret with the empirical average of scalarized regret via uniform convergence properties of all functions of the form \(f()=_{a}s_{}(^{}a)\). By using \(s_{}^{}\) and setting \(p=\), we derive our final fast hypervolume regret rates for stochastic linear bandits, which is the combination of the scalarized regret rates and the hypervolume regret rates.

**Theorem 11** (HyperVolume Regret of ExploreUCB).: _Let \(z^{k}\) be a reference point such that over all \(a\), \(B_{l}^{}a-z B_{u}\). Then, with constant probability, running Algorithm 1 with \(s_{}^{}(y)\) and \(=_{+}\) gives hypervolume regret bound, for \(k\) constant,_

\[_{z}(^{})-_{z}(^{} _{T}) O(d}+ }})\]

## 5 Experiments

In this section, we empirically justify our theoretical results by comparing hypervolume convergence curves for multiobjective optimization in synthetic, linear bandit and blackbox optimization environments with multiple scalarizations and weight distributions. Our empirical results highlight the advantage of the hypervolume scalarization with uniform weights in maximizing the diversity and hypervolume of the resulting Pareto front when compared with other scalarizations and weight distributions, especially when there are a mild number of output objectives \(k\). Our experiments are not meant to show that scalarizations is the best way to solve multiobjective optimization; rather, it is a simple yet competitive baseline that is easily parallelized in a variety of settings. Also, we use slightly altered form of our hypervolume scalarization as \(s_{}(y)=_{i}y_{i}/_{i}\), which is a simply a monotone transform and does not inherently affect the optimization. All error bars are given between the 30 to 70 percentile over independent repeats.

### Synthetic Optimization

Our synthetic optimization benchmarks assume the knowledge of \(\) and the Pareto frontier and thus we can compute the total hypervolume and compare the hypervolume regret of multiple scalarizations with the uniform \(_{+}\) distribution. For our experiments, we fix our weight distribution and compare the three widely types of scalarizations that were previously mentioned: the Linear, Chebyshev, and the Hypervolume scalarization. We focus on the \(k=3\) setting and apply optimization for a diverse set of Pareto frontiers in the region \(x,y,z>0\). We discretize our region into \(30\) points per dimension to form a discrete Pareto frontier and set our reference point to be at \(z=[-,-,-]\) for \(=1\)e-4 and run for \(10\) repeats.

The synthetic Pareto frontiers that we are consider are a product of 1-dimensional frontiers and specifically, \(z=g(x) g(y)\), where \(g(x)=(-x),3-(x),( x)+1\), which form a concave, convex, and concave/convex Pareto frontiers respectively. Now that since the derivatives of these functions are all negative in our feasible region, \(z\) is a valid Pareto front. From our combination of functions, we observe that both Hypervolume and Chebyshev scalarizations enjoy fast convergence, while the performance of the Linear scalarization consistently lacks behind, surprisingly even for convex Pareto frontiers (see full plots in C.1). Interestingly, we observe that generally the Hypervolume scalarization does better on concave Pareto frontiers and on some convex-concave frontiers; however since these are static algorithms, it is not surprising that the Chebyshev distribution can perform better in certain convex regimes. However, we still advocate the usage of the hypervolume indicator as it is guaranteed to have a uniform spread especially when the number of objectives is increased, as shown by our later experiments.

### Stochastic Linear Bandits

We run Algorithm 1 and compare scalarization effects for the multiobjective linear bandit setting. We set our reference point to be \(=-\) in \(k\) dimension space, since our action set of \(=\{a:\|a\|=1\}\) and our norm bound on \(^{}\) ensures that our rewards are in \([-1,1]\).

In conjunction with the scalarizer, we use our weight distribution \(=_{+}\), which samples vectors uniformly across the unit sphere. In addition, we also compare this with the bounding box distribution methods that were suggested by (Paria et al., 2018), which samples from the uniform distribution from the min to the max each objective and requires some prior knowledge of the range of each objective (Hakanen and Knowles, 2017). Given our reward bounds, we use the bounding box of \([-1,1]\) for each of the \(k\) objectives. Following their prescription for weight sampling, we draw our weights for the linear and hypervolume scalarization uniformly in \(\) and take an inverse for the Chebyshev scalarization. We name this the boxed distribution for each scalarization, respectively.

To highlight the differences between the multiple scalarizations, we configure our linear bandits parameters to be anti-correlated, which creates a convex Pareto front with non-uniform curvature. Note that a perfect anti-correlated Pareto front would be linear, which would cause linear scalarizations to always optimize at the end points. We start with simple \(k=2\) case and let \(_{0}\) be random and \(_{1}=-_{0}+\), where \(\) is some small random Gaussian perturbation (we set the standard deviation to be about \(0.1\) times the norm of \(_{i}\)). We renormalize after the anti-correlation to ensure \(\|^{}\|=1\). We run our algorithm with inherent dimension \(d=4\) for \(T=100,200\) rounds with \(k=2,6,10\).

As expected, we find the hypervolume scalarization consistently outperforms the Chebyshev and linear scalarizations, with linear scalarization as the worst performing (see Figure 4). Note that when we increase the output dimension of the problem by setting \(k=10\), the hypervolume scalarization shows a more distinct advantage. The boxed distribution approach of (Paria et al., 2018) does not seem to fare well and consistently performs worse than its uniform counterpart. While linear scalarization provides relatively good performance when the number of objective \(k 5\), it appears that as the number of objectives increase in multi-objective optimization, more care needs to be put into the design of scalarization and their weights due to the curse of dimensionality, since the regions of non-uniformity will exponentially increase. We suggest that as more and more objectives are being added to modern machine learning systems, using smart scalarizations is critical to an uniform exploration of the Pareto frontier.

### BBOB Functions

We empirically demonstrate the competitiveness of hypervolume scalarizations for Bayesian Optimization by comparing them to the popular BO method of EHVI (Hupkens et al., 2015). Running our proposed multiobjective algorithms on the Black-Box Optimization Benchmark (BBOB) functions,

Figure 3: Comparisons of multiple scalarizations for the synthetic concave Pareto frontier given by \(z=(-x-y)\). The hypervolume regret for Linear is constant, and the Hypervolume enjoys a faster regret convergence rate than the Chebyshev.

which can be paired up into multiple bi-objective optimization problems (Tusar et al., 2016). Our goal is to use a wide set of non-convex benchmarks to supplement our experiments on our simple toy example of linear bandits. For scalarized approaches, we use hypervolume scalarizations with the scalarized UCB algorithm with a constant standard deviation multiplier of \(1.8\) and all algorithms with use a Gaussian Process as the underlying model with a standard Matern kernel that is tuned via ARD Williams and Rasmussen (2006).

Our objectives are given by BBOB functions, which are usually non-negative and are minimized. The input space is always a compact hypercube \([-5,5]^{n}\) and the global minima is often at the origin. For bi-objective optimization, given two different BBOB functions \(f_{1},f_{2}\), we attempt to maximize the hypervolume spanned by \((-f_{1}(x_{i}),-f_{2}(x_{i}))\) over choices of inputs \(x_{i}\) with respect to the reference point \((-5,-5)\). We normalize each function due to the drastically different ranges and add random observation noise. We also apply vectorized shifts of the input space of \(,-\) on the two functions respectively, so that the optima of each function do not co-locate at the origin.

We run each of our algorithms in dimensions \(d=8,16,24\) and optimize for \(160\) iterations with \(5\) repeats. From our results, we see that both EHVI and UCB with hypervolume scalarizations are competitive on the BBOB problems but the scalarized UCB algorithm seems to be able to explore the extreme ends of the Pareto frontier, whereas EHVI tends to favor points in the middle (see Appendix and Figure 5). From our experiments, this trend appears to be consistent across different functions and is more prominent as the input dimensions \(d\) increase.

Figure 4: Comparisons of the cumulative hypervolume plots with some anti-correlated \(\). When the output dimension increase, there is a clearer advantage to using the hypervolume scalarization over the linear and Chebyshev scalarization. We find that the boxed weight distribution does consistently worse than the uniform distribution.