# Neural Image Compression:

Generalization, Robustness, and Spectral Biases

 Kelsey Lieberman

Department of Computer Science

Duke University

Durham, NC USA

kelsey.lieberman@duke.edu

&James Diffenderfer

Lawrence Livermore National Laboratory

Livermore, CA USA

diffenderfer2@llnl.gov

Charles Godfrey

Thomson Reuters Labs

Eagan, MN USA

charles.godfrey@thomsonreuters.com

&Bhaya Kailkhura

Lawrence Livermore National Laboratory

Livermore, CA USA

kailkhural@llnl.gov

Work done at Pacific Northwest National Laboratory.

###### Abstract

Recent advances in neural image compression (NIC) have produced models that are starting to outperform classic codecs. While this has led to growing excitement about using NIC in real-world applications, the successful adoption of any machine learning system in the wild requires it to generalize (and be robust) to unseen distribution shifts at deployment. Unfortunately, current research lacks comprehensive datasets and informative tools to evaluate and understand NIC performance in real-world settings. To bridge this crucial gap, first, this paper presents a comprehensive benchmark suite to evaluate the out-of-distribution (OOD) performance of image compression methods. Specifically, we provide CLIC-C and Kodak-C by introducing 15 corruptions to the popular CLIC and Kodak benchmarks. Next, we propose spectrally-inspired inspection tools to gain deeper insight into errors introduced by image compression methods as well as their OOD performance. We then carry out a detailed performance comparison of several classic codecs and NIC variants, revealing intriguing findings that challenge our current understanding of the strengths and limitations of NIC. Finally, we corroborate our empirical findings with theoretical analysis, providing an in-depth view of the OOD performance of NIC and its dependence on the spectral properties of the data. Our benchmarks, spectral inspection tools, and findings provide a crucial bridge to the real-world adoption of NIC. We hope that our work will propel future efforts in designing robust and generalizable NIC methods. Code and data will be made available at https://github.com/klieberman/ood_nic.

## 1 Introduction

Consider the Mars Exploration Rover, whose scientific objective is to search for clues to past activity of water (and perhaps life) on Mars. To achieve this, the rover collects images of interesting rocks and soils to be analyzed by the scientists on Earth. Sending these images down the Earth-bound data stream in their original form is too slow and expensive due to limited bandwidth. Thus, it is well accepted that image compression could play a key role in producing scientific breakthroughs .

Employing image compression in such a setting is challenging for three main reasons: 1) a _high compression ratio_ is desired due to low communication bandwidth, 2) given the battery-operated nature of these devices, the compression module has to be _lightweight_ so it consumes less memory and power, and 3) _robustness and generalization_ to environmental noises and domain shifts, respectively, are desired due to limited Mars-specific training data. These requirements are not specific to the planetary exploration use case but also arise in a wide range of scientific applications which use image compression in the wild .

Recently, neural image compression (NIC) has demonstrated remarkable performance in terms of rate-distortion and runtime overhead on in-distribution (IND) data --satisfying requirements 1) and 2). However, there is limited work on understanding the out-of-distribution (OOD) robustness and generalization performance of image compression methods (requirement 3) . Our work is driven by several open fundamental empirical and theoretical questions around this crucial issue.

_How can the expected OOD performance of image compression models be reliably assessed? Can we gain a deeper understanding of the modus operandi of different image compression methods? How do training data properties and biases impact data-driven compression methods?_

Main Contributions:This paper takes a critical view of the state of image compression and makes several contributions toward answering the aforementioned questions. 

First, we design _comprehensive benchmark datasets_ for evaluating the OOD performance of image compression methods. Inspired by existing OOD benchmarks for classification and detection , we design CLIC-C and Kodak-C by introducing 15 common shifts emulating train-deployment distribution mismatch to the popular CLIC and Kodak datasets. 

Next, we focus on understanding the image compression performance. The de-facto approach is to use rate-distortion (RD) curves measured with perceptual quality metrics, such as PSNR. Such scalar metrics, although easy to compute, are known to be extremely limited in what they can capture and sometimes can even be misleading . To complement RD curves, we propose _spectrally-inspired inspection tools_ that provide a more nuanced picture of (a) compression error, and (b) OOD performance of a given method. Specifically, we introduce a power spectral density (PSD) based approach to understand the reconstruction error. Our approach not only quantifies how much error was made but also highlights precisely where it was made (in the frequency domain). Similarly, to understand the OOD performance of a compression method in unseen deployment scenarios, we propose _Fourier error heatmaps_--a visualization tool for highlighting the sensitivity of the reconstruction performance of a compression method to different perturbations in the frequency domain. 

Using our benchmark datasets and inspection tools, we carry out _a systematic empirical comparison_ of classic codecs (i.e., JPEG2000, JPEG, and VTM) with various NIC models (fixed rate, variable rate, and pruned versions of the scale hyperprior model , as well as efficient learned image compression (ELIC) ). 

Finally, we develop _theoretical tools_ to connect NIC OOD performance with its training data properties.

Main Findings:Our analysis resulted in some invaluable insights about the state of image compression. We summarize some of our findings below.

* Compression methods yielding the same PSNR (or bpp) can produce very different spectral artifacts. Our tools help uncover hidden spectral biases and highlight the limitations of de-facto RD curve-based performance comparison.
* As the compression rate increases, different codecs prioritize different parts of the frequency spectrum. By precisely characterizing this behavior, our tools help in advancing the current understanding of the modus operandi of image compression methods.
* Image compression models generalize to low- and mid-frequency shifts better than high-frequency shifts. This finding calibrates our expectations for image compression performance on OOD data.
* NIC models are better at denoising high-frequency corruptions than classic codecs. This finding reveals that unlike classic codecs, NIC models have an inherent spectral bias due to the image frequencies present in their training data.
* Identifying the most suitable compression method becomes exceptionally challenging without the knowledge of spectral characteristics of OOD shifts. Our systematic evaluation identifies this open issue with current compression methods and suggests the design of next-generation NIC models that can adapt themselves at runtime based on the spectral nature of the data to be a potentially worthwhile direction to pursue in the future.

We corroborate our findings with a detailed theoretical analysis, showing that multiple overarching trends in our experimental results can be attributed to neural compression models' spectral bias.

_Appendix A has a detailed related work discussion, while all references are listed in the main paper._

## 2 Out-of-distribution image compression datasets

To evaluate NIC in the presence of environmental or digital distribution shifts, we generated variants of the CLIC and Kodak datasets, which we refer to as CLIC-C and Kodak-C. Following the techniques presented in  for studying the performance of DNN classifiers encountering distributional shifts "in the wild", our -C datasets consist of images augmented by 15 common corruptions. For each image in the original dataset, the -C dataset contains a corrupted version of the image for each of the 15 common corruptions2, and for each of five corruption severity levels, with 1 being the lowest severity and 5 being the highest. A sample of some corruptions on CLIC-C is provided in Figure 0(a).

While each -C dataset offers a broad sampling of environmental or digital image corruptions, it also provides a spectrally diverse collection of corruptions, in the sense that each corruption can be categorized as low, medium, or high frequency based on the frequency content used for perturbations. We will write \(PSD()\) to denote the function that converts the input image from the spatial to the frequency domain by computing the power spectral density of the input. Practically, computing \(PSD()\) is done by applying the fast Fourier transform (FFT) , followed by a shift operation to center the zero-frequency component, then taking the absolute value. Now suppose we have a set \(=\{X_{k}\}_{k=1}^{N}\) of uncorrupted images and some corruption function \(c()\) (e.g., frost, gaussian noise, etc.). We analyze the spectrum each corruption \(c()\) by computing \(_{i=1}^{N}PSD(X_{i}-c(X_{i}))\) (see Figure 0(a)). We classify the corruptions into types of frequencies: low, medium, and high using the characterization from , which has been adopted by the neural network robustness community. Note that categorizing a corruption as high is more akin to saying it "contains substantial high-frequency content" rather than saying it "exclusively consists of high-frequency content."

## 3 Spectral inspection tools

While existing scalar metrics, such as PSNR, are able to summarize the visual similarity of reconstructed images to the original, we will demonstrate that such metrics can provide an incomplete (and sometimes misleading) picture when measuring the impact of compression in OOD settings. Notably, existing tools do not consider the impact of compression on different frequency ranges of images within a dataset. To more thoroughly analyze the effects of image compression, we propose to measure and visualize the effect of image compression in the spectral domain. Given an image compression model \(\) that returns reconstructed images, we introduce tools for analyzing compression

Figure 1: **(a) Top row: An original CLIC image and the same image with 3 different corruptions in CLIC-C (severity 5). Bottom left: Average PSD of CLIC dataset, \(_{k=1}^{N}PSD(X_{k})\). Bottom row, other figures: Average PSD of the difference between the corrupted images and the clean images for each given CLIC-C corruption \(c\), \(_{k=1}^{N}PSD(c(X_{k})-X_{k})\). b) CLIC-C corruptions categorized as low, medium, or high based on corruption average \(PSD\).**

error in the Fourier domain to better understand (\(i\)) which _spectral frequencies_ are distorted by \(\), (\(ii\)) the _OOD generalization_ error, and (\(iii\)) the _robustness_ error in the presence of distributional shifts.

**Definition 3.1** (Spectral Measure of Distortion Error).: To analyze (\(i\)), we evaluate the image compression model \(\)'s ability to reconstruct components of an image across a range of frequencies. To quantify this, we compute the average PSD of the difference between each image \(X_{k}\) in a dataset \(\) and the reconstructed version \((X_{k})\) of \(X_{k}\): \((,):=_{k=1}^{N}PSD(X_{k}- (X_{k}))\).

**Definition 3.2** (Spectral Measure of OOD Generalization Error).: For (\(ii\)), we evaluate \(\)'s ability to faithfully reconstruct OOD images. To quantify this, we extend the metric \((,)\) to account for a corrupted version \(c()\) of \(\) as follows: \((,,c):=_{k=1}^{N}PSD(c(X_{k}) -(c(X_{k})))\).

**Definition 3.3** (Spectral Measure of OOD Robustness Error).: For (\(iii\)), we evaluate \(\)'s denoising ability. To quantify this, we compute the average PSD of the difference between each uncorrupted image \(X_{k}\) and the reconstructed version \((c(X_{k}))\) of the corresponding corrupted image \(c(X_{k})\): \((,,c):=_{k=1}^{N}PSD(X_{k}- (c(X_{k})))\).

The \(PSD\) function used in the above formulas converts the input image from the spatial to frequency domain by applying the Fast Fourier Transform (FFT) followed by a shift operation to center the zero-frequency component. The proposed tools are computed for a set of images by averaging the power spectral density (PSD) of the difference between the compressed image and the original for each image in the set of images. For simplicity, when \((,,c)\) is clear from the context, we will just write \(\), \(\), or \(\). Note that \(\) provides insight into the compression model \(\)'s ability to generalize to a distribution shift \(c\) while \(\) visualizes the denoising effect (or lack thereof) of \(\) across the frequency domain.

In Appendix B, we present results using an additional tool, _the Fourier heatmap_, that utilizes Fourier basis perturbations as corruptions and is used to corroborate our findings for the specific -C datasets and corruptions we consider. This tool can be leveraged when specific OOD data is unavailable.

## 4 Experiments and findings

Using our spectral inspection tools and OOD datasets, we analyze the performance of several image compression methods and identify several inter- and intra-class differences between classic codecs and NIC methods. We show results for two classic codecs, JPEG and JPEG2000, and two NIC models, SH NIC and ELIC, in the main body and report the remaining results in Appendices C and D.

**Classic codecs.** We apply each of the following algorithms over several compression rates \(q\).

* **JPEG**
* **JPEG2000**
* Versatile Video Coding (VVC) (equivalently h.266) using the VVC Test Model (VTM) software 

**Neural Image Compressors (NIC) Models.** NIC optimization uses a hyperparameter \(\) to control the relative weight of distortion (quality of reconstruction) and rate (level of compression) terms in the objective function. We train each NIC model over several values of \(\). All models were optimized on the train split of the 2020 CLIC dataset . Further details on their model architectures and training can be found in Appendix I.

* **SH NIC**: Scale-hyperprior model from Balle _et al._ optimized for PSNR (_i.e.,_ distortion objective is mean squared error) .
* **ELIC**: Efficient Learned Image Compression optimized for PSNR .
* **V**ariant of SH NIC optimized for MS-SSIM .
* **V**ariable-rate version of SH NIC optimized using Loss Conditional Training .
* **Variable-rate model above with 80-95% of weights pruned using gradual magnitude pruning .

**Evaluation setup.** We compare distortion, robustness, and generalization error of different image compression methods under three constraints: (a) **no constraint**, (b) **fixed-bpp**, and (c) **fixed-PSNR**. In (a), we compare methods over their full range of rate-distortion tradeoffs by generating rate-distortion curves. In (b), we compare models with hyper-parameters which give a very similar bits per pixel (bpp) result on a particular dataset. For example, we find that on the CLIC dataset, SH NIC with \(=0.15\), ELIC with \(=0.15\), JPEG2000 with \(q=10\), and JPEG with \(q=75\) all give a bpp close to 1.21. Thus, comparing these three models with those hyper-parameters on CLIC under a fixed-bpp constraint, _emulates a setting in which a fixed budget is available to store images_. Analogously, in (c) we compare models with hyper-parameters yielding a fixed PSNR. This allows the comparison of spectral properties of data distributions that _achieve the same quality according to the scalar PSNR metric_. Scenarios (b) and (c) are used when evaluating \(,,\), Fourier heatmaps, and accuracy on a downstream task.

**Test data.** All models are tested on (a) in-distribution (IND) and (b) corrupted (or OOD) datasets. For (a), we use the 2020 CLIC test split, the full Kodak dataset, and the ImageNet validation split. For (b), we use the corresponding -C datasets for each of the datasets in (a). The main body contains results for the CLIC/CLIC-C dataset. Analogous results for Kodak are in Appendix G.

### Evaluating spectral distortion on IND data

On in-distribution (IND) data, the existing RD curve metrics in the center of Figure 2 highlight the established trend that these NIC models outperform the JPEG2000 and JPEG across the compression rates that the NIC model is trained on (bpp \([0.1,1.5]\)), with ELIC outperforming SH NIC and JPEG2000 outperforming JPEG.

Next, we use our spectral inspection tool \(\) to better understand the effects of different image compression methods. Specifically, Figure 2 shows plots of \(\) under three fixed-bpp and three fixed-PSNR scenarios on the clean CLIC dataset. We highlight some surprising insights below.

**Two methods yielding the same PSNR can produce very different spectral artifacts.** Under the fixed-PSNR constraint (right side of Figure 2), each column consists of methods with hyper-parameters selected to give very similar PSNRs on the CLIC test set (_e.g._, models on the "high psnr" column all have PSNR \( 36.8\)). Despite having comparable PSNRs, the plots of \(\) vary greatly between the four models. In particular, the SH NIC models distort high frequencies more than medium frequencies (notice the warmer-colored rings around the edges of the \(\) plots with cooler-colored centers). JPEG2000, on the other hand, distorts low and medium frequencies more than high frequencies (notice the large rectangles of warmer colors). ELIC distorts all frequencies relatively evenly (the color gradients in the plots are very narrow).3 JPEG severely distorts one ring, but this ring includes lower frequencies (has a smaller radius) than the rings left by SH NIC. This same pattern holds under the fixed-bpp constraint (left side of Figure 2). These observations demonstrate that _PSNR is not a comprehensive metric_.

Figure 2: **Visualizing distortion via CLIC test set evaluation.****Left:** spectral measure of in-distribution reconstruction error \(\) under the fixed-bpp constraint at three rates. **Center:** Rate-distortion curves with vertical lines indicating fixed-bpp values and horizontal lines indicating fixed-PSNR values. **Right:**\(\) under fixed-PSNR constraint. Each \(\) plot is labeled with a tuple of that model’s (bpp, PSNR) on CLIC. Hotter colors (red) indicate more error in that frequency range.

**As the compression rate increases, different codecs prioritize different parts of the spectrum.** On the left side of Figure 2, each column represents a different "budget" scenario where the three methods have hyper-parameters which result in the models giving very similar bpps on the CLIC test set. Although it was previously known that the quality of the reconstructed images decreases as the bpp decreases, it was not previously known _which_ frequencies NIC models distort to achieve a given bpp. The \(\) plots show that JPEG2000 models corrupt low- and mid-frequency regions starting at low compression rates and these regions become more severe as the budget decreases. SH NIC models do almost the opposite--they sacrifice the highest frequencies first and expand this region into lower frequencies at more severe compression rates (_i.e._, as bpp decreases). JPEG has a mechanism more similar to JPEG2000 in that it corrupts one ring and increases the severity of this ring, while ELIC models corrupt all frequencies evenly and then corrupt low frequencies more as bpp decreases. This suggests that _as the compression rate increases, classic codecs corrupt the same frequencies more severely while NIC models change their corruption patterns_.

### Evaluating the generalization and the robustness on OOD data

We use the CLIC-C dataset and our spectral tools to study the OOD performance of different image compression methods. We show results for example shifts (one low, medium, and high-frequency representative) and three severities (1, 3, and 5 where 5 is most severe) in Figures 3 and 4 and discuss several interesting findings below.

#### 4.2.1 Rate-distortion curves on OOD data

**Image compression models generalize to low- and mid-frequency shifts better than high-frequency shifts.** The top row of Figure 3 shows how well different compression models generalize to shifted images in terms of RD curves. In other words, these plots show how well a compressor \(\) can reconstruct a given shifted image \(c()\) in terms of PSNR of \((c())\) with respect to \(c()\). The three examples of corruption in this figure show vastly different trends. On the low-frequency corruption (snow), all four models can reconstruct \(c()\) almost as well as these models can reconstruct clean images: note the PSNR range in the top left plot of Figure 3 is about 22-40 while the PSNR range for the clean data in Figure 2 is about 28-42 over the same bpp range. Interestingly, the three models can reconstruct the images with the glass blur (a medium-frequency shift) _better_ than they can reconstruct clean images (the PSNR of the data shifted with glass blur ranges from about 25-48 with bpp < 1). These results suggest that _image compression models are fairly effective at generalizing to low-frequency shifts and very effective at generalizing to medium-frequency shifts_. However, the

Figure 3: **Rate-distortion curves for a representative low, medium, and high-frequency shift.** Each shift and model has three curves for severity=1 (least transparent), severity=3, and severity=5 (most transparent). **Top row:** generalization of \((c())\) w.r.t. \(c()\) (_i.e._, PSNR of the reconstructed shifted images w.r.t. the original shifted images). **Bottom row:** denoising of \((c())\) w.r.t. \(\) (_i.e._, PSNR of the reconstructed shifted images w.r.t. the original clean images).

high-frequency shift (shot noise), gives a starkly different result. All four models give very low PSNRs with respect to \(c()\). Even at the lowest severity (severity=1), this PSNR is only in the low 20s. As the severity increases (_i.e._, as the lines become more transparent), the PSNR decreases even more to the point that, at the highest severity, none of the models can achieve a PSNR higher than 14. Notably, the main factor determining the PSNR is the severity of the corruption and not the compression model or bpp. This suggests that _it is significantly harder to generalize to high-frequency data than to low- or mid-frequency data._

**NIC models are better at denoising high-frequency corruptions than classic codecs.** The second row of Figure 3 shows how well different compressors \(\) denoise corrupted images in terms of the PSNR of \((c())\) with respect to \(\). These results show that all the models fail at denoising snow (low-frequency) and glass blur (medium-frequency) corruptions (PSNR does not change much with an increase in bpp, except at low bpps on glass blur). However, on shot noise (a high-frequency corruption) both NIC models achieve better PSNRs with respect to \(\) than both classic codecs. This trend is consistent for all three severity levels and suggests that _NICs may be a more effective method for denoising high-frequency corruptions than the previously-used JPEG and JPEG2000 methods_. The implication of this finding extends to the research area of adversarial example denoising .

#### 4.2.2 Spectral analysis on OOD data

We now take a deeper look at the Section 4.2.1 findings using our spectral inspection tools.

**Spectral artifacts are similar for low-frequency shifts and clean images.** The patterns of \(\) in Figure 4 measure how well each model generalizes to (or reconstructs) the shifted images. For the low-frequency shift (top row of Figure 4), the plots look strikingly similar to the patterns exhibited by the same models on clean data (Figure 2 top and bottom row): SH NIC models distort high frequencies more than low frequencies while JPEG2000 distorts low and medium frequencies more than high frequencies. Similarly, ELIC distorts all frequencies relatively evenly and JPEG severly distorts one ring of frequencies. This suggests that _the methods' modus operandi for generalization to data with low-frequency shifts is similar to their modus operandi on clean data_, which makes sense as clean data is dominated by low/mid frequencies. Interestingly, these generalization differences between compressors are not accompanied by differences in robustness metric \(\). All methods show similar patterns in their plots of \(\) patterns and these in turn look similar to the snow corruption plot in Figure 0(a). This is consistent with our finding from Figure 3 which showed that both NIC and

Figure 4: **Generalization error \(\) (top) and denoising error \(\) (bottom).** We plot both spectral metrics for one low, medium, and high-frequency corruption at severities 1 and 5. Each plot is labeled with a tuple of that model’s (bpp, PSNR) on the CLIC-C dataset with that corruption.

JPEG200 fail to denoise low-frequency corruptions. In other words, Figure 4 shows that _NIC and classic codecs fail in a very similar manner on low-frequency signal denoising tasks._

**Both NIC and classic codecs make almost no generalization error on medium-frequency shifts.** The second row of Figure 4 shows that all four methods have very small generalization errors (magnitudes < 0.2), and this low error is relatively uniform across all frequencies. This shows that all the models models are very effective at reconstructing all the frequencies in images with glass blur--in fact, they can reconstruct these images _better_ than they can reconstruct clean images--corroborating our first finding in Section 4.2.1. Again the \(\) plots for glass blur for both of these models look very similar to Figure 1a; _this similarity has a simple explanation due to a fundamental tradeoff between generalization and robustness_. This relationship between \(,\) and average PSD of corruptions is described more precisely in Appendix L.4.

**High-frequency corruptions uncover the spectral bias of NIC models.** Section 4.2.1 highlighted that high-frequency signals severely degrade the generalization performance of all image compression methods. From the RD curves with respect to the corrupt images (top right plot in Figure 3), we observe that at each severity the three models have almost identical performance in the usual 0-2 bpp range. _These results might lead us to expect that these models make similar reconstruction mistakes, but our spectral inspection tools indicate that this is not the case at all._ Our plots of \(\) on shot noise at severity=5 (bottom row, columns 2, 4, 6, and 8 of Figure 4) indicate that NIC models distort the highest frequencies significantly more than the low and medium frequencies (notice the orange borders of the plots) while JPEG and JPEG2000 exhibit different patterns. This nuance, which is equivalent to one we previously observed with clean data in Figure 2, becomes more apparent from the plots of \(\) on a high-frequency corruption because high-frequency signals are much more prevalent on this data than on the clean data. Additionally, the bottom right plot of Figure 3 shows that for shot noise, NIC models achieve higher PSNR of the reconstructed corrupt images with respect to the clean images than the classic codecs, _i.e.,_ they have a stronger denoising effect. In the bottom right of Figure 4 we see a more detailed picture: for high severity shot noise, NIC models achieve lower \(\) in high frequencies. Also, note that the NIC models have the smallest errors in \(\) whereas they have the largest errors in \(\) and vice versa. Thus, these findings suggest that _NIC models behave similarly to a low-pass filter_.

### Impact of spectral artifacts on downstream applications

In practice, image compression algorithms may be used as a pre-processing step before images are used for another downstream task. For this reason, practitioners should also consider the performance on downstream tasks when comparing compression methods. We analyze the effectiveness of the compression methods on the downstream task of ImageNet classification using a pre-trained ResNet-50 model and report the difference in top-1 accuracy after compression (Figure 5) .

Figure 5: **Effect of compressing corrupt images on classification accuracy.** Each bar shows the average difference in accuracy after compressing with different methods \(\) for a group of corruptions as classified in Table 0(b). Specifically, let \(A(X)\) be the top-1 accuracy of the model on dataset \(X\), measured in percentage points. Then we report \(A((c(X)))-A(c(X))\) over all -C corruptions in the corruption category with severity 3 (or on clean ImageNet in the case of “clean”). Each subplot shows results under a different fixed-PSNR constraint based on the PSNRs achieved by the compressors on the clean ImageNet dataset. Results for individual corruptions are in Figure 15.

**NIC can improve the robustness of downstream classification to high-frequency corruptions.** While in general, compression degrades classification performance on clean images (all compressors show negative differences for the "clean" category in Figure 5), in some cases NIC and JPEG can actually improve the robustness of the classification model against high-frequency corruptions. Specifically, at PSNR=36.93, the difference in accuracy is _positive_ for high-frequency corruptions with both SH NIC and ELIC, meaning that the classification model gave a higher accuracy on the set of corrupted images after compression than it did on the original corrupted images. Compressing with JPEG or JPEG2000 at the same rate caused a degradation in accuracy on these corruptions. However, at higher compression rates (PSNR=32.97 and PSNR=31.17), JPEG improves classification performance for high-frequency corruptions, while SH NIC and ELIC do not. On low- and mid-frequency corruptions, JPEG and JPEG2000 have a smaller degradations in accuracy compared to NIC the NIC models and no model gives an improvement in classification accuracy. Thus, _the ideal compressor for downstream tasks is dependent on the type of corruption and level of compression_.

**Pruning NIC models amplifies the robustness gains of NIC for downstream classification tasks.** Additional experimental results in Appendix C (Figure 9), show that _pruned NIC and NIC optimized for MS-SSIM act as even better high-frequency signal denoisers for this application_.

## 5 Theoretical analysis of the OOD performance of NIC

We corroborate our empirical findings with theoretical results. Here we summarize theoretical results on linear autoencoder-based NIC methods. For complete definitions, additional references, and proofs of the following statements, please refer to Appendix L. In Appendix L.3, we provide a more general result applicable to nonlinear models.

Recall a classical observation: in the setting of linearly auto-encoding a mean-centered distribution, the reconstruction function (_i.e._, encoder-decoder composition) is a projection onto the high-variance principal components of the input data  (see also ). Combining this with well-known facts about statistics of natural images, we show that a linear autoencoder applied to a natural image dataset retains only low-to-mid (spatial) frequency components, which account for the majority of the variance. Using this result, we state theoretical explanations for multiple trends in our experiments4.

**Lemma 5.1**.: _Let \(\) be a dataset of natural images and let \(}\) denote its (spatial) discrete Fourier transform. Assume the following (for supporting evidence see Appendix L):_

1. _The principal components of_ \(}\) _are roughly aligned with the spatial Fourier frequency basis._
2. _The associated variances are monotonically decreasing with frequency magnitude (more specifically according to the power law_ \(|^{}+||^{}}\)_)._

_If \(\) is a linear autoencoder trained by minimizing MSE on \(\), with latent space of dimension \(r\), and if "\(\)" denotes the spatial discrete Fourier transform, for any data point \(X\) with Fourier transform \(\)_

\[(X)}_{:,ij}&:i^{2}+j^{2} \\ 0&:\]

_where \(K\) is the number of channels in the images in \(\) and where \(_{:,ij}\) denotes the components of \(\) corresponding to spatial frequency \((i,j)\)._

**Corollary 5.2**.: _Under the hypotheses of Lemma 5.1, the robustness error of \(\) to a corruption \(c\) (as defined in Definition 3.3), measured in spatial frequency \((i,j)\), is_

\[(,,c)_{ij} _{k}|()}-})_{:,ij}|&:i^{2}+j^{2} \\ _{k}|_{k:,ij}|&:\]

**Corollary 5.3**.: _Under the hypotheses of Lemma 5.1, the generalization error of \(\) to a corruption \(c\) (as defined in Definition 3.2), measured in spatial frequency \((i,j)\), is_

\[(,,c)_{ij}0&:i^{2}+j^{2} \\ _{k}_{:,ij}|^{2}+2_{:,ij}(- )_{:,ij}+|(-)_{:,ij}|^{2}}&:\]Lemma 5.1 suggests that autoencoder compressors trained on natural images behave like low-pass filters, corroborating our claim in Section 4.2.2 (see also remark L.1).

Corollary 5.2 suggests that _autoencoder compressors trained on natural images are less robust to corruptions with large amplitude in low frequencies_ (in the sense that \(|(c(X)-X)_{:,ij}|^{2}\) is large for small values of \(ij\)). This is indeed what we see in Figure 3 (bottom left), where snow corruptions are detrimental to PSNR of \((c())\) w.r.t. \(\), and Figure 4, where the \((,,c)\) error for the NIC is concentrated in low frequencies. We also observe in Figure 5 that NIC is more beneficial for downstream classification accuracy in the case of high-frequency corruptions (e.g. shot noise) and less beneficial in the case of low-frequency corruptions (e.g. snow).

On the other hand, the conclusion of Corollary 5.3 is more involved than that of Corollary 5.2-the "cross term" \(2_{:,ij}(-)_{:,ij}\) is in general non-zero. However, there are cases where in expectation over the data set \(\) this cross term vanishes (_e.g._, when \(c\) is additive noise). In such cases, Corollary 5.3 suggests that _compressors trained on natural images generalize less successfully to shifts with large amplitude in high frequencies_. In Figure 3 (top right) we see that shot noise corruptions are detrimental to PSNR of \((c())\) w.r.t. \(c()\), and in Figure 4 we see that for the snow and shot noise corruptions, \((,,c)\) are concentrated in high frequencies.5 In summary, with both theoretical analysis of a simple mathematical model and empirical results, we find that _NICs have a spectral bias that causes them to overfit to discard high frequency components of natural images._.

## 6 Limitations

Due to the number of axes of variation present in our experiments (_e.g._, model type, compression rate, evaluation dataset, corruption type, corruption severity, evaluation metric), we were forced to constrain many variables. We present results for a limited number of NIC models all trained on one dataset, CLIC. Due to limitations on the number of models we could train and discrete choices for classic codec hyper-parameters, there is some variation within our fixed- {bpp,PSNR} bins.

Evaluating the robustness of any machine learning system is inherently a multi-faceted problem riddled with unknown-unknowns. While we focus on robustness to naturalistic input-data corruptions, there are other important distribution shifts for researchers and practitioners to consider, such as subtle changes in data collection methodology . We omit a study of NIC model _adversarial_ robustness to worst-case input data perturbations. Nevertheless, we hope that the our evaluation methods (including our metrics \(\{,,\}\) and Fourier heatmap spectral inspection tools) will be useful in future work on NIC model robustness.

## 7 Conclusion and future directions

We proposed benchmark datasets and inspection tools to gain a deeper understanding of the robustness and generalization behavior of image compression models. Using our spectral inspection tools, we uncovered the modus operandi of different compression methods. We also highlighted similarities and differences among them via a systematic OOD evaluation. Exploring the use of our tools in other image compression methods, including transformer-based architectures and implicit neural representations methods is expected to provide interesting insights [41; 72; 73; 45; 54]. Our OOD evaluations identify NIC model brittleness issues: designing practical robust training approaches and/or methods to efficiently adapt to distribution shifts at runtime is a worthwhile research direction.