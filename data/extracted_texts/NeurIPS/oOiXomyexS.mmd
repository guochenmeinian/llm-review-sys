# A Benchmark on Directed Graph Representation Learning in Hardware Designs

Haoyu Wang

Georgia Tech &Yinan Huang

Georgia Tech &Nan Wu

George Washington University &Pan Li

Georgia Tech

###### Abstract

To keep pace with the rapid advancements in design complexity within modern computing systems, directed graph representation learning (DGRL) has become crucial, particularly for encoding circuit netlists, computational graphs, and developing surrogate models for hardware performance prediction. However, DGRL remains relatively unexplored, especially in the hardware domain, mainly due to the lack of comprehensive and user-friendly benchmarks. This study presents a novel benchmark comprising five hardware design datasets and 13 prediction tasks spanning various levels of circuit abstraction. We evaluate 21 DGRL models, employing diverse graph neural networks and graph transformers (GTs) as backbones, enhanced by positional encodings (PEs) tailored for directed graphs. Our results highlight that bidirected (BI) message passing neural networks (MPNNs) and robust PEs significantly enhance model performance. Notably, the top-performing models include PE-enhanced GTs interleaved with BI-MPNN layers and BI-Graph Isomorphism Network, both surpassing baselines across the 13 tasks. Additionally, our investigation into out-of-distribution (OOD) performance emphasizes the urgent need to improve OOD generalization in DGRL models. This benchmark, implemented with a modular codebase, streamlines the evaluation of DGRL models for both hardware and ML practitioners.

## 1 Introduction

Directed graphs, where edges encode directional information, are widely utilized as data models in various applications, including email communication [62; 66], financial transactions [22; 41; 117], and supply chains [61; 113; 125]. Notably, hardware designs can be represented as directed graphs, such as circuit netlists [47; 124], control and data flow graphs [11; 26; 137; 144], or computational graphs [100; 150], often exhibiting unique properties. These graph structures reflect restricted connection patterns among circuit components or program operation units, with directed edges encapsulating long-range directional and logical dependencies.

Recently, employing machine learning (ML) to assess the properties of hardware designs via their directed graph representations has attracted significant attention [11; 14; 29; 45; 51; 71; 85; 100; 135]. Traditional simulation-based methods often require considerable time (hours or days) to achieve the desired accuracy in assessing design quality [27; 136; 137; 154], substantially slowing down the hardware development cycle due to repeated optimization-evaluation iterations. In contrast, ML models can serve as faster and more cost-effective surrogates for simulators, offering a balanced alternative between simulation costs and prediction accuracy [8; 15; 16; 19; 31; 59; 77; 91; 126; 134;136]. Such an approach is promising to expedite hardware evaluation, especially given the rapid growth of design complexity in modern electronics and computing systems .

Despite the promising use cases, developing ML models for reliable predictions on directed graphs, particularly within hardware design loops, is still in its early stages, largely due to the lack of comprehensive and user-friendly benchmarks. Existing studies in the ML community have primarily focused on undirected graphs, utilizing Graph Neural Networks (GNNs)  or Graph Transformers (GTs) . Among the limited studies on directed graph representation learning (DGRL) , most have only evaluated their models for node/link-level predictions on single graphs in domains such as web networks, or financial networks . These domains exhibit very different connection patterns compared to those in hardware design. To the best of our knowledge, CODE2 in the Open Graph Benchmark (OGB)  is the only commonly used benchmark that may share some similarities with hardware data. However, the graphs in CODE2 are IRs of Python programs, which may not fully reflect the properties of data in hardware design loops.

Numerous DGRL models for hardware design tasks have been developed by domain experts. While promising, hardware experts tend to incorporate domain-specific insights with off-the-shelf GNNs (e.g., developing hierarchical GNNs to mimic circuit modules  or encoding circuit fan-in and fan-out in node features ), with limited common design principles investigated in model development. In contrast, state-of-the-art (SOTA) DGRL techniques proposed by the ML community lack thorough investigation in these tasks. These techniques potentially offer a more general and effective manner of capturing data patterns that might be overlooked by domain experts.

**Present Benchmark.** This work addresses the aforementioned gaps by establishing a new benchmark consisting of representative hardware design tasks and extensively evaluating various DGRL techniques for these tasks. On one hand, the evaluation results facilitate the identification of commonly useful principles for DGRL in hardware design. On the other hand, the ML community can leverage this benchmark to further advance DGRL techniques.

Specifically, our benchmark collects five hardware design datasets encompassing a total of 13 prediction tasks. The data spans different levels of circuit abstraction, with graph sizes reaching up to 400+ nodes per graph across 10k+ graphs for graph-level tasks, and up to 50k+ nodes per graph for node-level tasks (see Fig. 1 and Table. 1). We also evaluate 21 DGRL models based on 8 GNN/GT backbones, combined with different message passing directions and various enhancements using positional encodings (PEs) for directed graphs . PEs are vectorized representations of node positions in graphs and have been shown to improve the expressive power of GT/GNNs for undirected graphs . PEs for directed graphs are still under-explored , but we believe they could be beneficial for hardware design tasks that involve long-range and logical dependencies.

Our extensive evaluations provide significant insights into DGRL for hardware design tasks. Firstly, bidirected (BI) message passing neural networks (MPNNs) can substantially improve performance for both pure GNN encoders and GT encoders that incorporate MPNN layers, such as GPS . Secondly, PEs, only when used stably , can broadly enhance the performance of both GTs and GNNs. This observation contrasts with findings from undirected graph studies, particularly in molecule property prediction tasks, where even unstable uses of PEs may improve model performance . Thirdly, GTs with MPNN layers typically outperform pure GNNs on small graphs but encounter scalability issues when applied to larger graphs.

With these insights, we identify two top-performing models: GTs with BI-MPNN layers (effective for small graphs in the HLS and AMP datasets) and the BI-Graph Isomorphism Network (GIN) , both enhanced by stable PEs. These models outperform all baselines originally designed by hardware experts for corresponding tasks, across all 13 tasks. Notably, this work is the first to consider GTs with BI-MPNN layers and using stable PEs in DGRL, so the above two models have novel architectures essentially derived from our benchmarking effort.

Furthermore, recognizing that hardware design often encounters out-of-distribution (OOD) data in production (e.g., from synthetic to real-world , before and after technology mapping , inference on different RISC-V CPUs ), for each dataset we evaluate the methods data with distribution shift to simulate potential OOD challenges. We observe that while ML models perform reasonably well on tasks (8 of 13) with diverse graph structures in the training dataset, they generally suffer from OOD generalization issues on the remaining tasks. This finding highlights the urgent need for future research to focus on improving the OOD generalization capabilities of DGRL models.

Lastly, our benchmark is implemented with a modular and user-friendly codebase, allowing hardware practitioners to evaluate all 21 DGRL models for their tasks with data in a PyG-compatible format , and allowing ML researchers to advance DGRL methods using the collected hardware design tasks.

## 2 Related Work

**Graph Representation Learning as Powerful Surrogate Models.** ML-based surrogate models have been widely adopted in scientific fields [96; 157] and recently extended in hardware design. While graph-learning-based surrogate models for hardware design have already demonstrated effectiveness [10; 11; 14; 71; 82; 85; 102; 120; 121; 128; 136; 137; 149], several aspects warrant further investigation. First, existing studies often rely on task-specific heuristics to encode circuit structural information [10; 14; 85; 91; 102; 121], hindering the migration of model-design insights from one task to an even closely related task. Second, the majority of these studies conduct message passing of GNNs along edge directions, with few considering BI implementation [45; 51], and there is an absence of a comparative analysis of different DGRL approaches. Third, the designed models are often trained and tested within similar data distributions [10; 51; 153], lacking systematic OOD evaluation for new or more complicated designs. Hence, it is imperative to establish a comprehensive benchmark to compare different DGRL approaches for hardware design tasks.

**Methods for DGRL.** NN architectures for DGRL can be classified into three types: spatial GNNs, spectral GNNs, and transformers. Spatial GNNs use graph topology as inductive bias, some employ bidirected message passing for regular directed graphs [57; 65; 104; 131], others use asynchronous message passing exclusively designed for directed acyclic graphs (DAGs) [30; 116; 151]. Spectral GNNs generalize the ideas of Fourier transform and corresponding spectral convolution from undirected to directed graphs [39; 40; 49; 64; 84; 94; 110; 119; 152]; Transformers with attention mechanism reply on designing direction-aware PEs to capture directed graph topology. This benchmark is the first to consider combining transformers with MPNN layers for DGRL, extending the ideas in . Regarding the choices of PEs, most studies are on undirected graphs [33; 53; 74; 127]. For

    & High-level Synthesis & Symbolic Reasoning & Pre-routing Timing Prediction & Computational Graph & Operational Amplifiers \\  & (MLS)  & (SR)  & (Time)  & (CG)  & (AMP)  \\  Type & digital & digital & digital & digital & analog \\  Level & graph & node & node & graph & graph \\  Target & regression & classification & regression & regression & regression \\  Task & LUT, DSP, CP & node shared by MAJ and XOR, root node of an adider & hold slack, setup slack & CPU/GPU/G/G/OGPU/640 & gain, PM, BW \\  Evaluation Metric & mse, r2 & accuracy, m recall, precision & mse, r2 & rmse, acc5, acc10 & mse, rmse \\  In-Darkation & CDFG & 24-hr & graph structure & network structure & stage3 \\  Out-of-Distribution & DFG & 32, 36, 48-hr & graph structure & network structure & stage2 \\  \# Training Graph & 16570-16570 & 1 - 1 & 7 - 7 & 5* - 10000 & 7223-7223 \\  \#Train Nodes & average & 95 & 4440 & 29839 & 218 & 9 \\ max & 474 & 4440 & 38676 & 430 & 16 \\  \# Train Edge & average & 123 & 10348 & 41268 & 240 & 15 \\ max & 636 & 10348 & 83225 & 487 & 36 \\   

Table 1: Statistics of selected datasets. In row # Training graph’, we report ‘# Graph Structures - # Samples’. #: in CG, there are only five unique CNN designs, yet the structure of graphs within each design may vary slightly.

Figure 1: Coverage of Datasets/Tasks.

directed graphs, the potential PEs are Laplacian eigenvectors of the undirected graphs by symmetrizing the original directed ones , singular vectors of adjacency matrices  and the eigenvectors of Magnetic Laplacians [36; 37; 42; 109]. No previous investigate benefit for DGRL from stably incorporating PE [53; 127], and we are the first to consider stable PEs for DGRL.

**Existing Relevant Benchmarks.** Dwivedi et al.  benchmark long-range reasoning of GNNs on undirected graphs; PyGSD  benchmarks signed and directed graphs, while focusing on social or financial networks. We also compare all the methods for directed unsigned graphs in PyGSD and notice that the SOTA spectral method therein - MagNet  still works well on node-level tasks on a single graph (SR), which shares some similar insights. The hardware community has released graph-structured datasets from various development stages to assist surrogate model development, including but not limited to NN workload performance [100; 150], CPU throughput [20; 89; 114], resource and timing in HLS [11; 137], design quality in logic synthesis , design rule checking in physical synthesis [17; 21; 45; 143], and hardware security . In addition to datasets, ProGraML  introduces a graph-based representation of programs derived from compiler IRs (e.g., LLVM/XLA IRs) for program synthesis and compiler optimization. Very recently, Google launched TPUgraph for predicting the runtime of ML models based on their computational graphs on TPUs . Our CG dataset includes computational graphs of ML models, specifically on edge devices.

## 3 Datasets and Tasks

This section introduces the five datasets with thirteen tasks used in this benchmark. The datasets cover both digital and analog hardware, considering different circuit abstraction levels, as illustrated in Fig. 1. Table 1 displays the statistics of each dataset. Next, we briefly introduce the five datasets, with details provided in Appendix. D. Although these datasets are generated by existing studies, we offer modular pre-processing interfaces to make them compatible with PyTorch Geometric and user-friendly for integration with DGRL methods.

**High-Level Synthesis (HLS) :** The HLS dataset collects IR graphs of C/C++ code after front-end compilation , and provides post-implementation performance metrics on FPGA devices as labels for each graph, which are obtained after hours of synthesis with Vitis  and implementation with Vivado . The labels to predict include resource usage, (i.e., look-up table (LUT) and digital signal processor (DSP)), and the critical path timing (CP). See Appendix. D.1 for graph input details.

_Significance:_ The HLS dataset is crucial for testing NNs' ability to accurately predict post-implementation metrics to accelerate design evaluation in the stage of HLS.

_OOD Evaluation:_ For training and ID testing, we use control data flow graphs (CDFG) that integrate control conditions with data dependencies, derived from general C/C++ code; As to OOD cases, we use data flow graphs (DFG) derived from basic blocks, leading to distribution shifts.

**Symbolic Reasoning (SR) :** The SR dataset collects bit-blasted Boolean networks (BNs) (unstructured gate-level netlists), with node labels annotating high-level abstractions on local graph structures, e.g., XOR functions, majority (MAJ) functions, and adders, generated by the logic synthesis tool ABC . Each graph supports two tasks: root nodes of adders, and nodes shared by XOR and MAJ functions. See Appendix. D.2 for detailed input encoding and label explanation.

_Significance:_ Reasoning high-level abstractions from BNs has wide applications in improving functional verification efficiency  and malicious logic identification . GNN surrogate models are anticipated to replace the conventional structural hashing and functional propagation [70; 112] and boost the scalability with significant speedup. For graph ML, due to significant variation in the size of gate-level netlists under different bit widths, SR is an ideal real-world application to evaluate whether GNN designs can maintain performance amidst the shifts in graph scale.

_OOD Evaluation:_ We use a \(24\)-bit graph (\(4440\) nodes) for training, and \(32,36,48\)-bit graphs (up to \(18096\) nodes) for ID testing, derived from carry-save-array multipliers before technology mapping. OOD testing data are multipliers after ASAP \(7\)nm technology mapping  with the same bits.

**Pre-routing Timing Prediction (TIME) :** The TIME dataset collects real-world circuits with OpenROAD  on SkyWater \(130\)nm technology . The goal is to predict slack values at timing endpoints for each circuit design by using pre-routing information. Two tasks are considered: hold slack and setup slack. Details are provided in Appendix. D.3.

_Significance:_ In physical synthesis, timing-driven placement demands accurate timing information, which is only available after routing. Repetitive routing and static timing analysis provide accurate timing but are prohibitively expensive. ML models that precisely learn routing behaviors and timing computation flows are highly expected to improve the efficiency of placement and routing.

_OOD Evaluation:_ We divide ID-OOD based on the difference in graph structures (e.g. 'blabla' and 'xtea' are different circuit designs, allocated into ID or OOD groups). See details in Appendix. D.3.1.

**Computational Graph (CG) :** The CG dataset consists of computational graphs of convolutional neural networks (CNNs) with inference latency on edge devices (i.e., Cortex A76 CPU, Adreno 630 GPU, Adreno 640 GPU) as labels. The CNNs have different operator types or configurations, either manually designed or found by neural architecture search (NAS). Details are in Appendix. D.4.

_Significance:_ Accurately measuring the inference latency of DNNs is essential for high-performance deployment on hardware platforms or efficient NAS [103; 106], which however is often costly. ML-based predictors offer the potential for design exploration and scaling up to large-scale hardware platforms.

_OOD Evaluation:_ We split ID-OOD with different graph structures. (e.g. 'DenseNets' and 'ResNets' are CNNs with different structures, allocated into different groups). See Appendix. D.4.1 for details.

**Operational Amplifiers (AMP) :** AMP dataset contains \(10,000\) distinct 2- or 3-stage operational amplifiers (Op-Amps). Circuit specifications (i.e. DC gain, phase margin (PM), and bandwidth (BW)) as labels are extracted after simulation with Cadence Spectre . Details are in Appendix. D.6.

_Significance:_ Analog circuit design is less automated and requires more manual effort compared to its digital counterpart. Mainstream approaches such as SPICE-based circuit synthesis and simulation , are computationally expensive and time-consuming. If ML algorithms can approximate the functional behavior and provide accurate estimates of circuit specifications, they may significantly reduce design time by minimizing reliance on circuit simulation .

_OOD Evaluation:_ For training and ID testing, we use 3-stage Op-Amps, which have three single-stage Op-Amps in the main feed-forward path). For OOD evaluation, we use 2-stage Op-Amps.

**Extensions** Although the datasets cover different levels of circuit abstraction, there are additional tasks in hardware design worth exploration with DGRL surrogates, as reviewed in Section 2. Our modular benchmark framework allows for easy extension to accommodate new datasets.

## 4 Benchmark Design

### Design Space for Directed Graph Representation Learning

In this section, we introduce the DGRL methods evaluated in this benchmark. Our evaluation focuses on four design modules involving GNN backbones, message passing directions, transformer selection, and PE incorporation, illustrated in Fig. 2. Different GNN backbones and transformer adoptions cover 10 methods in total with references in Tab. 2. We also consider their combinations with different message-passing directions and various ways to use PEs, which overall gives 21 DGRL methods.

For GNNs, we consider 4 spectral methods, namely GCN , DGCN , DiGCN  and MagNet , where the latter three are _SOTA spectral GNNs_ specifically designed for DGRL ; For spatial GNNs, we take GIN  and Graph Attention Network (GAT) , which are the most commonly used MPNN backbones for undirected graphs. We evaluate the combination of GCN, GIN and GAT with three different message-passing directions: a) 'undirected'(-) treats directed graphs as undirected, using the same NN parameters to perform message-passing along both forward and reverse edge directions; b) 'directed'(DI) only passes messages exclusively along the forward edge directions; c) 'bidirected'(BI) performs message passing in both forward and reverse directions with distinct parameters for either direction. The other GNNs (DGCN, DiGCN and MagNet) adopt spectral convolution that inherently considers edge directions. The combination of 'BI' with spatial GNN layers gives _the state-of-the-art spatial GNNs_ for DGRL, i.e., EDGNN .

For GTs, we adopt the eigenvectors of the graph Magnetic Laplacian (MagLAP) matrix as the PEs of nodes [40; 109], as they are directional-aware. The MagLap matrix \(_{q}\) is a complex Hermitian matrix with parameter \(q[0,1)\) named potential, which is treated as a hyper-parameter in our experiments. Note that when \(q=0\), MagLap degenerates to the symmetric Laplacian matrix \(_{0}\) as a special case. See Appendix B for a brief review of MagLap. The GT with the MagLap PEs attached to node features gives _the SOTA GT model_ for DGRL, named TmD for brevity, proposed in . GPS  is a GT model with MPNN layers [43; 48] interleaving with transformer layers , originally proposed for undirected graphs. We extend GPS to directed graphs by using MagLap PEs for transformer layers and DI/BI message passing in its MPNN layers. Hence, GPS is also an extension of TmD by incorporating MPNN layers. As transformers may not scale well on large graphs, we evaluate vanilla transformer layers and their lower-rank approximation Performer  for efficient computation, named as GPS-T and GPS-P, respectively.

### Stable Direction-aware Positional Encodings

Recent studies on undirected graphs have demonstrated that models by naively attaching PEs to node features may suffer from an issue of instability because small changes in the graph structure may cause big changes in PEs [53; 74; 127]. We name this way of using PEs as node-PE (NPE). The instability provably leads to undesired OOD generalization . We think this is also true for directed graphs and indeed observe the subpar model performance with NPE.

Therefore, besides NPE, we also consider a stable way of incorporating PEs for DGRL, namely 'edge PE' (EPE), inspired by . EPE was originally proposed for the undirected graph case. Specifically, we use the smallest \(d\) eigenvalues \(_{q}^{d}\) and their corresponding eigenvectors \(_{q}^{|V| d}\) from \(_{q}\). Then, we follow the equation in Table 3 to compute \(^{|V||V| d}\). Then, in GTs, \(_{u,v}\) is further added to the attention weight between nodes \(u\) and \(v\) as a bias term at each attention layer.

We note that PEs can also be used in more than GTs, to improve the expressive power of GNNs [53; 69; 74; 145]. We leverage this idea and enhance the GNN models for directed graphs with PEs. Specifically, for the GNNs NPE will use \(_{v}\) as extra node features of node \(v\) while EPE will use \(_{u,v}\) as extra edge features of edge \(uv\) if \(uv\) is an edge.

   \{_{q}\},\{_{q}\}]\)**} \\   \(=(\{_{q}(_{1}())_{ q}^{}\},...,\{_{q}(_{m}())_{q}^{ }\},\) \\ \(\{_{q}(_{1}())_{q}^{}\},..., \{_{q}(_{m}())_{q}^{}\})\) \\   

Table 3: Functions to obtain PEs. NPE directly concatenates the eigenvectors to node features. In contrast, before concatenating PE to the edge features, EPE employs the permutation equivariant functions \(:^{d}^{d}\) w.r.t. eigenvalue permutations and permutation equivariant function \(:^{|V||V| 2m}^{|V||V| d}\) to stably process the eigenvectors and eigenvalues, respectively.

Figure 2: The benchmark considers 21 combinations of message passing direction, GNN backbone, transformer selection and PE incorporation, covers 10 existing SOTA methods from graph ML community and discovers 2 novel top-performing models (see Table. 2).

The incorporation with EPE helps discover a novel GT model for directed graphs, i.e., GT with BI-MPNN layers enhanced by EPE, abbreviated as BI-GPS+EPE. We also make the first attempt to combine GNNs with PEs for directed graphs, which yields the model BI-GIN(E)+EPE.

### Hyper-Parameter Space and Tuning

For each combination of DGRL method in this benchmark, we perform automatic hyper-parameter tuning with RAY  adopting Tree-structured Parzen Estimator (TPE) , a state-or-the-art bayesian optimization algorithm. The hyper-parameter space involves searching batch size, learning rate, number of backbone layers, dropout rate in MPNN and MLP layers, hidden dimension, and MLP layer configurations. The detailed hyper-parameter space of each model is shown in Appendix. E.2. We auto-tune the hyper-parameters with seed \(123\) with \(100\) trial budgets and select the configuration with the best validation performance. Then, the selected configuration is used for model training and testing ten times with seeds \(0-9\) and the average is reported as the final performance.

## 5 Modular Toolbox

We develop a highly modular toolbox involving designing, auto hyper-parameter tuning, and evaluation for DGRL methods. The framework is shown in Fig. 3. The toolbox comes with the 21 DGRL methods, allowing practitioners to evaluate them on any new task with data compatible with PyTorch Geometric (PyG) . This may be used even beyond hardware design applications. Users can also customize new methods. Once the method is configured, auto hyper-parameter tuning can be performed using RAY . The toolbox also includes the above 5 datasets with 13 tasks that can be used to develop new DGRL models. For details please refer to the official document for this toolbox.

## 6 Experiments

In this section, we first evaluate DGRL methods combining different GNN backbones, message passing directions, transformer selection, and PE incorporation, across all 5 datasets and 13 tasks, using in-distribution (ID) and out-of-distribution (OOD) testing data.

### Main Results

The performances of the methods under all evaluation metrics for both in-distribution and out-of-distribution testing across all 13 tasks are reported from Table. 11 to Table. 33 in Appendix. G.1. We summarize the averaged ranking with respect to all evaluation metrics given a task in Table. 4. The details of ranking calculation is in Appendix. F.1. The results tell the following insights:

'Bidirected' (BI) message passing in the MPNN layers significantly boosts the models' performance on three GNN backbones (GCN, GIN, GAT) and one GT backbone (GPS-T): BI-GCN outperforms GCN on 10 out of 13 tasks in both ID and OOD evaluations. Similarly, in ID/OOD evaluations, BI-GIN outperforms GIN in 11/12 out of 13 tasks, BI-GAT outperforms GAT in 11/9 out of 13 tasks and BI-GPS-T outperforms GPS-T in 5/5 out of 6 tasks, respectively.

Figure 3: Illustration of the directed graph representation learning (DGRL) toolbox.

As to the models, on datasets with small graphs (HLS and AMP), BI-GPS-T consistently delivers excellent results, achieving top-3 performance in 5 out of 6 tasks on both ID and OOD testing data. BI-GIN also demonstrates competitive performance on these datasets. However, for datasets with larger graphs (SR, CG, and TIME), BI-GPS-T encounters a scalability issue. BI-GIN secures top-three performance in 6 out of 7 tasks in both ID and OOD testing data. For the'shared' and 'root' tasks from the SR dataset and the 'CPU' and 'GPU630' tasks from the CG dataset, MagNet  performs best in the ID setting. This is likely because training and testing are conducted on the same graph structures for these specific datasets, reducing the need for significant generalization across different graph structures. This scenario aligns well with the spectral filtering approach used by MagNet. These observations match findings from previous studies on directed networks . However, MagNet's performance falters in OOD evaluations which ask for the ability to generalize across different graph structures. GPS-P, despite its capability to handle large graphs, delivers only mediocre performance overall. _In conclusion, BI-GPS is well-suited for small (around one hundred nodes) directed graphs. For larger graphs, BI-GIN is efficient and performs well. For tasks where the training and testing data share the same graph structures, one may also attempt to adopt MagNet._

**Comparing PE-enhanced methods:** We further investigate the impact of different ways of using PEs. We combine NPE or EPE with the top-performing models from the previous section and evaluate BI-GIN+NPE, BI-GIN+EPE, and BI-GPS+EPE. Note that BI-GPS already utilizes NPE. We have chosen not to consider adding PE to MagNet because MagNet only accepts 1-dimensional edge weights, limiting its ability to leverage EPE. We provide a summary of the performance data from Table 34 to Table 43 in Appendix G.2 and report the average rankings of the methods for each task. All 18 methods in Table 4, along with the 3 new combinations, are included in the ranking. We detail the results of the most competitive methods in Table 5. For BI-GIN, EPE enhances its performance on 10 out of 13 tasks in the in-distribution (ID) testing data and 11 tasks in the out-of-distribution (OOD) testing data. Conversely, NPE only improves the performance of BI-GIN on 7 tasks in the ID testing and 4 tasks in the OOD testing and performs unstable for the rest tasks. Notably, EPE-enhanced BI-GIN surpasses MagNet on the CPU task in the CG dataset. For BI-GPS-T, EPE improves its performance on all 6 tasks in both ID and OOD testing, while NPE does not yield substantial improvements. This observation contrasts with previous work  on undirected graphs for molecular property prediction. _In conclusion, we find that incorporating PEs in a stable way as EPE significantly boosts the performance of different models across the selected tasks and datasets._

### Summary: The Recipe for DGRL

Through benchmarking various combinations within the design space, we have formulated a design recipe for DGRL methods tailored for encoding hardware data: _The use of 'bidirected' (BI) message passing and stable positional encodings (PE) can significantly enhance model performance. Therefore, we recommend BI-GPS-T+EPE for encoding small graphs and BI-GIN+EPE for large graphs._

We further compare the two models' performance with the baseline methods proposed by hardware design practitioners specifically for the corresponding tasks in the original papers. Results are shown in Table. 6. The comparison focuses on ID evaluation as for most of the tasks, the original studies did not even report OOD evaluations. We follow the same data split as baseline methods for fair comparison (see the details in Appendix C). BI-GIN+EPE achieves results comparable to, or better than, the baseline methods. BI-GPS+EPE achieves even better performance than BI-GIN+EPE for small graphs. Note that the baseline methods for certain tasks may incorporate domain-specific expert knowledge and additional data processing. For example, CKTGNN  for the AMP dataset modifies the graph structures into DAGs and employs an asynchronized message passing to mimic the signal flow in these amplifiers; 'timer-GNN'  is tailored for the TIME dataset to mimic the transmission rules of clock signals and designs a non-linear delay model (NLDM) along with a novel module 'cell library'. Such domain knowledge may further enhance BI-GPS+EPE and BI-GIN+EPE for these specific tasks, which is left for future research.

**Discussion on OOD Evaluation:** Despite BI-GPS-T+EPE and BI-GIN+EPE outperforming other methods in OOD testing across all tasks, we cannot yet conclude that these methods are sufficiently effective for practical OOD usage. _In fact, making accurate predictions with OOD data in hardware design remains a significant challenge._ When the graph structures in training sets are sufficiently diverse, such as in datasets with a large number of small graphs (e.g., AMP, HLS) or those with abundant local structures (e.g., SR), BI-GIN+EPE and BI-GPS-T+EPE tend to maintain reasonably good performance on OOD data. However, OOD generalization becomes challenging when the diversity of graph structures in the training set is limited. For instance, in the TIME dataset, which has a limited variety of graph structures for training and OOD testing data with entirely different graph structures, both BI-GIN+EPE and BI-GPS-T+EPE perform worse than timer-GNN , which integrates the knowledge of the physical structure of circuits (as shown in Table 21). We identify ensuring OOD performance, especially when training sets lack sufficiently diversified graph structures, as a key direction for future DGRL research.

## 7 Conclusions and Limitations

Through benchmarking 21 methods on in-distribution and out-of-distribution test sets across 13 tasks and 5 datasets within the hardware design loop, we find bidirected (BI) message passing neural networks can substantially improve the performance of both Graph Transformer (GT) encoders that incorporate MPNN layers and pure GNN encoders. Positional Encodings (PEs), particularly when used stably, can broadly enhance the performance of both GTs and GNNs. With these insights, we identify two top-performing models: BI-GPS-T+EPE and BI-GIN+EPE, both of which outperform the baseline models originally proposed for the corresponding tasks.

**Limitations**: Although the benchmark covers multiple stages in hardware design loop, there are other tasks [10; 17; 20; 89; 114; 143; 149] that could be included in this benchmark as DGRL tasks. Given technological advancements and the diversity of design tools, ensuring OOD performance remains an urgent open problem in hardware design. Future research may involve high-quality data collection [46; 56; 132; 138; 139] or the development of OOD-aware DGRL methods [78; 79; 80; 105].

   dataset &  &  &  &  & TIME  \\ (baseline’s name) &  &  &  &  &  \\  task & gain & PM & BW & dsp & mlet & cp & shared & cpu (average) & hold \\  metric & mseel & mseel & mseel & mseel & mseel & mseel & acccv7 & mseel & acc10† & 2† \\  Baseline & 0.52 & 1.15 & 4.47 & 3.94 & 2.45 & 0.88 & 0.99 & 3.20 & 0.80 & 0.99 & 0.97 \\ BI-GIN+EPE & 0.5140.07 & 1.1440.00 & 4.2040.13 & 1.2340.08 & 1.7340.10 & 0.6140.02 & 0.9940.00 & 2.7940.140.8640.02 & 0.9940.01 & 0.9940.00 \\ BI-GPS-T+EPE & 0.3440.08 & 1.1540.00 & 3.7940.11 & 1.2340.15 & 1.9640.13 & 0.6040.01 & - & - & - & - & - \\   

Table 6: Comparison of BI-GIN+EPE and BI-GPS-T+EPE with baselines specific for each dataset.