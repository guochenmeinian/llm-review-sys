# Approximate Heavy Tails in Offline (Multi-Pass)

Stochastic Gradient Descent

Krunoslav Lehman Pavasovic

Inria Paris, CNRS, Ecole Normale Superieure, PSL Research University

Paris, France

krunoslav.lehman-pavasovic@inria.fr

&Alain Durmus

CMAP, CNRS, Ecole Polytechnique, Institut Polytechnique de Paris

Paris, France

alain.durmus@polytechnique.edu

&Umut Simsekli

Inria Paris, CNRS, Ecole Normale Superieure, PSL Research University

Paris, France

umut.simsekli@inria.fr

###### Abstract

A recent line of empirical studies has demonstrated that SGD might exhibit a heavy-tailed behavior in practical settings, and the heaviness of the tails might correlate with the overall performance. In this paper, we investigate the emergence of such heavy tails. Previous works on this problem only considered, up to our knowledge, _online_ (also called single-pass) SGD, in which the emergence of heavy tails in theoretical findings is contingent upon access to an infinite amount of data. Hence, the underlying mechanism generating the reported heavy-tailed behavior in practical settings, where the amount of training data is finite, is still not well-understood. Our contribution aims to fill this gap. In particular, we show that the stationary distribution of _offline_ (also called multi-pass) SGD exhibits 'approximate' power-law tails and the approximation error is controlled by how fast the empirical distribution of the training data converges to the true underlying data distribution in the Wasserstein metric. Our main takeaway is that, as the number of data points increases, offline SGD will behave increasingly 'power-law-like'. To achieve this result, we first prove nonasymptotic Wasserstein convergence bounds for offline SGD to online SGD as the number of data points increases, which can be interesting on their own. Finally, we illustrate our theory on various experiments conducted on synthetic data and neural networks.

## 1 Introduction

Many machine learning problems can be cast as the following population risk minimization problem:

\[x F(x):=[f(x,Z)]\, Z_{z}\,\] (1)

where \(x^{d}\) denotes the model parameters, \(_{z}\) is the data distribution over the measurable space \((,)\) and \(f:^{d}\) is a loss function. The main difficulty in addressing this problem is that \(_{z}\) is typically unknown. Suppose we have access to an _infinite_ sequence of independent andidentically distributed (i.i.d.) data samples \(:=\{Z_{1},Z_{2},\}\) from \(_{z}\). In that case, we can resort to the _online_ stochastic gradient descent (SGD) algorithm, which is based on the following recursion:

\[X_{k+1}=X_{k}-_{i_{k+1}} f(X_{k},Z_{i})\,\] (2)

where \(k\) denotes the iterations, \(_{k}:=\{b(k-1)+1,b(k-1)+2,,bk\}\) is the batch of data-points at iteration \(k\), \(\) denotes the step size, \(b\) denotes the batch size such that \(|_{k}|=b\), and \(Z_{i}\) with \(i_{k}\), denotes the \(i\)-th data sample at the \(k\)-th iteration. This algorithm is also called'single-pass' SGD, as it sees each data point \(Z_{i}\) in the infinite data sequence \(\) only once.

While drawing i.i.d. data samples at each iteration is possible in certain applications, in the majority of practical settings, we only have access to a finite number of data points, preventing online SGD use. More precisely, we have access to a dataset of \(n\) i.i.d. points \(_{n}:=\{Z_{1},,Z_{n}\}\)1, and given these points the goal is then to minimize the empirical risk \(^{(n)}\), given as follows:

\[x^{(n)}(x):=_{i=1}^{n}f(x,Z_{i} )^{d}\.\] (3)

To attack this problem, one of the most popular approaches is the _offline_ version of (2), which is based on the following recursion:

\[X_{k+1}^{(n)}=X_{k}^{(n)}-_{i_{k+1}^{(n)}} f( X_{k}^{(n)},Z_{i})\,\] (4)

where \(_{k}^{(n)}\{1,,n\}\) denotes the indices of the (uniformly) randomly chosen data points at iteration \(k\) with \(|_{k}^{(n)}|=b n\) and \(^{(n)}\) emphasizes the dependence on the sample size \(n\). Analogous to the single-pass regime, this approach is also called the _multi-pass_ SGD, as it requires observing the same data points multiple times.

Despite its ubiquitous use in modern machine learning applications, the theoretical properties of offline SGD have not yet been well-established. Among a plethora of analyses addressing this question, one promising approach has been based on the observation that parameters learned by SGD can exhibit _heavy tails_. In particular,  have empirically demonstrated a heavy-tailed behavior for the sequence of stochastic gradient noise:

\[(^{(n)}(X_{k}^{(n)})-b^{-1}_{i_{k+1}^{(n)}}  f(X_{k}^{(n)},Z_{i}))_{k 1}\.\]

Since then, further studies have extended this observation to other sequences appearing in machine learning algorithms . These results were recently extended by , who showed that the parameter sequence \((X_{k}^{(n)})_{k 1}\) itself can also exhibit heavy tails for large \(\) and small \(b\). These empirical investigations all hinted a connection between the observed heavy tails and the generalization performance of SGD: heavier the tails might indicate a better generalization performance.

Motivated by these empirical findings, several subsequent papers theoretically investigated how heavy-tailed behavior can emerge in stochastic optimization. In this context,  have shown that when _online SGD_ is used with a quadratic loss (i.e., \(f(x,z=(a,y))=2^{-1}(a^{}x-y)^{2}\)), the distribution of the iterates \((X_{k})_{k 0}\) can converge to a heavy-tailed distribution, even with exponentially light-tailed data (e.g., Gaussian). More precisely, for a fixed step-size \(>0\), they showed that, under appropriate assumptions, there exist constants \(c_{+}\) and \(>0\), such that the following identity holds:

\[_{t}t^{}(\|X_{}\|>t)=c,\] (5)

where \(X_{}\) and \(\) denotes the stationary distribution of online SGD (2). This result illustrates that the distribution of the online SGD iterates follows a power-law decay with the _tail index_\(\): \((\|X_{}\|>t) t^{-}\) for large \(t\). Furthermore, \(\) depends monotonically on the algorithm hyperparameters \(\), \(b\), and certain properties of the data distribution \(_{z}\). This result is also consistent with [1, Example 1], which shows a simple instance from linear stochastic approximation such that for any fixed step-size \(\), there exists \(p_{c}>0\) such that for any \(p p_{c}\), \(_{k+}[\|X_{k}\|^{p}]=+\). In a concurrent study,  showed that this property is, in fact, not specific for quadratic problems and can hold for more general loss functions and different choices of stochastic optimizers, with the constraint that i.i.d. data samples are available at every iteration2.

Another line of research has investigated the theoretical links between heavy tails and the generalization performance of SGD. Under different theoretical settings and based on different assumptions,  proved generalization bounds (i.e., bounds on \(|^{(n)}(x)-F(x)|\)) illustrating that the heavy tails can be indeed beneficial for better performance. However, all these results rely on _exact_ heavy tails, which, to our current knowledge, can only occur in the _online_ SGD regime where there is access to an infinite sequence of data points. Hence the current theory (both on the emergence of heavy tails and their links to generalization performance) still falls short in terms of explaining the empirical heavy-tailed behavior observed in _offline_ SGD as reported in .

**Main problematic and contributions.** Although empirically observed, it is currently unknown how heavy-tailed behavior arises in offline SGD since the aforementioned theory  requires infinite data. Our main goal in this paper is hence to develop a theoretical framework to catch _how_ and _in what form_ heavy tails may arise in offline SGD, where the dataset is finite.

We build our theory based on two main observations. The first observation is that, since we have finitely many data points in offline SGD, the moments (of any order) of the iterates \(X_{k}^{(n)}\) can be bounded (see, e.g., ), hence in this case we cannot expect _exact_ power-law tails in the form of (5) in general. Our second observation, on the other hand, is that since the finite dataset \(_{n}\) can be seen as the first \(n\) elements of the infinite sequence \(\), as \(n\) increases the offline SGD recursion (4) should converge to the online SGD recursion (2) in some sense. Hence, when online SGD shows a heavy-tailed behavior (i.e., the case where \(n+\)), as we increase \(n\), we can expect that the tail behavior of offline SGD should be more and more 'power-law-like'.

To further illustrate this observation, as a preliminary exploration, we run offline SGD in a 100-dimensional linear regression problem, as well as a classification problem on the MNIST dataset, using a fully-connected, 3-layer neural network.3

In Figure 1, we plot the histograms of the parameter norms after \(1000\) (and \(5000\) resp.) iterations. We observe the following consistent patterns: _(i)_ the means and standard deviations of the parameters' estimated stabilizing distributions increase with \(n\), and _(ii)_, the quantity and magnitude of the parameters far from the bulk of the distribution increase with \(n\). In other words, as we increase the number of samples \(n\) in offline SGD, the behavior of the iterates becomes heavier-tailed.

Figure 1: Left: histograms of the parameter norms for Gaussian data linear regression. Right: histograms of NN parameter norms for the first layer, trained on MNIST. Norms exceeding the \(+2\) threshold are marked with a red asterisk.

Figure 2: Estimated tail indices

As another example, we utilize the tail-estimator from 4 to compare the estimated tail indices \(\) for offline and online SGD. The results are plotted in Figure 2 and correspond to 10 random initializations with different step-sizes (for further details, see Tail estimation). We observe that, as \(n\) increases, the estimated tail indices for offline SGD (shown in green) get closer to the true tail index corresponding to online SGD (the horizontal blue line).

Our main contribution in this paper is to make these observations rigorous and explicit. In particular, we extend the tail estimation results for online SGD  to offline SGD, and show that the stationary distribution of offline SGD iterates will exhibit _'approximate'_ heavy tails. Informally, for both quadratic and a class of strongly convex losses, we show that, with high probability, there exist constants \(c_{1},c_{2}\), such that for large enough \(t\) we have the following tail bound:

\[[}{t^{}}-_{1}(_{z},_{z}^{(n)} )\,](\|X_{}^{(n)}\|>t)\,[ }{t^{}}+_{1}(_{z},_{z}^{(n)})],\] (6)

where \(\) is the tail index of _online_ SGD as given in (5), \(X_{}^{(n)}^{(n)}\) denotes a sample from the stationary distribution \(^{(n)}\) of _offline_ SGD (4), \(_{z}^{(n)}=n^{-1}_{i=1}^{n}_{Z_{i}}\) denotes the empirical measure of the data points in the data sample \(_{n}=\{Z_{1},,Z_{n}\}\), and \(_{1}\) denotes the Wasserstein-1 distance (to be defined formally in the next section).

Our result indicates that the tail behavior of offline SGD is mainly driven by two terms: (i) a persistent term \((c/t^{})\) that determines the power-law decay, and (ii) a vanishing term \(_{1}(_{z},_{z}^{(n)})/t\), as we take \(n\). In other words, compared to (5), we can see that, with high-probability, \(X_{}^{(n)}\) exhibits an _approximate_ power-law decay behavior, with a discrepancy controlled by \(_{1}(_{z},_{z}^{(n)})\).

Fortunately, the term \(_{1}(_{z},_{z}^{(n)})\) has been well-studied in the literature. By combining our results with Wasserstein convergence theorems for empirical measures , we further present nonasymptotic tail bounds for offline SGD. Our main takeaway is as follows: as \(n\) increases, offline SGD will exhibit approximate power-laws, where the approximation error vanishes with a rate given by how fast the empirical distribution of the data points \(_{z}^{(n)}\) converges to the true data distribution \(_{z}\) as \(n\).

To prove our tail bounds, as an intermediate step, we prove nonasymptotic Wasserstein convergence results for offline SGD in the form: \(_{1}(,^{(n)})_{1}(_{z},_{z}^{(n)})\), with high probability, recalling that \(\) and \(^{(n)}\) respectively denote online and offline SGD stationary distributions. These results, we be-lieve, hold independent interest for the community. Finally, we support our theory with various experiments conducted on both synthetic quadratic optimization problems and real neural network settings.

## 2 Preliminaries and Technical Background

### Notation and preliminary definitions

We let \(_{d}\) denote the \(d d\) identity matrix. We denote \([n]=\{1,,n\}\), \(_{n,b}=\{[n],\||=b\}\). For a vector \(x^{d}\), \(\|x\|\) denotes the Euclidean norm of \(x\), and for matrix \(\), the norm \(\|\|=_{\|x\|=1}\|x\|\) denote its spectral norm. We denote with \(_{}(),_{}()\) the smallest and largest singular values of \(\), respectively. \((^{d})\) is the set of all probability measures on \(^{d}\), and \((X)\) denotes the probability law of a random variable \(X\). We denote the set of all couplings of two measures \(\) and \(\) with \((,)\). Finally, for two functions \(f(n)\) and \(g(n)\) defined on \(_{+}\), we denote \(f=(g)\), if there exist constants \(c_{+}\), \(n_{0}\), such that \(f(n) cg(n), n>n_{0}\). The Dirac measure concentrated at \(x\) is defined as follows: for a measurable set \(E\), \(_{x}(E)=1\) if \(x E\), \(_{x}(E)=0\), otherwise.

For \(p[1,)\), the Wasserstein-\(p\) distance between two distributions \(\) and \(\) on \(^{d}\) is defined as:

\[_{p}(,):=_{(,)}(\|x-y\|^{p} \;(x,y))^{1/p}.\]

We correspondingly define the Wasserstein-\(p\) distance between two distributions \(\) and \(\) on \(^{d d}\) as

\[_{p}(,):=_{(,)}(\| -\|^{p}\;(,))^{1/p}.\]

### Heavy tails in online SGD

We first formally define heavy-tailed distributions with a power-law decay, used throughout our work.

**Definition 1** (Heavy-tailed distributions with a power-law decay).: _A random vector \(X\) is said to follow a distribution with a power-law decay if \(_{t}t^{}(\|X\| t)=c_{0}\), for constants \(c_{0}>0\) and \(>0\), the latter known as the tail index._

The tail index \(\) determines the thickness of the tails: larger values of \(\) imply a lighter tail.

Recently,  showed that online SGD might produce heavy tails even with exponentially light-tailed data. More precisely, they focused on a quadratic optimization problem, where \(z(a,q)^{d+1}\) and \(f(x,z)=2^{-1}(a^{}x-q)^{2}\). With this choice, the online SGD recursion reads as follows:

\[X_{k+1}=X_{k}-_{i_{k+1}}(a_{i}a_{i}^{}\,X_ {k}-a_{i}q_{i})=(_{d}-_{k+1})X_{k}+_{k+1}\] (7)

where \((Z_{k})_{k 1}(a_{k},q_{k})_{k 1}\), \(_{k}:=b^{-1}_{i_{k}}a_{i}a_{i}^{}\), and \(_{k}:=b^{-1}_{i_{k}}a_{i}q_{i}\).

In this setting, they proved the following theorem.

**Theorem 1** ().: _Assume that \((a_{k},q_{k})_{k 1}\) are i.i.d. random variables such that \(a_{1}(0,^{2}\,_{d})\), with \(^{2}>0\) and \(q_{i}\) has a continuous density with respect to the Lebesgue measure on \(\) with all its moments being finite. In addition suppose that \([\|_{d}-_{1}\|]<0\). Then, there exists a unique \(>0\) such that \([\|_{d}-_{1}\|^{}]=1\) and the iterates \((X_{k})_{k 0}\) in (7) converge in distribution to a unique stationary distribution \(\) such that if \(X_{}\) and \(\):_

\[_{t}t^{}(\|X_{}\|>t)=c\;, c_{+}\;.\] (8)

The authors of  also showed that the tail index \(\) is monotonic with respect to the algorithm hyperparameters \(\) and \(b\): a larger \(\) or smaller \(b\) indicates heavier tails, i.e., smaller \(\)5.

In a concurrent study,  considered a more general class of loss functions and choices of stochastic optimization algorithms. They proved a general result, where we translate it for online SGD applied on strongly convex losses in the following theorem.

**Theorem 2** ().: _Assume that for every \(z\), \(f(,z)\) is twice differentiable and is strongly convex. Consider the recursion in (2) with a sequence of i.i.d. random variables \((Z_{k})_{k 1}\) and let \(R\) and \(r\) be two non-negative functions defined as: for any \(z\),_

\[R(z):=_{x^{d}}\|_{d}-^{2}f(x,z)\|, r(z):=_{\|x\|}_{}(_{d}- ^{2}f(x,z))\;.\]

_Further assume that \([R(Z_{1})+\| f(x^{},Z_{1})\|]<+\), for some \(x^{}^{d}\), \([ R(Z_{1})]<0\), and \((r(Z_{1})>1)>0\). Then, the iterates \((X_{k})_{k 1}\) in (2) admit a stationary distribution \(\). Moreover, there exist \(,>0\) such that \([r(Z)^{}]=1\), \([R(Z)^{}]=1\), and for any \(>0\):_

\[_{t}t^{+}(\|X_{}\|>t )>0,_{t}t^{-}(\|X_{}\|> t)<+\;,\]

_where \(X_{}\)._

The result illustrates that power laws can arise in general convex stochastic optimization algorithms. We note that in general, Theorem 2 does not require _each_\(f(,z)\) to be strongly convex, in fact, it can accommodate non-convex functions as well. However, we are not aware of any popular non-convex machine learning problem that can satisfy all the assumptions of Theorem 2. Nevertheless, for better illustration, in Section F, we show that an \(_{2}\)-regularized logistic regression problem with random regularization coefficients falls into the scope of Theorem 2.

The two aforementioned theorems are limited to the online setting, and it is unclear whether they apply to a finite number of data points \(n\). In the subsequent section, we aim to extend these theorems to the offline setting.

Main results

### Quadratic objectives

We first focus on the quadratic optimization setting considered in Theorem 1 as its proof is simpler and more instructive. Similarly as before, let \((a_{i},q_{i})_{i 1}\) be i.i.d. random variables in \(^{d+1}\), such that \(z_{i}(a_{i},q_{i})\). Following the notation from (4), we can correspondingly define the _offline_ SGD recursion as follows:

\[X_{k+1}^{(n)}=X_{k}^{(n)}-_{i_{k+1}^{(n)}}a_ {i}_{i}^{}X_{k}^{(n)}-a_{i}q_{i}=(_{d}-_ {k+1}^{(n)})X_{k}^{(n)}+_{k+1}^{(n)},\] (9)

where \(_{k}^{(n)}:=b^{-1}_{i_{k}^{(n)}}a_{i}a_{i}^{}\,\ _{k}^{(n)}:=b^{-1}_{i_{k}^{(n)}}a_{i}q_{i}\,\) and \(_{k}^{(n)}\) is as defined in (4). Now, \((_{k}^{(n)},_{k}^{(n)})_{k 1}\) are i.i.d. random variables with respect to the empirical measure:

\[_{,}^{(n)}=^{-1}_{i=1}^{} _{\{}_{i}^{(n)},}_{i}^{(n)}\}}\,\] (10)

where we enumerate all possible choices of minibatch indices \(_{n,b}=\{\{1,,n\}:||=b\}\) as \(_{n,b}=\{_{1}^{(n)},_{2}^{(n)},,_{}^{(n)}\}\) and \((}_{i}^{(n)},}_{i}^{(n)})_{i=1}^{ }\) are i.i.d. random variables defined as follows:

\[}_{i}^{(n)}=_{j_{i}^{(n)}}a_ {j}a_{j}^{}\,}_{i}^{(n)}=_{j _{i}^{(n)}}a_{j}q_{j}\.\] (11)

We denote by \(_{,}\) the common distribution of \((}_{i}^{(n)},}_{i}^{(n)})_{i=1}^{ }\). Note that it does not depend on \(n\) but only \(b\).

With these definitions at hand, we define the two marginal measures of \(_{,}\) and \(_{,}^{(n)}\) with \(_{}\), \(_{}\), and \(_{}^{(n)}\), \(_{}^{(n)}\), respectively. Before proceeding to the theorem, we have to define Wasserstein ergodicity. A discrete-time Markov chain \((Y_{k})_{k 0}\) is said to be (Wasserstein-1) geometrically ergodic if it admits a stationary distribution \(_{Y}\) and there exist constants \(c 0\) and \((0,1)\), such that

\[_{1}((Y_{k}),_{Y}) c^{- k}\,\ \.\] (12)

The chain is simply called (Wasserstein-1) ergodic if \(_{k}_{1}((Y_{k}),_{Y})=0\).

We can now state our first main contribution, an extension of Theorem 1 to the offline setting:

**Theorem 3**.: _Let \(n 1\) and \(_{n}\) be the probability that \((X_{k}^{(n)})_{k 0}\) is not ergodic (in the Wasserstein sense)6 with a stationary distribution \(^{(n)}\) having finite \(q\)-th moment with \(q>1\). Assume that the conditions of Theorem 1 hold with \(>1\). Then, for any \(>0\), there exist constants \(},}\), and \(t_{0}>0\) such that for all \((0,1]\), \(t>t_{0}\), with probability larger than \(1-_{n}-\), the following inequalities hold:_

\[[}}-}}{ tn^{1/2}}}}{}}](\|X_{ }^{(n)}\|>t)\ [2^{}}+}}{ tn^{1/2}}}}{}}]\,,\] (13)

_where \(c\) is given in (8)._

This result shows that whenever the online SGD recursion admits heavy tails, the offline SGD recursion will exhibit 'approximate' heavy tails. More precisely, as can be seen in (13), the tails will have a global power-law behavior due to the term \(t^{-}\), where \(\) is the tail index determined by online SGD. On the other hand, the power-law behavior is only approximate, as we have an additional term, which vanishes at a rate \((n^{-1/2})\). Hence, as \(n\) increases, the power-law behavior will be more prominent, which might bring an explanation for why heavy tails are still observed even when \(n\) is finite.

To establish Theorem 3, as an intermediate step, we show that \(^{(n)}\) converges to \(\) in the Wasserstein-1 metric. The result is given in the following theorem and can be interesting on its own.

**Theorem 4**.: _Under the setting of Theorem 3, for \(p,q>0\) with \(1/p+1/q=1\), \(p>d/2\), \(q<\), the following holds with probability larger than \(1-_{n}\):_

\[_{1}(,^{(n)}) c_{0}}_{p}( _{,},_{,}^{(n)})\;,\] (14)

_where \(c_{0}=([\|X_{0}^{(n)}\|^{q})]^{1/q}+1\) with \(X_{0}^{(n)}^{(n)}\), and \(_{A}=[\|_{d}-_{1}\|]\)._

This result shows that the stationary distribution of offline SGD will converge to the one of online SGD as \(n\), and the rate of this convergence is determined by how fast the empirical distribution of the dataset converges to the true data distribution, as measured by \(_{p}(_{,},_{,}^{(n)})\). Once (14) is established, to obtain Theorem 3, we use the relationship that \(_{1}(,^{(n)})_{1}((\|X_{}^{(n) }\|),(\|X_{}\|))=_{0}^{}|(\|X_{}^{ (n)}\|>t)-(\|X_{}\|>t)|t\) (see Lemmas 1 and 3 in the Appendix). Finally, by exploiting the assumptions made on \(_{,}\) in Theorem 1, we can invoke  (see Lemma 2 in Section A.1) and show that \(_{p}(_{,},_{,}^{(n)})\) behaves as \((n^{-1/2})\).

### Strongly convex objectives

We now focus on more complex loss functions, as in Theorem 2. For simplicity, we consider \(b=1\). The general case, while similar, would complicate the notation and, in our opinion, make our results more difficult to digest. We start by rewriting offline SGD with respect to an empirical measure \(_{z}^{(n)}\):

\[X_{k+1}^{(n)}=X_{k}^{(n)}- f(X_{k}^{(n)},_{k+1}^{(n)})\;,\] (15)

where \((_{k}^{(n)})_{k 1}\) are i.i.d. random variables associated with the empirical measure defined for any \(\) as:

\[_{z}^{(n)}()=n^{-1}_{j=1}^{n}_{_{j}^{(n )}}()\;.\] (16)

We first make the following assumption.

**Assumption 1**.:
1. _There exists_ \(L>0\) _such that_ \(\| f(x,z)- f(x,z^{})\| L(\|x\|+1)(\|z-z^{}\|)\)_, for any_ \(z,z^{}\) _and_ \(x^{d}\)_._
2. _The data distribution_ \(_{z}\) _has finite_ \(q\)_-th moments with some_ \(q 1\)_._

Assumption 1-(a) is a Lipschitz-like condition that is useful for decoupling \(x\) and \(z\), and is commonly used in the analysis of optimization and stochastic approximations algorithms; see, e.g., . We can now state our second main contribution, an extension of Theorem 2 to the offline setting.

**Theorem 5**.: _Let \((X_{k})_{k 0}\) and \((X_{k}^{(n)})_{k 0}\) be defined as in (2) and (4) with \(b=1\) and \(n 1\). Assume Assumption 1 and the conditions of Theorem 2 with \(>1\) hold. Further assume that \(R(Z_{1})\) is non-deterministic (see Theorem 2), \((X_{k})_{k 0}\) is geometrically ergodic and \(_{n}\) is the probability that \((X_{k}^{(n)})_{k 0}\) is not ergodic (in the Wasserstein sense). Then, for every \(>0\), there exist constants \(c,c_{}\), \(c_{}\), and \(t_{0} 0\), such that for all \(t>t_{0}\), the following inequalities hold with probability larger than \(1-_{n}\):_

\[}}{t^{+}}- _{1}(_{z},_{z}^{(n)})(\|X_{ }^{(n)}\|>t)2^{-}}{t^{- }}+_{1}(_{z},_{z}^{(n)}),  n,\]

_where \(c=([\|X_{0}^{(n)}\|]+1)L/(1-_{R})\) with \(_{R}=[R(Z_{1})]\), and \(X_{0}^{(n)}^{(n)}\)._

This theorem shows that the approximate power-laws will also be apparent for more general loss functions: for large enough \(n\), the tails of offline SGD will be upper- and lower-bounded by two power-laws with exponents \(\) and \(\). Note that the ergodicity of \((X_{k})_{k 0}\) can be established by using similar tools provided in . On the other hand, the assumption on \(R(Z_{1})\) being non-deterministic and \([R^{}(Z_{1})]=1\) with \(>1\) jointly indicate that \(_{R}=[R(Z_{1})]<1\), which is a form of contraction on average, hence the strong convexity condition is needed.

Similarly to Theorem 3, in order to prove this result, we first obtain a nonasymptotic Wasserstein convergence bound between \(^{(n)}\) and \(\), stated as follows:

**Theorem 6**.: _Under the setting of Theorem 5, the following holds with probability greater than \(1-_{n}\):_

\[_{1}(,^{(n)}) c_{0}L}_{1}( _{z},_{z}^{(n)})\,\]

_with \(c_{0}=[\|X_{0}^{(n)}\|]+1\), where \(X_{0}^{(n)}^{(n)}\)._

The convergence rate implied by Theorem 6 is implicitly related to the finite moments of the data-generating distribution \(_{z}\). Using the results of  ( Lemma 2 in the Appendix), we can determine the convergence rate \(r\), where with high probability it will hold that \(_{1}(,^{(n)})=(n^{-r})\), with \(r(0,1/2]\). Let the data have finite moments up to order \(q\). Then, for example, if \(q>4d\), we get \(r=1/2\), i.e., the fastest rate. As another example: if \(d>2\) and \(q=3\), we obtain a rate \(r=1/d\). In other words, the moments of the data-generating distribution determine whether we can achieve a dimension-free rate or fall victim to the curse of dimensionality. Thus, if the data do not admit higher-order moments, our results show that we need a large number of data points \(n\) to be able to observe power-law tails in offline SGD.

## 4 Experiments

In this section, we support our theoretical findings on both synthetic and real-world problems. Our primary objective is to validate the tail behavior of offline SGD iterates by adapting previous online SGD analyses , in which the authors investigated how heavy-tailed behavior relates to the step size \(\) and batch size \(b\), or their ratio \(/b^{7}\).

### Linear regression

**Experimental setup.** In the linear regression examples, we examine the case with a quadratic loss and Gaussian data. In this simple scenario, it was observed that online SGD could exhibit heavy-tailed behavior . The model can be summarized as follows: with initial parameters \(_{0}(0,_{x}^{2}_{d})\), features \(a_{i}(0,^{2}_{d})\), and targets \(y_{i} a_{i},_{0}(a_{i}^{}_{0},_ {y}^{2})\), for \(i=1,,n\), and \(,_{x},_{y}>0\). In our experiments, we fix \(=1\), \(_{x}=_{y}=3\), use either \(d=1\) or \(d=100\), and simulate the statistical model to obtain \(\{a_{i},y_{i}\}_{i=1}^{n}\).

In order to examine the offline version of the model (i.e., for offline SGD), we utilize a finite dataset with \(n\) points rather than observing new samples at each iteration. We then analyze the same experimental setting with an increasing number of samples \(n\) and illustrate how similar heavy-tailed behavior emerges in offline SGD.

Figure 3: QQ-plots of 1D linear regression experiment. Left: Online SGD exhibits heavy-tails. Right: Offline SGD with varying \(n\); larger \(n\) exhibits heavier tails.

Preliminary tail inspection.We begin by analyzing how the tail behavior differs between online and offline SGD (with varying \(n\) in the latter). Specifically, in Figure 3, we depict a 1-dimensional linear regression task by analyzing the QQ-plots of the estimated stabilizing distributions after 1000 iterations. We observe that online SGD with a sufficiently large \(\) exhibits heavy, non-Gaussian tails, underscoring the prevalence of heavy tails even in such simple scenarios. Furthermore, we also observe that offline SGD exhibits increasingly heavier tails as the sample size \(n\) increases, as our theoretical results suggest.

Tail estimation.We now set \(d=100\) and run the corresponding offline and online SGD recursions. We then use a tail-index estimator , which assumes that the recursions both converge to an _exact_ heavy-tailed distribution. While this is true for online SGD due to Theorem 1, offline SGD will only possess _approximate_ heavy-tails, and the power-law behavior might not be apparent for small \(n\). Hence, for small \(n\), we expect the estimated tail index for offline SGD will be inaccurate and get more and more accurate as we increase \(n\).

We illustrate this in Figure 2, in which we plot the range of estimated offline SGD tail indices (marked in green) corresponding to 10 random initializations, while varying \(n\) and \(\). We can see that, across all learning rates, the variance of the tail estimation decreases as \(n\) increases and that the estimated values get closer to the estimated tail index for online SGD (marked as the horizontal blue line).

Further analyses.We now run online and offline SGD recursions, varying \(\) from \(0.001\) to \(0.01\), \(b\) from 1 to 20, and \(n\) from \(1\) to \(500\). Each hyperparameter configuration is run 1600 times with distinct initializations, yielding 1600 estimated samples from the stationary distributions, used to estimate the tail indexes. In order to estimate the tail-indexes \(\) (online SGD) and \(^{(n)}\) (offline SGD) of the respective stationary distributions, we follow the procedure as explained in . Finally, in Figure 4, we plot the absolute difference of the estimated indexes, \(|^{(n)}-|\).

We find that a larger number of data samples leads to a smaller discrepancy between the online and offline approximations across all batch sizes \(b\) and step sizes \(\). This trend is consistently observed. Moreover, we observe that larger values of \(\) lead to a smaller discrepancy on average, across all \(n\). The conclusion here is that, as \(n\) increases, the power-law tails in offline SGD become more apparent and the estimator can identify the true tail index corresponding to online SGD even for moderately large \(n\), which confirms our initial expectations.

### Neural networks (NN)

To test the applicability of our theory in more practical scenarios, we conduct a second experiment using fully connected (FC) NNs (3 layers, 128 neurons, ReLU activations), as well as larger architectures, such as LeNet (60k parameters, 3 convolutional layers, 2 FC layers)8, and AlexNet (62.3M parameters, 5 convolutional layers, 3 FC layers). The models are trained for \(10,000\) iterations using cross-entropy loss on the MNIST and CIFAR-10 datasets. We vary the learning rate from \(10^{-4}\) to \(10^{-1}\), and the batch size \(b\) from 1 to 10, with offline SGD utilizing \(25\%\), \(50\%\), and \(75\%\) of the training data.

We proceed similarly to the linear regression experiment and again replicate the method presented in : we estimate the tail index per layer, and plot the corresponding results, with different colors representing different data proportions (\(1.00\) indicates the full data set). The results for the fully connected network are presented in Figure 5 (on CIFAR-10 & MNIST), LeNet (on MNIST)

Figure 5: Estimated tail indices for a 3-layer fully connected NN

in Figure 7, and AlexNet (on CIFAR-10) in Figure 6. The LeNet CIFAR-10 and AlexNet MNIST results can be found in the Appendix D.

Our observations show that the estimated \(^{(n)}\) has a strong correlation with \(\): using a reasonably large proportion of the data enables us to estimate the tail index that is measured over the whole dataset. Moreover, although the dependence of \(^{(n)}\) on \(/b\) varies between layers, the measured \(^{(n)}\)'s correlate well with the ratio \(/b\) across all datasets and NN architectures9. While our theory does not directly cover this setup, our results show that similar behavior is also observed in more complicated scenarios.

## 5 Conclusion

We established a relationship between the data-generating distributions and stationary distributions of offline and online SGD. This enabled us to develop the first theoretical result illuminating the heavy-tailed behavior in offline SGD. We extended previous results encompassing both quadratic losses, as well as more sophisticated strongly convex loss functions. Through an experimental study, we validated our theoretical findings in a variety of settings.

**Limitations.** There are two main limitations to our work. Firstly, our analysis focuses predominantly on the 'upper' tails of the distributions. Studying the bulk of the distribution of the iterates may reveal new findings. For example, research in this direction could connect our findings to learning theory by leveraging existing generalization bounds (e.g., see Corollary 2 in  for a link between 'lower' tails and generalization error). Secondly, it would be of great interest to extend our results to the non-convex deep learning settings. Finally, since this is a theoretical paper studying online and offline SGD, our work contains no direct potential negative societal impacts.

**Acknowledgments.** We thank Benjamin Dupuis for the valuable feedback. AD would like to thank the Isaac Newton Institute for Mathematical Sciences for support and hospitality during the programme _The mathematical and statistical foundation of future data-driven engineering_ when work on this paper was undertaken. Umut Simsekli's research is supported by the French government under management of Agence Nationale de la Recherche as part of the "Investissements d'avenir" program, reference ANR-19-P3IA-0001 (PRAIRIE 3IA Institute) and the European Research Council Starting Grant DYNASTY - 101039676.

Figure 7: Estimated tail indices, LeNet, MNIST