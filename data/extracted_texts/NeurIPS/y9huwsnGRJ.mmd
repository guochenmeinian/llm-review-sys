# Continuously Learning, Adapting, and Improving:

A Dual-Process Approach to Autonomous Driving

 Jianbaio Mei\({}^{1,2,*}\) &Yukai Ma\({}^{1,2,*}\) &Xuemeng Yang\({}^{2}\) &Licheng Wen\({}^{2}\) &Xinyu Cai\({}^{2}\)

Xin Li\({}^{2,4}\) &Daocheng Fu\({}^{2}\) &Bo Zhang\({}^{2}\) &Pinlong Cai\({}^{2}\) &Min Dou\({}^{2}\) &Botian Shi\({}^{2,}\) &Liang He\({}^{3}\) &Yong Liu\({}^{1,}\) &Yu Qiao\({}^{2}\)

\({}^{1}\) Zhejiang University \({}^{2}\) Shanghai Artificial Intelligence Laboratory

\({}^{3}\) East China Normal University \({}^{4}\) Shanghai Jiao Tong University

###### Abstract

Autonomous driving has advanced significantly due to sensors, machine learning, and artificial intelligence improvements. However, prevailing methods struggle with intricate scenarios and causal relationships, hindering adaptability and interpretability in varied environments. To address the above problems, we introduce **LeapAD**, a novel paradigm for autonomous driving inspired by the human cognitive process. Specifically, LeapAD emulates human attention by selecting critical objects relevant to driving decisions, simplifying environmental interpretation, and mitigating decision-making complexities. Additionally, LeapAD incorporates an innovative dual-process decision-making module, which consists of an Analytic Process (System-II) for thorough analysis and reasoning, along with a Heuristic Process (System-I) for swift and empirical processing. The Analytic Process leverages its logical reasoning to accumulate linguistic driving experience, which is then transferred to the Heuristic Process by supervised fine-tuning. Through reflection mechanisms and a growing memory bank, LeapAD continuously improves itself from past mistakes in a closed-loop environment. Closed-loop testing in CARLA shows that LeapAD outperforms all methods relying solely on camera input, requiring 1-2 orders of magnitude less labeled data. Experiments also demonstrate that as the memory bank expands, the Heuristic Process with only 1.8B parameters can inherit the knowledge from a GPT-4 powered Analytic Process and achieve continuous performance improvement. Project page: https://pjlab-adg.github.io/LeapAD/.

+
Footnote †: * equal contribution, \(\) corresponding author

## 1 Introduction

Since the early 21st century, starting with the DARPA Grand Challenge , humanity has explored replacing human drivers with computer algorithms. Over the past two decades, advancements in sensor technology, machine learning, and artificial intelligence have propelled the evolution of self-driving technology. Recent data-driven approaches achieved considerable success, as evidenced by new vehicle models featuring intelligent driving assistance and the commercial operation of L4 robotaxis in several cities . However, these methods depend heavily on diverse training data distributions, resulting in a superficial understanding of underlying semantics and potential misconceptions in complex situations. This is because data-driven approaches primarily perform induction on observed patterns without the capability for deduction, thus constraining their performance to the coverage of the annotated data. Therefore, there is an urgent need for a system capable of reasoning about unseen scenarios and utilizing knowledge in a human cognition manner.

The latest advancements in Large Language Models (LLMs) and Vision Language Models (VLMs), noted for their embedded world knowledge and robust explanatory and reasoning capabilities, have captured the interest of researchers [5; 6; 7; 8]. For example, in the autonomous driving field, some knowledge-based methods [9; 10; 11; 12] employ LLMs and VLMs as the driving agents. However, these methods perform open-loop testing, which merely evaluates errors between model output and the ground truth from datasets, failing to reflect the dynamic interactions between ego car and the real-world environment . Consequently, they are often inadequate to effectively assess the responsiveness and adaptability of driving agents.

In fact, human learning to drive involves a continuous interaction and exploration process within closed-loop environments, where drivers make decisions based on the surroundings and receive feedback accordingly. As per the dual-process theory [14; 15; 16], human intelligence operates on two levels: 1) _Heuristic Process_ (_System-I_), which is automatic, quick, empirical, and domain-specific; and 2) _Analytic Process_ (_System-II_), which is rational, slow, and excels in logical reasoning and creativity across various domains. This dual-process thinking is evident in the progression from novice to experienced driver. Initially, individuals rely heavily on common sense due to their lack of driving experience. Through training, they develop driving skills via a closed-loop learning process involving continuous trial and error, along with rational analysis (Analytic Process) to evaluate their behavior. These skills become internalized over time, forming muscle memory that enables quick, instinctive reactions in familiar driving scenarios (Heuristic Process). Even after obtaining driver's license, individuals continue to gain experience and learn from accidents to enhance driving skills.

To this end, we develop a dual-process closed-loop autonomous driving system that is continuously **l**earning, **a**dapting and improving, named **LeapAD**. Similar to the human attention mechanism, the scene understanding module in LeapAD mainly focuses on critical objects that may affect driving decisions, simplifying the environmental description and the decision-making process. Following such scene understanding, we develop a dual-process decision-making module that emulates human cognitive processes, featuring a Heuristic Process and an Analytic Process [17; 15]. Through a closed-loop setup, Analytic Process accumulates experience and builds a transferable memory bank of high-quality driving decisions. The knowledge can be adapted to various scenarios and then transferred to the lightweight model in Heuristic Process through supervised fine-tuning (SFT). The Heuristic Process is employed for closed-loop decision-making using a few-shot strategy. When traffic accidents occur, the Analytic Process intervenes to analyze these incidents and update the memory bank, enabling the system to continuously improve through self-reflection. The main contributions of our work are summarized as follows:

\(\) We develop an innovative closed-loop autonomous driving approach that emulates the critical object attention mechanisms and the learning processes observed in human driving behavior.

\(\) We propose a dual-process decision-making module inspired by human cognition theory. In the absence of human involvement, our approach enables the fast, empirical Heuristic Process to inherit the capabilities of the slow, rational Analytic Process in a self-supervised manner.

\(\) LeapAD utilizes the Analytic Process and a reflection mechanism to accumulate a transferable memory bank, enabling the system to achieve continuous learning and generalization capabilities in a closed-loop driving environment.

\(\) Extensive experiments in CARLA show that LeapAD not only outperforms all other methods relying solely on camera input, but also achieves this with 1-2 orders of magnitude less annotated data.

## 2 Related Works

### Large Vision Language Models

Inspired by the successful deployment of Large Language Models (LLMs) like LLaMAs [18; 19] and Vicuna , a plethora of Vision Language Models (VLMs) [21; 22; 23; 24; 25; 26; 27; 28; 29] has emerged to broaden their applicability to multi-modal understanding. Various models, such as BLIP2  which utilizes the Q-former, Flamingo  leveraging a perceiver resampler, and LLaVA  alongside MiniGPT-4  that incorporate instruction tuning, have been innovated to enhance feature alignment, few-shot learning, and create versatile visual agents. Moreover, models like Qwen-VL  with its three-stage training, and InternVL 's image-text alignment method, assist in achieving advanced multi-lingual and fine-grained visual comprehension. The rise of VLM and visual-language-action (VLA) models has injected the vitality of autonomous driving, presenting researchers with new opportunities.

### Empowering Autonomous Driving with Foundation Models

Recent work [33; 34; 9; 10; 11; 35] explores the use of large foundation models in autonomous driving, leveraging their embedded world knowledge and powerful interpretation and reasoning capabilities. For understanding driving scenarios, a series of datasets and benchmarks [36; 37; 6; 38] have been proposed. To improve the interpretability of autonomous driving, LMDrive  and DriveMLM  use LLMs to generate human-instructed decisions in the simulated environment, which is data-dependent and hard to adapt to the real world. Agent-Driver  adopts LLM agent for planning, which is less efficient due to excess environmental data. ELM  introduces a vision-language model tailored for embodied understanding within driving scenarios. RAG-Driver  improves driving interpretation and signal prediction by integrating retrieval augmentation and in-context learning. Recent DriveVLM-Dual  integrates VLM and data-driven planning pipelines, providing solutions for deployment. Contrary to the mentioned techniques, our LeapAD draws from attention mechanisms and observational learning and decision-making in human driving. It utilizes a memory bank for experience storage and replay in a closed-loop scenario, enabling continuous learning via memory and reflection mechanisms.

### From Data-Driven to Knowledge-driven Autonomous Driving

While the prevailing data-driven approaches [40; 41; 42; 43; 44; 45; 46; 47; 48; 49; 2] have led to success in both academia and industry in past decades, allowing autonomous driving technology to be used in people's daily lives. However, these methods are limited to the distribution of training data and frequently encounter adaptability issues and long-tail challenges when expanding across different areas [50; 51]. On the other hand, human drivers possess a deep common sense of understanding the world, which enables them to adapt to unexpected scenarios. This highlights the need for a shift to the knowledge-driven approaches, which involve using empirical reasoning and induction to learn from the environment [52; 53], and updating insights to develop specialized skills [54; 55]. Knowledge-driven methods acquire general knowledge rather than merely implementing predefined human rules or abstracting characteristics from collected data in specific domains . These approaches enhance performance, interpretability, and safety by integrating human-like logic into AI systems, particularly in managing complex traffic scenarios. In the era of foundation models, the advanced reasoning and knowledge application capabilities exhibited by LLMs and VLMs have proven highly effective for complex tasks such as understanding, reasoning, and decision-making within the domain of autonomous driving [56; 33; 57]. These foundation models have embedded world knowledge and robust explanatory and reasoning capabilities through extensive training on diverse datasets and captured the researchers' interest [5; 6; 7; 8].

## 3 Methodology

### Overview

In this section, we introduce how we design our anthropomorphic closed-loop autonomous driving system, LeapAD. Figure 1 illustrates that LeapAD consists of three main components: the VLM for scene understanding (Section 3.2), the dual-process decision-making module comprising the Analytic Process (Section 3.3) and the Heuristic Process (Section 3.4), along with the action executor for low-level control (Appendix A). In the CARLA simulator, LeapAD utilizes VLM to process the surrounding images and generate descriptions of critical objects. These scene descriptions are then fed into the dual-process decision-making module in order to derive scene reasoning and driving decisions. Finally, these high-level decisions are forwarded to the action executor, translated into control signals, and interact with the simulator.

In closed-loop driving environments, the fine-tuned lightweight model in Heuristic Process is used to perform quick, empirical decisions with the transferable experience in the memory bank. And when the Heuristic Process encounters accidents, the Analytic Process intervenes. The Analytic Process exploits LLMs to analyze traffic accidents, leveraging its embedded world knowledge, particularly its understanding of traffic rules. It then generates corrected, high-quality driving experiences, enriching the memory bank and enabling continuous learning for the entire system.

### Scene Understanding with VLM

Human drivers typically focus on critical elements surrounding the vehicle to prevent information overload, enhance reaction time, and minimize cognitive load. This approach helps improve driving concentration and reduces accident probabilities. Inspired by such a mechanism, the scene understanding module in LeapAD is designed to selectively identify critical objects, simplifying the description of the surrounding environment and reducing the load on decision-making processes.

Specifically, since off-the-shelf foundation VLMs lack domain-specific knowledge in the driving domain, we perform SFT and prompt the VLMs to output the linguistic descriptions of the objects that may influence subsequent driving decisions. The description of these critical objects includes their semantic, spatial, motion attributes, and behavioral reasoning. Integrating these aspects promotes a comprehensive understanding of the environment, which can ensure safety and adaptability in complex and dynamic driving environments. For a specific driving scene, the descriptions generated by VLM can be expressed as \(D=\{A_{s,i},A_{l,i},A_{m,i},C_{r,i}\}_{i=0}^{N-1}\), where \(N\) denotes the number of the critical objects. For each critical object \(O_{i}\), the description contains: _i)_ the semantic attribute \(A_{s}\) describes its semantic category, usually important traffic participants (e.g., vehicles and cyclists) and infrastructure (e.g., traffic lights and stop signs). _ii)_ The spatial attribute \(A_{l}\) indicates its bounding box, the lane it locates, and the distance from the ego car, which are important for safety and collision avoidance. _iii)_ The motion attribute \(A_{m}\) refers to the motion direction of the object. _iv)_ Behavioral reasoning \(C_{r}\) describes why the object is critical and how it influences the driving decision of the ego car. For example, when the ego car goes straight, the stop sign on the right side is of high importance because it indicates the need to stop at the intersection. We provide an example to further illustrate the descriptions of critical objects in the driving scene, as shown in Figure 9 in Appendix B. Notably, the VLM not only excels in simulated environments but also demonstrates robust performance in real-world scenarios.

### Analytic Process

Based on the scene descriptions provided by the VLM, we design the Analytic Process to imitate the rational thinking of a human driver. The Analytic Process relies on logical reasoning, employing rational thinking to analyze complex situations and make safe driving decisions. The LLMs, through their extensive pre-training on diverse datasets, have encapsulated vast amounts of world knowledge, equipping them with the ability to handle intricate problems with nuanced understanding

Figure 1: The detailed architecture of our proposed LeapAD. The scene understanding module analyzes surrounding images and provides descriptions of critical objects that may influence driving decisions. These scenario descriptions are then fed into the dual-process decision module, which drives reasoning and decision-making. The generated decisions are then transmitted to action executors, where they are converted into control signals for interaction with the simulator. The Analytic Process then uses an LLM to accumulate experience in driving analysis and decision-making, conducting reflections on accidents. The experience is stored in the memory bank and transferred to a lightweight language model, forming our Heuristic Process for quick responses and continuous learning.

and reasoning . This capability aligns with the requirements of the Analytic Process in driving scenarios, where decisions must be made based on deep analysis and contextual understanding of the environment. Our Analytic Process harnesses the power of LLMs, leveraging its world knowledge to understand the scene descriptions and perform high-quality driving analysis and decisions. We empirically found that prompting LLMs with specific traffic rules provided in Appendix C further improves safety and is more reliable for on-road scenarios.

Furthermore, we integrate the VLM and the Analytic Process to run closed-loop experiments and collect the high-quality decision-making processes and results generated by the Analytic Process as "experience" in a memory bank. The accumulated experience can be seamlessly transferred to the Heuristic Process, facilitating it to react quickly based on experience when handling similar situations, as described in Section 3.4.

**Reflection mechanism.** We also employ the Analytic Process to reflect on traffic accidents, as shown in Figure 2. Specifically, when VLM and Heuristic Process run in a closed-loop driving scenario, any accident will trigger the reflection mechanism. During this procedure, the scene description \(D\), reasoning \(R\), and decision \(S\) of the preceding frames before the accident are forwarded to Analytic Process. It is then required to meticulously analyze the cause of the event, locate the error, and provide corrected reasoning and decisions. The insights gained from the reflection procedure are further integrated into the memory bank, allowing the LeapAD to continuously learn from failures and progressively lead to more informed and accurate decision-making in future driving scenarios. Importantly, the experience in the memory bank has good transferability and generalization. It can be directly utilized by other lightweight models and easily generalized to different scenarios, as demonstrated in section 4.4.

### Heuristic Process

While the Analytic Process can offer more precise driving reasoning and decisions due to its detailed analysis and careful consideration, the inherent slow processing causes duplicated and redundant effort, limiting its application in practical driving scenarios. In contrast, human drivers form muscle memory through repeated practice and experience, requiring less effort over time. To reflect this quick and empirical thinking pattern and facilitate practical application, we craft a Heuristic Process in LeapAD incorporating a lightweight language model. Specifically, we perform supervised fine-tuning (SFT) using the samples stored in the accumulated memory bank mentioned in Section 3.3 to distill knowledge into the lightweight language model. By this means, the Heuristic Process achieves behavior adaption to various scenarios and runs much faster than Analytic Process (about 5 times faster in our experiments). We empirically found that the lightweight model without SFT is unable to produce appropriate driving decisions.

**Few-shot Prompting.** Moreover, we perform few-shot prompting  to enhance the Heuristic Process's generalization ability for unseen scenes and mitigate hallucinations for more robust decisions.

Figure 2: Detailed procedure of the reflection mechanism. When Heuristic Process encounters traffic accidents, the Analytic Process intervenes, analyzing historical frames to pinpoint errors and provide corrected samples. These corrected samples are then integrated into the memory bank to facilitate continuous learning.

Through such a mechanism, the Heuristic Process can effectively leverage the experience and deep insights from the existing memory bank, improving the accuracy of future driving decisions. To facilitate the retrieval of similar driving scenes from the memory bank for few-shot prompting, we primarily rely on the embedding similarity between the current scene's descriptions and those stored in the memory bank. However, if directly calculating text similarity based on the original descriptions, the presence of redundant linguistic information in descriptions can complicate the differentiation between scenes. Thus, we propose a novel scene encoding method to extract and encode compressed captions that comprise key elements such as the critical object's category, lane, and distance from the ego car. This approach streamlines the procedure of querying similar scenarios, enhancing retrieval efficiency and accuracy by prioritizing the most influential aspects for driving decisions of each scenario. Afterward, the compressed captions are sent to a text encoder to encode the embedding vectors, which are expressed as follows:

\[=T_{e}(F_{c}(D)),\] (1)

where \(D\) is the scene description, \(F_{c}\) denotes the compressing process, and \(T_{e}\) indicates the text encoder. Subsequently, the cosine similarity between the query embedding \(_{q}\) for the current scene and the embedding \(\{_{i}\}_{i=0}^{M-1}\) for the memory bank with the size of \(M\) is computed by:

\[s(_{q},_{i})=_{q}_{i}}{\| _{q}\|\|_{i}\|}.\] (2)

We select top-k samples with the highest similarity scores as queried scenes. The scene descriptions \(\{D_{i}\}_{i=0}^{k-1}\), reasoning \(\{R_{i}\}_{i=0}^{k-1}\), and decisions \(\{S_{i}\}_{i=0}^{k-1}\) of k samples and the scene descriptions \(D_{c}\) of the current scene are both fed into the Heuristic Process for the final reasoning \(R_{c}\) and decision \(S_{c}\).

## 4 Experiments

### Data preparation

Data for VLM.We construct the instruct-following datasets for supervised fine-tuning of our VLM by integrating Rank2Tell , DriveLM , and data collected within CARLA . To maintain consistency across all the datasets, we adopt a uniform standard reference format for critical objects as: <ref>In {camera view}, {properties}</ref><box>{coordinates}</box>. For each dataset, specific Q&A pairs are created to suit their unique structures and contents. The conversations are structured in a summary-elaboration manner, with the first question for the Rank2Tell and DriveLM datasets focusing on determining the number, semantic, and spatial attributes, such as the bounding box coordinates of key objects. For the Rank2Tell dataset, we follow up by inquiring about the moving state, importance, and corresponding reasoning for each critical object. For the DriveLM dataset, we retain most of the original questions but eliminate redundant ones. We extract only \(6\) frames of data from Rank2tell and DriveLM and organize them in the standardized format. The data gathered from the CARLA simulator is exclusively dedicated to the closed-loop experiments detailed in Section 4.3. A comprehensive training dataset of \(5\) frames is collected from Town 01-04, 06, 07, and 10. To identify key objects within the scene, we design several automatic annotation rules, as detailed in Appendix B. For clarity, we provide the data illustration in Figure 9 in Appendix B.

Data for Heuristic Process.We leverage the integration of Analytic Process and VLM to accumulate experience within the closed-loop setup and save it in the memory bank for subsequent SFT and few-shot prompting of Heuristic Process. Moreover, our approach incorporates dynamic updates to address errors encountered by the Heuristic Process, as mentioned in the reflection mechanism

Figure 3: The illustration of the fine-tuning process. We fine-tune the VLM (Qwen-VL-7B) using 11K instructions-following data for scene understanding (left). Also, we utilize the collected samples in the memory bank to fine-tune Qwen-1.5 used in Heuristic Process, as illustrated in the right part.

outlined in Section 3.3. The memory bank in our approach is configured to a default size of \(9.0\), including samples collected from various towns (01-04, 06, 07, and 10). It is worth noting that samples are obtained in a closed-loop environment without human involvement. Each sample consists of the scene descriptions \(D\) depicted in Section 3.2, reasoning \(R\), and decisions \(S\). The reasoning \(R\) explains the process of decision-making based on the scene descriptions \(D\) and chain of thought.

### Implementation Details

We employ Qwen-VL-7B  as the VLM for scene understanding, GPT-4 as the Analytic Process for rational and logic thinking, and Qwen1.5-1.8B  as Heuristic Process for automatic and quick thinking in LeapAD. We use the OpenAI embedding model as the text encoder \(T_{e}\) to extract text embedding. To fully excite our VLM's capabilities in autonomous driving, we perform SFT with the instruction-following data discussed in Section 4.1. We utilize the AdamW optimizer  with \(_{1}=0.9\) and \(_{2}=0.95\), coupled with a cosine decay of the learning rate, initially set to \(1e^{-5}\). The batch size is set to 16, and the model is trained for 5 epochs on 8 A100 GPUs, requiring about 26 hours. The input image resolution is set at \(448 448\) pixels. For Heuristic Process, we conduct SFT on Qwen1.5-1.8B for 5 epochs using samples stored in the memory bank, taking about 6 hours. The training hype-parameters are consistent with the training procedure of VLM. The detailed fine-tuning process is shown in Figure 3. The dual-process decision module outputs meta-actions (e.g., "AC", "DC", "IDLE", "STOP") at a frequency of 2 HZ, which are further refined to control signals, as detailed in the Appendix A. Please refer to Appendix D for more details about the reflection mechanism and Appendix B for the performance of VLM on both simulated and real datasets.

### Evaluation in Closed-Loop Driving

We conduct closed-loop experiments in CARLA, a popular and realistic open-source simulator, to evaluate the performance of our LeapAD. To validate the effectiveness, we conduct a comprehensive assessment in a closed-loop driving scenario on the Town05 benchmark. Our evaluation metrics include Driving Score (DS), Route Completion (RC), and Infraction Score (IS). RC signifies the proportion of the route successfully navigated by the agent, while IS indicates penalties incurred from accidents. By multiplying RC by IS, we obtain the final metric DS for evaluating our method's driving performance on a route. Table 1 compares our method with competitive methods on the Town05 Short benchmark. Specifically, we provide three different configurations to evaluate our methods comprehensively: _i)_ VLM + GPT-4 represents directly using non-fine-tuned GPT-4 as the decision module along with the VLM (Qwen-VL ); _ii)_ LeapAD (w/o Town05) represents the dual-process system with the memory bank of 9K samples accumulated from various towns (01-04, 06, 07, and 10) except Town05; _iii)_ LeapAD denotes the dual-process system with the memory bank of 18K samples accumulated from various towns (01-07, and 10) and 0.1K reflection data in Town05.

As shown in Table 1, our LeapAD outperforms all other methods that rely solely on camera sensor input. Besides, our method surpasses TransFuser , which additionally utilizes LiDAR sensor inputs. It is worth noting that in all experiments, we only used a total of \(11\) data to fine-tune the

   Method & Modality & Type & Annotations & DS \(\) & RC \(\) \\  InterFuser  & L+C & DD & \(3\) & **94.95\(\)1.91** & **95.19\(\)2.57** \\ TransFuser  & L+C & DD & \(228\) & 54.52\(\)4.29 & 78.41\(\)3.75 \\  VAD  & C & DD & 228K & 64.30 & 87.30 \\ NEAT  & C & DD & \(130\) & 58.70\(\)4.11 & 77.32\(\)4.91 \\ Roach  & C & DD & - & 65.26\(\)3.63 & 88.24\(\)5.16 \\ WOR  & C & DD & \(1\) & 64.79\(\)5.53 & 87.47\(\)4.68 \\ LBC  & C & DD & \(157\) & 30.97\(\)4.17 & 55.01\(\)5.14 \\ CLLRS  & C & DD & \(720\) & 7.47\(\)2.51 & 13.40\(\)1.09 \\ VLM + GPT-4 & C & KD & \(11\) & 81.31\(\)2.37 & 94.22\(\)3.18 \\
**LeapAD (w/o Town05)** & C & KD & \(11\) & 75.73\(\)1.36 & 92.10\(\)1.44 \\
**LeapAD** & C & KD & \(11\) & **83.11\(\)0.28** & **94.98\(\)0.54** \\   

Table 1: Comparison of our LeapAD with competitive methods on Town05 Short benchmark. Notably, LeapAD demonstrated superior performance with a smaller data footprint, outperforming other approaches. “DD” & “KD” denote data-driven and knowledge-driven, respectively. “L” & “C” indicate LiDAR and camera modalities.

VLM, while all other methods employ tens to hundreds of times more data. Moreover, our dual-process decision module does not involve human annotations, demonstrating the labeling efficiency of LeapAD. For instance, although InterFuser  achieves higher performance than our LeapAD, it relies on 3 million camera and LiDAR annotations, approximately 272 times more than our method. As shown in the results, we observe that even without prior driving experience in Town05, LeapAD can surpass other camera-input methods. However, there remains a gap compared to VLM + GPT-4, which integrates the scene understanding module and the Analytic Process, achieving a DS of 81.31. This demonstrates that GPT-4's understanding of world knowledge and common sense aids in performing driving-specific tasks. But using GPT-4 directly as the decision-making module is both time-consuming and expensive, making it impractical for deployment in vehicles. On the other hand, with the continuous accumulation and adaptation of experience in the test town, our LeapAD surpasses VLM + GPT-4, while only using a 1.8B model in Heuristic Process. By leveraging an enriched memory bank, it achieves a final DS of 83.11. This result fully validates the effectiveness of our dual-process decision-making module. Moreover, we provide the evaluation results on the Town05 Long benchmark and visualizations in Appendix E and F.

### Ablation Study

We conduct extensive ablation studies about the number of few shots, size of the memory bank, reflection mechanism, and accumulated experience in a closed-loop driving setup to demonstrate the generalization and continuous learning capabilities of our LeapAD.

Ablation on the number of few-shot.We highlight the importance of few-shot prompting in using accumulated experience to guide current decision-making. The experiments are tested on the Town05 Short benchmark with the memory bank consisting of \(9\) samples automatically collected by Analytic Process in Town05. The results are presented in Figure 4, showing that our approach surpasses several methods (e.g., CLIRS , LBC  in Table 1) even with a zero-shot setting. Furthermore, there is a notable performance improvement when moving from zero-shot to one-shot scenarios. Moreover, there is a consistent increase in closed-loop experiment results as the number of shots is increased to three, which experimentally demonstrates the value of the experience in the memory bank and the effectiveness of the few-shot strategy.

The impact of memory sizes.The memory bank contains accumulated experiences crucial for improving the performance of our approach. Therefore, we conduct additional ablation studies to explore the impact of the size of the memory bank, which is equipped with the few-shot strategy (defaulting to 3-shot). We conduct closed-loop evaluations with memory banks of different sizes: _i)_ base memory bank with \(9\) samples. _ii)_ compressed memory banks with 900 and 90 samples evenly sampled from the base memory bank. _iii)_ no memory bank in system. The quantitative results are presented in Figure 4 and illustrate a gradual performance increase as the memory size grows. This

    & \)(m)} &  &  &  &  &  \\  & & & Few-shot & SFT & Few-shot & SFT & & & \\   &  &  &  & ✓ & & 66.40 & 90.40 & 73.81 \\  & & & ✓ & ✓ & & & 75.73 & 92.10 & 82.66 \\  & & & & & & ✓ & 69.90 & 91.79 & 76.64 \\  & & & & & ✓ & ✓ & 78.07 & 91.69 & 85.89 \\  & & ✓ & ✓ & ✓ & ✓ & 83.11 & 94.98 & 87.78 \\  Town01 & 129.1 & & & & ✓ & ✓ & 68.68 & 100.0 & 68.68 \\  Town04 & 119.3 & & & & ✓ & ✓ & 95.08 & 97.96 & 96.56 \\   

Table 2: Generalization of accumulated knowledge in the memory bank. We evaluate the performance of our LeapAD across various towns (Town05, Town01, and Town04) by leveraging memory banks accumulated from diverse sources. \(L_{avg}\) denotes the average lengths of routes within each town.

Figure 4: The illustration for ablation studies of few-shot and memory size. See Appendix E for the detailed data.

further demonstrates the continuous learning capability of our proposed LeapAD, indicating that our model's performance can improve with accumulated experience.

Effectiveness of the reflection mechanism.Reflection plays a crucial role in the continuous learning capability of our proposed LeapAD. It includes reflecting on mistakes and incorporating correct experiences into the memory bank, fostering self-improvement through proactive summarization and accumulation of experiences in unfamiliar scenes, notably corner cases. To enhance experimental efficiency, we employ a configuration of three shots and a memory bank with 900 stored memories in the Town05 environment. Reflective experiments are conducted by selecting routes with scores below 50. incorporated, and the post-reflection experiences were added to the memory bank. Figure 5 indicates that reflection significantly enhances out method's performance, albeit with some instances where individual sequence scores temporarily decrease, potentially due to the inherent randomness of the simulation environment and the limitations of the VLM model. Addressing these limitations will be the focus of our future work.

Generalization of accumulated knowledge.Finally, we conduct a series of experiments to demonstrate the generalization and transferability of the experience in the memory bank. The results are illustrated in Table 2, which shows the robustness of our proposed LeapAD on different towns. As shown in Row 1 and Row 3, solely employing experience adaption (SFT) from different towns with zero-shot, our LeapAD has achieved commendable performance on the Town05 Short benchmark, surpassing many methods in Table 1. Implementing the few-shot strategy yields substantial enhancements (Row 2 & 4), further highlighting the effectiveness of the experience in the memory bank. Furthermore, we perform cross-validation to demonstrate the generalization of the accumulated experience, focusing on two setups: _i)_ testing on Town05 with the memory bank collected from other towns (Row 1 & 2); _ii)_ testing on the other towns (Town01, 04) with the memory bank accumulated only from Town05 (Row 6 & 7). Comparing Row 2 with Row 4, our LeapAD utilizing different memory sources achieves comparable performance in the same town (Town05). Additionally, our proposed LeapAD demonstrates good performance across different towns when using the same memory bank (Row 4, 6 & 7). In this section, several low-quality samples in the memory bank on routes with low driving scores are withdrawn when accumulating experience, and no special memory processing is performed on those experiments in Figure 4.

## 5 Conclusion

In this paper, we introduce LeapAD, a dual-process closed-loop autonomous driving system with continuous learning, adapting, and improving capabilities. Similar to human attention, our approach selectively prioritizes critical objects that can influence driving decisions, simplifying the scene description and reducing decision-making complexity. Furthermore, the dual-process decision-making module mimics human cognitive processes through a fast, empirical Heuristic Process and a slow, rational Analytic Process. Through reflection mechanisms and a transferable memory bank, LeapAD continuously improves from past experiences in a closed-loop environment, demonstrating continuous learning capabilities and strong adaptability to various driving scenarios. Moreover, LeapAD can be seamlessly integrated with the mainstream cloud-edge architectures employed in intelligent vehicles. The Heuristic Process operates at the edge, enabling instant decision-making within the vehicle, while the Analytic Process handles more complex scenarios in the cloud.

Figure 5: Effectiveness of the reflection mechanism. The \(x\)-axis represents the rounds of reflection, while the \(y\)-axis denotes the resulting driving score. The dashed line illustrates performances on different routes after multi-round reflection, and the red “average score” denotes the mean performance across all routes.

## 6 Limitations and Broader Impacts

Currently, LeapAD relies solely on single-frame camera inputs, without any temporal input. Another bottleneck of our approach is the VLM's inability to participate in the reflection mechanism, which hinders further system improvements. Additionally, there is a notable gap between predefined agent behaviors in the CARLA benchmark and those in real-world scenarios, underscoring the need for a high-fidelity world simulator. For impacts, autonomous driving systems gather extensive data on driving behaviors, routes, and passenger movements, raising concerns about data privacy and legal implications. Nonetheless, advancements in technology and regulatory frameworks can help address these issues, paving the way for safer, more efficient, and accessible driving systems.

## 7 Acknowledgments

This research was supported by the NSFC 62088101 Autonomous Intelligent Unmanned Systems. Additionally, it received support from the Shanghai Artificial Intelligence Laboratory, the National Key R&D Program of China (Grant No. 2022ZD0160104), and the Science and Technology Commission of Shanghai Municipality (Grant No. 22DZ1100102).