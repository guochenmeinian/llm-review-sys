# Qualitative Mechanism Independence

Oliver E. Richardson

Dept of Computer Science

Cornell University

Ithaca NY 14853

oli@cs.cornell.edu

&Spencer Peters

Dept of Computer Science

Cornell University

Ithaca NY 14853

speters@cs.cornell.edu

&Joseph Y. Halpern

Dept of Computer Science

Cornell University

Ithaca NY 14853

halpern@cs.cornell.edu

###### Abstract

We define what it means for a joint probability distribution to be _(QIM-)compatible_ with a set of independent causal mechanisms, at a qualitative level--or, more precisely, with a directed hypergraph \(\), which is the qualitative structure of a probabilistic dependency graph (PDG). When \(\) represents a qualitative Bayesian network, QIM-compatibility with \(\) reduces to satisfying the appropriate conditional independencies. But giving semantics to hypergraphs using QIM-compatibility lets us do much more. For one thing, we can capture functional _dependencies_. For another, QIM-compatibility captures important aspects of causality: we can use compatibility to understand cyclic causal graphs, and to demonstrate compatibility is essentially to produce a causal model. Finally, compatibility has deep connections to information theory. Applying compatibility to cyclic structures helps to clarify a longstanding conceptual issue in information theory.

## 1 Introduction

The structure of a (standard) probabilistic graphical model (like a Bayesian Network or Markov Random Field) encodes a set of conditional independencies among variables. This is useful because it enables a compact description of probability distributions that have those independencies; it also lets us use graphs as a visual language for describing important qualitative properties of a probabilistic world. Yet these kinds of independencies are not the only important qualitative aspects of a probability measure. In this paper, we study a natural generalization of standard graphical model structures that can describe far more than conditional independence.

For example, another qualitative aspect of a probability distribution is that of functional _dependence_, which is also exploited across computer science to enable compact representations and simplify probabilistic analysis. Acyclic causal models, for instance, specify a distribution via a probability over _contexts_ (the values of variables whose causes are viewed as outside the model), and a collection of equations (i.e., functional dependencies) . And in deep learning, a popular class of models called _normalizing flows_ specify a distribution by composing a fixed distribution over some latent space, say a standard normal distribution, with a function (i.e., a functional dependence) fit to observational data. Functional dependence and independence are deeply related and interacting notions. For instance, if \(B\) is a function of \(A\) (written \(A B\)) and \(A\) is independent of \(C\) (written \(A\!\!\! C\)), then \(B\) and \(C\) are also independent (\(B\!\!\! C\)).1 Moreover, dependence can be written in terms of independence: \(Y\) is a function of \(X\) if and only if \(Y\) is conditionally independent of itself given \(X\) (i.e., \(X Y\) iff \(Y\!\!\! Y X\)). Traditional graph-based languages such as Bayesian Networks (BNs) and Markov Random Fields (MRFs) cannot capture these relationships. Indeed, the graphoid axioms (which describe BNs and MRFs)  and axioms for conditional independence , do not even consider statements like \(A\!\!\! A\) to be syntactically valid. Yet such statementsare perfectly meaningful, and reflect a deep relationship between independence, dependence, and generalizations of both notions (grounded in information theory, a point we will soon revisit).

This paper provides a simple yet expressive graphical language for describing qualitative structure such as dependence and independence in probability distributions. The idea is to specify the inputs and outputs of a set of _independent mechanisms_: processes by which some target variables \(T\) are determined as a (possibly randomized) function of some source variables \(S\). This idea generalizes intuition going back to Pearl  by allowing, for example, two mechanisms to share a target variable. So at a qualitative level, the modeler specifies not a (directed) graph, but a (directed) _hypergraph_.

If we were interested in a concrete probabilistic model, we would also need to annotate this hypergraph with quantitative information describing the mechanisms. For directed acyclic graphs, there are two standard approaches: supply conditional probability distributions (cpts) to get a BN, or supply equations to get a causal model. Correspondingly, there are two approaches to probabilistic modeling based on hypergraphs. The analogue of the first approach--supplying a probability \(P(T|S)\) for each mechanism--leads to the notion of a _probabilistic dependency graph (PDG)_. The analogue of the second approach--supplying an equation describing \(T\) as a function of \(S\) and independent random noise--leads to a novel generalization of a causal model (Definition 4). Models of either kind are of interest to us only insofar as they explain how hypergraphs encode qualitative aspects of probability. Qualitative information in a PDG was characterized by Richardson and Halpern  using a scoring function that, despite having some attractive properties, lacks justification and has not been fully understood. In particular, the PDG formalism does not appear to answer a basic question: _what does it mean for a distribution to be compatible with a directed hypergraph structure?_

We develop precisely such a notion (Definition 2) of compatibility between a distribution \(\) and a directed hypergraph qualitatively representing a collection of independent mechanisms--or, for short, simply (QIM-)compatibility. This definition allows us to use directed hypergraphs as a language for specifying structure in probability distributions, of which the semantics of qualitative BNs are a special case (Theorem 1). Yet QIM-compatibility can do far more than represent conditional independencies in acyclic networks. For one thing, it can encode arbitrary functional dependencies (Theorem 2); for another, it gives meaningful semantics to cyclic models. Indeed, compatibility lets us go well beyond capturing dependence and independence. The fact that Pearl  views causal models as representing independent mechanisms suggests that there might be a connection to causality. In fact, there is. A _witness_ that a distribution \(\) is compatible with a hypergraph \(\) is an extended distribution \(\) that is nearly equivalent to (and guarantees the existence of) a causal model that explains \(\) with dependency structure \(\) (Propositions 3 to 5). As we shall see, thinking in terms of witnesses and compatibility allows us to tie together causality, dependence, and independence.

Perhaps surprisingly, compatibility also has deep connections with information theory (Section 4). The conditional independencies of a BN can be viewed as a certain kind of information-theoretic constraint. Our notion of compatibility with a hypergraph \(\) turns out to imply a generalization of this constraint (closely related to the qualitative PDG scoring function) that is meaningful for all hypergraphs (Theorem 7). Applied to cyclic models, it yields a causally inspired notion of pairwise interaction that clarifies some important misunderstandings in information theory (Examples 5 and 6).

Saying that one approach to qualitative graphical modeling has connections to so many different notions is a rather bold claim. We spend the rest of the paper justifying it.

## 2 Qualitative Independent-Mechanism (QIM) Compatibility

In this section, we present the central definition of our paper: a way of making precise Pearl's notion of "independent mechanisms", used to motivate Bayesian Networks from a causal perspective. Pearl [19, p.22] states that _"each parent-child relationship in a causal Bayesian network represents a stable and autonomous physical mechanism."_ But, technically speaking, a parent-child relationship only partially describes the mechanism. Instead, the autonomous mechanism that determines the child is really represented by that child's joint relationship with all its parents. So, the qualitative aspect of a mechanism is best represented as a directed _hyperarc_, that can have multiple sources.

**Definition 1**.: A _directed hypergraph_ (or simply a hypergraph, since all our hypergraphs will be directed) consists of a set \(\) of nodes and a set \(\) of directed hyperedges, or _hyperarcs_; each hyperarc \(a\) is associated with a set \(S_{a}\) of source nodes and a set \(T_{a}\) of target nodes. We write \(S^{_{i}}T\) to specify a hyperarc \(a\) together with its sources \(S=S_{a}\) and targets \(T=T_{a}\). Nodesthat are neither a source nor a target of any hyperarc will seldom have any effect on our constructions; the other nodes can be recovered from the hyperarcs (by selecting \(:=_{a}S_{a} T_{a}\)). Thus, we often leave \(\) implicit, referring to the hypergraph simply as \(\). 

Following the graphical models literature, we are interested in hypergraphs whose nodes represent variables, so that each \(X\) will ultimately be associated with a (for simplicity, finite) set \((X)\) of possible values. However, one should not think of \(\) as part of the information carried by the hypergraph. It makes perfect sense to say that \(X\) and \(Y\) are independent without specifying the possible values of \(X\) and \(Y\). Of course, when we talk concretely about a distribution \(\) on a set of variables \((,)\), those variables must have possible values--but the _qualitative_ properties of \(\), such as independence, can be expressed purely in terms of \(\), without reference to \(\).

Intuitively, we expect a joint distribution \(()\) to be qualitatively compatible with a set of independent mechanisms (whose structure is given by a hypergraph \(\)) if there is a mechanistic explanation of how each target arises as a function of the variable(s) on which it depends and independent random noise. This is made precise by the following definition.

**Definition 2** (QIM-compatibility).: Let \(\) and \(\) be (possibly identical) sets of variables, and \(=\{S_{a}T_{a}\}_{a}\) be a hypergraph with nodes \(\). We say a distribution \(()\) is _qualitatively independent-mechanism compatible_, or (QIM-)compatible, with \(\) (symbolically: \(\)) iff there exists an extended distribution \((\,_{})\) of \(()\) to \(\) and to \(_{}=\{U_{a}\}_{a}\), an additional set of "noise" variables (one variable per hyperarc) according to which:

1. the variables \(\) are distributed according to \(\) (i.e., \(()=()\)),
2. the variables \(_{}\) are mutually independent (i.e., \((_{})=_{a}(U_{a})\) ), and
3. the target variable(s) \(T_{a}\) of each hyperarc \(a\) are determined by \(U_{a}\) and the source variable(s) \(S_{a}\) (i.e., \( a\). \((S_{a},U_{a}) T_{a}\)).

We call such a distribution \((\,_{})\) a _witness_ that \(\) is QIM-compatible with \(\). 

While Definition 2 requires the noise variables \(\{U_{a}\}_{a}\) to be independent of one another, note that they need not be independent of any variables in \(\). In particular, \(U_{a}\) may not be independent of \(S_{a}\), and so the situation can diverge from what one would expect from a randomized algorithm, whose randomness \(U\) is assumed to be independent of its input \(S\). Furthermore, the variables in \(\) may not be independent of one another conditional on the value of some \(X\).

**Example 1**.: \((X,Y)\) is compatible with \(=\{\{X\}, \{Y\}\}\) (depicted in PDG notation as ) iff \(X\) and \(Y\) are independent, i.e., \((X,Y)=(X)(Y)\). For if \(U_{1}\) and \(U_{2}\) are independent and respectively determine \(X\) and \(Y\), then \(X\) and \(Y\) must also be independent. 

This is a simple illustration of a more general phenomenon: when \(\) describes the structure of a Bayesian Network (BN), then QIM-compatibility with \(\) coincides with satisfying the independencies of that BN (which are given, equivalently, by the _ordered Markov properties_, _factoring_ as a product of probability tables, or _d-separation_). To state the general result (Theorem 1), we must first clarify how the graphs of standard graphical and causal models give rise to directed hypergraphs.

Suppose that \(G=(V,E)\) is a graph, whose edges may be directed or undirected. Given a vertex \(u V\), write \(_{G}(u):=\{v:(v,u) E\}\) for the set of vertices that can "influence" \(u\). There is a natural way to interpret the graph \(G\) as giving rise to a set of mechanisms: one for each variable \(u\), which determines the value of \(u\) based the values of the variables on which \(u\) can depend. Formally, let \(_{G}:=\,_{G}(u) \{u\}\,}_{u V}\) be the hypergraph _corresponding_ to the graph \(G\).

**Theorem 1**.: _If \(G\) is a directed acyclic graph and \((G)\) consists of the independencies of its corresponding Bayesian network, then \(_{G}\) if and only if \(\) satisfies \((G)\)._

Theorem 1 shows, for hypergraphs that correspond to directed acyclic graphs (dags), our definition of compatibility reduces exactly to the well-understood independencies of BNs. This means that QIM-compatibility, a notion based on the independence of causal mechanisms, gives us a very different way of characterizing these independencies--one that can be generalized to a much larger class of graphical models that includes, for example, cyclic variants . Moreover, QIM-compatibility can capture properties other than independence. As the next example shows, it can capture determinism.

**Example 2**.: If consists of just two hyperarcs pointing to a single variable \(X\), then a distribution \((X)\) is QIM-compatible with \(\) iff \(\) places all mass on a single value \(x(X)\).

[MISSING_PAGE_FAIL:4]

easy to see that a setting of the exogneous variables determines the values of the endogenous variables (symbolically: \(M\)). A _probabilistic SEM_ (PSEM) \(=(M,P)\) is a SEM, together with a probability \(P\) over the exogenous variables. When \(\), the distribution \(P()\) extends uniquely to a distribution over \(()\). A cyclic PSEM, however, may induce more than one such distribution, or none at all. In general, a PSEM \(\) induces a (possibly empty) convex set of distributions over \(()\). This set is defined by two (linear) constraints: the equations \(\) must hold with probability 1, and the marginal probability over \(\) must equal \(P\). Given a PSEM \(\), let consist of all joint distributions \((,)\) that satisfy the two constraints above; this set captures the behavior of \(\) in the absence of interventions. A joint distribution \(()\) over \(\)_can arise from_ a (P)SEM \(\) iff there is some \(\{\}\) whose marginal on \(\) is \(\).

We now review the syntax of a language for describing causality. A _basic causal formula_ is one of the form \([]\), where \(\) is a Boolean expression over the endogenous variables \(\), \(\) is a subset of them, and \(()\). The language then consists of all Boolean combinations of basic formulas. In a causal model \(M\) and context \(()\), a Boolean expression \(\) over \(\) is true iff it holds for all \((,)(,)\) consistent with the equations of \(M\). Basic causal formulas are then given semantics by \((M,)[]\) iff \((M_{},)\), where \(M_{}\) is the result of changing each \(f_{Y}\), for \(Y\), to the constant function \([Y]\), which returns (on all inputs \(\)) the value of \(Y\) in the joint setting \(\). The dual formula \(:=[]\) is equivalent to \([]\) in SEMs where each context \(\) induces a unique setting of the endogenous variables . A PSEM \(=(M,P)\) assigns probabilities to causal formulas according to \(_{}():=P(\{():(M, )\})\).

Some authors assume that for each variable \(X\), there is a special "independent noise" exogenous variable \(U_{X}\) on which only the equation \(f_{X}\) can depend; we call a PSEM \((M,P)\)_randomized_ if it contains such exogenous variables that are mutually independent according to \(P\), and _fully randomized_ if all its exogenous variables are of this form. Randomized PSEMs are clearly a special class of PSEMs, but note also that every PSEM can be converted to an equivalent randomized PSEM by extending it with additional dummy variables \(\{U_{X}\}_{X}\) that can take only a single value. Thus, we do not lose expressive power by using randomized PSEMs. In fact, _qualitatively_, randomized PSEMs are more expressive: they can encode independence.

### The Equivalence Between QIM-Compatibility and Randomized PSEMs

We are now equipped to formally describe the connection between QIM-compatibility and causality. At a high level, this connection should be unsurprising: witnesses and causal models both relate dependency structures to distributions, but in "opposite directions". QIM-compatibility starts with distributions and asks what dependency structures they are compatible with. Causal models, on the other hand, are explicit (quantitative) representations of dependency structures that give rise to sets of distributions. We now show that the existence of a causal model coincides with the existence of a witness. We start by showing this for the hypergraphs generated by graphs (like Bayesian networks, except possibly cyclic), which we show correspond to fully randomized causal models (Proposition 3). We then give a natural generalization of a causal model that exactly captures QIM-compatibility with an arbitrary hypergraph (Proposition 4). In both cases, the high-level result is the same: \(\) iff there is a causal model that "has dependency structure \(\)" that gives rise to \(\).

More precisely, a randomized causal model \(\)_has dependency structure_\(\) iff there is a 1-1 correspondence between \(a\) and the equations of \(\), such that the equation \(f_{a}\) produces a value of \(T_{a}\) and depends only on \(S_{a}\) and \(U_{a}\). The definition above emphasizes the hypergraph; for readers interested in causality, here is an equivalent one that emphasizes the causal model: \(\) is of dependency structure \(\) iff the targets of \(\) are disjoint singletons corresponding to the elements of \(\) (so \(=\{S_{Y}\{Y\}\}_{Y}\)), and \(_{}(Y) S_{Y}\{U_{Y}\}\) for all \(Y\). We start by presenting the result in the case where \(\) corresponds to a directed graph.

**Proposition 3**.: _Given a graph \(G\) and a distribution \(\), \(_{G}\) iff there exists a fully randomized PSEM of dependency structure \(_{G}\) from which \(\) can arise._

In other words, compatibility with a hypergraph corresponding to a graph means arising from a fully randomized PSEM of the appropriate dependency structure. In light of this, Theorem 1 can be viewed as formalizing a phenomenon that seems to be almost universally implicitly understood: every acyclic fully randomized SEM induces a distribution with the independencies of the corresponding Bayesian Network. Conversely, every distribution with those independencies arises from such a causal model. Both halves have been recognized before. Druzdzel and Simon [4, Theorem 1] arguably establish one direction of the correspondence (turning a BN into a causal model), but their statement of the result obscures the possibility of a converse.2 Pearl's _causal Markov condition_[20, Theorem 1], on the other hand, is closely related to that converse (as will be made explicit by our Proposition 3). Yet, to the best of our knowledge, the two results have not before been combined and recognized as an equivalent characterization of a BN's conditional independencies.

Like before, QIM-compatibility allows us to go much futher. It is easy to extend Proposition 3 to the dependency structures of all randomized PSEMs. But what happens if \(\) contains hyperarcs with overlapping targets? Here the correspondence starts to break down for a simple reason: by definition, there is at most one equation per variable in a (P)SEM; thus, no PSEM can have dependency structure \(\). Nevertheless, the correspondence between witnesses and causal models persists if we simply drop the (traditional) requirement that \(\) is indexed by \(\). This leads us to consider a natural generalization of a (randomized) PSEM that has an arbitrary set of equations--not just one per variable.

**Definition 4**.: Let \((,)\) be a hypergraph. A _generalized randomized PSEM_\(=(,,,P)\)_with structure_\(\) consists of sets of variables \(\) and \(=\{U_{a}\}_{a}\), together with a set of functions \(\!=\!\{f_{a}:(S_{a})(U_{a}) (T_{a})\}_{a}\), and a probability \(P_{a}\) over each independent noise variable \(U_{a}\). The meanings of \(\{\!\{\}\!\}\) and _can arise_ are the same as for a PSEM. 

**Proposition 4**.: \(\) _iff there exists a generalized randomized PSEM with structure \(\) from which \(\) can arise._

Generalized randomized PSEMs can capture functional dependencies, and constraints. For instance, an equality (say \(X=Y\)) can be encoded in a generalized randomized PSEM with a second equation for \(X\). Indeed, we believe that generalized randomized PSEMs can capture a wide class of constraints, and are closely related to _causal models with constraints_, a discussion we defer to future work.

### Interventions and the Correspondence Between Witnesses and Causal Models

We have seen that QIM-compatibility with \(\) (i.e., the existence of a witness \(\)) coincides exactly with the existence of a causal model \(\) from which a distribution can arise. But which witnesses correspond to which causal models? The answer to this question will be critical to extend the correspondence we have given so that it can deal with interventions. Different causal models may give rise to the same distribution, yet handle interventions differently.

There are two directions of the correspondence. Given a randomized PSEM \(\), distributions arising from it are compatible with its dependency structure, and the corresponding witnesses are exactly the distributions in \(\{\!\{\}\!\}\) (see Appendix E). In particular, if \(\) is acyclic, there is a unique witness. The converse is more interesting: how can we turn a witness into a causal model?

**Construction 5**.: Given a witness \(()\) to compatibility with a hypergraph \(\) with disjoint targets, construct a PSEM according to the following (non-deterministic) procedure. Take \(:=_{a}T_{a}\), \(:=_{}(\!-\!)\), and \(P():=()\). For each \(X\), there is a unique \(a_{X}\) whose targets \(T_{a_{X}}\) contain \(X\). Since \(=(U_{a_{X}},S_{a_{X}}) T_{a_{X}}\) (this is just property (c) in Definition 2), \(X T_{a_{X}}\) must also be a function of \(S_{a_{X}}\) and \(U_{a_{X}}\) ; take \(f_{X}\) to be such a function. More precisely, for each \(u(U_{a_{X}})\) and \((S_{a_{X}})\) for which \((U_{a_{X}}\!=\!u,S_{a_{X}}\!=\!)>0\), there is a unique \(t(T_{a_{X}})\) such that \((u,,t)>0\). In this case, set \(f_{X}(u,,):=t[X]\). If \((U_{a_{X}}\!=\!u,S_{a_{X}}\!=\!)=0\), \(f_{X}(u,,)\) can be an arbitrary function of \(u\) and \(\). Let \(_{}()\) denote the set of PSEMs that can result.

It's clear from Construction 5 that \(_{}()\) is always nonempty, and is a singleton iff \((u,s)>0\) for all \((a,u,s)_{a}(U_{a},S_{a})\). A witness with this property exists when \(\) is positive (i.e., \((\!\!=\!\!)>0\) for all \(()\)), in which case the construction gives a unique causal model. Conversely, we have seen that an acylic model \(\) gives rise to a unique witness. So, in the simplest cases, models \(\) with structure \(\) and witnesses \(\) to compatibility with \(\) are equivalent. But there are two important caveats.

1. A causal model \(\) can contain more information than a witness \(\) if some events have probability zero. For instance, \(\) could be a point mass on a single joint outcome \(\) of all variables that satisfies the equations of \(\). But \(\) cannot be reconstructed uniquely from \(\) because there may be many causal models for which \(\) is a solution.

[MISSING_PAGE_FAIL:7]

with the qualitative PDG scoring fuction \(\), which we use to show that our information-theoretic constraints degrade gracefully on "near-compatible" distributions.

We now review the critical information theoretic concepts and their relationships to (in)dependence (see Appendix C.1 for a full primer). Conditional entropy \(_{}(Y|X)\) measures how far \(\) is from satisfying the functional dependency \(X Y\). Conditional mutual information \(_{}(Y;Z|X)\) measures how far \(\) is from satisfying the conditional independence \(Y\!\!\! Z X\). Linear combinations of these quantities (for \(X,Y,Z\)) can be viewed as the inner product between a coefficient vector \(\) and a \(2^{||}-1\) dimensional vector \(_{}\) that we will call the _information profile_ of \(\). For three variables, the components of this vector are illustrated in Figure 1 (right). It is not hard to see that an arbitrary conjunction of (conditional) (in)dependencies can be expressed as a constraint \(_{} 0\), for some appropriate choice of vector \(\).

We now formally introduce the qualitative PDG scoring function \(\), which interprets a hypergraph structure \(\) as a function of the form \(_{}_{}\). This _information deficiency_, given by

\[_{}()=_{}_{}:=-_{}()+_{a}_{}(T_{a } S_{a}),\] (2)

is the difference between the number of bits needed to (independently) specify the randomness in \(\) along the hyperarcs of \(\), and the number of bits needed to specify a sample of \(\) according to its own structure (\(\)). While \(\) has some nice properties4, it can also behave unintuitively in some cases; for instance, it can be negative. Clearly, it does not measure how close \(\) is to being structurally compatible with \(\), in general. Nevertheless, there is still a fundamental relationship between \(\) and QIM-compatibility, as we now show.

### A Necessary Condition for QIM-Compatibility

What constraints does QIM-compatibility with \(\) place on a distribution \(\)? When \(G\) is a dag, we have seen that if \(_{G}\), then \(\) must satisfy the independencies of the corresponding Bayesian network (Theorem 1); we have also seen that additional hyperarcs impose functional dependencies (Theorem 2). But these results apply only when \(\) is of a very special form. More generally, \(\) implies that \(\) can arise from some randomized causal model whose equations have dependency structure \(\) (Propositions 3 and 4). Still, unless \(\) has a particularly special form, it is not obvious whether or not this says something about \(\). The primary result of this section is an information-theoretic bound (Theorem 7) that generalizes most of the concrete consequences of QIM-compatibility we have seen so far (Theorems 1 and 2). The result is a connection between information theory and causality; it yields an information-theoretic test for complex causal dependency structures, and enables causal notions of structure to dispel misconceptions in information theory.

**Theorem 7**.: _If \(\), then \(_{}() 0\)._

Theorem 7 applies to all hypergraphs, and subsumes every general-purpose technique we know of for proving that \(\). Indeed, the negative directions of Theorems 1 and 2 are immediate consequences of it. To illustrate some of its subtler implications, we return to the 3-cycle in Example 4.

**Example 5**.: It is easy to see (e.g., by inspecting Figure 1) that \(_{3}()=_{}(Y|X)+_{}(Z|Y)+ _{}(X|Z)-_{}(XYZ)=-_{}(X;Y;Z)\). Theorem 7 therefore tells us that a distribution \(\) that is QIM-compatible with the 3-cycle cannot have negative interaction information \(_{}(X;Y;Z)\). What does this mean? When \((X;Y;Z)<0\), conditioning on one variable causes the other two to share more information than they did before. The most extreme instance is \(_{xor}\), the distribution in which two variables are independent and the third is their parity (illustrated on the right). It seems intuitively clear that \(_{xor}\) cannot arise from the 3-cycle, a causal model with only pairwise dependencies. This is difficult to prove directly, but is an immediate consequence of Theorem 7. \(\)

For many, there is an intuition that \((X;Y;Z)<0\) should require a fundamentally "3-way" interaction between the variables, and should not arise through pairwise interactions alone . This has

Figure 1: \(_{}\).

been a source of conflict , because traditional ways of making precise "pairwise interactions" (e.g., maximum entropy subject to pairwise marginal constraints and pairwise factorization) do not ensure that \((X;Y;Z) 0\). But QIM-compatibility does. One can verify by enumeration that the 3-cycle is the most expressive causal structure with no joint dependencies, and we have already proven that QIM-compatibility with that hypergraph implies non-negative interaction information. QIM-compatibility has another even more noteworthy clarifying effect on information theory.

There is a school of thought that contends that _all_ structural information in \(()\) is captured by its information profile \(_{}\). This position has fallen out of favor in some communities due to standard counterexamples: distributions that have intuitively different structures yet share an information profile . However, with "structure" explicated by compatibility, the prototypical counterexample of this kind suddenly supports the very notion it was meant to challenge, suggesting in an unexpected way that the information profile may yet capture the essence of probabilistic structure.

**Example 6**.: Let \(A,B\), and \(C\) be variables with \((A),(B),(C)=\{0,1\}^{2}\). Using independent fair coin flips \(X_{1}\), \(X_{2}\), and \(X_{3}\), define two joint distributions, \(P\) and \(Q\), over \(A,B,C\) as follows. Define \(P\) by selecting \(A:=(X_{1},X_{2})\), \(B:=(X_{2},X_{3})\), and \(C:=(X_{3},X_{1})\). Define \(Q\) by selecting \(A:=(X_{1},X_{2})\), \(B:=(X_{1},X_{3})\), and \(C:=(X_{1},X_{2} X_{3})\). Structurally, \(P\) and \(Q\) appear to be very different. According to \(P\), the first components of the three variables (\(A,B,C\)) are independent, yet they are identical according to \(Q\). Moreover, \(P\) has only simple pairwise interactions between the variables, while \(Q\) has \(_{xor}\) (a clear 3-way interaction) embedded within it. Yet \(P\) and \(Q\) have identical information profiles (see right): in both cases, each of \(\{A,B,C\}\) is determined by the values of the other two, each pair share one bit of information given the third, and \((A;B;C)=0\).

This example has been used to argue that multivariate Shannon information does not take into account important structural differences between distributions . We are now in a position to give a novel and particularly persuasive response, by appealing to QIM-compatibility. Unsurprisingly, \(P\) is compatible with the 3-cycle; it is clearly consists of "2-way" interactions, as each pair of variables shares a bit. But, counterintuitively, the distribution \(Q\) is _also_ compatible with the 3-cycle! (The reader is encouraged to verify that \(U_{1}=X_{3} X_{1}\), \(U_{2}=X_{2}\), and \(U_{3}=X_{3}\) serves as a witness.) To emphasize: this is despite the fact that \(Q\) is just \(_{xor}\) (which is certainly not compatible with the 3-cycle) together with a seemingly irrelevant random bit \(X_{1}\). By the results of Section 3, this means there is a causal model without joint dependence giving rise to \(Q\)--so, despite appearances, \(Q\) does not require a 3-way interaction. Indeed, \(P\) and \(Q\) are QIM-compatible with precisely the same hypergraphs over \(\{A,B,C\}\), suggesting that they don't have a structural difference after all. \(\)

In light of Example 6, one might reasonably conjecture that the converse of Theorem 7 holds. Unfortunately, it does not (see Appendix C.3); the quantity \(_{}()\) does not completely determine whether or not \(\). We now pursue a new (entropy-based) scoring function that does. This will allow us to generalize Theorem 7 to distributions that are only "near-compatible" with \(\).

### A Scoring Function for QIM-Compatibility

Here is a function that measures how far a distribution \(\) is from being QIM-compatible with \(\).

\[\!Inc_{}():=_{( ,\,)\\ ()=()}-_{}( )+_{a}_{}(U_{a})+_{a }_{}(T_{a}|S_{a},U_{a}).\] (3)

\(\!Inc\) is a direct translation of Definition 2 (a-c); it measures the (optimal) quality of an extended distribution \(\) as a witness. The infimum restricts the search to \(\) satisfying (a), the first two terms measure \(\)'s discrepancy of with (b), and the last term measures \(\)'s discrepancy with (c). Therefore:

**Proposition 8**.: \(\!Inc_{}() 0\)_, with equality iff \(\)._

Although they seem to be very different, \(\!Inc\) and \(\) turn out to be closely related. In fact, modulo the infimum, \(\!Inc_{}\) is a special case of \(\)--not for the hypergraph \(\), but rather for a transformed one \(^{}\) that models the noise variables explcitly. To construct \(^{}\) from \(\), add new nodes \(=\{U_{a}\}_{a}\), and replace each hyperarc

\[\). (Intuitively, this hyperarc creates functional dependencies in the spirit of Theorem 2.) With these definitions in place, we can state a theorem that bounds \(\!Inc\) above and below with information deficiencies (Theorem 9). The lower bound generalizes Theorem 7 by giving an upper limit on \(_{}()\) even for distributions \(\) that are not QIM-compatible with \(\). The upper bound is tight in general, and shows that \(\!Inc_{}\) can be equivalently defined as a minimization over \(_{^{}}\).

**Theorem 9**.:
1. _If_ \((,)\) _is a hypergraph,_ \(()\) _is a distribution, and_ \((,)\) _is an extension of_ \(\) _to additional variables_ \(=\{U_{a}\}_{a}\) _indexed by_ \(\)_, then:_ \[_{}()\!Inc_{}() _{^{}}().\]
2. _For all_ \(\) _and_ \(\)_, there is a choice of_ \(\) _that achieves the upper bound. That is,_ \[\!Inc_{}()=_{^{}}():&(,) \\ ()=()}.\]

The semantics of PDGs are based on the idea of measuring (and resolving) _inconsistency_, which is defined as a minimization over \(\) (plus a term that captures relevant concrete probabilistic information). Thus, Theorem 9 (b) tells us that QIM-compatibility (with \(\)) can be captured with a qualitative PDG (namely, \(^{}\)). It follows that our notion of QIM-compatibility can be viewed as a special case of the semantics of PDGs--one that, as we have shown, has a causal interpretation.

## 5 Discussion and Conclusions

We have shown how directed hypergraphs can be used to represent structural aspects of distributions. Moreover, they can do so in a way that generalizes conditional independencies and functional dependencies and has deep connections to causality and information theory. This notion of QIM-compatibility can be captured with PDGs, and also partially explains the qualitative foundations of these models. Still, many questions remain open.

Perhaps the most important open problem is that of computing whether or not a given distribution \(\) is QIM compatible with a directed hypergraph \(\). We have implemented a rudimentary approach (based on solving problem (3) to calculate \(\!Inc\)) that works in practice for small examples, but that approach scales poorly, and its correctness has not yet been proved. Even representing a distribution \(\) over \(n\) variables requires \((2^{n})\) space in general, and a candidate witness \(\) is even bigger: if all variables are binary, \(||=m\), and \(|S_{a}|,|T_{a}| k\) for all \(a\), then a direct implementation of (3) is a non-convex optimization problem with at most \(2^{n+mk(2^{k})}\) variables. Even accepting the (substantial) cost of representing extended distributions, we do not have a bound on the time needed to solve the optimization problem. There are more compact ways of representing the joint distributions \(\) used in practice (by assuming (in)dependencies), but we do not know if such independence assumptions make it easier to determine whether \(\) for arbitrary \(\). But computing \(_{}()\) can be much easier.5 We suspect that Theorem 7, a nontrivial condition for QIM-compatibility that requires only computing \(_{}()\), could play a critical role in designing such an inference procedure.

Another major open problem is that of more precisely understanding the implications of QIM-compatibility in cyclic models. We do not yet know, for example, whether the same set of distributions are QIM-compatible with the clockwise and counter-clockwise 3-cycles.

As mentioned in Section 3, our notion of QIM-compatibility has led us to a generalization of a standard causal model (Definition 4). A proper investigation of this novel modeling tool (which we have not attempted in this paper) would include concrete motivating examples, a careful account of interventions and counterfactuals in this general setting, and results situating these causal models among other generalizations of causal models in the literature.

We hope to address these questions in future work.