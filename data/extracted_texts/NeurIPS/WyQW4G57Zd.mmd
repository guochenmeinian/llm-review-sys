# Stochastic Optimal Control for Diffusion Bridges in Function Spaces

Byoungwoo Park\({}^{1}\), Jungwon Choi\({}^{1}\), Sungbin Lim\({}^{2,3}\); Juho Lee\({}^{1}\)

KAIST\({}^{1}\), Korea University\({}^{2}\), LG AI Research\({}^{3}\)

{bw.park, jungwon.choi, juholee}@kaist.ac.kr,

sungbin@korea.ac.kr

Equal advising.

###### Abstract

Recent advancements in diffusion models and diffusion bridges primarily focus on finite-dimensional spaces, yet many real-world problems necessitate operations in infinite-dimensional function spaces for more natural and interpretable formulations. In this paper, we present a theory of stochastic optimal control (SOC) tailored to infinite-dimensional spaces, aiming to extend diffusion-based algorithms to function spaces. Specifically, we demonstrate how Doob's \(h\)-transform, the fundamental tool for constructing diffusion bridges, can be derived from the SOC perspective and expanded to infinite dimensions. This expansion presents a challenge, as infinite-dimensional spaces typically lack closed-form densities. Leveraging our theory, we establish that solving the optimal control problem with a specific objective function choice is equivalent to learning diffusion-based generative models. We propose two applications: 1) learning bridges between two infinite-dimensional distributions and 2) generative models for sampling from an infinite-dimensional distribution. Our approach proves effective for diverse problems involving continuous function space representations, such as resolution-free images, time-series data, and probability density functions. Code is available at https://github.com/bw-park/DBFS.

## 1 Introduction

Stochastic Optimal Control (SOC) is designed to steer a noisy system toward a desired state by minimizing a specific cost function. This methodology finds extensive applications across various fields in science and engineering, including rate event simulation , stochastic filtering and data assimilation , non-convex optimization , modeling population dynamics . SOC is also related to diffusion-based sampling methods that are predominant in machine learning literature. Specifically, if we choose the terminal cost of a control problem as the log density ratio between a target distribution and a simple prior distribution, solving the optimal control reduces to learning a diffusion-based generative models  built upon the Schrodinger bridge problem .

While SOC associated diffusion-based generative models have been well-established for finite-dimensional spaces , their theoretical foundations and practical algorithms for infinite-dimensional spaces remain underexplored. There is a growing interest in developing generative models in function spaces. Examples include learning neural operators for partial differential equations (PDEs) , interpreting images as discretized functions through implicit neural representations (INRs) , and operating in function spaces for Bayesian neural networks (BNNs) . Models that operate in function spaces are more parameter-efficient as they avoid resolution-specific parameterizations. In response to this demand, several extensions ofdiffusion-based generative models for infinite-dimensional function spaces have been proposed [3; 25; 32; 41; 42; 53]. However, SOC theory for building diffusion bridges in function spaces is still demanding in the community of generative modeling.

To address these challenges, this work introduces an extension of SOC for diffusion bridges in infinite-dimensional Hilbert spaces, particularly focusing on its applications in sampling problems. Specifically, we demonstrate the idea of Doob's \(h\)-transform [13; 59] can be derived from SOC theory and extend its formulation into Hilbert spaces. Due to the absence of a density with respect to the Lebesgue measure in infinite-dimensional spaces, building a diffusion bridge between function spaces is a nontrivial task separated from the finite-dimensional cases [51; 61]. To this end, we propose a Radon-Nikodym derivative relative to a specified Gaussian reference measure in Hilbert space. Leveraging the infinite-dimensional Doob's \(h\)-transform and SOC, we then formulate diffusion bridge-based sampling algorithms in function spaces. While the infinite-dimensional Doob's \(h\)-transform has already been derived in [2; 26; 31], our main goal is not merely to derive it. Instead, we aim to generalize various finite-dimensional sampling problems [51; 61; 73; 77] into the infinite-dimensional space by exploiting the theory of infinite-dimensional SOC.

To demonstrate the applicability of our theory, we present learning algorithms for two representative problems. First, we introduce an infinite-dimensional bridge-matching algorithm as an extension of previous methods [51; 61] into Hilbert spaces, which learns a generative model to bridge two distributions defined in function spaces. As an example, we show that our framework can learn smooth transitions between two image distributions in a resolution-free manner. Second, we propose a simulation-based Bayesian inference algorithm [73; 77] that operates in function space. Instead of directly approximating the target Bayesian posterior, our algorithm learns a stochastic transition from the prior to the posterior within the function space. We demonstrate the utility of this approach by inferring Bayesian posteriors of stochastic processes, such as Gaussian processes. We summarize our contributions as follows:

* Based on the SOC theory, we derive the Doob's \(h\)-transform in Hilbert spaces. We propose a \(h\) function as a Random-Nikodym derivative with respect to a Gaussian measure in infinite-dimensional space.
* Based on the infinite-dimensional extension of the Doob's \(h\)-transform, we present the diffusion bridge and simulation-based Bayesian inference algorithm in function spaces.
* We demonstrate our method for various real-world problems involving function spaces, including resolution-free image translation and posterior sampling for stochastic processes.

Notation.Consider a real and separable Hilbert space \(\) with the norm and inner product denoted by \(\|\|_{}\) and \(,_{}\). Throughout the paper, we consider a path measure denoted by \(^{()}\) on the space of all continuous mappings \(=C([0,T],)\). The stochastic processes associated with this path measure \(^{()}\) are denoted by \(^{()}\), and their time-marginal distribution at time \(t[0,T]\) as push-forward measure \(_{t}^{()}:=(_{t}^{()})_{\#}^{()}\). Furthermore, for a function \(:[0,T]\), we define \(D_{},D_{}\) as the first and second order Frechet derivatives with respect to the variable \(\), respectively, and \(_{t}\) as the derivative with respect to the time variable \(t[0,T]\).

## 2 A Foundation on Stochastic Optimal Control for Diffusion Bridges

In this section, we first present a brief introduction to the theory of stochastic optimal control (SOC) in infinite dimensions and the Verification Theorem (Lemma 2.1), which is the key to understanding the theoretical connection between SOC and the diffusion bridges. Then we propose Doob's \(h\)-transform in Hilbert spaces based on the SOC theory (Theorems 2.2 and 2.3).

### Preliminaries

Gaussian Measure and Cameron-Martin Space.Let \((,,)\) and \((,())\) be two measurable spaces and consider \(\)-valued random variable \(:\) such that the push-forward measure \(:=_{\#}\) induced by \(\) is Gaussian, i.e., a real-valued random variable \( u,_{}\) follows Gaussian distribution on \(\) for any \(u\). Then, there exist a unique mean \(m_{}\) given by \( m_{},u_{}=_{}[ ,u_{}]\) and a nonnegative, symmetric, and self-adjoint covariance operator \(Q:\) defined by \( u,Qv_{}=_{}[-m_ {},u_{},-m_{},v _{}]\) for any \(u,v\).

We write \(=(m_{},Q)\) and say \(\) is centered if \(m_{}=0\). For a covariance operator \(Q\), we assume \(\)-valued centered \(\) follows the distribution \((0,Q)\) supported on \(\) so that \(Q\) is guaranteed to be compact. Hence, there exists an eigen-system \(\{(^{(k)},^{(k)}):k\}\) such that \(Q(^{(k)})=^{(k)}^{(k)}\) holds and \((Q)=_{k=1}^{}^{(k)}<\). We define the _Cameron-Martin space_ by \(_{0}:=Q^{1/2}()\), \(_{0}\) is a separable Hilbert space endowed with the inner product \( u,v_{_{0}}:= Q^{-1/2}u,Q^{-1/2}v_{ }\).

Stochastic Differential Equations in Hilbert Spaces.The standard \(^{d}\)-valued Wiener process has independent increments \(w_{t+_{t}}-w_{t}(0,_{t}_{d})\). In the case of infinite-dimensional Hilbert space \(_{0}\), however, such identity covariance may not be a trace class. We consider a larger space \(_{0}_{1}\) such that \(_{0}\) is embedded into \(_{1}\) with a Hilbert-Schmidt embedding \(J:_{0}_{1}\). Let \(Q:=JJ^{*}\) and we define \(_{1}\)-valued \(Q\)-Wiener process [17, Proposition 4.7] as \(_{t}^{Q}=_{k=1}^{}Q^{1/2}^{(k)}w_{t}^{(k)}\). We focus on the Cameron-Martin space \(_{0}\) where the Wiener process has increments \((0,_{t}_{t})\), and a larger space \(_{1}=\), where the Wiener process has increments \((0,_{t}Q)\). Then we define a path measure \(\) and associated stochastic differential equation (SDE) in \(\) as follows

\[d_{t}=_{t}+ d_{t}^{Q}, _{0}, t[0,T],\] (1)

where \(:\) is a linear operator, a constant \(>0\) and a \(Q\)-Wiener process \(^{Q}\) defined on a probability space \((,,(_{t})_{t 0},)\). For a more comprehensive understanding, see .

### Stochastic Optimal Control in Hilbert Spaces

From the _uncontrolled_ SDE introduced in equation (1), various sampling problems in \(^{d}\) including density sampling  and generative modeling  can be solved by adjusting the SDE with proper drift (control) function \(^{d}\). Motivated by these approaches, introducing stochastic optimal control (SOC) to solve real-world sampling problems, we aim to introduce SOC to the infinite-dimensional Hilbert space \(\). We consider that a controlled path measures \(^{}\) is induced by following infinite-dimensional SDE defined as follows:

\[d_{t}^{}=[_{t}^{}+ Q^{1 /2}_{t}]dt+ d}_{t}^{Q},_{0}^ {}=_{0}, t[0,T]\] (2)

where \(_{()}:[0,T]\) is infinite-dimensional Markov control (see Section A.1.2 for more details). We refer to the SDE in equation (2) as _controlled_ SDE. The controlled SDE can be exploited to the various problems. In general, it can be done by finding the optimal control function that minimizes the objective functional with suitably chosen cost functionals depending on the problem:

\[(t,_{t},)=_{^{}}[ _{t}^{T}[R(_{s})]ds+G(_{T}^{}) _{t}^{}=_{t}],\] (3)

where \(R:\) are running cost and \(G:\) is terminal cost. The measurable function \((t,,)\), representing the total cost incurred by the control \(\) over the interval \([t,T]\), given that the control strategy from the interval \([0,t]\) has resulted in \(_{t}^{}=\). The objective is to minimize the objective functional in (3) over all admissible control policies \(\), where \(\) is the Hilbert space of all square-integrable \(\)-valued processes adapted to \(^{Q}\) defined on \([0,T]\). Then we define the _value function_\((t,)=_{}(t,,)\), the optimal costs conditioned on \((t,)[0,T]\). By using the dynamic programming , we can solve the Hamilton-Jacobi-Bellman (HJB) equation,

\[_{t}_{t}+_{t}+_{}[, Q^{1/2}D_{}_{t}+R ]=0,(T,)=G(),\] (4)

where \(_{t}:=_{t}^{},D_{ }_{t}_{}+[ ^{2}QD_{}_{t}]\). We demonstrate that with specific choices of cost functionals \(R\) and \(G\) in (3), the optimal control \(^{*}\) of the minimization problem aligns with the proper drift function for sampling problems we will discuss later. To do so, we start with how the HJB equation can characterize the optimal controls.

**Lemma 2.1** (Verification Theorem).: _Let \(\) be a solution of HJB equation (4) with \(R():=\|\|_{}^{2}\) satisfying the assumptions in A.1. Then, we have \((t,)(t,x,)\) for every \(\) and \((t,)[0,T]\). Let \((^{*},^{^{*}})\) be an admissible pair such that_

\[_{s}^{*}=*{arg\,inf}_{}[ _{s}, Q^{1/2}D_{}_{t}+ \|_{s}\|_{}^{2}]=- Q^{1/2}D_{} (s,_{s}^{^{*}})\] (5)

_for almost every \(s[t,T]\) and \(\)-almost surely. Then \((^{*},^{^{*}})\) satisfying \((t,)=(t,,^{*})\)._Lemma 2.1 demonstrate that with specific choices of running costs, the solution to the HJB equation in (4) is the optimal cost of the minimization problem in (3) with the closed-form optimal control \(_{t}^{*}=- Q^{1/2}D_{t}\). In the subsequent subsection, we reveal the connection between the optimal controlled process, characterized by the controlled SDE with optimal control \(^{*}\), and the conditioned SDE in \(\). Additionally, we show various problems depending on the choice of the terminal cost \(G\).

### Doob's \(h\)-transform for Diffusion Bridges in Hilbert Spaces

The _conditioned_ SDE is a stochastic process that is guaranteed to satisfy a set constraint defined over the interval \([0,T]\). For instance, a _Diffusion Bridge_ is a stochastic process that satisfies both terminal constraints \(_{0}=_{0}\), \(_{T}=_{T}\) for any \(_{0},_{T}\). We will show that with a proper choice of the terminal cost \(G\), the conditioned SDE is a special case of controlled SDE. For this, let us define the function \(h:[0,T]\):

\[h(t,)=_{}()_{e^{(T-t) }A_{},Q_{T-t}}(d)=_{}[ (_{T})|_{t}=],\] (6)

where \(_{e^{t}A_{},Q_{t}}\) is a Gaussian measure with mean function \(e^{tA}\) and covariance operator \(Q_{t}=_{0}^{t}e^{(t-s)A}Qe^{(t-s)A}ds\) and \(:=e^{-G}\) for the function \(G\) in (3). The function \(h\) evaluates the future states \(_{T}\) using \(\) which propagated by (1) for a given initial \(\) at time \(t[0,T]\). It can be shown that the function \(h\) satisfies the Kolmogorov-backward equation  with terminal condition,

\[_{t}h_{t}+h_{t}=0, h(T,)=( ).\] (7)

Now, we employ the Hopf-Cole transformation  to establish an inherent connection between two classes of PDEs, the linear PDE in (7) and the HJB equation in (4), which provide us a key insight to deriving the Doob's \(h\)-transform in function spaces utilizing the SOC theory.

**Theorem 2.2** (Hopf-Cole Transform).: _Let \(_{t}=- h_{t}\). Then \(_{t}\) satisfies the HJB equation:_

\[_{t}_{t}+_{t}-\|  Q^{1/2}D_{}_{t}\|_{}^{2}=0, (T,)=G().\] (8)

According to Theorem 2.2, the solution of linear PDE in equation (7) is negative exponential to the solution of the HJB equation in (8). Given that it already verified that the optimal control \(^{*}\) results the value function \(_{t}\), which has explicit form as described in (8), we find that the relationship of two PDEs through \(_{t}=- h_{t}\) leads to a distinct form of optimal control \(^{*}=- Q^{1/2}D_{}= Q^{1/2}D_{} h\), where \(D_{} h:=D_{}h/h\). Consequently, it yields another class of SDE as follows:

\[d_{t}^{h}=[_{t}^{h}dt+^{2}QD_{ } h(t,_{t}^{h})]dt+ d}_{t }^{Q},_{0}^{h}=_{0},\] (9)

where \(}_{t}^{Q}\) is a \(Q\)-Wiener process on \(^{h}\). This representation is consistent with infinite-dimensional conditional SDE  which induces an expansion of Doob's \(h\)-transform  in Hilbert space \(\).

The Doob's \(h\)-transform in finite-dimensional spaces is well-established to construct the diffusion bridge process under the assumption that \(h(t,)=(_{T} d_{T}|_{t}= )\) has an explicit Radon-Nikodym density function , enable to simulate the bridge SDEs. In contrast, although the choice of \(()=_{d_{T}}(_{T})\) in (6) yields same representation of \(h(t,)=(_{T} d_{T}|_{t}= )\), we cannot easily define the Radon-Nikodym density in \(\) due to the absence of an equivalent form of Lesbesgue measure which hinder the computation of \(D_{} h(t,_{t}^{h})\) in (9) explicitly. Hence, to define the diffusion bridge process in \(\), we need to identify an explicit density form of \(h(t,)=(_{T} d_{T}|_{t} =)\). The following theorem reveals the explicit form of \(h\) function and becomes a key ingredient in deriving infinite dimensional diffusion bridge processes.

**Theorem 2.3** (Explicit Representation of \(h\)).: _For any \(t>0\) and any \(\), the measure \(_{e^{t}A_{},Q_{t}}\) and \(_{0,Q_{}}\) are equivalent, where \(_{0,Q_{}}\) is an invariant measure of \(\) in (1) as \(t\) where \(Q_{}=-Q^{-1}\). Moreover, for any \(,\), the Radon-Nikodym density \(_{e^{t}A_{},Q_{t}}}{d_{0,Q_{}}}( )=q_{t}(,)\) is given by_

\[q_{t}(,) =(1-_{t})^{-1/2}-(1 -_{t})^{-1}Q_{}^{-1/2}e^{tA},Q_{}^{-1/2}e^{tA} _{}\] (10) \[+(1-_{t})^{-1}e^{tA}Q_{}^{-1/2},Q_{ }^{-1/2}_{}-_{t}(1- _{t})^{-1}Q_{}^{-1/2},Q_{}^{-1/2} _{},\] (11)

_where \(_{t}=Q_{}^{1/2}(Q_{t}^{-1/2}e^{tA})^{*}(Q_{}^{-1/2}Q_{t}^{1/2} )^{*}(Q_{}^{1/2}(Q_{t}^{-1/2}e^{tA})^{*}(Q_{}^{-1/2}Q_{t}^{1/2})^{*})\), \(t 0\)._Theorem 2.3 states that the marginal distribution of certain classes of SDEs described in (1) has an explicit Radon-Nikodym density with respect to their invariant measure. Therefore, by the time-homogeneity of the process in (1), it allows us to define the \(h\) function explicitly:

\[h(t,)=_{}()_{e^{(T-t)A_{ },Q_{T-t}}}(d)=_{}()q_{T -t}(,)_{0,Q_{}}(d).\] (12)

This framework enables the construction of an infinite-dimensional bridge process, by selecting \(\) in (12) properly. Below, we demonstrate the infinite-dimensional diffusion bridge.

**Example 2.4** (Diffusion Bridge in \(\)).: _Let \(\{(^{(k)},^{(k)}):k\}\) be an eigen-system of \(\). Then for each \(k\), the SDE system in equation (1) can be represented as:_

\[d_{t}^{(k)}=-a_{k}_{t}^{(k)}dt+} d_{t}^{(k)},^{(k)}(0)=_{0}^{(k)},\] (13)

_where \(^{(k)}=-a_{k}^{(k)}\), \(Q^{(k)}=^{(k)}^{(k)}\), \(_{t}^{(k)}=_{t},^{(k)}_{}\) and \(_{t}^{(k)}=_{t},^{(k)}_{}\). Then, for any \(_{T}\), the conditional law of \(_{T}^{(k)}\) given \(_{t}^{(k)}\) is a Gaussian \((_{T|t}^{(k)}_{t}^{(k)},_{T|t}^ {(k)})\) with_

\[_{T|t}^{(k)}=e^{-a_{k}(T-t)},_{T|t}^{(k)}= ^{2}}{2a_{k}}(1-e^{-2a_{k}(T-t)}).\] (14)

_Now, by setting the terminal condition in (6) as \(():=_{_{T}}()\) (i.e., Dirac delta of \(_{T}\)) then \(h(t,)=q_{T-t}(,_{T})\). Thus, for each coordinate \(k\), we get following representation:_

\[d_{t}^{(k)}=[-a_{k}_{t}^{(k)}+e^{-a_{k}( T-t)}}{1-e^{-2a_{k}(T-t)}}(_{T}^{(k)}-e^{-a_{k}(T-t)}_{t}^{(k)} )]dt+}d_{t}^{(k)},\] (15)

_with two end points conditions \(_{0}^{(k)}=_{0}^{(k)}\) and \(_{T}^{(k)}=_{T}^{(k)}\)._

### Approximating path measures

Since the function \(h\) is intractable for a general terminal cost \(\) in (12), simulating the conditioned SDEs in (9) requires some approximation techniques. As observed in Theorem 2.2, finding the function \(h\) is equal to learning the control function \(\) such that \(^{}\) is equal to \(^{}:=^{^{}}=^{h}\). Therefore, with a parametrization \(:=(,)\) the approximation can be done by neural network parameterization \(,^{}^{^{}}\) with local minimum \(^{}=_{}D(^{}||^{})\), where\(D(^{}||^{})\) is a divergence between \(^{}\) and \(^{}\). For example, the cost functional described in equation (3) can be represented as relative-entropy loss \(D_{}(^{}||^{})=_{ ^{}}[^{}}{d^{}}]^ {2}\). Therefore, the training loss for \(\) can be estimated by first simulating the parameterized control path and then calculating (3) for a specified cost functional \(R,G\). Moreover, if we can access to the \(^{}\), one can define the variational optimization  where the loss is defined as cross-entropy loss \(D_{}(^{}||^{})=_{ ^{}}[^{}}{d^{}}]\). See [20; 48] for more details about the approximation technique and other loss functions.

## 3 Simulating Diffusion Bridges in Infinite Dimensional Spaces

Leveraging the SOC theory within \(\), we show how our approach generalizes existing diffusion-based sampling methods. Specifically, incorporating the relation between _controlled_ SDEs (2) and _conditioned_ SDEs (9), we introduce two learning algorithms that allow us to simulate various diffusion bridge-based sampling algorithms.

### Infinite Dimensional Bridge Matching

In this section, our objective is to learn a control \(\) that yields \(^{}\) such that \(\{_{t}^{}\}_{t[0,T]}\) satisfies \(_{t}^{}_{t}^{}\) for all pre-specified \(_{t}^{}\) over the interval \(t[0,T]\). Specifically, we assume that the end-point marginals \(_{0}^{}\) and \(_{T}^{}\) follow the laws of two data distributions \(_{0}\) and \(_{T}\), respectively, and the intermediate marginals \(\{_{t}^{}\}_{t(0,T)}\) are defined as a mixture of diffusion bridge paths. Thislearning problem is referred to as the _Bridge Matching_ (BM) algorithm  and can be expressed as a solution of the SOC problem structured as

\[_{}D(^{}|^{}),d_{t}^{}=[d _{t}^{}+ Q^{1/2}_{t}]dt+ d}_{t}^{Q},_{0}^{}_{0}.\] (16)

In (16), various divergences can be chosen for the same learning problem, as discussed in Section 2.4. Here, we will choose the cross-entropy because the relative entropy requires the appropriate selection of the terminal cost \(G\) in (3), which is intractable since we do not have access to the distributional form of \(_{0},_{T}\). Furthermore, keeping the entire computational graph of \(^{}\) with parameterized \(\) can become resource-intensive, especially for higher-dimensional datasets like images .

Now, we specify the optimal path measure \(^{}\) for a problem in (16). Let \(_{|0,T}\) be a path measure induced by (15) and \(_{t|0,T}\) be a marginal distribution of \(_{|0,T}\). Moreover, let \(^{}=_{|0,T}_{0,T}\) for an independent coupling \(_{0,T}=_{0}_{T}\). Then the optimal path measure \(^{}\) is defined as _Mixture of bridge_. Under regular assumptions, the optimal control \(^{}\) that induces the optimal path measure \(^{}\) can be constructed as a mixture of functions \(h\) in (9) by choosing \(G()=_{_{T}}()\).

**Theorem 3.1** (Mixture of Bridges in \(\)).: _Let us consider a marginal distribution of \(^{}\) at \(t[0,T]\), \(_{t}^{}(d_{t})=_{t|0,T}(d_{t})_{0,T}(d _{0},d_{T})\) has density \(p_{t}^{}\) with respect to some Gaussian reference measure \(_{}\,i.e.,_{t}^{}(d_{t})/_{}(d _{t})=p_{t}^{}(_{t})\). Then the optimal path measure \(^{}\) associated with:_

\[d_{t}^{}=[_{t}^{}+_{ _{T}^{}(d_{T}|_{t}^{})} [^{2}QD_{}(_{T};_{T|t} _{t}^{},_{T|t})]]dt+ d }_{t}^{Q},\] (17)

_where \(_{T|t}=e^{(T-t)}\) and \(_{T|t}=^{2}_{0}^{T-t}e^{(T-t-s)}Qe^{(T -t-s)}ds\) and \(_{t}^{}_{t}\) for \(t[0,T]\)._

Objective Functional for Bridge Matching.With the structure of \(^{}\) specified in (17) we can estimate the divergence between the optimal target path measure \(^{}\) and a path measure \(^{}\). To accomplish this, we first define

\[(t,;)=Q^{1/2}[_{_{T} ^{}(d_{T}|)}[ Q^{1/2}D_{ }(_{T};_{T|t}_{t}^{ },_{T|t})]-(t,;)].\] (18)

Then, by applying the Girsanov theorem3 which provides us the Radon-Nikodym derivative between \(^{}\) and \(^{}\), we can derive the cross-entropy loss in equation (16):

\[D_{}(^{^{}}|^{})=_ {^{}}[^{}}{d^{^{ }}}]=_{^{}}[_{0}^{T} \|(t,_{t}^{};)\|_{_{0}}^{2} ds]\] (19)

Then, under the neural network parameterization of control function \(^{}\), we can reformulate the SOC problem in (16) as a learning problem with the training loss function represented by:

\[_{}()=_{t_{0,T}} _{^{}(_{T} d_{T}|_{t}^{ })}[\| Q^{1/2}D_{}( _{T};_{T|t}_{t}^{},_{T|t })-(t,_{t}^{};)\|_{}^{2}]\] (20)

The \(_{}()\) in (20) yields the infinite-dimensional BM summarized in Alg 1.

``` Input: Initial condition \(_{0}\), energy functional \(\) for\(n=1,,N\)do  Simulate \(_{0,T}^{^{}}^{^{}}\) with \(_{0}^{^{}}=_{0}\)  Compute \(_{}(_{k})\) with (24)  Update \(_{n+1}\) with \(_{_{n}}_{}(_{n})\) endfor Output: Approximated optimal control \(^{^{}}\) ```

**Algorithm 2** Bayesian Learning in \(\)

### Bayesian Learning in Function Space

In the previous section, we observed that by appropriately defining a terminal cost functional \(G\) in (3), the SOC problem aligns with the sampling problem, where optimal control effectively steersthe distribution from \(_{0}\) to the target distribution \(_{T}\), where we can access samples from \(_{0}\) and \(_{T}\). However, accessing samples from unknown target distribution \(_{T}\) is generally not feasible. For instance, for a \(_{T}\), a posterior distribution over function. In this case, although direct samples from \(_{T}\) are unattainable, its distributional representation is given as [3; 66]:

\[}{d_{}}(_{T})(-(_{T})),_{}=(_{ },Q_{}),\] (21)

where \(\) is a energy function. Here, our primary objective is to sample from a distribution over function \(_{T}:=_{T}^{}\) by simulating the controlled diffusion process \(\{_{t}^{}\}_{t[0,T]}\) over finite horizon \([0,T]\) with \(T<\). It can be represented as a solution of the following SOC problem:

\[_{}D(^{}|^{}),d_{t}^{}=[_{t}^{}+ Q^{1/2} _{t}]dt+ d}_{t}^{Q},_{0}^{ }=_{0}.\] (22)

The following theorem implies that with a suitable terminal cost functional \(G\) in (3), it is possible to achieve \(_{T}^{^{*}}_{T}\) as an expansion of [54; 71] for infinite dimensional space \(\).

**Theorem 3.2** (Exact sampling in \(\)).: _Consider that the initial distribution \(_{0}\) is given as the Dirac measure \(_{_{0}}\) for some \(_{0}\) and the following objective functional_

\[()=_{^{}}[_{0}^{T}\|_{s}\|_{}^{2}ds-}{d_{T} }(_{T}^{})]\] (23)

_where \(_{T}=(e^{T}_{0},Q_{T})\) as a marginal distribution of \(_{T}\) in (1) with a well-defined terminal cost \(}{d_{T}}\) by Theorem 2.3. Then, \(_{T}^{^{*}}_{T}\)._

Objective Functional for Bayesian Learning.Unlike problem in (16) where we can access to the target path measure \(^{*}\) directly, it is not feasible here because \(h(t,)=_{}[-}{d_{T}}( _{T})|_{t}=]\) does not have an explicit solution. Therefore, we will use the relative-entropy loss as our training loss function:

\[_{}()=D_{}(^{^{}} |^{*})=_{^{^{}}}[_{0}^{T} \|(s,_{s}^{^{}};)\|_{ }^{2}ds-}{d_{T}}(_{T}^{^{ }})].\] (24)

The key difference from previous algorithms [73; 77] is that the Radon-Nikodym derivative \(}{d_{T}}(_{T}^{})\) may not be well-defined on \(\) due to the absence of the Lesbesgue measure. However, the Theorem 2.3 suggests that by choosing certain classes of Gaussian measure \(i.e.,_{}:=(e^{t},Q_{t})\), the Radon-Nikodym density of \(}{d_{}}\) and \(}{d_{}}\) has explicit form since \(_{}\) and \((0,Q_{})\) are equivalent. Thus, using the chain rule, the terminal cost for any \(\) can be computed as follows:

\[}{d_{T}}()=-()-}}{d(0,Q_{})}()+}{d (0,Q_{})}().\] (25)

With \(_{}()\) in (24), the infinite-dimensional bayesian learning algorithm is summarized in Alg 2.

## 4 Related Work

Most diffusion models operate within the framework of time-reversal , where the generation process is learned from its corresponding time-reversed SDEs . In contrast, diffusion models based on conditioned SDEs, such as diffusion bridges, built upon the theory of Doob's \(h\)-transform, offer a conceptually simpler approach as they solely rely on a forward process.  proposes generative models with this concept, showing that the mixture of forward diffusion bridge processes effectively transports between couplings of two distributions.  introduces a family of first hitting diffusion models that generate data with a forward diffusion process at a random first hitting time based on Doob's \(h\)-transform. Combining time-reversal with the \(h\)-transform,  proposes a diffusion bridge process on constrained domains. Moreover, [51; 61] presented that the Schrodinger bridge problem can be solved by an iterative algorithm, which is improved by  to enhance efficiency. Furthermore,  generalizes the Schrodinger bridge matching algorithm by introducing an approximation scheme with a non-trivial running cost. Compared to prior works, which primarily focus on finite-dimensional spaces, our work extends the formulation of Doob's \(h\)-transform into Hilbert space, enabling the development of various sampling algorithms in function spaces.

Experiments

This section details the experimental setup and the application of the proposed Diffusion Bridges in Function Spaces (**DBFS**) for generating functional data. We interpret the data from a functional perspective, known as _field_ representation [75; 79], where data are seen as a finite collection of function evaluations \(\{[_{i}],_{i}\}_{i}^{N}\). Here, a function \(\) maps points \(_{i}\) from a coordinate space \(\) to a signal space \(\), i.e., \(:\). Additional experimental details are provided in Appendix A.8.

### Bridge Matching

First, we present empirical results for the infinite-dimensional BM algorithm discussed in Sec 3.1, applied to 1D and 2D data. For 1D data, we consider \(=\) and \(=\). For 2D data, we assume \(=^{2}\) and \(=\) for probability density or grayscale images, and \(=^{3}\) for RGB images.

**Bridging Field.** We begin by validating our bridge matching Algorithm in Alg 1 on bridging probability density function within \(\). Specifically, we set \(_{0}:=_{p_{0}}\) with a ring-shaped density function \(p_{0}\) and \(_{T}:=_{p_{T}}\) characterized by a Gaussian mixture density function \(p_{T}\). The functions map each grid points \(_{i}\) to the probability in \(=\). Therefore, both density functions can be represented as their field representations \(\{p_{0}[_{i}],_{i}\}_{i}^{N},\{p_{T}[_{i}], _{i}\}_{i}^{N}\), respectively. Figure 1 illustrates the progressive propagation of the target optimal bridge process \(^{}\) from \(p_{0}\) to \(p_{T}\). Despite the \(^{}\) is trained on the functions generated from \(^{}\) which are evaluated on a coarse grid \(\{_{i}\}_{i}^{32^{2}}\), \(^{^{}}\) is capable of producing accurate functional evaluations on a finer grid \(\{_{i}\}_{i}^{256^{2}}\). This resolution-invariance property indicates that our method is adept at learning continuous functional representations, rather than merely memorizing the discrete evaluations.

**1D function generation.** We conducted an experiment on a 1D function generation task, comparing our baseline methods [22; 52] on three datasets: Quadratic, Melbourne, and Gridwatch, following the setup from . For generative modeling, we set the initial distribution \(_{0}\) as \((0,Q)\) with RBF kernel for the covariance operator \(Q\) and the terminal distribution as data distribution \(_{T}\), respectively. We employing the bridge matching algorithm in Alg 1. For quantitative evaluation, we used the power of a kernel two-sample hypothesis test to distinguish between generated and ground-truth samples. Table 1 shows that our method performs comparably to baseline infinite-dimensional methods. Additionaly, The generated samples compared to the ground-truth for each dataset are provided in Figure 2.

**Unpaired Image Transfer.** We compare our proposed model with a finite (fixed)-dimensional baseline through an experiment on unpaired image transfer between the MNIST and EMNIST datasets at \(32^{2}\) resolution, as well as wild and cat images from the AFHQ dataset , downsampled to \(64^{2}\) resolution (AFHQ-64). Specifically, we evaluate the performance of [51; 61] and our DBFS model. For a fair comparison, we follow the iterative training scheme of  based on

   & **NDP** & **SP-SGM** & **DBFS** (Ours) \\  Quadratic & \(\) 99.0 & 5.4 \(\) 0.7 & **5.1 \(\) 0.4** \\ Melbourne & 12.8 \(\) 0.4 & **5.3 \(\) 0.7** & 9.67 \(\) 0.45 \\ Gridwatch & 16.3 \(\) 1.8 & 4.7 \(\) 0.5 & **3.9 \(\) 0.4** \\  

Table 1: A Power\((\%)\) of a kernel two-sample test.

Figure 2: Results on 1D function generation. (Left) Real data and (Right) generated samples from our model.

the public repository4, where two forward and backward control networks are trained alternately. For quantitative evaluation, we estimate the FID score between the generated samples and real datasets. We set \(=1\) for both  and our method, while FID scores for  are taken from . Table 2 shows that our method performs comparably to the finite-dimensional method. Additionally, we provide generated samples at various unseen resolutions in Figure 3 to demonstrate the resolution-invariant property of our infinite-dimensional models. We note that our method may have slightly lower FID scores compared to finite-dimensional baselines, which may align with the observation in  that resolution-agnostic methods tend to have lower FID scores compared to resolution-specific ones. This could be because resolution-specific methods can incorporate domain-specific design features in their score networks. Samples generated from the reverse direction can be found in Figure A.2.

### Bayesian Learning

We validate our Bayesian learning algorithm for modeling functional data. Specifically, we will consider the temporal data as a function. We denote \([]=\{[_{i}]\}_{i=1}^{||}\) as a collection of a function evaluation on a set of 1-dimensional observation grid \(=\{_{i}\}_{i}^{||}\) where \(0_{0}<<_{||} I\). We assume that each observed time series approximates a corresponding underlying continuous function \(:^{d}\) as the number of observations increases \(,\{[_{i}]\}_{i=1}^{||} \). For given observations \([]\), our goal is to infer the posterior distribution on some set of unobserved grid \(=[0,I]-\)\(,([]|[])\) and therefore modeling distribution over \(\) on \([0,I]\). Please refer to Section A.8.2 for further details.

Functional RegressionTo verify the effectiveness of the proposed DBFS in generating functions in the 1D domain, we conducted regression experiments using synthetic data generated from the Gaussian Process (GP) by following the experimental settings in . Figure 4 shows the sampled trajectories of a controlled dynamics \(_{t}^{}\) for \(t[0,,T]\) trained on data generated from GP with RBF covariance kernel. The stochastic process begins from the deterministic function \(_{0}^{}=_{0}\) at \(t=0\) and propagates towards the conditional posterior distribution \(_{T}^{}([]|[ ])\) at \(t=T\).

  Method & **(A)** & **(B)** \\  IDBM  & 8.2 & - \\ DSDM\({}^{}\) & **6.0** & **25.4** \\ 
**DBFS** (Ours) & 9.1 & 44.4 \\   \(\) result from .

Table 2: Test FID on unpaired image transfer task. **(A)** EMNIST \(\) MNIST, **(B)** AFHQ-64 Wild \(\) Cat. (Left) Real data and (Right) generated samples from our model. For generation at unseen resolutions, the images within the red and blue boxed initial conditions were upsampled (using bi-linear transformation) from the observed resolution (\(32^{2}\)) for EMNIST and (\(64^{2}\)) for AFHQ-64 Wild, respectively.

Figure 3: Results on Unpaired image transfer task. **(Up)** EMNIST \(\) MNIST **(Down)** AFHQ-64 Wild \(\) Cat. (Left) Real data and (Right) generated samples from our model. For generation at unseen resolutions, the images within the red and blue boxed initial conditions were upsampled (using bi-linear transformation) from the observed resolution (\(32^{2}\)) for EMNIST and (\(64^{2}\)) for AFHQ-64 Wild, respectively.

Imputation.We evaluate our method against recent diffusion-based imputation method where the goal is to infer the conditional distribution \(p([]|[])\) of unobserved grid \([]\) give observations \([]\). CSDI  utilizes DDPM  to learn the reverse process by treating the temporal data \([]\) as a \(^{|| d}\) dimensional feature. Extending this, DSDP-GP  enhances CSDI by incorporating noise derived from a stochastic process, instead of simple Gaussian noise. We maintained the same training setup as these models, including random seeds and the model architecture for control \(^{}\) in (2). Consistent with their methodology, we employed the Physionet dataset , which comprises medical time-series data collected on an hourly rate. Since the dataset inherently contains missing values, we selected certain degrees of observed values to create an imputation test set for evaluation. We then reported the results on this test set, varying the degrees of missingness. Table 3 shows that we outperform the previous methods even though it solely relies on forward propagation of controlled SDEs in (9) without denoising procedure.

## 6 Conclusion and Limitation

In this work, we shed light on the application of the infinite-dimensional Doob's \(h\)-transform, exploiting SOC theory in infinite-dimensional spaces. By developing an explicit Radon-Nikodym density, we address the challenge posed by the absence of an equivalent to the Lebesgue measure. With specified cost functions for control objectives, it enables us to extend previous algorithm based on the finite-dimensional Doob's \(h\)-transform into infinite-dimensional function spaces, such as resolution-free unpaired image transfer and functional Bayesian posterior sampling.

Compared to the recent infinite-dimensional score-based diffusion model , our work restricts the coefficients for the stochastic dynamics to be time-independent. This limitation prevents us from defining a noise schedule for the diffusion model , which may hinder performance improvements. Additionally, in Bayesian learning, computing the gradient of the proposed training loss function (24) can be computationally demanding. Thus, developing a more scalable algorithm would be an interesting direction for future work. Furthermore, as our model can be applied to any functional domain, we have limited our experiments to regular 1D and 2D domains, leaving the extension to more general domains for future work.

## Broader Societal Impact

Similar to other works in the literature, our proposed method holds the potential for both beneficial outcomes, such as automated data synthesis, and adverse implications, such as the deep fakes, depending on how it is used. We adhere to ethical standards for using our model in generative AI.

    &  &  &  \\   & context & target & context & target & context & target \\  CNP & 0.97 \(\) 0.01 & 0.45 \(\) 0.01 & 0.85\(\) 0.01 & 0.21 \(\) 0.02 & -0.16\(\) 0.01 & -1.75 \(\) 0.02 \\ NP & 0.90 \(\) 0.01 & 0.42 \(\) 0.01 & 0.77 \(\) 0.01 & 0.20 \(\) 0.03 & -0.18 \(\) 0.01 & -1.34 \(\) 0.03 \\ 
**DBFS** & **1.02 \(\) 0.01** & **0.47 \(\) 0.01** & **0.93 \(\) 0.01** & **0.25 \(\) 0.01** & **-0.15 \(\) 0.01** & -1.88 \(\) 0.02 \\   

Table 4: Regression results. “context” and “target” refer to the log-likelihoods at \(\) and \(\), respectively.

Figure 4: Sampled functions from a learned stochastic process \(_{t}^{}\) evaluated on \([0,I]\) for \(t[0,,T]\). The grey line represents the mean function \([_{t}^{}]\) and the blue-shaded region represents the confidence interval. (Left) GP with RBF kernel. (Right) Physionet.

   Model & \(10\%\) & \(50\%\) & \(90\%\) \\  CSDI\({}^{}\) & 0.60 \(\) 0.27 & 0.66 \(\) 0.06 & 0.84 \(\) 0.04 \\ DSDP-GP\({}^{}\) & 0.52 \(\) 0.04 & 0.64 \(\) 0.05 & 0.81 \(\) 0.03 \\ 
**DBFS** (Ours) & **0.50 \(\) 0.04** & **0.61 \(\) 0.04** & **0.77 \(\) 0.03** \\    \(\) results from .

Table 3: Test imputation RMSE on Physionet.