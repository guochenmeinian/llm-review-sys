# Efficient and Learnable Transformed Tensor Nuclear Norm with Exact Recoverable Theory

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

The tensor nuclear norm represents the low-rank property of tensor slices under a transformation. Finding a good transformation is crucial for the tensor nuclear norm. However, existing transformations are either fixed and not adaptable to the data, leading to ineffective results, or they are nonlinear and non-invertible, which prevents theoretical guarantees for the transformed tensor nuclear norm. Besides, some transformations are too complex and computationally expensive. To address these issues, this paper first proposes a fast data-adaptive and learnable column-orthogonal transformation learning framework with an exact recoverable theoretical guarantee. Extensive experiments have validated the effectiveness of the proposed models and theories.

## 1 Introduction

In real-life scenarios, many high-dimensional tensor data, such as hyperspectral images (HSIs), multispectral images (MSIs), and multi-frame videos, exhibit strong low-rank properties. Leveraging such low-rank structures of tensor data is crucial for solving tensor data restoration tasks, including but not limited to tensor completion (TC) [1; 2] and tensor robust principal component analysis (TRPCA) [3; 4]. Numerous methods have achieved outstanding results in practical applications by exploiting the low-rank property of tensors, such as video processing [5; 6], hyperspectral denoising [7; 8; 9], classification [10; 11].

There are various definitions of tensor rank, which differ from the rank used for matrices [12; 1]. Two well-known types of tensor decomposition are based on the CANDECOMP/PARAFAC (CP) and Tucker decompositions, which define the CP rank and Tucker rank, respectively . These decompositions have been widely studied and have demonstrated competitive performance in low-rank tensor recovery. Computing the CP rank is known to be NP-hard, and a clear convex surrogate for this rank has not been established. On the other hand, computing the Tucker rank involves unfolding tensors along each mode into matrices, which may result in the loss of intrinsic high-order interactive information. In addition to these two ranks, the tensor tubal rank is also commonly used for tensor decomposition . This rank is computed via tensor singular value decomposition (t-SVD), which was initially derived from a novel definition of the tensor-tensor (t-t) product . Unlike other methods, t-SVD can operate on an integral third-order tensor without reshaping it into matrices, by using the discrete Fourier transform (DFT). For a third-order tensor \(}^{n_{1} n_{2} n_{3}}\), assuming that its third mode has a low-rank property, the transformed tensor \(}}\) can be obtained as follows:

\[}}=}_{3},\] (1)

where \(_{3}\) denotes mode-3 tensor product , and \(^{n_{3} n_{3}}\) is corresponding DFT matrix which satisfies \(^{T}=^{T}=n_{3}\). Then the definition of the tensor tubal rank of \(}\) is \(_{t}(})=_{t}(})\).

[MISSING_PAGE_EMPTY:2]

is denoted as \(}(i,j,:)\). The mode-n unfolding matrix of \(}\) is denoted as \(_{(n)}=_{n}(})\), and \(_{n}(_{(n)})=}\), where \(_{n}\) is the inverse of unfolding operator. The mode-\(n\) product of a tensor \(}^{I_{1} I_{2} I_{3}}\) and a matrix \(^{J_{n} I_{n}}\) is denoted as \(}:=}_{n}\) (see definition in ). Some norms of vector, matrix and tensor are used. We denote the \(\|}\|_{1}=_{ijk}|a_{ijk}|\), the infinity norm as \(\|}\|_{}=_{ijk}|a_{ijk}|\) and the Frobenius norm as \(\|}\|_{F}=|a_{ijk}|^{2}}\), respectively.

### Adaptive Transformation

For a third-order tensor \(}^{n_{1} n_{2} n_{3}}\), assuming that its third mode has low-rank property, it can be factorized as

\[}=}_{3},\] (3)

where \(_{3}\) denotes mode-3 tensor product, \(}^{n_{1} n_{2} r_{3}}\), \(^{n_{3} r_{3}}(r_{3} n_{3})\) satisfying \(^{T}=\) and \(r_{3}=(_{(3)})\). According to low-rank tensor decomposition (3), we have.

\[}=}_{3}^{T}_{(3) }=_{(3)}^{T}=_{(3)}.\] (4)

Therefore, if we regard \(}\) as a transformed tensor \(}}\), then \(^{T}\) can be regarded as the transform matrix \(\), and \(\) is the inverse transform of \(^{T}\). Then we denote the TNN under the COM learned from the data as the Adaptive TNN (**ATNN**), which can be reformulated as:

\[\|}}\|_{*}=_{k=1}^{r_{3}}\|}}^{(k)}\|_{*}=_{k=1}^{R}\|(}_{3}^{T})^{(k )}\|_{*},}=}_{3}^{T}_{3} .\] (5)

**Remark 1**: _It should be noted that comparing Eq. (5) and Eq. (2), it can be seen that ATNN has faster solution efficiency than DFT-transformed TNN since the transformed tensor under COM transform has fewer slices. The stronger the low rank of the tensor, that is, the lower the \(r_{3}/n_{3}\) value, the higher the solution efficiency of ATNN can be obtained. However, since we want to ensure that the information of \(}\) with a rank of \((_{(3)})\) before and after the transform will not be lost, i.e., \(}=}_{3}^{T}_{3}\) is established, the condition \(r_{3}(_{(3)})\) must hold._

### T-product and T-SVD

Here, we give the definitions of t-product and t-SVD based on COM transform.

For \(}^{n_{1} n_{2} n_{3}}\), \(}^{n_{2} n_{4} n_{3}}\), the COM \(^{T}\) transformed tensor of \(}\), \(}\) are \(}}=}^{T} ^{n_{1} n_{2} R},}}=} ^{T}^{n_{2} n_{4} R}\), respectively, via Eq. (1), then we define

\[}}=(}})= }}^{(1)}&&\\ &}}^{(2)}&&\\ &&&\\ &&&}}^{(R)},}}= (}}).\] (6)

**Definition 1** (T-product): _Let \(}^{n_{1} n_{2} n_{3}},}^{n_{2} n_{4} n_{3}}\) and COM \(^{T}^{r_{3} n_{3}},(r_{3} n_{3})\) satisfying \(^{T}=_{R}\), then the t-product under transform \(^{T}\) is defined as_

\[}=}*_{L}}=((}})(}})) _{3}=(}}\,}})_{3}^{n_{1} n_{4} n_{3}},\] (7)

_where \(}}=}_{3}^{T}^{n_{1} n_{2} r_{3}}\) and \(}}=}_{3}^{T}^{n_{2} n_{4} r_{3}}\)._

According to the Definition 1, we have \(}=}*_{L}}}}=}}\,}}\) since \((}})=}}=}_{3}^{T}=(}}\, }})_{3}_{3}^{T}=( }}\,}})_{3}(^{T} )=(}}\,}})\).

The t-product enjoys many similar properties to the matrix-matrix product. For example, the t-product is associate, i.e., \(}*(}*})=(}*})*}\). We also need some other concepts on tensors.

**Definition 2** (Transpose): _The transpose of a tensor \(}^{n_{1} n_{2} n_{3}}\) is the tensor \(}^{T}^{n_{2} n_{1} n_{3}}\) obtained by transposing each of the frontal slices._

**Definition 3** (Identity tensor): _A third-order tensor \(}^{n n n_{3}}\) is called identity tensor if it satisfies that each frontal slice is identity matrix, i.e., \(^{(i)}=\) for all \(i=1,,n_{3}\)._

**Definition 4** (Orthogonal tensor): _A third-order tensor \(}^{n n n_{3}}\) is called orthogonal tensor if it satisfies that \(}^{T}_{L}}=}_{L}}^{T}=}\)._

**Definition 5** (F-diagonal tensor): _A tensor is called f-diagonal if each of its frontal slices is a diagonal matrix._

**Theorem 1** (T-SVD): _Let \(}^{n_{1} n_{2} n_{3}}\). Then it can be factorized as_

\[}=}_{L}}_{L}}^{T},\] (8)

_where \(}^{n_{1} n_{1} n_{3}}\), \(}^{n_{2} n_{2} n_{3}}\) are orthogonal, and \(}^{n_{1} n_{2} n_{3}}\) is f-diagonal._

By replacing DFT transform with COM transform \(^{T}\), we can prove the above Theorem .

**Definition 6** (Tensor tubal rank  & TNN ): _For \(}^{n_{1} n_{2} n_{3}}\), the tensor tubal rank, denoted as \(_{t}(})\), is defined as the number of nonzero singular tubes of \(}\), where \(}\) is from the t-SVD of \(}=}_{L}}_{L}}^{T}\). We can write_

\[_{t}(})=\#\{i,}(i,i,:)\}.\] (9)

_And its tensor nuclear norm (TNN) is defined as_

\[\|}\|_{}=_{i}\|}(i,i,:)\|_{1}=\|}\|_{1}.\] (10)

Using the t-product definition, we can get \(}=}_{L}}_{L}}^{T}}=}\,}\, }^{T}\), thus we have

\[\|}\|_{}=\|}\|_{1}=\|}}\|_{}=\|}\|_{}=\|}}\|_{}\] (11)

by combing Eq. (5), Eq. (6) and Eq. (10).

## 3 Tensor Recovery via ATNN Minimization

### Models

The observed tensor and the tensor that needs to be recovered are denoted as \(}\) and \(}_{0}\), respectively. For the tensor completion (TC), the observation \(}\) has the support set \(()\), i.e., \(}_{}(})=}_{}(}_{0})\). For the tensor robust principal component analysis (TRPCA), the observation \(}\) is corrupted with a sparse component \(}_{0}\) (which may represent foreground and sparse noise), denoted as \(}=}_{0}+}_{0}\).

If the COM \(^{T}\) satisfying Eq. (5) is known, we can obtain the following two models:

\[:&_{},}}\,\|}_{3}^{T}\|_{}+ \|}\|_{1},\ s.t.\,}=}+},\\ :&_{}}\,\|}_{3}^{T}\|_{},\ s.t.\,}_{}(})=}_{}(}).\] (12)

Actually, it is often not possible to obtain \(^{T}\) that satisfies Eq. (5) in advance. Recall Eq. (5), where the constraint \(}=}_{3}^{T}_{3}\) shows that the information of \(}\) after the change and inverse change will not be lost, as long as \(\) is obtained from the SVD decomposition of \(}\), Eq. (5) can be satisfied. Hence, we can learn a suitable COM \(\) from the data. By decomposing \(}\) as \(}=}}_{3}\) and setting \(}=}_{3}^{T}\), we can obtain the following alternative model to Eq. (12):

\[:&_{}},},}\,\|}}\|_{ }+\|}\|_{1},\ s.t.\,}=}}_{3}+},^{T}=,\\ :&_{}}, }\,\|}}\|_{},\ s.t.\,}_{}(})=}_{}(}}_{3}),^{T}=.\] (13)

### Incoherence Conditions

The incoherence condition is one of the most vital theoretical tools in low-rank recovery . Below, we define \(}_{i}\) as the tensor column basis and the tensor incoherence conditions similar to .

**Definition 7** (Tensor Incoherence Conditions): _For \(}_{0}^{n_{1} n_{2} n_{3}}\) with t-SVD rank \(R\), it has the skinny t-SVD \(}_{0}=}_{L}}_{L}}^{T}\). Then \(}_{0}\) is said to satisfy the tensor incoherence conditions with parameter \(\) if_

\[_{i[1,n_{1}]}\|}^{T}_{L}}_{i}\|_{F} }},_{j[1,n_{2}]}\|}^{T}_{L} }_{j}\|_{F}}},\|} _{L}}^{T}\|_{F}n_{2}}}.\] (14)

### Main results

We now demonstrate that both the model (12) and (13) possess exact recovery capability.

**Theorem 2** (TRPCA Theorem): _Consider ATNN-based TRPCA model (12) and (13). Suppose that \(}_{0}^{n n n_{3}}\) obeys the tensor incoherence conditions (14) and \(}_{0}\)'s support set, denoted as \(_{0}\), is uniformly distributed among all sets of cardinality \(m\). Then, there exist universal constants \(c_{1},c_{2}>0\) such that \((}_{0},}_{0})\) is the unique solution to model (12) and (13) when \(=1/\) with probability at least \(1-c_{1}(nn_{3})^{-c_{2}}\), provided that_

\[_{t}(}_{0})_{r}^{-1}n^{-2}(n)\;\; {and}\;\;m_{s}n^{2}n_{3},\] (15)

_where \(_{r},_{s}>0\) are some numerical constants._

**Theorem 3** (TC Theorem): _Consider ATNN-based TC model (12) and (13). Suppose that \(}_{0}^{n n n_{3}}\) obeys the tensor incoherence conditions (14) and \((p)\). Then, there exist universal constants \(c_{0},c_{1},c_{2}>0\) such that \(}_{0}\) is the unique solution to model model (12) and (13) with probability at least \(1-c_{1}(nn_{3})^{-c_{2}}\), provided that_

\[p c_{0} Rn^{-1}^{2}(n).\] (16)

**Remark 2**: _It should be noted that although the model (12) and (13) are slightly different, they are the same in the proof of the exact recoverable theory. Assume that the optimal values of models (12) and (13) are \((}},}})\) and \((}},},}})\), respectively. A recoverable theory of model (12) requires proving \((}},}})=(}_{0},}_{0})\) under the given \(\) in advance. A recoverable theory of model (13) requires proving \((}}_{3}},}})=( }_{0},}_{0})\) under the final learned \(}\)._

### Solving Algorithm

This subsection derives efficient algorithms for solving the ATNN-based TRPCA and TC problem via the Alternating Direction Method of Multipliers (ADMM) framework .

We first write the augmented Lagrangian function of the TRPCA problem in Eq. (13) as:

\[_{}},},,^{ T}=}\|}}\|_{*}+\|}\|_{1}+\|}-}} _{3}-}+/\|_{F}^{2},\] (17)

where \(\) is the penalty parameter and \(\) is the lagrange multiplier.

Due to page limitation, we provide Algorithm 1 for solving Eq. (17) using the soft-thresholding operator \(()\) and the singular value soft-thresholding operator SVD\(()\). Additionally, for the ATNN-TC model (13), we provide Algorithm 2 directly. For more detailed information, please refer to the supplementary material.

### Computational Complexity Analysis

As depicted in Algorithm 1 and 2, each iteration of the algorithm involves updating \(}}\) through small-scale SVD computations, updating \(\) through small-scale SVD computation, updating \(}\) through soft thresholding operations, and some matrix multiplications. For a third-order tensor \(}^{n_{1} n_{2} n_{3}}\), the time complexity of the soft threshold operator is \((n_{1}n_{2}n_{3})\), the time complexity of solving \(\) is \((n_{3}r_{3}^{2})\), and the time complexity of solving \(}}\) is \((r_{3}n_{1}n_{2}^{2})\). Thus, the overall time complexity of Algorithm 1 and 2 is \((r_{3}n_{1}n_{2}^{2}+n_{3}r_{3}^{2}+n_{1}n_{2}n_{3})\). Similarly, for the DFT-transformed TRPCA and TC models, the time complexity is \((n_{3}n_{1}n_{2}^{2}+n_{1}n_{2}n_{3})\). By comparing the two time complexities mentioned above, it can be observed that their ratio is positively correlated with \(r_{3}/n_{3}\). Therefore, as the low-rank property of the tensor in the third dimension becomes stronger, the acceleration capability of the proposed algorithm in this paper also becomes stronger.

## 4 Experiments

In this section, we present numerical experiments to validate the main results stated in Theorems 2 and 3. Following the suggestion of Theorem 2, we set \(=1/,n_{2}\}}\) for the TRPCA task in all experiments. However, it should be noted that further performance improvements can be achieved by carefully tuning the value of \(\). The suggested value in the theory provides a useful guideline in practical applications. All simulations were conducted on a PC equipped with an Intel(R) Core(TM) i5-10600KF 4.10GHz CPU, 32 GB memory, and a GeForce RTX 3080 GPU with 10 GB memory.

### Simulated Experiments

In this section, we will verify the correct recovery guarantee of Theorem 2 and 3 on randomly generated problems. We generate a tensor with tubal rank \(R\) as a product \(}_{0}=}*_{L}}^{T}\), where \(}\) and \(}\) are \(n R n\) tensors with entries independently sampled from \((0,1/n)\) distribution and the COM \(^{r_{3} n}\) is generated by orthogonalizing the random matrix with entries independently sampled from \((0,1)\). For the TRPCA task, the support set \(\) (with size \(m\)) of \(}_{0}\) with independent Bernoulli \( 1\) entries is chosen uniformly at random, and the observation tensor is set as: \(}=}_{0}+}_{0}\). For the TC tasks, the observation \(}\) is set as \(}=}_{}(}_{0})\).

Next, we investigate how the tubal rank of \(}_{0}\) and the sparsity of \(}_{0}\) (and missing ratio of \(}_{0}\) ) affect the performance of model (12) and (13). We consider \(n=50\) and two values of \(r_{3}\), i.e., \(r_{3}=5,20\). We vary the sparsity \(_{s}}_{0}\) as \([0.01:0.01:0.5]\), the missing ratio \(\) of \(}_{0}\) as \([0.01:0.02:0.99]\), and tubal rank of \(}_{0}\) as \([1:1:50]\), respectively. For each combination of \((R,_{s})\) and \((R,)\), we perform 10 tests instances and declare a trial successful if the recovered tensor \(}}\) satisfies \(\|}}-}_{0}\|_{F}/\|}_{0}\|_{F } 0.01\). The fraction of successful recoveries are plotted in Figure 1. From Figure 1, we observe that there is a significant region where the recovery is correct for both models. Furthermore, two notable phenomena can be observed from the figure:

1. The phase transition diagram in the first row of Figure 1 closely resembles the second row, indicating that even if we don't know the correct COM \(\) in the model (12), we can learn the COM \(\) through model (13).
2. The phase transition diagram of \(r_{3}=5\) is much better than that of \(r_{3}=20\) for both TRPCA and TC tasks, which shows that it is necessary to consider the low-rank property of mode 3.

### Real Experiments

To validate the effectiveness of the proposed ATNN model in tensor recovery task, we conducted experiments on various datasets, including hyperspectral images (HSI), multispectral images (MSI), color video images, and surveillance videos. Due to page limitations, we have included the results of robustness analysis, parameter settings for robustness, convergence verification, and more detailed experimental outcomes in the Supplementary Material.

For comprehensive comparison, we have included additional state-of-the-art methods except those listed in Table 1. These methods include CTV  and TCTV  for the TRPCA task, LRMC , HaLRTC , UTNN , and OITNN  for the TC task, and GODEC , DECOLOR , OMoGMF , RegL1 , and PRMF  for background modeling. Before conducting this experiment, the gray value of each band was normalized into  via the max-min formula.

   &  &  &  &  \\   & PSNR & SSIM & Times & PSNR & SSIM & Times & PSNR & SSIM & Times & PSNR & SSIM & Times \\  RPCA & 32.08 & 0.5223 & 28.99 & 24.98 & 0.8264 & 6.59 & 17.88 & 0.5920 & **17.92** & 18.47 & 0.5418 & **18.28** \\ SNN & 26.02 & 0.7178 & 136.2 & 31.34 & 0.9492 & 121.1 & 16.14 & 0.5238 & 176.2 & 16.77 & 0.5297 & 176.7 \\ KBR & 22.64 & 0.6438 & 167.2 & 20.91 & 0.4477 & 58.63 & 20.26 & 0.4162 & 252.1 & 20.91 & 0.5454 & 162.9 \\ TNN & 19.619 & 0.3728 & 419.2 & 17.09 & 0.2345 & 120.2 & 0.23 & 0.2572 & 322.4 & 15.51 & 0.1744 & 324.8 \\ CTNN & 17.21 & 0.2036 & 485.7 & 15.38 & 0.1163 & 130.7 & 15.64 & 0.1218 & 363.4 & 14.55 & 0.1162 & 353.9 \\ CTV & 33.85 & 0.9454 & 170.2 & 31.91 & 0.8872 & 41.85 & 29.35 & 0.7770 & 103.8 & 27.33 & 0.7721 & 102.2 \\ TCTV & 32.12 & 0.9090 & 815.2 & 29.62 & 0.8554 & 172.5 & **32.85** & **0.9204** & 641.3 & 27.36 & 0.7534 & 627.9 \\ Ours & **39.82** & **0.9913** & **21.34** & **35.31** & **0.9721** & **5.32** & 29.46 & 0.9108 & 29.22 & **27.53** & **0.8563** & 19.30 \\  

Table 2: Quantitative comparison of all RPCA-based competing methods under salt-and-pepper noise with the variance of **0.6**. The best and second results are highlighted in bold italics and underline.

   &  &  &  &  \\   & PSNR & SSIM & Times & PSNR & SSIM & Times & PSNR & SSIM & Times & PSNR & SSIM & Times \\  LRMC & 18.53 & 0.4623 & **24.38** & 15.17 & 0.2834 & **2.93** & 15.96 & 0.3972 & **7.61** & 13.11 & 0.1902 & **10.95** \\ HaLRTC & 22.09 & 0.6676 & 54.37 & 18.87 & 0.3912 & 30.34 & 20.62 & 0.4542 & 64.48 & 19.01 & 0.3570 & 92.65 \\ KBR & 31.42 & 0.9022 & 1589 & 29.92 & 0.8591 & 725.7 & 26.06 & 0.7208 & 1253 & 24.14 & 0.6422 & 1292 \\ TNN & 30.01 & 0.8824 & 1019 & 26.43 & 0.7126 & 207.9 & 26.10 & 0.6712 & 419.2 & 23.46 & 0.6012 & 441.2 \\ CTNN & 33.36 & 0.9432 & 378.9 & 31.69 & 0.9172 & 114.4 & 27.61 & 0.8041 & 129.6 & 25.71 & 0.7362 & 136.2 \\ UTNN & 27.89 & 0.8652 & 487.6 & 21.80 & 0.5982 & 156.3 & 17.28 & 0.4131 & 116.6 & 16.27 & 0.3183 & 117.9 \\ FTNN & 34.87 & 0.5320 & 4376 & 32.56 & 0.9092 & 1263 & 28.48 & 0.8143 & 1587 & 25.25 & 0.7253 & 2054 \\ OITNN & 32.92 & 0.9396 & 838.2 & 28.46 & 0.8142 & 292.4 & 27.28 & 0.7442 & 448.6 & 24.06 & 0.6516 & 391.8 \\ TCTV & 33.33 & 0.9391 & 2116 & 31.81 & 0.8960 & 861.4 & **31.77** & **0.9143** & 1570 & 28.38 & 0.8442 & 1488 \\ S2NTNN & 37.36 & 0.9749 & 168.7 & **35.15** & **0.9431** & 40.78 & 27.44 & 0.7589 & 104.2 & **31.28** & **0.8679** & 113.2 \\ Ours & **38.06** & **0.9793** & 232.4 & 33.94 & 0.9293 & 58.34 & 28.83 & 0.8164 & 156.3 & 25.81 & 0.7146 & 142.4 \\  

Table 3: Quantitative comparison of all competing methods under missing ratio with **0.95**. The best and second results are highlighted in bold italics and underline, respectively.

Figure 1: TRPCA and TC phase transition diagrams for varying tubal ranks of \(}_{0}\) and sparsities of \(}_{0}\) or missing ratio of \(}_{0}\). The first and second rows show the phase transition diagrams based on models (13) and (12), respectively, under different \(r_{3}\) settings.

#### 4.2.1 Hyperspectral and Multispectral Image Recovery

Two HSI images, i.e., WDC 1 and PaviaU 2 datasets are used. The sizes of the two data are \(256 256 191\) and \(256 256 93\), respectively. Two MSI images in CAVE dataset 3, i.e., Cloth and Beans are used. The size of the two data is \(512 512 31\).

For the TRPCA task, we conducted experiments with six different levels of salt and pepper noise variance: 0.1, 0.2, 0.3, 0.4, 0.5, and 0.6. Table 2 reports the performance metrics of each method under a variance of 0.6, demonstrating that our ATNN outperforms all competing methods. Notably, our method achieves superior performance despite only utilizing the low-rank property of tensors, surpassing the performance of CTV and TCTV, which additionally exploit the local smoothness and low-rank property of images. Furthermore, our method exhibits comparable computational efficiency to RPCA, indicating that the introduction of the learnable COM matrix effectively reduces the time complexity of the model. To better visualize the comparison, we choose three bands of HSI to form a pseudo-color image to show four representative competing methods' visual restoration performance, as shown in Figure 2. From the images, it is evident that our proposed ATNN model can effectively remove noise and preserve more detailed information.

For the TC task, since all the methods achieve very accurate recovery results when the sample ratio (SR) is high, we test four different SRs: 0.01, 0.05, 0.1 and 0.2. The metric of each tested algorithm under an SR of 0.05 is placed in Table 3. As can be seen from the metrics in the table, our proposed method excels in recovery performance and running time.

#### 4.2.2 Background Modeling from Surveillance Video

The aim of this task is to separate the background and foreground from Surveillance Video. We choose nine video sequences in Li dataset 4 with the known foreground of size \(144 176 20\) for testing, as shown in Table 4. It can be seen from the table that our proposed model is far ahead in

    &  &  \\   & airp. & boot. & shop. & lobb. & esca. & curt. & camp. & water. & foun. & Average \\  RPCA  & 0.8721 & 0.9168 & 0.9445 & 0.9130 & 0.9050 & 0.8722 & 0.8917 & 0.8345 & 0.9418 & 0.8991 & 2.37 \\ GODEC  & 0.9001 & 0.9046 & 0.9187 & 0.8556 & 0.9125 & 0.9131 & 0.8693 & 0.9370 & 0.9099 & 0.9023 & 0.64 \\ DECOLOR  & 0.8627 & 0.8910 & 0.9462 & 0.9241 & 0.9077 & 0.8864 & **0.9485** & 0.8000 & 0.9443 & 0.8952 & 8.902 & 8.902 \\ OMOGMF  & 0.9143 & 0.9238 & 0.9478 & 0.9252 & 0.9112 & 0.9049 & 0.8877 & 0.8958 & 0.9419 & 0.9170 & 3.92 \\ RegL  & 0.8977 & **0.9249** & 0.9423 & 0.8819 & 0.4159 & 0.8899 & 0.8871 & 0.8920 & 0.9194 & 0.8501 & 10.74 \\ PRMF  & 0.8905 & 0.9218 & 0.9415 & 0.8818 & 0.9065 & 0.8806 & 0.8865 & 0.8799 & 0.9166 & 0.9006 & 13.68 \\ CTV  & 0.9178 & 0.9107 & **0.9541** & 0.9337 & 0.9148 & 0.8710 & 0.8814 & **0.9386** & 0.9383 & 0.9180 & 10.28 \\ TNN  & 0.5218 & 0.5694 & 0.6605 & 0.6313 & 0.5981 & 0.5823 & 0.5456 & 0.6642 & 0.5781 & 0.5947 & 16.87 \\ CTNN  & 0.6859 & 0.9116 & 0.6835 & 0.6613 & 0.6582 & 0.6988 & 0.5881 & 0.5272 & 0.5450 & 0.6295 & 17.39 \\ ATNN & **0.9185** & 0.9227 & 0.9484 & **0.9362** & **0.9158** & **0.9162** & 0.8912 & 0.9152 & **0.9456** & **0.9233** & **2.32** \\   

Table 4: AUC comparison of all competing methods on all video sequences in the Li dataset. The best and second results in each video sequence are highlighted in bold italics and underline, respectively.

    &  &  &  &  \\   & PSNR & SSIM & Times & PSNR & SSIM & Times & PSNR & SSIM & Times & PSNR & SSIM & Times \\  LRMC & 10.81 & 0.2626 & **8.06** & 8.79 & 0.1192 & **7.21** & 11.57 & 0.2713 & **6.92** & 13.27 & 0.3660 & **13.41** \\ HalfRT & 17.65 & 0.5327 & 61.04 & 15.55 & 0.3336 & 44.87 & 14.20 & 3.4844 & 42.46 & 16.43 & 0.4890 & 87.63 \\ KRR & 29.76 & 0.9118 & 689.2 & 23.97 & 0.7193 & 668.2 & 26.49 & 0.8164 & 798.2 & 26.42 & 0.6284 & 0.8480 & 1043 \\ TNN & 31.94 & 0.9343 & 217.5 & 23.15 & 0.6052 & 181.5 & 26.27 & 0.7658 & 493.6 & 28.56 & 0.8660 & 249.6 \\ CTNN & 28.63 & 0.8463 & 192.0 & 22.13 & 0.5779 & 152.7 & 25.06 & 0.7263 & 196.2 & 25.59 & 0.7740 & 174.7 \\ UTNN & 21.72 & 0.7239 & 172.4 & 16.51 & 0.2857 & 167.6 & 20.24 & 0.5394 & 202.7 & 21.21 & 0.7060 & 162.6 \\ FTNN & 30.74 & 0.9252 & 1258 & 29.07 & 0.6781 & 1123 & 25.43 & 0.7778 & 1335 & 28.77 & 0.8770 & 1494 \\ OTNN & 32.68 & 0.9533 & 397.5 & 23.89 & 0.7206 & 296.7 & 27.14 & 0.8340 & 472.3 & 29.43 & 0.9010 & 322.3 \\ TCTV & 33.41 & 0.9542 & 874.8 & **26.69** & **0.8071** & 821.4 & **29.10** & **0.8747** & 1103 & **30.65** & **0.9170** & 772.2 \\ S2NTNN & 33.16 & 0.9520 & 168.7 & 23.57 & 0.6091 & 83.98 & 27.33 & 0.8093 & 100.7 & 29.11 & 0.8872 & 90.61 \\ Ours & **33.74** & **0.9574** & 95.89 & 24.16 & 0.6252 & 78.21 & 27.44 & 0.7773 & 80.11 & 29.72 & 0.9021 & 78.94 \\   

Table 5: Quantitative comparison of all competing methods on color video under missing ratio with 0.95. The best and second results are highlighted in bold italics and underline, respectively.

terms of evaluation metrics and running time. Even compared to the CTV model that simultaneously utilizes local smoothness and low-rank priors, our method outperforms it. It is worth noting that although tensor-based models have a higher performance ceiling than matrix-based models due to their ability to capture more complex structures, for TNN regularization, if the variation matrix is not well defined, the results can even be worse than matrix-based methods. This further highlights the necessity of learning the transform matrix.

#### 4.2.3 Color Video Completion

We selected four color video sequences, namely Akiyo, Foreman, Carphone, and Mobile, from the open-source YUV video dataset5. To ensure efficient comparison, we considered the first 100 frames of each color video sequence. As the color video is represented as a fourth-order tensor in RGB format with dimensions \(144 176 3 100\), we reshaped it into a tensor of size \(144 176 300\). We adopted similar sample ratio (SR) settings as mentioned in Subsection 4.2.1. The performance metrics of all competing methods are presented in Table 5. It is evident that our proposed model consistently ranks within the top three, outperforming TCTV even under the Akiyo dataset. In comparison to other TNN models with fixed transform matrices, our model exhibits superior performance and remarkable computational efficiency. Furthermore, we provided the recovered images of some competing methods in Figure 3 for better visual comparison. For the convenience of observation, we have enlarged a part of the picture and placed the repair indicator below the picture. It can be seen that our proposed ATNN model has a strong ability to preserve the local information of the data.

## 5 Conclusion

In this paper, we introduce an efficient and learnable transformed tensor nuclear norm (TNN) model with a provable recovery guarantee. Our approach leverages the low-rank property of the third mode of the tensor to represent the tensor to be repaired as a combination of a small-sized tensor and a column-orthogonal matrix. The column-orthogonal matrix serves as an adaptively learned transform matrix derived from the data. By employing the nuclear norm on the small-sized tensor, our model achieves higher computational efficiency compared to existing methods. Additionally, we provide a theoretical framework that guarantees exact recovery for our proposed model with a column-orthogonal transform matrix. Extensive experimental results demonstrate the effectiveness of our approach and the validity of our theoretical findings.

**Limitations** There are two shortcomings in our work. Firstly, the recoverable theory does not explain how the low-rank property of the third dimension of the tensor affects the model's restoration performance. Secondly, the ATNN model only learns the low-rank property of the tensor, without incorporating image priors. These two points will be the focus of our future research.

Figure 3: Recovered images of all competing methods under sample ratio of 0.05 on the 10th frame of Akiyo data.

Figure 2: Denoised images of all competing methods with bands 58-27-9 as R-G-B under sparse noise with missing percent is 0.6 on simulated WDC dataset.