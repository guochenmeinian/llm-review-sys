# Riemannian Black Box Variational Inference

Mykola Lukashchuk\({}^{1}\) &Wouter W. L. Nuijten\({}^{1}\) &Dmitry Bagaev\({}^{1,2}\)

Ismail Senoz\({}^{1,2}\) &Bert de Vries\({}^{1,2,3}\)

\({}^{1}\)Eindhoven University of Technology &\({}^{2}\)Lazy Dynamics &\({}^{3}\)GN Hearing

Eindhoven, The Netherlands

{m.lukashchuk, w.w.l.nuijten, d.v.bagaev, i.senoz, bert.de.vries}@tue.nl

###### Abstract

We introduce Riemannian Black Box Variational Inference (RBBVI) for scenarios lacking gradient information of the model with respect to its parameters. Our method constrains posterior marginals to exponential families, optimizing variational free energy using Riemannian geometry and gradients of the log-partition function. It excels with black-box or nondifferentiable models, where popular methods fail. We demonstrate efficacy by inferring parameters from the SIR model and tuning neural network learning rates. The results show competitive performance with gradient-based (NUTS) and gradient-free (Latent Slice Sampling) methods, achieving better coverage and matching Bayesian optimization with fewer evaluations. RBBVI extends variational inference to settings where model gradients are unavailable, improving efficiency and flexibility for real-world applications.

## 1 Introduction

Bayesian Inference focuses on updating beliefs about hypotheses based on newly available evidence. Previously too costly, it is now more feasible thanks to Markov-Chain Monte Carlo (MCMC) algorithms that can sample from difficult posterior distributions and Variational Inference methods that can directly optimize an approximate posterior distribution. However, widely used MCMC methods, such as the No-U-Turn Sampler (NUTS)  and well-known variational inference methods such as Automatic Differentiation Variational Inference (ADVI)  or Stochastic Variational Inference (SVI)  require that the gradient of the log-probability density function with respect to the parameters be computable.

Gradient-free methods, such as Ensemble Slice Sampling (ESS) , propose a way to sample from the posterior distribution over parameters even when the gradient is unavailable. Although these methods are gradient-free and nonparametric, they require significant evaluations of the log-probability density function, which may be computationally expensive.

This paper introduces Riemannian Black Box Variational Inference (RBBVI) for approximating posterior marginal distributions, addressing computational challenges in two ways: by constraining the posterior to a predefined exponential family , we balance approximation accuracy with computational cost; optimizing variational free energy allows for early stopping, potentially reducing function evaluations compared to sampling methods.

RBBVI is particularly well-suited for approximate inference in probabilistic models with black-box components. This makes the proposed method ideal for scenarios where nondifferentiable and computationally expensive operations are frequent or for hyperparameter tuning, where gradients might not be easily accessible. To demonstrate this, we address the problem of inferring the optimal learning rate of gradient descent while training a neural network. In this situation, the gradient of the loss function with respect to the learning rate is not directly available. Since training a neural network is costly, it is crucial to minimize the number of executions during hyperparameter tuning.

## 2 Riemannian Variational Inference

We are concerned with Bayesian inference in a generative model \(p(,y)\) with \(\) unobserved parameters and \(y\) observed data. We are interested in the inference task of determining \(p(|y)\). In this paper, we assume a factorizable generative model with independent priors over \((_{1},,_{n})\)

\[p(y,_{1},,_{n})=p(y|_{1},,_{n})_{i}p_{ i}(_{i}),\] (1)

where \(p(y,|_{1},,_{n})\) is a generative process that is possibly not differentiable with respect to \(\).

Variational inference addresses this by introducing an approximate posterior distribution \(q\) on which we want to maximize the evidence lower bound (ELBO) or equivalently minimize the Free Energy

\[[q,p](y)= q(),\] (2a) where the goal is to compute \[q^{*}=F[q,p](y),\] (2b)

for a given observation \(y\).

The problem (2b) is a nonparametric one. To cast it into a parametric optimization problem, we assume the following functional form of \(q(_{1},,_{n})\) to be a factorized posterior \(_{i}q_{i}(_{i})\), where each constrained \(q_{i}(_{i})\) to be a known exponential family

\[q_{_{i}}(_{i})=(_{i}^{T}T_{i}(_{i})-A_{i}( _{i})+_{i}(_{i})),\] (3)

with natural parameters \(_{i}\), sufficient statistics \(T_{i}\), a base measure \(_{i}\), and known log-partition function \(A_{i}\). This turns the problem (2b) into the following parametric problem

\[^{*}=*{argmin}_{=(_{i},,_{n}) }[_{i}q_{_{i}}(_{i}),p](y).\] (4)

The fruitful idea is to apply gradient-based methods to the Free Energy objective \(F\) with respect to the parameters \(\). This approach was first proposed by Amari  with the following gradient update

\[^{k+1}=^{k}-^{-1}(^{k})_{}F|_ {=^{k}},\] (5)

where \(\) is the Fisher information matrix. The update rule (5) has gained further popularity, and Khan  has developed extensions to the rule. The typical challenge in applying the rule (5) is that \(\) usually lies within an open constraint set, so the update may not always meet the constraints. Lin  addresses this issue for positive-definite constraints (e.g., Gamma, Gaussian) using Riemannian gradient descent. It is crucial to note that even when the gradient of \(p(y,_{1},,_{n})\) with respect to \((_{1},,_{n})\) does not exist or is intractable, the gradient \(_{}F\) can still exist and be tractable, depending on the specific choice of \(q\).

Similarly to Lin's approach, we assume that each \(_{i}\) belongs to a constraint set \(_{i}\) that forms a Riemannian manifold with \(_{i}\) as its metric. For readers interested in a comprehensive treatment of these concepts, we recommend the book by Absil et al. . For readers new to manifold theory, a manifold \(\) can be thought of as a set that, at any point \(x\) can be approximated by a vector space. This vector space is called the tangent space \(T_{x}\). An important detail is that the dimensionality of \(T_{x}\) remains constant for each point \(x\) in the manifold. A Riemannian manifold is equipped with a Riemannian metric, which defines a smooth inner product on each tangent space, allowing us to measure distances and angles between tangent vectors. The Riemannian gradient \( f(x)\) at a point \(x\) on \(\) is the unique tangent vector in \(T_{x}\) that satisfies \( f(x),_{x}=Df(x)[]\) for all \( T_{x}\), where \(,_{x}\) denotes the Riemannian metric in \(x\). To move along the manifold in the direction of a tangent vector, we use a retraction \(R_{x}:T_{x}\). Specifically, for a tangent vector \( T_{x}\), the curve \((t)=R_{x}(t)\) satisfies \((0)=x\) and \((0)=\).

We equip each \(_{i}\) with a Riemannian metric \(_{i}\) and a known closed-form retraction \(R_{i}\). We treat \(=_{i}_{i}\) as a product manifold with the product retraction \(R_{}()=(R_{_{1}}^{1}(_{i}),,R_{_{n}}^{n}(_ {n}))\), leading to the following update rule

\[^{k+1}=R_{^{k}}(-^{-1}(^{k} )_{}F|_{=^{k}}),\] (6a) where \[()=_{1}(_{1})& &\\ &&\\ &&_{n}(_{n}).\] (6b)

The problem in implementing the scheme (6a) then boils down to a fast computation of \(_{}F\).

## 3 Gradient computation

To compute \(_{}F\), we employ the integration by parts as described in [21, Appendix: The Gradient of the ELBO] for the Euclidean case, the proof can be trivially extended to the Riemannian setting via [7, Proposition 8.59]. The integration by parts yields the following expression for the gradient of the Free Energy

\[_{}[_{i}q_{_{i}}(_{ i}),p](y)=_{_{i}q_{_{i}}(_{i})}[ q_{_{i}}(_{i})}{p(y,_{1},,_{n})} T_{1}(_{1})-_{_{1}}A(_{1})\\ \\ T_{n}(_{n})-_{_{n}}A(_{n})].\] (7)

The form of \(_{}F\) given in the equation (7) leads to an important observation: the differentiability of \(F\) (both in the Euclidean and Riemannian senses) does not depend on the properties of \(p(y,_{1},,_{n})\) with respect to \((_{1},,_{n})\). Instead, it depends solely on the existence of \(_{_{i}}A(_{i})\). When \(p(y,_{1},,_{n})\) is differentiable in terms of \((_{1},,_{n})\), a Monte Carlo method with favorable convergence properties is used to estimate the gradient (6a) with the reparameterization trick . This approach can be extended to nondifferentiable functions by approximating the nondifferentiable function with a differentiable surrogate (smooth approximation), as in the RELAX method  and then applying the reparameterization trick.

The key observation of our study is as follows: we can construct a first-order approximation to \(_{}F\) using the form (7) without an explicit smooth approximation of \(p(y,_{1},,_{n})\) via

\[_{}F_{q_{_{1}}(_ {1})}[}(_{1})}{p(y,_{1},_{2}, ,_{n})}(T_{1}(_{1})-_{_{1}}A_{1}(_{1})) ]\\ \\ _{q_{_{n}}(_{n})}[}( _{n})}{p(y,_{1},,_{n})}(T_{n}(_{n})-_{_{ n}}A_{n}(_{n}))],\] (8)

where \(_{j}=_{q_{_{j}}(_{j})}[_{j}]\).

The error term for the approximation (8) can be obtained from Theorem 1 provided in Appendix E applied to each component of the gradient. For each \(i\), we define a function \(h_{i}\) that depends on all variables except \(_{i}\)

\[h_{_{i}}(_{1},,_{i-1},_{i+1}, ,_{n})=p(y,_{1},,_{i-1},_{i},_{i+1}, ,_{n})\] (9)

Applying Theorem 1 to each \(h_{_{i}}\), we get

\[_{_{j i}q_{_{j}}(_{j})}[h_{_ {i}}(_{1},,_{i-1},_{i+1},,_{n})] h_ {_{i}}(_{1},,_{i-1},_{i+1},,_{n}),\] (10)

where the approximation error is the limit expression from Theorem 1.

To estimate the right-hand side of equation (8) we employ REINFORCE estimator  corrected on the exponential family sufficient statistics (for details see Appendix C)

\[_{i},,_{N} q_{_{i}}(_{i})\] (11a) \[h_{i}(_{i},_{i}) =}(_{i})}{p(y,_{1},_{2},,_{i},_{n})}(T_{i}(_{i})-_{_{i}}A_{i}( _{i}))\] (11b) \[f_{i}(_{i},_{i}) =T_{i}(_{i})-_{_{i}}A(_{i})\] (11c) \[A[h] =_{i}h_{i}(_{i},_{i})\] (11d) \[[h,f] =_{i}(h_{i}(_{i},_{i})-A[h] )^{T}f_{i}(_{i},_{i})\] (11e) \[_{q_{_{i}}(_{i})}[h_{i}(_{i}, _{i})] _{_{i}}F=_{i}h_ {i}(_{i},_{i})-[h,f]_{i}(_{i})^{-1}f _{i}(_{i},_{i}).\] (11f)

Algorithm 1 in Appendix D presents the complete implementation of the procedure described in Equation (6a). This algorithm integrates all key components of our method, offering a comprehensive description of RBBVI.

## 4 Experimental Results

Experiments presented in this section were implemented in Python  and Julia . The code is publicly available at https://github.com/biaslab/GradientFreeVI. For the SIR model experiments in Subsection 4.1, we utilized the model implementation from Frost's SIR repository1, integrating their Turing.jl  model specification. This integration allowed us to compare with the NUTS  and LSS (Latent Slice Sampling)  samplers using the Turing.jl framework.

### Parameter Inference for a SIR Model

To evaluate our method, we use the Susceptible-Infected-Recovered (SIR) epidemiological model . This provides a benchmark in an "ideal" scenario where gradients are readily available, allowing comparison against gradient-based and gradient-free approaches. The SIR model dynamics are governed by the following system of ordinary differential equations

\[&=- cS = cS- I\\ &= I=  cS\] (12)

where \(S\), \(I\), and \(R\) represent the susceptible, infected, and recovered populations respectively, \(C\) tracks cumulative cases, \(N=S+I+R\) is the total population, \(\) is the infection rate, \(c=10\) is the contact rate, and \(=0.25\) is the recovery rate. We simulate daily infections by solving this system numerically with a population size of 1000 and observe infections through a Poisson distribution. Our task is to estimate the infection rate \(\) and the initial proportion of infected \(i_{0}=\) given only observed data, with uniform priors on both parameters.

We simulate daily infections using known parameters and model observed infections with a Poisson distribution. Our task is to estimate the infection rate \(\) and the initial proportion of infected \(i_{0}\) given only observed data, with uniform priors. Our generative model is

\[ i_{0}&(0,1) (0,1)\\ C_{t}&=_{0}^{t} cS( )d X_{t}=C_{t}-C_{t-1} Y_{t}(X_{t }).\] (13)

For our approximate posterior, we use Beta distributions for \(i_{0}\) and \(\), as they represent proportions in \(\).

We compared RBBVI with NUTS  and LSS samplers . Table 1 (the table is provided in Appendix A) reveals distinct trade-offs between the methods. Under limited computational resources, our approach demonstrates strong performance, achieving superior coverage compared to nonparametric alternatives. The result highlights the key advantage of our parametric approach: efficient uncertainty quantification with restricted computational resources. However, as computational budgets increase, gradient-based methods like NUTS show their strengths through superior MSE values, while LSS also achieves excellent coverage. These results position our method as particularly valuable when computational efficiency is crucial or gradient information is unavailable. Meanwhile, we acknowledge that gradient-based methods like NUTS should be preferred when gradient information and substantial computational resources are available.

### Inferring Neural Network training hyperparameter

In this experiment, we tune the learning rate for training a simple neural network on the MNIST dataset . We cast this as an inverse problem, defining our forward generative model as training the network with a given learning rate \(\)

\[p(y,X,)=p(y|X,)p()p(X)\]

with \(p(X)\) uniform and

\[p(y|X,)(-L(y_{v},f_{}(X_{v}))),\] (14)

where

\[f_{}=f_{w()}, w()=}L(y_{t},f_{w}(X_{t})).\] (15)

Here, \(L\) is the loss function, \(X_{v},X_{t},y_{v},y_{t}\) are validation and training splits, and \(f_{w}\) is the neural network with parameters \(w\). The function \(f_{}\) represents the trained neural network, where the optimal parameters \(w()\) depend on the learning rate \(\) used during training. Crucially, each forward model evaluation requires training a network with the given learning rate.

We compare our method against several hyperparameter optimization techniques: Bayesian Optimization with Gaussian Processes (GP)  using different kernels: Radial Basis Function (RBF) and Matern kernel  with \(=1.0\) and \(=2.5\), Tree-structured Parzen Estimator (TPE) ; and running inference over the same probabilistic model with LSS sampler .

The results in Table 2 (the table is provided in Appendix A) show that our method achieves comparable or better performance than advanced Bayesian optimization techniques with significantly fewer tuning steps. It provides direct uncertainty quantification for the optimal learning rate, enabling effective ensemble training. Our approach balances exploration and exploitation better than other methods, achieving high accuracy for individual models and ensembles. The detailed analysis of the experiment is provided in Appendix B.

## 5 Conclusion

In this work, we introduced RBBVI and demonstrated its application in two key areas: obtaining a posterior distribution over the unknown parameters of an ordinary differential equation (ODE) and tuning the learning rate of a neural network. Future research could investigate the assumption of a joint prior distribution over the parameters as mentioned in Equation 1. Additionally, our method could be utilized as a subroutine within larger probabilistic models. Notably, our algorithm was used as an inference subroutine in RxInfer.jl  in our experiments.