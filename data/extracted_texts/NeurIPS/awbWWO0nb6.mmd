# Characterization of Overfitting in Robust Multiclass Classification

Jingyuan Xu

Weiwei Liu

School of Computer Science, Wuhan University

National Engineering Research Center for Multimedia Software, Wuhan University

Institute of Artificial Intelligence, Wuhan University

Hubei Key Laboratory of Multimedia and Network Communication Engineering, Wuhan University

{jingyuanxu777,liuweiwei863}@gmail.com

Correspondence to: Weiwei Liu <liuweiwei863@gmail.com>.

###### Abstract

This paper considers the following question: Given the number of classes \(m\), the number of robust accuracy queries \(k\), and the number of test examples in the dataset \(n\), how much can adaptive algorithms robustly overfit the test dataset? We solve this problem by equivalently giving near-matching upper and lower bounds of the robust overfitting bias in multiclass classification problems.

## 1 Introduction

Learning models that are robust to adversarial perturbations has garnered significant research attention in recent years. However, despite this progress, a pervasive issue continues to plague these models, namely _robust overfitting_. A common approach to overcome overfitting is to divide the dataset into a training set, and a holdout (or test) set. Nonetheless, modern machine learning is _adaptive_ in its nature. Prior information about a model's performance on the test set inevitably influences future modeling choices in extensive experiments and competitions. Recent studies have shown that excessive reuse of the holdout dataset can also leads to overfitting in non-robust setting , and a body of subsequent work has quantitatively explored this phenomenon in the framework of _perfect test label reconstruction_. Accordingly, in this paper we attempt to address the following questions: Can adaptive behavior result in overfitting in an adversarial setting? If so, by how much can adaptive algorithms robustly overfit the test dataset?

To solve these questions, we generalize the framework of perfect reconstruction to the adversarial setting, and analyze the average case performance that can be achieved by an adaptive algorithm, denoted as \(h_{}(k,n,m)\), where \(k,n,m\) represents the number of robust accuracy queries, test samples and classes, respectively. This term equivalently measures the maximum level of robust overfitting in a multiclass classification problem. In this paper, we derive both upper and lower bounds of \(h_{}(k,n,m),\) and demonstrate that our upper bounds and lower bounds are matching within logarithmic factors when \(n\) and the distribution of test dataset features \(_{}\) are fixed.

### Related works

**Perfect test label reconstruction.** The question of perfect test label reconstruction in non-robust setting dates back to decades ago . The developments on studying biasing results due to adaptive reuse of the test data start with the work of , which broadly fall in the field of adaptive data analysis .  first pose the problem of characterizing the overfitting bias as a function of \(k,n,m\), but they fail to give upper and lower bounds on the same order of \(m,\) which is left as an openquestion .  close this question and determine the amount of overfitting possible in multiclass classification. The theory on quantitative overfitting analysis in adversarial setting remains blank.

**Adversarial robustness.** It has been shown that deep neural networks are fragile to imperceptible distortions in the input space . Perhaps the most common method to improve adversarial robustness is adversarial training [15; 16]. Theoretically, [17; 18; 19; 20] study the PAC learnability of adversarial robust learning problem, and [21; 22] study adversarial robustness under self-supervised learning. [23; 24] investigates the adversarial robustness from the perspective of ordinary differential equations. Besides,  analyze the trade-off between robustness and fairness,  study the worst-class adversarial robustness in adversarial training.

## 2 Summary of our results

In the remainder of this article, \(,\) and \(^{d}\) represent the sets of real numbers, natural numbers and \(d\)-dimensional vectors over \(\), respectively. We denote the set \(\{1,,n\}\) (for \(n\)) by \([n]\). If \(A\) and \(B\) are sets, we use \(B^{A}\) to denote the collection of all mappings from \(A\) to \(B\) and \(2^{A}\) to denote the power set of \(A\), that is the collection of all subsets of \(A\). We denote the indicator function by \(\{\}\), that is \(1\) if an event happens and \(0\) otherwise. If \(\) is a distribution, we use \(()\) to denote the support of \(\), which is defined by the closure of the set of possible values of a random variable having \(\) as its distribution. Besides, \(\|\|_{p}\) represents the \(_{p}\) norm and \(d_{p}(,)\) represents the distance function induced by \(_{p}\) norm. Finally, we use big tilde notations \(,\) and \(\) as variants of big O notations that ignores logarithmic factors.

### Problem formulation

Let \(=^{d}\) be the instance space and \(=\{1,,m\}\) be the label space. Let \(S=\{(x_{i},c_{i})\}_{i=1}^{n}\) denote the test set, whose features, denoted as \(_{S}=\{x_{1},,x_{n}\}\), are independent and identically distributed (i.i.d.) according to some distribution \(_{}\) on \(^{2}\). For simplification, we use \(=(c_{1},,c_{n})\) to describe the vector of test set labels. Let \(f:\) be a function, its _robust accuracy_ on the test set with respect to (w.r.t.) a small perturbation \(: 2^{}\) is defined by

\[_{}(f;S)_{i =1}^{n}\{ x^{}(x_{i}),f(x^{})=c_{ i}\}.\]

The perturbation \((x)\) is required to be nonempty, so some choice of \(x^{}\) is always available. This paper focuses the case when the perturbation is the \(p\)-norm ball with a small radius \(r\), i.e. \((x)=\{z:\|z-x\|_{p} r\}\) for some \(p 1\). \(r=0\) gives the _identity perturbation_: \((x)\{x\}\). Note that in this case, the definition of robust accuracy is reduced to standard (non-robust) accuracy.

In this work, we mainly study the robust overfitting attack algorithms, which do not have access to the test set \(S\). Instead, they have query access to robust accuracy of the model on \(S\), that is, for any classifier \(f\), the algorithm is able to obtain the value \(_{}(f;S)\). We refer to this access as a _query_. A _k-query algorithm_\(\) makes \(k\) queries \(f_{1},,f_{k}\) on \(S\), and based on the values of \(_{S}\) and \(_{}(f_{1};S),,_{}(f_{k};S)\), \(\) outputs a classifier \(=(S)\). We say a \(k\)-query algorithm \(\) is based on hypothesis class \(^{}\) if \(f_{1},,f_{k}\). The performance of the algorithm on \(S\) is measured by

\[h_{}(;S)[_{ }(;S)],\]

where the expectation is over the algorithm's randomization. It is also of interest to ask the performance of an algorithm when \(\) are drawn according to some distribution \(_{}\) over \([m]^{n}\). Let \(=_{}_{Y},\) for an algorithm \(\), define its performance w.r.t. \(\) by

\[h_{}(;)}_{S }h_{}(;S).\]

And we evaluate the algorithms under the assumption that they do not have any prior knowledge about the test labels. That is, the prior distribution of test labels is uniform over all possible labeling:

\[h_{}()}_{S_{S }^{n}_{m}^{n}}h_{}(;S),\]where \(_{m}^{m}\) denotes the uniform distribution over \([m]^{n}\). Since the best robust accuracy is \(1/m\) without making any queries (\(k=0\)), \(h_{}(;S)-1/m\) measures how much \(\) robustly overfits \(S\). The goal of this paper is to find the largest robust overfitting possible for a multiclass classification problem. So we define the performance that is achievable by an algorithm after making \(k\) queries on any \(S\) by

\[h_{}(k,n,m)_{}h_{}(),\]

and we are interested in the value of \(h_{}(k,n,m)-1/m,\) or \(h_{}(k,n,m)\) equivalently. In the rest of this paper, we aim at deriving bounds of \(h_{}(k,n,m)\) for given \(k,n\) and \(m\).

### Our main results

Our bounds on \(h_{}(k,n,m)\) have two different regimes, which can be summarized as the following theorem.

**Theorem 1** (Informal).: _let \(_{}\) be the distribution of test sample features. For \(k=(n/m),\)_

\[_{_{}}(n)[+(})] h_{}(k,n,m)+ {O}(}).\]

_For \(k=(n/m),\)_

\[_{_{}}(n)[+ ()] h_{}(k,n,m)+ (),\]

_where \(_{_{}}(n) 1\) and is monotonically decreasing w.r.t. \(n\)._

When \(=\), our upper bounds match the best known upper bounds , while our lower bounds differ from the known optimal lower bounds  by a factor \(_{_{}}(n)\). Since overfitting in the context of robust learning has some requirements on the test samples (e.g. the well-separated property for different classes ), we may not able to ensure a non-trivial lower bound on \(h_{}(k,m,n)\) for some \(_{}\). Intuitively, \(_{_{}}(n)\) measures how easily to sample \(n\) 'good' (for robust overfitting) test data features from \(_{}\). The specific form of \(_{_{}}(n)\) is presented in Section 3.2. Note that for a fixed size of \(S\) whose features are i.i.d. according to a fixed distribution \(_{}\), the upper and lower bounds are matching up to a logarithmic factor, that is,

\[h_{}(k,n,m)=(+} ), k=(n/m),\]

and

\[h_{}(k,n,m)=(+),  k=(n/m)\]

for any fixed \(n\) and \(_{}\).

### Overview of our techniques

Next, we give a brief overview of proof techniques used to obtain the main results. We first note that throughout this paper we use the notion of corrupted hypothesis , which transforms the formulation of robust accuracy to a non-robust one thus greatly simplifying the proofs. The definition of corrupted hypothesis is presented in the beginning of Section 3.

* We establish the upper bounds via minimum description length argument, following closely a proof of an analogous result by  for non-robust setting. Note that their bounds can be viewed as trivial upper bounds of \(h_{}(k,n,m)\) since non-robust accuracy always upper bounds robust accuracy. We tighten the bounds by considering the query class of an algorithm. The details are presented in Theorem 2.
* To obtain the lower bounds, we propose computationally efficient algorithms for two regions of \(k\) respectively. The algorithms are modified from , who study the worst case overfitting bias in a non-robust setting. To take the perturbation of features into account, we extend their queries to the whole feature space \(\) by assigning each label of \(x\) to be the 'closest' label in \(_{S}\) in the sense of \(p\)-norm. The theoretical guarantees are given in Theorems 3 and 4.

### Discussion

Although we equivalently derive both upper bounds and lower bounds of robust overfitting bias, there remains a gap in finding whether the lower and upper bounds can match up to a constant factor. In non-robust setting, it is proven that the \(\) factor in upper bounds can be removed for \(k=1\). It is interesting to ask if this result holds for adversarial robust setting and, more ambitiously, for all \(k\). We leave it as an open question.

## 3 Proofs of main results

To make the proofs more readable, we introduce the notion of corrupted hypothesis .

Consider a given hypothesis \(f:\). A labeled adversarial sample \((,y)\) is classified correctly if \( f^{-1}(y)\). A labeled example \((x,y)\) is classified correctly if \((x) f^{-1}(y)\). Let \(}=\{\},\) where \(\) is the special "always wrong" output, i.e. \(y\) for every \(y}\). We define the mapping \(_{}:^{}}^ {}\):

\[_{}(f)(x)=y,&(x) f^{-1}(y),\\ ,&.\]

The corrupted set of hypotheses induced by perturbation \(\) is then defined by \(}=\{_{}(f):f\}.\)

### Upper bounds

The upper bounds relies on the following theorem, showing in a probabilistic view that finding a classifier in some given hypothesis class with desired robust accuracy requires learning many bits about the test labeling.

**Theorem 2**.: _Let \(m,n,k\) be positive integers and \(_{m}^{n}=_{}^{n}_{m}^{n},\) where \(_{m}^{n}\) denotes the uniform distribution over \([m]^{n}\). Let \(^{}\) be a hypothesis class and \(\) be an perturbation. Then there exists a constant \(C_{} 1\) satisfying: For every \(\)-based \(k\)-query algorithm \(,>0,b=k(n+1)1+(1/),\) we have_

\[_{S_{m}^{n},f=(S)}\{_{ }(f;S)}}{m}+2} \}, k<,\]

_and_

\[_{S_{m}^{n},f=(S)}\{_{ }(f;S)}}{m}+\} , k.\]

Proof.: For any fixed hypothesis \(f,\) denote \(_{}(f)\) by \(\). By the definition of corrupted hypotheses, for every \(i[n],\)

\[_{x_{i}_{}}\{ x^{} (x_{i}),f(x^{})=c_{i}\} =_{x_{i}_{}}\{(x)=c_{i}\}\] \[=_{x_{i}_{}}\{(x_{i})=c_{i} |(x_{i})\}_{x_{i}_{}}\{(x_{i})\}\] \[+_{x_{i}_{}}\{(x_{i})= c_{i}|(x_{i})=\}_{x_{i}_{}}\{(x_{i})=\}.\]

We observe that \(\{(x_{i})\}\) is a constant related to \(f,\) let \(C(f)\{(x_{i})\}\), since \(\{(x_{i})=c_{i}|(x_{i})=\}=0,\) we have

\[_{x_{i}_{}}\{ x^{} (x_{i}),f(x^{})=c_{i}\}=_{x_{i}_{}}\{(x_{i})=c_{i}|(x_{i})\}_{x_{i} _{}}\{(x_{i})\}=.\]

This implies that \(\{ x^{}(x_{i}),f(x^{})=c_{i}\}\) is a Bernoulli random variables with bias \(.\) By the Chernoff bound, for any fixed \(f,\)

\[_{S_{m}^{n}}\{_{i=1}^{n}\{  x^{}(x_{i}),f(x^{})=c_{i}\}+\} e^{-}{2C(f)+m}}.\]Denote \(_{f}C(f)\) by \(C_{}\), then

\[\{_{}(f;S)}}{m}+\}\{_{}(f;S)+\} e^{-}{2C_{}+m}} e^{-}{2C_{ }+m}},\] (1)

holds for every \(f\). Consider the execution of \(\) with responses of robust accuracy fixed to some sequence of values \(=(_{1},,_{k})\{0,1/n,,1\}^{k}\). Denote the resulting predictor by \(^{},\) its output distribution is fixed, hence by Eq.(1), we have

\[_{S_{m}^{n},f=^{}}\{_{}(f;S)}}{m}+ \} e^{-}{2C_{}+m}}.\]

Denote the set of all possible values of \(\) by \(V.\) For every test set \(S,\) the accuracy oracle outputs some responses in \(V.\) Therefore,

\[_{S_{m}^{n},f=(S)}\{_{}(f;S)}}{m}+\}\] \[ _{ V}_{S_{m}^{n},f=^{ }}\{_{}(f;S)}}{m}+\}\] \[ (n+1)^{k} e^{-}{2C_{}+m }}.\]

Now if \(,\) then by definition of \(b\), \(.\) It follows that \(m 2 2C_{},\) hence \(}{2C_{}+m}\) and

\[(n+1)^{k} e^{-}{2C_{}+m}} e^ {k(n+1)-}=e^{}=.\]

If \(<,\) in this case \(2}.\) We obtain that \(m<2,\) thus \(}{2C_{}+m}}{4}\) and

\[(n+1)^{k} e^{-}{2C_{}+m}} e^ {k(n+1)-}{4}}=e^{}=,\]

and we complete the proof. 

The corollary below follows immediately from Theorem 2, which gives the upper bounds of \(h_{}(k,n,m)\).

**Corollary 1**.: _Let \(m,n,k\) be positive integers and \(\) be a perturbation, then_

\[h_{}(k,n,m)++2}, k<\]

_and_

\[h_{}(k,n,m)+, k \]

Proof.: Denote \(_{}(f;S) X.\) Substitute \(=1/n\) in Theorem 2 and notice that \(C_{} 1\) for any hypothesis class \(\), hence for \(k<\) we have

\[\{X+2}\} .\] (2)

Let \(c=+2},\) it remains to show \(X c+1/n.\) It is trivial for \(c 1.\) For the case that \(c<1,\) let \(P_{X}\) be the probability distribution of \(X,\) by the definition of expectation,

\[X=_{0}^{1}XdP_{X}=_{0}^{c}XdP_{X}+_{c}^{1}XdP_{X} c _{0}^{c}dP_{X}+_{c}^{1}dP_{X} c+,\]

where we use the fact that \(_{c}^{1}dP_{X} 1/n\) by Eq.(2) in the last step. The case of \(k\) can be proved using similar arguments, and we complete the proof.

### Lower bounds

The lower bounds of \(h_{}(k,n,m)\) are derived from two designed algorithms, namely \(^{small}\) and \(^{big}(C)\). \(^{small}\) is divided into two cases based on whether \(k=1,\) and the precise analysis is presented in Theorem 3. \(^{big}(C)\) accepts a parameter \(C\) for calculating an intermediate variable, and we gain our Theorem 4 by setting \(C=_{_{}}(n)\). Finally, the lower bounds of \(h_{}(k,n,m)\) follow from

\[h_{}(k,n,m)=_{}h_{}() h_{ }(^{small}^{big}(_{_{ }}(n))).\]

To simplify the expression, we first introduce some definitions. For each \(_{S}^{n},\) define

\[_{S}=\{x j_{1} j_{2}[n]d_{p}(x,x_{j_{1}})=d_{p}(x,x_{j_{2}})=_{i[n]}d_{p}(x,x_{i})\},\]

and

\[_{_{}}(n)=_{_{S}( _{}^{n})}_{(_{S})}dP_{_ {}},\]

where \((_{S})=\{(x)|x_{S}\}\) and \(P_{_{}}\) is the distribution function of \(_{}\).

With these definitions, we present that:

1. Let \(f^{1}(x)\) be the all one query, i.e. \(f^{1}(x)=1, x\).
2. Output \(\) that \[(x)=1& x,_{}(f^{1},S) 1/m, \\ 2& x,\]

**Theorem 3**.: _Let \(n m\) and \(_{m}^{n}=_{}^{n}_{m}^{n}\). Then for \(1 k 1+n/2m,\)_

\[h_{}(^{small},_{m}^{n})_{}}(n)}{m}+_{ }}(n) k}{mn}}.\]

Proof.: Case: \(k=1:\) For \(l\{1,,m\}\), let \(N_{l}\) be the number of examples with label \(l\). Since the labels are uniformly distributed and \(\) is always a constant predictor, \((N_{1},,N_{m})\) follows a multinomial distribution with parameters \((n;,,)\). Then by the construction of \(\), the number of robustly and correctly predicted labels is then given by \(N_{1} 1\{N_{1} n/m\}+N_{2} 1\{N_{1}<n/m\},\) and the expected robust accuracy is given by

\[}_{_{m}^{n}}[h_{}(^{ small};S)]=}[N_{1} 1\{N_{1} n/m\}+N_{2} 1 \{N_{1}<n/m\}].\]

We conclude that

\[}_{_{m}^{n}}[h_{}(^{ small};S)]+}\]

by citing the following lemma:

**Lemma 1** (Lemma 4 in .).: _Let \(n m 2\). If \((N_{1},,N_{m})\) is distributed according to a multinomial distribution with parameters \((n;,,),\) then_

\[}[N_{1} 1\{N_{1} n/m\}+N_{2} 1\{N_{1}<n/m \}]+}.\]

Case: \(k>1:\) For a fixed \(S,\) and hence, a fixed \(=^{small}(S),\) for each \(l\{1,,m,\},\) let \(N_{i,l}^{S}\) be the number of examples in \(B_{i}\) s.t. \(_{}()(x)=l\). Since whether \(_{}()(x)\) equals to '\(\)' is only depends on the distribution of \(x\), we have that \((N_{i,1}^{S},,N_{i,m}^{S},N_{i,}^{S})\) follows a multinomial distribution with parameters \((|B_{i}|;,,,1-C(S)),\) where \(C(S)=\{_{}()(x)\}\).

Then our predictions robustly and correctly predicts \(\{N_{i,1}^{S},N_{i,2}^{S}\}\) examples in \(B_{i}\) and hence \(h_{}(;S)=_{i=1}^{k-1}\{N_{i,1}^{S},N_{i,2}^{S}\}\). We will show it later that

\[[\{N_{i,1}^{S},N_{i,2}^{S}\}]|}{m} +|}{m}}.\]

By summing over the blocks, we can lower bound the expected total number of robustly correct predictions made by \(^{small}:\)

\[_{i=1}^{k-1}[\{N_{i,1}^{S},N_{i,2}^{S}\}] +} {C(S) n}{m}+}.\]

To obtain a lower bound of \(C(S)\) that is independent of the choice of \(S,\) for each \(S\) we define \(g_{S}\) satisfying:

\[g_{S}(x)=c_{i}& x_{S},\\ g_{S}(x_{j^{}})&j^{}=_{i[n]}d_{p}(x,x_{j})& \]

and let \(_{n}=\{g_{S}:S((_{}) )^{n}\}\). It is easy to see that \(^{small}(S)_{n}\) for all \(S.\) Hence by the definition of \(_{_{}}(n),\) we have

\[_{_{}}(n)=_{g_{S}_{n}} \{_{}(g_{s})(x)\} C(S).\]

We conclude that

\[_{i=1}^{k-1}[\{N_{i,1}^{S},N_{i,2}^{S}\}] _{}}(n) n}{m}+_{}}(n) nk}{m}}.\]

Normalizing by \(n\) proves the desired result.

It remains to lower bound \([\{N_{i,1}^{S},N_{i,2}^{S}\}]\). Since \(N_{i,1}^{S}\) and \(N_{i,2}^{S}\) follow a binomial distribution with parameters \((|B_{i}|;)\), \(E[N_{i,1}^{S}+N_{i,2}^{S}]=|}{m}\) for all \(S.\) Let \(N^{}\) be an independent copy of \(N_{i,2}^{S}\). \(N_{i,1}^{S}\) and \(N^{}\) are negatively correlated, hence

\[[|N_{i,1}^{S}-N_{i,2}^{S}|][| N_{i,1}^{S}-N^{}|] [N_{i,1}^{S}-|B_{i}|]\] \[[(N_{i,1}^{S}-|B_{i} |)^{2}]}{2}}\] \[|}{2m}(1-)}\] \[|}{4m}}\]

For all \(S\).

Then we conclude that

\[\{N_{i,1}^{S},N_{i,2}^{S}\}=^{S}+N_{i,2}^{S}}{2}+^{S}-N_{i,2}^{S}|}{2}|}{m}+|}{m}},\]

which completes the proof. 

We then present \(^{big}(C)\) and the theoretical analysis for \(k=(n/m)\).

1. Let \(t:=1+\)
2. Define query \(f_{1},,f_{k}\) satisfying: 1. For \(1 j t,f_{1}(x_{j}),,f_{k}(x_{j})\) are uniformly chosen from all sequences in \([m]^{k}\) that have each element in \([m]\) appearing exactly \(k/m\) times. 2. For \(j>t,f_{i}(x_{j})=\) for all \(i=1,,k\). 3. For \(x_{S},f_{i}(x)=f_{i}(x_{j^{}})\) for each \(i[k],\) where \(j^{}=_{i[n]}d_{p}(x,x_{j})\).
3. Output \(\) such that: \[(x_{j})=_{y[m]}_{i:f_{i}(x_{j})=y}_{}(f_{i};S)^{3},&1 j t,\\ 1,&j>t.\] and predicts the rest of \(x\) by \((x)=(x_{j^{}}),\) where \(j^{}=_{i[n]}d_{p}(x,x_{j})\).

**Theorem 4**.: _Let \(k>_{X}}(n)}\) and let \(_{m}^{n}=_{}^{n}_{m}^{n},\)_

\[h_{}(^{big}(_{_{}}(n)), _{m}^{n})_{}}(n)}{m}+_{}}(n) k}{144n m}.\]

Proof.: For \(l[m]\), let \(A_{l}\) be the total number of robustly and correctly predicted examples by all the queries that predict the first examples as '\(l\)', i.e.

\[ A_{l}:=& n_{i: x^{ }(x_{1}),f_{i}(x^{})=l}_{}(f_{i} ;S)=_{i: x^{}(x_{1}),f_{i}(x^{})=l} _{j=1}^{n}\{f_{i}(x^{})=y_{j}, x^{} (x_{j})\}\\ =& W_{0}\{l=y_{1}\}+_{i: x ^{}(x_{1}),f_{i}(x^{})=l}_{j=2}^{t}\{ f_{i}(x^{})=y_{j}, x^{}(x_{j})\},\] (3)

where \(W_{0}\) is the number of queries that predict the whole perturbation set \((x_{1})\) as '\(y_{1}\)'.

Let

\[M_{l}:=_{i: x^{}(x_{1}),f_{i}(x^{})=l}_{j =2}^{t}\{f_{i}(x^{})=y_{i}, x^{}(x_{ i})\},\]

then for \(l y_{1},\)

\[A_{y_{1}}-A_{l}=W_{0}+M_{y_{1}}-M_{l}.\]

Since \(\{f_{i}(x^{})=y_{j}, x^{}(x_{j})\}\) are independent for \(j j^{},\) and are negatively associated across \(i\) for any fixed \(j,\) therefore, by the Chernoff bound, it satisfies that for \(<1\)

\[\{|M_{l}-[M_{l}]|> \,[M_{l}]\} 2(-}{3}\, [M_{l}]).\]

Suppose \(\) satisfies that \(\,[M_{l}]\) and \(}{3}\,[M_{l}] 3 m,\) then by Eq. (3) and the union bound

\[\,\{*{arg\,max}_{l[m]}A_{l} y_{1}\}< (m-1)},\]

and with probability at least \(3/4,(x_{1})=y_{1}.\)

We now derive the bounds on \(.\) To this end, we first need to bound \([M_{l}].\) Define \(_{n}\) as that in the proof of Theorem 3. Let \(}_{n}\) denotes the corrupted set of \(_{n}.\) For each \(}_{t},\) define \(_{}:}\) that takes value '\(\)' on \((x_{j})\) for \(j=t+1,,n\) and coincides with \(\) otherwise, that is,

\[_{}(x)=,&x_{j=t+1,,n}(x_{j}),\\ (x),&.\]

Let \(_{n}\) be the set which contains all such \(_{}.\) It is easy to see that \(_{}(f_{1}),,_{}(f_{k})_ {n}.\) Note that \(_{g_{n}}\{g(x)\}=_{ _{}}(n),\) we have

\[_{}}(n)}{m}\{f_{i}(x^{ })=y_{j}, x^{}(x_{j})\}.\]

Now for each \(l\) by the linearity of expectations,

\[(t-1)_{}}(n)}{m} [M_{l}](t-1).\]

Thus \(\,[M_{l}]\) holds for

\[}{(t-1)k}=,\]

and \(}{3}\,[M_{l}] 3 m\) holds for \(}{_{_{}}(n) (t-1)k}}.\) Therefore, we can find a suitable \(\) whenever

\[}{_{_{}}(n)(t-1)k}} <1.\]

If we choose \(t=1+_{}}(n)k}{36 m}\) and \(k>_{}}(n)}m m,\) the aforementioned conditions hold. Note that \(\{_{}()\}_{ _{}}(n),\) hence the expected number of robustly and correctly predicted labels is at least

\[ t+_{}}(n)}{m}(n-t) _{}}(n) n}{m}+t(-_{}}(n)}{m})_{}}(n) n}{m}+_{}}(n) k}{144 m},\]

which completes the proof. 

## 4 Conclusion

In this work, we study the overfitting bias in the context of robust multiclass learning. We formally define the adaptive algorithms in an adversarial setting and analyze the average case performance that can be achieved by an adaptive algorithm. Upper bounds and lower bounds are both derived, and are matching within logarithmic factors when the number of test samples and distribution of data features are fixed.