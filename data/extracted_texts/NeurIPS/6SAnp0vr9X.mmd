# Scale-invariant Optimal Sampling for Rare-events

Data with Sparse Models

 Jing Wang

Department of Statistics

University of Connecticut

Storrs, CT 06269

jing.7.wang@uconn.edu

&HaiYing Wang

Department of Statistics

University of Connecticut

Storrs, CT 06269

haiying.wang@uconn.edu

&Hao Helen Zhang

Department of Mathematics

University of Arizona

hzhang@math.arizona.edu

###### Abstract

Subsampling is effective in tackling computational challenges for massive data with rare events. Overly aggressive subsampling may adversely affect estimation efficiency, and optimal subsampling is essential to mitigate the information loss. However, existing optimal subsampling probabilities depends on data scales, and some scaling transformations may result in inefficient subsamples. This problem is more significant when there are inactive features, because their influence on the subsampling probabilities can be arbitrarily magnified by inappropriate scaling transformations. We tackle this challenge and introduce a scale-invariant optimal subsampling function in the context of sparse models, where inactive features are commonly assumed. Instead of focusing on estimating model parameters, we define an optimal subsampling function to minimize the prediction error, using adaptive lasso as an example to outline the estimation procedure and study its theoretical guarantee. We first introduce the adaptive lasso estimator for rare-events data and establish its oracle properties, thereby validating the use of subsampling. Then we derive a scale-invariant optimal subsampling function that minimizes the prediction error of the inverse probability weighted (IPW) adaptive lasso. Finally, we present an estimator based on the maximum sampled conditional likelihood (MSCL) to further improve the estimation efficiency. We conduct numerical experiments using both simulated and real-world data sets to demonstrate the performance of the proposed methods.

## 1 Introduction

Rare-events data refer to binary-response data that are highly imbalanced, i.e., the number of zeros (a.k.a "controls" or "negative instances") are possibly hundreds or thousands of times as large as the number of ones (a.k.a. "cases" or "positive instances"). This type of data is common in various fields, such as medicine, natural science, political science, and social science, where examples of rare events can be rare diseases, natural disasters, wars, and financial crises, respectively. Modern technologies also prompt us to pay more attention to rare-events data. For example, in modern online recommendation systems, clicks are usually rare events compared with nonclicks. Statistical analyses, including parameter estimation and inferences, pose unique challenges for rare-events data because of high imbalance. In addition, rare-events data often involve sparse models. For instance,rare diseases might be linked to a limited number of key genes. Therefore, researchers frequently adopt sparse models in genome-wide association studies for analyzing rare diseases. A different yet related example is the use of deep neural networks to predict click-through rates in modern online recommendation systems. These networks are typically overparameterized, necessitating methods that balance rare-events data with the sparsity of the underlying models. Data balancing is a popular approach to overcome challenges caused by imbalanced data and is usually accomplished through subsampling the zeros  or oversampling the ones . In addition, rare-events data are often massive in order to obtain an adequate number of ones, and computation is demanding. Therefore, we focus on the subsampling approach since it addresses the imbalance issue and reduce the computational burden simultaneously.

It is shown in  that the efficiency of parameter estimation is essentially determined by the number of ones for rare-events logistic regression, and subsampling does not reduce the estimation efficiency as long as sufficient zeros are kept. In case of excessive removal of zeros,  developed an optimal sampling approach to minimize information loss. However, the optimal sampling probabilities in  are scale-dependent, which may lead to inefficient results. Figure 1 illustrates the issue using a simulated example, with details in Section D.1 of the appendix. We generate the data from the same logistic regression model and transform one of the covariates with different scales \(s=0.01,0.1,1,10\), and \(100\). Then we apply two optimal subsampling methods in , labeled with "A-OS" and "L-OS" in Figure 1. It is observed that the prediction errors of A-OS and L-OS are significantly impacted by the data scaling. The A-OS may perform similarly to the Uni (simple random sampling or uniform sampling) in Figure 0(a) when \(s=0.01\); so is the L-OS in Figure 0(b) when \(s=100\). This scale-dependent issue is not specific to logistic regression and rare-events data in ; it is a wide concern in literature for various data types and models, including but not limited to . In this paper, we propose a scale-invariant optimal subsampling method to overcome the issue. It is labeled "P-OS" in Figure 1.

The scale-dependence issue can seriously impact variable selection results for sparse models, where true parameters are zero for inactive covariates. In this case, inactive variables may be arbitrarily transformed without changing the underlying model, but the A-OS or L-OS would be highly influenced and may lead to misleading results. To resolve this issue, we investigate scale-invariant optimal subsampling in the context of variable selection, for which one main goal is to distinguish active and inactive features.

Penalty-based feature selection methods are widely used. Specifically, the adaptive lasso is a popular choice due to its oracle properties, convexity, and practical ease of implementation [see 30, 28]. While penalization methods have been used for bias reduction in rare-events analysis , variable selection for rare-events data has not been investigated. Conducting effective variable selection is difficult in the context of rare-events data analysis, mainly due to the scarcity of information available for ones. An inaccurate variable selection result can subsequently impact both the effectiveness of optimal subsampling and the efficiency of parameter estimation. In this paper, we address the challenge of variable selection in the context of rare-events data. First, we propose the full data adaptive lasso and study its theoretical properties. Next, we introduce a novel subsampling estimator that seamlessly combines penalty-based variable selection and optimal sampling into one unified framework for rare-events data. The implementation of the adaptive lasso requires a pilot estimator to construct

Figure 1: Prediction errors with different scale transformation of the same model. (a): with non-sparse parameter \((-1,-1,-0.01,-0.01,-0.01,-0.01)^{}\). (b): with sparse parameter \((-1,0,0,0,0,0)^{}\).

data-dependent weights for covariates. Given that optimal sampling also relies on pilot estimates [see 23, 1], the adaptive lasso emerges as a natural choice for conducting variable selection method in the context of subsampled rare-events data. We validate the new estimators by proving their oracle properties and also develop an efficient algorithm to facilitate their practical implementation when handling massive real-world data sets. In summary, our main contributions are listed as follows:

* We propose scale-invariant optimal subsampling to enhance parameter estimation and variable selection. Existing optimal subsampling methods are scale-dependent, which may lead to unreliable or misleading results.
* We define adaptive lasso and establish its oracle properties for rare-events data, which show that the asymptotic variances are determined by the number of ones in the data and the active features in the model.
* We present a practical subsampling algorithm based on optimal probabilities that significantly reduces the computational burden and accelerates the optimization for penalty-based feature selection methods.

The rest of the paper is organized as follows. Section 2 introduces the model setup. Section 3 investigates nonuniform sampling and variable selection tailored for rare-events data. We propose new methods to construct scale-invariant optimal probabilities. Section 4 discusses theoretical properties of the MSCL estimator and presents a two-step algorithm to implement the proposed methods. Section 5 conducts numerical experiments on simulated and real data sets. Section 6 concludes the paper. Proofs and mathematical details are presented in the appendix.

## 2 Background and model setup

We use the subscript \({}_{ t}\) to indicate the true parameters. For a \(p\)-dimensional vector \(\), we use \(x_{(i)}\) to represent its \(i\)-th element. For an index subset \(\{i:1,2,...,p\}\), we use \(_{()}\) to denote the subvector of \(\), whose elements correspond to the indexes in \(\). Furthermore, we use \(^{ 2}\) to denote \(^{ T}\), use "\(\)" to denote convergence in distribution, use "\(\)" to denote convergence in probability, and use "\(\)" to denote convergence almost surely. We use \(\) to denote an identity matrix of a suitable dimension and use \(\) to denote a vector of zeros of a suitable dimension.

Let \((_{1},y_{1}),(_{2},y_{2}),...,(_{N},y_{N})\) denote \(N\) sample points from the joint distribution of \((,y)\), where \(\{_{i}\}_{i=1}^{N}\) denote the \(p\)-dimensional predictors and \(\{y_{i}\}_{i=1}^{N}\) the binary responses. Assume that the probability of \(y\) being a one (\(y=1\)) given \(\) is

\[p(;_{ t}):=(y=1|)=+ f(;_{ t})}}{1+e^{_{ t}+f(;_{ t})}}= ;_{ t})}}{1+e^{g(;_{ t})}},\]

where \(_{ t}=(_{ t},_{ t}^{ T})^{ T}\) is the vector of true parameters and \(f(;_{ t})\) is a smooth function of \(_{t}\). For rare-events data, \(N_{1} N_{0}\), where \(N_{1}=_{i=1}^{N}y_{i}\) is the number of ones (i.e. \(y_{i}=1\)) and \(N_{0}=N-N_{1}\) is the number of zeros (i.e. \(y_{i}=0\)). Following the model setup used in , we assume that \(_{ t}-\) as \(N\), which implies that, under appropriate moment conditions,

\[}{N_{0}}=\{p(;_{ t})\}}{1- \{p(;_{ t})\}}+o(1)=\{e^{_{ t }+f(;_{ t})}\}+o(1) 0,\ .\] (1)

Under this assumption, the asymptotic variance of the full data maximum likelihood estimator (MLE) is of order \(1/N_{1}\) instead of \(1/N\), indicating that the estimation efficiency is determined by the number of rare ones. Therefore, we can keep all the ones and sample the zeros to save computational costs. There could be a variance inflation due to aggressive subsampling, and  developed optimal subsampling functions to reduce the variance inflation. Specifically, the authors proposed non-uniform optimal sampling functions under the A- and L-optimality criteria, respectively, as follows: \(^{ scale}_{ A-OS}() p(;_{ t})\| ^{-1}(;_{ t})\|\) and \(^{ scale}_{ L-OS}() p(;_{ t})\| (;_{ t})\|\), where \(=\{e^{f(;_{ t})}^{ 2}(;_{ t})\}\) and \((;)\) denotes the derivative of \(g(;)\) with respect to \(\). However, the sampling functions \(^{ scale}_{ A-OS}()\) and \(^{ scale}_{ L-OS}()\) proposed in  depend on the scale of \(\), and may not perform well for certain measurement scale of \(\). For example, if \(g(;_{ t})=_{ t}+^{ T}_{ t}\), then \(^{ scale}_{ L-OS}()\) is proportional to \(1+\|\|\), which will be influenced by the scale of \(\). Similarly, scale changes in \(\) may also change \(^{ scale}_{ A-OS}()\), although the impact may not be in the same direction, as demonstrated in Figure 1. Besides parameter estimation, variable selection is another important topic, which has not been studied in the literature on rare-events data. This work aims to fill this gap.

## 3 Nonuniform sampling with variable selection for rare-events data

The adaptive lasso [30; 28] is a popular variable selection method because it has oracle properties and is easy to implement. We define the full data adaptive lasso for rare-events data as

\[}^{ adp}_{ mle}:=_{}\{_{i=1 }^{N}[y_{i}g(_{i};)-\{1+e^{g(_{i};)}\}] -_{N}_{j=1}^{p}|}{|_{ pl(j)}|^{ }}\},\] (2)

where \(_{N}\) and \(\) are tuning parameters, and \(}_{ pl}\) is a consistent pilot estimator of \(_{t}\). In practice, it is common to set \(=1\). In the literature, iterative algorithms such as coordinate descent are commonly used to solve the adaptive lasso . However, their computational demand can become prohibitive when dealing with massive data. It is feasible to alleviate the computational burden by subsampling zeros and create a smaller subset of data for adaptive lasso. To be specific, consider Algorithm 1.

```
1:For \(i=1,...,N\):
2:if\(y_{i}=1\)then
3: include \((_{i},y_{i})\) in the subsample;
4:else
5: Compute \((_{i})\) and generate \(u_{i} U\);
6:if\(u_{i}(_{i},y_{i})\)then
7: include \((_{i},y_{i})\) and record \((_{i})\) in the subsample;
8:endif ```

**Algorithm 1** Poisson Subsampling algorithm

The inclusion probability in Algorithm 1 for the \(i\)th observation is \((_{i},y_{i})=y_{i}+(1-y_{i})(_{i})\), where \(\) is the baseline sampling rate for the zeros and \(()>0\) satisfies \(\{()\}=1\). Let the subsample from Algorithm 1 be \(\{_{i}^{ sub},y_{i}^{ sub}\}_{i=1}^{N_{ sub}^{*}}\), which is biased since \((_{i},y_{i})\)'s depend on the responses. We introduce an Inverse Probability Weighting (IPW) adaptive lasso estimator to correct for the bias, defined as

\[}^{ adp}_{ w}:=_{}\{_{i=1}^{ N_{ sub}^{*}}^{ sub}g(_{i}^{ sub};)- \{1+e^{g(_{i}^{ sub};)}\}]}{(_{i}^{ sub},y_ {i}^{ sub})}-_{N}_{j=1}^{p}|}{|_{ pl (j)}|^{}}\}.\] (3)

To save space, we put the general assumptions used throughout this paper in Section B.1 of the appendix. We use \(\) to denote the set of indexes of active variables, i.e., \(=\{j:_{ t(j)} 0\}\) and \(^{c}\) to denote the set of indexes of inactive variables, i.e., \(^{c}=\{j:_{ t(j)}=0\}\). We first study the asymptotic properties of \(}^{ adp}_{ w}\) in the following theorem.

**Theorem 1**.: _Let \(}_{ pl}\) be a consistent pilot estimate such that \(_{N}/(}|_{ pl(j)}|^{})}{{}}\) for \(j^{c}\). Under Assumptions 1-4, if \(_{N}/} 0\), then the IPW adaptive lasso estimator defined in (3) has the following properties:_

1. _Consistency in variable selection: The estimated active set_ \(}_{ w}:=\{j:^{ adp}_{ w(j)} 0\}\) _satisfies that_ \(_{N}(}_{ w}=)=1\)_._
2. _Asymptotic normality: The estimator of the active parameter vector satisfies that_ \[}_{ w()}^{-1/2}(}^{ adp}_{  w()}-_{ t()})(,),\] _where_ \(_{ w()}=\{e^{f(;_{1})} \}_{()}^{-1}_{ w()}_{( )}^{-1}=\{e^{f(;_{1})}\}\{ _{()}^{-1}+c_{ sub()}\}\)_,_ \(_{()}=\{e^{f(;_{1})}_{( )}^{ 2}(;_{1})\}\)_,_ \(_{ sub()}=_{()}^{-1}\{;_{1})}}{()}_{()}^{ 2}(;_{1})\}_{()}^{-1},\ c=\{e^{f( ;_{1})}_{()}^{ 2}(;_{1})\}_{( )}^{-1}=\{e^{f(;_{1})}_{( )}^{ 2}(;_{1})\}_{()}^{-1}= \{e^{f(;_{1})}_{()}^{ 2}(;_{1})\}_{( )}^{-1}=\{e^{f(;_{1})}_{( )}^{ 2}(;_{1})\}_{()}^{-1}= \{e^{f(;_{1})}_{()}^{ 2}(;_{1})\}_{( )}^{-1}=\{e^{f(;_{1})}_{( )}^{ 2}(;_{1})\}_{()}^{-1}=\{e^{f(;_{1})}_{()}^{ 2}(;_{1})\}_{( )}^{\(_{N}e^{_{}}/\), and \(_{()}(;_{})\) consists of the elements of gradient vector \((;_{})\) with indexes in the active set \(\).

**Remark 1**.: _Theorem 1 shows that the estimation efficiency of \(}^{}_{()}\) is predominantly determined by the number of ones instead of the full data size. The term \(c_{()}\) is the variation inflation due to subsampling. The full data adaptive lasso in (2) correspond to the scenario with \(=1\) and \(()=1\), for which \(c=_{N}e^{_{}}/=0\). Intuitively, \(c\) can be interpreted as the imbalance rate in the subsample. If we include sufficient zeros (\(c=0\)), the subsampling does not reduce the estimation efficiency of \(}^{}_{()}\)._

From Theorem 1, we see that there maybe information loss reflected as an inflated variance if \(c 0\). To minimize the information loss due to sampling, we derive optimal functions as follows, where \(^{}_{}()\) corresponds to the A-optimality criterion  and \(^{}_{}()\) corresponds to the L-optimality criterion  in design of experiments. Here, the A-optimality minimizes the trace of the asymptotic variance of \(}^{}_{()}\); the L-optimality focuses on the asymptotic variance of a linearly transformed estimator \(_{()}}^{}_{()}\), which is proportional to \(_{()}\). The A-optimality criterion has a more direct interpretation, while an advantage of the L-optimality criterion is that the resulting optimal function is often faster to calculate.

**Proposition 1**.: _The A-optimal function that minimizes \((_{()})\) is_

\[^{}_{}()=;_{ })\|_{()}^{-1}_{()}(;_{})\|}{\{p(;_{}) \|_{()}^{-1}_{()}(;_{ })\}}.\] (4)

_The L-optimal function that minimizes \((_{()})\) is_

\[^{}_{}()=;_{ })\|_{()}(;_{})\|}{ \{p(;_{})\|_{()} (;_{})\}}.\] (5)

Unlike the optimal sampling function in , \(^{}_{}()\) (or \(^{}_{}()\)) relies only on the active variables. This implies that a first-step pilot estimator given by the adaptive lasso algorithm can benefit from sparse estimation methods when calculating optimal probabilities. For example, employing the standard lasso can effectively eliminate a large number of inactive variables to facilitate the computation of optimal \(^{}_{}()\) and \(^{}_{}()\). However, in practice, pilot estimators are often obtained from a small subsample size, introducing additional uncertainty. Therefore, it becomes crucial to exercise caution and be conservative by over-selecting variables during the first step to prevent the exclusion of important variables. As a consequence, although theoretically \(^{}_{}()\) and \(^{}_{}()\) do not depend on inactive variables, they are affected by inactive variables in practical implementations.

### Scale invariant optimal function

As discussed in Section 1, scaling dependent optimal probabilities may impact the performance of variable selection in practice. To address the issue, we propose to construct a scale invariant optimal function by focusing on the prediction error of an estimator \(}\), defined below.

\[(})=_{}[\{p(; {})-p(;_{})\}^{2}]= \{p(;})-p(;_{})\}^ {2}_{},\]

where \(_{}\) is the probability measure of \(\). The probability term \(p(;_{})\) involves both the covariates \(\) and the parameter vector \(_{}\), and it often does not depend on the scale of \(\). For example, in the logistic regression model, the value \(p(;_{})\) is only related to \(^{}_{}\). If we change the scale of \(x_{(j)}\), the value of \(_{}\) would change accordingly under the same data-generating model and so \(p(;_{})\) remains the same. Thus, re-scaling covariates would not affect this criterion. In the following, we give an optimal function that minimizes the prediction error.

**Theorem 2**.: _Under the assumptions of Theorem 1, for the IPW adaptive lasso estimator defined in (3), its prediction error satisfies_

\[N_{1}e^{-2_{}}(}^{}_{ ()})^{-1}\{e^{f(; _{})}\}^{}_{()}^{1/ 2}_{()}^{-1}_{()}_{( )}^{-1}_{()}^{1/2}_{()}_{( )}.\] (6)_where \(_{()}(,)\), and \(_{()}=[e^{2f(;_{1})}_{()}^{ 2}(,_{1})]\). The optimal function that minimizes the asymptotic mean of the prediction error in (6) is given as_

\[_{}^{}()=;_{1}) \|_{()}^{}_{()}^{-1}_{()}(;_{1})\|}{[p(;_{1})\|_{()}^{}_{() }^{-1}_{()}(;_{1})\|]}.\] (7)

We refer this prediction oriented criterion as P-optimality criterion. As we expect, the optimal function in (7) is unaffected by the scale of \(\) for a class of functions \(g\). The following proposition proves that \(_{}^{}()\) is invariant to rescaling of \(\).

**Proposition 2**.: _If \(g(;)\) satisfies that for every non-singular matrix \(\) there exists a non-singular matrix \(\), such that_

\[g(;^{})=g(;),\] (8)

_then, \(_{}^{}()\) is invariant to scale changes of \(\)._

**Remark 2**.: _The condition in (8) is not restrictive and it is quite easy to satisfy. One simple example of \(g(;)\) that satisfies the condition is a linear function \(g(;)=+^{}\), which corresponds to the logistic regression. The condition is also satisfied by more complex models. For example, consider an L-layer neural network_

\[g(;^{1},^{2},...,^{L},^{1},...,^{L})=f^{L} (f^{L-1}(...f^{1}(^{}^{1}+^{1}))^{}+^{L}),\]

_where \(^{l}\) are the weights and \(^{l}\) are the biases in each layer, \(l=1,2,...,L\). If \(\) is rescaled to \(\), we can change \(^{1}\) to \((^{T})^{-1}^{1}\) so that the value of \(g\) does not change. That is_

\[g(;(^{T})^{-1}^{1},^{2},...,^ {L},^{1},...,^{L})=f^{L}(f^{L-1}(...f^{1}(^{}^{1}+^{1}))^{}+^{L})\] \[=g(;^{1},^{2},...,^{L},^{1},..., {b}^{L}).\]

## 4 Penalized MSCL estimator

The IPW estimator in (3) is not the most efficient estimator, because it assigns smaller weights for more informative data points with larger sampling probabilities. To improve the estimation efficiency, we propose the penalized MSCL estimator for variable selection given as

\[}_{}^{}:=*{arg\,max}_{ }\{_{i=1}^{N_{}^{}}[y_{i}^{ }g(_{i}^{};)-\{1+e^{g(_{i}^{ },)+l_{i}^{}}\}]-_{N}_{j=1}^{p} |}{|_{(j)}|^{}}\},\] (9)

where \(l_{i}^{}=-\{(_{i}^{})\}\). The MSCL estimator introduced in  is defined as the minimizer of the objective function in (9), excluding the penalization term. In this paper, we extend this approach by proposing a penalized MSCL estimator to ensure model sparsity. We present the oracle properties of the penalized MSCL estimator in the following theorem.

**Theorem 3**.: _Let \(}_{}\) be a consistent pilot estimate such that \(_{N}/(}|_{(j)}|^{}) {}\) for \(j^{c}\). Under Assumptions 1-3 and 5, if \(_{N}/} 0\), the estimator based on MSCL function with adaptive lasso penalty defined in (9) have the following properties:_

1. _Consistency in variable selection: The estimated active set_ \(}_{}:=\{j:_{(j)}^{} 0\}\) _satisfies that_ \(_{N}(}_{}=)=1\)__
2. _Asymptotic normality: The estimator of the active parameter vector satisfies that_ \[}_{()}^{-1/2}(}_{ ()}^{}-_{()} )(,),\] (10) _where_ \(_{()}=\{e^{f(;_{i}) }\}_{()}^{-1}\) _and_ \(_{()}=[;_{i})}_{()}^{ 2}(;_{i})}{1+c^{-1}()e^{f(;_{i})}}]\)_._

The penalized MSCL estimator has the same asymptotic variance as the MSCL estimator under the true model, indicating that it is more efficient than the penalized IPW estimator . We prove this by comparing the asymptotic variances and present the result in the following theorem.

**Theorem 4**.: _If the asymptotic variances \(_{()}\) for \(}_{()}^{}\) in (2) and \(_{()}\) for \(}_{()}^{}\) in (9), are finite, i.e., \(0<_{()},_{()}<\), then \(_{()}_{()}\), where the inequalities hold in the sense of Loewner ordering._

Thus, we give a practical two-step algorithm based on the penalized MSCL estimator. Since the optimal sampling functions contain unknown values and the adaptive lasso penalty also requires a consistent pilot estimator to build weights, it is natural to combine optimal sampling and the adaptive lasso into one unified framework. We recommend to use the lasso for pilot estimation. One reason is that it does estimation and variable selection simultaneously, and excluding some inactive variables improves the estimation accuracy of optimal probabilities. This also reduces the computational burden for subsequent steps. Another reason is that the lasso estimator tends to include more variables in practice and therefore has a low risk of excluding important variables in the pilot step. We present an outline of the practical implementation in Algorithm 2. More details are given in Section C.

```
1: First stage screening: * Take a pilot sample of expected sample size \(N_{}\) using \(\{(y_{i})=_{0}+y_{i}(_{1}-_{0})\}_{i=1}^{N}\) and obtain a lasso penalized MSCL pilot estimator and an estimated active set \(}_{}\). * Calculate approximate optimal sampling probabilities \(\{(_{i},y_{i})=y_{i}+(1-y_{i})(x_{i})\}_{i=1}^ {N}\) based on (4), (5), or (7).
2: Second stage screening: Use Algorithm 1 with the estimated optimal sampling probabilities to obtain a subsample of expected sample size \(N_{}\) and compute the adaptive lasso penalized MSCL estimator based on \(}_{}\). ```

**Algorithm 2** Two-step subsampling adaptive lasso algorithm

## 5 Numerical experiments

In this section, we use numerical experiments on both simulated and real data to investigate the performances of our proposed optimal subsampling and variable selection procedures.

### Simulation design

We consider a logistic regression with \(g(;)=+^{}\) and the following three true parameters \(_{}\) of dimension 50. We set different \(_{}\) so that the proportion of ones is \(0.005\):

1. **Case A:**\(_{}=(0.75,0.75,_{7}^{},0.75,0,0.75,0,75, {0}_{37}^{})^{}\) and \(_{}=-5.8\).
2. **Case B:**\(_{}=(3,-2,_{7}^{},0.85,0,-0.75,_{ 38}^{})^{}\) and \(_{}=-6.2\).
3. **Case C:**\(_{}=(3,2,_{7}^{},0.85,_{40}^{})^{}\) and \(_{}=-7.5\).

Here, \(_{d}\) denotes the zero vector of dimension \(d\). We use \(p_{}\) and \(p_{^{c}}\) to denote the number of active and inactive variables, respectively, and assume that \(\) is a normal random vector. The active components \(x_{(,j)}\), \(1 j p_{}\) of \(\) have variances 0.25 and the inactive components \(x_{(^{c},j)}\), \(1 j p_{^{c}}\)of \(\) have variances \(100/p_{^{c}}^{3},100/(p_{^{c}}-1)^{3},...,100/3^{3},100 /2^{3},100/1^{3}\). The correlation between the \(i\)-th and \(j\)-th elements of \(\) is \(0.5^{[i-j]},1 i,j p\). We repeat our experiments \(S=500\) times generating \(N=500000\) data points in each run and use a pilot sample of size \(N_{}=500\) for obtaining pilot estimates based on the lasso. We consider uniform sampling, the full data lasso, and the full data adaptive lasso for comparison. We use the 5-fold cross-validation and Bayesian information criterion (BIC) to determine the tuning parameter \(\) for the lasso and the adaptive lasso, and choose \(=1\) for the adaptive lasso.

#### 5.1.1 Estimation and prediction efficiency

We present the empirical median squared error (eMSE) for parameter estimation in Figure 2. All optimal sampling estimators outperform the uniform sampling. As the sampling rate increases, sampling estimators outperform the full data lasso estimator eventually in all of the three cases. Among the three optimal subsampling methods, \(}_{}^{}\) performs better than the other two subsampling methods.

Figure 3 shows the results of the empirical median squared prediction error (eMSPE). Similarly to the results of eMSE, optimal sampling estimators perform better than the uniform sampling, meaning optimal sampling results in less information loss. It is possible that sampling estimators outperform the full data lasso estimator as the sampling rate increases, despite that the latter uses all of the data. In general, \(}_{}^{}\) performs the best among the three optimal subsampling algorithms.

#### 5.1.2 Variable selection and computational complexity

In this section, we discuss the results of variable selection in terms of the first stage screening and the second stage screening. Table 1 presents the mean numbers of selected variables in Case C, where the numbers in the parentheses are the corresponding standard errors. Results for Cases A and B are similar so are put in Table 4 of the appendix.

While the first stage screening significantly reduces the dimension in Table 1, it indeed includes inactive variables as expected. In the second stage screening, the mean numbers of selected variables are close to the true numbers of active variables for all subsampling methods. However, the mean number of selected variables from uniform sampling is smaller than the true number of active variables especially when the sampling rate is low. This indicates that the second-stage screening of uniform sampling may exclude active variable. We present the rates of missing active variables in Table 2 for Case C. It shows that uniform sampling has higher rates of excluding active variables than optimal subsampling procedures, so optimal sampling may be preferable in practice. Results for Cases A and B are similar and are put in Section E.1. We also investgate the rates of selecting the true model in that section.

  \(\) & first-stage & Uni & A-OS & L-OS & P-OS \\ 
0.0025 & 13.27(0.34) & 2.84(0.02) & 2.97(0.02) & 2.96(0.02) & 2.96(0.02) \\
0.005 & 12.46(0.32) & 2.94(0.02) & 3.04(0.03) & 3.05(0.03) & 3.06(0.03) \\
0.0075 & 12.76(0.33) & 2.97(0.01) & 3.04(0.02) & 3.03(0.02) & 3.03(0.02) \\
0.01 & 12.81(0.34) & 2.96(0.01) & 3.03(0.02) & 3.02(0.01) & 3.02(0.01) \\  

Table 1: Mean number of selected variables in Case C

Figure 3: eMPSE of estimated probability with different sampling rates.

Figure 2: eMSE for different true parameters with different sampling rates.

#### 5.1.3 Computational time

We present the mean computational times of different algorithms in Table 3. Our codes are written in the _julia_ programming language  and implemented on a Linux workstation. The lasso pathes are solved with _Lasso.jl_. As shown in Table 3, subsampling algorithms significantly reduce the computational times compared with full data estimators. Although optimal sampling requires to calculate sampling probabilities, they use only about 0.77% of the computational time that the full data adaptive lasso requires. As we discussed in Section C.2, optimal sampling algorithms reduce both sample size and the data dimension. Therefore, the computational cost of the coordinate decent algorithm, which often requires a large number of iterations, is significantly reduced.

### Real data

We evaluate the performances of proposed estimators on two real data sets.

1. **Covtype data set:** It is available at https://archive.ics.uci.edu/ml/datasets/covertype, with \(N=581012\) observations and 54 covariates - 10 being quantitative and 44 being qualitative with dummy coding. We drop the 14th and 54th columns to avoid exact colinearity of the dummy variables. Our goal is to classify whether the forest cover type is Cottonwood/Willow (labeled as 1) or not (labeled as 0). The proportion of Cottonwood/Willow is 0.473%, which is highly imbalanced.
2. **Font data set:** It is available at https://archive.ics.uci.edu/ml/datasets/Character+Font+Images, with 0.50% of the \(N=832670\) responses being the GADUGI font. The first 10 covariates are about the value, size, and style of the characters and there are additional 400 pixel values of the \(20 20\) images. We remove the 4th, 9th, and 10th covariates because they are constants.

For both data sets, we apply Algorithm 2 on the logarithmic-transformed data. We use pilot samples of size \(N_{}=1000\) for the covtype data and \(N_{}=1500\) for the font data due to its higher dimension. Since we do not know the true parameter for real data, we use area under the curve (AUC) to measure the performances of subsampling algorithms. We repeat the experiment for \(S=500\) and compute the empirical median AUC using the full data. The results are summarized in Figure 4. As shown in Figure 4, nonuniform sampling outperforms uniform sampling in general. There is one case for font data set that \(}_{}^{}\) is worse than the uniform sampling when the sampling rate is high. For the covtype data set, among the three estimators based on optimal sampling, \(}_{}^{}\) performs the best and \(}_{}^{}\) is worst. For the font data set, \(}_{}^{}\) and \(}_{}^{}\) are similar, and \(}_{}^{}\) based on the scale invariant optimal sampling function is significantly better.

## 6 Conclusion and limitations

In this paper, we investigated the problem of scale-invariant optimal subsampling in the context of variable selection for rare-events data. We derived optimal probabilities based on the A- and L

  \(\) & Uni & A-OS & L-OS & P-OS \\ 
0.0025 & 0.168(0.017) & 0.086(0.013) & 0.088(0.013) & 0.084(0.013) \\
0.005 & 0.100(0.013) & 0.068(0.011) & 0.066(0.011) & 0.066(0.011) \\
0.0075 & 0.066(0.011) & 0.046(0.009) & 0.048(0.010) & 0.046(0.009) \\
0.01 & 0.068(0.011) & 0.052(0.010) & 0.054(0.010) & 0.054(0.010) \\  

Table 2: Rates of excluding active variables (false negative rate) in Case C

  Case & Uni & A-OS & L-OS & P-OS & A-lasso (full) & Lasso (full) \\  A & 0.29 & 1.09 & 0.91 & 1.06 & 129.62 & 112.97 \\ B & 0.31 & 1.23 & 1.20 & 1.27 & 129.89 & 122.40 \\ C & 0.31 & 1.02 & 0.93 & 1.00 & 130.33 & 121.29 \\  

Table 3: Mean computational time (seconds)optimality criteria, and discussed their limitations. Furthermore, we proposed scale-invariant optimal probabilities based on prediction errors to overcome the limitations. Both analytical and numerical results show the desirable properties of the proposed methods.

Our investigation has the following limitations.

* Our proposed criterion optimizes the probabilities by minimizing the asymptotic mean squared error in estimating rare-event probabilities. While this prioritizes the accuracy of estimation, it puts less emphasis on the quality of variable selection. Further research is needed to devise optimal probabilities that focus on variable selection performance metrics.
* Our theoretical analysis is based on asymptotic properties, with optimal probabilities defined through the asymptotic normality. Although our results may hold for sufficiently sparse models, they may not generalize to cases where the model is dense or over-parameterized, because asymptotic normality may no longer be applicable. Therefore, an important direction for future research is to study the non-asymptotic properties of our estimators, such as prediction error bounds. Non-asymptotic behaviors are particularly of interest in high-dimensional regimes.
* We employ Lasso as the pilot estimator. However, other variable selection methodologies, such as sure independence screening, can also be considered. Exploring the impact of different pilot estimators on our method's performance represents another avenue for future investigations.
* We assume that the underlying full model is correctly specified and possesses a sparse structure. Our analysis does not account for model misspecification. Further research is required to address scenarios where the model is possibly misspecified or where the number of features vastly exceeds the number of observations.