# Efficient Discrepancy Testing for Learning

with Distribution Shift

 Gautam Chandrasekaran

UT Austin

&Adam R. Klivans

UT Austin

&Vasilis Kontonis

UT Austin

&Konstantinos Stavropoulos

UT Austin

&Arsen Vasilyan

UC Berkeley

gautamc@cs.utexas.edu. Supported by the NSF AI Institute for Foundations of Machine Learning (IFML).

###### Abstract

A fundamental notion of distance between train and test distributions from the field of domain adaptation is discrepancy distance. While in general hard to compute, here we provide the first set of provably efficient algorithms for testing _localized_ discrepancy distance, where discrepancy is computed with respect to a fixed output classifier. These results imply a broad set of new, efficient learning algorithms in the recently introduced model of Testable Learning with Distribution Shift (TDS learning) due to Klivans et al. (2023).

Our approach generalizes and improves all prior work on TDS learning: (1) we obtain _universal_ learners that succeed simultaneously for large classes of test distributions, (2) achieve near-optimal error rates, and (3) give exponential improvements for constant depth circuits. Our methods further extend to semi-parametric settings and imply the first positive results for low-dimensional convex sets. Additionally, we separate learning and testing phases and obtain algorithms that run in fully polynomial time at test time.

## 1 Introduction

Distribution shift remains a central challenge in machine learning. While practitioners may exert some level of control over a model's training distribution, they have far less insight into future, potentially adversarial, test distributions. Developing algorithms that can predict whether a trained classifier will perform well on an unseen test set is therefore critical to the widescale deployment of modern foundation models.

A heavily-studied framework for modeling distribution shift is domain adaptation, where a learner has access to labeled examples from some training distribution, unlabeled examples from some test distribution and is asked to output a hypothesis with low error on the test distribution. Overthe last twenty years, researchers in domain adaptation and related fields  have established bounds for out-of-distribution generalization in terms of some type of distance between train and test distributions. By far the most commonly studied notion is discrepancy distance:

\[_{}(,^{})=_{f_{1 },f_{2}}*{}_{ }[f_{1}() f_{2}()]-*{ }_{^{}}[f_{1}() f_{2}( )]\]

Estimating or even testing discrepancy distance, however, seems difficult, as its definition involves an enumeration over all classifiers from some underlying function class (in Appendix F we give the first hardness result for computing discrepancy distance in general). As such, obtaining provably efficient algorithms for domain adaptation has seen little progress (none of the above works give polynomial-time guarantees).

In search of efficient algorithms for learning with distribution shift with certifiable error guarantees, recent work by  defined the _Testable Learning with Distribution Shift_ (TDS learning) framework. In this model (similar to domain adaptation), a learner receives labeled examples from train distribution \(\), _unlabeled_ examples from test distribution \(^{}\), and then runs a test. If the (efficiently computable) test accepts, the learner outputs \(h\) that is guaranteed to have low test error with respect to \(^{}\). No guarantees are given if the test rejects, but it must accept (with high probability) if the marginals of \(\) and \(^{}\) are equal. This framework has led to the first provably efficient algorithms for learning with distribution shift for certain concept classes (for example, halfspaces) .

It is straightforward to see that if algorithm \(\) learns concept class \(\) in the (ordinary) PAC/agnostic model, and we have an efficient _localized_ discrepancy tester for \(\), then \(\) is learnable in the TDS framework: simply apply the discrepancy tester to the output of \(\) and accept if this quantity is small. A dream scenario would be to augment all known PAC/agnostic learning algorithms with associated localized discrepancy testers. This is nontrivial in part because we cannot make any assumptions on the test distribution \(^{}\) (our test has to always accept or reject correctly). Nevertheless, our main contribution is a suite of new discrepancy testers for well-studied function class/training distribution pairs that unifies and greatly expands all prior work on TDS learning.

### Our Contributions

**Optimal Error Guarantees via \(_{1}\) Sandwiching.** The work of  followed a moment-matching approach to show that the existence of \(_{2}\) sandwiching polynomial approximators implies TDS learning up to a constant factor of the optimum error. Although their result implies TDS learning for several fundamental concept classes, the \(_{2}\) sandwiching requirement seems restrictive for classes such as constant-depth circuits or polynomial threshold functions. In Theorem 3.1, we provide TDS learning results in terms of the much more well-understood notion of \(_{1}\) sandwiching, resolving one of the main questions left open in . As such, we obtain exponential improvements for TDS learning constant depth circuits (AC\({}^{0}\)), and the first results for degree-2 polynomial threshold functions (see Table 1). Our result also bridges a gap between TDS learning and testable agnostic learning , since the latter has been known to be implied by \(_{1}\) sandwiching . Additionally, in the agnostic setting, the error guarantees we achieve are essentially optimal (as opposed to the constant-factor approximation by ).

**Universal TDS Learners.** A natural and important goal in TDS learning is to design algorithms that accept and make trustworthy predictions whenever the distribution shift is benign. In Theorems 4.2 and 5.1, we give the first TDS learners that are guaranteed to accept whenever the test marginal falls in a wide class of distributions that are not necessarily close to the training distribution (in say statistical distance) but, instead, share some mild structural properties. In the literature of testable agnostic learning, testers with relaxed completeness criteria are called universal . Our universal TDS learners accept all distributions that are sufficiently concentrated and anti-concentrated and work for convex sets with low intrinsic dimension (Theorem 4.2) and halfspace intersections (Theorem 5.1). Surprisingly, our algorithms can handle distributions that are heavy-tailed and multimodal, for which efficient (ordinary) agnostic learning algorithms are not known to exist. Our algorithms exploit localization guarantees from the training phase (e.g., subspace or boundary recovery) to relax the requirements of the testing phase.

**Fully Polynomial-Time Testing.** All of the TDS learners we provide consist of two decoupled phases. In the training phase, the algorithm uses labeled training examples to output a candidate hypothesis \(h\). The testing phase receives the candidate \(h\) and uses unlabeled test examples to decide whether to reject or accept and output \(h\). Separation of the two phases is an important feature of our approach, as it may be desirable for these tasks to be performed by distinct parties who have different amounts of available (computing) resources. Efficient implementations of the testing phase are of utmost importance, especially for potential users of large pre-trained models who need to certify that the candidate model at hand is safe to deploy. In Theorem5.1, we give _the first TDS learner for intersections of halfspaces that runs in fully polynomial test time_, and additionally improves the overall runtime of the previous state-of-the-art TDS learner for intersection of halfspaces by . In fact, our TDS learner's overall runtime is polynomial in the dimension \(d\), while the time complexity of the TDS learner given by  involved a factor of \(d^{O((1/))}\), where \(\) is the error parameter.

### Our Techniques

Our approach for designing TDS learners focuses on efficient algorithms for testing a new notion of localized discrepancy distance:

**Definition 1.1** (Localized Discrepancy).: Let \(\) be a distribution over \(^{d}\) and let \(,\{ 1\}^{}\) be hypothesis and concept classes respectively. Define neighborhood \(\) to be a function \(: 2^{}\). For \(\), the \((,)\)-localized discrepancy from \(\) to \(^{}\) is defined as:

\[_{,}(,^{ })=_{f()}^{}}{}[() f()]- {}{}[() f( )]\]

Testing localized discrepancy is clearly easier than testing the traditional (global) discrepancy distance, since global discrepancy is defined with respect to a supremum over all pairs of concepts within some given class, while localized discrepancy only depends on a small neighborhood of concepts around some given reference classifier \(\).

Assume for a moment that we have fixed a neighborhood function \(\) and have obtained a learner that always outputs a classifier close to the ground truth function \(f^{*}\) (i.e., \(f^{*}()\)). In this case, if we can test localized discrepancy, then we obtain a TDS learner as follows: output \(\) if the corresponding localized discrepancy is small and reject otherwise (recall \(\) is close to the ground truth for both training and test distributions).

The algorithmic challenge is finding a definition of neighborhood that admits both an efficient learner (for outputting a classifier close to the ground truth) and an efficient localized discrepancy tester. Smaller neighborhoods make the learning problem more difficult while larger neighborhoods make discrepancy testing more challenging.

Ultimately, the appropriate localized discrepancy relaxation of the testing phase depends on the guarantees one can ensure during training, which, in turn, depends on the properties of the concept class \(\) and the training distribution. For our main applications below we briefly describe the choice of neighborhood and the corresponding discrepancy tester. Note that we give a different discrepancy tester for each of the following cases.

**Classes with Low-Degree Sandwiching Approximators.** We show that the existence of degree-\(\)\(_{1}\)-sandwiching approximators for a class \(\) over \(^{d}\) turns out to be sufficient to design a localized discrepancy tester that runs in time \(d^{O()}\) where the notion of neighborhood is widest possible, i.e., \(()=\).6 In this case, the requirement for the training algorithm is minimal, as the ground truth \(f^{*}\) lies within \(\), which coincides with \(()\). The proposed tester is based on estimating the chow parameters of the reference hypothesis \(\) under the test marginal and checking whether they closely match the chow parameters of \(\) under the training marginal. For more details, see Section3.

**Convex Sets with Low Intrinsic Dimension.** For convex sets with few relevant dimensions, there are algorithms from standard PAC learning that guarantee approximate recovery of the relevant subspace. This guarantee allows one to choose a much stronger notion of neighborhood whilestill ensuring that \(f^{*}()\). The appropriate notion of neighborhood contains low-dimensional concepts whose relevant subspace is geometrically close to the subspace of the reference hypothesis. The corresponding tester exhaustively checks that the marginal \(^{}\) is well-behaved on the relevant subspace. For more details, see Section4.

**Intersections of Halfspaces.** For intersections of halfspaces, we prove a structural result stating that finding a hypothesis with low Gaussian disagreement with the ground truth \(f^{*}\) implies approximate pointwise recovery of the boundary of \(f^{*}\). It is therefore sufficient to check whether the marginal of the test distribution assigns unreasonably large mass near the boundary of the training output hypothesis \(\), which can be done in fully polynomial time. Any proper algorithm for learning halfspace intersections under Gaussian training marginals is then sufficient for our purposes. For more details, see Section5.

### Related Work

**Domain Adaptation.** In the past two decades, there has been a long line of research on generalization bounds for domain adaptation. The work of  introduced the notion of discrepancy distance, following work by , which used similar notions of distance between distributions. Other important notions of distribution similarity include bounded density ratios  and related notions . A type of localized discrepancy distance was defined by  and used to provide improved sample complexity bounds for domain adaptation. None of the above works give efficient (polynomial-time) algorithms. Here, we give a more general notion of localization and use it to obtain efficient and universal algorithms for TDS learning.

**TDS Learning and Related Models.** The framework of TDS learning was defined by , where it was shown that any class that admits degree-\(\)\(_{2}\)-sandwiching approximators can be TDS learned in time \(d^{O()}\) up to error \(O()\), where \(\) is the standard (and necessary) benchmark for the error in domain adaptation when the training and test distributions are allowed to be arbitrary. Here, we show that the relaxed notion of \(_{1}\)-sandwiching approximators suffices for TDS learning and we improve the error guarantee to nearly-match the information-theoretically optimal \(\) (see Section3). For intersections of halfspaces under Gaussian training marginals,  gave TDS learners with improved guarantees compared to those given by  through \(_{2}\) sandwiching. Our TDS learners for halfspace intersections are superior to the ones from  in terms of overall runtime, universality and test-time efficiency (see Section5).

Another related framework for learning with distribution shift is _PQ learning_, which was defined by . In PQ learning, the learner may reject regions of the domain where it is not confident to make predictions, but the total mass of these regions under the training distribution must be small. In fact, PQ learning is known to imply TDS learning (see ). However, the only known algorithms for PQ learning, which were given by , require access to oracles for learning primitives that are known to be hard even for simple classes (see ).

The framework of TDS learning is also related to testable agnostic learning, where the goal of the tester is to certify a near-optimal error guarantee. Testable agnostic learning was defined by  and there are several subsequent works in this framework . There are many important differences between TDS learning and testable agnostic learning, including the fact that, in testable agnostic learning, there is no distribution shift and that in TDS learning, the learner does not have access to labels from the distribution on which it is evaluated. In particular, testable agnostic learning is only defined in the presence of noise in the labels, while TDS learning is meaningful even when the labels are generated noise-free (i.e., realizable learning).

**PAC Learning.** In the standard framework of PAC learning, there is an abundance of algorithmic ideas and techniques that aim to achieve efficient learning, under various assumptions (see e.g., ). In this work, we make use of polynomial regression , dimension reduction techniques , as well as techniques for robustly learning geometric concepts , in order to obtain efficient TDS learners. In fact, our approach of designing TDS learning algorithms through localized discrepancy testing sheds a light on what kinds of guarantees from the training algorithms are desirable for learning in the presence of distribution shift. For example, we show that if approximate subspace recovery is guaranteed after training, then the discrepancy testing problem can be relaxed to an easier, localized version. Moreover, our results on TDS learning halfspace intersections emphasize the importance of proper learners in the context of learning with distribution shift.

## 2 Preliminaries

We use standard big-O notation (and \(\) to hide poly-logarithmic factors), \(^{d}\) is the \(d\)-dimensional euclidean space and \(_{d}\) the standard Gaussian over \(^{d}\), \(\{ 1\}^{d}\) is the \(d\)-dimensional hypercube and \((\{ 1\}^{d})\) the uniform distribution over \(\{ 1\}^{d}\), \(\) is the set of natural numbers \(=\{1,2,\}\) and \(^{d}\) denotes a vector with \(=(_{1},,_{d})\) and inner products \(\). See also Appendix A.

**Localized Discrepancy Testing.** Testing localized discrepancy (Definition1.1) is defined as follows.

**Definition 2.1** (Testing Localized Discrepancy).: For a set \(\) of distributions and \(\) over \(\) and \(>0\), we say that \(\) is a \((,)\)-tester for localized discrepancy from \(\) with respect to \(\), if, \(\), upon receiving \(\) and a set \(X\) of \(m_{}\) i.i.d. examples from some distribution \(^{}\) over \(\) satisfies:

1. (Soundness.) With probability at least \(3/4\): If \(\) accepts, then \(_{,}(,^{}) \).
2. (Completeness.) If \(^{}\), then \(\) accepts with probability at least \(3/4\).

For a concept class \(\), a distribution \(\) over \(\), \((0,1)\), we say that \(\) has \(\)-\(_{1}\)**sandwiching degree**\(\) with respect to \(\) if for any \(f\), there exist polynomials \(p_{},p_{}\) over \(\) with degree at most \(\) such that (1) \(p_{}() f() p_{}()\) for all \(\) and (2) \(_{}[p_{}()-p_{}()]\).

**Learning Setting.** For \(^{d}\), the learner is given labeled samples from a training distribution \(^{}_{^{}}\) over \(\{ 1\}\) with \(\)-marginal \(^{}_{}=\) and unlabeled examples from the marginal \(^{}_{^{}}\) of a test distribution \(^{}_{^{}}\) over \(\{ 1\}\). For a concept class \(\{\{ 1\}\}\), in the **realizable setting**, there is \(f^{*}\) that generates the labels for both \(^{}_{^{}}\) and \(^{}_{^{}}\). In the **agnostic setting**, the standard goal in domain adaptation is to achieve an error guarantee that is competitive with the information-theoretically optimal joint error \(=_{f}((f;^{}_{^{}})+(f;^{}_{ ^{}}))\), achieved by some \(f^{*}\), where \((f;^{}_{^{}})= _{(,)^{}_{^{}}}[y f()]\) (and similarly for \((f;^{}_{^{}})\)).

**Definition 2.2** (Universal TDS Learning).: Let \(\) be a concept class over \(^{d}\), \(\) a distribution over \(\) and \(\) some class of distributions over \(\). The algorithm \(\) is said to \(\)-universally TDS learn \(\) with respect to \(\) up to error \(\) and probability of failure \(\) if, upon receiving \(m_{}\) labeled samples from a training distribution \(^{}_{^{}}\) with \(\)-marginal \(\) and \(m_{}\) unlabeled samples from a test distribution \(^{}_{^{}}\), w.p. at least \(1-\), algorithm \(\) either rejects, or accepts and outputs a hypothesis \(h:\{ 1\}\) such that:

1. (Soundness.) If \(\) accepts, then the output \(h\) satisfies \((h;^{}_{^{}})\).
2. (Completeness.) If \(^{}_{}\) then \(\) accepts.

In the agnostic setting, parameter \(\) may depend on \(=(;^{}_{^{}},^{}_{^{}})\), whereas in the realizable setting, \(=(0,1)\). If \(=\{\}\), then we simply say that \(\)\(\)-TDS learns \(\) w.r.t. \(\).

Note that the success probability for TDS learning can be amplified through repetition  and we will consider \(=0.1\) unless specified otherwise.

## 3 Classes with Low Sandwiching Degree

Prior work on TDS learning by  showed that the existence of degree-\(\)\(_{2}\)-sandwiching approximators implies TDS learning in time \(d^{O()}\). A major question left open was whether the more traditional notion of \(_{1}\) sandwiching (see DefinitionC.1) suffices for TDS learning. We answer this question in the affirmative, and as a consequence we obtain exponential improvements in the runtime of TDS learning for constant depth circuits (AC\({}^{0}\)) and the first TDS learning results for degree-\(2\) polynomial threshold functions (see Table1). For more details, see Appendix C.

**Theorem 3.1** (\(_{1}\)-sandwiching implies TDS learning).: _Let \(,(0,1)\) and let \(\{\{ 1\}\}\) be a concept class such that the \(\)-approximate \(_{1}\)-sandwiching degree of \(\) under \(\) is \(()\)_Then, there exists a TDS learning algorithm for \(\) with respect to \(\) up to error \(+_{}+O()\) and fails with probability at most \(\) with time and sample complexity \((d^{()},)(1/)\)._

Note that prior work  had only obtained a bound of \(O()\) in the above error guarantee. Our techniques allow us to achieve the optimal dependence of simply \(\).

For Gaussian and uniform halfspaces, intersections and functions of halfspaces, as well as for decision trees over the uniform distribution, the \(_{2}\)-sandwiching approach of  provided TDS learning algorithms with similar runtime as the one obtained here, but their error guarantee was \(O()+\) instead of \(+_{}+\) (where \(_{}=_{f}(f;_{}^{})\)), which is the best known upper bound on the error, even information theoretically (see ).

**Localized discrepancy testing via Chow matching.** The improvements we obtain here are based on the idea of substituting the moment-matching tester of  with a more localized test, depending on a candidate output hypothesis \(\) provided by a training algorithm run on samples from the training distribution. In particular, we estimate the Chow parameters \(_{_{}^{}}[()^{}]\) for all low-degree monomials \(^{}=_{i=1}^{d}_{i}^{_{i}}\) and reject if they do not match the corresponding quantities \(_{}[()^{ }]\) under the training marginal. We obtain the following result.

**Proposition 3.2** (Informal, see Theorem C.3).: _For any class \(\) with low sandwiching degree under \(\), the low-degree Chow matching tester is a tester for localized discrepancy for the neighborhood \(()=\), i.e., it certifies that \(_{_{}^{}}[ {f}() f()]_{}[ () f()]+\) for all \(f\)._

**Proof Outline.** The main observation for obtaining the localized discrepancy testing result is that the disagreement between two functions is a linear function of their correlation, i.e., \(2\,_{_{}^{}}[ () f()]=1-_{ _{}^{}}[()f()]\), and, because \(f\), it is sandwiched by two polynomials \(p_{},p_{}\), which implies \(_{_{}^{}}[ {f}()f()]_{_{ }^{}}[()p_{}()]-_{_{}^{}}[p_{ }()-p_{}()]\). The latter quantity can be certified to be close to the corresponding quantity under the training marginal \(\) by Chow (and moment) matching.

Although the notion of neighborhood we require here is quite generic, it is sufficient to provide significant improvements over prior work. The discrepancy tester is localized in the sense that it certifies properties of the tested marginal distribution that are related to a particular candidate hypothesis \(\), but actually considers the whole concept class \(\) to be inside the neighborhood of \(\). Since the concept \(f^{*}\) that achieves \(=_{f}((f;_{}^{})+(f;_{}^{ }))\) lies within \(\) by definition, the total test error of \(\) is directly related to the error achieved by the training algorithm, whenever the Chow matching tester accepts.

## 4 Non-Parametric Low-Dimensional Classes

For non-parametric classes like convex sets over \(^{d}\), dimension-efficient TDS learning is impossible, even from an information-theoretic perspective  and \(2^{(d)}\) time is required even in the realizable setting. However, the best known upper bound on the \(_{1}\) sandwiching degree for convex sets is given indirectly by known results in approximation of convex sets by intersections of halfspaces (see, e.g.,  and references therein) and implies a TDS learning algorithm that runs in time doubly exponential in \(d\). Improving on the doubly exponential bound based on \(_{1}\)-sandwiching,

    & **Concept class** & **Training Marginal** & **Time** & **Prior Work** \\ 
1 & Degree-2 PTFs & \(_{d}\\ (\{ 1\}^{d})\) & \(d^{(1/^{})}\) & None \\ 
2 & Circuits of size \(s\), depth \(t\) & \((\{ 1\}^{d})\) & \(d^{O((s/))^{O(t)}}\) & \(d^{ O((s/))^{O(t)}}\) \\  & & & only for formulas \\   

Table 1: New results for TDS learning through \(_{1}\) sandwiching. For constant-depth formulas, we achieve an exponential improvement compared to  (which used \(_{2}\)-sandwiching), and our results work for circuits as well.

we provide a realizable TDS learner with singly exponential (in \((d)\)) runtime for convex sets that are \(\)-balanced, meaning that the Gaussian mass of both the interior and the exterior of the convex set is at least \(\). For convex sets with only a few relevant dimensions, our results actually give dimension-efficient TDS learners. For more details, see Appendix D.

**Theorem 4.1** (TDS Learning of Convex Subspace Juntas).: _For \((0,1/2)\), \(d,k\), let \(\) be the class of \(\)-balanced convex sets over \(^{d}\) with \(k\) relevant dimensions. There is an \(O()\)-TDS learner for \(\) with respect to \(_{d}\) in the realizable setting, which, for the training phase, uses \((d)2^{(k/)}\) samples and time and, for the testing phase, uses \((d)(k/)^{O(k)}\) samples and time._

We note that the balancing assumption is mild, since it can be tested by using examples from the training distribution and has been used in prior work on realizable TDS learning of intersections of halfspaces with respect to the Gaussian distribution .

**Universal TDS Learners.** Importantly, the TDS learner of Theorem 4.1 can be made universal with respect to a wide class of distributions that enjoy some mild concentration and anti-concentration properties. The cost is an exponential deterioration of the runtime of the training phase. In other words, finding a hypothesis with better performance on the training distribution suffices to give error guarantees for a wide range of test distributions, including, for example, multi-modal and heavy-tailed distributions. We believe that this result is interesting even from an information-theoretic perspective. In Table 2 in the appendix, we give a more precise trade-off between universality and training runtime.

Let \(_{k}\) be the class of distributions \(\) over \(^{d}\) such that \(_{}[()^{4}] C\) for any \(^{d-1}\) and for any subspace \(W^{d}\) of dimension at most \(k\), the marginal density of \(\) on \(W\) is upper bounded by \(C^{k^{2}}\), where \(C\) is some positive universal constant. Then the following is true.

**Theorem 4.2** (Universal TDS Learning of Convex Subspace Juntas).: _There is a \(_{k}\)-universal \(O()\)-TDS learner for \(k\)-dimensional \(\)-balanced convex sets over \(^{d}\) with respect to \(_{d}\) in the realizable setting, which, for the training phase, uses \((d)(2^{O(k^{2}/)})\) samples and time and, for the testing phase, uses \((d)k^{O(k^{3}/^{2})}\) samples and time._

We remark that the testing time for the universal TDS learner of Theorem 4.2 is still singly exponential in \((k)\), although the dependence on \(\) is exponentially worse. Having lower testing runtime is a desirable feature because the potential users of large machine learning models might have limited resources compared to those available during training. We provide a more thorough discussion about this feature in the following section.

**Cylindrical grids tester for localized discrepancy.** To obtain our TDS learning results of Theorems 4.1 and 4.2, we once more make use of the localized discrepancy testing framework. In particular, we identify low-dimensionality (Definition D.1) and boundary smoothness (Definition D.4) of the underlying concept class as sufficient conditions for efficient testing of localized discrepancy when the notion of localization is defined with respect to the subspace neighborhood (Theorem D.7). The subspace neighborhood \(_{s}()\) contains low-dimensional concepts \(f\) whose relevant subspace is geometrically close to the relevant subspace for \(\) (see Definition D.2). For TDS learning, we combine such testers with known learning algorithms for subspace recovery of low-dimensional convex sets (see, e.g.,  and Theorem D.13) to ensure that the training phase will output some hypothesis \(\) such that the ground truth \(f^{*}\) lies within \(_{s}()\).

In other words, we exploit the existence of training algorithms with stronger guarantees (i.e., approximate subspace recovery) than merely training error bounds, to relax the discrepancy testing problem to a low-dimensional localized version, while still providing end-to-end results for TDS learning. This relaxation not only improves the testing runtime, but also enables universality, since the localized discrepancy between two distributions can be much smaller than the global discrepancy between them (see also  and references therein).

The idea behind the localized discrepancy tester for the subspace neighborhood is to split the disagreement between \(\) and an arbitrary concept \(f_{s}()\) under the test distribution in two parts: (1) the disagreement between \(\) and a rotated version \(\) of \(f\) where the input \(\) is projected on the relevant subspace of the given hypothesis \(\) instead of the actual, unknown relevant subspace of \(f\) and (2) the disagreement between \(\) and \(f\). For part (2), we use the fact that the relevant subspace of \(f\) is geometrically close to the relevant subspace for \(\) (since \(f_{s}()\)). We conclude that and \(\) can only disagree far from the origin and, hence, testing that the test marginal is appropriately concentrated suffices to give the desired bound.

**Low-dimensional disagreement between concepts with smooth boundaries.** For part (1), we use the fact that the \(k\)-dimensional relevant subspace \(V\) for \(\) is known. We construct a grid on \(V\) and run tests to certify that the probability (under the test marginal) of falling inside each of the cells is not unreasonably large. In order to bound the size of the grid, we also test that the probability of falling far from the origin on the subspace \(V\) is appropriately bounded. We then argue that the disagreement region can be approximated reasonably well by discretizing with respect to an appropriately refined grid. To ensure that the discretization of the near-boundary region does not introduce a significant error blow-up, it is important that \(\) and \(\) have smooth boundaries (see Figure 2 in the appendix).

## 5 Fully Polynomial-Time Testers

Algorithms for TDS learning that are efficient in testing time, can be useful to check whether a pre-trained model can be applied to a particular population, without the need for overly expensive resources. Here, we focus on the class of balanced intersections of halfspaces (see subsectionE.9) and provide the first TDS learner for this class that runs in fully polynomial time during test time. Moreover, the proposed tester is universal with respect to a wide class of distributions that satisfy some concentration and anticoncentration properties.

Let \(_{1}\) be the class of distributions \(\) over \(^{d}\) such that for any \(^{d-1}\) we have \(_{}[()^{4}] C\) and, also, that the one-dimensional density of the projection \(\) where \(\) is upper bounded by \(C\), where \(C\) is some positive universal constant. Then the following is true (see also subsectionE.10).

**Theorem 5.1** (Universal TDS Learning of Balanced Intersections).: _For \((0,1/2)\), \(d,k\), there is a \(_{1}\)-universal \(O()\)-TDS learner for the class of \(\)-balanced intersections of \(k\) halfspaces over \(^{d}\) w.r.t. \(_{d}\) in the realizable setting, which, for the training phase, uses \((d)(O(k^{5}/))\) samples and time and, for the testing phase, uses \((d,k,1/)\) samples and time._

For comparison, the previous state-of-the-art TDS learning algorithm for halfspace intersections by  had overall runtime \(d^{O((k/))}+(d)(O(k^{6}/^{8}))\) and testing runtime \(d^{O((k/))}+(d)(k/)^{O(k^{2})}\) (although training and testing were not explicitly separated). Hence, the overall runtime of the algorithm of subsectionE.1 is better than the previous state-of-the-art, but also enjoys two additional properties: (1) the testing time is fully polynomial and (2) the tester is universal with respect to a wide class (of multimodal and even heavy-tailed distributions).

We note that it is not by chance that these two properties are satisfied simultaneously: they both relate to the fact that it suffices to solve a simple discrepancy testing problem. Since the tested property is relaxed, more distributions should satisfy it and testing the property can be made efficient. For comparison, as well as to provide a TDS learner with better overall runtime in some regimes, we may trade-off universality and test-time efficiency to obtain the following result (see subsectionE.10).

**Theorem 5.2** (TDS Learning of Balanced Intersections).: _For \((0,1/2)\), \(d,k\), there is an \(O()\)-TDS learner for the class of \(\)-balanced intersections of \(k\) halfspaces over \(^{d}\) w.r.t. \(_{d}\) in the realizable setting, which, for the training phase, uses \((d)(k/)^{O(k^{3})}\) samples and time and, for the testing phase, uses \((dk)^{O((1/))}\) samples and time._

_Remark 5.3_.: The algorithms of subsectionE.1 and 5.2 can both tolerate some amount of noise, i.e., provide an \(O()\) error guarantee even when \(=_{f}((f;^{}_{})+(f;^{}_{ }))\) is non-zero (but sufficiently small). For subsectionE.1, the amount of noise that can be tolerated is \(=(-(k/))\), while for subsectionE.2, the tolerated amount is \(=(k/)^{-O(k)}\) (see subsectionE.1). The amount of noise tolerated by the non-universal tester is more, because the test is more expensive and, therefore, does a better job in translating the guarantees of the training phase to guarantees for the test error. For comparison, the Chow matching tester of subsectionE.1 runs much more expensive tests and can, therefore, tolerate much more noise, i.e., \(=O()\).

**Discrepancy testing through boundary proximity.** We once more use the framework of localized discrepancy testing, in order to obtain TDS learners with strong guarantees. In order to achieve fully polynomial-time performance, we aim to use a tester that is as simple as possible. In particular, for a given halfspace intersection \(\), we test whether the probability that an example drawn from the test marginal falls close to the boundary of \(\), i.e., close to at least one of the defining halfspaces (see LemmaE.13 and DefinitionE.3). We also test concentration of the test distribution marginal.

Interestingly, we show that these two tests are sufficient for certifying low localized discrepancy from the Gaussian distribution with respect to the notion of disagreement neighborhood \(_{e}\), i.e., \(f_{e}()\) if the Gaussian disagreement \(_{_{d}}[f()( )]\) between \(f\) and \(\) is small enough (see DefinitionE.2). In particular, we show that if \(f\) is a balanced intersection and \(f_{e}()\), then \(f\) and \(\) can only differ either (1) far from the origin or (2) close to the boundary of \(\) (see PropositionE.4 and LemmaE.12). Importantly, this property is point-wise: for any \(^{d}\) such that \(f()()\), \(\) will either satisfy (1) or (2) and, hence, no distribution over \(^{d}\) can fool our tester.

In the heart of our proof is a geometric lemma which demonstrates that any balanced convex set is locally balanced as well (LemmaE.12), meaning that for any point \(^{d}\), there is a large number of points near \(\) with the same label as \(\). Therefore (unless the norm of \(\) is large), any hypothesis \(\) with low Gaussian disagreement from the ground truth \(f^{*}\), must encode all of the local structure (or boundary) of \(f^{*}\) that is not very far from the origin. To show this, we use a geometric argument about convex sets (see Figure1 for the case when the label of \(\) is \(1\). The other case is simpler and follows by the existence of a separating hyperplane between a convex set and any point outside it).

Since we have a localized discrepancy tester with respect to the disagreement neighborhood, all we need from the training phase is to output some intersection of halfspaces \(\) with low training error (so that the ground truth \(f^{*}\) lies within \(_{e}()\)). Hence, we may use any proper PAC learning algorithm for intersections of halfspaces under the Gaussian distribution. We use the algorithm by  (see also TheoremE.11).

_Remark 5.4_.: We note that the three important properties we used to apply the method of boundary proximity are that (1) the hypothesis \(\) returned by the learning algorithm admits an efficient boundary proximity tester and (2) the ground truth \(f^{*}\) is locally balanced and (3) that \(\) and \(f^{*}\) are both low-dimensional. For more details, see AppendixE.

## 6 Limitations, Future Work and Broader Impacts

**TDS learning beyond discrepancy testing.** We show that all of the known results in TDS learning can be achieved (and improved) by decoupling the training and testing phases. While separating training and testing phases is appealing and well-motivated by real-world scenarios, it is an interesting open question whether using the examples from the test marginal during training time could lead to improved TDS learning algorithms.

**Characterizations of discrepancy testing complexity.** We provide several positive results for localized discrepancy testing which imply new results in TDS learning. Moreover, on the lower bounds side, in AppendixF, we show that global discrepancy testing is NP-hard even for simple classes under no further assumptions. It is an interesting open question to explore tight characterizations for dimension-efficient, universal or fully polynomial-time localized discrepancy testing.

**Lifting the balancing assumption.** For our universal TDS learners (and universal discrepancy testers), we require that the underlying concept class only contains concepts that are not too biased

Figure 1: If \(\) lies within a balanced convex set \(\), then many points close to \(\) lie within \(\) as well, i.e., there is a cone \(^{}\) with \(^{}(,)\), where \((,)\) is a ball around \(\). The ball centered at \(_{c}\) exists due to the fact that \(\) is balanced: any balanced convex set contains some ball with non-negligible radius. The convex hull of \(\) and the ball at \(_{c}\) lies within \(\). (See also Fig.3)

towards one of the two possible labels under the training distribution (so that the training examples include enough information for localization). This condition is mild and can be easily tested by using training examples. However, better understanding of the importance of this condition for (universal) TDS learning could potentially lead to (or rule out) improved and/or universal algorithms for broader concept classes, e.g., polynomial threshold functions.

**Relaxing assumptions on training marginal.** Our main results in this work hold under the assumption that the marginal of the training distribution is either the Gaussian distribution or the uniform distribution over the hypercube. Such assumptions are standard in learning theory, as they serve as a concrete theoretical testbed for simplifying the analysis and presentation of the proposed algorithms and ideas. Relaxing those assumptions is an important and obvious goal for future work and parts of our analysis hint towards such relaxations (see, e.g., Remarks D.10 and E.5).

**Broader Impacts.** We do not identify any direct potential negative societal impacts. In fact, although our results are of theoretical nature, our algorithms might, in principle, help mitigate potentially unfair outcomes of applying certain pre-trained models on populations that are misrepresented in training data. Our discrepancy testers will either certify low prediction error on the deployment population or signal that the model at hand might not be applicable to the deployment population and another model should be considered.