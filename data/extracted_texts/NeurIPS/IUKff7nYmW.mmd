# Lower Bounds and Optimal Algorithms for Non-Smooth Convex Decentralized Optimization over Time-Varying Networks

Lower Bounds and Optimal Algorithms for Non-Smooth Convex Decentralized Optimization over Time-Varying Networks

 Dmitry Kovalev

Yandex Researh

dakovalev1@gmail.com

&Ekaterina Borodich

MIPT1

borodich.ed@phystech.edu

Alexander Gasnikov

Innopolis University, MIPT, Skoltech

gasnikov@yandex.ru

&Dmitrii Feoktistov

Innopolis University, MSU2

feoktistovdd@my.msu.ru

###### Abstract

We consider the task of minimizing the sum of convex functions stored in a decentralized manner across the nodes of a communication network. This problem is relatively well-studied in the scenario when the objective functions are smooth, or the links of the network are fixed in time, or both. In particular, lower bounds on the number of decentralized communications and (sub)gradient computations required to solve the problem have been established, along with matching optimal algorithms. However, the remaining and most challenging setting of non-smooth decentralized optimization over time-varying networks is largely underexplored, as neither lower bounds nor optimal algorithms are known in the literature. We resolve this fundamental gap with the following contributions: (i) we establish the first lower bounds on the communication and subgradient computation complexities of solving non-smooth convex decentralized optimization problems over time-varying networks; (ii) we develop the first optimal algorithm that matches these lower bounds and offers substantially improved theoretical performance compared to the existing state of the art.

## 1 Introduction

In this paper, we study the decentralized optimization problem. Specifically, given a set of \(n\) compute nodes connected through a communication network, our goal is to solve the following finite-sum optimization problem with quadratic regularization:

\[_{x^{d}}[p(x)=_{i=1}^{n}f_{i}(x)+ {2}\|x\|^{2}],\] (1)

where \(r 0\) is a regularization parameter, and each function \(f_{i}(x)^{d}\) is stored on the corresponding node \(i\{1,,n\}\). Each node \(i\) can perform computations based on its local state and data, and can directly communicate with other nodes through the links in the communication network.

Decentralized optimization problems find applications in a wide variety of fields. These include network resource allocation (Beck et al., 2014), distributed model predictive control (Giselsson et al., 2013), power system control (Gan et al., 2012), distributed spectrum sensing (Bazerque and Giannakis, 2009), and optimization in sensor networks (Rabbat and Nowak, 2004). In addition, such problems cover the supervised training of machine learning models through empirical risk minimization, thus attracting significant interest from the machine learning community (Lian et al., 2017; Ryabinin et al., 2021; Ryabinin and Gusev, 2020).

### Time-varying Networks

In our paper, we focus on the setting in which the links in the communication network are allowed to change over time. Such time-varying networks (Zadeh, 1961; Kolar et al., 2010) hold significant relevance to many practical applications. For instance, in sensor networks, changes in the link structure can be caused by the motion of sensors and disturbances in the wireless signal connecting pairs of sensors. Similarly, in distributed machine learning, connections between compute nodes can intermittently appear and disappear due to network unreliability (Ryabinin and Gusev, 2020). Lastly, we anticipate that the time-varying setting will be supported by future-generation federated learning systems (Konecny et al., 2016; McMahan et al., 2017), where communication between pairs of mobile devices or between mobile devices and servers will be affected by their physical proximity, which naturally changes over time.

### Convex Setting

In this work, we consider the decentralized optimization problem in the case when the objective function is convex (or strongly convex). At first glance, it may seem that the convexity assumption is restrictive and should not be considered. However, as we will see further, even in this fundamental setting, the existing algorithmic developments are limited and have significant gaps that need to be closed. Moreover, considering the convex optimization setting offers important benefits compared to general non-convex functions. One such benefit is that convex optimization often serves as a source of inspiration for the development of algorithms that turn out to be highly effective in solving practical problems, even non-convex ones.

For example, state-of-the-art optimization algorithms such as Adam(Kingma and Ba, 2014) and RMSProp(Hinton et al., 2012) employ the momentum trick, which is observed to be efficient for numerous tasks, including the training of deep neural networks. However, from the perspective of non-convex optimization theory, momentum is useless because, for non-convex problems, the iteration complexity of the standard gradient method cannot be improved (Carmon et al., 2020). On the other hand, it was theoretically proven that momentum substantially boosts the convergence speed of the gradient method when applied to convex functions (Nesterov, 1983). In other words, convex optimization theory suggests that the momentum trick should be used, while non-convex theory suggests that it should not, and the former aligns much more closely with practical observations. A similar situation can be seen with other state-of-the-art optimization methods, including distributed local gradient methods (Mishchenko et al., 2022; Sadiev et al., 2022; Karimireddy et al., 2020), adaptive gradient methods (Duchi et al., 2011), etc. Such inconsistency between non-convex theoretical convergence guarantees for optimization algorithms and their actual performance in practice can be attributed to the fact that the class of non-convex functions is far too broad. This is why many optimization research papers try to narrow down this class by considering additional assumptions such as Polyak-Lojasiewicz condition (Karimi et al., 2016), bounded non-convexity (Carmon et al., 2018; Allen-Zhu, 2018), quasi-strong convexity (Necoara et al., 2019), etc. However, these assumptions can be seen as relaxations of the standard convexity property. Therefore, we naturally opt to focus on the convex decentralized optimization problem, leaving potential generalizations for future work.

### Related Work and Main Contributions

Decentralized optimization has been attracting a lot of attention for more than a decade. Plenty of algorithms have been developed, including EXTRA(Shi et al., 2015), DIGing(Nedic et al., 2017), SONATA(Scutari and Sun, 2019), NIDS(Li et al., 2019), APM-C(Li et al., 2018; Rogozin et al., 2021), and many others. In recent years, the focus of the research community has shifted towards the more complex task of finding, in some sense, the best possible algorithms for solving decentralizedoptimization problems (Scaman et al., 2017, 2018; Lan et al., 2020; Kovalev et al., 2020, 2021b, a, 2022; Hendrikx et al., 2021; Li et al., 2022; Li and Lin, 2021; Metelev et al., 2024). This task consists of finding a lower bound on the complexity5 of solving a given subclass of decentralized problems and finding an algorithm whose complexity matches this lower bound. Such algorithms are called optimal because their complexity cannot be improved for a given problem class due to the established lower bounds.

We discuss the four main classes of decentralized optimization problems that cover smooth6 and non-smooth objective functions, and fixed and time-varying communication networks. We reference the existing state-of-the-art research papers that collectively solve the task of finding optimal algorithms for these classes. These papers are summarized in Table 1. In the case of smooth and strongly convex objective functions and fixed communication networks, Scaman et al. (2017) established the lower bounds on the number of communication rounds and the number of local gradient computations required to find the solution. These lower bounds were matched by OPAPC algorithm of Kovalev et al. (2020). In the case of smooth and strongly convex problems over time-varying networks, lower complexity bounds were provided by Kovalev et al. (2021), and two optimal algorithms were developed: ADOM+ (Kovalev et al., 2021) and AccGT (Li and Lin, 2021). In the case of non-smooth convex problems over fixed networks, lower bounds were established by Scaman et al. (2018), and two optimal algorithms were proposed: DCS (Lan et al., 2020) and MSPD (Scaman et al., 2018).

Our paper primarily focuses on the remaining and most challenging setting of non-smooth convex decentralized optimization problems over time-varying networks. Only a few algorithms have been developed for this setting, including the distributed subgradient method (D-SubGD) by Nedic and Ozdaglar (2009), the subgradient-push method (SubGD-Push) by Nedic and Olshevsky (2014), and ZOSADOM by Lobanov et al. (2023). Moreover, to the best of our knowledge, neither lower complexity bounds nor optimal algorithms have been proposed in this setting. Consequently, in this work, we close this significant gap with the following key contributions:

* We establish the first lower bounds on the number of decentralized communications and local subgradient computations required to solve problem (1) in the non-smooth convex setting over time-varying networks,
* We show that our lower bounds are tight by developing the first optimal algorithm that matches these lower bounds. The proposed algorithm has state-of-the-art theoretical communication complexity, which outclasses the existing methods described in the literature.

## 2 Notation and Assumptions

In this paper, we are going to use the following notations: \(\) denotes the Kronecker matrix product, \(_{p}\) denotes a \(p p\) identity matrix, \(_{p}=(1,,1)^{}^{p}\), \(_{j}^{p}^{p}\) for \(j\{1,,p\}\) denotes the \(j\)-th unit basis vector, where \(p\{1,2,\}\). In addition, \(\|\|\) denotes the standard Euclidean norm of a vector, and \(,\) denotes the standard scalar product of two vectors.

   & **Smooth Setting** & **Non-Smooth Setting** \\ 
**Fixed** & Kovalev et al. (2020)\({}^{}\) & Lan et al. (2020)\({}^{}\) \\
**Networks** & Scaman et al. (2017)\({}^{*}\) & Scaman et al. (2018)\({}^{*}\) \\ 
**Time-Varying** & Kovalev et al. (2021)\({}^{**}\) & **Algorithm 1 (this paper)\({}^{}\)** \\
**Networks** & Li and Lin (2021)\({}^{}\) & **Theorems 1 and 2 (this paper)\({}^{*}\)** \\  

Table 1: Summary of the existing state-of-the-art results in decentralized convex optimization. Multiple paper references are provided for each problem setting: papers marked with \({}^{*}\) provide lower complexity bounds, and papers marked with \({}^{}\) provide optimal algorithms that match the corresponding lower bounds.

### Objective Function

Further, we describe the assumptions that we impose on problem 1. As discussed in Section 1.2, we assume the convexity of the objective function in problem (1). In particular, we assume that functions \(f_{1}(x),,f_{n}(x)\) are convex, which is formally described in Assumption 1.

**Assumption 1**.: _Each function \(f_{i}(x)\) is convex. That is, for all \(x^{},x^{d}\) and \(\), the following inequality holds:_

\[f_{i}( x+(1-)x^{}) f_{i}(x)+(1-)f_{i}(x^{}).\] (2)

In addition, we assume that the objective functions \(f_{1}(x),,f_{n}(x)\) are Lipschitz continuous, which is formalized in Assumption 2. This property is widely used in the theoretical analysis of non-smooth optimization algorithms, such as the subgradient method (Nesterov, 2013), dual extrapolation method (Nesterov, 2009), etc.

**Assumption 2**.: _Each function \(f_{i}(x)\) is \(M\)-Lipschitz continuous for \(M 0\). That is, for all \(x^{},x^{d}\), the following inequality holds:_

\[|f_{i}(x)-f_{i}(x^{})| M\|x-x^{}\|.\] (3)

We also need the following Assumption 3, which ensures the existence of a solution to problem (1). Note that in the strongly convex case (\(r>0\)), the solution always exists and is unique. However, in the convex case (\(r=0\)), we need to explicitly assume the existence of a solution.

**Assumption 3**.: _There exists a solution \(x^{*}^{d}\) to problem (1) and a distance \(R>0\) such that_

\[\|x^{*}\| R.\] (4)

### Decentralized Communication

Next, we formally describe the decentralized communication setting. The communication network is typically represented by a graph \((,)\), where \(=\{1,,n\}\) is the set of compute nodes and \(\) is the set of links in the network. As mentioned earlier, we allow the communication links to change over time. Thus, we introduce the continuous time parameter \( 0\) and a set-valued function \(()_{+} 2^{}\), which represents the time-varying set of edges.7 Our time-varying network is then denoted as \(()=(,())\).

Decentralized communication is typically represented via a matrix-vector multiplication with the so-called gossip matrix associated with the communication network (Scaman et al., 2017; Kovalev et al., 2021a). In the time-varying setting, we represent the gossip matrix by a matrix-valued function \(()_{+}^{n n}\), which satisfies the following Assumption 4.

**Assumption 4**.: _For all \( 0\), the gossip matrix \(()^{n n}\) associated with the time-varying communication network \((,())\) satisfies the following properties:_

* \(()_{ij}=0\) _if_ \(i j\) _and_ \((j,i)()\)_,_
* \(()_{n}=0\) _and_ \(()^{}_{n}=0\)_._

We also define the so-called condition number of the network \( 1\), which indicates how well the network \(()\) is connected (Scaman et al., 2017; Kovalev et al., 2021a). In particular, the communication complexity of most decentralized optimization algorithms depends on \(\). Assumption 5 provides the formal definition of this quantity.

**Assumption 5**.: _There exists a constant \( 1\) such that the following inequality holds for all \( 0\):_

\[\|()x-x\|^{2}(1-1/)\,\|x\|^{2}\ \ \ \ x\{(x_{1},,x_{n})^{n}:_{i=1}^{n}x_{i}=0\}\,.\] (5)

## 3 Lower Complexity Bounds

### Decentralized Subgradient Optimization Algorithms

In this section, we present the lower bounds on the number of decentralized communications and the number of local subgradient computations required to solve problem (1). These lower boundsapply to a particular class of algorithms, which we refer to as the class of _decentralized subgradient optimization algorithms_. This class can be seen as an adaptation of _black-box optimization procedures_(Scaman et al., 2018) to the time-varying network setting, or an adaptation of _first-order decentralized optimization algorithms_(Kovalev et al., 2021a) to the non-smooth optimization setting.

Non-smooth optimization algorithms typically perform incremental updates by computing the subgradient of a given objective function. The set of all subgradients of a convex function, called the subdifferential, can be multivalued in general. Thus, it is necessary to select the specific subgradient that the algorithm will use. This is done by the _subgradient oracle_, which is described by Definition 1.

**Definition 1**.: _For each \(i\), a function \(f_{i}(x)^{d}^{d}\) is called a subgradient oracle associated with the function \(f_{i}(x)\) if, for all \(x^{d}\), it satisfies \(f_{i}(x) f_{i}(x)\). That is, for each \(i\) and for all \(x,x^{}^{d}\), the following inequality holds:_

\[f_{i}(x^{}) f_{i}(x)+f_{i}(x),x^{}-x.\] (6)

Further, we provide the formal description of the class of decentralized subgradient optimization algorithms in the following Definition 2.

**Definition 2**.: _An algorithm is called a decentralized subgradient optimization algorithm with the subgradient computation time \(_{}>0\) and decentralized communication time \(_{}>0\) if it satisfies the following constraints:_

* **Internal memory.** _At any time_ \( 0\)_, each node_ \(i\) _maintains an internal memory, which is represented by a set-valued function_ \(_{i}()_{+} 2^{^{d}}\)_. The internal memory can be updated by subgradient computation or decentralized communication, which is formally represented by the following inclusion:_ \[_{i}()_{i}^{}() _{i}^{}(),\] (7) _where set-valued functions_ \(_{i}^{}(),_{i}^{}() _{+} 2^{^{d}}\) _are defined below._
* **Subgradient computation.** _At any time_ \( 0\)_, each node_ \(i\) _can update its internal memory_ \(_{i}()\) _by computing the subgradient_ \(f_{i}(x)\) _of the function_ \(f_{i}(x)\)_, which takes time_ \(_{}\)_. That is, for all_ \( 0\)_, the set_ \(_{i}^{}()\) _is defined as follows:_ \[_{i}^{}()=(\{x,f_{i}(x):x_{i}(-_{})\})&_{ }\\ &<_{}.\] (8)
* **Decentralized communication.** _At any time_ \( 0\)_, each node_ \(i\) _can update its internal memory_ \(_{i}()\) _by performing decentralized communication across the communication network, which takes time_ \(_{}\)_. That is, for all_ \( 0\)_, the set_ \(_{i}^{}()\) _is defined as follows:_ \[_{i}^{}()= _{(j,i)()}_{j}(-_{}) &_{}\\ &<_{}.\] (9)
* **Initialization and output.** _At time_ \(=0\)_, each node_ \(i\) _must initialize its internal memory with the zero vector, that is,_ \(_{i}(0)=\{0\}\)_. At any time_ \( 0\)_, each node_ \(i\) _must specify a single output vector from its internal memory,_ \(x_{o,i}()_{i}()\)_._

### Lower Bounds

Now, we are ready to present the lower bounds on the execution time \( 0\) required to find an \(\)-approximate solution8 to problem (1) by any algorithm satisfying Definition 2. Theorem 1 provides the lower bound in the strongly convex case (\(r>0\)), and Theorem 2 provides the lower bound in the convex case (\(r=0\)). These lower bounds naturally depend on the precision \(>0\), the parameters of the problem, including the Lipschitz constant \(M>0\), the regularization parameter \(r 0\), the distance \(R>0\), and the parameters of the network, including the condition number \( 1\), communication time \(_{}>0\), and subgradient computation time \(_{}>0\).

**Theorem 1**.: _For arbitrary parameters \(M,r,,_{},_{}>0\) and \( 1\), there exists an optimization problem of the form (1) satisfying Assumptions 1, 2 and 3, corresponding subgradient oracles given by Definition 1, a time varying network \(()=(,())\), and a corresponding time-varying gossip matrix \(()\) satisfying Assumptions 4 and 5, such that at least the following time \(\) is required to reach precision \(p(x_{o,i}())-p(x^{*})\) by any decentralized subgradient optimization algorithm satisfying Definition 2:_

\[(_{}}+_ {}}{r}).\] (10)

**Theorem 2**.: _For arbitrary parameters \(M,R,,_{},_{}>0\) and \( 1\), there exists an optimization problem of the form (1) with zero regularization (\(r=0\)) satisfying Assumptions 1, 2 and 3, corresponding subgradient oracles given by Definition 1, a time varying network \(()=(,())\), and a corresponding time-varying gossip matrix \(()\) satisfying Assumptions 4 and 5, such that at least the following time \(\) is required to reach precision \(p(x_{o,i}())-p(x^{*})\) by any decentralized subgradient optimization algorithm satisfying Definition 2:_

\[(_{}+_{ }R^{2}}{^{2}}).\] (11)

The proofs of Theorems 1 and 2 can be found in Appendix B. Further, we provide a brief and informal description of the main theoretical ideas that underlie these proofs:

* We select a specific "hard" instance of problem (1). In particular, we choose the objective function of the form \(p(x)=a_{j=1}^{d-1}_{j+1}^{d}-_{j}^{d},x -a_{1}^{d},x+ x^{2}\), which was used by Arjevani and Shamir (2015); Scaman et al. (2018) in the proof of lower bounds on the communication complexity in centralized and fixed-network settings. One can show that the gap \(p(x)-p(x^{*})\) is lower-bounded by a positive constant as long as the last component of the vector \(x\) is zero, and it takes \((_{} d)\) time to break this bound due to the constraint on the subgradient updates (8).
* We split the objective function between two nodes of a star-topology network with a time-varying central node, which was previously utilized by Kovalev et al. (2021) in the proof of lower bounds for optimizing smooth functions. One can show that it takes \((n)=()\) communications to exchange information between the two selected nodes due to the time-varying center. This contrasts with the fixed path-topology network used by Scaman et al. (2017, 2018), where such an exchange would take \((n)=()\) communications. Moreover, using the constraint (8), we can show that it takes \((_{} nd)\) time to make the last component of the vector \(x\) nonzero and break the lower bound on the gap \(p(x)-p(x^{*})\), thanks to the way we split the objective function.
* Based on the above considerations, we show that the total execution time required to solve the problem is lower-bounded by \((_{} nd+_{} d)\). Thus, we obtain the desired results by making a specific choice of the dimension \(d\), network size \(n\), and other parameters of problem (1).

### Comparison with the Lower Bounds in Centralized and Fixed Network Settings

We compare the lower complexity bounds for solving non-smooth convex optimization problems in the three main distributed optimization settings: centralized, decentralized fixed network, and

 
**Setting** & **Centralized** & **Fixed networks9** & **Time-varying networks** \\ 
**Strongly convex** & \((M/)\) & \((M/)\) & \(( M/)\) \\ 
**Convex** & \((MR/)\) & \((MR/)\) & \(( MR/)\) \\  

Table 2: Lower bounds on the communication complexity of solving problem (1) in the centralized (Arjevani and Shamir, 2015), decentralized fixed network (Scaman et al., 2018), and decentralized time-varying network (Theorems 1 and 2) settings.

decentralized time-varying network. The lower subgradient computation complexity bounds coincide in these cases (Nesterov (2013),Scaman et al. (2018),Theorems 1 and 2). However, the situation with the communication complexity is different. See Table 2 for a summary.

Theorems 1 and 2 imply that the communication complexity in the decentralized time-varying network setting is proportional to the network condition number \(\). In contrast, the communication complexity in the fixed network setting is proportional to \(\), which reflects the fact that time-varying networks are more difficult to deal with compared to fixed networks. In particular, there was a long-standing conjecture that the "upgrade" from the factor \(\) to the factor \(\) in communication complexity is impossible in the time-varying network setting. Only recently, this conjecture was proved for smooth functions by Kovalev et al. (2021), and now we resolve this open question in the non-smooth case as well.

## 4 Optimal Algorithm

In this section, we develop an optimal algorithm for solving the non-smooth convex decentralized optimization problem (1) over time-varying networks. The design of our algorithm relies on a specific saddle-point reformulation of the problem, which we describe in the following section.

### Saddle-Point Reformulation

Let functions \(F(x)(^{d})^{n}\) and \(G(y,z)(^{d})^{n}(^{d})^{n}\) be defined as follows:

\[F(x)=_{i=1}^{n}f_{i}(x_{i})+}{2}\|x\|^{2} G (y,z)=}{2}\|y+z\|^{2},\] (12)

where \(x=(x_{1},,x_{n})(^{d})^{n}\), and \(r_{x},r_{yz}>0\) are some constants that satisfy

\[r_{x}+1/r_{yz}=r.\] (13)

Consider the following saddle-point problem:

\[_{x(^{d})^{n}}_{y(^{d})^{n}}_{z( ^{d})^{n}}[Q(x,y,z)=F(x)- y,x-G(y,z)]  z^{},\] (14)

where \(^{}(^{d})^{n}\) is the orthogonal complement to the so-called consensus space \((^{d})^{n}\), defined as follows:

\[=\{(x_{1},,x_{n}):x_{1}==x_{n}\},^{ }=\{(x_{1},,x_{n}):_{i=1}^{n}x_{i}=0\}.\] (15)

One can show that the saddle-point problem (14) is equivalent to the minimization problem (1). This is justified by the following Lemma 1. The proof of the lemma can be found in the Appendix A.

**Lemma 1**.: _Problem (14) is equivalent to problem (1) in the following sense:_

\[_{x(^{d})^{n}}_{y(^{d})^{n}}_{z^{}}Q(x,y,z)=n_{x^{d}}p(x).\] (16)

The saddle-point reformulation of the form (14) was first introduced by Kovalev et al. (2020, 2021a) to develop optimal decentralized algorithms for optimizing smooth functions. However, these are not applicable to the non-smooth case. To the best of our knowledge, the only attempt to adapt the reformulation (14) to the non-smooth setting was made by Lobanov et al. (2023). However, their results have significant downsides, which we discuss in Section 4.3.

### New Algorithm and its Convergence

Now, we present Algorithm 1 for solving problem (1). We provide upper bounds on the number of decentralized communications \(K\) and the number of subgradient computations \(K T\) required to find an \(\)-approximate solution to the problem. Theorems 3 and 4 provide the upper bounds in the strongly convex (\(r>0\)) and convex (\(r=0\)) cases, respectively. The proofs can be found in Appendix D. The total execution time of Algorithm 1 is upper-bounded as \(=(_{} K+_{} K T)\), where the communication time \(_{}>0\) and the subgradient computation time \(_{}>0\) are described in Definition 2. This upper-bound on the execution time cannot be improved because of the lower bounds established in the previous Section 3. Therefore, Algorithm 1 is an optimal algorithm for solving problem (1).

**Theorem 3**.: _Under Assumptions 1, 2, 3, 4 and 5, let \(r>0\) (strongly convex case). Then Algorithm 1 requires \(K=()\) decentralized communications (line 6 of Algorithm 1) and \(K T=(}{r})\) subgradient computations (line 11 of Algorithm 1) to reach precision \(p(x_{o}^{K})-p(x^{*})\)._

**Theorem 4**.: _Under Assumptions 1, 2, 3, 4 and 5, let \(r=0\) (convex case). Then Algorithm 1 requires \(K=()\) decentralized communications (line 6 of Algorithm 1) and \(K T=(R^{2}}{^{2}})\) subgradient computations (line 11 of Algorithm 1) to reach precision \(p(x_{o}^{K})-p(x^{*})\)._

The design of Algorithm 1 is based on the fundamental Forward-Backward algorithm (Bauschke and Combettes, 2011). Let \(=(^{d})^{n}(^{d})^{n}^{}\) be a Euclidean space, and consider a monotone operator \(A(u)\) and a maximally-monotone multivalued operator \(B(u) 2^{}\) defined as follows:

\[A(u)=0\\ _{y}G(y,z)\\ _{z}G(y,z), B(u)= F (x)-y\\ x\\ 0,\] (17)

where \(u=(x,y,z)\), and \(=(_{n}-(1/n)_{n}_{n}^{}) _{d}^{nd nd}\) is the orthogonal projection matrix onto \(^{}\). Then problem (14) is equivalent to the following monotone inclusion problem:

\[u0 A(u)+B(u).\] (18)

The basic Forward-Backward algorithm iterates \(u^{k+1}=(+B)^{-1}(u^{k}-A(u^{k}))\), where \(\) is the identity operator and \((+B)^{-1}\) denotes the inverse of the operator \((u)+B(u)\), which is called resolvent. Algorithm 1 can be obtained by making the following major modifications to these iterations:

* We accelerate the convergence of the Forward-Backward algorithm using Nesterov acceleration (Nesterov, 1983). Although this mechanism cannot be applied to the general monotone inclusion problem (18), Kovalev et al. (2020) showed that it can be used when the operator \(A(u)\) is equal to the gradient of a smooth convex function, which is true in our case.
* Computation of the operator \(A(u)\) requires multiplication with the matrix \(\). This, in turn, requires an exact averaging of a vector, which is difficult to do over the time-varying network. Kovalev et al. (2021b) showed that this obstacle can be tackled with the Error-Feedback mechanism for decentralized communication, which we also utilize.
* At each iteration of the algorithm, we have to compute the resolvent, which requires solving an auxiliary subproblem \(_{x}_{y}}{2}\|x-x^{k}\|^{2}+F(x)- y,x- }{2}\|y-y^{k}\|^{2}\). This problem cannot be solved exactly, so we have to find an approximate solution using anadditional "inner" algorithm based on the subgradient method (Nesterov, 2013) and the Chambolle-Pock operator splitting (Chambolle and Pock, 2011). We also have to conduct a careful analysis to find an efficient way to combine the inner and the "outer" Forward-Backward algorithms and avoid unnecessary waste of subgradient calls.

The design of Algorithm 1 shares some similarities with the algorithm of Kovalev et al. (2021) such as **(i)** and **(ii)** above. However, Kovalev et al. (2021) simply add the gradient \( F(x)\) to the operator \(A(u)\) and use the accelerated version of the Forward-Backward algorithm, which we obviously cannot do as the function \(F(x)\) is not smooth. Instead, we have to put the subdifferential \( F(x)\) into the operator \(B(u)\) and follow **(iii)** above. Part **(iii)**, in turn, shares some similarities with the algorithm of Lan et al. (2020). However, Lan et al. (2020) simply have a zero operator \(A(u)=0\), which makes **(i)** and **(ii)** above unnecessary in their case. In contrast, we cannot make such simplifications because we work in the much more complicated setting of time-varying networks.

### Comparison with the Existing Results

One could naturally expect that the existing optimal algorithms, originally developed for fixed networks, such as DCS(Lan et al., 2020) and MSPD(Scaman et al., 2018), could be applied to solve problem (1) over time-varying networks. However, this is not the case, which is justified by the lack of corresponding theoretical guarantees and was shown empirically by Kovalev et al. (2021). Therefore, we have to consider only those algorithms that were specifically developed for the time-varying network setting.

We provide a comparison of our Algorithm 1 with the existing state-of-the-art decentralized methods for solving convex non-smooth optimization problems over time-varying networks in Table 3.10 These include D-SubGD(Nedic and Ozdaglar, 2009), SubGD-Push(Nedic and Olshevsky, 2014), and ZO-SADOM(Lobanov et al., 2023). The first two algorithms have poor performance: D-SubGD converges only to limited precision, and SubGD-Push converges at a slow rate of \((^{2}(1/)/^{2})\), which does not match even the iteration complexity of the standard centralized subgradient method, let alone the improved complexity of Algorithm 1. The complexity of ZO-SADOM is also worse than the lower bounds. Moreover, the theoretical results of Lobanov et al. (2023) have substantial drawbacks compared to ours:

 
**Algorithm** & **Strongly-convex case complexity** & **Convex case complexity** \\  D-SubGD &  \\  SubGD-Push & \(_{}\)\((M,R,d) n^{2n}^{2}}{^{2}}+_{ }(M,R,d) n^{2n}^{2}}{^{2}}\) \\  ZO-SADOM & \(_{}}{}+_{}d}{r}\) & \(_{}}{}+ _{}R^{2}d}{^{2}}\) \\ 
**Algorithm 1** & \(_{}\)\(}+_{}}{r}\) & \(_{}\)\(+_{}R^{2}}{^{2}}\) \\ 
**Lower Bounds** & \(_{}\)\(}+_{}}{r}\) & \(_{}\)\(+_{}R^{2}}{^{2}}\) \\  

Table 3: The execution time \(\) required to find an \(\)-approximate solution to the decentralized optimization problem (1) by the following algorithms: D-SubGD(Nedic and Ozdaglar, 2009), SubGD-Push(Nedic and Olshevsky, 2014), ZO-SADOM(Lobanov et al., 2023), and Algorithm 1 (this paper). Decentralized communication and subgradient computation complexities are marked with green and yellow colors, respectively. For D-SubGD, the complexity is not provided because the algorithm converges only to a neighborhood of the solution. For SubGD-Push, \((M,R,d)\) denotes a certain polynomial in \(M,R,d\). For ZO-SADOM, the differences from the optimal complexities are highlighted in red color.

* Lobanov et al. (2023) do not provide any theoretical insights or innovations in the analysis of their algorithm. In particular, they use the randomized smoothing technique (Duchi et al., 2012) to obtain a smooth approximation of the objective \(p(x)\), and apply the existing algorithm of Kovalev et al. (2021) to minimize this approximation. In contrast, we develop a new algorithm that directly works with the original non-smooth objective \(p(x)\).
* ZO-SADOM has extra factors \(d^{1/4}(1/)\) and \(d(1/)\) in the decentralized communication and subgradient computation complexities, respectively, compared to the optimal complexity of our Algorithm 1. Thus, the performance of ZO-SADOM can be poor when applied, for instance, to large-scale machine learning problems in which the dimension \(d\) can be huge.