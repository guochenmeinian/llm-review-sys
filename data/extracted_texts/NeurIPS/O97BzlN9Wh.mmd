# GDeR: Safeguarding Efficiency, Balancing, and Robustness via Prototypical Graph Pruning

Guibin Zhang\({}^{*}\)\({}^{1,2}\), Haonan Dong\({}^{*}\)\({}^{1}\), Yuchen Zhang\({}^{2}\), Zhixun Li\({}^{3}\), Dingshuo Chen\({}^{4}\),

**Kai Wang\({}^{5}\), Tianlong Chen\({}^{6}\), Yuxuan Liang\({}^{7}\), Dawei Cheng\({}^{1}\)\({}^{1,2}\), Kun Wang\({}^{18}\)\({}^{1}\)**

\({}^{1}\)Tongji University, \({}^{2}\)Shanghai AI Laboratory, \({}^{3}\)CUHK, \({}^{4}\)UCAS,

\({}^{5}\)NUS, \({}^{6}\)UNC-Chapel Hill, \({}^{7}\)HKUST (Guangzhou) \({}^{8}\)NTU

\({}^{*}\) Equal Contribution, \({}^{}\) Corresponding author

dcheng@tongji.edu.cn, wk520529wjh@gmail.com

###### Abstract

Training high-quality deep models necessitates vast amounts of data, resulting in overwhelming computational and memory demands. Recently, data pruning, distillation, and coreset selection have been developed to streamline data volume by _retaining_, _synthesizing_, or _selecting_ a small yet informative subset from the full set. Among these methods, data pruning incurs the least additional training cost and offers the most practical acceleration benefits. However, it is the most vulnerable, often suffering significant performance degradation with imbalanced or biased data schema, thus raising concerns about its accuracy and reliability in on-device deployment. Therefore, there is a looming need for a new data pruning paradigm that maintains the efficiency of previous practices while ensuring balance and robustness. Unlike the fields of computer vision and natural language processing, where mature solutions have been developed to address these issues, graph neural networks (GNNs) continue to struggle with increasingly large-scale, imbalanced, and noisy datasets, lacking a unified dataset pruning solution. To achieve this, we introduce a novel dynamic soft-pruning method, GDeR, designed to update the training "basket" during the process using trainable prototypes. GDeR first constructs a well-modeled graph embedding hypersphere and then samples _representative, balanced, and unbiased subsets_ from this embedding space, which achieves the goal we called Graph Training Debugging. Extensive experiments on five datasets across three GNN backbones, demonstrate that GDeR (I) achieves or surpasses the performance of the full dataset with \(30\% 50\%\) fewer training samples, (II) attains up to a \(2.81\) lossless training speedup, and (III) outperforms state-of-the-art pruning methods in imbalanced training and noisy training scenarios by \(0.3\% 4.3\%\) and \(3.6\% 7.8\%\), respectively. The source code is available at https://github.com/inslstenc3/GDeR.

## 1 Introduction

Data-centric AI, though continuously providing high-quality data for upcoming artificial general intelligence , presents a significant hurdle for their on-device deployment during training and inference phases . To democratize existing state-of-the-art methods , considerable efforts are directed toward identifying unbiased and core data within training datasets and conducting troubleshooting to deepen our solid understanding of the intrinsic property of data schema . To date, _data pruning_, _distillation_ and _coreset selection_ aim to retain, synthesize or choose a small but informative dataset from original full set. While the sample size undergoes significant reshaping and reduction, methods like dataset distillation inevitably lead to additional training costs . As a hardware-friendly candidate and accelerator for training and inference, data pruning serves as a promising candidate by mitigating the high computational burden.

[MISSING_PAGE_FAIL:2]

Technical Background

NotationsConsider an undirected graph \(=(,)\), where \(\) represents the node set and \(\) signifies the edges. The feature matrix for the graph is designated as \(^{|| F}\). Each node \(v_{i}\) is associated with a feature vector of \(F\) dimensions. The adjacency matrix \(\{0,1\}^{N N}\) represents the connectivity between nodes, where \([i,j]=1\) suggests the presence of an edge \(e_{ij}\), and 0 indicates no edge. In graph-level training tasks, specifically for graph classification, given a set of \(N\) graphs \(\{\}=\{_{1},_{2},,_{N}\}\), where each graph \(_{i}=(^{i},^{i})\) is as defined above, and their corresponding labels \(^{N}\) with \(C\) being the total number of classes, we aim to learn graph representations \(^{N^{}}\) with \([i,:]\) for each \(_{i}\) that effectively predict \(_{i}\).

Graph Neural Networks (GNNs).GNNs [50; 51] have become pivotal for learning graph representations, achieving benchmark performances in various graph tasks at _node-level_, _edge-level_, and _graph-level_. The success of GNN mainly stems from message-passing mechanism:

\[_{i}^{(l)}=(_{i}^{(l-1)}, \{_{j}^{(l-1)}:v_{j}(v_{i})\}),\ 0 l L.\] (1)

Here, \(L\) represents the number of GNN layers, where \(_{i}^{(0)}=_{i}\), and \(_{i}^{(l)}(1 l L)\) denotes the node embedding of \(v_{i}\) at the \(l\)-th layer. \((v_{i})\) denotes the 1-hop neighbors of \(v_{i}\), and \(()\) and \(()\) are used for aggregating neighborhood information and combining ego/neighborhood-representations, respectively. Finally, a sum/mean pooling operation is commonly used for READOUT function to obtain the graph-level embedding. While promising, the increasing volume of graph samples [55; 19; 56] poses significant computational challenges for both training and pre-training of GNNs. Efficiently accelerating graph-level training remains an unresolved issue.

Data PruningCurrent data pruning methods can be categorized as static or dynamic . Static data pruning involves heuristic-based metrics or limited training to assess sample importance and perform pruning before formal training, like EL2N  and Influence-score . On the other hand, dynamic data pruning dynamically selects different training samples during training [58; 23; 59], often achieving better results than static pruning. In the graph domain, attempts related to data pruning include edge-level sampling techniques like GraphSAGE  and GraphSAINT . However, to the best of our knowledge, there is currently no method specially designed for graph-level data pruning, let alone one that can simultaneously improve the balance and robustness of GNNs.

Imbalance in GNNsDeep imbalanced learning has been one of the significant challenges in deep learning . The current mainstream research can be broadly categorized into three approaches: (1) _re-sampling_[63; 64; 65], which balances the number of samples from different classes; (2) _re-balancing_[66; 67; 68], which adjusts the loss values for samples from different classes; and (3) _post-hoc processing_, which shifts the model logits based on label frequencies. In the domain of graph learning, most efforts to address the imbalance issue focus on node-level classification imbalances [70; 71; 72], yet solutions targeting graph-level imbalance are relatively limited. Despite a preliminary attempt , which requires complex up-sampling and regrouping operations, there is still a need for a straightforward yet effective solution to graph imbalance issue.

Robustness in GNNsAs for robustness learning, many studies showcase graph classification is vulnerable to adversarial attacks [73; 74]. Given a set of training or test graphs, an attacker could perturb the graph structure  and/or node features to deceive a graph classifier into making incorrect predictions for the perturbed testing graph. Traditional empirical and certified defenses [76; 77; 78; 79] often involve complex designs and additional components. In this paper, we propose subtle adjustments during training, leveraging prototypes to enhance the robustness of graph training.

## 3 Methodology

### Problem Formulation

In the classic scenario of graph-level training (not limited to specific tasks like graph classification, regression, or pre-training), given a graph dataset \(=\{z_{i}\}_{i=1}^{||}=\{(_{i},_{i}) \}_{i=1}^{||}\), a GNN encoder is employed to extract graph-level embeddings \(=\{_{i}\}_{i=1}^{||}\) for each graph sample, which are then utilized for downstream tasks. The goal of \(\) is to find an oracle function that changes with time (epochs) and can determine the current most representative, balanced, and denoised core subset \(_{t}\):

\[_{t}=_{t-1}(,\{_{i}^{(t-1)}\}_ {i=1}^{||}),\] (2)

where \(_{t-1}\) is the selection function at the \((t-1)\)-th epoch. Given a preset sparsity ratio \(s\%\), the subset's volume is fixed as \(|_{t}|=(1-s)\%||\).

### Overview of the Proposed Method

As shown in Figure 2, given an arbitrary GNN, \(\) selects a training sample set \(_{t}\) within a specified budget for each epoch. At the \(t\)-th epoch, after the GNN \(f_{}:\;^{E}\) outputs graph embeddings \(^{E}\) from the input graph \(_{i}\) with \(=f_{}(_{i})\), these are projected into a hyperspherical embedding space via a _projector_\(g_{}:\;^{E}^{D}\). \(\) allocates a set of \(M\) trainable prototypes \(^{c}=\{_{k}^{c}\}_{k=1}^{K}\) for each class \(c\), with associated losses used to shape the embedding space, ensuring inter-class separation and intra-class compactness. In this regularized space, \(\) formulates a sampling distribution by focusing on samples unfamiliar to the model, excluding those from the majority prototype cluster and with high outlier risk, thereby providing a subset of samples \(S_{t+1}\) for the next epoch. Through this balanced and robust dynamic pruning mechanism, \(\) achieves unbiased graph representations at a significantly lower training cost than the full dataset.

### Projection onto Hyperspherical Embedding Space

At the \(t\)-th epoch, \(\) maintains a subset \(_{t}\) with a given budget, where \(s\%=|_{t}|/||\) is a constant, representing the dataset pruning ratio. Given the feature representations \(^{|_{t}| E}\) output by \(f_{}\), we first project these features into a hyperspherical embedding space, denoted as \(^{}=g_{}(),=^{}/|| ^{}||_{2}\). This projection has been shown to be beneficial for compactly embedding samples of the same class . The projected embeddings \(^{D}\), which lie on the unit sphere (\(||||^{2}=1\)), can naturally be modeled using the von Mises-Fisher (vMF) distribution . Here, we first consider the graph classification scenario1, in which we allocate \(K\) prototypes \(^{c}=\{_{k}^{c}\}_{k=1}^{K}\) for each class \(c\) (\(1 c C\)). Following conventional practices in hyperspherical space modeling , we model a vMF distribution as the combination of a center prototype representation \(_{k}\) and the concentration parameter \(\):

\[p_{D}(;_{k},)=Z_{D}()( _{k}^{}),\;Z_{D}()=}{ (2)^{D/2}I_{D/2-1}()},\] (3)

where \( 0\) denotes the tightness around the mean, \(Z_{D}()\) represents a normalization factor , \((_{k}^{})\) is called the angular distance and \(I_{v}\) is the modified Bessel function of the first kind with order \(v\). In our multi-prototype settings, we model the probability density of a graph embedding \(_{i}\) in class \(c\) as follows:

\[p(_{i};^{c},)=_{k=1}^{K}Z_{D}()( _{k}^{c}_{i}),\] (4)

Figure 2: The overview of our proposed \(\). \(\) comprises hypersphere projection, embedding space modeling, sampling distribution formatting, and the final dynamic sampling. We present the dynamic sample selection process of \(\) within one epoch.

Further, the embedding \(_{i}\) is assigned to class \(c\) with the normalized probability as shown above:

\[p(y_{i}=c_{i};\ \{^{j},\}_{j=1}^{C})=^{K}Z_{D}()(_{k}^{}_{i}/)}{_{j=1}^{C }_{k^{}=1}^{K}Z_{D}(^{})(_{k^{}}^{j }_{i}/)},\] (5)

where \(\) is a temperature coefficient. Given that we have now allocated a corresponding class for each graph embedding, we aim to further encourage: _allocation correctness_, meaning that the allocation should be consistent with the ground truth label; _intra-class compactness_, meaning that graph embeddings should be close to the appropriate prototypes belonging to their own class; and _inter-class separateness_, meaning that graph embeddings should be distant from prototypes of other classes. To achieve _and_ _, we have designed the compactness loss_ below:

\[_{}=-_{t}|}_{i=1}^{|_{t}|}^{K}Z_{D}()(_{k}^{y_{i}} _{i}/)}{_{c=1}^{C}_{k^{}=1}^{K}Z_{D}(^{ })(_{k^{}}^{y_{i}}_{i}/)},\] (6)

where \(y_{i}\) represents the class index for \(_{i}\). Equation (6) is the maximum likelihood estimation of \(_{,}_{i=1}^{|_{t}|}p(y_{i}=c|_{i},\{\{ _{k}^{c},\}_{k=1}^{K}\}_{j=1}^{C})\), which not only boosts the allocation correctness but also enforces graph embeddings to compactly surround the appropriate prototypes. Furthermore, to achieve _, namely encouraging inter-class separateness, we design the separation loss_, optimizing large angular distances among different class prototypes:

\[_{}=_{i=1}^{C}_{j=1}^ {C}_{j i}_{k=1}^{K}(_{k}^{j}_{i}/)\] (7)

where \(()\) is an indicator function. Through the above regularization, we obtain \(C\) prototype clusters \(\{_{c}\}_{c=1}^{C}\), each composed of \(K\) prototype centers \(\{_{k}\}_{k=1}^{K}\) and surrounding sample sets \(\{^{(C)}\}\). After modeling this hypersphere, we proceed with sample selection on the current subset \(^{(t)}\).

### Efficient, Balanced and Robust Graph Debugging

Traditional dynamic dataset pruning methods typically rely on loss-based metrics to select informative subsets [58; 23], which, however, can make the model more vulnerable to imbalance and malicious perturbation (as discussed in Section 1). In this subsection, while selecting a representative subset \(^{(t)}\), we also intend to further ensure it is balanced and noise-free. Our first step is to locate samples that are at risk of being outliers in the embedding space. We propose using a _prototype-based Mahalanobis distance_ to estimate the outlier risk of each graph sample:

\[_{}(_{i})=-_{c}[-_{y_{i} c} _{k}[(_{i}-_{k}^{c})^{}_{k}^{-1}( _{i}-_{k}^{c})]],\] (8)

where \(_{k}^{K K}\) is the sample covariance of all the prototypes in class \(c\). Equation (8) calculates the maximum distance of \(_{i}\) to all prototypes within its class, which serves as a robust outlier detection metric . Furthermore, we intend to evaluate the effectiveness of each sample. Given that the distance of an embedding from its cluster center has been shown to be a good indicator of the model's familiarity with it , we compute the distance of each graph sample to its class-specific prototypes as a familiarity metric:

\[_{}(_{i})=^{K}( _{k}^{y_{i}},_{i})}{_{c=1}^{C}_{k^{}=1}^{K} _{c y_{i}}(_{k^{}}^{y_{i}}, _{i})},\] (9)

which suggests that if a graph sample is significantly closer to its own prototypes and farther from those of other classes, the model is more familiar with it. We implement the distance function using the angular distance in Equation (3). When considering the data balancing issue, we formulate the balancing score for each sample \(_{i}\) as follows:

\[_{}(_{i})=|\{_{i}|_{k} (_{_{i}}(_{k}),_{i}) \}|/|\{_{_{i}}()\}|,\] (10)

where \(_{_{i}}(_{k})\) denotes the closest prototype to \(_{i}\), and \(_{_{i}}()\) denotes the prototype cluster that \(_{i}\) currently belongs to. Equation (10) evaluates whether the graph sample \(_{i}\) belongs to a minority from a prototype-cluster perspective. Finally, we assign sampling probabilities to all samples in \(^{(t)}\):\[(_{i})=}^{}(_{i})}{( _{}^{}(_{i})+)(_{}^{ }(_{i})+)},\] (11)

where \(()^{}\) represents the Sigmoid transformation. Equation (11) is designed to sample with higher probability those samples that the model is less familiar with, have a lower outlier risk, and belong to a minority group. Now, at the \(t\)-th epoch, we obtain the final sampling probability distribution \(^{(t)}():\ _{_{t}})}{_{}()\,d}\,}\). Recall that we have \((1-s)\%\) of samples pruned in the \(t\)-th epoch, _i.e._, \(}_{t}=_{t}\). For \(}_{t}\), we use the probability distribution \(^{(t-1)}()\) from the \((t-1)\)-th epoch 2. Specifically, we formulate \(\)'s coreset sampling function \(_{t}\) in Equation (2) as follows:

\[_{t}(,)=S(_{t},^{(t )}(),(t)) S(}_{t},^{(t-1)}(),(t)),\] (12)

where \(_{t}\) outputs the selected samples \(_{t+1}\) for the next epoch's training, \(S(,,N)\) is a sampling operator that samples \(N\) samples from \(\) with probability distribution \(\), and \((t)\) (\((t)\)) is the scheduler function (with implementation placed in Appendix B.5) that control the number of samples drawn from \(_{t}\) (\(}_{t}\)), respectively, subject to the given budget \((t)+(t)=|| s\%=|_{t}|\).

### Optimization and Extension

OptimizationAside from the original task-specific loss of GNN training denoted as \(_{}\), \(\) has additionally introduced \(_{}\) and \(_{}\). The overall training objective of \(\) is formulated as:

\[_{}=_{}+_{1} _{}+_{2}_{},\] (13)

where \(_{1}\) and \(_{2}\) are co-efficient adjusting the relative importance of two losses. We conclude the algorithm workflow table of \(\) in Appendix C.

ExtensionFinally, we advocate that \(\) is not limited to graph classification but can also be seamlessly adapted to tasks such as graph regression and graph pre-training. The key distinction between these tasks and graph classification is that each graph sample does not have a ground truth class index, which makes ground truth class-based calculations, such as those in Equations (6) and (7), infeasible. One straightforward approach is to manually set \(M\) virtual classes, using the class assigned by Equation (5) as the graph sample's current class. However, this may result in prototypes and hyperspherical embeddings that do not accurately reflect the underlying clustering distribution . To address this, we leverage ProtNCELoss  as a self-supervised signal, providing a more reliable reflection of the data's structure. Detailed implementation can be found in Appendix D.

## 4 Experiments

In this section, we conduct extensive experiments to answer the following research questions: (**RQ1**) Can \(\) effectively boost GNN efficiency (under both supervised and unsupervised settings)? (**RQ2**) Does \(\) genuinely accelerate the GNN training? (**RQ3**) Can \(\) help alleviate graph imbalance? (**RQ4**) Can \(\) aid in robust GNN training?

### Experiment Setup

Datasets and BackbonesWe test \(\) on two widely-used datasets, mutag and dhfr; two OGB large-scale datasets, ogbg-molhiv and ogbg-molpba; one large-scale chemical compound dataset ZINC . Following , we adopt a 25%/25%/50% train/validation/test random split for the mutag and dhfr under imbalanced scenarios and 80%/10%/10% under normal and biased scenarios, both reporting results across 20 data splits. For ogbg-molhiv and ogbg-molpba, we use the official splits provided by . For ZINC, we follow the splits specified in . We choose three representative GNNs, including GCN , PNA  and GraphGPS . Detailed dataset and backbone settings are in Appendices B.1 and B.2.

Parameter ConfigurationsThe hyperparameters in \(\) include the temperature coefficient \(\), prototype count \(K\), loss-specific coefficient \(_{1}\) and \(_{2}\). Practically, we uniformly set \(K=2\), and tune the other three by grid searching: \(\{1e-3,1e-4,1e-5\}\), \(\{1e-1,5e-1\}\),\(\{1e-1,1e-5\}\). Detailed ablation study on hyperparameters is placed in Section 4.5.

### GDeR makes GNN training way faster

To answer **RQ1** and **RQ2**, we comprehensively compare GDeR with **fourteen** widely-used static pruning methods and **three** dynamic pruning methods, as outlined in Table 1, with more detailed explanations in Appendix B.3. Following , we add hard random and soft random pruning as baselines for a more comprehensive comparison. Specifically, we set the dataset remaining ratio \((1-s)\%\{20\%,30\%,50\%,70\%\}\). The performance results are shown in Tables 1, 2 and 7 and the efficiency comparisons are in Figure 3. Our observations (**Obs.**) are as summarized follows:

Obs.\(\)GDeR achieves maximum graph pruning with performance guarantees.As shown in Tables 1 and 2, GDeR consistently outperforms both static or dynamic baselines under various pruning ratios. For instance, on ogbg-molhiv+PNA, GDeR experiences only a \(0.5\%\) performance decay even with \(80\%\) pruning, surpassing the current state-of-the-art method InfoBatch, which suffers a \(1.7\%\) decay. When pruning \(50\%\) and \(30\%\) of the data, GDeR even achieves performance improvements of \(0.1\%\) and \(0.5\%\), respectively.

Obs.\(\)**The degree of redundancy varies across different datasets.We observe that ogbg-molhiv is more sensitive to pruning than ogbg-molhiv, which suggests the degree of redundancy varies between datasets. For example, when pruning \(80\%\) of the data, GraphGPS on ogbg-molpcba exhibits a performance decay ranging between \(3.5\% 13.9\%\), significantly higher than the \(2.5\% 11.5\%\) decay observed on ogbg-molhiv. However, as the remaining ratio increases, GDeR quickly recovers and surpasses the full dataset performance by \(0.2\%\) at the \(50\%\) pruning level.

   &  &  \\   & 20 & 30 & 50 & 70 & 20 & 30 & 50 & 70 \\   & Hard Random & \(72.1_{ 4.2}\) & \(72.4_{ 3.9}\) & \(73.5_{ 2.8}\) & \(75.6_{ 0.7}\) & \(20.5_{ 7.6}\) & \(22.9_{ 5.2}\) & \(24.7_{ 3.4}\) & \(28.0_{ 0.1}\) \\  & CD  & \(71.9_{ 4.4}\) & \(72.6_{ 3.7}\) & \(73.8_{ 2.5}\) & \(75.9_{ 0.4}\) & \(19.8_{ 8.3}\) & \(22.6_{ 5.5}\) & \(23.7_{ 4.4}\) & \(27.8_{ 0.3}\) \\  & Herding  & \(63.0_{ 13.3}\) & \(64.9_{ 11.4}\) & \(66.8_{ 9.5}\) & \(75.2_{ 1.1}\) & \(12.4_{ 15.7}\) & \(14.0_{ 14.1}\) & \(15.5_{ 12.6}\) & \(21.8_{ 6.3}\) \\  & K-Means  & \(61.5_{ 1.8}\) & \(65.9_{ 1.0}\) & \(69.5_{ 6.8}\) & \(74.7_{ 2.6}\) & \(18.5_{ 9.6}\) & \(23.4_{ 4.7}\) & \(23.2_{ 4.9}\) & \(27.6_{ 0.5}\) \\  & Least Confidence  & \(72.1_{ 4.2}\) & \(72.1_{ 43.9}\) & \(75.6_{ 0.7}\) & \(75.9_{ 0.4}\) & \(20.1_{ 1.7}\) & \(23.4_{ 4.2}\) & \(25.0_{ 3.1}\) & \(27.8_{ 0.3}\) \\  & Margin  & \(72.9_{ 3.4}\) & \(71.3_{ 5.0}\) & \(75.1_{ 1.2}\) & \(76.0_{ 0.3}\) & \(20.2_{ 7.9}\) & \(23.3_{ 4.8}\) & \(25.0_{ 3.1}\) & \(28.3_{ 0.2}\) \\  & Forgetting  & \(72.6_{ 3.7}\) & \(73.0_{ 3.3}\) & \(73.9_{ 2.4}\) & \(75.7_{ 0.6}\) & \(20.7_{ 7.4}\) & \(23.1_{ 5.0}\) & \(24.1_{ 4.0}\) & \(27.9_{ 0.2}\) \\  & GraNd-4  & \(68.5_{ 7.8}\) & \(72.7_{ 13.6}\) & \(73.8_{ 2.5}\) & \(75.7_{ 1.0}\) & \(20.2_{ 7.9}\) & \(22.9_{ 5.2}\) & \(25.0_{ 3.1}\) & \(28.0_{ 0.1}\) \\  & GraNd-20  & \(74.1_{ 1.6}\) & \(74.0_{ 2.3}\) & \(74.9_{ 1.4}\) & \(75.9_{ 0.1}\) & \(21.2_{ 6.9}\) & \(23.8_{ 4.3}\) & \(24.9_{ 3.2}\) & \(27.8_{ 0.3}\) \\  & DeepFool  & \(71.9_{ 4.4}\) & \(72.5_{ 8.3}\) & \(73.0_{ 3.3}\) & \(75.6_{ 0.7}\) & \(19.3_{ 8.3}\) & \(22.7_{ 5.4}\) & \(24.0_{ 4.1}\) & \(27.7_{ 0.4}\) \\  & Craig  & \(71.8_{ 4.5}\) & \(72.3_{ 4.0}\) & \(73.5_{ 2.8}\) & \(76.0_{ 0.3}\) & \(20.5_{ 7.6}\) & \(23.1_{ 5.0}\) & \(24.7_{ 3.4}\) & \(27.8_{ 0.3}\) \\  & Glister  & \(73.3_{ 3.0}\) & \(74.4_{ 2.9}\) & \(75.0_{ 1.3}\) & \(76.2_{ 0.1}\) & \(20.6_{ 7.5}\) & \(23.4_{ 4.7}\) & \(25.0_{ 3.1}\) & \(27.9_{ 0.2}\) \\  & Influence  & \(71.5_{ 4.8}\) & \(72.7_{ 13.6}\) & \(73.5_{ 2.5}\) & \(75.2_{ 1.1}\) & \(19.7_{ 1.8}\) & \(22.3_{ 5.8}\) & \(23.9_{ 4.2}\) & \(27.2_{ 0.9}\) \\  & EL2N-2  & \(73.0_{ 3.3}\) & \(74.5_{ 1.8}\) & \(75.0_{ 1.3}\) & \(76.1_{ 0.2}\) & \(20.9_{ 7.2}\) & \(23.5_{ 4.6}\) & \(24.3_{ 3.8}\) & \(27.6_{ 0.5}\) \\  & DP  & \(72.1_{ 4.2}\) & \(73.5_{ 2.8}\) & \(74.7_{ 1.6}\) & \(76.0_{ 0.3}\) & \(20.0_{ 8.1}\) & \(22.7_{ 5.4}\) & \(24.6_{ 3.5}\) & \(27.7_{ 0.4}\) \\   & Soft Random & \(74.3_{ 2.0}\) & \(73.9_{ 2.4}\) & \(76.1_{ 0.2}\) & \(76.2_{ 0.1}\) & \(22.7_{ 5.4}\) & \(24.8_{ 3.3}\) & \(27.0_{ 1.1}\) & \(27.8_{ 0.3}\) \\  & \(\)-greedy  & \(73.8_{ 2.5}\) & \(73.6_{ 2.7}\) & .G \(\) can significantly accelerate GNN training.Figure 3 illustrates the per-epoch time and corresponding performance of each pruning method compared to full dataset training on ogbg-molhiy+GraphGPS. It is evident that \(\) can achieve a \(2.0\) speedup without any performance loss (corresponding to \(50\%\) per-epoch time). Even with a significant \(3.3\) speedup, \(\) only experiences a moderate drop of \(0.9\%\), which is superior to baselines including InfoBatch by a margin of \(1.1\% 4.2\%\). Additionally, we observe from Table 7 that pretraining on ZINC with only \(30\%\) of the data leads to a \(1.53\%\) ROC-AUC improvement, with \(2.81\) training time acceleration.

### GDeR Mitigates Graph Imbalance

To answer **RQ3**, we tested \(\) in extremely imbalanced scenarios and compared its performance with other dynamic pruning methods. Following , we randomly set 25%/25% graphs as training/validation sets and within each of them, we designate one class as the minority class and reduce the number of graphs for this class in the training set (while increasing the others) until the imbalance ratio reached 1:9, which creates an extremely imbalanced scenario. The reported metrics are the average of 50 different data splits to avoid bias from data splitting. We observe from Figure 4 that:

Obs.G \(\) can effectively mitigate imbalance issues.As observed in Figure 4, baseline pruning methods struggle to outperform "no-pruning" GCN, resulting in substantial losses in speedup efficacy. In contrast, \(\) offers a more meaningful pruning approach. For instance, on dhfr, pruning 50% of the data results in a \(4.3\%\)improvement in F1-Macro. This demonstrates that \(\) not only saves computational resources but also effectively mitigates data imbalance issues.

   &  &  \\   & 20 & 30 & 50 & 70 & 20 & 30 & 50 & 70 \\   Least Confidence \\  } & Random & \(69.3_{ 9.4}\) & \(72.7_{ 6.0}\) & \(73.4_{ 5.3}\) & \(75.6_{ 1.3}\) & \(19.4_{ 78}\) & \(21.7_{ 5.5}\) & \(23.9_{ 3.3}\) & \(26.3_{ 0.9}\) \\  & CD  & \(72.6_{ 6.1}\) & \(73.0_{ 5.7}\) & \(75.3_{ 3.4}\) & \(76.7_{ 2.0}\) & \(18.0_{ 9.2}\) & \(20.7_{ 6.5}\) & \(21.7_{ 5.5}\) & \(26.4_{ 0.8}\) \\  & Herding  & \(69.5_{ 9.2}\) & \(73.3_{ 5.4}\) & \(74.5_{ 2.2}\) & \(75.9_{ 2.8}\) & \(13.3_{ 13.9}\) & \(14.0_{ 13.2}\) & \(17.8_{ 9.4}\) & \(23.0_{ 4.2}\) \\  & K-Center  & \(67.2_{ 11.5}\) & \(70.8_{ 79.7}\) & \(72.6_{ 13.9}\) & \(73.9_{ 4.1}\) & \(16.9_{ 10.9}\) & \(19.4_{ 78}\) & \(22.8_{ 4.4}\) & \(26.1_{ 1.1}\) \\  & Least Confidence  & \(73.9_{ 8.4}\) & \(74.2_{ 4.5}\) & \(78.8_{ 2.9}\) & \(77.3_{ 1.4}\) & \(19.4_{ 7.6}\) & \(21.9_{ 5.3}\) & \(23.5_{ 3.7}\) & \(26.0_{ 1.2}\) \\  & Margin  & \(74.0_{ 4.7}\) & \(74.4_{ 4.3}\) & \(75.8_{ 2.9}\) & \(77.5_{ 1.2}\) & \(18.8_{ 8.4}\) & \(21.5_{ 5.7}\) & \(23.9_{ 3.3}\) & \(27.0_{ 0.2}\) \\  & Forgetting  & \(74.2_{ 4.5}\) & \(74.8_{ 3.9}\) & \(75.6_{ 3.1}\) & \(76.9_{ 18}\) & \(18.3_{ 9.9}\) & \(21.9_{ 5.3}\) & \(23.3_{ 3.9}\) & \(26.8_{ 0.4}\) \\  & GraNd-4  & \(73.8_{ 4.9}\) & \(74.2_{ 4.5}\) & \(75.3_{ 3.4}\) & \(77.5_{ 1.2}\) & \(18.0_{ 9.2}\) & \(21.3_{ 5.9}\) & \(23.6_{ 3.6}\) & \(26.9_{ 0.3}\) \\  & DeepFool  & \(72.2_{ 6.5}\) & \(73.3_{ 5.4}\) & \(74.9_{ 3.8}\) & \(75.5_{ 3.2}\) & \(17.6_{ 9.8}\) & \(21.9_{ 19.3}\) & \(23.2_{ 4.4}\) & \(26.5_{ 0.7}\) \\  & Craig  & \(73.5_{ 5.2}\) & \(74.4_{ 4.3}\) & \(76.0_{ 2.7}\) & \(77.9_{ 19.8}\) & \(18.7_{ 2.7}\) & \(24.5_{ 2.7}\) & \(27.1_{ 10.1}\) \\  & Glister  & \(73.6_{ 5.1}\) & \(74.0_{ 4.7}\) & \(78.5_{ 2.9}\) & \(78.0_{ 0.7}\) & \(19.9_{ 7.3}\) & \(22.5_{ 4.4}\) & \(28.2_{ 4.4}\) & \(27.0_{ 0.2}\) \\  & Influence  & \(72.9_{ 5.8}\) & \(73.7_{ 5.0}\) & \(74.8_{ 3.9}\) & \(77.4_{ 3.3}\) & \(17.7_{ 5.5}\) & \(21.9_{ 5.3}\) & \(23.5_{ 3.7}\) & \(26.6_{ 0.6}\) \\  & EL2N-20  & \(74.0_{ 4.7}\) & \(75.5_{ 3.2}\) & \(76.9_{ 1.8}\) & \(77.7_{ 1.0}\) & \(19.1_{ 1.8}\) & \(22.9_{ 4.3}\) & \(24.0_{ 3.2}\) & \(26.0_{ 1.2}\) \\  & DP  & \(72.0_{ 6.7}\) & \(74.1_{ 4.6}\) & \(76.0_{ 2.7}\) & \(76.9_{ 1.8}\) & \(19.6_{ 7.6}\) & \(21.5_{ 5.7}\) & \(24.9_{ 2.3}\) & \(26.4_{ 0.8}\) \\   Obs. \(\) \\  } & Soft Random & \(74.0_{ 4.7}\) & \(74.9_{ 3.8}\) &

### GDeR Aids in GNN Robustness

We divide **RQ4** into two sub-questions: (1) Is GDeR more robust to outlier perturbation compared to previous data pruning methods? (2) Can GDeR compete with mainstream methods designed to enhance GNN robustness? In practice, following , we introduce perturbations to \(k\%\) of the graph samples in the training set by adding Gaussian noise to the node features of the selected graphs. We compare GDeR against both data pruning baselines and GNN robustness enhancement baselines. The experimental results are presented in Figure 5, and we observe:

Obs.GDeR is a resource-saving GNN robustness booster.From Figure 5 (_Left_), we observe that GDeR effectively counters noise perturbation, outperforming the GNN under outlier attacks at both \(30\%\) and \(50\%\) pruning rates. Notably, InfoBatch, which performed competitively in **RQ1**, suffers a significant performance drop (\(2.0\% 6.1\%\)) in this biased training scenario, which is likely due to its loss magnitude-based sample selection mechanism, inadvertently amplifying the negative impact of high-loss outlier samples on the model. From Figure 5 (_Right_), we conclude that GDeR performs as well as or better than current robust GNN plugins, and it shows the most significant improvement in accuracy, with increases of \(3.6\%\) and \(7.8\%\) at noise ratios of \(5\%\) and \(30\%\), respectively.

### Ablation & Sensitivity Study

**Ablation Study** To evaluate the effectiveness of the different modules in GDeR, we propose three variants: (1) GDeR w/o \(_{e}\), (2) GDeR w/o \(_{r}\), and (3) GDeR w/o \(_{b}\). GDeR w/o \(_{e}\) represents removing \(_{e}\) from Equation (11), with the other two variants defined similarly. We observe from Table 3 that removing any component leads to a performance drop for GDeR, while removing \(_{b}\) in the imbalance scenario or \(_{r}\) in the biased scenario results in the most significant impact; GDeR w/o \(_{e}\) consistently underperforms across all scenarios, indicating that selecting highly representative samples is fundamental to the success of dynamic pruning methods.

Sensitivity and Efficiency AnalysisWe investigate the impact of \(K\), on the performance and efficiency of GDeR. Specifically, we vary \(K\{1,2,4\}\) on ogbg-moldiv+GraphGPS and observe changes in performance and per-epoch time. We observe from Table 4 that \(K=1\) leads to an under-learning of the hypersphere, resulting in consistently lower performance. While \(K=4\) shows a marginal performance gain compared to \(K=2\), for efficiency considerations, we opt for \(K=2\) across all experiments. Additionally, we observe that data pruning significantly saves per-epoch time, with \(s=20\) resulting in per-epoch times being \(40\% 60\%\) of those achieved with \(s=70\).

   Ratio (\(\%\)) & Metric & \(K=1\) & \(K=2\) & \(K=4\) \\   & Perf. & \(75.8_{ 1.5}\) & \(_{ 1.4}\) & \(76.1_{ 0.9}\) \\  & Time & \(15.32\) & \(16.44\) & \(17.16\) \\  & Perf. & \(78.2_{ 1.4}\) & \(78.7_{ 1.3}\) & \(_{ 0.23}\) \\  & Time & \(19.97\) & \(20.18\) & \(22.08\) \\  & Perf. & \(81.9_{ 2.0}\) & \(79.1_{ 1.9}\) & \(_{ 2.2}\) \\  & Perf. & \(26.19\) & \(31.30\) & \(39.55\) \\   

Table 4: Sensitivity analysis on \(K\). We report the ROCAUC (%) and per-epoch time (s) on ogbg-moldiv+GraphGPS.

Figure 5: (_Left_) We report the performance of several top-performing pruning methods when perturbation noise is added to \(10\%\) of the training set of mutag. The black dashed line represents the original GNN performance without pruning. (_Right_) We compare GDeR with DropEdge and GRAND under different noise settings, utilizing GDeR with pruning ratios of \(10\%\) and \(30\%\).

Conclusion & Future Work

In this work, we propose the graph training debugging concept and explore soft dataset pruning in the graph learning area for the first time. Particularly, we present a prototype-guided soft pruning method, termed GDeR, which initially establishes a well-modeled graph embedding hypersphere and subsequently samples _representative, balanced, and noise-free subsets_ from this embedding space, debugging and troubleshooting graph processing. In the future, we plan to extend this concept to the CV realm, aiming to expedite the process of image training and provide efficient insights for the development of high-quality visual large-scale models.