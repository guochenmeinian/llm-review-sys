# Online Corrupted User Detection and Regret Minimization

Zhiyong Wang

The Chinese University of Hong Kong

zywang21@cse.cuhk.edu.hk

&Jize Xie

Shanghai Jiao Tong University

xjzzjl@sjtu.edu.cn

&Tong Yu

Adobe Research

worktongyu@gmail.com

&Shuai Li

Shanghai Jiao Tong University

shuaili8@sjtu.edu.cn

&John C.S. Lui

The Chinese University of Hong Kong

cslui@cse.cuhk.edu.hk

Corresponding author.

###### Abstract

In real-world online web systems, multiple users usually arrive sequentially into the system. For applications like click fraud and fake reviews, some users can maliciously perform corrupted (disrupted) behaviors to trick the system. Therefore, it is crucial to design efficient online learning algorithms to robustly learn from potentially corrupted user behaviors and accurately identify the corrupted users in an online manner. Existing works propose bandit algorithms robust to adversarial corruption. However, these algorithms are designed for a single user, and cannot leverage the implicit social relations among multiple users for more efficient learning. Moreover, none of them consider how to detect corrupted users online in the multiple-user scenario. In this paper, we present an important online learning problem named LOCUD to learn and utilize unknown user relations from disrupted behaviors to speed up learning, and identify the corrupted users in an online setting. To robustly learn and utilize the unknown relations among potentially corrupted users, we propose a novel bandit algorithm RCLUB-WCU. To detect the corrupted users, we devise a novel online detection algorithm OCCUD based on RCLUB-WCU's inferred user relations. We prove a regret upper bound for RCLUB-WCU, which asymptotically matches the lower bound with respect to \(T\) up to logarithmic factors, and matches the state-of-the-art results in degenerate cases. We also give a theoretical guarantee for the detection accuracy of OCCUD. With extensive experiments, our methods achieve superior performance over previous bandit algorithms and high corrupted user detection accuracy.

## 1 Introduction

In real-world online recommender systems, data from many users arrive in a streaming fashion . There may exist some corrupted (malicious) users, whose behaviors (_e.g._, click, rating) can be adversarially corrupted (disrupted) over time to fool the system . These corrupted behaviors could disrupt the user preference estimations of the algorithm. As a result, the system would easily be misled and make sub-optimal recommendations ,which would hurt the user experience. Therefore, it is essential to design efficient online learning algorithms to robustly learn from potentially disrupted behaviors and detect corrupted users in an online manner.

There exist some works on bandits with adversarial corruption . However, they have the following limitations. First, existing algorithms are initially designed for robust online preference learning of a single user. In real-world scenarios with multiple users, they cannot robustly infer and utilize the implicit user relations for more efficient learning. Second, none of them consider how to identify corrupted users online in the multiple-user scenario. Though there also exist some works on corrupted user detection , they all focus on detection with _known_ user information in an offline setting, thus can not be applied to do online detection from bandit feedback.

To address these limitations, we propose a novel bandit problem "_Learning and Online Corrupted Users Detection from bandit feedback_" (LOCUD). To model and utilize the relations among users, we assume there is an _unknown_ clustering structure over users, where users with similar preferences lie in the same cluster . The agent can infer the clustering structure to leverage the information of similar users for better recommendations. Among these users, there exists a small fraction of corrupted users. They can occasionally perform corrupted behaviors to fool the agent  while mimicking the behaviors of normal users most of the time to make themselves hard to discover. The agent not only needs to learn the _unknown_ user preferences and relations robustly from potentially disrupted feedback, balance the exploration-exploitation trade-off to maximize the cumulative reward, but also needs to detect the corrupted users online from bandit feedback.

The LOCUD problem is very challenging. First, the corrupted behaviors would cause inaccurate user preference estimations, which could lead to erroneous user relation inference and sub-optimal recommendations. Second, it is nontrivial to detect corrupted users online since their behaviors are dynamic over time (sometimes regular while sometimes corrupted), whereas, in the offline setting, corrupted users' information can be fully represented by static embeddings and the existing approaches  can typically do binary classifications offline, which are not adaptive over time.

We propose a novel learning framework composed of two algorithms to address these challenges.

**RCLUB-WCU.** To robustly estimate user preferences, learn the unknown relations from potentially corrupted behaviors, and perform high-quality recommendations, we propose a novel bandit algorithm "_Robust CLUstering of Bandits With Corrupted Users_" (RCLUB-WCU), which maintains a dynamic graph over users to represent the learned clustering structure, where users linked by edges are inferred to be in the same cluster. RCLUB-WCU adaptively deletes edges and recommends arms based on aggregated interactive information in clusters. We do the following to ensure robust clustering structure learning. (i) To relieve the estimation inaccuracy caused by disrupted behaviors, we use weighted ridge regressions for robust user preference estimations. Specifically, we use the inverse of the confidence radius to weigh each sample. If the confidence radius associated with user \(i_{t}\) and arm \(a_{t}\) is large at \(t\), the learner is quite uncertain about the estimation of \(i_{t}\)'s preference on \(a_{t}\), indicating the sample at \(t\) is likely to be corrupted. Therefore, we use the inverse of the confidence radius to assign minor importance to the possibly disrupted samples when doing estimations. (ii) We design a robust edge deletion rule to divide the clusters by considering the potential effect of corruptions, which, together with (i), can ensure that after some interactions, users in the same connected component of the graph are in the same underlying cluster with high probability.

**OCCUD.** To detect corrupted users online, based on the learned clustering structure of RCLUB-WCU, we devise a novel algorithm named "_Online Cluster-based Corrupted User Detection_" (OC-CUD). At each round, we compare each user's non-robustly estimated preference vector (by ridge regression) and the robust estimation (by weighted regression) of the user's inferred cluster. If the gap exceeds a carefully-designed threshold, we detect this user as corrupted. The intuitions are as follows. With misleading behaviors, the non-robust preference estimations of corrupted users would be far from ground truths. On the other hand, with the accurate clustering of RCLUB-WCU, the robust estimations of users' inferred clusters should be close to ground truths. Therefore, for corrupted users, their non-robust estimates should be far from the robust estimates of their inferred clusters.

We summarize our contributions as follows.

\(\) We present a novel online learning problem LOCUD, where the agent needs to (i) robustly learn and leverage the unknown user relations to improve online recommendation qualities under the disruption of corrupted user behaviors; (ii) detect the corrupted users online from bandit feedback.

\(\) We propose a novel online learning framework composed of two algorithms, RCLUB-WCU and OCCUD, to tackle the challenging LOCUD problem. RCLUB-WCU robustly learns and utilizes the unknown social relations among potentially corrupted users to efficiently minimize regret. Based on RCLUB-WCU's inferred user relations, OCCUD accurately detects corrupted users online.

\(\) We prove a regret upper bound for RCLUB-WCU, which matches the lower bound asymptotically in \(T\) up to logarithmic factors and matches the state-of-the-art results in several degenerate cases. We also give a theoretical performance guarantee for the online detection algorithm OCCUD.

\(\) Experiments on both synthetic and real-world data clearly show the advantages of our methods.

## 2 Related Work

Our work is related to bandits with adversarial corruption and bandits leveraging user relations.

The work  first studies stochastic bandits with adversarial corruption, where the rewards are corrupted with the sum of corruption magnitudes in all rounds constrained by the _corruption level_\(C\). They propose a robust elimination-based algorithm. The paper  proposes an improved algorithm with a tighter regret bound. The paper  first studies stochastic linear bandits with adversarial corruptions. To tackle the contextual linear bandit setting where the arm set changes over time, the work  proposes a variant of the OFUL  that achieves a sub-linear regret. A recent work  proposes the CW-OFUL algorithm that achieves a nearly optimal regret bound. All these works focus on designing robust bandit algorithms for a single user; none consider how to robustly learn and leverage the implicit relations among potentially corrupted users for more efficient learning. Moreover, none of them consider how to online detect corrupted users in the multiple-user case.

Some works study how to leverage user relations to accelerate the bandit learning process in the multiple-user case. The work  utilizes a _known_ user adjacency graph to share context and payoffs among neighbors. To adaptively learn and utilize _unknown_ user relations, the paper  proposes the clustering of bandits (CB) problem where there is an _unknown_ user clustering structure to be learned by the agent. The work  uses collaborative effects on items to guide the clustering of users. The paper  studies the CB problem in the cascading bandit setting. The work  considers the setting where users in the same cluster share both the same preference and the same arrival rate. The paper  studies the federated CB problem, considering privacy and communication issues. All these works only consider utilizing the relations among normal users; none of them consider how to robustly learn the user relations from potentially disrupted behaviors, thus would easily be misled by corrupted users. Also, none of them consider how to detect corrupted users from bandit feedback.

To the best of our knowledge, this is the first work to study the problem to (i) learn the unknown user relations and preferences from potentially corrupted feedback, and leverage the learned relations to speed up learning; (ii) adaptively detect the corrupted users online from bandit feedback.

## 3 Problem Setup

This section formulates the problem of "_Learning and Online Corrupted Users Detection from bandit feedback_" (LOCUD) (illustrated in Fig.1). We denote \(\|\|_{}=^{}}\), \([m]=\{1,,m\}\), number of elements in set \(\) as \(||\).

In LOCUD, there are \(u\) users, which we denote by set \(=\{1,2,,u\}\). Some of them are corrupted users, denoted by set \(}\). These corrupted users, on the one hand, try to mimic normal users to make themselves hard to detect; on the other hand, they can occasionally perform corrupted behaviors to fool the agent into making sub-optimal decisions. Each user \(i\), no matter a normal one or corrupted one, is associated with a (possibly mimicked for corrupted users) preference feature vector \(_{i}^{d}\) that is _unknown_ and \(\|_{i}\|_{2} 1\). There is an underlying clustering structure among all the users representing the similarity of their preferences, but it is _unknown_ to the agent and needs to be learned via interactions. Specifically, the set of users \(\) can be partitioned into \(m\) (\(m u\)) clusters, \(V_{1},V_{2}, V_{m}\), where \(_{j[m]}V_{j}=\), and \(V_{j} V_{j^{}}=\), for \(j j^{}\). Users in the same cluster have the same preference feature vector, while users in different clusters have different preference vectors. We use \(^{j}\) to denote the common preference vector shared by users in the \(j\)-th cluster \(V_{j}\), and use \(j(i)\) to denote the index of cluster user \(i\) belongs to (_i.e.,_\(i V_{j(i)}\)). For any two users \(k,i\), if \(k V_{j(i)}\), then \(_{k}=^{j(i)}=_{i}\); otherwise \(_{k}_{i}\). We assume the arm set \(^{d}\) is finite. Each arm \(a\) is associated with a feature vector \(_{a}^{d}\) with \(_{a}_{2} 1\).

The learning process of the agent is as follows. At each round \(t[T]\), a user \(i_{t}\) comes to be served, and the learning agent receives a set of arms \(_{t}\) to choose from. The agent infers the cluster \(V_{t}\) that user \(i_{t}\) belongs to based on the interaction history, and recommends an arm \(a_{t}_{t}\) according to the aggregated information gathered in the cluster \(V_{t}\). After receiving the recommended arm \(a_{t}\), a normal user \(i_{t}\) will give a random reward with expectation \(_{a_{t}}^{}_{i_{t}}\) to the agent.

To model the behaviors of corrupted users, following [29; 9; 5; 12], we assume that they can occasionally corrupt the rewards to mislead the agent into recommending sub-optimal arms. Specifically, at each round \(t\), if the current served user is a corrupted user (i.e., \(i_{t}}\)), the user can corrupt the reward by \(c_{t}\). In summary, we model the reward received by the agent at round \(t\) as

\[r_{t}=_{a_{t}}^{}_{i_{t}}+_{t}+c_{t}\,,\]

where \(c_{t}=0\) if \(i_{t}\) is a normal user, (_i.e._, \(i_{t}}\)), and \(_{t}\) is 1-sub-Gaussian random noise.

As the number of corrupted users is usually small, and they only corrupt the rewards occasionally with small magnitudes to make themselves hard to detect, we assume the sum of corruption magnitudes in all rounds is upper bounded by the _corruption level_\(C\), _i.e._, \(_{t=1}^{T} c_{t} C\)[29; 9; 5; 12].

We assume the clusters, users, and items satisfy the following assumptions. Note that all these assumptions basically follow the settings from classical works on clustering of bandits [8; 19; 25; 36].

**Assumption 1** (Gap between different clusters).: _The gap between any two preference vectors for different clusters is at least an unknown positive constant \(\)_

\[^{j}-^{j^{}}_{2} >0\,, j,j^{}[m]\,,j j^{}\,.\]

**Assumption 2** (Uniform arrival of users).: _At each round \(t\), a user \(i_{t}\) comes uniformly at random from \(\) with probability \(1/u\), independent of the past rounds._

**Assumption 3** (Item regularity).: _At each round \(t\), the feature vector \(_{a}\) of each arm \(a_{t}\) is drawn independently from a fixed unknown distribution \(\) over \(\{^{d}:_{2} 1\}\), where \(_{}[^{}]\)'s minimal eigenvalue \(_{x}>0\). At \( t\), for any fixed unit vector \(^{d}\), \((^{})^{2}\) has sub-Gaussian tail with variance no greater than \(^{2}\)._

Let \(a_{t}^{*}_{a_{t}}_{a}^{}_{i_{t}}\) denote an optimal arm with the highest expected reward at round \(t\). One objective of the learning agent is to minimize the expected cumulative regret

\[R(T)=[_{t=1}^{T}(_{a_{t}^{}}^{}_{i_{t} }-_{a_{t}}^{}_{i_{t}})]\,.\] (1)

Another objective is to detect corrupted users online accurately. Specifically, at round \(t\), the agent will give a set of users \(}_{t}\) as the detected corrupted users, and we want \(}_{t}\) to be as close to the ground-truth set of corrupted users \(}\) as possible.

## 4 Algorithms

This section introduces our algorithms RCLUB-WCU (Algo.1) and OCCUD (Algo.2). RCLUB-WCU robustly learns the unknown user clustering structure and preferences from corrupted feed

Figure 1: Illustration of LOCUD. The _unknown_ user relations are represented by dotted circles, _e.g._, user 3, 7 have similar preferences and thus can be in the same user segment (_i.e._, cluster). Users 6 and 8 are corrupted users with dynamic behaviors over time (_e.g._, for user 8, the behaviors are normal at \(t_{1}\) and \(t_{3}\) (blue), but are adversarially corrupted at \(t_{2}\) and \(t_{4}\) (red)[29; 12]), making them hard to be detected online. The agent needs to learn user relations to utilize information among similar users to speed up learning, and detect corrupted users 6, 8 online from bandit feedback.

back, and leverages the cluster-based information to accelerate learning. Based on the clustering structure learned by RCLUB-WCU, OCCUD can accurately detect corrupted users online.

```
1:Input: Regularization parameter \(\), confidence radius parameter \(\), threshold parameter \(\), edge deletion parameter \(_{1}\), \(f(T)=\).
2:Initialization:\(_{i,0}=_{d d},_{i,0}=_{d 1},}_{i,0}=_{d  d},}_{i,0}=_{d 1},T_{i,0}=0\), \( i\); A complete graph \(G_{0}=(,E_{0})\) over \(\).
3:forall\(t=1,2,,T\)do
4: Receive the index of the current served user \(i_{t}\), get the feasible arm set at this round \(_{t}\).
5: Determine the connected components \(V_{t}\) in the current maintained graph \(G_{t-1}=(,E_{t-1})\) such that \(i_{t} V_{t}\).
6: Calculate the robustly estimated statistics for the cluster \(V_{t}\): \(_{V_{t},t-1}=+_{i V_{t}}_{i,t-1},_{V_{t},t-1}=_{i V_{t}}_{i,t-1},}_{V_{t},t-1}=_{V_ {t},t-1}^{-1}_{V_{t},t-1}\) ;
7: Select an arm \(a_{t}\) with largest UCB index in Eq.(3) and receive the corresponding reward \(r_{t}\);
8: Update the statistics for robust estimation of user \(i_{t}\): \(_{i_{t},t}=_{i_{t},t-1}+w_{i_{t},t-1}_{a_{t}}_{i_{t}}^ {},_{i_{t},t}=_{i_{t},t-1}+w_{i_{t},t-1}r_{t}_{a_{t}}\,,T _{i_{t},t}=T_{i_{t},t-1}+1\,,\) \(_{i_{t},t}^{}=+_{i_{t},t},}_{i_{ t},t}=_{i_{t},t}^{-1}_{i_{t},t}\,,w_{i_{t},t}=\{1, /\|_{a_{t}}\|_{_{i_{t},t}^{-1}}\}\) ;
9: Keep robust estimation statistics of other users unchanged: \(_{,t}=_{,t-1},_{,t}=_{,t-1},T_{,t} =T_{,t-1}\), \(}_{,t}=_{,t-1}\), for all \(, i_{t}\);
10: Delete the edge \((i_{t},) E_{t-1}\), if \[\|}_{i_{t},t}-}_{,t}\|_{2} _{1}f(T_{i_{t},t})+f(T_{,t})+ C\,,\] and get an updated graph \(G_{t}=(,E_{t})\);
11: Use the OCCUD Algorithm (Algo.2) to detect the corrupted users.
12:endfor ```

**Algorithm 1** RCLUB-WCU

### RCLUB-WCU

The corrupted behaviors may cause inaccurate preference estimations, leading to erroneous relation inference and sub-optimal decisions. In this case, how to learn and utilize unknown user relations to accelerate learning becomes non-trivial. Motivated by this, we design RCLUB-WCU as follows.

**Assign the inferred cluster \(V_{t}\) for user \(i_{t}\).** RCLUB-WCU maintains a dynamic undirected graph \(G_{t}=(,E_{t})\) over users, which is initialized to be a complete graph (Algo.1 Line 2). Users with similar learned preferences will be connected with edges in \(E_{t}\). The connected components in the graph represent the inferred clusters by the algorithm. At round \(t\), user \(i_{t}\) comes to be served with a feasible arm set \(_{t}\) for the agent to choose from (Line 4). In Line 5, RCLUB-WCU detects the connected component \(V_{t}\) in the graph containing user \(i_{t}\) to be the current inferred cluster for \(i_{t}\).

**Robust preference estimation of cluster \(V_{t}\).** After determining the cluster \(V_{t}\), RCLUB-WCU estimates the common preferences for users in \(V_{t}\) using the historical feedback of all users in \(V_{t}\) and recommends an arm accordingly. The corrupted behaviors could cause inaccurate preference estimates, which can easily mislead the agent. To address this, inspired by , we use weighted ridge regression to make corruption-robust estimations. Specifically, RCLUB-WCU robustly estimates the common preference vector of cluster \(V_{t}\) by solving the following weighted ridge regression

\[}_{V_{t},t-1}=*{arg\,min}_{^{d}}_{i_{t} V_{t}}w_{i_{s},s}(r_{s}-_{a_{s}}^{})^{2}+\|\|_{2}^{2}\,,\] (2)

where \(>0\) is a regularization coefficient. Its closed-form solution is \(}_{V_{t},t-1}=_{V_{t},t-1}^{-1}_{V_{t},t-1}\), where \(_{V_{t},t-1}=+_{i_{s} V_{t}}w_{i_{s},s}_{a_{s}} _{a_{s}}^{}\), \(_{V_{t},t-1}=_{i_{s}[t-1] i_{s} V_{t}}w_{i_{s},s}r_{a_{s}} _{a_{s}}\).

We set the weight of sample for user \(i_{s}\) in \(V_{t}\) at round \(s\) as \(w_{i_{s},s}=\{1,/\|_{a_{s}}\|_{M_{i_{s},s}^{-1}}\}\), where \(\) is a coefficient to be determined later. The intuitions of designing these weights are as follows. The term \(\|_{a_{s}}\|_{M_{i_{s},s}^{-1}}\) is the confidence radius of arm \(a_{s}\) for user \(i_{s}\) at \(s\), reflecting how confident the algorithm is about the estimation of \(i_{s}\)'s preference on \(a_{s}\) at \(s\). If \(\|_{a_{s}}\|_{M_{i_{s},s}^{-1}}\) is large, it means the agent is uncertain of user \(i_{s}\)'s preference on \(a_{s}\), indicating this sample is probably corrupted.

Therefore, we use the inverse of confidence radius to assign a small weight to this round's sample if it is potentially corrupted. In this way, uncertain information for users in cluster \(V_{}\) is assigned with less importance when estimating the \(V_{t}\)'s preference vector, which could help relieve the estimation inaccuracy caused by corruption. For technical details, please refer to Section 5.1 and Appendix.

**Recommend \(a_{t}\) with estimated preference of cluster \(V_{t}\).** Based on the corruption-robust preference estimation \(}_{V_{t},t-1}\) of cluster \(V_{t}\), in Line 7, the agent recommends an arm using the upper confidence bound (UCB) strategy to balance exploration and exploitation

\[a_{t}=*{argmax}_{a_{t}}_{a}^{}}_{V_{t},t-1}+_{a}_{_{V_{t},t-1 }^{-1}}_{a,t}+C_{a,t}\,,\] (3)

where \(=+)+d(1+ )}+ C\) is the confidence radius parameter, \(_{a,t}\) denotes the estimated reward of arm \(a\) at \(t\), \(C_{a,t}\) denotes the confidence radius of arm \(a\) at \(t\). The design of \(C_{a,t}\) theoretically relies on Lemma 2 that will be given in Section 5.

**Update the robust estimation of user \(i_{t}\).** After receiving \(r_{t}\), the algorithm updates the estimation statistics of user \(i_{t}\), while keeping the statistics of others unchanged (Line 8 and Line 9). Specifically, RCLUB-WCU estimates the preference vector of user \(i_{t}\) by solving a weighted ridge regression

\[}_{i_{t},t}=*{arg\,min}_{^{d}}_{i_{a}=i_{t}}w_{i_{s},s}(r_{s}-_{a_{s}}^{})^{2}+_{2}^{2}\] (4)

with closed-form solution \(}_{i_{t},t}=(+_{i_{t},t})^{-1}_{i_{t},t}\,,\) where \(_{i_{t},t}=_{=i_{t}}}w_{ i_{s},s}_{a_{s}}_{a_{s}}^{}\), \(_{i_{t},t}=_{=i_{t}}}w_{ i_{s},s}r_{a_{s}}_{a_{s}}\,,\) and we design the weights in the same way by the same reasoning.

**Update the dynamic graph.** Finally, with the updated statistics of user \(i_{t}\), RCLUB-WCU checks

```
1: Initialize \(}_{t}=\); input probability parameter \(\).
2: Update the statistics for non-robust estimation of user \(i_{t}\)\(}_{i_{t},t}=}_{i_{t},t-1}+_{a_{t}}_{a_{t}}^ {}\), \(}_{i_{t},t}=}_{i_{t},t-1}+r_{t}_{a_{t}}\,,\)\(}_{i_{t},t}=(+}_{i_{t},t})^{-1}}_{i_{t},t }\,,\)
3: Keep non-robust estimation statistics of other users unchanged\(}_{,t}=}_{,t-1},}_{,t}= }_{,t-1},}_{,t}=}_{ ,t-1},\) for all \(, i_{t}\,.\)
4:for all connected component \(V_{j,t} G_{t}\)do
5: Calculate the robust estimation statistics for the cluster \(V_{j,t}\): \(_{V_{j,t},t}=+_{ V_{j,t}}_{,t}\,,T_{V_ {j,t}}=_{ V_{j,t}}T_{,t}\,,\)\(_{V_{j,t},t}=_{ V_{j,t}}_{V_{j,t},}\,,\)\(}_{V_{j,t},}=_{V_{j,t},}^{-1}_{V_{j,t},}\,;\)
6:for all user \(i V_{j,t}\)do
7: Detect user \(i\) to be a corrupted user and add user \(i\) to the set \(}_{t}\) if the following holds: \[}_{i,t}-}_{V_{i,t},t} _{2}>}{ d})+2()}+ }{}(}_{i,t})}+}+ ,t}}{ d})+2()}+ + C}{}(_{V_{i,t},t})}}\,,\] (5) where \(_{}()\) denotes the minimum eigenvalue of the matrix argument.
8:endfor
9:endfor ```

**Algorithm 2** OCCUD (At round \(t\), used in Line 11 in Algo.1)

whether the inferred \(i_{t}\)'s preference similarities with other users are still true, and updates the graph accordingly. Precisely, if gap between the updated estimation \(}_{i_{t},t}\) of \(i_{t}\) and the estimation \(}_{,t}\) of user \(\) exceeds a threshold in Line 10, RCLUB-WCU will delete the edge \((i_{t},)\) in \(G_{t-1}\) to split them apart. The threshold is carefully designed to handle the estimation uncertainty from both stochastic noises and potential corruptions. The updated graph \(G_{t}=(,E_{t})\) will be used in the next round.

### Occud

Based on the inferred clustering structure of RCLUB-WCU, we devise a novel online detection algorithm OCCUD (Algo.2). The design ideas and process of OCCUD are as follows.

Besides the robust preference estimations (with weighted regression) of users and clusters kept by RCLUB-WCU, OCCUD also maintains the non-robust estimations for each user by online ridge regression without weights (Line 2 and Line 3). Specifically, at round \(t\), OCCUD updates the non-robust estimation of user \(i_{t}\) by solving the following online ridge regression:

\[}_{i_{t},t}=*{arg\,min}_{^{d}}_{{}_{s[t]}_{s i_{t}}}{(r_{s}-_{a_{s}}^{ })^{2}}+\|\|_{2}^{2}\,\] (6)

with solution \(}_{i_{t},t}=(+}_{i_{t},t})^{-1} }_{i_{t},t}\), where \(}_{i_{t},t}=_{{}_{s[t]}_{s[t]}}{_{a _{s}}_{a_{s}}^{}}}_{i_{t},t}=_{{}_{s[t]} _{i_{s}=i_{t}}}{r_{a_{s}}_{a_{s}}}\).

With the robust and non-robust preference estimations, OCCUD does the following to detect corrupted users based on the clustering structure inferred by RCLUB-WCU. First, OCCUD finds the connected components in the graph kept by RCLUB-WCU, which represent the inferred clusters. Then, for each inferred cluster \(V_{j,t} G_{t}\): (1) OCCUD computes its robustly estimated preferences vector \(}_{V_{i,t}}\) (Line 5). (2) For each user \(i\) whose inferred cluster is \(V_{j,t}\) (_i.e.,\(i V_{j,t}\)_), OCCUD computes the gap between user \(i\)'s non-robustly estimated preference vector \(}_{i,t}\) and the robust estimation \(}_{V_{i,t},t}\) for user \(i\)'s inferred cluster \(V_{j,t}\). If the gap exceeds a carefully-designed threshold, OCCUD will detect user \(i\) as corrupted and add \(i\) to the detected corrupted user set \(}_{t}\) (Line 7).

The intuitions of OCCUD are as follows. On the one hand, after some interactions, RCLUB-WCU will infer the user clustering structure accurately. Thus, at round \(t\), the robust estimation \(}_{V_{i,t},t}\) for user \(i\)'s inferred cluster should be pretty close to user \(i\)'s ground-truth preference vector \(_{i}\). On the other hand, since the feedback of normal users are always regular, at round \(t\), if user \(i\) is a normal user, the non-robust estimation \(}_{i,t}\) should also be close to the ground-truth \(_{i}\). However, the non-robust estimation of a corrupted user should be quite far from the ground truth due to corruptions. Based on this reasoning, OCCUD compares each user's non-robust estimation and the robust estimation of the user's inferred cluster to detect the corrupted users. For technical details, please refer to Section 5.2 and Appendix. Simple illustrations of our proposed algorithms can be found in Fig.2.

## 5 Theoretical Analysis

In this section, we theoretically analyze the performances of our proposed algorithms, RCLUB-WCU and OCCUD. Due to the page limit, we put the proofs in the Appendix.

### Regret Analysis of RCLUB-WCU

This section gives an upper bound of the expected regret (defined in Eq.(1)) for RCLUB-WCU.

The following lemma provides a sufficient time \(T_{0}()\), after which RCLUB-WCU can cluster all the users correctly with high probability.

Figure 2: Algorithm illustrations. Users 6 and 8 are corrupted users (orange), and the others are normal (green). (a) illustrates RCLUB-WCU, which starts with a complete user graph, and adaptively deletes edges between users (dashed lines) with dissimilar robustly learned preferences. The corrupted behaviors of users 6 and 8 may cause inaccurate preference estimations, leading to erroneous relation inference. In this case, how to delete edges correctly is non-trivial, and RCLUB-WCU addresses this challenge (detailed in Section 4.1). (b) illustrates OCCUD at some round \(t\), where person icons with triangle hats represent the non-robust user preference estimations. The gap between the non-robust estimation of user 6 and the robust estimation of user 6â€™s inferred cluster (circle \(C_{1}\)) exceeds the threshold \(r_{6}\) at this round (Line 7 in Algo.2), so OCCUD detects user 6 to be corrupted.

**Lemma 1**.: _With probability at least \(1-3\), RCLUB-WCU will cluster all the users correctly after_

\[T_{0}() 16u()+4u\{ }}(),_{x}^{2}}(_{x}^{2}}),}{^{2}_{x}},}{^{2}}}\}\]

_for some \((0,)\), where \(_{x}_{0}^{_{x}}(1-e^{-- x)^{2}}{2^{2}}})Kdx\), \(|_{t}| K, t[T]\)._

After \(T_{0}()\), the following lemma gives a bound of the gap between \(}_{V_{t},t-1}\) and the ground-truth \(_{i_{t}}\) in direction of action vector \(_{a}\) for RCLUB-WCU, which supports the design in Eq.(3).

**Lemma 2**.: _With probability at least \(1-4\) for some \((0,)\), \( t T_{0}()\), we have:_

\[_{a}^{}(}_{V_{t},t-1}-_{i_ {t}})\,\|_{}\|_{_{V_{t},t-1}^{-1}} C _{a,t}\,.\]

With Lemma 1 and 2, we prove the following theorem on the regret upper bound of RCLUB-WCU.

**Theorem 3** (**Regret Upper Bound of RCLUB-WCU)**.: _With the assumptions in Section 3, and picking \(=+}{C}\), the expected regret of the RCLUB-WCU algorithm for \(T\) rounds satisfies_

\[R(T) O(}{^{2}_{x}}+_{x}^{2}})u(T)+Od(T)+O mCd^{1.5}(T)\,.\] (7)

**Discussion and Comparison.** The regret bound in Eq.(7) has three terms. The first term is the time needed to get enough information for accurate robust estimations such that RCLUB-WCU could cluster all users correctly afterward with high probability. This term is related to the _corruption level_\(C\), which is inevitable since, if there are more corrupted user feedback, it will be harder for the algorithm to learn the clustering structure correctly. The last two terms correspond to the regret after \(T_{0}\) with the correct clustering. Specifically, the second term is caused by stochastic noises when leveraging the aggregated information within clusters to make recommendations; the third term associated with the _corruption level_\(C\) is the regret caused by the disruption of corrupted behaviors.

When the _corruption level_\(C\) is _unknown_, we can use its estimated upper bound \(\) to replace \(C\) in the algorithm. In this way, if \(C\), the bound will be replacing \(C\) with \(\) in Eq.(7); when \(C>\), \(R(T)=O(T)\), which is already optimal for a large class of bandit algorithms .

The following theorem gives a regret lower bound of the LOCUD problem.

**Theorem 4** (Regret lower bound for LOCUD).: _There exists a problem instance for the LOCUD problem such that for any algorithm_

\[R(T)(d+dC)\,.\]

Its proof and discussions can be found in Appendix D. The upper bound in Theorem 3 asymptotically matches this lower bound in \(T\) up to logarithmic factors, showing our regret bound is nearly optimal.

We then compare our regret upper bound with several degenerated cases. First, when \(C=0\), _i.e._, all users are normal, our setting degenerates to the classic CB problem . In this case the bound in Theorem 3 becomes \(O(1/_{x}^{2} u(T))+O(d(T))\), perfectly matching the state-of-the-art results in CB . Second, when \(m=1\) and \(u=1\), _i.e._, there is only one user, our setting degenerates to linear bandits with adversarial corruptions , and the bound in Theorem 3 becomes \(O(d(T))+O(Cd^{1.5}(T))\), it also perfectly matches the nearly optimal result in . The above comparisons also show the tightness of the regret bound of RCLUB-WCU.

### Theoretical Performance Guarantee for OCCUD

The following theorem gives a performance guarantee of the online detection algorithm OCCUD.

**Theorem 5** (**Theoretical Guarantee for OCCUD)**.: _With assumptions in Section 3, at \( t T_{0}()\), for any detected corrupted user \(i}_{t}\), with probability at least \(1-5\), \(i\) is indeed a corrupted user._

This theorem guarantees that after RCLUB-WCU learns the clustering structure accurately, with high probability, the corrupted users detected by OCCUD are indeed corrupted, showing the high detection accuracy of OCCUD. The proof of Theorem 5 can be found in Appendix D.

Experiments

This section shows experimental results on synthetic and real data to evaluate RCLUB-WCU's recommendation quality and OCCUD's detection accuracy. We compare RCLUB-WCU to LinUCB  with a single non-robust estimated vector for all users, LinUCB-Ind with separate non-robust estimated vectors for each user, CW-OFUL  with a single robust estimated vector for all users, CW-OFUL-Ind with separate robust estimated vectors for each user, CLUB, and SCLUB. More description of these baselines are in Appendix F. To show that the design of OCCUD is non-trivial, we develop a straightforward detection algorithm GCUD, which leverages the same cluster structure as OCCUD but detects corrupted users by selecting users with highest \(\|}_{i,t}-}_{V_{i,t}-1}\|_{2}\) in each inferred cluster. GCUD selects users according to the underlying percentage of corrupted users, which is unrealistic in practice, but OCCUD still performs better in this unfair condition.

**Remark.** The offline detection methods [39; 6; 18; 32] need to know all the user information in advance to derive the user embedding for classification, so they cannot be directly applied in online detection with bandit feedback thus cannot be directly compared to OCCUD. However, we observe the AUC achieved by OCCUD on Amazon and Yelp (in Tab.1) is similar to recent offline methods [18; 32]. Additionally, OCCUD has rigorous theoretical performance guarantee (Section 5.2).

### Experiments on Synthetic Dataset

We use \(u=1,000\) users and \(m=10\) clusters, where each cluster contains \(100\) users. We randomly select \(100\) users as the corrupted users. The preference and arm (item) vectors are drawn in \(d-1\) (\(d=50\)) dimensions with each entry a standard Gaussian variable and then normalized, added one more dimension with constant 1, and divided by \(\). We fix an arm set with \(||=1000\) items, at each round, 20 items are randomly selected to form a set \(_{t}\) to choose from. Following [40; 3], in the first \(k\) rounds, we always flip the reward of corrupted users by setting \(r_{t}=-_{a_{t}}^{}_{i,t}+_{t}\). And we leave the remaining \(T-k\) rounds intact. Here we set \(T=1,000,000\) and \(k=20,000\).

Fig.3(a) shows the recommendation results. RCLUB-WCU outperforms all baselines and achieves a sub-linear regret. LinUCB and CW-OFUL perform worst as they ignore the preference differences among users. CW-OFUL-Ind outperforms LinUCB-Ind because it considers the corruption, but worse than RCLUB-WCU since it does not consider leveraging user relations to speed up learning.

The detection results are shown in Tab.1. We test the AUC of OCCUD and GCUD in every \(200,000\) rounds. OCCUD's performance improves over time with more interactions, while GCUD's performance is much worse as it detects corrupted users only relying on the robust estimations. OCCUD finally achieves an AUC of 0.855, indicating it can identify most of the corrupted users.

### Experiments on Real-world Datasets

We use three real-world data Movielens , Amazon, and Yelp . The Movielens data does not have the corrupted users' labels, so following , we manually select the corrupted users. On Amazon data, following , we label the users with more than 80% helpful votes as normal users, and label users with less than 20% helpful votes as corrupted users. The Yelp data contains users and their comments on restaurants with true labels of the normal users and corrupted users.

We select 1,000 users and 1,000 items for Movielens; 1,400 users and 800 items for Amazon; 2,000 users and 2,000 items for Yelp. The ratios of corrupted users on these data are 10%, 3.5%, and

Figure 3: Recommendation results on the synthetic and real-world datasets

30.9%, respectively. We generate the preference and item vectors following [37; 21]. We first construct the binary feedback matrix through the users' ratings: if the rating is greater than 3, the feedback is 1; otherwise, the feedback is 0. Then we use SVD to decompose the extracted binary feedback matrix \(R_{u m}=SX^{}\), where \(=(_{i}),i[u]\) and \(X=(_{j}),j[m]\), and select \(d=50\) dimensions. We have 10 clusters on Movielens and Amazon, and 20 clusters on Yelp. We use the same corruption mechanism as the synthetic data with \(T=1,000,000\) and \(k=20,000\). We conduct more experiments in different environments to show our algorithms' robustness in Appendix.G. The recommendation results are shown in Fig.3(b)-(d). RCLUB-WCU outperforms all baselines. On the Amazon dataset, the percentage of corrupted users is lowest, RCLUB-WCU's advantages over baselines decrease because of the weakened corruption. The corrupted user detection results are provided in Tab.1. OCCUD's performance improves over time and is much better than GCUD. On the Movielens dataset, OCCUD achieves an AUC of 0.85; on the Amazon dataset, OCCUD achieves an AUC of 0.84; and on the Yelp dataset, OCCUD achieves an AUC of 0.628. According to recent works on offline settings [18; 32], our results are relatively high.

## 7 Conclusion

In this paper, we are the first to propose the novel LOCUD problem, where there are many users with _unknown_ preferences and _unknown_ relations, and some corrupted users can occasionally perform disrupted actions to fool the agent. Hence, the agent not only needs to learn the _unknown_ user preferences and relations robustly from potentially disrupted bandit feedback, balance the exploration-exploitation trade-off to minimize regret, but also needs to detect the corrupted users over time. To robustly learn and leverage the _unknown_ user preferences and relations from corrupted behaviors, we propose a novel bandit algorithm RCLUB-WCU. To detect the corrupted users in the online bandit setting, based on the learned user relations of RCLUB-WCU, we propose a novel detection algorithm OCCUD. We prove a regret upper bound for RCLUB-WCU, which matches the lower bound asymptotically in \(T\) up to logarithmic factors and matches the state-of-the-art results in degenerate cases. We also give a theoretical guarantee for the detection accuracy of OCCUD. Extensive experiments show that our proposed algorithms achieve superior performance over previous bandit algorithms and high corrupted user detection accuracy.

## 8 Acknowledgement

The corresponding author Shuai Li is supported by National Key Research and Development Program of China (2022ZD0114804) and National Natural Science Foundation of China (62376154, 62006151, 62076161). The work of John C.S. Lui was supported in part by the RGC's SRFS2122-4S02.

   &  &  &  &  &  &  \\    & & OCCUD & 0.599 & 0.651 & 0.777 & 0.812 & **0.855** \\    &  & 0.477 & 0.478 & 0.483 & 0.484 & 0.502 \\    & OCCUD & 0.65 & 0.750 & 0.785 & 0.83 & **0.85** \\    &  & 0.450 & 0.474 & 0.485 & 0.489 & 0.492 \\   &  & 0.639 & 0.735 & 0.761 & 0.802 & **0.840** \\    &  & 0.480 & 0.480 & 0.486 & 0.500 & 0.518 \\   &  & 0.452 & 0.489 & 0.502 & 0.578 & **0.628** \\    &  & 0.473 & 0.481 & 0.496 & 0.500 & 0.510 \\  

Table 1: Detection results on synthetic and real datasets