# Convergence Analysis of Split Federated Learning on Heterogeneous Data

Pengchao Han

Guangdong University of Technology, China

hanpengchao@gdut.edu.cn

&Chao Huang

Montlair State University, USA

huangch@montlair.edu

&Geng Tian

Southern University of Science and Technology, China

12332463@mail.sustech.edu.cn

&Ming Tang

Southern University of Science and Technology, China

tangm3@sustech.edu.cn

&Xin Liu

University of California, Davis, USA

xinliu@ucdavis.edu

Equal contribution.

Corresponding author.

This work was partially supported by the National Natural Science Foundation of China (Grants 62202214 and 62401161), Guangdong Basic and Applied Basic Research Foundation (Grants 2023A1515012819 and 2022A1515110056), and USDA-020-67021-32855.

problem when clients' data distributions are heterogeneous, aka non-identically and independently distributed (non-IID). A large number of studies have proposed algorithms to address the client drift issue, e.g., [15; 10; 14; 25].

Split learning (SL)  is another distributed approach. By splitting the model across clients and a main server, SL can substantially reduce the computational workload on edge devices. Moreover, recent studies in [34; 17] show that SL can outperform FL when data is highly heterogeneous. However, SL's sequential training among clients can lead to high latency in each training round and potential performance loss (e.g., caused by catastrophic forgetting), which impedes its practical applicability in real-world distributed systems.

In light of above challenges, Thapa et. al in  proposed split federated learning (SFL) as a hybrid approach that synergizes the strengths of both FL and SL. SFL combines parallel training of FL with partial model training of SL. They proposed two major SFL algorithms: SFL-V1 and SFL-V2. An illustration of these SFL algorithms are shown in Fig. 1. Specifically, the global model (to be trained) is first split at a cut layer into two parts: a client-side model and a server-side model. Then, the clients are responsible for training only the client-side model under the coordination of a _fed server_ (similar to FL). Another server, known as the _main server_, is tasked with training the server-side model by collaborating with the clients (similar to SL). SFL aims to leverage parallel processing to reduce latency, while benefiting from the reduced computational workloads and enhanced data heterogeneity handling of SL.

Following , there has been an emerging volume of empirical studies on SFL. e.g., [22; 21; 3; 23; 8; 31; 5]. However, **a convergence analysis of SFL is missing in the literature**, and this paper aims to provide a comprehensive convergence analysis under different conditions. Convergence theory is crucial for understanding the learning performance of SFL, particularly in the context of _heterogeneous data_ and _partial participation_ scenarios. In practical distributed systems, clients are prone to have different data distributions. Moreover, not all clients may be active or available at all times. These two issues can significantly affect the learning performance of SFL. We aim to provide convergence guarantees for SFL on heterogeneous data (under both full and partial participation). We further compare the results to FL and SL, which provides insights into the practical deployment of various distributed approaches.

### Related Work

**Convergence theories of FL and SL**. There are many convergence results on FL. Most studies focus on data heterogeneity, e.g., [30; 16; 11; 10; 12]. Some studies look at partial participation, e.g., [35; 29; 26]. There are also convergence results on Mini-Batch SGD, e.g., [24; 33; 32], where  argued that the key difference between FL and Mini-Batch SGD is the communication frequency.

To our best knowledge, there is only one recent study  discussing the convergence of SL. The major difference to SL analysis lies in the sequential training manner across clients, while SFL clients perform parallel training.

Figure 1: An illustration of SFL framework, and there are two major algorithms, i.e., SFL-V1 (left) and SFL-V2 (right) . More discussions on SFL-V1 and SFL-V2 are given in Sec. 2.

### Challenges and Contributions

**Challenges of SFL convergence analysis**. When data is homogeneous (IID) across clients, the convergence theory in  (mainly developed for FL) can be applied to SFL. When data is heterogeneous, however, the theory cannot be directly applied due to the client drift problem. The challenge is intensified with clients' partial participation, which induces bias in the training process. Despite that prior FL theories have handled data heterogeneity  and partial participation , SFL convergence analysis imposes unique challenges due to the dual-paced model aggregation and model updates at the client-side and server-side. More specifically,

_Dual-paced model aggregation in SFL-VI_: In SFL-V1, the main server maintains one server-side model for each client, and it periodically aggregates the server-side models. When the main server aggregates its models at the same frequency as the clients, the analysis is the same to that of FL. However, FL analysis cannot be applied when aggregations occur at different frequencies, and it is challenging to analyze the impact of such discrepancy on SFL convergence.

_Dual-paced model updates in SFL-V2_: In SFL-V2, the main server only maintains one version of server-side model. The clients update the client-side models in a parallel manner while the main server updates the server-side model in a sequential fashion. Hence, each client's local update depends on the randomness of the previous clients who have interacted with the main server. While  handled sequential client training, their theory cannot be applied to SFL-V2 as they did not consider the aggregation of client-side models. This makes our analysis more challenging than FL and SL.

**Contributions**. We summarize our contributions as follows:

* We provide the first comprehensive convergence analysis of SFL. The analysis is more challenging than prior FL analysis due to the dual-paced model aggregation and model updates. To this end, we derive a key decomposition result (Proposition 3.5) that enables us to analyze the convergence from the server-side and client-side separately.
* Based on the decomposition result, we prove that the convergence guarantees of both SFL-V1 and SFL-V2 are \(O(1/T)\) for strongly convex objective and \(O(1/[]{T})\) for general convex objective, where \(T\) denotes the total number of rounds for SFL training. We further extend the analysis to non-convex objectives and more practical scenarios where some clients may be unavailable during training.
* We conduct simulations on various datasets. We show that the results are consistent with our theories. We further show two surprising results: (i) SFL achieves a better performance when clients maintain a larger portion of the global model; (ii) SFL-V2 outperforms FL and SL when clients have highly heterogeneous data and the number of client is large.

The rest of the paper is organized as follows. Sec. 2 formulates the SFL model. Sec. 3 presents the convergence results for SFL. We conduct experiments in Sec. 4 and conclude in Sec. 5.

## 2 Problem Formulation

### Model

We consider a set of clients \(=\{1,2,,N\}\), where each client \(n\) has a local private dataset \(_{n}\) of size \(D_{n}=|_{n}|\). Suppose the global model parameterized by \(\) has \(L\) layers. In SFL, the global model is split at the \(L_{c}\)-th layer (i.e., the cut layer) into two segments: a client-side model \(_{c}\) (from the first layer to layer \(L_{c}\)) and a server-side model \(_{s}\) (from layer \(L_{c}+1\) to layer \(L\)), where \(=[_{c};_{s}]\). Let \(_{c,n}\) denote the local client-side model of client \(n\). The clients train models with the help of two servers: (i) fed server, which periodically aggregates clients' local models \(_{c,n}\) (similar to FL), and (ii) main server, who trains the server-side model \(_{s}\). In this work, we consider two major SFL algorithms: SFL-V1 and SFL-V2 . In SFL-V1, the main server maintains a separate server-side model \(_{s,n}\) corresponding to each client \(n\). In comparison, in SFL-V2, the main server only maintains one model \(_{s}\).

Let \(F_{n}(;_{n})\) denote the loss of model \(\) over client \(n\)'s mini-batch instance \(_{n}\), which is randomly sampled from client \(n\)'s dataset \(_{n}\). Let \(F_{n}()_{_{n}_{n}}[F_{n}(;_{n})]\) denote the expected loss of model \(\) over client \(n\)'s dataset. The goal of SFL is to minimize the expected loss of the modelover the datasets of all clients:

\[_{}f()=_{n=1}^{N}a_{n}F_{n}(),\] (1)

where \(a_{n}\) is the weight of client \(n\) satisfying \(_{n}a_{n}=1\). Typically, \(a_{n}=D_{n}/_{n^{}}D_{n^{}}\), where a client with a larger data size is assigned a larger weight .

### Algorithm Description

We provide a brief description of SFL. Refer to Appendix B for a more detailed discussion. SFL takes a total number of \(T\) rounds to solve (1). At the beginning of each round \(t\), clients download the recent global client-side model from the fed server, where the model is an aggregated version of the client-side models of the clients from the previous round \(t-1\). Each round \(t\) contains two stages:

**Stage 1: model training**. Clients and the main server train the full global model for \(\) iterations in each round. In each iteration \(i<\), there are three steps:

_Step 1: client forward propagation_. Each client \(n\) samples a mini-batch of data \(_{n}^{t,i}\) from \(_{n}\), computes the intermediate features (e.g., activation values at the cut layer) over its current model \(_{c,n}^{t,i}\), and sends the activation to the main server. The clients perform forward propagation in parallel.

_Step 2: main server training_. Upon receiving the activation of each client \(n\),

* SFL-V1: the main server computes the loss using the current server-side model \(_{s,n}^{t,i}\). It then computes the gradients over \(_{s,n}^{t,i}\) to update the model. It also computes the gradient over the activation at the cut layer, and sends it to client \(n\).
* SFL-V2: the main server computes the loss \(F_{n}(\{_{c,n}^{t,i},_{s}^{t,i}\})\), based on which it then updates the server-side model \(_{s}^{t,i}\). It also computes and sends the gradient over activation at the cut layer to client \(n\). Note that the main server sequentially interacts with the clients in a randomized order.

_Step 3: client backward propagation_. Receiving gradient at the cut layer, each client \(n\) computes the client-side gradient using the chain rule, and then updates its model \(_{c,n}^{t,i}\).

**Stage 2: model aggregation**. Model aggregation can occur for both client-side and server-side models. For the client side, after \(\) iterations of model training (i.e., at the end of round \(t\)), each client sends its current client-side model to the fed server. The fed server aggregates the clients' models (e.g., weighted averaging), which will be downloaded in the next round \(t+1\):

\[_{c}^{t+1}_{n}a_{n}_{c,n}^{t,}.\] (2)

For the server side, (i) in SFL-V1, after \(\) iterations of training, the main server aggregates all server-side models. Note that \(\) does not necessarily need to equal \(\), but when equality holds, SFL-V1 can be regarded as FL (despite the model splitting). (ii) In SFL-V2, no aggregation occurs since the main server only maintains one model.

### Client Participation

We consider two cases: (i) _full participation_ where all clients are available during training. This can model the scenarios where clients are organizations or companies who likely have sufficient computation and communication resources ; (ii) _partial participation_ where some clients may be unavailable during training. This can model the cases where clients are edge devices (e.g., mobile phones) that are usually resource-constrained and may be disconnected from the SFL process.

To model partial participation, we consider independent participation probabilities for each client, allowing for arbitrary and heterogeneous participation probabilities. Specifically, we use \(q_{n}\) to denote client \(n\)'s participation level (or probability), and \(=(q_{n},n)\). If \(q_{n}=1\), client \(n\) participates in every round of SFL with probability one. If \(q_{n}<1\), client \(n\) is unavailable in some rounds. Denote \(^{t}()\) as the set of participating clients in round \(t\). In the presence of partial participation, we need to modify (2) (and the potential server-side aggregation) to offset the incurred bias:

\[_{c}^{t+1}_{n^{t}()}}{q_{n}} _{c,n}^{t,}.\] (3)

## 3 Convergence Analysis

We first make technical assumptions in Sec. 3.1. Then, we present a key technical result in Sec. 3.2 to support the SFL convergence analysis. Finally, we provide the convergence results under full participation and partial participation in Sec. 3.3 and Sec. 3.4, respectively.

### Assumptions

We start with some conventional assumptions for convergence analysis in the FL literature.

**Assumption 3.1**.: (\(S\)_-Smoothness_) Each client \(n\)'s loss function \(F_{n}\) is \(S\)-smooth. That is, for all \(,^{d}\),

\[F_{n}() F_{n}()+ F_{n}(),- +\|-\|^{2}.\] (4)

The smoothness assumption holds for many loss functions in, for example, logistic regression, softmax classifier, and \(l_{2}\)-norm regularized linear regression .

**Assumption 3.2**.: (_Unbiased and bounded stochastic gradients with bounded variance_) The stochastic gradients \(_{n}()\) of \(F_{n}()\) is unbiased with the variance bounded by \(_{n}^{2}\).

\[_{_{n}_{n}}[_{n}(,_{n })]= F_{n}(),\] (5)

\[_{_{n}_{n}}[\|_{n}(, _{n})- F_{n}()\|^{2}] _{n}^{2}.\] (6)

**Assumption 3.3**.: (_Bounded gradients_) The expected squared norm of stochastic gradients is bounded by \(G^{2}\).

\[_{_{n}_{n}}\|_{n}(,_{ n})\|^{2} G^{2}.\] (7)

The value of \(_{n}\) measures the level of stochasticity.

**Assumption 3.4**.: (_Heterogeneity_) There exists an \(^{2}\) such that the divergence between local and global gradients is bounded by \(^{2}\).

\[\| F_{n}()- f()\|^{2 }^{2}.\] (8)

A larger \(^{2}\) indicates a larger degree of data heterogeneity.

### Decomposition

As discussed in Sec. 1.3, analyzing the performance bound of SFL can be more challenging than that of conventional FL counterparts due to the dual-paced model aggregation and model updates. To address this challenge, we decompose the convergence analysis into the server-side and client-side updates, respectively. We give the decomposition below.

**Proposition 3.5**.: _(Convergence decomposition) Let \(^{*}[_{c}^{*};_{s}^{*}]\) denote the optimal global model that minimizes \(f()\), and \(^{T}[_{c}^{T};_{s}^{T}]\) is the global model obtained after \(T\) rounds of SFL training. Under Assumption 3.1, we have_

\[[f(^{T})]-f(^{*})( ||_{s}^{T}-_{s}^{*}||^{2}+||_{c}^{T}- _{c}^{*}||^{2}).\] (9)

The proof is given in Appendix C.4. Proposition 3.5 is particularly useful. It shows that despite the challenging dual-paced updates, to bound the SFL performance gap, it suffices to separately bound the gap at the server-side and client-side models. Note that our decomposition can be easily applied to other distributed approaches such as SL. In addition, such a decomposition is not necessarily loose, as our derived bounds for SFL achieve the same order as in FL (see Appendix H.2 for details).

### Results under Full Participation

Built upon Proposition 3.5, we first present the convergence results under full participation. For convenience, define

\[I^{}\|^{0}-^{*}\|^{2},  8S/-1,_{}\{,\},_{ }\{,\},\] (10)

and let \(^{t}\) represent the learning rate at round \(t\). Let \(f^{*}\) denotes the optimal global loss, i.e., \(f^{*} f(^{*})\). All results are obtained based on Assumptions 3.1-3.4. The convergence results for SFL-V1 and SFL-V2 are summarized in Theorems 3.6 and 3.7, respectively1.

**Theorem 3.6**.: _( \(}\))_

\(\)_-strongly convex: Let Assumptions 3.1 - 3.3 hold, and \(^{t}(+t)}\) for client-side model and \(^{t}=(+t)}\) for server-side model,_

\[[f(^{T})]-f^{*} ^{N}a_{n}^{2}2_{n}^{2}\!+\!G^{2} }{^{2}(+T)}\!+\!\!_{n=1}^{N}\!a_{ n}2_{n}^{2}\!+\!G^{2}}{^{3}(+T)( +1)}\!+\!}}{2(+T)}.\] (11)

_General convex: Let Assumptions 3.1 - 3.3 hold, and \(^{t}}\)._

\[[f(^{T})]-f^{*} }}{2(T+1)}+(^{2}+^{2})I^{}N}{_{}^{2}(T+1)}_{n=1}^{N}a_{n}^ {2}(2_{n}^{2}+G^{2}))^{}\] (12) \[+(^{2}+^{2})SI^{}}{_{}^{2}(T+1)}_{n=1}^{N}a_{n}(2_{n}^{2}+G^{2}) )^{}.\]

_Non-convex: Let Assumptions 3.1, 3.2, and 3.4 hold, and \(^{t}\{},}{8SN_{ }^{2}_{n=1}^{N}a_{n}^{2}}\}\),_

\[\!_{t=0}^{T-1}\!^{t}\![\!\|_{}f(^{t})\|^{2}\!]\!\!} f(\!^{0}\!)\!-\!f^{*}+\!\!+ \!^{2})}{T_{}}\!_{n=1}^{N}\!\!a_{n}^{2}_{n }^{2}+^{2}\!_{t=0}^{T-1}\!^{t}^{2}\,.\] (13)

**Theorem 3.7**.: _( \(}\))_

\(\)_-strongly convex: Let Assumptions 3.1 - 3.3 hold, and \(^{t}=}(+t)}\) for client-side model and \(^{t}=}(+t)}\) for server-side model,_

\[\![\!f(^{T})\!]\!-\!f^{*} ^{N}\!\!(a_{n}^{2}\!+\!1)(2_{n}^{2}\!+\!G^{ 2})}{^{2}(\!+\!T)}\!+\!\!_{n=1}^{N }\!\!(a_{n}\!+\!1)(2_{n}^{2}\!+\!G^{2})}{^{3}( \!+\!T)(\!+\!1)}\!+\!}}{2(\!+\!T)}.\] (14)

_General convex: Let Assumptions 3.1 - 3.3 hold, and \(^{t}\),_

\[\![\!f(\!^{T})\!]\!-\!f^{*} }}{2(T\!+\!1)}\!+\!\!(\!}}{T\!+\!1}\!_{n=1}^{N}\!\!\!(a_{n}^{2}\!+\!1)(2_{n }^{2}\!+\!G^{2})\!)^{}\!+\!\!(\!}}{T\!+\!1}\!_{n=1}^{N}\!\!\!(a_{n}\!+\!1)(2_{n }^{2}\!+\!G^{2})\!)^{}.\] (15)

_Non-convex: Let Assumptions 3.1, 3.2, and 3.4 hold, and \(^{t}\{,}\}\),_

\[\!_{t=0}^{T-1}^{t}\![\!\|_{}f(^{t})\|^{2}\!]\!\! f(^{0})\!-\!f^{*}+\!_{n=1}^{N}\!\!(a_{n}^{2} +1)_{n}^{2}+^{2}\!_{t=0}^{T-1}^{t} ^{2}\,.\] (16)Proofs of Theorems 3.6-3.7 are given in Appendices D-E, respectively. We summarize the key findings below.

**Convergence rate**. The convergence bounds of both SFL-V1 and SFL-V2 achieve an order of \(O(1/T)\) on strongly convex (and non-convex) objectives. For general convex objectives, the convergence rate becomes \(O(1/)\).2 Note that our bounds match the existing bounds for FL and SL (in terms of the order of \(T\)) on heterogeneous data for strongly convex objectives. For a more detailed comparison, please refer to Appendix H.2.3

**Impact of data heterogeneity**. The convergence bounds increase as the level of data heterogeneity increases. For example, in (13), the bound increases in \(^{2}\) (see Assumption 3.4). This means that SFL tends to perform worse when clients' data are more heterogeneous, which is a commonly observed phenomenon in distributed learning, e.g., FL.

**Choice of learning rate.** One should use a smaller learning rate when the number of local iteration \(\) increases. This bears a similar spirit to . In addition, our results indicate that a proper choice of constant learning rate suffices for SFL convergence. It would be an interesting direction to investigate whether diminishing learning rates are able to achieve faster convergence.

**Comparison between SFL-V1 and SFL-V2.** The convergence results between the two SFL versions are very similar, except that \(a_{n}^{2}\) (and \(a_{n}\)) in SFL-V1 are replaced by \(a_{n}^{2}+1\) (and \(a_{n}+1\)) in SFL-V2. See (11) and (14) for an inspection. We will show in Sec. 4 that SFL-V1 and SFL-V2 achieve similar accuracy (except under highly heterogeneous data).

### Results under Partial Participation

Now, we present the results under partial participation.

**Theorem 3.8**.: _( SFL-V1: partial participation)_

\(\)**-strongly convex**_: Let Assumptions 3.1 - 3.3 hold, and \(^{t}=}(+t)}\) for client-side model and \(^{t}=}(+t)}\) for server-side model,_

\[[f(^{T})]-f^{*}^{N}}a_{n}^ {2}\!(2_{n}^{2}\!+\!G^{2}\!+\!}{q_{n}})}{^{2} (+T)}\!+\!^{N}}a_{n}\!(2_ {n}^{2}\!+\!G^{2})}{^{3}(+T)(+1)}\! +\!}}{2(+T)}.\] (17)

**General convex**_: Let Assumptions 3.1 - 3.3 hold, and \(^{t}}}\),_

\[[f(^{T})]-f^{*}}}{2(T+1)}+(^{2}+^{2})I^{ }N}{_{}^{2}(T+1)}_{n=1}^{N}a_{n}^{2}(2_{n} ^{2}+G^{2}+}{q_{n}}))^{}\] (18) \[+(^{2}+^{2})SI^{}}{_{}^{2}(T+1)}_{n=1}^{N}a_{n}(2_{n}^{2}+G^{2}) )^{}.\]

**Non-convex**_: Let Assumptions 3.1, 3.2, and 3.4 hold, and \(^{t}\{}},}{8SN_{ }^{2}_{n=1}^{N}^{2}}{q_{n}}}\}\),_

\[^{T-1}}^{t}\![\!\|_{}f (^{t})\|^{2}\!]\!\!}\! (f(^{0})\!-\!f^{*})\!\!+\!\!+\! ^{2})}{T_{}}\!_{n=1}^{N}\!\!^{2}}{q_{n}}\! (_{n}^{2}\!+\!^{2})\!_{t=0}^{T-1}\!(^{t} )^{2}.\] (19)

**Theorem 3.9**.: _( SFL-V2: partial participation)_

\(\)**-strongly convex**_: Let Assumptions 3.1 - 3.3 hold, and \(^{t}=}(+t)}\) for client-side model and \(^{t}=}(+t)}\) for server-side model,_

\[\![\!f(^{T})\!]\!-\!f^{*}\!\!^{N}}\!\!(\!a_{n}^{2}\!+\!1\!)\!(2_{n}^{2} \!+\!G^{2}+}{q_{n}})}{^{2}(\!+\!T)}\!+\! ^{N}}\!\!(\!a_{n}\!+\!1\!)\!(2\! _{n}^{2}\!+\!G^{2}\!)}{^{3}(+T)(+1 )}\!+\!}}{2(+T)}.\] (20)_General convex_: _Let Assumptions 3.1 - 3.3 hold, and \(^{t}\)._

\[[f(^{T})]-f^{ *}}}{2(T+1)}&+(}}{T+1}_{n=1}^{N}(a_{n}^{2}+1)(2_{n}^{2}+G^{2}+ ^{2}}{q_{n}}))^{}\\ &+(}}{T+1}_{n=1}^{N}( a_{n}+1)(2_{n}^{2}+G^{2}))^{}.\] (21)

_Non-convex_: _Let Assumptions 3.1, 3.2, and 3.4 hold, and \(^{t}\{,_{n=1}^{N} ^{2}}{q_{n}}}\}\),_

\[_{t=0}^{T-1}^{t}[\|_{}f (^{t})\|^{2}](f( {x}_{0})-f^{*})+_{n=1}^{N}^{2}+1} {q_{n}}(_{n}^{2}+^{2})_{t=0}^{T-1}(^{t} )^{2}.\] (22)

The proofs are given in Appendices F-G.

**Impact of partial participation**. In practical cross-device settings, some clients may not participate in all rounds of training, i.e., \(q_{n}<1\) for some \(n\). This brings an additional term \(G^{2}/q_{n}\) to the convergence bound (e.g., see (12) and (18)), meaning that partial participation worsens SFL performance. This is also observed in FL literature (e.g., ) and is consistent with our experimental results.

## 4 Experimental Results

### Setup

We conduct experiments on CIFAR-10 and CIFAR-100 .4 To simulate data heterogeneity, we adopt the widely used Dirichlet distribution  with a controlling parameter \(\). Here, a smaller \(\) corresponds to a higher level of data heterogeneity across clients. We use ResNet-18, which contains four blocks, as the model structure and consider four types of model splitting represented by \(L_{c}=\{1,2,3,4\}\), where \(L_{c}=n\) means the model is split after the \(n\)-th residual block. We consider two major distributed approaches as the benchmark, i.e., FL (in particular FedAvg ) and SL . The learning rates for SFL-V1, SFL-V2, FL, and SL are set as \(0.01\). The batch-size \(b_{s}\) is 128, and we run experiments for \(T=200\) rounds. Unless stated otherwise, we use \(N=10\), \(=0.1\), \(E=5\), where \(E\) is the number of local epochs for client-side model aggregation (i.e., every \(E\) times of training performed over each client's dataset, their client-side models are aggregated at the fed server), and hence \(=}{b_{s}} E\). We set \(=\) for the fair comparison to vanilla FL. The experiments are run on a CPU (Intel(R) Xeon(R) Gold 5320 at 2.20GHz) and a GPU (A100-PCIE-80GB). **Our codes are provided in https://github.com/TIANGeng708/Convergence-Analysis-of-Split-Federated-Learning-on-Heterogeneous-Data.**

### Impact of system parameters on SFL performance

**Impact of cut layer**. We first investigate how the choice of the cut layer \(L_{c}\) affects the SFL performance. The results are reported in Fig. 2. We observe that for both SFL-V1 and SFL-V2,

Figure 2: Impact of the choice of cut layer on SFL performance.

the performance increases in \(L_{c}\) (i.e., clients have a larger proportion of the global model). This is associated with our empirical observation that the average client gradient variance gets smaller with \(L_{c}\). Intuitively, a smaller gradient variance implies a lower degree of the client drift issue, which leads to a better algorithm performance.5 Based on this observation, we use \(L_{c}=4\) for SFL (and SL) for the following experiments.

**Impact of data heterogeneity**. We study the impact of data heterogeneity on SFL performance, where we use \(\{0.1,0.5,1,\}\), and \(=\) means clients have IID data. The results are reported in Fig. 3. We observe that a higher level of data heterogeneity (i.e., a smaller \(\)) leads to slower algorithm convergence and a lower accuracy for both SFL-V1 and SFL-V2. The observation is consistent with our convergence bound, e.g., in (16), the performance bound increases in \(^{2}\). Note that the negative impact of heterogeneity is commonly observed in distributed learning literature including FL  and SL .

**Impact of partial participation**. We study the impact of client participation and let \(q_{n}=q\{0.2,0.5,1\}, n\). The results are reported in Fig. 4. We observe that a lower level of participation leads to less stable convergence and also a smaller accuracy. This is consistent with our convergence results, e.g., in (20), the bound decreases in clients' participation level \(q_{n}\). Partial participation is expected in practical cross-device scenarios where clients are resourced-constrained edge devices. It is important to develop efficient algorithms as well as effective incentive mechanisms to encourage clients' participation in SFL.

### Comparison among SFL, FL, and SL.

We now compare SFL to FL and SL. We consider different combinations of data heterogeneity \(\{0.1,0.5\}\) and cohort sizes \(N\{10,50,100\}\). The results are reported in Fig. 5. When data is mildly heterogeneous (i.e., \(=0.5\)), SFL and FL have similar convergence rates and accuracy performance. Note that SL seems to under-perform SFL and FL. We think this is mainly due to the catastrophic forgetting issue, which has been observed in [21; 2].

**SFL outperforms FL and SL under highly heterogeneous data and a large client number**. When data becomes more non-IID (i.e., \(=0.1\)), SFL-V2 tends to outperform FL and SL. The improvement becomes more significant as the cohort size gets larger. The bottleneck of FL is the client drift issue caused by data heterogeneity. The bottleneck of SL is associated with the catastrophic forgetting. SFL-V2 is a hybrid combination of FL and SL, which can lead to a better tradeoff between client drift and forgetting. By appropriately choosing the cut layer, SFL-V2 outperforms

Figure 4: Impact of client participation on SFL performance.

Figure 3: Impact of data heterogeneity on SFL performance.

FL and SL. This observation also indicates that SFL-V2 can be a more appealing solution than FL for practical cross-device systems, as it achieves a better performance while requiring smaller computation overheads from edge devices.

## 5 Conclusion

In this work, we provided the first comprehensive convergence analysis of SFL for strongly convex, general-convex, and non-convex objectives on heterogeneous data. One key challenge is the dual-paced model updates. We get around this issue by decomposing the performance gap of the global model into the client-side and server-side gaps. We further extend our analysis to the more practical scenario with partial client participation. Experimental experiments validate our theories and further show that SFL can outperform FL and SL under highly heterogeneous data and a large client number. One limitation of our work is that our bounds for SFL achieve the same order (in terms of training rounds) as in FL, yet the experiments showed that SFL outperforms FL under high heterogeneity. This is possibly due to that tighter bounds for SFL are to be derived, which is an important future work. For future work, one can apply our derived bounds to optimize SFL system performance, considering model accuracy, communication overhead, and computational workload of clients. It is also interesting to theoretically analyze how the choice of the cut layer affects the SFL performance.

Figure 5: Performance comparison on CIFAR-10.