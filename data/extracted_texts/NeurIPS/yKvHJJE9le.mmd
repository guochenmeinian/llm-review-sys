# Safe Time-Varying Optimization based on Gaussian Processes with Spatio-Temporal Kernel

Jialin Li

ETH Zurich (currently with UIUC)

lijial@ethz.ch &Marta Zagorowska

NTNU (currently with TU Delft)

m.a.zagorowska@tudelft.nl &Giulia De Pasquale

Eindhoven Univeristy of Technology

g.de.pasquale@tue.nl &Alisa Rupenyan

Zurich University of Applied Sciences

alisa.rupenyan@zhaw.ch &John Lygeros

ETH Zurich

jlygeros@ethz.ch

###### Abstract

Ensuring safety is a key aspect in sequential decision making problems, such as robotics or process control. The complexity of the underlying systems often makes finding the optimal decision challenging, especially when the safety-critical system is time-varying. Overcoming the problem of optimizing an unknown time-varying reward subject to unknown time-varying safety constraints, we propose TVSAFEOPT, a new algorithm built on Bayesian optimization with a spatio-temporal kernel. The algorithm is capable of safely tracking a time-varying safe region without the need for explicit change detection. Optimality guarantees are also provided for the algorithm when the optimization problem becomes stationary. We show that TVSAFEOPT compares favorably against SAFEOPT on synthetic data, both regarding safety and optimality. Evaluation on a realistic case study with gas compressors confirms that TVSAFEOPT ensures safety when solving time-varying optimization problems with unknown reward and safety functions.

## 1 Introduction

We seek to interactively optimize an unknown time-varying reward function \(f:\), where \(\) is a finite set of decisions, and \(:=\{0,1,2,,T\},\;T_{+}\) denotes the discretized time domain. We assume that the optimization problem is safety-critical, that is, there are constraints that evaluated decisions must satisfy with high probability. Similar to the reward, the constraints are also unknown and potentially time-varying, encoded through \(c_{i}:,\;i_{c }:=\{1,2,,m\},\) where \(\;m_{+}\) denotes the number of safety constraints. The optimization problem at time \(t\) is

\[_{}f(,t)\] (1) \[c_{i}(,t) 0,\;i_{c}\]

Both the reward function and the safety constraints are assumed to be unknown but can be evaluated. This is a plausible setting, for example, for UAV that need to perform rescue missions in dangerous and poorly lit environments.

### Related Work

Bayesian Optimization (BO) is a well-established approach for interactively optimizing unknown reward functions. Various BO based approaches have been proposed to solve a wide range of problems in robotics [1; 2], combinatorial optimization , sensor networks , and automatic machine learning [5; 6]. However, Safe Bayesian Optimization in the time-varying setting is still under-explored.

**Safe Bayesian Optimization** To address safety requirements in safety-critical applications, Safe Bayesian Optimization (SBO)  has been proposed to avoid unsafe decisions with high probability by interactively optimizing a reward function under safety constraints. SAFEOPT , one of the first SBO algorithms, expands an initial safe set iteratively based on new evaluations and an

Figure 1: Comparison of safe sets computed by TVSAFEOPT (top row), ETSAFEOPT (middle row), and SAFEOPT (bottom row) at \(t=30,\ t=100,\,t=170\). Because TVSAFEOPT takes the possible changes in time into consideration, the safe sets computed by TVSAFEOPT are contained in the ground truth safe regions while those computed by ETSAFEOPT and SAFEOPT have multiple violations. The reason for the violations in ETSAFEOPT is that the algorithm is unable to detect small changes in the constraints, confirming that the performance of ETSAFEOPT depends on the event detection algorithm.

updated Gaussian Process (GP) model of safety functions. It calculates two subsets, maximizers and expanders, from the current safe set and selects the most uncertain decision within their union to balance maximizing the reward function and expanding the safe set. Subsequent algorithms extend SAFEOPT to handle multiple constraints , decouple safe set expansion from optimization , and expand the safe set in a goal-oriented manner . These methods also explore disconnected safe regions [11; 12] and enhance information-theoretic efficiency [13; 14]. They have been applied to controller tuning for a ball-screw drive  and quadrupeds , and adaptive control on a rotational motion system . However, SBO typically does not take into account changes with time.

**Contextual Bayesian Optimization** Contextual Bayesian Optimization (CBO) has been introduced to address the influence of external environmental factors on reward and safety functions. Krause and Ong  extend the Gaussian Process Upper Confidence Bound (GP-UCB) algorithm  by incorporating contextual variables into unconstrained BO, demonstrating sub-linear regret analogous to GP-UCB. An advancement of this framework is proposed in , with the Safe Contextual GP-UCB optimizing the contextual upper confidence bound within a safe set to manage room temperature via a PID controller. Berkenkamp et al.  present a contextual adaptation of SAFEOPT, discussing its safety and optimality guarantees by framing contextual SBO as distinct SBO sub-problems. Additionally, Konig et al.  extends GOOSE  to the contextual domain for model-free adaptive control scenarios. Similarly to SBO, CBO does not explicitly consider time-varying problems.

**Time-Varying Bayesian Optimization** Time-Varying Bayesian Optimization (TVBO) addresses problems where the objective is time-dependent, modeled with a temporal kernel . Methods in this setting include periodical resetting , change detection [24; 25], sliding-window approaches using recent data , and discounting via exponentially decaying past observations . However, these techniques have been developed for unconstrained BO and are unsuitable for safety-critical applications.

**Time-Varying Safe Bayesian Optimization** In the safety-critical time-varying setting, contextual lower confidence bounds can be optimized within the safe set , but it does not guarantee optimality theoretically. An event triggering mechanism is introduced to SBO to restart exploration from a backup policy , but it may not trigger reliably during changes, posing a safety risk. Extensions to SBO with contextual variables provide theoretical safety and optimality analyses [8; 16], treating contextual SBO as separate sub-problems for each contextual value, and assuming an initial safe set for each. However, ensuring optimality requires each contextual value to appear frequently, which is impractical in time-varying scenarios.

### Methodology and Contributions

**Methodology** We propose the TVSAFEOPT algorithm to optimize an unknown time-varying reward subject to unknown time-varying safety constraints. The algorithm focuses on Time-Varying Safe Bayesian Optimization (TVSBO). TVSAFEOPT utilizes a spatio-temporal kernel and time Lipschitz constants as prior knowledge about how the problem depends on time. The temporal part of the kernel encodes the continuity of the functions with time while the Lipschitz constants explicitly provide upper bounds on how fast the functions may change. Instead of considering safe sets at previous iteration as safe at the current iteration, which might lead to unsafe decisions, TVSAFEOPT robustly subtracts the safety margin when updating the safe sets (Figure 1). In this way, the algorithm is capable of adapting in real time and guarantees safety even when exploring the safe region of non-stationary problems.

**Contributions** Our contributions are threefold: a) We propose the TVSAFEOPT algorithm based on Gaussian processes with spatio-temporal kernels; b) We provide formal safety guarantees for TVSAFEOPT in the most general time-varying setting and optimality guarantees for TVSAFEOPT for

   & 
 Handling Changes \\ in Time \\  & Safety Guarantee & Optimality Guarantee & Safe Seed \\  A-GOOSE [21; 17] & Spatio-temporal kernel & ✓ & ✗ & For all \(t\) \\ C-SAFEOPT  & Spatio-temporal kernel & ✓ & ✗ & For all \(t\) \\ ETSAFEOPT  & Event detection & ✗ & ✗ & For all \(t\) \\ TVSAFEOPT (ours) & Spatio-temporal kernel & ✓ & ✓ & For initial \(t\) \\  

Table 1: Overview of safe learning methods based on BO for time-varying problems.

locally stationary optimization problems; c) We show TVSAFEOPT performs well in the most general time-varying setting both on synthetic data and on a realistic case study on gas compressors. In Table 1, we compare Adaptive GOOSE, Contextual SAFEOPT, ETSAFEOPT, and TVSAFEOPT in terms of how they handle changes in time, safety guarantees, optimality guarantees, and required safe seeds.

#### 1.2.1 Expected societal impact

The TVSAFEOPT algorithm proposed in this paper extends the state of the art in Time-Varying Safe Bayesian Optimization by enabling solving optimization problems with time-varying reward and constraints without pre-defining the time changes that can be compensated.Thus, the algorithm can be used at the design stage of operating strategies for safety-critical systems, such as medical dosage design  and controller design in robotics , or during online operation of chemical plants  or autonomous racing .

## 2 TVSAFEOpt Algorithm

The TVSAFEOPT algorithm builds upon SAFEOPT , to handle time-varying reward function and safety functions. The key new feature of TVSAFEOPT is its capability of safely transferring the current safe set to the next time step. TVSAFEOPT achieves this with the help of the spatio-temporal kernel as well as the sequence of time Lipschitz constants. The approach is summarized in Algorithm 1.

### Assumptions

Following , we incorporate the reward and safety functions into an auxiliary function \(h:\), where \(:=\{0\}_{c}\),

\[h(,t,i):=f(,t)&i=0\\ c_{i}(,t)&i_{c}\] (2)

We model the auxiliary function using a prior Gaussian Process (GP) with zero mean and spatio-temporal kernel \(:()( )\), . We require \(h\) to be Lipschitz continuous with respect to both \(\) and \(t\), and to have bounded norm in the Reproducing Kernel Hilbert Space (RKHS)  associated with the kernel \(\) as formalized in the following.

**Assumption 2.1**.: The spatio-temporal kernel is positive definite, and satisfies \(((,t,i),(,t,i)) 1\), for all \(,t,i\). The function \(h(,t,i)\) has bounded norm in the RKHS associated with kernel \(\). The function \(h(,t,i)\) is \(L_{}\)-Lipschitz continuous with respect to \(\) in the domain \(\) with respect to some metric \(d:_{ 0}\) for all \(t\), \(i\). There exists a sequence \(\{L(t)\}_{t,t<T}\), such that, for all \(\), \(i\), \(t,t<T\), \(|h(,t+1,i)-h(,t,i)| L(t)\).

At each algorithm iteration \(k\), we make a decision \(_{k}\), which we then apply to the system and get noisy measurements \(y^{i}_{k}\) of the reward function and safety functions during the iteration. We use the index \(k\) to refer to the algorithm iteration. Even though \(k\) and \(t\) might differ in principle, in practice we run one algorithm iteration \(k\) for each time step \(t\).

**Assumption 2.2**.: Observations \(y^{i}_{k}=h(_{k},t,i)+^{i}_{k},\  i,\ t\) are perturbed by i.i.d. zero mean and \(\)-sub-Gaussian noise.

Based on the measurements, we compute the posterior GP and make the decision for the next time step. To start the exploration, an initial set of safe decisions is assumed to be available to the algorithm. To ensure that the safe set remains non-empty after the first iteration, it is necessary that the initial safety function values at every decision within the initial safe set are positive.

**Assumption 2.3**.: An initial set \(S_{0}\) of safe decisions is known and for all decisions \( S_{0}\), we have \(c_{i}(,0)>0,\  i_{c}\).

Similar assumptions have also been made for the standard SAFEOPT algorithm  and are necessary to ensure feasibility of the exploration steps and to be able to identify new safe decision.

### Safety Updates

To ensure safety, based on Assumption 2.1 and 2.2, we extend the definition of the confidence intervals from  so that, with high probability, they contain \(f\) and \(c_{i}\) using the posterior GP estimate given the data sampled so far. The confidence intervals for \(h(,t,i)\) given training samples until iteration \(k 1\) are defined for all \(\) and for all \(i\) as

\[Q_{k}(,i):=[_{k-1}(,i)}_{k -1}(,i)],\] (3)

where \(_{k}\) is a scalar that determines the desired confidence interval, \(_{k-1}(,i)\) and \(_{k-1}(,i)\) are the posterior mean and standard deviation of \(h(,t,i)\) inferred with \(_{k}\), training samples till iteration \(k\). The probability of the true function value \(h\) lying within this interval depends on the choice of \(_{k}\). We provide more details for this choice in Section 2.4.

We now construct a tighter confidence interval for \(h(,t,i)\) by using the sequence \(\{Q_{}(,i)\}_{ k}\) instead of \(Q_{k}(,i)\) alone. To this end, we recursively define for all \(\) and for all \(i\) the intersection

\[C_{k}(,i):=(C_{k-1}(,i)[-L(t-1),L(t-1)]) Q_{k}( ,i),\] (4)

where \(\) denotes the Minkowski sum, \(C_{0}(,i)\) is \([L(0),)\) for all \( S_{0}\), \(i_{c}\) and \(\) otherwise. We use the lower bound \(l_{k}(,i):= C_{k}(,i)\) and the upper bound \(u_{k}(,i):= C_{k}(,i)\), to define the width of \(C_{k}(,i)\)

\[w_{k}(,i):=u_{k}(,i)-l_{k}(,i)\] (5)

further used to update the safe set as well as pick the next decision to explore.

Based on the updated posterior and Lipschitz constants, we can update the safe set \(S_{k}\) with the lower bounds \(l_{k}\) and the previous safe set \(S_{k-1}\) as

\[S_{k}=_{i_{c}}_{ S_{k-1}}\{^{} l_{k}(,i)-L_{}d(, ^{})-L(t) 0\}.\] (6)

The set \(S_{k}\) contains decisions that with high probability fulfill the safety constraints given the GP confidence intervals and the Lipschitz constants. In contrast to SAFEOPT, the safe set of TVSAFEOPT is allowed to shrink to adapt to the potential change of the safe region given the time-varying setting. However, the safe set might even become empty after the update. This is either because the safe region indeed becomes empty or because the updated safe set conservatively excludes all decisions with a lower bound of some safety function below \(L\) to guarantee safety. In all these cases, if the updated safe set is empty, we terminate the algorithm.

### Safe Exploration and Exploitation

With the safe set updated, the next challenge is to trade off between exploitation and expansion of the safe region. As in the standard SAFEOPT, the potential maximizers are those decisions, for which the upper confidence bound of the reward function is higher than the largest lower confidence bound

\[M_{k}=\{ S_{k} u_{k}(,0)_{ ^{} S_{k}}l_{k}(^{},0)\}.\] (7)

To identify the potential expanders, \(G_{k}\), containing all decisions that could potentially expand the safe set, we first quantify the potential enlargement of the current safe set after sampling a new decision \(\). To do so, we define the function

\[e_{k}():=|\{^{} S_{k}  i_{c}:u_{k}(,i)-L_{}d(, ^{})-L(t) 0\}|,\] (8)

where \(||\) refers to the cardinality of a set, and then update

\[G_{k}=\{ S_{k} e_{k}()>0\}.\] (9)

At iteration \(k\), TVSAFEOPT selects a decision \(_{k}\) within the union of potential maximizers (7) and expanders (9)

\[_{k}=*{arg\,max}_{ G_{k} M_{k},i }w_{k}(,i),\] (10)with \(w_{k}\) from (5). The objective of the greedy selection process in (10) is to take the most uncertain decision among the expanders \(G_{k}\) and the maximizers \(M_{k}\). The decision \(_{k}\) is then applied to the system and after making observations of the reward and safety functions, \(_{k}:=(y_{k}^{0},y_{k}^{1},,y_{k}^{m})\), we add \((_{k},_{k})\) to the training samples.

At any iteration, we can obtain an estimate for the current best decisions from

\[}_{k}=*{arg\,max}_{ S_{k}}l_{k}( ,0),\] (11)

which returns the maximizer of the lower bound of the reward function within the current safe set.

### Safety Guarantee

To provide safety guarantees, we need the confidence intervals in (3) to contain the safety functions with high probability for all iterations. Note that the parameter \(_{k}\) in (3) tunes the tightness of the confidence interval. The following lemma guides us to make a proper choice for \(_{k}\): This choice depends on the information capacity \(_{k}^{h}\) associated with the kernel \(\), namely is the maximal mutual information  we can obtain from the GP model of \(h\) through \(k\) noisy measurements \(_{_{k}}\) at data points \(_{k}:=\{(_{},,i_{})\}_{<k}\)

\[_{k}^{h}:=_{_{k}}I(_{_{k}};h).\] (12)

**Lemma 2.4**.: _Assume that \(h(,t,i)\) has RKHS norm associated with \(\) bounded by \(B>0\) and that measurements are perturbed by \(\)-sub-Gaussian noise. Let the variable \(_{k}^{h}\) be defined as in (12). For any \((0,1)\), let \(}=B+}^{h}+1+( 1/))}\), then the following holds for all decisions \(\), function indices \(i\), and iterations \(k 1\) jointly with probability at least \(1-\):_

\[|h(,t,i)-_{k-1}(,i)|}_{k-1}( ,i).\]

Proof.: This lemma is a straightforward consequence of Lemma 1 of , a contextual extension of Lemma 4.1 of . We can prove it by selecting time as the context and picking \(\{t\}_{t 1,t}\) as the context sequence.

Lemma 2.4 indicates that, by selecting \(_{k}\) properly, the confidence intervals \(Q_{k}\) will w.h.p. contain the reward function and the safety functions. Due to this, they can be leveraged to provide theoretical guarantees for safety and optimality.

The following theorem provides a sufficient condition for safety of TVSAFEOPT.

**Theorem 2.5**.: _Let Assumptions 2.1 - 2.3 hold, and let \(_{k}^{h}\) be defined as in (12). For any \((0,1)\), let \(}=B+}^{h}+1+(1/ ))}\), then TVSAFEOPT guarantees that with probability at least \(1-\), for all \(i_{c}\) and for all \(t 0,\) and \( S_{k}\) it holds \(c_{i}(,t)\ \ 0.\)_

The proof builds on Lemma 2.4 to show first that for all \(t 0\), for all \(i\) and for all \(,\) then \(h(,t,i) C_{k}(,i)\) with high probability. Then using the recursive definition of the safe set from (6), we obtain w.h.p. \(c_{i}(,t)\ \ l_{k}(^{},i)-L_{}d( ,^{})-L(t)\ 0,\) which concludes the proof. For details we refer the reader to Appendix B.

### Near-Optimality Guarantee

In many safety critical real world applications, such as nuclear power plant operations, medical devices calibration, automated emergency response systems, the reward function is stationary most of the time. The problems are stationary until some changes happen and become stationary again when the systems reach new equilibria . However, ensuring optimality is non-trivial even when the problem becomes stationary. Suppose the auxiliary function (2) becomes stationary in a time interval \([,]\), namely suppose there exist \(> 1\) such that \( t_{1},t_{2}[,],f(,t_{1})=f (,t_{2})=:()\) and \(c(,t_{1})=c(,t_{2})=:()\), so that the optimization problem (1) becomes

\[_{}()\] (13) subject to \[_{i}() 0,\ i_{c}.\]

We first define the largest safe set expanded from a set \(S\) subject to a measurement error \(a\) within

* a single time step: \[R_{a}(S):=S\{ i_{c}, _{i}^{} S,s.t.\ _{i}(_{i}^{})-L_{ }d(,_{i}^{})-a 0\}\]
* \(n\) time steps: \(R_{a}^{n}(S):=(R_{a} R_{a}(R_{a}(S )))}_{n}\)) \()\)
* arbitrary time steps: \(_{a}(S):=_{n}R_{a}^{n}(S)\)

We also define \(_{}\) as an upper bound of the sum of all time Lipschitz constants, that is, \(_{=0}^{T-1}L()_{}\).

We find it reasonable that a tight upper bound \(_{}\) can be provided when the underlying system slowly switches to the new stationarity condition.

Given these definitions, we are now in the position to provide optimality guarantees for TVSAFEOPT. In particular, we aim at comparing the found reward value \((_{k})\) with the optimal reward value within the largest safe set obtained in ideal conditions with no measurement error, \(_{0}(S_{0})\). We also aim at providing TVSAFEOPT with an upper bound on the iterations needed to find a near-optimal solution. The following theorem states the optimality guarantee of TVSAFEOPT.

**Theorem 2.6**.: _Let Assumptions 2.1 - 2.3 hold, let \(_{k}^{h}\) be defined as in (12) and, for any \((0,1)\), let \(}=B+}^{h}+1+(1/ ))}\). Define \(}_{k}\) as in (11), and, for any \(>0\), let \(k^{*}(,)\) be the smallest positive integer satisfying_

\[}{_{k^{*}}_{k^{*}}^{h}}(|_{0}(S_{0})|+1)}{^{2}},\]

_where \(b_{1}=8/(1+^{-2})\). Then, the TVSAFEOPT algorithm, applied to (13), guarantees that, with probability at least \(1-\), there exists \(k k^{*}\) such that_

\[(}_{k})_{ R_{+ _{}}(S_{0})}()-.\]The proof consists in showing a decaying upper bound of uncertainty \(w_{k}(,i)\) and exploiting local stationarity of (13) to provide bounds on the expansion of the safe set \(S_{k}\). Details can be found in Appendix C.

## 3 Experiments

### Synthetic Example

We first illustrate TVSAFEOPT on a synthetic two-dimensional time-varying optimization problem

\[_{x,y}-e^{x^{2}}-(1+y^{2})+0.01t\] \[\ [x+0.5-0.5(1-t) ]^{2}+[y-0.3-0.5(1-t) ]^{2} 1.\]

Figure 1 compares the safe sets computed by TVSAFEOPT, ETSAFEOPT, and SAFEOPT at \(t=30\), \(t=100\) and \(t=170\). All algorithms start from the same singleton initial safe set \(S_{0}=\{(-0.5,0.0)\}\). Implementation details are described in Appendix A. Figure 1 illustrates that the safe sets computed by TVSAFEOPT are contained in the ground truth safe regions while those computed by SAFEOPT and ETSAFEOPT have multiple violations. Due to the dependence on time of the example (Figure 3), the initial safe set becomes unsafe at \(t=30,t=170\). Taking the possible changes in time into consideration, TVSAFEOPT correctly identifies the possible unsafety of the initial safe set. In contrast, SAFEOPT always consider the initial safe set to be safe. Meanwhile, ETSAFEOPT correctly identifies the lack of safety of the initial safe set at \(t=30\), but fails at \(t=170\). This is because the event trigger is naturally insensitive to continuous changes. This toy example indicates that, in contrast to SAFEOPT and ETSAFEOPT, TVSAFEOPT safely adapts to the time changes of the optimization problem.

In this example, TVSAFEOPT and ETSAFEOPT overall find better reward function values than SAFEOPT, see Figure 3. The reward function value found by TVSAFEOPT is close to the optimal values when the reward function changes slowly, which supports Theorem 2.6.

Quantitative metrics are listed in Table 2. Taking SAFEOPT as a baseline, TVSAFEOPT and ETSAFEOPT achieves less violations, lower cumulative regret at the cost of covering less part of the safe region. Furthermore, TVSAFEOPT has little violations, and achieves larger coverage ratio than ETSAFEOPT. Meanwhile, its cumulative regret is just slightly higher than that of ETSAFEOPT.

Figure 2: Comparison between TVSAFEOPT, SAFEOPT, and approximate optimization on the gas compressor case study, showing average of 10 repetitions with different initial sets. (a): The cardinality of the safe sets, (b): The ratio between the number of unsafe decisions in the safe sets and the cardinality of the safe sets, (c): The ratio between the number of safe decisions in the safe sets and the cardinality of the ground truth safe regions. TVSAFEOPT robustly shrinks its safe sets based on its observations and thus maintains much less violations in its safe sets than SAFEOPT and approximate optimization, at the cost of covering less of the ground truth safe region.

### Gas Compressor Case Study

#### 3.2.1 Problem Setup

We show the performance of the proposed algorithm in a compressor station with three identical compressors operating in parallel at the time-varying compressor head \(H_{t}\) with time-varying power consumption at time \(t\) (adapted from , details in Appendix A.3)

\[_{m_{i}} _{i=1}^{N}}(_{1}+_{2}_{i}+_{3}_{t}+_{4}_{i}^{2}+_{5}_{i} _{t}+_{6}_{t}^{2})\] (14) s.t. \[_{i=1}^{N}m_{i} M_{t}\] (15) \[m_{i} _{1}_{t}^{2}+_{2}_{t}+_{3}\,  i=1,,N\] (16) \[m_{i} _{1}_{t}^{2}+_{2}_{t}+_{3}\,  i=1,,N\] \[m_{i} _{1}}_{t}+_{2}\, i=1,,N\] \[m_{i} _{1}}_{t}^{2}+_{2}} _{t}+_{3}\, i=1,,N,\] (17)

where the objective (14) corresponds to the power to run the station with \(N\) compressors, here \(N=3\), affected by individual degradation \(d_{it}\), \(i=1,l,N\). The station must also satisfy time-varying demand \(M_{t}\) in (15). In practice, it is common to linearly approximate (16)-(17) with respect to the compressor head \(H_{t}\) (dashed lines in Figure 4) .

#### 3.2.2 Results

We compare the performance of TVSAFEOPT, SAFEOPT, and approximate optimization. ETSAFEOPT is not applicable to this case study because the magnitude of changes in the demand \(M_{t}\), compressor head \(H_{t}\), and degradation \(d_{it}\) keeps triggering the event trigger and thus the maintained safe set becomes empty very quickly. Implementation details are described in Appendix A. Figure 2 compares the number of unsafe decisions in the safe sets calculated by TVSAFEOPT, SAFEOPT, and approximate optimization. We see that, by considering the uncertainty with respect to the decision variables, SAFEOPT maintains fewer unsafe decisions in its safe sets than the approximate optimization. However, SAFEOPT tends to expand its safe sets regardless of external changes. TVSAFEOPT further improves this based on SAFEOPT by taking into consideration the time-varying safety functions. TVSAFEOPT robustly shrinks its safe sets based on its observations and thus maintains much

   & ETSAFEOPT & TVSAFEOPT \\  Violations & -84.4\% \(\) 1.7 \% & -99.99\% \(\) 0.01\% \\ Coverage Ratio & -30.9\% \(\) 2.9 \% & -21.0\% \(\) 1.3\% \\ Cumulative Regret & -73.6\% \(\) 14.7\% & -66.9\% \(\) 14.4\% \\ 

Table 2: Synthetic example: comparison of TVSAFEOPT and ETSAFEOPT with respect to SAFEOPT, showing the average and the standard deviation results from five runs with different initial safe sets (chosen randomly from the feasible space).

   & SAFEOPT & TVSAFEOPT \\  Violations & -89.2\% \(\) 4.2 \% & -96.8\% \(\) 1.0\% \\ Coverage Ratio & -35.7\% \(\) 2.6 \% & -61.0\% \(\) 1.3\% \\ Cumulative Regret & +95.8\% \(\) 32.3\% & +178.3\% \(\) 29.2\% \\ 

Table 3: Compressors case study: comparison of TVSAFEOPT and SAFEOPT with respect to Approximate Optimization, showing the average and the standard deviation results from 10 runs with different initial safe sets (chosen randomly from \([x_{0}-0.5/d,x_{0}+0.5/d]\) where \(x_{0}\) is the initial safe seed and \(d\) is the distance to the boundary of the feasible region). ETSAFEOPT is not included due to its high dependency on event detection methods, which are unavailable for compressor degradation.

less violations in its safe sets than SAFEOPT (70.4%) and approximate optimization (96.8%). It achieves this at the cost of covering less of the ground truth safe region than SAFEOPT (39.3%) and Approximate Optimization (61.0%).

The right-hand side of Figure 3 shows that TVSAFEOPT preserves safety at the expense of optimality. In the compressor case study, TVSAFEOPT overall finds lower reward function values than SAFEOPT and approximate optimization, which is consistent with the fact that it covers a lower fraction of the ground truth safe regions and the reward function changes significantly between iterations. Because of its strong focus on safety, TVSAFEOPT deviates more from the ground truth. The cumulative regret of TVSAFEOPT is above the one of SAFEOPT by 42.1%, and the one of approximate optimization by 178.3%. This illustrates the trade-off between safety and optimality in the presence of strong uncertainties due to the varying reward and safety constraints. Quantitative metrics using Approximate Optimization as the baseline are listed in Table 3.

## 4 Limitations and Conclusion

**Limitations** The compressor case study demonstrated that TVSAFEOPT ensures safety at the expense of optimality if the stationarity assumption is not satisfied. The assumption about the local stationarity of the optimization problem (1) is thus the main limitation. Even though TVSAFEOPT demonstrates good empirical performance with respect to safety even when the problem is non-stationary, theoretical guarantee for its near-optimality in the non-stationary case warrant further investigation.

The need for obtaining the Lipschitz constants with respect to both \(\) and \(t\) in order to compute the safe set \(S_{k}\) in (6) may prove limiting in real applications. To overcome this limitation, we propose practical modifications in Appendix A.1.

**Conclusions** We propose TVSAFEOPT algorithm, which extends SAFEOPT to handle time-varying optimization problems. In conclusion, TVSAFEOPT outperforms SAFEOPT in terms of adaptation to changes in time and maintains fewer unsafe decisions in its safe sets for time-varying problems. This is at the cost of covering less of the ground truth safe regions and may lead to poorer performance in terms of optimality.

We prove the safety guarantee for TVSAFEOPT in the general time-varying setting and prove its near-optimality guarantee for the case in which the optimization problem becomes stationary. The two theoretical results together guarantee that TVSAFEOPT is capable of safely transferring safety of the decisions into the future and, based on the transferred safe sets, it will find the near-optimal decision when the reward function stops changing. We show that TVSAFEOPT performs well in practice for the most general settings where both the reward function and the safety constraint are time-varying, both on synthetic data and for real case study on a gas compressor.

Figure 3: Comparison of reward functions from different methods with different initial safe sets, averaged over 5 runs for the synthetic example (left) and 10 runs for the compressor case study (right, indicating power in MW obtained from maximization of (14)), with error bars, with respect to the optimal values (black). In the synthetic example, TVSAFEOPT finds better reward function values than SAFEOPT, and similar to these of ETSAFEOPT. In the compressor case study, TVSAFEOPT finds lower reward function values than SAFEOPT, but guarantees fewer violations (Table 2 and 3) than either SAFEOPT or Approximate Optimization.