# Front-door Adjustment Beyond Markov Equivalence

with Limited Graph Knowledge

 Abhin Shah

Massachusetts Institute of Technology

abhin@mit.edu

&Karthikeyan Shanmugam

Google Research

karthikeyanvs@google.com

&Murat Kocaoglu

Purdue University

mkocaoglu@purdue.edu

###### Abstract

Causal effect estimation from data typically requires assumptions about the cause-effect relations either explicitly in the form of a causal graph structure within the Pearlian framework, or implicitly in terms of (conditional) independence statements between counterfactual variables within the potential outcomes framework. When the treatment variable and the outcome variable are confounded, front-door adjustment is an important special case where, given the graph, causal effect of the treatment on the target can be estimated using _post-treatment_ variables. However, the exact formula for front-door adjustment depends on the structure of the graph, which is difficult to learn in practice. In this work, we provide testable conditional independence statements to compute the causal effect using front-door-like adjustment without knowing the graph under limited structural side information. We show that our method is applicable in scenarios where knowing the Markov equivalence class is not sufficient for causal effect estimation. We demonstrate the effectiveness of our method on a class of random graphs as well as real causal fairness benchmarks.

## 1 Introduction

Causal effect estimation is at the center of numerous scientific, societal, and medical questions (Nabi et al., 2019; Castro et al., 2020). The \(do()\) operator of Pearl represents the effect of an experiment on a causal system. For example, the probability distribution of a target variable \(y\) after setting a treatment \(t\) to \(t\) is represented by \((y|do(t=t))\) and is known as an interventional distribution. Learning this distribution for any realization \(t=t^{}\) is what causal effect estimation entails. This distribution is different from the conditional distribution \((y|t=t)\) as there may be unobserved confounders between treatment and outcome that cannot be controlled for.

A causal graph, often depicted as a directed acyclic graph, captures the cause-and-effect relationships between variables and explains the causal system under consideration. A semi-Markovian causal model represents a causal model that includes unobserved variables influencing multiple observed variables (Verma and Pearl, 1990; Acharya et al., 2018). In a semi-Markovian graph, directed edges between observed variables represent causal relationships, while bi-directed edges between observed variables represent unobserved common confounding (see Figure 1). Given any semi-Markoviangraph, complete identification algorithms for causal effect estimation are known. For example, if \((|do(t=t))\) is uniquely determined by the observational distribution and the causal graph, the algorithm by Shpitser and Pearl (2006) utilizes the graph to derive an _estimand_, i.e., the functional form mapping the observational distribution to the interventional distribution.

Certain special cases of estimands have found widespread use across several domains. One such special case is the _back-door adjustment_(Pearl, 1993) shown in Figure 1(left). The back-door adjustment utilizes the pre-treatment variable \(\) (that blocks back-door paths) to control for unobserved confounder as follows:

\[(|do(t=t))=_{}(|t=t,=)(=),\] (1)

where the do-calculus rules of Pearl (1995) are used to convert interventional distributions into observational distributions by leveraging the graph structure. However, the back-door adjustment is often inapplicable, e.g., in the presence of an unobserved confounder between \(t\) and \(\). Surprisingly, in such scenarios, it is sometimes possible to find the causal effect using the _front-door adjustment_(Pearl, 1995) shown in Figure 1(right). Utilizing the front-door variable \(\), the front-door adjustment estimates the causal effect from observational distributions using the following formula (which is also obtained through the do-calculus rules and the graph structure):

\[(|do(t=t))\!=\!_{}_{t^{}}(|t=t^{},=)(=t^{}) (=|t=t)\] (2)

Recently, front-door adjustment has gained popularity in analyzing real-world data (Glynn and Kashin, 2017; Bellemare et al., 2019; Hunernmund and Bareinboim, 2019) due to its ability to utilize post-treatment variables to estimate effects even in the presence of confounding between \(t\) and \(\). However, in general, front-door adjustment also relies on knowing the causal graph, which may not always be feasible, especially in domains with many variables.

An alternative approach uses observational data to infer a Markov equivalence class, which is a collection of causal graphs that encode the same conditional independence relations (Spirtes et al., 2000). A line of work (Perkovic et al., 2018; Jaber et al., 2019) provide identification algorithms for causal effect estimation from partial ancestral graphs (PAGs) (Zhang, 2008), a prominent representation of the Markov equivalence class, whenever every causal graph in the collection shares the same causal effect estimand. However, learning PAGs from data is challenging in practice due to the sequential nature of their learning algorithms, which can propagate errors between tests (Strobl et al., 2019). Further, to the best of our knowledge, there is no existing algorithm that can incorporate side information, such as known post-treatment variables, into PAG structure learning.

In this work, we ask the following question: _Can the causal effect be estimated with a testable criteria on observational data by utilizing some structural side information without knowing the graph?_

Recent research has developed such testable criteria to enable back-door adjustment without knowing the full causal graph (Entner et al., 2013; Cheng et al., 2020; Gultchin et al., 2020; Shah et al., 2022). These approaches leverage structural side information, such as a known and observed parent of the treatment variable \(t\). However, no such results have been established for enabling front-door adjustment. We address this gap by focusing on the case of unobserved confounding between \(t\) and \(\), where back-door adjustment is inapplicable. Traditionally, this scenario has been addressed by leveraging the presence of an instrumental variable (Mogstad and Torgovitsky, 2018) or performing sensitivity analysis (Veitch and Zaveri, 2020), both of which provide only bounds in the non-parametric case. In contrast, we achieve identifiability by utilizing structural side information.

**Contributions.** We propose a method for estimating causal effects without requiring the knowledge of causal graph in the presence of unobserved confounding between treatment and outcome. Our approach utilizes front-door-like adjustments based on post-treatment variables and relies on conditional independence statements that can be directly tested from observational data. We

Figure 1: Representative graphs for back-door adjustment (left) and front-door adjustment (right).

require one structural side information which can be obtained from an expert and is less demanding than specifying the entire causal graph. We illustrate that our framework provides identifiability in random ensembles where existing PAG-based methods are not applicable. Further, we illustrate the practical application of our approach to causal fairness analysis by estimating the total effect of a sensitive attribute on an outcome variable using the German credit data with fewer structural assumptions. The source code of our implementation is available at https://github.com/abhin-shah/FD-adjustment-with-limited-graph.

### Related Work

**Effect estimation from causal graphs/Markov equivalence Class:** The problem of estimating interventional distributions with the knowledge of the semi-Markovian model has been studied extensively in the literature, with important contributions such as Tian and Pearl (2002) and Shpitser and Pearl (2006). Perkovic et al. (2018) presented a complete and sound algorithm for identifying valid adjustments from PAGs. Going beyond valid adjustments, Jaber et al. (2019) proposed a complete and sound algorithm for identifying causal effect from PAGs. However, our method can recover the causal effect in scenarios where these algorithms are inapplicable.

**Effect estimation via front-door adjustment with causal graph:** Several recent works have contributed to a better understanding of the statistical properties of front-door estimation (Kuroki, 2000; Kuroki and Cai, 2012; Glynn and Kashin, 2018; Gupta et al., 2021), proposed robust generalizations (Hunermund and Bareinboim, 2019; Fulcher et al., 2020), and developed procedures to enumerate all possible front-door adjustment sets (Jeong et al., 2022; Wienobst et al., 2022). However, all of these require knowing the underlying causal graph. By contrast, Bhattacharya and Nabi (2022) verified the front-door criterion without knowing the causal graph using Verma constraint-based methodology. While their method was limited to a small set of graphs, ours leverages conditional independence, making it applicable to a much broader class of graphs. We note that they're applicable in different settings, depending on what the analyst knows about the problem.

## 2 Preliminaries and Problem Formulation

**Notations.** For a sequence of realizations \(r_{1},,r_{n}\), we define \(\{r_{1},,r_{n}\}\). For a sequence of random variables \(r_{1},,r_{n}\), we define \(\{r_{1},,r_{n}\}\). Let \(\) denote the indicator function.

**Semi-Markovian Model and Effect Estimation.** We consider a causal effect estimation task where \(\) represents the set of observed features, \(\) represents the observed treatment variable, and \(}\) represents the observed outcome variable. We denote the set of all observed variables jointly by \(\{,\,,}\}\). Let \(\) denote the set of unobserved features that could be correlated with the observed variables.

We assume \(\) follows a semi-Markovian causal model (Tian and Pearl, 2002) as below.

**Definition 1**.: _A semi-Markovian causal model (SMCM) \(\) is specified as follows:_

1. \(\) _is a directed acyclic graph (DAG) over the set of vertices_ \(\) _such that each element of the set_ \(\) _has no parents._
2. \(}\)_, let_ \(^{(o)}(})\) _and_ \(^{(u)}(})\) _denote the set of parent of_ \(}\) _in_ \(\) _and_ \(\)_, respectively._
3. \(()\) _is the unobserved joint distribution over the unobserved features._
4. _The observational distribution is given by_ \((})=_{}}_{ }(} |^{(o)}(}),^{(u)}(}))\)_._
5. _The interventional distribution when the variables_ \(\) _are set to a fixed value_ \(\) _is given by_ \[(}|do(=))=_{}= }}_{}}_{ } (}|^{(o)}(}),^{(u)}(}) ).\] (3)
6. _For any_ \(}_{1},}_{2}\)_, if_ \(^{(u)}(}_{1})^{(u)}(}_{2})\)_, then_ \(}_{1}\) _and_ \(}_{2}\) _have a bi-directed edge in_ \(\)_._

In this work, we are interested in the causal effect of \(\) on \(}\), i.e., \((}|do(=t))\). We define this formally by marginalizing all variables except \(}\) in the interventional distribution in (3).

**Definition 2**.: _The causal effect of \(\) (when forced to a value \(t\)) on \(}\) is given by:_

\[(}|do(=t))\!=\!\!_{ }\{}\}} }\{}\},}|do( =t).\] (4)Next, we define the notion of average treatment effect for a binary treatment \(\).

**Definition 3**.: _The average treatment effect (ATE) of a binary treatment \(\) on outcome \(\) is given by \(=[|do(=1)]-[|do( =0)]\)._

Next, we define when the causal effect (Definition 2) is said to be identifiable from the observational distribution and the causal graph.

**Definition 4**.: _(Causal effect identifiability) Given an observational distribution \(()\) and a causal graph \(\), the causal effect \((|do(=))\) is identifiable if it is identical for every semi-Markovian Causal model with \((a)\) same graph \(\) and \((b)\) same observational distribution \(()\)._

In a causal graph \(\), a path is an ordered sequence of distinct nodes where each node is connected to the next in the sequence by an edge. A path starting at node \(w_{1}\) and ending at node \(w_{2}\) in \(\) is _blocked_ by a set \(\{w_{1},w_{2}\}\) if there exists \(w\) such that (a) \(w\) is not a collider or (b) \(w\) is a collider and neither \(w\) nor any of it's descendant is in \(\). Further, \(w_{1}\) and \(w_{2}\) are said to be _\(d\)-separated_ by \(\) in \(\) if \(\) blocks every path between \(w_{1}\) and \(w_{2}\) in \(\). Let \(w_{1}_{d}w_{2}|\) denote that \(w_{1}\) and \(w_{2}\) are d-separated by \(\) in \(\). Similarly, let \(w_{1}_{p}w_{2}|\) denote that \(w_{1}\) and \(w_{2}\) are conditionally independent given \(\). We assume causal faithfulness, i.e., any conditional independence \(w_{1}_{p}w_{2}|\) implies a d-separation relation \(w_{1}_{d}w_{2}|\) in the causal graph \(\).

### Adjustment using pre-treatment variables

It is common in causal effect estimation to consider pre-treatment variables, i.e., variables that occur before the treatment in the causal ordering, and identify sets of variables that are _valid adjustments_. Specifically, a set \(\) forms a valid adjustment if the causal effect can be written as \((|do(=))=_{} (|=,=)( =)\). In other words, a valid adjustment \(\) averages an estimate of \(\) regressed on \(\) and \(\) with respect to the marginal distribution of \(\), A popular criterion to find valid adjustments is to find a set \(\) that satisfies the _back-door criterion_(Pearl, 2009). Formally, a set \(\) satisfies the back-door criterion if (a) it blocks all back-door paths, i.e., paths between \(\) and \(\) that have an arrow pointing at \(\) and (b) no element of \(\) is a descendant of \(\). While, in general, back-door sets can be found with the knowledge of the causal graph, recent works (see the survey Cheng et al. (2022)) have proposed testable criteria for identifying back-door sets with some causal side information, without requiring the entire graph.

### Adjustment using post-treatment variables

While back-door adjustment is widely used, there are scenarios where no back-door set exists, e.g., when there is an unobserved confounder between \(\) and \(\). If no back-door set can be found from the pre-treatment variables, Pearlian theory can be used to identify post-treatment variables, i.e., the variables that occur after the treatment in the causal ordering, to obtain a _front-door adjustment_.

**Definition 5** (_Front-door criterion_).: _A set \(\) satisfies the front-door criterion with respect to \(\) and \(\) if (a) \(\) intercepts all directed paths from \(\) to \(\) (b) all back-door paths between \(\) and \(\) are blocked, and (c) all back-door paths between \(\) and \(\) are blocked by \(\)._

If a set \(\) satisfies the front-door criterion, then the causal effect can be written as

\[(|do(=))\!=\!_{} _{^{}}(|=^{ },=)(=^{}) (=|=).\] (5)

Intuitively, front-door adjustment estimates the causal effect of \(\) on \(\) as a composition of two effects: \((a)\) the effect of \(\) on \(\) and \((b)\) the effect of \(\) on \(\). However, one still needs the knowledge of the causal graph \(\) to find a set satisfying the front-door criterion.

Inspired by the progress in finding back-door sets without knowing the entire causal graph, we ask: _Can testable conditions be derived to identify front-door-like sets using only partial structural information about post-treatment variables?_ To that end, we consider the following side information.

**Assumption 1**.: _The outcome \(\) is a descendant of the treatment \(\)._

**Assumption 2**.: _There is an unobserved confounder between the outcome \(\) and the treatment \(\)._

**Assumption 3**.: \(\)_, the set of all children of the treatment \(\), is observed and known._Assumption 1 is a fundamental assumption in most causal inference works, as it forms the basis for estimating non-trivial causal effects. Without it, the causal effect would be zero. Assumption 2 rules out the existence of sets that satisfy the back-door criteria, necessitating a different way of estimating the causal effect. Assumption 3 captures our side information by requiring every children of the treatment to be known and observed. To contrast, the side information in data-driven works on back-door adjustment requires a parent of the treatment to be known and observed (Shah et al., 2022).

Our assumptions imply that \(\) intercepts all the directed paths from \(\) to \(}\). Given this, it is natural to ask whether \(\) satisfies the front-door criterion (Definition 5). We note that, in general, this is not true. We illustrate this via Figure 2 where we provide a causal graph \(^{toy}\) satisfying our assumptions. However, \(\) is not a valid front-door set in \(^{toy}\) as the back-door path between \(\) and \(}\) via \(^{(i)}\) is not blocked by \(\). Therefore, estimating the causal effect by assuming \(\) is a front-door set might not always give an unbiased estimate. In the next section, we leverage the given side information and provide testable conditions to identify front-door-like sets.

## 3 Front-door Adjustment Beyond Markov Equivalence

In this section, we provide our main results, an algorithm for ATE estimation, and discuss the relationship to PAG-based methods. Our main results use observational criteria for causal effect estimation under Assumptions 1 to 3 using post treatment variables.

### Causal effect estimation using post-treatment variables

First, we state a conditional independence statement implying causal identifiability. Then, we provide additional conditional independence statements resulting in a unique formula for effect estimation.

Causal identifiability (Definition 4) implies that the causal effect is uniquely determined given an observational distribution \(()\) and the corresponding causal graph \(\). We now show that satisfying a conditional independence statement (which can be tested solely from observational data, without requiring the graph \(\)) guarantees identifiability. We provide a proof in Appendix D.

**Theorem 3.1** (**Causal Identifiability**).: _Suppose Assumptions 1 to 3 hold. If there exists a set \(\{t,,}\}\) such that \(\!\!\!_{d}}|t,\), then the causal effect of \(t\) on \(}\) is identifiable from observational data without the knowledge of the underlying causal graph \(\)._

While the above result leads to identifiability, it does not provide a formula to compute the causal effect. In fact, the conditional independence \(\!\!\!_{d}}|t,\) alone is _insufficient_ to establish a unique formula, and different causal graphs lead to different formula. To illustrate this, we provide two SMCMs where Assumptions 1 to 3 and \(\!\!\!_{d}}|t,\) hold, i.e., causal effect is identifiable from observational data via Theorem 3.1, but the formula is different. First, consider the SMCM in Figure 3(top) with \(=(_{1},_{2})\) where causal effect is given by following formula (derived in Appendix D):

\[(}|do(=t))=_{z_{1},z_{2},}_{t^{}}(}|z_{1},z_{2},t^{ })(t^{}|z_{1})(z_{2}|) (|t,z_{1})(z_{1}).\] (6)

Next, consider the SMCM in Figure 3(bottom) with \(=_{2}\) where the causal effect is given by the front-door adjustment formula in (5) as \(\) satisfies the front-door criterion. It remains to explicitly show that the formula in (6) is different from (5). To this end, we create a synthetic structural equation model (SEM) respecting the graph in Figure 3(top) and show that the formula in (5) gives a non-zero ATE error. In our SEM, the unobserved variable has a uniform distribution over \(\). Each observed variable except \(t\) is a sum of \((i)\) a linear combination of its parents with

Figure 3: SMCMs on (top) & (bottom) satisfy \(\!\!\!_{d}}|t,\) but have different causal effect estimation formulae.

Figure 2: The graph \(^{toy}\) satisfying Assumptions 1 to 3 where \(u_{i}\) are unobserved.

[MISSING_PAGE_FAIL:6]

### Algorithm for ATE estimation

The ATE can be computed by taking the first moment version of (9) or (10). In Algorithm 1, we provide a systematic way to estimate the ATE using Theorem 3.2 by searching for a set \(\{t,,\}\) such that (a) p-value of conditional independence in (7) passes a threshold \(p_{v}\) and (b) there exists a decomposition \(=(^{(i)},^{(o)})\) such that p-values of conditional independencies in (8) pass the threshold \(p_{v}\). Then, for every such \(\), the algorithm computes the ATE using the first moment version of (9), and averages. The algorithm produces another estimate by using (10) instead of (9).

### Relation to PAG-based algorithms

Now, we exhibit how our approach can recover the causal effect in certain scenarios where PAG-based methods are not suitable. PAGs depict ancestral relationships (not necessarily direct) with directed edges and ambiguity in orientations (if they exist across members of the equivalence class) by circle marks. Figure 4(c) shows the PAG consistent with SMCM in Figure 4(a). While we formally define PAGs in Appendix B, we refer interested readers to Triantafillou and Tsamardinos (2015). The IDP algorithm of Jaber et al. (2019) is sound and complete for identifying causal effect from PAGs.

Consider SMCM in Figure 4(a) where our approach recovers the causal effect as \((i)\) Assumptions 1 to (3), \((ii)\) (7), and \((iii)\) (8) hold (where \((ii)\) and \((iii)\) can be tested from observational data). However, the IDP algorithm fails to recover the effect from the PAG. To see this, consider SMCM in Figure 4(b) which is Markov equivalent to SMCM in Figure 4(a), i.e., the PAG in Figure 4(c) is also consistent with SMCM in Figure 4(b). Intuitively, when the strength of the edge between \(t\) and \(\) is very small but the strength of the edge between \(t\) and \(\) is very high for both Figure 4(a) and Figure 4(b), causal effect in Figure 4(b) remains high while the causal effect in Figure 4(a) goes to zero.

We note that Assumptions 1 and 3, and (7) do not hold for the SMCM in Figure 4(b).

**Remark 2**.: _Obtaining a PAG requires a large number of sequential conditional independence tests where the choice of the next test depends on the previous ones (Claassen et al., 2013). The erroneous tests and orientation steps can potentially alter the structure of the PAG non-locally (see Strobl et al. (2016) for an example). This makes it difficult to control the false discovery rate for PAG based methods. Moreover, incorporating arbitrary side information into a PAG in a systematic way is still an open problem. In contrast, our approach does not rely on constructing a graphical object such as a PAG and the conditional independence tests could be carried out in parallel. Thus, our method can be viewed as a way to mitigate the issues associated with sequential testing by using structural side information. However, in scenarios where the structural side information is not available, we may have to resort to PAG-based methods._

## 4 Empirical Evaluation

We evaluate our approach empirically in 3 ways: \((i)\) we demonstrate the applicability of our method on a class of random graphs, \((ii)\) we assess the effectiveness of our method in estimating the ATE using finite samples, and \((iii)\) we showcase the potential of our method for causal fairness analysis.

### Applicability to a class of random graphs

In this experiment, we create a class of random SMCMs, sample 100 SMCMs from this class, and check if (7) and (8) hold by checking for corresponding d-separations in the SMCMs.

Figure 4: (a) An SMCM satisfying (7) and (8). (b) An SMCM obtained from (a) by modifying the edges between \(t\) and \(\) and between \(t\) and \(\). (c) The PAG corresponding to SMCM in (a) and (b).

**Creation of random SMCMs.** Let \(p||\) denote the dimension of observed variables including \(\), \(t\), and \(\). Let \(_{},,_{}\) denote a causal ordering of these variables. Our random ensemble depends on two parameters: \((i)\)\(d p/2\) which is the expected in-degree of variables \(_{d},,_{}\) and \((ii)\)\(q p\) which controls the number of unobserved features. For \(1 i<j p\), we add \(_{}_{}\) with probability 0.5 if \(j 2d\) and with probability \(d/(j-1)\) if \(j>2d\). We note that this procedure is such that the expected in-degree of variables \(_{d},,_{}\) is same (and equal to \(d\)) which is consistent with other recent work (e.g., Addanki et al. ). Next, for \(1 i<j p\), we add \(_{}\ \ \ \ _{}\) with probability \(q/p\) such that the expected number of unobserved features is \(q(p-1)/2\). Then, we choose \(_{}\) as \(\), any variable that is ancestor of \(\) but not its parent or grandparent as \(\), and all children of \(\) as \(\). Finally, we add \(\ \ \ \ \) if missing.

**Results.** We compare the success rate of two approaches: \((i)\) exhaustive search for \(\) satisfying (7) and (8) which is exponential in \(p\) and \((ii)\) search for a \(\) of size at-most 5 satisfying (7) and (8) which is polynomial in \(p\). We provide the number of successes of these approaches as a tuple in Table 1 for various \(p\), \(d\), and \(q\). We see that the two approaches have comparable performances. We also compare with the IDP algorithm by providing it the true PAG. However, it gives 0 successes across various \(p\), \(d\), and \(q\). We provide results for another random ensemble in Appendix G.

### Estimating the ATE

In this experiment, we generate synthetic data using the 6 random SMCMs in Section 4.1 for \(p=10\), \(d=2\), and \(q=1.0\) where our approach was successful indicating existence of \(=(^{(i)},^{(j)})\) such that the conditional independence statements in Theorem 3.2 hold. Then, we use Algorithm 1 to compute the error in estimating ATE and compare against a Baseline which uses the front-door adjustment in (5) with \(=\) given the side information in Assumption 3. We provide the results for the same experiment for specific choices of SMCMs including the one in Figure 2 in Appendix G. We also provide the 6 random SMCMs in Appendix G. We use RCoT hypothesis test [Strobl et al., 2019] for conditional independence testing from finite data.

**Data generation.** We use the following procedure to generate data from every SMCM. We generate unobserved variables independently from \(\) which denotes the uniform distribution over \(\). For every observed variable \(\), let \(()(^{()}(),^{( )}())^{d_{v} 1}\) denote the set of observed and unobserved parents of \(\) stacked as a column vector. Then, we generate \(\) as

\[=_{}^{}()+0.1\ \ (0,1) \{\}=((_{t}^{}()))\] (11)

where the coefficients \(_{}^{d_{v} 1}\) with every entry sampled independently from \(\). Also, to generate the true ATE, we intervene on the generation model in (11) by setting \(t=0\) and \(t=1\).

**Results.** For every SMCM, we generate \(n\) samples of every observed variable in every run of the experiment. We average the ATE error over 10 such runs where the coefficients in (11) vary across runs. We report the average of these averages over the 6 SMCMs in Figure 5 for various \(n\). While the error rates of Baseline and Algorithm 1 are of the similar order for \(n=100\), Algorithm 1 gives much lower errors for \(n=1000\) and \(n=10000\) showing the efficacy of our method.

    & & \(p=10\) & & & \(p=15\) & \\  & \(d=2\) & \(d=3\) & \(d=4\) & \(d=2\) & \(d=3\) & \(d=4\) \\   \(q=0.0\) & \((43,43)\) & \((20,20)\) & \((21,21)\) & \((27,26)\) & \((9,9)\) & \((4,2)\) \\ \(q=0.5\) & \((23,23)\) & \((16,16)\) & \((7,7)\) & \((18,17)\) & \((4,3)\) & \((0,0)\) \\ \(q=1.0\) & \((6,6)\) & \((4,4)\) & \((5,5)\) & \((9,9)\) & \((10,9)\) & \((0,0)\) \\   

Table 1: Number of successes out of 100 random graphs for our methods shown as a tuple. The first method searches a \(\) exhaustively and the second method searches a \(\) with size at-most 5.

Figure 5: Average ATE for Algorithm 1 and Baseline vs. number of samples.

### Experiments with real-world fairness benchmarks

Next, we describe how our results enable finding front-door-like adjustment sets in fairness problems. In a typical fairness problem, the goal is to ensure that the outcome variable \(\) does not unfairly depend on the sensitive/protected attribute, e.g., race or gender (which we define to be treatment variable \(t\)), which would reflect undesirable biases. Often, the outcome is a descendant of the sensitive attribute (as per Assumption 1), and both outcome and sensitive attribute are confounded by unobserved variables (as per Assumption 2). Furthermore, there are be a multitude of measured post-sensitive-attribute variables that can affect the outcome. This stands in contrast to the usual settings for causal effect estimation, where pre-treatment variables are primarily utilized.

Fairness problems are typically evaluated using various fairness metrics, such as causal fairness metrics or observational metrics. Causal metrics require knowing the underlying causal graph, which can be a challenge in practice. Observational criteria can be decomposed into three types of effects (Zhang and Bareinboim, 2018; Plecko and Bareinboim, 2022): spurious effects, direct effects, and indirect effects (through descendants of sensitive attribute). In some scenarios, capturing the sum of direct and indirect effects is of interest, but even this requires knowing the causal graph.

Now, we demonstrate the application of our adjustment formulae in Theorem 3.2 to compute the sum of direct and indirect effects of the sensitive attribute on the outcome, while separating it from spurious effects. The sum of these effects is indeed the causal effect of sensitive attribute on the outcome. In other words, we consider the following fairness metric: \([|do(t=1)]-[|do(t=0)]\). We assume that all the children of the sensitive attribute are known, which may be easier to justify compared to the typical assumption in causal fairness literature of knowing the entire causal graph.

German Credit Dataset.The German Credit dataset (Hofmann, 1994) is used for credit risk analysis where the goal is to predict whether a loan applicant is a good or bad credit risk based on applicant's 20 demographic and socio-economic attributes. The binary credit risk is the outcome \(\) and the applicant's age (binarized by thresholding at \(25\)(Kamiran and Calders, 2009)) is the sensitive attribute \(t\). Further, the categorical attributes are one-hot encoded.

We apply Algorithm 1 with \(n_{r}=100\) and \(p_{v}=0.1\) where we search for a set \(=(^{(o)},^{(i)})\) of size at most \(3\) under the following two distinct assumptions on the set of all children \(\) of \(t\):

1. When considering \(\!=\!\{\#\}\), Algorithm 1 results in \(^{(i)}\!=\!\{\}\), \(^{(o)}\!=\!\{\}\), \(_{z}=0.0125 0.0011\), and \(_{s}=0.0105 0.0018\).
2. When considering \(\!=\!\{\#\}\), Algorithm 1 results in \(^{(i)}\!=\!\{\}\), \(^{(o)}\!=\!\{\}\), \(_{z}=0.0084 0.0008\), and \(_{s}=-0.0046 0.0021\).

Under the first assumption above, the causal effect using the adjustment formulae in (9) and (10) have same sign and are close in magnitude. However, under the second assumption, the effect flips sign. The results suggest that the second hypothesis regarding \(\) is incorrect, implying that applicant's job may indeed be a direct child of applicant's age, which aligns with intuition.

The dataset has only 1000 samples, which increases the possibility of detecting independencies in our criterion by chance, even with the size of \(\) constrained. To address this issue, we use 100 random bootstraps with a sample size equal to half of the training data and evaluate the p-value of our conditional independence criteria for all subsets returned by our algorithm. We select the subset \(\) with the highest median p-value (computed over the bootstraps) and use it in our adjustment formulae on a held out test set. To assess the conditional independencies associated with the selected \(\), we plot a histogram of the corresponding p-values for all these bootstraps. If the conditional independencies hold, we expect the p-values to be spread out, which we observe in the histograms in Figure 6 for the first choice of \(\). We report similar results for the second choice of \(\) in Appendix G.

**Adult Dataset:** We perform a similar analysis on the Adult dataset (Kohavi and Becker, 1996). With suitable choices of \(\), Algorithm 1 was unable to find a suitable \(\) satisfying \(_{p}|\), \(t\). This suggests that in this dataset, there may not be any non-child descendants of the sensitive attribute, which is required for our criterion to hold. More details can be found in Appendix G.

## 5 Conclusion, Limitations, and Future Work

In this work, we proposed sufficient conditions for causal effect estimation through a generalized front-door adjustment given structural side information irrespective of the number or complexity of the latent confounders. Our approach can identify causal effect in graphs where known Markov equivalence classes do not allow identification. However, our approach relies primarily on two assumptions: Assumption 2 and Assumption 3.

Assumption 2 plays a crucial role in Theorem 3.2 (see the discussion in Section E.3) as it requires the presence of an unobserved confounder between the treatment variable and the outcome variable. This assumption is necessary for the applicability of our approach. If Assumption 2 does not hold, it implies that there is a set that satisfies the back-door criterion, and existing methods for finding back-door adjustment sets (Entner et al., 2013; Cheng et al., 2020; Shah et al., 2022) can be utilized. This suggests that our results could be derived under the weaker condition that there is an unblockable back-door path between \(\) and \(\). However, in many real-world scenarios, the presence of unobserved variables that potentially confound the treatment and the outcome is common, and we expect Assumption 2 to be true.

Assumption 3 is the requirement of knowing the entire set of children of the treatment variable within the causal graph. While this is strictly less demanding than specifying the entire causal graph, it may still present practical challenges in real-world scenarios. For instance, in large-scale observational studies or domains with numerous variables, exhaustively identifying all the children may be computationally demanding. It remains unclear whether one can estimate the causal effect using front-door-like adjustment with even less side information, e.g., knowing only one child of the treatment variable or knowing any subset of children of the treatment variable. An important future direction could be to approximate the causal effect when only the children corresponding to weak edges are unknown. Such variations around our condition are promising directions for future work. However, until then, one could seek input from domain experts. These experts possess valuable knowledge and insights about the specific domain under study, which can aid in identifying all the relevant variables that serve as children of the treatment.

The time complexity of Algorithm 1 is exponential due to its search over all possible subsets of observed variables (except \(t,,\)). While this is inherent in the general case, recent work by Shah et al. (2022) proposed a scalable approximation for conditional independence testing using continuous optimization by exploiting the principle of invariant risk minimization, specifically for back-door adjustment without the need for the causal graph. However, extending this approach to multiple conditional independence tests, as required in (7) and (8), remains an open challenge. Therefore, exploring the development of continuous optimization-based methods for scalability of front-door adjustment in the absence of the causal graph is crucial. Further, Algorithm 1 could potentially be augmented with ideas from double machine learning and inverse variance weighting for bias and variance reduction.

Lastly, it is important to note that Theorem 3.2 provides only sufficient conditions for causal effect estimation. This means that there may be cases where front-door-like adjustment is possible, but the conditions stated in Theorem 3.2 do not hold. Specifically, there could be scenarios, such as when the outcome variable is a child of the children of the treatment variable, i.e., \(y\) is a child of \(\), where conditions (7) and (8) are not satisfied.

Figure 6: Histograms of p-values of the conditional independencies in (9) and (10) over 100 bootstrap runs for \(=\{\}\).