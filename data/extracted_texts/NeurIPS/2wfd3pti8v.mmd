# Automated Efficient Estimation using

Monte Carlo Efficient Influence Functions

 Raj Agrawal

Basis Research Institute, Broad Institute

raj@basis.ai

Sam Witty

Basis Research Institute, Broad Institute

sam@basis.ai

Andy Zane

Basis Research Institute, UMass Amherst

andy@basis.ai

&Eli Bingham

Basis Research Institute, Broad Institute

eli@basis.ai

###### Abstract

Many practical problems involve estimating low dimensional statistical quantities with high-dimensional models and datasets. Several approaches address these estimation tasks based on the theory of influence functions, such as debiased/double ML or targeted minimum loss estimation. We introduce _Monte Carlo Efficient Influence Functions_ (MC-EIF), a fully automated technique for approximating efficient influence functions that integrates seamlessly with existing differentiable probabilistic programming systems. MC-EIF automates efficient statistical estimation for a broad class of models and functionals that previously required rigorous custom analysis. We prove that MC-EIF is consistent, and that estimators using MC-EIF achieve optimal \(\) convergence rates. We show empirically that estimators using MC-EIF are at parity with estimators using analytic EIFs. Finally, we present a novel capstone example using MC-EIF for optimal portfolio selection.

## 1 Introduction

Over the past several decades, there has been remarkable progress on robust and efficient statistical estimation, especially for high dimensional problems. A particularly compelling class of such methods are built on a foundation of _efficient influence functions_ (EIF), i.e., functional derivatives in the space of probability distributions . These methods have been particularly fruitful in causal inference applications, where estimating quantities such as the average treatment effect require modeling high-dimensional nuisance parameters relating confounders to treatment and outcome variables. Intuitively, these methods focus finite statistical resources on quantities that matter, and not on nuisance parameters that only indirectly inform the statistical quantities we wish to estimate.

Despite their successes, estimation methods based on the EIF have lagged behind the kinds of automation that machine learning practitioners have grown accustomed to, instead requiring complex manual derivation on a case-by-case basis. This is contrasted with the generality of automatic differentiation (AD) systems  and probabilistic programming languages (PPLs) such as Pyro  or Gen , which automate numerical computations for probabilistic inference. EIF-based estimators have historically eluded this level of automation and generality, because exact recovery of the EIF requires solving high-dimensional integral equations.

**Contributions.** We introduce _Monte Carlo Efficient Influence Functions_ (MC-EIF), a general and automated technique for numerically computing EIFs using only quantities that are already available from existing AD and PPL systems. Our key insight is that EIFs can be expressed equivalently as a product of (i) the gradient of the functional, (ii) the inverse Fisher information matrix, and (iii) thegradient of the log-likelihood, as shown in Theorem 3.4 in Section 3. In Section 4, we show how MC-EIF can be used to automatically construct a variety of efficient estimators for a broad class of models and functionals, avoiding the need for complex manual and error-prone derivations.

In summary, we show that: (i) MC-EIF provides accurate estimates of the true EIF, enabling efficient estimation, and (ii) MC-EIF is very general, applying to many functionals and models that can be written as probabilistic programs. In Section 3, we introduce MC-EIF and provide a non-asymptotic error bound on the quality of our approximation. We show how estimators using MC-EIF achieve the same asymptotic guarantees as using analytic EIFs in Section 4. In Section 5, we show empirically that MC-EIF produces more accurate estimates of the EIF than existing automated approaches, and using MC-EIF as a drop-in replacement for the analytic EIF does not degrade estimation accuracy in a variety of benchmarks, including a novel capstone on optimal portfolio allocation.

**Related Work.** Influence function-based estimators have a rich history in the statistics and machine learning literature . Despite their effectiveness, these methods have historically required custom and complex mathematical analysis for specific combinations of models and functional. Even an incomplete recent survey of the influence function-based estimation literature yields a large collection of complex scenario-specific research. For targeted minimum loss estimation (TMLE) ; cluster-randomized trials , continuous time-dependent interventions , mixed experimental and observational data , mediation analysis with longitudinal data , subgroup treatment effect estimation , survival and competing risks analysis , continuous time-to-event outcomes , and variable importance measures for effect estimates . For double/debiased machine learning ; difference-in-differences , instrumental variable designs , and mediation analysis .. Importantly, our work does not introduce novel efficient estimators; instead it aims to lower the mathematical burden for practitioners who wish to use existing influence function-based efficient estimator templates (see Section 4) with custom models and/or functionals.

Our work is not the first to attempt to automate and generalize computations for efficient statistical estimation. Perhaps the closest technique we are aware of is approximating the influence function using finite differences on kernel-smoothed empirical distributions . We provide a thorough comparison with this method in Section 5, demonstrating how MC-EIF automates and scales better to high dimensional problems, exactly the settings where efficient estimation is most useful. Recent work has made progress towards general efficient estimators, but still impose strong restrictions on models and/or functionals. DML-ID  extends double machine learning to nonparametric causal graphs and marginal density under intervention functionals. Similarly, the kernel debiased plugin estimator  implements a version of TMLE that bypasses the influence function computations for models defined in a RKHS. Finally, other recent work  approximates the efficient influence function for generalized method-of-moment estimators.

Finally, we note that there are a number of intriguing connections between three related but distinct mathematical objects: the _efficient influence function_ in semiparametric statistics , the _natural gradient_ in information geometry , and the so-called _empirical influence function_ in robust statistics and machine learning . A comprehensive review of these connections is beyond the scope of this paper, and we focus here on two particularly important points for contextualizing our work. First, we emphasize that **the efficient and empirical influence functions are not equivalent**: the efficient influence function is a fundamental mathematical object in semiparametric statistical theory which quantifies the effect of perturbing a functional in an arbitrary direction in the space of probability measures, while the empirical influence function is a distinct and somewhat more specialized  object quantifying the effect of perturbing individual training points in a parametric statistical model. More specifically, in the parametric setting the efficient influence function is defined as shown in Theorem 3.4 in terms of the Fisher information matrix , whereas the empirical influence function is defined in terms of the Hessian of a model at the training points, two quantities with very different mathematical and statistical properties that are not straightforwardly interchangeable . Second, we note that **existing algorithms for computing natural gradients and empirical influence functions cannot immediately be adapted to efficient estimation**. Specifically, our algorithm described in Section 3 for Monte Carlo approximation of the efficient influence function is similar in structure to some previous algorithms developed for estimating the natural gradient  and empirical influence function . This would seem to suggest porting other methods that compute more heavily biased approximations of the natural gradient [GLB\({}^{+}\)18] and empirical influence function to computing the efficient influence function, as some of these methods are known to scale to even the largest neural network models deployed in practice today [GBA\({}^{+}\)23]. However, these approximations are not directly applicable in our setting because provably efficient estimation is only known to be possible with tight control over any approximation error introduced in computing the efficient influence function, as discussed in Section 4 below and in [JWZ22a]. Relaxing these restrictions to enable similarly scalable variations on the basic MC-EIF framework of Section 3 is an important direction for future work.

## 2 Problem Statement

**General Problem.** We consider the estimation of some estimand \(^{*}^{L}\), where \(L\) denotes the dimension of the target quantity. Typically, we can express \(^{*}=(^{*})\) for some known functional \(\), where \(\) maps a probability distribution to a vector in \(^{L}\), and \(^{*}(x)\) denotes the true data-generating distribution over some vector of observables \(x^{D}\), \(D\). Many estimation tasks involve high-dimensional _nuisance_ parameters, or quantities of no immediate value to the analyst. For example, to estimate the average treatment effect, one might need to adjust for high-dimensional confounders.

**Semiparametric Solution.** Semiparametric statistics provides a mathematical framework for optimally estimating \(^{*}\) in the presence of potentially complex, high-dimensional nuisance parameters. A standard way to estimate \(^{*}\) is with the _plug-in approach_; construct an estimate \(}\) of \(^{*}\) and report \(=(})\). Unfortunately, the plug-in approach can lead to provably sub-optimal estimates of \(^{*}\) due to poor estimates of \(^{*}\)[Tsi06, CCD\({}^{+}\)18, FS23]. Instead, a general recipe for efficiently estimating \(^{*}\) from finite data \(\{x_{n}\}_{n=1}^{N}\), where \(x_{n}}}{{}}^{*}(x)\) for \(n=1,,N\), is given by the following three-steps: (i) use \(N/2\) samples to construct an initial estimate \(}\) of \(^{*}\), (ii) compute the influence function (to be defined shortly) of \(\) at the estimate \(}\), and (iii) evaluate the influence function at the held out \(N/2\) datapoints to derive a corrected estimate.1 In Section 4, we elaborate on how influence functions are used to construct several popular efficient estimators.

**Influence Functions.** A central premise of this paper is that to automate efficient estimation, it suffices to automate the computation of _influence functions_, which can be thought of as gradients in function space. We make this precise below.

**Definition 2.1**.: (Gateaux derivative) Consider the \(\)-perturbed probability distribution \(_{}(1-)+= +(-)\), where \(\) is some probability distribution. \(\) is _Gateaux_ differentiable at \(\) if the following limit exists:

\[(_{})_{=0}=_{  0}_{})-()}{}.\]

The Gateaux derivative can be viewed as a generalization of the directional derivative from ordinary calculus; it characterizes how much a functional changes at a point \(\) in the direction \(-\).

**Definition 2.2**.: (Influence function) Suppose there exists a square integrable function \( L^{2}()\) such that

\[(_{})_{=0}= ,q-p_{L^{2}}=_{x^{D}}(x)(q(x)-p(x))dx\]

for all \(\) and \(_{x}[(x)]=0\), where \(\) denotes some space of probability distributions and \(p()\) and \(q()\) are the density functions for \(\) and \(\), respectively. Then, \(\) is called an influence function for \(\) at \(\).

An influence function is a re-centered "functional gradient" in \(L^{2}()\): just as the Euclidean inner product between the gradient of a function and a vector yields the directional derivative in ordinary differential calculus, the \(L^{2}()\) inner product between the influence function and perturbation \(-\) yields the Gateaux directional derivative. Influence functions, however, are not always unique [Tsi06, Ken16] -- some may lead to higher asymptotic variance estimators than others. The optimal influence function minimizes asymptotic variance, and is called the _efficient influence function (EIF). When the EIF exists, it is \(\) almost everywhere unique, and found through a Hilbert space projection onto what is known as the nuisance tangent space. We defer details to  and .

As the influence function in Definition 2.2 is defined implicitly as a solution to an infinite set of integral constraints over \(\), it is often hard to find. Entire papers have been written to analytically derive influence functions; see, for example, the papers listed in Section 1. For even experts in machine learning and statistics, such derivations are out-of-reach, time consuming, and error prone.

## 3 Monte Carlo Efficient Influence Function

Much of the work in semiparametric statistics and efficient estimation has focused on scenarios where the nuisance function is modeled nonparametrically . However, practitioners often use high-dimensional parametric models such as generalized linear models, neural networks, and tensor splines in practice due to their flexibility and ability to scale to large datasets. Due to the richness of these high-dimensional spaces, inference is still statistically challenging and benefits from efficient estimation; see, for example, Table 1 in . Specifically, in contrast to traditional low-dimensional parametric models where maximum likelihood estimation is typically efficient , high-dimensional parametric models often exhibit distinct asymptotic behaviors . In these high-dimensional models, estimates may converge slower than classic \(O_{p}(})\) rates without the application of efficient inference methods . A key question we address is whether using a high-dimensional parametric model simplifies the process of solving Definition 2.2. We show that it does below.

**Notation.** We let \(^{p}\) denote a finite-dimensional parameter specifying a distribution on the observed random variables \(x^{D}\) for \(p<\), \(p\). \(_{}(x)\) corresponds to a distribution in this space, and \(_{^{*}}(x)\) the true distribution, or the one closest to the true data-generating distribution in Kullback-Leibler distance. We let \(()\) denote a function \(^{p}^{L}\) that equals the evaluation of the functional \((_{})\) for all \(\). Under mild differentiability assumptions, we provide the analytic formula for the EIF in Theorem 3.4.

The first assumption states that the density of \(_{}(x)\) is continuous and differentiable with respect to \(\), a condition satisfied by many parametric model families. For example, the univariate Gaussian density \(}(-0.5(x-)^{2})\) is a continuous and differentiable function of its mean, \(\).

**Assumption 3.1**.: \( x^{D}\), the map \(_{}(x)\) is continuous and differentiable with respect to \(\).

The next assumption is also satisfied for many functionals. For example, consider the mean functional \((_{})=_{x_{}}[x]\). Continuing with the univariate Gaussian example from above, where the mean is unknown, we have \(()=\), which is a continuous and differentiable function of \(\).

**Assumption 3.2**.: \(()\) is a continuous and differentiable function of \(\).

The last assumption requires that the Fisher information matrix be invertible, which is necessary for \(\) to be identifiable .

**Assumption 3.3**.: Fisher information \(I()_{x_{}(x)}[_{} _{}(x)_{}_{}(x)^{T}]\) is invertible.

**Theorem 3.4**.: _(Theorem 3.5 in ) Suppose Assumption 3.1, Assumption 3.2, and Assumption 3.3 hold. Then, the efficient influence function \(_{}()\) at \(\) evaluated at the point \(^{D}\) equals_

\[[_{}()]^{T}I()^{-1}_{}_{}( ). \]

While Equation 1 has been around for many decades, it has mainly been used as a theoretical tool for mathematical statisticians. In particular, Equation 1 is typically evaluated at the true data generating parameter \(^{*}\) to characterize the theoretical asymptotic variance of an estimator. In other instances, it is used to derive approximate confidence intervals; see, for example, Chapter 3 in . In the following Sections, we discuss how Equation 1 provides a key ingredient in automating efficient estimation in high-dimensional parametric models.

### Numerically Approximating the EIF

Given a model \(_{}()\) and functional \(()\), we seek to automatically compute Equation 1. Our _Monte Carlo efficient influence function_ (MC-EIF) estimator achieves this automation by replacing \(()\) and \(I()\), which are typically unknown, with stochastic approximations \(_{M}()\) and \(_{M}()\) computed from \(M\) Monte Carlo samples:

\[_{,M}()[_{}_{M}()]^{T }_{M}()^{ 1}_{}_{}(). \]

Here, we show that Equation 2 leads to an automated and accurate approach to numerically computing EIFs using only quantities provided by existing AD and PPL systems.

**Approximating \(_{M}()^{ 1}_{}_{}()\).** We draw \(x_{m}}{}_{}(x),1 m M\) for \(M\), and let

\[_{M}()=_{m=1}^{M}_{}_{}( x_{m})_{}_{}(x_{m})^{T}. \]

A naive approach for computing \(_{M}()^{ 1}_{}_{}()\) is calculating the full \(p p\) matrix in Equation 3, inverting it, and then taking its product with the score vector \(_{}_{}(x_{m})^{T}^{p}\) computed from AD. This naive approach takes \(O(Mp^{2}+p^{3})\) time and \(O(p^{2})\) memory which might be too expensive for large \(p\). Instead, we exploit AD and numerical linear algebra techniques to avoid explicitly storing and inverting the approximate Fisher information matrix, similar to . Suppose that we have a black-box method to compute Fisher vector products \(_{M}()v\) for arbitrary vectors \(v^{p}\). Then, we could use the conjugate gradient algorithm to iteratively find \(_{M}()_{}^{-1}_{}()\), where the cost of each conjugate gradient step is determined by the cost to compute \(_{M}()v\). While the number of conjugate gradient steps needs to be \(p\) for an exact inverse, often far fewer iterations are required for a close approximate solution . To make computing \(_{M}()v\) efficient, we collect the \(M\) simulated datapoints in the matrix \(X_{M}^{M D}\) and let

\[_{}(X_{M})(_{}(x_{1}),, _{}(x_{M}))^{T}^{M}.\]

Then, \(_{M}()v\) equals

\[[J_{M}^{T}J_{M}]v=[J_{M}^{T}][ J_{M}v], \]

where \(J_{M}=_{}_{}(X_{M})^{M p}\) is the Jacobian matrix. We use _Pearlmutter's trick_ to avoid computing the entire Jacobian matrix . In particular, this method allows us to compute the Jacobian vector product \(v_{M}=[J_{M}v]^{M}\) in time proportional to a single evaluation of \(_{}(X)\) and \(O(M+p)\) memory. Similarly, we use the vector Jacobian product to compute \(J_{M}^{T}v_{M}\).

**Approximating \(_{}}_{M}()\).** Robust estimation with MC-EIF does not require exact gradients. Instead, it only requires a sequence of gradient estimators \(\{_{}_{m}()\}_{m=1}^{}\) of \(_{}()\) whose error can be bounded above by some \(_{m}>0\), where the \(M\)th iterate \(_{}_{M}()\) is used in Equation 2.2 Using such a sequence guarantees that the approximation error of Equation 2 is not dominated by \(_{}_{M}()\). In practice, the target functional \(()\) might be quite complex, making gradient estimation challenging. For example, it might involve taking expectations with respect to conditionals of \(_{}(x)\), or be defined implicitly as a solution to an optimization problem as in .

One particularly simple and general way to address this challenge is to implement a Monte Carlo estimator of \(\) that can be transformed via automatic differentiation into an efficient Monte Carlo estimator for its gradient, a well-understood problem that is beyond the scope of this paper to review. We note that for the very wide class of functionals that can be written as nested expectations, recent work  gives formal statements of smoothness assumptions and theoretical results sufficient to obtain the oracle rate \(_{m}\) in terms of numbers of samples, as well as algorithms that can be implemented using automatic differentiation software like PyTorch . For example code snippets of functionals, see Appendix B.

### Theoretical Guarantees for MC-EIF

We conclude by deriving a non-asymptotic error bound for how well Equation 2 approximates Equation 1. For fixed input dimension \(D\) and model sizes \(p\), Equation 2 converges to Equation 1 at a \(O_{p}(1/)\) rate by the Law of Large Numbers. As we are interested in high-dimensional parametric families, we analyze the behavior of our approximation as a function of both input dimension \(D\) and model size \(p\). To prove our result, we use standard tools and assumptions from empirical process theory such as the requirement of sub-Gaussian tails .

**Assumption 3.5**.: Suppose \(x_{}(x)\). There exists a universal constant \(0<C_{1}<\) such that the normalized score vector \(}_{}_{}(x)\) is a sub-Gaussian random vector with parameter \(C_{1}\).

As \([\|_{_{j}}_{}(x)\|_{2}^{2}]=O(D)\), \(1 j p\), the division by \(\) in Assumption 3.5 ensures that the variance of the score does not grow unboundedly as \(D\). Thus, our assumption that \(\) is sub-Gaussian is mild. Assumption 3.6 below ensures that the functional and score are smooth enough by bounding their gradients.

**Assumption 3.6**.: There exist universal constants \(C_{2},C_{3}<\) such that \(\|_{}()\|_{F}<C_{2}\) and \(\|_{}(x^{*})}{D}\|_{2}<C_{3}\) for any \(x^{*}^{D}\), for any \(p\) and \(D\).

Unlike our Monte Carlo approximation to the Fisher information matrix, we do not assume a particular type of estimator for \(_{}()\). To prove convergence of MC-EIF to the true EIF, we assume that \(_{}_{M}()\) converges to \(_{}()\) at the following rate:

**Assumption 3.7**.: Let \(_{M}_{}()-_{}_{M}() ^{L p}\) denote the approximation error. There exists a universal constant \(C_{}<\) such that for \(M>C_{}\) for any \(>0\),

\[(\|_{M}\|_{F}>})< (),\ \ (\|_{}_{M}()\|_{F}>C_{2})<(),\]

In Appendix A.1, we prove that Monte Carlo estimators of \(_{}()\) with gradient clipping  satisfy Assumption 3.7. Hence, Assumption 3.7 is a mild condition. Under these three assumptions, and the ones in Theorem 3.4, we prove the following result in Appendix A.1, which states that \(M\) must scale linearly with \(p p\) to guarantee close pointwise approximation.

**Theorem 3.8**.: _Suppose Assumption 3.1, Assumption 3.2, Assumption 3.3, Assumption 3.5, Assumption 3.6, and Assumption 3.7 hold. Then, there exists universal constants \(0<C_{4}\) and \(C_{5}<\), such that for any \(>0\) and \(M>(C_{5}(p+)C_{1}^{2},C_{})\),_

\[|_{}(x^{*})-_{,M}(x^{*})| C_{4}_{}(^{1})}, \]

_for \(x^{*}^{D}\) with probability at least \(1-2(-)\), where \(()\) and \(_{}()\) denotes the largest eigenvalue of a matrix._

## 4 MC-EIF for Automated Efficient Inference

In Theorem 3.8, we proved that MC-EIF is close to the true efficient influence function pointwise. In this Section we; (i) show how MC-EIF can be used to automate the construction of popular efficient estimators, and (ii) prove how many Monte Carlo samples are needed to ensure that key statistical properties hold when MC-EIF is used instead of the true EIF. In doing so, MC-EIF brings conceptual clarity to the practice of constructing efficient estimators, and how these estimators can be implemented using existing differentiable probabilistic programming languages like Pyro .

All three of the efficient estimator templates we explore in this Section involve some combination of plug-in estimation and EIF-based computations. A key practical benefit of our work is that MC-EIF-based efficient estimators are entirely modular; advances in general-purpose probabilistic inference technology directly translate to advances in efficient estimation under our framework.

### Von Mises One Step Estimator

We start with the simple _Von Mises One Step Estimator_, which corrects the plug-in estimator in Section 2 by adding the average value of the efficient influence function on a held out dataset. Despite its simplicity, this estimator achieves optimal statistical rates . Our one step estimator using MC-EIF (\(_{,M}(x)\)) instead of the true efficient influence function (\(_{}(x)\)) is provided in Algorithm 1.

**Input:** Target functional \(\), initial estimate of parameters \(\), held out datapoints \(\{x_{n}\}_{n=N/2+1}^{N}\), Number of Monte Carlo samples \(M\)

\(_{}()\) {plug-in estimate} {MC-EIF one step correction}

**Return:**\(_{}+C\)

**Algorithm 1** MC-EIF one step estimator

**Theoretical Guarantees.** We call the one step estimator that uses the true EIF instead of MC-EIF in Algorithm 1 the _analytic one step estimator_. Below we prove how many MC samples are needed to ensure our estimator for finite \(M\) has the same statistical properties as the analytic one step estimator.

**Proposition 4.1**.: _Let \(_{*}\) denote the output of the analytic one step estimator and \(\) the output of Algorithm 1 for \(M=\) and \(M<\), respectively. If \(M=(Np p)\), \(p>O( N)\) and the assumptions in Theorem 3.8 hold, then \(\|_{*}-\|_{2}=o_{p}(1/)\)._

By Proposition 4.1, MC-EIF is asymptotically efficient when the number of Monte Carlo samples in Algorithm 1 grows faster than \(Np p\).

### Debiased/Double ML

Next, we express debiased/double ML (DML) [CCD\({}^{+}\)18] in terms of MC-EIF. To rewrite DML explicitly in terms of MC-EIF, we largely follow [CCD\({}^{+}\)18, IN22].

```
Input: Vector of estimating equations \(g\), initial estimate of parameters \(\), held out datapoints \(\{x_{n}\}_{n=N/2+1}^{N}\), Number of Monte Carlo samples \(M\) \(f()_{n=N/2+1}^{N}g(x_{n},(p_{}), )+_{,M}(x_{n},)\) {MC-EIF orthogonal moment function} Return:\(\{:f()=0\}\)
```

**Algorithm 2** MC-EIF debiased ML

**Construction of Orthogonal Generalized Method of Moment (GMM) Estimators.** GMM-based estimators are defined by a nuisance functional \(()^{J}\), \(J\), and a set of \(K\) functions \(\{g_{k}(x,(_{}),)\}_{k=1}^{K}\), often called _estimating equations_. These estimating equations are selected so that their roots uniquely identify \(^{*}\) when the nuisance parameters \((_{})\) are estimated correctly:

\[_{x_{^{*}}(x)}[g(x,(_{^{*}}), )]=0=^{*}, \]

where \(g(g_{1},,g_{K})\). As an example, \(g\) might be the gradient of the log-likelihood function. To make GMM-based estimators less sensitive to incorrect estimation of the nuisance parameters, [CCD\({}^{+}\)18, IN22, CNS22] replace \(g()\) with the _orthogonal moment function_, constructed using influence functions. In our setting3, the orthogonal moment function equals the following:

\[g(x,(_{}),)+_{}(x,), \]

where \(_{}(x,)\) is the efficient influence function associated with the functional \(_{}()=_{x_{}}[g(x,(_{ }),)]\) for fixed \(\) by Equation 2.6 in [IN22]. By Theorem 3.4,

\[_{}(x,)[_{}_{}()]^{T}I() ^{1}_{}_{}(x). \]

Since \(g\) is a known by assumption, we can readily use the Monte Carlo methods in [KW14, SHWA15] to automatically approximate \(_{}_{}()\). We summarize the DML algorithm in Algorithm 2 which replaces Equation 8 with our MC-EIF approximation.

**Theoretical Guarantees.** For general estimating equations, it is difficult to quantity how errors in our MC-EIF approximation to Equation 8 lead to changes in final estimates. When the estimating equations have more structure, however, we obtain a similar result as in Proposition 4.1.

**Assumption 4.2**.: \(g(x_{n},(_{}),)=m(x_{n},(_{}))-\) for some vector of known functions \(m()\).

Assumption 4.2 was made in several works  already. We prove an analogous rate guarantee as in Proposition 4.1 under Assumption 4.2.

**Proposition 4.3**.: _Let \(_{*}\) denote the output of the analytic DML estimator and \(\) the output of Algorithm 2 for \(M=\) and \(M<\), respectively. If \(M=(Np p)\), \(p>O( N)\) and the assumptions in Theorem 3.8and Assumption 4.2 hold, then \(\|_{*}-\|_{2}=o_{p}(1/)\)._

### Targeted Minimum Loss Estimation

We conclude by writing targeted minimum loss estimation (TMLE)  explicitly in terms of MC-EIF. Unlike the one step estimator or DML, TMLE directly corrects the estimated distribution \(p_{}(x)\) and then plugs in the corrected distribution into the functional \(\) as the final estimate. To perform this correction it perturbs \(p_{}\) in the direction of the influence function, searching for the optimal step size by maximizing the perturbed likelihood on the held out dataset. Intuitively, TMLE can be viewed as a form of gradient ascent in function space. We show one step TMLE  in Algorithm 3. The multi-step TMLE version is computed by iterating Algorithm 3 multiple times until \(\) approximately equals 0 .

```
Input: Target functional \(\), initial estimate of parameters \(\), held out datapoints \(\{x_{n}\}_{n=N/2+1}^{N}\), Number of Monte Carlo samples \(M\) \(p(,x)(1+^{T}_{,M}(x))p_{}(x)\) {MC-EIF projected \(\)-perturbed density function} \(_{^{L}:p(,x) }_{n=N/2+1}^{N} p(,x_{n})\) {Maximum likelihood search over \(\)} Return:\((p(,))\)
```

**Algorithm 3** MC-EIF one step TMLE

## 5 Experiments

We start by comparing the quality of MC-EIF against other methods for influence function approximation. Then, we show how MC-EIF behaves when; (i) the number of Monte Carlo samples is varied, (ii) the dimensionality of the input is varied, and (iii) the efficient estimator type is varied. Our empirical results ultimately validate our theoretical results in Section 3 and Section 4. Finally, we show how MC-EIF can be used to automate the construction of efficient estimators for new functionals by revisiting a classic problem in optimal portfolio theory. Our MC-EIF implementation is publicly available in the Python package ChiRho. All results shown here are end-to-end reproducible.

In , the authors target the nonparametric influence function, which is the unique influence function when \(=L^{2}()\) in Definition 2.1. By contrast, we target the efficient influence function. Thus, for evaluation, we compare how well the empirical Gateaux method from  approximates the nonparametric influence function and how well our MC-EIF method approximates the efficient influence function on the same data-generating process.

To have a ground truth for comparison, we select a simple model and functional where we can analytically compute the nonparametric and efficient influence functions. To this end, we consider the problem of estimating the expected density, \(()=(x)^{2}dx\) as in . We further suppose that \(x N(,)\). We consider two parametric model families: one where \(\) is unknown but \(=1\), and one where both \(\) and \(\) are unknown, which we call \(_{1}\) and \(_{2}\) respectively. As the nonparametric influence function makes no assumptions on the underlying model family, it remains fixed across \(_{1}\) and \(_{2}\) and always equals \(2((X)-())\) . However, the EIF equals zero for \(_{1}\), as the expected density does not depend on \(\). Hence, any plug-in estimate for models in \(_{1}\) will result in a correct value of the expected density, and thus no distributional perturbations produce any change. In \(_{2}\), the efficient influence function for the expected density depends on the unknown \(\). See Figure 7 in the Appendix for further intuition around the expected density influence functions in parametric (in unknown \(\)) and non-parametric settings.

Figure 1 summarizes how well the empirical Gateaux derivative method approximates the nonparametric influence function and how well our MC-EIF method approximates the EIF at the point\(_{}=N(0,1)\). We see that MC-EIF is able to approximate the efficient influence function very well (\(M=10^{4}\) samples). By contrast, the empirical Gateaux derivative is highly sensitive to the choice of two kernel smoothing hyperparameters, \(\) and \(\). As the true influence function is not known, it is not always clear how to select \(\) and \(\).4 Such numerical instability was already discussed in , where the precision necessary must get exponentially smaller with input dimension, making it infeasible when \(D 10.5\) MC-EIF, however, has only a single tunable parameter (\(M\)), where larger \(M\) unambiguously provides a better approximation. In Theorem 3.8, we provided conditions for this improvement, and Figure 9 of the Appendix corroborates the unsurprising improvement empirically. We further discuss challenges in automating the empirical Gateaux method in Appendix C. We attempted to use the empirical Gateaux derivative as a baseline for other experiments, but were unable to achieve numerically stable solutions for any \(p>2\) without prohibitively long run-times.

Next, we focus on a classic model consisting of a binary treatment, high-dimensional continuous confounders, and Gaussian distributed response; see Appendix E for the precise model formula. We assume that the analyst is interested in estimating the average treatment effect (ATE), where the true ATE is zero but unknown. All influence function computations are relative to an initial point estimate \(\), found through maximum a posteriori estimation using 500 training datapoints. Due to the exponential runtime in dimension for the methods in , we focus on comparing MC-EIF with the analytic influence function for ATE below.

**Sensitivity to Dimensionality.** Theorem 3.8 implies that for a fixed number of Monte Carlo samples \(M\), the quality of the approximation degrades with the square root of model dimension \(p\). In Figure 2, we empirically show how approximation quality degrades as \(p\) increases for \(M=10^{4}\) fixed. Based on Figure 2, the empirical results closely match the theoretical behavior predicted by Theorem 3.8.6 We also show how the computational complexity of MC-EIF scales as \(p\) increases in Figure 2.

**Sensitivity to Estimator Type.** Here, we consider a high-dimensional setup where there are 200 confounders but only 500 training datapoints. We simulate 100 different datasets with this configuration to approximate the sampling distribution of different efficient estimators. In Figure 3, we see that across estimators, using MC-EIF instead of the true EIF results in minimal downstream error. This is consistent with our theoretical results in Section 4. While MC-EIF is agnostic to the choice of efficient estimator, one may prefer some over others depending on the problem. See Figures 5 and 6 of the Appendix for an example performance comparison between efficient estimators of the ATE.

**Ability to Handle New Functionals.** To illustrate MC-EIF's flexibility, we revisit a classic problem in optimal portfolio theory. Suppose that \(x^{D}\) is a vector of asset returns. We are interested in estimating the optimal portfolio weights \(^{*}^{D}\) that maximize the expected return while minimizing the variance of the portfolio. Then, the Markowitz optimal portfolio  is given by:

\[_{}(_{})=_{^{D}}^{T }_{_{}}[x]-^{T}(x;_{ }),_{i=1}^{D}_{i}=1, \]

where \(\) is the tradeoff between expected return and variance (measure of risk), and \((x;_{})\) denotes the covariance matrix with respect to \(_{}\). Hence, the optimal weights functional \(_{}(_{})\) depends on a high-dimensional nuisance, namely the \(D D\) covariance matrix of returns. The target \(^{*}_{,}=_{}(_{})\) is a much lower \(D\)-dimensional target parameter. Setting \(=\) corresponds to the _global minimum variance portfolio_, for which there is (to our knowledge) no efficient estimator in the literature. We show results in Table 1 indicating substantial improvement in a synthetic data experiment; a detailed description of this experiment may be found in Appendix E.2.

## 6 Limitations

As discussed in Assumptions 3.1 and 3.2, both the likelihood and the target functional must be differentiable with respect to \(\). In practice, especially if the model involves latent discrete random variables, some degree of relaxation, marginalization, or reparameterization may be required to ensure differentiability . Recall also that while MC-EIF operates on models with finite parametrizations (Section 3), its capacity to handle high-dimensional nuisance parameters means it can likely apply to, for example, function approximators that recover some of the value proposition offered by non-parametric model components . Additionally, as discussed in Appendix D, infinite-dimensional models (like the Gaussian process) can often be reduced to finite ones where MC-EIF can be applied. That said, future work is needed to fully explore the practical and empirical capabilities of MC-EIF in these settings, including how the polynomial complexity of Fisher information matrix inversions plays out in practice.

## 7 Conclusion

We have shown both theoretically and empirically that MC-EIF can reliably be used to automate efficient estimation. Our key contributions include MC-EIF's consistency and capability to achieve optimal convergence rates. Empirical evidence shows that MC-EIF performs comparably to traditional estimators using analytic EIFs. Additionally, we illustrate the practical application of MC-EIF in scenarios where the analytic EIF is not known. Given these contributions, there are many exciting areas of future work. For example, one may with to construct more powerful provably efficient estimators on top of MC-EIF (see Appendix D) and explore the growing connection between semi-parametric theory and heuristic methods in deep learning . Additionally, there are many methods that could be used to accelerate the calculation of the Fisher information matrix, which is a computational bottleneck in MC-EIF. Given its foundational role in statistics, various techniques--such as using Kronecker-factored approximations --could improve efficiency without sacrificing performance.

 Metric & One Step MC-EIF & Plug-in \\   REV & \(\) & \(2.60.35\) \\ RMSE & \(\) & \(.14.02\) \\  

Table 1: **Empirical results for Markowitz optimal portfolio optimization.** Using MC-EIF, Algorithm 1 achieves lower relative expected volatility (REV) and RMSE compared to the oracle estimator.

Figure 3: **Comparison between ATE estimators using MC-EIF and analytic EIF.** MC-EIF produces ATE estimates very close to the diagonal, representing an oracle estimator of the EIF.