# CODA: A Correlation-Oriented Disentanglement and Augmentation Modeling Scheme for Better Resisting Subpopulation Shifts

CODA: A Correlation-Oriented Disentanglement and Augmentation Modeling Scheme for Better Resisting Subpopulation Shifts

 Ziquan OU

Department of Data Science

City University of Hong Kong

ziquanou2-c@my.cityu.edu.hk

&Zijun ZHANG

Department of Data Science

City University of Hong Kong

zijzhang@cityu.edu.hk

Correspondence Author

###### Abstract

Data-driven models learned often struggle to generalize due to widespread subpopulation shifts, especially the presence of both spurious correlations and group imbalance (SC-GI). To learn models more powerful for defending against SC-GI, we propose a **Correlation-Oriented Disentanglement and Augmentation (CODA)** modeling scheme, which includes two unique developments: (1) correlation-oriented disentanglement and (2) strategic sample augmentation with reweighted consistency (RWC) loss. In (1), a bi-branch encoding process is developed to enable the disentangling of variant and invariant correlations by coordinating with a decoy classifier and the decoder reconstruction. In (2), a strategic sample augmentation based on disentangled latent features with RWC loss is designed to reinforce the training of a more generalizable model. The effectiveness of CODA is verified by benchmarking against a set of SOTA models in terms of worst-group accuracy and maximum group accuracy gap based on two famous datasets, ColoredMNIST and CelebA.

## 1 Introduction

One grand challenge that impedes the generalization of machine learning models is 'Subpopulation shifts', the alterations in the relative proportions of subpopulations between training and testing datasets . In reality, one frequently encountered scenario is that specific groups in data are underrepresented, which we tag as the _group imbalance (GI)_, contributed by class imbalance (CI), attribute imbalance (AI), or their combination . Due to GI, models trained to minimize average loss tend to favor the majority groups and thus fail to generalize across minority groups .

Another widely discussed issue in subpopulation shifts is the _spurious correlations (SC)_, the incidental correlations between non-causal features and labels during training time that do not hold in the real world. SC can significantly compromise the efficacy of a model  and has been observed in various applications, such as speech recognition , medical imaging , object recognition , image captioning , etc. For instance, object recognition models that classify animal species have been shown to generalize poorly to new environments since their classifications mistakenly favor image backgrounds over biological characteristics of animals . Learning such correlations can result in degraded performance on data breaking these spurious patterns, e.g., when animals are moved indoors or to an uncommon context, such as cows on a beach instead of in a pasture.

Prior research has extensively explored the developments of robust models performing uniformly well across subpopulations. Reported studies have varied from attempts of developing models without pre-identified spurious attributes [21; 23; 26; 20] to methods leveraging knowledge of these spurious attributes to inform and guide training processes [25; 13; 30; 14; 15]. A critical observation in  unveiled that methods trained without utilizing spurious attributes still rely on them in the model selection; otherwise, a significant performance drop would be observed. The potential of better utilizing spurious attributes to further strengthen models in defending subpopulation shifts has yet to be fully explored, especially in terms of more innovations in utilizing spurious attributes model selection, addressing SC by mixing, or tackling GI via reweighting. Meanwhile, it is also of great interest to explore the utilization of spurious attributes as a means to enhance model performance rather than as impediments to be overcome.

This paper thus aims to develop a novel method of learning models for better defending the SC-GI type of subpopulation shifts from the aspect of innovating the mechanism of dealing with spurious attributes. Considering the object recognition task with backgrounds, addressing SC can be translated to a more straightforward question - Can we design a model capable of reliably recognizing the same object across a range of spurious attributes, such as diverse backgrounds? To answer this question implies that the developed model needs to focus on the invariant and causal features pertinent to object identification, as conceptually illustrated in Figures 1a\(\)1c. Conducting such a study leads to two further pivotal technical questions:

_Q1: How to synthesize samples that vary in spurious attributes yet retain accurate class information?_

Figure 1: (a) \(\) (c): Same bird embedded in different backgrounds. A robust model is expected to predict consistently well on objects in all images. (d) \(\) (f): The feature extraction and exchange process of COD. Z represents spurious correlations, and T represents causal correlations.

Figure 2: Overview of the CODA Framework on ColoredMNIST dataset. In ColoredMNIST, samples with digit less than 5 are negative samples (\(Y=0\)), and the rest are positive samples (\(Y=1\)). Each sample is either painted red (\(A=1\)) or green (\(A=0\)), with color spuriously correlated with the label in training set. In stage one, CODA first learns to encode and disentangle causal correlations from spurious ones. The decoder reconstructs the input data from the two encodings, while the decoy classifier is employed to lure the spurious information flowing towards the variance encoder. In stage two, CODA further enhances robustness by creating synthesized samples through the recombination of encoded features from different inputs, ensuring that the resultant samples maintain original class information but vary in spurious attributes. Finally, a robust classifier is trained with a novel reweighted consistency loss to deliver consistent performance across both original and synthetic samples, thereby reinforcing its resilience to spurious correlations.

* _Based on the synthesized samples, how to design a learning mechanism for developing models more powerful for addressing the SC-GI subpopulation shifts?_

To make a response, a novel framework, the **Correlation Oriented Disentanglement and Augmentation (CODA)**, is developed in this work to develop machine learning models better handling the SC-GI subpopulation shifts by disentangling variant and invariant features, coordinated with a strategic sample augmentation process. The overview of the CODA framework is shown in Figure 2. Two unique developments in CODA are briefed as follows:

Correlation-Oriented Disentanglement (COD)To facilitate the disentangling between class information and spurious information, a novel bi-branch encoding process called Correlation-Oriented Disentanglement (COD) is developed in this paper. As shown in Figures 1d\(\)1f, COD operates through a 'trap and disentangle' mechanism. The variance encoder, coordinated with a decoy classifier that predicts the spurious attribute and a novel design of disentangling loss, extracts only the necessary information about the spurious attributes. The decoder and a reconstruction loss then simultaneously regularize the invariance encoder to capture distinct and complementary information (including invariant features and label-irrelevant features). These bi-branch encoders, coupled with the learned decoder, facilitate the generation of a rich and diverse synthetic dataset.

Strategic Sample Augmentation with Reweighted Consistency LossBuilding on insights from recent studies [29; 13], which highlight the effectiveness of upweighting sampling probabilities or losses for minority groups, we extend this concept by strategically generating additional synthetic samples for these groups. By integrating variant and invariant features extracted from different samples, the decoder can generate realistic synthetic data that exhibit different spurious information while preserving class fidelity, aligning with the insight shown in Figures 1a\(\)1c. To complement this, we introduce a novel weighted consistency loss designed to prompt the classifier to deliver uniform predictions across both the original and synthetic samples. Our experimental results affirm that CODA harmonizes effectively with pre-existing robust classification methodologies by integrating the proposed weighted consistency objective.

To the best of our knowledge, the work most akin to ours from the conceptual aspect is CAMEL , which applies CycleGAN for learning image transformations. CODA clearly differs from CAMEL in the following aspects: (1) CycleGAN is deterministic and yields a single fixed output for a given input sample, while CODA introduces substantially more flexibility in synthetic data by mixing variant features from multiple samples. (2) CycleGAN is limited to one-to-one transformations, necessitating \(\) models to cover all potential mappings for \(n\) attribute values within one spurious attribute. In contrast, CODA can simultaneously learn multiple transformations and can be readily extended to accommodate multiple spurious attributes by incorporating additional decoy classifiers. (3) GANs are notoriously challenging to train with instability issues. In contrast, CODA offers a more stable and expedient training process.

The primary contributions of this paper are as follows: (1) The potential of better utilizing spurious attributes, rather than treating them as impediments to be overcome, is explored. A novel correlation-oriented disentanglement and augmentation framework for handling the SC-GI type of subpopulation shifts is thus developed. (2) A bi-branch encoder network architecture coordinated with a decoy classifier and subsequent decoder is designed to realize disentangled representation learning for handling SC. (3) A strategic sample augmentation with a novel weighted consistency loss proposed for upweighting samples predicted with low confidence is developed to better handle the SC-GI. The proposed CODA framework can operate synergistically with existing robust classification methods. (4) Extensive experiments conducted confirm that CODA can drive the learning to focus on causal rather than spurious features and uplift the performance on defending extreme SC-GI subpopulation shifts.

## 2 Preliminaries

### Formulation of learning models defending subpopulation shifts

Consider classification tasks in which we aim to predict a label \(y\) based on an input \(x\). Each instance in the dataset is also characterized by an attribute \(a\), which may influence the prediction. We define a group by a tuple \(g=(y,a)\), where each group has its own distribution \(P_{g}\)Then the training and testing data distributions can be expressed as mixtures of these subpopulation distributions: \(P_{}=_{i=1}^{||}_{i}P_{i}\) and \(P_{}=_{i=1}^{||}_{i}P_{i}\), where \(,_{||}\) represent the mixture weights. Subpopulation shifts occur when the mixture weights for training and testing differ, i.e., \(\). If the mixture weights of specific groups dominate, group imbalance occurs, potentially leading to a spurious correlation between the attribute and the label.

Given a loss function \(\), our objective is to identify a function \(f:\) that minimizes the worst-case expected loss over all possible mixtures , formally defined as:

\[f^{*}=*{argmin}_{f}_{_{||}}_{(x,y)_{i=1}^{||}_{i}P_{i}}[(y,f(x))].\] (1)

### Benchmarks for defending subpopulation shifts

Empirical Risk Minimization (ERM)Consider a training dataset \(D=\{(x_{i},y_{i},a_{i})\}_{i=1}^{N}\) comprising \(N\) samples. Let \(_{}\) denote the empirical training distribution. Then common machine learning practice applying ERM aims to find a function \(f\) that minimizes the average empirical loss:

\[f^{*}_{}=*{argmin}_{f}_{(x,y)_{ }}[(y,f(x))].\] (2)

However, ERM typically fails in scenarios with subpopulation shifts due to group imbalance and learning spurious correlations that do not hold in testing data.

Reweighting Groups (RWG)Given the highly imbalanced nature of subpopulation shifts, Idrissi et al.  studied the efficacy of data balancing techniques, especially RWG. RWG adopts a group-balanced sampling strategy to upweight minority groups, as shown in Eq. (3):

\[p_{g}=| N_{g}},\] (3)

where \(N_{g}\) is the number of training samples in group \(g\), and \(p_{g}\) represents the probability of sampling an instance from group \(g\). Despite its simplicity, RWG achieves competitive performance and serves as a strong baseline in studying subpopulation shifts.

Group Distributionally Robust Optimization (GDRO)The study  showed that optimizing Eq. (1) is equivalent to minimizing the maximum expected loss over all groups. The empirical optimization objective in GDRO is expressed as:

\[f^{*}_{}=*{argmin}_{f}_{g}_{(x,y)_{g}}[(y,f(x))].\] (4)

### Disentangled representation learning

Disentangled representation learning targets extracting data representations that separate the distinct sources of variation and serves as the base of the COD development in this work. This section explores relevant models that have generated significant impacts on such a topic.

Variational Autoencoder (VAE) and its variantKingma and Welling  postulated that the data generative process is governed by an unobserved vector of latent codes \(z\) with prior distribution \(p(z)\). The Vanilla Variational Autoencoder (VAE) is introduced to approximate the intractable true posterior with a variational posterior \(q_{}(z|x)\) and to learn a decoder \(p_{}(x|z)\), with parameters \(\) and \(\) respectively. VAE's objective is to maximize:

\[_{}(,)=_{p_{}(x)}[ _{q_{}(z|x)}[(p_{}(x|z)]-(q_{}(z|x)\|p(z))]\] (5)

\(\)-VAE  incorporated a hyperparameter \(\) to the KL term in Eq. (5) to control the trade-off between the reconstruction quality and the independence intensity between latent variables. When \(>1\), the model prioritizes learning independent latent factors.

The study  showed that the KL term in Eq. (5) can be decomposed into two components:

\[_{p_{}(x)}[(q_{}(z|x)\|p(z))]=I(x;z)+ {KL}(q_{}(z)||p(z)),\] (6)in which \(q_{}(z)=_{p_{}(x)}[q_{}(z|x)]\), and \(I(x;z)\) represents the mutual information between \(x\) and \(z\) under the distribution of \(p_{}(x)q(z|x)\). A higher value of \(\) enforces a closer approximation of the latent codes to the factorized prior \(p(z)\), leading to more independent latent codes. However, this also imposes a stronger penalty on the mutual information \(I(x;z)\), which may reduce the amount of information about \(x\) retained in \(z\) and potentially worsen the reconstruction quality.

Flexibly Fair VAE (FFVAE)FFVAE  aimed to learn feature representations \(t\) that achieve subgroup fairness and \(z\) targeted for sensitive attributes, with the following objective:

\[_{}(,,) =_{p_{}(x)}[_{q_{}(z,t|x)}[  p_{}(x|z,t)+ p_{}(a|z)]\] \[-(q_{}(z,t|x)\|p(z,t))]-(q(z,t) \|q(t)_{j}q(z_{j})),\] (7)

in which \(p_{}(a|z)\) models the prediction of sensitive attributes. The \(\)-weighted KL divergence term encourages the latent variables \(z_{j}\) to be independent of both \(t\) and \(z_{i}\) for all \(i j\).

Due to the intractability of the second KL term in Eq. (7), FFVAE employs adversarial density ratio estimation . If an estimator cannot differentiate whether a sample pair \((z,t)\) comes from \(q(z,t)\) or the factorized distribution \(q(t)_{j}q(z_{j})\), the second KL term is minimized, suggesting the independence of \(z\) and \(t\). However, this approach inevitably introduces a new density estimator component, along with a GAN training objective, which can be challenging and unstable to train.

## 3 Correlation-Oriented Disentanglement and Augmentation (CODA)

This section explains the novel mechanism of CODA on utilizing spurious attributes for defending the SC-GI subpopulation shifts, which is composed of two parts, disentangling variant and invariant features as well as a strategic sample augmentation with a reweighted consistency loss based on the disentangled features.

### Correlation-Oriented Disentanglement (COD)

Given a sample \((x,y,a,g)\), we aim to learn encodings \(z^{K_{1}}\) and \(t^{K_{2}}\), defined by stochastic parametric encoders \(q_{}(z|x)=(z|_{z}(x),_{z}^{2}(x))\) and \(q_{}(t|x)=(t|_{t}(x),_{t}^{2}(x))\) respectively. Factorial priors \(p(z)\) for \(z\) and \(p(t)\) for \(t\) are assumed. Our model includes a decoder, denoted by \(p_{}(x|z,t)\), and a decoy classifier \(p_{}(a|z)\), which predicts the spurious attribute \(a\).

In this paper, we propose the following training objective for disentangled representation learning:

\[_{}(,,,) =_{p_{}(x)}[_{q_{}(z|x)q_{ }(t|x)}[ p_{}(x|z,t)+ p_{}(a|z)]\] \[-(q_{}(z|x)\|p(z))-(q_{}(t| x)\|p(t))].\] (8)

By applying Eq. (6), Eq. (8) can be re-written as:

\[_{}(,,,) =_{p_{}(x)}[_{q_{}(z|x)q_{ }(t|x)}[(x|z,t)}_{}+ (a|z)}_{}]\] \[-[_{}]-[(q_{}(z)||p(z))+(q_{}(t)||p(t))}_{ }].\] (9)

To clarify, Eq. (8) is the practical training objective for implementation, while the equivalent Eq. (9) offers justification for motivation of the proposed COD. The objective function in Eq. (9) consists of four components: (1) a reconstruction loss to ensure \(z\) and \(t\) collectively encode the information in \(x\), (2) a classification loss that encourages \(z\) to predict spurious attributes accurately, (3) mutual information terms that limit the extent to which encoders capture relevant information from \(x\), and (4) KL divergence terms that penalize the encoders if they diverge from the factorial priors.

The working mechanism of the four components in Eq. (9) is described as follows: The classification loss term rewards \(z\) to be maximally predictive of the spurious attribute. By assigning heavy weight (\(>1\)) on minimizing \(I(x;z)\), we limit the expressive power of \(z\), ensuring it encodes only the necessary information about the spurious attributes. In contrast, we place a relatively low limit on minimizing \(I(x;t)\), thus ensuring that the reconstruction quality of the decoder is not degraded. Whilethe reconstruction loss term ensures that \(z\) and \(t\) collectively capture all the information contained in \(x\), \(t\) is expected to carry distinct and complementary information. Furthermore, the two KL terms regularize the variational marginals to match the factorial priors, thus facilitating disentangling within each feature representation. A preliminary theoretical exploration of the performance guarantee of the decoder training has been conducted with a mathematical proof, which is offered in Appendix A.

We emphasize that our goal is to separate spurious and variant correlations from those that are causal and invariant, rather than to seek disentanglement within each individual representation, i.e., imposing each \(t_{i}\) to be independent of \(t_{j}\) (for all \(j i\)). Consequently, a lower weight on the final KL divergence term is both justified and sufficient, as it supports our objective without imposing unnecessary constraints on the independence within the invariant feature space. Our proposed method circumvents the need for density estimation, thus avoiding the complexities and instabilities associated with training objectives based on the GAN-like density estimator.

### Strategic sample augmentation with reweighted consistency loss

Strategic sample augmentationThrough the disentanglement of variant and invariant features, as outlined in the previous section, we can now strategically generate synthetic samples for augmentation by leveraging the trained decoder. For a given batch of \(B\) samples \(\{(x_{i},y_{i},a_{i},g_{i})\}_{i=1}^{B}\), we begin by extracting feature representation pairs \(\{(z_{i},t_{i})\}_{i=1}^{B}\), where \(z_{i}=q_{}(z|x_{i})\) and \(t_{i}=q_{}(t|x_{i})\). With hyperparameters \(L\), which controls the number of synthetic samples per batch instance, we randomly select \(L\) indices from \(\{1,...,B\}\) for each instance, yielding mixing set \(\{\{h_{i,j}\}_{j=1}^{L}\}_{i=1}^{B}\). By combining features from different instances, we create the set of synthetic samples \(\{\{_{i,j}\}_{j=1}^{L}\}_{i=1}^{B}\), where \(_{i,j}=p_{}(x|z_{h_{i,j}},t_{i})\). These samples exhibit varied spurious information but retain their original class information. A model trained to perform well across augmented samples is likely to learn robust decision-making rules that do not depend on spurious correlations.

Reweighted consistency lossA natural intuition to prevent the final model \(f_{}\) from utilizing spurious correlations is to enforce the model to deliver consistent predictions on the original samples \(x_{i}\) and the set of synthesized samples \(_{i}=\{_{i,j}\}_{j=1}^{L}\). To realize, we propose the following reweighted consistency loss:

\[_{}(x_{i},_{i},y_{i})=[_{i=1}^{ L}(1-f_{}(_{i,j})_{y_{i}})^{}(f_{}(_{i,j}) \|_{i})+(f_{}(x_{i})\|_{i})],\] (10)

in which \(f_{}(_{i,j})_{y_{i}}\) is the predicted probability of the true class for \(_{i,j}\), and \(_{i}=Normalize(_{j=1}^{L}f_{}(_{i,j})_{y_{i }}^{}f_{}(_{i,j}))\) is the weighted mean prediction for the synthesized samples, normalized to ensure that the probabilities sum to one.

In Eq. (10), we downweight the synthesized samples with low confidence in predicting the right class to mitigate its effect in jeopardizing \(_{i}\). Conversely, we upweight their KL losses to penalize inconsistencies with other samples that have greater confidence in the ground-truth class.

At last, given loss function \(\), we formulate our final optimization objective as follows:

\[_{CODA}(x_{i},_{i},y_{i})=(y_{i},f_{}(x_{i}))+ _{}(x_{i},_{i},y_{i}).\] (11)

Pseudo codes of training and deployment of the proposed CODA are offered in Appendix B.

## 4 Experiments

In this section, we evaluate the efficacy of the proposed CODA methodology. Specifically, we aim to answer two questions: (1) Can CODA learn disentangled encodings that extract spurious and causal correlations, respectively? (Section 4.2); (2) Does CODA enhance robustness in addressing SC-GI subpopulation shifts, and what are the critical factors contributing to its effectiveness? (Section 4.3)

### Setup

Dataset descriptionExperiments are conducted on the ColoredMNIST and CelebA datasets . Here we provide a brief introduction, with comprehensive details available in Table 1 and Appendix C * **ColoredMNIST**: This variant of the MNIST dataset  incorporates color (red or green) into the original grayscale digits. Digits below five are labeled negative, while the rest are positive. Within the training set, 85% of the negative/positive samples are painted green/red, introducing color as a spurious correlation. Conversely, in the testing set, this ratio is reduced to 15%. Following , labels are flipped with a probability of 0.25.
* **CelebA**: The CelebA dataset consists of a large collection of celebrity face images coupled with 40 binary attributes. The task is to predict hair color (blond or non-blond), which exhibits a strong spurious correlation with the gender attribute (male or female).

Evaluation protocolIn alignment with , we evaluate robustness of all methods using worst-group accuracy, the lowest test accuracy across all groups, as gold-standard. In addition, we also report the average accuracy and the maximum group accuracy gap. Model selection is based on the highest worst-group accuracy obtained during validation.

Hyperparameters tuningFor COD, we employ Adam optimizer  and adopt pre-trained ResNet-18 and ResNet-50 encoders for ColoredMNIST and CelebA, respectively. For learning the robust classifier, we train all approaches on both datasets using SGD optimizer  with momentum 0.9, and adopt a 3-layer CNN and a pre-trained ResNet-50 for ColoredMNIST and CelebA on all approaches, respectively. Additional training details are available in Appendix D.

### Disentangling and synthesis abilities of CODA

CODA can generate samples varying in spurious attributes yet retaining accurate class information.Generated samples visualized in Figure 3 well justify the superior disentangling and synthesis capabilities of CODA. It is clear that the generated samples in Figure 3 are visually appealing. It is

    & & Group 1 & Group 2 & Group 3 & Group 4 & \(SC\) & \(GI\) & \(DGPS\) \\   & Training & 21330 (42.66\%) & 3776 (7.55\%) & 3724 (7.45\%) & 21370 (42.74\%) & & & \\  & Validation & 2510 (25.1\%) & 2526 (25.3\%) & 2474 (24.7\%) & 2490 (24.9\%) & ✓ & ✓ & High \\  & Testing & 761 (7.61\%) & 4378 (43.8\%) & 4122 (41.2\%) & 739 (7.39\%) & & & \\   & Training & 71629 (44.01\%) & 22880 (14.06\%) & 66874 (41.08\%) & 1387 (0.85\%) & & & \\  & Validation & 8535 (42.96\%) & 2874 (14.47\%) & 8276 (41.66\%) & 182 (0.92\%) & ✓ & ✓ & Low \\   & Testing & 9767 (48.93\%) & 2480 (12.42\%) & 7535 (37.75\%) & 180 (0.90\%) & & & \\   

Table 1: Dataset statistics. \(SC\) indicates spurious correlations, \(GI\) indicates group imbalance, and \(DGPS\) indicates the degree of group proportion shifts between training and testing sets.

Figure 3: Visualization of the synthesized samples. Images from the top-row and the leftmost column are real samples, while the remaining images are reconstructions. Each reconstructed image is generated by combining \(t\) extracted from the corresponding leftmost sample and \(z\) from the corresponding top-row sample. The main diagonal images represent same sample reconstructions.

evident that the digit color/gender in the reconstructed images is consistent with the top-row samples, while the residual features--such as digit, written style, and size/background, posture, hairstyle, and hair color--are determined by the leftmost samples. This indicates that the variance encoder captures only the necessary information about the spurious attribute, while the invariance encoder encapsulates distinct and complementary information, including class-related and irrelevant details. These findings are in harmony with our training objectives outlined in Section 3.1.

CODA can separate spurious information from causal information.We further evaluate the ability of CODA to disentangle spurious and causal information through four classification tasks on ColoredMNIST. In each task, we fix the weights of the learned variance and invariance encoders and extract the corresponding latent codes (\(z\) and \(t\)) for each image. Here \(z\) and \(t\) are expected to carry color and digit information, respectively. A variance classifier and an invariance classifier, both structured as simple 3-layer MLPs, are then employed with: one using \(z\) as input and the other using \(t\) to predict the digit label (whether the digit \( 5\)) or the spurious attribute (color).

Results are presented in Table 2. We observe that the variance classifier achieved perfect performance in predicting color. In contrast, it achieved \(0\%\) worst-group accuracy and 15\(\%\) average group accuracy in predicting digit, which conformed to the color assignment ratio of 15\(\%\) in the testing set. Conversely, the invariance classifier exhibited robust label classification capabilities, even without applying any reweighting or sample augmentation technique. Its poor color classification performance, comparable to random guessing, justifies the effective disentanglement achieved by CODA.

    &  &  \\ method & Worst. Acc. & Max. Acc. Gap & Worst. Acc. & Max. Acc. Gap & Worst. Acc. & Max. Acc. Gap \\  LFF & \(58.99 1.95\) & \(12.83 4.38\) & \(54.68 7.32\) & \(15.32 10.65\) & \(49.38 4.23\) & \(21.35 9.29\) \\ JTT & \(71.09 0.73\) & \(2.59 1.83\) & \(69.81 0.79\) & \(6.9 0.63\) & \(62.07 0.52\) & \(12.82 1.84\) \\ ERM & \(9.63 2.94\) & \(87.07 3.5\) & \(0.02 0.02\) & \(99.98 0.02\) & \(0.00 0.00\) & \(100.00 0.00\) \\ RVG & \(71.33 0.45\) & \(2.71 0.46\) & \(70.93 1.22\) & \(2.8 1.33\) & \(68.18 2.59\) & \(8.08 1.23\) \\ ODRO & \(71.84 0.65\) & \(3.32 0.27\) & \(69.65 1.59\) & \(3.96 2.05\) & \(70.42 0.78\) & \(4.17 0.75\) \\  CODA+ERM \(\) & \(71.31 0.84\) & \(3.3 0.58\) & \(71.12 0.92\) & \(3.21 1.91\) & \(71.03 0.53\) & \(3.59 0.53\) \\ CODA+ERWG \(\) & \(71.72 0.95\) & \(2.58 1.51\) & \(71.91 0.21\) & \(2.42 0.32\) & \(70.60 1.22\) & \(2.42 0.93\) \\ CODA+GDRO \(\) & \(72.05 0.27\) & \(1.91 0.44\) & \(71.86 0.58\) & \(2.09 0.22\) & \(71.44 0.69\) & \(2.36 0.54\) \\   

Table 4: Performance metrics (\(\%\)) for ColoredMNIST v2, v3, and v4.

    &  &  \\ Classifier & Avg. Acc. & Worst. Acc. & Max. Acc. Gap & Avg. Acc. & Worst. Acc. & Max. Acc. Gap \\  variance classifier & \(15.00 0.00\) & \(0.00 0.00\) & \(100.00 0.00\) & \(100.00 0.00\) & \(100.00 0.00\) & \(0.00 0.00\) \\ invariance classifier & \(72.17 0.31\) & \(71.29 0.44\) & \(2.64 0.83\) & \(41.44 0.21\) & \(35.73 0.35\) & \(35.60 1.24\) \\   

Table 2: Average test accuracy (\(\%\)), worst-group test accuracy (\(\%\)), and maximum test group accuracy gap (\(\%\)) of the classifiers on the ColoredMNIST dataset. Variance and invariance classifiers take z and t as inputs, respectively. Results are averaged over three independent trials.

    &  &  \\ method & Avg. Acc. & Worst. Acc. & Max. Acc. Gap & Avg. Acc. & Worst. Acc. & Max. Acc. Gap \\  LFF  & \(67.64 5.19\) & \(50.91 2.92\) & \(24.36 7.08\) & \(89.67 0.44\) & \(73.11 1.43\) & \(20.72 2.40\) \\ JTT  & \(72.11 0.36\) & \(71.01 0.50\) & \(5.15 1.83\) & \(92.10 0.26\) & \(76.45 0.75\) & \(20.90 0.92\) \\ ERM & \(17.02 0.76\) & \(2.08 0.70\) & \(92.70 0.71\) & \(95.05 0.38\) & \(47.78 2.30\) & \(51.80 2.45\) \\ RWG  & \(72.94 0.45\) & \(71.64 0.15\) & \(2.70 1.06\) & \(92.87 0.23\) & \(83.44 1.55\) & \(10.78 1.70\) \\ GDRO  & \(73.03 0.25\) & \(71.08 1.02\) & \(3.27 1.13\) & \(93.01 0.08\) & \(88.22 0.89\) & \(4.92 1.11\) \\  CODA+ERM \(\) & \(72.20 0.57\) & \(71.74 0.24\) & \(2.45 1.02\) & \(91.89 0.35\) & \(83.65 0.32\) & \(9.87 1.08\) \\ CODA+RWG \(\) & \(73.20 0.12\) & \(72.11 0.51\) & \(2.36 0.67\) & \(91.72 0.12\) & \(86.56 0.82\) & \(7.28 1.01\) \\ CODA+GDRO \(\) & \(73.02 0.23\) & \(71.98 0.57\) & \(2.37 0.94\) & \(90.91 0.24\) & \(89.26 0.26\) & \(4.01 0.24\) \\   

Table 3: Performance metrics (\(\%\)) for ColoredMNIST and CelebA. Results are averaged over three independent trials. Red/blue/green represents the first/second/third highest performance. \(\) indicates that CODA+X shows improvements over a base method denoted by X in terms of worst-group accuracy and maximum group accuracy on both datasets, X \(\) {ERM, RWG, GDRO}.

### Benchmarking studies and analysis

CODA enhances performance and robustness over existing robust classification methods.Table 3 illustrates the comprehensive performance metrics for CODA compared with benchmarking methods. On ColoredMNIST, ERM performed worst in all metrics due to the intense subpopulation shift and the spurious correlation. While on CelebA, which has a less intense difference in group proportions, ERM achieved the highest average accuracy but failed in worst-group accuracy due to group imbalance and the spurious correlation. We observe that CODA consistently offered improved worst-group accuracy over vanilla ERM, RWG, and GDRO, and significantly curtailed the group accuracy discrepancy across both datasets. This enhancement in robust accuracy suggests that CODA can be effectively integrated with prevailing robust classification methodologies. Scalability of CODA to the multi-classification scenario is further evaluated on a dataset called MultipleColoredMNIST, which is detailed in Appendix E.1. Experimental results in Table 7 present that CODA can be scaled up to scenarios with multiple spurious attribute values, demonstrating its great potential in solving complex subpopulation shifts.

Enhanced robustness of CODA to extreme SC-GI subpopulation shifts.Additional experiments are conducted to assess the robustness of CODA against varying degrees of subpopulation shifts. Color bias is introduced with probabilities \(p\) and \(1-p\) in training and testing sets, respectively. ColoredMNIST v2, v3, and v4 are then created with \(p=0.8,0.9,\)\(0.95\), respectively. A higher value of \(p\) indicates greater differences in group proportions, increased group imbalance, and a more intense spurious correlation. Other dataset settings are consistent with ColoredMNIST. Experimental results are shown in Table 4 (complete results are presented in Appendix E.2). As the bias intensity increased, CODA maintained more consistent performance metrics compared to other methods,

Figure 4: Sensitivity analysis on the weight of the reweighted consistency loss. When \(=0\), the methods degrade to vanilla ERM, RWG, and GDRO.

   Methods & \(L\) & Avg. Acc. (std) & West Acc. (std) \\   & 0 & \(16.60 1.23\) & \(0.00 0.00\) \\  & 1 & \(96.90 0.29\) & \(88.78 0.87\) \\  & 2 & \(97.12 0.07\) & \(90.36 0.68\) \\  & 4 & \(97.06 0.11\) & \(91.85 0.68\) \\   & 0 & \(95.54 0.24\) & \(85.46 0.44\) \\  & 1 & \(96.92 0.04\) & \(90.87 0.93\) \\   & 2 & \(96.66 0.28\) & \(91.35 0.70\) \\   & 4 & \(96.94 0.08\) & \(91.10 1.16\) \\   & 0 & \(94.99 0.33\) & \(82.16 4.60\) \\  & 1 & \(96.68 0.03\) & \(89.88 0.50\) \\   & 2 & \(96.70 0.16\) & \(90.10 1.10\) \\   & 4 & \(96.85 0.05\) & \(90.42 1.39\) \\   

Table 5: Sensitivity analysis on the number of synthesized samples per instance on MultipleColoredMNIST. When \(L=0\), the methods degrade to vanilla ERM, RWG, and GDRO.

which suggested that CODA is more robust to extreme subpopulation shifts compared with baseline methods and can effectively adapt its learning to focus on causal rather than spurious features.

The critical role of the optimal coefficient selection for RWC to the success of CODA.Figure 4 presents a sensitivity analysis of the parameter \(\) from Eq. (11) on ColoredMNIST dataset. We observe that an elevated \(\) value (\( 100\)) compromises model performance due to excessive regularization. Conversely, a diminutive \(\) value fails to contribute significantly owing to insufficient regularization intensity. Thus, an optimal \(\) value is instrumental for the robust learning of the model.

Trade-off between robust classification performance and computational costs.Another critical hyperparameter in training CODA is the number of synthetic samples per instance controlled by \(L\). A larger \(L\) introduces more variability to synthesized samples, driving the model to "forget" the spurious attributes in decision-making. A sensitivity analysis of \(L\) on the MultipleColoredMNIST dataset is provided in Table 5. It is observable that increasing \(L\) generally improves the worst-group accuracy. However, a larger \(L\) also implies higher computational costs. Furthermore, excess \(L\) may not introduce more variability (depending on the complexity of the dataset), e.g., \(L\) greater than 10 in MultipleColoredMNIST can result in redundant synthesized samples. Thus, the value of \(L\) needs to be selected carefully for best handling the trade-off between classification performance and computational efficiency.

## 5 Conclusion

In this study, we introduced CODA, a novel approach designed to enhance the robustness of machine learning models against the SC-GI subpopulation shifts. Our extensive experiments based on the ColoredMNIST and CelebA datasets provided compelling evidence that CODA could successfully disentangle variant and invariant feature representations and, more importantly, utilize these representations for sample augmentation to significantly improve model robustness.

However, it is important to acknowledge some limitations of CODA, notably its reliance on pre-identified spurious attributes. This dependency requires a potentially costly labeling effort. Additionally, while CODA incurs no additional computational costs at deployment, the training phase is more resource-intensive due to the necessity of data augmentation processes.

Despite these limitations, results of this study offered a promising direction for creating machine learning models that robustly generalize beyond biased training distributions and uphold robustness across diverse subpopulations.