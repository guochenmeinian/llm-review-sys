# Polyhedral Complex Derivation from

Piecewise Trilinear Networks

 Jin-Hwa Kim

NAVER AI Lab & SNU AIIS

Republic of Korea

j1nhwa.kim@navercorp.com

###### Abstract

Recent advancements in visualizing deep neural networks provide insights into their structures and mesh extraction from Continuous Piecewise Affine (CPWA) functions. Meanwhile, developments in neural surface representation learning incorporate non-linear positional encoding, addressing issues like spectral bias; however, this poses challenges in applying mesh extraction techniques based on CPWA functions. Focusing on trilinear interpolating methods as positional encoding, we present theoretical insights and an analytical mesh extraction, showing the transformation of hypersurfaces to flat planes within the trilinear region under the eikonal constraint. Moreover, we introduce a method for approximating intersecting points among three hypersurfaces contributing to broader applications. We empirically validate correctness and parsimony through chamfer distance and efficiency, and angular distance, while examining the correlation between the eikonal loss and the planarity of the hypersurfaces. The code is available at https://github.com/naver-ai/tropical-nerf.pytorch.

## 1 Introduction

Recent advancements in visualizing deep neural networks  significantly contribute to understanding their intricate structures. This progress provides valuable insights into the expressivity, robustness, training methodologies, and distinctive geometry of neural networks. By leveraging the inherent piecewise linearity in the Continuous Piecewise Affine (CPWA) functions, _e.g._, ReLU neural networks, each region of the input space is represented as a convex polyhedron. The assembly of these sets constructs a polyhedral complex that delineates the decision boundaries of neural networks .

Building upon these breakthroughs, we explore the exciting prospect of analytically extracting a mesh representation from neural implicit surface networks . The extraction of a mesh not only offers a precise visualization and characterization of the network's geometry but also does so efficiently through the utilization of vertices and faces, in contrast to sampling-based methods . The sampling-based methods are limited by their black-box nature, which can obscure the underlying structure and lead to inefficiencies in capturing fine geometric details.

These networks typically learn a signed distance function (SDF) by utilizing ReLU neural networks. However, recent approaches incorporate non-linear positional encoding techniques, such as trigonometric functions  or trilinear interpolations using hashing  or tensor factorization , to mitigate issues like spectral bias , ensuring fast convergence, and maintaining high-fidelity. Consequently, applying mesh extraction techniques based on CPWA functions becomes challenging.

Focusing on the successful and widely-adopted trilinear interpolating methods, we present novel theoretical insights and a practical methodology for precise mesh extraction. Following a novel reviewof the _edge subdivision_ method , an efficient mesh extraction technique for CPWA functions, within the framework of tropical geometry (Section 3), we demonstrate that ReLU neural networks incorporating the trilinear module are piecewise trilinear networks (Definition 4.1). Then, we establish that the hypersurface within the trilinear region becomes a plane under the eikonal  constraint (Theorem 4.5), a common practice during the training of SDF.

Building upon this observation, we propose a method for approximating the determination of intersecting points among three hypersurfaces. Given the inherent curvature of these surfaces, achieving an exact solution is infeasible. In our approach, we utilize two hypersurfaces and a diagonal plane for a more feasible and precise approximation (Theorem 4.7). Additionally, we introduce a methodology for arranging vertices composed of faces to implicitly represent normal vectors. We experimentally confirm accuracy and simplicity using chamfer distance, efficiency, and angular distance, simultaneously exploring the relationship between the eikonal loss and the planarity of the hypersurface. In Figure 1, we present the analytically generated skeleton and normal map produced by our method using piecewise trilinear networks composed of HashGrid and ReLU neural networks. For a more detailed view, please refer to Figure 10 in Appendix.

Our contributions are summarized as follows:

1. We present novel theoretical insights and a practical methodology for precise mesh extraction, from the piecewise trilinear networks using the HashGrid.
2. We provide a theoretical analysis of the piecewise trilinear networks under the eikonal constraint revealing that, within a trilinear region, a hypersurface transforms into a plane.
3. We validate its correctness and parsimony through chamfer distance and efficiency, and angular distance, showing the correlation between the eikonal loss and hypersurface planarity.

## 2 Related work

Mesh extraction in deep neural networks.A conventional black-box approach is to assess a given function at sampled points to derive the complex of the function, commonly through marching cubes  or marching tetrahedra [10; 16]. Despite the inclusion of mesh optimization techniques  in modern mesh packages, this exhaustive method often generates redundant complexities due to discretization, increasing the computational load by using unnecessary mesh elements (_e.g._, fragmented planners). Aiming for exact extraction, initial efforts focused on identifying linear regions  and employing _Analytical Marching_ to exactly reconstruct the zero-level isosurface. Contemporary approaches involve region subdivision, wherein the regions of the complex are progressively subdivided from neuron to neuron and layer to layer, allowing for the efficient calculation of the exponentially increasing linear regions [4; 19; 20; 21]. Nevertheless, many previous studies have explored CPWA functions consisting of fully connected layers and ReLU activation, primarily owing to the mathematical simplicity of hyperplanes defining linear regions. However, this restricts their applications in emerging domains of deep implicit surface learning that diverge from CPWA functions.

Figure 1: The mesh is analytically extracted from piecewise trilinear networks, comprising both HashGrid  and ReLU neural networks, that have been trained to learn a signed distance function with the eikonal loss. We start with initial vertices and edges defined using the grid marks (1), and its linear subdivision (2a); however, intersecting polygons (_ref._ Section 3.2) need bilinear subdivision (2b) and consequentially trilinear subdivision (2c). Note that the linear and bilinear subdivisions are specific instances of trilinear subdivisions with straightforward solutions.

Positional encoding.The spectral bias of a multi-layer perceptron (MLP) hinders effectively learning high frequencies, both theoretically and empirically . To address this limitation, Fourier feature mapping, employing trigonometric projections similar to those used in the Transformer architecture , proves successful in representing complex 3D objects and scenes. Furthermore, to address its slow convergence and enhance rendering quality, novel positional encoding methods using trilinear interpolations, _e.g._, HashGrid  or TensoRF , are introduced. Both techniques generate positional features through trilinear interpolation among the eight nearest corner features derived from pre-defined 3D grids. These features are obtained by hashing from multi-resolution hash tables or factorized representations of a feature space, respectively. However, these approaches cause the function represented by neural networks to deviate from CPWA functions, as trilinear interpolation is not an affine transformation. Consequently, the complex regions are divided by intricate hypersurfaces.

Eikonal equation and SDF.An eikonal 1 equation is a non-linear first-order partial differential equation governing the propagation of wavefronts. Notably, this finds application in the regularization of a signed distance function (SDF) in the context of neural surface modeling [6; 8; 23]. If \(\) represents a subset of the space \(\) equipped with the metric \(d\), the SDF \(f()\) is defined as follows:

\[f()=-d(,)&\\ d(,)&^{}\] (1)

where \(\) denotes the boundary of \(\). The metric \(d\) is defined (with a slight notational abuse) as:

\[d(,):=_{}d(,)\] (2)

where \(d\) represents the shortest distance from \(\) to \(\) in the Euclidean space of \(\). In the Euclidean space with a piecewise smooth boundary, the SDF exhibits differentiability almost everywhere, and its gradient adheres to _the eikonal equation_. Specifically, for points \(\) on the boundary, \( f()=N()\) where the Jacobian of \(f\) represents the outward normal vector, or equivalently, \(| f()|=1\).

## 3 Preliminaries

We present an overview of tropical geometry (Section 3.1) to provide a formal definition of the tropical hypersurface and the tropical algebra of neural networks. Then, we discuss the edge subdivision algorithm  for extracting the tropical hypersurface (Section 3.2). We supplement Appendix A.1 for less familiar readers. Later, we extend this idea to include considerations for trilinear interpolation in Section 4. You may choose to skip these sections if you are already acquainted with these concepts.

### Tropical geometry

Tropical 2 geometry [25; 26] describes polynomials and their geometric characteristics. As a skeletonized version of algebraic geometry, tropical geometry represents piecewise linear meshes using _tropical semiring_ and _tropical polynomial (ref._ Appendix A.1). The set of points where a tropical polynomial \(f\) is non-differentiable, due to tropical sum \(:=()\), is called _tropical hypersurface_:

**Definition 3.1** (Tropical hypersurface).: The tropical hypersurface of a tropical polynomial \(f()=c_{1}^{_{1}} c_{r}^{_{r}}\) is defined as:

\[V(f)=\{^{d}:c_{i}^{_{i}}=c_{j}^{_{ j}}=f()\ _{i}_{j}\}\]

where the tropical monomial \(c_{i}^{_{i}}\) with \(d\)-variate \(\) is defined as \(c_{i} x_{1}^{a_{i,1}} x_{d}^{a_{i,d}}\) with \(d\)-variate \(_{i}=(a_{i,1},,a_{i,d})\) and _tropical product_\(:=+\).

**Definition 3.2** (ReLU neural networks).: Assuming input and output dimensions are consistent, \(L\)-layer neural networks with ReLU activation are a composition of functions defined as:

\[^{(L)}=^{(L)}^{(L-1)}^{(L-1)}^{(1)} ^{(1)}\] (3)

where \(()=(,0)\) and \(^{(i)}()=^{(i)}+^{(i)}\).

Although the neural networks \(\) is generally non-convex, it is known that the difference of two tropical _signomials_ (allowing a real-valued \(\) in a tropical polynomial) can represent \(\) (_ref._ Appendix A.3). Given this observation, we proceed to examine the following proposition:

**Proposition 3.3** (Decision boundary of neural networks).: _The decision boundary for \(L\)-layer neural networks with ReLU activation \(^{(L)}()=0\) is a subset of or equals with the region where two tropical monomials, or two arguments of \(\), equal (Definition 3.1), as follows:_

\[\{:^{(i)}_{j}()=0,\ i(1,,L), \ j(1,,H)\ \ i L\ \ (1)\}\]

_where the subscript \(j\) denotes the \(j\)-th neuron, assuming the hidden size of neural networks is \(H\), while the final \(L\)-th layer has a single output for rather discussions as an SDF (Definition 4.3). Remind that tropical operations satisfy the usual laws of arithmetic for recursive consideration._

The piecewise hyperplanes corresponding to \(^{(i)}_{j}\) are the _candidates_ shaping the decision boundary. It enables for-loop iterations over the neurons across layers, as in Algorithm 2, not visiting every exponentially growing linear region [18; 27]. The equality in Proposition 3.3 generally does not hold, but we can filter them by checking if \(^{(L)}_{1}()=0\). For more details, please refer to Berzins . We note that our formal explanation through tropical geometry is unprecedented in the previous work .

### Edge subdivision for tropical geometry

Polyhedral 3 complex derivation from a multitude of linear regions is inefficient and may be infeasible in some cases. Rather, Berzins  argue that tracking vertices and edges of the decision boundary sequentially considering the polynomial number of hyperplanes is particularly efficient, even enabling parallel tensor computations for edge subdivisions.

Initially, we start with a unit cube of eight vertices and a dozen edges, denoted by \(\) and \(\), respectively. For each piecewise linear, or _folded_ in their term, hyperplane, we find the intersection points of each one of the edges and the hyperplane (if any) to add to \(\). The divided edges by the intersection are also added to \(\). Note that we also find new edges of polygons, the intersections of convex polyhedra representing corresponding linear regions , and the folded hyperplane. Repeating these for all folded hyperplanes, before selecting all vertices \(^{}\) where \((^{})=0\). Then, the valid edges connecting those vertices would represent the decision boundary.

To elaborate with details, the order of subdividing is invariant as stated in Proposition 3.3; however, we must perform the subdivision with all hyperplanes in the previous layers in advance if we want to keep the current set of edges not crossing linear regions. One critical advantage of _this principle_ is that we can find the intersection point by evaluating the output ratio of the two vertices of an edge, \((_{0})\) and \((_{1})\), which are proportional to the distances to the hyperplane by Thales's theorem . The intersection point would simply be \(}_{0,1}=(1-w)_{0}+w_{1}\) where \(w=|d_{0}|/|d_{0}-d_{1}|\) and \(d_{k}=^{(l)}_{j}(_{k})\), upon the fact that \(d_{0} d_{1}<0\) if the hyperplane divides the edge.

Updating edges needs two steps: dividing the edge into two new edges and adding new edges of intersectional polygons by a hyperplane for convex polyhedra representing linear regions. The latter is a tricky part that we need to find every pair of two vertices among \(\{}_{,}\}\), both within the same linear region _and_ on the two common hyperplanes, obviously including the current hyperplane. They argue that the _sign-vectors_ for the preactivations provide an efficient way to find them.

**Definition 3.4** (Sign-vectors).: For the current hyperplane specified by the \(i^{*}\)-th layer and its \(j^{*}\)-th preactivation, we define the sign-vectors with a small positive constant \(\):

\[(_{k})_{(i,j)}=+1&\ ^{(i)}_{j}(_{k}) \ >+\\ 0&\ |^{(i)}_{j}(_{k})|\ +\\ -1&\ ^{(i)}_{j}(_{k})\ <-\] (4)

for all \(i\) and \(j\) where \((i,j)(i^{*},j^{*})\), and \((i,j)\{0\}\) is an ascending indexing function from lower layers, handling arbitrary hidden sizes of networks to vectorize a signed matrix.

Notice that a hyperplane divides a space into two half-spaces, two linear regions. Collectively, if the sign-vectors for the \(i\)-th layer and its \(j\)-th preactivation of two vertices have the same values except for zeros, which are wild cards for matching, we can say that the two vertices are within the same linear region in the current step \((i^{*},j^{*})\). For the second, the sign-vector has at least three zeros specifying a point by at least three hyperplanes. If two zeros are at the same indices in the two sign-vectors, the two vertices are on the same two hyperplanes, forming an edge. Notice that our principle asserts edges should be within linear regions.

Berzins  argue that the edge subdivision provides the optimal time and memory complexities of \((||)\), linear in the number of vertices, while it can be efficiently computed in parallel. According to Hanin and Rolnick , the number of linear regions is known for \(o(N^{L}/L!)\) where \(N\) is the total number of neurons, or \((L,1)\) in our notation.

## 4 Method

### Piecewise trilinear networks

**Definition 4.1** (Trilinear interpolation).: Let a unit cube be in the \(D\)-dimensional space, where its corners are represented by \(^{2^{D} F}\) where \(F\) is a corner-feature dimension. Given weights \(^{D}\), the trilinear interpolation function \(\) is defined as:

\[(;)=_{i=0}^{2^{D}-1}(i,)_{i} ^{F}\] (5)

where the interpolating weight \((i,)\) is defined using a left-aligned and zero-trailing binarization function \(\{0,1\}^{D}\) (_ref._ Appendix B.1) as follows:

\[(i,)=_{j=1}^{D}(1-(i)_{j})(1-_{j})+(i) _{j}_{j}\] (6)

which is the volume of the opposite subsection of the hypercube divided by the weight point \(\). For a general hypercube, scaling the weight for a unit hypercube gets the same result. Going forward, we assume \(D\)=3 for trilinear interpolation without explicitly stating it otherwise.

**Lemma 4.2** (Nested trilinear interpolation).: _Let a nested cube be inside of a unit cube, where its positions of the eight corners deviate \(-_{j}\) or \(+_{j}\), such that \(_{j},_{j} 0\), from \(_{j}\) for each dimension \(j\), using the notations of Definition 4.1. The eight corners of the nested cube are the trilinear interpolations of the eight corners of the unit cube. Then, the trilinear interpolation with the unit cube and the nested cube for \(\) is identical._

Proof.: Notice that trilinear interpolation is linear for each dimension to prove it. The detailed proof can be found in Lemma D.1. 

**Definition 4.3** (Piecewise trilinear networks).: Let a positional encoding module be \(:^{D}^{F}\) using the trilinear interpolation of spatially nearby learnable vectors on a three-dimensional grid, _e.g._, HashGrid  or TensoRF , where \(\) is an instance of \(\) in Definition 4.1. Usually, they transform the input coordinate \(\) to \(\) as a relative position inside a unit grid in a corresponding resolution. \(\) is a learnable parameter specified in the corresponding method. Then, we define trilinear neural networks \(\), by prepending \(\) to the neural networks \(\) from Definition 3.2. Here, the input and output dimensions of \(^{(L)}\) are \(F\) and \(1\) (an SDF distance), respectively.

\[^{(L)}=^{(L)}\] (7)

Note that \(\) is _gridwise_ trilinear. Using Lemma 4.2, \(\) is trilinear within the composite intersections of linear regions of \(\) and trilinear regions of \(\). (We discuss how to access _virtual_ cubic corner features where trilinear regions are not cubic in Section 5.) So, we regard \(\) as _piecewise_ trilinear.

### Curved edge subdivision in a trilinear space

In a trilinear space, \(\) projects a line to a curve except the lines on the grid. Notably, the diagonal line \(=(t,t,t)^{}\) where \(t\) is projected to a cubic Bezier curve (_ref._ Proposition D.2). We aim to generalize for the _curved_ edge subdivision for _hypersurfaces_.

**Lemma 4.4** (Curved edge of two hypersurfaces).: _In a piecewise trilinear region, let an edge \((_{0},_{7})\) be the intersection of two hypersurfaces \(_{i}()=_{j}()=0\), while \(_{0}\) and \(_{7}\) are on the two hypersurfaces. Then, the edge is defined as:_

\[\{:()=(1-t)(_{0})+t(_{7})\;\;\; \;^{D}\;\;\;\;t\}.\]

Proof.: The detailed proof using the piecewise linearity of \(\) is provided in Lemma D.4. 

Notice that it does not decrease the number of variables to find a line solution since the trilinear interpolation \(\)_still_ forms hypersurfaces making complex cases. Yet, we theoretically demonstrate that the eikonal constraints on \(\) render them hyperplanes with linear solutions.

**Theorem 4.5** (Hypersurface and eikonal constraint).: _A hypersurface \(()=0\) intersects two points \((_{0})=(_{7})=0\) while \((_{1 6}) 0\) for the remaining six points. These points form a cube, with \(_{0}\) and \(_{7}\) positioned on the diagonal of the cube. The hypersurface satisfies the eikonal constraint \(\|()\|_{2}^{2}=1\) for all \(^{3}\). Then, the hypersurface of \(()=0\) is a plane._

**Corollary 4.6** (Affine-transformed hypersurface and eikonal constraint).: _Let \(_{0}()\) and \(_{1}()\) be two affine transformations defined by \(_{i}^{}+_{i}\), \(i\{0,1\}\). A hypersurface \(_{0}()=0\) passing two points \(_{0}(_{0})=_{0}(_{7})=0\) while \(_{0}(_{1 6}) 0\) satisfies the eikonal constraint \(\|_{1}()\|_{2}^{2}=1\) for all \(^{3}\). Then, the hypersurface of \(_{0}()=0\) is a plane._

The proofs using its partial derivatives can be found in Theorem D.5 and Corollary D.6.

Since we aim for a practical polyhedral complex derivation that piecewise trilinear networks represent, we replace one of the hypersurfaces forming the curved edge with a diagonal plane in a piecewise trilinear region. We choose this option not only for its mathematical simplicity but also due to the characteristics of trilinear hypersurfaces, as illustrated in Figure 9, Appendix G. Thus, the new vertices lie on at least two hypersurfaces, and the new edges exist on the same hypersurface, while the eikonal constraint minimizes any associated error from this approximation. This error is tolerated by the hyperparameter \(=\)1e-4 as specified in Definition 3.4 and Section 6. More discussions on this matter can be found in Appendix C.1.

**Theorem 4.7** (Intersection of two hypersurfaces and a diagonal plane).: _Let \(_{0}()=0\) and \(_{1}()=0\) be two hypersurfaces passing two points \(_{0}\) and \(_{7}\) such that \(_{0}(_{0})=_{1}(_{0})=0\) and \(_{0}(_{7})=_{1}(_{7})=0\), \(_{i}:=_{0}(_{i})\) and \(_{i}:=_{1}(_{i})\), \(_{}=_{0};\;_{1};\;_{4};\;_{5}\), \(_{}=_{2};\;_{3};\;_{6};\;_{7}\), and \(=[(1-x)^{2};\;x(1-x);\;(1-x)x;\;x^{2}]\). Then, \(x\) of the intersection point of the two hypersurfaces and a diagonal plane of \(x=z\) is the solution of the following quartic equation:_

\[^{}_{}_{}^{}-_{ }_{}^{}=0, y= ^{}_{}}{^{}(_{}- _{})}(_{}_{}).\] (8)

Proof.: Please refer to Theorem D.7 for the detailed proof, which uses linear algebra to rearrange two trilinear equations with two variables to get a solution. 

Note that finding roots of a polynomial is the eigenvalue decomposition of a companion matrix , which can be parallelized (_ref._ Lemma D.8). Given that the companion matrix remains small for a quartic equation in \(^{4 4}\), the overall complexity remains \((||)\). For the detailed complexity analysis on the proposed method, please refer to Appendix E.

### Skeletonization, faces, and normals

**Skeletonization** selects the vertices such that: \(^{}=\{\;|\;|()|, \}\), and the edges \(^{}\) such that their two vertices are among \(^{}\). Recall that because a decision boundary is a subset of the _tropical hypersurface_ (Definition 3.1 and Proposition 3.3), this step ensures accurate mesh extraction.

**Faces** are formed by edges lying on the same plane and sharing a common region. This is identified by evaluating the sign-vectors (_ref._ Definition 3.4 and Section 5). Note that faces are not inherently triangular; however, if needed, they can be triangulated via _triangularization_ for further analysis.

**Normals** are conventionally described by the order of the vertices as each face has ambiguity with two opposite directions. Let \(_{0,1,2}\) be the vertices forming a triangular face. The normal is defined using cross-product as \(=(_{1}-_{0})(_{2}-_{0})\) where the normal is orthogonal to both vectors, with a direction given by the right-hand rule. Please refer to Appendix B.2 for the details.

## 5 Implementation

We employ the HashGrid  for \(\), while our discussion on its generalizability is provided in Appendix C.2. We illustrate our method in Algorithm 1, 2, and Figure 2, inspired by Hanin and Rolnick  for its visualization of linear regions. We describe the implemental details of the algorithms in the following sections and the corresponding caption of Figure 6.

Initialization.While the original edge subdivision algorithm  starts with a unit cube of eight vertices and a dozen edges, we know that the unit cube is subdivided by orthogonal planes consisting of the grid. Let an input coordinate be \(^{3}\), and there is a unit cube such that one of its corners is at the origin. Taking into account multi-resolution grids, we obtain the marks \(m_{i}\), such that the grid planes are \(x=m_{i}\), \(y=m_{i}\), and \(z=m_{i}\), following Algorithm 4 in Appendix. Notice that we carefully consider the offset \(s/2\), which prevents the zero derivatives from aligning across all resolution levels (_ref._ Appendix A of Muller et al. ). Leveraging the obtained marks, we derive the associated grid vertices and edges, which serve as the initial sets for \(\) and \(\), respectively. Please refer to Figure 1(a) where its multi-resolution grids are visualized using randomized colors.

Optimizing sign-vectors.The number of orthogonal planes may significantly surpass the number of neurons, making it impractical to allocate elements for the sign-vectors (Definition 3.4). To address this, leveraging the orthogonality of the grid planes, we store a plane index along with an indicator of whether the input is on the plane (\(=0\)) or not (\(=1\)).

Piecewise trilinear region.In Theorem 4.7, we need the outputs of corners \(\) and \(\) in a common piecewise trilinear region; however, some corners may be outside of the region. For this, we replace all ReLU activations using the mask \(\) that: \(_{j}^{(i)}=(_{j}^{(i)}(_{0})>)( _{j}^{(i)}(_{7})>)\), where \(_{0}\) and \(_{7}\) are the vertices of an edge of interest, for the calculated cubic corners \(_{0...7}\). This implies that \(\) exhibits linearity, except for instances where two vertices simultaneously deviate from linearity. For \(\) and \(\), we select the last two pairs of \(i\) and \(j\) such that \(_{(i,j)}(_{0})=_{(i,j)}(_{7})=0\), indicating two common hypersurfaces passing two points \(_{0}\) and \(_{7}\).

## 6 Experiment

Objective.For a given trilinear neural network with the eikonal constraint, our goal is to get a boundary mesh of the zero-set of the SDF. (Note that NeuS  showed how to convert the density

Figure 2: Trilinear regions in the xy-plane at \(z=0.04\), identified by the sign-vectors (Definition 3.4), are represented with random colors. (a) Grids described in Section 5 and Algorithm 4. (b) The neurons of the first layer representing folded hypersurfaces (blue arrow). (c) All neurons representing every nonlinear boundary. (d) Select all zero-set vertices and edges. (e) Skeletonized as in Section 4.3.

networks of NeRFs to an SDF in the frameworks of volume rendering.) To evaluate this, we utilize marching cubes with excessive sampling to get a pseudo-ground truth mesh to remove Bayes error caused by underfitting. We explicitly specify the samplings in the results.

Hyperparameters.We used the number of layers \(L\) of 3 and hidden size \(H\) of 16 for the networks, and \(\) of 1e-4 for the sign-vectors (_ref._ Definition 3.4). The weight for the eikonal loss is 1e-2. For HashGrid, the resolution levels of 4, feature size of 2, base resolution \(N_{}\) of 2, and max resolution \(N_{}\) of 32 _by default_. \(N_{}\) and \(N_{}\) are doubled (x2) or quadrupled (x4) for _Medium_ or _Large_ settings in Figure 4. We use the official Python package of tinycudnn 4 for the HashGrid module.

Chamfer distance and efficiency.The chamfer distance is a metric used to evaluate the similarity between two sets of sampled points from two meshes. Let \(_{0}\) and \(_{1}\) be the two sets of points. Specifically, the bidirectional chamfer distance (CD) is defined as follows:

\[(_{0},_{1})=}(_{0},_{1})+}( _{1},_{0}),\ \ }(_{0},_{1})=_{0}|}_{_{0}}_{_{1} }\|-\|_{2}^{2}.\] (9)

We randomly select 100K points on the faces through ray-marching from the origin, directing toward a randomly chosen point on a unit sphere.

Table 1 and Figure 4 show the results for the Standford 3D Scanning repository . Varying the number of samples in marching cubes , we plot the baseline with respect to the number of generated vertices. Given that our method extracts vertices from the intersection points of hypersurfaces, it enables parsimonious representations using the lower number of vertices having better CD, summarized by chamfer efficiency (CE) 5 in Table 1, and ours are located in the lower-left region compared with the baselines in Figure 4. In particular, we observe a strong CE in a simple object, _e.g._, Drill Bit, which achieved a CE of 47.8 versus 19.2 (MC).

Our method inherently holds an advantage over MC in capturing optimal vertices and faces, especially in cases where the target surfaces exhibit planar characteristics. When dealing with curved surfaces, the smaller grid size of the _Large_ model in Figure 4 views a curved surface in a smaller interval, and it tends to approach the plane. From the plotting of _Small_ to

Figure 3: Chamfer distance for the bunny with the _Large_ model comparing with MC, MT, and NDC.

_Large_, our CDs (colored crosses) are decreasing to zero, consistently with better CEs, confirming this speculation. The complete results of the _Large_ models and its visualization can be found in Tables 6 to 8 in Appendix F.1 and the right side of Figure 10 in Appendix, respectively. We also compare ours with Marching Tetrahedra (MT)  and Neural Dual Contour (NDC)  in Figure 3, where our method achieved the lowest chamfer distance and the most efficiency method with respect to the number of vertices. For the rationale behind our selection, please refer to Appendix F.3.

Angular distance.The angular distance measures how much the normal vectors deviate from the ground truths. Analogous to the chamfer distance, we sample 100K points on the surface and calculate the normal vectors as described in Section 4.3. The angular distance is defined as follows:

\[(_{0},_{1})=_{i}^{-1}_{0}^{(i)},_{1}^{(i)} \] (10)

In Table 5 in Appendix, the angular distances for the Stanford bunny are shown. As we expected, our approach efficiently estimates the faces using a parsimonious number of vertices compared to the sampling-based method. We confirm this trend is consistent across other objects.

Eikonal constraint for planarity.To assess the efficacy of the eikonal constraint, which enforces the planarity of hypersurfaces as outlined in Theorem 4.5, we quantify the flatness error associated with the planarity constraints presented in the proof of Theorem D.5. Let \(_{0}\) and \(_{7}\) be two vertices consisting of a diagonal edge, while \(_{1 6}\) are its remaining cubic corners. We obtain \((_{1 6})\) in a piecewise trilinear region as described in Section 5. This evaluation is conducted as follows:

\[_{}= _{}\|_{i \{1,2,4\}}(_{i})\|_{1}+\|_{i\{3,5,6\}}( _{i})\|_{1}+_{i=1}^{3}\|_{j\{i,7-i \}}(_{j})\|_{1}.\] (11)

In Figure 5, we empirically validate that the eikonal loss enforces planarity in the hypersurfaces within piecewise trilinear regions, as described in Theorem 4.5. The absence of the eikonal loss results in elevated planarity errors, leading to the construction of an inaccurate mesh.

    &  &  &  &  & Drill & Lucy \\  MC \# & \(||\) & CD \(\) & CE \(\) & \(||\) & CD \(\) & CE \(\) & \(||\) & CD \(\) & CE \(\) & CE \(\) & CE \(\) & CE \(\) \\ 
32 & 1283 & 4106 & 19.0 & 1416 & 6330 & 11.2 & 1032 & 6951 & 13.9 & 11.2 & 7.5 & **24.9** \\
64 & 5367 & 1371 & 13.6 & 6090 & 1936 & 8.5 & 4362 & 2465 & 9.3 & 8.3 & 19.2 & 16.0 \\
128 & 21825 & 393 & 11.6 & 52236 & 542 & 7.3 & 18219 & 722 & 7.6 & 6.6 & 17.4 & 10.7 \\
196 & 49569 & 141 & 14.3 & 57341 & 203 & 8.6 & 41351 & 276 & 8.8 & 7.5 & 15.3 & 11.7 \\  Ours & 4341 & 900 & **25.6** & 5104 & 1243 & **15.8** & 3710 & 1738 & **15.5** & **13.9** & **47.8** & 23.6 \\   

Table 1: Chamfer distance (CD) and chamfer efficiency (CE) for the Stanford 3D Scanning repository . The CD (\(\)1e-6) is evaluated using the marching cubes (MC) with 256\({}^{3}\) grid samples as the reference ground truth for all measurements. Please refer to Table 2 and Table 3 for the full results, and Table 4 for standard deviation and time spent in Appendix (Ours took 0.97 \(\) 0.21 while MC also took within 1 sec for the bunny.)Visualization.We provide the qualitative analyses in Figure 6 comparing with MT [10; 16] and NDC , along with MC. While the competitors exhibit over-smoothing or inaccuracies, particularly in the nose region, our method preserves surface details with consistent normals and outperforms in both accuracy and generalization. In addition, we present Figures 10 to 13 in Appendix G encompassing the comparison between the _Small_ and _Large_ models (Figure 10), visualizing the marching cubes varying the number of samples (Figure 11), detailed comparisons (Figure 12), and the gallery of the Stanford 3D Scanning meshes from the _Large_ models (Figure 13).

Limitations.Although we implement the algorithm using pre-defined parallel tensor operations in PyTorch , achieving time and memory complexity of \((||)\) as detailed in Appendix E, our method inherently requires forward passing the intermediate vertices during edge subdivisions iterating over neurons, which depends on previous steps (Algorithm 1). For the Stanford bunny using the _Small_ model, the intermediate counts for vertices and edges exceed 11K and 19K, respectively, although they are eventually reduced to 4.3K vertices for face extraction. This overhead is negligible for the _Small_ models, taking 0.97 seconds; however, for the _Large_ models, the process takes 4.15\(\)0.61 seconds for 140.3\(\)5.6K vertices with our optimized algorithm, compared to 1.31 and 11.88 seconds for marching cubes with 256 and 512 samples per axis, respectively. We note that parallelizing over multiple GPUs would be a reliable option to improve latency. For the discussions on satisfying the eikonal equation in practice and the generalization to other positional encodings using trilinear interpolation, please refer to Appendix C.1 and Appendix C.2, respectively.

## 7 Conclusions

In conclusion, our exploration of novel techniques in visualizing trilinear neural networks unveils its intricate structures and extends mesh extraction applications beyond CPWA functions. Focused on trilinear interpolating methods, our study yields novel theoretical insights and a practical methodology for precise mesh extraction. Notably, Theorem 4.5 shows the transformation of hypersurfaces to planes within the trilinear region under the eikonal constraint. Empirical validation using chamfer distance and efficiency, and angular distance affirms the correctness and parsimony of our methodology. The correlation analysis between eikonal loss and hypersurface planarity confirms the theoretical findings. Our proposed method for approximating intersecting points among three hypersurfaces, coupled with a vertex arrangement methodology, broadens the applications of our techniques. This work establishes a foundation for future research and practical applications in the evolving landscape of deep neural network analysis and toward real-time rendering mesh extraction.

Figure 6: This figure provides a detailed visualization of Figure 10 in the Appendix and its competitors. MC 64, MT 32 (Marching Tetrahedra), and NDC (Neural Dual Contour ) suffer over-smoothing or inaccuracy of the actual surface in the Small networks within the nose, whereas our method reflects these details (see the boundaries of a nose) with consistent normals (in colors). MT efficiently demands SDF values by utilizing six tetrahedra within grids to get intermediate vertices. However, it is inefficient in terms of the number of vertices extracted. NDC faces a generalization issue for a zero-shot setting for the given networks, producing unsmooth surfaces.