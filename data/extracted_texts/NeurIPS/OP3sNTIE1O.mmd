# Data Augmentation with Diffusion for

Open-Set Semi-Supervised Learning

Seonghyun Ban1, Heesan Kong1, Kee-Eung Kim1,2

1Kim Jaechul Graduate School of AI, KAIST

2School of Computing, KAIST

shban@ai.kaist.ac.kr, hskong@ai.kaist.ac.kr, kekim@kaist.ac.kr

Equal Contribution.Corresponding Author.

###### Abstract

Semi-supervised learning (SSL) seeks to utilize unlabeled data to overcome the limited amount of labeled data and improve model performance. However, many SSL methods typically struggle in real-world scenarios, particularly when there is a large number of irrelevant instances in the unlabeled data that do not belong to any class in the labeled data. Previous approaches often downweight instances from irrelevant classes to mitigate the negative impact of class distribution mismatch on model training. However, by discarding irrelevant instances, they may result in the loss of valuable information such as invariance, regularity, and diversity within the data. In this paper, we propose a data-centric generative augmentation approach that leverages a diffusion model to enrich labeled data using both labeled and unlabeled samples. A key challenge is extracting the diversity inherent in the unlabeled data while mitigating the generation of samples irrelevant to the labeled data. To tackle this issue, we combine diffusion model training with a discriminator that identifies and reduces the impact of irrelevant instances. We also demonstrate that such a trained diffusion model can even convert an irrelevant instance into a relevant one, yielding highly effective synthetic data for training. Through a comprehensive suite of experiments, we show that our data augmentation approach significantly enhances the performance of SSL methods, especially in the presence of class distribution mismatch.

## 1 Introduction

Deep neural networks (DNNs), trained using a large amount of labeled datasets, have shown to achieve remarkable performance in a variety of supervised learning tasks, such as image classification (LeCun et al., 2015; Krizhevsky et al., 2017) and object detection (Everingham et al., 2010; Lin et al., 2014). Nonetheless, the intensive labor of annotating vast datasets often renders the construction of sufficiently large labeled datasets prohibitively expensive for numerous applications (Oliver et al., 2018). To address this, semi-supervised learning (SSL) (Chapelle et al., 2009) has emerged as a viable approach, which aims to leverage abundant unlabeled data to overcome the limited availability of labeled data.

Recent progress in SSL has made many noteworthy advancements, including techniques such as pseudo-labeling (Lee, 2013; Pham et al., 2021), consistency regularization (Sajjadi et al., 2016; Tarvainen and Valpola, 2017; Sohn et al., 2020), and entropy minimization (Grandvalet and Bengio, 2004; Miyato et al., 2018; Berthelot et al., 2019). However, a common limitation of these methods is their reliance on the critical assumption that both unlabeled and labeled data instances are drawnfrom an identical distribution. This often leads to significant performance degradation when there is a class distribution mismatch, as noted in Oliver et al. (2018). Given that real-world settings often deviate from this assumption (Guo et al., 2020), it becomes crucial to address the class distribution mismatch for successfully applying SSL in realistic scenarios.

A prevalent approach to mitigate the class distribution mismatch in SSL involves selectively utilizing unlabeled data through a weighting function which serves to reduce the influence of irrelevant unlabeled samples (Chen et al., 2020; Guo et al., 2020). While these filtering methods are intuitively appealing and have shown their effectiveness in mitigating negative effect of the class distribution mismatch, they may result in the loss of valuable information such as invariance, regularity, and diversity within the data: even though the labeled data contains only white trucks, could we generate images of red trucks using the red bike images in the unlabeled dataset?

In this paper, we propose a generative data augmentation approach that leverages a diffusion model to enrich labeled data using both labeled and unlabeled samples. A key challenge lies in utilizing the diversity of the unlabeled data to compensate the limited amount of labeled data, while minimizing the generation of samples that are irrelevant to the classes in the labeled dataset. To address this, we integrate diffusion model training with a discriminator that evaluates the relevance of each unlabeled instance. The discriminator's resulting score is used to assign weights to unlabeled instances, allowing those with higher relevance to contribute more significantly to the training of the diffusion model.

In addition, drawing inspiration from the approach in Meng et al. (2022), we add noise to each unlabeled sample and utilize them as guide images during the data generation process. As depicted in Figure 1, we found that incorporating class conditions into this generation process can transform possibly irrelevant unlabeled samples into labeled samples while preserving key characteristics of the original unlabeled samples (e.g., outline, color arrangement, shape, etc.).

Our extensive experimental results, utilizing CIFAR-10, CIFAR-100 (Krizhevsky and Hinton, 2009), ImageNet-30 (Deng et al., 2009), and ImageNet-100 (Cao et al., 2022) datasets with six baseline methods, demonstrate that our approach further improves the performance of recent SSL methods, especially under the class distribution mismatch.

## 2 Related Works

### Standard Semi-Supervised Learning

Semi-Supervised Learning (SSL) aims to leverage both labeled and unlabeled data to mitigate issues related to the scarcity and high annotation cost of labeled data. Since many SSL methods operate under the assumption that labeled and unlabeled data are sampled from an identical distribution,

Figure 1: Transforming unlabeled data using a diffusion model. Initially, the unlabeled data includes classes like trees, fish, and mountains, which are irrelevant to the labeled dataâ€™s classes such as trucks, cars, and ships. The reverse process with class conditioning resolves this mismatch while preserving the diversity of the original unlabeled samples. More examples can be found in Appendix H.

we refer to this as the standard SSL setting. Among the various approaches to the standard SSL setting, we briefly review two of the most representative methods: pseudo-labeling and consistency regularization.

Pseudo-labeling (Scudder, 1965; McLachlan, 1975; Lee, 2013) is a technique where the model-predicted labels of the unlabeled data are treated as if they were true labels. Essentially, this method simply converts unlabeled data into labeled data. On the other hand, consistency regularization (Bachman et al., 2014) has become a crucial component in recent SSL regimes. This approach applies data augmentation on the unlabeled data to regularize the model to yield similar outputs for augmented views of the same instance (Sajjadi et al., 2016; Laine and Aila, 2017; Sohn et al., 2020).

However, these methods often fail when there is a mismatch between the distributions of labeled and unlabeled data. In some cases, their performance may be even worse than simply discarding all the unlabeled data (Oliver et al., 2018). The primary source of the problem is the presence of unlabeled instances that do not belong to any of the classes present in the labeled data, which we refer to as out-of-distribution (OOD) instances. They may exacerbate confirmation bias (Arazo et al., 2020) in pseudo-labeling approaches or intensify the overconfidence problem in consistency regularization approaches (Chen et al., 2020).

### Open-set Semi-Supervised Learning

The open-set SSL setting refers to the practical yet challenging scenario where the class distributions of labeled and unlabeled dataset differ significantly. A prevalent solution to the class distribution mismatch is to filter out OOD instances from the unlabeled dataset. To achieve this, it is necessary to accurately identify them, despite the absence of label information. Uncertainty-Aware Self-Distillation (UASD), proposed by Chen et al. (2020), formulates temporally ensembled networks and utilizes ensemble prediction to quantify predictive uncertainty of labels to identify OOD instances. DS3L (Guo et al., 2020) adopts a meta-learning approach to selectively use unlabeled data that enhances generalization performance. OpenMatch (Saito et al., 2021) leverages one-vs-all classifiers as the OOD detector to filter out OOD instances. Safe-Student (He et al., 2022) employs teacher-student mechanism and introduces energy-discrepancy, a new scoring function for detecting OOD instances. The above methods follow the detect-and-filter paradigm, which is the dominant approach of open-set SSL, assuming that OOD instances are fundamentally harmful.

In contrast to these detect-and-filter approaches, several studies share similar goals to ours, aiming to harness the potential of OOD unlabeled data rather than simply discarding them. T2T (Huang et al., 2021) incorporates a warm-up training step using OOD instances to perform a self-supervised pretext task for learning effective discriminative features. TOOR (Huang et al., 2022) introduces a weighting mechanism to evaluate the transferability of each OOD instance based on domain similarity and class tendency, and uses adversarial domain adaptation to align the feature distributions of transferable OOD instances and in-distribution (ID) instances. Fix-A-Step (Huang et al., 2023) leverages OOD instances to obtain useful data augmentation to promote diversity of training data, and integrate this idea into MixMatch (Berthelot et al., 2019). IOMatch (Li et al., 2023) takes into consideration that the OOD detector may be unreliable, particularly when labeled data are scarce. It instead employs a multi-binary classifier to produce unified open-set pseudo-labels for labeled and unlabeled data, including OOD instances.

Our approach significantly deviates from these open-set SSL methods. It is primarily centered on developing an effective data augmentation strategy from both labeled and unlabeled data, which can be used to transform an unlabeled OOD instance into a labeled ID instance.

### Recent Diffusion-based Augmentation Approaches

In this section, we provide a detailed comparison of DWD with diffusion-based methods, namely DPT (You et al., 2023) and DA-Fusion1(Trabucco et al., 2024).

DPT is a simple yet effective method that integrates diffusion models into SSL. To generate semantically accurate images, they trained a semi-supervised classifier on partially labeled real images and used it to assign pseudo-labels for all the data. Subsequently, they trained a conditional diffusion model using the pseudo-labels to synthesize images and then re-trained the semi-supervised classifier using these generated images. However, they still rely on the fundamental assumption behind the standard SSL setting. When faced with mismatch in class distributions, they suffer from the confirmation bias in pseudo labels of OOD unlabeled images and become ineffective. In contrast, our approach addresses the class distribution mismatch by integrating the discriminator into the training of the diffusion model.

DA-Fusion is a data augmentation method that utilizes a large pretrained text-to-image diffusion model (i.e., Stable Diffusion, Rombach et al., 2022). Similar to ours, it also initiates the reverse process with partially noised real images rather than generating images from scratch. However, the purpose of the generation process is distinctly different from that of our approach. While DA-Fusion aims to augment given labeled samples with subtle visual details already contained in the pretrained diffusion model, our method properly trains a diffusion model to capture both the labeled data distribution and the diversity of unlabeled samples from the given datasets, and transforms irrelevant unlabeled samples into labeled ones.

## 3 Preliminaries

Diffusion models (Sohl-Dickstein et al., 2015)incrementally add Gaussian noises to the data during its forward process and progressively removes this noise during the reverse process to reconstruct the original data. Given a data point \(_{0}\), the forward process is defined as a Markov chain that produces a sequence of noisy samples \(_{1},...,_{T}\) according to a variance schedule \(_{1},...,_{T}\):

\[q(_{t}|_{t-1}):=(_{t};}_{t-1},_{t}), q(_{1:T}|_{0}):=_{t=1}^{T}q(_{t}|_{t-1})\] (1)

The forward process exhibits a notable property in that \(_{t}\) at any arbitrary time step \(t\{1,...,T\}\) can be obtained in closed form:

\[_{t}=_{t}}_{0}+_{t })}\] (2)

where \(_{t}=1-_{t}\), \(_{t}=_{i=1}^{t}_{i}\) and \((,)\). As the reverse process can be expressed using the same functional form when \(_{t}\) is sufficiently small (Feller, 1949; Sohl-Dickstein et al., 2015), the reverse process is also defined as a Markov chain with learned Gaussian transitions starting at \(p(_{T})=(_{T},,)\):

\[p_{}(_{t-1}|_{t}):=(_{t-1}; _{}(_{t},t),_{}( _{t},t)), p_{}(_{0:T}):=p(_{T}) _{t=1}^{T}p_{}(_{t-1}|_{t})\] (3)

Denoising Diffusion Probabilistic Models (DDPMs) Ho et al. (2020)propose to use a simplified Gaussian distribution parameterization of the reverse process, which sets \(_{}\) to time-dependent constants and reparameterizes the mean function approximator \(_{}(_{t},t)\) with noise predictor \(_{}(_{t},t)\) which predicts \(\) in (2). The reverse process is then learned by the following objective:

\[L_{ddpm}=_{_{0},t,}[\|_{}(_{t},t)-\|_{2}^{2}]\] (4)

For the conditional DDPM, the primary modification is the incorporation of conditions \(\) (such as classes or texts) as an additional input, expressed as \(_{}(_{t},,t)\). This adaptation allows the diffusion model to take into account specific conditions or attributes during the reverse process, thereby enhancing its applicability to more targeted scenarios.

Positive-Unlabeled (PU) Learning (Liu et al., 2002; Li and Liu, 2003; Du Plessis et al., 2015; Kiryo et al., 2017)is a binary classification task in a situation where negative labels are missing. It aims to train models using positive-labeled and unlabeled data to perform binary classification. The main idea involves indirectly estimating the model loss on negative samples using the class prior. Given that unlabeled data are drawn from \(p^{n}()=\,p^{+}()+(1-)\,p^{-}()\), where \(=\,p(Y=1)\) is the class prior and \(p^{+}()=p(\,|\,Y=1)\) and \(p^{-}()=p(\,|\,Y=-1)\) are positive and negative class-conditional densities, the loss can be reformulated as:

\[[(g(),Y)]=_{p^{+} }[(g(),1)]+(1-)_{p^{-}}[(g(),-1)]\] \[=_{p^{+}}[(g(),1)]-_{p^{+ }}[(g(),-1)]+_{p^{-}}[(g(),-1)]\] (5)

Here, \(\) denotes a loss function and \(g\) represents the model.

## 4 Methodology

In this section, we introduce our data augmentation method, which leverages a diffusion model to generate synthetic data to address the scarcity of labeled data. As previously discussed, we start with training the diffusion model on labeled and unlabeled data while mitigating the class distribution mismatch. Subsequently, we employ the reverse diffusion process to transform unlabeled samples into synthesized labeled samples.

### Training Diffusion Model

A simple training scheme for SSL dataThe diffusion model trained only on the labeled data will inevitably overfit and merely generate replications due to their limited amount. It is thus essential to train the diffusion model on both labeled and unlabeled data, while taking advantage of the label information. We adopt a class-conditional diffusion model, shown in Figure 2, where labeled data are used for conditional training while unlabeled data are used for unconditional training, trained with the loss

\[L_{}=_{(_{0},)_{l}, t,}[||_{}(_{t},,t)- ||_{2}^{2}]+_{_{0} _{u},t,}[||_{}( _{t},t)-||_{2}^{2}],\] (6)

where \(\) serves as a hyper-parameter that controls balance between labeled and unlabeled data, \(_{l}\) and \(_{u}\) represent labeled and unlabeled datasets. Intuitively, this straightforward objective aims to train the diffusion model to reconstruct not only the limited labeled data but also the abundant unlabeled data, thereby regularizing the model against overfitting to the labeled data. It is noteworthy that this approach shares similarities with the consistency regularization technique in the sense that the unlabeled data are utilized for regularization purposes.

DiscriminatorHowever, when we train the diffusion model with the loss in (6), OOD unlabeled samples can have a negative impact on capturing important characteristics of the labeled data distribution. These samples should be made contribute less towards the overall training loss. In line with aforementioned filtering methods (Chen et al., 2020; Guo et al., 2020), we leverage a discriminator to weigh the unlabeled data instances. The discriminator is tasked with differentiating between positive samples that are closely aligned with the distribution of labeled data and negative samples that are irrelevant. To train the discriminator, we adopt PU learning with the training loss

\[L_{}=_{_{l}}[- _{}()+(1-_{}()) ]+_{_{u}}[-(1-_{}( ))],\] (7)

where \(_{}\) denotes the discriminator parameterized by \(\), and \(\) represents the ratio of positive samples among unlabeled samples, i.e. belonging to one of the classes in the labeled dataset. This ratio can either be estimated from the dataset (Menon et al., 2015; Jain et al., 2016; Christoffel et al., 2016) or treated as a hyperparameter.

We then use the discriminator to assign weights on the unlabeled instances so that they align with the distribution of labeled data. A simple algebraic manipulation tells us that the following weight formula yields an unbiased loss estimation via importance sampling:

Figure 2: Schematic diagram of Discriminator-Weighted Diffusion (DWD). The conditional diffusion model is trained using both labeled and unlabeled data. The unlabeled data is utilized for unconditional training without class conditions. The pre-trained discriminator assigns weights to each unlabeled data sample to mitigate the potential negative impact of OOD samples.

[MISSING_PAGE_FAIL:6]

\(\) in the composition of the unlabeled dataset. For example, when \(\) = 75\(\%\), the unlabeled dataset contains three non-animal classes and one animal classes. We refer Appendix C for further details on the composition of the unlabeled dataset.

The CIFAR-10/100 task uses CIFAR-10 as the labeled dataset, and CIFAR-100 as the unlabeled dataset. While the whole CIFAR-100 was taken as the unlabeled dataset, we sampled 100 images per class from CIFAR-10 to simulate the scarce labeled data scenario. Notably, class labels in CIFAR-10 and CIFAR-100 do not exactly overlap, though there are similarities (e.g., "horse" in CIFAR-10 and "cattle" in CIFAR-100). Thus, this task complements the SixAnimal task, which had an exact class overlap between labeled and unlabeled data.

The ImageNet-30 task uses the ImageNet-30 dataset Hendrycks et al. (2019), which is a subset of ImageNet limited to 30 classes. Following Saito et al. (2021), we selected 5% of the data from the first 20 classes (approximately 50 samples per class) based on the alphabetical ordering of class names for the labeled dataset, and used the remaining data as the unlabeled dataset.

The ImageNet-100 task uses ImageNet-100 dataset, which sub-sampled 100 classes from ImageNet, as described in Cao et al. (2022). We divided these classes equally into 50\(\%\) ID and 50\(\%\) OOD classes following alphabetical order. From each ID class, we selected a small portion (10\(\%\)) as labeled data with the remaining data forming the unlabeled dataset. This task assesses the effectiveness on higher-resolution images with a greater diversity of classes. Please refer to Appendix D for extensive results under various sizes of labeled dataset.

Baseline SSL methodsSince we use DWD to transform the unlabeled dataset into a dataset devoid of class distribution mismatch, we comprehensively consider as baseline SSL methods those which operate under the standard setting as well as the open-set setting. The baseline SSL methods under the standard setting are MixMatch (Berthelot et al., 2019), FixMatch (Sohn et al., 2020), and Meta Pseudo Labels (MPL) (Pham et al., 2021), and the methods under the open-set setting are OpenMatch (Saito et al., 2021), Fix-A-Step (Huang et al., 2023), and IOMatch (Li et al., 2023).

  
**Task Name** & **MixMatch** & **FixMatch** & **MPL** & **OpenMatch** & **Fix-A-Step** & **IOMatch** & DWD-SL \\  SixAnimal (\(\) = 75\(\%\)) & 80.77\(\)0.11 & 82.50\(\)0.16 & 65.62\(\)0.47 & 80.34\(\)0.21 & 85.34\(\)0.17 & 83.05\(\)0.16 & **85.86\(\)0.28** \\ CIFAR-10/100 & 71.02\(\)0.32 & 78.91\(\)0.15 & 70.95\(\)0.34 & 70.15\(\)0.30 & 74.60\(\)0.31 & 77.66\(\)0.22 & **80.05\(\)0.14** \\ ImageNet-30 & 68.67\(\)0.37 & 70.07\(\)0.26 & 72.65\(\)0.70 & 72.78\(\)0.48 & 79.67\(\)0.81 & 79.23\(\)0.29 & **82.20\(\)0.38** \\ ImageNet-100 & 69.30\(\)0.41 & 65.11\(\)0.32 & 68.43\(\)0.33 & 65.42\(\)0.36 & 65.80\(\)0.49 & 66.85\(\)0.19 & **82.81\(\)0.31** \\   

Table 1: Performance comparison on four tasks. We report the mean accuracy averaged over three seeds, along with standard error. Top scores for each task are highlighted.

  
**Task Name** & **MixMatch** &  **Mixmatch** \\ **+DWD-UT** \\  & **FixMatch** &  **FixMatch** \\ **+DWD-UT** \\  & **MPL** & 
 **MPL** \\ **+DWD-UT** \\  \\  SixAnimal (\(\) = 75\(\%\)) & 80.77\(\)0.11 & **84.72\(\)0.22** & 82.50\(\)0.16 & **87.17\(\)0.19** & 65.62\(\)0.47 & **83.88\(\)0.18** \\ Cifar-10/100 & 71.02\(\)0.32 & **80.47\(\)0.49** & 78.91\(\)0.15 & **83.80\(\)0.25** & 70.95\(\)0.34 & **80.24\(\)0.56** \\ ImageNet-30 & 68.67\(\)0.37 & **85.20\(\)0.10** & 70.07\(\)0.26 & **81.87\(\)0.61** & 72.65\(\)0.70 & **90.20\(\)0.23** \\ ImageNet-100 & 69.30\(\)0.41 & **81.62\(\)0.36** & 65.11\(\)0.32 & **80.38\(\)0.34** & 68.43\(\)0.33 & **75.66\(\)0.26** \\   

Table 2: Performance of standard SSL methods before and after applying DWD-UT. Highlighted scores show significant increases without overlapping intervals.

  
**Task Name** & **OpenMatch** &  **OpenMatch** \\ **+DWD-UT** \\  & **Fix-A-Step** &  **Fix-A-Step** \\ **+DWD-UT** \\  & **IOMatch** & 
 **IOMatch** \\ **+DWD-UT** \\  \\  SixAnimal (\(\) = 75\(\%\)) & 80.34\(\)0.21 & **85.71\(\)0.33** & 85.34\(\)0.17 & **86.68\(\)0.23** & 83.05\(\)0.16 & **87.20\(\)0.13** \\ Cifar-10/100 & 70.15\(\)0.30 & **80.99\(\)0.03** & 74.60\(\)0.31 & **79.02\(\)0.75** & 77.66\(\)0.22 & **83.22\(\)0.16** \\ ImageNet-30 & 72.78\(\)0.48 & **75.28\(\)0.68** & 79.67\(\)0.81 & **82.95\(\)0.45** & 79.23\(\)0.29 & **81.96\(\)0.26** \\ ImageNet-100 & 65.42\(\)0.36 & **80.02\(\)0.45** & 65.80\(\)0.49 & **76.23\(\)0.37** & 66.85\(\)0.19 & **80.19\(\)0.13** \\   

Table 3: Performance of open-set SSL methods before and after applying DWD-UT.

### DWD-SL: Labeled Dataset Augmentation

Table 1 reports the comparative performance of DWD-SL against various baseline SSL methods. The results clearly demonstrate that DWD-SL substantially surpasses the performance of methods for standard SSL. This suggests that DWD successfully captures both the inherent distribution of the labeled data and the diversity of the unlabeled data, yielding highly effective synthetic labeled data for training.

Notably, DWD-SL even achieves competitive or superior results relative to open-set SSL methods. This advantage stems from DWD-SL's ability to transform the diversity of unlabeled data into labeled samples, rather than using this diversity merely as a form of regularization, as seen in baseline SSL methods. For further implementation details, please refer to Appendix C.

### DWD-UT: Unlabeled Dataset Transformation

Table 2 and Table 3 show the impact of DWD-UT on the performances of the baseline SSL methods. From the results, we can confirm that DWD-UT effectively addresses the performance degradation caused by the class distribution mismatch. Notably, the most significant improvement was observed in the MPL method. Given that MPL is based on pseudo-labeling, this result indicates that DWD-UT effectively mitigates the confirmation bias associated with pseudo-labeling of OOD instances in the unlabeled dataset.

Figure 3 shows how performance degrades over the range of \(\) in the SixAnimal task. We can clearly see that using DWD-UT makes SSL methods generally robust to the degree of class distribution mismatch, even though they operate under the assumption that there are no OOD instances in the unlabeled data.

We also remark that DWD-UT further improves the performance of open-set SSL methods. This implies that DWD-UT is orthogonal to the OOD mitigation mechanisms used in open-set SSL methods, offering a distinct contribution in addressing the class distribution mismatch: while most of the open-set SSL methods operate under the detect-and-filter paradigm to focus on excluding the OOD instances due to their negative impact, the diffusion model provides a powerful tool for making up the diversity lost by such exclusion.

It is also notable that DWD-UT frequently outperforms DWD-SL, indicating a synergistic effect between DWD-UT and baseline SSL methods. This may be attributed the underlying data selection mechanism in the SSL methods (e.g. thresholding used in pseudo-labeling, weighting function in filtering-based methods), which also contribute to selectively strengthen the impact of synthetic data.

Additionally, to provide direct evidence of DWD-UT's effectiveness in reducing the class distribution mismatch, we compute the minimum distance between each unlabeled data sample and the class centroids of labeled data in the latent space. We refer Appendix E for the results.

### Ablation Studies

We carried out a series of ablation studies on DWD-UT, assessing different training schemes for the diffusion model and varying noise levels for perturbing seed images. For these studies, we employed MPL as the baseline SSL method.

Table 4 shows the results of ablation studies conducted on different training schemes for the diffusion model. Several observations can be drawn from these results. Firstly, the utilization of the discriminator to filter or reduce the weight of OOD instances culminates in a rather marginal performance improvement. Secondly, the incorporation of the diffusion model to generate synthetic data contributes to a substantial performance surge above the baseline, even when fine-tuned solely

Figure 3: Standard SSL performance with varying \(\).

with the labeled data. This suggests that transforming irrelevant unlabeled data is more effective than simply filtering them out. Lastly, the extra step of fine-tuning the diffusion model with the unlabeled dataset and applying discriminative weighting also offers a nontrivial advantage.

Table 5 shows the variations in performance with different noise levels during the data transformation process. The results indicate that introducing a moderate level of noise (\(t=600 800\)) to the unlabeled data during the forward diffusion process, as opposed to initiating from pure Gaussian noise (\(t=1000\)), enhances performance. Therefore, it can be inferred from these findings that the efficacy of DWD-UT is contingent upon the balance between the level of noise and the information contained in the unperturbed data. We remark that the optimal noise level can differ among data instances. While we fixed the noise level to \(t=600\) in our experiments for simplicity, determining the noise level individually for each sample presents a potential avenue for future research.

### Comparison with Recent Diffusion-based Augmentation Approaches

We conducted further experiments on the ImageNet-30 task to compare the performance of DWD with those of DPT and DA-Fusion. To ensure fairness in comparison, we equalized the implementation of the model structure, data generation process, and the number of augmented data. As shown in Table 6, both DPT and DA-Fusion have demonstrated effectiveness, yet their performance falls short compared to that of DWD. This is because DPT, assuming no distribution shift, sometime generates wrongly labeled synthetic images due to the confirmation bias in pseudo label of OOD unlabeled images, and DA-Fusion only augments given labeled samples with subtle visual details (Please refer to Appendix I for examples). In contrast, DWD synthesizes new labeled samples by transforming diverse unlabeled data, successfully resolving the distribution mismatch.

### Additional Experiments

We also conducted additional experiments to analyze computational costs, investigate the effect of the number of generated data, and assess hyper-parameter sensitivity. For detailed experimental results and analysis, please refer to Appendix F.

  
**Method** & **MixMatch** & **FixMatch** & **MPL** & **DPT** & **DA-Fusion** & **DWD-SL** \\  Accuracy (\%) & 68.67\(\)0.37 & 70.07\(\)0.26 & 72.65\(\)0.70 & 78.28\(\)0.48 & 75.26\(\)0.39 & **82.20\(\)0.28** \\   

Table 6: Performance of standard SSL and generative augmentation methods on ImageNet-30.

   Training Method & SixAnimal & Cifar-10/100 & ImageNet-30 & ImageNet-100 \\  MPL & 65.62 & 70.95 & 72.65 & 68.43 \\ MPL + \(_{}\) & 67.19 & 71.73 & 83.60 & 70.74 \\ MPL + \(_{}[_{l}]\) & 78.70 & 75.33 & 87.44 & 73.38 \\ MPL + \(_{}[_{l},_{u}]\) & 80.78 & 76.79 & 88.09 & 74.12 \\ MPL + \(_{}[_{l},_{u},_{}]\) & **83.88** & **80.24** & **90.20** & **75.66** \\   

Table 4: MPL performance using different training schemes. The notation \(_{}[X]\) indicates the inclusion of component \(X\) in finetuning the diffusion model. MPL + \(_{}\) represents that the discriminator is utilized for filtering unlabeled data.

   Noise Level & \(t=0\) & \(t=200\) & \(t=400\) & \(t=600\) & \(t=800\) & \(t=1000\) \\  Accuracy (\%) & 65.62\(\)0.47 & 73.65\(\)0.28 & 82.03\(\)0.18 & **83.88\(\)0.18** & **83.83\(\)0.11** & 82.06\(\)0.13 \\   

Table 5: MPL performance on SixAnimal with varying noise levels. DWD-UT is not applied at \(t=0\).

Conclusion

In this paper, we highlighted the potential of diffusion models for addressing class distribution mismatch in SSL. We introduced Discriminator-Weighted Diffusion (DWD), a semi-supervised training scheme that leverages a discriminator to identify OOD instances within the unlabeled data, facilitating effective training of the diffusion model. Our qualitative and quantitative results demonstrate that DWD captures both the characteristics of labeled data and the diversity of unlabeled data.

Notably, DWD exhibits a unique capability to convert irrelevant samples into relevant ones, making it compatible with other SSL methods and illustrating the orthogonality of our approach. Our extensive experiments show that DWD significantly enhances SSL performance in scenarios with class distribution mismatch. We hope that DWD will inspire future research focused on addressing distribution mismatch from a data-centric perspective.