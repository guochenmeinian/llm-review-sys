# Evaluating the structure of cognitive tasks

with transfer learning

Bruno Aristimunha\({}^{1,2}\) Raphael Y. de Camargo\({}^{2}\) Walter H. Lopez Pinaya\({}^{3}\)

Sylvain Chevallier\({}^{1}\) Alexandre Gramfort\({}^{1}\) Cedric Rommel\({}^{1,4}\)

\({}^{1}\)Universite Paris-Saclay, Inria, France

\({}^{2}\)Federal University of ABC, Santo Andre, Brazil

\({}^{3}\)King's College London, London, United Kingdom

\({}^{4}\)Valeo.ai, Paris, France

###### Abstract

Electroencephalography (EEG) decoding is a challenging task due to the limited availability of labelled data. While transfer learning is a promising technique to address this challenge, it assumes that transferable data domains and tasks are known, which is not the case in this setting. This study investigates the transferability of deep learning representations between different EEG decoding tasks. We conduct extensive experiments using state-of-the-art decoding models on two recently released EEG datasets, ERP CORE and M\({}^{3}\)CV, containing over 140 subjects and 11 distinct cognitive tasks. We measure the transferability of learned representations by pre-training deep neural networks on one task and assessing their ability to decode subsequent tasks. Our experiments demonstrate that, even with linear probing transfer, significant improvements in decoding performance can be obtained, with gains of up to 28% compared with the pure supervised approach. Additionally, we discover evidence that certain decoding paradigms elicit specific and narrow brain activities, while others benefit from pre-training on a broad range of representations. By revealing which tasks transfer well and demonstrating the benefits of transfer learning for EEG decoding, our findings have practical implications for mitigating data scarcity in this setting. The transfer maps generated also provide insights into the hierarchical relations between cognitive tasks, hence enhancing our understanding of how these tasks are connected from a neuroscientific standpoint.

## 1 Introduction

While brain encoding consists in predicting brain activations given a certain stimulus, brain decoding tackles the inverse problem: translating recorded neural activity into its originating stimulus or behavior . This stimulus or behavior can be a visual or auditory element presented, the subject internal mental state (e.g. sleep stage), or the cognitive or motor task being performed during the experiment. Brain decoding has several important applications, such as the diagnosis of neurological disorders [2; 3; 4], the detection of seizures [5; 6], automatic processing of polysomnographic recordings  and brain-computer interfaces [8; 9; 10], among others. Electroencephalography (EEG) is a common and affordable way to record the neural activity in this context . It has the benefit of being non-invasive, having very high time resolution compared to functional magnetic resonance imaging (fMRI) and not requiring a complex and costly infrastructure such as magnetoencephalography (MEG). In recent years, there has been an increasing interest in using deep learning (DL) models for EEG decoding . As an example, DL has been shown to be the gold standard when it comes toautomatic sleep stage classification  and has also demonstrated impressive performances in brain-computer interfaces .

Unfortunately, DL models are notorious for being data-hungry to extract generalizable discriminative representations. This characteristic can be a problem when it comes to EEG decoding since the acquisition of labelled EEG data remains a constraint, resulting in datasets of limited size. Indeed, EEG annotation often requires a specialist to run experiments or visually inspect recorded signals for specific patterns. In addition, EEG signals have a very low signal-to-noise ratio, especially when we compare to other fields of application which were DL thrived, such as image, speech, and text. This characteristic makes EEG decoding even more challenging for DL methods in the context of small datasets.

A common technique in DL for dealing with scarce data scenarios is transfer learning (TL), which consists in applying what you have learned in one context to another . In other words, it can be used to leverage a large dataset to improve the performance in a related smaller dataset, making it a promising technique to alleviate the lack of EEG decoding data. However, TL assumes the knowledge of transferable data domains and tasks, which is not fully understood when it comes to brain data. Indeed, even beyond EEG decoding, understanding hierarchical relations between cognitive tasks remains a core question in neuroscience.

Inspired by the Taskonomy study  from the computer vision field, this work investigates the relations between cognitive tasks in an EEG decoding setting. Specifically, we measure the transferability of representations learned by DL models between cognitive tasks. This transferability is measured by pre-training DL models to decode the EEG signals of subjects carrying certain tasks and assessing how well a classifier can reuse the learned representations to decode a subsequent task. We carry extensive experiments with three state-of-the-art decoding models  trained and evaluated on two recently released EEG datasets, ERP CORE  and M\({}^{3}\)CV , containing in total over 140 subjects with 11 distinct decoding modalities. This enables us to create transfer maps capturing the relationships between pairs of cognitive tasks, as presented in Figure 1. From an EEG processing perspective, our maps can be used to leverage related datasets for alleviating EEG data scarcity with transfer learning. We show that even with a linear probing transfer method, we are able to boost by up to \(28\%\) the performance of some tasks. From a neuroscientific standpoint, our results broaden our understanding of the connections between cognitive tasks. We discover evidence that some decoding paradigms elicit very specific and narrow brain activities, since no other paradigm transfer well into them. On the other hand, the decoding of some cognitive tasks benefits from pre-training on all other paradigms, thus demonstrating that they rely on a broad range of representations.

## 2 Related Works

Transfer Learning and Taskonomy.Transfer learning refers to the technique of leveraging knowledge acquired from one source domain and task to enhance the performance in another target domain and task . Domain adaptation, domain generalization and self-supervised learning are hence considered sub-fields of TL under this broad definition . The most common TL approach consists in fine-tuning on a target dataset a model that was pre-trained on a source dataset. In this context, the main factor determining the success or failure of TL is the relationship between source and target domains and tasks . Numerous studies have examined the relationship between tasks for TL purposes . One of the most influential works in this area is Taskonomy , which investigates these relationships in the context of computer vision tasks. Although we take great inspiration from it, Taskonomy tries to uncover the relation between _visual learning tasks_, while we focus in relating _cognitive tasks_. In this sense, while Taskonomy works with the same input images, analyzing transfer to different output distributions \(P_{S}(Y) P_{T}(Y)\), our setting is more challenging as we need to transfer between joint distributions of input EEG signals and output decoded stimuli \(P_{S}(X,Y) P_{T}(X,Y)\) (_c.f._ subsection 3.2).

Uncovering cognitive tasks relations with EEG.While we study the transfer between different tasks, most EEG decoding works in transfer learning focus on transfering between different subjects performing the same fixed task . They hence enter in the more specific sub-category of domain adaptation and generalization. Beyond the transfer learning framework, some works have also studied the structure of cognitive tasks from the perspective of self-supervised representations  and invariances shared by different datasets .

Most related to our work, [52; 53; 34; 54] measure the transferability between cognitive tasks, drawing inspiration from the Taskonomy framework . However, these works are all based on fMRI data and most use _encoding_ models for very specific types of visual or language stimuli. In contrast, our work uses EEG _decoding_ models to compare a broader range of stimuli in different modalities. By working with decoding instead of encoding models, our results are not only useful to understand the relation between cognitive tasks, but also to improve the performance of automatic EEG processing systems in real-world scenarios where data is scarce.

## 3 Method

### EEG Decoding

From a machine learning perspective, EEG decoding is defined as a classification problem, where the outputs \(y\) correspond to the stimulus or behavior class and the inputs are EEG recordings \(=^{m c}\) with \(m\) time-steps and \(c\) electrodes. Hence, given a model \(f_{}:\) with parameters \(\) and a training dataset \(_{}=\{(_{i},y_{i})\}_{i=1}^{N_{}}\), training amounts to solving the empirical risk minimization problem:

\[_{}}}_{_{}}( f_{}(_{i}),y_{i}),\] (1)

where \(\) is the balanced cross-entropy loss. The performance of the decoding model \(f_{}\) obtained can then be evaluated over a held-out test set \(_{}\) (_c.f._ Figure 2 A, B, C).

Figure 1: Learned tranferability maps for both datasets with three different DL models. These graphs depict the transferability of representations used for EEG decoding, capturing the intricate interplay between cognitive tasks. Each node corresponds to a distinct paradigm. Arrow width represents the average transfer performance when using the representations learned from a source task to decode a target task. Top figures correspond to ERP CORE (1(a), 1(b), 1(c)) and bottom ones to M\({}^{3}\)CV(1(d), 1(e), 1(f)).

### Transfer learning

More generally, we assume that our dataset corresponds to observations of a joint random variable \((X,Y)\) valued on a space \(\), where some decision function \(f\) exists such that \(Y=f(X)\). Following , a _domain_ is defined by a feature space and inputs distribution \(=\{,P(X)\}\). Likewise, a task consists of an output space and a decision function \(=\{,f\}\). Transfer learning aims to use the knowledge extracted from a source domain \(_{S}\) and task \(_{S}\) to improve the performance of a model \(f_{}\) on another target domain \(_{T}\) and task \(_{T}\). In practice, domains and tasks are materialized by source and target datasets \(_{S}=\{(x_{i},y_{i}) P_{S}(X,Y);Y=f_{S}(X)\}\) and \(_{T}=\{(x_{i},y_{i}) P_{T}(X,Y);Y=f_{T}(X)\}\).

In our context of EEG decoding, the source and target datasets correspond to different cognitive tasks performed by the same cohort of subjects in comparable experimental settings (_c.f._ section 4). Hence, while source and target domains share the same feature space \(=^{m c}\), they differ in terms of marginal distributions of input trial recordings \(P_{S}(X) P_{T}(X)\). Regarding learning tasks, source and target datasets differ in terms of decision functions \(f_{S} f_{T}\) and output spaces \(_{S}_{T}\). As opposed to our setting, Taskonomy  works with a common source and target domains \((_{S},P_{S}(X))=(_{T},P_{T}(X))\).

### Transferability through linear probing

We evaluate the transferability between source and target datasets through _linear probing_[55; 56], as described below. We assume that \(f_{}=h_{} r_{}\) is a neural network made of two parts: a representer model \(r_{}:\), with parameters \(\), and a classifier head \(h_{}:\), with parameters \(\). While the representer \(r_{}\) is responsible for learning useful representations for the learning task, the classifier head \(h_{}\) is just the last linear layer of the network used to deliver the classification decision. When assessing the transferability between a source and target datasets (_c.f._ Figure 2):

Figure 2: **A. Data splitting and alignment. Source and target tasks correspond to different ERP and BCI paradigms; B. EEG decoding models as a representer network and a classification head; C. Standard EEG decoding training and evaluation; D. Transfer with linear probing. Only the classification head \(h_{}\) is re-trained, while the representer network \(r_{w_{S}}\) trained on the source task is kept intact.**1. We first train the whole model \(f_{_{S}}=h_{_{S}} r_{_{S}}\) on the training split of the source dataset \(_{S,}\) by solving equation (1) ;
2. Then we freeze the representer parameters \(_{S}\) and retrain the classifier head \(h_{_{T}}\) from scratch on the training split of the target dataset \(_{T,}\): \[_{T}_{}}}_{_{T, }}\!(h_{}(r_{_{S}}(_{i})),y _{i});\] (2)
3. Finally, we evaluate the network obtained \(h_{_{T}} r_{_{S}}\) on the test split of the target dataset \(_{T,}\) and use this metric to assess the transferability between \(S\) and \(T\).

We evaluate the transferability through linear probing since it assesses whether the representations learned from the source dataset allow us to easily (linearly) classify the target data. In contrast, fine-tuning (_i.e._ pushing the training of the whole model \(h\) and \(r\) further with target data) would modify the learned source representations, which could complicate the analysis .

## 4 Experiments

ERP CORE and M\({}^{3}\)CV datasets.During EEG decoding experiments, subjects perform cognitive tasks with stimuli that evoke specific brain signatures. When the nature of the stimuli is similar, they can be categorized into the same paradigm. EEG decoding studies have been interested in a very large and diverse number of paradigms, which can be categorized as exogenous (where an external stimulus is used _e.g._ event related potential) or endogenous (where stimuli are induced by a predetermined mental task or behavior, _e.g._ motor imagery) . Only a small number of EEG datasets contain recordings in a diverse set of paradigms with the same subjects and configurations. Most existing datasets include a limited number of subjects  or a limited number of cognitive tasks .

In our study, we use two of the few EEG datasets that explore a large diversity of paradigms with a single large cohort of subjects in comparable experimental settings. The first dataset, ERP CORE , comprises \(40\) subjects (\(25\) females and \(15\) males between \(18\) and \(30\) years old). It focuses on exogenous paradigms, featuring seven isolated tasks eliciting specific event-related potential components (ERP), namely Active Visual Oddball (P3b), Word Pair Judgement (N400), Face Perception (N170), Passive Auditory Oddball (MMN), Flankers (LRP and ERN) and Simple Visual Search (N2pc). These tasks are represented in Figure 3 and explained in further details in subsection A.1.

The second dataset, M\({}^{3}\)CV , is a large multi-task, multi-session, multi-subject investigation of EEG commonality and variability. It includes \(106\) subjects who performed specific tasks in six different paradigms. In this work, we only focus on trials for which the subject and task labels were available, namely: Motor Execution (ME), Transient-State Sensory (TSS), Resting-State (RS) and Steady-State Sensory (SSS). This reduces our dataset to \(95\) subjects (\(22\) females and \(73\) males between \(19\) and \(24\) years old) corresponding to the enrolment and calibration subsets of the original dataset.

For this dataset, the definition of labels was straightforward. Decoding labels for the _RS_ task simply corresponded to whether the subjects had their eyes open or closed. For the _TSS_ and _SSS_ tasks, labels were directly defined based on the stimulus presented to the subjects, _i.e._ whether it was a visual, auditory or somatosensory stimulation (3-class classification problem). Likewise, decoding labels of the _ME_ task corresponded to the movement being executed by the subjects, _i.e._ either the right foot, the right hand or the left hand (3-class classification problem).

Data splitting.The datasets were randomly split into a training, a validation, and a test set with respective proportions of \(56\%\), \(24\%\) and \(20\%\). Each split contains data from different subjects since we want to assess the cross-subject generalization of our models. Trainings and evaluations were repeated with different splits following a 5-fold cross-validation scheme.

In the standard decoding experiments (subsection B.1), models were trained and evaluated using data from the same cognitive task (_c.f._ Figure 2 C). In the transfer learning experiments (section 5), models were pre-trained on training subjects of some task \(A\), then fine-tuned through linear probingon data from the same subjects performing a different task \(B\) and finally evaluated on unseen test subjects carrying out this same task \(B\), as described in subsection 3.3 and illustrated in Figure 2 D. Thanks to this data splitting alignment across cognitive tasks, we ensure that the test subjects remain the same after transfer, avoiding any leakage between test and training sets.

Decoding models.We evaluated the transferability of learned tasks using three state-of-the-art deep learning models: ShallowNet , EEGNet , and EEGInception . These architectures delivered state-of-the-art results in several EEG decoding tasks and datasets , and were assessed in a standard setting without transfer in the appendix (subsection B.1). In all our experiments, we used the implementations available in the Braindecode library  with default hyperparameter values. More training and preprocessing details can be found in Appendix A.

## 5 Results and Findings

ERP COREWe now analyse the transfer performance between paradigms to quantify how transferable each cognitive task is in relation to one another. Figure 4(a) shows the obtained balanced accuracy for each pair of source and target cognitive tasks in the ERP CORE dataset. A first intriguing observation is the asymmetry of the transfer matrices obtained, regardless of the model used, indicating that the transferability is highly directional. We can see that some tasks do not transfer well, leading to accuracies close to chance (\(50\%\) in this dataset). Notably, no source task is correctly transferring either to LRP or N400 paradigms. This means that these cognitive tasks rely on very specific representations that are not elicited by the other tasks and are hence erased by models pre-trained on other paradigms.

Conversely, representations learned on LRP seem useful for decoding ERN and MMN, as they lead to accuracies comparable to a model fully trained and evaluated in a standard fashion (diagonal values). This suggests that LRP elicits brain activations common to ERN and MMN, which are learned by the decoding networks into its hidden representations. More strikingly, pre-training on some source tasks (_e.g._ ERN) improves performance on some other target tasks (_e.g._ N170),

Figure 3: Illustration of experiments recorded in ERP CORE (**A** to **F**) and M\({}^{3}\)CV datasets (**G** to **J**). A detailed description of these tasks can be found in subsection A.1.

even _exceeding_ the reference performance of a model fully trained on this target task. The best example of this is the MMN task, whose performance is boosted beyond the reference accuracy when transferring _from all possible source tasks_. With ShallowNet we observe improvements of \(28.3\%,6.1\%,4.6\%,3.7\%,2.7\%\), and \(2.2\%\) for the LRP, N2pc, ERN, N400, P3, and ERN sources.

In order to better visualize these complex connections between tasks, we processed the matrices from Figure 4(a) into transferability maps, shown in Figure 1. Arrows' widths are proportional to corresponding transfer accuracies, where performances close to chance level were omitted (_c.f._ subsection A.5 for details). The figure clearly shows that LRP is a very good source task and that MMN is a great target task. Note that all three different architectures lead to consistent maps overall, evidencing the stability of our findings.

M\({}^{3}\)Cv.Similar asymmetrical transferabilities were obtained for the M\({}^{3}\)CVdataset (_c.f._ Figure 4(b)), the best example being SSS and TSS tasks, which share the same class labels: visual, auditory or somatosensory stimuli. Surprisingly, while SSS transfers well to TSS, the opposite is not true, showing that steady-state signals have a specific footprint uncaptured by transient state representations.

From a paradigms perspective, we can see that no transfer accuracies exceed the reference diagonal values in this dataset. Nonetheless, RS appears as a great target task, benefiting from representations learned in all source tasks. To a smaller extent, TSS also exhibits good performances for all source tasks when using the ShallowNet architecture. We hypothesize that this is only visible for this architecture because it is the only one capable of extracting the information shared by all 4 paradigms, given its superior decoding performance for this dataset (_c.f._ subsection B.1). On the contrary, it appears that it is very difficult to transfer onto the SSS paradigm, the extreme case being obtained with EEGInception, for which the chance accuracy is attained for all sources (\(33\%\) here).

Figure 4: Transfer balanced accuracy for each pair of sources and target cognitive tasks in the ERP CORE and M\({}^{3}\)CVdataset. Cell values correspond to average performance and standard-deviation across 5-fold cross-validation. Diagonal values correspond to standard decoding balanced accuracies, without any transfer (_c.f._ Figure 2 C).

The consistently strong connections towards RS and TSS from all neighboring tasks are more easily seen on the transferability maps of Figure 1, as well as the aforementioned SSS\(\)TSS asymmetry.

## 6 Discussion and impact

Concerning the potential applications, cognitive maps such as Figure 1 can significantly enhance and optimize the training of predictive models. As exemplified in this study, one compelling approach is to leverage a task that exhibits strong transferability as a template for decoding challenging cognitive tasks, as shown for MMN or N170 ERPs. This aspect proves especially crucial in psychophysical experiments, where subject numbers are limited while experimental variables are abundant. These factors seem to be observed in other areas, such as computer vision .

Additionally, the cognitive taxonomy maps can play a pivotal role in the design of improved Human Machine Interfaces (HMIs) for Brain-Computer Interface (BCI) applications. Our focus particularly centers around integrated BCIs , which extend beyond mere control functions and delve into scenarios involving error detection and negative potential. By incorporating insights gained from cognitive mapping, we can significantly enhance the performance and effectiveness of HMIs in such contexts. For example, the detection of ERN could help to mitigate situations where the BCI system selects unwanted commands, resulting in user frustration.

Further discussion on the potential impact of this work for clinical applications, source localization, better functional networks understanding and BCI illiteracy mitigation can be found in Appendix C.

## 7 Conclusion

Our study investigates the transferability of deep learning representations through extensive experiments on two EEG datasets. To our knowledge, our work is the first to construct representation transfer maps for EEG decoding. These maps reveal a complex and asymmetric hierarchical relationship between cognitive tasks, enhancing our understanding of brain decoding and neural representations. Our findings also have very practical implications for mitigating data scarcity, demonstrating performance improvements in real world data.

One limitation of our work is that we focus on ERP and BCI datasets. Future work could hence extend our analysis to a broader range of cognitive tasks, or even investigate the transferabily across datasets that do not share the same cohort of subjects. Other interesting avenues for investigation could be the study of other types of transferability, for example by carrying out a similar analysis in a self-supervised setting.