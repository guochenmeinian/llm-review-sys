# Partial Multi-Label Learning with Probabilistic Graphical Disambiguation

Jun-Yi Hang, Min-Ling Zhang

School of Computer Science and Engineering, Southeast University, Nanjing 210096, China

Key Laboratory of Computer Network and Information Integration (Southeast University),

Ministry of Education, China

{hangjy, zhangml}@seu.edu.cn

Corresponding author

###### Abstract

In partial multi-label learning (PML), each training example is associated with a set of candidate labels, among which only some labels are valid. As a common strategy to tackle PML problem, _disambiguation_ aims to recover the ground-truth labeling information from such inaccurate annotations. However, existing approaches mainly rely on heuristics or ad-hoc rules to disambiguate candidate labels, which may not be universal enough in complicated real-world scenarios. To provide a principled way for disambiguation, we make a first attempt to explore the probabilistic graphical model for PML problem, where a directed graph is tailored to infer latent ground-truth labeling information from the generative process of partial multi-label data. Under the framework of stochastic gradient variational Bayes, a unified variational lower bound is derived for this graphical model, which is further relaxed probabilistically so that the desired prediction model can be induced with simultaneously identified ground-truth labeling information. Comprehensive experiments on multiple synthetic and real-world data sets show that our approach outperforms the state-of-the-art counterparts.

## 1 Introduction

Partial multi-label learning aims to induce a multi-label predictor from inaccurately annotated examples, where a set of candidate labels is assigned to each training example but only some of these candidate ones are valid. The problem of PML naturally arises in many real-world applications [39; 51; 52; 20]. For instance, as shown in Figure 1, the data collected from the crowdsourcing platform is inevitable to contain inaccurate supervision information due to potential unreliable annotators, where invalid labels exist in the set of candidate labels.

Formally, let \(=^{d}\) denote the input space and \(=\{l_{1},l_{2},,l_{t}\}\) denote the label space with \(t\) class labels. A partial multi-label example is denoted as \((,S)\), where \(\) is its feature vector and \(S\) is its set of candidate labels. As a basic assumption of PML, the ground-truth labels reside in the candidate label set, i.e. \(Y S\), and are concealed from the learning algorithm. Given a partial multi-label data set \(=\{(_{i},_{i})|1 i m\}\), the goal of PML is to derive a multi-label predictor \(h: 2^{}\) which can accurately predict all the ground-truth labels for an unseen instance.

A straightforward strategy for tackling the problem of PML is to simply treat all the candidate labels as valid ones and then apply off-the-shelf multi-label learning approaches [50; 23] to induce the predictor. This naive strategy is obviously suboptimal as the learning process will be significantly misled by the noisy labels in the candidate label set.

Considering that the ground-truth labels are concealed in the candidate label set, it is a common strategy of existing approaches to learn from partial multi-label data by disambiguation, i.e. recovering the ground-truth labeling information from candidate labels. The basic idea of disambiguation is to estimate the labeling confidence for each candidate label from observed inaccurately annotated examples, which reflects how likely the candidate label can be a ground-truth one. For example, some approaches introduce the smoothness assumption to directly elicit the labeling confidence via label propagation [48; 26], label enhancement [31; 41], or cluster assignment [39; 3], etc. While some other works heuristically believe that the noisy labels in the candidate label set are generally sparse, so that the noisy label matrix [30; 29] or the noisy label identifier  can be learned with sparsity regularization. Although feasible results have been achieved in these approaches, a potential limitation is that they rely on heuristics or ad-hoc rules for disambiguation, which may not be widely applicable in some challenging scenarios. For example, sparsity on underlying noisy labels can hardly be satisfied in some extremely low-quality annotation scenarios.

To improve this, we explore a principled manner for disambiguation, which is regarded as a task of latent variable inference in this paper. Accordingly, a novel partial multi-label learning approach named Pard, i.e. Partial multi-label learning with probAbilistic-gRaphical **D**isambiguation, is presented. By regarding the concealed ground-truth labels as latent variable, a directed graphical model is tailored to describe the generative process of partial multi-label data. With the directed graphical model, a unified variational lower bound of the data log-likelihood is derived via variational inference, which allows to disambiguate the candidate labels and induce the prediction model simultaneously. Specifically, the ground-truth labeling information is identified by fitting the generative model of PML data, where the intrinsic structure information of data can be captured for principled disambiguation. While the desired prediction model is optimized with a confidence-smoothed cross entropy loss. Comprehensive experimental studies show that our approach performs better than well-established PML algorithms.

The rest of this paper is organized as follows. Section 2 briefly reviews related works. Section 3 presents details of the proposed Pard approach. Section 4 reports experimental results over a wide range of synthetic and real-world data sets. Section 5 concludes this paper.

## 2 Related Work

Partial multi-label learning is an emerging weakly-supervised learning problem, which has received wide attention in recent years [39; 40; 36]. Here, we would like to first make a brief review on two closely related learning problems, i.e. _multi-label learning_[50; 23] and _partial label learning_[6; 24].

Multi-label learning (MLL) deals with the problem where an example can be associated with multiple labels simultaneously. According to the order of label correlations considered, existing MLL approaches can be grouped into three categories, including _first-order approaches_ which treat each class label independently [2; 14], _second-order approaches_ which explore label correlations between pairwise class labels [8; 53], and _high-order approaches_ which consider label correlations among a subset or the whole set of class labels [32; 44]. With the same goal, both MLL and PML aim to learn a multi-label predictor from multi-semantic objects. Nevertheless, the key difference between these

Figure 1: An exemplary partial multi-label learning scenario. Among the set of 7 candidate labels given by crowdsourcing annotators, only 4 labels are valid including _tree_, _light_, _mountain_, and _road_.

two learning problems lies in whether the ground-truth labels are accessible or not during the learning process, which also makes PML more challenging than MLL since the supervision information is inaccurate.

Partial label learning (PLL) deals with the problem where each example is associated with multiple candidate labels, among which only one is valid. The problem of PLL can be tackled in several different strategies, such as transforming into well-studied supervised learning problems [49; 34], disambiguating the candidate labels [9; 45; 43], or learning with theoretically consistent algorithms [24; 10], etc. Conceptually speaking, PLL and PML possess similar form of supervision, where false positive labels reside in the candidate label set. However, the task of PML is more complicated than PLL since the desired predictor is a multi-label one in PML instead of a single-label one in PLL and the number of ground-truth labels is further unknown.

To solve the PML problem, the most commonly employed strategy is disambiguation, i.e. recovering the ground-truth labeling information from candidate labels. Existing approaches mainly rely on some heuristics or ad-hoc rules to disambiguate candidate labels, which can be roughly grouped into three categories in terms of the heuristics or rules exploited, including _smoothness assumption-based approaches_, _low-rank constraint-based approaches_, and _sparsity regularization-based approaches_. The first category of approaches rely on smoothness assumption that close instances may share similar labels for disambiguation. As a seminal work, an iterative procedure is proposed in  to optimize the labeling confidence of each candidate label and the prediction model alternatively, where the labeling confidence scores are obtained by assuming cluster structures exist in the feature space. Follow-up works employ smoothness assumption to design different disambiguation mechanisms, such as propagating labels in a graph based on instance similarity [48; 26], recovering numerical labels with label enhancement [31; 41; 42], or performing implicit disambiguation by jointly embedding . Low-rank constraint-based approaches turn to the low-rank property for disambiguation. For example, low-rank matrix decomposition is exploited to recover the ground-truth labeling information in  and a low-rank subspace is learned in  to elicit credible labels from improved subspace representations. While sparsity regularization-based approaches [30; 29; 35] impose sparsity on noises hiding in candidate label set, which facilitate the disambiguation in a roundabout manner. A potential limitation of these approaches is that the above heuristics or ad-hoc rules can be hardly held in some challenging scenarios, which may lead to suboptimal performance of induced prediction model.

Therefore, it is quite natural to consider whether it is possible to perform disambiguation in a principled manner, which is still an underexplored direction with only a few attempts. PML-GAN  recovers ground-truth labeling information with an instance reconstruction process, corresponding to a minimax adversarial game to implicitly model instance distribution. While MILI-PML  disambiguates candidate labels by maximizing the mutual information between features and identified ground-truth labels. With a totally different methodology, our approach regards disambiguation as a task of latent variable inference, which is formalized in a maximum likelihood framework with a concise variational lower bound of the log-likelihood on observed PML data. As another pioneer work towards this direction, PML-MD  devises a meta-learning framework, where disambiguation is performed with the guidance from an accurately annotated validation set. Moving one step forward, we make a first attempt to tackle the problem via modelling the generative process of partial multi-label data with a tailored directed graphical model. Compared with PML-MD, our approach is more flexible since there is no need to include a clean validation set for disambiguation, which may not be easily accessible in many real-world scenarios. We will detail our approach in the next section.

## 3 The Pard Approach

### Overview

To tackle the problem of partial multi-label learning, Pard disambiguates the candidate labels and induces the prediction model simultaneously by optimizing towards a unified variational lower bound of the data log-likelihood. In the following content, we will present the tailored directed graphical model which describes the generative process of partial multi-label data. Then, we derive a variational lower bound of the data log-likelihood and further explain how to relate it with disambiguation and predictor induction. Finally, essential implementation issues w.r.t. the optimization procedure are detailed.

Some necessary notations have been introduced in section 1. For notation briefness, a \(t\)-dimensional indicator vector \(\{0,1\}^{t}\) is utilized to denote the set of candidate labels \(S\), where \(s_{k}=1\) indicates \(l_{k} S\) and \(s_{k}=0\) otherwise. Similarly, a \(t\)-dimensional indicator vector \(\{0,1\}^{t}\) is utilized to denote the set of ground-truth labels \(Y\).

### Probabilistic Graphical Disambiguation Framework

Considering that only the instance and its associated candidate labels can be observed in the partial multi-label training set, we tailor a directed graphical model to describe the generative process of partial multi-label data, which involves an unobserved latent variable \(\) as the ground-truth labels. The generative process consists of three steps: (1) sample an instance \(\) from the marginal distribution \(p_{}()\); (2) sample a latent \(\) as the ground-truth labels of the instance \(\) from the ground-truth class posterior distribution \(p_{}(|)\); (3) corrupt the instance's ground-truth labels to obtain its candidate labels \(\) by \(p_{}(|,)\). Accordingly, the joint probability \(p_{}(,,)\) can be factorized as

\[p_{}(,,)=p_{}()p_{} (|)p_{}(|,).\] (1)

Given the partial multi-label training set \(\), the above directed graphical model can be learned via maximizing the log-likelihood on the observed data. However, it is generally challenging to directly estimate the parameter of a directed graphical model by likelihood maximization due to computational intractability . To make the optimization tractable, the variational lower bound of the log-likelihood2 is derived as follows

\[ p_{}(|)(,; ,)=_{q_{}(|,)}[ p_{ }(|,)]-[q_{}(| ,)\|p_{}(|)],\] (2)

where \([||]\) denotes the KL-divergence between two distributions. Here, the meaning of the ground-truth class posterior distribution \(p_{}(|)\) is comprehensible, which is actually the desired prediction model3. While the variational posterior \(q_{}(|,)\) (a.k.a. inference model) attempts to disambiguate the candidate label set by inferring the most probable ground-truth labels from which the candidate labels could have been corrupted given the instance \(\). Correspondingly, \(p_{}(|,)\) (a.k.a. generative model) corrupts the identified ground-truth labels to recover the observed candidate labels.

To move one step further for comprehending the learning behavior of the above three models, we reformulate the variational lower bound via unfolding the KL-divergence term

\[(,;,)= \,_{q_{}(|,)}[ p_ {}(|,)]+H[q_{}(|, )]\] \[+_{q_{}(|,)}[ p_ {}(|)],\] (4)

where \(H[]\) denotes the entropy of a distribution. In the above objective, the first two terms present an entropy-regularized autoencoder process (w.r.t. \(\)), with which the intrinsic structure information of data can be captured and utilized for disambiguation. While the last term is actually a cross entropy loss for inducing the prediction model with identified ground-truth labeling information \(q_{}(|,)\). By optimizing all these terms in a unified variational lower bound, the models can gradually capture the underlying generative process of partial multi-label data, so that the candidate label set is disambiguated and the desired prediction model is induced simultaneously.

### Additional Training Techniques

In this section, we present additional techniques that allow the derived variational lower bound to be optimized efficiently.

**Inputs:** Training set \(=\{(_{i},S_{i})|1 i m\}\), batch size \(b\) and maximal iteration \(T\).

**Process:**

```
1: Initialize model parameters \(,\);
2:for\(t=1:T\)do
3: Sample a batch of training examples \(=\{(_{i_{k}},S_{i_{k}})|1 k b\}\) from training set \(\);
4: Compute unbiased estimator of the variational lower bound on \(\) by Eq. (6) and Eq. (7);
5: Update model parameters \(,\) via gradient ascent.
6:endfor ```

**Outputs:** Model parameters \(,\). ```

**Algorithm 1** Pseudocode of the Optimization Procedure for Pard

Continuous Relaxing with Gumbel-Softmax Trick.It is quite challenging to compute the first expectation term in Eq. (3). Actually, it has a high complexity of \((2^{t})\) to analytically compute the first expectation term in Eq. (3), since the ground-truth labels \(\) can take \(2^{t}\) different values. In addition, estimating it by Monte Carlo sampling is non-differentiable, since sampling from discrete variational posterior \(q_{}(|,)\) prevents gradients from flowing through the inference model.

To circumvent this problem, we exploit _Gumbel-Softmax trick_ to smooth the sampling process so that the expectation term can be efficiently estimated by Monte Carlo sampling in a differentiable manner. Specifically, the Bernoulli variable \(\) is relaxed by the binary Concrete variable \( BinConcrete(,)\), which is a continuous alternative with the reparameterization form as

\[=+1)/]},\] (5)

where \(=}{1-}\) and \(\) is the parameter of the multivariate Bernoulli distribution \(q_{}(|,)\). \(1\) is a sampling from Logistic distribution and \(>0\) is a temperature parameter. In the limit \( 0\), a binary Concrete variable smoothly converges to its Bernoulli counterpart. With the above sampling trick, an unbiased estimation of the expectation term can be obtained and gradients w.r.t. the distribution parameter \(\) (or w.r.t. the parameter of the inference model equivalently) are well-defined by the chain rule

\[&_{q_{}(|, )}[ p_{}(|,)]_{i=1}^{L} p_{}(|,^{(i)})\\ & where^{(i)} BinConcrete(,). \] (6)

Closed-Form Solution of the KL-Divergence Term.The KL-divergence term in Eq. (3) can not be integrated analytically in general cases. To make it tractable, we exploit mean-field approximation technique and derive a closed-form solution of the KL-divergence term as follows

\[&[q_{}(|, )||p_{}(|)]=_{k=1}^{t}p_{}^{y_{k} }^{y_{k}}}{p_{}^{y_{k}}}+(1-p_{}^{y_{k}})^{y_{k}}}{1-p_{}^{y_{k}}},\] (7)

where \(p_{}^{y_{k}}=q_{}(y_{k}=1|,)\) and \(p_{}^{y_{k}}=p_{}(y_{k}=1|)\). Detailed derivation process can be found in Appendix C.

With these training techniques, the derived variational lower bound can be straightforwardly optimized with standard stochastic gradient methods. Algorithm 1 summarizes the pseudocode of the optimization procedure, where the candidate labels and the prediction model are updated simultaneously.

## 4 Experiments

### Experimental Setup

#### 4.1.1 Data Sets

For comprehensive performance evaluation, five real-world and a number of synthetic PML data sets are employed in this paper. Table 1 summarizes detailed characteristics of each data set. Specifically,the first five data sets are real-world PML data sets, where candidate labels are collected from web users and manually examined to specify the ground-truth labels. While the last five data sets, including _corel5k_, _rcv1-s1_, _Corel16k-s1_, _iaprtc12_ and _espgame_, are multi-label data sets.

Following , a synthetic PML data set is generated from one multi-label data set by adding random labeling noise. Accordingly, for data sets with more than 100 class labels, we filter out their rare labels to keep the 15 most frequent labels and remove instances without relevant labels. Then, we randomly flip the irrelevant labels of an instance until the number of irrelevant labels in the set of candidate labels equals to \(\%\) number of ground-truth labels. We vary the value of \(\) in the range of \(\{100,150,200,250\}\), so that a total of \(5 4=20\) synthetic PML data sets are generated for experimental studies.

#### 4.1.2 Evaluation Metrics

Five widely-used evaluation metrics for multi-label learning are employed to evaluate the performance of each approach, including _Average precision_, _Hamming loss_, _One-error_, _Coverage_ and _Ranking loss_. Detailed definitions on these metrics can be found in .

#### 4.1.3 Implementation Details

The inference model \(q_{}(|,)\) and the generative model \(p_{}(|,)\) are instantiated by fully-connected neural networks with ReLU activations, where the hidden dimensionalities are set to \([256;512;256]\) and \([256;512]\) respectively. For fair comparison with existing PML approaches, the prediction model is implemented as a linear model. To compute the objective function in Eq. (3), a trade-off parameter \(\) is introduced for the KL-divergence term and Monte Carlo sampling with sampling number \(L=1\) is conducted to estimate the first expectation term, where the temperature parameter \(=2/3\) as suggested by . In the following experiments, we set \( 1\) so that the objective function is still a valid lower bound of the data log-likelihood. For network optimization, Adam with a batch size of 128, weight decay of \(10^{-4}\), momentums of 0.999 and 0.9 is employed. In this paper, all experiments are conducted on one V100 GPU.

### Comparative Studies

Pard4 is compared against six well-established PML approaches with parameter configurations suggested in respective literatures:

* Fpml : Fpml employs the low-rank approximation of the instance-label association matrix to estimate the labeling confidence and then trains multi-label predictor. [\(_{1}=0.1,_{2}=1,_{3}=10\)]

   Dataset & \#Examples & \#Features & \#Class Labels & Cardinality & Domain \\  YeastBP & 6139 & 6139 & 217 & 5.54 & Biology1 \\ YeastCC & 6139 & 6139 & 50 & 1.35 & Biology1 \\ YeastMF & 6139 & 6139 & 39 & 1.01 & Biology1 \\ Music\_emotion & 6833 & 98 & 11 & 2.42 & Music1 \\ Music\_style & 6839 & 98 & 10 & 1.44 & Music1 \\   corel5k & 5000 & 499 & 374 & 3.52 & Images2 \\ rcv1-s1 & 6000 & 944 & 101 & 2.88 & Text2 \\ Corel16k-s1 & 13766 & 500 & 153 & 2.86 & Images2 \\ iaprtc12 & 19627 & 1000 & 291 & 5.72 & Images3 \\ epsgame & 20770 & 1000 & 268 & 4.69 & Images3 \\   

* http://palm.seu.edu.cn/zhangml/
* http://mulan.sourceforge.net/datasets.html
* http://lear.inrialpes.fr/people/guillaumin/data.php

Table 1: Characteristics of the experimental data sets. The first five ones are real-world PML data sets and the last five ones are multi-label data sets employed to generate synthetic PML data sets.

[MISSING_PAGE_FAIL:7]

* Across all evaluation metrics, Pard achieves the best performance in 82.4% cases over all the 25 data sets.
* As shown in Table 4, Pard achieves statistically better performance against other approaches which rely on heuristics or ad-hoc rules for disambiguation. The superior performance of Pard is consistent across almost all real-world data sets and synthetic data sets under varied noise levels, which provides a strong evidence for the effectiveness of probabilistic graphical disambiguation to facilitate partial multi-label learning.
* Meantime, Pard significantly outperforms Pml-md which also disambiguates PML data in a principled manner. Note that Pml-md requires an accurately annotated validation set to perform disambiguation during the learning process. The superior performance of Pard against Pml-md indicates that Pard is an effective and more flexible approach for principled disambiguation.

### Further Analyses

#### 4.3.1 Ablation Study

To validate that the disambiguation process in Pard is effective for facilitating partial multi-label learning, we implement a baseline which induces prediction model with cross-entropy loss by directly treating all the candidate labels as valid ones. As shown in Figure 2, a clear performance degradation

   } & Fpml &  & Pml-ni & Pml-md &  &  \\  _Average precision_ & **win** [1.2e-5] & **win** [1.2e-5] & **win** [1.8e-5] & **win** [1.2e-5] & **win** [1.7e-5] & **win** [1.2e-5] \\ _Hamming loss_ & **win** [8.2e-3] & **win** [4.6e-5] & **win** [2.1e-5] & **win** [8.5e-5] & **tie** [7.0e-1] & **win** [3.5e-5] \\ _One-error_ & **win** [1.2e-5] & **win** [1.2e-5] & **win** [4.6e-5] & **win** [1.2e-5] & **win** [1.8e-4] & **win** [1.2e-5] \\ _Coverage_ & **win** [1.2e-5] & **win** [1.2e-5] & **win** [1.4e-5] & **win** [1.2e-5] & **win** [2.4e-5] & **win** [4.0e-5] \\ _Ranking loss_ & **win** [1.2e-5] & **win** [1.2e-5] & **win** [1.2e-5] & **win** [1.2e-5] & **win** [1.2e-5] & **win** [2.0e-5] & **win** [2.5e-5] \\   

Table 4: Summary of the Wilcoxon signed-ranks test for Pard against other comparing approaches at 0.05 significance level. \(p\)-values are shown in the brackets.

   } &  &  &  & {is witnessed in the baseline model, which demonstrates the disambiguation process induced from the variational lower bound can facilitate partial multi-label learning.

#### 4.3.2 Parameter Sensitivity

Figure 3 gives some illustrative examples on how the performance of Pard changes when the value of the trade-off parameter \(\) changes. The performance of Pard is relatively stable as the value of \(\) changes within a reasonable range, which is a desirable property when deploying Pard in real-world applications. Similar results can be observed on other data sets.

#### 4.3.3 Running Time Comparision

For Pard, the training phase only involves a pair of forward and backward computations among the inference, generative and prediction models, which is efficient thanks to the training techniques presented in section 3.3. Figure 4 illustrates the empirical training and test time of each comparing approach, which shows that Pard is competitive with exisiting approaches in time overhead.

Figure 4: Running time (training/test) of each comparing approach on real-world data sets. For histogram illustration, the \(y\)-axis corresponds to the logarithm of running time.

Figure 3: Validation performance of Pard with varying trade-off parameter \(\).

Figure 2: Predictive performance of Pard and the baseline in terms of _Average precision_ and _Ranking loss_ on real-world data sets.

## 5 Limitation

Our primary focus is on partial multi-label learning in this paper. However, there are other weakly-supervised multi-label learning problems that receive increasing attention from related community. The probabilistic graphical disambiguation framework of Pard currently has not been tested on these problems, such as learning with partial labels which deals with incompletely annotated data [7; 19; 1; 4], learning with single positive label which aims to induce an accurate multi-label predictor from multi-label data annotated with only one positive labels [5; 28; 15; 38; 16; 22], and learning with general noisy labels where noise may exist in every label of inaccurately annotated data [18; 21; 36]. In addition, we do not implement Pard and investigate its behavior in large model environment, which are also important to practitioners. We will explore these points in the future.

## 6 Conclusion

In this paper, an attempt towards principled disambiguation for partial multi-label learning is presented, where a directed graphical model is tailored to describe the generative process of partial multi-label data. By maximizing the data log-likelihood on given partial multi-label data set with a unified surrogate objective derived by variational inference, Pard achieves to disambiguate the candidate label set and induce the prediction model simultaneously. Comprehensive experiments show the superiority of our approach. Since disambiguation lies in the heart of partial multi-label learning, we hope that Pard will encourage more future researches to explore alternative implementations for principled disambiguation.