# Reliable Learning of Halfspaces under Gaussian marginals

Ilias Diakonikolas

University of Wisconsin-Madison

ilias@cs.wisc.edu

&Lisheng Ren

University of Wisconsin-Madison

lren29@wisc.edu

&Nikos Zarifis

University of Wisconsin-Madison

zarifis@wisc.edu

###### Abstract

We study the problem of PAC learning halfspaces in the reliable agnostic model of Kalai et al. (2012). The reliable PAC model captures learning scenarios where one type of error is costlier than the others. Our main positive result is a new algorithm for reliable learning of Gaussian halfspaces on \(^{d}\) with sample and computational complexity

\[d^{O((\{1/,1/\}))}(2^{(1/)^{O((1/ ))}},2^{(1/)})\,\]

where \(\) is the excess error and \(\) is the bias of the optimal halfspace. We complement our upper bound with a Statistical Query lower bound suggesting that the \(d^{((1/))}\) dependence is best possible. Conceptually, our results imply a strong computational separation between reliable agnostic learning and standard agnostic learning of halfspaces in the Gaussian setting.

## 1 Introduction

Halfspaces (or Linear Threshold Functions) is the class of functions \(f:^{d}\{ 1\}\) of the form \(f()=(,-t)\), where \(^{d}\) is called the weight vector and \(t\) is called the threshold. The problem of learning halfspaces is one of the classical and most well-studied problems in machine learning--going back to the Perceptron algorithm --and has had great impact on many other influential techniques, including SVMs  and AdaBoost .

Here we focus on learning halfspaces from random labeled examples. The computational complexity of this task crucially depends on the choice of the underlying model. For example, in the realizable PAC model (i.e., with clean labels), the problem is known to be efficiently solvable (see, e.g., ) via a reduction to linear programming. Unfortunately, this method is quite fragile and breaks down in the presence of noisy labels. In the noisy setting, the computational complexity of the problem depends on the choice of noise model and distributional assumptions. In this work, we study the problem of distribution-specific PAC learning of halfspaces, with respect to Gaussian marginals, in the reliable agnostic model of . Formally, we have the following definition.

**Definition 1.1** ((Positive) Reliable Learning of Gaussian Halfspaces).: _Let \(_{d}\) be the class of halfspaces on \(^{d}\). Given \(0<<1\) and i.i.d. samples \((,y)\) from a distribution \(D\) supported on \(^{d}\{ 1\}\), where the marginal \(D_{}\) is the standard Gaussian \((,)\), we say that an algorithm reliably learns \(_{d}\) to error \(\) if the algorithm with high probability outputs a hypothesis \(h:^{d}\{ 1\}\) such that \(_{(,y) D}[h()=1 y=-1]\) and \(_{(,y) D}[h()=-1 y=1]+\)_where \(}}{{=}}_{f(D)} _{(,y) D}[f()=-1 y=1]\), with_

\[(D)=\{f_{d}:_{(,y) D}[f()= 1 y=-1]=0\}\{f()=-1\}\.\]

_We say that \(f=*{argmin}_{f(D)}_{(,y) D }[f()=-1 y=1]\) is the optimal halfspace on distribution \(D\) and for the conditions above that hypothesis \(h\) satisfies, we say that \(h\) is \(\)-reliable with respect to \(_{d}\) on distribution \(D\)._

In other words, a (positive) reliable learner makes almost no false positive errors, while also maintaining the best possible false negative error--as compared to any hypothesis with no false positive errors. Note that if there is no hypothesis (in the target class) that makes no false positive errors, then essentially we have no requirement for the false negative error of the returned hypothesis. The algorithm can then simply return the \(-1\) constant hypothesis.

The reliable agnostic PAC model was introduced by  as a one-sided analogue of the classical agnostic model , and has since been extensively studied in a range of works; see, e.g., . The underlying motivation for this definition comes from learning situations where mistakes of one type (e.g., false positive) should be avoided at all costs. Typical examples include spam detection--where incorrectly detecting spam emails is much less costly than mislabeling an important email as spam--and detecting network failures--where false negatives may be particularly harmful. Such scenarios motivate the study of reliable learning, which can be viewed as minimizing a loss function for different costs for false positive and false negative errors (see, e.g., ). In a historical context, reliable learning is related to the Neyman-Pearson criterion  in hypothesis testing, which shows that the optimal strategy to minimize one type of error subject to another type of error being bounded is to threshold the likelihood ratio function. More recently, reliable learning has been shown  to be equivalent to the PQ-learning model --a recently introduced learning model motivated by covariance shift.

The algorithmic task of agnostic reliable learning can be quite challenging. While reliable learning can be viewed as minimizing a loss function with different cost for false positive and false negative error, in general, such a loss function will result in a non-convex optimization problem. As pointed out in , distribution-specific reliable learning can be efficiently reduced to distribution-specific agnostic learning (such reduction preserves the marginal distribution). A natural question, serving as a motivation for this work, is whether reliable learning is qualitatively easier computationally--for natural concept classes and halfspaces in particular.

Before we state our contributions, we briefly summarize prior work on agnostically learning Gaussian halfspaces. Recall that, in agnostic learning, the goal is to output a hypothesis with error \(+\), where \(\) is the optimal 0-1 error within the target class. Prior work has essentially characterized the computational complexity of agnostically learning Gaussian halfspaces. Specifically, it is known that the \(L_{1}\) polynomial regression algorithm of  is an agnostic learner with complexity \(d^{O(1/^{2})}\). Moreover, there is strong evidence that this complexity upper bound is tight, both in the Statistical Query (SQ) model  and under plausible cryptographic assumptions . It is worth noting that the aforementioned hardness results hold even for the subclass of homogeneous halfspaces.

Given the aforementioned reduction of reliable learning to agnostic learning , one can use \(L_{1}\)-regression as a reliable agnostic learner for Gaussian halfspaces, leading to complexity \(d^{O(1/^{2})}\). Prior to this work, this was the best (and only known) reliable halfspace learner. Given the fundamental nature of this problem, it is natural to ask if one can do better for reliable learning.

_Is it possible to develop faster algorithms for reliably learning Gaussian halfspaces compared to agnostic learning?_

In this work, we provide an affirmative answer to this question.

To formally state our main result, we need the notion of the bias of a Boolean function.

**Definition 1.2** (Bias of Boolean Function).: _We define the bias \([0,1/2]\) of \(h:^{d}\{ 1\}\) under the Gaussian distribution as \(=(h)}}{{=}}(_{ _{d}}[h()=1],_{ _{d}}[h()=-1])\)._

The main result of this paper is encapsulated in the following theorem:

**Theorem 1.3** (Main Result).: _Let \(D\) be a joint distribution of \((,y)\) supported on \(^{d}\{ 1\}\) with marginal \(D_{}=_{d}\) and let \(\) be the bias of the optimal halfspace on distribution \(D\) (with respect to Definition 1.1). There is an algorithm that uses \(N=d^{O((\{1/,1/\}))}(2^{(1/)^{O( (1/)}},2^{(1/)})\) many samples from \(D\), runs in \((N,d)\) time, and with high probability returns a hypothesis \(h()=(,-t)\) that is \(\)-reliable with respect to \(_{d}\). Moreover, for \(</2\), any SQ algorithm for the problem requires complexity \(d^{((1/))}\)._

For more detailed theorem statements of our upper and lower bounds, see Appendix B for the algorithmic result and Appendix C for the SQ hardness result.

Theorem 1.3 gives a significantly more efficient algorithm (in terms of both sample complexity and computational complexity) for reliably learning Gaussian halfspaces, compared to agnostic learning. Specifically, as long as \(>0\) is a universal constant, the overall complexity is polynomial in \(d\) and quasi-polynomial in \(1/\)--as opposed to \(d^{(1/)}\) in the agnostic setting. While the complexity of our algorithm (namely, the multiplicative factor that is independent of \(d\)) increases as the optimal halfspace becomes more biased, it is always bounded above by the complexity of agnostic learning.

Finally, we note that our algorithm also applies to the fully reliable learning model , since one can easily reduce the fully reliable learning to positive reliable and negative reliable learning (as observed in ).

### Overview of Techniques

Instead of directly considering the optimal halfspace for a distribution \(D\) (as defined in Definition 1.1), we introduce the following definition as a relaxation.

**Definition 1.4** (Reliability Condition).: _We say that a distribution \(D\) supported on \(X\{ 1\}\) satisfies the reliability condition with respect to \(f:X\{ 1\}\) if \(_{(,y) D}[f()=+1 y=-1]=0\)._

Notice that \(h\) being \(\)-reliable on distribution \(D\) is equivalent to \(h\) having better false negative error compared with any \(f\) such that \(D\) satisfies the reliability condition with respect to \(f\) (instead of compared with the optimal halfspace). At the same time, given any fixed \(f\), such a definition allows the adversary to arbitrarily corrupt negative labels, thus allowing for more manageable analysis.

We start with a brief overview of our SQ lower bound construction, followed by the high-level idea enabling our nearly matching algorithm.

SQ Lower BoundAs follows from Definition 1.4 and the subsequent discussion, the adversary in reliable learning can arbitrarily corrupt the negative labels. We leverage this idea to construct an instance where the corruption level suffices to match many moments, meaning that labels \(y\) are uncorrelated with any polynomial of degree at most \((1/)\). To prove this, we construct an (infinite) feasibility Linear Program (LP) with the following properties: if the LP is feasible, there exists an instance for which no low-degree polynomial correlates with the labels; see Lemma 3.3. To show the existence of such an instance, we leverage a technique from  that exploits (an infinite generalization of) LP duality. Specifically, we show that it is possible to add noise to the labels whose uncorrupted value is negative so that all low-degree moments are uncorrelated with the observed labels \(y\). This implies that no algorithm that relies on low-degree polynomials can succeed for reliable learning. This allows us to show that SQ algorithms fail if they do not use queries with tolerance at most \(1/d^{((1/))}\) or exponentially many queries.

Reliable Learning AlgorithmAs discussed in the previous paragraph, an adversary can arbitrarily corrupt the negative labels which can make various algorithmic approaches fail. In more detail, the adversary can corrupt \(((1/))\) moments; that is, any SQ algorithm needs to rely on higher-order moment information. One of the main difficulties of this setting is that there may exist weight vectors \(,^{}\) with \(\|-^{}\|_{2}(1)\) while at the same time the 0-1 error of \(\) and \(^{}\) is nearly the same. This might suggest that no approach can verify that the algorithm decreases the angle between the current weight vector and the optimal vector. To overcome this obstacle, we develop an algorithm that performs a random walk over a "low-dimensional" subspace. To establish the correctness of ouralgorithm, we prove that at some point during its execution, the algorithm will find a weight vector sufficiently close to the optimal vector.

To show that such a low-dimensional subspace exists, we proceed as follows: We first prove that there exists a non-trivial polynomial \(p\) of degree \(O((1/))\) that correlates with the negative labels (by the term nontrivial, we are referring to the requirement that we cannot use the constant polynomial, as this trivially correlates with the labels); see Claim B.5. This implies that the low-degree moment tensors, i.e., \(_{(,y)}[\{y=-1\}^{  k}]\) for some \(k\) between \(1\) and \(O((1/))\), correlate non-trivially with \((^{*})^{ k}\), where \(^{*}\) is the target weight vector. Thus, we can use these moment tensors to construct a low-dimensional subspace. We leverage the structure of the problem, namely that the (observed) negative labels are uncorrupted, to show that the correlation is in fact almost constant. As a consequence, this allows us to construct a subspace whose dimension depends only on the degree of the polynomial \(p\) (which is \(O((1/))\)) and the desired excess error \(\).

We then proceed as follows: in each round, as long as the current solution \(\) is not optimal, i.e., there are negative samples on the region \(\{^{d}:-t 0\}\), our algorithm conditions on a thin strip, projects the points \(\) on the orthogonal complement of \(\), and reapplies the above structure result. This leads (with constant probability) to an increase in the correlation between \(\) and \(^{*}\). Assuming that the correlation is increased by \(\) in each round with probability at least \(1/3\), we roughly need at most \(1/\) successful updates. Therefore, if we run our algorithm for \(3^{1/}\) steps, it is guaranteed that with probability at least \(1/3\) we will find a vector almost parallel to \(^{*}\).

Prior Algorithmic TechniquesRoughly speaking, prior techniques for reliable learning relied on some variant of \(L_{1}\)-regression. In that sense, our algorithmic approach departs from a direct polynomial approximation. Concretely, for distribution-free reliable learning, the algorithm from  uses a one-sided variant of \(L_{1}\) regression--where instead of approximating the target function in \(L_{1}\) norm, they use the hinge loss instead. For distribution-specific (and Gaussian in particular) reliable learning of halfspaces, the only previous approach uses the reduction of  to agnostic learning. While our algorithm also leverages polynomial approximation, our approach employs significantly different ideas and we believe it provides a novel perspective for this problem.

Technical Comparison with Prior WorkOur algorithm shares similarities with the algorithm of  for learning Gaussian halfspaces with Massart noise (a weaker semi-random noise model). Both algorithms perform a random walk in order to converge to the target halfpace. Having said so, our algorithm is fundamentally different than theirs for the following reasons. The algorithm of  partitions \(^{d}\) into sufficiently angles and searches in each one of them for a direction to update the current hypothesis at random. Our algorithm instead conditions on \(y=-1\), which are the points that are uncorrupted, and uses the guarantee (that we establish) that the first \(((1/))\) moments of the distribution (conditioned on \(y=-1\)) correlate with the unknown optimal hypothesis. This leads to an algorithm with significantly faster runtime.

Our SQ lower bound leverages techniques from . Essentially, we formulate a linear program to construct a noise function that makes all low-degree polynomials uncorrelated with the labels \(y\). This condition suffices to show that no SQ algorithm can solve the problem without relying on higher moments. To prove the existence of such a noise function, we use (a generalization of) LP duality of an infinite LP, which provides the necessary conditions for the existence of such a function.

### Related Work

This work is part of the broader research program of characterizing the efficient learnability of natural concept classes with respect to challenging noise models. The complexity of this general learning task depends on the underlying class, the distributional assumptions and the choice of noise model. A long line of prior work has made substantial progress in this direction for the class of halfspaces under Gaussians (and other natural distributions), and for both semi-random  and adversarial noise . An arguably surprising conceptual implication of our results is that the complexity of reliable learning for Gaussian halfspaces is qualitatively closer to the semi-random case.

### Preliminaries

We use lowercase boldface letters for vectors and capitalized boldface letters for matrices and tensors. We use \(,\) for the inner product between \(,^{d}\). For \(,^{d}\), we use \(_{}()}}{{=}},}{\|\|_{ 2}^{2}}\) for the projection of \(\) on the \(\) direction. Similarly, we use \(_{}()=-_{}()\) for the projection of \(\) on the orthogonal complement of \(\). Additionally, let \(^{V}^{(V)}\) be the projection of \(\) on the subspace \(V\) and reparameterized on \(^{(V)}\). More precisely, let \(_{V}^{d(V)}\) be the matrix whose columns form an (arbitrary) orthonormal basis for the subspace \(V\), and let \(^{V}}}{{=}}(_{V})^{ }\). For \(p 1\) and \(^{d}\), we use \(\|\|_{p}}}{{=}}(_{i=1} ^{n}|_{i}|^{p})^{1/p}\) to denote the \(_{p}\)-norm of \(\). For a matrix or tensor \(\), we denote by \(\|\|_{F}\) the Frobenius norm of \(\).

We use \(_{d}\) to denote the standard normal distribution \((,)\), where \(\) is the \(d\)-dimensional zero vector and \(\) is the \(d d\) identity matrix. We use \( D\) to denote a random variable with distribution \(D\). For a random variable \(\) (resp. a distribution \(D\)), we use \(P_{}\) (resp. \(P_{D}\)) to denote the probability density function or probability mass function of the random variable \(\) (resp. distribution \(D\)). We also use \(:\) to denote the cdf function of \(_{1}\). We use \(\) to denote the indicator function.

For a boolean function \(h:^{d}\{ 1\}\) and a distribution \(D\) supported on \(^{d}\{ 1\}\), we use \(R_{+}(h;D)}}{{=}}_{(, y) D}[h()=1 y 1]\) (resp. \(R_{-}(h;D)}}{{=}}_{(, y) D}[h()=-1 y-1]\)) to denote the false positive (resp. false negative) 0-1 error.

## 2 Algorithm for Reliably Learning Gaussian Halfspaces

In this section, we describe and analyze our algorithm establishing Theorem1.3. Due to space limitations, some proofs have been deferred to AppendixB. For convenience, we will assume that \(\) (the bias of the optimal halfspace) is known to the algorithm and that the excess error satisfies \(/3\). These assumptions are without loss of generality for the following reasons: First, one can efficiently reduce the unknown \(\) case to the case that \(\) is known, by guessing the value of \(\). Second, if \(\) is large, there is a straightforward algorithm for the problem (simply output the best constant hypothesis).

**Notation:** We use the notation \(_{d}^{}\) for the set of all LTFs on \(^{d}\) whose bias is equal to \(\). Given the above assumptions, it suffices for us to give a reliable learning algorithm for \(_{d}^{}\) instead of \(_{d}\).

The high-level idea of the algorithm is as follows. Without loss of generality, we assume that there exists an \(\)-biased halfspace that correctly classifies all the points with label \(y=-1\)--since otherwise the algorithm can just return the hypothesis \(h()-1\).

Let \(f()=(^{*},-t^{*})\) be the optimal halfspace and let \(\) be our current guess of \(^{*}\). Assuming that \(^{*}\) is not sufficiently close to \(\) and the hypothesis that classifies all the points as negative is not optimal, we show that there exists a low-degree polynomial of the form \(p(,)\) with correlation at least \(2^{-O(t^{*2})}\) with the negative labels. By leveraging this structural result, we use a spectral algorithm to find a direction \(\) that is non-trivially correlated with \(_{}(^{*})\) with at least some constant probability.

Unfortunately, it is not easy to verify whether \(,_{}(^{*})\) is non-trivial. However, conditioned on the algorithm always getting a \(\) that has good correlation, we show that it only takes at most \((1/)^{O(t^{*2})}\) steps to get sufficiently close to \(^{*}\). Therefore, repeating this process \(2^{(1/)^{O(t^{*2})}}\) many times will eventually find an accurate approximation to \(^{*}\).

The structure of this section is as follows: In Section2.1, we give our algorithm for finding a good direction. Section2.2 describes and analyzes our random walk procedure.

### Finding a Non-Trivial Direction

Here we present an algorithm that finds a direction that correlates non-trivially with the unknown optimal vector. We first show that there exists a zero-mean \(O((1/))\)-degree polynomial that sign-matches the optimal hypothesis. Furthermore, using the fact that the optimal hypothesis alwayscorrectly guesses the sign of the negative points, this gives us that the polynomial correlates with the negative (clean) points. Using this intuition, our algorithm estimates the first \(O((1/))\) moments of the distribution \(D_{}\) conditioned on \(y=-1\). This guarantees that at least one moment correlates with the optimal hypothesis, as a linear combination of the moments generates the sign-matching polynomial. Then, by taking a random vector that lies in the high-influence directions (which form a low-dimensional subspace), we guarantee that with constant probability, this vector correlates well with the unknown optimal vector. The main result of the section is the following.

**Proposition 2.1**.: _Let \(D\) be a joint distribution of \((,y)\) supported on \(^{d}\{ 1\}\) with marginal \(D_{}=_{d}\) and \((0,1)\). Suppose \(D\) satisfies the reliability condition with respect to \(f()=(^{*},-t^{ *})\) with \(t^{*}=O()\) and \(_{(,y) D}[y=-1]\). Then there is an algorithm that draws \(N=d^{O(t^{*^{2}})}/^{2}\) samples, has \((N)\) runtime, and with probability at least \((1)\) returns a unit vector \(\) such that \(,^{*}((1/)^{-O(t^{*^{2} })},^{O(1)})\)._

We start by showing that for any distribution satisfying the reliability condition with respect to some \(f()=(^{*},-t^ {*})\), there exists a degree-\(O(t^{*^{2}})\) zero-mean polynomial of the form \(p(^{*},)\) that has correlation at least \(2^{-O(t^{*^{2}})}\,_{(,y) D}[y=-1]\) with the labels.

**Lemma 2.2** (Correlation with an Orthonormal Polynomial).: _Let \(D\) be a joint distribution of \((,y)\) supported on \(^{d}\{ 1\}\) with marginal \(D_{}=_{d}\). Suppose \(D\) satisfies the reliability condition with respect to \(f()=(^{*},-t^ {*})\). Then there exists a polynomial \(p:\) of degree at most \(k=O(t^{*^{2}}+1)\) such that \(_{z_{1}}[p(z)]=0\), \(_{z_{1}}[p^{2}(z)]=1\) and \(_{(,y) D}[y\,p(^{*}, )]=2^{-O(t^{*^{2}})}\,_{(,y) D}[y=-1]\)._

Proof Sketch of Lemma 2.2.: Note that since \(p\) is a zero-mean polynomial with respect to \(D_{}\), we have that \(_{(,y) D}[y\,p(^{*}, )]=-2\,_{(,y) D}[(y=-1)\,p(^{*},)]\). Then, using the fact that the distribution \(D\) satisfies the reliability condition, the statement boils down to showing that for any \(\)-mass inside the interval \([t^{*},]\), the expectation of \(p\) on this \(\) mass is at least \(2^{-O(t^{*^{2}})}\). To prove this statement, it suffices to construct a polynomial \(p\) that is non-negative on \([t^{*},]\) and such that the \(/2\)-tail of \(p\) in that interval is at least \(2^{-O(t^{*^{2}})}\). To achieve this, we show that the sign-matching polynomial used in  meets our purpose. 

Our algorithm uses the following normalized Hermite tensor.

**Definition 2.3** (Hermite Tensor).: _For \(k\) and \(^{d}\), we define the \(k\)-th Hermite tensor as_

\[(_{k}())_{i_{1},i_{2},,i_{k}}=} _{\\ }_{\{a,b\} P}(- _{i_{a},i_{b}})_{\{c\} P}_{i_{c}}\;.\]

Given that there is such a polynomial, we show that if we take a flattened version of the Chow-parameter tensors (which turns them into matrices) and look at the space spanned by their top singular vectors, then a non-trivial fraction of \(^{*}\) must lie inside this subspace. We prove the following lemma, which is similar to Lemma 5.10 in . See Appendix B for the proof.

**Lemma 2.4**.: _Let \(D\) be the joint distribution of \((,y)\) supported on \(^{d}\{ 1\}\) with marginal \(D_{}=_{d}\). Let \(p:\) be a univariate, mean zero and unit variance polynomial of degree \(k\) such that for some unit vector \(^{*}^{d}\) it holds \(_{(,y) D}[(y=-1)p(^{*}, )]\) for some \((0,1]\). Let \(^{ m}\) be an approximation of the order-\(m\) Chow-parameter tensor \(^{m}=_{(,y) D}[(y=-1)_{m} ()]\) such that \(\|^{ m}-^{m}\|_{F}/(4)\). Denote by \(V_{m}\) the subspace spanned by the left singular vectors of flattened \(^{ m}\) whose singular values are greater than \(/(4)\). Moreover, denote by \(V\) the union of \(V_{1},,V_{k}\). Then, for \(=_{(,y) D}[y=-1]\), we have that_

1. \((V)=O(^{2}(1/)^{k}k^{2}/^{2}+1)\)_, and_
2. \(\|_{V}(^{*})\|_{2}=(/( (1/)^{k/2}))\)_._

By Lemma 2.4, taking a random unit vector \(\) in \(V\) will give us \(,^{*}\|_{V}(^{*})\|/\). We are ready to prove Proposition 2.1. For the algorithm pseudocode, see Appendix B.

Proof Sketch of Proposition 2.1.: The idea is that the empirical estimate \(^{ m}\) obtained using

\[d^{O(\{t^{*},2,1\})}(1/)/^{2}\]

 many samples will satisfy \(\|^{ m}-^{m}\|_{F}/(4)\) with high probability. Then, by Lemma 2.2 and Lemma 2.4, if we take \(\) to be a random unit vector in \(V\), with constant probability we will have \(,^{*}=(1/)^{-O(t^{*})}\). For \(,^{*}=^{O(1)}\), the proof relies on a different version of Lemma 2.4. 

### Random Walk to Update Current Guess

We now describe how we use Proposition 2.1 to construct an algorithm for our learning problem. Let \(\) be the current guess for \(^{*}\). For convenience, we assume that \(,^{*}=(1/)\). Let \(D^{}\) be the distribution of \(^{}\) conditioned on \( B\), where \(B=\{^{d}:,-t^{*}  0\}\). We next show that the \(\)-marginals of \(D^{}\) are standard Gaussian and that \(D^{}\) satisfies the reliability condition with respect to the halfspace \(h()=(^{}, -t^{})\) with \(^{}=^{*}\) and \(|t^{}||t^{*}|\).

**Lemma 2.5**.: _Let \(D\) be the joint distribution of \((,y)\) supported on \(^{d}\{ 1\}\) with marginal \(D_{}=_{d}\) and \((0,1)\). Suppose \(D\) satisfies the reliability condition with respect to \(f()=(^{*},-t^{*})\). Suppose that \(h()=(,-t)\) with \(,^{*}>0\) and \(t-t^{*}[0,/100]\) does not satisfy \(R_{h}^{+}(D)/2\). Let \(B=\{^{d}:,-t 0\}\) and \(D^{}\) be the distribution of \((^{},y)=(^{},y)\) given \( B\), then_

1. \(D^{}\) _has marginal distribution_ \(D_{^{}}=_{d-1}\)_,_
2. \(D^{}\) _satisfies the reliability condition with respect to_ \(h^{}()=(^{},-t^{})\)_, where_ \(^{}=^{*}/\|^{* }\|_{2}\) _and_ \(|t^{}||t^{*}|\)_, and_
3. \(_{(^{},y) D^{}}[y=-1]/2\)_._

Proof Sketch of Lemma 2.5.: Item 1 follows by definition. For Item 2, we consider two cases: \(t^{*}>0\); and \(t^{*} 0\). For the case \(t^{*} 0\), we prove that the distribution \(D^{}\) satisfies the reliability condition with respect to \(h^{}()=(^{},)\), where \(^{}=^{*}/\|^{* }\|_{2}\). For the case \(t^{*}>0\), we prove that the distribution \(D^{}\) satisfies the reliability condition with respect to \(h^{}()=(^{}, -t^{})\), where \(^{}=^{*}/\|^{* }\|_{2}\) and \(t^{}=t^{*}\). Then Item 3 follows from the fact that \(h\) does not satisfy \(R_{h}^{+}(D)/2\). 

By Lemma 2.5, given any current guess \(\) such that \(h()=(,-t^{*})\) does not satisfy \(R_{+}(h;D)/2\), the corresponding distribution \(D^{}\) satisfies the reliability condition with respect to \(h^{}\) and \(_{(,y) D^{}}[y=-1]/2\). Therefore, \(D^{}\) satisfies the assumptions of Proposition 2.1. So, if we apply the algorithm in Proposition 2.1, we will with probability at least \((1)\) get a unit vector \(\) such that \(,=0\) and \(,^{*}=(1/)^{-O(t^{*})}\).

The following fact shows that by updating our current guess in the direction of \(\) with appropriate step size, we can get an updated guess with increased correlation with \(^{*}\).

**Fact 2.6** (Correlation Improvement, Lemma 5.13 in ).: _Fix unit vectors \(^{*},^{d}\). Let \(^{d}\) such that \(,^{*} c\), \(,=0\) and \(\|\|_{2} 1\) with \(c>0\). Then, for \(^{}=+}{\|+ \|_{2}}\), with \(=c/2\), we have that \(^{},^{*},^{*}+^{2}/2\)._

Notice that because \(\|_{}(^{*})\|_{2}\) is unknown, we cannot always choose the optimal step size \(\). Instead, we will use the same \(\) to do sufficiently many update steps such that after that many updates, we are certain that \(\|_{}(^{*})\|_{2} 3\). We then take the new step size \(_{}=/2\) and repeat this process, until \(\) and \(^{*}\) are sufficiently close to each other.

We are now ready to describe our algorithm (Algorithm 1) and prove its correctness.

Notice that given that we know the bias \(\), \(t\) must be either \(-^{-1}()\) or \(^{-1}()\). For convenience, we assume that \(t=^{-1}()\). To account for the case that \(t=-^{-1}()\), we can simply run Algorithm 1 twice and pick the output halfspace with the smallest \(t\) value (or even run a different efficient algorithm, since \(t 0\) as explained in Appendix B). For convenience, we also assume \((2^{(1/)^{O((1/))}},2^{(1/)} )=2^{(1/)^{O((1/))}}\). To account for the other case, we can simply initialize the step size \(=^{c}\) for a sufficiently large constant \(c\) instead of \(=(1/)^{-ct^{*}^{2}}\)Proof Sketch of the algorithmic part of Theorem 1.3.: Let \(f()=(^{*},-t^{*})\) be the optimal halfspace with \(\) bias. We need to show that with high probability Algorithm 1 returns a hypothesis \(h()=(,-t)\) such that \(R_{+}(h;D)\) and \(R_{-}(h;D) R_{-}(f;D)+\).

To do so, it suffices to show that \(R_{+}(h;D)\); given \(R_{+}(h;D)\), \(R_{-}(h;D) R_{-}(f;D)+\) follows from our choice of \(t\). For convenience, we can assume \(h\) never satisfies \(R_{+}(h;D)/2\) in Step (2a) (otherwise, we are done). We can also assume that the subroutine in Proposition 2.1 always succeeds since the algorithm repeats Step (2) sufficiently many times. Given the above conditions, using Fact 2.6, one can show that each time after \(c/^{2}\) many updates in Step (2b), we must have \(\|_{}^{*}\|_{2} 3\). Therefore, when we have \(/100\), then \(\|_{}^{*}\|_{2} 3/100\), which implies \(R_{+}(h;D)/2\). 

## 3 Nearly Matching SQ Lower Bound

In this section, we establish the SQ hardness result of Theorem 1.3. Due to space limitations, some proofs have been deferred to Appendix C.

Proof OverviewTo establish our SQ lower bound for reliable learning, we first prove an SQ lower bound for a natural decision version of reliably learning \(\)-biased LTFs. We define the following decision problem over distributions.

**Definition 3.1** (Decision Problem over Distributions).: _Let \(D\) be a fixed distribution and \(\) be a distribution family. We denote by \((,D)\) the decision problem in which the input distribution \(D^{}\) is promised to satisfy either (a) \(D^{}=D\) or (b) \(D^{}\), and the goal is to distinguish the two cases with high probability._

We show that given SQ access to a joint distribution \(D\) of \((,y)\) supported on \(^{d}\{ 1\}\) with marginal \(D_{}=(,)\), it is hard to solve the problem \((,D)\) with the following distributions.

1. Null hypothesis: \(D\) is the distribution so that \(y=1\) with probability \(1/2\) independent of \(\).

2. Alternative hypothesis: \(D\), where \(\) is a family of distributions such that for any distribution \(D\), there exists an \(\)-biased LTF \(f\) such that \(R_{+}(f;D)=0\).

In order to construct such a family of distributions \(\), we start by constructing a joint distribution \(D^{}\) of \((z,y)\) over \(\{ 1\}\) such that the marginal distribution of \(z\) is \(_{1}\) and the conditional distributions \(z y=1\) and \(z y=-1\) both match many moments with the standard Gaussian \(_{1}\). Moreover, there is \(\) probability mass on the positive side of the marginal distribution of \(z\) that is purely associated with \(y=1\) (i.e., \(_{(z,y) D}[y z c]=1\) where \(c=^{-1}(1-)\)). We then embed this distribution \(D\) along a hidden direction inside the joint distribution of \((,y)\) on \(^{d}\{ 1\}\) to construct a family of hard-to-distinguish distributions using the "hidden-direction" framework developed in  and enhanced in .

We can now proceed with the details of the proof. We start by defining the pairwise correlation between distributions.

**Definition 3.2** (Pairwise Correlation).: _The pairwise correlation of two distributions with pdfs \(D_{1},D_{2}:^{d}_{+}\) with respect to a distribution with density \(D:^{d}_{+}\), where the support of \(D\) contains the support of \(D_{1}\) and \(D_{2}\), is defined as \(_{D}(D_{1},D_{2})}}{{=}}_{ ^{d}}D_{1}()D_{2}()/D()d-1\). Furthermore, the \(\)-squared divergence of \(D_{1}\) to \(D\) is defined as \(^{2}(D_{1},D)}}{{=}}_{D}(D_{1},D_ {1})\)._

In particular, the framework in  allows us to construct a family of \(2^{d^{(1)}}\) distributions on \(^{d}\{ 1\}\) whose pairwise correlation is \(d^{-(n)}\) where \(n\) is the number of matching moments \(D^{}\) has with the standard Gaussian. Then, using standard SQ dimension techniques, this gives an SQ lower bound for the distinguishing problem. After that, we reduce the distinguishing problem to the problem of reliably learning \(\)-biased LTFs under Gaussian marginals with additive error \(</3\).

In order to construct such a distribution \(D^{}\) of \((z,y)\) supported on \(\{ 1\}\), we reparameterize \(_{(z,y) D^{}}[y|z]\) as \(g(z)\). For a function \(g:\), we use \(\|g\|_{p}=_{t_{1}}[|g(t)|^{p}]^{1/p}\) for its \(L_{p}\) norm. We let \(L^{1}(R)\) denote the set of all functions \(g:\) that have finite \(L_{1}\)-norm.

We use linear programming over one-dimensional functions in \(L^{1}()\) space to establish the existence of such a function. Specifically, we show the following:

**Lemma 3.3**.: _For any sufficiently large \(n\), there exists a function \(g:[-1,+1]\) such that \(g\) satisfies the following properties:_

1. \(g(z)=1\) _for all_ \(z c\)_, where_ \(c=^{-1}(1-3^{-2n}/4)\)_, and_
2. \(_{t_{1}}[g(z)z^{k}]=0\) _for all_ \(k[n]\)_._

Proof Sketch of Lemma 3.3.: We let \(P_{n}\) denote the set of all polynomials \(p:\) of degree at most \(n\) and let \(L^{1}_{+}()\) denote the set of all nonnegative functions in \(L^{1}()\). Then, using linear programming, we will get the following primal:

\[&g L^{1}()\\ &_{z_{1}}[p(z)g(z)]=0\,& p P_{n}\\ &_{z_{1}}[g(z)h(z)\{t c\}]\|h(z) \{z c\}\|_{1}\,& h L^{1}_{+}()\\ &_{z_{1}}[g(z)H(z)]\|H\|_{1}\,& H L^{1}( )\]

Then, using (infinite-dimensional) LP duality, we get that the above primal is feasible if and only if there is no polynomial of degree \(n\) such that \(_{t_{1}}[|p(t)|(t c)]<_{t _{1}}[p(t)(t c)]\).

Using Gaussian hypercontractivity (see ), one can show that for every polynomial \(p\) and \(c\), it holds

\[_{z_{1}}[|p(z)|]<2 3^{n}\,_{1}}{}[|p(z)|](_{1}}{ }[z c])^{1/2}\.\]

From our choice of the parameter \(c\), we have that \(_{z_{1}}[z c] 3^{-2n}/4\); thus, \(_{z_{1}}[|p(z)|]<_{z_{1}}[|p( z)|]\), which is a contradiction. Therefore, such a polynomial \(p\) cannot exist.

We have proven the existence of the function \(g\) in Lemma3.3. Now, we construct a joint distribution of \((z,y)\) on \(\{ 1\}\) such that \([y|z]\) is exactly \(g\), as we discussed in the proof outline. For a joint distribution \(D\) of \((x,y)\) supported on \(X\{ 1\}\), we will use \(D_{+}\) to denote the conditional distribution of \(x\) given \(y=1\); and \(D_{-}\) for the distribution of \(x\) given \(y=-1\).

**Lemma 3.4**.: _For any sufficiently large \(n\), there exists a distribution \(D\) on \(\{ 1\}\) such that for \((z,y) D\):_

1. _the marginal distribution_ \(D_{z}=_{1}\)_;_
2. \(_{(z,y) D}[y|z=z^{}]=1\) _for all_ \(z^{}^{-1}(1-3^{-2n}/4)\)_;_
3. \(_{(z,y) D}[y]=0\) _and_ \(_{(z,y) D}[z^{k}]=_{(z,y) D}[z^{k} y=1]= _{(z,y) D}[z^{k} y=-1]\) _for all_ \(k[n]\)_;_
4. \(^{2}(D_{+},_{1}),^{2}(D_{-},_{1})=O(1)\)_._

Proof Sketch for Lemma3.4.: The properties here directly follow from the properties of \(g\). 

Using the framework introduced in , we can construct a set of alternative hypothesis distributions \(=\{D_{}: V\}\) on \(^{d}\{ 1\}\), where \(V\) is a set of exponentially many pairwise nearly-orthogonal vectors and the marginal distribution of each \(D_{}\) on direction \(\) is the distribution \(D\) in Lemma3.4. This effectively embeds the distribution \(D\) in a hidden direction \(\). The size of the family \(\) is exponential in \(d\), and the distributions in it have small pairwise correlations. The details of \(\) are deferred to AppendixC. Now, we are ready to give a proof sketch for the SQ hardness part of our main theorem1.3.

Proof Sketch of the SQ hardness part of Theorem1.3.: Let \(\) be the set of distributions discussed above. We also let \(D_{}\) be the joint distribution of \((,y)\) such that \(_{d}\) and \(y(1/2)\) independent of \(\). Then, using standard SQ dimension techniques, one can show that any SQ algorithm that solves \((,D_{})\) requires either queries of tolerance at most \(d^{-()}\) or makes at least \(2^{d^{(1)}}\) queries. By reducing the decision problem \((,D_{})\) to reliably learning \(\)-biased LTFs with \(</3\) accuracy, we get the lower bound part of the statement in Theorem1.3. 

## 4 Conclusions and Open Problems

In this paper, we study the problem of learning halfspaces under Gaussian marginals in the reliable learning model. Our main contribution is the design of the first efficient learner for this task whose complexity beats the complexity of agnostically learning this concept class. Moreover, we provide rigorous evidence, via an SQ lower bound, that no fully-polynomial time algorithm exists for general halfspaces. The obvious open question is whether the dependence on \(\) in the complexity of our algorithm can be improved. Specifically, is it possible to design a reliable learner with complexity \(d^{((1/))}(1/)\)? Is it possible to obtain similarly efficient reliable learners under more general marginal distributions (e.g., strongly log-concave or discrete distributions)? More broadly, it would be interesting to characterize the computational separation between (distribution-specific) reliable and agnostic learning for other natural concept classes.

Acknowledgements

ID was supported in part by NSF Medium Award CCF-2107079 and an H.I. Rommes Faculty Fellowship. LR was supported in part by NSF Medium Award CCF-2107079. NZ was supported in part by NSF Medium Award CCF-2107079.