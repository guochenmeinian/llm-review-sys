# From Alexnet to Transformers:

Measuring the Non-linearity of Deep Neural Networks

with Affine Optimal Transport

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

In the last decade, we have witnessed the introduction of several novel deep neural network (DNN) architectures exhibiting ever-increasing performance across diverse tasks. Explaining the upward trend of their performance, however, remains difficult as different DNN architectures of comparable depth and width - common factors associated with their expressive power - may exhibit a drastically different performance even when trained on the same dataset. In this paper, we introduce the concept of the non-linearity signature of DNN, the first theoretically sound solution for approximately measuring the non-linearity of deep neural networks. Built upon a score derived from closed-form optimal transport mappings, this signature provides a better understanding of the inner workings of a wide range of DNN architectures and learning paradigms, with a particular emphasis on the computer vision task. We provide extensive experimental results that highlight the practical usefulness of the proposed non-linearity signature and its potential for long-reaching implications.

## 1 Introduction

Deep neural networks (DNNs) are undoubtedly the most powerful AI models currently available [1; 2; 3; 4; 5]. Their performance on many tasks, including natural language processing (NLP)  and computer vision , is already on par or exceeds that of a human being. One of the reasons explaining such progress is of course the increasing computational resources [8; 9]. Another one is the endeavour for finding ever more efficient neural architectures pursued by researchers over the last decade. As of today, the transformer architecture  has firmly imposed itself as a number one choice for most, if not all, of the recent breakthroughs [11; 12; 13] in the machine learning and artificial intelligence fields.

LimitationsBut why transformers are more capable than other architectures? Answering this question requires finding a meaningful measure to compare the different famous models over time gauging the trend of their intrinsic capacity. For such a comparison to be informative, it is particularly appropriate to consider the computer vision field that produced many of the landmark neural architectures improving upon each other over the years. Indeed, the decade-long revival of deep learning started with Alexnet's  architecture, the winner of the ImageNet Large Scale Visual Recognition Challenge  in 2012. By achieving a significant improvement over the traditional approaches, Alexnet was the first truly deep neural network to be trained on a dataset of such scale, suggesting that deeper models were likely to bring even more gains. In the following years, researchers proposed novel ways to train deeper models with hundreds of layers [16; 17; 18; 19] pushing the performance frontier even further. The AI research landscape then reached a turningpoint with the proposal of transformers , starting their unprecedented dominance first in NLP and then in computer vision . Surprisingly, transformers are not particularly deep, and the size of their landmark vision architecture is comparable to that of Alexnet, and this despite a significant performance gap between the two. Ultimately, this gap should be explained by the differences in the expressive power  of the two models: a term used to denote the ability of a DNN to approximate functions of a certain complexity. Unfortunately, the existing theoretical results related to this either associate higher expressive power with depth [22; 23; 24] or width [25; 26; 27; 28] falling short in comparing different families of architectures. This, in turn, limits our ability to understand what underpins the achieved progress and what challenges and limitations still exist in the field, guiding future research efforts.

ContributionsWe argue that quantifying the non-linearity of a DNN may be what we were missing so far to understand the evolution of the deep learning models at a more fine-grained level. To verify this hypothesis in practice, we put forward the following contributions:

1. We propose a first theoretically sound measure, called the affinity score, that estimates the non-linearity of a given (activation) function using optimal transport (OT) theory. We use the proposed affinity score to introduce the concept of the non-linearity signature of DNNs defined as a set of affinity scores of all its activation functions.
2. We compare non-linearity signatures of a wide range of popular DNNs used in computer vision: from Alexnet to vision transformers (ViT) and their more recent variations. Through this, we clearly illustrate the disruptive patterns in the evolution of the deep learning field.
3. We demonstrate that non-linearity signature can be predictive of DNNs performance and used to meaningfully identify the family of approaches to which a given DNN belongs. We further show that the non-linearity signature is unique as it doesn't correlate strongly with other potential candidates used for this task.

The rest of the paper is organized as follows. We start by presenting the relevant background knowledge on OT in Section 2. Then, we introduce the affinity score together with its different theoretical properties in Section 3. Section 4 presents experimental evaluations on a wide range of popular convolutional neural networks. Finally, we conclude in Section 5.

## 2 Background

Optimal TransportLet \((X,d)\) be a metric space equipped with a lower semi-continuous _cost function_\(c:X X_{ 0}\), e.g the Euclidean distance \(c(x,y)=\|x-y\|\). Then, the Kantorovich formulation of the OT problem between two probability measures \(,(X)\) is given by

\[_{c}(,)=_{(,)}_{ }[c],\] (1)

where \((,)\) is the set of joint probabilities with marginals \(\) and \(\), and \(_{}[f]\) denotes the expected value of \(f\) under \(\). The optimal \(\) minimizing equation 1 is called the _OT plan_. Denote by \((X)\) the law of a random variable \(X\). Then, the OT problem extends to random variables \(X,Y\) and we write \(_{c}(X,Y)\) meaning \(_{c}((X),(Y))\).

Assuming that either of the considered measures is _absolutely continuous_, then the Kantorovich problem is equivalent to the _Monge problem_

\[_{c}(,)=_{T:T_{\#}=}_{X}[c(X,T(X))],\] (2)

where the unique minimizing \(T\) is called the _OT map_, and \(T_{\#}\) denotes the _push-forward measure_, which is equivalent to the _law_ of \(T(X)\), where \(X\).

Wasserstein distanceLet \(X\) be a random variable over \(^{d}\) satisfying \([\|X-x_{0}\|^{2}]<\) for some \(x_{0}^{d}\), and thus for any \(x^{d}\). We denote this class of random variables by \(_{2}(^{d})\). Then, the \(2\)-Wasserstein distance \(W_{2}\) between \(X,Y_{2}(^{d})\) is defined as

\[W_{2}(X,Y)=_{||x-y||^{2}}(X,Y)^{}.\] (3)

We now proceed to the presentation of our main contribution.

Non-linearity signature of deep neural networks

Among all non-linear operations introduced into DNNs in the last several decades, activation functions remain the only structural piece that they all inevitably share. Without non-linear activation functions, most of DNNs, no matter how deep, reduce to a linear function unable to learn complex patterns. Activation functions were also early identified  as a key to making even a shallow network capable of approximating any function, however complex it may be, to arbitrary precision.

We thus build our study on the following intuition: if activation functions play in important role in making DNNs non-linear, then measuring their degree of non-linearity can provide us with an approximation of the DNN's non-linearity itself. To implement this intuition in practice, however, we first need to find a way to measure the non-linearity of an activation function. Surprisingly, there is no widely accepted measure for this, neither in the field of mathematics nor in the field of computer science. To fill this gap, we will use the OT theory to develop a so-called _affinity score_ below.

### Affinity score

IdentifiabilityWe consider the pre-activation signal \(X\) of an activation function within a neural network, and the post-activation signal \((X)\) denoted by \(Y\) as input and output random variables. Our first step to build the affinity score then is to ensure that we can identify when \(\) is linear with respect to (wrt) \(X\) (for instance, when an otherwise non-linear activation is _locally linear_ at the support of \(X\)). To show that such an identifiability condition can be satisfied with OT, we first recall the following classic result from the literature characterizing the OT maps.

**Theorem 3.1** ().: _Let \(X_{2}(^{d})\), \(T(x)=(x)\) for a convex function \(\) with \(T(X)_{2}(^{d})\). Then, \(T\) is the unique optimal OT map between \(\) and \(T_{\#}\)._

Using this theorem about the uniqueness of OT maps expressed as gradients of convex functions, we can prove the following result (all proofs can be found in the Appendix C):

**Corollary 3.2**.: _Without loss of generality, let \(X,Y_{2}(^{d})\) be centered, and let \(Y=(X)=TX\), where \(T\) is a positive definite linear transformation. Then, \(T\) is the OT map from \(X\) to \(Y\)._

Whenever the activation function \(\) is linear, the solution to the OT problem \(T\) exactly reproduces it.

CharacterizationWe now seek to understand whether \(T\) can be characterized more explicitly. For this, we prove the following theorem stating that \(T\) can be computed in closed-form using the normal approximations of \(X\) and \(Y\).

**Theorem 3.3**.: _Let \(X,Y_{2}(^{d})\) be centered and \(Y=TX\) for a positive definite matrix \(T\). Let \(N_{X}((X),(X))\) and \(N_{Y}((Y),(Y))\) be their normal approximations where \(\) and \(\) denote mean and covariance, respectively. Then, \(W_{2}(N_{X},N_{Y})=W_{2}(X,Y)\) and \(T=T_{}\), where \(T_{}\) is the OT map between \(N_{X}\) and \(N_{Y}\) and can be calculated in closed-form_

\[ T_{}(x)=Ax+b,& A=(Y)^{}((Y)^{}(X) (Y)^{})^{-}(Y)^{},\\ & b=(Y)-A(X).\] (4)

Upper boundWhen the activation \(\) is non-linear wrt \(X\), the affine OT mapping \(T_{}(X)\) will deviate from the true activation outputs \(Y\). One important step toward quantifying this deviation is given by the famous Gelbrich bound, formalized by means of the following theorem:

**Theorem 3.4** (Gelbrich bound ).: _Let \(X,Y_{2}(^{d})\) and let \(N_{X},N_{Y}\) be their normal approximations. Then, \(W_{2}(N_{X},N_{Y}) W_{2}(X,Y)\)._

This upper bound provides a first intuition of why OT can be a great tool for measuring non-linearity: the cost of the affine map solving the OT problem on the left-hand side increases when the map becomes non-linear. We now upper bound the difference between \(W_{2}(N_{X},N_{Y})\) and \(W_{2}(X,Y)\), two quantities that coincide _only_ when \(\) is linear.

**Proposition 3.5**.: _Let \(X,Y_{2}(^{d})\) and \(N_{X},N_{Y}\) be their normal approximations. Then,_

1. \(|W_{2}(N_{X},N_{Y})-W_{2}(X,Y)|[((X) (Y))^{}]}{[(X)]+ [(Y)]}}\)2.2 For \(T_{ aff}\) as in (4), \(W_{2}(T_{ aff}X,Y)[(Y)]}\).

To have a more informative non-linearity measure, we now need to normalize the non-negative Wasserstein distance \(W_{2}(T_{ aff}X,Y)\) to an interpretable interval of \(\). The bound given in Proposition 3.5 lets us define the following _affinity score_

\[_{ aff}(X,(X))=1-(T_{ aff}X,(X))}{[((X))]}}.\] (5)

The proposed affinity score quantifies how far a given activation \(\) is from an affine transformation. It is equal to 1 for any input for which the activation function is linear, and 0 when it is maximally non-linear, i.e., when \(T_{ aff}X\) and \((X)\) are independent random variables.

**Remark 3.6**.: _One may wonder whether a simpler alternative to the affinity score can be to use, instead of \(T_{ aff}\), a mapping \(T_{W}(x)=Wx\) defined as a solution of a linear regression problem \(_{W}||Y-WX||_{F}^{2}\). Then, one can use the coefficient of determination (\(R^{2}\) score) to measure how well \(T_{W}\) fits the observed data. This approach, however, has two drawbacks. First, following the famous Gauss-Markov theorem, \(T_{W}\) is an optimal linear (linear in \(Y\)) estimator. On the contrary, \(T_{ aff}\) is a globally optimal non-linear mapping aligning \(X\) and \(Y\). Second, \(R^{2}\) compares the fit of \(T_{W}\) with that of a mapping outputting \((Y)\) for any value of \(X\). This is contrary to \(_{ aff}\) that compares how well \(T_{ aff}\) fits the data wrt to the worst possible cost incurred by \(T_{ aff}\) as quantified in Proposition 3.5. This gives us a bounded score, i.e. \(_{ aff}\), whereas \(R^{2}\) is not lower bounded, i.e. \(R^{2}[-,1]\). We confirm experimentally in Section 4 that the two coefficients do not correlate consistently across the studied DNNs suggesting that \(R^{2}\) is a poor proxy to \(_{ aff}\)._

Figure 1: Illustration of how the non-linearity of a given neural network is measured. (**Top**) The non-linearity signature of a DNN is a collection of affinity scores calculated for each activation function spread across its hidden layers. (**Bottom**) The affinity score is calculated based on 3 main steps. First, given an input (grey) and an output (red) of an activation function (_left_), we estimate the best affine OT fit \(T_{ aff}(X)\) (green) transporting the input to the output (_middle-left_). Second, we measure the mismatch between the two by summing the transportation costs (_middle-right_) to obtain the Wasserstein distance \(W_{2}(T_{ aff}X,Y)\). Finally, this distance is normalized with the magnitudes of variance (arrows in the rightmost plot) of the output data based on its covariance matrix.

### Non-linearity signature

We now turn our attention to the definition of a non-linearity signature of deep neural networks. We define a neural network N as a composition of layers \(F_{i}\) where each layer \(F_{i}\) is a function taking as input a tensor \(_{i}^{h_{i} w_{i} c_{i}}\) (for instance, an image of size \(224 224 3\) for \(i=1\)) and outputting a tensor \(_{i}^{h_{i+1} w_{i+1} c_{i+1}}\) used as an input of the following layer \(F_{i+1}\). This defines \(=F_{L}... F_{i}\)...\( F_{1}=_{k=1,,L}F_{k}\) where \(\) stands for a composition.

We now present the definition of a non-linearity signature of a network N. Below, we abuse the compositional structure of \(F_{i}\) and see it as an ordered sequence of functions.

**Definition 3.1**.: _Let \(=_{k=1,,L}F_{k}\) be a neural network. Define by \(\) a finite set of common activation functions such that \(:=\{|:^{h w c}^{h w c}\}\). Let \(r\) be a pooling operation such that \(r:^{h w c}^{c}\). Then, the non-linearity signature of N given an input \(\) is defined as follows:_

\[_{}(;)=\{_{}(r(_ {i}),(r(_{i}))), F_{i},  i=\{1,,L\}\}.\]

Non-linearity signature, illustrated in Figure 1, associates to each network N a vector of affinity scores calculated over the inputs and outputs of all activation functions encountered across its layers.

What makes an activation function non-linear?We now want to understand the mechanism behind achieving a lower or higher non-linearity with a given (activation) function. This will explain what the different values of the affinity scores stand for when defining the non-linearity signature of a DNN. In Figure 2(A), we show how the ReLU function , defined element-wise as \((x)=(0,x)\), achieves its varying degree of non-linearity. Interestingly, this degree depends only on the range of the input values. Second, in Figure 2(B) we also show how the shape of activation functions impacts their non-linearity for a fixed input: surprisingly, piece-wise linear ReLU function is more non-linear than \((x)=1/(e^{-x}+1)\) or \((x)=(e^{-x}-e^{x})/(e^{-x}+e^{x})\). Similar observations also apply to compare polynomials of varying degrees (Figure 2(C)). We refer the reader to Appendix D for more visualizations of the affinity score of popular activation functions.

### Related work

Layer-wise similarity analysis of DNNsA line of work that can be distantly related to our main proposal is that of quantifying the similarity of the hidden layers of the DNNs as proposed  and  (see  for a complete survey of the subsequent works).  extracts activation patterns of the hidden layers in the DNNs and use CCA on the singular vectors extracted from them to measure how similar the two layers are. Their analysis brings many interesting insights regarding the learning dynamics of the different convnets, although they do not discuss the non-linearity propagation in the

Figure 2: **(A)** Non-linearity of ReLU depends on the range of input values (_red_); **(B)** ReLU, Tanh, and Sigmoid exhibit different degrees of non-linearity for the same input; **(C)** Affinity score captures the increasing non-linearity of polynomials of different degrees.

convnets, nor do they propose a way to measure it.  proposed to use a normalized Frobenius inner product between kernel matrices calculated on the extracted activations of the hidden layers and argued that such a similarity measure is more meaningful than that proposed by .

Impact of activation functions provides the most comprehensive survey on the activation functions used in DNNs. Their work briefly discusses the non-linearity of the different activation functions suggesting that piecewise linear activation functions with more linear components are more non-linear (e.g., ReLU vs. ReLU6).  show theoretically that smooth versions of ReLU allow for more efficient information propagation in DNNs with a positive impact on their performance. Our work provides a first extensive comparison of all popular activation functions; we also show that smooth version of ReLU exhibit wider regions of high non-linearity (see Appendix D).

Non-linearity measureThe only work similar to ours in spirit is the paper by  proposing the non-linearity coefficient in order to predict the train and test error of DNNs. Their coefficient is defined as a square root of the Jacobian of the neural network calculated wrt its input, multiplied by the covariance matrix of the Jacobian, and normalized by the covariance matrix of the input. The presence of the Jacobian in it calls for the differentiability assumption making its application to most of the neural networks with ReLU non-linearity impossible as is. The authors didn't provide any implementation of their coefficient and we were not able to find any other study reporting the reproduced results from this work.

## 4 Experimental evaluations

We consider computer vision models trained and evaluated on the same Imagenet dataset with 1,000 output categories (Imagenet-1K) publicly available at . The non-linearity signatures of different studied models presented in the paper is calculated by passing batches of size 512 through the pre-trained models for the entirety of the Imagenet-1K validation set (see Appendix H for more datasets) with a total of 50,000 images. We include the following landmark architectures in our study: Alexnet , four VGG models , Googlenet , Inception v3 , five Resnet models , four Densenet models , four MNASNet models , four EfficientNet models , five ViT models, three Swin transformer  and four Convnext models . We include MNASNet and EfficientNet models as prominent representatives of the neural architecture search approach . Such models are expected to explicitly maximize the accuracy for a given computational budget. Swin transformer and Convnext models are introduced as ViTs with traditional computer vision priors. Their presence will be useful to better grasp how such priors impact ViTs. We refer the reader to Appendix E for more practical details.

History of deep vision models at a glanceWe give a general outlook of the developments in computer vision over the last decade when seen through the lens of their non-linearity. In Figure 3 we present the minimum, median, and maximum values of the affinity scores calculated for the considered neural networks (see Appendix F for raw non-linearity signatures). We immediately see that until the arrival of transformers, the trend of the landmark models was to decrease their non-linearity, rather than to increase it. On a more fine-grained level, we note that pure convolution architectures such as Alexnet (2012) and VGGs (2014) exhibit a very low spread of the affinity score values. This trend changes with the arrival of the inception module first used in Googlenet (2014): the latter includes activation functions that extend the range of the non-linearity on both ends of the spectrum. Importantly, we can see that the trend toward increasing the maximum and average non-linearity of the neural networks has continued for almost the whole decade. Even more surprisingly, EfficientNet models (2019), trained through neural architecture search, have strong negative skewness toward higher linearity, although they were state-of-the-art in their time. The second surprising finding comes with the arrival of ViTs (2020): they break the trend and leverage the non-linearity of their hidden activation functions becoming more or more non-linear with the varying size of the patches (see Appendix F for a more detailed comparison with raw signatures). This trend remains valid also for Swin transformers (2021), although introducing the computer vision priors into them makes their non-linearity signature look more similar to pure convolutional networks from the early 2010s, such as Alexnet and VGGs. Finally, we observe that the non-linearity signature of a modern Convnext architecture (2022), designed as a convnet for 2020s using the best practices of Swin transformers, further confirms this observation.

Figure 4: Best found dependency between the different statistics extracted from the non-linearity signatures of the DNN families and their respective Imagenet-1K accuracy. The results are compared in terms of the \(R^{2}\) score against the most precise of the other common DNN characteristics such as depth, size, and the GFLOPS.

Figure 3: Median, minimum, and maximum values of non-linearity signatures of the different architectures spanning a decade (2012-2022) of computer vision research. We observe a clear trend toward the increase of the spread and the maximum values of the linearity in neural networks lasting until the arrival of transformers in 2020. ViTs have a distinct pattern of maximizing the non-linearity of their activation functions. Swin transformers and Convnext models retain this property from them while remaining close to the pure convolutional networks.

**Closer look at accuracy/non-linearity trade-off** Different families of vision models leverage different characteristics of their internal non-linearity to achieve better performance. To better understand this phenomenon, we now turn our attention to a more detailed analysis of the accuracy/non-linearity trade-off by looking for a statistic extracted from their non-linearity signatures that is the most predictive of their accuracy as measured by the \(R^{2}\) score. Additionally, we also want to understand whether the non-linearity of DNNs can explain their performance better than the traditional characteristics such as the number of parameters, the number of giga floating point operations per second (GFLOPS), and the depth. From the results presented in Figure 4, we observe the following. First, the information extracted from the non-linearity signatures often correlates more with the final accuracy, than the usual DNN characteristics. This is the case for Residual networks (ResNets and DenseNets), ViTs, and vision models influenced by transformers (Post-ViT). Unsurprisingly, for models based on neural architecture search (NAS-based, i.e. EfficientNets and MNASNets) the number of parameters is the most informative metric as they are specifically designed to reach the highest accuracy with the increasing model size and compute. For Pre-residual pure convolutional models (Alexnet, VGGs, Googlenet, and Inception), the spread of the non-linearity explains the accuracy increase similarly to depth. Second, we observe that all models preceding ViTs were implicitly optimizing the spread of their affinity score values to achieve better performance. After the arrival of the transformers, the observed trend is to increase either the median or the minimum values of the non-linearity. This suggests a fundamental shift in the implicit bias that the transformers carry.

Figure 5: Comparing the different families of the neural architectures based on their non-linearity signatures. **(A)** Hierarchical clustering of all DNNs considered in our study revealing meaningful clusters with close architectural characteristics; **(B)** 9 representative architectures from all studied families and the similarities between them. Note how the similarities between early convnets and other models is decreasing with time until computer vision priors are introduced into Swin transformers in 2021; **(C)** Distributions of affinity scores in each network. Most models expand the non-linearity ranges of their activation functions compared to early convnets. ViTs are dominated by highly non-linear activation functions, Resnets have a bimodal distribution, Densenets, and EfficientNets have a diametrically skewed distribution compared to ViTs. **(D)** Comparing the same convnet with 20 layers when trained with (Residual Resnet20) and without (Plain Resnet20) residual connections (top row). Residual connections introduce a clear trend toward a bimodal distribution of affinity scores; the same effect is observed for Resnet18 and Resnet34 (bottom row).

**Distinct signature for every architecture**  Non-linearity signature correctly identifies the different families of neural architectures. To show this, we perform hierarchical clustering using pairwise dynamic time warping (DTW) distances  between the non-linearity signatures of the models from Figure 3. The results in Figure 5 (A), as well as the pairwise distance matrix between a representative of each studied family in Figure 5 (B) (see Appendix G for the full matrix), show that we correctly cluster all similar models together, both within their respective families (such as the different variations of the same architecture) and across them (such as the cluster of Swin and pure convolution models). Additionally, we highlight the individual affinity scores' distributions of representative models in Figure 5 (C). Finally, we highlight the exact effect of residual connections proposed in 2016 and used ever since by every benchmark model in Figure 5 (D). It reveals vividly that residual connections make the distribution of the affinity scores bimodal with one such mode centered around highly linear activation functions. This confirms in a principled way that residual connections indeed tend to enable the learning of the identity function just as suggested in the seminal work that proposed them . Non-linearity signatures can also be applied to meaningfully identify training methods, such as popular nowadays self-supervised approaches, for a fixed architecture (see Appendix I).

**Uniqueness of the affinity score**  No other metric extracted from the activation functions of the considered networks exhibits a strong consistent correlation with the non-linearity signature. To validate this claim, we compare in Table 1 the Pearson correlation between the non-linearity signature and several other metrics comparing the inputs and the outputs of the activation functions. We can see that for different models the non-linearity correlates with different metrics suggesting that it captures the information that other metrics fail to capture consistently across all architectures. This becomes even more apparent when analyzing the individual correlation values (in Appendix G). Overall, the proposed affinity score and the non-linearity signatures derived from it offer a unique perspective on the developments in the ML field.

## 5 Discussions

We proposed the first sound approach to measure non-linearity of activation functions in neural networks and defined their non-linearity signature based on it. We further used non-linearity signatures to provide a meaningful overview of the evolution of neural architectures proposed over the last decade with clear interpretable patterns. We showed that until the arrival of transformers, the trend in DNNs was to decrease their non-linearity, rather than to increase it. Vision transformers changed this pattern drastically. We also showcased that our measure is unique, as no other metric correlates strongly with it across all architectures.

In the future, our work can be applied to study the non-linearity of the LLM models to better understand the effect of different architectural choices in them. On a higher level, our approach can also be used to identify new disruptive neural architectures by identifying those of them that leverage different internal non-linearity characteristics to obtain better performance. This capacity of identifying novel technologies is even more crucial in the age of very large models where experimenting with the building blocks of the optimized backbone comes at a very high cost.

 Models & cka & norm & sparsity & entropy & \(R^{2}\) \\  VGGs & 0.0 \(\) 0.05 & -0.67 \(\) 0.06 & -0.18 \(\) 0.03 & **-0.90 \(\) 0.04** & -0.21 \(\) 0.06 \\ ResNets & 0.53 \(\) 0.04 & -0.41 \(\) 0.19 & **-0.68 \(\) 0.02** & -0.38 \(\) 0.12 & -0.48 \(\) 0.24 \\ DenseNets & 0.88 \(\) 0.02 & -0.76 \(\) 0.02 & **-0.89 \(\) 0.02** & -0.66 \(\) 0.03 & 0.85 \(\) 0.04 \\ MNASNets & **0.67 \(\) 0.11** & -0.54 \(\) 0.14 & -0.63 \(\) 0.07 & -0.55 \(\) 0.16 & 0.45 \(\) 0.17 \\ EfficientNets & **0.42 \(\) 0.10** & -0.16 \(\) 0.22 & -0.17 \(\) 0.23 & -0.16 \(\) 0.14 & 0.21 \(\) 0.12 \\ ViTs & -0.22 \(\) 0.40 & **-0.67 \(\) 0.20** & -0.09 \(\) 0.56 & 0.17 \(\) 0.25 & -0.10 \(\) 0.34 \\ Swins & -0.15 \(\) 0.13 & **-0.53 \(\) 0.10** & -0.26 \(\) 0.17 & 0.06 \(\) 0.35 & -0.13 \(\) 0.13 \\ Convnexts & 0.69 \(\) 0.08 & 0.21 \(\) 0.15 & 0.23 \(\) 0.16 & 0.02 \(\) 0.09 & **0.79 \(\) 0.05** \\  Average & 0.33 \(\) 0.45 & **-0.44 \(\) 0.34** & -0.32 \(\) 0.42 & -0.31 \(\) 0.39 & 0.14 \(\) 0.49 \\ 

Table 1: Pearson correlations between the non-linearity signature and other metrics, for all the architectures evaluated in this study. The highest absolute value in each group is reported in **bold**.