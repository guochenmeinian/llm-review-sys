# PromptRestorer: A Prompting Image Restoration Method with Degradation Perception

Cong Wang\({}^{1}\), Jinshan Pan\({}^{2}\), Wei Wang\({}^{3}\), Jiangxin Dong\({}^{2}\), Mengzhu Wang\({}^{4}\),

**Yakun Ju\({}^{1}\), Junyang Chen\({}^{5}\)**

\({}^{1}\)The Hong Kong Polytechnic University, \({}^{2}\)Nanjing University of Science and Technology,

\({}^{3}\)Dalian University of Technology, \({}^{4}\)Hebei University of Technology, \({}^{5}\)Shenzhen University

These authors equally contribute to this work.

###### Abstract

We show that raw degradation features can effectively guide deep restoration models, providing accurate degradation priors to facilitate better restoration. While networks that do not consider them for restoration forget gradually degradation during the learning process, model capacity is severely hindered. To address this, we propose a **Prompt**ing image **Restorer**, termed as **PromptRestorer**. Specifically, PromptRestorer contains two branches: a restoration branch and a prompting branch. The former is used to restore images, while the latter perceives degradation priors to prompt the restoration branch with reliable perceived content to guide the restoration process for better recovery. To better perceive the degradation which is extracted by a pre-trained model from given degradation observations, we propose a prompting degradation perception modulator, which adequately considers the characters of the self-attention mechanism and pixel-wise modulation, to better perceive the degradation priors from global and local perspectives. To control the propagation of the perceived content for the restoration branch, we propose gated degradation perception propagation, enabling the restoration branch to adaptively learn more useful features for better recovery. Extensive experimental results show that our PromptRestorer achieves state-of-the-art results on 4 image restoration tasks, including image deraining, deblurring, dehazing, and desnowing.

## 1 Introduction

Image restoration aims to recover clear high-quality images from given degraded ones. It is highly ill-posed since only degraded images can be exploited, statistical observations are thus required to well-pose the problems . Although conventional approaches can recover images to some extent, they typically involve solving optimization algorithms that are difficult due to the non-convexity and non-smooth problems. Additionally, the observations may not always hold, which can cause algorithms to fail.

With the emergence of convolutional neural networks (CNNs)  and Transformers , which perform well at implicitly learning the priors from large-scale data, learning-based methods have dominated recent image restoration tasks and achieved impressive performance . However, these methods are usually built without explicitly considering the specific degradation information, which accordingly limits model capacity (**Case 1** in Fig. 1). An alternative approach is to design a conditional branch to learn additional information to provide the restoration network with useful content for modulation  (**Case 2** in Fig. 1). However, we note that while conditional branches in these models are learnable, they may not effectively provide degradation information, as the optimizable parameters result in gradually clearer features during the learning process, leading to the degradation vanishing which accordingly limits model performance.

Recently, prompt learning has been shown an effective tool to improve model performance by designing various prompts [115; 98; 104; 23; 114; 46; 53; 43]. The prompt usually serves as the guidance tool to correct the networks toward better results . However, prompt learning still keeps a margin for image restoration, and existing prompts may not be suitable for image restoration since they cannot effectively model degradation priors well. Hence, we ask: _Is there a reasonable prompting manner to correct degraded image restoration networks to facilitate better recovery?_

_The answer is in the riddle_. This paper proposes the **PromptRestorer**, a **Prompt**ing image **Restorer**, to overcome degradation vanishing in image restoration via promoting by exploring degradation input itself for better restoration (**Case 3** in Fig. 1). Our idea is simple: we directly exploit the raw degraded features extracted by a pre-trained model from the degraded inputs to generate more reliable prompting content to guide image restoration. Raw degraded features preserve accurately degraded information, which can consistently prompt the restoration network with accurate degraded priors, enabling the restoration network to perceive the degradation for better restoration. Hence, we design the PromptRestorer, which consists of two branches: (a) the restoration branch and (b) the prompting branch. The former is used to restore images and the latter is used to generate reliable prompting features to guide the restoration network for better restoration. To better perceive the degradation, we propose a **Prompting**Degradation **P**erception **M**odulator (**PromptDPM**), which consists of **G**lobal **P**rompting **P**erceptor (**G2P**) and **L**ocal **P**rompting **P**erceptor (**L2P**). The G2P adequately exploits the self-attention mechanism to form global prompting attention, while the L2P considers the pixel-level perception to build local prompting content. To control the propagation of perceived features in the restoration branch, we propose **G**ated **D**egradation Perception **P**ropagation (**GDP**), enabling the restoration network to adaptively learn more useful features to facilitate better restoration.

The main contributions of this work are summarized below:

* We propose PromptRestorer, which is the first approach to our knowledge that takes advantage of the prompting learning for general image restoration by considering raw degradation features in restoration, enabling the restoration model to overcome degradation vanishing while consistently retaining the degradation priors to facilitate better restoration.
* We propose a prompting degradation perception modulator that is used to perceive degradation from global and local perspectives, which is able to provide the restoration network

Figure 1: **(a)** compares different restoration frameworks. Unlike existing approaches that are built within the architectures such as **Cases 1-2**, which are unable to memorize the degradation well during the learning process, we propose a prompting method (**Case 3**) that directly exploits raw degradation features extracted by a pre-trained model from the given degradation observations to guide restoration. In **(b)**, we observe that both **Cases 1-2** outperform our method in early iterations, as they effectively memorize degraded information. However, both **Cases 1-2** experience degradation vanishing with further iterations (better demonstrated in Sec. 4.3), while our prompting method persists in guiding the restoration network with accurate degradation priors, accordingly producing better restoration quality. In **(c)**, visual performance demonstrates that our prompting method recovers sharper images. Quantitative results are reported in Tab. 5.

with more reliable perceived content learned from the degradation priors, enabling it to better guide the restoration process.
* We propose gated degradation perception propagation that exploits a gating mechanism to control the propagation of the perceived features, enabling the model to adaptively learn more useful features for better image restoration.

Fig. 1 summarises framework comparisons, and their learning curves and visual performance. Deeper analysis and discussion about them are provided in Sec. 4.2.

## 2 Related Work

In this section, we review image restoration, conditional modulation, and prompt learning.

**Image Restoration.** Recently, CNN-based architectures [110; 112; 103; 4; 24; 102; 89; 91; 87; 19; 88; 117] and Transformer-based models [96; 56; 49; 12; 93; 93] have been shown to outperform conventional restoration approaches [37; 83; 64; 47; 7; 79]. These learning-based methods usually adopt U-Net architectures [50; 18; 103; 100; 1; 93; 108; 101], which have been demonstrated the effectiveness because of hierarchical multi-scale representation and effective learning between shallow and deeper layers by skip connection [111; 59; 102; 31]. We refer the readers to recent excellent literature reviews on image restoration [5; 54; 82], which summarise the main designs in deep image restoration models.

Although these models have achieved promising performance, they do not explicitly take degradation into consideration for model design which is vital for restoration, limiting the model capacity.

**Conditional Modulation.** Conditional modulation usually involves implicitly modulating the additional content to guide the restoration [30; 10; 16; 17; 36; 35; 34; 60; 57; 92]. These approaches usually contain two branches: a basic network and a conditional network. The conditional network provides additional information to guide the basic network for restoration via spatial feature transform (SFT) . Among these methods, blur kernel , semantics , and degraded input [57; 16] which serve as the additional conditions are broadly known.

The learnable nature of the conditional network in these models does not effectively provide degradation information for the basic network. As parameters are optimized in the learning process, features become gradually clear.

**Prompt Learning.** Prompt learning methods have been studied broadly in natural language processing (NLP) [75; 78; 8]. Due to high effectiveness, prompt learning is recently used in vision-related tasks [115; 98; 104; 23; 114; 46; 53; 43; 71; 29; 40; 86; 28]. In vision prompt learning, many works seek useful prompts to correct task networks toward better performance .

Although prompt learning has shown promise in various vision tasks, it still keeps a margin in general image restoration. This paper proposes an effective prompting method, enabling the restoration model to overcome the degradation vanishing in the learning process for better restoration.

## 3 PromptRestorer

Our goal aims to overcome degradation vanishing and better perceive degradation in deep restoration models to improve image recovery quality. To achieve this, we introduce a prompting strategy that helps the model consistently memorize degradation information, enabling it to prompt restoration with better degradation for better restoration. To better perceive degradation, we propose the **Prompting********************(**Degradation **P**ereception **M**odulator (**PromptDPD**), which can provide more reliable perceived content to guide the restoration network. To control the propagation of the perceived content, we propose the **G**ated **D**egradation Perception **P**ropagation (**GDP**), enabling the restoration network to adaptively learn more useful features for better restoration.

### Overall Pipeline

Fig. 2 shows the framework of our PromptRestorer, which contains two branches: (a) the restoration branch and (b) the prompting branch. The restoration branch is used to restore images, where each block is prompted by the prompting branch. The prompting branch first generates the accurate degradation feature extracted by a pre-trained model, and then the feature is to prompt the restoration branch, enabling the restoration branch to better perceive the degradation prior for better recovery.

**Restoration Branch.** Given a degraded input image \(^{H W 3}\), we first applies a \(3 3\) convolution as the feature extraction to obtain low-level embeddings \(_{0}^{H W C}\); where \(H W\) denotes the spatial dimension and \(C\) is the number of channels. Next, the shallow features \(_{0}\) gradually are hierarchically encoded into deep features \(_{l}^{}{l} lC}\). After encoding the degraded input into low-resolution latent features \(_{3}^{}{3} 3C}\), the decoder progressively recovers the high-resolution representations. Finally, a reconstruction layer which contains 4 Transformer blocks as the refinement followed by a \(3 3\) convolution is applied to decoded features to generate residual image \(^{H W 3}\) to which degraded image is added to obtain the restored output image: \(}=+\). Both encoder and decoder at \(l\)- level consist of multiple **C**ontinuous **G**ated **T**ransformers (**CGT**) with expanding channel capacity. To help better recovery, the encoder features are concatenated with the decoder features via skip connections  by \(1\)1 convolutions.

**Prompting Branch.** The prompting branch, as shown in Fig. 2(b), aims to generate and perceive degradation features and then provide useful guidance content for the restoration branch. We note VQGAN  has been demonstrated that it can generate high-quality images while representing the features of input images. However, it tends to damage image structure after vector quantization . To avoid this problem, we only exploit the encoder of pre-trained VQGAN to represent the deep features of the degraded inputs. We first use the pretrained encoder to extract degraded features \(_{l}^{}{l} lC}\); where \(l\) denotes the \(l\)- level layer in the pre-trained encoder. Then, the degraded features are exploited to generate reliable prompting content to prompt the restoration branch by PromptDPM (see Sec. 3.2). The generated prompting content is transmitted to each CGT to guide the restoration branch.

**Continuous Gated Transformers.** CGT exploits the perceived features from PromptDPM to provide the Transformer block with more reliable content to overcome degradation vanishing to facilitate better restoration. Each CGT consists of three Transformer blocks (Fig. 2(c)) with residual connections  and the input in each block is gated by GDP (see Sec. 3.3) to control the propagation of perceived features. Let \(\), \(\), and \(\) respectively denote the operations of PromptDPM (expressed in (2)), GDP (expressed in (7)), and Transformer, the features flow in \(k^{th}\) block in one CGT at \(l\)- level encoder/decoder, which can be expressed as:

\[_{k}=(_{k-1});_{k-1}= _{k-1},_{l});_{l}=(_{k-1}, _{l}),\] (1)

Figure 2: Overall pipeline of our **PromptRestorer**. PromptRestorer contains two branches: **(a)** the restoration branch and **(b)** the prompting branch. The restoration branch is used to restore images, where each block **(c)** in CGT is prompted by the prompting branch. The prompting branch first generates precise degradation features extracted by a pre-trained model from degradation observations, then these features prompt the restoration branch to facilitate better restoration via PromptDPM **(d)**.

where \(_{k}\) means the output of \(k^{th}\) Transformer block in one CGT, especially \(_{0}\) is the downsampled/upsampled features at \((l-1)\)- level encoder/decoder; \(_{l}\) refers to the generated features of PromptDPM at \(l\)-level layer; \(_{k-1}\) means the gated features between \(_{k-1}\) and \(_{l}\), which serves as the input of \(k^{th}\) Transformer block. Each Transformer block consists of multi-head attention  followed by an improved ConvNeXt  as the feed-forward network (see Fig. 2(c)).

### Prompting Degradation Perception Modulator

To better perceive the degradation to prompt the restoration network with more reliable perceived content from the degradation priors, we propose the PromptDPM (see Fig. 2(d)). The PromptDPM consists of 1) **G**lobal **P**rompting **P**erceptor (**G2P**, introduced in Sec. 3.2.1) and 2) **L**ocal **P**rompting **P**erceptor (**L2P**, introduced in Sec. 3.2.2) to respectively perceive the degradation from global and local perspectives, enabling to generate more useful content to guide the restoration branch. From a restoration tensor \(^{H W}\) and a degradation tensor \(^{}\), we prompt \(\) with \(\):

\[(,)=W_{p}^{ }(,),^{}(, )+,\] (2)

where \(^{}(,)\) and \(^{}(,)\) respectively denote the operations of G2P and L2P; \([,]\) means the concatenation at channel dimension; \(W_{p}()\) refers to the \(1 1\) point-wise convolution.

#### 3.2.1 Global Prompting Perceptor

The G2P, shown in Fig. 3(a), fully exploits the self-attention mechanism to form the global prompting attention induced by the degraded features. The G2P contains the global perception attention followed by an improved ConvNeXt . Our global perception attention consists of 1) **Q**uery-**I**nduced **A**ttention (**Q**-**InAtt**) and 2) **K**ey-**V**alue-**I**nduced **A**ttention (**KV**-**InAtt**). The Q-InAtt considers re-forming the query vector induced by degradation features to build a representative query to perform attention, while the KV-InAtt re-considers key and value vectors induced by other degradation counterparts to search for more similar content with the restoration query. From a layer normalized restoration tensor \(^{}\), our G2P first generates _restoration query_ (**Q**), _key_ (**K**), and _value_ (**V**) projections from the restoration features. It is achieved by applying \(1{}1\) convolutions to aggregate pixel-wise cross-channel context followed by \(3{}3\) depth-wise convolutions \(W_{d}()\) to encode channel-wise spatial context, yielding \(W_{d}W_{p}\), \(W_{d}W_{p}\), and \(W_{d}W_{p}\). Meanwhile, we similarly convert the degradation tensor \(^{}\) into _degradation query_ (\(}\)), _key_ (\(}\)), and _value_ (\(}\)) projections: \(}{=}W_{d}W_{p}\), \(}{=}W_{d}W_{p}\), and \(}{=}W_{d}W_{p}\). Then, we respectively conduct Q-InAtt and KV-InAtt:

\[_{}=_{}W_{p} [,}],, ;_{}=_{} ,W_{p}[,}],W_{p}([,}],\] (3)

where \(_{()}(},},} )=}(}}/)\); Here, \(\) is a learnable scaling parameter to control

Figure 3: **(a)** Global Prompting Perceptor (**G2P**); **(b)** Local Prompting Perceptor (**L2P**).

the magnitude of the dot product of \(\) and \(}\) before applying the softmax function. Similar to the conventional multi-head SA , we divide the number of channels into 'heads' and learn separate attention maps. Then two induced attentions are fused and followed by an improved ConvNeXt:

\[^{{}^{}}=W_{p}[_{}, _{}]+;=W_{p}W_{d} W_{p}W_ {d}LN(^{{}^{}})+^{{}^{}},\] (4)

where the \(W_{p}W_{d} W_{p}W_{d}()\) means the improved ConvNeXt shown in the latter of Fig. 2(c); \(LN()\) means the operation of layer normalization .

#### 3.2.2 Local Prompting Perceptor

The L2P, as shown in Fig. 3(b), adequately considers the pixel-level degradation perception, enabling to better perceive degradation from spatially neighboring pixel positions. The L2P consists of a local perception modulator followed by a separable depth-level convolution. The local perception modulator contains two core components: 1) **Deg**radation-**Induced **Band** (**Deg**-**InBan**) and 2) **Rest**oration-**Induced **Band** (**Res**-**InBan**). The former is achieved by exploiting the degradation features to induce spatially useful content from restoration content to guide restoration gating fusion, while the latter utilizes the deep restoration features to induce more useful features from another degradation counterpart to form the degradation gating. Given the degradation tensor \(^{}\), we first exploit the point-wise convolution and \(3 3\) depth-wise convolution to encode two _degradation_ projections, yielding \(}\)=\(W_{d}^{Q}W_{p}^{Q}\) and \(}\)=\(W_{d}^{K}W_{p}^{K}\). Meanwhile, the restoration tensor \(^{}\) are also encoded into two _restoration_ projections: \(\)=\(W_{d}^{Q}W_{p}^{Q}\) and \(\)=\(W_{d}^{K}W_{p}^{K}\). Then, we respectively conduct Deg-InBan and Res-InBan:

\[_{}=W_{p} W_{d}([ },]);\,_{}=}W_{}W_{d}([ },]),\] (5)

where \(()\) denotes the sigmoid function that controls the gating level. Then, the perceived features in the two bands are fused via concatenation and \(1 1\) convolution and followed by a depth-level separable convolution \(W_{p} W_{d}()\):

\[^{{}^{}}=W_{p}[_{ },_{}]+;=W_{p} W_{d} (^{{}^{}})+^{{}^{}}.\] (6)

### Gated Degradation Perception Propagation

The GDP aims to control the propagation of the perceived degradation, enabling to adaptively learn more useful features in Transformer blocks to facilitate better restoration. Given the output restoration tensor \(_{k-1}^{}\) of \((k-1)^{th}\) Transformer block in one CGT and the perceived tensor \(_{l}^{}\) which is the output feature of one PromptDPM at \(l\)- level, the input of \(k^{th}\) Transformer block can be obtained by gating the \(_{k-1}\) with \(_{l}\) by \(1 1\) convolution and gated control function sigmoid \(()\) with residual learning :

\[_{k-1},_{l}=(W_{p} _{l})_{k-1}+_{k-1}.\] (7)

### Learning Strategy

To train the network, two objective loss functions are adopted, including image reconstruction loss (\(_{i}\)) for pixel recovery and frequency loss (\(_{f}\)) for detail enhancement :

\[=_{i}+_{f},_{i}=\| }-\|_{1};\;_{f}=\|(})-()\|_{1},\] (8)

where \(\) denotes the ground truth image; \(\) denotes the Fast Fourier transform; \(\) is a weight that is empirically set to be 0.1.

## 4 Experiment

We evaluate PromptRestorer on benchmarks for 4 image restoration tasks: **(a)** deraining, **(b)** deblurring, **(c)** desnowing, and **(d)** dehazing. We train separate models for different image restoration tasks. Our PromptRestorer employs a 3-level encoder-decoder. From level-1 to level-3, the number of CGT is \(\), attention heads are \(\), and number of channels is \(\). The expanding channel capacity factor \(\) is 4. For downsampling and upsampling, we adopt pixel-unshuffle and pixel-shuffle , respectively. We train models with AdamW optimizer with the initial learning rate \(3e^{-4}\) gradually reduced to \(1e^{-6}\) with the cosine annealing . The patch size is set as \(256 256\).

[MISSING_PAGE_FAIL:7]

**Image Dehazing Results.** We perform the image dehazing experiments on both synthetic benchmark RESIDE SOTS-Indoor , and real-world hazy benchmarks Dense-Haze  and NH-Haze . Tab. 3 summarise the quantitative results. Compared to the recent works DeHamer  and MAXIM , our method receives \(4.33\) dB and \(5.91\) dB PSNR gains on the SOTS-Indoor, respectively. On the real-world benchmark NH-Haze , our PromptRestorer can achieve \(0.7203\) of the SSIM result, which is a new record and significantly outperforms current state-of-the-art approaches DeHamer . The results on both synthetic and real-world benchmarks have demonstrated the effectiveness of our PromptRestorer on the image dehazing task. Fig. 6 shows the visual results, where our PromptRestorer is more effective in removing haze than other methods.

**Image Desnowing Results.** For the image desnowing task, we compare our PromptRestorer on the CSD , SRRS , and Snow100K  datasets with existing state-of-the-art methods . We also compare recent Transformer-based general image restoration approaches Restormer  and Uformer . As shown in Tab. 4, our PromptRestorer yields a \(2.05\) dB PSNR improvement over the state-of-the-art approach  on the CSD benchmark . The visual results in Fig. 7 show that our PromptRestorer is able to remove spatially varying snowflakes than competitors.

  
**Benchmark** & **Metrics** & **DempNet ** & **JSTASR ** & **HDCW-Net ** & **TransWeather ** & **MSP-Former ** & **Ufomer ** & **Restorer ** & **PromptRestorer** \\   & PSNR \(\) & 20.13 & 27.96 & 29.96 & 31.76 & 33.75 & 33.80 & **35.43** & **37.48** \\  & SSIM \(\) & 0.81 & 0.88 & 0.91 & 0.93 & 0.96 & 0.96 & **0.97** & **0.99** \\   & PSNR \(\) & 20.38 & 25.82 & 27.78 & 28.29 & 30.76 & 30.12 & **32.24** & **33.99** \\  & SSIM \(\) & 0.84 & 0.89 & 0.92 & 0.92 & 0.95 & 0.96 & **0.96** & **0.96** & **0.99** \\   & PSNR \(\) & 30.50 & 23.12 & 31.54 & 31.82 & 31.43 & 33.81 & **34.67** & **36.62** \\  & SSIM \(\) & 0.94 & 0.86 & 0.95 & 0.95 & **0.96** & 0.94 & 0.95 & **0.97** \\   

Table 4: **Image desnowing** results on CSD (2000) , SRRS (2000) , and Snow100K (2000) . Our PromptRestorer achieves the best metrics on all datasets on the image desnowing problem.

  
**Benchmark** & **Metrics** & **DempNet ** & **JSTASR ** & **HDCW-Net ** & **TransWeather ** & **MSP-Former ** & **Ufomer ** & **Restorer ** & **PromptRestorer** \\   & PSNR \(\) & 20.13 & 27.96 & 29.96 & 31.76 & 33.75 & 33.80 & **35.43** & **37.48** \\  & SSIM \(\) & 0.81 & 0.88 & 0.91 & 0.93 & 0.96 & 0.96 & **0.97** & **0.99** \\   & PSNR \(\) & 20.38 & 25.82 & 27.78 & 28.29 & 30.76 & 30.12 & **32.24** & **33.99** \\  & SSIM \(\) & 0.84 & 0.89 & 0.92 & 0.92 & 0.95 & 0.95 & 0.96 & **0.96** & **0.96** & **0.99** \\   & PSNR \(\) & 30.50 & 23.12 & 31.54 & 31.82 & 31.43 & 33.81 & **34.67** & **36.62** \\  & SSIM \(\) & 0.94 & 0.86 & 0.95 & 0.95 & 0.96 & 0.94 & 0.95 & **0.97** \\   

Table 4: **Image desnowing** results on CSD (2000) , SRRS (2000) , and Snow100K (2000) . Our PromptRestorer achieves the best metrics on all datasets on the image desnowing problem.

Figure 6: **Image dehazing** example on SOTS-Indoor .

Figure 7: **Image desnowing** example on CSD (2000) .

### Analysis and Discussion

For ablation experiments, following [84; 20], we train the image deblurring model on GoPro dataset  for \(1000\) epochs only and set the number of Transformer in each CGT is 1. Params mean the number of learnable parameters. Testing is performed on the GoPro testing dataset . FLOPs are computed on image size \(256{}256\). Next, we describe the influence of each component individually.

**Effect on Prompting.** The core design of our PromptRestorer is the 'prompting', which exploits a pre-trained model to extract raw degradation features from the degraded observations and then generate perceived content to guide the restoration branch (i.e., **Case 3** in Fig. 1). Compared to existing frameworks such as **Cases 1-2** in Fig. 1, our proposed prompting strategy shows superior performance, as demonstrated in Tab. 5. Our method achieved \(0.877\) dB gains compared to **Case 1**, and \(0.369\) dB higher than **Case 2**. Interestingly, the learnable condition branch in **Case 2**2, despite consuming more FLOPs and Params, results in worse performance than ours. Our approach directly exploits raw degradation features to prompt restoration with persistent degradation priors to facilitate better recovery. Fig. 1(c) shows two examples, where our model that exploits raw degradation features as prompting generates sharper and clearer images.

**Effect on PromptDPM.** We analyze the impact of PromptDPM on restoration quality in Tab. 6 by disabling one component at a time. Each model in L2P and G2P consumes similar Params and FLOPs, while our full model achieves the best performance. Disabling L2P or G2P results in a decrease in performance by \(0.196\) dB and \(0.318\) dB, respectively. These experiments conclusively demonstrate the effectiveness of each component in L2P and G2P for restoration.

**Effect on GDP.** To understand the impact of GDP, we disable it to compare with full model in Tab. 7. Note that the computational cost of the GDP is negligible compared to disabling it as it only involves a 1\({}\)1 convolution and sigmoid function for the gating mechanism, while it leads to a gain of \(0.091\) dB. This finding highlights the significance of controlling the propagation of the perceived degradation features.

### Visualization Understanding for Degradation Vanishing

To emphasize the understanding of degradation vanishing, we visualize the features learned in the condition/prompting branches to better comprehend the learned status of these branches in Fig. 8. Notably, both **Cases 1-2** exhibit sharper results in later iterations compared to earlier ones, which fail to provide the restoration branch with sufficient degraded information and cause the restoration

   Experiment & PSNR & FLOPs (G) & Params (M) \\  w/o L2P & 30.819 & 148.34 & 12.60 \\ w/o Res-InBan & 30.952 & 153.39 & 12.97 \\ w/o Deg-InBan & 30.964 & 153.39 & 12.97 \\  Full (_Ours_) & **31.015** & 157.04 & 13.24 \\   

Table 6: **Ablation experiments on PromptDPM.**

   Experiment & PSNR & FLOPs (G) & Params (M) \\  w/o GDP & 30.924 & 154.60 & 12.95 \\  w/ GDP (_Ours_) & **31.015** & 157.04 & 13.24 \\   

Table 7: **Effect on GDP.** Our GDP which controls the degradation propagation is effective.

   Case in Fig. 1 & PSNR & FLOPs (G) & Params (M) \\ 
1 & 30.138 & 105.58 & 10.16 \\
2 & 30.646 & 157.04 & 16.77 \\ 
3 (_Ours_) & **31.015** & 157.04 & 13.24 \\   

Table 5: **Effect on prompting.** Our method that directly exploits the raw degradation to prompt restoration performs better.

models to not perceive the degradation well, thereby hindering the model capacity. In contrast, as the restoration branch needs to adapt perceived features from the PromptDPM which is to perceive the raw degradation features from inputs, our model (**Case 3**) initially exhibits inferior performance (around 20K iterations) as shown in Fig. 1(b). However, with better adaptation to the degradation information after more iterations, the prompting branch can better prompt the restoration branch consistently with more reliable perceived content learned from the raw degradation, enabling our restoration branch to overcome degradation vanishing and improve restoration quality, as shown in Fig. 1(c).

## 5 Concluding Remarks

In this paper, we investigate the degradation vanishing in the learning process for image restoration. To solve this problem, we have proposed the PromptRestorer which explores the raw degradation features extracted by a pre-trained model from the given degraded observations to guide the restoration process to facilitate better recovery. Extensive experiments have demonstrated that our PromptRestorer favors against state-of-the-art approaches on 4 restoration tasks, including image deraining, deblurring, dehazing, and desnowing.