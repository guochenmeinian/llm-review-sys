# Online Inventory Problems: Beyond the i.i.d. Setting with Online Convex Optimization

Massil Hihat\({}^{1,2}\), Stephane Gaiffas\({}^{1,2}\), Guillaume Garrigos\({}^{1,2}\), Simon Bussy\({}^{1}\)

\({}^{1}\)LOPF, Califrais' Machine Learning Lab, Paris, France

\({}^{2}\)Universite Paris Cite and Sorbonne Universite, CNRS,

Laboratoire de Probabilites, Statistique et Modelisation, Paris, France

{hihat, stephane.gaiffas, garrigos}@lpsm.paris, simon.bussy@califrais.fr

###### Abstract

We study multi-product inventory control problems where a manager makes sequential replenishment decisions based on partial historical information in order to minimize its cumulative losses. Our motivation is to consider general demands, losses and dynamics to go beyond standard models which usually rely on newsvendor-type losses, fixed dynamics, and unrealistic i.i.d. demand assumptions. We propose MaxCOSD, an online algorithm that has provable guarantees even for problems with non-i.i.d. demands and stateful dynamics, including for instance perishability. We consider what we call non-degeneracy assumptions on the demand process, and argue that they are necessary to allow learning.

## 1 Introduction

An inventory control problem is a problem faced by an inventory manager that must decide how much goods to order at each time period to meet demand for its products. The manager's decision is driven by the will to minimize a certain _regret_, which often penalizes missed sales and storage costs. It is a standard problem in operations research and operations management, and the reader unfamiliar with the topic can find a precise description of this problem in Section 2.

The classical literature of inventory management focuses on optimizing an inventory system with complete knowledge of its parameters: we know in advance the demands, or the distribution they will be drawn from. Many efforts have been put into characterizing the optimal ordering policies, and providing efficient algorithms to find them. See e.g. the Economic Order Quantity model , the Dynamic Lot-Size model  or the newsvendor model . Nevertheless, in many applications, the parameters of the inventory system are unknown. In this case, the manager faces a joint learning and optimization problem that is typically framed as a _sequential decision making_ problem: the manager bases its replenishment decisions on data that are collected over time, such as past demands (observable demand case) or past sales (censored demand case). The early attempts to solve these _online_ inventory problems employed various techniques and provided only weak guarantees or no guarantees at all .

With the recent advances in online learning frameworks such as online convex optimization (OCO), bandits, or learning with expert advice, the literature of learning algorithms for inventory problems took a great leap forward. There is currently a growing body of research aiming at solving various online inventory problems while providing strong theoretical guarantees in the form of _regret bounds_.

However, these works rely on mathematically convenient but unrealistic assumptions. The most common one being that the demands are assumed to be independent and identically distributed (_i.i.d._) across time, which rules out correlations and nonstationarities that are common in real-world scenarios.

Furthermore, these works focus on specific cost structures (typically the _newsvendor_ cost) and inventory dynamics (like lost sales models with nonperishable products), which we detail in Section 2.2. The main goal of this paper is to go beyond these restrictions and consider general demand processes, losses and dynamics, in order to provide numerical methods backed with theoretical guarantees compatible with real-world problems.

To do so, we recast the online inventory problem into a new framework called Online Inventory Optimization (OIO), which extends OCO. Our main contribution is a new algorithm called MaxCOSD, which can be seen as a generalization of the Online Subgradient Descent method. It solves OIO problems with provable theoretical guarantees under minimal assumptions (see Section 4). Here is an informal version of our main statement:

**Theorem 1** (Informal version of Theorem 12).: _Consider an OIO problem that satisfies convexity and boundedness assumptions. Assume further that demands are not degenerate (see Assumption 10). Then, running MaxCOSD (see Algorithm 2) with adequate adaptive learning rates gives an optimal \(O()\) regret, both in expectation and in high probability._

Our main assumption is a _non-degeneracy_ hypothesis on the demand process, which we present and discuss in Section 5. This assumption generalizes typical hypotheses made in the inventory literature, while not requiring the demand to be _i.i.d._. We also show that this assumption is sharp, in the sense that the OIO cannot be solved without such assumption. Finally, in Section 6 we present numerical experiments on both synthetic and real-world data that validate empirically the versatility and performances of MaxCOSD. The appendices gather the proofs of all our statements.

This paper helps to bridge the gap between OCO and inventory optimization problems, and we hope that it will raise awareness of OCO researchers to this family of under-studied problems, while being of importance to the industry.

## 2 A general model for online inventory problems

In this section, we present a new but simple model allowing to study a large class of online inventory problems. Then, in a series of remarks we discuss particular instances of these problems and the limitations of our model.

### Description of the model and main assumptions

In the following, \(n=\{1,2,\}\) refers to the number of products and \(_{+}^{n}\) denotes the _feasible set_. An _online inventory optimization_ (OIO) problem is a sequential decision problem where an _inventory manager_ interacts with an _environment_ according to the following protocol.

First, the environment sets the initial inventory state to zero (\(x_{1}=^{n}\)), and chooses (possibly random) _demands_\(d_{t}_{+}^{n}\) and _losses_\(_{t}:^{n}\) for every time period \(t\). Then, the interactions begin and unfold as follows, for every time period \(t\):

1. The manager observes the _inventory state_\(x_{t}^{n}\), where \(x_{t,i}\) encodes the quantity of the \(i^{}\) product available in the inventory.
2. The manager raises this level by choosing an _order-up-to level_\(y_{t}\) which satisfies the _feasibility_ constraint: \[y_{t} x_{t}.\] (1) Then, the manager receives instantaneously \(y_{t,i}-x_{t,i} 0\) units of the \(i^{}\) product.
3. The manager suffers a loss \(_{t}(y_{t})\) and observes a subgradient \(g_{t}_{t}(y_{t})\).
4. The environment updates the inventory state by choosing \(x_{t+1}^{n}\) satisfying the following _inventory dynamical constraint_: \[x_{t+1}[y_{t}-d_{t}]^{+}\,.\] (2)

The goal of the manager is to design an online _algorithm_ that produces feasible order-up-to levels \(y_{t}\) which minimizes the cumulative loss suffered using past observations (past inventory states and subgradients). Let us emphasize here the fact that demands and losses are not directly observable. Throughout the paper, we make the following assumptions on the feasible set and the losses.

**Assumption 2** (Convex and bounded problem).:
1. _(Convex and bounded constraint)_ The feasible set \(\) is closed, convex, nonnegative (\(_{+}^{n}\)) and bounded: \( D\) for some \(D 0\).
2. _(Convex losses)_ For every \(t\), the loss function \(_{t}\) is convex.
3. _(Uniformly bounded subgradients)_ There exists \(G>0\) such that, for all \(t\), \(y\) and \(g_{t}(y)\) we have \(\|g\|_{2} G\).

Apart from the non-negativity assumption \(_{+}^{n}\) which is specific to inventory problems, Assumption 2 is very common in online convex optimization .

**Definition 3** (Regret).: Given an horizon \(T\), we measure the performance of an algorithm with the usual notion of _regret_ which is defined as:

\[R_{T}=_{t=1}^{T}_{t}(y_{t})-_{y}_{t=1}^{T}_ {t}(y).\] (3)

Observe that \(R_{T}\) is possibly random, so we call its expectation the _expected regret_\([R_{T}]\).

Notice that in our model any constant strategy is feasible (see Lemma 26 in the appendix). Thus, the regret (3) is well-defined and can be interpreted as the difference between the cumulative loss incurred by the algorithm and that incurred by the best feasible constant strategy1. It is an easy exercise to see that under Assumption 2 we always have \(R_{T} DGT\) (see Lemma 27 in the appendix). Thus, our goal is to design algorithms with _sublinear_ regret with respect to \(T\), achieving \([R_{T}] o(T)\). Note that some authors consider the equivalent notion of averaged regret \((1/T)R_{T}\). In this context, we would talk about _no-regret_ algorithms.

### Description of standard inventory models and limitations of our model

**Remark 4** (On the demands).: Demands are modeled by a stochastic process \((d_{t})_{t}_{+}^{n}\) with fixed in advance distribution. In other words, we consider a general oblivious model for demands where we make _no_ assumptions of regularity, stationarity or independence. Thus, our model accommodates both _i.i.d._ and _deterministic_ demands , while also allowing for correlations and nonstationarities that appear for instance in autoregressive models. However, we rule out strategic behaviors: this is not a game-theoretic model.

**Remark 5** (On the dynamic).: Inventory states \(x_{t}\) are constrained by the inventory dynamical constraint (2) which links states, demands, and order-up-to levels. This constraint resembles the notion of _partial perishability_ introduced in [9, Section 3.3] which imposes further that inventory states are non-negative. In the following, we present some standard dynamics that conform to our model. We warn the reader that we try here to simplify the vocabulary used in the scattered inventory literature, and that some authors  may refer to these dynamics using different terms2. 
* **Stateless dynamic.** In stateless inventory problems, we assume that no product is carried over from one period to the other, _i.e._\(x_{t}=\). Observe that due to the non-negativity assumption \(_{+}^{n}\), the feasibility constraint (1) is satisfied by any choice of \(y_{t}\) in stateless problems. This means that stateless inventory problems coincide with the usual online convex optimization (OCO) framework . See Appendix D.1 for a discussion on the relationship between OCO and OIO. Any dynamic which is not stateless is called **stateful**, see below.
* **Backlogging dynamic.** In backlogging inventory problems, excess demand stays on the books until it is satisfied and inventory leftovers are carried over to the next period. It corresponds to set \(x_{t+1}=y_{t}-d_{t}\). Notice that in this case the inventory state may be negative to represent backorders. This kind of dynamic has been widely studied in the context of classical inventory theory due to its linear nature, see e.g. [26, Chapter 4].

* **Lost sales dynamic.** Assume that products are nonperishable, excess demand is lost and inventory leftovers are carried over to the next period. We refer to this case as the lost sales dynamic which corresponds to set \(x_{t+1}=[y_{t}-d_{t}]^{+}\). See e.g. .
* **Perishable dynamic.** In perishable inventory systems , newly ordered products are fresh units that have a fixed usable lifetime. To model such a dynamic, it is necessary to track the entire age distribution of the on hand inventory and to specify the stockout type (lost sales or backlogging) and the issuing policy (i.e. how items are issued to meet demand). For instance,  describes a perishable setting modeling a single product with first-in-first-out issuing policy, which satisfies our inventory dynamical constraint (2).

All those dynamics are what we call _deterministic_ dynamics, in the sense that they take the form:

\[( t) x_{t+1}=X_{t}(y_{1},d_{1},,y_{t},d_{t}),\] (4)

where \(X_{t}:(_{+}^{n})^{t}^{n}\) is a fixed in advance function satisfying \(X_{t}(y_{1}^{},d_{1}^{},,y_{t}^{},d_{t}^{}) [y_{t}^{}-d_{t}^{}]^{+}\) for all realizations \((_{t}^{})_{t}\), \((d_{t}^{})_{t}\) and \((y_{t}^{})_{t}\).

**Remark 6** (On the feasible set).: The feasible set \(\) models fixed constraints on the order-up-to levels. Since it should satisfy Assumption 2.i), our framework does not allow for discrete sets as they appear in  for instance. This is one of the main limitations of our work. Typical choices include box constraints: \(=_{i=1}^{n}[_{i},_{i}]\), or capacity constraints : \(=\{y_{+}^{n}_{i=1}^{n}y_{i} M\}\). Note that in some instances, the parameters of the box constraint is dictated by some assumptions on the problem. For instance, it is assumed in  that \(=[0,D]\) where \(D\) is a known upper bound for an optimal constant policy.

**Remark 7** (On the losses).: Losses \((_{t})_{t}\) are random functions drawn before the interactions start. As for demands, we consider an oblivious model for the losses which allows to handle both the _i.i.d._ case and the _deterministic_ case. Most interestingly, losses can depend on the demands. This allows to consider the _newsvendor_ loss, which writes \(_{t}(y)=c(y,d_{t})\) with:

\[c(y,d)=_{i=1}^{n}(h_{i}[y_{i}-d_{i}]^{+}+p_{i}[d_{i}- y_{i}]^{+}).\] (5)

Here \(h_{i}_{+}\) and \(p_{i}_{+}\) are respectively the unit holding cost (a.k.a. overage cost) and unit lost sales penalty cost (a.k.a. underage cost) of product \(i[n]\). The newsvendor loss satisfy assumptions 2.ii) and 2.iii) with \(G=_{i[n]}\{h_{i},p_{i}\}\). Our model also accommodates the newsvendor loss with time-varying unit cost parameters, as long as these remain bounded.

Because the losses are drawn before-hand, our model usually does not allow to incorporate costs that depend explicitly on the inventory states such as purchase costs, outdating costs, or fixed costs. However, there are exceptions: when the dynamic is lost sales, purchase costs can be included into our model, by considering the newsvendor loss onto which a cost transformation is applied (a.k.a. _explicit formulation_[26, Paragraph 4.3.2.4]). See also  and the references therein.

**Remark 8** (On the observability structure and subgradients).: To handle arbitrary losses, we required in our model that in addition to inventory states \(x_{t}\), at least one subgradient \(g_{t}_{t}(y_{t})\) is revealed at each period. In the case of the newsvendor loss, this is less demanding than both the _observable demand_ setting and the _censored demand_ setting . In the former, the demand \(d_{t}\) is revealed instead of a subgradient \(g_{t}\), meaning that the manager has complete information on the newsvendor loss \(_{t}=c(,d_{t})\). In the latter, the sale \(s_{t}:=\{y_{t},d_{t}\}\) is revealed, allowing the manager to compute a subgradient through the following formula (see Lemma 28 in Appendix B):

\[(h_{i}_{\{y_{t},i>s_{t,i}\}}-p_{i}_{\{y_{t,i}=s_{t,i }\}})_{i[n]}_{t}(y_{t}).\]

In this case, we see that no randomization is involved in the choice of the subgradient. This means that the subgradient selection is _deterministic_, in the sense that:

\[( t) g_{t}=_{t}(_{t},y_{t}),\] (6)

where \(_{t}:^{^{n}}^{n}\) is a fixed in advance function such that \(_{t}(_{t}^{},y_{t}^{})_{t}^{}(y_{t} ^{})\) for all realizations \((_{t}^{})_{t}\) and \((y_{t}^{})_{t}\).

**Remark 9** (OIO vs OCO).: In this final remark, we would like to point out that OIO is a novel and strict extension of OCO, that is, OIO cannot be casted into OCO or one of its known extensions. More details on this are provided in Appendix D.1.

## 3 Partial results for simple inventory problems

Previous works on online inventory problems mainly focused on two settings: stateless inventory problems and stateful inventory problems with _i.i.d._ demands. Both settings are discussed here.

### Stateless inventory problems

In the literature of stateless inventory problems, arbitrary deterministic demands have already been considered. This has been done for instance in [13; 34; 35], which assume demand is observable and rely on the "learning with expert advice" framework. On the other hand  is the first work that considered the stateless setting with censored demand. See also  which tackled these problems in the discrete case, by reducing them to partial monitoring (an online learning framework that generalizes bandits). All these works achieve a \(O()\) regret (up to logarithmic terms), but are restricted to the newsvendor cost structure.

In our work, we aim at solving inventory problems with arbitrary demands and losses. Recall that under Assumption 2, stateless inventory problems coincide with the standard OCO framework  since feasibility (1) is trivially verified (see Remark 5). Thus, a natural choice to solve stateless inventory problems is the Online Subgradient Descent (OSD) method, which we recall in Algorithm 1.

```
1Parameters: learning rates \((_{t})_{t}\), initial order-up-to level \(y_{1}\)
2for\(t=1,2,\)do
3 Output \(y_{t}\);
4 Observe \(g_{t}_{t}(y_{t})\);
5 Set \(y_{t+1}=_{}(y_{t}-_{t}g_{t})\); ```

**Algorithm 1**OSD

Classical regret analysis of OSD (this is essentially proven in [8; Theorem 3.1], see also Corollary 20 in the appendix) shows that taking _decreasing_ learning rates of the form \(_{t}= D/(G)\) where \(>0\), leads to a regret bound \(R_{T}=O(GD)\). It must be noted that the \(O()\) scaling is _optimal_ under Assumption 2 (see e.g. [22, Theorem 5] or [21, Theorem 5.1]).

### Stateful i.i.d. inventory problems

When non-trivial dynamics are involved, inventory problems are much more complex and have mainly been studied in the _i.i.d._ demands framework. We review here the literature of joint learning and inventory control with censored demand and refer to the recent review of [5; Chapter 11] for further references. We stress that all those papers obtain rates for the _pseudo-regret_, a lower bound of the expected regret which we consider in this paper (see Appendix D.2 for more details).

The seminal work of Huh and Rusmevichientong  is the first that derives regret bounds for the single-product _i.i.d._ newsvendor case under censored demand, it is also the sole work that considers general dynamics through their notion of _partial perishability_[9; Section 3.3]. They were able to design an algorithm called Adaptive Inventory Management (AIM) based on a subgradient descent and dynamic projections onto the feasibility constraint (1) which achieves a \(O()\) pseudo-regret. Their main assumption is that the demands should not be degenerate in the sense that \([d_{1}]>0\) and that the manager should know a lower bound \(0<<[d_{1}]\). This lower bound is then used in AIM to tune adequately the learning rate of the subgradient descent. Their analysis is based on results from queuing theory which rely heavily on the _i.i.d._ assumption.

Shi et al.  designed the Data-Driven Multi-product (DDM) algorithm which extend the AIM method of  to the multi-product case under capacity constraints. They also derived a \(O()\) pseudo-regret bound by assuming further that demands are pairwise independent across products and that \([d_{1,i}]>0\) for all \(i[n]\) amongst other regularity conditions.

Zhang et al.  tackled the case of single-product _i.i.d._ perishable inventory systems with outdating costs. They designed the Cycle-Update Policy (CUP) algorithm which updates the order-up-to level according to a subgradient descent, but only when the system experiences a stockout, _i.e._ when \(x_{t}=0\), the order-up-to level remains unchanged otherwise. Feasibility is guaranteed using sucha policy. However, in order to derive \(O()\) pseudo-regret they need to ensure that the system experiences frequently stockouts. To do so, they consider a stronger form of non-degeneracy, namely, \([d_{1} D]>0\) where \(=[0,D]\).

Variants of the subgradient descent have also been developed in order to achieve \(O()\) pseudo-regret in inventory systems that includes lead times  or fixed costs  which are both beyond the scope of our model.

To summarize, an optimal \(O()\) rate for the pseudo-regret is achievable in many stateful inventory problems, under the _i.i.d._ assumption. To prove so, most of the cited works developed specific variants of the subgradient descent that accommodates the specific dynamic at play. We will show in Section 4 that this optimal \(O()\) rate can be achieved by our algorithm MaxCOSD when applied to general inventory problems, with no _i.i.d._ assumption on the demand.

## 4 MaxCOSD: an algorithm for general inventory problems

In this section, we introduce and study our main algorithm: the Maximum Cyclic Online Subgradient Descent (MaxCOSD) algorithm. It is a variant of the subgradient descent where instead of changing the order-up-to levels at every period, updates are done only at certain _update periods_ denoted \((t_{k})_{k}\). These define _update cycles_\(_{k}=\{t_{k},,t_{k+1}-1\}\) during which the order-up-to level remains unchanged: \(y_{t}=y_{t_{k}}\) for all \(t_{k}\). Update periods are dynamically triggered by verifying, at the beginning of each time period \(t\), whether a _candidate order-up-to level_\(_{t}\) is feasible or not. This candidate is computed by making a subgradient step in the direction of the subgradients accumulated during the cycle and using the following _adaptive_ learning rates,3

\[_{t}=}^{t}g_{s}\|_{2}^{2}+ _{m=1}^{k-1}\|_{s_{m}}g_{s}\|_{2}^{2}}}\] (7)

The pseudo-code for MaxCOSD is given in Algorithm 2.

```
1Parameters: learning rate parameter \(>0\), initial order-up-to level \(y_{1}\)
2Initialization: Set \(_{1}=y_{1}\), \(t_{1}=1\), \(k=1\);
3for\(t=1,2,\ \)do
4 Output \(y_{t}\);
5 Observe \(g_{t}_{t}(y_{t})\) and \(x_{t+1}\);
6 Compute \(_{t+1}=_{}(_{t_{k}}-_{t}_{s =t_{k}}^{t}g_{s})\) where \(_{t}\) is defined3 in Eq. (7);
7if\(x_{t+1}_{t+1}\)then
8 Set \(y_{t+1}=_{t+1}\), \(t_{k+1}=t+1\), \(k=k+1\);
9else
10 Set \(y_{t+1}=y_{t}\); ```

**Algorithm 2**MaxCOSD

MaxCOSD is inspired by CUP , which handles the feasibility constraint through cyclical updates. This approach differs for instance from AIM  or DDM , where the feasibility is enforced through projections onto the constraint. Among the differences between MaxCOSD and CUP is the fact that their cycle definition differ: in CUP stockouts trigger updates, whereas MaxCOSD relies directly on the feasibility condition, making its updates more frequent. Also, we use adaptive learning rates inspired by AdaGrad-Norm learning rates [27, Theorem 2] which allows us to be adaptive to the constant \(G\) and obtain high probability regret bounds which are not available for CUP. Finally, and most importantly, the assumptions required by CUP are restrictive: _i.i.d._ demands, single-product, perishable dynamic and a strong form of a demand non-degeneracy. On the other hand, MaxCOSD performs well under much milder assumptions, which we introduce next.

**Assumption 10** (Uniformly probably positive demand).: There exists \((0,1]\) and \(>0\) such that, for all \(t\), almost surely,

\[[ i[n],\ d_{t,i}\ \ _{1},d_{1}, ,_{t-1},d_{t-1}].\] (8)

In simple settings we recover through Assumption 10 conditions that already appeared in the literature:

* In single-product _i.i.d._ newsvendor inventory problems, our assumption is equivalent to the existence of \(>0\) such that \([d_{1}]>0\), that is, \([d_{1}>0]>0\), or equivalently \([d_{1}]>0\). This is exactly the non-degeneracy assumption required by  in AIM.
* In its multi-product extension,  assumes also pairwise independence across products. If we rather require mutual independence across products, then, Assumption 10 rewrites \([d_{1,1}>0][d_{1,n}>0]>0\), thus, our assumption reduces to \([d_{1,i}]>0\) for all \(i[n]\) which is also required by  in their algorithm DDM.
* We recover an assumption made for CUP  by requiring \(=D\) where \(=[0,D]\), and where \(D\) is also assumed to be large enough (see Remark 6).
* If the demand is deterministic, then \(=1\) and Eq. (8) becomes \(d_{t,i}\) for all \(i[n]\).
* If the demand is discrete, i.e. \(d_{t,i}\{0,1,\}\) for all \(t,i[n]\), then, we can take \(=1\) and rewrite Eq. (8) as follows: \([ i[n],d_{t,i}=0|_{1},d_{1},,_{t-1},d_{ t-1}] 1-\).

In addition to Assumption 10 we also introduce a mild technical condition.

**Assumption 11** (Deterministic dynamic and subgradient selection).: Dynamics and subgradient selections are deterministic, see Eq. (4) and Eq. (6).

We can now state our main result: under this new set of assumptions MaxCOSD achieves an optimal \(O()\) regret bound both in expectation and in high probability.

**Theorem 12**.: _Consider an inventory problem, and let assumptions 2, 10 and 11 hold. Then, MaxCOSD (see Algorithm 2) run with \(y_{1}\) and \(>0\) is feasible. Furthermore, when \((0,/D]\), it enjoys the following regret bounds for all \(T\),_

\[[R_{T}]GD}{}( ++1),\]

_and for any confidence level \((0,1)\) we have with probability at least \(1-\),_

\[R_{T} GD(++1)(1+ ()).\]

The obtained regret scales in \(O()\), which is similar to other methods in the literature (see Section 3.2). As for the scaling in the constants \(\) and \(\), our rate scales like \(O()\) and we do not know whether this can be improved or not. As a matter of comparison, CUP enjoys the same scaling (see [32, Theorem 2 & Remark 3 & Assumption 1]).

## 5 Non-degenerate demands are needed for stateful inventory problems

Throughout this paper, we have seen instances of OIO which can be solved with sublinear regret rates: stateless OIO (equivalent to OCO), and some stateful OIO. It must be noted that, contrary to OCO, solving those stateful OIO problems required a non-degeneracy assumption on the demand (see Assumption 10 and Section 3.2). We argue here that such an assumption is necessary for solving stateful OIO. Note that this idea is not new, and was already observed in the conclusion of : _"To control for the impact of overordering, demands must be bounded away from zero, at least in expectation."_. Our contribution is to make this observation formal.

**Proposition 13**.: _Given any feasible deterministic4 algorithm for the single-product lost sales newsvendor inventory problem with observable demand over \(=[0,D]\), there exists a sequence of demands such that the regret is linear, i.e. \(R_{T}=(T)\)._Proposition 13 shows that Assumption 2 is not sufficient to reach sublinear regret in general inventory problems. This is totally unusual from an OCO perspective, and is a specificity of _stateful_ OIO. Furthermore, the above result shows that what prevents us from reaching sublinear rates is not the limited feedback (demands and losses are observable in this example) but rather _zero demands_. This is why it is necessary to make an assumption preventing demands to be too small, in some sense. Note that one may think of imposing positive demands to circumvent this difficulty, but this is not sufficient. Indeed, a sequence of demands converging too fast to zero can also be problematic.

**Proposition 14**.: _Given any feasible algorithm for the single-product lost sales problem with observable demand over \(=[0,D]\) such that \(y_{1}(0,D]\), there exists a constant sequence of losses and a sequence of positive demands such that the regret is linear, i.e. \(R_{T}=(T)\)._

Let us now investigate why degenerated demand becomes a problem when going from stateless to stateful OIO. The main difference between the two is that the feasibility constraint is always trivially satisfied for stateless OIO (see Remark 5). Instead, for stateful OIO, we can show that the higher is the demand, the easier it is for the feasibility constraint to be satisfied.

**Lemma 15**.: _Let \(y,y^{},d_{+}^{n}\). If \(\|y^{}-y\|_{2}_{i[n]}d_{i}\), then, \(y^{}[y-d]^{+}\). In particular, given an inventory problem and a time period \(t\), taking \(y_{t+1}_{+}^{n}\) such that \(\|y_{t+1}-y_{t}\|_{2}_{i[n]}d_{i,t}\) ensures that \(y_{t+1}\) is feasible, in the sense that \(x_{t+1} y_{t+1}\)._

The above lemma shows that if \(y_{t+1}\) is taken close enough from the previous \(y_{t}\), then the algorithm is feasible. The key point here is that "close enough" is controlled by the demand, meaning that when the demand is closer to zero there are less feasible choices for the manager. In such a case, we understand that it may be impossible to achieve sublinear regret, because the set of feasible choices could be too reduced.

The distance between two consecutive decisions can easily be controlled in methods based on subgradient descents, through their learning rates. This is why Lemma 15 is very helpful in the design of efficient feasible algorithms. It has been employed in the proof of our main result regarding MaxCOSD (Theorem 12). In the following, we further illustrate its usefulness by showing that OSD (see Algorithm 1) with adequate learning rates is feasible when the demand is _uniformly positive_.

**Assumption 16** (Uniformly positive demand).: There exists \(>0\) such that for all \(t\), \(i[n]\),

\[d_{t,i}.\] (9)

**Theorem 17**.: _Consider an inventory problem, and let assumptions 2 and 16 hold. Then, OSD (see Algorithm 1) run with \(y_{1}\) and \(_{t}= D/(G)\) where \((0,/D]\), is feasible and satisfies for all \(T\) that \(R_{T}(1+2)(2)^{-1}GD\)._

## 6 Numerical results

The goal of the following numerical experiments5 is to show the versatility and performances of MaxCOSD in various settings. Let us consider the following problems.

* **Setting 1.** Single-product lost sales inventory problem with _i.i.d._ demands drawn according to \((1)\).
* **Setting 2.** Single-product perishable inventory problem with a lifetime of \(2\) periods and _i.i.d._ demands drawn according to \((1)\).
* **Setting 3.** Multi-product lost sales inventory problem with \(n=100\) and capacity constraints. Demands are _i.i.d._ and drawn independently across products according to \((_{i})\) where the intensities \(_{i}\) have been drawn independently according to \(\).
* **Setting 4.** Multi-product lost sales inventory problem with \(n=3049\) and capacity constraints. Demands are taken from the real-world dataset of the M5 competition .
* **Setting 5.** Multi-product lost sales inventory problem with \(n=3049\) and box constraints. As in Setting 4 we considered demands from the M5 competition dataset .

We use the newsvendor loss in all the settings. In all the settings the cost parameters satisfy \(p_{i}/h_{i}=200\) since this ratio is known to exceed 200 in many applications . In settings 1, 2 and 3, \(h_{i}=1\) and in settings 4 and 5, \(h_{i}\) and \(p_{i}\) are proportional to the real average selling costs.

In settings 1, 2, 3 and 4 we compare MaxCOSD against the following baselines: AIM  for Setting 1, CUP  for Setting 2, and DDM  for settings 3 and 4. In Setting 5, we ran a parallelized version of MaxCOSD, that is, one instance of MaxCOSD per product, and a parallelized version of AIM. Notice that in Settings 4 and 5 demands are not _i.i.d._ and thus, do not fit the assumptions of the baselines considered. Notice also that Theorem 12 requires MaxCOSD's learning rate to be small enough (\(/D\)), which we do not try to enforce here. All the algorithms have been initialized with \(y_{1}=\). Settings 1, 2 and 3 have been run \(10\) times, with different demand realizations generated through independent samples.

Figure 1 shows, for every setting, the regret obtained after \(T\) periods as a function of the learning rate parameter \([10^{-5},10^{1}]\). We picked \(T=1969\) for all the settings because it corresponds to the number of periods available in our real-world dataset . We see that MaxCOSD performs well compared to baselines whenever the number of handled products remains low (Settings 1,2,3,5). Instead, we see that MaxCOSD is less efficient when the number of products becomes large, in particular in the Setting 4. The performance of MaxCOSD in the large \(n\) regime can be explained by the fact that the cycles become longer, as it becomes less likely that the feasibility condition is satisfied. Indeed, we have seen in Lemma 15 that the larger the overall demand is, the easier feasibility holds. But when \(n\) grows, \(_{i}d_{i,t}\) becomes smaller, making the problem harder.

## 7 Conclusion

In this paper, we address Online Inventory Optimization problems by introducing MaxCOSD, the first algorithm which can be applied to a wide variety of real-world problems. More precisely, MaxCOSD enjoys an optimal \(O()\) regret without assuming the demand to be _i.i.d._, and can handle a large class of dynamics, including perishability models. We achieved this result by applying ideas and methods from online learning to OIO problems.

Still, there is a lot of space for improvements and future developments. First, we observed that for problems with a large number of products and capacity constraints, the empirical performance of MaxCOSD could be improved. To do so, one would need to better handle the feasibility constraint, by using for instance projections onto the feasibility constraint, an idea already used by DDM, but with no theoretical guarantees so far in real-world scenarios. Second, we obtained regret bounds under minimal structural assumptions on the problem (convex lipschitz losses), but we could expect to obtain better rates by making stronger assumptions on the problem. One such assumption, which is classical in the Online Convex Optimization literature, is to assume further that the losses are strongly convex or exp-concave, typically leading to a logarithmic \(O((T))\) regret. Another assumption,

Figure 1: Regret in settings 1 to 5 (from left to right) as a function of the learning rate parameter \(\).

which is more specific to the Online Inventory literature, is to make some regularity assumption directly on the demand, also leading to a logarithmic pseudo-regret in the newsvendor case [3, Subsection 2.3]. Finally, even if our model is quite versatile, it has its limits, and more work is needed to improve it. For instance, we have seen in Section 2.2 that we do not accommodate for outdating costs as they appear in . Also, we do not handle discrete feasible sets for which two promising techniques have been applied in the literature: expert algorithms  and probabilistic rounding [9, Subsection 3.4]. We could also hope to further weaken our non-degeneracy Assumption 10, by making an hypothesis which applies independently to each product, without having to assume pairwise independence across products. We believe that an adequate adaptation of online convex optimization techniques to the online inventory framework will prove to be a successful strategy for overcoming those challenges.