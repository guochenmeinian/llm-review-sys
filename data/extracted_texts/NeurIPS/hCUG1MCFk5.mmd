# On the Generalization Properties of Diffusion Models

Puheng Li

Department of Statistics

Stanford University

puhengli@stanford.edu

&Zhong Li1

Machine Learning Group

Microsoft Research Asia

lzhong@microsoft.com

&Huishuai Zhang

Machine Learning Group

Microsoft Research Asia

huzhang@microsoft.com

&Jiang Bian

Machine Learning Group

Microsoft Research Asia

jiabia@microsoft.com

This work was done when Puheng Li was an undergraduate student at Peking University and a research intern at MSRA. The first two authors contributed equally to this work and are ordered alphabetically.Corresponding author.

###### Abstract

Diffusion models are a class of generative models that serve to establish a stochastic transport map between an empirically observed, yet unknown, target distribution and a known prior. Despite their remarkable success in real-world applications, a theoretical understanding of their generalization capabilities remains underdeveloped. This work embarks on a comprehensive theoretical exploration of the generalization attributes of diffusion models. We establish theoretical estimates of the generalization gap that evolves in tandem with the training dynamics of score-based diffusion models, suggesting a polynomially small generalization error (\(O(n^{-2/5}+m^{-4/5})\)) on both the sample size \(n\) and the model capacity \(m\), evading the curse of dimensionality (i.e., not exponentially large in the data dimension) when _early-stopped_. Furthermore, we extend our quantitative analysis to a _data-dependent_ scenario, wherein target distributions are portrayed as a succession of densities with progressively increasing distances between modes. This precisely elucidates the _adverse_ effect of "_modes shift_" in ground truths on the model generalization. Moreover, these estimates are not solely theoretical constructs but have also been confirmed through numerical simulations. Our findings contribute to the rigorous understanding of diffusion models' generalization properties and provide insights that may guide practical applications.

## 1 Introduction

As an emerging family of deep generative models, diffusion models (DMs; [16; 45]) have experienced a surge in popularity, owing to their unparalleled performance in a wide range of applications ([22; 39; 68; 15; 3; 35; 4; 60; 33; 69; 64; 63; 53]). This has led to notable commercial successes, such as DALL-E (), Imagen (), and Stable Diffusion (). Mathematically, diffusion models learn an unknown underlying distribution through a two-stage process: (i) first, successively and gradually injecting random noises (forward process); (ii) then reversing the forward process through denoising for sampling purposes (reverse process). To achieve this, an equivalent formulation of diffusion models called score-based generative models (SGMs; [50; 52]) is employed. SGMs implement the aforementioned two-stage process via the continuous dynamics represented by a joint group of coupled stochastic differential equations (SDEs) ([54; 20]).

Despite their impressive empirical performance, the theoretical foundation of DMs/SGMs remains underexplored. Generally, fundamental theoretical questions can be categorized into several aspects. By considering machine learning models as mathematical function classes from certain spaces, one can identify three central aspects: approximation, optimization and generalization. At the forefront lies the generalization problem, which aims to characterize the learning error between the learned and ground truth distributions.

The development of generalization theory for diffusion models is pressing due to both theoretical and practical concerns:

* In theory, the generalization issues of generative modeling (or learning for distributions) may exhibit as the memorization phenomenon, if the modeled distribution is eventually trained to converge to the empirical distribution only associated with training samples. Intuitively, memorization arises from two reasons: (i) it is useful for the hypothesis space to be large enough to approximate highly complex underlying target distributions (universal convergence; ); (ii) the underlying distribution is unknown in practice, and one can only use a dataset with finite samples drawn from the target distribution. Rigorous mathematical characterizations of memorization are developed for bias potential models and GANs in  and , respectively. A natural question is, does a similar phenomenon occur for diffusion models? To answer this, a thorough investigation of generalization properties for DMs/SGMs is required.
* In practice, the generalization capability of diffusion models is also an essential requirement, as the memorization can lead to potential privacy and copyright risks when models are deployed. Similar to other generative models and large language models (LLMs) [5; 70; 19; 6], diffusion models can also memorize and leak training samples [5; 46], hence can be subsequently attacked using specific procedures and algorithms [28; 18; 62]. Although there are defense methods developed to meet privacy and copyright standards ([11; 14; 58]), these approaches are often heuristic, without providing sufficient quantitative understandings particularly on diffusion models. Therefore, a comprehensive investigation of the generalization foundation of diffusion models, including both theoretical and empirical aspects, is of utmost importance in improving principled tutorial guidance in practice.

The current work develops the generalization theory of diffusion models in a mathematically rigorous manner. Our main results include the following:

* We derive an upper bound of the generalization gap for diffusion models along the training dynamics. This result suggests, with _early-stopping_, the generalization error of diffusion models scales polynomially small on the sample size (\(O(n^{-2/5})\)) and the model capacity (\(O(m^{-4/5})\)). Notably, the generalization error also escapes from the curse of dimensionality.
* This "uniform" bound is further extended to a _data-dependent_ setting, where a sequence of unidimensional Gaussian mixtures distributions with an increasing modes' distance is considered as the ground truth. This result characterizes the effect of "_modes shift_" quantitatively, which implies that the generalization capability of diffusion models is _adversely_ affected by the distance between high-density regions of target distributions.
* The theoretical findings are numerically verified in simulations.

The rest of this paper is organized as follows. In Section 2, we discuss the related work on the convergence and training fronts of diffusion models and also the generalization aspects of other generative modeling methods. Section 3 is the central part, which includes the problem formulation, main results, and consequences. Section 4 includes numerical verifications on synthetic and real-world datasets3. All the details of proofs and experiments are found in the appendices.

## 2 Related Work

We review the related work on diffusion models concerning the central results in this paper.

* First, on the convergence theory, [7; 9] established elaborate error estimates between the modeled and target distribution given the discretization and time-dependent score matching tolerance. Compared to the present work, they did not evolve the concrete training dynamics since the setting therein focuses on the properties of optimizers.
* Second, on the training front,  proposed a set of techniques to enhance the training performance of score-based generative models, scaling diffusion models to images of higher resolution, but without any characterization of possible generalization improvements. Similar to [7; 9],  also provided error estimates between the modeled and target distributions in a point-wise sense and again did not evolve the detailed training dynamics.
* Third, on the generalization and memorization side, corresponding theories are developed for bias potential models and GANs in  and , respectively, where the modeled distribution learns the ground truth with early-stopping and diverges or converges to the empirical distribution only associated with training samples after sufficiently long training time. The current work extends the mathematical analysis to the case of diffusion models under a data-dependent setting.
* As a supplement, we also discuss related literature regarding low-density learning.  illustrated the difficulty of learning from low-density regions with toy formulations and simulations, which motivates the sampling method of annealed Langevin dynamics as the predecessor of (score-based) diffusion models.  restudied similar problems under the pure score matching regime (without the denoising or time-dependent dynamics) and attributed the difficulty to increasing isoperimetry of distributions with modes shift.  defined the Hardness score and numerically justified that decreasing manifold densities leads to the increasing Hardness score, and consequently applied the Hardness score as the regularization to the sampling process to enhance synthetic images from low-density regions. As a comparison, this work establishes a mathematically rigorous estimate on the generalization gap that _quantitatively_ depends on the range of low-density regions (between modes) in target distributions for (score-based) diffusion models that requires _denoising_.

## 3 Formulation and Results

In this section, we first introduce the problem setup. Next, we state the main theoretical results, subsequent consequences, and possible connections. The numerical illustration is provided at last.

### Problem Formulation

Since DMs/SGMs have already grown into a large family of generative models with an enormous number of variants, there are various ways to define the parameterization of diffusion models. Here, we adopt (one of) the most fundamental architectures proposed in , where the forward perturbation and reverse sampling process are both implemented by a joint group of coupled (stochastic) differential equations. See Figure 1 for an illustration of the problem formulation.

Figure 1: Illustration of the problem formulation and important notations.

Forward perturbation.We start with the setting of unsupervised learning. Given an unlabeled dataset \(_{}=\{_{i}\}_{i=1}^{n}^{d}\) with the sample \(_{i}}{}p_{0}()\), where \(p_{0}\) denotes the underlying (ground truth or target) distribution, the forward diffusion process is defined as

\[d=(,t)dt+g(t)d_{t},(0) p_{0}.\] (1)

Here, the drift coefficient \((,t):^{d}^{d}\) is a time-dependent vector-valued function, and the diffusion coefficient \(g():_{ 0}\) is a scalar function, and \(_{t}\) denotes the standard Wiener process (a.k.a., Brownian motion). The SDE (1) has a unique, strong solution under certain regularity conditions (i.e., globally Lipschitz coefficients in both state and time; see ). From now on, we denote by \(p_{t}((t))\) the marginal distribution of \((t)\), and let \(p_{t|s}((t)|(s))\) be the (perturbation) transition kernel from \((s)\) to \((t),0 s<t T<\) with \(T\) as the time horizon. By appropriately selecting \(\) and \(g\), one can force the SDE (1) to converge to a prior distribution (typically a Gaussian). Common examples include the (time-rescaled) Ornstein-Uhlenbeck (OU) process,4 which is a special case of the linear version of (1):

\[d=f(t)dt+g(t)d_{t},(0) p_{0}.\] (2)

Reverse sampling.According to  and , both the following reverse-time SDE and probability flow ODE share the same marginal distribution as the forward-time SDE (1):

\[d=(,t)-g^{2}(t)_{} p_{t }()dt+g(t)d}_{t},\] (3) \[d=(,t)-g^{2}(t)_{} p_{t}()dt,\] (4)

where \(}_{t}\) is a standard Wiener process when time flows backwards from \(T\) to \(0\), and \(dt\) is an infinitesimal negative time step. With the initial condition \((T) p_{T}\), where \(\) is a known prior distribution such as the Gaussian noise, one can (numerically) solve (3) or (4) to transform noises into samples from \(p_{0}\), which is exactly the goal of generative modeling.

Loss objectives.The only remaining task is to estimate the unknown (Stein) score function \(_{} p_{t}()\). This is achieved by minimizing the following weighted sum of denoising score matching () objectives:

\[(;()):=_{t(0,T)} [(t)_{(0) p_{0}}[_{( t) p_{t|0}}[\|_{t,}((t))-_{(t)} p _{t|0}((t)|(0))\|_{2}^{2}]]],\] (5)

with \(^{*}:=_{}(;())\), where \((0,T)\) denotes the uniform distribution over \([0,T]\), and \((t):[0,T]_{+}\) is a weighting function, which is typically selected as

\[(t) 1/_{(t) p_{t|0}}[\|_{(t)}  p_{t|0}((t)|(0))\|_{2}^{2}]}\] (6)

according to (). The score function \(_{t,}:^{d}^{d}\) is time-dependent and can be parameterized as a neural network (encoded with the time information) such as the U-net() architecture commonly applied in the field of image segmentation. Alternatively, one can also define the time-dependent score matching loss

\[}(;()):=_{t(0,T)}[(t)_{(t) p_{t}}[\|_{t, {}}((t))-_{(t)} p_{t}((t))\|_{2}^{2}] ],\] (7)

which is equivalent to (5) up to a constant independent of \(\) by .

In practice, expectations in the objective (5) can be respectively estimated with empirical means over time steps in \([0,T]\), data samples from \(p_{0}\) and \(p_{t|0}\), which is efficient when the drift coefficient \((,t)\) is linear. Specifically, if the forward-time SDE takes the form of (2), the transition kernel \(p_{t|0}\) has a closed form ()

\[p_{t|0}((t)|(0))=((t);r(t)(0),r^{2}(t)v^{2}(t )_{d}),\] (8)

where \((;,)\) denotes the multivariate Gaussian distribution evaluated at \(\) with the expectation \(\) and covariance \(\), and \(r(t):=e^{_{0}^{t}f()d}\), \(v(t):=^{t}()}{r^{2}()}d}\).

Training.We aim to investigate the gradient flow training dynamics over the empirical loss

\[}_{n}()=-_{}_{n}()} }_{n}(}_{n}();()),}_{n}(0):=}_{n}^{0},\] (9)

where \(}_{n}\) is the Monte-Carlo estimation of \(\) defined in (5) on the training dataset,5 with an auxiliary gradient flow over the population loss

\[()=-_{()} (();()),(0):=^{0}=}_{n}^{0}.\] (10)

In both cases, the weighting function \(()\) is selected as in (6). Denote the score function learned at the training time \(\) evaluated at the SDE time \(t\) with respect to the empirical loss and population loss as \(_{t,}_{n}()}((t))\) and \(_{t,()}((t))\), respectively. The corresponding density functions, denoted by \(p_{t,}_{n}()}((t))\) and \(p_{t,()}((t))\), are obtained by solving

\[_{(t)} p_{t,}_{n}()}((t) )=_{t,}_{n}()}((t)),_{(t)}  p_{t,()}((t))=_{t,()}((t )),\] (11)

and then normalizing, respectively.

Score networks.We parameterize the score function \(_{t,}\) as the following random feature model

\[_{t,}():=( +(t))=_{i=1}^{m}_{i}(_{i}^ {}+_{i}^{}(t)),\] (12)

where \(\) is the ReLU activation function, \(=(_{1},,_{m})^{d m}\) is the _trainable_ parameter, while \(=(_{1},,_{m})^{}^{m d}\) and \(=(_{1},,_{m})^{}^{m d_{x}}\) are randomly initialized and _frozen_ during training, and \(:_{ 0}^{d_{x}}\) is the embedding function concerning the time information. Assume that \(_{i}\), \(_{i}\) and \(_{i}\) are i.i.d. sampled from an underlying distribution \(\). Then, as \(m\), we get

\[_{t,}()}_{t,}}() :=_{(,,)}( ^{}+^{}(t))\] \[=_{(,)_{0}}[(,)(^{}+^{}(t))],\] (13)

with \((,):=(,)}_{^{d}} (,,)d\) and \(_{0}(,):=_{^{d}}(,,)d\). By the positive homogeneity property of the ReLU activation, we can assume that \(\|\|_{1}+\|\|_{1} 1\) w.l.o.g.

One can view \(}_{t,}}()\) as a continuous version of the random feature model. Correspondingly, the optimal solution is denoted as \(}^{*}\) when replacing the parameterized score function \(_{t,}()\) in the loss objective (5) or (7) by \(}_{t,}}()\). Define the kernel \(k_{_{0}}(,^{}):=_{(,)_{0}} [(^{}+^{}(t))(^{}^{}+^{}(t))]\), and let \(_{k_{_{0}}}\) be the induced reproducing kernel Hilbert space (RKHS; ), we have \(}_{t,}}_{k_{_{0}}}\) if the RKHS norm \(}_{t,}}_{_{k_{_{0}}} }^{2}:=_{(,)_{0}}\|(,)\|_{2}^ {2}=\|\|\|_{2}\|_{2}^{2}(_{0})<\), and the corresponding discrete version can be defined by the empirical average, i.e., \(\|_{t,}\|_{_{k_{_{0}}}}^{2}:=\| \|_{F}^{2}=_{i=1}^{m}\|(_{i},_{i})\|_{2}^{2}\).

**Remark 1**.: _There are more modern and complex mathematical tools such as neural tangent kernels (NTKs) and mean fields that can be selected as the score networks. Employing these modern tools is valuable at least for theoretical completeness and we leave these as the future work.6_

The goal is to measure and bound the generalization error evolving with the gradient flow training dynamics (9) between the learned distribution and target distribution, using the common Kullback-Leibler (KL) divergence.

**Definition 1** (KL divergence).: _Given two distributions \(p\) and \(q\), the KL divergence from \(q\) to \(p\) is defined as \(D_{}(p||q)=_{^{d}}p()()}{q( )})d\)._

Based on the above definitions, the generalization gap along the gradient flow training dynamics (9) is formulated as \(D_{}(p_{0}||p_{0,}_{n}()})\), which is only a function of the training time \(\). The goal is to estimate \(D_{}(p_{0}||p_{0,}_{n}()})\).

### Main Results

In this section, we state the main results of the generalization capability of the (score-based) diffusion models and how it evolves as the training proceeds. Based on the formulation in Section 3.1, we theoretically derive several upper bounds to estimate \(D_{}(p_{0}\|p_{0,}_{n}()})\) under different settings. The results cover both the positive and negative aspects: in the data-independent setting where the target distribution has finite support, the generalization gap is proved to be small; while in the data-dependent setting where the target distribution possesses shift modes, the generalization is adversely affected by the modes' distance.

#### 3.2.1 Data-Independent Generalization Gap

In this section, we provide the characterization of the generalization capability for diffusion models given a target distribution defined on a finite domain. Generally, the KL divergence from the learned distribution \(p_{0,}_{n}()}\) at the training time \(\) to the target distribution \(p_{0}\) can be estimated as follows.

**Theorem 1**.: _Suppose that the target distribution \(p_{0}\) is continuously differentiable and has a compact support set, i.e., \(||||_{}\) is uniformly bounded, and there exists a reproducing kernel Hilbert space (RKHS) \(\) (:=\(_{k_{_{0}}}\)) such that \(}_{0,}}\). \(\). Assume that the initial loss, trainable parameters, the embedding function \((t)\) and weighting function \((t)\) are all bounded. Then for any \(>0\), \( 1\), with the probability of at least \(1-\), we have_

\[D_{}(p_{0}\|p_{0,}_{n}()}) [}{mn}+}{m^{2}}+] +[+}}(}^{ })+}(^{}) ]+D_{}(p_{T}\|), 1,\]

_where \(\) hides the term \(d(d+1)\), the polynomials of \((1/^{2})\), finite RKHS norms and universal positive constants only depending on \(T\)._

**Remark 2**.: _Since \(p_{0}\) is compactly supported, the target score function \(_{0}()=_{} p_{0}( )\) is also defined on a compact domain. According to , \(_{0}\) is contained in the Barron function space with a finite Barron norm, and hence in a certain RKHS with a finite RKHS norm. Therefore, it is reasonable to require that the global minimizer \(_{0,^{}}\) or \(}_{0,}^{}}\) is also contained in some RKHS._

Proof sketch.Theorem 1 is proved via the following procedure.

1. According to Theorem 1 in , the KL divergence on the left-hand side can be upper bounded by the population loss of the trained model up to a small error. That is, \[D_{}(p_{0}\|p_{0,}_{n}()}) }(}_{n}();g^{2}())+D_{ }(p_{T}\|).\] (14)
2. We use the model trained with respect to the population loss (10) to perform the decomposition: \[}(}_{n}()) =[}(}_{n}())- }(())]+}( ())\] \[[}(}_{n}( ))-}(())]+}}(}())+ I _{1}+I_{2}+I_{3},\] (15) where we omit the weighting function \(g^{2}()\) for simplicity. Here, \(}}\) is the loss objective obtained by replacing \(_{t,}\) in \(}\) (defined in (7)) by \(}_{t,}\), and \(I_{3}\) summarizes the resulting Monte Carlo error.
3. \(I_{3}\) can be estimated via a similar argument as in  (Lemma 48).
4. \(I_{2}\) can be upper bounded via a standard analysis on the gradient flow dynamics over convex objectives.
5. \(I_{1}\) can be reduced as the norm product of \(_{0,}_{n}()}\), \(_{0,()}\) and their gap, then 1. the former can be bounded with a square-root rate growth via a general norm estimate of parameters trained under the gradient flow dynamics; 2. the latter can be estimated by the Rademacher complexity (see e.g., Chapter 26 in ).

Combining all above gives the desired result. The detailed proof is found in Appendix A.1.

Discussion on error bounds.The three error terms are further analyzed as follows.

* The first term is the main error, which implies an _early-stopping_ generalization gap. In fact, if one selects an early-stopping time \(_{}\) as \(_{}=(n^{})\), and let \(m n\), we have \[D_{}(p_{0}\|p_{0,_{n}(_{})} )(1/n)^{}+(1/m)^{}.\] (16)
* The second term is \(m\)-dependent and corresponds to the approximation error, which is \(o(1)\) when \(m 1\). In fact, the random feature model is a universal approximator to Lipschitz continuous functions on a compact domain (Theorem 6 in ). See more details in Appendix A.1 (the last paragraph).
* The third term is exponentially small in \(T\) since \(\) (e.g. the Gaussian density) is log-Sobolev, according to a classical result in e.g.  (Theorem 3.20, Theorem 3.24 and Remark 3.26).

**Remark 3**.: _In practice, it is common to use the test error to evaluate the generalization performance. For diffusion models, a straightforward approach is to compute the negative log-likelihood (averaged in bits/dim; equivalent to the KL divergence) on the test dataset during training with the instantaneous change-of-variable formula () and probability flow ODE (defined in (4)), where the true score function \(_{} p_{t}()\) is replaced by \(_{t,()}()\)._

**Remark 4**.: _Previous literature has established similar bounds for bias potential models () and GANs (). Theorem 1 extends the corresponding results to the setting of diffusion models. Furthermore, this upper bound is finer in the sense that it incorporates the information regarding the model capacity (the hidden dimension \(m\) in this case), which shows that more parameters benefit the learning and generalization, as expected._

#### 3.2.2 Data-Dependent Generalization Gap

In Section 3.2.1, we derive estimates on the generalization error for diffusion models along the training dynamics, where the target distribution is assumed to be finitely supported. In reality, this is often not the case, where target distributions usually possess distant multi-modes, from simple Gaussian mixtures to complicated Boltzmann distributions of physical systems (). Under these settings, the above analysis in Section 3.2.1 can not directly apply since the data domain is unbounded. It remains a problem to quantitatively characterize the generalization behavior of diffusion models given these target distributions with distant multi-modes or modes shift.

To provide a fine-grained demonstration of the generalization capability of diffusion models when applied to learn distributions with distant multi-modes, as an illustrating example, the Gaussian mixture with two modes is selected as the target distribution.

**Theorem 2**.: _Suppose the target distribution \(p_{0}\) is a one-dimensional 2-mode Gaussian mixture: \(p_{0}(x)=q_{1}(x;-,1)+q_{2}(x;,1)\), where \(>)}\), \(q_{1}\), \(q_{2}>0\) with \(q_{1}+q_{2}=1\) are all constants. Under the conditions of Theorem 1 (except the uniform boundness of inputs), we have_

\[D_{}(p_{0}\|p_{0,_{n}()}) ()[}{mn}+}{m^{2}} ]++[}{m}+}}( ^{*})+}(^ {*})]+D_{}(p_{T}\|),\]

_where \( 1\), \(\) hides the polynomials of \((1/^{2})\), finite RKHS norms and universal positive constants only depending on \(T\)._

Proof sketch.Theorem 2 is proved following a similar procedure with Theorem 1, except the input data \(x\) does not have a uniform bound here. This problem mainly affects the last step (5 (b)) in the proof sketch of Theorem 1, and can be handled by using the fact

\[|x|[-)},+)}]=()\] (17)

given the target Gaussian mixture distribution. The detailed proof is found in Appendix A.2.

**Remark 5**.: _Theorem 2 indicates that, even for a simple target distribution (e.g. a one-dimensional 2-mode Gaussian mixture), the generalization error of diffusion models can be polynomially large regarding the modes' distance. Although Theorem 2 provides only an upper bound, the modes shift effect holds due to the model-target inconsistency (the last paragraph in Appendix A.2) and the following consistent experiments (Section 4.1.2)._

Figure 2: An illustration of modes shift.

Numerical Verifications

In this section, we numerically verify the previous theoretical results and insights (early-stopping generalization and modes shift effect) on both synthetic datasets and real-world datasets.

### Simulations on Synthetic Datasets

#### 4.1.1 Early-Stopping Generalization

First, we illustrate the early-stopping generalization gap established in Theorem 1. We select the one-hidden-layer neural network with Swish activations as the score network, which is trained using the SGD optimizer with a fixed learning rate \(0.5\). The target distribution is set to be a one-dimensional 2-mode Gaussian mixture with the modes' distance equalling 6, and the number of data samples is 1000. We measure the KL divergence from the trained model to the target distribution \(D_{}(p_{0}\|p_{0,_{}()})\) along with the training epochs.

From Figure 3, one can observe that the KL divergence achieves its minimum at approximately the \(800\)-th training epoch, and it starts to increase after this turning point. The experimental results are consistent with Theorem 1 (over multiple runs), which states that there exist early-stopping times when diffusion models can generalize well, indicating the effectiveness of our upper bound. Further, the KL divergence begins to oscillate after the minimum point, which may suggest a phase transition in the training dynamics, and the transition point is around the (optimal) early-stopping time.

#### 4.1.2 Modes Shift Effect

Next, we numerically test the relationship between the modes' distance and generalization (density estimation) performance. All the configurations remain the same as Section 4.1.1, except that the target Gaussian mixtures have different modes' distances.

In Figure 4, the modeled distributions exhibit the following two-stage dynamics: (i) first gradually fitting the two modes (epoch \(=100 1000\)); (ii) then diverging (epoch \(=1000 1900\)). This aligns with the KL divergence dynamics (Figure 3) and again verifies the corresponding theoretical results (Theorem 1). However, Figure 5 shows that when the modes are distant from each other, there is _difficulty_ in the learning process. In Figure 5, the optimal generalization is achieved at epoch \(=100\), but is still far from well generalizing. As the training proceeds, the learned model is almost always a single-mode distribution (epoch \(=1000\), \(1900\)). This phenomenon is aligned with the results established in Theorem 2, which states that when there are distant modes in the target distribution, the generalization performance is relatively poor.

Figure 4: The training dynamics when the distance between two modes is 6 (\(=3\)).

Figure 3: The KL divergence dynamics.

### Simulations on Real-World Datasets

In this subsection, we verify our results on the MNIST dataset using the standard U-net architecture as the score network, which suggests that the adverse effect of modes shift on the generalization performance of diffusion models also appears _in general_.

The setup is as follows. First, we perform a \(K\)-means clustering on \(\) (\(\) denote the MNIST dataset) to get \(=_{k=1}^{K}_{k}\), and \(}_{k}\) as the center of \(_{k}\), \(k=1,2,,K\). Let \((i^{*},j^{*}):=*{arg\,max}_{i j}\|}_{i}-}_{j}\|_{2}\), and \(_{}:=_{i^{*}}_{j^{*}}\). \(_{}\) is similarly constructed by \(*{arg\,min}\) indices. Then, by randomly selecting the same number of data samples and using the same configuration, we train two separate diffusion models on \(_{}\) and \(_{}\), respectively, and then perform inference (sampling). The training loss curves and sampling results are shown in Figure 6 and Figure 7, respectively. One can observe a significant performance gap: the diffusion model trained on \(_{}\) appears a higher learning loss and worse sampling quality compared to those of \(_{}\).

Figure 5: The training dynamics when the distance between two modes is 30 (\(=15\)).

Figure 6: The training loss dynamics.

Figure 7: Sampling of the farthest (left) and nearest (right) clusters.

### Discussion

We compare the results developed in this work with former corresponding literature as follows:

* The previous work  also studied the adverse effect of modes shift, which particularly reported a contrastive simulation indicating the degraded performance when modeling Gaussian mixtures with the increasing distance between modes (see Figure 2 in  and compare with Figure 4 and Figure 5). However, the results therein are established and tested under the "pure" score matching setting, without the denoising or time-dependent dynamics. As a comparison, Theorem 2 establishes a theoretical estimate on the generalization gap for diffusion models that requires _denoising_, and this upper bound _directly_ depends on the distance between modes of target distributions, instead of a circuitous characterization in  to attribute the difficulty of learning modes shift to increased isoperimetry of corresponding target distributions.
* Similar adverse effect of modes shift has also been theoretically analyzed and numerically verified on recurrent neural networks (RNNs), see e.g., [23; 24]. There, the modes shift is understood as a type of long-term memory. This is the phenomenon of the "curse of memory": When there is long-term memory in the target, it requires a large number of parameters for the approximation. Meanwhile, the training process will suffer from severe slowdowns. Both of these effects can be exponentially more pronounced with increasing memory or modes shift.
* The very recent work  also considered the problem of learning Gaussian mixtures using the denoising diffusion probabilistic model (DDPM) objective, but under a _teacher-student_ setting. That is, given the Gaussian mixtures target,  parametrized the score network model in the same form of the score function target, with the goal to identify true parameters. Consequently, there are all positive convergence results developed in , despite that the time and sample complexity increases with the distance between modes. As a comparison, Theorem 2 adopts a pre-selected score network model without incorporating any information from the ground truth, and hence establish negative results concerning the modes shift. In fact, if the goal is to identify only true positions of the target Gaussian mixture (this is exactly the setting of ), the teacher-student setup seems not necessary (see Figure 5, where the true position is also learned efficiently using the one-hidden-layer Swish neural network as the score network, but the modes are always weighed incorrectly). In addition,  did not take the whole denoising dynamics into account. That is, the gradient descent (GD) analysis therein was performed on the denoising score matching objective successively at only two time stages: a larger \(t_{1}\) ("high noise") and a smaller \(t_{2}\) ("low noise"), which is often not the case in practice.

## 5 Conclusion

In this paper, we provide a theoretical analysis of the fundamental generalization aspect of training diffusion models under both the data-independent and data-dependent settings, and early-stopping estimates of the generalization gap along the training dynamics are derived. Quantitatively, the data-independent results indicate a polynomially small generalization error that escapes from the curse of dimensionality, while the data-dependent results suggest the adverse effect of modes shift in target distributions. Numerical simulations have illustrated and verified these theoretical analyses. This work forms a basic starting point for understanding the intricacies of modern deep generative modeling and corresponding central concerns such as memorization, privacy, and copyright arising from practical applications and business products. More broadly, the approach here may have the potential to be extended to other variants in the diffusion models family, including a general SDE-based design space (), consistency models (), rectified flows ([27; 26]), Schrodinger bridges ([59; 56; 10; 44; 47; 25]), etc. These are certainly worthy of future exploration.