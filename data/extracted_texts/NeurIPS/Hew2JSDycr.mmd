# BiScope: AI-generated Text Detection by Checking Memorization of Preceding Tokens

Hanxi Guo

Purdue University

guo778@purdue.edu

&Siyuan Cheng

Purdue University

cheng535@purdue.edu

&Xiaolong Jin

Purdue University

jin509@purdue.edu

&Zhuo Zhang

Purdue University

zhan3299@purdue.edu

&Kaiyuan Zhang

Purdue University

zhan4057@purdue.edu

&Guanhong Tao

University of Utah

guanhong.tao@utah.edu

&Guangyu Shen

Purdue University

shen447@purdue.edu

&Xiangyu Zhang

Purdue University

xyzhang@cs.purdue.edu

###### Abstract

Detecting text generated by Large Language Models (LLMs) is a pressing need in order to identify and prevent misuse of these powerful models in a wide range of applications, which have highly undesirable consequences such as misinformation and academic dishonesty. Given a piece of subject text, many existing detection methods work by measuring the difficulty of LLM predicting the next token in the text from their prefix. In this paper, we make a critical observation that how well the current token's output logits memorizes the closely preceding input tokens also provides strong evidence. Therefore, we propose a novel bi-directional calculation method that measures the cross-entropy losses between an output logits and the ground-truth token (forward) and between the output logits and the immediately preceding input token (backward). A classifier is trained to make the final prediction based on the statistics of these losses. We evaluate our system, named BiScope, on texts generated by five latest commercial LLMs across five heterogeneous datasets, including both natural language and code. BiScope demonstrates superior detection accuracy and robustness compared to nine existing baseline methods, exceeding the state-of-the-art non-commercial methods' detection accuracy by over \(0.30\) F1 score, achieving over \(0.95\) detection F1 score on average. It also outperforms the best commercial tool GPTZero that is based on a commercial LLM trained with an enormous volume of data. Code is available at [https://github.com/MarkGHK/BiScope](https://github.com/MarkGHK/BiScope).

## 1 Introduction

Given the superior performance of Large Language Models (LLMs) in understanding and generating text, they have become an integral part of human society, assisting people with daily activities such as summarizing articles, polishing emails, and more. However, the widespread use of LLMs also raises concerns about the misuse of AI-generated text. For instance, students and academics may utilize LLMs to produce content for their assignments and research , compromising academic integrity. Adversarial individuals could leverage LLMs to efficiently create inflammatory and fraudulent content on social media . Additionally, the development of LLMs themselves faces challenges related to the quality of existing datasets, which may be compromised by the significantinclusion of AI-generated text . All of these issues underscore the urgent need to distinguish AI-generated text from human-written text .

Despite this urgency, current AI-generated text detection techniques fall short as LLMs become increasingly diverse and advanced. Our experiments demonstrate that most of the existing approaches cannot achieve an F1 score exceeding 80% on the Yelp dataset  when using the latest LLMs (e.g., Claude-3-Opus) to generate content. A close examination of these approaches reveals inherent limitations by design. Specifically, there are three kinds of methods that do not need pre-training or additional information on the LLMs that generate the data (_e.g._, watermarking ). The first kind  directly prompts another LLM or NLP model to classify whether the subject text is AI-generated. While intuitive, the inevitable model hallucination  consistently prevents it from achieving a high accuracy. The second kind of methods  examines the linguistic features of the subject text, which are increasingly susceptible to deception as LLMs become more sophisticated and human-like in their responses. The third approach  feeds partial or entire text to a surrogate model and checks how well the output text aligns with the surrogate model's preference via various metrics or downstream classifiers. While this method outperforms the first two approaches, it only examines the next token information in the output logits, representing just part of model behaviors, thereby naturally limiting its performance.

In this work, we explore the potential of leveraging internal model states to detect AI-generated text. Like existing methods, we hypothesize that since LLMs are trained on vast corpora of data from the Internet, their training data likely exhibit significant similarities, leading to similar behaviors across models. Therefore, we use a surrogate model to approximate the behaviors of the one used to generate the subject text. We also make a critical observation that, in causal language models (_e.g._, GPT), the current token's output logits encode information about both the next token (_i.e._, prediction) and its preceding input tokens (_i.e._, memorization), indicating a bidirectional relationship between the output logits and the input text. Specifically, when these causal language models encounter human data, they tend to memorize more preceding token information while predicting less next token information in their output logits.

To reveal this relationship, we calculate two kinds of cross-entropy losses by feeding different portions of the subject text into the surrogate model. One is the forward information, calculated as the cross-entropy loss between the output logits and the expected next token in the subject text. The other is the backward information, calculated as the cross-entropy loss between the output logits and the most preceding input token. We then train a binary classifier on the collected statistical loss features to make the final prediction. We also introduce several novel improvements in the prototype, such as providing a summary of the subject text to better guide the surrogate model, thereby enhancing its practical effectiveness and robustness, and using parallel model inference to enhance efficiency. As such, we propose BiScope, an effective and efficient AI-generated text detector by harnessing both the prediction and memorization features of the LLM through its output logits.

Our contributions are as follows:

* We propose a novel AI-generated text detection algorithm that exploits both the preceding token information (_i.e._, memorization) and the next token information (_i.e._, prediction) via an innovative bi-directional cross-entropy loss calculation method. Additionally, we are the first to utilize text summaries to guide the detection, further enhancing its effectiveness and robustness toward heterogeneous data.
* We extend existing datasets and craft a large-scale public dataset for more challenging AI-generated texts, consisting of \(25\) distinct groups and more than \(22,000\) samples. The dataset is sourced from five different text domains (both natural language and code) and generated by the five latest commercial LLMs. This dataset presents more challenging scenarios compared to existing datasets, which are typically sourced from open-source LLMs with fewer parameters and capabilities. We also craft a paraphrased version of our dataset.
* We develop a prototype named BiScope, a detection pipeline without any fine-tuning needed for the detection LLM. We evaluate it on our dataset and compare it with nine state-of-the-art baseline techniques. Our results show that BiScope can achieve an average F1 score of over \(0.95\), taking less than \(200\) milliseconds to detect a sample (when the summary procedure is disabled), while the baseline techniques achieve only \(0.70\)-\(0.85\) F1 scores and take up to \(27\) seconds per sample. BiScope also outperforms the best commercial tool,GPTZero, in 72% of cases. Additionally, we conduct a comprehensive ablation study to verify the effectiveness and robustness of each component of BiScope.

## 2 Background and Related Work

In addition to various watermarking techniques [7; 19; 44; 46; 20; 24; 15; 52] that require fine-tuning or additional information about the LLMs generating the text, several efforts have been directed towards the detection of AI-generated texts with minimal prior knowledge about the generative models. These efforts broadly fall into three categories. As stated in SS 1, the first two categories perform worse than the last category, hence we mainly focus on the methods in the third category that use a surrogate LLM in this paper. The methods in the third category can be further divided into two types: statistical methods and training-based methods.

**Statistical Methods.** These techniques [45; 34; 21; 33] primarily utilize pre-trained LLMs to simulate the generation process of the target generative AI, analyzing the statistical differences between AI-generated texts and human-written ones. These methods commonly serve as zero-shot approaches, assigning scores to indicate the probability of texts being AI-generated. For example, Zero-shot Query [32; 48] prompts a pre-trained LLM to score the input text. LogRank [11; 35] calculates the average probability rank of each token in a text processed through a pre-trained LLM, where higher ranks suggest the text is AI-generated. LRR  improves on LogRank by incorporating token confidence. DetectGPT  involves masking parts of the text to see how an LLM reconstructs them, and Raidar  employs the LLM to rewrite the text. Both methods assume that AI-generated texts are more likely to be preserved accurately in the process. Binoculars  analyzes the cross-entropy between the output logits from two surrogate models with different fine-tuning configurations.

**Training-based Methods.** This type includes methods train an NLP model to distinguish between AI-generated and human-written texts. For example, OpenAI  uses a RoBERTa-based model for training an AI-text classifier. Such methods can be susceptible to adversarial attacks or paraphrasing. The state-of-the-art technique RADAR  leverages adversarial training to improve the robustness of the classifier. There are also commercial services for the detection of AI-generated texts. For example, **GPTZero** employs a multi-step statistical detection process and utilizes a pre-trained commercial LLM to deliver the prediction.

Our approach, BiScope, is a statistical method that uniquely incorporates meticulous statistical feature extraction via a bi-directional calculation method to ensure its general effectiveness and robustness against paraphrasing across five text domains and five of the latest commercial LLMs. To evaluate BiScope, we compare it with nine existing detection methods, including Zero-shot Query [48; 32], LogRank , LRR , DetectGPT , RADAR , Raidar , OpenAI Detector , Binoculars , and GhostBuster , as well as with the most renowned commercial detection API, **GPTZero**. We surpass these baseline methods in both effectiveness and efficiency.

## 3 Methodology of BiScope

### Design Motivation

Although existing AI-generated text detection methods have been proven to be robust against texts generated by various open-source LLMs, their performance degrades in more complex and real-world scenarios, especially when dealing with the latest commercial LLMs and heterogeneous text genres. The degradation can be attributed to the following two reasons: **feature insufficiency** and **contextual heterogeneity**.

**Feature Insufficiency.** Existing methods focus on analyzing the difficulty a surrogate LLM experiences in predicting the next token given the preceding input text. For example, these methods use the rank or the probability of the next token as a metric or compare the discrepancy between the input text and the surrogate model's generation. Figure 1(a) presents the detection F1 score of a toy example that uses the average next token rank from Llama-2-7B as the feature and a random forest model as the classification model on both human text (in blue) and GPT-4-Turbo's text (in orange). The detection F1 score only reaches 0.55, which is just slightly better than random guesses. This indicates the lack of a clear separation using only next token ranks. One may argue that the random forest may not be powerful enough. However, we will show later that using additional features proposed in the paper, the same random forest configuration could achieve much better results.

We observe that the internals of the surrogate LLM when used to predict the subject text have much richer information that can be used. Figure 2 illustrates how LLM encodes information. The arrows and texts in green illustrate the information related to the next token, while the arrows and texts in gray show the information related to the preceding tokens. In the auto-regressive generation mode, the LLM receives the tokens preceding to the current position as the input and outputs the logits that contains its prediction for the next token. During this procedure, its internal states encode the preceding tokens (i.e., memorization)  while implicitly "planning" for the next token , namely, as observed by researchers in , the internal states show similarities to the encodings of future tokens. The output logits, which can be considered as a reduced representation of the model's internal states, also contains both the information to predict the next token and the information of preceding tokens. Existing methods focus only on the former by comparing the output logits with the expected next token. In this paper, we propose to consider the preceding token information as well. In particular, we hypothesize the following: **for human-written text, the surrogate LLM has a poor prediction for the next token and a strong memory of the previous token, reflected in the output logits, whereas the behaviors for LLM-generated text are the opposite.** Intuitively, it's like when we humans are unsure of what to say next, and the last word tends to stay in our minds.

To validate our hypothesis, we conducted an experiment in which we compared the current output logits with the preceding token for a piece of a given text, leveraging the same random forest as before. Figure 1(b) and (c) present the detection F1 score when only using the preceding token's rank and when using both the preceding and next tokens' ranks (to distinguish human and LLM texts), reaching 0.73 and 0.78 F1 scores, respectively, denoting a 0.2 F1 score improvement compared to using the next token information alone. Observe that in (d) for next token prediction, the AI texts (in orange) tend to have a smaller CE loss than human texts (in blue), indicating the LLM has a better prediction for the AI texts. In (e) for previous token memorization, the human texts tend to have a smaller loss than the AI texts, indicating the LLM has poorer memory for AI texts. Figures (a) and (b) and an additional example in Appendix B show a similar trend. These support our hypothesis.

Thus, in BiScope, we design a novel bi-directional cross-entropy loss computation method that computes the cross-entropy losses between the output logits and the expected next token, and between the output logits and the preceding token. Figure 1(d)-(f) illustrate the F1 scores when using the cross-entropy losses for next token, previous token, and both. Observe they achieve better results compared to using plain ranks, due to the more wealthy information encoded. An additional example using GPT-Neo-2.7B in Appendix B shows a similar trend.

**Contextual Heterogeneity.** In addition to insufficient feature utilization, we also observe that contextual heterogeneity significantly influences detection accuracy. Existing methods directly use surrogate LLMs to generate the given text in an auto-regressive manner, without incorporating any

Figure 1: Comparison of detection F1 scores when utilizing the rank Figure 2: Comparison and cross-entropy loss regarding next token, preceding token or both. of output logits information The surrogate detection model is Llama-2-7B.

additional information of the context (for the text). As such, given a prefix part of the text, the LLM may have a diverse set of possible completions, limiting the ability to separate human and LLM texts.

To alleviate this problem, we formalize our detection as a guided completion task, using a surrogate LLM to first summarize the entire input text. These text summaries are then used to guide the completion, providing complementary contextual information and making the features more robust.

### Overview of BiScope

The entire workflow of BiScope can be summarized in four key steps, shown in Figure 3.

Step 1: **Completion Prompt Generation.** In the first step, we initialize the detection as a guided text completion task. We use a surrogate LLM to summarize the input text and generate a text summary as a guidance. We then divide the input text into two segments. The first segment, along with a completion request, is utilized to construct a text completion request. The text summary guidance and the text completion request form a completion prompt. Details are presented in SS 3.3.

Step 2: **Loss Computation In Text Completion.** Given the completion prompt and the second segment of the input text from Step 1, we then calculate our novel bi-directional cross-entropy losses for the tokens in the second text segment using multiple open-source LLMs in parallel. Details are presented in SS 3.4. The use of multiple LLMs is to reduce the uncertainty.

Step 3: **Statistical Feature Extraction.** We vary the separation of the two segments at different positions of the subject text (e.g., one-fourth, half, and three-fourth of the whole length). For each setup, we collect the statistics of the bi-directional cross-entropy loss values. The statistics are concatenated to form a feature vector. More details and justifications are presented in SS 3.5.

Step 4: **Feature Classification.** In the final step, we use the concatenated feature vector to train a binary classifier, which determines whether the input text is human-generated or AI-generated. Further details are presented in SS 3.6.

### Completion Prompt Generation

In BiScope, we calculate the bi-directional cross-entropy losses within a guided text completion scenario. This scenario involves providing a text summary guidance and a short sub-string of the input text to force LLMs to generate the remainder of the text. Specifically, to alleviate the impact of contextual heterogeneity during text generation, we first utilize a surrogate LLM to summarize the entire input text and obtain a summary as guidance. We then divide the input text into two segments (e.g., the first 10% and the remaining 90%). The first segment, referred to as Input Text Segment 1, serves as the sub-string in a text completion request, while the second segment, referred to as Input Text Segment 2, is used as the completion ground-truth in SS 3.4. By appending the text completion request after the summary guidance, we construct a completion prompt shown as follows:

Given the summary:  {Text Summary Guidance}  Complete the following text:  {Input Text Segment 1}

Figure 3: Overview of BiScope. Arrows and texts in brown indicate text summarization.

The text in black indicates the text completion request, while the text in brown indicates the guidance, which is summarized using the following prompt:

Write a title for this text: {Input Text}

The summary contains the aggregated contextual information of the entire text, providing complementary guidance to the LLM completion, in addition to the first segment. To balance the detection accuracy and efficiency, BiScope can also disable this text summary procedure to achieve faster AI-generated text detection with satisfactory accuracy.

### Loss Computation In Text Completion

After crafting the completion prompt, we then feed it into multiple open-source LLMs in parallel to obtain multiple output logits that correspond to the Input Text Segment 2 from SS 3.3 using the _teacher forcing pattern_, which feeds the ground-truth token prefixes (Input Text Segment 2) to compute the output logits at each token position. These output logits can be used to measure how likely the LLMs predict the next token given its prefix in the subject text and how well the LLMs memorize the preceding token, according to our discussion in SS 3.1. We hence propose a bi-directional cross-entropy calculation method in BiScope, which consists of both forward and backward cross-entropy calculations. The forward cross-entropy (\(\)) calculation is identical to the commonly used cross-entropy in most LLM training processes, utilizing the output logits and the next ground-truth token to capture the output logits' next-token-related information. In contrast, the backward cross-entropy (\(\)) is calculated between the output logits and the immediate preceding input token, capturing how much the logits memorizes the preceding token. The detailed \(\) and \(\) calculations at token position \(i\) with LLM \(\) are shown in Equation 1:

\[_{i}=-_{z=1}^{||||}_{i+1}^{z}( _{i}^{z}),_{i}=-_{z=1}^{||||} _{i}^{z}(_{i}^{z}) \]

where \(\) indicates the vocabulary of the LLM, \(_{i}\) denotes the soft-maxed output logits from \(\) at position \(i\) of the generated text (when given the preceding tokens from the completion prompt). \(}_{i}\) indicates the ground-truth token encoding at the same position.

### Statistical Feature Extraction

The aforementioned bi-directional cross-entropy loss values may have different characteristics when the text is partitioned at different positions. Intuitively, when the text is partitioned at a ratio of 1:9, meaning that we use the first 10% of the text to perform the completion, there tends to be a lot more uncertainty compared to a partition of 9:1. A naive design is to fix a partition ratio. However, finding the most effective partition is difficult. Another design is to use the loss values computed at all positions. However, it can hardly deal with length variations of input texts. Therefore, our design is to partition the whole text into \(n\) segments (\(n=10\) in our implementation). For each segment, we collect the bidirectional loss value statistics over all the positions with the segment, including the _mean_, _maximum_, _minimum_, and _standard deviation_ values. This allows us to align texts of various lengths and leverage the later classification to figure out the best partition positions (through learning). Additionally, this multi-segment analysis requires only a one-time inference of the input text, as the loss calculation at each position is independent of the others via teacher forcing. This allows BiScope to obtain various and sufficient features with high efficiency.

### Feature Classification

In the final step, we concatenate all the statistical features of both the \(\) and \(\) vectors from all the detection LLMs into a one-dimensional feature vector, which is then used to train a binary classifier to perform the classification. Due to the generality of these features, the binary classifier can be directly used to detect unseen data, whether from unknown LLMs or unfamiliar text domains.

[MISSING_PAGE_FAIL:7]

[MISSING_PAGE_FAIL:8]

baselines with a \(0.29\) average F1 score increase. Additionally, existing baselines experience an overall \(0.03\) F1 detection score drop compared to their performance on the normal dataset. In contrast, our BiScope performs even better on the paraphrased dataset, with an overall \(0.02\) average F1 score increase. Under the out-of-distribution setting, we train the classifiers for all the methods on the normal dataset, while testing them on the paraphrased dataset, exploring the generality of the detection against unseen paraphrased data. Our BiScope outperforms existing baselines with an average \(0.29\) F1 detection score increase.

### Comparison with The Latest Commercial Detection Method

We also compare BiScope with the latest version (2024-01-09) of the most renowned commercial AI-generated text detection API, GPTZero , across all five datasets, as shown in Figure 6. BiScope outperforms GPTZero in 72% of the cases. Specifically, BiScope achieves a \(0.02\), \(0.01\), and \(0.01\) average F1 detection score increase on the Arxiv, Essay, and Creative datasets, respectively. On the Yelp dataset, BiScope's F1 detection score is \(0.04\) lower than GPTZero's. However, on the code dataset, BiScope performs significantly better than GPTZero, achieving a \(0.19\) average F1 score improvement, demonstrating BiScope's superior generality from natural language to code. Note that GPTZero's detection model is pre-trained on millions of data points, while our BiScope's classifier is trained on at most \(4,000\) test samples for each case.

### Efficiency Analysis

To address real-world challenges, efficiency is crucial for detection methods. We compared BiScope with nine baselines across five datasets, detailing average processing times for a single sample in Figure 8. RADAR is the fastest at \(0.01\)s per sample, while its adversarial training overhead may be considerable. Processing times for the other baselines are as follows: zero-shot query at \(0.32\)s, LogRank at \(0.05\)s, LRR at \(0.10\)s, DetectGPT at \(15.95\)s, Raidar at \(27.42\)s, OpenAI Detector at \(0.03\)s, Binoculars at \(0.19\)s, and GhostBuster at \(0.37\)s. Zero-shot query, LogRank, LRR, and OpenAI Detector are much quicker than DetectGPT, Raidar, Binoculars, and GhostBuster but offer lower detection performance and robustness. Our BiScope processes a sample in \(0.14\)s without summary guidance, matching the real-time levels of zero-shot query, LogRank, and LRR, while improving detection F1 score by over \(0.30\). With summary guidance, BiScope's processing time increases to \(1.35\)s per sample, still 12 to 20 times faster than DetectGPT and Raidar, and achieves the highest detection score.

### Ablation Study

We further evaluate the importance of each component in BiScope with two categories of ablation experiments. Since BiScope utilizes six open-source LLMs in parallel and ensemble their features, we first investigate the contribution of each LLM's feature in Figure 7 individually. Then, we further explore the contribution of BiScope's \(\) and \(\) losses respectively, compared with their aggregated performance, shown as Figure 8. More detailed results are shown in Appendix E. We also present more detailed ablation study on the impact of different segmentation strategies in multi-point splitting (Appendix E.3), and the impact of the completion prompt (Appendix E.4), in Appendix E.

**BiScope's Performance with Different Base Models.** We individually test all the detection base models in BiScope both with and without the summary procedure, including Gemma-2B, Gemma-7B, Llama-2-7B, Mistral-7B, Llama-3-8B, and Llama-2-13B. All the detection models help BiScope achieve over a \(0.84\) overall F1 detection score across all five datasets, demonstrating high consistency across different detection base models. As the size of the detection base model increases, BiScope performs progressively better, with F1 scores improving from \(0.84\) to \(0.95\).

**Importance of \(\) and \(\) in BiScope's Detection.** To demonstrate the rationality of the proposed bi-directional cross-entropy losses, we also evaluate BiScope by only using either \(\) or \(\) losses, and using both of them with the Llama-2-7B model, as shown in Figure 8. When using both the \(\) and \(\) losses, BiScope achieves the best average F1 detection score across the five datasets, which is \(0.94\), highlighting the necessity of combining both \(\) and \(\) loss features. When only using \(\) or \(\), BiScope reaches \(0.86\) and \(0.93\) average F1 detection scores, respectively, indicating that \(\) is more discriminative than \(\).

## 5 Limitations and Future Work

Our BiScope can achieve over a \(0.95\) F1 detection score across five datasets generated by the five latest commercial LLMs, both with and without intentional paraphrasing, illustrating the importance of the preceding token information in the output logits. However, in the OOD cross-dataset setting, there is a noticeable \(>0.10\) detection F1 score drop, highlighting the challenges in this setting. Thus, there is still room for future research to achieve more effective and robust detection in few-shot and cross-dataset settings, where the training set contains fewer samples and the test set comes from different text domains. Additionally, exploring ways to further exploit preceding token information and combine it with next token information should also be a future direction in the field of AI-generated text detection.

## 6 Conclusion

Existing methods to differentiate AI-generated texts from human-generated texts often analyze the difficulty for a surrogate LLM to generate the next token based on previous tokens from the text. We propose a more discriminative approach via a novel bi-directional cross-entropy calculation method, leveraging both the preceding token information and the next token information in the output logits. We integrate this method into a four-step detection pipeline, BiScope, which consists of Completion Prompt Generation, Loss Computation in Text Completion, Statistical Feature Extraction, and Feature Classification. We evaluate BiScope on five datasets, including both natural language and code, against six existing detection methods. BiScope surpasses all these methods, improving the average F1 detection score by \(0.30\) and also outperforming the well-known commercial API - GPTZero in 72% cases, while maintaining a real-time processing speed of less than 200ms per sample.