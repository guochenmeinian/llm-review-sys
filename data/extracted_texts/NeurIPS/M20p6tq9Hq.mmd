# Identifiability Guarantees for Causal Disentanglement

from Purely Observational Data

 Ryan Welch

Massachusetts Institute of Technology

Broad Institute of MIT and Harvard

&Jiaqi Zhang

LIDS, Massachusetts Institute of Technology

Broad Institute of MIT and Harvard

&Caroline Uhler

LIDS, Massachusetts Institute of Technology

Broad Institute of MIT and Harvard

Equal contributions.

###### Abstract

Causal disentanglement aims to learn about latent causal factors behind data, holding the promise to augment existing representation learning methods in terms of interpretability and extrapolation. Recent advances establish identifiability results assuming that interventions on (single) latent factors are available; however, it remains debatable whether such assumptions are reasonable due to the inherent nature of intervening on latent variables. Accordingly, we reconsider the fundamentals and ask what can be learned using just observational data.

We provide a precise characterization of latent factors that can be identified in nonlinear causal models with additive Gaussian noise and linear mixing, without any interventions or graphical restrictions. In particular, we show that the causal variables can be identified up to a _layer_-wise transformation and that further disentanglement is not possible. We transform these theoretical results into a practical algorithm consisting of solving a quadratic program over the score estimation of the observed data. We provide simulation results to support our theoretical guarantees and demonstrate that our algorithm can derive meaningful causal representations from purely observational data.

## 1 Introduction

Advances in representation learning play a pivotal role in the application of machine learning across various fields, including natural language processing, computer vision, and life sciences (c.f., ). The emerging field of causal disentanglement holds the promise to augment such advances by identifying and learning some aspects about the latent causal factors behind data . These latent causal factors have been shown to improve the interpretability of high-level concepts behind complex high-dimensional data  and enable extrapolation to predict how novel interventions will affect the data .

In pursuit of causal disentanglement, two _critical_ questions are: (1) to theoretically understand to what extent the latent causal factors are identifiable, and (2) to algorithmically design efficient methods to learn these factors with finite samples. Despite the recent surge of interest in this area, these questions remain difficult given the inherent challenges of both disentanglement and causal discovery. In the disentanglement literature, the latent factors are assumed to be independent, and it is known that identifying them is not possible without further knowledge on the data-generating process . Relaxing the independence assumption, causal disentanglement considers potentially related latentfactors and aims to discover not only the latent factors but also their latent causal relations. Since this extends disentanglement, the latent factors are unidentifiable without additional information. Furthermore, learning causal relations is notoriously challenging as the number of variables grows: the underlying structure is generally not unique , and it is computationally and sample inefficient to learn complex causal graphs [12; 51].

To overcome these difficulties, a trend in recent works has been to consider having access to interventional data, where a common assumption is to assume that interventions on all single latent factors are available [43; 2; 47; 59; 50; 48; 9]. Although a goal of causal disentanglement is to be able to control individual latent factors, it is debatable whether assuming existence of direct interventions on latent factors is reasonable [36; 7; 49], since one can argue that direct interventions on (single) latent factors make these factors non-latent. Furthermore, it might be infeasible to perform interventions on (some of) the factors due to ethical or cost reasons. As a consequence, it is important to understand what can be achieved solely based on observational data.

In our work, we consider causal disentanglement from purely observational data. The key idea behind our approach is to utilize _asymmetries_ in the joint distribution of the latent factors. In particular, we consider latent factors that are generated by an unknown nonlinear causal model with additive Gaussian noises, from which we obtain observations after an unknown linear mixing. Nonlinear models with additive Gaussian noises have been a popular choice in the causal discovery literature due to their flexibility, intriguing identifiability properties (in the fully observed setting), and benign statistical sample complexities [31; 38; 35; 61]. These models imply asymmetric relationships between causes and effects, which can be utilized to distinguish causal directions. Beyond their theoretical properties, these models are commonly chosen to represent real world causal systems, such as gene regulatory networks , given their ability to fit non-parametric relationships.

**Contributions and Organization.** We define nonlinear additive Gaussian noise models in the context of causal disentanglement in Section 2. We provide a precise characterization of latent factors that can be identified in such models, with purely observational data and no graphical restrictions. In particular, we show that the latent variables can be identified up to a layer-wise transformation that is consistent with the underlying causal ordering, and that further disentanglement is not possible. These results are provided in Section 3. We transform these theoretical results into practical algorithms in Section 4 by building upon recent successes of combining score matching and causal discovery [35; 29] to devise a method that solves a quadratic program over the score estimation of the observed data. The resulting algorithm enjoys efficiency and flexibility to be combined with any existing off-the-shelf score estimation method. We demonstrate our results empirically with simulations in Section 5, and conclude with a discussion in Section 6.

### Related Work

**Causal disentanglement.** Previous works in causal disentanglement have mostly considered varying assumptions on: the available data, the underlying causal model of the latent factors, and the mixing function between latent factors and observed data. Assuming the availability of interventional data, [24; 43; 9] established results for parametric causal models, whereas [47; 2; 59; 50; 17; 48] studied non-parametric causal models. Most of these works assume linear mixing (or a special case of polynomial mixing that can be easily reduced to linear functions), with the exception of [9; 50; 17; 48], where stronger assumptions on either the parametric causal model or more interventions are required to compensate for the general mixing functions. Prior to these works, [1; 8] established results assuming counterfactual data, which usually leads to stronger identifiability as one can now contrast counterfactual pairs.

Few recent works considered identifiability without interventions [45; 58; 56]. These works typically assume that (parts of) the latent factors can be observed after multiple different mixing functions. In the case where only one observational dataset is available, which is the setting of this paper, previous works have obtained results assuming both parametric models as well as additional structural restrictions on the mixing function [11; 19; 54; 55; 21]. Such structural restrictions refer to constraints on the set of latent variables that determine each observed variable, which is distinct from functional restrictions on the mixing function such as linearity. An example of such restrictions is the pure child assumption [40; 14], specifying that each observed variable has only one latent parent. To the best of our knowledge, _our work is the first to establish identifiability guarantees of causal disentanglement_in the purely observational setting without imposing any structural assumptions over the mixing function_. We summarize these comparisons to prior works in Table 1.

We additionally recognize that identifiability of latent factors from purely observational data has been considered outside of causal disentanglement [35; 20]. However, these results do not extend to the setting considered in this work, given the assumed data generating processes to do encapsulate the causal graph.

**Score matching in causal discovery.** Since our algorithm builds upon discovery methods using score matching, we briefly review these approaches. Works in this direction have mainly focused on causal discovery when all causal variables are observable in identifiable paramteric causal models such as nonlinear additive Gaussian noise or additive non-Gaussian noise models [35; 29; 34; 37; 28]. These methods first learn a topological ordering of the causal variables using the second-order derivative of the log-likelihood estimated from score matching. They then apply regression based DAG pruning techniques [10; 26] to retrieve the full causal structure. We note that these works do not inherently extend to causal disentanglement, for they assume direct access to the causal variables that disentanglement intends to learn.

Expanding these ideas to causal disentanglement is difficult, since we do not observe the latent factors and can only estimate the log-likelihood of the observed variables. Surprisingly, our theory suggests a simple principle to obtain meaningful estimates of the latent factors from the log-likelihood of the observed variables. Moreover, we show that a simple quadratic program can be used to implement this principle, which leads to an efficient algorithm borrowing strength from both nonlinear optimization and machine learning.

Our principle for identifiability directly expands the main result from , where variance properties on the diagonal elements of the Jacobian over the score of causal variables are used to derive a topological ordering. While we utilize this result, it is not sufficient for disentanglement given the aforementioned Jacobian can only be determined up to an unknown quadratic form when the causal variables are unobserved. Therefore, our principle additionally relies on properties of the entire Jacobian matrix, which we present in Section 3.2.

Additionally, we recognize the inherent difficulties of both non-convex optimization and second-order score estimation essential for modern score matching methods, which we discuss further in Section 4.1 and Section 5.1 respectively.

## 2 Setup

We now formally define the causal disentanglement problem and introduce relevant definitions. We consider the observed variables \(X=(X_{1},...,X_{d})^{}^{d 1}\) as generated from the latent causal factors \(Z=(Z_{1},...,Z_{n})^{}^{n 1}\) via an unknown invertible linear mixing. We do not assume that

    & Data & Latent Model & Structural Mixing & Identifiability Results \\ 
[1; 8] & Counterfact. & General & **No** & Fully identifiable. \\
[43; 9; 48; 50] & Hard Interv. & LG & **No** & Fully identifiable. \\
[2; 49; 50] & Hard Interv(s). & General & **No** & Fully identifiable. \\
[49; 59] & Soft Interv. & General & **No** & Up to transitive closure. \\
 & Multi-view & LG & **No** & Block-wise identifiable. \\
 & Multi-view & NL & **No** & Block-wise identifiable. \\
[14; 19] & **Purely Obs.** & Discrete & Yes & Up to Markov equivalence. \\
[11; 54; 55] & **Purely Obs.** & LNG & Yes & Fully identifiable. \\
 & **Purely Obs.** & NL & Yes & Fully identifiable. \\
**This work** & **Purely Obs.** & NLG & **No** & Up to causal layers. \\   

Table 1: **Comparison of our results to prior works on causal disentanglement.** For the latent model, \(L\) stands for linear mechanisms whereas \(NL\) stands for nonlinear mechanisms; \(G\) stands for Gaussian noise whereas \(NG\) stands for non-Gaussian noise; _Discrete_ refers to discrete causal variables. Here, we summarize the identifiability results in terms of latent causal graph identification.

the latent dimension \(n\) is known a priori, but rather can be learned as given by the principle presented in Lemma 1 of . These latent factors follow a joint distribution \(p()\), which factorizes according to an unknown directed acyclic graph (DAG) \(\). We summarize the setup in the following assumption.

**Assumption 1** (Linear mixing).: _Our data-generating process can be written as_

\[X=H Z, Z p(Z)=_{i=1}^{n}p(Z_{i}|Z_{pa(i)}),\]

_where \(H^{d n}\) has full column rank and \(pa(i)\) denotes the parents of node \(i\) in \(\)._

We assume linear mixing as it is essential for our theoretical guarantees presented in Section 3.2. However, our results also extend to settings where the true mixing function can be reduced to a linear map, such as in the case of a special class of polynomials . For the distribution of \(Z\), we consider nonlinear additive Gaussian noise models as follows.

**Assumption 2** (Nonlinear additive Gaussian noise model.).: _The factorization term in the joint distribution over \(Z\) is specified by_

\[Z_{i}=f_{i}(Z_{pa(i)})+_{i}, i[n],\]

_where \(f=\{f_{i}:i[n]\}\) are twice continuously differentiable, non-linear2 functions that capture the dependence of \(Z_{i}\) on its parents, and \(=\{_{i}:i[n]\}\) denote exogenous noise variables, which are mutually independent and mean-zero Gaussians, i.e., \(_{i}(0,_{i}^{2})\)._

We use \(p_{X}()\) to denote the induced distribution over the observed variables \(X\). We consider causal disentanglement from purely observational data, where we only have access to a dataset consisting of samples from \(p_{X}()\). Our goal is to learn the most about \(Z\) (or equivalently, \(,\), and \(f\)) using this dataset. We additionally note that this problem has also been called _causal representation learning_ in literature. Figure 1 illustrates the described setup.

**Estimators.** We denote generic estimators of \(Z\) and \(\) from \(X\) by \((X):^{d}^{n}\) and \(}(X):^{d}^{n}\) respectively. In our setup, these estimators are constructed by learning the inverse of the unknown mixing matrix \(H\). We denote a valid estimate of this mixing matrix by \(^{d n}\), and its Moore-Penrose inverse by \(^{}=^{}(^{})^{-1}\). To obtain an estimate of \(Z\), we use \((X)=^{} X\). For simplicity, we denote the transformation from the estimated latent \((X)\) to the true latent factors \(Z\) by the matrix \(^{n n}\), where \(=H^{}\) and \(Z=(X)\).

**Graph notation.** We use \(ch(i)\), \(an(i)\) and \(de(i)\) to denote the children, ancestors and descendants of node \(i\) in \(\), respectively. Node \(i\) is called a root node if \(an(i)=\), and a leaf node if \(de(i)=\). We define the \(k^{th}\) layer of \(\), denoted by \(layer(k)\), to be the set of all nodes whose longest path to a leaf node is \(k\). Figure 2 illustrates this concept. With a slight abuse of notation, we will interchangeably use \(Z_{i} layer(k)\) to denote \(i layer(k)\).

Figure 1: **The considered data-generating process.** The latent variables \(Z\) follow a nonlinear causal model with additive Gaussian noises. We observe them after an unknown linear mixing (gray edges).

Figure 2: **Layers of the causal DAG.** A latent variable is contained in \(layer(k)\) if its longest path to a leaf node is \(k\).

Identifiability Results

In this section, we present our main theoretical results. We start by providing a precise characterization of latent factors that are identifiable in Section 3.1. We then demonstrate identifiability by providing a constructive proof in Section 3.2. Counterexamples showing that further disentanglement is not possible and our results cannot be strengthened are given in Section 3.3. Detailed proofs are deferred to Appendix A. Throughout this section, we consider the infinite-data regime where enough samples are obtained to exactly determine the observational distribution \(p_{X}()\).

### Layer-wise Transformations

For each latent causal factor \(Z_{i}\), we show that its identifiability is dependent on the layer of the corresponding node. Specifically, we show that \(Z_{i} layer(k)\) can be identified up to a linear combination of all variables in \(layer(k) layer(k+1) layer(r)\), where \(r\) denotes the top most layer. The formal definition is as follows.

**Definition 1** (Identifiability up to upstream layers).: _The latent causal variables \(Z\) are identifiable up to upstream layers if it is possible to learn \((X)\) from \(p_{X}()\) such that:_

\[(X)=P_{} C Z, Z^{n},\]

_where \(P_{}^{n n}\) is a permutation matrix, and \(C^{n n}\) is a constant matrix with non-zero diagonal entries and \([C]_{i,j}\) = 0 for all \(i,j\) such that \(i layer(k)\) and \(j_{l k}layer(l)\)._

This identifiability notion implies that each causal variable can be learned up to a linear combination that does not depend on its descendants. Intuitively, this implies that variables that are more upstream in the underlying causal DAG can more easily be identified. In particular, the root nodes (i.e., the most upstream causal factors) can be identified up to a linear transformation of themselves.

Beyond this \(Z\)-based notion of identifiability, we can further disentangle the exogenous noise variables up to a transformation that depends only on its own layer. The formal definition is as follows.

**Definition 2** (Identifiability up to layers).: _The exogenous noise variables \(\) are identifiable up to layers if it is possible to learn \(}(X)\) from \(p_{X}()\) such that:_

\[}(X)=P_{} C, ^{n},\]

_where \(P_{}^{n n}\) is a permutation matrix, and \(C^{n n}\) is a constant matrix with non-zero diagonal entries and \([C]_{i,j}\) = 0 for all \(i,j\) such that \(i layer(k)\) and \(j layer(k)\)._

Next, we prove these notions of identifiability in a constructive way using the score function of \(p_{X}()\).

### Identification via Score Functions

Our analysis will rely on the _score function_ of the observational distribution of \(X\), denoted by

\[s_{X}(x)=_{x} p_{X}(x),\]

as well as its _Jacobian matrix_ whose \(ij^{th}\) entry is given by \([J_{X}(x)]_{ij}=_{x_{i}}_{x_{j}} p_{X}(x)\). Since \(X\) and \(Z\) are related through a linear transformation, we can easily write out the closed form for both the score and associated Jacobian of the latent variables \(Z\) as follows.

**Lemma 1**.: 1

_Under Assumption 1, the score functions and associated Jacobian matrices over \(X\) and \(Z\) are related via the following transformations:_

\[s_{Z}(z)=H^{}s_{X}(x), J_{Z}(z)=H^{}J_{X}(x)H.\]

For an estimator \((X)= X\), we utilize Lemma 1 to obtain the following:

\[J_{}()=^{}J_{X}(x)=^{}J_{Z}(z).\]This shows that we can compute \(J_{}\) once we estimate \(\) and \(J_{X}\) from \(p_{X}()\), and that \(J_{}\) relates to the Jacobian matrix over the true latent variables, \(J_{Z}\), via a quadratic form \(J_{}=^{}J_{Z}\), where \(\) is a product of the unknown \(H^{}\) and \(\).

Under the nonlinear additive Gaussian noise model in Assumption 2,  demonstrated that the \(i^{th}\) diagonal element of \(J_{Z}\) will have zero variance if and only if node \(i\) is a leaf node in \(\). Building on this result, we can derive a sufficient and necessary condition for when the \(i^{th}\) diagonal element of \(J_{}\) will have zero variance involving the unknown matrix \(\) as follows.

**Lemma 2**.: _The \(i^{th}\) diagonal element of \([J_{}()]_{ii}\) has zero variance, i.e., \(([J_{}()]_{ii})=0\), if and only if the \(i^{th}\) column of \(\) has zero entries in every element corresponding to non-leaf nodes._

This result provides the intuition that leads to the principle for achieving identifiability. In particular, if we maximize the number of zero-variance terms in the diagonal elements of the estimated Jacobian \(J_{}\), then the unknown matrix \(\) must have a maximum number of columns with zeros in all indices corresponding to non-leaf nodes. Since \(Z=\), we can derive the relation between \(\) and \(Z\) under this maximization, which we summarize in the following lemma.

**Lemma 3**.: _If we learn \(\) by solving_

\[_{^{n}} \|(J_{}(^{}x))\|_{0},\] (1) \[ ()=n,\]

_then it follows that_

\[_{i}=(Z_{non-leaf})&\ \ ([J_{}()]_{ii}) 0,\\ (Z)&\ \ ([J_{}() ]_{ii})=0,\]

_where the number of \(i[n]\) such that \(([J_{}()]_{ii})=0\) equals to the number of leaf nodes in \(\)._

It follows from this lemma that we can obtain representations of all non-leaf nodes as linear transformations of all non-leaf latent variables (i.e. \(layer(1)\) and above). In other words, we can disentangle the leaf nodes out from the non-leaf nodes. Given this identified linear transformation of the non-leaf nodes, we can iteratively apply Lemma 3 to prune representations of each variable as a linear combination of all variables in its own and upstream layers. This leads to our main theorem.

**Theorem 1**.: _Under Assumptions 1 and 2, the latent variables \(Z\) are identifiable up to their upstream layers from purely observational data._

Importantly, this result holds without any structural restrictions on the mixing function or the latent causal DAG. It indicates that we can derive representations of latent factors free of all downstream variables, and that it is easier to disentangle the more upstream causal factors.

Building on Theorem 1, we can show a stronger notion of identifiability for the exogenous noise variables. Consider any \(layer(i)\) representation given by a linear combination of all variables in \(layer(i+1) layer(r)\), where \(r\) denotes the top most layer. Then from the structural equations, it follows that this representation depends nonlinearly on the exogenous noise variables associated with \(layer(i+1) layer(r)\) and linearly on the the exogenous noise variables associated with \(layer(i)\), which we denote by \(_{layer(i)}\). Thus, if we regress this representation on all upstream layer representations, e.g., using kernel regression, then the residual terms will equate to a linear combination of \(_{layer(i)}\). Performing this procedure over all layers \(i\), we can determine layer-wise transformations of \(\), giving rise to the following theorem.

**Theorem 2**.: _Under Assumptions 1 and 2, the exogenous noise variables \(\) are identifiable up to their layers from purely observational data._

### Impossibility Results

Next, we show that further disentanglement is not possible. In particular, we cannot further disentangle the exogenous noise variables within any given layer. The following example illustrates this with two variables. Suppose the exogenous noise variables \(_{1}\) and \(_{2}\) are identified via two linear combinations denoted by

\[}_{1}=a_{1}_{1}+a_{2}_{2},}_{2}=b_{1}_{1}+b_{2}_{2}.\]We only know that they are independent mean-zero Gaussian variables. However, any linear coefficients with \(a_{1}b_{1}_{1}^{2}+a_{2}b_{2}_{2}^{2}=0\) satisfy \(Cov(}_{1},}_{2})=a_{1}b_{1}_{1}^{2}+a_{2} b_{2}_{2}^{2}=0\), which means \(}_{1}\) and \(}_{2}\) are independent. This indicates that \(}_{1}\) and \(}_{2}\) do not provide enough information to further disentangle \(_{1}\) or \(_{2}\). In general, this impossibility result holds for arbitrary graphs.

**Proposition 1**.: _Under Assumptions 1 and 2, the exogenous noise variables \(\) are generally midenti-fiable beyond layer-wise transformation from observational data._

## 4 Algorithm for Layer Recovery

We now transition to developing practical algorithms to recover the guaranteed causal representations. Our approach consist of two steps: (1) solving for the representations of latent variables up to upstream-layer transformations, and (2) solving for representations of exogenous noise variables up to layer-wise transformations, where step 2 utilizes the output of step 1.

### Step 1: Quadratic Programming on Estimated Scores

The proof sketch in Section 3.2 provides a simple principle for causal disentanglement. It suggests that we can solve for the estimated mixing function, \(\), at each iteration by maximizing the number of zero-variance terms in the Jacobian of the estimated latent score (i.e., Equation (1)). However, this rank-constrained optimization problem is discontinuous and non-convex, leading to an NP-hard problem . Moreover, the objective function involves the \(_{0}\)-norm of a vector of variance terms, which can be hard to optimize.

To resolve these difficulties, we reduce this optimization problem into a sequence of easier problems. Note that \(Var[J_{}(z)]_{ii}\) depends only on the \(i^{th}\) column of \(\), which we denote as \([]_{i}\). It follows that we can solve for each column separately by solving for \([]_{i}\) such that \(Var[J_{}(z)]_{ii}=0\) while not violating the rank constraint. Considering the finite-sample setting where we plug in the sample estimate for \(Var[J_{}(z)]_{ii}\), this problem can be formulated as the following quadratically constrained quadratic program (QCQP):

\[_{h^{n}} 0\] (2) such that \[h^{}_{X}(x^{(m)})h=0, m[N],\] \[h^{}h=1,\] \[h^{}[]_{j}=0, j[i-1].\]

Here, we use estimated zero-centered Jacobians \(_{X}\) of observed samples \(x^{(m)}\), given by \(_{X}(x^{(m)})_{X}(x^{(m)})-_{X}(X)\) with \(_{X}(X)}{{N}}_{m=1}^{N}_{X}(x^{(m)})\). The constraint \(h^{}_{X}(x^{(m)})h=0\) is equivalent to enforcing the sample estimate of \(Var[J_{}(z)]_{ii}\) to be zero. The additional constraints \(h^{}h=1\) and \(h^{}[]_{j}=0\) ensure that we do not violate the rank constraint. A formal derivation of equivalence is given in Appendix B.

Breaking the problem in Equation (1) into a series of problems in Equation (2) allows us to operate over a lower dimensional space and use any off-the-shelf solvers for QCQP. In practice, we use the cutting plane method for mixed integer programming . Algorithm 1 summarizes the overall approach, where we construct the \(layer(k)\) representations iteratively by solving a series of QCQPs.

### Step 2: Layer-wise Nonlinear Regression

Given the learned representation \(\) from Algorithm 1, we now proceed to disentangle the exogenous noise variables, which fully determine the randomness of the observations.

Following the proof of Theorem 2, we can recover a representation of the exogenous noise variables \(_{layer(k)}\) by non-linearly regressing the \(layer(k)\) representation of \(Z\) on all upstream representations and taking the residual terms. This procedure is summarized in Algorithm 2.

```
1:Input:\(N\) samples of \(X\) in the observational distribution.
2:Estimate \(_{X}(x^{(m)}), m[N]\) using any off-the-shelf score estimation method (see Section 5).
3:Initialize \(=0^{n N}\), \(=(x^{(1)},,x^{(N)})^{d N}\), and \(k=n\).
4:while\(k>0\)do
5: Initialize \(=0^{k d}\).
6:for\(i=1,,d\)do
7: Set \([]_{i}\) to be the solution of Equation (2). Break when no feasible solution is found.
8:endfor
9: Fill in all-zero columns of \(\) with random vectors to remain full column rank.
10: Compute \(=^{}\) and \(J_{}(^{(m)})=^{}_{X}(^{(m)}), m[N]\).
11: Set \(=0^{0 N}\).
12:for\(i=1,...,k\)do
13:if\(Var[J_{}()]_{i,i}=0\)then
14: Set \([]_{n-k}=[]_{i}\) and let \(k k-1\).
15:else
16:\(,[]_{i}\).
17:endif
18:endfor
19:endwhile
20:Return:\(\) ```

**Algorithm 1** Recovering \(Z\) up to upstream layers.

```
1:Input:\(^{n N}\) estimated from Algorithm 1. Denote the number of layers as \(K\).
2:Initialize \(}=0^{n N}\). Set \(}_{layer(K)}=_{layer(K)}\).
3:for\(k=K-1,...,0\)do
4: Fit nonlinear regression on \(_{layer(k)}\) using \(}_{layer(k+1)},,}_{layer(K)}\).
5: Set \(}_{layer(k)}\) as the residual terms.
6:endfor
7:Return:\(}\). ```

**Algorithm 2** Recovering \(\) up to layers.

## 5 Numerical Results

We test our proposed algorithms using simulations4. Algorithm 1 requires estimating the score of the observational distribution and its performance relies on the quality of this estimation. To evaluate this, we conduct two sets of experiments. In Section 5.1, we use perfect score oracles, which compute the Jacobian matrices exactly using the ground-truth data-generating process. This serves as a verification of our theoretical results. In Section 5.2, we estimate the score functions from the samples using two popular score-estimation methods. Details of the experiments can be found in Appendix C.

### Score Oracle Simulations: Validation of Theoretical Results

To further validate our theoretical results, we run Algorithms 1 and 2 to learn the latent causal factors and the exogenous noise variables. We consider the following causal graphs with 4 nodes: (1) a line graph represented as \(Z_{1} Z_{2} Z_{3} Z_{4}\), and (2) a Y-structure represented as \(Z_{1} Z_{2} Z_{3}\), \(Z_{2} Z_{4}\). For each case, we generate 2000 observational samples and compute the corresponding scores using the ground-truth link functions.

We present the results of our estimation in Figure 3. The scatter plots depict the relationships between the ground-truth \(_{i}\) and the estimated \(}_{j}\), where we color the dots with the values of \(Z_{1}\). The heatmaps show the mean absolute correlations (MAC) between the ground-truth \(_{i}\) and the estimated \(}_{j}\). For the estimated latent causal factors \(\), we see trends that are consistent with Theorem 1 in both cases, where the root node is perfectly identified and \(Z_{2}\) is estimated with some mixing of \(Z_{1}\).

For the estimated exogenous noise variables \(}\), the results validate Theorem 2. In the line graph, our algorithm perfectly disentangles all variables; in the Y-structure, we can perfectly disentangle \(_{1}\) and \(_{2}\), while \(_{3}\) and \(_{4}\) are mixed.

### Results using Score Estimation

In this set of experiments, we aim to mimic real-world settings where the score functions are estimated from samples. We use two popular methods to generate point-wise estimates of the Jacobians of the scores: the second-order Stein estimator [5; 44] and the sliced score matching with variance reduction (SSM-VR) estimator . We then plug these estimators into Algorithms 1 and 2.

We use the same sampling procedure on the four-node line graph as described in the previous section with varying sample sizes. Here we evaluate the mean absolute correlation (MAC) between the true and estimated exogenous noise variables. We adjust the tolerance of our QCQP solver to account for noisy estimates (see Appendix C). Table 2 reports the results averaged across 10 repeated runs. With noisy score estimates, we can still learn these variables although, as expected, accuracy decreases as compared to the results using oracle score estimates, where we can recover the exogenous noise almost perfectly.

As reliable higher-order score estimation is an active area of research [27; 41; 30], we seek to evaluate how the accuracy of our algorithm can increase under improved score estimation. Specifically, we consider how the MAC of exogenous noise estimates behaves under varying levels of noise in the plug-in Jacobians. We perturb the true Jacobian matrices with noise and plot the returned MAC with respect to the signal-to-error ratio (SER) in Figure 4. This shows that the accuracy improves with

Figure 3: **Score oracle simulations.** (A) Estimated versus true latent variables on the line graph. (B) Estimated versus true latent variables on the Y-structure. (C) Estimated versus true exogenous variables on the line graph. (D) Estimated versus true exogenous variables on the Y-structure.

higher SER. We also mark the MAC of Stein estimation and SSM-VR, which are approximately around 2 and 6 SERs respectively.

## 6 Discussion

In this work, we derive partial identifabilty guarantees of causal disentanglement from purely observational data and linear mixing without any structural restrictions. In particular, we utilize asymmetries in nonlinear causal models with additive Gaussian noise. We provide a precise characterization of identifiability in this setting, where the latent causal factors can be identified up to upstream layers and the exogenous noise variables can be identified up to their layers. We show that further disentanglement is not possible without additional assumptions or alternative datasets.

These theoretical analyses indicate a simple but hard to optimize principle for deriving efficient algorithms. We show that this optimization problem can be solved via a series of simpler quadratically constrained quadratic programs. This leads to a flexible algorithm that allows us to use any off-the-shelf QCQP solvers and score estimation methods. We demonstrate its correctness and efficiency using simulations.

While we view this work as having a primarily theoretical contribution, we additionally believe that the notion of layer-wise identifiability has many practical implications. In particular, our methods can be used to identify hierarchical topics at various layers of a causal system. For instance, when applied to a latent genealogical tree, each layer representation would contain all prior ancestral information used to determine the traits of a given generation.

In future work, it would be interesting to extend our results to latent causal models with other asymmetries. In particular, we believe our result could be extended to learn upstream layer representations of nonlinear additive models with generic noise as an extension of , by modifying the principle to achieve identifiability in Equation (1). It would also be interesting to understand how our identifiability results in the purely observational setting could aid when additional external data, such as interventions or multi-modal data, are available. Additionally, since our work shows that causal disentanglement can be solved orthogonally to score estimation, extending and testing our proposed approaches to applications where there exist pretrained score estimators would be another interesting avenue to pursue. Furthermore, given further disentanglement beyond layer-wise identifiability is not possible with purely observational data, it remains unclear what minimum faithfulness assumptions are required to achieve stronger identifiability guarantees, which we view as an import question.

**Broader impact.** Our work advances the field of causal representation learning, where it was commonly thought that without interventional data causal variables could only be discovered up to linear combinations of all variables without structural assumptions. While our work has many potential applications, we feel that no particular societal consequence needs to be highlighted.