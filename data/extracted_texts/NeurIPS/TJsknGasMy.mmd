# Bounding the Taylor Expansion Remainder Term:

Differentially Private Stochastic Gradient Descent with Fixed-Size Minibatches: Tighter RDP Guarantees with or without Replacement

Jeremiah Birrell

Texas State University

jbirrell@txstate.edu &Reza Ebrahimi

University of South Florida

ebrahimim@usf.edu &Rouzbeh Behnia

University of South Florida

behnia@usf.edu &Jason Pacheco

University of Arizona

pachecoj@cs.arizona.edu

###### Abstract

Differentially private stochastic gradient descent (DP-SGD) has been instrumental in privately training deep learning models by providing a framework to control and track the privacy loss incurred during training. At the core of this computation lies a subsampling method that uses a privacy amplification lemma to enhance the privacy guarantees provided by the additive noise. Fixed size subsampling is appealing for its constant memory usage, unlike the variable sized minibatches in Poisson subsampling. It is also of interest in addressing class imbalance and federated learning. Current computable guarantees for fixed-size subsampling are not tight and do not consider both add/remove and replace-one adjacency relationships. We present a new and holistic Renyi differential privacy (RDP) accountant for DP-SGD with fixed-size subsampling without replacement (FSwoR) and with replacement (FSwR). For FSwoR we consider both add/remove and replace-one adjacency, where we improve on the best current computable bound by a factor of \(4\). We also show for the first time that the widely-used Poisson subsampling and FSwoR with replace-one adjacency have the same privacy to leading order in the sampling probability. Our work suggests that FSwoR is often preferable to Poisson subsampling due to constant memory usage. Our FSwR accountant includes explicit non-asymptotic upper and lower bounds and, to the authors' knowledge, is the first such RDP analysis of fixed-size subsampling with replacement for DP-SGD. We analytically and empirically compare fixed size and Poisson subsampling, and show that DP-SGD gradients in a fixed-size subsampling regime exhibit lower variance in practice in addition to memory usage benefits.

## 1 Introduction

Differentially private stochastic gradient descent (DP-SGD) (Abadi et al., 2016) (DP-SGD) has been one of the cornerstones of privacy preserving deep learning. DP-SGD allows a so-called moments accountant technique to sequentially track privacy leakage (Abadi et al., 2016). This technique is subsumed by Renyi differential privacy (RDP) (Mironov, 2017), a relaxation of standard differential privacy (DP) (Dwork and Rothblum, 2016) that is widely used in private deep learning and implemented in modern DP libraries such as Opacus (Meta Platforms, 2024) and autodp (Zhu and Wang, 2019; Zhu et al., 2022). RDP facilitates rigorous analysis when the dataset is accessed by a sequence of randomized mechanisms as in DP-SGD. While other privacy accountant frameworks such as \(f\)-DP (Dong et al., 2022), privacy loss distributions (PLD) (Koskela et al., 2020), Privacy Random Variable (PRV) (Gopi et al., 2021), Analytical Fourier Accountant (AFA) (Zhu et al., 2022), and Saddle-Point Accountant (SPA) (Alghamdi et al., 2023) have been proposed to improve conversion to privacy profiles, RDP is still one of the main privacy accountants used in popular deep learning tools and applications. Thus, we expect providing tighter bounds specific to RDP will have important practical implications for the community. Each iteration of DP-SGD can be viewed as a private release of information about a stochastic gradient. DP accounting methods bound the total privacy loss incurred by applying a sequence of DP-SGD mechanisms in training. Privacy of the overall mechanism is ensured through the application of two random processes: 1) a randomized mechanism that subsamples minibatches of the training data, 2) noise applied to each gradient calculation (e.g., Gaussian). Informally, if a mechanism \(\) is \((,)\)-DP then a mechanism that subsamples with probability \(q(0,1)\) ensures privacy \((O(q),q)\)-DP; a result known as the "privacy amplification lemma" (Li et al., 2012; Zhu and Wang, 2019). Computing the privacy parameters of a mechanism requires an accounting procedure that can be nontrivial to design. Abadi et al. (2016) compute DP parameters for the special case of Gaussian noise, which was later extended to track RDP parameters by Mironov (2017). These analyses are limited to Poisson subsampling mechanisms which produce minibatches of variable size. This creates engineering challenges in modern machine learning pipelines and also does not allow for sampling with replacement. Fixed-size minibatches are preferable as they can be aligned with available GPU memory, leading to higher learning throughput. In practice, fixed size minibatches are of interest in practical applications such as private federated learning. To address the issue, Wang et al. (2019) and Zhu et al. (2022) propose the latest fixed-size accounting methods. Wang et al. (2019) provide computable RDP bounds for FSwoR that cover general mechanisms under replace-one adjacency, while Zhu et al. (2022) give computable bounds for FSwoR under add/remove adjacency. Specifically, the study in (Wang et al., 2019) provides a general formula to convert the RDP parameters of a mechanism \(\) to RDP parameters of a subsampled (without replacement) mechanism, but the bounds they provide are only tight up to a constant factor at leading order (i.e., comparing dominant terms in the asymptotic expansion in \(q\)). Moreover, while the FSwoR results under add/remove adjacency relationship in (Zhu et al., 2022) are in parallel to our results, their accountant is not readily applicable to FSwoR under replace-one adjacency relationship.

In our work, we (1) present a new and holistic RDP accountant for DP-SGD with fixed-size subsampling without replacement (FSwoR) and with replacement (FSwR) that considers both add/remove and replace-one adjacency. We note that FSwoR is equivalent to shuffling the dataset at the start of every iteration and then taking the first \(|B|\) elements, which is conveniently similar to the default behavior of common deep learning libraries (e.g. Pytorch's DataLoader iterator object) while FSwR latter is implemented, e.g., in Pytorch's RandomSampler, and is widely used to address class imbalance in classifiers (Mease et al., 2007) and biased client selection in federated learning applications (Cho et al., 2022). (2) Our FSwoR improves on the best current computable bound under replace-one adjacency (Wang et al., 2019) by a factor of \(4\). (3) Our FSwoR accountant includes non-asymptotic upper and lower bounds and, to the authors' knowledge, is the first such analysis of fixed-size RDP with replacement for DP-SGD. (4) For the first time, we show that FSwoR and the widely-used Poisson subsampling have the same privacy under replace-one adjacency to leading order in the sampling probability. This has important practical benefits given the memory management advantages of fixed-size subsampling. Thus our results suggest that FSwoR is often preferable to Poisson subsampling. The implementation of our accountant is included in Supplementary Materials and is also publicly available to the community at https://github.com/star-ailab/FSRDP.

## 2 Background and Related Work

Mironov (2017) proposed a differential privacy definition based on Renyi divergence, RDP, that subsumes the celebrated moments accountant (Abadi et al., 2016) used to track privacy loss in DP-SGD. RDP and many other flavors of DP rely on subsampling for _privacy amplification_ to ensure that privacy guarantees hold when DP-SGD is applied on samples (i.e., minibatches) of training data (Bun et al., 2018; Balle et al., 2018). Later works such as (Mironov et al., 2019; Zhu and Wang, 2019) propose a generic refined bound for subsampled Gaussian Mechanism that improves the tightness of guarantees in RDP. However, these methods also produce variable-sized minibatches. Bun et al. (2018), Balle et al. (2018), and Wang et al. (2019) propose fixed-size subsampled mechanisms. Balle et al. (2018) provide a general fixed-size subsampling analysis with and without replacement but their bounds focus on tight \((,)\)-DP bounds for a single step, and are not readily applicable to DP-SGD.

The AFA developed by Zhu et al. (2022) is an enhancement of the moments accountant offering a lossless conversion to \((,)\) guarantees and is designed for general mechanisms. However, in the context of DP-SGD, there are still technical and practical difficulties. For instance, in DP-SGD there is generally a large number of training steps, in which case the numerical integrations required by Algorithm 1 in Zhu et al. (2022) involve the sum of a large number of oscillatory terms. This can lead to numerical difficulties, especially in light of the lack of rigorous error bounds for the double (Gaussian) quadrature numerical integration approach as discussed in their Appendix E.1. In addition, the bounds in Zhu et al. (2022) are not readily applicable under replace-one adjacency. Due to these considerations, and the fact that RDP is still widely used, in this work, we focus on improving the RDP bounds from Wang et al. (2019).Hayes et al. (2024) uses the results in (Zhu et al., 2022) to provide a bound specific to DP-SGD when one is only concerned with training data reconstruction attacks rather than the membership inference attacks, which leads to a relaxation of DP to provide a bound that is only applicable to defending against data reconstruction and not membership inference. Our work can be viewed as a complimentary work to (Hayes et al., 2024) that is specific to DP-SGD and provides conservative bounds protecting against membership inference attacks (and thus any other type of model inversion attacks including training data reconstruction) in the RDP context.

In summary, to our knowledge, Wang et al. (2019) provide the best computable bounds in the fixed-size regime for RDP that are practical for application to DP-SGD. While the computations in (Wang et al., 2019) have the attractive property of applying to a general mechanism, in this work, we show that there is room for obtaining tighter bounds specific to DP-SGD with Gaussian noise. Our FS-RDP bounds address this theoretical gap by employing a novel Taylor expansion expansion approach, which precisely captures the leading order behavior in the sampling probability, while employing a computable upper bounds on the integral remainder term to prevent privacy leakage. For convenience, we provide the definition of RDP below.

**Definition 2.1** (\((,)\)-RDP (Mironov et al., 2019)).: Let \(\) be a randomized mechanism, i.e., \((D)\) is a probability distribution for any choice of allowed input (dataset) \(D\). A randomized mechanism is said to have \((,)\)-RDP if for any two adjacent datasets \(D,D^{}\) it holds that \(D_{}((D)\|(D^{}))\), where the Renyi divergence of order \(>1\) is defined by

\[D_{}(Q\|P) [()^ {}P(x)dx]\,.\] (1)

The definition of dataset adjacency varies among applications. In this work we consider two such relations: 1) The add/remove adjacency relation, where datasets \(D\) and \(D^{}\) to be adjacent if one can be obtained from the other by adding or removing a single element; we denote this by \(D_{a/r}D^{}\). 2) The replace-one adjacency definition, denoted \(D_{ro}D^{}\), wherein \(D\) is obtained from \(D^{}\) by replacing a single element. In the next section we derive new RDP bounds when \(\) is DP-SGD using fixed-size minibatches, with or without replacement.

## 3 Renyi-DP Bounds for SGD with Fixed-size Subsampling

In this section we present our main theoretical results, leading up to Renyi-DP bounds for SGD for fixed-size subsampling done without replacement (Thm. 3.3 for add/remove adjacency and Thm. 3.4 for replace-one adjacency) and with replacement (Thm. 3.7). In Sec. 3.4, we also compare our results with the analysis in (Wang et al., 2019) and show that our analysis yields tighter Renyi bounds by a factor of approximately \(4\).

### FS-RDP: Definition and Initial Bounds

Given a loss function \(\), a training dataset \(D\) with \(|D|\) elements, and a fixed minibatch size, we consider the DP-SGD NN parameter updates with fixed-size minibatches,

\[_{t+1}^{D}=_{t}^{D}-_{t}G_{t}\,, G_{t}= (_{i B_{t}^{D}}(_{}(_{t},D_{i}))+Z_{t})\,,\] (2)

where \(t\) is the iteration number, the initial condition \(_{0}^{D}\) is independent of \(D\), \(_{t}\) are the learning rates, the noises \(Z_{t}\) are Gaussians with mean \(0\) and covariance \(C^{2}_{t}^{2}I\), and the \(B_{t}^{D}\) are random minibatcheswith fixed size; we denote the fixed value of \(|B_{t}^{D}|\) by \(|B|\) for brevity. We will consider fixed-size subsampling both without and with replacement; in the former, \(B_{t}^{D}\) is a uniformly selected subset of \(\{0,...,|D|-1\}\) of fixed size \(|B|\) for every \(t\) and in the latter, \(B_{t}^{D}\) is a uniformly selected element of \(\{0,...,|D|-1\}^{|B|}\) for every \(t\). We assume the Gaussian noises and minibatches are all independent jointly for all steps. Here Clip denotes the clipping operation on vectors, with \(^{2}\)-norm bound \(C>0\), i.e., \((x) x/\{1,\|x\|_{2}/C\}\). We derive a RDP bound (Mironov, 2017) for the mechanism consisting of \(T\) steps of DP-SGD (2), denoted:

\[_{[0,T]}^{FS}(D)(_{0}^{D},...,_{T}^{D})\,.\] (3)

Specifically, we consider the cases without replacement, \(_{[0,T]}^{FS_{}}(D)\), and with replacement, \(_{[0,T]}^{FS_{}}(D)\). To obtain these FS-RDP accountants we bound \(D_{}(_{[0,T]}^{FS}(D)\|_{[0,T]}^{FS}(D^{}))\), where \(D^{}\) is any dataset that is adjacent to \(D\); as previously stated, we will consider both add/remove and replace-one adjacency. By taking worst-case bounds over the input state at each step, as done in Theorem 2.1 in (Abadi et al., 2016), we decompose the problem into a sum over steps

\[D_{}(_{[0,T]}^{FS}(D)\|_{[0,T]}^{FS}(D^{})) _{t=0}^{T-1}_{_{t}}D_{}(p_{t}(_{t+1}|_{t},D)\|p_{t}(_{t+1}|_{t},D^{}))\,\] (4)

where the time-inhomogeneous transition probabilities are,

\[p_{t}(_{t+1}|_{t},D) =}_{b}N_{_{t}(_{t},b,D),_{t}^{2}}(_{t+1})\,,\] (5) \[_{t}(_{t},b,D)_{t}-_{t}_{i b}(_{}(_{t},D_{i}))\,.\]

Here \(N_{,^{2}}()\) is the Gaussian density with mean \(\) and covariance \(^{2}I\), \(_{t}^{2} C^{2}_{t}^{2}_{t}^{2}/|B|^{2}\), and the summation is over the set of allowed index minibatches, \(b\), with normalization constant \(Z_{|B|,|D|}=\) for FS\({}_{}\)-RDP and \(Z_{|B|,|D|}=|D|^{|B|}\) for FS\({}_{}\)-RDP. When additional clarity is needed we use the notation \(p_{t}^{_{}}\) and \(p_{t}^{_{}}\) to distinguish the transition probabilities for these respective cases.

### FS\({}_{}\)-RDP Upper Bounds

The computations thus far mimic those in (Abadi et al., 2016; Mironov et al., 2019), with the choice of subsampling method and adjacency relation playing no essential role. That changes in this section, where we specialize to the case of subsampling without replacement. First, in Section 3.2.1 we consider the add/remove adjacency relation; the proof in this case contains many of the essential ideas of our method but is simpler from a computational perspective. The more difficult case of replace-one adjacency will then be studied in Section 3.2.2

#### 3.2.1 Add/remove Adjacency

In Appendix A we derive the following Renyi divergence bound for FS\({}_{}\)-subsampled DP-SGD under add/remove adjacency.

**Theorem 3.1**.: _Let \(D_{a/r}D^{}\) be adjacent datasets. With transition probabilities defined as in (5) and letting \(q=|B|/|D|\) we have_

\[_{_{t}}D_{}(p_{t}^{_{}}(_{t+1}| _{t},D)\|p_{t}^{_{}}(_{t+1}|_{t},D^{}))  D_{}(qN_{1,_{t}^{2}/4}+(1-q)N_{0,_{t}^{2}/4}\|N_{0, _{t}^{2}/4})\,.\] (6)

The key step in the proof consists of the decomposition of the mechanism given in Lemma A.1. We note that the r.h.s. of (6) differs by a factor of \(1/4\) in the variances from the corresponding result for Poisson subsampling in Mironov et al. (2019). This is due to the inherent sensitivity difference between fixed-size and Poisson subsampling under add/remove adjacency; see (28) - (29). To bound the r.h.s. of (3.1) we will employ a Taylor expansion computation with explicit remainder bound. As the r.h.s. of (6) has the same mathematical form as the Poisson subsampling result of Mironov et al. (2019), and therefore can be bounded by the same methods employed there, the Taylor expansion method is not strictly necessary in the add/remove case. However, we find it useful to illustrate the Taylor expansion method in this simpler case before proceeding to the significantly more complicated replace-one case in Section 3.2.2, where the method in Mironov et al. (2019) does not apply.

The Renyi divergences on the r.h.s. of (6) can be written

\[D_{}(qN_{1,_{t}^{2}/4}+(1-q)N_{0,_{t}^{2}/4}\|N_{0,_{t} ^{2}/4})=[H_{,_{t}}(q)]\,,\] (7)

where for any \(>1\), \(>0\) we define

\[H_{,}(q) \!(/4}()+(1-q)N_{0,^{2} /4}()}{N_{0,^{2}/4}()})^{}\!\!\!N_{0,^{2}/ 4}()d\,.\] (8)

Eq. (8) does not generally have a closed form expression. We upper bound it via Taylor expansion with integral formula for the remainder at order \(m\) (c.f. Thm. 1.2, (Stewart, 2022)):

\[H_{,}(q)=_{k=0}^{m-1}}{k!}}{dq^{k}}H_{ ,}(0)+R_{,,m}(q)\,,\] (9)

where the remainder term is given by

\[R_{,,m}(q)=q^{m}_{0}^{1}}{(m-1)!} }{dq^{m}}H_{,}(sq)ds\,.\] (10)

Note that we do not take \(m\) and so \(H_{,}\) is not required to be analytic in order to make use of (9). Also note that (9) is an equality, therefore if we can compute/upper-bound each of the terms then we will arrive at a computable non-asymptotic upper bound on \(H_{,}(q)\), without needing to employ non-rigorous stopping criteria for an infinite series, thus avoiding privacy leakage. The order \(m\) is a parameter that can be freely chosen by the user. To implement (9) one must compute the derivatives \(}{dq^{k}}H_{,}(0)\) and bound the remainder (10). We show how to do both of those steps for general \(m\) in Appendix B; in the following theorem we summarize the results for \(m=3\), which we find provides sufficient accuracy in our experiments.

**Theorem 3.2** (Taylor Expansion Upper Bound).: _For \(q<1\) we have_

\[H_{,}(q)=1+}{2}(-1)M_{,2}+R_{, ,3}(q)\,,\] (11)

_where the remainder has the bound_

\[R_{,,3}(q) q^{3}(-1)|-2|_{=0}^{ -3}q^{}_{,+3}+ _{,3}&-3>0\\ (1-q)^{-3}_{,3}&-3 0 \] \[ _{,,3}(q)\,,\] (12)

_and the \(M\) and \(\) parameters are given by (41) and (44) respectively._

The reason for the complexity of the formulas (11) - (12) is the need to obtain a rigorous upper bound, and not simply an asymptotic result. Results for other choices of \(m\) are given in Appendix B.

Combining Theorem 3.2 with equations (4) - (8) we now arrive at a computable \(T\)-step \(_{}\)-RDP guarantee.

**Theorem 3.3** (\(T\)-step \(_{}\)-RDP Upper Bound: Add/Remove Adjacency).: _Assuming \(q<1\), the mechanism \(_{[0,T]}^{_{}}(D)\), defined in (3), has \((,_{[0,T]}^{_{}}())\)-RDP under add/remove adjacency, where_

\[_{[0,T]}^{_{}}()_{=0}^{T-1}[1+}{2}(-1)M_{,2}+ {R}_{,,3}(q)]\,,\] (13)

_where \(M\) and \(\) are given by (41) and (12) respectively._

More generally, using the calculations in Appendix B one obtains RDP bounds for any choice of the number of terms, \(m\). The result (13) corresponds to \(m=3\), which we find to be sufficiently accurate in practice; see Figure 6.

#### 3.2.2 Replace-one Adjacency

Theorem 3.1 applies to add/remove adjacency, but our method of proof can also be used in the replace-one adjacency case, where it yields the following FS\({}_{}\)-RDP upper bounds.

**Theorem 3.4** (FS\({}_{}\)-RDP Upper Bounds for Replace-one Adjacency).: _Let \(D_{r o}D^{}\) be adjacent datasets. Assuming \(q:=|B|/|D|<1\), for any integer \(m 3\) we have_

\[_{_{t}}D_{}(_{t}^{_{}}( _{t+1}|_{t},D)||_{t}^{_{}}(_{t+1}| _{t},D^{}))\] (14) \[ 1+q^{2}(-1) (e^{4/{_{t}}^{2}}-e^{2/{_{t}}^{2}})+_{k=3}^{m-1} }{k!}_{,_{t},k}+_{, _{t},m}(q),\]

_where \(_{,_{t},k}\) is given by (80) and \(_{,_{t},m}(q)\) by (87)._

The derivation, found in Appendix C, follows many of the same steps as the add/remove-adjacency case from Theorem 3.1, though deriving bounds on the terms in the Taylor expansion is significantly more involved and the resulting formulas are more complicated. The decomposition from Lemma A.1 again constitutes a key step in the proof. For comparison purposes, in Appendix C.1 we derive the analogous result for Poisson-subsampling under replace-one adjacency; see Theorem C.9.

A corresponding \(T\)-step RDP bound, analogous to Theorem 3.3, for replace-one adjacency can similarly be obtained by combining Theorem 3.4 with Eq. (4).

**Theorem 3.5** (\(T\)-step FS\({}_{}\)-RDP Upper Bound: Replace-one Adjacency).: _Assuming \(q<1\) and for any integer \(m 3\), the mechanism \(_{[0,T]}^{_{}}(D)\), defined in (3), has \((,_{[0,T]}^{_{}}())\)-RDP under replace-one adjacency, where_

\[_{[0,T]}^{_{}}()_{t=0}^{ T-1}[1+q^{2}(-1)(e^{4/{_{t}}^{2} }-e^{2/{_{t}}^{2}})+_{k=3}^{m-1}}{k!}_ {,_{t},k}+_{,_{t},m}(q)].\] (15)

_Here \(_{,_{t},k}\) is given by (80) and \(_{,_{t},m}(q)\) by (87)._

We emphasize that one strength of our approach is that it provides a unified method for deriving computable bounds in both the add/remove and replace-one adjacency cases. We also note that Theorem 11(b) of Zhu et al. (2022), Theorem 6 of Balle et al. (2018), and Theorem 5 in Mironov et al. (2019) combine to provide an alternative method for deriving the add/remove result of Theorem 3.1 but not the replace-one result of Theorem 3.4. Unlike in the corresponding add/remove theorems, using \(m>3\) in Theorems 3.4 and 3.5 is often required to obtain acceptable accuracy, though we generally find that \(m=4\) is sufficient; see Figure 2.

### FS\({}_{}\)-RDP Upper and Lower Bounds

We similarly obtain RDP bounds for DP-SGD using fixed-size minibatches with replacement, i.e., (2) with minibatches \(B_{t}^{D}\) that are iid uniformly random samples from \(\{0,...,|D|-1\}^{|B|}\). First we present upper bounds on the RDP of \(_{[0,T]}^{_{}}(D)\). The derivation follows a similar pattern to that of our results for FS\({}_{}\)-subsampling, first using a probabilistic decomposition of the mechanism (see Lemma D.1) and then expanding (see Appendix D.1).

**Theorem 3.6** (Fixed-size RDP with Replacement Upper Bound).: _Assuming \(|D|>|B|\) and under add/remove adjacency, the mechanism \(_{[0,T]}^{_{}}(D)\) has \((,_{[0,T]}^{_{}}())\)-RDP with (\(H_{,}\) given by (8))_

\[_{[0,T]}^{_{}}()_{t=0}^{ T-1}[_{n=1}^{|B|}_{n}H_{, _{t}/n}()]\,,\] (16) \[ 1-(1-|D|^{-1})^{|B|},_{n} ^{-1}|D|^{-n}(1-|D|^{-1})^{|B|-n}\,.\]

The functions \(H_{,}\) were previously bounded above in Theorem 3.2 (for order \(m=3\)), and more generally in Appendix B (for general \(m\)). It is straightforward to show that \(=O(q)\) and

[MISSING_PAGE_FAIL:7]

while our FS\({}_{}\)-RDP bound under replace-one adjacency from Theorem 3.4 gives

\[^{}_{t}() q^{2}(e^{4/_{t}^{2}}-e^{2/_{t}^{2}})+O(q^{3})\] (19) \[= 2q^{2}/_{t}^{2}+O(q^{2}/_{t}^{4})+O(q^{3})\,.\]

Therefore, to leading order, our methods all have the same behavior and give tighter RDP bounds by a factor of \(4\) than that of Wang et al. (2019). We emphasize that the adjacency relation used by Wang et al. (2019) is replace-one and therefore, strictly speaking, should be compared only with our Theorem 3.4, which also uses replace-one adjacency. Figure 2 shows a non-asymptotic comparison between these RDP bounds, with ours being tighter significantly tighter than that of Wang et al. (2019). In particular, our bound from Theorem 3.4 with \(m=4\) remains close to the theoretical lower bound from Wang et al. (2019) over the entire range of \(\)'s pictured, which is a sufficiently large range for practical application to DP, e.g., larger than the default range used in Meta Platforms (2024).

Following the setting in (Abadi et al., 2016), we provide corresponding \((,)\)-DP guarantees in Figure 3 shows corresponding \(\) for \(\{1e-4,1e-5,1e-6,1e-7,1e-8,1e-9,1e-10\}\) after 250 training epochs in DP-SGD. To translate RDP bounds to \((,)\)-DP, we used Theorem 21 in (Balle et al., 2020), which is also used in the Opacus library. As shown in Figure 3, our FS\({}_{}\) bounds with \(m\{3,4,5\}\) (solid lines) are close to the lower-bound provided in (Wang et al., 2019) (circles) over a range of \(\)'s that depend on the value of \(m\). These guarantees are significantly tighter than the upper bound from Wang et al. (2019) (dashed line). In our experiments, we observe that \(m=4\) and \(m=5\) yields essentially the same results and we find that \(m=4\) suffices to obtain good results in practice while outperforming (Wang et al., 2019).

## 4 Comparing Fixed-size and Poisson Subsampling

In Sec. 3.4 we demonstrated that our Renyi-DP-SGD bounds with fixed-size subsampling in Thm. 3.3 are tighter than the general-purpose fixed-size subsampling method from Wang et al. (2019). However, the most commonly used implementations of DP-SGD rely on Poisson subsampling, not fixed-size, and there the comparison is more nuanced. In this section we compare Poisson and fixed-size subsampling and point out advantages and disadvantages of each.

### Privacy Comparison

In terms of privacy guarantees, all else being equal, when using replace-one adjacency we find that DP-SGD with fixed-size subsampling yields the same privacy guarantees as Poisson subsampling to leading order; specifically, when moving from add/remove to replace one-adjacency, our fixed-size subsampling DP bounds do not change at leading order but the Poisson subsampling DP bounds change by a factor of 2 to match the fixed-size results. In contrast, when using add/remove adjacency we find that Poisson subsampling has a natural advantage over fixed-size subsampling by approximately a factor of \(2\). Here we outline the reason for this intuitively.

The derivation of Renyi-DP bounds when using Poisson subsampling, (see Abadi et al. (2016); Mironov et al. (2019)) shares many steps with our derivation for fixed-size subsampling without replacement in Appendix A. In both cases, to leading order the bound on the Renyi divergence is proportional to \(\|-^{}\|^{2}\), where \(\) and \(^{}\) are the sum of the gradients under the adjacent datasets \(D\) and \(D^{}\). When using Poisson subsampling, under add/remove adjacency, \(^{}\) differs from \(\) by the addition or deletion of a single term in the sum with probability \(q\), while under replace-one adjacency, \(^{}\) differs from \(\) by the replacement of one element with probability \(q\). Therefore in the former case, \(\|-^{}\|\) is the norm of a single clipped vector, hence it scales with the clipping threshold, \(C\), while

Figure 3: FS\({}_{}\)\((,)\)-DP guarantees under replace-one adjacency; comparison of Wang et al. (2019) upper and lower bounds with our Theorem 3.4 for various choices of \(m\). \(_{t}=6\), \(|B|=120\), \(|D|=50,000\).

Figure 2: Comparison of FS\({}_{}\)-RDP bounds under replace-one adjacency from Theorem 3.4 for various choices of \(m\) with the upper and lower bounds from Wang et al. (2019). \(_{t}=6\), \(|B|=120\), \(|D|=50,000\).

in the latter, \(\|-^{}\|\) is the norm of the difference between two clipped vector, hence it scales with \(2C\), as in the worst case the two vectors are anti-parallel. In fixed-size subsampling and under both adjacency relations, \(^{}\) differs from \(\) by replacing one element with another (due to the fixed-size minibatch constraint) and therefore \(\|-^{}\|\) scales like \(2C\). After squaring and at leading order, this leads to a factor of \(4\) difference in the Renyi divergences between Poisson and fixed-size cases under add/remove adjacency while under replace-one adjacency the Poisson and fixed-size results agree; see Appendix C.1 for a more precise analysis of the latter comparison.

Translating this to \((,)\)-DP then leads to an approximate factor of \(2\) difference in \(\) for the same \(\) under add/remove adjacency, as shown in Appendix G, while under replace-one adjacency the different subsampling methods lead to the same DP guarantees at leading order. When the higher order terms are taken into account, Poisson subsampling regains a slight privacy advantage under replace-one adjacency; see Figures 4 and 7.

### Comparison on CIFAR10

Our numerical comparisons in Section 3.4 showed that FS\({}_{}\)-RDP yields significantly tighter guarantees than its counterpart from Wang et al. (2019). It is also useful to compare the empirical privacy guarantees of fixed-size versus the Poisson subsampling RDP commonly used in DP implementations such as Opacus. To this end, we use CIFAR10 and a simple convolutional neural network (CNN) to compare the canonical Poisson subsampling RDP with FS-RDP. Our setup closely follows the procedure in (Abadi et al., 2016). Note that the goal of this comparison is not to achieve the state-of-the-art privacy guarantees on CIFAR10 with any specific neural network. Instead we aim to compare the performance and guarantees with the alternative fixed-size and Poisson subsampling methods. Following Abadi et al. (2016), we used a simple CNN network that is pre-trained on CIFAR100 dataset non-privately. Our CNN has six convolutional layers 32, 32, 64, 128, 128, and 256 square filters of size \(3 3\), in each layer respectively. Since using Batch Normalization layers leads to privacy violation, we used group normalization instead as a common practice that is also used the Opacus library (Meta Platforms, 2024). Our network has 3 group normalization layers of size 64, 128, and 256 after the second, fourth, and sixth convolution layer. Similar to Abadi et al. (2016), this model reaches the accuracy of 81.33% after 250 epochs of training in a non-private setting. For the Poisson subsampling RDP, we simply used the one in Opacus.

Fig. 4 compares the privacy guarantees \((,)\) for FS\({}_{}\)-RDP and the method proposed by Wang et al. (2019) on the above CNN model after 250 training epochs with \(_{t}=6\), \(|B|=120\), clipping threshold \(C=3.0\), and learning rate \(lr=1e-3\) on CIFAR10 following the same setting in Abadi et al. (2016). Fig. 4 also compares the testing accuracy of Poisson subsampled RDP in Opacus with our FS\({}_{}\)-RDP. We ran each method 5 times with different random seeds for sampling: \(0\), \(1,364\), \(2,560\), \(3,000\), and \(4,111\). Shaded areas show 3-sigma standard deviations around the mean. Both logical and physical minibatch sizes were set to 120 in Opacus. Experiments were run on a single work station with an NVIDIA RTX 3090 with 24GB memory. The runtime for all experiments was under 12 hours. As shown in Figure 4, FS\({}_{}\)-RDP yields substantially tighter bounds than (Wang et al., 2019) (top panel) and reaches the average accuracy of 63.87% after 250 epochs (vs. 61.57% for Poisson subsampled RDP) (bottom panel). Figure 4 indicates that for a fixed \(\), FS\({}_{}\)-RDP surpasses the accuracy of Poisson subsampled RDP in Opacus, but with slightly higher epsilon guarantees, as shown in the top panel. This behavior matches the approximate calculation from Eq. (150) as well as the discussion in Section 4.1; specifically, Poisson and FS\({}_{}\)-RDP agree to leading order but the higher order contributions give Poisson subsampling a slight privacy advantage at the same level of added noise. We emphasize that these results all apply to the replace-one notion of adjacency, as used in (Wang et al., 2019) and also our Theorem 3.4; we did not find existing computable RDP bounds for Poisson-subsampling under replace-one adjacency and so we used the new result in Theorem C.9. We conjecture that the performance difference observed in the bottom panel of Figure 4

Figure 4: Privacy guarantees of FS\({}_{}\)-RDP, Wang et al.’s, and Poisson Subsampled RDP (**top**). Comparing FS\({}_{}\)-RDP performance against Poisson subsampled RDP (**bottom**). \(_{t}=6\), \(C=3\), \(|B|=120\), \(|D|=50,000\), \(lr=1e-3\).

is due to the difference in variance between Poisson and fixed-size subsampling, which we derive in Appendix F. Specifically, there we show that fixed-size subsampling has reduced variance compared to Poisson when the parameters are away from a minimizer. Additional experiments, gauging the sensitivity of FSwoR-RDP to key parameters including \(\) and \(|B|\), are given in Appendix H.

### Memory Usage Comparison

The RDP accountant used in common DP libraries assumes a Poisson subsampling mechanism that leads to variable-sized minibatches during the training. That is, the size of each mini-batch cannot be determined in advance. Allowing the minibatches to have variable sizes creates an engineering challenge: an uncharacteristically large minibatch can cause an out-of-memory error, and depending on how fine tuned the minibatch size is to the available GPU memory this could be a frequent occurrence. To tackle this issue, the Opacus implementation requires the additional complication of wrapping the Pytorch DataLoader object into a BatchMemoryManager object, to alleviate the memory intensive nature of Poisson subsampling. BatchMemoryManager requires privacy practitioners to define two minibatch sizes: one is a _logical_ minibatch size for Poisson sampling and the other is a _physical_ minibatch size that determines the actual space allocated in memory and is determined by the practitioner via a variable named max_physical_batch_size (Meta Platforms, 2024). This design follows the distinction between 'lots' and minibatches described in the moments accountant (Abadi et al., 2016).

Our proposed FS-RDP does not require this memory management and is much less memory intensive. Figure 5 depicts the GPU memory footprints during 100 epochs of privately training the above CNN on CIFAR10 with FSwoR-RDP and three of the most common DP accountants: RDP (Mironov et al., 2019), \(f\)-DP (Dong et al., 2022), and PRV (Gopi et al., 2021). As shown in Figure 5, the memory usage of FS-RDP remains constant at 14,826 MB. However, the memory usage varies from 7,984 MB to 23,280 MB (almost twice larger than FS-RDP) for Poisson subsampled RDP in Opacus. Similar memory usage is observed for other Opacus accountants that use Poisson subsampling mechanism (i.e., \(f\)-DP and PRV). This fluctuating memory usage could result in undesirable outcomes in settings where resource-constrained devices are considered. For instance, in federated learning environments, erratic memory usage could result in a higher dropout rate and delay the global model's convergence (Liu et al., 2021). It could also undermine model's accuracy and fairness, preventing lower-end devices from participating in the training process (Imteaj et al., 2021).

## 5 Conclusion

Differentially private stochastic gradient descent with fixed-size minibatches has attractive properties including reduced gradient estimator variance and simplified memory management. Our work presents a holistic RDP accountant for DP-SGD with fixed-size subsampling without replacement (FSwoR) and, in the FSwoR case, consider both add/remove and replace-one adjacency. As we showed theoretically and empirically, since FSwoR under replace-one adjacency leads to the same leading-order privacy guarantees as the widely-used Poisson subsampling, we suggest using the former over the latter to benefit from the memory management and reduced variance properties. For subsampling without replacement under replace-one adjacency, we obtained significantly tighter RDP bounds (4 times improvement) over the most recent computable results (Wang et al., 2019). For subsampling with replacement we obtained the first non-asymptotic upper and lower RDP bounds for DP-SGD. We also provided the first comparison of gradient estimator's variance and privacy guarantees between FS-RDP and Poisson subsampled RDP commonly used in DP libraries. Our analysis revealed that FS-RDP reduces the variance of the gradient estimator. We highlighted the memory usage advantages of FS-RDP over Poisson subsampled RDP, which makes it a practical choice for privately training large deep learning models. We made FS-RDP's implementation and its evaluations available online such that it can be added to common DP libraries.

Figure 5: Comparing memory usage of FS-RDP with other Opacus privacy accountants in each training epoch. We used \(|B|=120\), and \(|D|=50,000\). Unlike other methods, FS-RDP’s memory usage remains constant.