# Adaptive Principal Component Regression

with Applications to Panel Data

 Anish Agarwal

Department of IEOR

Columbia University

New York, NY 10027

aa5194@columbia.edu

&Keegan Harris

School of Computer Science

Carnegie Mellon University

Pittsburgh, PA 15213

keeganh@cs.cmu.edu

&Justin Whitehouse

School of Computer Science

Carnegie Mellon University

Pittsburgh, PA 15213

jwhiteho@cs.cmu.edu

&Zhiwei Steven Wu

School of Computer Science

Carnegie Mellon University

Pittsburgh, PA 15213

zhiwei@cs.cmu.edu

For part of this work, Anish was a postdoc at Amazon, Core AI.

###### Abstract

Principal component regression (PCR) is a popular technique for fixed-design _error-in-variables_ regression, a generalization of the linear regression setting in which the observed covariates are corrupted with random noise. We provide the first time-uniform finite sample guarantees for online (regularized) PCR whenever data is collected _adaptively_. Since the proof techniques for analyzing PCR in the fixed design setting do not readily extend to the online setting, our results rely on adapting tools from modern martingale concentration to the error-in-variables setting. As an application of our bounds, we provide a framework for experiment design in panel data settings when interventions are assigned adaptively. Our framework may be thought of as a generalization of the synthetic control and synthetic interventions frameworks, where data is collected via an adaptive intervention assignment policy.

## 1 Introduction

An omnipresent task in machine learning, statistics, and econometrics is that of making predictions about outcomes of interest given an action and conditioned on observable covariates. An often overlooked aspect of the prediction task is that in many settings the learner only has access to _imperfect observations_ of the covariates, due to e.g. measurement error or inherent randomness in the problem domain. Such settings are sometimes formulated as _error-in-variables_ regression: a _learner_ is given access to a collection of data \((Z_{n},a_{n},Y_{n})_{n 1}\), where \(Z_{n}^{d}\) are the _observed covariates_, \(a_{n}\{1,,A\}\) is the _action taken_, and \(Y_{n}\) is the _outcome_ for each observation \(n\). Typically, the outcomes are assumed to be generated by a linear model \(Y_{n}:=(a_{n}),X_{n}+_{n}\) and \(Z_{n}:=X_{n}+_{n}\), where \(X_{n}^{d}\) are the _true covariates_, \(_{n}^{d}\) is the covariate noise, \((a_{n})^{d}\) is an _unknown slope vector_ associated with action \(a_{n}\), and \(_{n}\) is the response noise. Note that the learner does not get to see the true covariates \(X_{n}\). Observe that when \(_{n}=0\) we recover the traditional linear regression setting. Such an error-in-variables model can encompass many forms of data corruption including measurement error, missing values, discretization, and differential privacy--see  for details.

Our point of departure from previous work is that we allow the sequence of data \((Z_{n},a_{n},Y_{n})_{n 1}\) to be chosen _adaptively_. In other words, we provide bounds for learning in the error-in-variables regression setting when the data seen at the current round \(n\) is allowed to depend on the previously-seen data \((Z_{m},a_{m},Y_{m})_{1 m<n}\). Adaptive data collection occurs when the choices of future observations can depend on the inference from previous data, which is common in learning paradigms such as multi-armed bandits [58; 78], active learning , and time-series analysis [76; 36]. Similar to prior work on adaptive data collection that shows that valid statistical inference can be done when the true covariates are observed [34; 67; 43; 91; 92], our work provides the first time-uniform finite sample guarantees for error-in-variables regression using adaptively collected data.

Concretely, we focus on analyzing _principal component regression (PCR)_, a method that has been shown to be effective for learning from noisy covariates [10; 7] and a central tool for learning from panel data [8; 5; 7]. At a high level, PCR "de-noises" the sequence of observed covariates \((Z_{n})_{n 1}\) as \((_{n})_{n 1}\) by performing hard singular value thresholding, after which a linear model is learned using the observed outcomes \((Y_{n})_{n 1}\) and the denoised covariates \((_{n})_{n 1}\). See Section 3.2 for further technical background on PCR.

### Contributions

1. We derive novel time-uniform bounds for an online variant of regularized PCR when the sequence of covariates is chosen adaptively. The techniques used to derive bounds for PCR in the fixed-sample regime  do not extend to the setting in which data is collected adaptively; thus, we require new tools and ideas to obtain our results. Specifically, our results rely on applying recent advances in martingale concentration [50; 51], as well as more classical results on self-normalized concentration [3; 32; 33] which are commonly applied to online regression problems, to the error-in-variables setting. As an example of the bounds we obtain, consider the task of estimating the underlying relationship \((a)\) between true (i.e. noiseless) covariates and observations, given access to \(n\) adaptively-chosen noisy covariates and their corresponding actions and observations. The \(_{2}\) estimation error of the adaptive PCR estimator \(_{n}(a)\) can be bounded as \[\|_{n}(a)-(a)\|_{2}^{2}=(_{n}(a)^{2}}({ X}_{n}(a))^{2})\] with high probability, where \({ snr}_{n}(a)\) is the _signal-to-noise ratio_ associated with action \(a\) at round \(n\) (Definition 3.5), a measure of how well the true covariates stand out from the noise. \(({ X}_{n}(a))\) is the _condition number_ of the true covariates. Intuitively, if \({ snr}_{n}(a)\) is high the true covariates can be well-separated from the noise, and therefore PCR accurately estimates \((a)\) as long as the true covariates are well-conditioned. Despite the harder setting we consider, our PCR bounds for adaptively-collected data largely match the bounds currently known for the fixed-sample regime, and even improve upon them in two important ways: (1) Our bounds are _computable_, i.e. they depend on _known_ constants and quantities available to the algorithm. (2) Unlike Agarwal et al. , our bounds do not depend on the \(_{1}\)-norm of \((a)\), i.e., we do not require approximate sparsity of \((a)\) for the bounds to imply consistency. This is important because PCR is a rotationally-invariant algorithm, and so its performance guarantees should not depend on the orientation of the basis representation of the space to be learned. The price we pay for adaptivity is that \({ snr}_{n}(a)\) is defined with respect to a bound on the _total_ amount of noise seen by the algorithm so far, instead of just the noise associated with the rounds that \(a\) is taken. As a result, our bound for \(_{n}(a)\) may not be tight if \(a\) is seldomly selected.
2. We apply our PCR results to the problem of online experiment design with _panel data_. In panel data settings, the learner observes repeated, noisy measurements of _units_ (e.g. medical patients, subpopulations, geographic locations) under different _interventions_ (e.g. medical treatments, discounts, socioeconomic policies) over _time_. This is an ubiquitous method of data collection, and as a result, learning from panel data has been the subject of significant interest in the econometrics and statistics communities (see Section 2). A popular framework for learning from panel data is _synthetic control_ (SC) [1; 2], which uses historical panel data to estimate counterfactual unit measurements under control. Synthetic interventions (SI)  is a recent generalization of the SC framework which allows for counterfactual estimation under treatment, in addition to control. By leveraging online PCR, we can perform counterfactual estimation of unit-specific treatment effects under both treatment and control, as in the SI framework. However, unlike the traditional SI framework, we are the first to establish statistical rates for counterfactual unit outcome estimates under different interventions _while allowing for both units and interventions to be chosen adaptively_. Such adaptivity may naturally occur when treatments are prescribed to new units based on the outcomes of previous units. For example, this is the case when the intervention chosen for each unit is the one which appears to be best based on observations in the past.

## 2 Related work

Error-in-variables regressionThere is a rich literature on error-in-variables regression (e.g. [42; 57; 28; 44; 84; 47; 41]), with research focusing on topics such as high-dimensional [62; 56; 31; 72] and Bayesian settings [70; 81; 40]. Principal component regression (PCR) [54; 22; 10; 7] is a popular method for error-in-variables regression. The results of Agarwal et al.  are of particular relevance to us, as they provide finite sample guarantees for the fixed design (i.e. non-adaptive) version of the setting we consider.

Self-normalized concentrationThere has been a recent uptick in the application of self-normalized, martingale concentration to online learning problems. In short, self-normalized concentration aims to control the growth of processes that have been normalized by a random, or empirical, measure of accumulated variance [32; 33; 50; 51; 88]. Self-normalized concentration has led to breakthroughs in wide-ranging areas of machine learning such as differential privacy [85; 86], PAC-Bayesian learning , convex divergence estimation , and online learning [87; 29; 3]. Of particular importance for our work are the results of Abbasi-Yadkori et al. , which leverage self-normalized concentration results for vector-valued processes [32; 33] to construct confidence ellipsoids for online regression tasks. We take inspiration from these results when constructing our estimation error bounds for PCR in the sequel.

Learning in panel data settingsOur application to panel data builds off of the SI framework [8; 9], which itself is a generalization of the canonical SC framework for learning from panel data [1; 2; 52; 35; 17; 60; 89; 13; 14; 59; 16; 20; 23; 27; 39]. In both frameworks, a _latent factor model_ is often used to encode structure between units and time-steps [25; 61; 15; 18; 19; 68; 64; 65]. Specifically, it is assumed that unit outcomes are the product of unit- and time/intervention-specific latent factors, which capture the heterogeneity across time-steps, units, and interventions, and allows for the estimation of unit-specific counterfactuals under treatment and control. Other extensions of the SI framework include applications in biology , network effects , combinatorially-many interventions , and intervening under incentives [45; 66]. Finally, there is a growing line of work at the intersection of online learning and panel data. Chen  views the problem of SC as an instance of online linear regression, which allows them to apply the regret guarantees of the online learning algorithm _follow-the-leader_ to show that the predictions of SC are comparable to those of the best-in-hindsight weighted average of control unit outcomes. Farias et al.  build on the SC framework to estimate treatment effects in adaptive experimental design, while minimizing the regret associated with experimentation. The results of Farias et al.  are part of a growing line of work on counterfactual estimation and experimental design using multi-armed bandits [69; 77; 90; 24].

## 3 Setting and background

NotationWe use boldface symbols to represent matrices. For \(N\), we use the shorthand \([N]:=\{1,,N\}\). Unless specified otherwise, \(\|v\|\) denotes the \(_{2}\)-norm of a vector \(v\), and \(\|\|_{op}\) the operator norm of matrix \(\). We use \((a_{1},,a_{k})\) to represent a \(k k\) diagonal matrix with entries \(a_{1},,a_{k}\). For two numbers \(a,b\), we use \(a b\) as shorthand for \(\{a,b\}\), and \(a b\) to mean \(\{a,b\}\). Finally, \(^{d-1}\) denotes the \(d\)-dimensional unit sphere.

### Problem setup

We now describe our error-in-variables setting. We consider a _learner_ who interacts with an _environment_ over a sequence of rounds. At the start of each round \(n 1\), the environment generates covariates \(X_{n} W^{*}^{d}\), where \(W^{*}\) is a low-dimensional linear subspace of dimension \((W^{*})=r<d\)We assume that \(r\) (but not \(W^{*}\)) is known to the learner. Such "low rank" assumptions are reasonable whenever, e.g. data is generated according to a _latent factor model_, a popular assumption in high-dimensional statistical settings [53; 12; 48]. As we will see in Section 5, analogous assumptions are often also made in panel data settings. The learner then observes _noisy_ covariates \(Z_{n}:=X_{n}+_{n}\), where \(_{n}^{d}\) is a random noise vector. Given \(Z_{n}\), the learner selects an _action_\(a_{n}[A]\) and observes \(Y_{n}:=(a_{n}),X_{n}+_{n}\), where \(_{n}\) is random noise and \((a)\) for \(a[A]\) are unknown slope vectors in \(W^{*}\) that parameterize action choices such that \(\|(a)\|_{2} L\) for some \(L\). We require that the covariate noise is "well-behaved" according to one of the two the following assumptions:

**Assumption 3.1** (**SubGaussian Covariate Noise**).: _For any \(n 1\), the noise variable \(_{n}\) satisfies (a) \(_{n}\) is \(\)-subGaussian, (b) \(_{n}=0\), and (c) \(\|_{n}_{n}^{}\|_{op}\), for some constant \(>0\)._

**Assumption 3.2** (**Bounded Covariate Noise**).: _For any \(n 1\), the noise variable \(_{n}\) satisfies (a) \(\|_{n}\|\), (b) \(_{n}=0\), and (c) \(_{n}_{n}^{}=\), for some positive-definite matrix \(\) satisfying \(\|\|_{op}\), for some constant \(>0\)._

Note that Assumption 3.2 is a special case of Assumption 3.1, which allows us to get stronger results in some settings. We also impose the following constraint on the noise in the outcomes.

**Assumption 3.3** (**SubGaussian Outcome Noise**).: _For any \(n 1\), the noise variable \(_{n}\) satisfies (a) \(_{n}=0\), (b) \(_{n}\) is \(\)-subGaussian, and (c) \(_{n}^{2}\), for some constant \(\)._

Under this setting, the goal of the learner is to estimate \((a)\) for \(a[A]\) given an (possibly adaptively-chosen) observed sequence \((Z_{n},a_{n},Y_{n})_{n 1}\). For \(n 1\), we define the matrix \(_{n}^{n d}\) to be the matrix of _observed_ (i.e. noisy) covariates, with \(Z_{1},,Z_{n}\) as its rows. Similarly, \(_{n}=(X_{1},,X_{n})^{T}^{n d}\) is the matrix of _noiseless_ covariates (which are unobserved), and \(_{n}=(_{1},,_{n})^{T} R^{n d}, _{n}=(Y_{1},,Y_{n})^{T}^{n 1}\), and \(_{n}=(_{1},,_{n})^{T}^{n 1}\) are defined analogously. For any action \(a[A]\), let \(N_{n}(a):=\{s n:a_{s}=n\}\) be the _set of rounds_ up to and including round \(n\) on which action \(a\) was chosen. Likewise, let \(c_{n}(a):=|N_{n}(a)|\) denote the _number of rounds_ by round \(n\) on which action \(a\) was chosen. For \(a[A]\), we enumerate \(N_{n}(a)\) in increasing order as \(i_{1} i_{c_{n}(a)}\). Finally, we define \(_{n}(a)^{c_{n}(a) d}\) to be \((a)=(Z_{i_{1}},,Z_{i_{c_{n}(a)}})^{T}\), and define \(_{n}(a),_{n}(a),_{n}(a),\) and \(_{n}(a)\) analogously.

### Principal component regression

Background on singular value decompositionAny matrix \(^{n d}\) may be written in terms of its singular value decomposition \(=^{T},\) where \(^{n d n}\) and \(^{d d n}\) are matrices with orthonormal columns, and \(=(_{1}(),,_{d n}())^{(d n)(d n)}\) is a diagonal matrix containing the singular values of \(\), where we assume \(_{1}()_{d n}() 0\). Given a _truncation level_\(k\), we define the truncation of \(\) onto its top \(k\) principal components as \(_{k}:=_{k}(_{1}(),, _{k d n}())_{k}^{T}\), where \(_{k}^{n k d n}\) is the matrix with the first \(k d n\) columns of \(\), and \(_{k}^{n k d n}\) is defined analogously. Given such a singular value decomposition, we can define the projection matrix onto the subspace spanned by the top \(k\) right singular vectors as \(_{k}^{d d}\) given by \(_{k}:=_{k}_{k}^{T}\).

For \(n 1\), \(a[A]\), and \(_{n}(a)\) as defined above, we write the \(k\)-truncated singular value decomposition of \(_{n}(a)\) as \(_{n,k}(a)=}_{n,k}(a)(_{1}( _{n}(a)),,_{k n d}(_{n}(a))) {}_{n,k}^{T}(a)\), and the corresponding projection onto the top \(k\) right singular vectors of \(_{n}(a)\) as \(}_{n,k}(a)\). When \(k=r\), we leverage the simplified notation \(}_{n}(a):=}_{n,r}(a)\). (Recall \(r=(W^{*})\).) By \(\), we denote the projection matrix onto the true, underlying subspace \(W^{*}\). While \(\) is never known, our results leverage the fact that \(}_{n}(a)\) converges to \(\) nicely over time. We define the projected noisy covariate matrix matrix to be \(}_{n}(a):=_{n}(a)}_{n}(a)\), and define \(}_{n}(a),}_{n}(a)\) similarly. Any quantity with a "\(}}}}}\). Any quantity with a "\(}}}}}}}}}\)" is defined equivalently to quantities with "\(}{}}}}}}}}}}\)", except with \(\) in place of \(}_{n}(a)\). We are now ready to introduce our procedure for estimating \((a)\) for \(a[A]\), called _adaptive_ (or _online_) principal component regression.

**Definition 3.4** (**Adaptive Principal Component Regression**).: _Given regularization parameter \( 0\) and truncation level \(k\), for \(a[A]\) and \(n 1\) let \(}_{n}(a):=_{n}(a)}_{n,k}(a)\) and \(}_{n}(a):=}_{n}(a)^{T}}_{n}(a)+}_{n,k}(a)\). Regularized principal component regression estimates \((a)\) as_

\[_{n}(a):=}_{n}(a)^{-1} }_{n}(a)_{n}(a).\]

[MISSING_PAGE_FAIL:5]

Adaptive bounds for online (regularized) PCR

We now present the main results of this work--high-probability, time- and action-uniform bounds measuring the convergence of the PCR estimates \(_{n}(a)\) to the true slope vectors \((a)\). Unlike existing results , our bounds are valid when the covariates \((X_{n})_{n 1}\) and actions \((a_{n})_{n 1}\) are determined in an online (potentially adversarial) manner.

We first point out why the analysis of Agarwal et al.  breaks down in the setting of adaptive (or online) PCR. First, many of the concentration inequalities leveraged in Agarwal et al.  do not hold in the adaptive design setting. As a particular example, the authors leverage the Hanson-Wright inequality  for quadratic forms to study how the noisy covariate matrix \(_{n}\) concentrates around the true matrix \(_{n}\). This inequality fails to hold when the design points \((X_{n})_{n 1}\) depend on the previous observations. Second, the techniques leveraged by Agarwal et al.  to extend the convergence guarantees of PCR to the multiple action setting fail to hold when the \(n\)-th action \(a_{n}\) is selected based on previous observations. Lastly, the bounds presented in  are are inherently fixed-time in nature--a simple way to convert existing fixed-time bounds to time-uniform ones would be to perform a union bound over time steps, but that introduces looseness in the bounds.

We are able to construct our bounds by exploiting connections between online PCR and self-normalized martingale concentration . In particular, we combine martingale-based results for constructing confidence ellipsoids for online regression  with methods for high-dimensional covariance estimation  to prove our results. Exploiting this connection is what allows us to extend the results of Agarwal et al.  to the adaptive design, time-uniform setting. We begin with a bound which, up to constants and polylogarthmic factors, captures the rate of convergence of online PCR in terms of (a) the underlying signal to noise ratio and (b) the conditioning of the observed data.

**Theorem 4.1** (**Rate of Convergence for Online PCR**).: _Let \((0,1)\) be an arbitrary confidence parameter. Let \(>0\) be chosen to be sufficiently small, as detailed in Appendix F. Further, assume that there is some \(n_{0} 1\) such that \((_{n_{0}}(a))=r\) and \(_{n}(a) 2\) for all \(n n_{0}\). Then, with probability at least \(1-O(A)\), simultaneously for all actions \(a[A]\) and time steps \(n n_{0}\), we have_

\[\|_{n}(a)-(a)\|_{2}^{2}=(_{n}(a)^{2}}(_{n}(a))^{2}),\]

_where \((_{n}(a)):=(_{n}(a))}{_{r}( _{n}(a))}\) is the condition number (ignoring zero singular values) of \(_{n}(a)\)._

Theorem 4.1 is proved in Appendix E. We begin by comparing our bounds to those of Agarwal et al. . At any fixed time, our bounds take on roughly the same form as those of the aforementioned authors, having an inverse quadratic dependence on the signal to noise ratio. To make their bounds non-vacuous, the authors need to make the "soft sparsity" assumption of \(\|(a)\|_{1}=O()\). Our bound, on the other hand, suffers no dependence on the \(_{1}\)-norm of the \((a)\)'s. This makes intuitive sense, as the specific choice of a basis should not impact the rate of convergence of PCR. However, our bounds pay a price for adaptivity--in particular, the signal to noise ratio associated with an action is defined with respect to a bound on the _total_ operator norm of the matrix \(_{n}\). If an action is selected very infrequently, the above bound may become loose.

While the above bound is stated in terms of signal to noise ratio, if we make additional assumptions, we can obtain bounds directly in terms of \(d,n,\) and \(r\). In particular, the following "well-balancing" assumptions suffice.

**Assumption 4.2** (**Well-balancing assumptions**).: _For all \(n n_{0}\), the following hold: (a) \(_{i}(_{n}(a))=((a)d}{r}})\) for all \(i[r]\), (b) \(c_{n}(a)=(c_{n}(a^{}))\) for all \(a,a^{}[A]\), and (c) \(A=O(r)\)._

**Corollary 4.3**.: _Assume the same setup as Theorem 4.1, and further assume Assumption 4.2 holds. Then with probability at least \(1-O(A)\), simultaneously for all actions \(a[A]\) and time steps \(n n_{0}\), we have_

\[\|_{n}(a)-(a)\|_{2}^{2}=(} {d n}).\]Corollary 4.3 shows that Theorem 4.1 obtains the same estimation rate as Theorem 4.1 of Agarwal et al.  if assumption Assumption 4.2 holds. This "well-balancing" assumption says roughly that all non-zero singular values of \(_{n}\) are of the same order, each action is selected with the same frequency, and that the number of actions is, at most, proportional to dimension of the true, unknown subspace. As noted by Agarwal et al. , the assumption of a "well-balanced spectrum" (for \(_{n}\)) is common in many works in econometrics and robust statistics, and additionally holds with high probability if the entries of \(_{n}\) are i.i.d.. Further, it is often the case that there only few available actions (for instance, in the synthetic control literature there are only two actions ), justifying the assumption that \(A=O(r)\). Lastly, ensuring that each action is played (very roughly) the same number of times can be viewed as a price for adaptivity.

The proof of Theorem 4.1 is immediate as a corollary from the following, more complicated bound. Theorem 4.4 below measures the convergence of \(_{n}(a)\) to \((a)\) in terms of empirical (i.e. observed) quantities. We imagine this bound to be the most practically relevant of our results, as, unlike the results of Agarwal et al. , it is directly computable by the learner, involves known constants, and places minimal conditions on the signal to noise ratio.

**Theorem 4.4** (**Empirical Guarantees for Online PCR**).: _Let \((0,1)\) be an arbitrary confidence parameter. Let \(>0\) be chosen to be sufficiently small, as detailed in Appendix F. Further, assume that there is some \(n_{0} 1\) such that \((_{n_{0}}(a))=r\) and \(_{n}(a) 2\) for all \(n n_{0}\). Then, with probability at least \(1-O(A)\), simultaneously for all actions \(a[A]\) and time steps \(n n_{0}\), we have_

\[\|_{n}(a)-(a)\|_{2}^{2}}{ }_{n}(a)^{2}}[74+216(_{n}(a))^{2} ]+_{n}(a)}{_{r}(_{n}(a))^{2}},\]

_where \((_{n}(a)):=(_{n}(a))}{_{r}( _{n}(a))}\), \(\|(a)\|_{2} L\), and in the above we define the "error" term \(_{n}(a)\) to be_

\[_{n}(a) :=32 L^{2}+64^{2}(() +r(1+(_{n}(a))^{2}}{}))\] \[+6^{2}(a)_{}(c_{n}(a))}+10^{2}_ {}(c_{n}(a))+6c_{n}(a).\]

We see that the above bound, with the exception of the third term, more or less resembles the bound presented in Theorem 4.1, just written in terms of the observed covariates \(_{n}(a)\) instead of the true covariates \(_{n}(a)\). We view the third term as a slowly growing "error" term. In particular, all terms in the quantity \(_{n}(a)\) are either constant, logarithmic in the singular values of \(_{n}(a)\), or linear in \(c_{n}(a)\), the number of times by round \(n\) action \(a\) has been selected. This implies that \(_{n}(a)=(n+d)\), ensuring \(_{n}(a)\) is dominated by other terms in the asymptotic analysis. We now provide the proof of Theorem 4.4. The key application of self-normalized, martingale concentration comes into play in bounding the quantities that appear in the upper bounds of terms \(T_{1}\) and \(T_{2}\) (to be defined below).

Proof.: Observe the decomposition, for any \(n 1\) and \(a[A]\)

\[_{n}(a)-(a)=}_{n}(a)(_{n}(a)-(a))+(^{}-}_{n}^{ }(a))(a),\]

where \(^{}\) is the projection onto the subspace orthogonal to \(W^{*}\) and \(}_{n}^{}(a)\) is the projection onto the subspace orthogonal to the learned subspace (i.e. that spanned by \(_{n,r}(a)\)). Since \(}_{n}(a)(_{n}(a)-(a))\) and \((^{}-}_{n}^{}(a))(a)\) are orthogonal vectors, we have

\[\|_{n}(a)-(a)\|_{2}^{2}=\|}_{n}(a)(_{n}(a)-(a))\|_{2}^{2}+\| (}_{n}^{}(a)-^{})(a)\|_{2}^ {2}.\]

We bound these two terms separately, beginning with the second term. Going forward, fix an action \(a[A]\). Observe that with probability at least \(1-\), simultaneously for all \(n n_{0}(a)\),

\[\|(}_{n}^{}(a)-^{}) (a)\|_{2}^{2} \|}_{n}^{}(a)-^{} \|_{op}^{2}\|(a)\|_{2}^{2}\] \[ L^{2}\|}_{n}^{}(a)-^{ }\|_{op}^{2}=L^{2}\|}_{n}(a)- \|_{op}^{2}\] \[U_{n}^{2}}{_{r}(_{n}(a))^{2}} U_{n}^{2}}{_{r}(_{n}(a))^{2}},\]where the equality in the above comes from observing \(\|}_{n}^{}(a)-^{}\|_{op}=\| }_{n}(a)-\|_{op}\), the second-to-last last inequality comes from applying Lemma B.4, and the last inequality follows from the second part of Lemma B.6.

We now bound the first term. Observe that we can write

\[&\|}_{n}(a)(_{n}(a)-(a))\|_{2}^{2}( _{n}(a))^{2}}\|}_{n}(a)(_{n}(a)-(a))\|_{2}^{2}\\ &(_{n}(a))^{2}}[ {\|}_{n}(a)_{n}(a)-_{n}(a) (a)\|_{2}^{2}}_{}}+_{n} (a)(a)-}_{n}(a)(a)\|_{2}^{2}}_{}}],\] (1)

where the first inequality follows from the fact that \(}_{n}(a)(}_{n} (a))^{2}}}_{n}(a)^{}}_{n}(a)\) and \(_{r}(_{n}(a))=_{r}(}_{n}(a))\), and the second inequality comes from applying the parallelogram inequality. First we bound \(T_{1}\). We have, with probability at least \(1-O()\), simultaneously for all \(n n_{0}(a)\)

\[ T_{1}& 8\| }_{n}(a)^{1/2}(_{n}(a)-(a))\|_{2}^{2} +6\|_{n}(a)\|_{2}^{2}+8\|}_{n}(a) (a)-_{n}(a)(a)\|_{2}^{2}\\ & 32 L^{2}+64^{2}(( )+r(1+(_{n}(a))^{2}}{}) )+16L^{2}U_{n}^{2}\\ &+6^{2}(a)_{}(c_{n}(a))}+10^{2} _{}(c_{n}(a))+6c_{n}(a)+8T_{2},\] (2)

where the first inequality follows from Lemma D.1, and the second inequality follows from applying Lemmas C.1 and D.3. \(_{}(n)=2(2n)+(}{12})\), as defined in Lemma A.2. We now bound \(T_{2}\). With probability at least \(1-O()\) simultaneously for all \(n n_{0}\), we have

\[ T_{2}& 2L^{2}_{1}( _{n}(a))^{2}\|-}_{n}(a)\|_{op }^{2}+2L^{2}\|_{n}\|_{op}^{2}\\ &_{1}(_{n}(a))^{2}U_{n}^{2}}{ _{r}(_{n}(a))^{2}}+2L^{2}U_{n}^{2}\\ &_{1}(_{n}(a))^{2}U_{n}^{2}}{ _{r}(_{n}(a))^{2}}+2L^{2}U_{n}^{2}.\] (3)

The first inequality follows from Lemma D.2, the second inequality follows from applying Lemmas B.4 and B.3, and the final inequality follows from Lemma B.6.

Piecing the above inequalities together yields the desired result, which can be checked via the argument at the end of Appendix D. A union bound over actions then yields that the desired inequality holds over all actions \(a[A]\) with probability at least \(1-O(A)\). 

## 5 Application to causal inference with panel data

We now apply our bounds for adaptive PCR to online experiment design in the context of panel data. In this setting, the learner is interested in estimating _unit-specific counterfactuals_ under different _interventions_, given a sequence of unit _outcomes_ (or _measurements_) over _time_. Units can range from medical patients, to subpopulations or geographic locations. Examples of interventions include medical treatments, discounts, and socioeconomic policies. _Synthetic control (SC)_ is a popular framework used to estimate counterfactual unit outcomes in panel data settings, had they not been treated (i.e. remained under _control_) [1; 2]. In SC, there is a notion of a _pre-intervention_ time period in which all units are under control, followed by a _post-intervention_ time period, in which every unit undergoes one of several interventions (including control). At a high level, SC fits a model of a unit's pre-treatment outcomes using pre-treatment data from units who remained under control in the post-intervention time period. It then constructs a "synthetic control" by using the learned model to predict the unit's post-intervention outcomes, had they remained under control. _Synthetic interventions (SI)_ is a recent generalization of the SC framework, which allows for counterfactual estimation of unit outcomes under different interventions, in addition to control . Using our bounds from Section 4, we show how to generalize the SI framework of Agarwal et al.  to settings where interventions are assigned via an _adaptive intervention assignment policy_.

As a motivating example, consider an online e-commerce platform (learner) which assigns discounts (interventions) to users (units) with the goal of maximizing total user engagement on the platform. For concreteness, suppose that the e-commerce platform assigns discounts _greedily_ with respect to the discount level which appears to be best at the current round (i.e. maximizes total engagement for the current user), given the sequence of previously observed (user, discount level, engagement level) tuples. Under such a setting, the intervention assigned at the current round \(n\) will be correlated with the observed engagement levels at previous rounds, thus breaking the requirement of the SI framework  that the intervention assignment is not adaptive to previously observed outcomes.

Formally, we consider a panel data setting in which the principal observes units over a sequence of rounds. In each round \(n\), the learner observes a unit \(n\) under _control_ for \(T_{0}\) time steps, followed by one of \(A\)_interventions_ (including control, which we denote by \(0\)) for the remaining \(T-T_{0}\) time steps, where \(T\). Overloading notation to be consistent with the literature on panel data, we denote the potential outcome of unit \(n\) at time \(t\) under intervention \(a\) by \(Y^{(a)}_{n,t}\), the set of unit \(n\)'s pre-treatment outcomes (under control) by \(Y_{n,pre}:=[Y^{(0)}_{n,1},,Y^{(0)}_{n,T_{0}}]^{T}^{T_{0}}\), and their post-intervention potential outcomes under intervention \(a\) by \(Y^{(a)}_{n,post}:=[Y^{(a)}_{n,T_{0}+1},,Y^{(a)}_{n,T}]^{T}^{T -T_{0}}\). We use \(a\) to refer to an arbitrary intervention in \(\{0,,A-1\}\) and \(a_{n}\) to denote the _realized_ intervention unit \(n\) actually receives in the post-intervention time period. We posit that potential outcomes are generated by the following _latent factor model_ over units, time steps, and interventions.

**Assumption 5.1** (**Latent Factor Model)**.: _Suppose the outcome for unit \(n\) at time step \(t\) under treatment \(a\{0,,A-1\}\) takes the form_

\[Y^{(a)}_{n,t}= U^{(a)}_{t},V_{n}+^{(a)}_{n,t},\]

_where \(U^{(a)}_{t}^{r}\) is a latent factor which depends only on the time step \(t\) and intervention \(a\), \(V_{n}^{r}\) is a latent factor which only depends on unit \(n\), and \(^{(a)}_{n,t}\) is zero-mean SubGaussian random noise with variance at most \(^{2}\). We assume, without loss of generality, that \(| U^{(a)}_{t},V_{n}| 1\) for all \(n 1\), \(t[T]\), \(a\{0,,A-1\}\)._

Note that the learner observes \(Y^{(a)}_{n,t}\)_for only the intervention \(a_{n}\) that unit \(n\) is under at time step \(t\)_, and never observes \(U^{(a)}_{t}\), \(V_{n}\), or \(^{(a)}_{n,t}\). Such "low rank" assumptions are ubiquitous within the panel data literature (see references in Section 2). We assume that \(r\) is known to the learner, although principled heuristics exist for estimating \(r\) in practice from data (see, e.g. Section 3.2 of Agarwal et al. ). Additionally, we make the following "causal transportability" assumption on the latent factors.

**Assumption 5.2** (**Linear span inclusion)**.: _For any post-intervention time step \(t[T_{0}+1,T]\) and intervention \(a\{0,,A-1\}\), we assume that \(U^{(a)}_{t}(\{U^{(0)}_{t}:t[T_{0}]\})\)._

Intuitively, Assumption 5.2 allows for information to be inferred about the potential outcomes in the post-intervention time period using pre-treatment observations. The goal of the learner is to estimate unit-specific counterfactual outcomes under different interventions _when the sequence of units and interventions is chosen adaptively_. In line with previous work in SI and SC, our target causal parameter is the (counterfactual) _average expected post-intervention outcome_.

**Definition 5.3**.: _The average expected post-intervention outcome of unit \(n\) under intervention \(a\) is_

\[^{(a)}_{n,post}:=}_{t=T_{0}+1}^{T}Y^{(a)}_{n,t},\]

_where the expectation is taken with respect to \((^{(a)}_{n,t})_{T_{0}<t T}\)._

While we consider the _average_ post-intervention outcome, our results may be readily extended to settings in which the target causal parameter is any _linear_ combination of post-intervention outcomes. Next we show that under Assumption 5.1 and Assumption 5.2, \(^{(a)}_{n,post}\) may be written as a linear combination of unit \(n\)'s _pre_-intervention outcomes. We note that similar observations have previously been made in the panel data literature (e.g. ), but we include the following lemma for completeness' sake.

**Lemma 5.4** (**Reformulation of average expected post-intervention outcome**).: _Under Assumption 5.1 and Assumption 5.2, there exists slope vector \((a)^{T_{0}}\), such that the average expected post-intervention outcome of unit \(n\) under intervention \(a\) is expressible as_

\[_{n,post}^{(a)}=}(a),Y_ {n,pre}.\]

\((a)\) may be interpreted as a unit-independent measure of the causal relationship between pre- and post-intervention outcomes. Using this reformulation, adaptive guarantees for the estimation of causal effects over time may now be obtained by applying our online PCR results of Section 4. Overloading the notation of Section 3, we let \(_{n}=(Y_{1,pre},,Y_{n,pre})^{T}\), \(_{n}=(Y_{1,pre},,Y_{n,pre})^{T}\), \(_{n,pre}=(_{n,1}^{(0)},,_{n,T_{0}}^{(0)})^{T}\), \(_{n}=(_{1,pre},,_{n,pre})^{T}\)\(_{n}=_{t=T_{0}+1}^{T}_{n,t}^{(a_{n})}\), \(_{n}=(_{1},,_{n})^{T}\), and

\[_{n}=(}_{t=1}^{T_{0}}Y_{1,t}^{(a_{1})}, ,}_{t=1}^{T_{0}}Y_{n,t}^{(a_{n})})^{T}.\]

Finally, we define quantities such as \(_{n}(a)\), \(_{n}(a)\), \(_{n}(a)\) analogously to Section 3. We now turn to bounding our primary quantity of interest in the panel data setting: prediction error for the average expected post-intervention outcome.

**Theorem 5.5** (**Prediction error of average expected post-intervention outcome**).: _Let \((0,1)\) be an arbitrary confidence parameter and \(>0\) be chosen to be sufficiently small, as detailed in Appendix F. Further, assume that Assumptions 5.1 and 5.2 are satisfied, there is some \(n_{0} 1\) such that \((_{n_{0}}(a))=r\), and \(_{n}(a) 2\) for all \(n n_{0}\). If \(T_{0}T\) and \(r n}\), then under Assumption 4.2 with probability at least \(1-O(A)\), simultaneously for all interventions \(a\{0,,A-1\}\)_

\[|}_{n,post}^{(a)}-_{n,post}^{(a)}| =(}}+  n}}+)(T_{0} n)}})\]

_where \(}_{n,post}^{(a)}:=} _{n}(a),Y_{n,pre}\) is the estimated average post-intervention outcome for unit \(n\) under intervention \(a\)._

A more complicated expression which does not require Assumption 4.2 or \(T_{0}T\) may be found in Appendix G. Observe that \(|}_{n,post}^{(a)}-_{n,post}^{(a)}| 0\) with high probability as \(T,T_{0},n\).

We conclude this section by comparing our results with those of the (non-adaptive) synthetic interventions framework of Agarwal et al. . Since we are regressing over _time_, our method for estimating \(}_{n,post}^{(a)}\) is known as a _horizontal_ regression method in the panel data literature. This is in contrast to _vertical_ regression methods, which regress over _units_. See Shen et al.  for more details on the similarities and differences between horizontal and vertical regression methods in panel data settings. While we do not exactly match the bound of Agarwal et al.  since their synthetic interventions framework of uses a vertical regression method, the two bounds are similar, with the notable differences being as follows: (1) The bound of  contains a "slow" \((r^{1/2}T_{0}^{-1/4})\) term which does not appear in our analysis. (2) The non-adaptive SI bound also contains a term which scales as \((}{}})\) in the worst case, while our bound has no such dependence. However, this comes at the price of slow rate whenever \(L\) is large compared to \(}\).

## 6 Conclusion

We obtain the first adaptive bounds for principal component regression and apply them to the problem of online experiment design in the context of panel data, where we allow for interventions to be assigned according to an adaptive policy. Exciting directions for future work include applications of our results to domains such as differential privacy, and using our bounds to obtain contextual bandit algorithms (e.g. based on LinUCB ) capable of regret minimization when given access to noisy contexts.