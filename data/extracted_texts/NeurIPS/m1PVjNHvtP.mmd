# GLinSAT: The General Linear Satisfiability Neural Network Layer By Accelerated Gradient Descent

Hongtai Zeng\({}^{1}\) Chao Yang\({}^{2}\) Yanzhen Zhou\({}^{1}\) Cheng Yang\({}^{2}\) Qinglai Guo\({}^{1}\)

\({}^{1}\) State Key Laboratory of Power Systems, Department of

Electrical Engineering, Tsinghua University

\({}^{2}\) Decision Intelligence Lab, Alibaba DAMO Academy

zenght20@mails.tsinghua.edu.cn, xiuxin.yc@alibaba-inc.com, zhouyzh@126.com, charis.yangc@alibaba-inc.com, guoqinglai@tsinghua.edu.cn

Corresponding author.

###### Abstract

Ensuring that the outputs of neural networks satisfy specific constraints is crucial for applying neural networks to real-life decision-making problems. In this paper, we consider making a batch of neural network outputs satisfy bounded and general linear constraints. We first reformulate the neural network output projection problem as an entropy-regularized linear programming problem. We show that such a problem can be equivalently transformed into an unconstrained convex optimization problem with Lipschitz continuous gradient according to the duality theorem. Then, based on an accelerated gradient descent algorithm with numerical performance enhancement, we present our architecture, GLinSAT, to solve the problem. To the best of our knowledge, this is the first general linear satisfiability layer in which all the operations are differentiable and matrix-factorization-free. Despite the fact that we can explicitly perform backpropagation based on automatic differentiation mechanism, we also provide an alternative approach in GLinSAT to calculate the derivatives based on implicit differentiation of the optimality condition. Experimental results on constrained traveling salesman problems, partial graph matching with outliers, predictive portfolio allocation and power system unit commitment demonstrate the advantages of GLinSAT over existing satisfiability layers. Our implementation is available at https://github.com/HunterTracer/GLinSAT.

## 1 Introduction

Constrained decision-making problems are pervasive across various disciplines. For example, logistics companies need to arrange delivery routes to minimize transportation costs while ensuring that all orders are delivered on time. Power system operators need to decide how to allocate electricity production between different power plants to meet ever-changing electricity demand while maintaining system stability. Unfortunately, directly solving these complex constrained decision-making problems via commercial optimization solvers requires a large amount of time. As a result, in scenarios that require rapid response, traditional solvers may not be suitable due to their long computation time. With the development of deep learning, it is hopeful that neural networks can capture the domain characteristics and complex relationships involved in constrained decision-making problems through their powerful expressive capability and the solution time can be thus reduced. In recent years, research on how to use neural networks to solve constrained decision-making problems has become a topic of general interest. Despite the great success of neural networks on classification and regression tasks, making the outputs of neural networks satisfy specific constraints is not straightforward, which still needs to be further investigated.

A natural idea to impose constraints on the neural network outputs is to penalize the constraint violation in the training stage of supervised learning or reinforcement learning [1; 2; 3]. However, such an approach requires a careful selection of each penalty coefficient to achieve a balance between decision objectives and constraint violations. As the complexity of constraints increases, choosing appropriate penalty factors may require a large number of attempts, which is time-consuming. Moreover, it is often difficult to theoretically guarantee the boundedness of constraint violations , which makes penalty-based methods less attractive. Ref.  managed to determine the width of neural networks required for ensuring feasibility by modeling these networks using binary variables and solving a complex mixed-integer bilevel programming. However, this approach necessitates shrinking the original feasible region and can only handle inequality constraints, which limits its broader application. There are also methods in the literature that are better suited for inequality constraint satisfaction. Ref.  uses gauge function to map the neural network outputs from a \(^{}\)-norm unit ball into a given polyhedral. Despite its success in the field of control, this method may encounter difficulties in handling equality constraints since the polyhedral need to contain the origin as an interior point. Ref.  first calculates a reference point within the interior of a convex region using convex programming in the offline stage, and then computes a feasible point based on this reference point through simple arithmetic operations in the online stage. Despite its efficiency potentially being affected when constraints are not fixed, the method may encounter difficulties in satisfying equality constraints, as it requires computing the null space of the equality constraints. Since the basis for the null space of a matrix is typically dense, calculating the null space for large matrices may present both efficiency and memory challenges. Another way to encode constraints in neural networks is to reformulate the original problem as a Markov decision problem [8; 9]. During the solution process, the decision variables are generated one by one and the value range of the next variable is determined by the value of the current variable so that constraints can be satisfied compulsorily. However, not all decision-making problems can be equivalently converted to Markov decision problems which limits the application of such an approach.

Due to the limitations of the above approaches, many researchers want to use a more reliable way to ensure that the outputs of neural networks satisfy specific constraints. A promising way is to integrate optimization solvers as neural network layers. When we embed a solver for end-to-end learning, we need to pay special attention to the following two issues: the first one is the _supported constraint types_, and the second one is the _efficiency_.

As for the issue of supported constraint types, some frameworks can directly impose combinatorial constraints on neural network outputs through integrating black-box commercial mixed-integer programming solvers at the cost of inexact gradient estimates and poor utilization of GPUs (since modern commercial solvers are CPU-based) [10; 11; 12]. These approaches need to solve combinatorial optimization problems in both training and inference stages, which is time-consuming. Instead of directly handling the combinatorial constraints, some researchers manage to make neural network outputs satisfy constraints obtained from the continuous relaxation of the original problem, e.g. the widely used double stochastic matrix constraint in Ref. [13; 14; 15] solved by Sinkhorn algorithm [16; 17; 18]. Another example is the positive semi-definite (PSD) matrix constraint with unit diagonals as a continuous relaxation of the original MAXSAT problem . However, both of the above methods can only express specific constraints, which limits their application. Recently, LinSAT, which is based on a generalized Sinkhorn algorithm, is proposed to impose positive linear constraints on neural network outputs . However, the requirement for all elements in constraints to be non-negative limits the application of LinSAT. For example, even for a simple constraint \(x y\), namely \(x-y 0\), LinSAT cannot be used due to the negative coefficient in front of \(y\), which shows the limited expressiveness of LinSAT. Decision variables with negative constraint coefficients occur a lot in real-life decision-making problems, such as the bin packing problem , chemical process scheduling , power system unit commitment , etc.

To deal with general linear constraints in a differentiable way, currently, there are two main approaches, CvxpyLayers  and OptNet . However, when solving a batch of problems, both of them may encounter efficiency issues. Although CvxpyLayers can achieve parallelism through multiprocessing on the CPU, there are only a dozen of cores in one CPU, leading to limited parallelism performance. On the other hand, OptNet presents a GPU-based batch quadratic programming interior point solver where batch matrix factorization are performed to accelerate the solution process. Unfortunately, batch matrix factorization may be still a computational bottleneck even when GPU is used. Although some scholars have also studied how to parallelize parts of operations in matrix factorization on the GPU [26; 27], the degree of parallelism still highly depend on the structure of the matrix and its elimination tree. Two nodes in the elimination tree can be computed in parallel only when there is no direct branch connecting them. As a result, matrix factorization cannot fully utilize the parallel computing ability of the GPU due to the sequential characteristics in the elimination tree .

In this paper, we investigate how to apply bounded and general linear constraints to neural network outputs in a differentiable way while ensuring batch processing can be performed efficiently on the GPU.

**The contributions of this paper include:**

1) To impose general linear and bounded constraints on neural network outputs in a differentiable way, we formulate the corresponding projection problem as an entropy-regularized linear programming where negative logistic entropic regularization terms are added into the objective function. We show that such an entropy-regularized linear programming problem can be transformed into an unconstrained convex optimization problem with Lipschitz continuous gradient, and thus can be solved by gradient descent based algorithms where no matrix factorization operation is required.

2) We design GLinSAT, a general linear satisfiability layer to impose linear constraints on neural network outputs based on a state-of-the-art accelerated gradient descent algorithm with numerical performance enhancement. Since the main operations in GLinSAT is matrix-vector product and no matrix factorization is involved, it is convenient to execute these operations in parallel on the GPU. Although all the operations involved in GLinSAT are differentiable which means that we can directly use the automatic differentiation mechanism to perform back propagation, we also provide an alternative way for derivative calculation based on the optimality condition to reduce the memory consumption.

3) We then provide experimental results to demonstrate the capabilities of our proposed method. Experiments on constrained traveling salesman problems, partial graph matching with outliers, predictive portfolio allocation and power system unit commitment show the efficacy of our proposed method and advantages over existing methods. A comparison of methodologies for imposing constraints on neural networks outputs is presented in Table 1. A pipeline that shows how our approach works is provided in Fig. 1.

   Ref. & Abbr. of & Constraint & GPU & Matrix & Exact & Explicit & Implicit \\  & approach & & type & comput- & factorization free & ent & propagation & propagation \\ 
[10; 11; 12] & Perturbed & combination & – & – & – & ✗ & ✗ & ✓ \\
[13; 14; 15] & Spinkhorn & double & ✓ & ✓ & ✓ & ✓ & ✗ \\  & & & stochastic & & ✓ & ✓ & ✓ & ✗ \\  & & matrix & & & & & & \\  & & PSD matrix & & & & & & \\
 & SATNet & with unit & ✓ & ✓ & ✓ & ✗ & ✓ \\  & & diagonals & & & & & & \\
 & LinSAT & positive & ✓ & ✓ & ✓ & ✓ & ✗ \\  & & linear & & & & & \\
 & CvxpyLayers & & cone & ✗ & ✓ & ✗ & ✓ \\
 & OptNet & linear & ✓ & ✗ & ✓ & ✗ & ✓ \\  This & & & & & & & \\ article & GLinSAT & linear & ✓ & ✓ & ✓ & ✓ & ✓ \\    Note: Explicit/Implicit backpropagation means that this algorithm performs backward propagation based on automatic differentiation mechanism/implicit differentiation. **-** means that this algorithm feature is dependent on the implementation of the backend solver.

Table 1: Comparison with existing optimizer layers for imposing constraints on the outputs of neural networks

## 2 Methodology

Sec. 2.1 formulates the neural network output projection problem as an entropy-regularized linear programming by introducing logistic entropy regularization terms in the objective function. Based on duality theorem, the original problem can be transformed into an unconstrained convex optimization problem with Lipschitz continuous gradient. Then, in Sec. 2.2, based on a variant of accelerated gradient descent method, we design GLinSAT, which solves the projection problem using a GPU-friendly algorithm with several numerical enhancements. The corresponding time complexity is also provided in Sec. 2.2. Moreover, although all the operations in the forward pass of GLinSAT are differentiable, in Sec. 2.3, we provide an alternative way based on the optimality condition to calculate the derivatives for memory saving.

### Reformulation of the neural network output projection problem

Here, we want to use a differentiable way to project the output of the neural network \(^{}^{n^{}}\) into variables \(^{}^{n^{}}\) that are as similar as possible but satisfy the following constraints (1).

\[_{1}^{}^{}_{1}^{}\] (1a) \[_{2}^{}^{}_{2}^{}\] (1b) \[_{3}^{}^{}=_{3}^{}\] (1c) \[^{}^{}^{}\] (1d)

where \(_{1}^{}^{m_{1}^{} n^{}}\), \(_{2}^{}^{m_{2}^{} n^{}}\), \(_{3}^{}^{m_{3}^{} n^{}}\), \(_{1}^{}^{m_{1}^{}}\), \(_{2}^{}^{m_{2}^{}}\), \(_{3}^{}^{m_{3}^{}}\), \(^{},^{}^{n^{}}\). Moreover, we also suppose that the feasible region in (1) is non-empty.

Apparently, any general linear constraints with bounded variables like (1) can be converted to the standard form like (2) by shifting bounds and introducing slack variables (see Appendix A.4):

\[=\] (2a) \[\] (2b)

where \(m=m_{1}^{}+m_{2}^{}+m_{3}^{}\), \(n=n^{}+m_{1}^{}+m_{2}^{}\), \(^{m n}\), \(^{m}\), \(^{n}_{+}\). Here, we denote the vector obtained from padding \((m_{1}^{}+m_{2}^{})\) zeros after the original vector \(^{}\) as \(\). Now, the original problem is transformed into a problem of projecting \(^{n}\) onto \(^{n}\) that satisfy constraints (2). In the following sections, we mainly focus on such a transformed problem in standard form.

In this paper, we aim for the vector \(\) after projection to be as close as possible to the vector \(\) prior to projection, while adhering to specified constraints. Here, we use the dot product as a measure of vector similarity. Consequently, our objective function becomes that of maximizing the dot product of vectors \(\) and \(\), which is equivalently described as minimizing the dot product of \(-\) and \(\). Besides, as pointed by , the optimal solution to an linear programming may not be differentiable (or even continuous) with respect to its parameters. Therefore, additional regularization terms need to be included in the objective to make the optimization problem differentiable. Inspired by entropy-regularized optimal transport, here we formulate the projection problem as an entropy-regularized linear programming to make the entire problem differentiable. Logistic entropy regularization terms

Figure 1: A pipeline that shows how GLinSAT layer works.

are added into the objective as follows:

\[_{}f()=_{ }-^{T}+_{j=1}^{n}( }{u_{j}}}{u_{j}}+(1-}{u_{j}}) (1-}{u_{j}}))\] (3a) \[\ =\] (3b)

where \(>0\) is the inverse temperature parameter that controls the approximation degree between the entropy-regularized problem and the original linear programming. The regularization coefficient \(1/\) controls the smoothness of the outputs. The smaller \(1/\) is, the more the outputs tend to be at the extreme point of the feasible region. As \(+\), the optimal solution of the entropy-regularized problem should approach that of the original linear programming.

**Remark 1**.: _It is noteworthy that unlike entropy-regularized optimal transport problems where only regularization terms in the form of \(x x\) are involved in the objective, here logistic entropy regularization terms with respect to both \(x/u\) and its complement \(1-x/u\) are added into the objective. **Actually, additionally incorporating the complementary entropy regularization terms is the most important part for the derivation of the Lagrange dual problem.** Otherwise, we cannot obtain a simple closed-form expression of the dual objective in the following derivation. Similarly, if we use the common \(^{2}\)-norm as the regularization term, we cannot obtain an analytical expression either._

If we denote the dual variables with respect to the equality constraints (3b) as \(\), the Lagrange dual function for (3) can be expressed as follows:

\[g()=_{}(-^{T} +^{T}(}{}}{}+(-}{})- }{}))-^{T})+^{T} \] (4)

where \(,}{}\) represents the element-wise multiplication and division of vector \(\) and \(\) respectively. Since the derivative magnitude of \(x x+(1-x)(1-x)\) tends to infinity when \(x 0^{+}\) or \(x 1^{-}\), the infimum in (4) can be attained only on a stationary point instead of a boundary point. When the infimum in (4) is attained, by making the derivative of the inner function equal to zero, we have:

\[--^{T}+}{} }{-}=}\] (5)

After simplifying the above formula, we can get that when the infimum in (4) is attained, the optimal value of \(()\) can be expressed as:

\[()=(- (--^{T}))\] (6)

where \(()\) is the sigmoid function. Substituting equation (6) into equation (4), we have:

\[g()=^{T}( (--^{T}))+^{T}\] (7)

Since \(()\) is a strictly concave function, by minimizing the opposite of \(g()\), we can obtain the following Lagrange dual problem (8), which is exactly an unconstrained convex optimization problem.

\[_{^{m}}-g()=_{ ^{m}}-^{T}(( --^{T}))-^{T}\] (8)

We can easily show that \(f()\) is a strongly convex function and \(-g()\) has Lipschitz continuous gradient (see explanations in Appendix A.5). Therefore, gradient descent based algorithms can be directly applied to solve such a problem.

### Forward pass in GLinSAT

In the previous section, we have shown that the original entropy-regularized linear programming problem (3) can be equivalently converted into an unconstrained convex optimization problem (8) with Lipschitz continuous gradient. Theoretically, it can be solved readily through gradient descent based method. However, in the actual calculation process, it will be hard to choose a suitable step size if we just use vanilla gradient descent method. If the step size is much greater than the local Lipschitz constant, the algorithm may diverge. Otherwise, the convergence may be too slow.

Considering the strong convexity property of the entropy regularization terms, here we use a variant of accelerated gradient descent method, adaptive primal-dual accelerated gradient descent (APDAGD), which can adaptively approximate the local Lipschitz constant . The detailed procedure of solving the entropy-regularized linear programming problem (3) in GLinSAT is provided in Algorithm 1.

Compared with the original version of APDDAGD, here we improve the numerical performance of Algorithm 1 from the following two aspects. First, we use a smoother way to update the approximation of the local Lipschitz constant \(M\) in GLinSAT. In Algorithm 1, \(M\) is decreased only when the decrease of the dual objective satisfies the corresponding condition for at least two consecutive times. As a result, when \(M\) is already a good estimate of the local Lipschitz constant, the frequency of needless updates can be reduced, which will lead to less computation time. Second, to handle the round-off error, we also use a small number \(\) to relax the criterion for the decrease of the objective function. Otherwise, due to the existence of numerical error, the criterion of sufficient decrease in objective may be never satisfied. If we do not relax the criterion, \(M\) may become a large number and the algorithm will get stuck.

In addition, it is noteworthy that most of the operations involved in Algorithm 1 are calculation of matrix-vector products, vector-vector element-wise products and unary functions. Therefore, it is convenient to execute these operations in parallel on the GPU for solving a batch of entropy-regularized linear programming problems.

As for the time complexity of Algorithm 1, based on Theorem 1 and Theorem 2 in the supplementary material of , it can be easily proved that the number of iterations required by Algorithm 1 is roughly proportional to \(\) and inversely proportional to \(\). The corresponding result is given in Corollary 1 and the detailed discussions can be found in Appendix A.6.

``` Input:\(^{m n}\), \(^{m}\), \(^{n}\), \(^{n}_{+}\), inverse temperature \(>0\), tolerance \(>0\),  initial estimate of Lipschitz constant \(L^{(0)}\), initial estimate of dual variables \(^{(0)}\),  numerical precision \(>0\)  Set \(k=0\), \(M^{(0)}=L^{(0)}\), \(^{(0)}=^{(0)}=^{(0)}\), \(^{(0)}=(-(--^{T}^{(0)}))\), \(^{(0)}=^{(0)}=0\), \(f=\); while\(\|^{(k)}-\|_{2}>\)do  Set \(^{(k+1)}=(1+^{(k)}})/(2M^{(k)})\);  Set \(^{(k+1)}=^{(k)}+^{(k+1)}\);  Set \(^{(k+1)}=^{(k+1)}/^{(k+1)}\);  Set \(^{(k+1)}=^{(k)}+^{(k+1)}(^{(k)}-^{(k)})\);  Set \((^{(k+1)})=(- (--^{T}^{(k+1)}))\);  Set \(^{(k+1)}=^{(k)}-^{(k+1)}((^{(k+1)})-)\);  Set \(^{(k+1)}=^{(k)}+^{(k+1)}(^{(k+1)}-^{(k)})\); if\((-g(^{(k+1)}))-(-g(^{(k+1)}))--\|(^{(k+1)})-b\|_{2}^{2}/(2M^{(k)})\)then if\(f=\)then  Set \(M^{(k+1)}=M^{(k)}/2\); else  Set \(M^{(k+1)}=M^{(k)}\);  end if  Set \(k=k+1\); else  Set \(M^{(k)}=2M^{(k)}\), \(f=\);  end if  end while Output: Optimal primal variables \(^{(k)}\), Optimal dual variables \(^{(k)}\) ```

**Algorithm 1**Solving the entropy-regularized linear programming problem in GLinSAT

**Corollary 1**.: _Assume that the optimal dual solution \(^{*}\) of problem (3) satisfies \(\|^{*}\|_{2} R\). Then, for given tolerance \(>0\), the number of required iterations is \(O(\|\|_{2}())\)._

### Backward pass in GLinSAT

Since all the operations involved in Algorithm 1 are differentiable with respect to \(\), a natural idea is to directly use the auto differential mechanism to calculate the derivatives in the backward pass. However, directly backward propagation may require ever growing memory to store computational graphs and may cost much time when the forward pass requires a lot of iteration steps. To save the memory usage and accelerate the derivative calculation, we also provide an alternative way based on the optimality condition to calculate the derivatives in GLinSAT.

First, by calculating the derivative of \(-g()\), we can obtain the optimality condition as follows:

\[()=((- (--^{T})))-=\] (9)

According to implicit differentiation and chain rule, differentiating equation (9), we can get:

\[}{}=-(}{ })^{-1}}{}\] (10)

Furthermore, according to equation (6), the derivative of loss function \(l\) with respect to \(\) can be calculated as:

\[}=}}{}+}}{ y}}{}+}}{}=}}{}-(}}{}+})(}{ })^{-1}}{}\] (11)

In the actual implementation of GLinSAT, we do not explicitly form these Jacobian matrices \(}{},}{},(}{})^{-1}}{}\). Instead, we directly form the matrix-vector products \(}}{}, { l}{}}{}\). In addition, since the jacobian matrix \(}{}\) is positive semi-definite (see derivations in Appendix A.7), we can use conjugate gradient method to calculate the inverse-matrix-vector products in GLinSAT. Therefore, only matrix-vector product operations are involved in the calculation of derivatives. Moreover, for the sake of completeness, in GLinSAT, we also implement derivatives with respect to \(\), \(\), \(\) for future potential usage. The detailed derivation process of all derivatives is provided in Appendix A.7.

## 3 Experimental Results

In this section, experiments on constrained traveling salesman problems, partial graph matching with outliers, predictive portfolio allocation and power system unit commitment are used to demonstrate the advantages of GLinSAT through comparison with the state-of-the-art linear satisfiability layers LinSAT , CvxypLayers  and OptNet . For OptNet, LinSAT and GLinSAT, the regularization coefficients of nonlinear terms are all set to \(1/\). For CvxypLayers, the projection problem to be solved is set to the same as (3). The first three experiments originate from Ref. . The last experiment is the unit commitment problem in actual power systems. In the following sections, GLinSAT-(Dense/Sparse)-(Explicit/Implicit) means that GLinSAT is used with dense/sparse matrix and backpropagation is performed using automatic differential/implicit differential. LinSAT-(Dense/Sparse)-(100/500) means that LinSAT is used with dense/sparse matrix and maximum iteration number is set to 100/500. The reason we cannot set the maximum iteration number in LinSAT to \(+\), as we do in GLinSAT, is that LinSAT may iterate endlessly and get stuck in such a case. All the experiments are conducted on a computer with a 24-core Intel(R) Xeon(R) Platinum 8360H CPU and a NVIDIA Tesla A100 GPU through Pytorch 2.2. Our code is provided in https://github.com/HunterTracer/GLinSAT.

### Constrained traveling salesman problem

Using the traveling salesman problem (TSP) dataset in , here we test the performance of each satisfiability layer through experiments on TSP with starting and ending cities constraint and priority constraint respectively. The mathematical formulation of TSP with starting and ending cities constraint (TSP-StartEnd) and TSP with priority constraint (TSP-Priority) is provided in AppendixA.8. The detailed experimental settings are provided in Appendix A.8. We report the average batch processing performance in Table 2 where \(\) is set to 0.1. The results when \(\) is set to 10\({}^{}\) are similar therefore we display the results in Table A.1 and Table A.2 in Appendix A.8.

From Table 2, it can be seen that GLinSAT-Dense-Implicit outperforms all the other methods with minimum total storage and shortest total computation time. We can also find that our proposed GLinSAT is memory-efficient. Even though we choose the GLinSAT-Dense-Explicit method which will cost the most memory among all versions of GLinSAT, the total memory usage is still less than that of LinSAT-Sparse-100. We also attempted to set the maximum number of iterations for LinSAT to \(+\), but at this point LinSAT will get stuck and we cannot obtain a reasonable result. Contrarily, for our proposed GLinSAT, the convergence is guaranteed, so setting the maximum iteration number to \(+\) will not affect the result.

To obtain feasible tours, we exploit two kinds of post-processing methods in the validation stage . The first one is rounding and the second one is beam search where the width of the beam is set to 2048. Table 3 shows the average tour length and feasibility ratio of each method. Since CvxpLyayers and OptNet are hundreds of times slower than LinSAT and GLinSAT, we are unable to obtain trained models within reasonable time and thus the results are not included.

    &  &  \\   & GPU Mem./MB &  & GPU Mem./MB &  \\  Layer & Proj. & Backprop. & Proj. & Backprop. & Proj. & Backprop. & Proj. & Backprop. \\  CvxpLyayers & — & — & 112.1 & 18.39 & — & — & 116.5 & 19.94 \\ OptNet & 14305 & 5005 & 18.92 & 0.929 & 14333 & 5005 & 20.26 & 1.136 \\ LinSAT-Dense-100 & 14977 & 181.2 & **0.278** & 0.417 & 15009 & 180.9 & **0.276** & 0.418 \\ LinSAT-Dense-500 & 74108 & 181.2 & 1.323 & 1.927 & 74272 & 180.9 & 1.317 & 1.929 \\ GLinSAT-Dense-Explicit & 4380 & **4.868** & 0.382 & 0.240 & 4898 & **4.880** & 0.440 & 0.270 \\ GLinSAT-Dense-Implicit & **13.35** & 532.33 & 0.306 & **0.143** & **13.36** & 53.22 & 0.349 & **0.146** \\ LinSAT-Sparse-100 & 7971 & 132.0 & 0.281 & 0.358 & 8026 & 132.6 & 0.286 & 0.368 \\ LinSAT-Sparse-500 & 39020 & 133.5 & 1.356 & 1.614 & 39309 & 133 & 1.397 & 1.645 \\ GLinSAT-Sparse-Explicit & 2787 & 5.426 & 0.603 & 0.326 & 3127 & 5.983 & 0.652 & 0.355 \\ GLinSAT-Sparse-Implicit & 62.95 & 24.71 & 0.454 & 0.158 & 63.27 & 24.51 & 0.495 & 0.165 \\    Note: The GPU memory used by CvxpLyayers is not counted since CvxpLyayers use the CPU parallel mechanism. Statistics of CvxpLyayers and OptNet are based on the first epoch since we cannot obtain a well-trained model in reasonable time.

Table 2: Average allocated GPU memory and solution time of different satisfiability layers during batch processing of projection and backpropagation when \(\) is set to 0.1 in TSP training phase

    &  &  \\   &  &  &  &  \\  & with \(\) = 10\({}^{}\) & & with \(\) = 10\({}^{}\) & & with \(\) = 10\({}^{}\) & & with \(\) = 10\({}^{}\) \\  Layer & Mean & Feas. & Mean & Feas. & Mean & Feas. & Mean & Feas. \\  & Length & Ratio & Length & Ratio & Length & Ratio & Length & Ratio \\  LinSAT-Dense-100 & 4.007 & 15.3\% & 3.843 & **100\%** & 4.114 & 41.6\% & 3.952 & **100\%** \\ LinSAT-Dense-500 & 3.926 & 93.6\% & 3.823 & **100\%** & 4.098 & 91.5\% & 3.947 & **100\%** \\ GLinSAT-Dense-Explicit & 3.939 & 94.2\% & 3.817 & **100\%** & 4.079 & **93.5\%** & 3.934 & **100\%** \\ GLinSAT-Dense-Implicit & **3.922** & 94.2\% & **3.811** & **100\%** & **4.068** & 93.4\% & **3.927** & **100\%** \\ LinSAT-Sparse-100 & — & — & 3.843 & **100\%** & — & — & 4.567 & **100\%** \\ LinSAT-Sparse-500 & — & — & 3.818 & **100\%** & — & — & 4.400 & **100\%** \\ GLinSAT-Sparse-Explicit & 3.939 & 94.2\% & 3.817 & **100\%** & 4.078 & 92.6\% & 3.935 & **100\%** \\ GLinSAT-Sparse-Implicit & 3.929 & **94.6\%** & 3.818 & **100\%** & 4.073 & 93.4\% & 3.933 & **100\%** \\    Note: The output of LinSAT-Sparse when \(1/\) = 10\({}^{}\) is not a real number so that the results are not shown.

Table 3: Mean tour length and feasibility ratio obtained from using different \(\) and post-processing methods in TSP validation stage From Table 3, we can see that GLinSAT-Dense-Implicit results in the shortest mean tour length when beamsearch is used. It is also noteworthy that LinSAT will produce poor solution when we apply rounding to the results and the max iteration number is set to 100. Although setting the maximum number of iterations to 500 can improve LinSAT's performance, LinSAT's performance is still not as good as GLinSAT. Considering that the total computation time of LinSAT is more than five times that of GLinSAT at this time, it makes LinSAT less competitive.

### Partial graph matching with outliers

The detailed mathematical formulation of partial graph matching with outliers is provided in A.9. We carry out experiments on Pascal VOC Keypoint dataset  with Berkeley annotations  under the unfiltered setting [20; 33].

Considering there are graphs with different sizes in one batch, we stack constraints as block diagonal matrices and forward them to LinSAT and GLinSAT. However, CvxpyLayers and OptNet currently cannot handle large block diagonal matrices. Disciplined parameterized programming compilation in CvxpyLayers and matrix factorization of large matrices in OptNet will cost a significant amount of time. Therefore, we can only use a for-loop to handle a batch with different sizes separately. The average GPU memory usage and solution time across different satisfiability layers is provided in Table A.3 of Appendix A.9. In the validation stage, we use Hungarian algorithm and greedy strategy for obtaining feasible integer solutions . We regard the cost of matching a pair of nodes as the outputs of satisfiability layers, then use Hungarian algorithm to obtain a maximum matching. Finally, we use greedy strategy to preserve pairs with top-\(p\) matching scores for constraint satisfaction. The matching F1 scores between graph pairs across various satisfiability layers are shown in Table 4. The result of LinSAT-Dense-500 is not given due to out-of-memory (OOM) issues. According to Table 4, we can find GLinSAT yields the highest F1 scores across all satisfiability layers.

### Predictive portfolio allocation

In this section, we use the predictive portfolio allocation dataset in . Denote \(x_{i}\) as the predicted portfolio decision variable of asset \(i\), \(\) as the preferred portfolio asset. Our portfolio allocation needs to maximize the Sharpe ratio  while ensuring decision variables satisfy constraints \(_{i=1}^{n}x_{i}=1\), \(_{i}x_{i} q\) where \(q\) is a pre-defined positive constant. The details of experiments are provided in Appendix A.10. The average memory usage and solution time is shown in Table A.4 of Appendix A.10. According to Table A.4, we can find that our proposed GLinSAT is the fastest layer among all layers. In Table 5, we show the mean Sharpe ratio obtained from different satisfiability layers. Our proposed method always yields a high Sharpe ratio whether \(\) takes \(10^{-1}\) or \(10^{-2}\).

    & \(\) = 10\({}^{-1}\) & \(\) = 10\({}^{-2}\) & & \(\) = 10\({}^{-1}\) & \(\) = 10\({}^{-2}\) \\  Layer & Mean F1 & Mean F1 & Layer & Mean F1 & Mean F1 \\  CvxpyLayers & 0.616 & 0.605 & OptNet & 0.619 & 0.613 \\ LinSAT-Dense-100 & 0.619 & 0.614 & LinSAT-Dense-500 & \(\) & \(\) \\ GLinSAT-Dense-Explicit & **0.620** & **0.620** & GLinSAT-Dense-Implicit & 0.619 & **0.620** \\ LinSAT-Sparse-100 & **0.620** & 0.618 & LinSAT-Sparse-500 & 0.619 & 0.611 \\ GLinSAT-Sparse-Explicit & 0.619 & **0.620** & GLinSAT-Sparse-Implicit & **0.620** & **0.620** \\   

Table 4: Mean F1 scores across different satisfiability layers in partial graph matching problem

    & \(\) = 10\({}^{-1}\) & \(\) = 10\({}^{-2}\) & & \(\) = 10\({}^{-1}\) & \(\) = 10\({}^{-2}\) \\  Layer & S. Ratio & S. Ratio & Layer & S. Ratio & S. Ratio \\  CvxpyLayers & 2.535 & **2.600** & OptNet & **2.553** & 2.381 \\ LinSAT-Dense-100 & 2.245 & 2.409 & LinSAT-Dense-500 & 2.245 & 2.409 \\ GLinSAT-Dense-Explicit & 2.535 & **2.608** & GLinSAT-Dense-Implicit & 2.535 & **2.608** \\ LinSAT-Sparse-100 & 2.245 & 2.409 & LinSAT-Sparse-500 & 2.245 & 2.409 \\ GLinSAT-Sparse-Explicit & 2.535 & **2.608** & GLinSAT-Sparse-Implicit & 2.535 & **2.608** \\   

Table 5: Mean Sharpe ratio obtained from different satisfiability layers in portfolio allocation problem 

### Power system unit commitment

In this section, we carry out experiments about the unit commitment problem on a real provincial power system. In the unit commitment problem, there are hard constraints and soft constraints. Generally, constraints directly related to generators are regarded as hard constraints, e.g. the generator logical constraints, generator minimum up-time and down-time constraints. Constraints related to the section power and load balance are usually regarded as soft constraints where violation with large penalty coefficient is introduced in the objective . The unit commitment problem can be formulated into a mixed-integer linear programming (MILP) problem, which is detailed in Appendix A.11. Based on one-year power system load data, we first use Gurobi  to solve the MILP within a 0.1% optimality gap.

After obtaining the integer solution of the unit commitment problem, we then use supervised learning to train neural networks with satisfiability layers so that they can predict the optimal state of a unit while satisfying logical constraints, minimum up-time and down-time constraints. As pointed by , when we consider logical constraints and minimum up-time and down-time constraints, these constraints formulate a convex hull so that the extreme points of the corresponding feasible region are binary. As a result, we could expect that the outputs of satisfiability layers tend to be binary when \(1/ 0\), thereby making all constraints, including integer constraints, more likely to be satisfied after rounding operations. Once we obtain the predicted integer commitment status of the generators, we can fix the integer variables in the unit commitment problem and solve the corresponding linear programming problem, thereby providing a good initial point for the original mixed-integer programming problem.

Since negative coefficients occur in constraints, LinSAT cannot be used. In Table A.5 of Appendix A.11, we compare the performance of batch processing with different layers. When we stack constraints into block diagonal form to exploit parallelism, there are about 1000000 rows and 2000000 columns in the matrix. GLinSAT-Sparse-Implicit is the only way that will not report out-of-memory issues when we use GLinSAT. Both CvxpyLayers and OptNet cannot directly handle such a giant matrix within reasonable time thus we can only use a sequential way instead.

We train neural networks with \(=0.1\). Table 6 shows the feasibility ratio and average gap on feasible solutions obtained from fixing unit state variables to rounded outputs of neural networks and then solving the continuous unit commitment problem in validation stage. Since CvxpyLayers and OptNet are significantly slower than GLinSAT, we are unable to obtain trained models within reasonable time and the results are not included in Table 6. Table 6 shows that if we use sigmoid function to replace the satisfiability layer in training and validation, we cannot obtain any feasible solution. As \( 0\), the feasibility ratio increases. When using GLinSAT with \( 0.0005\), the feasibility ratio reaches 100%. In addition, when we set \(\) to exactly zero and solve the resulted projection problem in the form of linear programming (LP) via Gurobi, 100% feasible solutions are also found.

## 4 Conclusion

In this paper, we reformulate the neural network output projection problem into a convex optimization problem with Lipschitz continuous gradient. We then propose GLinSAT, a general linear satisfiability layer to impose linear constraints on neural network outputs where all the operations are differentiable and matrix-factorization-free. GLinSAT can fully leverage the parallel computing capabilities of the GPU. We showcase four applications of GLinSAT and the advantages of our proposed framework over existing satisfiability layers are illustrated.

   Training final layer & Validation final layer & \(1/\) & Feasibility Ratio & Average Gap \\  Sigmoid & Sigmoid & — & 0\% & — \\ GLinSAT-Sparse-Implicit & GLinSAT-Sparse-Implicit & 0.01 & 86.23\% & 0.1119\% \\ GLinSAT-Sparse-Implicit & GLinSAT-Sparse-Implicit & 0.005 & 95.41\% & 0.1381\% \\ GLinSAT-Sparse-Implicit & GLinSAT-Sparse-Implicit & 0.001 & 98.17\% & **0.1109\%** \\ GLinSAT-Sparse-Implicit & GLinSAT-Sparse-Implicit & 0.0005 & **100\%** & 0.1114\% \\ GLinSAT-Sparse-Implicit & GLinSAT-Sparse-Implicit & 0.0001 & **100\%** & 0.1114\% \\ GLinSAT-Sparse-Implicit & Gurobi-LP & 0 & **100\%** & 0.1114\% \\   

Table 6: Feasibility ratio and average gap obtained from using different \(1/\) in validation