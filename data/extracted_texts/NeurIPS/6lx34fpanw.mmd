# Improving Generalization in Federated Learning with Model-Data Mutual Information Regularization:

A Posterior Inference Approach

 Hao Zhang, Chenglin Li, Nuowen Kan, Ziyang Zheng, Wenrui Dai, Junni Zou, Hongkai Xiong

School of Electronic Information and Electrical Engineering

Shanghai Jiao Tong University

Correspondence to: Chenglin Li <LCL1985@sjtu.edu.cn>.

###### Abstract

Most of existing federated learning (FL) formulation is treated as a point-estimate of models, inherently prone to overfitting on scarce client-side data with overconfident decisions. Though Bayesian inference can alleviate this issue, a direct posterior inference at clients may result in biased local posterior estimates due to data heterogeneity, leading to a sub-optimal global posterior. From an information-theoretic perspective, we propose FedMDMI, a federated posterior inference framework based on model-data mutual information (MI). Specifically, a global model-data MI term is introduced as regularization to enforce the global model to learn essential information from the heterogeneous local data, alleviating the bias caused by data heterogeneity and hence enhancing generalization. To make this global MI tractable, we decompose it into local MI terms at the clients, converting the global objective with MI regularization into several locally optimizable objectives based on local data. For these local objectives, we further show that the optimal local posterior is a Gibbs posterior, which can be efficiently sampled with stochastic gradient Langevin dynamics methods. Finally, at the server, we approximate sampling from the global Gibbs posterior by simply averaging samples from the local posteriors. Theoretical analysis provides a generalization bound for FL w.r.t. the model-data MI, which, at different levels of regularization, represents a federated version of the bias-variance trade-off. Experimental results demonstrate a better generalization behavior with better calibrated uncertainty estimates of FedMDMI.

## 1 Introduction

Federated learning (FL), as an emerging distributed learning framework, has garnered considerable attention (McMahan et al., 2017). In this paradigm, clients collaborate to train a single global model, under the central coordination of a server. Notably, such a collaborative training proceeds without the necessity of sharing or exchanging the raw data of clients, thus providing a basic level of privacy protection. However, two primary challenges arise, specifically revolving around the intra-client data scarcity and inter-client data heterogeneity, since client models locally trained on these scarce and heterogeneous data are prone to overfitting and bias, leading to a diminished generalization performance for the globally aggregated model at the server.

A multitude of efforts have been made to address this issue from various perspectives, including federated optimization (Acar et al., 2021; Karimireddy et al., 2020), federated domain generalization (Nguyen et al., 2022; de Luca et al., 2022), federated knowledge distillation (Zhu et al., 2021; Afonin and Karimireddy, 2021), etc. Despite their progress, a majority of the existing FL formulations consistently treat it as a point-estimate (i.e., a single value estimated for each model weight) basedon the loss function optimized on local client data. From a probability theory perspective, however, using these single point-estimates as weights inherently poses a risk of overfitting on the scarce client-side training data. More crucially, this may also lead to overly confident decisions, due to the failure to provide reliable assessment of the uncertainty for models (Shridhar et al., 2019), which is indispensable in some safety-critical applications of federated learning, e.g., autonomous driving, healthcare, and finance.

Instead of single point-estimates, an alternative approach is to apply posterior inference over the model weights (Jospin et al., 2022), which is theoretically attractive for preventing overfitting to scarce training data and providing a natural way to assess uncertainty in weight estimates that can be further propagated into the model's prediction. Under the FL settings, however, little work has explored inferring a global posterior from the heterogeneous data across clients. To achieve the global posterior inference in FL, a typical framework comprises: _i)_ each client initializing a local model based on global posterior parameters and independently conducting a local posterior inference; _ii)_ the server receiving local posteriors and multiplicatively aggregating them based on global posterior decomposition. These two steps will then iterate until the global posterior converges. Following this framework, FedPA (Al-Shedivat et al., 2020) approximates these local posteriors via the Markov chain Monte Carlo (MCMC) method, and further reduces the computation cost. However, the data heterogeneity among clients may still lead to a biased local posterior inference, which in turn results in a sub-optimal global posterior. To mitigate this bias, FedEP (Guo et al., 2023) approximates the global posterior using an expectation propagation method, which, however, incurs extra storage and communication overhead. As a stateful method, FedEP is also not a suitable solution for low-participation FL scenarios. Consequently, the issue of biased local posteriors incurred by the data heterogeneity in federated posterior inference remains unresolved.

In this paper, from an information-theoretic perspective, we propose to infer the global posterior in FL by incorporating a global mutual information (MI) regularization between the model and data (FedMDMI), which has been proved to be an effective measure of generalization capability of the learning algorithms (Xu and Raginsky, 2017). Under the FL settings, we show that the proposed global MI regularization can effectively alleviate the bias of local posterior incurred by data heterogeneity, and thus improve generalization capability of the global posterior. However, due to the non-exchange restriction of raw data in FL, it is impractical for the server to measure this global MI explicitly. We therefore turn to decomposing the global MI into local MI terms, converting the global objective with MI regularization into several locally optimizable objectives based on the client data. For these local objectives, we show that the optimal local posterior is a Gibbs posterior, a conclusion well-established in the field of PAC-Bayesian learning (Alquier, 2021). Then, we employ the stochastic gradient Langevin dynamics (SGLD) method (Welling and Teh, 2011) to sample from this local Gibbs posterior, which provides an unbiased and efficient sampling-based posterior approximation. Finally, at the server, we approximate the sampling from the global Gibbs posterior by simply taking the average of samples from the local posteriors. This aggregation method has been successfully employed and proved to have a non-asymptotic convergence guarantee with the true global posterior in decentralized and federated scenarios (Gurbuzbalaban et al., 2021; Plassier et al., 2023). Through in-depth analysis, we provide a theoretical guarantee of our FedMDMI by establishing a generalization bound for FL w.r.t. the model-data MI. As a byproduct, differential privacy protection can also be brought by our FedMDMI. Our main contributions are as follows.

* We introduce an information-theoretic approach for the global posterior inference in FL. It incorporates a global model-data MI term as regularization, which enhances generalization by alleviating bias of inferred local posteriors, and offers certain client-level privacy protection as byproduct.
* We establish a generalization bound for FL w.r.t. the global model-data MI, showing that regularizing this global MI leads to a reduction in the generalization error. At different levels of regularization, it also represents a federated version of the bias-variance trade-off.
* Extensive empirical results validate that FedMDMI outperforms the other point-estimate and Bayesian inference-based baselines, while providing well-calibrated uncertainty estimates.

## 2 Related Work

**Model-Data Mutual Information (MI).** The mutual information (MI) between model and data quantifies the information that a model contains about the raw data, and serves as an effective measure of the model's complexity. Extensive research (Xu and Raginsky, 2017; Asadi et al., 2018) hasrevealed a theoretical connection between this MI and the generalization ability of learning algorithms in centralized learning. Russo and Zou (2016) further demonstrate that this MI can effectively bound and reduce the bias in data analysis for centralized learning. For distributed and federated learning, prior works (Yagli et al., 2020; Barnes et al., 2022; Sefidgaran et al., 2022) also establish generalization bounds based on local MI at clients. Recent studies (Chor et al., 2023; Sefidgaran et al., 2023) further explore the relationship between the generalization bound and communication rounds through the local MI. In contrast to these methods, our generalization bounds are based on global MI at the server, resulting in a tighter generalization bound. More significantly, we also provide a posterior inference method to estimate this MI.

**Bayesian Inference.** Compared to point-estimates of models, the posterior estimate is more suitable for FL with scarce local client data. Bayesian model ensemble learning-based methods, such as FedBE (Chen and Chao, 2020) and FedPPD (Bhatt et al., 2022), construct a robust global posterior distribution via ensemble learning and knowledge distillation, which, however, require additional auxiliary datasets at the server. Global posterior decomposition-based methods, on the other hand, decompose the global posterior into a product of client posteriors. Among them, FedPA (Al-Shedivat et al., 2020) proposes a computation- and communication-efficient framework for global posterior decomposition, where data heterogeneity may still result in a biased local inference and sub-optimal global posterior. While FedEP (Guo et al., 2023) introduces expectation propagation at the client side to obtain a sound global posterior at the server, this approach incurs additional storage and communication costs and may not be suitable for federated scenarios with low client participation. The work most closely related to ours is FALD (Plasier et al., 2023), which can be viewed as a special case of our FedMDMI when the hyperparameter \(\) is set to 1. We will further demonstrate that this hyperparameter \(\) is instrumental in controlling the tradeoff between fitting and generalization. Different from FALD, our FedMDMI further incorporates the global model as a more robust prior, and we derive a valuable generalization bound w.r.t. the model-data MI.

## 3 Preliminaries and Problem Statement

The objective of standard FL is to learn a single global model \(w\) from \(m\) clients via the following optimization problem:

\[_{w^{d}}L_{}(w)=_{i} L_{p(S_{i})}(w),\] (1)

where \(L_{p(S_{i})}(w)=_{z_{i} p(S_{i})}[_{i}(w,z_{i})]\) represents the local expected risk of the \(i\)-th client associated with data distribution \(p(S_{i})\) on local data \(S_{i}\), and the loss function \(_{i}(w,z_{i})\) is usually chosen as a negative log likelihood, i.e., \(- p(z_{i}|w)\). We further define a set of random variables \(S=\{S_{1},,S_{m}\}\) as the global dataset, consisting of \(m\) heterogeneous client datasets. Moreover, we let \(\{z_{i}^{j}\}_{j=1}^{n_{i}}\) denote the local training dataset of size \(n_{i}\) drawn independently from distribution \(p(S_{i})\). This setup also gives rise to the global empirical risk as:

\[_{w^{d}}_{}(w)=_{i }L_{S_{i}}(w),\] (2)

where \(L_{S_{i}}(w)=}_{j=1}^{n_{i}}_{i}(w,z_{i}^{j})\) is the local empirical risk.

From a probability theory perspective, employing a single point-estimate as the model weight, as shown in Eq. (2), may render the model susceptible to overfitting, particularly when dealing with small and scarce datasets at clients. In addition, this point-estimate also makes the model incapable of correctly evaluating the uncertainty in the client's local training data, leading to overly confident decisions. Motivated by the Bayesian inference, we thus treat the global model \(w\) as a random variable rather than a single point, and then estimate the global posterior of model \(w\) given the global dataset \(S\). Subsequently, the objective of FL converts to minimizing the posterior expected loss:

\[_{p(w|S)}L_{}(w)=_{p(w|S)}[_{i }L_{S_{i}}(w)],\] (3)

where \(p(w|S)=p(w|S_{1},,S_{m})\) denotes the global posterior. By taking an additional expectation over \(p(w|S)\), we are then able to evaluate the risk of learned global posterior rather than a single value-estimate of model weights \(w\).

  \(S_{i},S\) & random variables denoting local, global data \\ \(w\) & random variable denoting learned global model \\ \(T,t\) & number, index of communication rounds \\ \(K,k\) & number, index of local update step \\ \(w_{t,k}^{i}\) & sample of client \(i\)â€™s model at round \(t\) and step \(k\) \\ \(w_{t}\) & sample of aggregated server model at round \(t\) \\  

Table 1: Summary of notations.

However, it is intractable to directly infer the global posterior, since raw data of the clients cannot be exchanged in FL. A widely adopted solution is the **global posterior decomposition**(Neiswanger et al., 2014; Al-Shedivat et al., 2020), which decomposes the global posterior into a product of client's local posteriors, i.e., \(p(w|S)_{i}p(w|S_{i}),\) where \(^{}p_{i}(w)}\) denotes the ratio of global prior to the product of client priors, which can be viewed as a constant based on prior assumptions, e.g., the Gaussian priors. See Appendix A.4.1 for the detailed derivation of this decomposition.

Based on the global posterior decomposition, the update process to optimize Eq. (3) can then be performed as follows: _i)_ each client initializes the model based on global posterior received from the server and independently learns a local posterior (e.g., by variational inference or Markov Chain Monte Carlo); _ii)_ the server collects the local posteriors from clients and multiplicatively aggregates them to obtain the global posterior, which is then sent back to the clients for the next round of update. This iterative process continues until the global posterior converges, as depicted in Eq. (4):

\[\ p(w^{*}|S)=_{i}p(w^{*}|S_{i}) ;\ \ \ @note{footnote}{Here, clients are not required to estimate an optimal local posterior before uploading. Similar to FedAvg (McMahan et al., 2017), the local posteriors are uploaded after a certain number of updates.}:p(w^{*}|S_{i})=)}{} _{p(w|S_{i})}L_{S_{i}}(w).\] (4)

This iterative update process is similar to FedAvg (McMahan et al., 2017), but has distinctive features: _i)_ each client estimates a distribution \(p(w|S_{i})\) instead of a single value of \(w\), and _ii)_ the global aggregation on the server is changed from weighted averaging to multiplication. FedPA (Al-Shedivat et al., 2020) has enabled this process and further reduced computation and communication costs through federated least squares.

Though this posterior inference helps alleviate overfitting in scenarios with scarce client data as compared to single point-estimates, the heterogeneity of the data remains an issue. The independently learned local posteriors are susceptible to shifts induced by data heterogeneity, hindering their ability to generalize to data from other clients. Subsequently, the aggregation of biased local posteriors may lead to a sub-optimal global posterior (Guo et al., 2023). This then raises a fundamental question: how can we achieve a globally well-generalized posterior in federated heterogeneous scenarios.

## 4 Proposed FedMDMI

To reduce the model's dependency on heterogeneous data and mitigate biased local posteriors incurred by such heterogeneity, we are motivated to introduce an additional regularization on the mutual information (MI) between the model and data (MD). In this section, we elaborate on our FedMDMI with an overview illustrated in Figure 1, and procedure summarized in Algorithm 1 in Appendix A.1.

### Compressing Information in Weights by Model-Data MI Constraint

The model-data mutual information is denoted as \(I(w;S)\), which quantifies relevance between the model \(w\) and input data \(S\), and also serves as a measure of complexity of the learned model for generalization analysis. By incorporating this information-theoretic constraint as regularization, the original optimization formulation in Eq. (3) is converted to:

\[&_{p(w| S)}[_{i}L_{S_{i}}(w)],\\ & I(w;S)<I_{c},\] (5)

where the introduced MI constraint compresses information stored in model weights, and \(I_{c}\) denotes the upper bound of the global MI. Namely, if less information is extracted by the model from the global heterogeneous dataset, it is less likely that overfitting occurs. Furthermore, this MI constraint is also helpful in mitigating the bias incurred by data heterogeneity. If we denote the bias factor as \(\) that affects the generation of local heterogeneous data (such as the difference

Figure 1: Overview of FedMDMI: under MI constraint, each client uploads the sample from the local posterior to server and subsequently downloads the aggregated global sample from the global posterior.

in clients' locations, preferences, or habits), we then have the Markov chain \( S w\), implying \(I(w;) I(w;S)\). As a consequence, we can diminish \(I(w;S)\) to constrain \(I(w;)\), thereby rendering the model \(w\) insensitive to the bias factor \(\) from the diverse clients.

In essence, this newly introduced model-data MI term \(I(w;S)\) constrains the complexity of model space for searching, and also encourages the model \(w\) to learn essential information from the global heterogeneous data \(S\). Note that various studies in FL have also attempted to induce the model to learn invariant information across clients through another crucial MI constraint, which is the MI between input data and output representation, commonly known as the information bottleneck (Shwartz-Ziv and Tishby, 2017) regularization. However, accessing this MI constraint usually requires sharing additional feature representations of the data across clients, which is infeasible in FL (Zhang et al., 2023). In contrast, our proposed model-data MI term not only requires no additional information to be shared with clients, but also provides client-level privacy protection as a byproduct, which will be discussed in detail in Section 5.3.

### Global Model-Data MI Decomposition

While our new formulation in Eq. (5) is conceptually promising, it is still infeasible to directly measure the global model-data MI term \(I(w;S)\) in FL, where we are constrained to only leverage the distributed data at individual clients. Alternatively, we decompose it into several local MI terms \(I(w;S_{i})\), which can be determined locally by these clients.

**Proposition 4.1**.: _(Global Model-Data MI Decomposition). Suppose that \(S=\{S_{1},,S_{m}\}\) consists of data from the \(m\) clients and \(S^{i-1}\{S_{1},,S_{i-1}\}\), then based on the chain rule of MI, we have:_

\[I(w;S)=_{i=1}^{m}[I(w;S_{i})-I(S_{i};S^{i-1}) ]_{i=1}^{m}I(w;S_{i}).\] (6)

Proof.: See Appendix A.4.3 for the detailed proof. 

Therefore, instead of \(I(w;S)\), we can constrain its upper bound \(_{i=1}^{m}I(w;S_{i})\) in Eq. (5). By further introducing a Lagrange multiplier \( 0\), Eq. (5) then re-formulates to:

\[_{p(w|S)}-1.422638pt_{p(w|S)}[( _{i}L_{S_{i}}(w)+ I(w;S_{i}))],\] (7)

where \(\) is also viewed to balance the fitting and generalization. Based on the global posterior decomposition, the iterative update process to optimize Eq. (7) becomes:

Server aggregation: \[p(w^{*}|S)=_{i}p(w^{*}|S_{i});\] (8) Client update: \[p(w^{*}|S_{i})=*{arg\,min}_{p(w|S_{i})}-1.422638pt _{p(w|S_{i})}-1.422638pt[L_{S_{i}}(w)+ I(w;S_{i}) ].\] (9)

At each round, client update needs not to fully infer optimal local posterior. Consistent with FedAvg, it only updates for a certain number of iterations before sending learned local posterior to server.

### Local Posterior Inference

For the client update in Eq. (9), the second term \(I(w;S_{i})\) can be expressed as:

\[I(w;S_{i})=_{p(S_{i})}[p(w|S_{i})||p_{ i}(w)],\] (10)

which denotes the expectation of Kullback-Leibler (KL) divergence between the posterior \(p(w|S_{i})\) and marginal distribution \(p_{i}(w)\)3 over the local data distribution \(p(S_{i})\). Notably, this KL divergence plays a key role in the well-known PAC (Probably Approximately Correct)-Bayes bound4. PAC-Bayes learning (Alquier, 2021) provides a tight generalization bound for learning algorithms, where the KL divergence between the posterior \(p(w|S_{i})\) and prior \(p_{i}(w)\) is a dominant term within this bound. For a fixed prior, pioneer works (Xu and Raginsky, 2017; Alquier et al., 2016) have found an optimal posterior to minimize this bound, which is often referred to as the Gibbs posterior. Namely, the optimal posterior follows a typical Gibbs distribution.

**Lemma 4.2**.: _[_14_]_ _The Gibbs posterior is the minimum of the objective for client update in Eq. (9):_

\[p(w|S_{i})=}[-L_{S_{i} }(w)- p_{i}(w)],\] (11)

_where \(B_{i}\) is a normalization factor._

Proof.: See Appendix A.4.4 for the detailed proof. 

One possible way to obtain this Gibbs posterior is to seek its variational approximation (VA) [Alquier et al., 2016], which generally relies on simplified posterior distributions. However, a primary drawback of VA is its tendency to yield biased posterior estimates for complex posterior distributions. What is worse, in FL the data heterogeneity across clients itself contributes already to biased local posteriors, and this bias may be exacerbated by VA. Moreover, this method also results in at least doubling the communication overhead due to transmission of both the mean and covariance matrices. In contrast, Markov chain Monte Carlo (MCMC) methods offer an alternative class of sampling-based posterior approximations that are unbiased [Vadera et al., 2020], albeit with a slower convergence. Thus, we adopt the stochastic gradient Langevin dynamics (SGLD) [Welling and Teh, 2011], an MCMC method that has been proven effective and scalable in large-scale posterior inference problem.

Specifically, SGLD draws samples from the Gibbs posterior, by using the stochastic gradient update:

\[w_{t,k}^{i}=w_{t,k-1}^{i}-_{L}^{t,k} U_{i}(w_{t,k-1}^{i}) +h_{t,k},\] (12)

where \(w_{t,k}^{i}\) represents client \(i\)'s model at round \(t\) and step \(k\), \(_{L}^{t,k}\) is the local step size, \(h_{t,k}\) is a noise variable sampled from \((,^{t,k}})\) with \(\) being the identity matrix, and

\[ U_{i}(w_{t,k-1}^{i})=(L_{S_{i}}(w_{t,k-1}^{i})-  p_{i}(w)|_{w=w_{t,k-1}^{i}})\] (13)

is an unbiased estimate of gradient. Note that \(U_{i}\) corresponds to the exponent in the Gibbs posterior of Eq. (11), and \(p_{i}(w)|_{w=w_{t,k-1}^{i}}\) represents the prior \(p_{i}(w)\)'s probability density value at \(w=w_{t,k-1}^{i}\).

### Global Posterior Aggregation and Prior Selection

In theory, if the step size is annealed as \(_{L}^{t,k} 0\), the client update sequence \(w_{t,k}^{i}\) converges to the local Gibbs posterior in Eq. (11) with sufficiently large \(k\) and \(t\). The question then becomes: how can we obtain samples from the global posterior (i.e. the product of local Gibbs posteriors) expressed as

\[p(w|S)=_{i}p(w|S_{i})=} [-_{i}L_{S_{i}}(w)- p _{i}(w)],\] (14)

based on the samples drawn from these local posteriors.

Recent studies [Gurbuzbalaban et al., 2021, Plassier et al., 2023] have shown that when clients utilize SGLD for posterior inference in distributed or federated settings, leveraging the mean of samples from local posteriors to approximate samples from the target global posterior \(p(w|S)\), there is a non-asymptotic convergence guarantee5. In other words, we can approximate samples from the global posterior by simply taking an average of the samples drawn from the local posteriors. Specifically, in the local posterior inference, SGLD introduces uncertainty into the predictive estimates by incorporating Gaussian noises, and samples the local model \(w_{t,k}^{i}\) from the local posterior \(p(w|S_{i})\) in Eq. (11) through a Markov chain with steps:

\[ w_{t,k}^{i}(-_{i} _{k=1}^{K}_{L}^{t,k} U_{i}(w_{t,k-1}^{i}), _{k=1}^{K}^{t,k}}).\] (15)We then discuss how the prior is chosen in Eq. (13). This oracle prior (i.e., \(p_{i}(w)_{p(S_{i})}[p(w|S_{i})]\)) renders the mutual information the tightest, which, however, is infeasible to obtain. In fact, we can use an arbitrary prior \(r(w)\) (e.g., \((,)\)) to approximate \(p_{i}(w)\), based on following upper bound:

\[I(w;S_{i})=_{p(S_{i})}p(w|S_{i})\|r( w)-p_{i}(w)\|r(w)_{p(S_{ i})}p(w|S_{i})\|r(w).\] (17)

For the arbitrary prior \(r(w)\) to achieve a smaller MI, it must essentially predict the posterior (Dziugaite et al., 2021). Thus, we consider using the information of global model \(w_{t}\) as the prior of clients for update of the next round. Based on Eq. (16) for updating \(w_{t}\), we then define \(p_{i}(w)(w|_{t-1},_{t-1})\), where

\[_{t-1}=w_{t-1}-_{i}_{k=1}^{K}_{L}^{t- 1,k} U_{i}(w_{t-1,k-1}^{i}),\;_{t-1}=_{ k=1}^{K}^{t-1,k}}.\] (18)

Here the variance captures the uncertainty introduced by all the clients at the previous round \(t-1\). Meanwhile, Zhang et al. (2022) also show that using the global model as a local prior can alleviate local overfitting. Additionally, \(w_{t}\) is only a sample drawn from the global posterior. To better estimate the mean of this Gaussian prior, we approximate it with a global moving average, which is also utilized to accelerate the convergence6, as shown in Line 16 of Algorithm 1 in Appendix A.1.

## 5 FedMDMI Analysis

### Generalization Analysis via Model-Data MI

We first provide an information-theoretic generalization bound in terms of the model-data MI for FL. In FL settings, it is crucial to consider both the gaps arising from the unseen client data (i.e., participating error), and the gaps stemming from the unseen client distributions (i.e., participation gap). Following the framework proposed by Yuan et al. (2021) and Hu et al. (2023), we re-define the more general population risk in FL as:

\[L_{}(w)=_{p(S_{i}) P}[_{z_{i} p(S_ {i})}[_{i}(w,z_{i})]],\] (19)

where we denote \(P\) as a meta-distribution on \(D\), and \(D\) is the set of all distributions \(p(S_{i})\). This formulation takes into account the participation gap, as compared to Eq. (1). By recalling the global empirical risk \(L_{}(w)\) in Eq. (3), we define the expected generalization error as \([L_{}(w)-L_{}(w)]\).

**Theorem 5.1**.: _(Generalization Bounds for FL). Suppose that \(_{i}(w,z_{i}^{j})\) for all \(i\) is bounded by \(C\) and independent, then the expected generalization error satisfies:_

\[[L_{}(w)-L_{}(w)]I(w;S)}{2mn}}+I(w;D)}{2m}},\] (20)

_where \(m\) is the number of clients, \(n\) is the number of samples on the client (assuming, without loss of generality, that the number of samples for all clients is equal), and \(D\) is the set of distributions \(p(S_{i})\)._

Proof.: See Appendix A.4.5 for the detailed proof. 

_Remark 5.2_.: On the RHS of Eq. (20), \(I(w;S)\) relates to participating generalization error and serves as the regularized mutual information term that can be estimated in our FedMDMI, while \(I(w;D)\) relates to the participation gap that cannot be estimated due to unavailability of the non-participating clients. Moreover, this generalization bound \((}+})\) matches with the current bound (Hu et al., 2023).

_Remark 5.3_.: Several prior works (Yagli et al., 2020; Barnes et al., 2022; Sefidgaran et al., 2022) have also established a generalization bound based on clients' local MI \(I(w;S_{i})\) in distributed (or federated) learning. Additionally, some studies (Chor et al., 2023; Sefidgaran et al., 2023) in FL have explored generalization upper bounds w.r.t. the local time-varying mutual information \(I(w_{t},S_{i}^{t})\). In contrast to them, our generalization bound is based on a participation gap framework, with the first term (global MI \(I(w;S)\)) exhibiting a tighter bound than the previous local MI \(_{i}I(w;S_{i})\). For more details, we provide more elaboration of this distinction in Appendix A.4.2.

### Fitting vs. Generalization with Data Heterogeneity

As demonstrated in Theorem 5.1, the MI \(I(w;S)\), acting as a measure of the effective complexity of a model, controls participating generalization capability. The hyperparameter \(\) is employed in Eq. (7) to regulate this MI, thereby balancing fitting and generalization of the learned model. Here, we empirically investigate this trade-off under two non-iid settings using the CIFAR-10 dataset. The experiments involve 100 clients with a \(10\%\) participation rate (refer to Section 6 for details). The train and test errors of the global model are plotted in Figure 2 under varying \(\).

It can be seen that with the increase of \(\), the train error increases slowly, while the test error decreases initially and then increases. This suggests that models with lower complexity (larger \(\)) tend to underfit, while those with higher complexity (smaller \(\)) tend to overfit. The MI \(I(w;S)\) allows us to recover a federated version of the bias-variance trade-off. Moreover, as \(\) increases, the gap between the test errors under different data heterogeneity decreases, indicating that the introduced \(I(w;S)\) can render \(w\) insensitive to data heterogeneity and alleviate the bias caused by such heterogeneity.

### Client-Level Privacy Protection

The proposed FedMDMI can also provide client-level privacy protection, according to the analysis on MI and posterior inference based on SGLD sampling. First, the proposed MI regularizer \(I(w;S)\) directly quantifies the extent to which the model memorizes data. Conversely, it reflects the degree of data information leakage. In the extreme case when \(I(w;S)=0\), \(w\) becomes entirely independent of \(S\) (e.g., akin to white noise) and leaks no information about the data. Thus, we restrict this MI to some extent for privacy protection. Second, SGLD in the local posterior inference has been widely demonstrated to provide strict differential privacy (Wang et al., 2015; Dziugaite and Roy, 2018). Following these works and assuming that \(_{i}(w,z_{i}^{j})\) is \(L\)-smooth, when \(k(^{2}}{(2/)})\), our FedMDMI also preserves a client-level \((,)\)-differential privacy. See Appendix A.4.6 for details.

### Limitation and Complexity Analysis

Though FedMDMI enjoys multi-fold benefits, including mitigating bias and overfitting on heterogeneous data to enhance generalization, and differential privacy as a byproduct, it may also have limitations. **First**, both the global posterior decomposition and global MI decomposition rely on the assumption that the global likelihood is conditionally independent given \(w\). While this assumption is commonly adopted in embarrassingly parallel (Neiswanger et al., 2014) and federated scenarios (Guo et al., 2023; Al-Shedivat et al., 2020), it may not be applicable in certain extreme FL scenarios. **Second**, we do not delve into the convergence rate of FedMDMI under non-convex settings. While numerous studies (Gurbuzbalaban et al., 2021; Plassier et al., 2023) have analyzed the convergence of SGLD for strongly convex objective in distributed and federated posterior inference, and empirically demonstrated its effectiveness for non-convex objective, the theoretical convergence of SGLD remains an open question when applied to the non-convex objectives in FL.

**Last**, regarding the complexity analysis, we begin by defining the dimensions of the neural network as \(d\). At each communication round, we adopt the SGLD to estimate the local posterior. Specifically, compared to the SGD employed in FedAvg and FedBE, our FedMDMI entails an additional step of generating the Gaussian noise with \(d\) dimensions, which is subsequently incorporated into each model update iteration. This results in an additional \((d)\) time and \((d)\) memory. In contrast, at each client, FedPA uses dynamic programming to approximate the inverse matrix \(d d\) of the neural network, introducing an additional \((l^{2}d)\) time and \((ld)\) memory, where \(l\) is the number of posterior samples. Similarly, FedEP(L) also requires approximating the covariance as the inverse Hessian, introducing an additional \((d^{3})\) time and \((d^{2})\) memory. For communication and aggregation at the server, our FedMDMI, along with FedAvg and FedPA, requires \((md)\) time and \((md)\) memory, where \(m\) denotes the number of clients. In contrast, FedEP requires \((md)\) time and \((md^{2})\) memory. Note

Figure 2: Train and test errors of the global model on CIFAR-10 dataset, where Dir (0.2) has a higher degree of data heterogeneity than Dir (0.7).

that FedBE not only requires \(((m+1+l)d)\) time and \(((m+1+l)d)\) memory, where \(l\) denotes the number of global model samples, but also performs the knowledge distillation at the server using unlabeled data, which is both memory- and time-intensive.

## 6 Experiments

**Datasets and Models.** We evaluate our FedMDMI on three benchmark datasets: CIFAR-10, CIFAR-100, and Shakespeare, with heterogeneous data splits. Specifically, for CIFAR-10 and CIFAR-100, each client has an uncertain number of classes through setting client sample labels according to the Dirichlet distribution. For example, with Dirichlet \((0.2)\) each client has \(80\%\) samples which belong to mostly three or four different classes, while with Dirichlet \((0.7)\) each client has \(80\%\) samples which belong to mostly five or six different classes. We use the CNN and RNN models similar to the prior works McMahan et al. (2017); Acar et al. (2021). Detailed experiment setup can be found in Appendix A.2.1.

**Comparison Methods.** Methods for comparison include the single point-estimate-based approaches: FedAvg McMahan et al. (2017), FedM FedAvg with momentum moving average Hsu et al. (2019), MimeLite Karimireddy et al. (2021), and SCAFFOLD Karimireddy et al. (2020), as well as the Bayesian inference-based approaches: FedBE Chen and Chao (2020), FedPA Al-Shedivat et al. (2020), FedEP (I) Guo et al. (2023), and FALD Plassier et al. (2023). Note that Guo et al. (2023) and Plassier et al. (2023) also propose various variants of their methods. In our evaluation, we opt for FedEP (I) and FALD, as they demonstrate superior overall performance. We present additional results of the other baseline (i.e., \(\)-PredBayes Hasan et al. (2024)) in Appendix A.3.5. In addition, for a fair comparison, we also incorporate the momentum moving average in the global model aggregation step of FedM, FedPA, FedEP, and FALD.

**Implementation.** We evaluate the performance of the global model after 4000 communication rounds for CIFAR-10 and CIFAR-100, and after 1000 rounds for Shakespeare, which is trained with 100 clients. We set the high (H) and low (L) client participation rates as \(10\%\) and \(5\%\), respectively. Clients are uniformly sampled at random without replacement at each round. The learning rate and hyperparameters for all approaches are individually tuned over a grid search. See Appendix A.2.3 for the additionally detailed settings of hyperparameters. Implementable code for evaluation of our FedMDMI is available at: https://github.com/haozzh/FedMDMI.

    &  \\   &  &  &  &  &  &  &  &  &  &  &  &  &  &  \\   & Dir (0.2)-L & 79.26\(\)0.07 & 82.12\(\)0.03 & 79.34\(\)1.02 & 82.11\(\)0.03 & 81.49\(\)0.07 & 82.29\(\)0.07 & 82.63\(\)0.04 & 82.26\(\)0.03 & **83.42\(\)**0.03 \\   & Dir (0.7)-L & 80.61\(\)1.29 & 82.46\(\)0.00 & 80.25\(\)0.00 & 82.25\(\)0.07 & 82.27\(\)0.05 & 82.60\(\)0.06 & 82.61\(\)0.06 & 83.18\(\)0.07 & 83.19\(\)0.01 \\   & Dir (0.7)-H & 80.61\(\)0.05 & 82.17\(\)0.00 & 79.80\(\)0.00 & 82.56\(\)0.00 & 82.56\(\)0.00 & 82.87\(\)0.00 & 83.80\(\)0.07 & 83.84\(\)0.07 & 88.40\(\)0.04 & **83.66\(\)**0.41 \\   & Dir (0.7)-H & 80.31\(\)0.00 & 82.69\(\)0.01 & 80.12\(\)0.03 & 83.04\(\)0.02 & 82.35\(\)0.03 & 82.93\(\)0.07 & **83.95\(\)**0.05 & 83.12\(\)**1.13 & 83.76\(\)**0.61 \\   & Dir (0.2)-L & 40.31\(\)0.01 & 47.71\(\)0.13 & 40.49\(\)0.03 & 47.76\(\)0.14 & 44.55\(\)0.03 & 48.59\(\)0.00 & 48.93\(\)0.00 & **49.46\(\)**0.05 \\   & Dir (0.7)-L & 40.21\(\)0.00 & 47.89\(\)0.008 & 41.09\(\)0.05 & 48.14\(\)0.01 & 45.50\(\)0.07 & 49.55\(\)0.07 & 49.55\(\)0.07 & 49.55\(\)0.07 & 49.86\(\)**0.05 \\   & Dir (0.7)-H & 40.32\(\)0.00 & 47.02\(\)0.00 & 40.82\(\)0.03 & 47.49\(\)0.01 & 44.82\(\)0.00 & 46.51\(\)0.07 & 49.05\(\)0.07 & 49.83\(\)0.07 & **49.76\(\)**0.01 \\   & Dir (0.7)-H & 40.21\(\)0.00 & 48.67\(\)0.02 & 42.39\(\)0.01 & 47.99\(\)0.04 & 46.29\(\

**Experiment Setting regarding Uncertainty Quantification for Image Tasks.** Uncertainty estimation is crucial for decision-making. Following Guo et al. (2017), Maddox et al. (2019), we utilize the expected calibration error (ECE) as a calibration metric of predictive uncertainty. To calculate ECE for a given model, we divide the test samples into \(20\) bins based on the model's confidence. Subsequently, we compute the absolute difference between the average confidence and accuracy within each bin and average these differences across all the bins. Additionally, reliability diagrams are plotted to illustrate the discrepancy between a method's confidence in its predictions and its actual accuracy. For a well-calibrated model, the discrepancy should be close to zero in each bin.

**Performance Evaluation.** The experimental results of all comparison methods under different non-iid settings are presented in Table 2 and Figures 3(c) and 3(d). In most cases, FedMDMI outperforms the other algorithms on the three datasets with varying heterogeneous data and client participation rates. This superior performance can be attributed to the proposed model-data MI regularization, which encourages the distributed clients to learn essential information and alleviates bias in the inferred local posteriors, thereby enhancing the generalization capability of the global model. It is worth noting that the convergence rate of the proposed FedMDMI may not be the fastest, especially when compared to the optimization-based method, SCAFFOLD. One potential explanation is because of our use of stochastic gradient Langevin dynamics (SGLD) to approximate the posterior, which often suffers from a slow convergence rate due to the variance introduced by the stochastic gradient (Wang et al., 2021a). However, compared to SCAFFOLD, our method not only achieves a superior generalization performance, but also offers an improved calibration of uncertainty. Due to space limit, we present some additional experimental results and additional discussion in Appendix A.3.

**Calibration and Uncertainty Estimation.** We evaluate the uncertainty estimates of all comparison methods, as shown in Table 3 and Figures 3(a) and 3(b). In most cases, our FedMDMI attains the lowest expected calibration error (ECE) and provides well-calibrated uncertainty estimates. Notably, the ECE of single point-estimation-based methods is consistently higher than that of posterior inference-based methods. While all these methods exhibit a tendency to be overconfident in their predictions, posterior inference demonstrates the potential to mitigate this overconfidence.

**Choice of appropriate \(\) and \(\).** We have analyzed the impact of \(\) that balances fitting and generalization in Section 5.2. We then analyze the hyperparameter \(\), which is used to estimate the mean of Gaussian prior and accelerate convergence. Due to space limit, we present these results in Appendix A.3.2, showing that even if \(=0\), FedMDMI still achieves higher accuracy than FedAvg.

## 7 Conclusion

We have proposed a federated posterior inference approach, which mitigated bias in the posterior estimates and improved generalization by introducing a global model-data MI regularization. To approximate this global MI based on distributed data over the clients, we decomposed it into local MI terms. We showed that the optimal posterior of the local objective with MI regularization was a Gibbs posterior, which could be efficiently sampled by SGLD. We further provided a generalization analysis based on this global MI, and analyzed its impact on fitting and generalization in FL, enabling to present a federated version of the bias-variance trade-off.

## 8 Acknowledgement

This work was supported in part by the National Natural Science Foundation of China under Grant 62125109, Grant T2122024, Grant 62320106003, Grant 62371288, Grant 62431017, Grant 62401357, Grant 62401366, Grant 61931023, Grant 61932022, Grant 62120106007, and in part by the Program of Shanghai Science and Technology Innovation Project under Grant 24BC3200800.

    &  &  \\   & Dr (0.2+) & Dr (0.7+) & Dr (0.2+) & Dr (0.7+) \\  FedAvg & 0.105 \(\) 0.0029 & 0.165 \(\) 0.0024 & 0.429 \(\) 0.0030 & 0.429 \(\) 0.0028 \\ FedM & 0.159 \(\) 0.0025 & 0.169 \(\) 0.0036 & 0.468 \(\) 0.0027 & 0.459 \(\) 0.0035 \\ Mindex & 0.125 \(\) 0.0041 & 0.178 \(\) 0.0044 & 0.460 \(\) 0.0022 & 0.470 \(\) 0.0022 \\ SCAFFOLD & 0.192 \(\) 0.0088 & 0.194 \(\) 0.0025 & 0.472 \(\) 0.0016 & 0.479 \(\) 0.0034 \\ FedM & 0.182 \(\) 0.0029 & 0.189 \(\) 0.0032 & 0.402 \(\) 0.0015 & 0.465 \(\) 0.0021 \\ FedM & 0.173 \(\) 0.0031 & 0.176 \(\) 0.0032 & 0.374 \(\) 0.0033 & 0.371 \(\) 0.0025 \\ FedM & 0.121 \(\) 0.0033 & **0.118**\(\) 0.0021 & 0.298 \(\) 0.0045 & 0.273 \(\) 0.0027 \\ FOLD & 0.135 \(\) 0.0028 & 0.127 \(\) 0.0030 & 0.267 \(\) 0.0018 & 0.290 \(\) 0.0023 \\ FedM & **0.115**\(\) 0.0019 & 0.129 \(\) 0.0031 & **0.261**\(\) 0.0023 & **0.263**\(\) 0.0029 \\   

Table 3: ECE (averaged over \(5\) random seeds).