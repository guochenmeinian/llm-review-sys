# Scalable Bayesian Optimization via Focalized Sparse Gaussian Processes

Yunyue Wei\({}^{1}\), Vincent Zhuang\({}^{2}\), Saraswati Soedarmadji\({}^{1}\), Yanan Sui\({}^{1}\)

\({}^{1}\) Tsinghua University

\({}^{2}\) Google DeepMind

weiyy20@mails.tsinghua.edu.cn

vincentzhuang@google.com

chenxuying24@mails.tsinghua.edu.cn

ysui@tsinghua.edu.cn

###### Abstract

Bayesian optimization is an effective technique for black-box optimization, but its applicability is typically limited to low-dimensional and small-budget problems due to the cubic complexity of computing the Gaussian process (GP) surrogate. While various approximate GP models have been employed to scale Bayesian optimization to larger sample sizes, most suffer from overly-smooth estimation and focus primarily on problems that allow for large online samples. In this work, we argue that Bayesian optimization algorithms with sparse GPs can more efficiently allocate their representational power to relevant regions of the search space. To achieve this, we propose focalized GP, which leverages a novel variational loss function to achieve stronger local prediction, as well as FoCALBO, which hierarchically optimizes the focalized GP acquisition function over progressively smaller search spaces. Experimental results demonstrate that FoCALBO can efficiently leverage large amounts of offline and online data to achieve state-of-the-art performance on robot morphology design and to control a 585-dimensional musculoskeletal system.

## 1 Introduction

Bayesian Optimization (BO) is a powerful approach for solving black-box optimization problems, demonstrating notable success in hyperparameter tuning, reinforcement learning, and scientific discovery. The efficacy of BO is attributed to its ability to model the unknown objective function using a surrogate model and to strategically select the next sample position by optimizing an acquisition function. Among the surrogate models, Gaussian Processes (GPs) are usually favored due to their flexibility and robust uncertainty quantification. However, the computation of the posterior GP covariance matrix scales as \((n^{3})\) with the number of data points \(n\), which can severely restrict the applicability of BO in handling large datasets. This poses a significant challenge for real-world applications with high-dimensional and heterogeneous function landscapes such as those in robot control, which often necessitate a substantial amount of data to adequately explore the vast search space. To extend the scope of BO to accommodate larger datasets (from long-horizon online trials and/or pre-collected offline datasets), it is imperative to employ surrogate models that offer enhanced computational efficiency.

Using sparse GP models is a popular method for reducing the computational cost of BO. Sparse GPs accomplish this by learning an approximation of the full GP, either by using asubset of data, ensemble of local models, or variational inference. However, classical sparse GP models are typically tailored for regression tasks, and therefore are designed to fit to the entire function landscape. Given limited representational resources, the resulting posterior is likely to be overly smooth, which may negatively impact the performance of BO. This issue is exacerbated in the high-dimensional setting, in which accurately fitting the entire domain is a far more challenging task. As such, several works have proposed strategies to improve BO performance with sparse GP models by focusing promising regions[10; 11] or advanced sparse GP models. However, most of their empirical evaluations are only conducted under large online sample setting in low-dimensional problems with fewer than 20 variables. It is unclear whether existing methods can be generalized to large offline data or high-dimensional setting.

In this work, we explore the application of sparse Gaussian processes for optimizing high-dimensional problems with large offline (and optionally large online) datasets. We argue that by iteratively identifying key sub-regions of the input space and focusing the modeling capacity on these areas, we can enhance the modeling fidelity of the sparse GP in regions that are most relevant, thereby improving the overall performance of the Bayesian optimization algorithm. To this end, we propose a novel loss function to train a variational sparse GP model (focalized GP) that emphasizes the fitting of local functional landscapes through weighting the training data. Along with focalized GP, we design a hierachical algorithm, FOCALBO, to propose sample points via acquisition function optimization across varying scales of the search space. Experimental results demonstrate that FOCALBO can improve upon commonly used acquisition functions in optimizing heterogeneous functions and can effectively utilize large offline datasets for efficient high-dimensional optimization. Furthermore, we showcase that FOCALBO can efficiently optimize a policy with 585 parameters to control a musculoskeletal system, leveraging both offline and online data. To the best of our knowledge, FOCALBO is the first sparse GP-based Bayesian optimization algorithm capable of efficiently optimizing high-dimensional problems under both large online sample and large offline data settings.

Our main contributions: 1) We design FOCALBO, which employs a hierarchical acquisition optimization strategy to achieve efficient optimization over high-dimensional problems with heterogeneous structure with limited representation capability. 2) Experimental results demonstrate the superior performance of FOCALBO in leveraging large offline datasets for online optimization, and its capability to optimize high-dimensional musculoskeletal system control problems involving over 500 variables.

## 2 Related Work

### Sparse Gaussian processes

Scaling Gaussian processes to large datasets is an important topic . It can be broadly divided into global approximation strategies and local approximation strategies.

Global sparse GPs perform distillation over the whole dataset to approximate the expensive full covariance matrix with a sparse representation. Several methods aim to choose a subset of representative training points from the whole dataset, and use the corresponding covariance matrix in place of the full covariance[14; 7; 15; 16]. Sparse kernels aim at removing uncorrelated entries in the full covariance to obtain a compact matrix[17; 18; 19; 20]. Sparse approximation methods use inducing variables to learn a low-rank representation of full covariance matrix[21; 22; 23; 24; 8; 9; 25; 26; 27]. Stochastic variational Gaussian process (SVGP) is a popular sparse GP method which employs variational inference to learn inducing variables and kernel hyperparameters jointly and enable training using stochastic gradient descent from mini-batch data. Recently, nearest neighbor information has also been used to further improve the scalability of sparse GP over massive amount of data[28; 29].

In contrast, local sparse GPs divide the entire dataset and employ local GPs trained from different data subsets to approximate the full GP. For a given test set, the prediction can be extracted from one of the local GPs[30; 31], mixture of GPs[32; 33] or product of GPs[34; 35].

### Scalable Bayesian optimization

Recent works have proposed modifications to sparse GPs for Bayesian optimization. Sparse GP has been used to determine the search region where local GPs are used to determine the next samples. Weighted-update online Gaussian processes (WOGP) was developed to select a subset of training points to approximate high performing regions of the input space. IMP-DPP is motivated by a similar observation and uses a weighted Determinantal Point Process to select training points as inducing variables for the SVGP. However, their proposed selection strategies require sequentially evaluating every training point, which can be computationally very expensive with large offline datasets. Combining SVGP with Thompson sampling has the same order of regret as standard Thompson sampling method. Online variational conditioning (OVC) was proposed to efficiently conditioning SVGPs in an online setting, enabling using look-ahead acquisition functions. Vecchia approximation of GP was also applied for Bayesian optimization, with improved performance compared to prior works. A concurrent work  aims at improving the acquisition optimization performance based on target-aware Bayesian inference .

Besides sparse GPs, Neural network[42; 43] and random forest can also be used as BO surrogate model to circumvent the cubic complexity of GP. Ensemble Bayesian optimization utilizes the addictive function structure and uses ensembles of addictive GPs in parallel to achieve scalability. Trust Region Bayesian optimization (TuRBO) and its variants uses exact GP to optimize over local regions, and employs a restart mechanism to achieve large number of evaluation, which is a representative line of works in high-dimensional Bayesian optimization[46; 47; 48]. TuRBO can also be combined with sparse GP models to further enhance the scalability[49; 50].

## 3 Background

### Bayesian optimization

For an unknown objective function \(f\), Bayesian optimization aims to solve \(_{}f()\) over input space \(^{d}\). BO mainly consists of two components: a surrogate model to approximate the objective function, and an acquisition function \(a\) to decide the next sample position based on surrogate model.

Gaussian process is a commonly used surrogate model. Consider a given dataset \(D=(,)\) where \(=(_{1},...,_{t})\) are input locations and \(=(y_{1},...,y_{t})\) are associated noisy observations of \(f()\). We assume the observation noise to be independent Gaussian, i.e. \(y_{i}=f(_{i})+,(0,^{2})\). Using GP with kernel function \(K\), the function distribution \(_{*}\) at test positions \(_{*}=(_{*,1},,_{*,t_{*}})^{T}\) is a multivariate Gaussian:

\[ p(_{*},)=(_ {*}& K_{_{*}}[K_{}+ I]^{-1},\\ & K_{_{*}_{*}}-K_{_{*}}[K_{}+  I]^{-1}K_{_{*}}),\] (1)

where \(K\) is the covariance matrix between subscript inputs. With the posterior distribution given \(D\), the next sample point is the maximum position of the acquisition function: \(_{t+1}=_{}a(|_{t})\), where \(_{t}\) is the GP model fitted on dataset collected at time step \(t\). Common-used choice of \(a\) includes upper confidence bound(UCB, ), expected improvement (EI, ) and Thompson sampling (TS, ). The inner optimization problem is usually solved by grid search, evolutionary algorithms, or gradient-based methods. When the online sample budget is large, batch optimization is commonly used to evaluate multiple inputs in parallel.

### Variational Gaussian process

For predictive distribution conditioned on given dataset of size \(t\), the computational complexity of exact Gaussian process is \((t^{3})\) for each test position due to the inverse of the covariance matrix \(K_{}\), which is expensive for large scale datasets with more than a few thousand points. A common used strategy is to approximate full GP regression using sparse GPs. In sparse GP, \(m t\) inducing variables \(=(u_{1},,u_{m})^{T}\) characterized by inducing inputs\(=(_{1},,_{m})\) are introduced to approximate the covariance matrix of the full GP. In this section, we focus on sparse GP derived from variational inference.

Variational GP  considers the joint latent prior

\[p(,)=(\\  0,K_{}&K_{}\\ K_{}&K_{}),\] (2)

where \(=(f(_{1}),,f(_{t}))^{T}\). A variational distribution \(q()=(,)\) is used to approximate the posterior over inducing variables using the exact conditional distribution of \(\) given \(\), that is, \(q(,)=p()q()\). The posterior of \(\) can be computed by marginalizing \(\) with analytic form:

\[q()= p()q()d=( {Am},K_{}-^{T}(K_{}-)),\] (3)

where \(=K_{}^{-1}K_{}\). The variational parameters \(,,\) are optimized by maximizing the Evidence Lower Bound (ELBO) which can be written in the following formulation:

\[_{1}=_{i=1}^{t}_{q(f(_{i}))}[ p(y_{i} f (_{i}))]-[q() p()]=_{ }+_{}\] (4)

where \([]\) is the KL divergence between two distributions. The ELBO breaks into a data likelihood term which factorized over training data, and a KL divergence term which can be computed in closed form. The factorization over data allows optimization via stochastic gradient descent (SGD), reducing the computational complexity to \((m^{3})\).

## 4 Focalized Gaussian Process for Bayesian Optimization

Prior studies about variational sparse GPs are mainly designed for regression tasks, where the goal is to fit global training data distribution. In Bayesian optimization, the next sample is determined by the predictive function distribution over test positions. Gradient-based and evolutionary-based acquisition function optimization methods employ local search from random starting points to find a local optimal of the acquisition function. Recent works also scale grid search-based optimization to high dimensional space by restricting the search space within local sub-regions. All the above procedure would benefit from an accurate estimation over sub-region of the input space. Therefore, a sensible way to improve BO performance is to allocate limited computational resources to obtain better prediction over specific search regions instead of the entire input domain.

We define the search region as the region where the acquisition function is optimized on, which is an axis-aligned hypercube with length \(=(l_{1},,l_{d})^{T}\) centered at \(\):

\[_{,}=\{- +\}.\] (5)

When \(=(1,,1)^{T}\) and \(=(0.5,,0.5)^{T}\), the acquisition optimization is performed over the entire input space \(\), as commonly-used in vanilla BO algorithms. In the rest of this section, we first present the derivation of focalized loss function to improve GP prediction over the search region. Then we demonstrate how to incorporate our proposed GP model into Bayesian optimization.

Figure 1: Performance comparison of focalized GP and SVGP over 1d GP functions. Posteriors are shown as mean \(\) 1 standard deviation.

### Focalized evidence lower bound

We recall eq.1 and rewrite the mean estimation \(_{t}(_{*})\) and variance estimation \(_{t}(_{*})\) for each test position \(_{*}\):

\[_{t}(_{*})&=_{i=1}^{t}k( _{*},_{i})[K_{}+ I]^{-1}y_{i},\\ _{t}(_{*})&=k(_{*},_{*})- _{i=1}^{t}_{j=1}^{t}k(_{*},_{i})_{ij}k(_{*}, _{j}),\] (6)

where \(_{ij}\) is the \((i,j)\)-th entry of \([K_{}+ I]^{-1}\). From eq. 6 we can observe that the mean estimation at \(_{*}\) is a linear combination of observation \(\) multiplied by \(k(_{*},)\), and the reduction of variance is a quadratic form of the covariance between \(_{*}\) and training points. Both estimation can be written as linear summations of constant values with kernel function as weight. As mentioned in prior works, data points far from the test positions have a vanishingly small influence on the predictive distribution with commonly used kernel functions. Utilizing this observation, we propose to weight the data likelihood term using the kernel function to focus training over points that contribute to the prediction of the search region:

\[_{}=_{i=1}^{t}w_{i}_{q(f(_{i}))}[  p(y_{i} f(_{i}))], w_{i}=_{_{*}_{ e,t}}k(_{i},_{*}).\] (7)

We use the maximum covariance of \(_{i}\) to positions in the search region as the corresponding weight to filter out points that have marginally influence to the search region during GP training. In this way, the model can selectively utilize the training data to achieve good local prediction. When using a popular kernel functions such as RBF or Matern kernel, the maximum kernel value is equivalent to finding the nearest point in the search region, which can be easily calculated when the region boundary is axis-aligned as defined in eq. 5.

We additionally regularize the sum of weights to make the model focus on improving prediction over search region:

\[_{}=_{,}|}{| _{,}|}=(^{t}w_{i}}{| _{,}|}-1),\] (8)

where \(|_{,}|=_{i=1}^{t}_{_{i} _{,}}\) is the number of training points in the search region. The proposed regularization term \(_{}\) encourages accurate local prediction instead of blurred global estimation, avoiding getting stuck on suboptimal of large kernel lengthscale. Combined with KL loss, our finalized new ELBO is as follows:

\[_{2}=_{}+_{}-_ {}.\] (9)

Compared to the original ELBO loss in SVGP, our proposed function maintains the same computational complexity and does not introduce additional hyperparameters. Our ELBO also reproduces eq. 4 when considering to predict the entire input space \(\). During the model training, both GP hyperparameters and variational parameters are jointly optimized to obtain focalized GP for Bayesian optimization. Figure 1 shows a comparison of focalized GP and SVGP over 1d functions sampled from GP. While SVGP can only able to vaguely predict the function, focalized GP accurately delineate the function landscape within search region by training with the focalized loss. Our proposed GP model is sensitive to high-performing positions within the search space which contribute to better acquisition optimization. We also systematically compare the GP prediction performance in Appendix B.3, where our GP model trained from focalized ELBO consistently achieves good prediction on small size of search space.

Theoretical implications of focalized ELBO.Our focalized ELBO can be interpreted as a soft variant of training a local approximation over datapoints that lie within the search region. Here, we illustrate how local approximations can substantially reduce the KL divergence of the approximate posterior over the search region, and discuss the effects of tighterapproximations on BO regret bounds. We focus on providing general theoretical intuition rather than deriving precise bounds due to the lack of existing convergence guarantees for ELBO maximization in the general setting.

Suppose that we know the optimal point lies in some small sub-region of \(\) that contains \(N^{}<<N\) training points. Corollary 19 in  shows that given a squared exponential kernel and some assumptions on the inducing point selection, for a fixed number of inducing points the KL-divergence upper bound scales super-quadratically in the number of training points. Hence, fitting locally can yield much tighter approximations than fitting globally (e.g. SVGP).

Next, we consider the impact of the KL approximation error on the optimization regret. Proposition 1 in  states that the gap between the means of the approximate and exact posteriors is upper bounded by \(()\), where \(\) is an upper-bound on the approximation KL-divergence. This has an immediate impact on the regret - for example, when GP-UCB  is combined with sparse GPs, the confidence bounds must be enlargement by an additive \(\) factor to account for the approximation error. Because the regret bound scales with \(}\) where \(_{T}\) is the maximum confidence interval coefficient, having a large approximation error can arbitrarily scale the regret incurred by the algorithm. In order to achieve no additional regret order, the additional approximation error noise must be uniformly bounded (Assumption 4 in ). Although focalized GP cannot guarantee a constant bound, it still directly reduces the regret of the algorithm, where we empirically investigate in Appendix B.1.

### Bayesian optimization with focalized GP

One advantage of focalized GP is that it can be easily integrated into existing BO algorithms. To further leverage the strong local modeling properties of focalized GP, we design FocalBO, a hierachical acquisition optimization framework described in Algorithm 1.

```
0: Initial Dataset \(_{0}\), Inducing Variable Size \(m\), Batch Size \(B\)
1:\(H 1\)
2:for\(t=1,2,\)do
3:\(\{_{t,i}\}_{i=1}^{B},\{h_{t,i}\}_{i=1}^{B}( _{t-1},H,m,B)\)
4: Observe \(\{y_{t,i}\}_{i=1}^{B}=\{f(_{t,i})+\}_{i=1}^{B}\)
5:\(_{t+1}_{t}\{(_{t,i},y_{t,i})\}_{i=1} ^{B}\)
6:\(i_{}*{argmax}_{i 1,,B}y_{i}\)
7:if\(h_{i_{}}<H\)then
8:\(H H-1\)
9:else
10:\(H H+1\)
11:endif
12:endfor ```

**Algorithm 1**FocalBO

At each BO iteration, FocalBO iteratively optimizes the acquisition function over a progressively smaller search region via focalized acquisition function (FocalAcq) as shown in Algorithm 2. The first depth of acquisition optimization starts with the entire input space \(\) with \(=(1,,1)^{T}\) and \(=(0.5,,0.5)^{T}\) (line 1). We train specific focalized GP base on the search region at each round of acquisition optimization (line 4-5). Our framework is compatible with any acquisition function that extracts instant posterior information from the GP and is optimized within pre-defined search region. After one round of acquisition function optimization, the search space length \(\) is halved to focus on a smaller search region centered at current best position \(_{}\)(line 6-7). In this way we can obtain a more accurate model for decision making, and also relieve the over-exploration problem when the problem dimension is high. One batch of inputs is proposed at each round of optimization, and the final decision is sampled from all proposed inputs via Softmax distribution over their corresponding acquisition function values (line 9). Our hierarchical optimization strategy enables collecting candidates from both global sparse estimation and local localized prediction, achieving balance between exploration and exploitation with constrained computation power.

The optimization depth \(H\) in FocalAcq controls the degree of utilizing local information from current best position, where the GP estimate variance decreases with the shrinkage of search space. The best-performing optimization depth is likely problem-dependent (e.g. high-dimensional functions may require higher optimization depths). Therefore in FocalBO, we propose to automatically adjust the optimization depth according to the instant optimization performance. At the beginning of the optimization, we initialize the optimization depth as 1, indicating global search of the input space (Algorithm 1, line 1). Then we keep track of the depth where the proposed positions are sampled from. If the depth of the best point in this round is less than the current optimization depth \(H\), we reduce \(H\) to encourage exploration of the input space, otherwise we increase \(H\) for better exploitation of \(_{}\) (line 6-10).

Our proposed framework is orthogonal to TuRBO-M , but bears some similarities in searching over multiple sub-regions and adaptively adjusting the search region. Our algorithm differs in that TuRBO-M constructs equal-sized trust regions and fits independent Exact GP using separated dataset, aiming at searching for different local optima in the search space. By contrast, the search region in FocalBO is constructed with different sizes to make decision based on both global and local information. Our framework allows data sharing across search regions, and the use of focalized GP helps to accurately estimate local region with limited representation. Additionally, FocalBO does not introduce extra hyperparameters. Finally, we demonstrate in Section 5 that TuRBO is complementary to FocalBO in optimizing high-dimensional problems.

## 5 Experiments

In this section, we extensively evaluate FocalBO over a variety of tasks. We first use synthetic functions to showcase the compatibility of FocalBO in improving commonly-used acquisition functions. Next, we consider the online optimization of robot morphology design that is additionally given a large offline dataset. We also show that FocalBO is able to optimize very high-dimensional musculoskeletal system control with both a large offline dataset and a large number of online budget. Finally we dig deeper into FocalBO to analyze how each of its components contributes to superior optimization performance.

We compare FocalBO with representative sparse GP models used for Bayesian optimization, including SVGP, WOGP, and Vecchia GP. We only run WOGP on synthetic functions due to its extremely low speed in dealing with the datasets in the remaining tasks. The number of inducing variables in sparse GP models is set as 50 for synthetic functions and as 200 for other tasks. The optimization performances are shown as mean \(\) 1 standard error for all considered problems over 10 independent trials.

### Synthetic functions

We select Shekel and Michalewicz as the test functions, which are heterogeneous with both smooth and rigid regions. We also sample functions directly from Gaussian processes to evaluate algorithm performance under full BO assumption. For each function, we choose to use different acquisition functions to optimize: TS optimized by grid search, EI optimized by analytic gradient, and probability of improvement (PI) optimized by Monte Carlo gradient. Optimization performances are shown in Figure 2. We observe that FocalBO significantly improves the performance of all acquisition functions compared to SVGP, and is able to consistently achieve top-tier performance over all problems. In Michalewicz function where a large fraction of the input space is flat, all baselines tend to increase the noise estimation to maintain a stationary prediction, while focalized GP is able to focus on the local search region and successfully optimize the function. Additional experiment with online samples as major data source is shown in Appendix B.2, where FocalBO still maintains comparable or better performance against baselines.

### Robot morphology design

We compare FocalBo to several baselines over robot morphology design task from Design-Bench, which provides large offline dataset with an exact function oracle. The goal of the task is to optimize the morphological structure of D'Kitty robot to improve the simulation performance under RL controller. While the benchmark is initially designed for offline model-based optimization (MBO), it can also be used as an offline-to-online BO benchmark. In this task, we use the training dataset with 10,000 points and additionally evaluate 128 points on-the-fly with batch size of 4. EI is used as the base acquisition function for better optimizing with small batch size. We also try to combine FocalBo with TuRBO to optimize over the high-dimensional space, with the results shown in Figure 3. We observe that FocalBo achieves significant improvement from the initial data while other baselines struggle to obtain performance gain, even combined with TuRBO. FocalBo with TuRBO effectively extracts information from large offline dataset and is the first GP-based method to achieve top-tier performance reported by prior MBO works.

### Human musculoskeletal system control

We further apply FocalBo to control a human arm musculoskeletal system for the task of pouring liquid into a cup, as shown in Figure 4(a). To control the musculoskeletal system, we optimize a linear policy \(|A||O|\), where \(|A|=5\) and \(|O|=117\) are the corresponding action and observation dimensions. The action dimension has been reduced from individual muscles to synergetic groups of muscles by applying principled component analysis to sampled action data from an RL agent (Appendix A.6). Although the original control dimension is reduced, the remaining 585-dimensional input space is still very high for existing high-dimensional BO algorithms. Therefore we consider a large offline-online setting, where we randomly sample 2000 points from the input space to serve as the offline dataset, and set the online budget as 3000 with batch size of 100. We use Thompson sampling as the base acquisition function. Figure 4(b) demonstrates that FocalBo outperforms other baselines, achieving higher maximum reward and faster convergence speed. Our supplementary video shows that the optimized policy is able to perform well on the task, demonstrating the successful application of FocalBo to high-dimensional control problems.

Figure 3: Optimization on robot morphology design. Function values are normalized by best and worst values in the unseen full dataset.

Figure 2: Optimization performance under different synthetic function and acquisition function. Sparse GP models are trained with 50 inducing variables. The offline dataset contains 2000 random data points and the online budget is 500 with batch size of 10.

### Algorithm analysis

To understand the reasons behind FoCALBO's superior optimization performance, we investigate the optimization depth in FoCALBO, which is the central component of the method. Figure 5(a) shows the evolution of optimization depth over different problems, where FoCALBO is able to adapt the optimization depth according to different function structure. For Shekel and musculoskeletal model control where the promising regions are distinct, the optimization exhibits an increasing trend to exploit current best points, while for other problems the depth tends to converge at a fixed level. Figure 5(b) shows the sources of proposed batches during the optimization of musculoskeletal system control. Overall the samples exhibits clear trend from exploration to exploitation over high-dimensional input space. Our hierarchical optimization strategy enables flexibility between exploration and exploitation.

## 6 Conclusion

In this paper, we propose FoCALBO, which uses a hierarchical acquisition optimization strategy equipped with focalized GP model to scale Bayesian optimization to problems with large offline datasets and/or a large number of online samples. Despite limited representation capability, FoCALBO consistently improves various acquisition functions in optimizing heterogeneous functions, and adeptly leverages large offline dataset for efficient optimization over robot morphology. Under the large offline-to-online optimization setting, FoCALBO achieves stable high-dimensional control of human musculoskeletal model with over 500 parameters. Ablation studies over the algorithm components further verify the principled design of FoCALBO. Future work may include theoretically analyzing FoCALBO, and applying the method to more complex problems, such as large-scale parameter tuning and whole-body human musculoskeletal system control.

Figure 4: Optimization of musculoskeletal system control. (a) Task illustration of initial and target state. Full video in supplementary. (b) Optimization performance of algorithms.

Figure 5: Algorithm analysis over optimization depth. (a) Depth evolution during optimization. (b) Samples source of each BO iteration during one trial of musculoskeletal system control optimization. Color bar indicates the number of samples proposed by corresponding optimization depth.