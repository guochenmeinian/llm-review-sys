# Target-Guided Adversarial Point Cloud Transformer Towards Recognition Against Real-world Corruptions

Target-Guided Adversarial Point Cloud Transformer Towards Recognition Against Real-world Corruptions

Jie Wang\({}^{1}\), Tingfa Xu\({}^{1,}\), Lihe Ding\({}^{2}\), Jianan Li\({}^{1,}\)

\({}^{1}\)Beijing Institute of Technology \({}^{2}\)The Chinese University of Hong Kong

https://github.com/Roywangj/APCT

Correspondence to: Jianan Li and Tingfa Xu.

###### Abstract

Achieving robust 3D perception in the face of corrupted data presents an challenging hurdle within 3D vision research. Contemporary transformer-based point cloud recognition models, albeit advanced, tend to overfit to specific patterns, consequently undermining their robustness against corruption. In this work, we introduce the Target-Guided Adversarial **P**oint Cloud **T**ransformer, termed **APCT**, a novel architecture designed to augment global structure capture through an adversarial feature erasing mechanism predicated on patterns discerned at each step during training. Specifically, APCT integrates an Adversarial Significance Identifier and a Target-guided Promptor. The Adversarial Significance Identifier, is tasked with discerning token significance by integrating global contextual analysis, utilizing a structural salience index algorithm alongside an auxiliary supervisory mechanism. The Target-guided Promptor, is responsible for accentuating the propensity for token discard within the self-attention mechanism, utilizing the value derived above, consequently directing the model attention towards alternative segments in subsequent stages. By iteratively applying this strategy in multiple steps during training, the network progressively identifies and integrates an expanded array of object-associated patterns. Extensive experiments demonstrate that our method achieves state-of-the-art results on multiple corruption benchmarks.

## 1 Introduction

3D point cloud recognition has garnered significant interest owing to its promising implications for robotics and autonomous driving. Prevailing techniques  have been predominantly designed and evaluated on clean data , overlooking the extensive corruptions present in real-world scenarios arising from sensor inaccuracies and physical constraints and leading to suboptimal performance when models are exposed to such conditions. Therefore, enhancing the resilience of point cloud models against real-world corruption emerges as a paramount yet daunting task.

Due to their elevated performance, existing transformer-based models  have emerged as the mainstream choice. Despite their effectiveness on clean datasets, these methods generally falter when faced with corrupted data. Upon closer examination, we discerned that prevailing models have a propensity to overfit to specific patterns (Fig. 0(a)). Such patterns can degrade in the presence of real-world corruptions, undermining the model reliability. Relying solely on these localized patterns for predictions can be fragile, especially with corrupted data. Thus, we theorize that if the model is encouraged to extract features from a broader region of the object during training, gathering more diverse perception cues, it would be more resilient, as proved in Fig. 0(b). This is because, even if some local patterns are compromised in corrupted data, the model could still source information from other intact areas to make accurate predictions.

To address the aforementioned limitation, we present a novel adversarial representation learning method, named Target-Guided Adversarial Point Cloud Transformer(APCT), for robust 3D perception.

Specifically, we first partition and extract local geometries from the point cloud by a mini-PointNet , resulting in a subset of tokens that encode these features. The tokens are then fed into stacked transformer blocks with two core modules, namely the Adversarial Significance Identifier and the Target-guided Promptor. The former module utilizes a dominant feature index mechanism along with an auxiliary supervision, to discern significance of all tokens, thus integrating global contextual analysis. Simultaneously, it signs a proportion of dominant tokens that are significant for perception in the current phase. Subsequently, the Target-guided Promptor, increases the dropping likelihood of token signed above during the self-attention process, thereby compelling the network to focus on less dominant tokens and to extract perceptive clues from alternative patterns. By iteratively engaging in such an adversarial process, the network gradually excavates and assimilates an extended array of patterns from objects (in Fig. 1(a)), thus making precise predictions against corruption.

We have extensively validated the effectiveness of our proposed method on multiple benchmarks, including ModelNet-C  and the more challenging ScanObjectNN-C . The results significantly underscore improvements in robustness and establish state-of-the-art performance on these datasets. In addition, our algorithm demonstrates pronounced generalization capabilities in downstream tasks, as evidenced by its adeptness in shape segmentation under corruptions in ShapeNet-C . These findings collectively underscore the method's generality and effectiveness in enhancing the robustness of point cloud perception models. Our contributions can be summarized as follows:

* We present a new framework, APCT, which effectively improves the resilience of point cloud model against various types of corruptions by leveraging adversarial mining strategy.
* We propose a novel adversarial dropout method that can stimulate the model to embrace broader valuable patterns by adversarially lifting dropout probability of specific patterns.
* We demonstrate the effectiveness of APCT through extensive experiments on multiple point cloud benchmarks under diverse corruption scenarios.

## 2 Related Work

### Transformer for Point Cloud Recognition

Amidst the burgeoning epoch of vision transformers, seminal works such as Point Transformer  and Point Cloud Transformer  ventured into the realm of leveraging attention mechanisms tailored

Figure 1: **Overall motivation**. We advocate for the model to broaden its attention to diverse patterns, mitigating the tendency to overfit to localized patterns. The left segment of the figure contrasts the confusion matrices of the standard transformer with our approach. The right portion showcases the performances of both the standard transformer and our methodology when confronted with objects exhibiting similar local patterns. Tokens with high / low contributions to classification are in red / blue, respectively. Standard transformer tends to overfit to localized patterns. While our method, by modulating tokens with significant contributions, enables the model to garner features from a varied spectrum of target segments, thereby ensuring greater robustness.

for point cloud semantics, thus pioneering this trajectory. The Point Cloud Transformer intrinsically integrates global attention across the entirety of the point cloud, mirroring certain challenges inherent to the Vision Transformer (ViT), notably the constraints of memory bandwidth and computational overhead. Contrarily, the Point Transformer accentuates local attention, distinctly focusing on each point and its proximate neighbors, effectively mitigating the aforementioned memory impediments. Subsequent to these, the Robust Point Cloud Classifier (RPC)  emerged, proffering a robust framework for point cloud classification. Infusing 3D representation, k-NN, frequency grouping, and self-attention, it posits itself as a formidable baseline in the annals of point cloud robustness inquiries. While these methods demonstrate remarkable accuracy, their performance tends to deteriorate in face of real-world corruptions. In this manuscript, we introduce a novel transformer-based model specifically architected to robustly handle real-world corruptions.

### Robust Learning Against Corruptions

In the realm of point cloud perception, deep learning has made significant strides [11; 12; 9; 13]. However, ensuring model robustness in the presence of corruptions remains a pivotal concern. Contemporary literature underscores the imperative of addressing point cloud corruptions [15; 14; 5; 7]. Some methodologies have hinged on preprocessing, incorporating denoising or completion strategies , to bolster a model's resilience against adversarial perturbations. Others have pursued augmentation pathways, spanning mix-based  and deformation-centric [5; 15] techniques. The advent of advanced auto-augmentations  has ushered in sample-adaptive data augmentations, targeting enhanced model robustness. Notwithstanding their merits, such interventions often mandate augmented computational overhead and may falter in scenarios of pronounced corruption. Another line of research aims to improve the robustness of deep learning architectures themselves. PointASNL  integrates adaptive sampling coupled with local-nonlocal modules, striving for heightened robustness. Concurrently, Ren _et al._ unveiled an attention-based backbone, RPC, tailored to withstand corruption. Nevertheless, these methods only make improvements to the feature extractor, without concerning the nature of the corruption problem. This manuscript introduces to leverage an adversarial dropping strategy to discern pertinent features from corrupted samples.

## 3 Methodology

We instead devise an adversarial analysis based framework (Fig. 2), which not only learns point recognition with current vital patterns, but more essentially, it automatically discovers and emphasizes the sub-important patterns, with the auxiliary supervised pattern miner. Patterns learned in such strategy are expected to be more discriminative and robust, hence facilitating final recognition of point clouds under corruptions. At each training iteration, our algorithm comprises of two phases. In **phase 1**, we perform adversarial mining over across all patterns, based on the token significance identification process. The propose is to search for the sub-optimal patterns that contribute less to the final recognition. In **phase 2**, we leverage deterministic dropping assignments and attribute elevated dropping rates to tokens pivotal for the final perception, as an constraint to enable these sub-optimal tokens to play a increasing significant role in perceptual. Engaging in this iterative adversarial procedure allows the network to progressively unearth and assimilate a comprehensive set of object patterns, as seen in Fig. 1(b), culminating in refined predictions in the face of corruption.

Figure 2: (a) Process of progressive adversarial dropping. The first line means token learned in each stage. (b) Visualization of token weights learned by the classifier. Compared with standard transformer, ours has an advantage in mining sample patterns.

### Overview Implementations

The overall implementations of Adversarial Point Cloud Transformer is shown in Fig. 3. Given an input set of point cloud \(^{N 3}\), we first partition the input point cloud into an assembly of \(n\) discrete patches, and subsequently, generating pertinent tokens with \(C\)-dimensional features, \(T=\{t_{j}|j=1,...,n\}^{n C}\). Taking these tokens as input for the following stages, the network initially employs the Adversarial Significance Identifier module to formulate a per-token dropping rate, assigning higher rates to tokens that are critical for classification. Subsequently, the Target-guided Promptor selectively eliminates key vectors based on the established rates. Through introducing such an adversarial progressive dropping scheme, the network gathers a diverse set of perception cues and assimilates various patterns from an expansive region of the underlying object structure, thus enhancing classifier resilience against potential corruptions.

The proposed architecture is segmented into three distinct stages, each consisting of multiple blocks. Within stages, the depth of self-attention blocks is conventionally configured to . Each stage is further equipped with a uniformly applied Adversarial Significance Identifier and an associated complementary supervision head. The default adversarial dropping ratio, is uniformly set to [0.2, 0.2, 0.2] across all stages. Each block within stages independently incorporates a Target-guided Promptor.

### Adversarial Significance Identifier

This module operates by meticulously processing the input tokens extracted from point clouds. It evaluates and distinguish the relative significance of each token and applies constraints particularly to those tokens identified as most crucial in the context of point representation learning, thereby efficiently unveiling underlying data structures through progressively mining patterns that sub-significant yet representative and insightful. Utilizing an auxiliary supervisory process, it integrates global contextual analysis and discerns significance of all input tokens \(T\); thus identifying the focal tokens, finally generating per-token dropout rate. To this end, it sorts tokens based on the feature channel responses via index number in auxiliary supervision process, then it establishes the mapping between tokens and the dropout rate, finally predict per-token dropout rate \(M=\{m_{j}|j=1,...,n\}^{n}\). The overall workflow is shown in Fig. 4.

**Focal tokens identification.** In the context of point cloud analysis, let \(T=\{t_{j}|j=1,...,n\}^{n C}\) represent a set comprising point cloud tokens. Initially, an essential step entails the organization of token contributions to final perception based on their associated feature channel responses, through the auxiliary supervisory process. Subsequent to this arrangement, we proceed with the identification of the most prominent tokens pertaining to each feature channel, resulting in the derivation of their respective index bank denoted as \(F_{}=\{f^{m}_{}|m=1,...,D\}^{k  C}\), where \(k\) signifies the number of tokens retained per channel feature. This process can be succinctly expressed as:

\[F_{topk}=TopK(T),\] (1)

where \(f^{m}_{}^{k}\) enumerates values within the range \((1,N)\), indicating the token associated with the feature response under consideration. Upon the construction of the index repository \(F_{topk}\), we perform a comprehensive aggregation of the elements within it. This process is pivotal for quantifying the occurrence frequency of each token in the ultimate perception of the model. This assists in delineating the tokens of substantial relevance. The mathematical representation is as follows:

\[M=(F_{topk}),\] (2)

where \(\) symbolizes the function employed to compute the token significance from \(F_{topk}\) in accordance with predefined indices. Consequently, the matrix \(M=\{m_{j}|j=1,...,n\}^{n}\) emerges as the importance matrix for tokens. Each element within this matrix, denoted by \(M_{j}^{1}\), serves to quantify the representation significance of the \(j-th\) token within the overall perception framework.

**Supervisory token identification process.** Current algorithms that optimize the network under the guidance of readily high-level labels at final layer is insufficient for guiding the selection of drop matrices in the intermediate stages of the network. This limitation may lead to the phenomena that constructed matrices do not accurately reflect the contributions of tokens, potentially compromising the efficiency of algorithm. Thus, the major question arises: _how can we optimize the selection of drop matrices to accurately represent each token's contribution?_

To rectify this, our framework innovates with an adversarial approach embedded within each stage, which cornerstone is the integration of specialized auxiliary heads, strategically positioned within thenetwork. Each auxiliary head is assigned the critical task of computing a unique and stage-specific loss, it identifies the patterns or tokens that the current stage predominantly focuses on and then intentionally drops these identified tokens. This process forces the network to shift its attention, thereby encouraging it to mine features from other, less emphasized regions.

The operation within these auxiliary heads begins with a dominant feature index operation applied to the tokens, which aligns with the identification methodology detailed in Eq. 1. This ensures that the drop matrices generated are a true reflection of tokens significance at every specific network stage.

Implementing these adversarial-focused auxiliary heads represents a significant leap in the optimization process. By introducing a targeted, stage-specific supervision issue at each stage, they offer a refined assessment of token contributions, a stark contrast to the broader, less specific results from the network's final layer. This precision in evaluation is pivotal to the nuanced understanding and optimization of each stage within the network, aligning token signification closely with the specific objectives of each stage in the network. The adversarial approach facilitates an augmented constraint term and plays an instrumental role in the selection of drop matrices at each stage, contributing substantially to the optimization process, encapsulated as follows:

\[_{A}=_{i=1}^{N} y^{*}_{\ i}-_{i} _{2},\] (3)

where \(\) and \(y^{*}\) denote the predicted and ground-truth labels, respectively, for the input point cloud \(^{N 3}\), with \(_{2}\) indicating the \(L_{2}\) norm. This constraint term, derived from the cumulative loss computed by all the auxiliary heads, ensures a comprehensive and layered supervision across the network. It allows the Adversarial Significance Identifier to discern the contribution of each token more accurately, thereby generating more targeted and effective supervisory signals for the token dropping process. This, in turn, enhances the overall efficacy and precision of the network learning.

**Derivation of per-token dropout rate.** The objective of \(()\) below is to refine the raw frequency distribution of tokens, as encapsulated within the matrix \(M\), transforming them into precise and actionable probability distribution. This transformation is critical for the effective application of dropout rates to tokens in the network. The specific functional representation is detailed below:

\[(m_{j},,,)=&_{j=1}^{n  m_{j}}m_{j}<\\ _{j=1}^{n m_{j}}&_{j=1}^{n  m_{j}}\\ &_{j=1}^{n m_{j}}>\] (4)

Herein, the parameter \(\) represents the mapping ratio, a pivotal factor whose impact and intricacies are thoroughly examined in a later ablation study. The variable \(n\) denotes the total number of tokens under consideration. The boundary parameters, \(\) and \(\), are pre-set to the values of \(0.05\) and \(0.95\), respectively. These parameters play a vital role in defining the range and sensitivity of the transformation function. The probability distribution thus generated by \(()\) is instrumental in

Figure 3: **Overall architecture** of our algorithm, composed of two key modules: Adversarial Significance Identifier and Target-guided Promptor. The former evaluates token significance within the context of the global perception, with the help of dominant feature indexing process from an auxiliary supervising loss that can bolster the precision of the index selection, then producing dropping rate for tokens. Subsequently, Target-guided Promptor enhances key dropout probabilities influenced by rate above, driving the model to explore auxiliary segments for pivotal information. This mechanism mitigates the propensity of the model to overfit to localized patterns.

dictating the dropout strategy in the following Target-guided Promptor. This structured approach ensures that the dropout process is both targeted and efficient, enhancing the overall performance.

### Target-guided Promptor

In traditional self-attention mechanism in transformers, the use of vanilla dropout techniques is prevalent, where each node in attention matrix is assigned a uniform stochastic discard probability. While this strategy aids in reducing overfitting and enhancing the generalization, it inherently overlooks the non-uniform characteristics of nodes in the matrix. The indiscriminate application of random dropout across all nodes fails to effectively penalize those with significantly higher attention scores; this oversight may result in a residual risk of overfitting to specific localized patterns. To address this shortcoming, our proposed methodology diverges from the conventional approach by independently targeting each key within the self-attention mechanism. As detailed in Fig. 5, this focused strategy efficiently penalizes keys with pronounced attention scores, thereby directly addressing the issue of overfitting to specific local patterns.

During each training epoch, this module adaptively masks a specified fraction of keys in the input key map using the matrix \(M\). Notably, for every distinct query, a unique masked key map is synthesized, as opposed to utilizing a shared masked key map for the entire set of query vectors. Given token features defined by \(T=\{t_{j}|j=1,...,n\}^{n C}\) accompanied by coordinates \(\), we derive the representations for query (\(Q\)), key (\(K\)) and value (\(V\)) as following:

\[Q,K,V=HW^{Q},\ HW^{K},\ HW^{V},\] (5)

where \(W^{Q},W^{K},W^{V}^{C C}\) are the learnable linear projections.

**Generating dropout target.** We aim to generate a vector \(M^{}\) whose elements have probability of being negative infinity, based on the value in \(M\) above. Based on the probability values encapsulated within matrix \(M\), we synthesize matrix \(M^{}\). Each element within \(M^{}^{n C}\) is assigned a value of negative infinity with a probability determined by the corresponding value in \(M\):

\[m^{}_{i}=0&with\ probability\ 1-m_{i}\\ -inf&with\ probability\ m_{i}\] (6)

This resultant vector is then expanded across feature channels.

**Dropping key process.** In preceding step, we derived the dropout rates \(M^{}\). This is subsequently employed to drop elements from the key vector \(K\). Specifically, by adding the vector \(M^{}\), which contains negative infinity values, to \(K\), the network disregards designated positions, thus achieving a targeted dropout implementation. The mechanism is defined as follows:

\[K^{}=K+M^{},\] (7)

The modified token features \(T^{}=\{t^{}_{i}|i=1,...,n\}^{n C}\) are derived by such formulation:

\[T^{}=MHA(Q,K^{},V,PE()),\] (8)

where \(MHA\) symbolizes the multi-head attention mechanism as delineated in , while \(PE()\) is indicative of the position embedding.

[MISSING_PAGE_FAIL:7]

them, delivering **4.0%** and **7.5%** mCE reduction for PointM2AE  and PointGPT , respectively. This confirms our algorithm is applicable in real-world corruptions. Notably, our method obtains consistent high performance of nearly all categories. it achieves \(48.9\%\), \(67.0\%\), \(30.0\%\), and \(63.0\%\) mCE over drop-global, drop-local, add-global, and add-local, respectively. These results are all the sota results in each subcategory, illustrating that our method performs well in the face of point adding and removing corruption, both globally and locally.

### Results on Shapenet-C

**Dataset.** Our method can generalize well to down-stream tasks, including part segmentation. To validate this, we conduct a part segmentation experiment on the ShapeNet-C dataset .

**Main Results.** Tab. 3 showcases the performance of our method, achieving a mCE score of **81.4%** and surpassing the previous sota GDANet and PointMAE by an impressive margin of \(10.9\%\) and \(11.3\%\), respectively. It is worth highlighting that PointMAE operates as a scheme of masked autoencoders for point cloud self-supervised learning, which is pretrained on large set of data. This underscores the substantial enhancement brought about by our technique in improving the model robustness

### Ablation Study

To validate the efficacy of our core algorithm designs and parameter settings, we conduct a series of ablative studies on ModelNet-C .

**Effect of adversarial dropping strategy.** To ascertain the impact of our core idea of adversarial dropping, we conducted an ablation study by removing the adversarial dropping process, along with the collaborative supervising identification process. As shown in Tab. 4, the baseline model, trained in the standard strategy, gains \(76.2\%\) and \(78.8\%\) mCE, on ModelNet-C and ScanObjectNN-C, respectively. Additionally considering the dropping strategy and supervising identification process \(_{A}\)(Eq. 3) can lead to \(4.0\%\) and \(4.6\%\) mCE reduction, respectively. However, adding dropping strategy without ancillary constraints from \(_{A}\) will lead to mCE increasing. These results verify that combining these two training objectives can yield the best results, indicating that mining data structures from subsidiary component can benefit detailed analysis of point cloud

**Visualization of Data Distribution.** To showcase the efficacy of our algorithm in mitigating model overfitting to particular patterns, we conduct an analysis on the statistical distribution of the patterns learned by the model. Specifically, we compute the variance of patterns learned from Level 2 Jitter

   Method & mCE & Scale & Jitter & Drop-G & Drop-L & Add-G & Add-L & Rotate \\  DGCNN[TOG2019] & 100.0 & 100.0 & 100.0 & 100.0 & 100.0 & 100.0 & 100.0 & 100.0 & 100.0 \\ PointNet[CVPR2017] & 117.8 & 108.2 & 105.0 & 98.3 & 113.2 & 138.6 & 117.3 & 143.8 \\ PointNet[+HMS2010] & 111.2 & 95.0 & 108.1 & 85.6 & 198.3 & 88.6 & 108.3 & 94.7 \\ PAConv[CVPR2021] & 92.7 & 92.7 & 107.2 & 92.5 & 92.7 & 74.3 & 94.8 & 94.8 \\ GDANet[AAAI2021] & 92.3 & 92.2 & **101.2** & 94.2 & 94.6 & 71.2 & 95.7 & 96.9 \\ PT[ICCV2021] & 104.9 & 107.6 & 107.2 & 103.2 & 108.1 & 111.2 & 106.6 & 90.7 \\ PointML[LRL2022] & 97.7 & 96.5 & 113.2 & 88.7 & 99.1 & 92.9 & 106.1 & **87.6** \\ Point-BERT[CVPR2022] & 103.3 & 93.8 & 109.8 & 87.3 & 92.7 & 117.0 & 119.9 & 102.5 \\ Point-MAE[ECCV2022] & 92.7 & **90.8** & 103.5 & **85.2** & **88.2** & 77.6 & 103.1 & 100.3 \\  APCT (**Ours**) & **81.4** & 93.9 & 109.9 & 86.6 & 93.4 & **40.1** & **41.6** & 103.8 \\ _vs. pre. SoTA_ & \(\)_10.9_ & & & & - & & & \\   

Table 3: Segmentation results in terms of mCE (\(\%,\)) on ShapeNet-C dataset.

   Method & mCE & Scale & Jitter & Drop-G & Drop-L & Add-G & Add-L & Rotate \\  DGCNN[TOG2019] & 100.0 & 100.0 & 100.0 & 100.0 & 100.0 & 100.0 & 100.0 & 100.0 \\ PointNet[CVPR2017] & 132.8 & 141.2 & 88.4 & 78.3 & 125.3 & 139.2 & 200.0 & 156.9 \\ PointNet[+VPR2017] & 96.9 & 89.7 & 110.3 & 55.0 & 127.7 & 94.7 & 90.5 & 110.7 \\ RPC[AAAI2021] & 132.6 & 131.7 & 107.3 & 145.5 & 130.5 & 114.2 & 158.7 & 140.2 \\ PointNeX[NIP5202] & 92.1 & 80.3 & 107.9 & 80.7 & 94.2 & 94.4 & 87.5 & 99.5 \\ PointM2AE[NIP5202] & 78.2 & 68.5 & 119.3 & 55.3 & 83.2 & 35.7 & 71.4 & 114.2 \\ PointGPT[NIP5202] & 84.7 & 119.9 & 104.0 & 58.5 & 76.9 & 36.1 & 72.2 & 125.1 \\  APCT (Ours) & **74.2** & 104.5 & 98.9 & 48.9 & 67.0 & 30.0 & 63.0 & 107.1 \\ _vs. pre. SoTA_ & \(\)_4.0_ & & & & - & & \\   

Table 2: Classification results on the ScanObjectNN-C dataset, mCE(\(\%,\)) is reported. \(\) denotes method designed specifically against corruption.

**Effect of selection number \(k\).** We next investigate the impact of the selection number \(k\) of Adversarial Significance Identifier in Fig. 8. Here \(k=1\) means directly treating the max-feat token as the single essential part. This baseline (\(k=1\)) obtains \(75.1\%\) mCE on ModelNet-C. After more essential pattern mining, we observe improvement against corruption, \(.eg.\), \(75.1\% 72.2\%\) mCE when \(k=2\). When \(k>2\), further increasing \(k\) gives marginal performance gains even worse results. We speculate this is because the model is distracted by some trivial patterns due to over-mining.

**Effect of mapping rate \(\).** Tab. 5 gives the performance with regard to the ratio \(\) in mapping function (in Eq. 4). The model performs better with a medium ratio \([0.2,0.2,0.2]\), showing that moderate mapping ratio is more favored. Moreover, at the asymptotic cases of \([_{1},_{2},_{3}]=[0.1,0.2,0.3]\) or \([_{1},_{2},_{3}]=[0.3,0.2,0.1]\), the performance drops considerably, evidencing that gradually adjusting the dropping strategy is not a sound solution.

**Disparity between ours and vanilla dropout.** Our method diverges distinctly from the vanilla dropout, from the perspectives of motivation, technical implementation, and empirical outcomes. From Motivation: we aim to address a nuanced challenge overlooked by standard dropout method: the tendency of deep learning models to make misguided inferences from local features within perturbed samples, particularly prevalent in real-world data scenarios. From Implementation: dropout fosters generalization by randomly attenuating network parameters. In contrast, our approach eschews simplistic random dropout in favor of a meticulously engineered mechanism that identifies and diminishes tokens deemed pivotal by the model in its preliminary assessments, thereby compelling the network to recalibrate and shift its focus to previously overlooked tokens, as seen in Fig. 13 and Fig. 13. For results, curves in Fig. 8 demonstrates that when contending with corruptions in the ModelNet-C dataset, our method significantly outperforms the standard dropout (**72.2%** vs \(74.5\%\)).

## 5 Conclusion

In this work, we introduce a new algorithm, tailored for point cloud recognition in the presence of real-world corruptions. Our algorithm incorporates an adversarial dropping strategy, facilitating the capture of diverse patterns, enabling the assimilate information from non-corrupted regions, thereby ensuring robust prediction under local pattern damaged scenario. Experimental evaluations on comprehensive benchmarks manifest its superiority.

_Limitations._ While current method can discern different patterns through adversarial strategies and render accurate judgments under corrupted scenarios, the optimal utilization of these cues has not been extensively explored in this paper. In future work, we intend to delve deeper into this aspect.