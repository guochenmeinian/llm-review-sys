# Fast yet Safe: Early-Exiting with Risk Control

Metod Jazbec\({}^{1,}\)1

Alexander Timans\({}^{1,}\)1

Tin Hadzi Veljkovic\({}^{1}\)

**Kaspar Sakmann\({}^{2}\)**  **Dan Zhang\({}^{2}\)**  **Christian A. Naesseth\({}^{1}\)**  **Eric Nalisnick\({}^{1,3}\)**

\({}^{1}\)UvA-Bosch Delta Lab, University of Amsterdam

\({}^{2}\)Bosch Center for AI, Robert Bosch GmbH   \({}^{3}\)Johns Hopkins University

Equal contributions. Corresponding authors: <m.jadbec@uva.nl, a.r.timans@uva.nl>

###### Abstract

Scaling machine learning models significantly improves their performance. However, such gains come at the cost of inference being slow and resource-intensive. Early-exit neural networks (EENNs) offer a promising solution: they accelerate inference by allowing intermediate layers to 'exit' and produce a prediction early. Yet a fundamental issue with EENNs is how to determine _when_ to exit without severely degrading performance. In other words, when is it'safe' for an EENN to go 'fast'? To address this issue, we investigate how to adapt frameworks of _risk control_ to EENNs. Risk control offers a distribution-free, _post-hoc_ solution that tunes the EENN's exiting mechanism so that exits only occur when the output is of sufficient quality. We empirically validate our insights on a range of vision and language tasks, demonstrating that risk control can produce substantial computational savings, all the while preserving user-specified performance goals.

## 1 Introduction

As predictive models continue to grow in size, so do the costs of running them at inference time . This presents a challenge to domains ranging from mobile computing to smart appliances to autonomous vehicles - all of which require models that operate on resource-constrained hardware . Even if computation is not limited by hardware, concerns over the energy usage and carbon footprint of large models motivates their efficient implementation . Additionally, since computational constraints can be dynamic, _e.g._, due to variable loads in web traffic or energy demand, it is desirable for models to be able to adjust their computational needs to changing conditions .

_Early-exit neural networks_ (EENNs) present a simple yet effective approach to such dynamic computation . Leveraging the neural network's compositional nature, EENNs can generate predictions at intermediate layers, thereby 'exiting' the computation 'early' when a stop condition is met. This early-exit ability has proven useful in settings ranging from vision and language to recommendations (, see SS 4). Yet the flexibility of EENNs does not come for free: predictions generated at early exits are usually inferior to those produced by the full model. In turn, a dilemma arises in which the exit condition must balance computational savings with predictive performance.

In this work, we address the EENN's efficiency _vs._ performance trade-off via statistical frameworks of _risk control_ (RC) . By tuning the EENN's exiting mechanism based on a user-specified notion of risk, RC aims to enhance the safety of early-exit outputs. We consider several risks that quantify the difference between the early-exit and full model's outputs, both in terms of prediction quality and uncertainty estimation. Moreover, we study RC frameworks that control the risk with varying degrees of stringency (_i.e._, in expectation _vs._ with high probability). We demonstrate the effectiveness of this light-weight, _post-hoc_ solution across a range of tasks, including image classification, semantic segmentation, language modeling, image generation with diffusion, and speculative decoding in large language models. In particular, we make the following contributions:* We formalize EENNs as risk-controlling predictors, ensuring risk control is amenable to the early-exit setting by explicitly linking risk control and early-exit requirements (Prop. 1 & Prop. 2).
* We propose risk functions to control early-exit performance both in terms of model predictions and their underlying predictive distributions (Eq. 6 & Eq. 8). Previous work has considered only prediction quality , not uncertainty quality (as we do).
* We improve upon prior work for language modeling , demonstrating that our adaptions of risk control allow for less conservative early-exiting and result in larger efficiency gains (SS 3.3, SS 5.3).
* We apply, for the first time, risk control to early-exiting in image classification, semantic segmentation, and image generation, as well as speculative decoding in large language models (SS 5).

## 2 Background

Data.Let \(\) denote the sample space and assume a data-generating distribution \(\) over it. We consider \(:=\{1,,K\}\) for classification and \(^{d}\) for regression. Observed samples from \(\) are split into disjoint train, calibration and test sets, denoted \(_{train}\), \(_{cal}\), and \(_{test}\). We assume samples \((,)\) in \(_{cal}\) and \(_{test}\) to be drawn _i.i.d._ from \(\), whereas \(_{train}\) is permitted to be drawn randomly from a different distribution (of same support).

Early-Exit Neural Networks.EENNs extend traditional _static_ network models by dynamically adjusting computations during the model's forward pass (_e.g._, the number of evaluated network layers) on the basis of an input sample's complexity or 'difficulty'. More formally, we define an EENN as a sequence of probabilistic classifiers \((=;_{l},_{l})\), where \(l=1,,L\) enumerates the model's exit layers, and \(_{l}\) and \(_{l}\) define the model's classification head and backbone parameters at the \(l\)-th exit, respectively. The final index \(L\) denotes the full model, _i.e._, all layers are evaluated for a given input sample \(\). The obtained predictive distribution \((=;_{l},_{l})\) at the \(l\)-th exit layer, denoted in short as \(_{l}(|)\), permits to retrieve both a predicted class label \(}_{l}=_{}_{l}()\) and an associated confidence score \(}_{l}\), which aims to capture model's certainty about the exit's current prediction. One common choice for classification tasks is the maximum class probability \(}_{l}=_{}_{l}()\). However, different notions of confidence are possible, as we explore in SS 5.2. At test-time, these confidence scores can be leveraged to determine the early-exit model's required computations for new samples via thresholding. For a given test input \(\), the EENN exits2 at the first layer for which its confidence exceeds a pre-specified threshold value \(_{l}\). For simplicity, a single threshold value \(_{l}=\), \(\,l\{1,,L-1\}\) is often fixed across exit layers, a setup we also consider here. The predictive distribution obtained from the model's early-exit mechanism is then given by 
\[_{}(|):=_{e}(|),e= E&E\\ L&E=,\ E:=\{l\{1,...,L-1\}:}_{l} \}.\] (1)

The threshold parameter \(\) regulates the trade-off between the EENN's accuracy and efficiency gains. Lower values equate larger speed-ups by increasing the likelihood of an early exit (and _vice versa_), at the cost of generally inferior predictions. Such _marginally monotone_ behavior, where model performance improves _on average_ across exits, is a core assumption for the practical use of EENNs (see also Fig. 1). We formalize it as

\[_{(,)}[(_{l}(|),)]_{(,)}[((_{l+1} (|),)] l=1,,L-1\] (2)

for some arbitrary loss function \(\), and elaborate on its connection to risk control in SS 3.3. It is common to determine early-exiting criteria by investigating these trade-offs between performance and efficiency on hold-out data, selecting thresholds that ensure the EENN meets a user's computational budget [36; 70] or performance goals [16; 21; 48]. A standard practice is to treat the EENN's predictive confidence (_e.g._, its softmax scores) as a heuristic for prediction quality. However, this is fallible, as EENNs can exhibit fluctuating or poorly-calibrated confidences [40; 37; 51], motivating more principled threshold selection.

Risk Control.Statistical frameworks for risk control (RC) [1; 4; 8] aim to improve prediction reliability by equipping threshold-based models with safety assurances. Specifically, consider a pre-trained prediction model \(\) whose outputs depend on a threshold \(\). For example, given a classification task, the set predictor \(: 2^{}\) described by Bates et al.  includes a class label in the set if its probability exceeds the threshold, _i.e._, \(_{}():=\{:(|) \}\). Next, a notion of error for \(_{}\) is captured by defining a problem-specific loss function \(:\). For instance, a meaningful choice for the set predictor could be the miscoverage loss \((_{}(),)=_{ }()\), where \([]\) is the indicator function. The risk associated with a particular threshold \(\) is then defined as the expected loss

\[():=_{(,)} (_{}(),),\] (3)

with \(\) the set of potential threshold candidates. RC frameworks leverage different probabilistic tools - which we detail further in SS 3.3 - to determine a subset \(\) for which the risk in Eq. 3 is guaranteed to be small. Note that \(\) is retrieved in a _post-hoc_ manner by leveraging the calibration set \(_{cal}\) sampled _i.i.d._ from \(\). Thus, \(()\) is a random quantity dependent on \(_{cal}\) for any \(\).

Given such a risk, desired safety assurances may vary in strength. For a tolerated risk level \((0,1)\), risk control _in expectation_ seeks to guarantee that

\[_{_{cal}^{n}}(),\] (4)

where the outer expectation is taken over randomly drawn calibration data of finite size \(|_{cal}|=n\). A stronger statement on risk control _with high probability_ requires additionally specifying a probability level \((0,1)\), and aims to ensure that

\[_{_{cal}^{n}}(() ) 1-.\] (5)

That is, rather than the average control over calibration data in Eq. 4, risk control according to Eq. 5 holds with high probability for any particular sampled set \(_{cal}\). In both cases, we may refer to \(_{}\) for any \(\) as a _risk-controlling predictor_. The risk level \(\) and probability level \(\) are user-specified parameters dictating how tightly the risk is controlled, and a particular choice has to consider the problem-specific setting and loss \(\). For example, a reasonable choice for the stated miscoverage loss may be \((,)=(0.05,0.1)\). Observing \(=\) implies that there is no risk-controlling predictor for the selected \((,)\), indicating overly stringent risk control conditions which \(_{}\) cannot satisfy.

The prediction guarantees obtained via RC are highly practical, since they are _(i)_ distribution-free, _i.e._, they do not impose any particular assumptions on the generating distribution \(\), _(ii)_ are _post-hoc_ applicable to any arbitrary choice of underlying predictor \(_{}\), and _(iii)_ hold in finite samples, thus not relying on asymptotic limit statements. Indeed, we experimentally find that the provided assurances hold even for remarkably small calibration sets (\(n 100\), see SS 5).

## 3 Safe Early-Exiting via Risk Control

We now detail our approach for early-exiting with safety guarantees based on risk control. We begin by outlining EENNs as risk-controlling predictors (SS 3.1). Next, we describe two general types of risk to measure performance drops resulting from early-exiting. Importantly, these risks can be employed to assess the quality of both predictions and predictive distributions (SS 3.2). Finally, we motivate and formalise how different risk control frameworks can be adapted to the early-exit setting (SS 3.3).

### EENNs as Risk-Controlling Predictors

As mentioned in SS 2, risk control requires a predictor \(_{}\) whose outputs depend on a threshold \(\). The EENN's confidence-based thresholding behaviour (following Eq. 1) lends itself naturally to such a formulation. For a particular exit threshold \(\), the EENN \(_{}(|)\) will act as such a threshold predictor. To ensure that the EENN satisfies the user's control requirements, the risk-controlling threshold set \(\) needs to be identified. Importantly, this can be done _post-hoc_ using a pre-trained EENN with fixed weights, since only the exit threshold \(\) is modified. In order to maximize computational savings while ensuring that the user-defined risk is managed, we select \(:=\), since a low threshold encourages earlier exiting. If \(=\) is empty, we default to \(=1\), the equivalent of relying strictly on the full model output \(_{L}(|)\).

### Early-Exiting Risks

We next detail two types of risk which can be employed to guard against performance drops due to early-exiting. Similarly to Schuster et al. , our risks are defined in terms of relative exit performance, permitting their calculation for both labelled and unlabelled calibration data. Moving beyond their setting, we suggest these risks for controlling the quality of both model _predictions_ and _predictive distributions_, from which confidence scores can be derived.

Performance Gap Risk.When calibration labels are present, these can be used to measure the early-exit performance through supervised losses. Let \(}_{l}()\) denote a general EENN output for some input \(\). It takes the form \(}_{l}\) for predictions and \(_{l}(|)\) for the underlying predictive distribution. The supervised _performance gap risk_ is then defined as

\[^{G}():=_{(,)} }_{}(),- }_{L}(),,\] (6)

where \(}_{}()\) and \(}_{L}()\) refer to early-exit and full model outputs, respectively. The choice of loss function \(\) is task-specific, and we outline relevant choices in SS 5, such as the \(0\)-\(1\) loss for image classification. For predictive distribution control, we suggest leveraging a squared distributional loss which, when averaged across samples, recovers the Brier score . Specifically, we define such a 'Brier loss' for classification tasks as

\[_{B}(_{l}(|),):=_{k=1}^{K}_ {l}(k|)-[=k]^{2},\] (7)

where \(_{l}(k|)\) denotes the predicted probability of a particular class \(k\), and \([=k]\) its one-hot encoded label. The Brier score is a _strictly proper scoring rule_, ensuring its suitability to assess probabilistic forecasts. Moreover, its mathematical formulation lends itself favorably to risk control when compared to other widely used probabilistic metrics. We defer further details to SS A.3. Addressing risk control of the underlying predictive distribution \(_{l}(|)\) is a compelling extension, as confidence or uncertainty estimates are typically derived from it. Particularly in safety-critical scenarios where reliable uncertainties are essential , such control can thus prove very useful.

Consistency Risk.In the case of unlabelled calibration data, an unsupervised version of Eq. 6 can be obtained by replacing the ground truth labels \(\) with labels \(}_{L}\) obtained from the full model. We define the unsupervised _consistency risk_ as

\[^{C}():=_{(,)} }_{}(),}_{L}- }_{L}(),}_{L},\] (8)

where only input samples \(\) are required for its evaluation.

For regular prediction losses, Eq. 8 collapses to evaluating the per-sample loss \((}_{},}_{L})\), since \((}_{L},}_{L})=0\). For predictive distribution control, the loss difference remains, and we substitute \(\) in Eq. 7 by sampling a label \(}_{L}_{L}(|)\) from the EENN's final layer. Our reliance on the last layer's output is motivated by the EENN's marginal monotonicity (Eq. 2 and Fig. 1). Finally, we note that both the performance gap risk \(^{G}()\) and consistency risk \(^{C}()\) are quite agnostic to the EENN's actual predictive performance. In both cases, the risk formulation aims to ensure prediction consistency via the _relative_ performance gap between exits, as opposed to _absolute_ performance with respect to observed ground truth labels.

### Risk Control Frameworks

After having defined our early-exit risks, we next outline how a desired risk-controlling exit threshold \(\) can be computed based on calibration data. We begin by considering a 'naive' empirical approach, followed by risk control _in expectation_ (Prop. 1) and _with high probability_ (Prop. 2).

Figure 1: Accuracy and Brier score  across exits for different EENNs for image classification on ImageNet (§ 5.1). _Marginally monotone_ performance trends (Eq. 2) are generally observed across models, with last-layer exits performing best.

Empirical Approach.For a tolerated risk level \((0,1)\), a 'naive' empirical threshold can be selected by picking the smallest threshold \(\) from the candidate set \(\) for which the risk on the calibration set \(_{cal}\) is controlled, _i.e._,

\[_{}:=\{:}(; _{cal})\}.\] (9)

Note that \(}(;_{cal})=_{i=1}^{n}( }_{}(_{i}),_{i})\) is the _empirical_ calibration risk, an approximation of the true risk in Eq. 3 computed on \(_{cal}\) (and likewise \(}(;_{test})\) denotes the empirical test risk). For the risks introduced in SS 3.2 the threshold \(_{}\) is always well-defined, since \(}(=1)\) is zero.

Risk Control in Expectation.The threshold \(_{}\) is a straight-forward choice, but can fail to control the risk on test data if the approximation quality of \(()\) by \(}(;_{cal})\) is poor, _e.g._, due to badly drawn calibration data. Perhaps surprisingly, only a slight modification of Eq. 9 is required to ensure risk control _in expectation_. Specifically, for a bounded loss function \( B\) where \(B>0\), and assuming a monotone risk \(()\), the threshold3

\[_{}:=\{:}(;_{cal})+\}\] (10)

guarantees Eq. 4, thus shielding against bad sample draws on average. It is easy to show that \(_{}=_{n}_{}\), and since our losses are designed to be upper-bounded by \(B\{1,2\}\), the two thresholds already coincide for small calibration sets (\(n 100\)). We formalize risk control in expectation in the following proposition for our early-exit setting:

**Proposition 1**.: _Let \(:(-,B]\) be a right-continuous bounded loss, and assume a marginally monotone EENN (Eq. 2). Then the exit threshold \(_{}\) ensures risk control in expectation, i.e., it holds that \(_{_{cal}^{n}}(_{})\) for any \((0,1)\)._

Our proposition is an extension of _Conformal Risk Control_ (CRC) to the early-exit setting, and a proof can be found in SS A.1. Our main technical insight is that risk control can be relaxed to assume monotone _risks_, rather than monotone _losses_ as in the original formulation . This relaxation is crucial for the early-exit setting, since we can relate monotone risks to assumptions of _marginal_ monotonicity on the EENN (see Lemma 1). In contrast, monotone losses translate to assuming _conditional_ monotonicity, a much stronger requirement suggesting the EENN's performance improves across exits _per sample_, and which has been shown to be violated in practice .

Risk control with High Probability.A stronger guarantee can be obtained by ensuring risk control _with high probability_ for any drawn calibration set. We employ the _Upper Confidence Bound_ (UCB) from Bates et al.  for this purpose. First, an empirical upper bound \(}^{+}(;_{cal})\) is derived to bound the risk \(()\) with high probability. That is, for a probability level \((0,1)\) it holds that

\[_{_{cal}^{n}}() }^{+}(;_{cal}) 1- .\] (11)

An exit threshold ensuring risk control according to Eq. 5 is then selected as

\[_{}:=\{:}^{+}( ^{};_{cal})<,^{} \}.\] (12)

Similarly to Prop. 1, we can now formalize risk control with high probability for the early-exit setting:

**Proposition 2**.: _Let \(:[-B,B]\) be a bounded loss, and assume a marginally monotone EENN (Eq. 2). Then the exit threshold \(_{}\) ensures risk control with high probability, i.e., it holds that \(_{_{cal}^{n}}((_{ })) 1-(,)(0,1)^{2}\)._

This reformulation of the main theorem from Bates et al.  (Thm. A.1) is proven in SS A.1, and an algorithmic description is given in Appendix B. We employ their suggested Waudby-Smith-Ramdas bound  (WSR) to compute \(}^{+}(;_{cal})\), but relax the bounding requirements on the loss from \(\) to \([-B,B]\) for \(B>0\). This change has important implications for the early-exit setting, since it admits'rewarding' the EENN when an earlier exit performs better than the final exit for some samples, a phenomenon known as _overthinking_. In practice, this results in a better risk estimate and less conservative early-exiting. See SS A.2 for more details on the effect of loss bounds.

**Learn-then-Test and CALM .**_Learn-then-Test_ (LTT) is another framework for high-probability risk control, where threshold selection is framed as a multiple hypothesis testing problem. In contrast to UCB (Prop. 2), LTT does not require risk monotonicity, and can thus also be employed when the EENN is suspected to violate marginally monotone behaviour. LTT in the early-exit setting has been employed by Schuster et al.  (CALM), presumably motivated by the avoidance of this assumption. However, expecting an EENN to marginally improve across exits is a core requirement which implicitly underlies any practical implementation. Since this assumption is usually also empirically satisfied (Fig. 1), there is no obvious reason to explicitly avoid it. Furthermore, correcting for multiple testing in LTT via _fixed sequence testing_ - as is done for CALM - will only yield practical savings if monotonicity is satisfied. We stress these observations since we find that UCB provides greater computational savings than LTT under the same guarantees (Fig. 2 and SS 5.3), including for small-sample regimes (\(n 100\)), which are of high practical interest and were not explored by Schuster et al. . Moreover, due to LTT's reliance on the Hoeffding-Bentkus bound , it cannot account for instances of model overthinking (see SS A.2). Thus, unless Eq. 2 is known to be violated, we recommend UCB over LTT in the early-exit setting.

## 4 Related Work

_Early-Exiting_[70; 29] as a dynamic approach to accelerate model inference is both orthogonal and complementary to static model compression techniques such as pruning, quantization, and knowledge-distillation [6; 79; 68; 84; 25]. Its wide-ranging applicability has been demonstrated across numerous vision [36; 48; 15; 69; 22] and language tasks [21; 83; 65; 78; 53]. While most prior work has focused on the trade-off between performance quality and computational savings, the _safety_ of early-exit models has received less attention to date [64; 65; 51; 38]. _Risk Control_ has gained traction due to an interest in efficient, _post-hoc_ approaches with safety assuresures for large models. Most related, _conformal prediction_ has been popularized as an effective method for uncertainty quantification with guarantees on the miscoverage risk [24; 3]. Recently, multiple proposals address the control of more general risk notions [4; 8; 1; 67; 54; 45], with explored applications ranging from imaging [71; 2; 81; 23; 43; 61; 10; 72] to language [86; 20; 45; 56] and beyond [39; 46]. Most closely related to our work is research by Schuster et al. , who first employ risk control for safe early-exiting in language modeling. We move beyond their setting by _(i)_ controlling the quality of both model predictions and uncertainty estimates (SS 3.2), _(ii)_ obtaining better efficiency gains through careful selection of our risk control framework (SS 3.3), and _(iii)_ extending early-exit risk control to novel tasks (SS 5). Ringel et al. 's work is also related: they apply risk control to exit early for a time series prediction task. Yet their emphasis is on exiting from a stream of input features, whereas we exit from the model itself (_i.e._, a stream of model layers).

## 5 Experiments

We empirically validate early-exiting via risk control on a suite of different tasks: image classification (SS 5.1), semantic segmentation (SS 5.2), language modelling (SS 5.3), image generation with diffusion (SS 5.4), and speculative decoding (SS 5.5). Our code is publicly available at https://github.com/metodj/RC-EENN. We begin by outlining our general risk control design and evaluation metrics.

Risk control design.We target control of the performance gap and consistency risks defined in SS 3.2. For predictions \(}_{i}\) we employ target-specific losses, and, when applicable, for predictive

Figure 2: Empirical test risk (_top_) and efficiency gains (_bottom_) for the CALM model  for text summarization on CNN/DM. Our adaptation of UCB  (Prop. 2) outperforms the LTT  approach in CALM by yielding larger efficiency gains under the same risk control assurances (see § 5.3 for details). Shading denotes the standard deviation across \(S=100\) calibration/test splits.

distributions \(_{l}(|)\) our Brier score formulation. We denote these four risks in short as \(^{G}(})\), \(^{G}(})\), \(^{C}(})\) and \(^{C}()\). Risk control requirements of different strength are assessed by varying the risk level \(\). Note that our approach is entirely _post-hoc_, and our experiments leverage existing pretrained EENNs when possible. Thus the underlying models are typically not modified, and we omit the commonly seen performance _vs._ FLOP curves to instead appropriately benchmark against different risk levels. For risk control with high probability, we set \(=0.1\) (_i.e._, 90 % probability). Reported numbers are averaged across multiple trials of calibration and test splitting (\(S=100\)) to account for sampling effects. Additional results across experiments can be found in Appendix D.

Evaluation metrics.We evaluate our results based on obtained test risks and efficiency gains. We assess whether the guarantees stated in SS 3.3 are satisfied by checking if the _empirical test risk_ for a given risk-controlling threshold is controlled, _i.e._, \(}(;_{test})\) holds. Ideally, the measured test risk should also approach \(\) from below, as to prevent overly conservative early-exiting. We measure efficiency gains by reporting the _average exit layer_ across test samples, or its relative improvement over last-layer exiting (in %). Similar gains in terms of arithmetic operations (FLOPS) are reported in Appendix D. We favour approaches which, while controlling the test risk, exit as early as possible.

### Image Classification

For image classification, we focus on the ImageNet dataset . We employ four state-of-the-art EENNs to demonstrate that our findings generalize across different models and architectures: **MSDNet**, **DViT**, **L2W-DEN**, and **Dyn-Perc** (see SS C.1 for details). We employ the standard 0-1 loss for predictions, and the Brier loss formulation from Eq. 7 for predictive distributions. Fig. 3 displays results for the small-sample calibration regime (\(n=100\)). In line with our theoretical guarantees, the test risk remains controlled across all models, risk types, and risk levels \(\) (_top_ row). The steeply decreasing efficiency curves affirm that even under strict control requirements, substantial efficiency gains can be obtained (_bottom_ row). For example, controlling the prediction gap risk at a strict \(5\%\) (\(^{G}(})\) for \(=0.05\)) results in a model average of \( 61\%\) less layers evaluated for control in expectation (CRC, Prop. 1), and \( 46\%\) for control with high probability (UCB, Prop. 2), see Table 2. Naturally, UCB produces more cautious early-exiting due to its stronger safety assurance, but these differences decrease for larger calibration sets (see SS D.1 for \(n=1000\)). This highlights the practical benefit of allocating more calibration samples: a larger sample size can aid to mitigate the price paid by a high-probability guarantee in terms of obtained inference speed-ups.

### Semantic Segmentation

For this task, we explore the effect of different confidence measures used in Eq. 1 on realizable speed-ups. We use the EENN with four exits proposed by Liu et al.  (ADP-C, see SS C.2). ADP-C permits _pixel-level_ early-exiting with per-pixel confidence scores. Since we desire to early-exit the

Figure 3: Empirical test risk (_top_) and efficiency gains (_bottom_) for different early-exit models, risks (§ 3.2) and risk levels \(\) on ImageNet (for calibration set size \(n=100\)). In line with theoretical results, the test risk is controlled across models, risk types, and levels. Despite guaranteeing control _in expectation_ (CRC, Prop. 1) or _with high probability_ (UCB, Prop. 2), obtained gains are substantial.

entire image instead, we explore _image-level_ aggregations alongside different confidence scores, which are briefly outlined below. As task-specific prediction losses, we consider the commonly used _mean intersection-over-union_ (mIoU) and _miscoverage_ for the labelled and unlabelled cases, respectively. For predictive distribution control, we employ pixel-averaged versions of the Brier loss in Eq. 7 (see SS A.3). We evaluate our approaches on Cityscapes validation data (80% \(_{cal}\), 20% \(_{test}\)); in addition, we finetune and evaluate ADP-C on a subset of the GTA5 dataset  in SS D.2.

We consider three pixel-level confidence scores: the top class softmax probability (**Top-1**), the difference between top two class probabilities (**Top-Diff**), and the normalized entropy over a pixel's predictive distribution (**Entropy**). In addition, we consider three image-level aggregation strategies: the image's average pixel confidence (**Mean**), its \(0.25\)-th quantile (**Quantile**), and a patch-based approach (**Patch**), wherein a sliding window of fixed size (_e.g._, \(50 50\) pixels) computes the mean confidence over pixels per patch, and the \(\) over such patch scores is retrieved. These aggregations consider both varying levels of prudence (Mean _vs._ Quantile) and granularity (Mean _vs._ Patch).

Table 1 displays obtained efficiency gains for risk control via UCB (Prop. 2) across different risk levels \(\{0.01,0.05,0.1\}\). In line with Fig. 3, increased speed-ups are observed as the risk requirements are relaxed (_i.e._, \(\) increases). Notably, for a given \(\) the gains for Brier-based risks tend to be smaller than for prediction risks, affirming more challenging risk control. The differences between combinations of per-pixel confidence and image-level aggregation are most pronounced for small \(\), where Patch records highest gains while Quantile is more conservative (see SS D.2 for full results). In Fig. 4, we display a qualitative example of the model's exiting behaviour. For a sample which exits at the first layer (_top_ row), the EENN's confidence map remains fairly stable across subsequent layers, suggesting an accurate model assessment has been reached early on. In contrast, a sample which exits at the final layer (_bottom_ row) will see a substantial improvement in model certainty, justifying additional computations. Such behaviour is also visible when stratifying all samples across their respective model exits (Fig. 4, _left_). For samples which exit later, the difference between distributional losses at the first and final layer increases, affirming that compute is spent meaningfully.

    & **Risk** & ^{G}(})\) (mIoU)} & ^{G}(})\) (Brier)} & ^{C}(})\) (Miscov.)} & ^{C}(})\) (Brier)} \\   & Level \(\) & **0.01** & **0.05** & **0.1** & **0.01** & **0.05** & **0.1** & **0.01** & **0.05** & **0.1** & **0.01** & **0.05** & **0.1** \\   & **Top-1** & 6.3 & 33.7 & 53.5 & 0.0 & 13.6 & 43.4 & 6.3 & 39.2 & 61.8 & 0.0 & 39.3 & 58.4 \\  & **Top-Diff** & 9.3 & 35.5 & 54.4 & 0.0 & 17.5 & 44.3 & 6.3 & 39.9 & 62.4 & 0.0 & 38.6 & 57.9 \\  & **Entropy** & 5.2 & 36.0 & 54.3 & 0.0 & 17.9 & 41.0 & 5.1 & 40.4 & 61.3 & 0.0 & 40.1 & 58.3 \\   & **Top-1** & 10.0 & 35.7 & 53.3 & 0.0 & 18.4 & 45.3 & 8.8 & 39.1 & 61.5 & 0.0 & 38.0 & 58.3 \\  & **Top-Diff** & 10.0 & 35.2 & 53.4 & 0.0 & 19.4 & 45.9 & 8.8 & 40.5 & 62.2 & 0.0 & 38.4 & 58.8 \\   & **Entropy** & 9.1 & 34.8 & 53.5 & 0.0 & 18.0 & 45.8 & 8.1 & 38.9 & 61.5 & 0.0 & 37.3 & 57.1 \\   

Table 1: Efficiency gains for semantic segmentation with risk control via UCB (Prop. 2) on Cityscapes. We evaluate for different risks (§ 3.2), confidence measures (§ 5.2) and risk levels \(\). Displayed values denote relative improvement over last-layer exiting in terms of mean exit layer (in %).

Figure 4: _Right:_ Example of our method’s early-exiting on Cityscapes . For two samples that exit early (\(l=1\)) and exit late (\(l=4\)), we display ground truth segmentation masks and confidence maps at the first and last model layer. _Left:_ For every sample, we compute the Brier loss difference \(_{B}=|_{B}(_{1}(|),)-_{B}(_{4 }(|),)|\) between first and last model layer (Eq. 7), and stratify values across respective exit layers; the red dot denotes the mean. For both figures, we consider the simplest combination of Top-1 confidence score and mean image-level aggregation (for \(=0.08\)).

### Language Modeling

For this task, we replicate the main experiments from Schuster et al.  (CALM), using their early-exit version of the T5 model  for text summarization on CNN/DM  and question answering on SQuAD . Recall that CALM makes use of the _Learn-then-Test_ (LTT) framework for early-exit prediction control, whereas we suggest the _Upper Confidence Bound_ (UCB). In contrast to their experiments which involve excessively large calibration sets (\(n 8000\)), we explore more practical settings of low calibration sample counts with \(n\{100,1000\}\). Our results for the _performance gap risk_ (Eq. 6) based on task-specific losses (_ROUGE-L_ for CNN/DM and _Token-F1_ for SQuAD) are displayed in Fig. 2 and SS D.3. In all cases, UCB exit thresholds provide large computational savings over LTT, while ensuring the same risk control with high probability (Eq. 5). Since particularly pronounced for \(n=100\), these results highlight the need for careful framework selection in order to minimize the cost of providing guarantees. Once more, risk control in expectation (CRC, Prop. 1) permits faster exiting due to its weaker safety assurance. Encouragingly, even with as few as \(n=100\) calibration samples, CRC exit thresholds reach near-optimal exiting, as indicated by their proximity to the ideal (diagonal) risk line. This suggests that even for modern language tasks, equipping an EENN with notions of safety does not necessitate a strong compromise on inference efficiency.

### Image Generation with Early-Exit Diffusion

To demonstrate the wide-ranging applicability of our proposal, we lastly consider early-exiting for image generation with diffusion. We employ the DeeDiff model , which performs early-exiting on the denoising network at each sampling step during the reverse diffusion process4. We target control of the _perceptual difference_ between images generated by the accelerated and full diffusion processes, which we measure with the LPIPS score , and where lower values indicate perceptually closer images. Our results on the CelebA dataset  are shown in Fig. 5 for both risk control via CRC (Prop. 1) and UCB (Prop. 2), asserting that the risk is controlled at all levels \(\). The impact of the risk level on image generation is additionally visualized for two examples. For strict control requirements the early-exit generations perceptually resemble the full model, whereas generated image quality visibly deteriorates for larger \(\) (but remains controlled). For smaller \(\), the speed-ups within each sampling step are relatively modest (_e.g._, \(\)15% for \(=0.05\)). However, such gains accrue over the large number of sampling steps in the image generation process (\(\)500), resulting in overall meaningful savings. Similar observations for CIFAR  are reported in SS D.4.

### Speculative Decoding for Large Language Models

While we primarily focus on early-exiting, our final experiment highlights how risk control can also be applied to other techniques for efficient inference. Here we consider accelerating the inference of large language models (LLMs) using the (soft) speculative decoding approach _BiLD_. BiLD uses a small draft model to generate multiple tokens autoregressively while the original LLM is only employed for verification.

Figure 5: Results for early-exit diffusion with DeeDiff  on CelebA . _Left:_ The quality of generated images is directly related to the target risk control level \(\). _Right:_ Empirical test risks are controlled for both CRC (Prop. 1) and UCB (Prop. 2) (for calibration set size \(n=500\)).

This step can be performed in a single forward pass for all proposed tokens, necessitating less computations from the larger, more expensive model. During verification the difference in token distributions between the models is computed, and the tokens generated by the draft model are rejected if the difference exceeds a tolerated threshold, triggering a "rollback" (see Eq. 3 in ). We apply our risk control frameworks to this rollback threshold, which dictates _(i)_ the similarity of generated text to the output produced solely by the original LLM, and _(ii)_ the associated inference speed-ups in terms of sentences (or samples) per second. Our results in Fig. 6 for the _performance gap risk_ (Eq. 6), as defined via the difference in sentence-level _BLEU_ scores, corroborate our previous findings for language modeling (Fig. 2 and SS 5.3). That is, our approaches via CRC (Prop. 1) and UCB (Prop. 2) provide meaningful speed-ups and improve upon the LTT method  used by CALM , while maintaining the desired risk control across test samples.

## 6 Discussion

Our work addresses how to select a'safe' exiting mechanism for early-exit neural networks (EENNs). We propose balancing the EENN's efficiency _vs._ performance trade-off via risk control, ensuring that accelerated inference does not compromise the quality of the early-exit outputs. We validate our light-weight, _post-hoc_ solution on a variety of tasks and improve upon prior work  (see SS 4).

Limitations and Future Work.A key limitation of our work is the reliance on a single shared exit threshold among layers (Eq. 1). While using a shared exit threshold is common , relaxing this condition could lead to further efficiency gains. This, however, introduces new challenges both in terms of theory (_e.g._, defining monotonicity requirements) and practice (_e.g._, substantially larger search spaces). Overcoming them by adopting recently proposed risk control techniques for high-dimensional thresholds  could prove promising for future extensions. Another (simple) workaround is to reduce the multi-dimensional problem back to a single threshold by use of a _threshold function_, as partially explored in . Instead of working directly with multiple thresholds, our risk control framework can then be applied to this scalar parameter. Additionally, multiple risk control extensions provide natural avenues for future work. Firstly, risk control as used in our work is achieved only _marginally_ across observations (Eq. 3), and one could aspire for more granular _exit-conditional_ control . Secondly, the employed risk control frameworks define risk in terms of the _expected_ loss. One could instead aim to control the tails of the loss, _e.g._, via specific quantiles of interest . Lastly, relaxing the _i.i.d_ assumption on calibration and test data could help extend risk-controlling EENNs to scenarios with test-time distribution shifts  or to online updating strategies .

Broader Impacts.EENNs provide a simple and effective approach to dynamic computation . Their computational savings can reduce energy costs and the carbon footprint, as well as allow the model to be deployed on resource-constrained hardware. By incorporating a'safe' exit mechanism into these models, we improve their trustworthiness and strengthen the reliability of their intermediate outputs, along with any decisions based on them. This facilitates safer model deployment in real-world applications and contributes to more responsible decision-making. While we do not foresee any direct negative consequences from our work, improper use of our risk control framework can lead to violations or misinterpretations of its provided guarantees. This, in turn, can risk instilling a false sense of security. Overall, we believe that our work outlines an effective approach to improve the reliability of EENNs and to safely balance their inherent efficiency _vs._ performance trade-off. In doing so, it contributes to the goal of developing models that are ultimately _fast yet safe_.

Figure 6: Empirical test risk (_top_) and efficiency gains (_bottom_) for the BiLD model  for a machine translation task (De–En) on IWSLT  (with \(n=500\)). We fix the fallback threshold to \(0.5\), and apply risk control to the _rollback_ threshold. Our adaptation of UCB again outperforms LTT by yielding larger efficiency gains under the same guarantees. Shading denotes the standard deviation across \(S=100\) calibration/test splits.