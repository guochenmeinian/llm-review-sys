# Learning the Efficient Frontier

Philippe Chatigny

Riskfuel

Toronto

pc@riskfuel.com

&Ivan Sergienko

Beacon Platform

New York

ivan.sergienko@beacon.io

&Ryan Ferguson

Riskfuel

Toronto

rf@riskfuel.com

&Jordan Weir

Riskfuel

Toronto

jw@riskfuel.com

&Maxime Bergeron

Riskfuel

Toronto

mb@riskfuel.com

Corresponding authorContribution was made when working at Riskfuel

###### Abstract

The efficient frontier (EF) is a fundamental resource allocation problem where one has to find an optimal portfolio maximizing a reward at a given level of risk. This optimal solution is traditionally found by solving a convex optimization problem. In this paper, we introduce NeuralEF: a fast neural approximation framework that robustly forecasts the result of the EF convex optimization problem with respect to heterogeneous linear constraints and variable number of optimization inputs. By reformulating an optimization problem as a sequence to sequence problem, we show that NeuralEF is a viable solution to accelerate large-scale simulation while handling discontinuous behavior.

## 1 Introduction

Making the least risky decision to maximize a cumulative reward over time is a central problem in machine learning and at the core of resource allocation optimization problems . In modern portfolio theory , this problem is commonly referred to as the efficient frontier (EF) . It involves distributing resources among \(n\) risky assets to maximize return on investment while respecting various constraints. These constraints (e.g., maximum allocation allowable for an asset) are set to prevent aggressive or unrealistic allocations in practice. Finding the optimal solution to this optimization problem given the expected risk and return of each asset under a set of constraints can be done by solving a convex optimization problem of quadratic programs (QP) and second-order cone programs (SOCP). Although a single optimization problem is not time-consuming to solve, its current computational cost remains the most significant bottleneck when performing the simulations necessary for financial applications .

Indeed, inputs to the EF problem such as future expectations of asset returns, co-variances, and even simulated client preferences on asset allocation are stochastic (c.f. Table 1). Thus, one needs to repeatedly solve the optimal allocation problem under a large number of different scenarios and Monte Carlo (MC) simulations  are commonly used to estimate the expected reward over time. Given an allocation function \(g\) and stochastic input \(Z\), we need to compute \((g(Z))= g(z)f_{Z}(z)\,dz\) where \(f_{Z}\) is the density function of \(Z\). Sampling the empiric mean of \(g(Z)\) approximates \((g(Z))\) with a convergence rate of \((1/)\) where \(N\) denotesthe number of samples. The computational cost of this simulation is therefore influenced by the size of \(N\) and the cost of computing \(g\). In spite of the vast literature of variance reduction techniques [5; 17] and the use of low-discrepancy sampling methods [10; 21] that aim to reduce \(N\), the results of the simulation will be misleading if the assumptions are not valid, leaving the cost of running \(g(z)\) as the principal bottleneck. This makes it practically impossible to run multiple MC simulations on different candidate assumptions in real time unless significant computational resources are available. Applications that heavily depend on MC simulations of the EF problem like basket option derivatives pricing face this bottleneck because their valuation depends on accurate estimates of the expected returns \((R)\), portfolio volatility \((V)\) and/or allocations \((X)\). The roll-out of new regulatory frameworks for financial applications of the EF problem (e.g. portfolio management) requiring more rigorous testing of \((g(Z))\) further increases the minimal acceptable \(N\), exacerbating the need for speed [37; 3].

The core problem then becomes finding a way reduce the computational cost of \(g\), making it possible to run a large number of MC simulations in a few seconds [27; 25]. Accelerating the optimization on highly-parallel hardware like graphical processing units (GPUs) can accelerate some convex optimization problems [13; 44; 11; 12], but not enough to run MC simulation in real-time effectively. Instead of only exploiting hardware, others have proposed to approximate the optimization step using deep neural networks (DNNs) and infer the result directly [18; 28; 48; 19]. However, proposed approaches fall short since they fail to simultaneously satisfy the following key requirements: (**1**) they do not provide theoretical guarantees that their forecast is within the domain set by constraints, (**2**) they do not show that their results can be applied at large scale faster than the optimization itself, (**3**) they can't handle a variable amount of heterogeneous inequality constraints and optimization inputs, and, (**4**) they are not robust to discontinuous behavior of optimization problems.

This work addresses all the shortcoming of DNN-based approaches mentioned above. We propose NeuralEF, a DNN-based model to approximate the computation of the EF problem robustly. Our model is up to 615X times faster than the baseline convex optimization when used with hardware acceleration. It is able to handle a variable number of assets and inequality constraints with consistent accuracy. In particular, we introduce a dynamic greedy allocation module to respect the constraints robustly that is agnostic to the DNN architecture. The remainder of this paper is organized as follows. Section 2 describes the EF problem and presents related works on convex optimization acceleration. Section 3 introduces NeuralEF and its training methodology. Section 4 outlines our empirical evaluations on the EF optimization problem. Finally, section 5 presents our conclusions.

## 2 Background and Related Work

### The Efficient Frontier

We seek an optimal allocation \(=[x_{1}, x_{n}]\) over \(n\)_risky_ assets given a soft volatility target \(_{}\). This means a portfolio with higher achieved volatility than \(_{}\) is valid only if the resulting allocation has the minimum volatility that can be achieved on the feasible domain. Finding the optimal allocation maximizing portfolio return at a given volatility target is conditional on the assets' expected returns \(=[r_{1},,r_{n}]\), volatilities \(=[v_{1},,v_{n}]\), and correlations \(=[[_{1,1},,_{1,n}],,[_{n,1},_{n,n}]]\). Constraints that must be satisfied include upper and lower bounds on total allocation of _risky_ assets \(_{},_{}\)

Figure 1: Illustration of the EF problem. The optimal allocations are at the frontier of the plot where the expected returns is maximized for a level of volatility. The yellow dot denotes the best allocation for eq. 2 for \(_{}=0.06\). The location of the yellow dot will vary under different conditions, which can be approximated under different scenarios (\(Z\)) using MC simulations.

and a minimum and maximum asset allocation limit per asset \(_{}=[x_{1}^{},,x_{n}^{}]\), \(_{}=[x_{1}^{},,x_{n}^{}]\). As is typical in finance, assets can belong to a set of \(m\) classes \(=[c_{1},,c_{n}];c_{i}[1,,m]\), and allocations are subject to a class maximum \(_{}=[_{c_{1}},_{c_{m}}];_{x c_{ j}}x_{i}_{c_{j}}\). We denote the set of convex optimization inputs by \(_{}=[,,,_{},_{ },,_{},_{},_{ },_{},_{}]\) and the resulting allocation by \(_{}=(_{})\).

This problem is illustrated in fig. 1 using random allocations where the EF is located at the left-most frontier of the plots. We can find this frontier along a range of volatility targets by solving a two-step conditional convex optimization problem where we first find the optimal weights that minimizes risk in a portfolio of \(n\) assets subject to linear weight constraints and then maximize the return if the risk of the portfolio is below \(_{}\).

Finding this minimum variance portfolio is equivalent to solving a QP problem of the form

\[:=^{}_{i}^{}_{i}\;\; i 1, ,w,\] (1)

where \(^{n}\) is a column vector of weights representing the allocation, \(\) is the covariance matrix of the portfolio's assets, \(_{i}\) is a row vector representing the \(i\)-th linear constraint (obtained from \(_{},_{},_{},_{ },_{}\)) and \(_{i}\) is the maximum required value for the \(i\)-th constraint. The result of eq. 1 allows us to calculate the minimum volatility \(_{}=^{}\) that can be achieved on the feasible domain.

If the resulting portfolio risk \(_{}<_{}\), then we can afford to maximize portfolio return. In this case, the objective function of the first problem becomes one of the constraints of a SOCP problem of the form

\[:=-^{}^{} _{}_{i}^{}_{i} i 1, ,w.\] (2)

Thus, the efficient frontier can be summarized by

\[_{}=(_{})=_{}>_{}.\] (3)

The EF optimization is sensitive at inflection points where one asset becomes more attractive than another. All else held equal, an infinitesimal difference in expected returns can cause a jump in optimal allocation for all assets. Modeling the EF problem is challenging due to the presence of such discontinuities, which grows factorially (\((N!)\)) as the number of assets increases.

### Accelerating Convex Optimizations

The simplest way to speed up eq. 3 is to implement the solver for direct use with highly parallelizable hardware. This has been done using GPUs for various convex optimizations, particularly for large problems with numerous unknowns . In particular,  showed that solving numerous optimizations simultaneously in a single batch leads to significant speedup. We replicated this experiment by writing a vectorized implementation of the optimization of eq. 3 in Pytorch to solve multiple EF problems at once. We observed accelerations which are consistent with the order of magnitude achieved in these works, but not sufficient to allow the completion of a full simulation in a matter of few seconds unless the GPU used has high memory capacity (e.g. 40 GB).

Several works  embed differentiable optimization problems in DNNs, offering a solution to robustly approximate the EF problem including the handling of the inequality constraints in eq. 1 and eq. 2. Their approaches aim to solve a parameterized optimization problem ensuring a constrained layer's output to align with homogeneous linear inequality constraints established by \(_{}\). This is done either by solving the optimization problem during training , or when initializating the model . To support a heterogenous set of constraints, one would need to specify a set of linear inequality constraints ahead of time. This approach is impractical as it cannot generalize to unspecified sets of constraints.

Other existing supervised learning (SL) approaches to approximate convex optimization with DNNs do not provide the desired flexibility and robustness for large-scale generalization . They use a DNN that takes \(_{}\) as input and outputs \(_{}\), treating inequality constraints as soft during training. Reinforcement learning (RL) approaches like POMO  and PPO  have also been applied variable length input combinatorial optimization problems with high label retrieval complexity where their learned policy tries to reduce an optimally gap by measuring the regrets from the optimal allocation. These DNN approaches do not guarantee that predicted values remain within the feasible domain and are often unable to handle the changing dimensionality of \(_{}\) and \(_{}\) based on \(n\) and the set of constraints selected. Our proposed method addresses these issues, resulting in a fast and accurate approximation of the convex optimizer that respects constraints.

## 3 Neural Approximation of the Efficient Frontier

To approximate the computation of the QP and conditional SOCP optimization described in sec. 2.1, we use a stacked transformer encoder architecture  as shown in fig. 2. The principal idea behind NeuralEF is to consider the optimization problem as a sequence-to-sequence (SEQ2SEQ) problem  and use the self attention mechanism to consider the relationships between the optimization inputs when approximating eq. 3. Contrary to large language models (LLMs) that solve quantitative mathematical problem by parsing the problem using a mix of natural language and mathematical notation where a forecast is built using the same notation , our SEQ2SEQ formulation explicitly parse the whole optimization problem by considering the optimization input directly and forecasts the output in the solution domain. We setup the SEQ2SEQ problem such that the inputs are a set of tokens, each representing a single asset, and the outputs are a one dimensional sequence of the optimal allocation. To convert the optimization problem in eq. 3 to a sequence representation, we divide the optimization input parameters in two types of features: global optimization inputs (\(,_{},_{},_{},\,_{}\)) and asset specific inputs (\(,,_{},_{}, {C}\)). These features along with a sequence of asset identifier (\(n\) values evenly spaced within \(\)) are used to rearrange the optimization input parameters into a set of vectors and are linearly projected into higher dimensional

Figure 3: Illustration with two assets of the domain output space that the dynamic greedy allocation rebalancing module will enforce. The output domain is highlighted by the cross hatch patterns and the constraints are highlighted by the red lines.

Figure 2: Illustration of the Transformer Encoder architecture of NeuralEF. On the left side the projection to a sequence representation from the optimization inputs considering 3 assets is shown as an example.

[MISSING_PAGE_FAIL:5]

We generated two test datasets \(_{}\), \(_{}\) of 1 million samples each on the the same domain as the training set described in table 1. All synthetic datasets mimic real-life distributions for the volatility and correlation inputs, encompassing area of the optimization domain around the discontinuity areas. Around 84% of the test samples feature at least two optimization inputs within \(\) proximity of each other to target discontinuity areas of eq. 3. This synthetic data allows for precise control over optimization inputs and encompasses a broad spectrum of scenarios, ranging from extreme to real-world cases targeting mainly the discontinuity regions. Consequently, it facilitates a comprehensive evaluation of the model's performance across various settings. All datasets have varying numbers of assets and asset classes, and include two allocation scenarios: full allocation (\(_{}=_{}=1\)) and partial allocation (\(_{}>_{}\)) where there is no obligation to allocate the full budget. Only valid optimization inputs \(_{}\), i.e. where \((_{})\) does not fail because of numerical difficulties in the solver or that no solution exists, where considered.

NeuralEF is a 7.9M parameter DNN and was trained on a single NVIDIA A100 GPU with stochastic gradient descent using the AdamW optimizer  and the \(L^{2}\) loss. We also used an annealing learning rate decay starting from \(5.5e^{-5}\) to \(1.0e^{-6}\). As stated in sec. 2, we also implemented a baseline EF optimization in PyTorch that we used solely for comparing the evaluation throughput (evaluations/seconds) between NeuralEF over the base pricer which was implemented using CVXOPT . The hyperparameters of NeuralEF are described in table. 2 and were selected by estimated guesses from the accuracy measured on \(_{}\).

### In-domain Interpolation

  
**Feature** & **Range** & **Feature** & **Range** \\  (\(_{}\)) volatility target & \([0.05,0.15]\) & (\(\)) volatility & \(\) \\ (\(\)) Correlation matrix & [-1, 1] & (\(\)) returns & [-1,2] \\ (\(_{}\)) maximum class allocation & [ 0.2, 1.0] & (\(wt_{}\)) maximum asset allocations & [0.01, 1.0] \\ (\(_{}\)) Allocation lower bound & [0.6, 1.0] & (\(_{}\)) Allocation upper bound & 1.0 \\ (\(n\)) Number of asset sampled &  & (\(m\)) Possible class &  \\   

Table 1: Input Domain of optimization input used for training.

  
**Name** & **Value** & **Name** & **Value** \\  Token dimension & 320 & (D) Transformer depth & 8 \\ Transformer \# heads & 8 & Transformer heads dimension & 32 \\ Feed forward projection & 1024 & Output activation & Sigmoid \\ Embedding method &  & Hidden activation & Swish  \\   

Table 2: HyperParameters of NeuralEF. Adjusting accuracy at the expense of throughput can be easily done by increasing the token dimension.

Figure 4: Cumulative distributions of the sum of absolute allocation error of allocations and portfolio returns per number of assets

We assess NeuralEF's accuracy by measuring its ability to predict portfolio weights, returns and volatility on \(_{}\). We use Mean square error (MSE), mean absolute error (MAE), and quantiles to evaluate the error distribution for portfolios with varying numbers of assets. Additionally, we test NeuralEF's precision in ranking asset importance in the allocation, check the precision of our model to forecast volatility (\(_{}=_{output}^{}_{output} max (_{},_{})\)), and check for feasibility of violating constraints. Table 3 summarizes the accuracy results for different numbers of assets considered. Overall, NeuralEF shows accurate performance on portfolio weight prediction with slight deviations only in the higher upper quantiles for all asset cases. The model also demonstrates a high level of accuracy on returns and volatility. The ability to rank assets in order of importance correlates with the ability to respect constraints not captured by DGAR. The optimality gap metrics (ranking precision, \(_{}\) and \(_{}\)) are by design highly sensitive to a slight \(\) deviation, which in practice wouldn't necessarily be impactful. However, this limitation is to be considered when considering NeuralEF in safety-critical scenarios. NeuralEF can easily be applied within MC simulations that targets \((R)\), \((V)\), and/or \((x)\) as failure to respect the unsupported constraints does not necessarily lead to large error on the allocation. With a sufficiently large \(N\), these errors do not impact the derived distributional features of \((g(Z))\).

We plot the error distribution per asset by displaying the cumulative distribution of the sum error for all \(x_{1},,x_{n}\), the absolute error on the expected return and the portfolio volatility in Fig. 4. The total weight allocation error does not exceed 1% total deviation in around 98% of cases, but the impact on the resulting returns and volatility is only noticeable in 1% of cases. From the remaining tail exceeding the 1% total deviation, we measured no case violating the volatility constraint and only 8% exceeded the class constraint. The source of these errors was mainly found in regions with abrupt changes in the allocation due to the nature of the optimization.

NeuralEF accurately captures the qualitative behavior of the optimization in discontinuous regions, but instability in these areas exposes a weakness of approximating function with discontinuous behavior using DNNs. We illustrate this behavior using one example from the 99.997th quantile worst predictions of \(_{}\), where we vary a single input parameter (\(r_{10}[-1.0,2.0]\)) while keeping the others constant, in Fig. 5. NeuralEF approximates discontinuities for most assets accurately, and errors on the portfolio returns are often attributed to ranking failure when NeuralEF transitions through these discontinuities. At the expense of always respecting constraints, DGAR can spread forecast errors to other assets with a poor \(\) ordering leading to a larger absolute error in the resulting forecast than not using DGAR. Despite some assets not being modeled properly, we observe often that for practical purposes, this doesn't impact the resulting portfolio return or the portfolio

   Asset case & Vertofolio weights & MSE & Vertofolio weights & MAE & 95 & quadratic & 99.997 quantile & Ranking precision \\ 
1 & 2.56-0.06 & 1.10-0.01 & 1.20-0.01 & 1.30-0.02 & 1.40-0.01 & 9.11-0.01 & 9.11-0.01 \\
2 & 2.56-0.06 & 3.57-0.06 & 1.50-0.02 & 1.30-0.02 & 1.30-0.01 & 9.96-0.01 \\
3 & 8.80-0.07 & 6.00-0.01 & 1.46-0.02 & 4.75-0.02 & 1.30-0.01 & 9.42-1.7 \\
4 & 2.56-0.06 & 1.38-0.01 & 1.40-0.02 & 4.56-0.02 & 1.50-0.01 & 9.56-1.57 \\
5 & 1.56-0.02 & 1.20-0.01 & 1.46-0.02 & 4.18-0.01 & 1.50-0.01 & 9.56-0.02 \\
6 & 1.56-0.02 & 1.20-0.01 & 1.46-0.02 & 4.48-0.02 & 1.50-0.01 & 9.56-0.02 \\
7 & 1.56-0.02 & 1.20-0.01 & 1.46-0.02 & 4.48-0.02 & 1.50-0.01 & 9.56-0.01 \\
8 & 1.56-0.02 & 1.20-0.01 & 1.46-0.02 & 4.48-0.02 & 1.50-0.01 & 9.56-0.01 \\
9 & 1.56-0.02 & 1.20-0.01 & 1.46-0.02 & 4.77-0.02 & 1.50-0.01 & 84.56-0.02 \\
10 & 1.17-0.02 & 1.20-0.02 & 5.20-0.02 & 5.20-0.01 & 1.10-0.01 & 3.51-0.01 \\
11 & 1.21-0.01 & 1.70-0.02 & 1.20-0.02 & 5.34-0.02 & 2.30-0.01 & 80.00-0.03 \\
12 & 1.66-0.08 & 1.00-0.01 & 1.36-0.02 & 4.30-0.02 & 1.40-0.01 & 7.56-0.01 \\    &  &  &  &  \\ 
2 & 2.56-0.06 & 1.00-0.02 & 1.20-0.01 & 1.20-0.01 & 1.50-0.01 & 10.00-0.01 \\
1 & 8.56-0.06 & 2.00-0.01 & 1.20-0.01 & 1.20-0.01 & 1.20-0.01 & 9.15-0.01 \\
4 & 5.26-0.06 & 1.70-0.01 & 1.45-0.02 & 4.00-0.02 & 1.20-0.

volatility, as illustrated in fig. 6 (a-b). An ablation study motivating the different NeuralEF's components is presented in sec. C.2

### Throughput Evaluation and Carbon Footprint Impact

We report a significant acceleration in the performance of NeuralEF compared to the single-tread baseline optimizer, with a 623X time improvement on a CPU (AMD 5950X achieving 559 eval./s). The main factors contributing to this improvement are running multiple optimizations in batches, the smaller computational cost of inferring the result compared to numerically solving the optimization using an interior-point solver, and the use of half-precision floating-point format4. We demonstrate the scalability of NeuralEF on fig. 7 for

Figure 5: Illustration of the behavior NeuralEF at discontinuous points of the optimization. The unstable regions on the allocation occurs where \(r_{10}[0,0.5]\). All assets change allocation either smoothly through that region or suddenly by a jump discontinuity.

Figure 6: Impact of the inflection point prediction failure using the same prediction shown in fig. 5 on the estimated return and volatility respectively (a,b). EF numerical calculation throughput per concurrent process and its emissions in kgCO\({}_{2}\)e/kWh (c). Emissions presented are for computing 1000 evaluations per concurrent process and are scaled by a factor of 1e3.

Figure 7: Throughput of the vectorized EF version on GPU (left), NeuralEF in FP16-precision (middle) and NeuralEF in FP32 precision (right) by batch size compared to the single-thread and multi-thread pricer.

both GPUs and CPUs as well as the impact of the different components. The highest achieved throughput are presented on table. 4.

Parallelizing the execution on CPU through concurrent processes of the base pricer can increase throughput, but the scaling ability of this approach is inferior to NeuralEF. Fig. 7 (c) shows that the throughput scales linearly with the number of cores until the concurrent processes saturate the CPU usage and prevent further speedup. Considering the AMD 5950X CPU as an example, we achieved a maximum throughput of 10377.80 eval./sec. 5. It would take 26.77 hours to generate a billion evaluations, whereas it would only take 41 minutes or 1.25 hours with NeuralEF respectively on a A100 or on two ISR chips. When accelerated on GPU, impractical large batch sizes are needed to compete with a concurrent CPU setup. Pytorch-EF needs batches of 1.2 million request to reach a maximum throughput of 111479 eval./sec. In comparison, NeuralEF can achieves 343760 eval./sec. using batch size of 80k request. From an ease of use standpoint, the accelerated throughput of NeuralEF on a few devices is more running multiple machines to achieve the same throughput on CPU or having to deal with large batch size in practice. The scaling advantage of NeuralEF also offer an avenue to reduce the carbon footprint of large-scale simulations.

NeuralEF is less environmentally impactful than running the same optimization on CPU. For a single AMD Ryzen 9, if we consider the total time to generate our training dataset of 1 billion EF optimizations, the total simulation on CPU would approximate to 1.39 kgCO\({}_{2}\)e. Increasing the throughput by running concurrent processes increases the CO\({}_{2}\) emission on the chip as it requires more energy as show in fig. 6 (c). Training NeuralEF is more environmentally expensive due to a cumulative 336 hours of computation on a single A100 GPU with an AMD server-grade CPU server resulting in approximately 5.71 kgCO\({}_{2}\)e. At inference, the total emissions for forecasting a billion EF optimization using NeuralEF is estimated to be 0.03 kgCO\({}_{2}\)e6. Hence, we can offset the total cost of training NeuralEF by running approximately 4.20 billions evaluations. Since MC error converges as \((1/)\), one could get a 4x more precise approximation to \((g(Z))\) with NeuralEF in the time it would takes to obtain \(N\) simulations on a single CPU. Given that the EF problem is a cornerstone

 
**A100:** & **Throughput (eval./sec.)** & **2080T:** & **Throughput (eval./sec.)** \\ Pytorch-EF & 11479.39 & Pytorch-EF & (26452.06 \\ NeuralEF (f932) & 12950.36 & NeuralEF (f912) & 3781.05 \\ NeuralEF (f916) & 34750.77 & NeuralEF (f916) & 107259.29 \\ NeuralEF (f916) clean-only & 36982.09 & NeuralEF (f916) clean-only & 114106.05 \\ NeuralEF (f916) no preprocessing & 401641.81 & NeuralEF (f916) no preprocessing & 118711.91 \\
**Intel Xeon Platinum 8480+ (ISR)** & **3090:** & **Throughput (eval./sec.)** \\ NeuralEF (f932) & 56930.39 & Pytorch-EF & 41052.53 \\ NeuralEF (f916 + AMX) & 221787.48 & NeuralEF (f912) & 77859.95 \\
**AMD 5950X (reference)** & **NeuralEF (f916) clean-only** & 167934.15 \\ single-addX & 559:15 & NeuralEF (f916) clean-only & 173388.66 \\ Concurrent processes (23) & 10377.80 & NeuralEF (f916) no preprocessing & 170650.62 \\  

Table 4: Maximum average throughput achieved. Note that two Intel Xeon Platinum 8480 CPUs were used simultaneously on a dual-socket machine to achieve the best throughput.

Figure 8: Scalability of DGAR throughput by number of assets and batch size.

of multiple applications in finance, 4.20 billions evaluations is easily offset in less than a week by a single organization.

### Out-of-domain Generalization

The generalization ability of our model was measured by testing it on a larger input domain on a new dataset \(_{}\) of 1 million samples using the same domain as in \(_{}\), but instead considering \(_{}[0.01,0.3]\), \(\), \(_{}[0.2,1.0]\). The accuracy of the model degrades significantly on the tail of the distribution, especially for larger asset cases, indicating that it is not recommended to use NeuralEF outside the training domain. However, scale invariance in eq. 3 when all returns have the same sign (e.g., \(=[0.3,0.4,0.5][3.3,3.4,3.5]\)), allows the model to accurately estimate optimization even with returns outside the training domain by rescaling \(\) by \(\) such that they fit within the training domain. One can revert to the base optimization in the rare cases that it goes out of the domain, e.g. where assets go above 200% returns or the 200% volatilities, both being highly unlikely cases. Otherwise, one can always train NeuralEF on a bigger domain than table. 1 with most likely more data. Because NeuralEF has been trained on synthetic data, we haven't observed behavior bias that arises directly from certain regime aside in cases where assets would oscillate in the inflection area of the optimization, i.e. when two "attractive" assets have returns/volatilities \(\) close to each other and/or near 0 across a prolonged period of time.

## 5 Conclusion and Broader Impacts

In this work we introduce NeuralEF, a fast DNN-based model that approximates the solution of a convex optimization problem by treating it as a SEQ2SEQ problem. Using the Efficient Frontier, a highly discontinuous resource allocation problem, we demonstrate NeuralEF's accuracy and its ability to handle variable-length input optimization parameters while robustly respecting linear constraints by means of a novel dynamic greedy allocation rebalancing module. This positions NeuralEF as an attractive solution to reduce the computational footprint of running large scale simulations and offers a practical means to accelerate convex optimization problems in application that rely on MC simulation such as securities pricing, portfolio management and valuation of unit-linked insurance policies .

More importantly, our reformulation of convex optimization as SEQ2SEQ offers a tangible step towards solving quantitative mathematical problems efficiently with DNNs . Whether it is easier to expedite optimization problems with heterogeneous constraints though a RL training paradigm  or a SL paradigm like done with NeuralEF hinges on additional experimental insights. However, we know that current LLMs struggle to solve hard mathematical tasks  and simply scaling them is impractical for achieving strong mathematical reasoning . Converting a quantitative mathematical problem into a sequence representation and then forecasting the results presents a more practical approach than solving it directly. This conceptually separate reasoning, i.e. how to formulate a mathematical problem given some inputs using a LLM, and solving it as two independent learning tasks that can be combined at inference.

Figure 9: Cumulative distributions of the sum of absolute allocation error of allocations and portfolio returns per number of assets for \(_{}\)