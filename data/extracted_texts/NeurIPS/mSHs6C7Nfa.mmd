# Improving the Training of Rectified Flows

Sangyun Lee

Carnegie Mellon University

sangyunl@andrew.cmu.edu

&Zinan Lin

Microsoft Research

zinanlin@microsoft.com

&Giulia Fanti

Carnegie Mellon University

gfanti@andrew.cmu.edu

###### Abstract

Diffusion models have shown great promise for image and video generation, but sampling from state-of-the-art models requires expensive numerical integration of a generative ODE. One approach for tackling this problem is rectified flows, which iteratively learn smooth ODE paths that are less susceptible to truncation error. However, rectified flows still require a relatively large number of function evaluations (NFEs). In this work, we propose improved techniques for training rectified flows, allowing them to compete with _knowledge distillation_ methods even in the low NFE setting. Our main insight is that under realistic settings, a single iteration of the Reflow algorithm for training rectified flows is sufficient to learn nearly straight trajectories; hence, the current practice of using multiple Reflow iterations is unnecessary. We thus propose techniques to improve one-round training of rectified flows, including a U-shaped timestep distribution and LPIPS-Huber premetric. With these techniques, we improve the FID of the previous 2-rectified flow by up to 75% in the 1 NFE setting on CIFAR-10. On ImageNet 64\(\)64, our improved rectified flow outperforms the state-of-the-art distillation methods such as consistency distillation and progressive distillation in both one-step and two-step settings and rivals the performance of improved consistency training (iCT) in FID. Code is available at https://github.com/sangyun884/rfpp.

## 1 Introduction

Diffusion models (Sohl-Dickstein et al., 2015; Ho et al., 2020; Song and Ermon, 2019; Song et al., 2020) have shown great promise in image (Ramesh et al., 2022) and video (Ho et al., 2022) generation. They generate data by simulating a stochastic denoising process where noise is gradually transformed into data. To sample efficiently from diffusion models, the denoising process is typically converted into a counterpart of Ordinary Differential Equations (ODEs) (Song et al., 2020) called probability flow ODEs (PF-ODEs).

Despite the success of diffusion models using PF-ODEs, drawing high-quality samples requires numerical integration of the PF-ODE with small step sizes, which is computationally expensive. Today, two prominent classes of approaches for tackling this issue are: (1) knowledge distillation (e.g., consistency distillation (Song et al., 2023), progressive distillation (Salimans and Ho, 2022)) and (2) simulation-free flow models (e.g., rectified flows (Liu et al., 2022), flow matching (Lipman et al., 2022)).

In knowledge distillation-based methods (Luhman and Luhman, 2021; Salimans and Ho, 2022; Song et al., 2023; Zheng et al., 2022) a student model is trained to directly predict the solution of the PF-ODE. These models are currently state-of-the-art in the low number of function evaluations (NFEs) regime (e.g. 1-4).

Another promising direction is simulation-free flow models such as rectified flows (Liu et al., 2022; Liu, 2022), a generative model that learns a transport map between two distributions defined via neural ODEs. Diffusion models with PF-ODEs are a special case. Rectified flows can learn smoothODE trajectories that are less susceptible to truncation error, which allows for high-quality samples with fewer NFEs than diffusion models. They have been shown to outperform diffusion models in the moderate to high NFE regime (Lipman et al., 2022; Liu et al., 2022; Esser et al., 2024), but they still require a relatively large number of NFEs compared to distillation methods.

Compared to knowledge distillation methods (Luhman and Luhman, 2021; Salimans and Ho, 2022; Song et al., 2023; Zheng et al., 2022) rectified flows have several advantages. First, they can be generalized to map two arbitrary distributions to one another, while distillation methods are limited to a Gaussian noise distribution. Also, as a neural ODE, rectified flows naturally support _inversion_ from data to noise, which has many applications including image editing (Hertz et al., 2022; Kim et al., 2022; Wallace et al., 2023; Couairon et al., 2022; Mokady et al., 2023; Su et al., 2022; Hong et al., 2023) and watermarking (Wen et al., 2023). Further, the likelihood of rectified flow models can be evaluated using the instantaneous change of variable formula (Chen et al., 2018), whereas this is not possible with knowledge distillation-based methods. In addition, rectified flows can flexibly adjust the balance between the sample quality and computational cost by altering NFEs, whereas distillation methods either do not support multi-step sampling or do not necessarily perform better with more NFEs (e.g. \(>4\)) (Kim et al., 2023).

Given the qualitative advantages of rectified flows, a natural question is, **can rectified flows compete with distillation-based methods such as consistency models (Song et al., 2023) in the low NFE setting?** Today, the state-of-the-art techniques for training rectified flows use the _Reflow_ algorithm to improve low NFE performance (Liu et al., 2022, 2023). Reflow is a recursive training algorithm where the rectified flow is trained on data-noise pairs generated by the generative ODE of the previous stage model. In current implementations of Reflow, to obtain a reasonable one-step generative performance, Reflow should be applied at least twice, followed by an optional distillation stage to further boost performance (Liu et al., 2022, 2023). Each training stage requires generating a large number of data-noise pairs and training the model until convergence, which is computationally expensive and leads to error accumulation across rounds. Even with these efforts, the generative performance of rectified flow still lags behind the distillation methods such as consistency models (Song et al., 2023).

We show that **rectified flows can indeed be competitive with the distillation methods in the low NFE setting by applying Reflow with our proposed training techniques**. Our techniques are based on the observation that under realistic settings, the linear interpolation trajectories of the pre-trained rectified flow rarely intersect with each other. This provides several insights: 1) applying Reflow once is sufficient to obtain straight-line generative ODE in the optima, 2) the training loss of 2-rectified flow has zero lower bound, and 3) other loss functions than the squared \(_{2}\) distance can be used during training. Based upon this finding, we propose several training techniques to improve Reflow, including: (1) a U-shaped timestep distribution, (2) an LPIPS-huber premetric, which we find to be critical for the few-step generative performance. After being initialized with pre-trained diffusion models such as EDM (Karras et al., 2022), our method only requires one training stage without additional Reflow or distillation stages, unlike previous works (Liu et al., 2022, 2023).

Our evaluation shows that on several datasets (CIFAR-10 (Krizhevsky et al., 2009), ImageNet 64\(\)64 (Deng et al., 2009)), our improved rectified flow outperforms the state-of-the-art distillation methods such as consistency distillation (CD) (Song et al., 2023) and progressive distillation (PD) (Salimans and Ho, 2022) in both one-step and two-step settings, and it rivals the performance of the improved consistency training (iCT) (Song et al., 2023) in terms of the Frechet Inception Distance (Heusel et al., 2017) (FID). Our training techniques **reduce the FID of the previous 2-rectified flow (Liu et al., 2022) by about \(75\%\)** (\(12.21 3.07\)) on CIFAR-10. Ablations on three datasets show that the proposed techniques give a consistent and sizeable gain. We also showcase the qualitative advantages of rectified flow such as few-step inversion, and its application to interpolation and image-to-image translation.

## 2 Background

### Rectified Flow

Rectified flow (see also flow matching (Lipman et al., 2022) and stochastic interpolant (Albergo and Vanden-Eijnden, 2022)) is a generative model that smoothly transitions between two distributions \(p_{}\) and \(p_{}\) by solving ODEs (Liu et al., 2022). For \( p_{}\) and \( p_{}\), we define the interpolation between \(\) and \(\) as \(_{t}=(1-t)+t\) for \(t\). Liu et al. (2022) showed that for \(_{0} p_{}\), the following ODE yields the same marginal distribution as \(_{t}\) for any \(t\):

\[_{t}}{dt}=_{t}(_{t}):=( _{t}-[|_{t}=_{t}]).\] (1)

Since \(_{1}=\), Eq. (1) transports \(p_{}\) to \(p_{}\). We can also transport \(p_{}\) to \(p_{}\) by drawing \(_{1}\) from \(p_{}\) and solving the ODE backwards from \(t=1\) to \(t=0\). During training, we estimate the conditional expectation \([|_{t}=_{t}]\) with a vector-valued neural network \(_{}\) trained on the squared \(_{2}\) loss:

\[_{}_{, p_{ }}_{t p_{t}}[(t)||-_{ }(_{t},t)||_{2}^{2}],\] (2)

where \(p_{}\) is the joint distribution of \(\) and \(\), \(_{}\) is parameterized by \(\), and \((t)\) is a weighting function. \(p_{t}\) is chosen to be the uniform distribution on \(\) in Liu et al. (2022, 2023). In the optimum of Eq. (2), \(_{}\) becomes the conditional expectation as it is a minimum mean squared error (MMSE) estimator, which is then plugged into the ODE (1) to generate samples. Instead of predicting the conditional expectation directly, Liu et al. (2022) choose to parameterize the velocity \(_{t}\) with a neural network \(_{}\) and train it on

\[_{}_{, p_{}}_{t p_{t}}[||(-)-_{ }(_{t},t)||_{2}^{2}],\] (3)

which is equivalent to Eq. (2) with \((t)=}\). See Appendix. A.

In this paper, we consider the Gaussian marginal case, i.e., \(p_{}=(,)\). In this case, if we define \(\) and \(\) as independent random variables (i.e., \(p_{}(,)=p_{}()p_{ }()\)) and use a specific nonlinear interpolation instead of the linear interpolation for \(_{t}\), Eq. (2) becomes the weighted denoising objective of the diffusion model (Vincent, 2011), and Eq. (1) becomes the probability flow ODE (PF-ODE) (Song et al., 2020b).

### Reflow

```
1:First iteration:
2:\(_{1}=_{}_{,  p_{}^{0}}_{t p_{t}}[(t) \|-_{}(_{t},t)\|_{2}^{2}]\)\(\) Train 1-rectified flow
3:for\(k=1\) to \(K-1\)do
4:\(T^{k}()=+_{1}^{0}(_{t}- _{_{k}}(_{t},t))dt\) with \(_{1}=\)
5:\(p_{}^{k}(,)=p_{}()(-T^{k}())\)\(\) Generate synthetic pairs for next coupling
6:\(_{k+1}=_{}_{,  p_{}^{k}}_{t p_{t}}[ (t)\|-_{}(_{t},t)||_{ 2}^{2}]\)\(\) Train \((k+1)\)-rectified flow
7:endfor ```

**Algorithm 1** Reflow Procedure

The independent coupling \(p_{}(,)=p_{}()p_{ }()\) is known to lead to curved ODE trajectories, which require a large number of function evaluations (NFE) to generate high-quality samples (Pooladian et al., 2023; Lee et al., 2023). Reflow (Liu et al., 2022) is a recursive training algorithm to find a better coupling that yields straighter ODE trajectories. Starting from the independent coupling \(p_{}^{0}(,)=p_{}() p_{}()\), the Reflow algorithm generates \(p_{}^{k+1}(,)\) from \(p_{}^{k}(,)\) by first

Figure 1: Rectified flow process (figure modified from Liu et al. (2022)). Rectified flow rewires trajectories so there are no intersecting trajectories \((a)(b)\). Then, we take noise samples from \(p_{}\) and their generated samples from \(p_{}^{1}\), and linearly interpolate them \((c)\). In Reflow, rectified flow is applied again \((c)(d)\) to straighten flows. This procedure is repeated recursively.

generating synthetic \((,)\) pairs from \(p^{k}_{}\), then training rectified flow on the generated synthetic pairs (Figure 1\((b)-(d)\)). We call the vector field resulting from the \(k\)-th iteration of this procedure \(k\)-rectified flow. Pseudocode for Reflow is provided in Algorithm. 1.

**Convergence:**Liu et al. (2022) show that Reflow trajectories are straight in the limit as \(K\). Hence, to achieve perfectly straight ODE paths that allow for accurate one-step generation, Reflow may need to be applied many times until equilibrium, with each training stage requiring many data-noise pairs, training the model until convergence, and a degradation in generated sample quality.

**Prior work has empirically found that Reflow should be applied at least twice** (i.e. \(3\)-rectified flow) for reasonably good one-step generative performance (Liu et al., 2022, 2023). This has been a major downside for rectified flows compared to knowledge distillation methods, which typically require only one distillation stage (Luhman and Luhman, 2021; Song et al., 2023; Zheng et al., 2022).

## 3 Applying Reflow Once is Sufficient

In this section, we argue that under practical settings, the trajectory curvature of the optimal 2-rectified flow is actually close to zero. Hence, prior empirical results requiring more rounds of Reflow may be the result of suboptimal training techniques, and we should focus on improving those training techniques rather than stacking additional Reflow stages.

First, note that the curvature of the optimal 2-rectified flow is zero if and only if the linear interpolation trajectories of 1-rectified flow-generated pairs do not intersect, or equivalently, \([|_{t}=(1-t)^{}+t^{ }]=^{}\) for all pairs \((^{},^{})\)(Liu et al., 2022).

To begin with, consider the manifold \(_{}\) of the synthetic distribution \(p^{1}()= p^{1}(,)d\). Consider two points \(^{}\) and \(^{}\) from the manifold, and two noises \(^{}\) and \(^{}\) that are mapped to \(^{}\) and \(^{}\) by 1-rectified flow. Here, we say two pairs \((^{},^{})\) and \((^{},^{})\) intersect if \( t\) s.t. \((1-t)^{}+t^{}=(1-t)^{} +t^{}\). For example, in Figure 2(a), we observe that the two trajectories intersect at an intermediate \(t\).

For an intersection to exist at \(t\) it must hold that 1) 1-rectified flow maps \(^{}\) to \(^{}\), and 2) \(^{}=^{}+(^{} -^{})\) by basic geometry. However, note that for realistic data distributions and if

Figure 2: An illustration of the intuition in Sec. 3. (a) If two linear interpolation trajectories intersect, \(^{}-^{}\) is parallel to \(^{}-^{}\). This generally maps \(^{}\) to an atypical (e.g., one with high autocorrelation or a norm that is too large to be on a Gaussian annulus) realization of Gaussian noise, so the 1-rectified flow cannot reliably map \(^{}\) to \(^{}\) on \(_{}\). (b) Generated samples from the pre-trained 1-rectified flow starting from \((,)\) (_right_), which is the standard setting, and \(^{}=+(^{}-^{ })\), where \(^{},^{}\) are sampled from 1-rectified flow trained on CIFAR-10 (_left_). Qualitatively, we see that the left samples have very low quality. (c) Empirically, we show the \(_{2}\) norm of \(z^{}=+(^{}-^{})\) compared to \(z^{}\), which is sampled from the standard Gaussian. \(^{}\) generally lands outside the annulus of typical Gaussian noise. (d) \(+(^{}-^{})\) has high autocorrelation while the autocorrelation of Gaussian noise is nearly zero in high-dimensional space.

1-rectified flow is sufficiently well-trained, \(^{}=^{}+(^{}- ^{})\) is not a common noise realization (e.g., it is likely to have nonzero autocorrelation or a norm that is too large to be on a Gaussian annulus), as shown visually in Figure 2(a). As 1-rectified flow is almost entirely trained on common Gaussian noise inputs, it cannot generally map an atypical \(^{}\) to \(_{}\). Figure 2(c) shows qualitatively that if we draw values of \(^{}\) by first drawing \(^{}(0,I)\) and then adding \((^{}-^{})\) for independent draws of \(^{}\), \(^{}\), the \(^{}\) vectors fall outside the annulus of typical standard Gaussian noise. Similarly, Figure 2(d) shows that the constructed noise vectors \(^{}\) have higher autocorrelation than expected. As a result, Figure 2(b) visually shows that the generated samples have little overlap with the expected samples from typical draws of \(^{}\).

This suggests empirically that when training 2-rectified flow, intersections are rare (i.e. \([|_{t}=(1-t)^{}+t^{ }]^{}\)), which in turn implies that the optimal 2-rectified flow trajectories are nearly straight. Hence, additional rounds of Reflow are unnecessary, while also degrading sample quality. This intuition allows us to focus on better training techniques for 2-rectified flow rather than training 3- or 4-rectified flow. It also leads us to several improved techniques, discussed in Sec. 4.

**Edge cases:** Note that if \(||^{}-^{}||_{2}\) is small, 1-rectified flow could map \(^{}\) to some point on \(_{}\). However, it does not alter the conclusion because the average of \(^{}\) and \(^{}\) is close to \(^{}\) anyway, so \([|_{t}=(1-t)^{}+t^{ }]^{}\). Similarly, if \(t\) is close to 1, \((^{}-^{})\), so 1-rectified flow can map \(^{}\) to \(_{}\). If the 1-rectified flow is \(L\)-Lipschitz, \(||^{}-^{}||_{2} L||^{ }-^{}||_{2}\). Therefore, the expectation \([|_{t}]\) again will not deviate much from \(^{}\).

## 4 Improved Training Techniques for Reflow

The observation in Sec. 3 suggests that the optimal 2-rectified flow is nearly straight. Therefore, if the one-step generative performance of the 2-rectified flow model is not as good as expected, it is likely due to suboptimal training. In this section, we show that the few-step generative performance of the 2-rectified flow can be significantly improved by applying several new training techniques.

### Timestep distribution

As in diffusion models, rectified flows are trained on randomly sampled timesteps \(t\), and the distribution from which \(t\) is sampled is an important design choice. Ideally, we want to focus the training effort on timesteps that are more challenging rather than wasting computational resources on easy tasks. One common approach is to focus on the tasks where the training loss is high (Shrivastava et al., 2016). However, the training error of rectified flows is not a reliable measure of difficulty because different timesteps have different non-zero lower bounds. To understand this, let us decompose the training error into two terms:

\[(,t):=}[||- _{}(_{t},t)||_{2}^{2}]=}[||-[|_{t}]| |_{2}^{2}]}_{}+}(,t).\] (4)

The first term does not depend on \(\) and thus cannot be reduced. The second term represents the actual minimizable training error, but its value cannot be directly observed because the first term is usually unknown. Fortunately, because of the finding in Sec. 3, we expect that the first term is nearly zero when training 2-rectified flow, so we can use \((,t)\) for designing the timestep distribution.

Figure 3 shows that the training loss of 2-rectified flow is large at each end of the interval \(t\) and small in the middle. We thus propose to use a U-shaped timestep distribution for \(p_{t}\). Specifically, we define \(p_{t}(u)(au)+(-au)\) on \(u\). We find that \(a=4\) works well in practice (Table 1). Compared to the uniform timestep distribution (config B), the U-shaped distribution (config C) improves

Figure 3: Training loss of the vanilla 2-rectified flow on CIFAR-10 measured on \(5,000\) samples after \(200,000\) iterations. The shaded area represents the 1 standard deviation of the loss. The dashed curve is our U-shaped timestep distribution, scaled by a constant factor for visualization.

the FID of 2-rectified flow from \(7.14\) to \(5.17\) (a \(28\%\) improvement) on CIFAR-10, \(12.39\) to \(9.03\) (\(27\%\)) on AFHQ, and \(8.84\) to \(6.81\) (\(23\%\)) on FFHQ in the one-step setting.

For 1-rectified flow training, \(p_{t}\) was chosen to be the uniform distribution (Liu et al., 2022, 2023) or logit-normal distribution (Esser et al., 2024) which puts more emphasis on the middle of the interval. When training 1-rectified flow, a model learns to simply output the dataset average when \(t=1\) and the noise average (i.e., zero) when \(t=0\). The meaningful part of the training thus happens in the middle of the interval. In contrast, from Eq. (3) we can see that 2-rectified flow learns to directly predict the data from the noise at \(t=1\) and the noise from the data at \(t=0\), which are nontrivial tasks. Therefore, the U-shaped timestep distribution is more suitable for 2-rectified flow.

### Loss function

Previously, the squared \(_{2}\) distance was used as the training metric for rectified flow to obtain the MMSE estimator \([|_{t}]\). However, as we have shown in Sec. 3 that \([|_{t}=(1-t)^{}+t^{ }]^{}\), we can generalize Eq. (2) or equivalently Eq. (3) to any premetric \(m\) (i.e. \(m(,)=0=\)):

\[_{}_{, p_{}}_{t p_{t}}[m(-,_{}(_{t},t))],\] (5)

Note that **without the intuition in Sec. 3, only the squared \(_{2}\) distance would have been a valid premetric**, as any other premetric makes the model deviate from the intended optimum (the posterior expectation \([|_{t}]\)). Although the choice of \(m\) does not affect the optimum, it does affect the training dynamics and thus the obtained model. Other than the squared \(_{2}\) distance, we consider the following premetrics:

* Pseudo-Huber (Charbonnier et al., 1997; Song and Dhariwal, 2023): \(m_{}(-,_{}(( _{t},t))=--_{}(_{t},t)||_{2}^{2}+c^{2}}-c\), where \(c=0.00054d\) with \(d\) being data dimensionality.
* LPIPS-Huber: \(m_{}(-,_{}( _{t},t))=(1-t)m_{}(-,_{ }(_{t},t))+(,_{t }-t_{}(_{t},t))\), where LPIPS\((,)\) is the learned perceptual image patch similarity (Zhang et al., 2018).
* LPIPS-Huber-\(\): \(m_{,}(-,_{}(_{t},t))=(1-t)m_{}(-,_{}(_{t},t))+(, _{t}-t_{}(_{t},t))\),

The Pseudo-Huber loss is less sensitive to the outliers than the squared \(_{2}\) loss, which can potentially reduce the gradient variance (Song and Dhariwal, 2023) and make training easier. In our initial experiments, we found that the Pseudo-Huber loss tends to work better than the squared \(_{2}\) loss with a small batch size (e.g. 128 on CIFAR-10). When the batch size is sufficiently large, it performs on par with the squared \(_{2}\) loss on CIFAR-10 and FFHQ-64 and outperforms it on AFHQ-64, as shown in Table 1. As it is less sensitive to the batch size, we choose to use the Pseudo-Huber loss in the following experiments.

We also explore the LPIPS, which forces the model to focus on reducing the perceptual distance between the generated data and the ground truth. Since LPIPS is not a premetric as two different

    &  &  &  \\  Base (Liu et al., 2022) (A) & 12.21 & - & - & - & - & - \\ (A) + EDM init + larger batch size (B) & 7.14 & 3.61 & 12.39 & 4.16 & 8.84 & 4.79 \\ (B) + Our \(p_{t}\) (C) & 5.17 & 3.37 & 9.03 & 3.61 & 6.81 & 4.66 \\ (C) + Huber (D) & 5.24 & 3.34 & 8.20 & 3.55 & 7.06 & 4.79 \\ (C) + LPIPS-Huber (E) & 3.42 & 2.95 & 4.13 & 3.15 & **5.21** & **4.26** \\ (C) + LPIPS-Huber-\(\) (F) & 3.38 & 2.76 & **4.11** & **3.12** & 5.65 & 4.41 \\ (F) + Incorporating real data (G) & **3.07** & **2.40** & - & - & - & - \\  NFE & 1 & 2 & 1 & 2 & 1 & 2 \\   

Table 1: Effects of the improved training techniques. The baseline (config A) is the 2-rectified flow with the uniform timestep distribution and the squared \(_{2}\) metric (Liu et al., 2022). Config B is the improved baseline with EDM initialization (Sec. 4.3) and increased batch size (\(128 512\) on CIFAR-10). FID (the lower the better) is computed using \(50,000\) synthetic samples and the entire training set. We train the models for \(800,000\) iterations on CIFAR-10 and \(1,000,000\) iterations on AFHQ and FFHQ and report the best FID for each setting.

points could have zero LPIPS if they are perceptually similar, we use it in combination with the Pseudo-Huber loss with the weighting \(1-t\), thereby relying more on LPIPS when \(t\) is close to 1 where the task is more challenging. Note that in \(m_{}\), the gradient vanishes when \(t\) is close to zero. To compensate, we experiment with \(m_{,}\) where we multiply LPIPS by \(\). Compared to config D, the LPIPS-Huber loss improves the FID of 2-rectified flow from \(5.24\) to \(3.38\) (a \(35\%\) improvement) on CIFAR-10, \(8.20\) to \(4.11\) (\(50\%\)) on AFHQ, and \(7.06\) to \(5.21\) (\(26\%\)) on FFHQ in the one-step setting, as seen in Table 1.

### Initialization with pre-trained diffusion models

Training 1-rectified flow from scratch is computationally expensive. Recently, Pokle et al. (2023) showed that pre-trained diffusion models can be used to approximate \([|_{t}=_{t}]\) in Eq. (1) by adjusting the signal-to-noise ratio. The following proposition is the special cases of Lemma 2 of Pokle et al. (2023) restated with extended proof and a minor fix. We provide the constants and proof in Appendix. C.1.

**Proposition 1**: _Let \(p^{}(|_{t},t)\) be the posterior distribution of the perturbation kernel \(((1-t),t^{2})\). Also, let \(p^{}(|_{t},t)\) and \(p^{}(|_{t},t)\) be the posterior distributions of \(((t),(1-(t))^{2})\) and \((,t^{2})\), each. Then,_

\[ p^{}(|_{t}=_{t},t) \;d= p^{}(|_{t}=s_{ {VP}}_{t},t_{})\;d= p^{ }(|_{t}=s_{}_{t},t_{})\;d,\] (6)

_where \(s_{}\) and \(s_{}\) are the scaling factors and \(t_{}\) and \(t_{}\) are the converted times for the VP and VE diffusion models, respectively._

We have explicitly computed the time and scale conversion factors for the VP and VE diffusion models in Table 2. See Appendix C for derivation.

Proposition 1 allows us to initialize the Reflow with the pre-trained diffusion models such as EDM (Karras et al., 2022) or DDPM (Ho et al., 2020) and use Table 2 to adjust the time and scaling factors.

Starting from the vanilla 2-rectified flow setup (Liu et al., 2022) (config A), we initialize 1-rectified flow with the pre-trained EDM (VE). We also increase the batch size from \(128\) to \(512\) on CIFAR-10 compared to Liu et al. (2022). Overall, these improve the FID of 2-rectified flow from \(12.21\) to \(7.14\) (a \(42\%\) improvement) in the one-step setting on CIFAR-10 (config B).

### Incorporating real data

Training 2-rectified flow does not require real data (i.e., it can be data-free), but we can use real data if it is available. To see the effects of incorporating real data, we integrate the generative ODE of 1-rectified flow backward from \(t=0\) to \(t=1\) using an NFE of 128 to collect \(50,000\) pairs of (real data, synthetic noise) on CIFAR-10. For quick validation, we take the pre-trained 2-rectified flow model (config F) and fine-tune it using the (real data, synthetic noise) pairs for \(5,000\) iterations with a learning rate of 1e-5. This improves the FID of 2-rectified flow from \(3.38\) to \(3.07\) in the one-step setting on CIFAR-10 (config G).

In this fine-tuning setting, we also explored using (synthetic data, real noise) pair with a probability of \(p\), but we found that not incorporating (synthetic data, real noise) pairs at all (i.e., \(p=0\)) performs

   \(t_{}\) & \(t_{}\) & \(s_{}\) & \(s_{}\) \\  \((-0.05++ t^{2}}}})\) & \(\) & \(})}{1-t}\) & \(\) \\   

Table 2: The converted time and scale for the variance preserving (VP) and variance exploding (VE) diffusion models. Here, \((t)=(-_{0}^{t}(19.9s+0.1)ds)\) following Song et al. (2020), and the perturbation kernel of the VE diffusion is \((,t^{2})\) following Karras et al. (2022).

the best. We expect that training from scratch will further improve the performance with different values of \(p\), and leave it to future work. A similar idea is also explored in Anonymous (2024).

## 5 Experiments

We call these combined improvements to Reflow training _2-rectified flow++_ and evaluate it on four datasets: CIFAR-10 Krizhevsky et al. (2009), AFHQ Choi et al. (2020), FFHQ Karras et al. (2019), and ImageNet Deng et al. (2009). We compare our improved Reflow to up to 20 recent baselines, in the families of diffusion models, distilled diffusion models, score distillation, GANs, consistency models, and rectified flows. The details of our experimental setup are included in Appendix E.

### Unconditional and class-conditional image generation

In Tables 3 and 4, we compare 2-rectified flow++ with the state-of-the-art methods on CIFAR-10 and ImageNet \(64 64\). We observe two main messages:

**On both datasets, 2-rectified flow++ (ours) outperforms or is competitive with SOTA baselines in the 1-2 NFE regime.** On CIFAR-10 (Table 3), our 2-rectified flow achieves an FID of \(3.07\) in one step, surpassing existing distillation methods such as consistency distillation (CD) (Song et al., 2023), progressive distillation (PD) (Salimans and Ho, 2022), diffusion model sampling with neural operator (DSNO) (Zheng et al., 2022), and TRAnsitive Closure Time-distillation (TRACT) (Berthelot et al., 2023). On ImageNet \(64 64\) (Table 4), our model surpasses the distillation methods such as CD, PD, DFNO, TRACT, and BOOT in one-step generation. We also close the gap with iCT (4.01 vs

  METHOD & NFE (\(\)) & FID (\(\)) & Prec. (\(\)) & Rec. (\(\)) \\  \\  DDMM (Song et al., 2020) & 50 & 13.7 & 0.65 & 0.56 \\  & 10 & 18.3 & 0.60 & 0.49 \\ DPM solver (Lu et al., 2022) & 10 & 7.93 & & \\  & 20 & 3.42 & & \\ DESI (Zhang and Chen, 2022) & 10 & 6.65 & & \\  & 20 & 3.10 & & \\ DDPM (Ho et al., 2020) & 250 & 11.0 & 0.67 & 0.58 \\ iDPPM (Nichol and Dhariwal, 2021) & 250 & 2.92 & 0.74 & 0.62 \\ ADM (Dariari and Nichol, 2021) & 250 & 2.07 & 0.74 & 0.63 \\ EDM (Karras et al., 2022) & 79 & 2.30 & & \\  \\  DFNO (LIPPS) (Zheng et al., 2022) & 1 & 7.83 & & 0.61 \\ TRACT (Berthelot et al., 2023) & 1 & 7.43 & & 0.61 \\  & 2 & 4.97 & & 2.49 \\  & 1 & 16.3 & 0.68 & 0.36 \\ PD (Salimans and Ho, 2022) & 1 & 15.39 & 0.59 & 0.62 \\  & 2 & 8.95 & 0.63 & 0.65 \\  & 4 & 6.77 & 0.66 & 0.65 \\  \\  Diff-Instruct (Luo et al., 2024) & 1 & 5.57 & & \\  & DMD (Yin et al., 2023) & 1 & 2.62 & \\  & 2 & 2.46 & 9.80 & \\ iCT-deep (Song and Dhariwal, 2023) & 1 & 251 & 9.76 & \\  & 2 & **2.24** & 9.89 & \\  & 2 & **2.14** & 9.89 & \\ CTM (Kim et al., 2023) & 1 & 5.19 & & \\ CTM (Kim et al., 2023) + GAN & 1 & **1.98** & & \\
**Retified flows** & & & & \\ 
1-rectified flow (+distill) (Liu et al., 2022) & 1 & 6.18 & 9.08 & \\
2-rectified flow (Liu et al., 2022) & 1 & 12.21 & 8.08 & \\  & 110 & 3.36 & 3.94 & 2.94 \\  +distill (Liu et al., 2022) & 1 & 4.85 & 9.01 & \\
3-rectified flow (Liu et al., 2022) & 1 & 8.15 & 8.47 & \\  & 104 & 3.96 & 9.01 & \\  & 1 & 5.21 & 8.79 & \\
**2-rectified flow++ (ours)** & 1 & 3.07 & & \\  & 2 & 2.40 & & \\  & & & **2-rectified flow++ (ours)** & 1 & 4.31 & \\  & & & 2 & 3.64 & \\   The red rows correspond to the top-5 baselines for the 1-NFE setting, and the blue rows correspond to the top 5 baselines for the 2-NFE setting. The lowest FID scores for 1-NFE and 2-NFE are **boldfaced**.

Table 4: Class-conditional generation on ImageNet \(64 64\).

  METHOD & NFE (\(\)) & FID (\(\)) & IS (\(\)) \\  \\  DDMM (Song et al., 2020) & 2.000 & 2.38 & 9.83 \\ DDPM (Ho et al., 2020) & 1000 & 3.17 & 9.46 \\ L5GM (Vahdat et al., 2021) & 147 & 2.10 \\ EDM (Karras et al., 2022) & 35 & 1.97 & \\  \\  Knowledge Distillation (Lahman and Luhman, 2021) & 1 & 9.36 \\ DFNO (LIPPS) (Zheng et al., 2022) & 1 & 3.78 \\ TRACT (Berthelot et al., 2023) & 1 & 3.78 \\  & 2 & 3.32 \\ PD (Salimans and Ho, 2022) & 1 & 9.12 \\  & 2 & 4.51 \\  \\  Diff-Instruct (Luo et al., 2024) & 1 & 4.53 & 9.89 \\ DMD (Yin et al., 2023) & 1 & 3.77 & \\
**GANs** & & & \\  BigGAN (Brock et al., 2018) & 1 & 14.7 & 9.22 \\ StyleGAN2 (Karras et al., 2020) & 1 & 8.32 & 9.21 \\ StyleGAN2 (Karras et al., 2020) & 1 & 2.92 & 9.83 \\
**Consistency models** & & & \\  CD (LIPPS) (Song et al., 2023) & 1 & 3.55 & 9.48 \\  & 2 & 2.93 & 9.75 \\ CT (LIPPS) (Song et al., 2023) & 1 & 8.70 & 8.49 \\  & 2 & 5.83 & 8.85 \\ iCT (Song and Dhariwal, 2023) & 1 & 2.83 & 9.54 \\  & 2 & 2.46 & 9.80 \\ iCT-deep (Song and Dhariwal, 2023) & 1 & 2.51 & 9.76 \\  & 2 & **2.24** & 9.89 \\  & 2 & **2.24** & 9.89 \\  & 1 & 5.19 \\ CTM (Kim et al., 2023) + GAN & 1 & **1.98** & & \\
**Retified flows** & & & \\ 
1-rectified flow (+distill) (Liu et al., 2022) & 1 & 6.18 & 9.08 \\
2-rectified flow (Liu et al., 2022) & 1 & 12.21 & 8.08 \\  & 110 & 3.36 & 3.94 \\  +distill (Liu et al., 2022) & 1 & 4.85 & 9.01 \\
3-rectified flow (Liu et al., 2022) & 1 & 8.15 & 8.47 \\  & 104 & 3.96 & 9.01 \\  & 2 & 5.21 & 8.79 \\
**2-rectified flow++ (ours)** & 1 & 3.07 \\  & 2 & 2.40 \\  & & & \\  

Table 3: Unconditional generation on CIFAR-10.

4.31), the state-of-the-art consistency model, even with half the batch size. Note that on ImageNet, our model does not use real data during training, while consistency training (CT) requires real data. We believe we could further reduce the gap by using config G in Tab. 1. Uncurated samples of our model are provided in Appendix. G.

**2-rectified flow++ reduces the FID of 2-rectified flows by up to 75%.** Compared to vanilla rectified flows (Liu et al., 2022), our one-step FID on CIFAR-10 is lower than that of the previous 2-rectified flow by \(9.14\) (a reduction of 75%), and of the 3-rectified flow by \(5.08\) (see also Table 1 for ablations on other datasets). In addition, it outperforms the previous 2-rectified flow with 110 NFEs using only one step and also surpasses 2-rectified flow \(+\) distillation, which requires an additional distillation stage.

### Reflow can be computationally more efficient than other distillation methods

At first glance, Reflow seems computationally expensive compared to CD and CT as it requires generating synthetic pairs before training. However, CD requires 4 (1 for student, 1 for teacher, and 2 for Heun's solver) forward passes for each training iteration, and CT requires 2 (1 for student and 1 for teacher) forward passes, while Reflow requires only 1. For example, in our ImageNet experiment setting, the total number of forward passes for Reflow is \(395\)M + \(1433.6\)M = \(1828.6\)M (395M for generating pairs and 1,433.6M for training), while the total numbers of forward passes for CD and CT would be \(1,433.6 4=5,734.4\)M and \(1,433.6 2=2,867.2\)M under the same setting. See Table 6 for the comparison. Moreover, generating pairs is a one-time cost since we can reuse the pairs for multiple training runs.

In terms of the storage cost, the synthetic images for ImageNet \(64 64\) require 42 GB. For noise, we only store the states of the random number generator, which is negligible.

While these results should be further validated for larger datasets, our results suggest that the fact that Reflow requires generating synthetic pairs does not necessarily make it less computationally efficient than other distillation methods.

### Effects of samplers

Unlike distillation methods, rectified flow is a neural ODE, and its outputs approach the true solution of the ODE as NFE increases (i.e., precision grows). Figure 4 shows that with the standard Euler solver, FID decreases as NFE increases on all datasets. Moreover, Heun's second-order solver further improves the trade-off curve between FID and NFE. This suggests that there may be further room for improvement by using more advanced samplers. We provide some preliminary ideas towards this goal in Appendix D.

   Method & Per iteration & Total & Rel. total cost \\  Reflow & \(1\) & \(1828.6\)M & \( 1\) \\ CD & \(4\) & \(5734.4\)M & \( 3.1\) \\ CT & \(2\) & \(2867.2\)M & \( 1.5\) \\   

Table 6: Comparison of the number of forward passes. Reflow uses \(395\)M forward passes for generating pairs and \(1,433.6\)M for training.

Figure 4: Effects of ODE Solver and new update rule.

### Inversion

Unlike distillation methods, rectified flows are neural ODEs, thus they allow for _inversion_ from data to noise by simply integrating the ODE in the backward direction. In diffusion models, inversion has been used for various applications such as image editing  and watermarking , but it usually requires many NFEs. Figure 5 (a) demonstrates that our 2-rectified flow++ achieves significantly lower reconstruction error than EDM. Notably, the reconstruction error of 2-rectified flow++ with only 2 NFEs is lower than that of EDM with 16 NFEs. In (b), we compare the quality of the inverted noise, where we find that the noise vectors of 2-rectified flow are more Gaussian-like than those of EDM, in the sense that their norm is closer to that of typical Gaussian noise. These are also shown visually in (c). In Figure 6, we show two applications of inversion: interpolating between two real images (a) and image-to-image translation (b). Notably, the total NFE used is only 6 (4 for inversion and 2 for generation), which is significantly lower than what is typically required in diffusion models (\( 100\)) .

## 6 Conclusion

In this work, we propose several improved training techniques for rectified flows, including the U-shaped timestep distribution and LPIPS-Huber loss. We show that by combining these improvements, 2-rectified flows++ outperforms the state-of-the-art distillation methods in the 1-2 NFE regime on CIFAR-10 and ImageNet \(64 64\) and closes the gap with iCT, the state-of-the-art consistency model. 2-rectified flows++ have limitations though--they still do not outperform the best consistency models (iCT), and their training is slower (by about 15% per iteration on ImageNet) than previous rectified flows because of the LPIPS loss. Despite these shortcomings, the training techniques we propose can easily and significantly boost the performance of rectified flows in the low NFE setting, without harming performance at the higher NFE setting.

Figure 5: Inversion results on CIFAR-10. (a) Reconstruction error between real and reconstructed data is measured by the mean squared error (MSE), where the x-axis represents NFEs used for inversion and reconstruction (e.g. 2 means 2 for inversion and 2 for reconstruction). (b) Distribution of \(\|\|_{2}^{2}\) of the inverted noises as a proxy for Gaussianity (NFE = 8). The green histogram represents the distribution of true noise, which is Chi-squared with \(3 32 32=3072\) degrees of freedom. (c) Inversion and reconstruction results using (8 + 8) NFEs. With only 8 NFEs, EDM fails to produce realistic noise, and also the reconstructed samples are blurry.

Figure 6: Applications of few-step inversion. (a) Interpolation between two real images. (b) Image-to-image translation. The total NFEs used are 6 (4 for inversion and 2 for generation).