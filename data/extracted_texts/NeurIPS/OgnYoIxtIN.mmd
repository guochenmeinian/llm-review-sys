# Zero-Shot Transfer of Neural ODEs

Tyler Ingebrand, Adam J. Thorpe, Ufuk Topcu

University of Texas at Austin

Austin, TX 78712

###### Abstract

Autonomous systems often encounter environments and scenarios beyond the scope of their training data, which underscores a critical challenge: the need to generalize and adapt to unseen scenarios in real time. This challenge necessitates new mathematical and algorithmic tools that enable adaptation and zero-shot transfer. To this end, we leverage the theory of function encoders, which enables zero-shot transfer by combining the flexibility of neural networks with the mathematical principles of Hilbert spaces. Using this theory, we first present a method for learning a space of dynamics spanned by a set of neural ODE basis functions. After training, the proposed approach can rapidly identify dynamics in the learned space using an efficient inner product calculation. Critically, this calculation requires no gradient calculations or retraining during the online phase. This method enables zero-shot transfer for autonomous systems at runtime and opens the door for a new class of adaptable control algorithms. We demonstrate state-of-the-art system modeling accuracy for two MuJoCo robot environments and show that the learned models can be used for more efficient MPC control of a quadrotor.

## 1 Introduction

Models that are adaptable, generalizable, and capable of learning online from minimal data are essential for autonomy. These models must adapt to unseen tasks and environments at runtime without relying upon a priori parameterizations. For example, consider an autonomous UAV delivery robot navigating in a dense, urban environment through varying wind patterns and carrying uncertain payloads. This scenario requires rapid adaptation to ensure safe and correct operation because conditions can change unpredictably and online model updates are impractical. While prior works can control autonomous systems in a single setting, they fail to adapt to the continuum of real-life scenarios. The key challenge is enabling _zero-shot transfer_ of learned models, where models quickly adapt to new data provided at runtime without retraining.

We present a method for modeling differential equations by learning a set of basis functions parameterized by neural ODEs. Our key insight is to learn a _space_ of functions that captures feasible behaviors of the system. By focusing on learning the structure of the space of differential equations, our approach implicitly learns how the dynamics change due to changes in the environment. Our approach is based on the theory of function encoders , a framework for zero-shot transfer that has been applied to task transfer in reinforcement learning contexts.

We formulate the space of learned functions as a linear space equipped with an inner product (e.g. a Hilbert space), and learn a set of basis functions over this space, where each basis function is represented by a neural ODE. This structure offers an efficient way to approximate online dynamics via a linear combination of the basis functions.

By representing functions in a Hilbert space and pre-training on a suite of functions, we can quickly identify the basis functions' coefficients for a new dynamical system at runtime using minimal data. This is useful, for instance, in scenarios where we can pre-train offline in simulation, but need toquickly identify dynamics online from a single trajectory in a zero-shot manner. This strategy greatly reduces the computational overhead associated with adapting or re-training a neural ODE to new tasks at runtime. The ability to efficiently encode the behavior of a system at runtime without retraining is a key component of our approach. Our approach is outlined in Figure 1.

Our approach yields models which generalize to a large set of possible system behaviors and achieves better long-term prediction accuracy than neural ODEs alone. We showcase our approach on a problem of predicting the behavior of a first-order ODE system with Van der Pol dynamics. We demonstrate the scalability of our approach on two MuJoCo robotics environments . Finally, we test the feasibility of using the learned model for downstream tasks such as model-predictive control (MPC). Our results show that our model achieves significantly better long-horizon prediction accuracy compared to the nearest baseline. Additionally, the MPC controller using our model has a lower slew rate, indicating that the improved model accuracy leads to more efficient control decisions.

### Contributions

**Representing Spaces of Dynamical Systems:** We propose a novel framework for representing spaces of dynamical systems, i.e. induced by hidden system parameters, variations in the underlying physics, or changing environmental features. Using a large-scale set of data collected offline, we learn a collection of neural networks that act as a functional basis. This approach is based in the theory of function encoders . Yet the extension to using neural ODEs as basis functions is non-trivial and poses several challenges, mainly from the need to integrate the learned model.

**A Method for Online Adaptation:** We construct a method for adapting neural ODE estimations based on online data without gradient updates, i.e. zero-shot transfer of system models. Our approach overcomes a significant challenge in learning behaviors of differential equations and dynamical systems. By offloading the computational effort to the training phase, we enable rapid online identification, adaptation, and prediction without retraining.

**Empirical Results:** We demonstrate accurate long-horizon predictions in challenging robotics tasks and show these models can be used for online control of quadrotor systems. We assess the quality of the approach in three areas and answer the following questions: 1) How well does our approach adapt to new dynamics online? 2) How does our approach compare to existing approaches for long-horizon prediction tasks? and 3) Does our approach work for downstream tasks such as control? We show that function encoders using neural ODEs as basis functions consistently outperform existing approaches.

## 2 Background

### Neural ODEs

Consider an ordinary differential equation \((t)=f(x(t),t)\), where \(f\) is Lipschitz continuous and \(x(t)^{n}\) is the state at time \(t\). Given an initial condition \(x(t_{0})\), the ODE solution can be written as

\[x(t_{f})=x(t_{0})+_{t_{0}}^{t_{f}}fx(),d.\] (1)

Figure 1: An illustration of our approach. The training phase uses a set of datasets \(\) to train basis functions \(\{g_{1},...,g_{k}\}\) to span \(\). The zero-shot phase uses online data to identify the coefficients for a new function, which can be estimated as a linear combination of the basis functions.

Note that in general, the explicit dependence of \(fx(t),t\) on \(t\) can be removed by augmenting the state \(x\) to include \(t\). As such, we omit \(t\) throughout.

Neural ODEs  parameterize the function \(f\) as a neural network. In particular, neural ODEs solve the ODE using an off-the-shelf integrator and optimize the neural network with respect to a prediction loss. The training procedure requires a dataset \(D=\{(t_{i},x(t_{i}))\}_{i=1}^{d}\) which is used to train the model via a supervised objective, such as mean squared error, back-propagated through the integrator.

Neural ODEs have demonstrated impressive accuracy for long-horizon predictions of continuous-time systems. Furthermore, they can be trained on trajectories with irregular time intervals between samples , and generalize better than multi-layer perceptron models. However, they lack adaptability and need to be retrained for every scenario.

### Function Encoders

To achieve zero-shot transfer, we employ the theory of _function encoders_. While typical machine learning approaches learn a single function, function encoders learn basis functions to span a _space_ of functions. This allows the function encoder to achieve zero-shot transfer within this space by identifying the coefficients of the basis functions for any function in the space at runtime. Once the coefficients have been identified, the function can be reproduced as a linear combination of basis functions. Despite the broad applicability of function encoders, the extension to capture solutions to differential equations via neural ODEs is non-trivial.

Formally, consider a function space \(=\{f f:^{m}\}\) where \(^{n}\). Instead of learning a single function, function encoders learn \(k\) basis functions \(g_{1},g_{2},,g_{k}\) that are parameterized by neural networks in order to span \(\). Define the inner product of \(\) as \( f,g_{}= f(x),g(x) dx\). Then, the functions \(f\) can be represented as a linear combination of basis functions,

\[f(x)=_{i=1}^{k}c_{i}g_{i}(x_{i}),\] (2)

where \(c^{k}\) are real coefficients and \(_{i}\) are the network parameters for \(g_{i}\). Let \(V\) be the volume of \(\). For any function \(f\), an empirical estimate of the coefficients \(c\) can be calculated using data \(\{(x_{j},f(x_{j}))\}_{j=1}^{m}\) via a Monte-Carlo estimate of the inner product,

\[c_{i}= f,g_{i}_{j=1}^{m}f(x_{ j}),g_{i}(x_{j}_{i}).\] (3)

The basis functions are trained using a set of datasets, \(=\{D_{1},D_{2},...\}\), where each dataset \(D_{i}=\{(x_{j},f_{i}(x_{j})\}_{j=1}^{m}\) consists of input-output pairs corresponding to a single function \(f_{i}\). For each function \(f_{i}\) and corresponding dataset \(D_{i}\), first compute the coefficients \(\{c_{1},c_{2},...,c_{k}\}\) via (3) and then obtain an empirical estimate of \(f_{i}\) via (2). Then compute the error of the estimate of \(f_{i}\) though the norm induced by the inner product of \(\). The loss function is simply the sum of the losses for all \(f_{i}\), which is minimized via gradient descent. For more details, see .

After training, the basis functions are fixed, and the coefficients \(c\) of a new function \(f\{g_{1},,g_{k}\}\) are computed via (3) or via least-squares, using data collected online. This is key for efficient, online calculations, since the approximation in (3) is effectively a sample mean and requires no gradient calculations.

**Orthogonality of the Basis Functions:** Note that function encoders do not enforce orthogonality of the basis functions explicitly . Using Gram-Schmidt to orthonormalize the basis functions during training can significantly increase the training time and is computationally intensive. Instead, during training the coefficients are computed using (3) presuming that the basis functions are orthogonal. This is key. This causes the basis vectors to naturally become more orthogonal as training progresses since the loss implicitly penalizes the basis functions if they are not orthonormal. See Appendix I.

## 3 Function Encoders With Neural ODEs as Basis Functions

Consider a space \(\) of Lipschitz continuous dynamical systems \(f:\). The space of dynamical systems can arise, for instance, due to uncertain parameters, minor variations in a first-order physics model, or changing environmental features. Given an initial condition \(x(t_{0})\), our goal is to estimate the state \(x(t_{f})\) at a future time \(t_{f}>t_{0}\). The integral form of the initial value problem is given by (1).

Our approach can be separated into two distinct phases: _offline training_ and _zero-shot prediction_. During _offline training_, we presume that we have access to an offline dataset \(=\{D_{1},D_{2},\}\), where \(D_{i}\) is a realization of a trajectory from a function \(f_{i}\). During _zero-shot prediction_, we seek to predict a previously unseen function \(f\) and have access to a minimal trajectory \(D\) taken from \(f\). We seek to learn a set of basis functions \(g_{1},,g_{k}\) that span \(\), where \(k\) is a user-specified hyper-parameter. By learning a set of basis functions that span the space \(\), we obtain a means to represent the behavior of any dynamical system in the space. However, we do not observe measurements of \(f\) directly since we cannot typically measure the instantaneous derivative \(\) of a dynamical system. Instead, we will equivalently learn a set of neural ODE basis functions such that the underlying neural networks which are being integrated correspond to \(g_{1},...,g_{k}\). We then seek to compute a representation of a new function using data collected online.

### Computing a Set of Neural ODE Basis Functions

For every \(f\), we define the integral term in (1) as a function \(H:\), given by,

\[Hx(t_{0}),t_{f}:=_{t_{0}}^{t_{f}}fx( )d.\] (4)

We model the dynamical system \(f\) using a function encoder as in (2). Using (2) in (4), and by the linearity of the definite integral, we have that,

\[Hx(t_{0}),t_{f}=_{t_{0}}^{t_{f}}_{ i=1}^{k}c_{i}g_{i}x()_{i}d=_{i=1}^{k}c_{i }_{t_{0}}^{t_{f}}g_{i}x()_{i}d=_{i=1}^ {k}c_{i}G_{i}x(t_{0}),t_{f},\] (5)

where \(g_{i}\) is neural network parameterized by \(_{i}\) and \(G_{i}(x(t_{0}),t_{f}):=_{t_{0}}^{t_{f}}g_{i}(x()_{i})d\). One interpretation of the above equation is that we can represent \(H\) as a weighted combination of basis functions \(G_{i}\), and the problem of learning a set of basis functions \(g_{1},,g_{k}\) can equivalently be viewed as learning a set of neural ODEs \(G_{1},,G_{k}\). Thus, we define the Hilbert space \(\) of functions \(H\) as in (4) and equip it with the following inner product,

\[ H,G_{}:=H(z,t),G(z,t) _{}d(z,t).\] (6)

We then learn basis functions \(G_{1},,G_{k}\) spanning \(\) where each basis function is a neural ODE.

From (6), the coefficients of a function \(H\) are given by \(c_{i}= H,G_{i}_{}\). However, from , computing the inner product exactly is generally intractable in high-dimensional spaces. We can empirically estimate the coefficients \(c_{i}\) using a trajectory of (potentially irregularly) sampled states \(\{x(t) t=t_{0},,t_{m}\}\) from a dynamics function \(f\). Using the trajectory, we form the dataset \(D=\{(x(t_{j}),x(t_{j+1}))_{j=0}^{m-1}\}\). We can compute \(c\) using \(D\) via a Monte-Carlo estimate of the inner product in (6),

\[c_{i}= H,G_{i}_{}_{j=0}^{m-1} x(t_{j+1})-x(t_{j}),G_{i}x(t_{j}),t_{j+1} _{},\] (7)

where \(V\) is the volume of the region of integration, and following from (1),

\[x(t_{j+1})-x(t_{j})=_{t_{j}}^{t_{j+1}}f()d=Hx(t_{j}),t_{j+1} .\] (8)

In other words, we substitute the difference between states \(x(t_{j+1})-x(t_{j})\) for \(H(x(t_{j}),t_{j+1})\) in (7).

Let \(=\{D_{1},D_{2},...\}\) be a set of datasets, where each \(D_{}=\{(x(t_{j}),x(t_{j+1}))\}_{j=0}^{m-1}\) is collected from a trajectory from a function \(f_{}\). For each dataset \(D_{}\), we compute the coefficients \(c_{1},,c_{k}\) according to (7). The coefficients can be used to approximate the corresponding \(H_{}\) via (5). We then evaluate the error of \(H_{}\) using the dataset \(D_{}\) and minimize its loss via gradient descent. This is done for multiple functions \(f\) at each gradient update to ensure the basis learns the space rather than a single function. We present this as Algorithm 1.

```
1:Input: Set of datasets \(\), number of basis functions \(k\), learning rate \(\)
2:Output: Neural ODE basis functions \(G_{1},G_{2},...,G_{k}\)
3:Initialize \(g_{1},g_{2},...,g_{k}\) as neural networks with parameters \(=\{_{1},_{2},...,_{k}\}\)
4:while not converged do
5: loss \(L=0\)
6:for all\(D_{}\)do
7:for\(i 1,...,k\)do
8:\(c_{i}_{j=0}^{m-1} x(t_{j+1})-x(t_{j}),G_{i}(x(t_ {j}),t_{j+1}-t_{j})_{}\)
9:endfor
10:\(L=L+_{j=0}^{m-1}\|(x(t_{j+1})-x(t_{j}))-_{i=1}^{k}c_{i}G_{i}(x(t_{j}),t _{j+1}-t_{j})\|^{2}\)
11:endfor
12:\(=-_{}L\)
13:endwhile ```

**Algorithm 1** Training Function Encoders with Neural ODE Basis Functions

Applying Algorithm 1 yields basis functions which span the space of dynamical systems, where each basis function is a neural ODE. This space describes possible behaviors of the system, where variations in environmental parameters, physics, etc. correspond to a particular dynamics function within this space. Therefore, this algorithm represents complicated system behaviors simply as a vector within a Hilbert space. Section 3.2 shows how to use these basis functions for zero-shot dynamics prediction from small amounts of online data.

### Efficient Online Transfer Without Retraining

After training, we fix the parameters of the basis functions \(g_{1},...,g_{k}\), and can compute the coefficient representation \(c^{k}\) for any function \(f\{g_{1},,g_{k}\}\) via (7). If \(\) is rich enough to capture the various behaviors of the systems in \(\), then we can estimate the behavior of any dynamics \(f\).

Given data collected online from a single trajectory, we can compute the coefficients using the Monte-Carlo estimate of the inner product as in (7). This approximation is a crucial component of the approach. It allows the inner product to be computed from data through an operation that is effectively a sample mean. Therefore, this approach can be computed online quickly even for large amounts of data. Then, given the coefficients, the future states of the system can be predicted using (5). These properties allow the neural ODE to achieve zero-shot transfer. Identifying the coefficients only requires inner product calculations, vector addition, and scalar multiplication, and so it can be computed online without any gradient updates.

**The Residuals Method:** The zero vector of the coefficients space corresponds to the zero function. Since the feasible dynamics are differentiated by their coefficients, it is numerically convenient if the coefficients corresponding to all feasible systems are centered around zero.

Thus, we can re-center the space of coefficients around the center of the _cluster_ of feasible dynamics. This is done by first modeling the average dynamics \(F_{avg}\) in the set of datasets \(\), and then learning the residuals between each function and \(F_{avg}\). In other words, the basis functions are trained to span the function space corresponding to \(R(x(t_{0}),t_{f})=x(t_{f})-x(t_{0})-F_{avg}(x(t_{0}),t_{f})\). This method can achieve better accuracy, but requires learning one additional neural ODE, \(F_{avg}\). Alternatively, an approximate dynamics model based on prior knowledge can be used as \(F_{avg}\). We describe the training procedure for this approach in Algorithm 2.

### Incorporating Zero-Order Hold Control Inputs

We can account for a zero-order hold (ZOH) control input \(u^{p}\) with minimal modifications. A ZOH control input is given by a piecewise constant function, meaning it is held constant over the period of integration. Given controlled dynamics, \(f:\), we modify the corresponding functions \(H\) to incorporate a constant input, \(Hx(t_{0}),u,t_{f}=_{i=1}^{k}c_{i}_{t_{0}}^{t_{f}}g_{i}(x (t_{0}),u_{i})d\). Then, using trajectory data that also includes the controls applied at each time interval, we can estimate the coefficients using datasets \(D=\{(x(t_{j}),u_{j},x(t_{j+1}))\}_{j=0}^{m-1}\), substituting \(g_{i}x(),u,_{i}\) in (5) and (7). The remainder of the training procedure is unchanged.

## 4 Numerical Experiments

We demonstrate the effectiveness of our approach for predicting and controlling dynamical systems through several numerical experiments. We first demonstrate that the approach can adapt to different dynamics using a Van Der Pol oscillator system. We then show long-horizon prediction accuracy on challenging MuJoCo robotics experiments and compare to neural ODEs (NODE)  and function encoders as in  using the residuals method (FE + Res). Lastly, we show the learned models are sufficiently accurate for downstream tasks on a difficult control task using a quadrotor system. The source code is available at https://github.com/tyler-inebrand/NeuralODEFunctionEncoder.

Current off-the-shelf integrators with adaptive step sizes do not support efficient batch calculations. Because this algorithm involves training numerous neural ODEs on a large amount of data, the ability to train on data in batches is required. Therefore, we implement an RK4 integrator since it can be efficiently computed for multiple data points in parallel. The Van der Pol visualization uses \(11\) basis functions while the MuJoCo and Drone experiments use \(100\). For ablations on how the hyper-parameters affect results, see Appendix G.

### Visualization on a Van der Pol Oscillator

We first demonstrate that our approach can adapt to a space of dynamics that vary according to a nonlinear parameter. The Van der Pol dynamics are defined as, \(=y\), \(=(1-x^{2})y-x\), where \([x,y]^{}^{2}\) is the state, and \(\) is a hidden parameter. We collect multiple datasets \(D_{}\) where \(\) is fixed for the duration of the trajectory, but varies between trajectories. We train basis functions using Algorithm 1. We then compute the coefficients via (7) and approximate the dynamics via (5).

We plot the results in Figure 2. As expected, we observe that our proposed approach can predict the dynamics of a space of Van der Pol systems without retraining. We can also see that a single neural ODE trained on the same data can only fit a single function. Therefore, its prediction corresponds most closely with the behavior of a single Van der Pol system that has the mean \(\) value. This illustrates that our approach is capable of adapting to different dynamics at runtime.

Figure 2: The approximated dynamics for different Van der Pol systems, where the parameter \(\) is varied. This plot shows that a NODE can only fit a single Van der Pol system, whereas FE + NODE + Res can fit a space of Van der Pol systems from \(5000\) example data points.

### Long-Horizon Prediction on MuJoCo Environments

We evaluate the performance of our proposed approach on the Half-Cheetah and Ant environments , shown in Figure 3. The hidden environmental parameters are the length of the limbs, the friction coefficient, and the control authority. Of the two environments, Ant is more difficult due to its higher degrees of freedom. For training, we collect a dataset of trajectories where the hidden parameters are unobserved, but held constant throughout the duration of a given trajectory. After training, we use \(200\) datapoints, equivalent to about seven seconds of data for a system running at \(30\) Hertz, and use only this data to identify the dynamics. Note this online phase is computationally simple, and can be done in only milliseconds on a GPU.

Neural ODEs (NODE) perform poorly because they have no mechanism to condition the prediction on the hidden-parameters. Effectively, NODE learns the mean dynamics over all dynamics functions in the training set. Function encoders using the residuals method (FE + Res) can implicitly condition their predictions on the hidden parameters through the coefficient calculation, though they are unable to achieve accurate long horizon predictions on the more challenging Ant problem. This is because it lacks the inductive bias of neural ODEs. Our approach (FE + NODE) can both implicitly condition the predictions on the hidden parameters through data, but also benefits from the inductive bias of neural ODEs. We see that the residuals method performs best out of all approaches in both environments. This is because the average model significantly reduces the epistemic uncertainty and provides a meaningful baseline from which to center the training. The average model acts as a good inductive bias and makes it easier to distinguish between the learned functions during training. We additionally compare against an oracle prediction approach (Oracle), which has access to the hidden parameters as an additional input with a neural ODE as the underlying architecture. While its 1-step prediction accuracy demonstrates good empirical performance, the long-horizon predictions are unstable. This is because Oracle is required to generalize to an entire space of dynamics with one NODE, which is a complex and difficult function to learn.

### Realistic Robotics Experiments and Control of a Quadrotor System

Lastly, we seek to test the accuracy of our approach for use on downstream tasks such as control on a realistic example using a robotic system. We seek to determine if the learned models are sufficiently accurate for model-based control in the presence of hidden parameters. We use a simulated quadrotor system using PyBullet , which is a highly nonlinear control system. We use the quadrotor's mass as a hidden parameter. The goal is to predict the future state of the quadrotor system under any hidden

Figure 3: Model performance on predicting the dynamics of MuJoCo robotics environments with hidden parameters. \(200\) example data points are given to identify dynamics. The results show that FE + NODE + Res. makes accurate, long-horizon predictions even in the presence of hidden parameters. Evaluation is over 5 seeds, shaded regions show the first and third quartiles around the median.

parameters, using \(2000\) data points collected online to identify the dynamics. Then, given the learned model of system behavior, we seek to control the quadrotor using gradient-based model predictive control (MPC) to reach a pre-specified hover point. The results are plotted in Figure 4.

The results show that FE + NODE + Res outperforms competing approaches at long-horizon predictions. Furthermore, we plot the 10-step MSE as a function of mass in Figure 4, and we observe that FE + NODE + Res accurately predicts the system behavior across varying masses. We observe a slight decay in performance for low masses which are more sensitive to control inputs during simulation, which causes the simulated trajectories to diverge more from the rest of the observed data. The neural ODE (NODE) performs poorly for different masses, and its performance decays quickly as the dynamics deviate from the mean behavior.

Lastly, we see that this prediction accuracy translates to the downstream performance of an MPC controller. While all approaches are sufficiently accurate for control due to the fact that MPC is partially robust to model inaccuracies, the prediction accuracy has a corresponding impact on the task performance. Neural ODEs (NODE) demonstrate a high slew rate, which reflects the need for repeated positional corrections necessitated by taking bad actions. In contrast, FE + NODE and FE + NODE + Res have lower slew rates as they make more accurate decisions. We plot two example trajectories that demonstrate this behavior in Figure 5.

## 5 Scope & Limitations

**Overhead:** Our approach incurs a cost of either increased inference time or memory, depending on if the basis functions are integrated sequentially or in parallel. We integrate them sequentially during

Figure 4: Model performance on the PyBullet quadrotor environment with varying mass. Function encoders improve model performance across varying masses. Shaded region is \(1^{}\) and \(3^{}\) quartiles over 200 trajectories (left) and over 5 trajectories (middle, right).

Figure 5: Qualitative analysis of the difference in control between NODEs and our approach. Two trajectories with the same initial position but different masses are shown. NODE is unaware of the mass, and so its \(z\) position requires constant correction. In contrast, FE + NODE (+Res) accounts for the mass through the coefficients, meaning it is more accurate and requires fewer corrections.

training to reduce memory overhead and allow for larger batch sizes, while integrating in parallel at execution to prioritize inference speed. See Appendix D.

**Data dependency:** In order to make efficient, online approximations of a new function \(f\) without gradient calculations, the basis functions must be trained to span the space of possible dynamics. To do so, there must be sufficient example datasets of possible dynamics under fixed hidden parameters in \(\). This implies a larger amount of data must be collected to learn a space of dynamics then would be needed to learn a single dynamics function.

**Integration:** The training procedure trains the basis functions on short time intervals \(t_{f}-t_{0}\), in which \(x(t)\). The basis functions have only been trained for inputs in the space of \(\), where their behavior outside of \(\) is unpredictable. As a result, it is necessary to either integrate each basis function for a short time interval before calculating the state according to (5), or to integrate the basis functions as described in B. Integrating the basis functions over long horizons without calculating the state of the system during intermediate steps may lead the predicted state to leave \(\), at which point the behavior of that basis function becomes unpredictable.

## 6 Related Work

**Basis Functions:** Function approximation techniques often employ a linear model over a predefined set of basis functions. Techniques such as Taylor series, Fourier series, and orthogonal polynomial systems utilize an infinite set of basis functions, theoretically allowing perfect function representation [6; 23; 7]. However, in high-dimensional spaces, these techniques become impractical due to the exponential growth in the number of basis functions. Additionally, many approaches depend on the choice of a feature map or kernel to define the function space [29; 25], which imposes structure by selecting the class of functions to learn from (e.g. using radial basis functions ). These design choices necessarily introduce approximation errors through the choice of function class, or may depend on prior domain knowledge, which may not always be available. Methods for identifying system dynamics that use a large library of pre-defined basis functions, such as Koopman operators  or nonlinear system identification through sparse regression such as SINDy [4; 26; 15], have received considerable attention. Yet these approaches typically employ a finely-crafted finite dictionary of basis functions, which requires careful choice to achieve good data-driven performance . Neural network approaches such as functional-link and orthogonal networks [30; 7] omit hidden layers and use gradient descent to learn a linear combination of features, encoding the function class into the network architecture, but fail to generalize well, and are not amenable to zero-shot transfer. In contrast, we compute the coefficients of the model through a well-defined inner product, which scales well with data and can be computed quickly. Furthermore, our basis functions are entirely learned from data during the training phase, similar to representation learning , and thus require no prior assumptions or domain knowledge.

**Neural ODEs:** In existing work, neural ODEs have proven to be a powerful tool for modeling dynamical systems [10; 24; 22; 11; 17] and stochastic differential equations [21; 13], but generally require an extensive data collection and training phase. While the model training can be enhanced  and the models can incorporate prior knowledge [9; 10] to reduce the training time, they inherently focus on a single system at a time. This inherently limits their ability to generalize across different systems without retraining. Notably, parameterized neural ODEs  pass the model parameters as an additional input to the neural ODE. This approach has been shown to achieve a form of transfer within the set of allowable parameters, but requires extensive knowledge of the system parameters and the structure of the dynamics, both at training and test time. In principle, our approach can be combined with these existing approaches to incorporate their distinct advantages, making our approach highly generalizable to different systems and modeling frameworks.

**Deep Learning Techniques:** Few-shot meta learning aims to solve a similar problem, where a learned model is adapted given an online dataset . However, meta learning requires gradient updates to the learned models, which may be too slow for real-time control. Transformers are another technique that can adapt given an online dataset by feeding that dataset as input to the encoder side of the transformer. However, transformers have long forward pass times and scale quadratically with the amount of data , and so they are not amenable for model-based control. Domain randomization in reinforcement learning is another technique to generate a policy which is robust to a large set of dynamics . In contrast, our dynamics model _adapts_ to the current dynamics, and thus our controller is adaptive, rather than robust.

## 7 Conclusion & Future Work

We introduced zero-shot neural ODEs, which accomplish both long-horizon predictions and zero-shot transfer. We demonstrated the performance of this approach on two challenging MuJoCo tasks and on the control of a quadrotor system. Our approach makes a significant step towards online adaptability of model-based control and has implications for the safe control of autonomous systems in the presence of uncertainty. In future work, we plan to address safety during training, perhaps using the properties of the Hilbert space to characterize the epistemic uncertainty. We also plan to explore theoretical extensions to stochastic differential equations and Hilbert spaces of probability measures.

## 8 Broader Impact

This approach demonstrates several clear benefits for enabling same-day adaptation, which is a critical need for autonomous systems that will be deployed in new, unstructured environments. Nevertheless, this approach will require a more thorough theoretical analysis before it can be deployed on actual robotics systems, e.g. to determine confidence or sample bounds to guarantee safety. Notably, this work is a step toward bridging the sim-to-real gap, though it remains unclear how well real-world systems will be represented by a set of basis functions learned in simulation.

## 9 Acknowledgements

Thank you to Dr. Cyrus Neary for helpful discussions. This material is based upon work supported by the National Science Foundation under NSF Grant Number 2214939. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation. This material is based upon work supported by the Air Force Office of Scientific Research under award number AFOSR FA9550-19-1-0005. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the U.S. Department of Defense.