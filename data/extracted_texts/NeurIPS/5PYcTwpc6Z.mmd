# SHARCS: Shared Concept Space for

Explainable Multimodal Learning

 Gabriele Dominici

Universita della Svizzera Italiana

Lugano, Switzerland

gabriele-dominici@usi.ch

&Pietro Barbiero

Universita della Svizzera Italiana

Lugano, Switzerland

University of Cambridge

Cambridge, UK

pietro-barbiero@usi.ch

Lucie Charlotte Magister

University of Cambridge

Cambridge, UK

lcm67@cam.ac.uk

&Pietro Lio

University of Cambridge

Cambridge, UK

pl219@cam.ac.uk

&Nikola Simidjievski

University of Cambridge

Cambridge, UK

ns779@cam.ac.uk

###### Abstract

Multimodal learning is an essential paradigm for addressing complex real-world problems, where individual data modalities are typically insufficient for accurately solving a given modelling task. While various deep learning approaches have successfully addressed these challenges, their reasoning process is often opaque; limiting the capabilities for a principled explainable cross-modal analysis and any domain-expert intervention. In this paper, we introduce SHARCS (SHARed Concept Space) - a novel concept-based approach for explainable multimodal learning. SHARCS learns and maps interpretable concepts from different heterogeneous modalities into a single unified concept-manifold, which leads to an intuitive projection of semantically similar cross-modal concepts. We demonstrate that such an approach can lead to inherently explainable task predictions while also improving downstream predictive performance. Moreover, we show that SHARCS can operate and significantly outperform other approaches in practically significant scenarios, such as retrieval of missing modalities and cross-modal explanations. Our approach is model agnostic and easily applicable to different types (and number) of modalities, thus advancing the development of effective, interpretable, and trustworthy multimodal approaches.

## 1 Introduction

Deep learning (DL) approaches for multimodal learning attain high performance by blending information from different data sources [22; 14]. However, the opaque reasoning of DL models  hinders the human ability to better understand the relationships in the data across modalities, which is imperative for safety-critical domains such as healthcare and biology, where this may often lead to novel insights and discoveries. To address this issue, many self-explainable methods were released [13; 28; 1; 2], offering an effective solution to bridge this knowledge gap. These methods can extract intuitive and human-readable explanations, and some even facilitate interaction with human experts, enabling a deeper understanding of the problem. However, they are often limited to single data modalities. A recent line of research focuses explicitly on developing or adapting existing methods for multimodal settings . While relevant, they are typically tailored for specific multimodal scenarios , provide only local explanations  or generate explanations for just one of the modalities  using an extra modality, thus failing to provide a general solution to multimodal problems.

In this paper, we introduce SHARCS (SHARed Concept Space), a novel interpretable concept-based approach (described in Section 2) designed to address general multimodal tasks. Our experiments (Section 3) demonstrate on four common data modalities (tabular, text, image, and graph data) that SHARCS (i) outperforms unimodal models and matches the task performance of existing baselines on challenging multimodal settings, (ii) attains high task accuracy even when a modality is missing, (iii) generates intuitive concept-based explanations for task predictions, and (iv) generates simple concept-based explanations for a data modality using the concepts emerging from other modalities, allowing human experts to uncover hidden cross-modal connections.

## 2 SHARCS: SHARed Concepts Space

SHARCS combines information from diverse data sources during training, emphasizing the integration of high-level, interpretable concept representations (as defined by Ghorbani et al. ), as opposed to traditional uninterpretable embeddings . This approach facilitates intuitive concept-based explanations and enables experts to explore the interrelationships between data modalities. In SHARCS, for example, a red ball is represented as a multimodal concept with a consistent representation in the shared space across input modalities (e.g., image, text, etc.).

**Local concepts** Figure 1 depicts SHARCS applied to two data modalities. The model utilizes concept encoders \(g_{1},,g_{n}\), each for a modality \(i=1,,n\), mapping inputs to local concepts. Modality-specific architectures \(_{1},,_{n}\) map inputs to latent concept representations. To convert latent concepts into a local concept space, we use batch scaling \(}:^{b k} ^{k}\) (with batch size \(b\)) and a sigmoid activation function \(:\), resulting in \(g_{i}=_{i}\). Batch rescaling before sigmoid activation triggers a concept when its representation significantly differs from others in the batch:

\[_{i,m}=_{i}(_{i,m})}{}}_{i}(_{i,j}) ^{-1}\] (1)

Here, \(B_{i,m}\) is the \(m\)-th batch's sample indexes, \(}\) represents permutation-invariant batch rescaling (e.g., batch normalization), and \(_{i}\) decipts local concepts for the \(i\)-th modality. They can be used to understand how local concepts combine into the shared concept space, offering another level of interpretability of the model.

**Shared concepts** SHARCS then maps the local concepts \(_{i}\) into a shared concept space. To this end, SHARCS applies a modality-specific set of concept encoders \(h_{1},,h_{n}\) mapping local concepts \(_{i} C^{k}\) into a set of shared concept embeddings \(_{i} S^{t}\) of size \(t\) i.e., \(h_{i}:C_{i} S\). Shared concept encoders resemble the structure of local encoders applying batch rescaling and a

Figure 1: **SHARCS (SHARed Concept Space)**: for each modality \(i\), the concept encoder module \(g_{i}\) produces a local concept embedding \(_{i}\). SHARCS then maps local concept embeddings into a shared concept representation \(_{i}\). To generate a semantically meaningful shared space, SHARCS minimises the distance between shared concepts of similar objects from different modalities. Finally, the label predictor \(f\) takes as input the concatenation of all shared concepts \(_{i}\) to solve the task at hand.

[MISSING_PAGE_EMPTY:3]

that the models need to leverage both modalities in order to provide correct predictions. Models that will learn only from one of the modalities will be able to solve a partial (local) single-modality task but will typically exhibit random performance on the global multimodal task. Furthermore, we test the interpretability of SHARCS and its ability to cope with real-world scenarios when a modality is missing. Further details of the experiments, dataset and model details, baselines and metrics used are in the Appendix B.

## 4 Results and discussion

**SHARCS' generalisation is on par with non-interpretable multimodal models.** As a proof-of-principle of our method, we first benchmarked it against unimodal approaches (see Figure 7 in the Appendix D). SHARCS achieves good performance across all four multimodal tasks, consistently outperforming (up to 81%) the unimodal baselines. Furthermore, the results presented in Table 1 show that SHARCS achieves slightly better or comparable performance than the other multimodal baselines. In particular, our approach can maintain good performance, despite the bottleneck introduced for computing concepts and the constraint of the shared space. More importantly, both concept-based approaches are the only two that can accurately model the CLEVR task, which further justifies the utility of the concept embeddings. Moreover, in terms of performance in scenarios with missing modalities, SHARCS consistently outperforms other baselines in Table 1. Its success lies in constructing a more robust and less noisy concept space, enhancing sample representation and enabling precise retrieval of missing modalities.

**SHARCS unveils meaningful concepts and.** SHARCS, much like our Concept Multimodal baselines, excels at extracting task-related concepts, evidenced by its completeness score  aligning closely with Accuracy in Table 1. Notably, SHARCS achieves higher completeness scores on three of the four datasets compared to solutions lacking a shared space, with improvements of up to 10% in MNIST+Superpixels. SHARCS uses the shared space to de-noise concepts, collapsing less significant ones into semantically richer representations. Additionally, SHARCS can offers insights into the prediction process by replacing the predictor function \(f\) with a decision tree (see Figures 12 and 13 in Appendix D). This enables users to understand how various concepts contribute to decisions, en

    &  &  \\  & **Model** & **Accuracy** & **Compl.** & **1st Modality** & **2nd Modality** \\   & Relative & **99.5 \(\) 0.3 & - & \(80.1 6.4\) & \(82.8 2.2\) \\  & Concept & \(99.0 0.8\) & \(96.2 1.2\) & \(68.0 2.0\) & \(57.0 6.1\) \\  & SHARCS & \(98.7 0.5\) & \(98.0 1.2\) & \( 0.9\) & \( 1.2\) \\   & Relative & \(80.4 0.2\) & - & \(52.6 4.9\) & \(30.1 2.4\) \\  & Concept & \(88.2 0.1\) & \(78.9 1.4\) & \(13.7 3.9\) & \(10.8 2.6\) \\  & SHARCS & \( 0.1\) & \( 0.2\) & \( 0.0\) & \( 0.4\) \\   & Relative & \( 0.1\) & - & \(92.9 1.4\) & \( 3.4\) \\  & Concept & \(93.9 0.0\) & \(91.3 0.1\) & \(89.4 1.3\) & \(13.4 2.1\) \\   & SHARCS & \(94.0 0.1\) & \( 0.3\) & \( 0.0\) & \(35.1 3.0\) \\   & Relative & \(48.7 0.5\) & - & \(49.9 0.0\) & \(49.0 0.1\) \\  & Concept & \(90.1 0.1\) & \( 1.2\) & \(51.4 2.8\) & \(48.6 2.7\) \\   & SHARCS & \( 0.2\) & \(81.5 1.1\) & \( 0.6\) & \( 0.4\) \\   

Table 1: The performance of SHARCS (Accuracy (%)) in scenarios with missing modalities, compared to Relative representation and Concept Multimodal variants. The global task accuracy is presented as a reference. SHARCS performs better than the baselines, particularly on harder tasks requiring both modalities. In some scenarios, SHARCS is able to retrieve modalities, leading to better downstream performance than the original data.

Figure 2: (a-c) Retrieval examples obtained by (a) SHARCS, (b) Relative representation, and (c) Concept Multimodal; on the MNIST+Superpixels dataset. The top two rows are samples of retrieved graphs using images, while the bottom two are retrieved images using graph samples. (d) tSNE plot of the SHARCS concept space

hancing task comprehension, revealing how concepts combine, and justifying sample classifications. Moreover, **SHARCS enhance cross-modal understanding.** This cross-modal explanation can be extended to individual concepts, demonstrating how specific concepts are represented in the other modality. Additionally, Figure 2d shows SHARCS' shared space for the MNIST+Superpixels dataset, where similar examples from different modalities are closely mapped. This property is extremely valuable, particularly when modalities lack expressiveness or share nuanced commonalities, shedding light on the critical relationship between modalities and samples, which can be beneficial across domains like medicine, biology, and healthcare. We envision this work as a foundation for the development and evaluation of interpretable multimodal approaches.

## 5 Acknowledgments

This study was funded by TRUST-ME (project 205121L_214991) and SmartCHANGE (GA No. 101080965) projects.