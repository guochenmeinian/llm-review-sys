# Binary Classification with Confidence Difference

Wei Wang\({}^{1,2}\), Lei Feng\({}^{3,2}\), Yuchen Jiang\({}^{4}\), Gang Niu\({}^{2}\), Min-Ling Zhang\({}^{5}\), Masashi Sugiyama\({}^{2,1}\)

\({}^{1}\) The University of Tokyo, Chiba, Japan

\({}^{2}\) RIKEN Center for Advanced Intelligence Project, Tokyo, Japan

\({}^{3}\) Nanyang Technological University, Singapore

\({}^{4}\) Alibaba Group, Beijing, China

\({}^{5}\) Southeast University, Nanjing, China

wangw@g.ecc.u-tokyo.ac.jp lfengqaq@gmail.com

jiangyuchen.jyc@alibaba-inc.com gang.niu.ml@gmail.com

zhangml@seu.edu.cn sugi@k.u-tokyo.ac.jp

###### Abstract

Recently, learning with _soft labels_ has been shown to achieve better performance than learning with _hard labels_ in terms of model generalization, calibration, and robustness. However, collecting pointwise labeling confidence for all training examples can be challenging and time-consuming in real-world scenarios. This paper delves into a novel weakly supervised binary classification problem called _confidence-difference (ConfDiff) classification_. Instead of pointwise labeling confidence, we are given only unlabeled data pairs with confidence difference that specifies the difference in the probabilities of being positive. We propose a risk-consistent approach to tackle this problem and show that the estimation error bound achieves the optimal convergence rate. We also introduce a risk correction approach to mitigate overfitting problems, whose consistency and convergence rate are also proven. Extensive experiments on benchmark data sets and a real-world recommender system data set validate the effectiveness of our proposed approaches in exploiting the supervision information of the confidence difference.

## 1 Introduction

Recent years have witnessed the prevalence of deep learning and its successful applications. However, the success is built on the basis of the collection of large amounts of data with unique and accurate labels. However, in many real-world scenarios, it is often difficult to satisfy such requirements. To circumvent the difficulty, various weakly supervised learning problems have been investigated accordingly, including but not limited to semi-supervised learning [1; 2; 3; 4], label-noise learning [5; 6; 7; 8; 9], positive-unlabeled learning [10; 11; 12], partial-label learning [13; 14; 15; 16; 17], unlabeled-unlabeled learning [18; 19], and similarity-based classification [20; 21; 22].

Learning with soft labels has been shown to achieve better performance than learning with hard labels in the context of supervised learning [23; 24], where each example is equipped with _pointwise labeling confidence_ indicating the degree to which the labels describe the example. The advantages have been validated in many aspects, including model generalization [25; 26], calibration [27; 28], and robustness [29; 30]. For example, with the help of soft labels, knowledge distillation [25; 31] transfers knowledge from a large teacher network to a small student network. The student network can be trained more efficiently and reliably with the soft labels generated by the teacher network [32; 33; 34].

However, collecting a large number of training examples with pointwise labeling confidence may be demanding under many circumstances since it is challenging to describe the labeling confidence for each training example exactly [35; 36; 37]. Different annotators may give different values of pointwiselabeling confidence to the same example due to personal biases, and it has been demonstrated that skewed confidence values can harm classification performance . Besides, giving pointwise labeling information to large-scale data sets is also expensive, laborious, and even unrealistic in many real-world scenarios . On the contrary, leveraging supervision information of pairwise comparisons may ameliorate the biases of skewed pointwise labeling confidence and save labeling costs. Following this idea, we investigate a more practical problem setting for binary classification in this paper, where we are given _unlabeled data pairs with confidence difference_ indicating the difference in the probabilities of being positive. Collecting confidence difference for training examples in pairs is much cheaper and more accessible than collecting pointwise labeling confidence for all the training examples.

Take click-through rate prediction in recommender systems  for example. The combinations of users and their favorite/disliked items can be regarded as positive/negative data. Collecting training data takes work to distinguish between positive and negative data. Furthermore, the pointwise labeling confidence of training data may be difficult to be determined due to the extraordinarily sparse and class-imbalance problems . Therefore, the collected confidence values may be biased. However, collecting the difference in the preference between a pair of candidate items for a given user is more accessible and may alleviate the biases. Section 4 will give a real-world case study of this problem. Take the disease risk estimation problem for another example. Given a person's attributes, the goal is to predict the risk of having some disease. When asking doctors to annotate the probabilities of having the disease for patients, it takes work to determine the exact values of the probabilities. Furthermore, the probability values given by different doctors may differ due to their diverse backgrounds. On the other hand, it is much easier and less biased to estimate the relative difference in the probabilities of having the disease between two patients. Therefore, the problem of learning with confidence difference is of practical research value, but has yet to be investigated in the literature.

As a related work, Feng et al.  elaborated that a binary classifier can be learned from pairwise comparisons, termed Pcomp classification. For a pair of samples, they used a pairwise label of one is being more likely to be positive than the other. Since knowing the confidence difference implies knowing the pairwise label, our method requires stronger supervision than Pcomp classification. Nevertheless, we argue that, in many real-world scenarios, we may not only know one example is more likely to be positive than the other, but also know how much the difference in confidence is, as explained in the above examples. Therefore, the setting of the current paper is not so restrictive compared with that of Pcomp classification. Furthermore, our setting is more flexible than that of Pcomp classification from the viewpoint of data generation process. Pcomp classification limits the labels of pairs of training data to be in \(\{(+1,+1),(+1,-1),(-1,-1)\}\). To cope with collected data with labels \((-1,+1)\), they either discard them or reverse them as \((+1,-1)\). On the contrary, our setting is more general and we take the examples from \((-1,+1)\) also into consideration explicitly in the data distribution assumption. Figure 1 shows the results of a pilot experiment. Here, Strategy1 denotes Pcomp-Teacher  discarding examples from \((-1,+1)\) while Strategy2 denotes Pcomp-Teacher reversing examples from \((-1,+1)\). We can observe that both strategies perform actually similarly. Since Strategy1 loses many data, it is intuitively expected that Strategy2 works much better, but the improvement is actually marginal. This may be because the training data distribution after reversing differs from the expected one. On the contrary, in this work we take examples from \((-1,+1)\) into consideration directly, which is a more appropriate way to handle these data.

Learning with pairwise comparisons has been investigated pervasively in the community , with applications in information retrieval , computer vision , regression , crowdsourcing , and graph learning . It is noteworthy that there exist distinct differences between our work and previous works on learning with pairwise comparisons. Previous works have mainly tried to learn a ranking function that can rank candidate examples according to relevance or preference. In this paper, we try to learn a _pointwise binary classifier_ by conducting _empirical risk minimization_ under the binary classification setting.

Our contributions are summarized as follows:

Figure 1: Experimental results for different strategies of handling examples from \((-1,+1)\).

* We investigate confidence-difference (ConfDiff) classification, a novel and practical weakly supervised learning problem, which can be solved via empirical risk minimization by constructing an _unbiased risk estimator_. The proposed approach can be equipped with any model, loss function, and optimizer flexibly.
* An estimation error bound is derived, showing that the proposed approach achieves the optimal parametric convergence rate. The robustness is further demonstrated by probing into the influence of an inaccurate class prior probability and noisy confidence difference.
* To mitigate overfitting issues, a risk correction approach  with consistency guarantee is further introduced. Extensive experimental results on benchmark data sets and a real-world recommender system data set validate the effectiveness of the proposed approaches.

## 2 Preliminaries

In this section, we discuss the background of binary classification, binary classification with soft labels, and Pcomp classification. Then, we elucidate the data generation process of ConfDiff classification.

### Binary Classification

For binary classification, let \(=^{d}\) denote the \(d\)-dimensional feature space and \(=\{+1,-1\}\) denote the label space. Let \(p(,y)\) denote the unknown joint probability density over random variables \((,y)\). The task of binary classification is to learn a binary classifier \(g:\) which minimizes the following classification risk:

\[R(g)=_{p(,y)}[(g(),y)],\] (1)

where \((,)\) is a non-negative binary-class loss function, such as the 0-1 loss and logistic loss. Let \(_{+}=p(y=+1)\) and \(_{-}=p(y=-1)\) denote the class prior probabilities for the positive and negative classes respectively. Furthermore, let \(p_{+}()=p(|y=+1)\) and \(p_{-}()=p(|y=-1)\) denote the class-conditional probability densities of positive and negative data respectively. Then the classification risk in Eq. (1) can be equivalently expressed as

\[R(g)=_{+}_{p_{+}()}[(g(),+1)]+_{-}_ {p_{-}()}[(g(),-1)].\] (2)

### Binary Classification with Soft Labels

When the soft labels of training examples are accessible to the learning algorithm, taking advantage of them can often improve the generalization performance . First, the classification risk in Eq. (1) can be equivalently expressed as

\[R(g)=_{p()}[p(y=+1|)(g(),+1)+p(y=-1|) (g(),-1)].\] (3)

Then, given training data equipped with confidence \(\{(_{i},r_{i})\}_{i=1}^{n}\) where \(r_{i}=p(y_{i}=+1|_{i})\) is the _pointwise positive confidence_ associated with \(_{i}\), we minimize the following unbiased risk estimator to perform empirical risk minimization:

\[_{}(g)=_{i=1}^{n}(r_{i}(g( _{i}),+1)+(1-r_{i})(g(_{i}),-1)).\] (4)

However, accurate pointwise positive confidence may be hard to be obtained in reality .

### Pairwise-Comparison (Pcomp) Classification

In principle, collecting supervision information of pairwise comparisons is much easier and cheaper than pointwise supervision information . In Pcomp classification , we are given pairs of unlabeled data where we know which one is more likely to be positive than the other. It is assumed that Pcomp data are sampled from labeled data pairs whose labels belong to \(\{(+1,-1),(+1,+1),(-1,-1)\}\). Based on this assumption, the probability density of Pcomp data \((,^{})\) is given as \(q(,^{})/(_{+}^{2}+_{-}^{2}+_{+}_{-})\) where \(q(,^{})=_{+}^{2}p_{+}()p_{+}(^{})+_{- }^{2}p_{-}()p_{-}(^{})+_{+}_{-}p_{+}()p_{-}(^{})\). Then, an unbiased risk estimator for Pcomp classification is derived as follows:

\[_{}(g)=_{i=1}^{n}((g( _{i}),+1)+(g(_{i}^{}),-1)-_{+}(g(_{i}),-1) -_{-}(g(_{i}^{}),+1)).\] (5)In real-world scenarios, we may not only know one example is more likely to be positive than the other, but also know how much the difference in confidence is. Next, a novel weakly supervised learning setting named ConfDiff classification is introduced which can utilize such confidence difference.

### Confidence-Difference (ConfDiff) Classification

In this subsection, the formal definition of confidence difference is given firstly. Then, we elaborate the data generation process of ConfDiff data.

**Definition 1** (Confidence Difference).: _The confidence difference \(c(,^{})\) between an unlabeled data pair \((,^{})\) is defined as_

\[c(,^{})=p(y^{}=+1|^{})-p(y=+1|).\] (6)

As shown in the definition above, the confidence difference denotes the difference in the class posterior probabilities between the unlabeled data pair, which can measure how confident the pairwise comparison is. In ConfDiff classification, we are only given \(n\) unlabeled data pairs with confidence difference \(=\{((_{i},^{}_{i}),c_{i})\}_{i=1}^{n}\). Here, \(c_{i}=c(_{i},^{}_{i})\) is the confidence difference for the unlabeled data pair \((_{i},^{}_{i})\). Furthermore, the unlabeled data pair \((_{i},^{}_{i})\) is assumed to be drawn from a probability density \(p(,^{})=p()p(^{})\). This indicates that \(_{i}\) and \(^{}_{i}\) are two i.i.d. instances sampled from \(p()\). It is worth noting that the confidence difference \(c_{i}\) will be positive if the second instance \(^{}_{i}\) has a higher probability to be positive than the first instance \(_{i}\), and will be negative otherwise. During the data collection process, the labeler can first sample two unlabeled data independently from the marginal distribution \(p()\), then provide the confidence difference for them.

## 3 The Proposed Approach

In this section, we introduce our proposed approaches with theoretical guarantees. Besides, we show the influence of an inaccurate class prior probability and noisy confidence difference theoretically. Furthermore, we introduce a risk correction approach to improve the generalization performance.

### Unbiased Risk Estimator

In this subsection, we show that the classification risk in Eq. (1) can be expressed with ConfDiff data in an equivalent way.

**Theorem 1**.: _The classification risk \(R(g)\) in Eq. (1) can be equivalently expressed as_

\[R_{ CD}(g)=_{p(,^{})}[(( ,^{})+(^{},))],\] (7)

_where_

\[(,^{})=(_{+}-c(,^{}))( g(),+1)+(_{-}-c(,^{}))(g(^{}),-1).\]

Accordingly, we can derive an unbiased risk estimator for ConfDiff classification:

\[_{ CD}(g)=_{i=1}^{n}((_{i},^{}_{i})+(^{}_{i},_{i})).\] (8)

Minimum-variance risk estimator.Actually, Eq. (8) is one of the candidates of the unbiased risk estimator. We introduce the following lemma:

**Lemma 1**.: _The following expression is also an unbiased risk estimator:_

\[_{i=1}^{n}((_{i},^{ }_{i})+(1-)(^{}_{i},_{i})),\] (9)

_where \(\) is an arbitrary weight._

Then, we introduce the following theorem:

**Theorem 2**.: _The unbiased risk estimator in Eq. (8) has the minimum variance among all the candidate unbiased risk estimators in the form of Eq. (9) w.r.t. \(\)._

Theorem 2 indicates the variance minimality of the proposed unbiased risk estimator in Eq. (8), and we adopt this risk estimator in the following sections.

### Estimation Error Bound

In this subsection, we elaborate the convergence property of the proposed risk estimator \(_{}(g)\) by giving an estimation error bound. Let \(=\{g:\}\) denote the model class. It is assumed that there exists some constant \(C_{g}\) such that \(_{g}\|g\|_{} C_{g}\) and some constant \(C_{}\) such that \(_{|z| C_{g}}(z,y) C_{}\). We also assume that the binary loss function \((z,y)\) is Lipschitz continuous for \(z\) and \(y\) with a Lipschitz constant \(L_{}\). Let \(g^{*}=_{g}R(g)\) denote the minimizer of the classification risk in Eq. (1) and \(_{}=_{g}_{}(g)\) denote the minimizer of the unbiased risk estimator in Eq. (8). The following theorem can be derived:

**Theorem 3**.: _For any \(>0\), the following inequality holds with probability at least \(1-\):_

\[R(_{})-R(g^{*}) 8L_{}_{n}()+4C_{}},\] (10)

_where \(_{n}()\) denotes the Rademacher complexity of \(\) for unlabeled data with size \(n\)._

From Theorem 3, we can observe that as \(n\), \(R(_{}) R(g^{*})\) because \(_{n}() 0\) for all parametric models with a bounded norm, such as deep neural networks trained with weight decay . Furthermore, the estimation error bound converges in \(_{p}(1/)\), where \(_{p}\) denotes the order in probability, which is the optimal parametric rate for empirical risk minimization without making additional assumptions .

### Robustness of Risk Estimator

In the previous subsections, it was assumed that the class prior probability is known in advance. In addition, it was assumed that the ground-truth confidence difference of each unlabeled data pair is accessible. However, these assumptions can rarely be satisfied in real-world scenarios, since the collection of confidence difference is inevitably injected with noise. In this subsection, we theoretically analyze the influence of an inaccurate class prior probability and noisy confidence difference on the learning procedure. Later in Section 4.5, we will experimentally verify our theoretical findings.

Let \(}=\{((_{i},_{i}^{}),_{i})\}_{i=1}^{n}\) denote \(n\) unlabeled data pairs with noisy confidence difference, where \(_{i}\) is generated by corrupting the ground-truth confidence difference \(c_{i}\) with noise. Besides, let \(_{+}\) denote the inaccurate class prior probability accessible to the learning algorithm. Furthermore, let \(_{}(g)\) denote the empirical risk calculated based on the inaccurate class prior probability and noisy confidence difference. Let \(_{}=_{g}_{}(g)\) denote the minimizer of \(_{}(g)\). Then the following theorem gives an estimation error bound:

**Theorem 4**.: _Based on the assumptions above, for any \(>0\), the following inequality holds with probability at least \(1-\):_

\[R(_{})-R(g^{*}) 16L_{}_{n}()+8C_{}}+_{i=1}^{n}| _{i}-c_{i}|}{n}+4C_{}|_{+}-_{+}|.\] (11)

Theorem 4 indicates that the estimation error is bounded by twice the original bound in Theorem 3 with the mean absolute error of the noisy confidence difference and the inaccurate class prior probability. Furthermore, if \(_{i=1}^{n}|_{i}-c_{i}|\) has a sublinear growth rate with high probability and the class prior probability is estimated consistently, the risk estimator can be even consistent. It elaborates the robustness of the proposed approach.

### Risk Correction Approach

It is worth noting that the empirical risk in Eq. (8) may be negative due to negative terms, which is unreasonable because of the non-negative property of loss functions. This phenomenon will result in severe overfitting problems when complex models are adopted [19; 22; 43]. To circumvent this difficulty, we wrap the individual loss terms in Eq. (8) with _risk correction functions_ proposed in Lu et al. , such as the rectified linear unit (ReLU) function \(f(z)=(0,z)\) and the absolute value function \(f(z)=|z|\). In this way, the corrected risk estimator for ConfDiff classification can beexpressed as follows:

\[_{}(g)=(f(_{i=1}^{n }(_{+}-c_{i})(g(_{i}),+1))+f(_{i=1}^{n}(_{-}-c_{i })(g(_{i}^{}),-1))\] \[+f(_{i=1}^{n}(_{+}+c_{i})(g(_{i} ^{}),+1))+f(_{i=1}^{n}(_{-}+c_{i})(g(_{i}),-1) )).\] (12)

Theoretical analysis.We assume that the risk correction function \(f(z)\) is Lipschitz continuous with Lipschitz constant \(L_{f}\). For ease of notation, let \((g)=_{i=1}^{n}(_{+}-c_{i})(g(_{i}),+1)/2n, {B}(g)=_{i=1}^{n}(_{-}-c_{i})(g(_{i}^{}),-1)/2n, {C}(g)=_{i=1}^{n}(_{+}+c_{i})(g(_{i}^{}),+1)/2n\), and \((g)=_{i=1}^{n}(_{-}+c_{i})(g(_{i}),-1)/2n\). From Lemma 3 in Appendix A, the values of \([(g)],[(g)],[ (g)]\), and \([(g)]\) are non-negative. Therefore, we assume that there exist non-negative constants \(a,b,c,\) and \(d\) such that \([(g)] a,[(g)] b,[ (g)] c,\) and \([(g)] d\). Besides, let \(_{}=_{g}_{}(g)\) denote the minimizer of \(_{}(g)\). Then, Theorem 5 is provided to elaborate the bias and consistency of \(_{}(g)\).

**Theorem 5**.: _Based on the assumptions above, the bias of the risk estimator \(_{}(g)\) decays exponentially as \(n\):_

\[0[_{}(g)]-R(g) 2(L_{f}+1)C_{},\] (13)

_where \(=n/C_{}^{2})}+n/C_{}^{2})}+n/C_{}^{2})}+n/C_{}^{2})}\). Furthermore, with probability at least \(1-\), we have_

\[|_{}(g)-R(g)| 2C_{}L_{f}}+2(L_{f}+1)C_{}.\] (14)

Theorem 5 demonstrates that \(_{}(g) R(g)\) in \(_{p}(1/)\), which means that \(_{}(g)\) is biased yet consistent. The estimation error bound of \(_{}\) is analyzed in Theorem 6.

**Theorem 6**.: _Based on the assumptions above, for any \(>0\), the following inequality holds with probability at least \(1-\):_

\[R(_{})-R(g^{*}) 8L_{}_{n}()+4C_{}(L_{f}+1)}+4(L_{f}+1)C_{}.\] (15)

Theorem 6 elucidates that as \(n\), \(R(_{}) R(g^{*})\), since \(_{n}() 0\) for all parametric models with a bounded norm  and \( 0\). Furthermore, the estimation error bound converges in \(_{p}(1/)\), which is the optimal parametric rate for empirical risk minimization without additional assumptions .

## 4 Experiments

In this section, we verify the effectiveness of our proposed approaches experimentally.

### Experimental Setup

We conducted experiments on benchmark data sets, including MNIST , Kuzushiji-MNIST , Fashion-MNIST , and CIFAR-10 . In addition, four UCI data sets  were used, including Optdigits, USPS, Pendigits, and Letter. Since the data sets were originally designed for multi-class classification, we manually partitioned them into binary classes. For CIFAR-10, we used ResNet-34  as the model architecture. For other data sets, we used a multilayer perceptron (MLP) with three hidden layers of width 300 equipped with the ReLU  activation function and batch normalization . The logistic loss is utilized to instantiate the loss function \(\).

It is worth noting that confidence difference is given by labelers in real-world applications, while it was generated synthetically in this paper to facilitate comprehensive experimental analysis. We firstly trained a probabilistic classifier via logistic regression with ordinarily labeled data and the same neural network architecture. Then, we sampled unlabeled data in pairs at random, and generated the class posterior probabilities by inputting them into the probabilistic classifier. After that, we generated confidence difference for each pair of sampled data according to Definition 1. To verify the effectiveness of our approaches under different class prior settings, we set \(_{+}\{0.2,0.5,0.8\}\) for all the data sets. Besides, we assumed that the class prior \(_{+}\) was known for all the compared methods. We repeated the sampling-and-training procedure for five times, and the mean accuracy as well as the standard deviation were recorded.

We adopted the following variants of our proposed approaches: 1) ConfDiff-Unbiased, which denotes the method working by minimizing the unbiased risk estimator; 2) ConfDiff-ReLU, which denotes the method working by minimizing the corrected risk estimator with the ReLU function as the risk correction function; 3) ConfDiff-ABS, which denotes the method working by minimizing the corrected risk estimator with the absolute value function as the risk correction function. We compared our proposed approaches with several Pcomp methods , including Pcomp-Unbiased, Pcomp-ReLU, Pcomp-ABS, and Pcomp-Teacher. We also recorded the experimental results of supervised learning methods, including Oracle-Hard having access to ground-truth hard labels and Oracle-Soft having access to pointwise positive confidence. All the experiments were conducted on NVIDIA GeForce RTX 3090. The number of training epoches was set to 200 and we obtained the testing accuracy by averaging the results in the last 10 epoches. All the methods were implemented in PyTorch . We used the Adam optimizer . To ensure fair comparisons, We set the same hyperparameter values for all the compared approaches, where the details can be found in Appendix H.

### Experimental Results

Benchmark data sets.Table 1 reports detailed experimental results for all the compared methods on four benchmark data sets. Based on Table 1, we can draw the following conclusions: a) On all the cases of benchmark data sets, our proposed ConfDiff-ABS method achieves superior performance against all of the other compared approaches significantly, which validates the effectiveness of our approach in utilizing supervision information of confidence difference; b) Pcomp-Teacher achieves

   Class Prior & Method & MNIST & Kuzushij & Fashion & CIFAR-10 \\  =0.2\)} & Pcomp-Unbiased & 0.761\(\)0.017 & 0.637\(\)0.052 & 0.737\(\)0.050 & 0.776\(\)0.023 \\  & Pcomp-ReLU & 0.800\(\)0.000 & 0.800\(\)0.000 & 0.800\(\)0.000 & 0.800\(\)0.000 \\  & Pcomp-ABS & 0.800\(\)0.000 & 0.800\(\)0.000 & 0.800\(\)0.000 & 0.800\(\)0.000 \\  & Pcomp-Teacher & 0.965\(\)0.010 & 0.871\(\)0.046 & 0.853\(\)0.017 & 0.836\(\)0.019 \\   & Oracle-Hard & 0.990\(\)0.000 & 0.939\(\)0.001 & 0.979\(\)0.001 & 0.894\(\)0.003 \\  & Oracle-Soft & 0.989\(\)0.001 & 0.939\(\)0.004 & 0.979\(\)0.001 & 0.893\(\)0.003 \\   & ConfDiff-Unbiased & 0.789\(\)0.041 & 0.672\(\)0.053 & 0.855\(\)0.024 & 0.789\(\)0.025 \\  & ConfDiff-ReLU & 0.968\(\)0.003 & 0.860\(\)0.017 & 0.964\(\)0.004 & 0.844\(\)0.020 \\  & ConfDiff-ABS & **0.975\(\)0.003** & **0.898\(\)0.003** & **0.965\(\)0.002** & **0.862\(\)0.015** \\  =0.5\)} & Pcomp-Unbiased & 0.712\(\)0.020 & 0.578\(\)0.036 & 0.723\(\)0.042 & 0.703\(\)0.042 \\  & Pcomp-ReLU & 0.502\(\)0.003 & 0.502\(\)0.004 & 0.500\(\)0.000 & 0.602\(\)0.032 \\  & Pcomp-ABS & 0.842\(\)0.012 & 0.727\(\)0.006 & 0.851\(\)0.012 & 0.583\(\)0.018 \\  & Pcomp-Teacher & 0.893\(\)0.014 & 0.782\(\)0.046 & 0.903\(\)0.016 & 0.779\(\)0.016 \\   & Oracle-Hard & 0.986\(\)0.000 & 0.929\(\)0.002 & 0.976\(\)0.001 & 0.871\(\)0.003 \\  & Oracle-Soft & 0.985\(\)0.001 & 0.928\(\)0.002 & 0.978\(\)0.001 & 0.877\(\)0.002 \\   & ConfDiff-Unbiased & 0.911\(\)0.046 & 0.712\(\)0.046 & 0.896\(\)0.036 & 0.720\(\)0.024 \\  & ConfDiff-ReLU & 0.944\(\)0.011 & 0.805\(\)0.015 & 0.960\(\)0.003 & 0.830\(\)0.007 \\  & ConfDiff-ABS & **0.964\(\)0.001** & **0.867\(\)0.006** & **0.967\(\)0.001** & **0.843\(\)0.004** \\  =0.8\)} & Pcomp-Unbiased & 0.799\(\)0.005 & 0.671\(\)0.029 & 0.813\(\)0.029 & 0.737\(\)0.022 \\  & Pcomp-ReLU & 0.910\(\)0.031 & 0.775\(\)0.022 & 0.897\(\)0.023 & 0.851\(\)0.010 \\  & Pcomp-ABS & 0.854\(\)0.027 & 0.838\(\)0.026 & 0.921\(\)0.017 & 0.849\(\)0.007 \\  & Pcomp-Teacher & 0.943\(\)0.026 & 0.814\(\)0.027 & 0.936\(\)0.014 & 0.821\(\)0.003 \\   & Oracle-Hard & 0.991\(\)0.001 & 0.942\(\)0.003 & 0.979\(\)0.000 & 0.897\(\)0.002 \\  & Oracle-Soft & 0.990\(\)0.002 & 0.945\(\)0.003 & 0.980\(\)0.001 & 0.904\(\)0.009 \\   & ConfDiff-Unbiased & 0.792\(\)0.017 & 0.758\(\)0.033 & 0.810\(\)0.035 & 0.794\(\)0.012 \\  & ConfDiff-ReLU & 0.970\(\)0.004 & 0.886\(\)0.009 & 0.970\(\)0.002 & 0.851\(\)0.012 \\  & ConfDiff-ABS & **0.983\(\)0.002** & **0.915\(\)0.001** & **0.975\(\)0.002** & **0.874\(\)0.011** \\   

Table 1: Classification accuracy (mean\(\)std) of each method on benchmark data sets with different class priors, where the best performance (excluding Oracle) is shown in bold.

superior performance against all of the other Pcomp approaches by a large margin. The excellent performance benefits from the effectiveness of consistency regularization for weakly supervised learning problems [1; 17; 71]; c) It is worth noting that the classification results of ConfDiff-ReLU and ConfDiff-ABS have smaller variances than ConfDiff-Unbiased. It demonstrates that the risk correction method can enhance the stability and robustness for ConfDiff classification.

UCI data sets.Table 2 reports detailed experimental results on four UCI data sets as well. From Table 2, we can observe that: a) On all the UCI data sets under different class prior probability settings, our proposed ConfDiff-ABS method achieves the best performance among all the compared approaches with significant superiority, which verifies the effectiveness of our proposed approaches again; b) The performance of our proposed approaches is more stable than the compared Pcomp approaches under different class prior probability settings, demonstrating the superiority of our methods in dealing with various kinds of data distributions.

### Experiments on a Real-world Recommender System Data Set

We also conducted experiments on a recommender system data set to demonstrate our approach's usefulness and promising applications in real-world scenarios. We used the KuaiRec  data set, a real-world recommender system data set collected from a well-known short-video mobile app. In this data set, user-item interactions are represented by watching ratios, i.e., the ratios of watching time to the entire length of videos. Such statistics could reveal the confidence of preference, and we regarded them as pointwise positive confidence. We generated pairwise confidence difference between pairs of items for a given user. We adopted the NCF  model as our backbone.

   Class Prior & Method & Optdigits & USPS & Pendigits & Letter \\  =0.2\)} & Pcomp-Unbiased & 0.771\(\)0.016 & 0.721\(\)0.046 & 0.743\(\)0.057 & 0.757\(\)0.028 \\  & Pcomp-ReLU & 0.800\(\)0.000 & 0.800\(\)0.000 & 0.800\(\)0.000 & 0.800\(\)0.000 \\  & Pcomp-ABS & 0.800\(\)0.001 & 0.800\(\)0.000 & 0.800\(\)0.000 & 0.800\(\)0.000 \\  & Pcomp-Teacher & 0.901\(\)0.023 & 0.894\(\)0.023 & 0.928\(\)0.019 & 0.883\(\)0.006 \\   & Oracle-Hard & 0.990\(\)0.002 & 0.984\(\)0.002 & 0.997\(\)0.001 & 0.978\(\)0.003 \\  & Oracle-Soft & 0.990\(\)0.003 & 0.984\(\)0.004 & 0.998\(\)0.001 & 0.971\(\)0.007 \\   & ConfDiff-Unbiased & 0.831\(\)0.078 & 0.840\(\)0.078 & 0.865\(\)0.079 & 0.732\(\)0.053 \\  & ConfDiff-ReLU & 0.953\(\)0.014 & 0.957\(\)0.007 & 0.987\(\)0.003 & 0.929\(\)0.008 \\  & ConfDiff-ABS & **0.963\(\)0.009** & **0.960\(\)0.005** & **0.988\(\)0.002** & **0.942\(\)0.007** \\  =0.5\)} & Pcomp-Unbiased & 0.651\(\)0.112 & 0.671\(\)0.090 & 0.748\(\)0.038 & 0.632\(\)0.019 \\  & Pcomp-ReLU & 0.630\(\)0.076 & 0.554\(\)0.048 & 0.514\(\)0.019 & 0.525\(\)0.023 \\  & Pcomp-ABS & 0.787\(\)0.031 & 0.814\(\)0.018 & 0.793\(\)0.017 & 0.748\(\)0.031 \\  & Pcomp-Teacher & 0.890\(\)0.009 & 0.860\(\)0.012 & 0.883\(\)0.018 & 0.864\(\)0.024 \\   & Oracle-Hard & 0.988\(\)0.003 & 0.980\(\)0.003 & 0.997\(\)0.001 & 0.975\(\)0.001 \\  & Oracle-Soft & 0.987\(\)0.003 & 0.980\(\)0.003 & 0.997\(\)0.001 & 0.967\(\)0.006 \\   & ConfDiff-Unbiased & 0.917\(\)0.006 & 0.936\(\)0.010 & 0.945\(\)0.052 & 0.755\(\)0.041 \\  & ConfDiff-ReLU & 0.921\(\)0.011 & 0.945\(\)0.009 & 0.981\(\)0.004 & 0.895\(\)0.006 \\  & ConfDiff-ABS & **0.962\(\)0.006** & **0.959\(\)0.004** & **0.988\(\)0.003** & **0.925\(\)0.003** \\  =0.8\)} & Pcomp-Unbiased & 0.765\(\)0.023 & 0.746\(\)0.012 & 0.743\(\)0.026 & 0.694\(\)0.031 \\  & Pcomp-ReLU & 0.902\(\)0.017 & 0.891\(\)0.024 & 0.913\(\)0.023 & 0.827\(\)0.025 \\  & Pcomp-ABS & 0.894\(\)0.019 & 0.879\(\)0.009 & 0.911\(\)0.009 & 0.870\(\)0.006 \\  & Pcomp-Teacher & 0.918\(\)0.007 & 0.933\(\)0.023 & 0.903\(\)0.008 & 0.872\(\)0.011 \\   & Oracle-Hard & 0.987\(\)0.003 & 0.983\(\)0.002 & 0.997\(\)0.001 & 0.976\(\)0.004 \\  & Oracle-Soft & 0.986\(\)0.003 & 0.985\(\)0.004 & 0.998\(\)0.001 & 0.965\(\)0.010 \\   & ConfDiff-Unbiased & 0.886\(\)0.037 & 0.803\(\)0.042 & 0.892\(\)0.096 & 0.748\(\)0.015 \\  & ConfDiff-ReLU & 0.949\(\)0.007 & 0.958\(\)0.008 & 0.986\(\)0.003 & 0.927\(\)0.008 \\  & ConfDiff-ABS & **0.964\(\)0.005** & **0.964\(\)0.003** & **0.987\(\)0.002** & **0.945\(\)0.007** \\   

Table 2: Classification accuracy (mean\(\)std) of each method on UCI data sets with different class priors, where the best performance (excluding Oracle) is shown in bold.

   Method & HR & NDCG \\  PPR & 0.464 & 0.256 \\ MRL & 0.476 & 0.271 \\ Oracle-Hard & 0.469 & 0.283 \\ Oracle-Soft & 0.534 & 0.380 \\ Pcomp-Teacher & 0.179 & 0.066 \\  ConfDiff-ABS & 0.570 & 0.372 \\   

Table 3: Experimental results on the KuaiRec data set.

Details of the experimental setup and the data set can be found in Appendix H. We employed 5 compared methods, including BPR , Margin Ranking Loss (MRL), Oracle-Hard, Oracle-Soft, and Pcomp-Teacher. Table 3 reports the hit ratio (HR) and normalized discounted cumulative gain (NDCG) results. Our approach performs comparably against Oracle in terms of NDCG and even performs better in terms of HR. On the contrary, Pcomp-Teacher does not perform well on this data set. It validates the effectiveness of our approach in exploiting the supervision information of the confidence difference.

### Performance with Fewer Training Data

We conducted experiments by changing the fraction of training data for ConfDiff-ReLU and ConfDiff-ABS (100% indicated that all the ConfDiff data were used for training). For comparison, we used 100% of training data for Pcomp-Teacher during the training process. Figure 2 shows the results with \(_{+}=0.5\), and more experimental results can be found in Appendix I. We can observe that the classification performance of our proposed approaches is still advantageous given a fraction of training data. Our approaches can achieve superior or comparable performance even when only 10% of training data are used. It elucidates that leveraging confidence difference may be more effective than increasing the number of training examples.

### Analysis on Robustness

In this subsection, we investigate the influence of an inaccurate class prior probability and noisy confidence difference on the generalization performance of the proposed approaches. Specifically, let \(_{+}=_{+}\) denote the corrupted class prior probability with \(\) being a real number around 1. Let \(_{i}=_{i}^{}c_{i}\) denote the noisy confidence difference where \(_{i}^{}\) is sampled from a normal distribution \((1,^{2})\). Figure 3 shows the classification performance of our proposed approaches on MNIST and Pendigits (\(_{+}=0.5\)) with different \(\) and \(\). It is demonstrated that the performance degenerates with \(=0.8\) or \(=1.2\) on some data sets, which indicates that it is important to estimate the class prior accurately.

## 5 Conclusion

In this paper, we dived into a novel weakly supervised learning setting where only unlabeled data pairs equipped with confidence difference were given. To solve the problem, an unbiased risk estimator was derived to perform empirical risk minimization. An estimation error bound was established to show that the optimal parametric convergence rate can be achieved. Furthermore, a risk correction approach was introduced to alleviate overfitting issues. Extensive experimental results validated the superiority of our proposed approaches. In future, it would be promising to apply our approaches in real-world scenarios and multi-class classification settings.

Figure 2: Classification performance of ConfDiff-ReLU and ConfDiff-ABS given a fraction of training data as well as Pcomp-Teacher given 100% of training data (\(_{+}=0.5\)).