# Honor Among Bandits:

No-Regret Learning for Online Fair Division

 Ariel D. Procaccia

Paulson School of Engineering and Applied Sciences, Harvard University | _E-mail_: arielpro@seas.harvard.edu.

Benjamin Schiffer

Department of Statistics, Harvard University | _E-mail_: bschiffer1@g.harvard.edu.

Shirley Zhang

Paulson School of Engineering and Applied Sciences, Harvard University | _E-mail_: szhang2@g.harvard.edu.

###### Abstract

We consider the problem of online fair division of indivisible goods to players when there are a finite number of types of goods and player values are drawn from distributions with unknown means. Our goal is to maximize social welfare subject to allocating the goods fairly in expectation. When a player's value for an item is unknown at the time of allocation, we show that this problem reduces to a variant of (stochastic) multi-armed bandits, where there exists an arm for each player's value for each type of good. At each time step, we choose a distribution over arms which determines how the next item is allocated. We consider two sets of fairness constraints for this problem: envy-freeness in expectation and proportionality in expectation. Our main result is the design of an explore-then-commit algorithm that achieves \((T^{2/3})\) regret while maintaining either fairness constraint. This result relies on unique properties fundamental to fair-division constraints that allow faster rates of learning, despite the restricted action space. We also prove a lower bound of \((T^{2/3})\) regret for our setting, showing that our results are tight.

## 1 Introduction

Fair allocation of indivisible goods is a fundamental problem with a wide range of applications; implemented algorithms for this task have been widely used in practice . We consider the online fair division setting, which introduces additional complexities as items arrive one by one and each item must be immediately and irrevocably allocated at its time of arrival. Crucially, this allocation must be done without knowledge of future items . One motivating example for this setting is a food bank that receives donations for a region and then allocates these donations among many different food pantries and soup kitchens in that region. Donations are often perishable, and therefore must be immediately allocated. Furthermore, donations can be unpredictable, and hence knowledge of future items is limited.

Two standard notions of fairness are _envy-freeness_ and _proportionality_. Envy-freeness implies that every player is at least as happy with their own allocation as with any other player's allocation. Intuitively, envy-freeness guarantees that no player will want to trade their allocation for that of another player. Proportionality is a slightly weaker notion, which requires only that each of the \(n\) players receive at least a \(1/n\) fraction of their total value for all items. Finding a solution which is envy-free or proportional is often interesting in and of itself, as can be seen from many previous results in fair division . In cases where there may exist multiple envy-free or proportional allocations, however, a natural goal is then to find the best solution among such allocations . In our work, we evaluate the quality of a fair solution by its (utilitarian) _social welfare_, which is defined as the sum over all players of each player's value for their own allocation.

We take a probabilistic approach to analyzing online fair division. In particular, we assume that there are a finite number of item types, and each player's value for each type of item is drawn froma random distribution. In practice, these distributions would not be known in advance and must be learned as items are allocated. For example, consider again the food bank. When a new food pantry opens, the values of that food pantry for different types of products are unknown. After items have been allocated to the food pantry, however, the food bank can easily collect information on the demand for various item types at the food pantry. Therefore, we primarily consider the setting where the player distributions are unknown in advance, and a player's true value for an item is observed if and only if that player receives the item. This problem can be viewed as a variant of the multi-armed bandits problem, as the goal is to learn unknown distributions (player values) while maintaining high reward (social welfare), subject to fairness constraints; with a finite number of types of items, pulling an arm represents allocating a specific item type to a specific player.

As is standard in the multi-armed bandits literature, we use the notion of _regret_ to measure the difference between our algorithm's performance and that of the optimal policy that knows the value distributions and is subject to the same fairness constraints. Our overarching challenge is this: _design online allocation algorithms that achieve low regret while maintaining fairness in the form of emvy-freeness or proportionality._

### Our Results

Our main result is that there exists a simple optimization-based explore-then-commit algorithm that achieves \((T^{2/3})\) regret and maintains envy-freeness in expectation (Algorithm 1 and Theorem 1). A variant of the same algorithm achieves \((T^{2/3})\) regret while maintaining proportionality in expectation. The key step of the algorithm is a linear program-based optimization that guarantees that the constraints are satisfied without significantly decreasing social welfare.

The main difficulty in this learning problem is that the envy-freeness and proportionality constraints depend on the unknown value distributions and may be tight constraints without any slack. We therefore develop novel machinery that relies on fundamental properties of these fairness notions. One observation is that our fairness constraints are always satisfied when players are treated equally. Another crucial property is that when players have unequal values, these fairness notions can be satisfied with slack (Property 2). The latter property is especially challenging to show for envy-freeness, and the combinatorial algorithm that achieves it (Lemma 1) should be of independent interest to researchers in fair division.

### Related Work

**Online Fair Division.** Work in online fair division generally deals with dividing goods when there is uncertainty about the future. Early work in the area focused on axiomatic questions [31; 1].

Our paper is most closely related to work by Benade et al. . Like us, they consider a setting where indivisible items arrive online and must be allocated immediately and irrevocably to players. They study several models for how the values of items are determined, ranging from a model where values are drawn i.i.d. from a distribution common to all players and items to, at the other extreme, and adversarial model with worst-case values. There are two fundamental differences between their work and ours. First, Benade et al.  do not optimize social welfare; rather, they seek to either just minimize envy, or do so while (approximately) satisfying the axiomatic notion of Pareto efficiency. Second, and more crucially, they assume that the values of all players for an item are known at the time of its arrival, whereas in our model the values are unknown. It is precisely this modeling choice that induces a learning problem and underlies the connection between our setting and multi-armed bandits, which is absent in prior work in online fair division.

Like us, Yamada et al.  also study online fair division through the lens of bandit learning. Their setting is similar to ours in that they consider a finite number of item types where player values for item types are initially unknown. However,  do not guarantee fairness through constraints - instead, they incorporate fairness through their objective function of Nash social welfare.  also make an additional assumption that player values are normalized, which we do not require for our results.

**Fairness in Multi-armed Bandits.** The other main body of literature related to our paper is multi-armed bandits with constraints. One notion of fairness in multi-armed bandits is the idea that similar individuals and/or groups should be treated similarly [9; 18; 23]. The fairness constraint of Joseph et al.  is that a worse arm is not pulled with higher probability than a better arm. Their definition of fairness is actually incompatible with maintaining envy-freeness (or proportionality), because maintaining envy-freeness may require allocating an item to a player with lower value to prevent envy. Another common fairness constraint in multi-armed bandits is that every arm receives a minimum fraction of pulls [10; 11; 20; 28]. This notion of fairness is also not compatible with envy-freeness because the optimal envy-free allocation may never give a player a specific item type. There also exist many other fairness notions in contextual bandits that are farther from our setting [15; 29; 32; 34]. Wei et al.  analyze a form of envy-freeness in contextual bandits, but their envy-freeness notion depends only on the treatment probabilities instead of the values.

Our paper is also closely related to work on multi-armed bandits subject to general linear constraints. Multiple works in linear bandits study "safety" with respect to a linear constraint that depends on the unknown true mean values [2; 8; 26]. Amani et al.  focus on a single constraint and specifically show that if there is positive slack in the optimal solution, then \((T^{1/2})\) regret is possible. If there is zero slack, however, their algorithm only achieves \((T^{2/3})\) regret. This differs from our work because envy-freeness and proportionality involve multiple constraints that can have zero slack. Note that our setting is similar but not equivalent to linear bandits, as a single arm is pulled in each step in our setting. There also exist many results for cumulative constraints in bandits [21; 22]. These are less closely related to our model as we consider constraints that must hold at every time step. Finally, there is a branch of multi-armed bandits that studies constraints in expectation at each step as in our paper. However, these works are also in the linear bandits setting and again require a safety gap that fairness constraints such as envy-freeness may not guarantee .

**Practical Motivation.** Mertzanidis et al.  apply online fair division algorithms through a partnership with a program in Indiana that redistributes rejected truckloads of food. The program, known as Food Drop, allocates 10,000+ pounds of rejected food per month to food banks. In this application, the available food arrives in an online and unpredictable way, and the trucks must be allocated immediately. More generally, the specific food donations depend on what items grocery stores or restaurants have remaining at the end of the day. Therefore, donations are unpredictable, which we model through randomness.

In practice, utilities for food donations such as in the Food Drop program may not be additive. However, if the deliveries are sufficiently infrequent, then additive player utilities are likely to be a good approximation. For example, in the food allocation data of , there were a total of 1760 donations from 169 donors over the course of five months and 277 organizations that received donations. Therefore, the organizations receive donations every 3-4 weeks on average, suggesting that donations can be largely regarded as independent.

## 2 Model

In this section we introduce our basic setting and terminology.

### Online Allocation With Unknown Values

Suppose we have a set of players \(N=[n]\) and a set of object types \(M=[m]\). Given a set of \(T\) indivisible items, an _allocation_\(A=(A_{1},...,A_{n})\) is a partition of the \(T\) items among the \(n\) players, where player \(i\) receives the items in \(A_{i}\). In our model, we assume that every item \(j\) has a type \(k(j)[m]\), and that there exists a (possibly unknown) matrix \(^{*}\) such that each player \(i\)'s value for an item of type \(k[m]\) is independently drawn from a sub-Gaussian distribution with mean \(^{*}_{ik}\). Player values are assumed to be independent across both players and items. We will often refer to \(^{*}_{i}\) as the vector of mean values for player \(i\). For a specific item \(j\), we denote player \(i\)'s value for item \(j\) as \(V_{i}(j)\), and similarly, player \(i\)'s value for their allocation \(A_{i}\) as \(V_{i}(A_{i})=_{j A_{i}}V_{i}(j)\). The (utilitarian) _social welfare_ of an allocation \(A\) is \((A)=_{i=1}^{n}V_{i}(A_{i})\).

We consider algorithms in the following online setting. At each time step \(t[T]\), an item \(j_{t}\) of type \(k_{t}\) arrives, where \(k_{t}\), for some known distribution \(\) supported on \([m]\). We will assume that \(=([m])\), or in other words that every item has an equal probability of being type \(1,...,m\). We make this choice purely for ease of exposition, in order to simplify notation; our results and techniques extend seamlessly to arbitrary distributions \(\) that do not depend on \(T\), as we explain in Appendix C.1. The algorithm observes the item type \(k_{t}\), and must then immediately allocate the item \(j_{t}\) to a player \(i_{t}\), at which time the algorithm observes that player's value \(V_{i_{t}}(j_{t})\). Note that the algorithm does not observe any other player's value for item \(j_{t}\). The high-level goal is to allocate these items in a manner that maximizes the social welfare of the final allocation of all \(T\) items.

We denote \(X^{n m}\) as a valid fractional allocation if \(_{i}X_{ik}=1\) for every \(k[m]\). One valid fractional allocation we will often refer to is the _uniform at random_ allocation (UAR), where every entry is \(\). At every time-step \(t\), before observing \(k_{t}\), the allocation algorithm \(\) takes as input the history \(H_{t}=\{(k_{t^{}},i_{t^{}},_{i^{}},(j_{t^{}})) :t^{}<t\}\) and returns a fractional allocation \(X_{t}=(H_{t})\), where \((X_{t})_{ik}\) represents the probability of allocating the item to player \(i\) if the item is of type \(k\). If the next item is of type \(k_{t}\), then the algorithm allocates the item randomly among the \(n\) players according to the distribution induced by the \(k_{t}^{}\) column of \(X_{t}\), i.e. \((X_{t}^{})_{k_{t}}\). Therefore, the \(t^{}\) item is allocated to player \(i\) with probability \((X_{t})_{ik_{t}}\). We denote the final realized allocation that \(\) returns as \(A()\), and the corresponding partial allocation up to time \(\) as \(A^{}()\). This online process is summarized in pseudo-code in Appendix A.

We will also assume (explicitly in our theorem statements) that for all \(i,k\), there exist known constants \(a,b>0\) such that \(a_{ik}^{*} b\). This assumption is necessary because if we allow the means of values to be arbitrary close to zero, then it can be impossible to achieve regret of \(o(T)\). This is formalized in Theorem 11 in Appendix C.2.

### Fairness Notions

We will primarily use two metrics of fairness to evaluate an online allocation algorithm \(\): envy-freeness in expectation and proportionality in expectation. Both are defined below. For two vectors \(x,y^{n}\), we use \( x,y=x y\) to represent the dot product of the two vectors.

**Definition 1**.: Let \(X_{t}=(H_{t})\) be the fractional allocation used by algorithm \(\) at time \(t\) given history \(H_{t}\). Then \(\) satisfies _envy-freeness in expectation (_EFE_) if for all \(t\) and all \(H_{t}\), \((X_{t})_{i}_{i}^{*}_{i^{}[n]}\;(X_{t})_{i^{}} _{i}^{*}\) for all \(i\).

**Definition 2**.: Let \(X_{t}=(H_{t})\) be the fractional allocation used by algorithm \(\) at time \(t\) given history \(H_{t}\). Then \(\) satisfies _proportionality in expectation (_PE_) if for all \(t\) and all histories \(H_{t}\), \((X_{t})_{i}_{i}^{*}_{i^{}[n]}\;(X_{t})_{i ^{}}_{i}^{*}\) for all \(i\)._

Intuitively, envy-freeness in expectation is equivalent to maintaining that at every time step \(t\) and before observing the item type \(k_{t}\), no player prefers the fractional allocation of any other player in \(X_{t}\). Similarly, proportionality in expectation is equivalent to maintaining that at every time step \(t\) and before observing the item type \(k_{t}\), the expected value of every player for their fractional allocation is at least \(1/n\) times that player's value if they received the item with probability \(1\).

In Appendix B, we justify some of the implicit choices behind these definitions. Specifically, we discuss why we consider envy-freeness in expectation rather than its realization, and also why we require envy-freeness in expectation to hold at every individual time step. Analogous results for proportionality can be found in Appendix B.1. For the former question, Theorem 3 shows that in our setting, no algorithm can with high probability output an allocation \(A()\) with realized envy less than \(\). Note that Benade et al.  show that in the adversarial setting, no algorithm can guarantee \(o()\) realized envy. Conversely, they also show that when values are generated randomly and observed before allocation, there exists an algorithm that _can_ guarantee \(o(1)\) realized envy with high probability. Theorem 3 shows that when values are still generated randomly but are _unknown_ at the time of allocation (as in our setting), no algorithm can guarantee \(o()\) realized envy with high probability. We complement Theorem 3 with Theorem 4, which shows that any algorithm \(\) that satisfies envy-freeness in expectation will output a final allocation \(A()\) with realized envy of at most \((T)\) with high probability. Therefore, envy-free in expectation algorithms are within a \((T)\) factor of being "optimal" in terms of final realized envy.

We also show that requiring envy-freeness in expectation at every time step does not lead to any social welfare loss compared to requiring envy-freeness in expectation only at the end of \(T\) rounds. More specifically, Theorem 5 (again in Appendix B) implies that requiring that no player is envious in expectation of any other player at the end of all \(T\) rounds is equivalent to maintaining envy-freeness in expectation at all times \(t[T]\) when maximizing social welfare. A key step of our proof of Theorem 5 is showing that for every time- or history-dependent algorithm \(\) which achieves envy-freeness in expectation at the end of \(T\) rounds, there exists another algorithm \(^{}\) that is time- and history-independent, envy-free in expectation at every time step, and achieves the same social welfare. Therefore, maximizing social welfare only over algorithms which are envy-free in expectation at every time step is sufficient even if envy-freeness in expectation at the end of \(T\) rounds is all that is desired.

We can formulate our fairness notions as linear constraints, in the spirit of prior work in fair division . Formally, define \( A,B_{F}\) as the Frobenius inner product of matrices \(A\) and \(B\). For \(B^{n m},c\), and a fractional allocation \(X\), we represent the linear constraint \( B,X_{F} c\) as the tuple \((B,c)\). A fractional allocation \(X\) satisfies a set of \(L\) linear constraints \(\{(B_{},c_{})\}_{=1}^{L}\) if for all \([L]\), \( B_{},X_{F} c_{}\). Because the constraints represent "fairness in expectation" relative to the mean values, we will explicitly let the constraint matrix \(B_{}(^{*})\) be a function of the mean value matrix \(^{*}\). Therefore, we will consider sets of constraints of the form \(\{(B_{}(^{*}),c_{})\}_{=1}^{L}\). Because these constraints are functions of \(\), we will also refer to families of constraints \(\{\{(B_{}(),c_{})\}_{=1}^{L}\}_{}\).

The following two remarks show how envy-freeness in expectation and proportionality in expectation can be represented within this framework.

**Remark 1**.: For every \([n^{2}]\), construct \(B_{}^{}(^{*})\) as follows. Define \(i=\) and \(i^{}=( n)+1\). For every \(k[K]\), let \((B_{}^{}(^{*}))_{ik}=_{ik}^{*}\) and \((B_{}^{}(^{*}))_{i^{}k}=-_{ik}^{*}\). For all \(i^{}\{i,i^{}\}\), let \((B_{}^{}(^{*}))_{i^{}}=0\). Then the envy-freeness in expectation constraints for mean \(^{*}\) as defined in section 1 correspond to \((^{*}):=\{(B_{}^{}(^{*}),0)\}_{=1}^{n^ {2}}\).

**Remark 2**.: For every \([n]\), construct \(B_{}^{}(^{*})\) as follows. For every \(k[m]\), \((B_{}^{pe}(^{*}))_{ k}=_{tk}^{*}\) and \((B_{}^{pe}(^{*}))_{ik}=-_{tk}^{*}\) for every \(i\). Then the proportionality in expectation constraints for mean \(^{*}\) as defined in Definition 2 correspond to \((^{*})=\{(B_{}^{pe}(^{*}),0)\}_{=1}^{n}\).

### Regret and Problem Formulation

An algorithm \(\) satisfies constraints \(\{(B_{}(^{*}),c_{})\}_{=1}^{L}\) if for all \(t[T]\), the fractional allocation \(X_{t}\) used by \(\) at time \(t\) satisfies the constraints \(\{(B_{}(^{*}),c_{})\}_{=1}^{L}\). When \(^{*}\) is known, the expected social welfare can be directly optimized over all algorithms \(\) that satisfy constraints \(\{(B_{}(^{*}),c_{})\}_{=1}^{L}\). This problem is equivalent to solving LP (1) with \(=^{*}\) and using the solution \(Y^{^{*}}\) as the fractional allocation for all time steps.

\[Y^{}:=\  X,_{F}\] \[\  B_{}(),X_{F} c_{} \] \[_{i}X_{ik}=1 k\] (1)

When \(^{*}\) is unknown, we define the regret of an algorithm \(\) as follows. Note that the baseline algorithm in this definition of regret is the optimal allocation algorithm under the constraints when \(^{*}\) is known.

**Definition 3**.: Let \(Y^{^{*}}\) be the solution to LP (1) for \(=^{*}\). Let \(X_{t}=(H_{t})\) be the fractional allocation used by algorithm \(\) at time \(t\) given history \(H_{t}\). Then the \(T\)-step regret of \(\) for constraints \(\{(B_{}(^{*}),c_{})\}_{=1}^{L}\) is \(T Y^{^{*}},^{*}_{F}-_{t=0}^{T-1} X_{t},^ {*}_{F}\).

We are now ready to present the formal problem statement. Because the constraints depend on the unknown values that are being learned, we only require constraint satisfaction with high probability.

**Problem 1**.: _Suppose we are given \(n,m,T,a,b\) such that \(0<a_{ik}^{*} b\) for all \(i[n]\), \(k[m]\). Given a family of fairness constraints \(\{\{(B_{}(),c_{})\}_{=1}^{L}\}_{}\) representing either envy-freeness in expectation or proportionality in expectation, the goal is to construct an algorithm \(\) such that with probability \(1-1/T\), \(X_{t}=(H_{t})\) satisfies the constraints \((B_{}(^{*}),c_{})\}_{=1}^{L}\) for all \(t[T]\) and the regret of \(\) for constraints \((B_{}(^{*}),c_{})\}_{=1}^{L}\) is \(o(T)\)._

Note that the \(o(T)\) regret in Problem 1 will be \((T^{2/3})\) for our results. We use the standard \(O()\) and \(()\) notation with respect to the number of time steps \(T\), and therefore the constants represented by this notation may depend on other problem parameters such as \(n\) and \(m\).

## 3 Fairness Machinery

Our goal in this section is to establish novel, fundamental properties of envy-freeness and proportionality in expectation, which will serve as a crucial part of the machinery underlying our regret bounds.

In the context of fairness, a natural assumption is that if a group of individuals are treated equally, then that group is considered to be treated fairly. In that spirit, our first key property is as follows.

**Property 1**.: _For any \([L]\), suppose that a fractional allocation \(X^{n m}\) satisfies \(X_{i_{1}}=X_{i_{2}},\; i_{1},i_{2}\{i:B_{}()_{i}\}\). Then \( B_{}(),X_{F} c_{}\)._

Informally, a set of constraints satisfies Property 1 if for any constraint in the set, the constraint is always satisfied when all players involved in the constraint have the same fractional allocation. An important consequence of Property 1 is that the uniform at random allocation satisfies every constraint. This implies that even with no information about the players' mean values, the uniform at random allocation will always be fair.

Note that envy-freeness in expectation satisfies Property 1 because any two players with equal allocations are never envious of each other. Proportionality in expectation also satisfies Property 1, because if every player has the same allocation, then every player is receiving exactly their proportional allocation.

**Observation 1**.: _The envy-freeness in expectation and proportionality in expectation constraints satisfy Property 1._

Our second key property is more technical and novel. Intuitively, the property requires the existence of a fractional allocation \(X^{}\) that is only slightly worse than the optimal constrained allocation \(Y^{}\), but unlike the latter allocation, in \(X^{}\) the constraints either hold with slack or all players involved in the constraint are treated equally. Interestingly, this property does not hold for arbitrary sets of linear constraints, but relies on structure inherent to the envy-freeness in expectation and proportionality in expectation constraints. The bulk of the theoretical work of this paper is proving that the envy-freeness in expectation and proportionality in expectation constraints satisfy this property.

**Property 2**.: _Let \(Y^{}\) be the solution to LP (1). Then there exists constants (relative to \(T\)) \(_{0}\) and \(C_{2}>0\) such that for any \(<_{0}\) and any \(\), there exists a fractional allocation \(X^{}\) such that \( X^{},_{F} Y^{},_{F}-C_{2}\), and such that for each \([L]\), either_

1. \( B_{}(),X^{}_{F} c_{}+\) _or_
2. \( i_{1},i_{2}\{i:B_{}()_{i}\}\)_,_ \(X^{}_{i_{1}}=X^{}_{i_{2}}\)_._

**Lemma 1**.: _The family of envy-freeness in expectation constraints satisfies Property 2._

Proof sketch.: We will informally argue that we can transform \(Y^{}\) into a fractional allocation \(X^{}\) which satisfies Property 2 through Algorithm 3. Algorithm 3 iterates over 'envy-with-slack-\(\)' graphs, which track whether a player prefers their allocation by at least \(\) over another player's allocation. More specifically, given parameters \(,X,\) and \(\), the corresponding 'envy-with-slack' graph has vertices \(N\) and edge set \(E\) such that a directed edge from \(i\) to \(i^{}\) exists if and only if \(X_{i}_{i}-X_{i^{}}_{i}<\). The weight of each such edge is \(X_{i}_{i}-X_{i^{}}_{i}\). At a high level, Algorithm 3 constructs 'envy-with-slack-\(\)' graphs with progressively smaller \(\), with \(\) for all iterations. The algorithm operates on sets of nodes called _equivalence classes_, where every pair of nodes in an equivalence class has the same allocation. Algorithm 3 makes progress in every iteration by either 1) merging two equivalence classes, or 2) removing an edge from the graph.

An overview of the algorithm is as follows. In each iteration, Algorithm 3 generally performs one of three operations and decreases \(\). First, if there exists an equivalence class \(S\) with at least one incoming edge but no outgoing edges, then operation remove-incoming-edge transfers allocation probability from nodes in \(S\) to all other nodes. This will remove all incoming edges to \(S\). If such an equivalence class does not exist, then Algorithm 3 finds a special type of directed cycle in the 'envy-with-slack' graph. The directed cycle is chosen so that the outgoing edge of each node \(i\) in the cycle is among \(i\)'s outgoing edges with minimal weight. Therefore, each node \(i\) in the cycle is pointing to an \(i^{} N\) for whom \(i\) has the least slack. If there exists some node \(i^{*} N\) which has an edge to some but not all of the nodes in the cycle, then operation cycle-shift gives each node in the cycle half of its current allocation and half of the next node's allocation. This will remove an outgoing edge from \(i^{*}\). If such a node does not exist, then Algorithm 3 either decreases \(\) to remove an edge or creates a new equivalence class by merging all equivalence classes that the nodes in the cycle belong to via operation average-clique.

However, such a merge may lead to envy, which is removed by Algorithm 4. Each call to Algorithm 4 removes envy from at least one edge. Algorithm 4 does so by first carefully redistributing allocation among the nodes until there exists a cycle where each node has non-negative envy (which is equivalent to a cycle with non-positive slack). Each node in the cycle is then given the allocation of the nextnode in the cycle. We prove that each call to Algorithm 4 decreases the number of edges with envy, while not increasing the number of edges in the 'envy-with-slack' graph. Furthermore, Algorithm 4 does not significantly decrease the social welfare of the allocation.

The three operations and Algorithm 4 each take as input an allocation \(X\) and returns a new allocation \(X^{}\) which is close in social welfare to \(X\). Furthermore, each iteration begins with an envy-free allocation, and the size of the edge set of the 'envy-with-slack' graphs never increases throughout the algorithm. The maximum size of an equivalence class is \(n\), so an edge must be removed from the 'envy-with-slack' graph every \(n\) iterations. There are at most \(n^{2}\) edges, and the algorithm therefore terminates in at most \(n^{3}\) iterations with an allocation which satisfies Property 2. For the numerous details, see Appendix F. 

**Lemma 2**.: _The family of proportionality in expectation constraints satisfies Property 2._

Proof sketch.: Define the slack \(S_{i}\) of a player \(i\) for an allocation as the amount by which that player's value for their allocation is greater than their proportional value. In other words, the slack is the amount of welfare a player can lose and still satisfy the proportionality constraint. We construct the fractional allocation \(X^{}\) in one of two different ways depending on the amount of total slack for the allocation \(Y^{}\) across all \(n\) players.

If the amount of total slack across all \(n\) players is less than \(\), then we take \(X^{}=\). Note that the total slack is equivalent to the change in social welfare between \(Y^{}\) and UAR. Therefore, because the total slack was less than \(\), the difference in social welfare between \(Y^{}\) and UAR is at most \(\) which is \(O()\). Furthermore, by definition the UAR allocation satisfies option 2 of Property 2 for all constraints \(\).

If the amount of total slack is greater than \(\), then we construct \(X^{}\) from \(Y^{}\) by transferring allocation away from players with slack greater than the required \(\) and redistributing this allocation so that every player has slack of at least \(\). Specifically, each player \(i\) loses \(_{ik}\) of their allocation for item \(k\), where

\[_{ik}:=_{ik}}{_{k^{}=1}^{m}Y^{}_{ik^{}} }}{_{i^{}=1}^{n}S_{i^{}}} {a}.\]

The allocation \(X^{}\) is then constructed as

\[X^{}_{ik}:=Y^{}_{ik}-_{ik}+_{i^{}=1}^{n} _{i^{}k}.\] (2)

Intuitively, this can be viewed as each player putting a part of their allocation (proportional to \(S_{i}\)) into a communal "pot." The pot, consisting of \(_{i^{}=1}^{n}_{i^{}k}\) for item \(k\), is then divided evenly among all \(n\) players to form \(X^{}\). By construction, no player loses more than \(S_{i}\) social welfare when the pot is created, and every player receives at least \(\) additional social welfare when the pot is redistributed. Therefore, in the resulting allocation \(X^{}\), every player prefers their allocation to their proportional value by at least \(\), i.e. each player has a slack of at least \(\) for \(X^{}\). Furthermore, the total difference in social welfare between \(Y^{}\) and \(X^{}\) is at most \(O()\). We have thus shown that in both cases, \(X^{}\) will satisfy all of the desired conditions. The full proof is relegated to Appendix E. 

It will be useful to introduce two further properties that are immediately satisfied by the definitions of envy-freeness in expectation and proportionality in expectation. Property 3 guarantees a form of Lipschitz continuity in \(\) for the constraints. This is unsurprising, as the entries in the matrices \(B_{}()\) for both envy-freeness in expectation and proportionality in expectation are linear in the entries of \(\). Property 4 guarantees that the non-zero entries in the constraint matrices stay the same for all values of \(\), which follows directly from Remarks 1 and 2 and the fact that \(_{ik}\) is bounded away from \(0\).

**Property 3**.: _There exists a \(K>0\) such that \(^{1},^{2}[a,b]^{n m}\) and \(>0\), if \(\|^{1}-^{2}\|_{1}\) then \(\|B_{}(^{1})-B_{}(^{2})\|_{1} K\)._

**Observation 2**.: _The envy-freeness in expectation and proportionality in expectation constraints satisfy Property 3._

**Property 4**.: _For all \(,^{}[a,b]^{n m}\), \(\{i:B_{}()_{i}\}=\{i:B_{}(^{})_{i}\}\)._

**Observation 3**.: _The envy-freeness in expectation and proportionality in expectation constraints satisfy Property 4._

Recall that Property 2 implies that for every constraint \(\), either the constraint \(\) has a slack of at least \(\) for \(X^{}\) or every player involved in constraint \(\) is treated equally under allocation \(X^{}\). A slack of \(\) in the constraint guarantees constraint satisfaction for all \(^{}\) close to \(\) if the constraints are continuous in \(\). Treating every player equally for a given constraint also guarantees that the constraints are satisfied for all \(^{}\) by Property 1. Therefore, Properties 1 and 2 together with continuity (Property 3) imply that there exists a fractional allocation \(X^{}\) such that the social welfare of \(X^{}\) is close to the social welfare of \(Y^{}\) and such that \(X^{}\) not only satisfies the constraints for \(\), but also satisfies the constraints for any \(^{}\) close to \(\).

## 4 Algorithm and Regret Bounds

In this section, we present our main result, an explore-then-commit algorithm which achieves \((T^{2/3})\) regret while maintaining either proportionality in expectation or envy-freeness in expectation. The key step in Algorithm 1 is the optimization in LP (3) to guarantee that the fairness constraints are satisfied with high probability. For \(_{+}^{n m}\) and \(_{+}^{n m}\), we define the confidence region \(=\{^{}^{n m}:_{ik}-_{ik} ^{}_{ik}_{ik}+_{ik}\: i,k\}\). Note that Algorithm 1 requires solving LPs with an infinite number of constraints, which we discuss further in Section 6.

```
0:\(n,m,T,\{(\{B_{}(),c_{}\})_{=1}^{L}\}_{}\) for\(t 1\) to \(T^{2/3}-1\)do  At time \(t\), use fractional allocation \(X^{t}=\). endfor \(N_{ik}_{=0}^{T^{2/3}-1}_{k_{}=k,i_{}=i}\) \(_{ik}}_{=0}^{T^{2/3}-1}_{k _{}=k,i_{}=i}V_{i_{}}(j_{})\) \(_{ik}=(4Tnm)/(2N_{ik})}\) \(\) Solution to the following LP: \[_{X}  X,_{F}\] s.t. \[ B_{}(),X_{F} c_{} [L],\] \[_{i=1}^{n}X_{ik}=1 k\] (3) for\(t T^{2/3}\) to \(T-1\)do  At time \(t\), use fractional allocation \(X^{t}=\). endfor ```

**Algorithm 1** Fair Explore-Then-Commit

**Theorem 1**.: _Suppose we are given \(n,m,T,a,b\) such that \(0<a^{*}_{ik} b\) for all \(i[n]\), \(k[m]\). If \(\{\{(B_{}(),c_{})\}_{=1}^{L}\}_{}=\{()\}_{}\) or \(\{\{(B_{}(),c_{})\}_{=1}^{L}\}_{}=\{()\}_{}\), then Algorithm 1 with probability \(1-1/T\) satisfies the constraints \(\{(B_{}(^{*}),c_{})\}_{=1}^{L}\) and achieves regret of \((T^{2/3})\) for constraints \(\{(B_{}(^{*}),c_{})\}_{=1}^{L}\)._

Proof sketch.: We have already shown in Section 3 that both envy-freeness in expectation and proportionality in expectation satisfy Properties 1, 2, 3, and 4. Therefore, it suffices to show that Algorithm 1 achieves \((T^{2/3})\) regret for any family of constraints \(\{\{(B_{}(),c_{})\}_{=1}^{L}\}_{}\) that satisfies Properties 1, 2, 3, and 4.

The allocations used during the warm-up steps of Algorithm 1 are uniform at random, and therefore these allocations satisfy the constraints \(\{(B_{}(),c_{})\}_{=1}^{L}\) for all \(\) by Property 1. Because the fractional allocations used in the first \(T^{2/3}\) steps are all \(\), each arm, or (player, item) pair, will be sampled with probability \(\) at each step. This implies by Hoeffding's inequality that with high probability, \(N_{ik}=(T^{2/3})\) for all \(i,k\). The \(i,k\) entry in the \(\) matrix is proportional to \(}}\), andtherefore \(\|\|_{1}=(T^{-1/3})\) with high probability. Because the value distributions are sub-Gaussian, a standard application of Hoeffding's inequality also gives that with high probability, the true mean matrix will be within our confidence region, i.e. \(^{*}\). To summarize, because we used \(\) for the first \(T^{2/3}\) steps, we have that

\[(\|\|_{1}(T^{-1/3}),^{*} ) 1-.\]

For the rest of the proof we will assume that the high probability event in the equation above holds. The next step is to show that \(\) has \(\|\|_{1}\) per-step regret compared to \(Y^{^{*}}\). Let \(K\) be the Lipschitz constant of Property 3. Using Property 2 with \(=^{*}\) and \(=2K\|\|_{1}=(T^{-1/3})\) gives that there exists an allocation \(X^{}\) such that the social welfare of \(X^{}\) is only \(O(\|\|_{1})\) less than the social welfare of the optimal allocation \(Y^{^{*}}\) and such that every constraint \(\) either has slack of at least \(2K\|\|_{1}\) (option 1 of Property 2) or every player is treated equally in constraint \(\) (option 2 of Property 2). We will now show that \(X^{}\) is a solution to LP (3). If option 1 holds for constraint \([L]\), then by Property 3, \(X^{}\) will satisfy the constraint \((B_{}(),c_{})\) for every \(\). Formally, if option 1 holds for constraint \(\), then for any \(\),

\[ B_{}(),X^{}_{F} = B_{}(),X^{}_{F}- B_{}( ^{*}),X^{}_{F}+ B_{}(^{*}),X^{}_{F}\] \[= B_{}()-B_{}(^{*}),X^{}_{F}+  B_{}(^{*}),X^{}_{F}\] \[ B_{}(^{*}),X^{}_{F}-\|B_{}( )-B_{}(^{*})\|_{1} _{ik} 1,\; i,k$]}\] \[ B_{}(^{*}),X^{}_{F}-2K\| \|_{1} \] \[ c_{}.\] [Property 2: option 1]

If option 2 holds for constraint \([L]\), then Properties 1 and 4 together guarantee that \(X^{}\) will satisfy the constraint \((B_{}(),c_{})\) for every \(\). Therefore, \(X^{}\) will satisfy all of the constraints \(\{B_{}(),c_{}\}_{=1}^{L}\) for every \(\), which implies that \(X^{}\) is a solution to LP (3).

Finally, because \(\) is the optimal solution to LP (3), \(\) must have higher social welfare than \(X^{}\) under means \(\). Because \(\|^{*}-\|_{1}\|\|_{1}\), this implies that \(\) must have at most \(O(\|\|_{1})\) less social welfare than \(X^{}\) under the true means \(^{*}\). An application of the triangle inequality gives that,

\[ Y^{^{*}},^{*}_{F}-,^{*} _{F} = Y^{^{*}},^{*}_{F}- X^{},^{* }_{F}+ X^{},^{*}_{F}-,^{*} _{F}\] \[=(\|\|_{1}+\|\|_{1})\] \[=(T^{-1/3}).\]

Thus, the total regret for the steps after the warm-up period is \((T^{2/3})\). The regret of the warm-up period is at most \((b-a)T^{2/3}\) due to the assumption that the mean values are bounded. We can therefore conclude that the total regret is \((T^{2/3})\), and this completes the proof of regret. Finally, we note that by construction of LP (3), if \(^{*}\) then the chosen fractional allocations \(\) must also satisfy the constraints \(\{(B_{}(^{*}),c_{})\}_{=1}^{L}\) as desired. See Appendix D for the full proof. 

## 5 Lower bounds

The following lower bound shows that Theorem 1 is tight up to \(\) factors. An equivalent result holds for proportionality, with the same proof.

**Theorem 2**.: _There exists \(a,b,n,m\) such that no algorithm can, for all \(^{*}[a,b]^{n m}\), both satisfy the envy-freeness constraints and achieve regret of less than \(}{(T)}\) with probability at least \(1-1/T\). The same is true for the proportionality constraints._

Proof sketch.: We defer the formal proof to Appendix G and provide brief intuition here.

Suppose there are two item types and two players. In this case envy-freeness and proportionality are equivalent, and therefore we will focus on the former. Consider the following two mean value matrices.

\[_{1} =2&3\\ 1&1 _{2} =2&3\\ 1&1+T^{-1/3}\]We will show that no algorithm can with probability \(1-1/T\) achieve regret of less than \((T^{2/3})\) and satisfy envy-freeness in expectation for both of these distributions. First, note that the expected social welfare maximizing allocation for \(_{1}\) is to give all items of type 1 to player 2 and all items of type 2 to player 1. On the other hand, any envy-free allocation for \(_{2}\) must give \((T^{-1/3})\) fraction of items of type 2 to player 2. This implies that if an algorithm is unable to distinguish between \(_{1}\) and \(_{2}\), then either the regret will be \((T^{2/3})\) for \(_{1}\) or the algorithm will not be envy-free for \(_{2}\).

Therefore, any algorithm that has regret of less than \((T^{2/3})\) and satisfies envy-freeness for both \(_{1}\) and \(_{2}\) must distinguish between \(_{1}\) and \(_{2}\). The only way to do this is to allocate at least \((T^{2/3})\) items of type \(2\) to player 2. However, this will result in regret under \(_{1}\) of \((T^{2/3})\). 

## 6 Discussion

We conclude by discussing some limitations and open questions. First, Algorithm 1 involves solving a linear program with an infinite number of linear constraints. Linear programs with an infinite number of constraints (called semi-infinite programs) are well-studied and occur in many applications [16; 24]. We also note that a finite number of (exponentially many) constraints suffices for envy-freeness in expectation and proportionality in expectation by bounding all of the possible extreme values of \(\). Nevertheless, we opted to avoid this representation because it significantly complicates the presentation of the algorithm. Furthermore, there also exists a polynomial time separation oracle for determining whether an allocation satisfies the infinitely many constraints, which would allow techniques such as the Ellipsoid Method  to solve the linear program in polynomial time.

Second, while the regret coefficients for proportionality are polynomial in \(n\), a practical limitation of Algorithm 1 for envy-freeness is that the \(\) term is exponential in \(n\). We expect, however, that the worst-case bound we present in Lemma 1 is far from tight. Whether there exists a bound on the regret that is polynomial in \(n\) for learning under envy-freeness in expectation constraints is an open question for future work.

The other natural question that remains open for future work is whether we can achieve \(()\) regret while maintaining envy-freeness in expectation or proportionality in expectation. If the optimal solution \(Y^{^{*}}\) has a positive slack in every constraint, then an upper confidence bound (UCB) approach would be likely to work. Unfortunately, the fairness constraints for envy-freeness in expectation and proportionality in expectation are often tight for the optimal allocation. Furthermore, the constraints have a constant (greater than \(1/n\)) dependence on every unknown value in the \(^{*}\) matrix. Therefore, every mean value \(^{*}_{ik}\) might need to be learned with high accuracy even if the optimal allocation does not allocate item type \(k\) to player \(i\).

We also note that there exist additional (albeit less prominent) fairness notions for the problem of online fair division, such as equitability, which may satisfy additional properties that allow for lower regret. We leave the question of studying more fairness notions for future work.

Finally, a broader question is whether the connection we have established between multi-armed bandits and online fair division might be leveraged to give a fresh perspective on additional problems in this area, such as online cake cutting .