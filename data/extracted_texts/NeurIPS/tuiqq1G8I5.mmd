# DisCEdit: Model Editing by Identifying Discriminative Components

Chaitanya Murti

Robert Bosch Centre for Cyberphysical Systems

Indian Institute of Science

mchaitanya@iisc.ac.in

&Chiranjib Bhattacharyya

Computer Science and Automation

Robert Bosch Centre for Cyberphysical Systems

Indian Institute of Science

chiru@iisc.ac.in

###### Abstract

Model editing is a growing area of research that is particularly valuable in contexts where modifying key model components, like neurons or filters, can significantly impact the model's performance. The key challenge lies in identifying important components useful to the model's predictions. We apply model editing to address two active areas of research, Structured Pruning, and Selective Class Forgetting. In this work, we adopt a distributional approach to the problem of identifying important components, leveraging the recently proposed _discriminative filters hypothesis_, which states that well-trained (convolutional) models possess discriminative filters that are essential to prediction. To do so, we define discriminative ability in terms of the Bayes error rate associated with the feature distributions, which is equivalent to computing the Total Variation (TV) distance between the distributions. However, computing the TV distance is intractable, motivating us to derive novel witness function-based lower bounds on the TV distance that require no assumptions on the underlying distributions; using this bound generalizes prior work such as Murti et al.  that relied on unrealistic Gaussianity assumptions on the feature distributions. With these bounds, we are able to discover critical subnetworks responsible for classwise predictions, and derive DisCEdit-SP and DisCEdit-U, algorithms for structured pruning requiring no access to the training data and loss function, and selective forgetting respectively. We apply DisCEdit-U to selective class forgetting on models trained on CIFAR10 and CIFAR100, and we show that on average, we can reduce accuracy on a single class by over 80% with a minimal reduction in test accuracy on the remaining classes. Similarly, on Structured pruning problems, we obtain 40.8% sparsity on ResNet50 on Imagenet, with only a 2.6% drop in accuracy with minimal fine-tuning. 1

## 1 Introduction

The black-box nature of neural networks makes understanding the precise mechanism by which a neural network makes a prediction (in the classification or regression settings), or generates a sample (in the generative settings) an active area of research , and relevant to several related problems,such as robustness, sparsity, and memorization. In particular, recent work aims to address this problem by identifying which _components_ - such as neurons, convolutional filters, or attention heads - in the model contribute most significantly to predictions . Prior work addressing this problem includes , which identified important filters by using human-defined concepts, and aligning them with filter responses to those concepts, whereas more recent work , uses an exhaustive regression-based approach. The field of structured pruning  also provides a variety of heuristics for component importance, including first- and second-order derivative information , feature map ranks , and layerwise reconstruction errors . Component attribution has also found attention in the fields of machine unlearning , where class-wise important components can be identified and edited to remove information about a given class or group.

In this work, we address this problem from a _distributional_ milieu: that is, by analyzing the distributions of feature maps for models trained on datasets with distinct classes or subgroups. Specifically, we use the _discriminative filters hypothesis (DFH)_ stated in , which states that well-trained models for classification possess a mix of _discriminative filters_ - filters that yield feature maps with distinct class-conditional distributions - and non-discriminative filters and that the discriminative filters are important to model predictions. Discriminative filters can be used to identify which filters contribute to the prediction for samples from a given class. Under restrictive assumptions of Gaussianity, the DFH was used in  to derive a structured pruning algorithm that required only some form of distributional access, and no access to the loss function and training set. However, several key challenges remain. First, is it possible to identify discriminative filters without restrictive assumptions on the filter outputs? Second, can discriminative filters be used in settings other than structured pruning? Last, can the performance of algorithms leveraging the DFH be improved upon with better identification of discriminative filters? In this work, we answer each of the questions affirmatively.

First, to identify discriminative filters without unrealistic assumptions on the feature map distributions, we derive tractable, witness function-based lower bounds on the Total Variation (TV) distance, with which we also reveal hitherto unknown ties between the TV distance and classical, discrimination-based classifiers. We then use our proposed methodology to identify discriminative filters for classwise model unlearning and structured pruning, which we call DisCEdit: **Dis**criminative **C**omponent identification for model **Editing**. Our methodology is simple - we first identify discriminative filters for a given class, and prune them (for class forgetting), called DisCEdit-U, or in the case of structured pruning, prune filters that are non-discriminative for all classes, called DisCEdit-SP. Note that our method for identifying discriminative filters requires only distributional access, and neither the training data nor the loss function. We illustrate our approach in Figure 1, and formally state our contributions below.

**Discriminative ability of a filter:** We quantify the discriminative ability of a filter in a neural network, as the worst possible Bayes error rate of binary classifiers trained upon the features it generates(See Section 3). Since, in general, computing the Bayes' error rate is intractable, we seek to approximate it using lower bounds on the TV distance.

**Witness function based Distribution Agnostic Lower bound on TV distance:** In order to identify discriminative filters without distributional assumptions, we propose a novel witness function-based lower bound on the TV distance between distributions to address this gap in Theorem 1. We propose a lower bound that relies only on knowledge of finitely many moments(Theorem 2) and derive another lower bound accounting for moment measurement errors in Theorem 3. These bounds do not require distribution-specific assumptions and hence enable this work to generalize previous work , which requires the distributions to be Gaussian( which is an unrealistic assumption). To be noted that these bounds are of independent interest as they are broadly applicable. Moreover, using a careful choice of witness function, our bounds reveal new connections between discriminant-based classifiers like

Figure 1: Identifying Discriminative Components for Model Unlearning and Structured Pruning

the Fisher linear discriminant and the Minimax Probability Machine, and the TV distance, which we state in Corollary 2.

**Model Editing using Lower Bounds:** We apply our lower bounds to the problem of identifying which components in a model contribute to predictions from certain classes.

1. **Class Unlearning:** We identify components capable of discriminating each class, which we then prune in order to unlearn that class, requiring no access to the loss function, called DisCEdit-U.
2. **Pruning without the training data or loss function:** Next, we derive a family of algorithms for structured pruning requiring no access to the training data or loss function by identifying non-discriminative filters with our proposed lower bounds, called DisCEdit-SP.

**Experimental Validation:** We produce a slate of experiments to illustrate the efficacy of identifying discriminative components for structured pruning and machine unlearning/class forgetting. We compare the efficacy of DisCEdit-SP for pruning VGG nets and ResNets trained on CIFAR10, and show that we achieve up to 76% sparsity with a.12% reduction in accuracy on VGG19, and on Imagenet, we achieve 40.8% sparsity with a 2.58% drop in accuracy with minimal fine-tuning. Similarly, for machine unlearning, we show that our method enables 83% drop in accuracy on the class to be forgotten, with a 1.2% increase in accuracy on the remaining classes, without any finetuning.

### Related Work

In this section, we introduce a brief summary of related literature. We provide a more detailed discussion of the literature in Appendix A.

Structured pruningStructured pruning reduces the inference time and power consumption of neural networks by removing entire filters or neurons, as opposed to unstructured pruning that removes individual weights [29; 18]. A variety of structured pruning methods require the loss function, and identify import components using gradient information [38; 30], or approximations of the Hessian of [29; 18; 51; 36].

A variety of structured pruning methods that do not rely on the loss function have been proposed, which identify important components by norms of the weights [31; 32], bounds on the reconstruction error incurred by pruning a filter [41; 59], the rank of the feature maps [35; 52], and coresets of feature maps . More recent approaches identify components based on the discriminative ability of the corresponding featuremaps, using metrics like the Hellinger distance between class-conditional feature maps , or Fisher discriminant-based methods [20; 21]. In this work, we formalize the notion of discriminative ability in terms of the Bayes risk and derive novel lower bounds on the total variation distance to approximate it effectively. Unlike previous works, we make no assumptions about the class-conditional distributions, and our pruning algorithms require no access to the training data or loss function. For a more comprehensive discussion on structured pruning, we refer readers to Appendix A or the surveys [19; 4].

Machine unlearningMachine Unlearning has recently received significant attention due to concerns like data privacy and security [5; 42]. A variety of works propose methods to forget data points while maintaining model accuracy, even in adaptive settings [47; 16; 22; 14]. Selective forgetting, where classes or groups are forgotten, connects machine unlearning to continual learning [58; 57]. Model editing for unlearning, however, remains an underexplored area of research. Recent studies machine unlearning can be enhanced by sparsifying models [23; 46], and discrimination-aware pruning has been used in federated settings  and for forgetting specific classes . Our work differs by directly utilizing the discriminative ability of model components to identify and remove those responsible for a given class, enabling effective unlearning without access to the original training data. For a more detailed discussion, we refer readers to Appendix A.

## 2 Background and Notation

In this section, we introduce our notation and provide basic background definitions.

NotationFor an integer \(N>0\), let \([N]:=\{1,,N\}\). Let \(_{N}\) be a vector of zeros of dimension \(N\). Let \(_{B}(\{a_{1},,a_{M}\})\) be the set of the \(B\) largest elements of \(\{a_{1},,a_{M}\}\). Suppose \(,\ \) are two distributions supported on \(\), with densities given by \(p(x)\) and \(q(x)\). For a function \(f:\), let \(_{p}=_{x}[f(x)]\), and let \(_{p}^{(2)}=_{x}[f(x)^{2}]\). Let \(\) be a data distribution. Suppose the dataset has \(C\) classes, then let \(_{c}\) be the class-conditional distribution of the \(c\)-th class, and let \(_{c}\) be the distribution of the complement of \(c\) (that is, samples are drawn from all classes other than \(c\)).

Suppose we have a neural network \(=(W_{1},,W_{L})\). Each layer yields (flattened) representations

\[Y^{l}(x)=[Y_{1}^{l}(X),,Y_{N_{l}}^{l}(X)],\] (1)

where \(N_{l}\) is the number of filters in layer \(l\). Since \(Y^{l}\) is dependent on \(X\), we assume that \(Y^{l}(X)^{l}\), and \(Y_{j}^{l}(X)_{j}^{l}\). Furthermore, let \(_{j,c}^{l}\) and \(_{j,c}^{l}\) be the class-conditional distributions and class-complement distributions of \(Y_{j}^{l}(X)\) respectively.

BackgroundIn this section, we provide relevant background for this work. First, let \(\) and \(\) be distributions supported on \(\), with moments \(_{p},_{p}\) and \(_{q},_{q}\). Then, recall that

\[(,;u)=(_{p}-_{q}) )^{2}}{u^{}(_{p}+_{q})u} (,;u)=(_{p}-_{q})|}{ _{p}u}+_{q}u}}.\] (2)

where \(\) denotes the Fisher discriminant , and \(\) denotes the Minimax probability machine [27; 28]. If we choose the optimal \(u\), denoted by \(u^{*}\), we write \(_{u}(,;u)=(,;u^{*})=^{*}(,)\) and \(_{u}(,;u)=(,;u^{*})=(,)^{*}\).

We define the TV and Hellinger distances as follows.

**Definition 1**.: _Let \(\) and \(\) be two probability measures supported on \(X\), and let \(p\) and \(q\) be the corresponding densities. Then, we define the Total Variation Distance_ TV _as_

\[(,)=_{A X}|(A)-(A)|=_{X}|p(x)-q(x)|dx\]

The _Bayes Optimal classifier_, as given in [9; 8], associated with distributions \(\) and \(\) with labels \(-1\) and \(1\) respectively is given by

\[f(x)=*{arg\,max}_{c\{-1,1\}}(c|x),\]

and has the error rate \(R^{*}(,)\), called the _Bayes Error Rate_. Next, we relate the Bayes classifier and the Bayes error rate (as described in, say, Devroye et al. ) of a classifier to the TV distance with the following identity. Consider a binary classification problem with instance \(x\) and labels \(c\{-1,1\}\), with class conditional distributions given by \(\) and \(\). The Bayes error rate satisfies the identity

\[2R^{*}(,)=1-(,).\] (3)

## 3 Editing Models by Identifying Discriminative Components

There are three central questions addressed in this work:

1. **Model Unlearning:** How do we edit components in order to reduce accuracy on certain groups or classes only?
2. **Structured pruning:** How do we remove components to ensure that the accuracy of all classes is minimally affected?
3. **Determining the Discrimination Ability of a Model Component:** How do we assess the Discrimination ability of filters without access to the training data or loss function, and without making any assumptions about the class-conditional feature distributions?

Inspired by Murti et al. , the key idea in this work for addressing each of the questions raised above is to identify _discriminative components_, that yield feature maps upon which accurate classifiers can be trained, and thus with distinct class-conditional distributions. A heuristic to address this problem would be to train a classifier upon the feature map; those features upon which accurate classifiers can be trained are generated by discriminative filters; however, this is highly impractical. Thus, as with , we address this problem by identifying filters for which the class-conditional distributions of the feature maps are distinct, which are identified based on estimates of the total variation distance between the class-conditional distributions of the associated feature maps. In this work, we formalize _discriminative ability_ of a component in terms of the best possible classifier that can be trained on the features generated by it. In the sequel, we illustrate similar but distinct notions of discriminative ability important for classwise unlearning, and structured pruning. We first formally define _discriminative ability_ and the _class-\(c\) discriminative ability_ as follows.

**Definition 2** (Discriminative Ability).: _Consider a CNN with \(L\) layers trained on a dataset with \(C\) classes, and consider the \(j\)th filter in the \(l\)th layer. The_ **class-\(c\) discriminative ability**_\(_{l,j}^{c}\), and the_ **discriminative ability**_\(_{l,j}\) of the filter are given by_

\[_{l,j}^{c}=R^{*}(_{j,c}^{l},_{j, }^{l}) _{l,j}=_{c[C]}\ _{l,j}^{c}=_{c[C]}\ R^{*}( _{j,c}^{l},_{j,}^{l}).\] (4)

**Classwise Unlearning** For classwise unlearning, we aim to identify those components that are responsible for predictions of a selected class or group within the dataset. Thus, we aim to identify _those components that are able to discriminate between the given class, say with label \(c\), and others_. As with Wang et al. , we say \(_{c}\) is the **Forget Set**, and \(_{}\) is the **Remain Set**. As noted in Shah et al. , Jia et al. , our aim is to minimize the test accuracy of the model on \(_{c}\), while maintaining the test accuracy on \(_{}\). Thus, to unlearn class \(c\), we edit those components for which the class-\(c\) discriminative ability, \(_{l,j}^{c}\) is low. An interesting point to note is that some components may be discriminative only for class \(c\), which we call _class-selective components_, whereas others may be discriminative for multiple classes. Note that when the dataset has a large number of classes, our experiments indicate that class-specific components generally can't be found.

**Structured Pruning:** Identifying discriminative components (specifically filters in convolutional networks) for structured pruning was first introduced in Murti et al. . Structured pruning involves removing components for a network while maintaining the accuracy of the classifier. Following Murti et al. , we aim to _retain components that are discriminative for multiple classes_. Our goal is to remove components from the model while maintaining the model's accuracy on each class conditional \(_{c}\). Thus, Definition 2 gives us a means by which we can identify discriminative components based on the worst Bayes error rate for discriminating the class conditional distributions of the given feature map. Filters for which \(_{l,j}\) is small are considered discriminative, as the best possible classifier that can be trained on those features will be highly accurate.

**Assessing the Discriminative Ability:** In general, the Bayes error rate cannot be computed. However, since the TV distance and the Bayes error rate are connected by the identity (3), which states that for two distributions \(,\), the Bayes risk is given by \((1-(,))\), we can reformulate our distributional pruning strategy as identifying those filters that generate features for which class-conditional distributions are well-separated in the Total Variation sense, and prune them. In , this was achieved by making the strong assumption that the distributions of the class-conditional feature maps were spherical Gaussian. In the sequel, we propose novel lower bounds on the total variation distance that require no restrictive Gaussianity assumptions, thereby enabling us to effectively identify discriminative components.

## 4 Witness Function-Based Lower Bounds for the Total Variation Distance

In this section, we derive lower bounds on the Total Variation Distance that rely on the moments of a _witness function_, a scalar-valued function whose moments can be used to derive bounds on divergences between distributions. More formally, we write \(f:\), where \(\) is the support of the distribution(s) in question. We then adapt our lower bound to a variety of scenarios, depending on the extent of the information about the distributions available to us. When access to only the first two moments is available, we derive lower bounds on the total variation distance based on the Fisher linear discriminant and the minimax probability machine.

Estimating the Total Variation distance is known to be \(\#\) complete . Estimating lower bounds on the TV distance is an active area of research (see Davies et al.  and the references within), with a variety of applications from clustering  to analyzing neural networks . However, most bounds such as those presented in Davies et al.  require prior knowledge about the distributions, and tractable estimation of lower bounds given access to collections of moments or samples, without assumptions on the distributions themselves, remains an open problem.

### Witness Function-based Lower Bounds on the TV Distance

In this section, we propose lower bounds on the TV distance that only requires access to the moments of a _witness function_, as described in Gretton et al. , Kubler et al. .

**Theorem 1**.: _Let \(,\) be two probability measures supported on \(^{d}\), and let \(p\) and \(q\) be the corresponding densities. Let \(\) be the set of functions with bounded first and second moments defined on \(\). Then,_

\[(,)_{f}\ _{p}-_{q})^{2}}{2 (_{p}^{2}+_{q}^{(2)})}\] (5)

Proof Sketch.: We provide a sketch of the proof. We express the quantity \(f_{p}-f_{q}\) in terms of the densities \(p(X)\) and \(q(X)\). We then isolate the integral of \(|p(x)-q(x)|\). After rearranging terms, we obtain the result. For the full proof, we refer readers to Appendix B. 

### Moment-based Lower Bounds on the TV distance

Motivated by the need to identify discriminative filters when we only have access to the moments of feature map distributions, we propose worst-case lower bounds on the TV distance given access to finitely many moments of the distributions \(\) and \(\).

Let \(_{k}():=\{\ :\ _{X}[X_{1}^{d_{1}}  X_{n}^{d_{n}}]=_{d_{1} d_{n}},\ _{i}d_{i} k\}\) be the set of probability measures whose moments are given by \(\), where \(_{X}[X_{1}^{d_{1}} X_{n}^{d_{n}}]= _{d_{1} d_{n}}\); similarly, let \(_{k}()\) be the set of measures whose moments are given by \(\). For any random variable \(X^{d}\) supported on \(\), suppose \(:^{d}^{n}\) for which there exist functions \(g\) and \(G\) such that \(_{X}[(X)]=g()\) and \([(X)(X)^{}]=G()\). Given two collections of moments of the same order, we want to measure the worst-case TV separation between _all_ distributions possessing the moments given in \(\) and \(\). We define this as

\[D_{}(_{k}(),_{k}())= _{_{k}(),_{k}( )}\ (,)\] (6)

For the sake of brevity, we write \(D_{}(_{k}(),_{k}())=D_{ }(,;k)\).

**Theorem 2**.: _Suppose \(\) and \(\) are sets of moments of two probability measures supported on \(\). Let \((X)\) be a vector of polynomials such that \(_{}[(X)]=g()\), \(_{}[(X)]=g()\), \(_{}[(X)(X)^{}]=G()\), and \(_{}[(X)(X)^{}]=G()\), and let \(f=u^{}((X)-)+g()}{2})\), be a witness function. Then, for any \(_{k}()\), \(_{k}()\), supported on a set \(^{d}\), we have_

\[D_{}(,;k) S_{}^{ }(,)(2+S_{}^{}(, ))^{-1} S_{}^{}(,)^{2} (+S_{}^{}(,))^{-2},\] \[S_{}^{}(,)=( g)^{} (()+())^{-1}( g)S_{}^{}(,)=_{u}(g( )-g())|}{G()u}+G( )u}}\]

_and \( g=g()-g()\) and \(()=G()-g()g()^{}\)._

Proof Sketch.: We apply Theorem 1 with the given witness function, and obtain an expression in terms of \(S_{}^{}(,)\). Since the bound holds for any distributions that yield the given moments of the witness function, the statement holds. The full proof is provided in Appendix B. 

Theorem 2 is a worst-case lower bound on the TV distance between distributions with given truncated moment sequences. While we focus our results on the case where \(f(x)=u^{}(x)\), where \((x)\) is a vector of monomials, this bound is valid for any choice of \(f\) with bounded first and second moments.

### Computing \((,)\) from the Lower Bound

In general, the bounds proposed in Theorem 1 are not tight. However, an interesting observation is that the lower bound proposed in Theorem 1 can, in certain cases, be used to compute the Bayes optimal classifier, and thus the true TV distance. Specifically, if the Bayes optimal classifier lies in a given set of functions \(\), the bound can be used to compute the Bayes classifier. We state one such case below in Corollary 1.

**Corollary 1**.: _Suppose \((_{p},)\) and \((_{q},)\) Let \(f(x;u)=u^{}(x-(_{p}-_{q}))\) be a witness function. Then,_

\[u^{}=*{arg\,max}_{u}\;_{x}[f( x;u)]-_{x}[f(x;u)])^{2}}{_{x}[f(x;u)^{ 2}]+_{x}[f(x;u)^{2}]}=^{-1}(_{p}-_{q})\]

_is the weight vector of the Bayes optimal classifier \(f_{Bayes}(x)=*{sign}(u^{}x+b)\), and \((,)=2()^{}(_{p} -_{q})}/2)-1\)._

Proof Sketch.: We find the \(u^{}\) that maximizes the the TV lower bound given in Theorem 1, and then apply the same to the exact expression of the TV distance between Gaussian measures with the same covariance. The full proof is provided in Appendix B. 

_Remark 4.1_.: This result illustrates the case where the Bayes' classifier lies in the set of functions \(:=\{f(x):f(x)=u^{}(x)\}\) for a given function \((x)\). In this case, if \((x)=x-(_{p}-_{q})\), and \(\) and \(\) are Gaussian with the same variance, the Bayes classifier is equivalent to the Fisher discriminant.

### Connections to Discriminant Based Classifiers

In this section, we exploit the bound stated in Theorem 1 to reveal extensive connections between the total variation distance and discriminant-based linear classifiers, specifically the Fisher Linear Discriminant and the Minimax Probability Machine, that are of independent interest to readers.

Specifically, we show that the TV distance is lower-bounded by monotonic functions of the Fisher Discriminant and the Minimax Probability Machine. We state this result formally in Corollary 2.

**Corollary 2**.: _Let \(,\) be two probability measures supported on \(X^{d}\), let \(p\) and \(q\) be the corresponding densities, and let \(_{p}\), \(_{q}\) and \(_{p}\), \(_{q}\) be the means and variances of \(\) and \(\) respectively. Then,_

\[(,)^{}(, )}{2+^{}(,)}(^{}(,)}{+^{}( ,)})^{2}.\]

Proof.: Choose \((x)=x\). Thus, \(g()=_{p}\), and \(G()=_{p}+_{p}_{p}^{}\). Substitute these into Theorem 2 to complete the proof. 

This lower bound can be improved upon by selecting a witness function of the form \(f(x;u)=u^{}(x)\) where \((x)\) is a vector of basis functions (such as monomials, if \(f(x;u)\) is a polynomial). Moreover, lower bounds that are robust to estimation error, based on the Fisher Discriminant and Minimax Probability Machines, can be derived by directly applying the techniques proposed in  (for the Fisher discriminant case) and  (for the Minimax Probability Machine case). We discuss this in Section 6.2.

### Lower bounds Robust to Estimation Errors

The lower bounds derived in Theorems 1 and 2 are functions of moments of the distributions, which must typically be estimated from samples. In practice, we use plug-in estimators for \(g()\), \(g()\), \(G()\) and \(G()\). Since these estimators are computed using samples, errors in estimation arise, which in turn creates errors in computing the lower bound.

This estimation error is a particularly challenging issue in high dimensions, where 'high dimensions' refers to the setting where the number of samples \(n\) is significantly less than the dimension of the data, \(d\). However, in typical neural networks such as VGG-nets and ResNets, the feature maps, particularly of the layers close to the output that can be effectively pruned (see, for instance, ), have low dimensional feature maps. For instance, on VGG16 trained on CIFAR10, the feature maps generated by the 5th layer are of dimension 64; thus, for a relatively small number of samples \(n\), the dimension is less than \(n\).

In this section, we present robust lower bounds for the case when \(f(x)=u^{}x\), and the moments being estimated are \(_{p}=_{}[x]\) and \(C_{p}=_{}[xx^{}]\) using plug-in estimators of the form

\[_{p}=_{i=1}^{N}x_{i}\ \ \ \ _{p}=_{i=1}^{N}x_{i}x_{i}^{}\] (7)

where \(x_{i}\) are drawn iid from \(\). We assume that we can quantify the estimation error for the above moments, and can apply lower bounds as proposed in Kim et al.  accordingly.

**Theorem 3**.: _Suppose \(,\) be two probability measures supported on \(X^{d}\), with densities \(p\) and \(q\), and let \(_{p}=_{}[x]\), \(_{q}=_{}[x]\) and \(C_{p}=_{}[xx^{}]\), \(C_{q}=_{}[xx^{}]\). Suppose we have plug-in estimates \(_{p}\), \(_{p}\), \(_{q}\), \(_{q}\) as defined in (7), that satisfy_

\[\|_{p}-_{p}\|_{2}_{p}\|_{q}-_{q} \|_{2}_{q}.\ \ \|C_{p}-_{p}\|_{F}_{p}\|C_{q}-_{q}\|_{F}_{q}.\]

_Then, with a witness function of the form \(f(x)=u^{}x\)_

\[D_{}(,;2)_{_{p},_{q}}\ ()^{}(C_{p}+C_{q}+ I)^{-1}(),\] (8)

_where \(=\{(_{p},_{q}):\|_{p}-_{p}\|_{2}_{p},\| _{q}-_{q}\|_{2}_{q}\}\), \(=_{p}-_{q}\), and \(=_{p}+_{q}\)._

Proof Sketch.: The proof is similar to the derivation of (15) in Kim et al. . A full proof is provided in Appendix B 

This result can also be applied to the estimation error of functions of \(x\), such as a vector of monomials \((x)\), provided the estimation error of each moment can be bounded.

## 5 DisCEdit: Distributional Algorithms for Model Editing

In this section, we leverage the lower bounds proposed in Theorems 1 and 2, and Corollary 2 to develop one-shot algorithms for model editing that require no access to the training data or loss function, but only access to the data distributions. We propose two algorithms, DisCEdit-SP and DisCEdit-U, that identify discriminative components (filters in CNNs), and prunes them to either unlearn a class (DisCEdit-U) or to sparsify the model with minimal loss of accuracy (DisCEdit-SP). A variety of variants of these algorithms based on different witness functions are provided in Appendix D.

### DisCEdit-SP: A Distributional Approach to Structured Pruning

In this section, we propose DisCEdit-SP, an algorithm for structured pruning that identifies filters (in convolutional networks) that are discriminative for multiple classes, and retains them. Unlike the approach proposed in Murti et al. , no restrictive assumptions on the Gaussianity of class-conditional feature distributions is needed. Furthermore, by assuming the distributions are Gaussian and using the closed-form Hellinger lower bound, \(\) pairwise TV distances need to be computed for each filter. We now state the DisCEdit-SPalgorithm.

Let \(Y^{l}(X)\) be the features generated by layer \(l\) of a neural network as defined in (1). We choose a witness function \(f=u^{}(Y^{l}_{j}(X))=^{l}_{j}(X)\), and let \(_{l,j,c}(u)=_{X_{c}}[u^{}^{l}_{j}(X)]\), \(_{l,j,}(u)=_{X_{c}}[u^{}^{l} _{j}(X)]\), \(^{(2)}_{l,j,c}(u)=_{X_{c}}[(u^{}^{l} _{j}(X))^{2}]\) and \(^{(2)}_{l,j,}(u)=_{X_{c}}[(u^{} ^{l}_{j}(X))^{2}\). Next, define \(r^{l}_{j}\) to be the saliency score for the \(j\)th filter in the \(l\)th layer as

\[r^{l}_{j}=_{c[C]}\ _{u}\ (_{l,j,c}(u)-_{l,j, }(u))^{2}(^{(2)}_{l,j,c}(u)+^{(2)}_{l,j,}(u) )^{-1}.\] (9)We use the lower bound established in Theorem 1 on the TV distances between the class conditional distributions to measure the _saliency_ or importance of a given filter. With this, we formally state DisCEdit-SP in Algorithm 1.

The DisCEdit-SP algorithm has several advantages. First, as compared to TVSPrune, it requires that only \(C\) TV distances be computed at each step. Second, by varying the choice of witness function, we obtain new algorithms for structured pruning; we can choose different witness functions for each class as well.

### DisCEdit-U:

A Distributional Approach to Machine Unlearning

We now state an algorithm for classwise unlearning based on model editing, called DisCEdit-U. Motivated by works such as Shah et al. , our algorithm requires identifying and editing (specifically pruning) class-selective components for the class which is to be unlearned. DisCEdit-Uuses the same setup as DisCEdit-SP. However, DisCEdit-Uonly requires identifying discriminative filters for a single class, we have

\[r_{j}^{l}=_{u}\ (_{l,j,c}(u)-_{l,j,}(u) )^{2}(_{l,j,c}^{(2)}(u)+_{l,j,}^{(2)}(u)) ^{-1}.\] (10)

We formally state DisCEdit-U in Algorithm 1. The DisCEdit-U algorithm has several advantages. As we show in our experiments in Appendix E, few samples are required to effectively compute the witness functions.

## 6 Empirical Evaluations

In this section, we empirically study the effectiveness of identifying discriminative filters for model editing tasks, specifically structured pruning and class unlearning. Additional experimental details are given in Appendix E. Experiments showing that class-conditional feature map distributions are non-gaussian, the effectiveness of variants of witness functions, the effectiveness of sparsity in class forgetting, and other ablations, are provided in Appendix E. Our experiment setup is provided in Appendix F, along with baseline accuracies of all models, shown in Table 11.

### Identifying Discriminative Subnetworks and Class Unlearning with DisCEdit-U

In this section, we investigate the utility of the lower bounds given in Theorems 1-3 in identifying discriminative subnetworks and for class unlearning.

**Experiment Setup:** We investigate VGG16, Resnet56, ResNet20, and a custom ViT (details given in Appendix F) trained on CIFAR10, and VGG16 and ResNet56 models trained on CIFAR100,

  &  &  \\ Dataset & Model & FA (NoFT) & RA (NoFT) & FA (FT) & FA (GA) & BA (GA)  & RA (RA)  & RA (IU)  \\   & VGG-16 & **8.7\%** & 82.5\% & **3.7\%** & 91.6\% & 22.5\% & 88.8\% & 11.42\% & 89.8\% \\  & ResNet56 & 16.3\% & 85.9\% & 9.7\% & 89.4\% & - & - & - & - \\  & ResNet20 & **9.4\%** & 33.9\% & **6.0\%** & 86.6\% & 11.52\% & 85.46\% & - & - \\  & ViT & 16.5\% & 66.3\% & 11.0\% & 71.2\% & - & - & - & - \\   & VGG16 & 11.3\% & 68.0\% & 10.7\% & 72.9\% & - & - & - & - \\  & ResNet56 & 31.1\% & 60.4\% & 17.9\% & 66.7\% & - & - & - & - \\   & ViT & 13.1\% & 44.2\% & 14.6\% & 61.0\% & - & - & - & - \\   

Table 1: A summary of results of class unlearning using DisCEdit-U. We take the average over the Forget and Remain accuracies (FA and RA) after applying DisCEdit-Uto each class. Note that FA=accuracy drop on forget class, RA=accuracy drop on remain set. Values are averaged over 10 trials. NoFT refers to using DisCEdit-U without fine-tuning, and with pruning only 5.4% of weights for VGG16, 1.8% of weights for ResNet56, 1.8% of weights for ResNet56, whereas FF refers to using DisCEdit-U with 1 epoch of fine-tuning, and with pruning ratios of 18.4%, 225, 16.6%, and 10.2% for VGG16, ResNet56, ResNet20, and our ViT respectively and identify subnetworks responsible for predictions from each class. We use the witness function \(f(x)=(\|x\|^{2})\) in our experiments, using 256 samples from the Forget class, and 1024 samples for the Remain class, from the training sets of CIFAR10 and CIFAR100's, for computing \(r_{l,j}^{c}\) for each filter. For VGG-16, we only consider the last 8 layers, and for ResNet56, we only consider the final layerblock. We then select the sparsity budgets \(B_{l}\), and prune the most discriminative filters for that layer. We also fine-tune the models for 1 epoch. We measure the accuracy on the class test set, and the class complement test sets both before and after fine-tuning, and we compare against models trained from scratch on the retain set (the class complement).

**Results:** We present a summary of our results in Table 1. In particular, we highlight that on CIFAR10 models, particularly VGG16, the performance is comparable to or outperforms baselines with minimal fine-tuning. There are two interesting observations: first, as the number of classes exceeds the width of the network (as was the case with ResNet56 trained on CIFAR100), the efficacy of our method is drastically affected. Second, fine-tuning models on the remain set still raises the accuracy on the forget set unless dramatically more filters are pruned. The reasons for this will be the focus of future work.

This set of experiments highlights the fact that for classifier models, it is possible to identify subnetworks responsible for predictions for each class. Identifying these subnetworks then facilitates classwise unlearning.

### Structured Pruning with DisCEdit-SP with Fine-Tuning

In this section, we investigate the ability for DisCEdit-SP to sparsify models effectively both with and without fine-tuning.

**Experiment Setup:** We prune VGG16, VGG19, and ResNet56 models trained on CIFAR10 with two sets of fixed sparsity budgets, and then fine-tune them for 50 epochs. We repeat the experiment for a ResNet50 trained on Imagenet, and fine-tune the pruned models for 100 epochs. We choose \(f(x)=u^{}(x)\), where \((x)=[1^{}x,(1^{}x)^{2}]^{}\) as our witness function in each of the experiments. For details about the pre-trained models used, refer to Appendix F.

**Results:** We show that models pruned with DisCEdit-SP without fine-tuning retain high accuracies, particularly on the CIFAR10 dataset. Moreover, after fine-tuning, DisCEdit-SPis able to almost fully recover the accuracy of the original models. Our results are summarized in Table 2, which shows the drop in accuracy achieved by the different pruning algorithms compared after fine-tuning.

## 7 Conclusions

In this work, we address the problem of model editing by analyzing discriminative properties of the feature maps. We leverage the notion of discriminative components to derive algorithms for two relevant tasks: structured pruning and class unlearning. Additionally, in order to identify discriminative components, we derive new lower bounds on the TV distance. These lower bounds also elucidate previously unknown connections between the Total Variation distance and discriminative classifiers, specifically the Fisher discriminant and the Minimax Probability Machine. Our experiments show that the model editing algorithms derived by our methods are highly effective, and match or outperform current state of the art in structured pruning, and can reduce accuracy almost completely on a given class, while maintaining accuracy on the remaining classes. This work, however, currently analyzes discriminative components (and thus, subnetworks responsible for classwise predictions) in classifier models. Current avenues of research include extending these results to unlearning and pruning of generative models as well. Lastly, the techniques proposed in this work can be extended to other editing tasks as well, such as debiasing.

    &  \\  Model & Sparsity & our work & TVSPune & CHIP & L1 \\  VGG16 & 61.2\% & **-0.37\%** & -0.98\% & -0.73\% & 1.26\% \\  & 75.05\% & **-1.32\%** & -1.54\% & -1.62 & -2.31 \\  VGG19 & 72.4\% & **-0.12\%** & -0.16\% & N/A & -2.41\% \\  & 76.1\% & **-0.36\%** & -1.13\% & N/A & -3.30\% \\  ResNet56 & 60.7\% & **-1.21\%** & -1.92\% & -1.77\% & -6.21\% \\   \\  Model & Sparsity & our work & TVSPune & CHIP & L1 \\  ResNet50 & 20.2\% & **+0.12\%** & -0.4\% & **+0.10\%** & -1.06\% \\  & 40.8\% & **-2.58\%** & -2.74\% & -2.76\% & -4.45\% \\   

Table 2: DisCEdit-SP performance on CIFAR10 and ImageNet models with fine-tuning. TVSPune refers to , and CHIP refers to . Sparsityâ€™ refers to parametric sparsity.