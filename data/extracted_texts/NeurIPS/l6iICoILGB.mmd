# Practical \(0.385\)-Approximation for Submodular Maximization Subject to a Cardinality Constraint

Murad Tukan

DataHeroes Israel

murad@dataheroes.ai &Loay Mualem

Department of Computer Science

University of Haifa

Haifa Israel

loaymual@gmail.com &Moran Feldman

Department of Computer Science

University of Haifa

Haifa Israel

moranfe@cs.haifa.ac.il

###### Abstract

Non-monotone constrained submodular maximization plays a crucial role in various machine learning applications. However, existing algorithms often struggle with a trade-off between approximation guarantees and practical efficiency. The current state-of-the-art is a recent \(0.401\)-approximation algorithm, but its computational complexity makes it highly impractical. The best practical algorithms for the problem only guarantee \(1/e\)-approximation. In this work, we present a novel algorithm for submodular maximization subject to a cardinality constraint that combines a guarantee of \(0.385\)-approximation with a low and practical query complexity of \(O(n+k^{2})\), where \(n\) is the size of the ground set and \(k\) is the maximum size of a feasible solution. Furthermore, we evaluate the empirical performance of our algorithm in experiments based on the machine learning applications of Movie Recommendation, Image Summarization, and Revenue Maximization. These experiments demonstrate the efficacy of our approach.

## 1 Introduction

In the last few years, the ability to effectively summarize data has gained importance due to the advent of massive datasets in many fields. Such summarization often consists of selecting a small representative subset from a large corpus of images, text, movies, etc. Without a specific structure, this task can be as challenging as finding a global minimum of a non-convex function. Fortunately, many practical machine learning problems exhibit some structure, making them suitable for optimization techniques (either exact or approximate).

A key structure present in many such problems is submodularity, also known as the principle of diminishing returns. This principle suggests that the incremental value of an element decreases as the set it is added to grows. Submodularity enables the creation of algorithms that can provide near-optimal solutions, making it fundamental in machine learning. It has been successfully applied to various tasks, such as social graph analysis , adversarial attacks , dictionary learning , data summarization , interpreting neural networks , robotics , and many more.

To exemplify the notion of submodularity, consider the following task. Given a large dataset, our goal is to identify a subset that effectively summarizes (or covers) the data, with a good representativeset being one that covers the majority of the data. Note that adding an element \(s\) to a set \(B\) is less beneficial to this goal than adding it to a subset \(A B\) due to the higher likelihood of overlapping coverage. Formally, if \(\) is the set of elements in the dataset, and we define a function \(f 2^{}\) mapping every set of elements to its coverage, then, the above discussion implies that, for every two sets \(A B\) and element \(s B\), it must hold that \(f(s A) f(s B)\), where \(f(s A) f(\{s\} A)-f(A)\) denotes the marginal gain of the element \(s\) with respect to the set \(A\). We say that a set function is _submodular_ if it obeys this property.

Unfortunately, maximizing submodular functions is NP-hard even without a constraint , and therefore, works on maximization of such functions aim for approximations. Many of these works make the extra assumption that the submodular function \(f 2^{}\) is _monotone_, i.e., that for every two sets \(A B\), it holds that \(f(B) f(A)\). Two of the first works of this kind, by Nemhauser and Wolsey  and Nemhauser et al. , showed that a greedy algorithm achieves a tight \(1-}{{e}}\) approximation for the problem of maximizing a non-negative monotone submodular function subject to a cardinality constraint using \(O(nk)\) function evaluations, where \(n\) is the size of the ground set \(\) and \(k\) is the maximum cardinality allowed for the output set. An important line of work aimed to improve the time complexity of the last algorithm, culminating with deterministic and randomized algorithms that have managed to reduce the time complexity to linear at the cost of an approximation guarantee that is worse only by a factor of \(1-\).

Unfortunately, the submodular functions that arise in machine learning applications are often non-monotone, either because they are naturally non-monotone, or because a diversity-promoting non-monotone regularizer is added to them. Maximizing a non-monotone submodular function is challenging. The only tight approximation known for such functions is for the case of unconstrained maximization, which enjoys a tight approximation ratio of \(}{{2}}\). A slightly more involved case is the problem of maximizing a non-negative (not necessarily monotone) submodular function subject to a cardinality constraint. This problem has been studied extensively. First, Lee et al.  suggested an algorithm guaranteeing \((1/4-)\)-approximation for it. This approximation ratio was improved in a long series of works , leading to a very recent \(0.401\)-approximation algorithm due to Buchbinder and Feldman , which improved over a previous \(0.385\)-approximation algorithm due to Buchbinder and Feldman . On the inapproximability side, it has been shown that no algorithm can guarantee a better approximation ratio than \(0.478\) in polynomial time .

Most of the results in the above-mentioned line of work are only of theoretical interest due to a very high time complexity. The two exceptions are the Random Greedy algorithm of Buchbinder et al.  that guarantees \(}{{e}}\)-approximation using \(O(nk)\) queries to the objective function, and the Sample Greedy algorithm of Buchbinder et al.  that reduces the query complexity to \(O_{}(n)\) at the cost of a slightly worse approximation ratio of \(}{{e}}-\).

### Our contribution

In this work, we introduce a novel combinatorial algorithm for maximizing a non-negative submodular function subject to a cardinality constraint. Our suggested method combines a practical query complexity of \(O(n+k^{2})\) with an approximation guarantee of \(0.385\), which improves over the \(}{{e}}\)-approximation of the state-of-the-art practical algorithm. To emphasize the effectiveness of our suggested method, we empirically evaluate it on \(3\) applications: (i) Movie Recommendation, (ii) Image Summarization, and (iii) Revenue Maximization. Our experiments on these applications demonstrate that our algorithm (Algorithm 3) outperforms the current practical state-of-the-art algorithms.

**Remark.** An independent work that recently appeared on arXiv  suggests another \(0.385\)-approximation algorithm for our problem using \(O(nk)\) oracle queries. Interestingly, their algorithm is very similar to a basic version of our algorithm presented in Appendix A. In this work, our main goal is to find ways to speed up this basic algorithm, which leads to our main result. In contrast, the main goal of  is to derandomize the basic algorithm and extend it to other constraints.

### Additional notation

Let us define some additional notation used throughout the paper. Given an element \(u\) and a set \(S\), we use \(S+u\) and \(S-u\) as shorthands for \(S\{u\}\) and \(S\{u\}\), respectively. Given also a set function \(f 2^{}\), we recall that \(f(u S)\) is used to denote the marginal contribution of \(u\) to \(S\). Similarly, given an additional set \(T\), we define \(f(T S) f(S T)-f(S)\). Finally, we denote by \(\) an arbitrary optimal solution for the problem we consider.

## 2 Method

In this section, we present our algorithm for non-monotone submodular maximization under cardinality constraints, which is the algorithm used to prove the main theoretical result of our work (Theorem 2.3). We begin with a brief overview of our algorithm. Motivated by the ideas underlying the impractical \(0.385\)-approximation algorithm of , our algorithm comprises three steps:

1. **Initial Solution:** We start by searching for a good initial solution that guarantees a constant approximation to the optimal set. This is accomplished by running the recent deterministic \(}{{4}}\)-approximation algorithm of Balkanski et al. .1 2. **Accelerated Local Search (Algorithm 1):** Next, the algorithm aims to find an (approximate) local optimum set \(Z\) using a local search method. This can be done using a classical local search algorithm at the cost of \(O_{}(nk^{2})\) queries (see Appendix A for more detail). As an alternative, we introduce, in Subsection 2.1, our accelerated local search algorithm Fast-Local-Search (Algorithm 1), which reduces the query complexity to \(O_{}(n+k^{2})\).
3. **Accelerated Stochastic Greedy Improvement (Algorithm 2):** It can be shown that when the set \(Z\) does not have a good value, it contains only little of the value of the optimal solution, and at the same time, it contains many of the elements that negatively affects this optimal solution. Thus, it makes sense to try to avoid this set. Accordingly, after obtaining the set \(Z\), our algorithm constructs a second possible solution using a stochastic greedy algorithm that picks only elements of \( Z\) in its first iterations. One can use for this purpose a version of the Random Greedy algorithm suggested by Buchbinder et al.  that uses \(O(nk)\) queries (see Appendix A for details). To get the same result using fewer queries, we employ Algorithm 2 (described in Subsection 2.2), which is accelerated using ideas borrowed from the Sample Greedy algorithm of .

Our final algorithm (given as Algorithm 3 in Subsections 2.3) returns the better among the two sets produced in the last two steps (i.e., the output sets of Algorithm 1, and Algorithm 2). Intuitively, this algorithm guarantees our target approximation ratio of \(0.385\) because when \(f(Z)\) is smaller than this value, the set \(Z\) is bad enough that avoiding it (in the first iterations) allows Algorithm 2 to get a good enough solution.

### Fast local search

In this section, we present our accelerated local search algorithm, which is the algorithm used to implement the first two steps of our main algorithm. The properties of this algorithm are formally given by Theorem 2.1. Let \(\) be an optimal solution.

**Theorem 2.1**.: _There exists an algorithm that given a positive integer \(k\), a value \((0,1)\), and a non-negative submodular function \(f:2^{}_{ 0}\), outputs a set \(S\) of size at max \(k\) that, with probability at least \(1-\), obeys_

\[f(S))+f(S)}{2+}  f(S))}{1+}.\]

_Furthermore, the query complexity of the above algorithm is \(O_{}(n+k^{2})\)._

Note that the guarantee of Theorem 2.1 is similar to the guarantee of a classical local search algorithm (see Appendix A for details). However, such a classical local search algorithm uses \(O_{}(nk^{2})\) queries, which is higher than the number of queries required for the algorithm from Theorem 2.1.

We defer the formal proof of Theorem 2.1 to Appendix B. However, we note that this proof is based on Algorithm 1. Algorithm 1 implicitly assumes that the ground set \(\) includes at least \(k+1\) dummy elements that always have a zero marginal contribution to \(f\). Such elements can always be added to the ground set (before executing the algorithm) without affecting the properties of \(f\), and removing them from the output set of the algorithm does not affect the guarantee of Theorem 2.1.

``` input :A positive integer \(k 1\), a submodular function \(f\), an approximation factor \((0,1)\), and a number \(L\) of iterations. output :A subset of \(\) of cardinality at most \(k\).
1 Initialize \(S_{0}\) to be a feasible solution that with probability at least \(1-\) provides \(c\)-approximation for the problem for some constant \(c(0,1]\).
2 Fill \(S_{0}\) with dummy elements to ensure \(|S_{0}|=k\).
3for\(j=1\) to \(_{2}\)do
4 Let \(S_{0}^{j} S_{0}\).
5for\(i=1\) to \(L\)do
6\(Z_{i}^{j}\) Sample \(\) items from \(\) uniformly at random.
7\(u_{i}^{j}_{u^{} Z_{i}^{j}}f(u_{i}^{j} S_{i-1}^ {j})\).
8if\(f(u_{i}^{j} S_{i-1}^{j}) 0\)then\(u_{i}^{j}\) dummy element that does not belong to \(S_{i-1}^{j}\).
9\(v_{i}^{j}_{v^{} S_{i-1}^{j}}f(v^{} S_{i-1 }^{j}-v^{})\).
10if\(f(S_{i-1}^{j})<f(S_{i-1}^{j}-v_{i}^{j}+u_{i}^{j})\)then\(S_{i}^{j} S_{i-1}^{j}-v_{i}^{j}+u_{i}^{j}\).
11else\(S_{i}^{j} S_{i-1}^{j}\).
12 Pick a uniformly random integer \(0 i^{*}<L\).
13iffor every integer \(0 t k\) it holds that \( S_{i^{*}}^{j},|S|=t}{}f(u S_{i^{*}}^{j})}^{j},|S|=t }{}f(v S_{i^{*}}^{j}-v)+ f(S_{i^{*}} ^{j})\)then return\(S_{i^{*}}^{j}\).
14return FAILURE. ```

**Algorithm 1**Fast-Local-Search\((k,f,,L)\)

Algorithm 1 starts by finding an initial solution \(S_{0}\) guaranteeing constant approximation (we implement this step using the deterministic \(}{{4}}\)-approximation algorithm of Balkanski et al. ). If the size of the initial solution is less than \(k\) (i.e., \(|S_{0}|<k\)), the algorithm adds to it \(k-|S_{0}|\) dummy elements. Then, Algorithm 1 makes roughly \(_{2}^{-1}\) attempts to find a good output. Each attempt trys to improve the (same) initial solution using \(L\) iterations. Each iteration consisting of three steps: In Step (i), the algorithm samples \(\) items, and picks the element \(u\) from the sample with the largest marginal contribution to the current solution \(S_{i-1}\). If there are no elements in the sample with a positive marginal contribution, the algorithm picks a dummy element outside \(S_{i-1}\) as \(u\). In Step (ii), the algorithm picks the element \(v S_{i-1}\) that has the lowest marginal value, i.e., the element whose removal from \(S_{i-1}\) would lead to the smallest drop in value. In Step (iii), the algorithm swaps the elements \(u\) and \(v\) if such a swap increases the value of the current solution. Once \(L\) iterations are over, the algorithm picks a uniformly random solution among all the solutions seen during this attempt (recall that the algorithm makes roughly \(_{2}^{-1}\) attempts to find a good solution). If the random solution found obeys the technical condition given on Line 13, then the algorithm returns it. Otherwise, the algorithm continues to the next attempt. If none of the attempts returns a set, the algorithm admits failure.

### Guided stochastic greedy

In this section, we prove Theorem 2.2, which provides the last step of our main algorithm.

**Theorem 2.2**.: _There exists an algorithm that given a positive integer \(k\), a value \((0,1)\), a value \(t_{s}\), a non-negative submodular function \(f^{N}_{ 0}\), and a set \(Z\) obeying the inequalities stated in Theorem 2.1, outputs a solution \(S_{k}\), obeying_

\[[f(S_{k})]  k}{k}^{k- t _{s} k-1}+^{k- t_{s} k}-^{k}f( )+\] \[+^{k}+^{k-1}- k }{k}^{k- t_{s} k-1}f( Z)\] \[+(^{k}-^{k- t_{s} k})f( Z)-2ef(),\]_where \( 1-1/k\). Moreover, this algorithm requires only \(O_{}(n)\) queries to the objective function._

The algorithm used to prove Theorem 2.2 is Algorithm 2. This algorithm starts with an empty set and adds elements to it in iterations (at most one element per iteration) until its final solution is ready after \(k\) iterations. In its first \( k t_{s}\) iterations, the algorithm ignores the elements of \(Z\), and in the other iterations, it considers all elements. However, except for this difference, the behavior of the algorithm in all iterations is very similar. Specifically, in each iteration \(i\) the algorithm does the following two steps. In Step (i), the algorithm samples a subset \(M_{i}\) containing \(O_{}(n/k)\) elements from the data. In Step (ii), the algorithm considers a subset of \(M_{i}\) (of size either \(s_{1} p(n-|Z|)\) or \(s_{2} pn\)) containing the elements of \(M_{i}\) with the largest marginal contributions with respect to the current solution \(S_{i-1}\), and adds a uniformly random element out of this subset to the solution (if this element has a positive marginal contribution).

``` input :A set \(Z\), a positive integer \(k 1\), values \((0,1)\) and \(t_{s}\), and a non-negative submodular function \(f\) output :A set \(S_{k}\)
1 Initialize \(S_{0}\).
2 Define \(p\{1,8k^{-1}^{-2}(2^{-1})\}\).
3 Define \(s_{1} k/(n-|Z|)\) and \(s_{2} k/n\).
4for\(i=1\) for\( k t_{s}\)do
5 Let \(M_{i} Z\) be a uniformly random set containing \( p(n-|Z|)\) elements.
6 Let \(d_{i}\) be uniformly random scalar from the range \((0,s_{1}[p(n-|Z|)]]\).
7 Let \(u_{i}\) be an element of \(M_{i}\) associated with the \( d_{i}\)-th largest marginal contribution to \(S_{i-1}\) (if \( d_{i}>|M_{i}|\), we set \(u_{i}\) to be a dummy element having 0 marginal contribution to \(f\)).
8if\(f(u_{i} S_{i-1}) 0\)then
9\(S_{i} S_{i-1}\{u_{i}\}\).
10else
11\(S_{i} S_{i-1}\).
12for\(i= k t_{s}+1\) to \(k\)do
13 Let \(M_{i}\) be a uniformly random set containing \( p n\) elements.
14 Let \(d_{i}\) be uniformly random scalar from the range \((0,s_{2}[p n]\).
15 Let \(u_{i}\) be an element of \(M_{i}\) associated with the \( d_{i}\)-th largest marginal contribution to \(S_{i-1}\).
16if\(f(u_{i} S_{i-1}) 0\)then\(S_{i} S_{i-1}\{u_{i}\}\).
17else\(S_{i} S_{i-1}\).
18return\(S_{k}\). ```

**Algorithm 2**Guided Stochastic Greedy

### \(0.385\)-Approximation guarantee

In this section, our objective is to prove the following theorem.

**Theorem 2.3**.: _Given an integer \(k 1\) and a non-negative submodular function \(f 2^{}_{ 0}\), there exists an \(0.385\)-approximation algorithm for the problem of finding a set \(S\) of size at most \(k\) maximizing \(f\). This algorithm uses \(O(n+k^{2})\) queries to the objective function._

The algorithm used to prove Theorem 2.3 is Algorithm 3. Our technical guarantee for Algorithm 3 is given as Lemma 2.4. When \(k\) is large enough, this lemma immediately implies Theorem 2.3 by choosing \(\) to be a small enough positive constant. If \(k\) is small, getting Theorem 2.3 from Lemma 2.4 requires a three steps process. First, we choose an integer constant \(\) such that \( k\) is large enough, and we create a new ground set \(_{}=\{u_{i} u,i[]\}\) and a new objective function \(g 2^{_{}}\) defined as \(g(S)=[f(R(S))]\), where \(R(S)\) is a random subset of \(\) that includes every element \(u\) with probability \(|S(\{u\}[])|/\). Then, we use Lemma 2.4 to get a set \(\) that provides \(0.385\)-approximation for the problem \(\{g(S)|S| k\}\). Finally, the Pipage Rounding technique of  can be used to get from \(\) a \(0.385\)-approximation for our original problem. Notice that since the size of \(\) is constant (as we consider the case of a small \(k\)), this rounding can be done using a constant number of queries to the objective.

**Lemma 2.4**.: _Algorithm 3 makes \(O_{}(n+k^{2})\) queries to the objective function, and returns a set whose expected value is at least \((c-O(+k^{-1}))f()\) for some constant \(c>0.385\)._Proof.: According to the proof of Theorem 2.1, our choice of the parameter \(L\) in Algorithm 1 guarantees that with probability at least \(1-\) the set \(Z\) obeys the inequalities

\[f(Z))+f(Z)}{2+}  f(Z))}{1+}.\]

Let us denote by \(\) the event that these inequalities hold. By Theorem 2.2,

\[[f(A)]  k}{k}^{k- t _{s} k-1}+^{k- t_{s} k}-^{k}f( )+\] \[+^{k}+^{k-1}- k }{k}^{k- t_{s} k-1}[f( Z)]\] \[+(^{k}-^{k- t_{s} k})[f( Z)]-2 f().\]

Since the output of Algorithm 2 is the better set among \(A\) and \(Z\), we can lower bound its value by any convex combination of lower bounds on the values of \(A\) and \(Z\). More formally, if we denote by \(p_{1}\), \(p_{2}\) and \(p_{3}\) any three non-negative values that add up to \(1\), then we get

\[[ \{f(A),f(Z)\}] p_{3} k}{k}^{k- t_{s} k-1}+^{k- t_{ s} k}-^{k}f()\] (1) \[+}{2+}+p_{3}^{k}+ ^{k-1}- k}{k}^{k- t_{s}  k-1}[f( Z)]\] \[+}{1+}+}{2+}-p _{3}^{k- t_{s} k}-^{k} [f( Z)]-2 p_{3}f().\]

To simplify the above inequality, we need to bound some of the terms in it. First,

\[ k}{k} ^{k- t_{s} k-1}+^{k- t_{s}  k}-^{k}2-t_{s}-^{k(1-t _{s})}-^{k}\] \[2-t_{s}-e^{t_{s}-1}-e^{-1} 2-t_{s}-e^{-t_{s}}e^{t_{s}-1}-,\]

where the first inequality holds since \( t_{s} k t_{s} k+1\), \( 1\), the second inequality follows since \(^{k(1-t_{s})} e^{t_{s}-1}1-^{1-t_{s}}\), and the last inequality holds since \(e^{t_{s}-1} 1\). Second,

\[^{k}+^{k-1}- k}{k} ^{k- t_{s} k-1}  2e^{-1}- k}{k}^{k-t_{s} k-2}- }{k}\] \[ 2e^{-1}-(2-t_{s})e^{t_{s}-1}-}{k}\] \[=-e^{t_{s}-1}2-t_{s}-2e^{-t_{s}}-}{k},\]

where the first inequality holds since \(^{k-1}^{k} e^{-1}1-\), and the second inequality holds since \(^{k-t_{s} k-2} e^{t_{s}-1}+4/k\). Finally, it holds that \(^{k}-^{k- t_{s} k} e^{-1}(1-)-e^{ t_{s}-1}/(1-) e^{-1}(1-)-e^{t_{s}-1}(1+)-e^{t_{s}-1}(1-e ^{-t_{s}})-\).

Plugging all the above lower bounds into Inequality (1) yields the promised simplified guarantee that

\[[\{f(A),f(Z)\} ] p_{3}2-t_{s}-e^{-t_{s}}e^{t_{s} -1}f()-O(+k^{-1})f()\] \[+}{2+}-p_{3}e^{t_{s}-1}2-t_{s }-2e^{-t_{s}}-O(k^{-1})[f( Z) ]\] \[+}{1+}+}{2+}- p_{3}e^{t_{s}-1}1-e^{-t_{s}}-O(k^{-1})[f( Z)].\]

By , for an appropriate choice of values for \(p_{1}\), \(p_{2}\), \(p_{3}\) and \(t_{s}\) the last inequality implies

\[[\{f(A),f(Z)\}](c-O(+ k^{-1}))f()\\ -O(k^{-1})[f( Z)+f(  Z)]\] (2)

for some constant \(c>0.385\). To get from the last inequality the bound on \([\{f(A),f(Z)\}]\) stated in the lemma, we need to show that the conditioning on \(\) and the last term of the inequality can both be dropped. To see why the conditioning can be dropped, note that the event \(\) happens with probability at least \(1-\), and when it does not happen the set returned by the algorithm still has a non-negative value. These observations show together that removing the conditioning on \(\) in Inequality (2) only affects the constant inside the big \(O\) notation. Notice now that since \( Z\) is always a feasible solution, it deterministically holds that \(f( Z) f()\). Similarly, since \(Z\) is a feasible solution, the submodularity of \(f\) guarantees that \(f( Z)+f( Z) f()+f(Z) 2f( )\). These two bounds allow us to drop the last term of Inequality (2) at the cost of increasing (again) the constant inside the big \(O\) notation.

To complete the proof of the lemma, note that Line 1 of Algorithm 3 requires \(O_{}n+k^{2}\) queries to the objective function as shown in the proof of Theorem 2.1, while Line 3 of Algorithm 3 requires \(O_{}(n)\) queries to the objective function as dictated by Theorem 2.2. 

## 3 Experiments

To emphasize the effectiveness of our suggested method from Section 2, in this section, we empirically compare Algorithm 3 with two benchmark algorithms on three machine-learning applications: movie recommendation, image summarization, and revenue maximization. Each one of these applications necessitates maximization of a non-monotone submodular function. The benchmark algorithms we consider are the Random Greedy algorithm of Buchbinder et al. , and the Random Sampling algorithm of . These algorithms are the current state-of-the-art practical algorithms for maximizing non-monotone submodular functions.

As stated, Algorithm 2 requires \(O(}{^{2}})\) queries to the objective function, where the dependence on \(\) comes from the choice of value for the parameter \(p\) of the algorithm. However, we have found out that in practice a more modest choice of value for \(p\) suffices. Specifically, in our experiments, we have replaced Line 2 of Algorithm 2 with \(p\{1,\}\). Throughout the experiments, we have set \(=0.1\); and all the reported results are averaged across \(8\) executions. We use shades in our plots to depict the standard deviations of the individual results obtained in these \(8\) executions.

**Software/Hardware**. Our algorithms were implemented in Python 3.11 using mainly "Numpy" , and Numba . The implementations' code can be found at https://github.com/muradtuk/385ApproximSubMax. The experiments were performed on a \(2.2\)GHz i9-13980HX (24 cores total) machine with \(64\)GB RAM.

### Personalized movie recommendation

Consider a movie recommendation system in which each user specifies what genres they are interested in, and the system has to provide a representative subset of movies from these genres. Assume that each movie is represented by a vector consisting of users' ratings for the corresponding movie. One challenge here is that each user does not necessarily rate all the movies. Hence, the vectors representing the movies do not necessarily have similar sizes. To overcome this challenge, low-rank matrix completion techniques  can be performed on the matrix with missing values to obtain a complete rating matrix. Formally, given a few ratings from \(k\) users to \(n\) movies we obtain in this way a rating matrix \(\) of size \(k n\). Following [33; 30], to score the quality of a selected subset of movies, we use the function \(f(S)=_{u}_{v S}s_{u,v}-_{u S}_{v S}s _{u,v}\). Here, \(\) is the set of \(n\) movies, \(\) is a parameter and \(s_{u,v}\) denotes the similarity between movies \(u\) and \(v\) (the similarity \(s_{u,v}\) can be calculated based on the matrix \(\) in multiple ways: cosine similarity, inner product, etc). Note that the first term in \(f\)'s definition captures the coverage, while the second term captures diversity. Thus, the parameter \(\) controls the importance of diversity in the returned subset. For any \( 0.5\), \(f(S)\) is monotone , however, it can be non-monotone for larger values of \(\).

We followed the experimental setup of the prior works  and used a subset of movies from the MovieLens data set  which includes \(10{,}437\) movies. Each movie in this data set is represented by a \(25\) dimensional feature vector calculated using user ratings, and we used the inner product similarity to obtain the similarity values \(s_{u,v}\) based on these vectors. When experimenting with this application, we fixed \(\) to be either \(0.55\) or \(0.75\), and varied \(k\).

The results of these experiments are depicted in Figure 1. One can observe that our proposed method, Algorithm 3, demonstrates superior performance compared to the other methods. Moreover, this performance is stable, and presents a much smaller variance compared to the variance in the performance of the two benchmark algorithms. The number of queries used by our algorithm is only slightly larger than the number of queries used by the Random Sampling algorithm of , and is typically smaller than the number of queries used by the Random Greedy algorithm of Buchbinder et al. , sometimes by as much as a factor of \(2\).

### Personalized image summarization

Consider a setting in which we get as input a collection \(\) of images from \(\) disjoint categories (e.g., birds, dogs, cats) and the user specifies \(r[]\) categories, and then demands a subset of the images in these categories that summarizes all the images of the categories. Following  again, to evaluate a given subset of images, we use the function \(f(S)=_{u}_{v S}s_{u,v}-|}_{ u S}_{v S}s_{u,v}\), where \(s_{u,v}\) is a non-negative similarity between images \(u\) and \(v\).

To obtain the similarity between pair of images \(u,v\), we utilized the _DINO-VITB16_ model  from HuggingFace  as the feature encoder for vision datasets. Specifically, the final layer CLS token

Figure 1: Experimental results for Personalized Movie Recommendation. Plots (a) and (b) compare the output of our algorithm with the benchmark algorithms mentioned at the beginning of Section 3 for a particular value of the parameter \(\) and a varying number \(k\) of movies. Plots (c) and (d) compare the number of queries used by the various algorithms.

embedding output was used as the feature representation. The similarity between pairs of images was then computed as the cosine similarity of the corresponding embedding vectors. To experiment in this setting, we used three datasets: (i) _CIFAR10_ - A dataset of \(50{,}000\) images belonging to \(10\) different classes (categories). (ii) _CIFAR100_ - A dataset of \(50{,}000\) images belonging to \(100\) different classes. (iii) _Tiny ImageNet_ - A dataset of \(100{,}000\) images belonging to \(200\) different classes. In each one of our experiments, the task was to summarize a set of \(10{,}000\) images sampled uniformly from one of these datasets. The upper bound \(k\) on the number images allowed in the summary varied between experiments. The results of our experiments are depicted in Figure 2.

Similarly to Section 3.1, we observe that our algorithm (Algorithm 3) produces higher values compared to the state-of-the-art practical algorithms, and enjoys a lower variance in the quality of its output. However, due to the small values used for \(k\), our algorithm requires significantly more queries to the objective function compared to the two other algorithms.

### Revenue maximization

Consider a company whose objective is to promote a product to users to boost revenue through the "word-of-mouth" effect. More specifically, given a social network, we need to choose a subset of

Figure 2: Experimental results for Personalized Image Summarization. Plots (a)–(c) compare the output of our algorithm with the benchmark algorithms mentioned at the beginning of Section 3 for a varying number \(k\) of images. Each plot corresponds to a different dataset. Plots (d)–(f) compare the number of queries used by the various algorithms.

up to \(k\) users to receive a product for free in exchange for advertising it to their network neighbors, and the goal is to choose users in a manner that maximizes revenue. The problem of optimizing this objective can be formalized as follows. The input is a weighted undirected graph \(G=(V,E)\) representing a social network, where \(w_{ij}\) represents the weight of the edge between vertex \(i\) and vertex \(j\) (with \(w_{ij}=0\) if the edge \((i,j)\) is absent from the graph). Given a set \(S V\) of users who have become advocates for the product, the expected revenue generated is proportional to the total influence of \(S\)'s users on non-advocate users, formally expressed as \(f(x)=_{i S}_{j V S}w_{ij}\). It has been demonstrated that \(f\) is non-monotone and submodular .

In our experiment, we compared the performance of Algorithm 3 and the two benchmark algorithms on the Facebook network  and the Advogato network . The results of this experiment are depicted in Figure 3. Once again, our algorithm enjoys both better output values and lower standard deviations compared to the benchmark algorithms. Our algorithm uses more queries compared to the Random Sampling algorithm of , but the ratio between the number of queries used by the two algorithms tends to decrease as \(k\) increases. The behavior of the Random Greedy algorithm of  greatly depends on \(k\). For smaller values of \(k\) this algorithm requires roughly as many queries as Random Sampling, but for larger value of \(k\) it requires significantly more queries than our algorithm.

## 4 Conclusion

In this work, we have presented a novel algorithm for submodular maximization subject to cardinality constraint that combines a practical query complexity of \(O(n+k^{2})\) with an approximation guarantee of \(0.385\), which improves over the \(}{{e}}\)-approximation of the state-of-the-art practical algorithms. In addition to giving a theoretical analysis of our algorithm, we have demonstrated its empirical superiority (compared to practical state-of-the-art methods) in various machine learning applications. We hope future work will be able to improve the query complexity of our algorithm to be cleanly linear without sacrificing either the approximation guarantee or the practicality of the algorithm.

Figure 3: Experimental results for Revenue Maximization. Plots (a) and (b) compare the output of our algorithm with the benchmark algorithms mentioned at the beginning of Section 3 for a varying number \(k\) of images on the Advogato and Facebook network datasets. Plots (c) and (d) compare the number of queries used by the various algorithms.