# TEG-DB: A Comprehensive Dataset and Benchmark of Textual-Edge Graphs

Zhuofeng Li\({}^{}\) Zixing Gou\({}^{}\) Xiangnan Zhang\({}^{}\) Zhongyuan Liu\({}^{}\) Sirui Li\({}^{}\)

**Yuntong Hu\({}^{}\) Chen Ling\({}^{}\) Zheng Zhang\({}^{}\) Liang Zhao\({}^{}\)**

\({}^{}\)Shanghai University Shandong University Johns Hopkins University China

University of Petroleum (East China) Emory University

###### Abstract

Text-Attributed Graphs (TAGs) augment graph structures with natural language descriptions, facilitating detailed depictions of data and their interconnections across various real-world settings. However, existing TAG datasets predominantly feature textual information only at the nodes, with edges typically represented by mere binary or categorical attributes. This lack of rich textual edge annotations significantly limits the exploration of contextual relationships between entities, hindering deeper insights into graph-structured data. To address this gap, we introduce Textual-Edge Graphs Datasets and Benchmark (TEG-DB), a comprehensive and diverse collection of benchmark textual-edge datasets featuring rich textual descriptions on nodes and edges. The TEG-DB datasets are large-scale and encompass a wide range of domains, from citation networks to social networks. In addition, we conduct extensive benchmark experiments on TEG-DB to assess the extent to which current techniques, including pre-trained language models (PLMs), graph neural networks (GNNs), proposed novel entangled GNNs and their combinations, can utilize textual node and edge information. Our goal is to elicit advancements in textual-edge graph research, specifically in developing methodologies that exploit rich textual node and edge descriptions to enhance graph analysis and provide deeper insights into complex real-world networks. The entire TEG-DB project is publicly accessible as an open-source repository on Github, accessible at https://github.com/Zhuofeng-Li/TEG-Benchmark.

## 1 Introduction

Text-attributed graphs (TAGs) are graph structures in which nodes are equipped with rich textual information, allowing for deeper analysis and interpretation of complex relationships . TAGs are widely utilized in a variety of real-world applications, including social networks , citation networks , and recommendation systems . Due to the universal representational capabilities of language, TAGs have emerged as a promising format for potentially unifying a wide range of existing graph datasets. This field has recently garnered rapidly growing interest, particularly in the development of foundational models for graph data .

Unfortunately, a central issue in designing the TAG foundation model is the lack of comprehensive datasets with rich textual information on both nodes and edges. Most traditional graph datasets solely offer node attribute embeddings, devoid of the original textual sentences, which results in a significant loss of context and limits the application of advanced techniques such as large language models (LLMs) . Despite some TAG datasets being present recently , their data usually only have text information on nodes where the edges are usually represented as binary or categorical. However, the textual information of edges in TAGs is crucial for elucidating the meaning of individual documents and their semantic correlations. For instance, as shown in Figure 1, this scientific article network illustrates the citation patterns of articles authored by Einstein and Planck in the field of quantum mechanics. When we need to conclude that 'Planck endorsed the probabilistic nature of quantum mechanics while Einstein opposed this view,' and if we consider it in terms of a TAG view, focusingsolely on the content of the papers authored by Einstein (Paper A) and Planck (Paper E), we would only conclude that both Einstein and Planck supported quantum mechanics. However, to further deduce that Einstein opposed studying quantum mechanics from a probabilistic perspective, it is necessary to adopt the Textual-Edge Graph (TEG) approach. This approach not only focuses on the paper contents but also pays greater attention to the citation information from the edge between Paper A and Book B, as well as the edge between Paper E and Book D. These edges provide essential citation context and reveal the relationships and influence between different scholarly works.

While compelling, TEGs face three significant challenges that make them an open problem. (1) _Comprehensive TEG datasets are absent._ Currently, there is a lack of comprehensive TEG datasets that simultaneously incorporate textual information from both nodes and edges, spanning multiple domains of varying sizes, and encompassing various mainstream graph learning tasks. This deficiency hinders the evaluation of TEG-based methods across diverse applications and domains. (2) _Existing experimental settings for TEG are disorganized._ Due to the inherent variety and complexity of TEGs, coupled with the absence of a standardized data format, existing works have adopted different datasets with different experimental settings . This causes great difficulties in model comparisons in this field. (3) _Comprehensive benchmarks and analyses for TEG-based methods are missing._ While some techniques can accommodate edge features, they typically process binary or categorical data. It remains unclear if these methods can effectively utilize rich textual information on edges, particularly in leveraging complex interactions between graph nodes.

**Present work.** Recognizing all the above challenges, our research proposes the Textual-Edge Graphs Datasets and Benchmark (TEG-DB). TEG-DB is a pioneering initiative offering a diverse collection of benchmark graph datasets with rich textual descriptions on both nodes and edges. To address the issue of inadequate TEG datasets, our TEG datasets as shown in Table 1 cover an extensive array of domains, including Book Recommendation, E-commerce, Academic, and Social networks. Ranging in size from small to large, each dataset contains abundant raw text data associated with both nodes and edges, facilitating comprehensive analysis and modeling across various fields. Moreover, to address the inconsistency in experimental settings and the lack of comprehensive analyses for TEG-based methods, we first represent the TEG dataset in a unified format, then conduct extensive benchmark experiments and perform a comprehensive analysis. These experiments are designed to evaluate the capabilities of current computational techniques, such as pre-trained language models (PLMs), graph neural networks (GNNs) and proposed novel entangled GNNs, as well as their integrations. Our contributions are summarized below:

* To the best of our knowledge, TEG-DB is the first open dataset and benchmark specifically designed for textual-edge graphs. We provide 9 comprehensive TEG datasets encompassing 4 diverse domains as shown in Table 1. Each dataset, varying in size from small to large, contains abundant raw text data associated with both nodes and edges. Our TEG datasets aim to bridge the gap of TEG dataset scarcity and provide a rich resource for advancing research in the TEG domain.
* We develop a standardized pipeline for TEG research, encompassing crucial stages such as data preprocessing, data loading, and model evaluation. With this framework, researchers can seamlessly replicate experiments, validate findings, and iterate on existing approaches with greater efficiency

Figure 1: An example of textual-edge graph about scientific article network in quantum theory: two papers are connected by citation links. Considering edge texts in the TEG enhances semantic understanding and improves text analysis.

and confidence. Additionally, this standardized pipeline facilitates collaboration and knowledge sharing within the TEG community, fostering innovation and advancement in the field.
* We conduct extensive benchmark experiments and perform a comprehensive analysis of TEG-based methods, delving deep into various aspects such as the impact of different models and embeddings generated by PLMs of various scales, the consequence of diverse embedding methods in GNNs including separate and entangled embeddings, the effect of edge text and the influence of different domain datasets. By addressing key challenges and highlighting promising opportunities, our research stimulates and guides future directions for TEG exploration and development.

## 2 Related Works

In this section, we will begin by providing a brief introduction to three commonly used learning paradigms for TAGs. Following this, we will delve into the comparisons between the current graph learning benchmarks and our proposed benchmark.

**PLM-based methods.** PLM-based methods leverage the power of PLM to enhance the text modeling within each node due to their pre-training on a vast corpus. The early works on modeling textual attributes were based on shallow networks, e.g., Skip-Gram  and GloVe . In recent years, Large Language Models (LLM) have become trending tools. Models like Llama , PaLM , and GPT  show their strong comprehension and inferring ability in cross-field natural language based tasks like code generation , legal consulting , make creative arts , as well as understanding and learning from Graphs . One of the key applications of pre-trained language models is text representation, in which low-dimensional embeddings capture the underlying semantics of texts. On the TAGs, the PLMs use the local textual information of each node to learn a good representation for the downstream task.

**GNN-based methods**. The rapid advancements in graph representation learning within machine learning have led to numerous studies addressing various tasks, such as node classification  and link prediction . Graph neural networks (GNNs) are acknowledged as robust tools for modeling graph data. These methods, including GCN , GAT , GraphSAGE , GIN , and RevGAT , develop effective message-passing mechanisms that facilitate information aggregation between nodes, thereby enhancing graph representations. GNNs typically utilize the "cascade architecture" advocated by GraphSAGE for textual graph representation, wherein node features are initially encoded independently using text modeling tools (e.g., PLMs) and then aggregated by GNNs to generate the final representation.

**LLM as Predictor.** In recent years, several recent studies [47; 4; 9] have delved into the potential of Large Language Models (LLMs) in analyzing graph-structured data. However, there is a lack of comprehensive research on the ability of LLMs to effectively identify and utilize key topological structures across various prompt scenarios, task complexities, and datasets. Chen et al.  and Guo et al.  proposed using LLMs on graph data but primarily focused on node classification within specific citation network datasets, limiting the exploration of LLMs' performance across various tasks and datasets. Furthermore, Ye et al.  fine-tuned LLMs on a specific dataset to outperform GNNs, focusing on a different research goal, which emphasizes LLMs' inherent ability to understand and leverage graph structures.

**Benchmarks for text-attributed graphs.** Current benchmarks in text-attributed graph representation learning can be divided into two stages. The first stage benchmark includes datasets such as mag  and ogbn-arxiv , which feature limited textual information primarily associated with nodes. The second stage benchmark is represented by CS-TAG , which builds upon the first stage by providing richer node-level textual data. However, these datasets face limitations in exploring representation learning for textual-edge graphs. Specifically, they typically include text only on nodes, with edges often represented as binary or categorical, which restricts a comprehensive understanding of node semantic relationships. Additionally, they lack coverage across diverse domains and tasks, hindering the development of robust and generalizable models. Furthermore, the lack of uniformity in representation formats introduces inconsistencies and complexities in analysis and modeling. Thus, there is a clear need for the development of a comprehensive benchmark with textual information on both nodes and edges in a unified format.

## 3 Preliminaries

A Textual-Edge Graph (TEG) is a graph-structured data format in which both nodes and edges have free-form text descriptions. These textual annotations provide rich contextual information about the complex relationships between entities, enabling a more detailed and comprehensive representation of data relations than traditional graphs.

**Definition 1** (Textual-edge Graphs). Formally, a TEG can be represented as \(=(,)\), which consists of a set of nodes \(\) and a set of edges \(\). Each node \(v_{i}\) contains a textual description \(d_{i}\), and each edge \(e_{ij}\) also associates with its text description \(d_{ij}\) describing the relation between \(v_{i}\) and \(v_{j}\).

**Challenges.** Current research on TEGs faces three significant challenges: (1) The scarcity of large-scale, diverse TEG datasets; (2) Inconsistent experimental setups and methodologies in previous TEG research; and (3) The absence of standardized benchmarks and comprehensive analyses for evaluating TEG-based methods. These limitations impede the development of more effective and efficient approaches in this emerging field.

## 4 A Comprehensive Dataset and Benchmark of Textual-Edge Graphs

We begin by offering a brief overview of the TEG-DB in Section 4.1. Afterward, we provide a comprehensive overview of the TEG datasets in Section 4.2, detailing their composition and the preprocessing steps to represent them in a unified format. Finally, we discuss three main methods for handling TEGs: PLM-based, GNN-based paradigm, and LLM as Predictor methods in Section 4.3.

### Overview of TEG-DB

In order to overcome the constraints intrinsic to preceding studies, we propose the establishment of the Textual-Edge Graphs Datasets and Benchmark, referred to as TEG-DB. This framework functions as a standardized evaluation methodology for examining the effectiveness of representation learning approaches in the context of TEGs. To ensure the comprehensiveness and scalability of TEG datasets, TEG-DB collects and constructs a novel set of datasets covering diverse domains like book recommendation, e-commerce, academia, and social networks, varying in size from small to large. These datasets are suitable for various mainstream graph learning tasks such as node classification and link prediction. Table 1 compares previous datasets with our TEG datasets. To enhance usability, we unify the TEG data format and propose a modular pipeline with three main methods for handling TEGs. To further foster TEG model design, we extensively benchmark TEG-based methods and conduct a thorough analysis. Overall, TEG-DB provides a scalable, unified, modular, and regularly updated evaluation framework for assessing representation learning methods on textual graphs.

### Data Preparation and Construction

In order to construct the dataset with simultaneous satisfaction of both rich textual information on nodes and edges, nine datasets from diverse domains and different scales are chosen. Specifically, we collect four User-Book Review networks from Goodreads datasets [40; 41] in the Book Recommendation domain and two shopping networks from Amazon datasets [11; 12] in the E-commerce

  Dataset &  & Edges & Notes/Class & Graph Domain & Size & Notes/set & Edge-over & Node Classification & Link Prediction \\   & Textual Space Network  & 71.26 & 88.617 & 2 & Social Networks & Small & & & & & \\  & Web-Edge Prove  & 22.420 & 171.052 & 4 & Social Networks & Small & & & & & \\  & edge-aware  & 169.43 & 116.248 & 40 & Academic & Medium & & & & & \\  &  & 3,327 & 4.732 & 6 & Academic & Small & & & & & \\  & Proposed  & 19.17 & 4.438 & 3 & Academic & Small & & & & & \\  & Cites  & 2,206 & 5.429 & 7 & Academic & Small & & & & & \\  & Cites  & 1,106.799 & 5.1287 & - & Academic & Large & & & & & \\  & CodeRank & 560.684 & 85.323 & 11 & Boost Recommendation & Large & & & & & \\  & Spa-Fuse & 37.058 & 17.7330 & 13 & E-commerce & Medium & & & & & \\  & Spa-Fuse & 43.562 & 59.9335 & 12 & E-commerce & Small & & & & & \\  & Back-Edge & 44.535 & 134.528 & 24 & E-commerce & Small & & & & & \\  & edge-aware-TEG  & 169.343 & 116.243 & 40 & Academic & Medium & & & & & \\   & Goullet-Based & 580.97 & 20.3695 & 11 & Best Recommendation & Large & & & & & \\  & Goodreads-Cites & 221.600 & 222.252 & 11 & Best Recommendation & Large & & & & & \\  & Goodreads-Cites & 216.600 & 513.459 & 11 & Best Recommendation & Large & & & & & \\  & Goodreads-Cites & 216.600 & 513.459 & 11 & Best Recommendation & Large & & & & & \\  & Goodreads-Cites & 137.411 & 217.428 & 379 & Best Recommendation & Medium & & & & & \\  & Amazon-Aspe & 31,899 & 62.508 & 62 & E-commerce & Small & & & & & \\  & Koullet & 278.022 & 56.084 & 3 & Social Networks & Large & & & & & \\  & Twitter & 18,761 & 23.764 & 566 & Social Networks & Small & & & & & \\  & Cites & 169.340 & 116.243 & 40 & Academic & Large & & & & & \\  

Table 1: Comparison between our TEG-DB datasets and existing datasets on TAG.

domain. Two social networks from Reddit and Twitter . One citation network from MAG  and The Semantic Scholar Open Data Platform  in the academic domain. The statistics of the datasets are shown in Table 1.

The creation of textual-edge graph datasets involves three main steps. Firstly, preprocessing the textual attributes within the original dataset, which includes tasks such as handling missing values, filtering out non-English statements, removing anomalous symbols, truncating excessive length and selecting the most relevant textual attributes as the raw text for nodes or edges. Secondly, constructing the TEG itself. The connectivity between nodes is derived from inherent relationships provided within the dataset, such as citation relationships between papers in citation networks. It is important to note that during graph construction, self-edges and isolated nodes are eliminated. Lastly, refining the constructed graph. It is noteworthy that our dataset encompasses all major tasks in graph representation learning: node classification and link prediction. Below are the specifics of each dataset:

**User-Book Review Network.** Four datasets within the realm of User-Book Review Networks, specifically labeled as Goodreads-History, Goodreads-Crime, Goodreads-Children, and Goodreads-Cosmics, were formulated. The Goodreads datasets are the main source. Nodes represent different types of books and reviewers, while edges indicate book reviews. Node labels are assigned based on the book categories. The descriptions of books are used as book node textual information while user information serves as the user node textual information and reviews of users are used as edges textual information. The corresponding tasks are to predict the categories of the books, which is formulated as a multi-label classification problem, and to predict whether there are connections between users and books. These comprehensive data help infer user preferences and identify similar tastes, enhancing online book recommendations, unlike existing datasets that often lack interaction texts.

**Shopping Networks.** Two datasets, Amazon-Apps and Amazon-Movie, are classified under Shopping Networks. The Amazon datasets are the primary source, encompassing item reviews and descriptions. Nodes represent different types of items and reviewers, while edges indicate item reviews. The descriptions of items are used as item node textual information, while user information serves as the user node textual information and reviews of users are used as edge textual information. The corresponding tasks are to predict the categories of the items, formulated as a multi-label classification problem, and to predict whether there are connections between users and items. These datasets have the potential to significantly enhance recommendation systems, providing richer data for more accurate suggestions and a personalized shopping experience.

**Citation Networks.** The raw data for the citation network is sourced from the MAG and The Semantic Scholar Open Data Platform. Nodes represent papers, and edges represent the citation relationship. The titles and abstracts of papers are used as node textual information, and citation information, such as the context and paragraphs in which papers are cited, is utilized as textual edge data. The corresponding task involves predicting the domain to which a paper belongs, formulated as a multi-class classification problem, and predicting whether there exists a citation relationship between papers. This dataset enhances academic network expressiveness, particularly benefiting tasks like node classification and link prediction in graph machine learning.

**Social Networks.** The Reddit dataset, sourced from Reddit and the Twitter dataset, derived from Twitter, represent two prominent social media platforms. Nodes represent users and topics. The edges indicate the post-relationship. The descriptions of topics are used as topic node textual information while user information serves as the user node textual information and post text in subreddits or tweets is used as edge textual information. The corresponding tasks are to predict the category of the topics, formulated as a multi-class classification problem, and to predict whether there are connections between users and topics. Utilizing these datasets enhances recommendation algorithm performance, providing more personalized and relevant suggestions, while also offering valuable insights into user interests and preferences for social network research and business decision-making.

### Adapting Existing Methods to Solve Problems in TEGs

**PLM-based Paradigm.** PLMs are trained on massive amounts of text data, allowing them to learn the semantic relationships between words, phrases, and sentences. This enables them to understand the meaning behind the text, not just on a superficial level, but also in terms of context and intent. So PLM-based methods leverage the power of PLM to enhance the text modeling within each node and edge, along with an extra multilayer perception (MLP) to integrate their textual information from TEG. The formulation of these methods is as follows:

\[_{u}^{(k+1)}&=_{}^{(k)} (_{u}^{(k)})\\ _{u}^{(0)}&=(T_{u})+_{v (u)}(T_{e_{v,u}})\] (1)

where \(_{u}^{(k)}\) denotes the node representation of node \(u\) in layer \(k\) of Multilayer Perceptron (MLP). \(T_{u}\) and \(T_{e_{v,u}}\) represent the raw text on node \(u\) and edge \(e_{v,u}\), respectively. The initial feature vector \(_{u}^{(0)}\) of node \(u\) is derived by encoding the text on node \(u\) and its neighboring edges using the Pre-trained Language Model (PLM). \(\) denotes the set of neighbors. \(\) refers to the trainable parameters within the MLP.

Although PLMs have considerably improved the representation of node text attributes, these models do not account for topological structures. This limitation hinders their ability to fully capture the complete topological information present in TEGs.

**Edge-aware GNN-based Paradigm.** GNNs are employed to propagate information across the graph, allowing for the extraction of meaningful representations via message passing, which are formally defined as follows:

\[_{u}^{(k+1)}=_{}^{(k)}(_{u}^{(k)}, _{}^{(k)}(\{_{v}^{(k)},_{ v,u},v(u)\}))\] (2)

where \(_{u}^{(k)}\) denotes the node representation of node \(u\) in layer \(k\) of GNN and the initial node feature vector \(_{u}^{(0)}\) is obtained by embedding its raw text through PLMs. \(e_{v,u}\) denotes the edge from node \(v\) to node \(u\) and its features \(_{v,u}\) are likewise derived from PLMs based on its raw text embeddings. \(k\) represents the layers of GNNs, \(\) denotes the set of neighbors, \(u\) denotes the target node, \(\) means the learning parameters in GNNs.

However, this approach presents two primary issues: (1) Existing Graph ML methods like GNNs typically work on structured attributes on edges instead of texts . In TEGs, edges are texts that contain rich semantic information, which is way beyond the typical focus of GNNs that are commonly based on connectivity (i.e., binary attribute denoting whether there is a connection or not) and edge attributes (i.e., categorical or numerical values on the edges). (2) GNN-based methods are limited in capturing the contextualized semantics of edge texts . In TEGs, where edge and node texts are often entangled, converting them into separate node and edge embeddings during the embedding process can result in the loss of critical information about their interdependence, which diminishes the effectiveness of GNNs throughout the entire message-passing process.

**Entangled GNN-based Paradigm.** Traditional edge-aware GNN-based approaches that first learn edge text embeddings and then apply GNNs have limitations for TEG data because edge texts and node texts are often closely entangled. Separating them into distinct node and edge embeddings may impair important information regarding their interaction. For instance, in a citation graph where each node represents a paper, an edge might indicate that one paper cites, criticizes, or utilizes a specific part of another paper. Therefore, the edge does not represent the relationship between the entirety of the two nodes, posing a significant challenge for methods that rely on node or edge embeddings representing the entirety of a node or edge. To avoid information loss during the interaction between nodes and edges after text embedding, we propose an approach that first entangles the edge text and node text before performing the embedding. The embedding obtained in this way is then added to the message-passing operation for each pair of connected nodes. The formulation of these methods is as follows:

\[_{u}^{(k+1)}&=_{ {}}^{(k)}(_{u}^{(k)},_{}^{(k)} (\{_{v}^{(k)},v(u)\}))\\ _{u}^{0}&=(T_{u},\{T_{v},T_{e_{v,u}},v(u)\})\] (3)

where \(_{u}^{(k)}\) denotes the node representation of node \(u\) in layer \(k\) of the GNN. \(T_{v}\), \(T_{u}\), and \(T_{e_{v,u}}\) represent the raw text on node \(v\), node \(u\), and the edge from \(v\) to \(u\), respectively. The initial node feature vector \(_{u}^{(0)}\) is obtained by embedding the entangled raw text of node \(u\) and its neighborhood 

[MISSING_PAGE_FAIL:7]

**Implementation details.** We conduct experiments on 3 PLM-based, 18 GNN-based, and 2 LLM-based methods. For PLM-based methods, the dimensions of node embedding are 3072, 1024, and 768 generated by GPT-3.5-TURBO, Bert-Large, and Bert respectively. We set the MLP hidden layer to 2, with the number of hidden units in each layer being one-fourth of the units in the previous layer. For GNN-based methods, we adhere to the settings outlined in the respective paper. The parameters shared by all GNN models include dimensions of node and edge embeddings, model layers, and hidden units, with respective values set to 3072, 1024, and 768, as generated by GPT-3.5-TURBO, Bert-Large, and Bert, and 2, 256, respectively. We utilize cross-entropy loss with the Adam optimizer to train and optimize all the above models. The batch size is 1024. Each experiment is repeated three times. See Appendix B.1 for more details.

**Evaluations metrics.** We investigate the performance of different baselines through two tasks: link prediction and node classification. For the link prediction task, we use the Area Under ROC Curve (AUC) metric and F1 score to evaluate the model performance. For node classification, the choice of evaluation metrics depends on the nature of the classification tasks involved. In the context of datasets encompassing Goodreads-Children, Goodreads-Crime, and comics from Goodreads, along with Amazon-Apps and Amazon-Movie datasets from Amazon, the classification tasks involve multi-label node classification. Hence, metrics such as AUC-micro and F1-micro are chosen for evaluation. Conversely, datasets about citation networks and social networks are characterized by multi-class node classification, thus metrics such as ACC and F1 are selected for assessment.

### Effectiveness Analysis for Link Prediction

In this subsection, we analyze the link prediction from the various models applied in the study. Table 2 and 3 represent the effect of link prediction on different datasets from various distinct models. The results on other datasets can be found in Appendix B.2. We can further draw several observations from Table 2 and 3. First, For PLM-based and GNN-based methods, the state-of-the-art methods for Goodreads-Children and Goodreads-Crime datasets are both GeneralConv. Under the condition of using the same embeddings, they outperform the worst method by approximately 5% and 7% in terms of AUC and F1 across these two datasets. For the Amazon-Apps and Amazon-Movie datasets, the state-of-the-art methods are EdgeGNN and GeneralConv. They outperform the worst method by approximately 3% and 7% in terms of AUC and F1 for Amazon-Apps, and by 8% and 7% in

    &  &  &  \\   &  & GPT-3.5-TURBO &  &  &  &  & GPT-3.5-TURBO &  &  &  \\   &  & F1* & AUC & F1* & AUC & F1* & AUC & F1 & AUC & F1 & AUC & F1 & AUC & F1 & AUC & F1 & AUC & F1 \\  MLP & 0.8708 & 0.8708 & 0.8708 & 0.8708 & 0.8708 & 0.8708 & 0.8709 & 0.8622 & 0.8823 & 0.8845 & 0.8709 & 0.8818 & 0.8719 & 0.8719 & 0.8718 & 0.8702 & 0.8719 & 0.8702 & 0.8703 & 0.8703 \\  GraphAtt & **0.9960** & **0.9961** & **0.9961** & **0.9961** & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9962 & 0.9963 \\ GraphAtt & **0.9960** & **0.9961** & **0.9961** & **0.9961** & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9962 & 0.9963 \\ GraphAtt & 0.9960 & 0.9960 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9962 & 0.9963 & 0.9963 & 0.9963 & 0.9964 & 0.9963 & 0.9964 & 0.9965 & 0.9966 & 0.9966 \\ GraphAtt & 0.9960 & 0.9960 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9962 & 0.9960 & 0.9961 & 0.9962 & 0.9963 & 0.9963 & 0.9964 & 0.9962 & 0.9964 \\   

Table 4: Node Classification ACC, Micro-AUC, Micro-F1 and F1 among PLM-based, GNN-based methods. AUC* and F1* represent Micro-AUC and Micro-F1 respectively. The best method on each dataset is BLM embedding on each dataset is shown in bold.

    &  &  &  &  &  \\   & AUC & F1* & AUC* & F1* & AUC* & F1* & AUC* & F1 & AUC* & F1 & AUC & F1 & AUC & F1 & AUC & F1 & AUC & F1 & AUC & F1 \\  GPT-3.5-TURBO & 0.5200 & 0.0300 & 0.5400 & 0.7000 & **0.5000** & **0.0100** & 0.5199 & 0.0918 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961 & 0.9961terms of AUC and F1 for Amazon-Movie, respectively. For the Citation and Twitter datasets, the state-of-the-art method is GraphTransformer. It outperforms the worst method by approximately 20% and 30% in terms of AUC and F1 for Citation, and by 12% and 9% in terms of AUC and F1 for Twitter, respectively. Second, Entangled-GPT methods, which entangle edge text and node text first before encoding with GPT consistently outperform the approach of directly encoding the text through GPT, yielding about 2% improvement in both AUC and F1 metrics across all datasets on the link prediction tasks. Third, For the LLM as Predictor methods, we find that they do not perform well in predicting links. The best method among them has an AUC and F1 gap of approximately 10% - 30% compared to the best PLM-based and GNN-based methods for all datasets. Fourth, using edge text provides at least approximately a 3% improvement in AUC and at least approximately an 8% improvement in F1 compared to not using edge text for all datasets.

### Effectiveness Analysis for Node Classification

In this subsection, we analyze the node classification results from various models. Table 4 and 5 display the impact on different datasets from various distinct, with additional results in Appendix B.3. We can derive some insights from the data. First, for PLM-based and GNN-based methods, the state-of-the-art models for Goodreads-Children and Goodreads-Crime are GraphsSAGE and GeneralConv, respectively, outperforming the worst method by approximately 8% and 20% in AUC-micro and F1-micro for Goodreads-Children, and by 4% and 15% for Goodreads-Crime. In the E-commerce domain, GraphSAGE is the top method for Amazon-Apps and Amazon-Movie, outperforming the worst method by about 10% and 6% in AUC-micro and F1-micro for Amazon-Apps, and by 1% and 10% for Amazon-Movie. GINE and EdgeConv also show superior performance, exceeding the worst method by approximately 35% and 40% in ACC and F1 for Citation, and by 5% and 12% for Twitter. Second, Entangled-GPT methods outperform the approach of directly encoding the text through GPT, yielding about 2% improvement in both AUC and F1 metrics across all datasets on the node classification tasks. Third, LLM as Predictor methods perform poorly in node classification, with the best method showing an AUC-micro gap of about 30% compared to the best PLM-based and GNN-based methods. Their low F1-micro score could be due to the large number of predicted categories. Third, incorporating edge text results in at least a 3% improvement in AUC-micro and a 6% improvement in F1-micro across all datasets, compared to not using edge text.

**Observation.**_(1) The state-of-the-art model varies across different datasets._ Data variability and complexity play significant roles in influencing model performance. _(2) Edge text is crucial for TEG tasks._ Including edge text enriches relationship information, enabling a more precise depiction of interactions and relationships between nodes, which enhances overall model performance. _(3) Encoding text in an entangled manner is more beneficial for avoiding information loss._ The advantage of this method over existing approaches is its ability to effectively preserve the semantic relationships between nodes and edges, making it more suitable for capturing complex relationships. _(4) The scale of PLMs significantly impacts the performance of TEG tasks, especially on datasets with rich text on nodes and edges._ Larger model scales result in higher-quality text embeddings and better semantic understanding, leading to improved model performance. _(5) When using LLMs as predictors, they struggle to fully comprehend graph topology information._ LLMs are designed for linear sequence data and do not inherently capture the complex relationships and structures present in graph data, leading to lower performance on TEGs link prediction and node classification.

### Parameter Sensitivity Analysis

We further analyze the impact of text embeddings generated from PLMs. For the link prediction task, as shown in Table 2, using small-scale PLMs like BERT improves the AUC and F1 scores by approximately 5% compared to not using text embeddings. Medium-scale models such as BERT-Large and large-scale models like GPT-3.5-TURBO improve the AUC and F1 scores by about 7% across all datasets. For node classification, as shown in Table 4, the improvement is slightly less pronounced. Small-scale PLMs like BERT improve the AUC-micro and F1-micro scores by approximately 3%, while medium-scale models like BERT-Large and large-scale models like GPT-3.5-TURBO improve these scores by about 3.5% across all datasets.

## 6 Discussion

Textual-Edge graphs have emerged as a prominent graph format, which finds extensive applications in modeling real-world tasks. Our research focuses on comprehensively understanding the textual attributes of nodes and their topological connections. Furthermore, we believe that exploring strategies to enhance the efficiency of LLMs in processing TEGs is deemed meaningful. Despite the proven effectiveness of LLMs, their operational efficiency, especially in managing TEGs, poses a significant challenge. Notably, employing APIs like GPT4 for extensive graph tasks may result in considerable expenses under current billing models. Additionally, deploying open-source large models such as LLaMa for tasks like parameter updates or inference in local environments demands substantial computational resources and storage capacity. Please refer to the Appendix C for more details.

## 7 Conclusion

We introduce the inaugural TEG benchmark, TEG-DB, tailored to delve into graph representation learning on TEGs. It incorporates textual content on both nodes and edges compared to traditional TAG with only node information. We gather and furnish nine comprehensive textual-edge datasets to foster collaboration between the NLP and GNN communities in exploring the data collectively. Our benchmark offers a thorough assessment of various learning approaches, affirming their efficacy and constraints. Additionally, we plan to persist in uncovering and building more research-oriented TEGs to further propel the ongoing robust growth of the domain.