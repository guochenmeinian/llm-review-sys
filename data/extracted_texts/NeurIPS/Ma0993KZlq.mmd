# Active Classification with Few Queries under Misspecification

Vasilis Kontonis

UT-Austin

vasilis@cs.utexas.edu

&Mingchen Ma

University of Wisconsin-Madison

mingchen@cs.wisc.edu

Equal Contribution

 Christos Tzamos

University of Athens and Archimedes AI

ctzamos@gmail.com

###### Abstract

We study pool-based active learning, where a learner has a large pool \(S\) of unlabeled examples and can adaptively ask a labeler questions to learn these labels. The goal of the learner is to output a labeling for \(S\) that can compete with the best hypothesis from a given hypothesis class \(\). We focus on halfspace learning, one of the most important problems in active learning.

It is well known that in the standard active learning model, learning the labels of an arbitrary pool of examples labeled by some halfspace up to error \(\) requires at least \((1/)\) queries. To overcome this difficulty, previous work designs simple but powerful query languages to achieve \(O((1/))\) query complexity, but only focuses on the realizable setting where data are perfectly labeled by some halfspace. However, when labels are noisy, such queries are too fragile and lead to high query complexity even under the simple random classification noise model.

In this work, we propose a new query language called threshold statistical queries and study their power for learning under various noise models. Our main algorithmic result is the first query-efficient algorithm for learning halfspaces under the popular Massart noise model. With an arbitrary dataset corrupted with Massart noise at noise rate \(\), our algorithm uses only \((1/)\) threshold statistical queries and computes an \((+)\)-accurate labeling in polynomial time. For the harder case of agnostic noise, we show that it is impossible to beat \(O(1/)\) query complexity even for the much simpler problem of learning singletons (and thus for learning halfspaces) using a reduction from agnostic distributed learning.

## 1 Introduction

Obtaining labeled examples is often challenging in applications as querying either human annotators or powerful pre-trained models is time-consuming and/or expensive. Active learning aims to minimize the number of labeled examples required for a task by allowing the learner to adaptively select for which examples they want to obtain labels. More precisely, in pool-based active learning, the learner has to infer the labels of a pool \(S\) of \(n\) unlabeled examples, and can adaptively select an example \(x S\) and ask for its label.

Even though it is known that active learning can exponentially reduce the number of required labels, this is unfortunately only true in very idealized settings such as datasets labeled by one-dimensionalthresholds or structured high-dimensional instances (e.g., Gaussian marginals) . It is well-known that without such distributional assumptions, even for linear classification in \(2\) dimensions, active learning yields no improvement over passive learning .

Active Learning with QueriesTo bypass the hardness results and establish learning without restrictive distributional assumptions  introduce enriched queries, where the learner is allowed to make more complicated queries. Broadly speaking, there are two lines of work that study active learning with enriched queries. The first one designs queries based on the structure of the hypothesis class it aims to learn. For example,  design comparison queries for learning halfspaces in \(2\) dimensions,  design same-leaf queries for learning decision trees, and  design derivative queries to learn polynomial threshold functions. The success of these queries heavily depends on the relation between the hypothesis class and the properties of the queries and thus a completely new query language has to be designed if the learning problem gets changed. The other line of work such as  study mistake-based queries, asking questions like if a positive example exists in a given set. These works break down a complicated learning problem into a small number of simple statistical tasks that require only very few rounds of interactions with a labeler who knows the hidden labels and can easily solve these tasks. These learning models can be formally summarized as follows.

**Definition 1.1** (Active Learning with Enriched Queries).: _Given a (multi)set of \(n\) unlabeled examples \(S\) over a domain \(\), a learner \(\) wants to output a hypothesis \(:\{ 1\}\) by adaptively submitting binary queries to a labeler who knows the hidden labels of the examples \(S\). Each query \(q:2^{S\{ 1\}}\{0,1\}\) is a function that takes a subset of examples in \(S\) together with their unknown labels as input and outputs a number in \(\{0,1\}\). If \(f(x):S\{ 1\}\) is the unknown labeling function, the learner aims to make the error of \(\),_

\[(f):=_{x S}((x) f(x))\]

_as small as possible compared to a target class of binary hypotheses \(\) over \(\)._

In the _realizable setting_ where the unknown labeling function belongs to the target hypothesis class \(\), several non-trivial hypothesis classes including the class of halfspaces have been proven efficiently learnable using only a logarithmic number of rounds of interactions. For example,  shows for any set \(S\) of \(n\) examples satisfying \(\)-margin condition with respect to the underlying halfspace \(h^{*}\), one can use \(O(d(d/))\) seed queries, which returns an example with a specified label in a given region, to perfectly learn labels of all examples in \(S\) efficiently. More recently,  shows that for an arbitrary set of \(n\) examples labeled by an arbitrary halfspace, efficiently learning all the labels only requires \((d^{3}(n))\) region queries, which ask if an example with a specified label exists in a given region.

While these results show that mistake-based queries are extremely powerful in the realizable case, they fail to capture most practical cases where there is typically model misspecification or errors in the data. In fact, it is not hard to see that even under tiny amounts of noise, these mistake-based queries become essentially unusable and can be simulated by label queries. For example, if the labels of the examples are flipped with probability \(\), say 10% (random classification noise ), then a region query over a region that contains more than \(10\) examples will return "yes" with extremely high probability, which provides no information to the learner. In fact, even for the more powerful seed query used in , where in addition an example with the specified label is returned,  shows that if an algorithm can learn the labels of a set of examples \(S\) with error \(+\), with ground truth in a given hypothesis class \(H\) corrupted by \(\)-level random classification noise using \(M()\) queries, then one can simulate such an algorithm using \(M()/\) label queries. Such a result implies even for simple hypothesis classes such as the class of intervals in real line or the class of halfspaces in \(2\) dimensions, one needs at least \((1/)\) seed/region queries to learn the labels of examples in a given dataset to error \(+\). The gap between the realizable setting and the noise setting motivates the following natural questions:

_Can we design a simple noise-tolerant query language, that allows learning non-trivial hypothesis classes efficiently with few queries?_

Similar to , in this work, we focus on the class of halfspaces, one of the most important hypothesis classes in active learning.

### Learning Model And Our Contribution

We propose a new query language called Threshold Statistical Queries (TSQ), which generalizes the region queries used in [10; 35] and study its power for learning halfspaces under noise.

**Definition 1.2** (Threshold Statistical Queries (TSQ)).: _Let \(S\) be a set of examples in a domain \(\) with a corresponding labeling function \(f:S\{ 1\}\). A threshold SQ query \(q(,)\) takes as input a function \((x,y)\) over \(S\{ 1\}\) and a threshold \(\), and answers whether \(_{x S}(x,f(x))\)._

TSQ is a simple generalization of region queries and vanilla label queries. For a region \(U S\) and a target label \(a\{ 1\}\), if \((x,y)=(x U f(x)=a)\), then \(q(,1)\) is exactly the region query, where it checks if at least one example in \(U\) has label \(a\{ 1\}\). Furthermore, if \(|U|=1\), then \(q(,1)\) is exactly the classic label queries.

Our goal is to study the power of TSQ for active learning under different label noise models. We consider 3 progressively more challenging noise models commonly studied in the literature: Random, Massart and Adversarial.

**Definition 1.3** (Active Learning under Label Noise).: _Let \(\) be a hypothesis class over domain \(\). Let \(S\) be a (multi)set of \(n\) examples and \(h^{*}\) be a ground truth function. For a parameter \([0,1/2)\), the labeling function \(f(x)\) over \(S\) is generated in the following way under the three label noise models._

* _Random Classification Noise (RCN)_ _: For each_ \(x S\)_,_ \(f(x)\) _is_ \(-h^{*}(x)\) _with probability_ \(\) _and_ \(h^{*}(x)\) _otherwise._
* _Massart Noise_ _: For each_ \(x S\)_,_ \(f(x)=-h^{*}(x)\) _with some unknown probability_ \((x)\) _and_ \(h^{*}(x)\) _otherwise._
* _Adversarial Label Noise_: For an unknown subset_ \(S^{}\) _containing_ \(\) _fraction of examples from_ \(S\)_,_ \(f(x)=-h^{*}(x)\) _for all_ \(x S^{}\) _and_ \(f(x)=h^{*}(x)\) _for all_ \(x S S^{}\)_._

_Given the unlabeled examples \(S\), and an error parameter \((0,1)\), the goal of the learner is to output a labeling \(\) over \(S\) such that with high probability \(()+\)_

We remark that in our model, after the labeling \(f(x)\) is generated, the label of each example \(x S\) will be fixed throughout the learning process, also known as persistent noise. This means if an algorithm keeps querying the label of the same example, it will receive the same answer. Furthermore, under the Random classification noise/Massart noise model, we will assume the size \(n\) of the dataset \(S\) is large enough (\((d,1/)\)), because if \(n\) is small we have even no guarantee on the error of the ground truth hypothesis. Our main algorithmic result is the first distribution-free halfspace learning algorithm that achieves both computational efficiency and query efficiency under the (persistent) Massart noise model and the Random Classification Noise model.

**Theorem 1.4**.: _Let \(=\{h(x)=(w x) w S^{d-1}\}\) be the class of halfspaces over \(^{d}\). Given parameters \(,(0,1)\), a set \(S\) of \(n=(d,1/,(1/))\) examples in \(\) and TSQ query access to an unknown labeling corresponding to a ground truth hypothesis \(h^{*}\) corrupted with Massart noise \([0,1/2)\), we can compute in \((n)\) time a labeling \(\) such that \(()+\), with probability at least \(1-\), making \((d^{3}^{3}(1/))\) threshold SQ queries._

Importantly, unlike , we make no structure assumption over the dataset \(S\), and the query complexity of our algorithm qualitatively matches the query complexity obtained by , which only holds in the realizable setting. Theorem1.4 shows a sharp separation between standard active learning/region queries which require \((1/)\) query complexity and threshold statistical queries where \((1/)\) query complexity suffices under the Massart noise and Random classification noise models. Furthermore, we will discuss in AppendixA that the TSQs we use in the algorithm have very simple strictures. A natural question is whether TSQ can tolerate more complex noise.

Our second main result is a negative result showing that even using TSQ, it is still hard to achieve query efficiency under the adversarial label noise even for simpler hypothesis classes such as the class of singleton and the class of intervals and thus for the class of halfspaces. Formally, we have the following theorem.

**Theorem 1.5**.: _Let \(\) be the class of singleton functions over the domain \(=\). For every \((0,1)\) and \(m>(1/)\), there is a set \(S\) of \(m\) examples over \(\) and a labeling function \(f\) for \(S\) such thatany learning algorithm \(\) that makes less than \((1/)\) TSQs must output, with probability at least \(1/3\), a labeling function \(\) with error \(()>+\), where \(=_{h}(h)\)._

As we can always embed an instance of learning singleton into an instance of learning a 2-dimensional halfspace, Theorem1.5 also implies a \((1/)\) query complexity for agnostic learning halfspaces with TSQ. This shows a sharp separation of the performance of TSQ under different noise models and leaves designing more robust query languages as an important future direction. From a technical perspective, unlike usual approaches in the active learning literature which explicitly construct hard instances [16; 28], we obtain our result via reduction from the agnostic distributed learning problem studied by  for which a communication complexity lower-bound has been established. To the best of our knowledge, this is the first result that connects distributed learning and active learning, two seemingly unrelated learning models.

Though, Theorem1.5 shows that agnostic learning up to error \(+\) cannot be achieved in a query efficient way, inspired by the work of , it is possible to use only \((d(1/))\) TSQ to learn the label of a dataset up to error \(O()+\) for every hypothesis class with finite VC dimension, though the running time of the algorithm is exponential. Such a result might be of independent interest as how to efficiently learn a hypothesis up to error \(O()+\) have already been studied in many agnostic learning literature such as [13; 14; 22]. We leave the proof of Theorem1.6 to AppendixC due to the space limit.

**Theorem 1.6**.: _Let \(\) be the space of examples and \(\) be a hypothesis class over \(\) with VC-dimension \(d\), there is an algorithm such that for every \(,(0,1)\), for every set \(S\) of \(n\) examples, and for every labeling function \(f(x)\), it makes \((d(1/))\) TSQs and outputs a labeling \(\) such that with probability \(1-\), \(() O()+\), where \(=_{h}(h)\)._

### Related Works

Active Learning with Mistake-Based QueriesLearning with mistake-based queries has a long history [1; 39; 5; 10]. A typical mistake-based query can be understood as follows. A learner selects a subset of examples \(T\) and proposes a possible labeling for them to a labeler. The labeler will return an example \(x T\) labeled incorrectly by the learner or return nothing when every example in \(T\) is labeled correctly. Beyond being quite successful in theory, mistake-based queries also have wide applications in commercial systems [11; 25]. In the realizable setting, it has been well-known that such queries can be used to implement the Halving algorithm  and achieve \(O(d(1/))\) query complexity for hypothesis classes of VC dimension \(d\). However, it is only until very recently [10; 35] that people know how to use these queries to design algorithms that achieve both computational efficiency and query efficiency. In the noisy setting,  shows that even under random classification noise, it is impossible to use such queries to do query-efficient learning even for very simple classes. In this work, we propose TSQ as a robust generalization of these queries.

Statistical Query Learning ModelClose to our threshold statistical learning model (TSQ) is the classic statistical learning model (SQ) proposed by . SQ was originally designed to overcome random classification noise but has numerous applications in learning theory literature as a refinement of the PAC learning model which captures most algorithms used in practice. It has been used as a tool for obtaining efficient learning algorithms robust to noise  and as an evidence of computational difficulty of a statistical problems . In the SQ model, the learner has no direct access to any example but can evaluate the expectation \(_{(x,y) D}\,(x,y)\) for an arbitrary bounded function \((x,y)\) within accuracy \(\). This means in SQ model, a learning algorithm should consider both the time used for computing \((x,y)\) but also have to consider the final accuracy. On the other hand, a TSQ is a boolean function of the unlabeled examples and their hidden labels. No matter the complexity, any TSQ, \(q()\) can be computed by the labeler accurately in time at most \(O(n)\). Furthermore, as in SQ model, a learner has no access to individual examples, SQ learning does not naturally fit in the active learning model. One even cannot implement classic active learning algorithms such as CAL or Halving [27; 28] in the SQ model. As opposed to SQ, our TSQ model is more powerful as it can isolate individual examples and thus fills such a gap. We remark that this more powerful type of access is not needed for Theorem1.4 and can be implemented with SQ queries of \(()\) accuracy.

Learning Halfspaces with Massart NoiseActive learning for halfspaces under Massart noise also has a long history. Many works [4; 46; 3; 48] design learning algorithms that achieve both computational efficiency and query efficiency under structured distributions such as the uniform distribution over the unit sphere, the Gaussian distribution, and log-concave distributions. On the other hand, without distributional assumptions, learning under Massart noise is much more challenging. Computationally efficient learning algorithm for learning halfspaces under Massart noise [18; 12; 20] were only recently discovered for passive learning. Our algorithm is the first one that works in an active learning setting and achieves both computational efficiency and query efficiency.

## 2 Learning Halfspaces under Massart Noise

In this section, we present Theorem1.4, our main algorithmic result. The full proof is left at AppendixA. To start with, we give a high-level overview of how our algorithm works. Similar to previous works on distribution-free learning halfspaces [9; 18; 35], our learning algorithms recursively run two subroutines over the dataset \(S\). The first subroutine is a weak learning algorithm that works under structured datasets \(S^{}\). More specifically, we assume that all points in the dataset have unit norm and for every direction \(w S^{d-1}\), there are at least \((1/d)\) fraction of the examples \(x\) in \(S^{}\) such that \(|w x|(1/)\). Intuitively, the regions \(\{x S^{}|w x|(1/)\}\) correspond to examples for which a halfspace with normal vector \(w\) is more confident about the label. If \(S^{}\) contains a non-trivial fraction of examples in \(S\) and we can run a weak learning algorithm over \(S^{}\) to learn a vector \(w\) that has a classification error \(+\) over \(\{x S^{}|w x|(1/)\}\), we are able to label a non-trivial fraction of examples in \(S\) with a low error. In Section2.1, we will design such a learning algorithm that is robust to Massart noise and achieves query efficiency and computational efficiency simultaneously. However, in general, it is not always possible to find a large enough subset from \(S\) that is in an approximate radially isotropic position. Forster's transform , a powerful preprocessing technique can be used to solve this issue. Given any set of \(n\) examples in \(^{d}\), we can always use Forster's transform to find a subset of \(kn/d\) examples that lie in a \(k\) dimensional subspace such that after a non-linear transformation, the transformed examples are in an approximate radially isotropic position. This implies that if we can implement our weak learning algorithm over the transformed data, each round, we are able to label \(1/d\) fraction of the whole dataset with small error and thus after \(d(1/)\) rounds of weak learning, only \(\) fraction of the examples are unlabeled. In Section2.2, we will show how to use Forster's transform to select a large fraction of the dataset for the weak learning algorithm and how to implement the weak learning algorithm over the transformed dataset using TSQ. Furthermore, we want to point out that the TSQs we use in our algorithms have very simple structures. We leave the discussion in detail in AppendixA.

### A Weak Learning Oracle

In this section, we present our weak learning algorithm, Algorithm1, which plays a central role in Theorem1.4. Our main algorithmic result in this section is the following theorem, the proof of which can be found in AppendixA.

**Theorem 2.1**.: _Let \(V^{d}\) be a subspace of dimension \(k\) and \(S V\) be a set of \(n=(k,1/,(1/))\) examples with unit length. Let \(h^{*}(x)=(w^{*} x),w^{*} B_{1}^{k}\) be the ground truth hypothesis. If for every unit vector \(w B_{1}^{k}\), at least \(1/4d\) fraction of examples \(x S\) satisfy \(|w x| 1/(2)\), and \(u w^{*} 1/(4)\), then under the Massart noise model, for every ground truth, with probability at least \(1-\), Algorithm1 outputs \((S^{},_{S^{}})\) such that \(|S^{}| n/(4k)\) and \(_{S^{}}\) has error at most \(+\) over \(S^{}\), using \((d^{2}^{2}(1/))\) TSQ, in \((n,k)\) time._

To understand why Algorithm1 is robust to Massart noise, we need to understand why such a problem is difficult. Let \(S\) be a subset of \(n\) example in an approximate radially isotropic position. Take the algorithm in  as an example. Such an algorithm uses a modified perception algorithm to learn some \(w\) that can perfectly classify all examples that have a large margin with respect to it. Namely, in each round, either the current hypothesis \(w_{i}\) perfectly classifies a large fraction of examples or seed/region queries are used to quickly find an example in that region that is misclassified by \(w_{i}\), which will be fed to the perception algorithm and improve \(w_{i}\). In the noisy setting, however, every example \(x\) has a constant probability of being misclassified by \(w_{i}\). This implies we need to use queries to find a "point" where \(w^{*}\) and \(w_{i}\) disagree. To do this, we associate each example \(x\) in the region \(S_{i}=\{x S|w x|(1/)\}\), with a variable \(Y_{x}\{0,1\}\), where \(Y_{x}=1\) if \((w_{i} x) y(x)\) and \(0\) otherwise. If the noise \((x)=\) for every example \(x\) i.e. Massart noise model degenerates to the random classification noise model, then consider the following point

\[=_{x S_{i}}(Y_{x}-)x=_{x S_{+}}(Y_{x}-)x+_{x S _{-}}(Y_{x}-)x,\]

where \(S_{+}\) is the subset of examples in \(S_{i}\) where \(w_{i}\) agrees with \(w^{*}\) and \(S_{-}=S_{i} S_{+}\). For each \(x S_{+},}Y_{x}=\), while for every \(x S_{-}\), \(}Y_{x}=1-\). This implies that in expectation, \(}=(1-2)_{x S_{-}}x\). After properly scaling, this gives a point in \(S_{i}\) where \(w_{i}\) and \(w^{*}\) disagree due to the convexity of the problem and thus serves as a counter-example to run the perception algorithm. In particular, since the contribution of each example \(x\) only depends on its true label, we can draw random samples from \(S_{i}\) and use TSQ along each coordinate to approximately find \(\) up to high accuracy using very few queries via binary search.

However, for Massart noise, this is not the correct way to design a learning algorithm. This is because \((x)\) is non-uniform over each \(x\). For simplicity, we assume \(w_{i} x>0\) for each \(x S_{i}\). As \((x)\), a simple calculation shows that \(E w^{*} 0\), where the randomness only comes from the Massart noise. The hope is that if \(w_{i}\) has an error \(+\) over \(S_{i}\), then \( w_{i}\) is larger than some positive number so that we find a counter-example. This is unfortunately not true. Because \(w_{i} x\) are different and \((x)\) are different, even if the error is large, some of the examples with large margins could force \(\) points to the opposite direction, making \( w_{i} 0\) as well. To overcome this issue, we consider using a slightly more complicated statistic here, where we define

\[:=_{x S_{i}}(Y_{x}-) x}\]

instead. Such a point is still easy to approximate up to error \(\) with only \(d(1/)\) TSQs, because it is each to compute \(w_{i} x\) for each \(x S_{i}\). But more importantly, when \(w_{i}\) has an error larger than \(+\), in expectation \(w_{i}\) and \(w^{*}\) will always disagree on \(\) because

\[|}w_{i}=|}_{x S_{i}}(Y_{x}- ) x} w_{i}=|}_{x S_{i}}(Y_{x }-)>.\] (1)

Furthermore, as \(w_{i} x\) is large for every \(x S_{i}\), \(\) has a bounded norm and thus can serve as a counter-example. A technical issue here is that the inequality \(} w^{*} 0\) is quite fragile, due to the randomness of the Massart noise, it is impossible to guarantee \( w^{*} 0\) actually holds after the labeling being fixed. This issue can be fixed using the following trick. Before run the learning algorithm, we will randomly sample a unit vector \(u\). We know from  that with constant probability \(u w^{*}>1/\) and thus by shifting \(\) a little towards \(-u\), this will give us a counter example and guarantee the whole algorithm succeeds with a constant probability.

Though, we find a counter-example and can use it to run a perception algorithm in a similar way to , this cannot give us a good query complexity. This is because (1) can only guarantee \( w_{i}>\), which requires to run the perception algorithm for \(O(1/^{2})\) rounds to converge to a good hypothesis. Thus, we will solve this problem using Vaidya's cutting plane method. We want to remind the reader of the following convex feasibility problem, which is closely related to our halfspace learning problem.

**Definition 2.2** (Convex Feasibility Problem).: _Let \(K^{d}\) be a convex body. A separation oracle with respect to \(K\) is a function on \(^{d}\) such that for any input \(x^{d}\), if \(x K\), then it reports "yes", otherwise it outputs some \((c^{t},b)^{d+1}\) such that for every \(y K\), \(c y b\) but \(c x b\). Assuming \(K B_{1}^{d}\), given a separation oracle with respect to \(K\) and \((0,1)\), the convex feasibility problem asks to either find some \(x K\) or prove that \(K\) does not contain a ball of radius \(\)._

There exists a long line of research for solving the convex feasibility problem for example, . We will use these algorithms as a subroutine of our learning algorithm.

**Theorem 2.3** (Vaidya's Algorithm).: _Let \(K P_{0} B_{1}^{d}\) be an unknown convex body. Vaidya's algorithm solves the convex feasibility problem for \(K\) as follows. In round \(i\), it maintains a convex body \(K P_{i} P_{0}\) and a point \(x_{i} P_{i}\) and sends \(x_{i}\) to the separation oracle of \(K\). If the oracle returns "yes", then it claims \(x_{i} K\), otherwise it computes in \((d,(1/))\) time a pair of \((P_{i+1},x_{i+1})\) based on \((c_{i}^{t},b_{i})\) the return of the separation oracle. In particular, after \(T=(d(1/))\) rounds, \(P_{T}\) does not contain a ball of radius \(\)._

Let the unknown convex body \(K\) that we want to solve for the convex feasibility problem be a ball of radius \(\) around \(w^{*}\) and we want to run Vaidya's algorithm to find some \(w_{i}\) close to \(w_{*}\). Consider the \(P_{i}\) maintained by Vaidya's algorithm. As with constant probability \(w^{*} u 1/\) as we mentioned earlier, we can guarantee that \(0 P_{i}\). Let \(x_{i}\) be the point used by Vaidya's algorithm. Then we will check the error of \(w_{i}=x_{i}/\|x_{i}\|\) over \(S_{i}\) is large, which can be done with a single TSQ. If the error is less than \(+\), we are done. Otherwise, we use \((d(1/))\) TSQ to approximately find a counter example \(\) for \(w_{i}\). Importantly, the halfspace \( w 0\) separate \(x_{i}\) and any \(w K\). This will make it possible to run the next round of Vaidya's algorithm. Since we only care about examples that have margin \((1/)\) with respect to \(w_{i}\), when \(w_{i}\) is within a ball of radius \(1/(d)\) centered at \(w^{*}\), every example in \(S_{i}\) is agreed by \(w_{i}\) and \(w^{*}\) and thus \(w_{i}\) is guaranteed to have error at most \(+\). Furthermore, in each round, Vaidya's algorithm shrinks the volume of \(P_{i}\) by a constant factor, and after at most \((d(1/))\) rounds, we are guaranteed to find a good hypothesis. This gives a weak learning algorithm with a desired query complexity.

### From Weak Learning to Strong Learning

We leave the formal analysis of the algorithm to Appendix A and discuss two technical issues raised in designing Algorithm 2. First, as required in Theorem 2.1, the dataset \(S\) should be large enough and satisfy the structured assumption. Thus, to run Algorithm 1, we need to recursively select a dataset of enough size that satisfies the structured assumption from the data we have not labeled. In fact, the structured assumption can be fulfilled by a dataset that is in approximate radially isotropic position.

**Definition 2.4** (Approximate Radially Isotropic Position).: _Let \(S\) be a multiset of non-zero points in \(^{d}\), we say \(S\) is in \(\)-approximate radially isotropic position, if for every \(x S\), \(\|x\|=1\) and for every \(u S^{d-1}\), \(_{x S}(u x)^{2}/|S| 1/d-\)._

**Lemma 2.5**.: _Let \(S\) be a multiset of non-zero points in \(^{d}\) that is in \(1/2d\)-approximate radially isotropic position. Then for every \(u S^{d-1}\), we have \(_{x S}(|u x| 1/2) 1 /4d\)._

Recent results show that for any dataset \(S\), one can efficiently find a non-trivial fraction of the data and a non-linear transformation such that after the transform, the data are in approximate radially isotropic position.

**Theorem 2.6** (Approximate Forster's Transform ).: _There is an algorithm such that given any set of \(n\) points \(S^{d}\{0\}\) and \(>0\), it runs in time \((d,n, 1/)\) and returns a subspace \(V\) of \(^{d}\) containing at least \((V)/d\) fraction of points in \(S\) and an invertible matrix \(A^{d d}\) such that \(F_{A}(S V)\) is in \(\)-approximate radially isotropic position up to isomorphic to \(^{(V)}\), where \(F_{A}(S V)=\{F_{A}(x):=Ax/\|Ax\| x S V\}\)._

Combine Theorem2.6 and Lemma2.5, we know that given any set of \(n\) examples \(S^{d}\), we can find a subset of at least \(kn/d\) examples \(S_{V}:=S V S\) that lies in some \(k\)-dimensional subspace \(V\) and some invertible matrix \(A\) such that \(F_{A}(S_{V})\) is in \(1/2k\)-approximate radially isotropic position (up to isomorphic to \(^{k}\)). Now, for convenience, we assume our transformed data \(F_{A}(S_{V})\) is exactly our original dataset and we focus on the transformed data. Notice that for each \(x S_{V}\), we have

\[(w^{*} x)=(A^{-T}w^{*} Ax)= (A^{-T}w^{*} F_{A}(x))=( {proj}_{A(V)}(A^{-T}w^{*}) f_{A}(x)),\]

which implies that each transformed example \(F_{A}(x)\) is labeled by halfspace \(v^{*}=_{A(V)}(A^{-T}w^{*})\) and has the same label as \(x\). So, we can use Algorithm1 to learn their labels. However, as Algorithm1 is run over the transformed data, we have to simulate every TSQ used by the algorithm via a TSQ over the original data. This issue can be overcome using the following argument. Since \(F_{A}\) is a bijection between \(x\) and \(F_{A}(x)\) and the outcome of the function \((x,y)\) used in a TSQ for each example \(x\) can be uniquely represented by two numbers, we can rewrite \((F_{A}(x),y)\) as a function of \(x\) for each \(F_{A}(x)\) such that for a TSQ as long as \(y(F_{A}(x))=f(x)\), the result of the query will be the same. This gives us a way to simulate the TSQ over \(S\).

``` Input:\(,(0,1)\), \(S^{d}\) of \(n\) examples Output:\(:S\{ 1\}\) a labeling for \(S\)\(L\), \(n|S|\) while\(|S|> n/2\)do  Apply Theorem2.6 to \(S\) with \(=1/2d\) to obtain a matrix \(A\) and a \(k\)-dimensional subspace \(V\)  Use a single TSQ to check if constant hypothesis \(+1(-1)\) has error \(+\) over \(S V\) if constant hypothesis has error at most \(+/2\) over \(S V\)then  Define \(\) to be the constant over \(S^{}=S V\) \(S S S^{}\) else  Run Algorithm1 over input parameter \(/2,/(d,(1/))\), \(V\), \(f_{A}(S V)\) and a random unit vector \(u V\) until some \((S^{},_{S^{}})\) is output. \(\) Though Algorithm1 is run over the transformed dataset \(f_{A}(S V)\), each TSQ can be simulated over the original data as \(F_{A}(x)\) preserves the ground truth label.  Define \((x)=_{S^{}}(F_{A}(x)), x,F_{A}(x) S^{}\) \(S S S^{}\)  Define \(=1\) for the rest of \( n/2\) examples in \(S\) return\(\) ```

**Algorithm 2** Strong Learning Halfspaces (Label \(S\) with few queries up to \(+\) error )

## 3 Agnostic Learning with Threshold SQ

In this section, we study learning with TSQs under the more challenging adversarial label noise proving Theorem1.5. In the previous section, we saw that using TSQ, learning halfspaces only requires \((1/)\) rounds of interactions. We show in this section that this is not the case for the adversarial label noise. We show that it is impossible to reduce the query complexity from \((1/)\) to \((1/)\) even for very simple classes such as the class of singletons (and thus the class of the halfspace in high dimensions). The classic method of proving query complexity lower bound [15; 16; 28] is to construct a hard instance directly. However, as there are infinite types of TSQs to be considered, it is impossible to construct a single hard instance that defeats all types of TSQs. Instead, we will build a reduction from a hardness result on agnostic distributed learning  that we define as follows.

**Definition 3.1** (Agnostic Distributed Learning).: _Let \(\) be the space of examples. Let \(a,b\) be two learners and \(S=<S_{a},S_{b}>\) be a collection of labeled examples, where \(S_{a}\) is the (multi)set of labeled examples owned by \(a\) and \(S_{b}\) is the (multi)set of labeled examples owned by \(b\). \(a,b\) only knows their own sample set. A learning protocol is a communication strategy, where in each round of communication \(a\) sends information by bits to \(b\) and after reviving information sent from \(a\), \(b\) sends information by bits back to \(a\) and finally the learning protocol outputs a hypothesis \(:\{ 1\}\). The error of \(\) is_

\[():=_{x S}( (x) f(x)),\]

_where \(f(x)\) is the true label of \(x\). Let \(S\) be a collection of labeled examples, and \(H\) be a hypothesis class. Given an accurate parameter \((0,1)\), the goal of the agnostic distributed learning problem is to design a learning protocol that outputs some \(\) such that \(()_{h H}(h)+\) while minimizing the number of bits communicated in the learning protocol._

In this paper, we will make use of the following slightly easier problem of agnostic distributed learning singleton functions, where the unlabeled examples owned by \(a,b\) are known to each other and they want to output a labeling with error at most \(\).

**Problem 3.2** (Distributed Learning Singleton).: _Consider the agnostic distributed problem. Let \(S=<S_{a},S_{b}>\) be a collection of examples, where for \(u\{a,b\},S_{u}=\{(i,y_{u}^{i})\}_{i=1}^{n}\), where \(y_{i}^{n}\{ 1\}\) for \(i[n]\). Let \(H=\{h_{i}(x)=2(x=i)-1 i\}\) be the class of singleton functions. The goal is to design a (randomized) learning protocol that outputs a hypothesis \(\) such that \(()_{h H}(h)+\) for \(=1/4n\) with probability at least \(2/3\)._

 shows the following hardness result for Problem3.2.

**Theorem 3.3** (Lemma 3 in ).: _If there is a (randomized) learning protocol that can solve Problem3.2 using \(T(n)\) bits of communication, then there is a (randomized) protocol that can solve the set-disjointness problem with \(T(n)(n)\) bits of communication._

According to , solving the set disjointness problem requires \((n)\) bits of communication, and thus solving Problem3.2 requires \((n)=(1/)\) bits of communication. The central result we use to prove Theorem1.5 is the following technical lemma, which means if one can agnostically learn the class of singleton functions with error \(\) using \(T(n)\) queries, then one can design a learning protocol for Problem3.2 with \(T(n)(n)\) bits of communication. This is enough to prove Theorem1.5, because given the hardness of Lemma3.4, we can create a hard problem by making multiple copies of each example used in the proof of Lemma3.4. This preserves the error of every hypothesis \(h:\{ 1\}\). We leave more details to AppendixB and in the rest of this section, we give an overview of the proof of Lemma3.4.

**Lemma 3.4**.: _Let \(S\) be a multiset of \(2n\) examples and \(f(x)\) be a hidden labeling function. Let \(=\{h_{i}(x)=2(x=i)-1 i\}\) be the class of singleton functions. If there is an algorithm \(\) that can make \(T(n)\) TSQ and outputs some \(\) such that \(()_{h H}(h)+\), with \(=1/4n\), then there is a learning protocol that can solve Problem3.2 with \(O(T(n)(n))\) bits of communications._

Consider \(\) to be a learning algorithm for singleton functions that can learn up to error \(\) with \(T(n)\) queries. Since both \(a,b\) know the unlabeled examples owned by each other and know the labels of examples owned by themselves, we will design a learning protocol for \(a,b\) to check the answer to each TSQ used by \(\) together using only \((n)\) bits of communication. Recall that in the definition of TSQ, each \(q_{i}\) answers if \(_{x S_{a}}(x,y)\), where \((x,y)\) given every \(x\) is a two-value function. Thus, to check the answer of \(q_{i}\), it is sufficient to check if \(_{x S_{a}}(x,y)-_{x S_{b}}(x,y)\). One possible way to check the answer is to let \(a\) send the number \(_{x S_{a}}(x,y)\) to \(b\). However, if a TSQ is very complicated, communicating such a number would cost too many bits. Two arguments are made to address this problem. First, we claim that we can assume every outcome of \(_{x S_{a}}(x,y)\) and \(-_{x S_{b}}(x,y)\) is an integer with bit complexity \(n\). Intuitively, this is because there are at most \(2^{n}\) different outcomes for \(_{x S_{a}}(x,y)\) and \(-_{x S_{b}}(x,y)\) and we can explicitly create a map from each outcome to such an integer. Second, we show that to compare a pair of integers with bit complexity \(n\) only \((n)\) bits of communication are required. To see why this is true, we can expand integers \(I_{a}=_{x S_{a}}(x,y)\) and \(I_{b}=-_{x S_{b}}(x,y)\) into binary strings. Then \(I_{a}>I_{b}\) if and only if there exists some index \(i\) such that \((I_{a})_{j}=(I_{b})_{j}\) for each \(j>i\) but \((I_{a})_{j}>(I_{b})_{j}\) for each \(j=i\). Thus, to compare \(I_{a},I_{b}\), we only need to binary search the first index \(j\) such that the partial binary strings of \(I_{a},I_{b}\) are different. Since checking whether two binary strings are equal only requires \(O( n)\) bits of communication, we only need \(O(^{2}n)\) bits of communication to compare the two integers.