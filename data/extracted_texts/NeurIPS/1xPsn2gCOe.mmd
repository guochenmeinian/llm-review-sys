# Computing a human-like reaction time metric from stable recurrent vision models

Lore Goetschalckx

These authors contributed equally to this work. Department of Cognitive, Linguistic, & Psychological Sciences, Brown University, Providence, RI 02912 Carney Institute for Brain Science, Brown University, Providence, RI 02912 {lore_goetschalckx,alekh_karkada_ashok,thomas_serre}@brown.edu

Lakshmi N. Govindarajan

Alexkh K. Ashok

Aarit Ahuja

Neuroscience Department, Brown University, Providence, RI 02912 {aarit_ahuja,david_sheinberg}@brown.edu

David L. Sheinberg

Neuroscience Department, Brown University, Providence, RI 02912 {aarit_ahuja,david_sheinberg}@brown.edu

Thomas Serre

###### Abstract

The meteoric rise in the adoption of deep neural networks as computational models of vision has inspired efforts to "align" these models with humans. One dimension of interest for alignment includes behavioral choices, but moving beyond characterizing choice patterns to capturing temporal aspects of visual decision-making has been challenging. Here, we sketch a general-purpose methodology to construct computational accounts of reaction times from a stimulus-computable, task-optimized model. Specifically, we introduce a novel metric leveraging insights from subjective logic theory summarizing evidence accumulation in recurrent vision models. We demonstrate that our metric aligns with patterns of human reaction times for stimulus manipulations across four disparate visual decision-making tasks spanning perceptual grouping, mental simulation, and scene categorization. This work paves the way for exploring the temporal alignment of model and human visual strategies in the context of various other cognitive tasks toward generating testable hypotheses for neuroscience. Links to the code and data can be found on the project page: https://serre-lab.github.io/rnn_rts_site/.

## 1 Introduction

The symbiosis between visual neuroscience and machine learning has created a distinctive and unprecedented phase in the field of vision. On the one hand, formidable advances in machine learning have supported the development of computational models of visual cognition that rival, and in some cases surpass, human-level performance on naturalistic tasks [1; 2; 3; 4; 5]. On the other hand, incorporating computational and neurophysiological constraints from biological visual systems has yielded significant benefits for AI models in terms of their performance [6; 7], efficiency , and robustness [9; 10; 11]. Additionally, performant computational vision models that operate directly on high-dimensional sensory inputs have shown great promise for scientific discovery through the generation of testable hypotheses for neuroscience [12; 13]. At the core of this synergistic loop lies the need for reliably quantifying the degree of "alignment" between models and the primate visual system, which can subsequently serve as a control knob for closed-loop hypothesis testing.

The notion of "alignment" is subjective and can be operationalized at varying levels of analysis . One of the most prominent alignment techniques is to quantify the degree to which model featurerepresentations predict time-averaged firing rates of single neurons across various stimuli [11; 15; 16; 17]. In contrast, computational-level alignment analyses typically use axiomatic attribution methods  to extract minimal sub-circuits from larger models and probe them to gain mechanistic insights . A third popular approach to alignment is at a higher behavioral level, where techniques focus on understanding the extent to which models and primates utilize similar "visual strategies". Top-down attention masks, diagnostic of human observers' visual strategies, are a commonly employed axis of comparison in this type of model alignment [7; 19]. At the same time, other behavioral measures such as object confusion patterns [20; 21] or human-derived pairwise image similarity ratings  are also widely considered effective quantities that can form the basis of alignment.

Each of these techniques has a common tenet: their purview is limited to measures of alignment that are global, time-independent summaries of neural or behavioral states. While this may be sufficient for task paradigms primarily involving feedforward processing, a large part of visual cognition is highly dynamic [23; 24; 25]. Understanding visual computations, thus, necessarily involves characterizing and modeling the time-varying properties of neural responses to complex and varied inputs. _Why, then, is there a dearth of alignment methods focusing directly on the level of visual processing dynamics?_ We posit a two-fold bottleneck. First, there is a need for more performant models that exhibit and mimic visual cortical dynamics at scale. Second, we lack the mathematical tools to extract meaningful dynamical signatures from such models and compare them with biological systems. While recent progress in biologically-inspired machine learning has started to open up solutions for the former [8; 19; 26; 27; 28], the latter remains a wide-open research area.

**Contributions.** In this study, we consider this temporal alignment perspective. Recent advances in training biologically motivated large-scale convolutional recurrent neural network models (cRNNs henceforth) on visual cognition tasks  have provided candidate models to study the temporal alignment problem. A cRNN's inherent design affords access to its time-varying dynamical properties that can be explicitly analyzed. Throughout this paper, we specifically focus on extracting a metric that captures a cRNN's dynamical signature and on quantifying the ability of this metric to explain primate decision time courses in the form of reaction times (RTs) in concomitant visual psychophysics tasks.

* We introduce a novel computational framework to train, analyze, and interpret the behavior of cRNNs on visual cognitive tasks of choice. Our framework triangulates insights from an attractor dynamics-based training routine  and evidential learning theory  to support stable and expressive evidence accumulation strategies.
* We derive a stimulus-computable, task- and model-agnostic metric to characterize evidence accumulation in cRNNs. Our metric does not require extra supervision and purely leverages internal cRNN activity dynamics.
* We comprehensively demonstrate the efficacy of our metric in capturing stimulus-dependent primate decision time courses in the form of reaction times (RTs) in four disparate visual cognitive challenges that include incremental grouping, mental simulation, and scene categorization. To the best of our knowledge, this is the first demonstration of qualitative temporal alignments between models and primates across task paradigms.

## 2 Related Work

**Cognitive process models.** The speed-accuracy tradeoff in human behavior is ubiquitous in cognitive science  and has garnered much attention from the modeling perspective. The most prominent of them is the Drift-Diffusion Model (DDM) family, which specifies RTs by determining when the amount of accumulated evidence for a behavioral choice from a noisy process reaches a threshold value [32; 33]. Though such models have had phenomenal successes in aligning neural and behavioral data , they are typically not stimulus-computable or rely on handcrafted heuristics . Moreover, such models are usually directly fitted to RT data [35; 36], unlike our approach, where RT is a derived quantity without any additional supervision.

**Computing reaction-time proxies from neural network models.** Several notable efforts have attempted to derive RT measures from neural network models to serve as a proxy for "computational cost" [37; 38; 39; 40; 26; 41; 42]. Spoerer et al.  introduced the notion of energy demand in their objective function that motivated parsimony regarding the number of computations the cRNN executes. Bansalet al.  discussed "algorithmic extrapolation" where their networks solved problems of greater difficulty than those in their training set by performing additional computations. Graves  proposed the use of a "halting unit" whose activation level determined the probability of continuing model computations. Finally, Figurnov et al. , motivated by , adaptively determined the spatial extent and number of processing layers in a deep convolutional network. In a broader sense, "conditional computing" approaches aim to learn dropout-like policies [44; 45] to train neural networks that can balance parsimony and performance. While the approaches presented in [37; 43; 44; 45] are impressive advances, they neither operate explicitly with cRNNs nor yield RT values for downstream comparisons on visual cognitive tasks. The elegant approach of  suffers from the primary drawback that it relies on the backpropagation through time (BPTT) algorithm. BPTT imposes high memory demands, limiting the number of timesteps a cRNN can perform and therefore condemning any derived measure to be coarse. Furthermore, vanilla BPTT forces the dynamics to be constant (i.e., the cRNN arrives at a solution at \(t=T\) for any input) making it non-stimulus-adaptive .

**Probabilistic interpretation of model uncertainty.** Decision certainty and computational parsimony are duals of each other. In other words, easier tasks require fewer computational resources, with models typically being most certain about their predictions, while the opposite holds for harder tasks. Modeling decision uncertainties provide another effective angle to capture the "computational demand" of a stimulus condition. While deterministic neural networks suffer from ill-calibrated prediction confidence in Softmax outputs, Bayesian neural networks derive prediction confidence from their weight uncertainties but are generally not performant. Inspired by the Dempster-Shafer theory of evidence , Sensoy et al.  propose a formulation that treats model outputs as parameters of a Dirichlet distribution that signifies the total amount of evidence accumulated for each class. Although influential, this body of work, called Evidential Deep Learning (EDL), has never been linked to RT measures or applied to visual cognitive tasks. We refer the interested reader to Ulmer et al.  for a comprehensive survey of this literature. In this paper, we specifically leverage EDL in conjunction with attractor dynamics to support the derivation of an RT proxy.

## 3 General Methods

### Models

cRNN.The model of interest chosen in this work is the horizontal gated recurrent unit (hGRU; ), a convolutional recurrent neural network model that we will canonically refer to as cRNN throughout the rest of the paper. In principle, our framework applies to other cRNN architectures as well. The hGRU is inspired by the anatomical and neurophysiological properties of the primate

Figure 1: **Computing a reaction time metric from a recurrent vision model.****a.** A schematic representation of training a cRNN with evidential deep learning (EDL; ). Model outputs are interpreted as parameters (\(\)) of a Dirichlet distribution over class probability estimates, with higher values (symbolized here by a darker gray) reflecting more generated evidence in favor of the corresponding class. In this framework, the width of the distribution signals the model’s uncertainty (\(\)) about its predictions. **b.** Visualization of our metric, \(_{cRNN}\), computed for an example stimulus (see Panel a) used in the task studied in Section 4. The metric, denoted \(_{cRNN}\), is defined as the area under the uncertainty curve, i.e., the evolution of uncertainty (\(\)) over time.

visual cortex. Architectural facets of the hGRU include an hypercolumnar organization, distinct excitatory and inhibitory subpopulations, and local- and long-range feedback mechanisms, rendering it overcomplete and an ideal candidate cRNN for our purposes. The hGRU and its extensions have previously demonstrated proficiency in learning long-range spatial dependency challenges, including naturalistic ones . For implementational details, refer to SI SSA.

Control models.To further motivate our cRNN choice, we refer to its ability to systematically generalize to more challenging task settings after being trained on less challenging ones . Inference-time flexibility and performance are critical desiderata, given that our goal is to probe the computational demands of a task via stimulus manipulations. We first demonstrate that the cRNN's performance remained well above chance on exceedingly challenging versions of the first task we consider (see Section 4.1) after training on a simplified version (see SI SSB for full experimental details). We trained pure feedforward convolutional neural networks (CNNs) as control models under identical training

Figure 2: **Human versus cRNN temporal alignment on an incremental grouping task.****a.** Description of the task (inspired by cognitive neuroscience studies ). **b.** Visualization of the cRNN dynamics. The two lines represent the average latent trajectories across \(1K\) validation stimuli labeled “yes” and “no” respectively. Marker size indicates average uncertainty \(\) across the same stimuli. Evident from the graph is that the two trajectories start to diverge after some initial time passes, clearly separating the two classes. Owing to the C-RBP training algorithm and attesting to the dynamics approaching an equilibrium, the step sizes become increasingly small over time. We also include snapshots of the latent activity in the cRNN for two example stimuli (one “yes”, one “no”; see Panel a) along the respective trajectory. Each snapshot represents \(}\) at time step \(t\), averaged across the channel dimension and smoothed by averaging \(}\) and \(}\). Notice the spread of activity over time. The cRNN gradually fills the segment containing the dots. The strategy can be appreciated even better in video format (see SI SSD). **c.** Comparison against data from the experiment with human participants in . The position of one dot (white, labeled “Fix”) was kept constant, while the position of the other was manipulated to create experimental conditions of varying difficulty. These manipulations have qualitatively similar effects on the cRNN as they do on human behavior. Error bars represent the standard error of the mean across stimuli. The significance levels for shown contrasts were adjusted downward from.1 (*),.05*,.01**, and.001*** using Bonferroni. The spatial uncertainty map shown on the right visualizes the spatial anisotropy observed in the model for the same example stimulus shown on the left.

data distributions. The CNNs struggled to generalize effectively, as did a naive control RNN model (Fig. S1). Because CNNs lack explicit temporal dynamics and our recurrent control models failed our generalization test, we limit the experimental results presented in this paper to our cRNN. For completeness, we remark that a Vision Transformer  passed the generalization test. However, we exclude these models from our analyses for two reasons. First, as such, Vision Transformers lack biological analogs. Second, our focus in this work is to derive RT measures from model dynamics, which transformers do not exhibit.

### Training Framework

General remarks.All model runs reported herein were done from _scratch_ using only the ground truth class labels for supervision. Any alignment between the cRNN model and humans would have had to emerge as a byproduct of task constraints. We emphasize that no human RT data were involved in our training routines. For the cRNNs, we computed a task loss only at the network's end state to preserve the ability to remain flexible during inference. The cRNNs were trained in a data-parallel manner on 4 Nvidia RTX GPUs (Titan/3090/A5000) with 24GB of memory each. Each training run took approximately 48 hours, except those in Section 7 (2 hours), which were faster due to the smaller training dataset size. They were furthermore trained with Adam , a learning rate of \(1e-3\), and \(=100\) for the C-RBP penalty (; also see SI SSA). We use \(T=40\) recurrent timesteps during the training phase, with an exception for the task in Section 6, where \(T=80\) and \(=1000\).

Stabilizing cRNNs.We train our cRNN model with the contractor recurrent back-propagation algorithm (C-RBP; ). C-RBP imposes an attractor-dynamic constraint on the cRNN's computational trajectory, imparting several benefits over the standard BPTT algorithm. C-RBP is significantly more memory efficient and affords arbitrary precision in the cRNN temporal dynamics (i.e., \(T\) can be high). C-RBP also allows the cRNN to learn stable and expressive solutions. We can observe this from the cRNN's latent trajectories, as visualized in Fig. 2b, where extrapolation in time (beyond \(T\)) is non-catastrophic. We argue that model instability is why BPTT-trained controls failed the generalization test (Fig. S1). Furthermore, stable solutions imparted by C-RBP allow our cRNNs to dynamically adapt their number of processing steps in a stimulus-dependent manner. That is, we pose that a C-RBP-trained cRNN can utilize its computational budget differently depending on the input (see Fig. S2 for an illustration). Finally, we note that our strategy to achieve stable recurrent solutions is in contrast to that employed by Bansal et al. , wherein cRNNs were stabilized through architectural choices along with an incremental training process.

Evidential loss.We augment our cRNN training objective with an evidential deep learning loss (EDL; ). In contrast to the classic cross-entropy loss, EDL considers cRNN outputs to be the parameters of a belief distribution rather than point estimates of class probabilities (Fig. 1a). We formalize cRNN beliefs as a Dirichlet distribution. Strong evidence in favor of one class causes the Dirichlet distribution to be peaked, reflecting low uncertainty (\(\)). In contrast, when there is a lack of overall evidence, the Dirichlet distribution becomes more uniform, thereby increasing \(\). For a complete mathematical specification of this loss formulation, refer to SI SSA.

### RT Metric (\(}\))

We derive a novel metric to quantify the differential computational demands imposed on the cRNN by stimulus manipulations and capture the essence of model decision time courses for alignment. Modeling uncertainty (\(\)) explicitly allows us to track its evolution over time from the cRNN (Fig. 1b). We formulate our RT metric (\(_{cRNN}\)) as the area under this uncertainty curve. Precisely, \(_{cRNN}=_{0}^{T}\,\,(t)\,dt\) (Fig. 1b). Intuitively, high (low) \(_{cRNN}\) can be understood as the cRNN spending a large (small) amount of time in an uncertain regime. Our metric affords direct comparisons to human RTs. In the following sections, we apply this metric to cRNNs trained on a host of visual cognitive tasks and study their alignment to human reaction time data.

## 4 Incremental Grouping

### Task, Stimuli, and Visualizations

Inspired by an incremental perceptual grouping task in humans , we propose an equivalent challenge for the cRNN where the model is required to determine whether two dots are on the same object (Fig. 2a). The stimuli consist of white outlines of natural shapes on a black background (\(150 150\) px). We created \(340K\) (\(15K\)) training (validation) outline stimuli from MS COCO images . The dots were placed semi-randomly such that there was no difference in the distribution of dot distances between the two stimulus classes.

We additionally introduce two novel types of visualizations to probe cRNN visual strategies. First, we track cRNN dynamics by looking at its latent activity \(}\) at every time step \(t\), averaged across the channel dimension and smoothed by averaging \(}\) and \(}\). To facilitate interpretation, we provide these videos for the reader (see SI SSD). Second, we compute a "spatial uncertainty" (SU) map for each outline stimulus by keeping one dot fixed and varying the position of the other. Each spatial coordinate has a value equal to \(_{cRNN}\) for that corresponding dot configuration. Examples are shown in Fig. 2c (right) and Fig. 3.

### Results

Despite its lightweight architecture, our cRNN solved the incremental grouping task, achieving \(98\%\) validation accuracy. Visualizing the cRNN latent activities revealed that the model learned a cognitively-viable filling-in strategy. Network activity originated at each of the dot locations and gradually spread, eventually filling up the whole object(s) (Fig. 2b). We note that this behavior is an emergent property from purely the classification task constraint instead of direct supervision for any form of segmentation. We then sought to ask if \(_{cRNN}\) effectively captures these visual decision-making dynamics. In the following sections, we report results detailing the relationship between \(_{cRNN}\) and a host of complex, topological stimulus properties.

\(}\) captures the serial spread of attention in our models.Human visual strategies in solving the incremental grouping task are thought to involve a serial spread of attentional resources, resulting in longer RTs for higher distances . To test this effect in our model, we took a subset of our validation outlines and repositioned the dots to be in the center of an object, \(14\) px apart. We then systematically kept moving the dots \(14\) px more apart until reaching the object boundary. A linear mixed-effects regression analysis revealed a significant positive effect of this manipulation on \(_{cRNN}\), \(b=1.46,SE=0.11,z=13.58,p<.001\) (Fig. S3, Fig. S4). The SU maps (Fig. 2c right, Fig. 3) exhibit this distance effect too. Placing the second dot further away from the fixed dot (indicated in white) yielded higher \(_{cRNN}\) values.

\(}\) recapitulates the spatial anisotropy in human RT data.Euclidean distance only paints a partial picture. Human RTs are affected by several other factors, such as topological distance, the proximity of the dots to boundaries, and the need to spread through narrow object regions, all amounting to a well-documented spatial anisotropy in the spread of visual attention [47; 52]. While anisotropy is evident in the SU maps from our cRNN (Fig. 2c right, Fig. 3), we also formally assess the alignment between humans and the cRNN in this regard, using human RT data from .

Figure 3: \(}\) **is spatially anisotropic.** We present spatial uncertainty (SU) maps to visualize the impact a given fixed dot position will have on model RTs when the position of the second dot is varied. Higher (lower) values of \(_{cRNN}\) represent slower (faster) model responses.

First, Jeurissen et al.  quantified their stimuli on an alternative dot distance measure that went beyond Euclidean distance to reflect the other aforementioned factors and was more predictive of human RT (see SI SSF). We found this measure to be a better predictor of \(_{cRNN}\) (\(r=.80\)) as well (versus \(r=.45\) for Euclidean distance), \(t(63)=4.68,p<.001\). Second, the stimulus set featured distinct experimental conditions, varying in expected difficulty based on the position of the dots (Fig. 2c left). As shown in Fig. 2c (middle), the effects of this manipulation on \(_{cRNN}\) were qualitatively aligned with those on human RT. A one-way repeated measures ANOVA across 22 outline stimuli revealed a significant effect of "Condition" on \(_{cRNN}\), \(F(3,63)=67.65,p<.001\), as well as on the average RTs from , \(F(3,63)=16.95,p<.001\). Furthermore, Fig. 2c (middle) presents the results of planned contrasts (paired t-tests). \(_{cRNN}\) was significantly higher for B compared to A, \(Cohen^{}s\ d=2.00,t(21)=9.39,p<.001\), but also for the more difficult Condition C compared to B, \(d=0.73,t(21)=3.42,p=.003\). Third, we observed a significant overall correlation between human RT and \(_{cRNN}\) on Yes-stimuli, \(r=.31,p=.01\). Fourth, on a novel test set of our own, paired t-tests showed that \(_{cRNN}\) was significantly higher when two dots on the same object were placed in narrow versus wide object regions, \(d=0.70,t(22)=3.34,p=.003\), and when the path was curved (i.e., longer topological distance) versus when it was not, \(d=0.98,t(22)=4.71,p<.001\) (see SI SSG, Fig. S5). Finally, SI SSG also describes an experiment in which we varied the distance between one dot and the object boundary while keeping the distance between the dots themselves constant. We found that our model exhibits higher values near the boundaries, which is strikingly similar to human behavioral results presented in .

Ambiguous stimuli.As a final way of gaining insight into the cRNN's task behavior, we looked at those stimuli in the validation set that elicited the highest \(_{cRNN}\) values. We observed that some were characterized by uncertainty curves that remain high, even at \(t=T\), suggesting the model deems them ambiguous. In a test set we designed to be ambiguous (it features occlusions), we frequently observed such non-decreasing uncertainty curves too (see SI SSH). We note that while our training procedure promotes stable attractor states in the model's _latent_ dynamics, this is disparate from readout dynamics allowing the framework to truly explore the spectrum of computation times and uncertainties.

Taken together, these results suggest that our metric is able to capture the dynamical signatures of object-based attention in our cRNNs and provides a means to quantify alignment with human visual strategies.

## 5 Visual Simulation - _Planko_

### Task and Stimuli

The Planko task (and corresponding dataset) was introduced in  and features stimuli (\(64 64\) px; \(80K\) training, \(5K\) validation) displaying a ball about to fall down and eventually land in one of two baskets ("left"/"right"). The outcome depends on the position and orientation of a set of planks placed in between the ball and the baskets (Fig. 4a). Humans are thought to solve this task through mental

Figure 4: \(}\)**from our model recapitulates human RTs on the Planko task.****a.** The stimuli consist of a ball on top, followed by ten randomly placed planks and finally two baskets in the bottom. Participants are shown these static stimuli and are asked to guess if the ball will end up in the left or the right basket when released and allowed to bounce around on the planks. **b.** Human RTs (collected in ) are predicted by \(_{cRNN}\). The five colored symbols reflect the data points obtained from the stimuli shown in the next panel. **c.** Five example stimuli of increasing \(_{cRNN}\).

visual simulation . Notably, feedforward CNNs struggle to solve the task  and when they do, they appear to adopt non-aligned strategies to humans . In contrast, cRNNs show evidence of simulation-like behavior on a variant of the task . With our metric, we are now able to directly compare human (collected by ) and cRNN RTs. To this end, we trained a cRNN from scratch on Planko (see Section 3.2 and SI SSA for details on training).

### Results

The stimuli displayed in Fig. 4 illustrate the challenge of the Planko task. Our cRNN achieves a performance of \(84\%\) on the validation set, well within the confidence interval of human accuracy . Stimuli presented to human participants in the original study (\(N=200\)) were used here as a held-out set. We observed a significant correlation between model \(_{cRNN}\) values and human RTs, \(r=.31,p<.001\)) (Fig. 4b). This result indicates that stimuli that were harder for humans tended to be computationally challenging for the cRNN (see examples in Fig. 4c).

_What makes a stimulus challenging?_ Variance in human RTs is known to be partially explained by the statistics of the planks. For instance, stimuli for which the outcome is more likely to change as a consequence of perturbing the plank configurations by a small amount were deemed "uncertain". Indeed, participants responded slower to these stimuli . We were able to replicate this result in our cRNN, \(r=.31,p<.001\). These results showcase how our methodology can be used to make stimulus-dependent RT predictions. This could help shed light on, for example, the remarkable yet under-examined ability of humans to flexibly adopt different strategies in a Planko task depending on the stimulus demand.

## 6 Mazes

### Task and Stimuli

We devised a maze task where the goal is to tell whether two cued locations are connected by a path (Fig. 5a). To build our training (\(N=34.5K\)) and validation (\(N=14K\)) set, we started from mazes provided by  but modified them to make them suitable for classification (the originals did not feature any disconnected paths). The cues were placed such that the two classes ("yes"/"no") did not differ in Euclidean cue distance. Each maze was \(144 144\) px.

### Results

Here too, we observed that the uncertainty curves and derived \(_{cRNN}\) values differed considerably depending on the input, even if nearly all mazes were classified correctly at \(t=T\) (\(99\%\) correct

Figure 5: **cRNN learns filling-in strategy to solve mazes.****a.** Task description. **b.** The cRNN model takes more time to solve mazes with longer path lengths, an effect previously found in human participants too. **c.** Latent activity visualizations for two yes-mazes. The cRNN gradually fills the segment containing the cues. The strategy can be appreciated even better in the videos supplied in the SI. **d.** Uncertainty curves for the two inputs shown in Panel c. The cRNN remains uncertain for much longer for the maze featuring the longest path. The uncertainty evolution is visualized dynamically in conjunction with the change in latent activity in the supplementary videos.

on validation mazes). For the Yes-mazes contained in a random subset of the validation set, we found that the model spent more time being uncertain (higher \(_{cRNN}\)) when the length of the path between the two cued locations was longer, \(r=.84,p<.001\) (Fig. 5b,d). Moreover, path length was a significantly better predictor than simple Euclidean distance (\(r=.39\)), \(t(234)=5.81,p<.001\). Similarly, human RTs on maze tasks have been shown to increase with path length . When the cued locations were on two distinct maze segments (No-mazes), \(_{cRNN}\) was significantly predicted by the mean of both segment lengths, \(r=.56,p<.001\). The kind of visual strategy that produced such distance effects can be understood by inspecting the visualizations of the latent activities (Fig. 5c). The model gradually spread activity along the maze segment(s) containing the cues. We strongly encourage the reader to watch our videos (see SI SI) to better appreciate this spread in conjunction with the evolution of uncertainty over time. Finally, we did not find evidence for an effect on \(_{cRNN}\) of the number of T-junctions on the path, which are known to predict human RT . We speculate that this potential misalignment, worth investigating in future work, could be due to the model not being restricted in how many possible paths it can explore at once.

## 7 Scene Categorization

### Task and Stimuli

To showcase how our general approach can also be applied to study higher-level visual tasks, we consider a natural versus manmade scene categorization task as our final challenge (Fig. 6). Human RT data from a rapid-scene categorization version of this task were already available from . We selected images from the SUN database  querying the same classes as in , but excluding the images shown to human participants, and performed a stratified train (\(N=8.8K\)) and validation (\(N=979\)) split. The image preprocessing pipeline entailed cropping the image to be square, resizing to \(150 150\) px, converting to grayscale, and random horizontal flipping. In addition, the images were matched for overall brightness.

### Results

The model was able to correctly classify \(83\%\) of the validation images and \(73\%\) of the held-out test images from . The errors can be understood, at least partly, in light of the less-than-clear-cut labels (e.g., an islet with a house on top, a building behind many trees). Each of the test images had previously been assigned a discriminability score , based on the average error rate of logistic classifiers trained on "gist" features . Human participants were reported to be slower with decreasing discriminability . Here, we show a similar trend in the model (Fig. 6b), with a linear regression analysis revealing a significant, negative discriminability slope, \(b=-0.47,SE=0.03,t=-16.45,p<.001\). Directly comparing \(_{cRNN}\) to human RT, we found them to be significantly correlated, \(r=.19,p<.001\). While our cRNN model of choice here does not perfectly account for empirical patterns in human reaction times, specifically in their non-monotonic reaction time readouts for the low-discriminability stimuli, they provide a promising

Figure 6: \(}\) **is predictive of the discriminability of a visual scene.****a.** Task description. **b.** Human RTs (collected in ) decrease as a function of discriminability, as do \(_{cRNN}\). Highly discriminable scenes are easier for both human participants and the cRNN model. Error bars represent the standard error of the mean.

start. Our framework is model-agnostic (e.g., see SI SSJ for results on a convLSTM) and thus can be used to test hypotheses on architectural improvements.

## 8 Discussion

We are in the midst of a paradigm shift in visual neuroscience. The continued development of computational models that rival human behavioral performance has called for tools to quantify how well the internal mechanisms of such models compare to biological truths. These efforts have demonstrably been beneficial for both the AI and neuroscience ecosystems.

In this work, we push this frontier by introducing a framework to characterize the evidence accumulation strategies of stable recurrent vision models. Our experiments thus far show the potential to generate novel hypotheses of interest to visual neuroscientists. The most direct application of our framework for experimental design is in taxonomizing stimuli in terms of the putative computational demand based on our metric toward understanding neural processes at varying timescales. Furthermore, the value proposition of this framework includes the ability to adjudicate between models based on the consistency of their latent dynamics with human reaction time data. For example, our metric from a cRNN trained on the maze task is uncorrelated with the number of T-junctions in the stimulus, indicating a potential divergence between serial and parallel exploration strategies (SI SSI). It is worth noting that distinguishing between serial and parallel attention models has been of long-standing interest . Similarly, testing a zoo of hierarchical models on the scene categorization task while keeping an eye on the degree of alignment with our metric can potentially lend novel mechanistic insights and help delineate bottom-up, lateral, and top-down processes . We are also enthusiastic about drawing theoretical parallels between our metric summarizing the cRNN's evidence accumulation strategy and the complexity of natural data statistics toward understanding the sample efficiency of learning in models and primates.

Limitations and an outlook for the future.Within the scope of this work, we have considered four disparate visual cognition tasks to showcase how our approach offers the means to study the temporal alignment between recurrent vision models and the human visual system. Of course, in the face of the myriad of tasks that cognitive scientists have used over centuries, our selection still needs to be improved. Our results do not directly speak to the diversity in response types, stimulus types, or naturalism, to name a few. However, our approach is general-purpose enough to adapt to newer tasks as long as they are cast as a classification problem. We believe this should cover a significant share of cognitive science and AI tasks. Extending the approach beyond choice tasks would require a considerable revision of how to make the model's uncertainty explicit. Another limitation is that there could easily be other cRNNs that align with human RTs better. While we motivate the choice for the cRNN in Section 3.1, our main contribution here is to introduce the overall framework integrating stable recurrent vision models with evidential learning theory to support the derivation of a novel RT metric. A comprehensive comparison of different models, apart from those in SI SSB, was hence beyond this work's scope. However, we are confident our framework paves the way to build a taxonomy of models in the future as well as generate testable hypotheses for neuroscience.

Broader impacts.With AI vision models becoming ubiquitous in our daily lives, the call to make them fairer, transparent, and robust is growing louder. Our framework facilitates this by allowing researchers to peek into the inner working of these AI models for transparency and thinking about their match to biological systems, which are arguably more robust. From a neuroscience perspective, computational models of RT are gaining prominence in computational psychiatry and hold the key to understanding many neurobiological disorders . We generally do not anticipate any negative impact on society in either scenario.