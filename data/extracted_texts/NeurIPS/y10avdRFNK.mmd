# Learning diffusion at lightspeed

Antonio Terpin

ETH Zurich

aterpin@ethz.ch &Nicolas Lanzetti

ETH Zurich

lnicolas@ethz.ch &Martin Gadea

ETH Zurich

mgadea@ethz.ch &Florian Dorfler

ETH Zurich

dorfler@ethz.ch

###### Abstract

Diffusion regulates numerous natural processes and the dynamics of many successful generative models. Existing models to learn the diffusion terms from observational data rely on complex bilevel optimization problems and model only the drift of the system. We propose a new simple model, \(^{*}\), which bypasses the complexity of existing architectures while presenting significantly enhanced representational capabilities: \(^{*}\) recovers the potential, interaction, and internal energy components of the underlying diffusion process. \(^{*}\) minimizes a simple quadratic loss and outperforms other baselines in terms of sample efficiency, computational complexity, and accuracy. Additionally, \(^{*}\) provides a closed-form optimal solution for linearly parametrized functionals, and, when applied to predict the evolution of cellular processes from real-world data, it achieves state-of-the-art accuracy at a fraction of the computational cost of all existing methods. Our methodology is based on the interpretation of diffusion processes as energy-minimizing trajectories in the probability space via the so-called JKO scheme, which we study via its first-order optimality conditions.

Source code: https://github.com/antonioterpin/jkonet-star

## 1 Introduction

Diffusion processes govern the homeostasis of biological systems , stem cells reprogramming , and the learning dynamics of diffusion models  and transformers . The diffusion process of interest often originates from three quantities: a drift term due to a potential field, the interaction with other particles, and a stochastic term. If these three components are known, predictions follow from simple forward sampling  or the recent work in optimization in the probability space . In this paper, we consider the case when the diffusion process is unknown, and we seek to learn its representation from observational data. The problem has been addressed when the trajectories of the individual particles are known , but it is often the case that we only have "population data". For instance, single-cell RNA sequencing techniques enabled the collection of large quantities of data on biological systems , but the observer cannot access the trajectories of individual cells since measurements are destructive . The most promising avenue to circumvent the lack of particle trajectories is the Jordan-Kinderlehrer-Otto (JKO) scheme  which predicates that the particles as a whole move to decrease an aggregate energy, while not deviating too much from the current configuration. However, the JKO scheme entails an optimization problem in the probability space. Thus, the problem of finding the energy functional that minimizes a prediction error (w.r.t. observational data) takes the form of a computationally-challenging infinite-dimensional bilevel optimization problem, whereby the upper-level problem is the minimization of the prediction error and the lower-level problem is the JKO scheme. Recent work  exploits the theory of optimal transport and in particular Brenier's theorem  to attack this bilevel optimization problem, a model henceforth referred to as \(\). Despite promising initial results in , this complexity undermines scalability, stability, and generality of the model.

Furthermore, to be practical, it is limited to learning only potential energies, modelling the underlying physics only partially. Alternatively, [10; 43] learn directly the transport map describing the evolution of the population (i.e., the effects), bypassing the representation of the underlying energy functional (i.e., the causes). Motivated by robustness, interpretability, and generalization, here we seek a method to learn the causes. In [23; 42], the authors try to learn a geometry that explains the observed transport maps. Unfortunately, the cost between two configurations along a cost-minimizing trajectory is often not a metric . Other attempts include recurrent neural networks , neural ODEs , and Schrodinger bridges [12; 28].

Contributions.We study the first-order necessary optimality conditions for the JKO scheme, an optimization problem in the probability space, and show that these conditions can be exploited to learn the energy functional governing the underlying diffusion process from population data, effectively bypassing the complexity of the infinite-dimensional bilevel optimization problem. We provide a closed-form solution in the case of linearly parametrized energy functionals and a simple, interpretable, and efficient algorithm for non-linear parametrizations. Via exhaustive numerical experiments, we show that, in the case of potential energies only, JK0net* outperforms the state-of-the-art in terms of solution quality, scalability, and computational efficiency and, in the until now unsolved case of general energy functionals, allows us to also learn interaction and internal energies that explain the observed population trajectories. When applied to predict the evolution of cellular processes, it achieves state-of-the-art accuracy at a fraction of the computational cost. Figure 1 shows an overview of our method, detailed in Section 3.

## 2 Diffusion processes via optimal transport

### Preliminaries

The gradient of \(:^{d}\) is \(^{d}\) and the Jacobian of \(:^{d}^{n}\) is \(^{n d}\). We say that \(f:^{d}\) has bounded Hessian if \(\|^{2}f(x)\| C\) for some \(C>0\) (and some matrix

Figure 1: Given a sequence of snapshots \((_{0},,_{T})\) of a population of particles undergoing diffusion, we want to find the parameters \(\) of the parametrized energy function \(J_{}\) that best _explains_ the particles evolution. Given \(\), the effects mismatch is the Wasserstein distance between the observed trajectory and the predicted trajectory obtained iteratively solving the \(}\) with \(J_{}\). The first-order optimality condition in  applied to the JKO step suggests that the “gradient” of \(J_{}\) with respect to each \(_{t}\) vanishes at optimality, i.e., for \(J_{}()=_{^{d}}V_{}(x)(x)\), this condition is depicted on the right. The gradient (dashed blue arrows) of the true \(V\) (level curves in dashed blue) at each observed particle \(x_{i}^{t+1}\) (blue circles) in the next snapshot \(_{t+1}\) opposes the displacement (dotted red arrows) from a particle \(x_{i}^{t}\) (red triangles) in the previous snapshot \(_{t}\). Instead, the gradient (solid green arrows) of the estimated \(V_{}\) (level curves in solid green) at each observed particle \(x_{i}^{t+1}\) (square) does not oppose the displacement from a particle \(x_{i}^{t}\) in the previous snapshot \(_{t}\). This mismatch in the causes of the diffusion process is what JK0net* minimizes.

norm \(\|\|\)). The divergence of \(F:^{d}^{n}\) is \(F\) and its laplacian is \(^{2}F\). The identity function is \(:^{d}^{d}\), \((x)=x\). We denote by \((^{d})\) the space of (Borel) probability measures over \(^{d}\) with finite second moment. For \((^{d})\), \(()\) is its support. The Dirac's delta measure at \(x^{d}\), is \(_{x}\). All the functions are assumed to be Borel, and for \(f:^{d}\), \(_{^{d}}f(x)(x)\) is the (Lebesgue) integral of \(f\) w.r.t. \(\). If \(\) is absolutely continuous w.r.t. the Lebesgue measure, \(x\), then it admits a density \(:^{d}_{ 0}\), and the integral becomes \(_{^{d}}f(x)(x)x\). The pushforward of \(\) via a (Borel) map \(f:^{d}^{d}\) is the probability measure \(f_{\#}\) defined by \((f_{\#})(B)=(f^{-1}(B))\); when \(\) is empirical with \(N\), \(=_{i=1}^{N}_{x_{i}}\), then \(f_{\#}=_{i=1}^{N}_{f(x_{i})}\). Given \(,(^{d})\), we say that a probability measure \((^{d}^{d})\) is a transport plan for coupling) between \(\) and \(\) if its marginals are \(\) and \(\). We denote the set of transport plans between \(\) and \(\) by \((,)\). The Wasserstein distance between \(\) and \(\) is

\[W_{2}(,)(_{(,)}_{^ {d}^{d}}\|x-y\|^{2}(x,y))^{}.\] (1)

When \(\) and \(\) are discrete, (1) is a linear program. If, additionally, they have the same number of particles, the optimal transport plan is \(=(,T)_{\#}\) for some (transport) map \(T:^{d}^{d}\). When \(\) is absolutely continuous, \(=(,)_{\#}\) for some convex function \(\).

### The JKO scheme

Many continuous-time diffusion processes can be modeled by partial differential equations (PDEs) or stochastic differential equations (SDEs):

**Example 2.1** (Fokker-Planck).: _The Fokker-Planck equation,_

\[=(V( x)(t,x))+^{2}(t,x),\] (2)

_describes the time evolution of the distribution \(\) of a set of particles undergoing drift and diffusion,_

\[X(t)=-V(X(t))t+W(t),\]

_where \(X(t)\) is the state of the particle, \(V(x)\) the driving potential, and \(W(t)\) the Wiener process._

The pioneering work of Jordan, Kinderlehrer, and Otto , related diffusion processes to energy-minimizing trajectories in the Wasserstein space (i.e., probability space endowed with the Wasserstein distance), providing a discrete-time counterpart of the diffusion process, the JKO scheme,

\[_{t+1}=*{argmin}_{(^{d})}J()+ W_{2}(,_{t})^{2},\] (3)

where \(J:(^{d})\{+\}\) is an energy functional and \(>0\) is the time discretization.

**Example 2.2** (Fokker-Plank as a Wasserstein gradient flow).: _The Fokker-Plank equation (2) results from the continuous-time limit (i.e., \( 0\)) of the JKO scheme (3) for the energy functional_

\[J()=_{^{d}}V(x)(x)+_{^{d}} (x)((x))x(x)=(x) x.\]

### Challenges

Section 2.2 suggests that we can interpret the problem of learning diffusion processes as the problem of learning the energy functional \(J\) in (3). Specifically, the setting is as follows: We have access to sample populations \(_{0},_{1},,_{T}\), and we want to learn the energy functional governing their dynamics. A direct approach to tackle the inverse problem is a bilevel optimization, used, among others, for the model JKOnet in . This approach bases on the following two facts. First, by Brenier's theorem, the solution of (3), \(_{t+1}\), can be expressed1 as the pushforward of \(_{t}\) via the gradient of a convex function \(_{t}:^{d}\) and, thus,

\[W_{2}(_{t},_{t+1})^{2}=_{^{d}}\|x-_{t}(x) \|^{2}_{t}(x).\]Second, the optimization problem (3) is equivalently written as

\[*{argmin}_{_{t} C}J(_{t\#}_{t})+_{^{d}}\|x-_{t}(x)\|^{2}_{t}(x),\]

where \(C\) is the class of continuously differentiable convex functions from \(^{d}\) to \(\). Therefore, the learning task can be cast into the following bilevel optimization problem, which minimizes the discrepancy between the observations (\(_{t}\)) and the predictions of the model (\(_{t}\)):

\[&_{J}\,_{t=1}^{T}W_{2}(_{t},_{t})^ {2}\\ &\,\,_{0}=_{0},_{t+1}=_{t}^{*}_{t},\\ &_{t}^{*}*{argmin}_{ C}J( _{t\#}_{t})+_{^{d}}\|x- _{t}(x)\|^{2}_{t}(x).\] (4)

A practical implementation of the above requires a parametrization of both the transport map and the energy functional. The former problem has been tackled via input convex neural network (ICNN) parametrizing \(_{t}\)[2; 8] or via the "Monge gap" . The second problem is only addressed for energy functional of the form \(J()=_{}V_{}(x)(x)\), without interaction and internal energies, where \(V_{}\) is a non-linear function approximator .

Challenges.This approach suffers from two major limitations. First, bilevel optimization problems are notoriously hard and we should therefore expect (4) to be computationally challenging. Second, most energy functionals are not potential energies but include interactions and internal energy terms as well. Although it is tempting to include other terms in the energy functional \(J\) (e.g., parametrizing interaction and internal energies), the complexity of the bilevel optimization problem renders such an avenue viable only in principle.

## 3 Learning diffusion at lightspeed

Our methodology consists of replacing the optimization problem (3) with its first-order necessary conditions for optimality. This way, we bypass its computational complexity which, ultimately, leads to the bilevel optimization problem (4). Perhaps interestingly, our methodology for learning diffusion is based on first principles: whereas e.g.  minimizes an error on the _effects_ (the predictions), we minimize an error on the _causes_ (the energy functionals driving the diffusion process); see Figure 1. As we detail in Section 4, the resulting learning algorithms are significantly faster and more effective.

### Intuition

To start, we illustrate our idea in the Euclidean case (i.e., \(^{d}\)) and later generalize it to the probability space (i.e., \((^{d})\)). Consider the problem of learning the energy functional \(J:^{d}\{+\}\) of the analog of the JKO scheme in the Euclidean space, the proximal operator

\[x_{t+1}=*{argmin}_{x^{d}}J(x)+\|x-x _{t}\|^{2}.\] (5)

Under sufficient regularity, we can replace (5) by its first-order optimality condition

\[J(x_{t+1})+(x_{t+1}-x_{t})=0.\] (6)

Given a dataset \((x_{0},x_{1},,x_{T})\), we seek the energy functional that best fits the optimality condition:

\[_{J}_{t=0}^{T-1}\|J(x_{t+1})+(x_{t+1}-x_ {t})\|^{2}.\] (7)

In the probability space, we can proceed analogously and replace (3) with its first-order optimality conditions. This analysis, which is based on recent advancements in optimization in the probability space , allows us to formulate the learning task as a single-level optimization problem.

### Potential energy

Consider initially the case where the energy functional is a potential energy, for \(V:^{d}\),

\[J()=_{^{d}}V(x)(x).\] (8)

The following proposition is the counterpart of (6) in \((^{d})\):

**Proposition 3.1** (Potential energy).: _Assume \(V\) is continuously differentiable, lower bounded, and has a bounded Hessian. Then, the JKO scheme (3) has an optimal solution \(_{t+1}\) and, if \(_{t+1}\) is optimal for (3), then there is an optimal transport plan \(_{t}\) between \(_{t}\) and \(_{t+1}\) such that_

\[_{^{d}^{d}}\|V(x_{t+1})+ {}(x_{t+1}-x_{t})\|^{2}_{t}(x_{t},x_{t+1})=0.\]

Proposition 3.1 is by all means the analog of (6), since for the integral to be zero, \(V(x_{t+1})+(x_{t+1}-x_{t})=0\) must hold for all \((x_{t},x_{t+1})(_{t})\). Since the collected population data \(_{0},_{1},,_{T}\) are not optimization variables in the learning task, the optimal transport plan \(_{t}\) can be computed beforehand. Thus, we can learn the energy functional representation by minimizing over a class of continuously differentiable potential energy functions the loss function

\[_{t=0}^{T-1}_{^{d}^{d}}\|V(x_ {t+1})+(x_{t+1}-x_{t})\|^{2}_{t}(x_{t},x_ {t+1}).\] (9)

### Arbitrary energy functionals

Consider now the general case where the energy functional consists of a potential energy (with the potential function \(V:^{d}\)), interaction energy (with interaction kernel \(U:^{d}\)), and internal energy (expressed as the entropy weighted by \(_{ 0}\)):

\[J()=_{^{d}}V(x)(x)+_{^{d} ^{d}}U(x-y)()(x,y)+_{^{d}} (x)((x))x.\] (10)

The first-order necessary optimality condition for the JKO scheme then reads as follows.

**Proposition 3.2** (General case).: _Assume \(V\) and \(U\) are continuously differentiable, lower bounded, and have a bounded Hessian. Then, the JKO scheme (3) has an optimal solution \(_{t+1}\) which is absolutely continuous with density \(_{t+1}\) and, if \(_{t+1}(x)=_{t+1}(x)x\) is optimal for (3), then there is an optimal transport plan \(_{t}\) between \(_{t}\) and \(_{t+1}\) such that_

\[0=_{^{d}^{d}}\|V(x _{t+1})+_{^{d}}U(x_{t+1}-x_{t+1}^{}) _{t+1}(x_{t+1}^{}).\] \[.+_{t+1}(x_{t+1})}{_{t+1}(x_{ t+1})}+(x_{t+1}-x_{t})\|^{2}_{t}(x_{t},x_{t+1}).\]

Thus, Proposition 3.2 suggests that the energy functional can be learned by minimizing over a class of continuously differentiable potential and internal energy functions and \(_{ 0}\) the loss function

\[_{t=0}^{T-1}_{^{d}^{d}}\| V(x_{t+1})+_{^{d}}U(x_{t+1}-x_{t+1}^{ })_{t+1}(x_{t+1}^{}).\] (11) \[.+_{t+1}(x_{t+1})}{_{t+1}(x_{t+ 1})}+(x_{t+1}-x_{t})\|^{2}_{t}(x_{t},x_{t+ 1}).\]

_Remark 3.3_.: We generalize the setting to time-varying energies in Section 4.4 and in Appendix B.

### Parametrizations

For our model \(^{*}\), we parametrize the energy functional at a measure \(=(x)x\) as follows:

\[J_{}()=_{^{d}}V_{_{1}}(x)(x)+_{ ^{d}^{d}}U_{_{2}}(x-y)( )(x,y)+_{3}_{^{d}}(x)((x))x,\]

where \(_{1},_{2}^{n},_{3}\), and we set \(=[_{1}^{},_{2}^{},_{3}^{}]^{} ^{2n+1}\).

Linear parametrizations.When the parametrizations are linear, i.e. \(V_{_{1}}(x)=_{1}^{}(x)\), \(U_{_{2}}(x-y)=_{2}^{}(x-y)\) for feature maps \(_{1},_{2}:^{d}^{n}\), the optimal \(^{*}\) can be computed in closed-form:

**Proposition 3.4**.: _Assume that the features \(_{1,i}\) and \(_{2,i}\) are continuously differentiable, bounded, and have bounded Hessian. Define the matrix \(y_{t}:^{d}^{(2n+1) d}\) by_

\[y_{t}(x_{t})\!\![_{1}(x_{t})^{}\!,_{ ^{d}}_{2}(x_{t}\!-\!x_{t}^{})^{} _{t}(x_{t}^{}),_{_{t}}(x_{t})}{_{t}(x_{t})} ]^{}\]

_and suppose that the data is sufficiently exciting so that \(_{t=1}^{n}_{^{d}}y_{t}(x_{t})y_{t}(x_{t})^{} _{t}(x_{t})\) is invertible. Then, the optimal solution of (11) is_

\[^{*}=(_{t=1}^{T}_{^{d}}y_{t}(x_{t}) y_{t}(x_{t})^{}_{t}(x_{t}))^{-1}(_{t=0}^{T-1} _{^{d}^{d}}y_{t}(x_{t+1})(x_{t+1}-x_{t})_{t}(x_{t},x_{t+1})).\] (12)

_Remark 3.5_.: The excitation assumption can be enforced via regularization terms \(_{i}\|_{i}\|^{2}\), with \(_{i}>0\), in the loss (11). Another practical alternative is to use pseudoinverse or solve the least-squares problem corresponding to (12) by gradient descent.

Non-linear parametrizations.When the parametrizations are non-linear, we minimize (11) by gradient descent.

Inductive biases.By fixing any of the parameters \(_{1},_{2},_{3}\) to zero, the corresponding energy term is dropped from the model. It is thus possible to inject into \(^{*}\) the proper inductive bias when additional information on the underlying diffusion process are known. For instance, if the process is deterministic and driven by an external potential, one can set \(_{2}=_{3}=0\). Similarly, if it can be assumed that the interaction between the particles is negligible, we can set \(_{2}=0\).

### Why first-order conditions

Here, we motivate the theoretical benefits of \(^{*}\) over \(\) using the desiderata:

  &  &  &  \\   & & & \(V(x)\) & \(\) & \(U(x)\) \\  \(\) & \((T(DNd+(N)}{^{2}}))\) & \((T(DNd+(N)}{^{2}}))\) & ✓ & ✗ & ✗ \\ \(\) & \((T(DNd+(N)}{^{2}}))\) & \((DNd+(N)}{^{2}})\) & ✓ & ✗ & ✗ \\ \(\) & \((T(Nd+(N)}{^{2}}))\) & \((TD(Nd+(N)}{^{2}}))\) & ✓ & ✗ & ✗ \\ \(\) & \((TD(Nd+(N)}{^{2}}))\) & \((D(Nd+(N)}{^{2}}))\) & ✓ & ✗ & ✗ \\ \(\) & \((TNd)\) & \((d)\) & ✓ & ✓ & ✗ \\ \(^{*}\) & \((TN^{2}d)\) & \((Nd)\) & ✓ & ✓ & ✓ \\ \(^{*}\) & \((TNdn+n^{3})\) & \((TNdn+n^{3})\) & ✓ & ✓ & ✗ \\ \(^{*}\) & \((TN^{2}dn+n^{3})\) & \((TN^{2}dn+n^{3})\) & ✓ & ✓ & ✓ \\ \(\) & \((TN^{2}dn+n^{3})\) & \((TN^{2}dn+n^{3})\) & ✓ & ✓ & ✓ \\ 

Table 1: Per-epoch complexity (in FLOPs) and per-particle minimum number of sequential operations (maximum parallelization) for the \(\) and \(^{*}\) model families (we refer to the linear parametrization of our model with \(^{*}_{t}\)). Here, \(T\) is the length of the population trajectory, \(N\) the number of particles in the snapshots of the population (assumed constant), \(d\) is the dimensionality of the system, \(n\) is the number of features for the linear parametrization, \(D,,\) (TF) are \(\) parameters: the number of inner operations (which may or not be constant), the accuracy required for the Sinkhorn algorithm, and a training modality (see  for details), respectively. MG stands for the Monge gap regularization .

1. Total computational complexity per epoch (i.e., the cost to process the observed populations).
2. Per-particle computational complexity (i.e., the cost to process a single particle when maximally parallelizing the algorithm, prior to merging the results).
3. Representational capacity of the method (i.e., which energy terms the model can learn).

We collect this analysis in Table 1. Fundamentally, the first-order optimality conditions allow a reformulation of the learning problem that decouples prediction of the population evolution and learning of the dynamics (such coupling is the crux of (4)). As a result, \(^{*}\) enjoys higher parallelizability. We also observe that the interaction energy comes with an increase in complexity, and in a way resembles the attention mechanisms in transformers . The linear dependence of \(^{*}\) on the size of the batch implies that our method can process larger batch sizes for free (to process the entire dataset we need fewer steps in an inverse relationship with the batch size). In practice, this actually increases the speed (less memory swaps). These considerations do not hold for the \(\) family. Finally, \(^{*}\) enjoys enhanced representational power and interpretability. \(^{*}_{l}\) generally needs more computation per epoch (primarily related to the number of features) but requires a single epoch. In Table 1 we also report the computational complexity of the variants of \(\) using a vanilla multi-layer perceptron (MLP) with Monge gap regularization  instead of a ICNN as a parametrization of the transport map. Despite the success in simplifying the training of transport maps over the use of ICNN , the Monge gap requires the solution of an optimal transport problem at every inner iteration, an unbearable slowdown .

_Remark 3.6_.: Unlike \(\), \(^{*}\) requires the construction of the optimal transport couplings beforehand. However, \(\) constructs a new optimal transport plan at each iteration depending on the current estimate of the potential, whereas \(^{*}\) needs to do so only once, at the beginning. Moreover, as discussed in Section 4.1, in Section 4.2, in the application to single-cell diffusion dynamics in Section 4.4, and in the ablations in Appendix C.2, this additional cost is minimal.

## 4 Experiments

The code for the experiments is available at https://github.com/antonioterpin/jkonet-star. We include the training and architectural details for the \(^{*}\) models family in Appendix C. The settings of the baselines considered are the one provided by the corresponding papers, reported for completeness in Appendix E, and the hardware setup is described in Appendix C.7. In all the experiments, we allow the models a budget of \(1000\) epochs.

Our models.We use the following terminology for our method. \(^{*}\) is the most general non-linear parametrization in Section 3.4 and \(^{*}_{V}\) introduces the inductive bias \(_{2}=_{3}=0\). Similarly, we refer to the linear parametrizations by \(^{*}_{l,V}\) and \(^{*}_{l}\).

Metrics.To evaluate the prediction capabilities we use the one-step-ahead earth-mover distance (EMD), \(_{(_{t},_{t})}_{^{d}^{d}}\|x-y\|(x,y)\), where \(_{t}\) and \(_{t}\) are the observed and predicted populations. In particular, we consider the average and standard deviation over a trajectory.

### Training at lightspeed

Experimental setting.We validate the observations in Section 3.5 comparing (i) the EMD error, (ii) the convergence ratio, and (iii) the time per epoch required by the different methods on a synthetic dataset (see Appendix B) consisting of particles subject to a non-linear drift, \(x_{t+1}=x_{t}-V(x_{t})\), with \(=0.01,T=5\), and the potential functions \(V(x)\) (31)-(45) in Appendix F, shown in Figure 2 and in Figure 6 in Appendix A.

Figure 2: Level curves of the true (green-colored) and estimated (blue-colored) potentials (31), (33), (36) and (37), see Appendix F. See also Figure 6 in Appendix A.

Results.Figure 3 summarizes our results. All our methods perform uniformly better than the baselines, regardless of the generality. The speed improvement of the JK0net\({}^{*}\) models family suggests that a theoretically guided loss may provide strong computational benefits on par with sophisticated model architectures. Our linearly parametrized models, JK0net\({}_{i}^{*}\) and JK0net\({}_{i,V}^{*}\), require a computational time per epoch comparable to the JK0net family, but they only need one epoch to solve the problem optimally. Our non-linear models, JK0net\({}^{*}\) and JK0net\({}_{V}^{*}\), instead both require significantly lower time per epoch and converge faster than the JK0net family. In these experiments, the computational cost associated with the optimal transport plans beforehand amounts to as little as \(0.03 0.01\)s, and thus has negligible impact on training time. The true and estimated level curves of the potentials are depicted in Figure 2 and Figure 6 in Appendix A. Compared to JK0net, our model also requires a simpler architecture: we drop the additional ICNN used in the inner iteration and the related training details (e.g., the strong convexity regularizer and the teacher forcing). Notice that simply replacing the ICNN in JK0net with a vanilla MLP deprives the method of the theoretical connections with optimal transport, which, in our experiments, appears to be associated with stability (NaN in Figure 3).

The results suggest orders of magnitude of improvement also in terms of accuracy of the predictions. These performance gains can be observed also between the linear and non-linear parametrization of JK0net\({}^{*}\). In view of Proposition 3.4, this is not unexpected: the linear parametrization solves the problem optimally, when the features are representative enough. However, the feature selection presents a problem in itself; see e.g. [4, SS3 and SS4]. Thus, whenever applicable, we invite researchers and practitioners to adopt the linear parametrization, and the non-linear parametrization as demanded by the dimensionality of the problem. We further discuss the known failure modes in Appendix G.

### Scaling laws

Experimental setting.We assess the performance of JK0net\({}_{V}^{*}\) to recover the correct potential energy given \(N\{1000,2500,5000,7500,10000\}\) particles in dimension \(d\{10,20,30,40,50\}\), generated as in Section 4.1.

Figure 3: Numerical results of Section 4.1. The scatter plot displays points \((x_{i},y_{i})\) where \(x_{i}\) indexes the potentials in Appendix F and \(y_{i}\) are the errors (EMD, normalized so that the maximum error among all models and all potentials is \(1\)) obtained with the different models. We mark with NaN each method that has diverged during training. The plot on the bottom-left shows the EMD error trajectory during training (normalized such that \(0\) and \(1\) are the minimum and maximum EMD), averaged over all the experiments. The shaded area represents the standard deviation. The box plot analyses the time per epoch required by each method. The statistics are across all epochs and all potential energies.

Results.We summarize our findings in Figure 4 for the potentials (31)-(33) and in Figure 7 in Appendix A for all other the potentials. Since the EMD error is related to the Euclidean norm, it is expected to grow linearly with the dimension \(d\) (i.e., along the rows); here, the growth is sublinear up to the point where the number of particles is not informative enough: along the columns, the error decreases again. The time complexity of the computation of the optimal transport plans is influenced linearly by the dimensionality \(d\), and is negligible compared to the solution of the linear program, which depends only on the number of particles; we further discuss these effects in Appendix C.2. We thus conclude that \(^{*}\) is well suited for high-dimensional tasks.

### General energy functionals

Experimental setting.We showcase the capabilities of the \(^{*}\) models to recover the potential, interaction, and internal energies selected as combinations of the functions in Appendix F2 and noise levels \(\{0.0,0.1,0.2\}\). To our knowledge, this is the first model to recover all three energy terms.

**Results.** We summarize our findings on the right. Compared to the setting in Section 4.1, there are two additional sources of inaccuracies: (i) the noise, which introduces an inevitable sampling error, and the (ii) the estimation of the densities (see Appendix C for training details). Nonetheless, the low EMD errors demonstrate the capability of \(^{*}\) to recover the energy components that best explain the observed populations.

### Learning single-cell diffusion dynamics

Experimental setting.Understanding the time evolution of cellular processes subject to external stimuli is a fundamental open question in biology. Motivated by the intuition that cells differentiate minimizing some energy functional, we deploy \(^{*}\) to analyze the embryoid body single-cell

Figure 4: Numerical results of Section 4.2, reported in full in Figure 7 in Appendix A. The colors represent the EMD error, which appears to scale sublinearly with the dimension \(d\).

Figure 5: Visualizations of Section 4.4. The top row shows the two principal components of the scRNA-seq data, ground truth (green, days 1-3, 6-9, 12-15, 18-21, 24-27) and interpolated (blue, days 4-5, 10-11, 16-17, 22-23). The bottom row displays the estimated potential level curves over time. The bottom left plot superimposes the same three level curves for days 1-3 (solid), 12-15 (dashed), and 24-27 (dashed with larger spaces) to highlight the time-dependency.

RNA sequencing (scRNA-seq) data  describing the differentiation of human embryonic stem cells over a period of 27 days. We follow the data pre-processing in [50; 49]; in particular, we use the same processed artifacts of the embryoid data, which contains the first 100 components of the principal components analysis (PCA) of the data and, following , we focus on the first five. The cells are sequenced in five snapshots (days 1-3, 6-9, 12-15, 18-21, 24-27); we visualize the first two principal components in Figure 5. The visualization suggests that the energy governing the evolution is time-varying, possibly due to unobserved factors. For this, we condition the non-linear parametrization in Section 3 on time \(t\) and minimize the loss

\[_{t=0}^{T-1}_{^{d}^{d}}\|V(x _{t+1},t+1)+(x_{t+1}-x_{t})\|^{2}_{t}(x_{ t},x_{t+1}).\]

To predict the evolution of the particles, then, we use the implicit scheme (see Appendix B)

\[x_{t+1}=x_{t}-V(x_{t+1},t+1).\]

We train the time-varying extension of \(_{V}^{*}\), \(\) and \(\)-vanilla for \(100\) epochs on \(60\%\) of the data at each time and we compute the EMD between the observed \(_{t}\) (\(40\%\) remaining data) and one-step ahead prediction \(_{t}\) at each timestep. We then average over the trajectory and report the statistics for \(5\) seeds.

Results.We display the time evolution of the first two principal components of the level curves of the inferred potential energy in Figure 5, along with the cells trajectory (in green the data, in blue the interpolated predictions). As indicated by the table on the right, \(^{*}\) outperforms \(\). We also compare \(^{*}\) with recent work in the literature which focuses on the slightly different setting, namely the inference of \(_{t}\) from the evolution at all other time steps \(_{k}\), \(k t\), without train/test split of the data (the numerical values are taken directly from [12; 49] and our statistics are computed over the timesteps). Since the experimental setting slightly differs, we limit ourselves to observe that \(^{*}\) achieves state-of-the-art performance, but with significantly lower training time: \(^{*}\) trains in a few minutes, while the methods listed take hours to run. We further discuss these results in Appendix E.

## 5 Conclusion and limitations

Contributions.We introduced \(^{*}\), a model which recovers the energy functionals governing various classes of diffusion processes. The model is based on the novel study of the first-order optimality conditions of the JKO scheme, which drastically simplifies the learning task. In particular, we replace the complex bilevel optimization problem with a simple mean-square error, outperforming existing methods in terms of computational cost, solution accuracy, and expressiveness. In the prediction of cellular processes, \(^{*}\) achieves state-of-the-art performance and trains in less than a minute, compared to the hours of all existing methods.

Limitations.Our work did not address a few important challenges, which we believe to be exciting open questions. On the practical side, \(^{*}\) owns its performances to a loss function motivated by deep theoretical results. However, its architecture is still "vanilla" and we did not investigate data domains like images. Moreover, this work does not investigate in detail the choice of features for the linear parametrization, which in our experiments displays extremely promising results nonetheless. We further discuss the known failure modes in Appendix G.

Outlook.We expect the approach followed in this work to apply to other exciting avenues of applied machine learning research, such as population steering , reinforcement learning [37; 44; 48], diffusion models [16; 22; 54] and transformers [19; 52].