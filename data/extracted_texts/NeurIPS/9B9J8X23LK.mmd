# Accelerating Motion Planning via Optimal Transport

An T. Le\({}^{1}\), Georgia Chalvatzaki\({}^{1,3,5}\), Armin Biess, Jan Peters\({}^{1-4}\)

\({}^{1}\)Department of Computer Science, Technische Universitat Darmstadt, Germany

\({}^{2}\)German Research Center for AI (DFKI) \({}^{3}\)Hessian.AI \({}^{4}\)Centre for Cognitive Science

\({}^{5}\)Center for Mind, Brain and Behavior, Uni. Marburg and JLU Giessen, Germany

###### Abstract

Motion planning is still an open problem for many disciplines, e.g., robotics, autonomous driving, due to their need for high computational resources that hinder real-time, efficient decision-making. A class of methods striving to provide smooth solutions is gradient-based trajectory optimization. However, those methods usually suffer from bad local minima, while for many settings, they may be inapplicable due to the absence of easy-to-access gradients of the optimization objectives. In response to these issues, we introduce Motion Planning via Optimal Transport (MPOT)--a _gradient-free_ method that optimizes a batch of smooth trajectories over highly nonlinear costs, even for high-dimensional tasks, while imposing smoothness through a Gaussian Process dynamics prior via the planning-as-inference perspective. To facilitate batch trajectory optimization, we introduce an original zero-order and highly-parallelizable update rule--the Sinkhorn Step, which uses the regular polytope family for its search directions. Each regular polytope, centered on trajectory waypoints, serves as a local cost-probing neighborhood, acting as a _trust region_ where the Sinkhorn Step "transports" local waypoints toward low-cost regions. We theoretically show that Sinkhorn Step guides the optimizing parameters toward local minima regions of non-convex objective functions. We then show the efficiency of MPOT in a range of problems from low-dimensional point-mass navigation to high-dimensional whole-body robot motion planning, evincing its superiority compared to popular motion planners, paving the way for new applications of optimal transport in motion planning.

## 1 Introduction

Motion planning is a fundamental problem for various domains, spanning robotics , autonomous driving , space-satellite swarm , protein docking . etc., aiming to find feasible, smooth, and collision-free paths from start-to-goal configurations. Motion planning has been studied both as sampling-based search  and as an optimization problem . Both approaches have to deal with the complexity of high-dimensional configuration spaces, e.g., when considering high-degrees of freedom (DoF) robots, the multi-modality of objectives due to multiple constraints at both configuration and task space, and the requirement for smooth trajectories that low-level controllers can effectively execute. Sampling-based methods sample the high-dimensional manifold of configurations and use different search techniques to find a feasible and optimal path , but suffer from the complex sampling process and the need for large computational budgets to provide a solution, which increases w.r.t. the complexity of the problem (e.g., highly redundant robots and narrow passages) . Optimization-based approaches work on a trajectory level, optimizing initial trajectory samples either via covariant gradient descent  or through probabilistic inference . Nevertheless, as with every optimization pipeline, trajectory optimization depends on initialization and can get trapped in bad local minima due to the non-convexity of complex objectives. Moreover, in some problem settings, objective gradients are unavailable or expensive to compute. Indeed, trajectory optimization is difficult to tune and is often avoided in favor of sampling-based methods with probabilistic completeness. We refer to Appendix H for an extensive discussion of related works.

To address these issues of trajectory optimization, we propose a zero-order, fast, and highly parallelizable update rule--the Sinkhorn Step. We apply this novel update rule in trajectory optimization, resulting in _Motion Planning via Optimal Transport (MPOT)_ - a gradient-free trajectory optimization method optimizing a batch of smooth trajectories. MPOT optimizes trajectories by solving a sequence of entropic-regularized Optimal Transport (OT) problems, where each OT instance is solved efficiently with the celebrated Sinkhorn-Knopp algorithm . In particular, MPOT discretizes the trajectories into waypoints and structurally probes a local neighborhood around each of them, which effectively exhibits a _trust region_, where it "transports" local waypoints towards low-cost areas given the local cost approximated by the probing mechanism. Our method is simple and does not require computing gradients from cost functions propagating over long kinematics chains. Crucially, the planning-as-inference perspective [15; 13] allows us to impose constraints related to transition dynamics as planning costs, additionally imposing smoothness through a Gaussian Process (GP) prior. Delegating complex constraints to the planning objective allows us to locally resolve trajectory update as an OT problem at each iteration, updating the trajectory waypoints towards the local optima, thus effectively optimizing for complex cost functions formulated in configuration and task space. We also provide a preliminary theoretical analysis of the Sinkhorn Step, highlighting its core properties that allow optimizing trajectories toward local minima regions.

Further, our empirical evaluations on representative tasks with high-dimensionality and multimodal planning objectives demonstrate an increased benefit of MPOT, both in terms of planning time and success rate, compared to notable trajectory optimization methods. Moreover, we empirically demonstrate the convergence of MPOT in a 7-DoF robotic manipulation setting, showcasing a fast convergence of MPOT, reflected also in its dramatically reduced planning time w.r.t. baselines. The latter holds even for 36-dimensional, highly redundant mobile manipulation systems in long-horizon fetch and place tasks (cf. Fig. 4).

Our **contribution** is twofold. _(i)_ We propose the Sinkhorn Step - an efficient zero-order update rule for optimizing a batch of parameters, formulated as a barycentric projection of the current points to the polytope vertices. _(ii)_ We, then, apply the Sinkhorn Step to motion planning, resulting in a novel trajectory optimization method that optimizes a batch of trajectories by efficiently solving a sequence of linear programs. It treats every waypoint across trajectories equally, enabling fast batch updates of multiple trajectories-waypoints over multiple goals by solving a single OT instance while retaining smoothness due to integrating the GP prior as cost function.

## 2 Preliminaries

Entropic-regularized optimal transport.We briefly introduce discrete OT. For a thorough introduction, we refer to [16; 17; 18].

**Notation.** Throughout the paper, we consider the optimization on a \(d\)-dimensional Euclidean space \(^{d}\), representing the parameter space (e.g., a system state space). \(_{d}\) is the vector of ones in \(^{d}\). The scalar product for vectors and matrices is \(x,y^{d}\), \( x,y=_{i=1}^{d}x_{i}y_{i}\); and \(,^{d d}\), \(,=_{i,j=1}^{d}_{ij }_{ij}\), respectively. \(\) is the \(l_{2}\)-norm, and \(_{}\) denotes the Mahalanobis norm w.r.t. some positive definite matrix \( 0\). For two histograms \(_{n}\) and \(_{m}\) in the simplex \(_{d}:=\{^{d}_{+}:^{} _{d}=1\}\), we define the set \(U(,):=\{^{n m}_{+ }_{m}=,^{} _{n}=\}\) containing \(n m\) matrices with row

Figure 1: Example of MPOT in the multimodal planar navigation scenario with three different goals. For each goal, we sample five initial trajectories from a GP prior. We illustrate four snapshots of our proposed Sinkhorn Step that updates a batch of waypoints from multiple trajectories over multiple goals. For this example, the **total planning time was 0.12s**. More demos can be found on [https://sites.google.com/view/sinkhorn-step/](https://sites.google.com/view/sinkhorn-step/)

and column sums \(\) and \(\) respectively. Correspondingly, the entropy for \( U(,)\) is defined as \(H()=-_{i,j=1}^{n,m}a_{ij} a_{ij}\).

Let \(_{i}^{n m}\) be the positive cost matrix, the OT between \(\) and \(\) given cost \(\) is \((,):=_{ U(,)}, {C}.\) Traditionally, OT does not scale well with high dimensions. To address this, Cuturi  proposes to regularize its objective with an entropy term, resulting in the entropic-regularized OT

\[_{}(,):=_{ U(,)} ,- H(). \]

Solving (1) with Sinkhorn-Knopp  has a complexity of \((n^{2}/^{3})\), where \(\) is the approximation error w.r.t. the original OT. Higher \(\) enables a faster but "blurry" solution, and vice versa.

Trajectory optimization.Given a parameterized trajectory by a discrete set of support states and control inputs \(=[_{0},_{0},...,_{T-1},_{T-1},_{T}]^{}\), trajectory optimization aims to find the optimal trajectory \(^{*}\), which minimizes an objective function \(c()\), with \(_{0}\) being the start state. Standard motion planning costs, such as goal cost \(c_{g}\) defined as the distance to a desired goal-state \(_{g}\), obstacle avoidance cost \(c_{obs}\), and smoothness cost \(c_{sm}\) can be included in the objective. Hence, trajectory optimization can be expressed as the sum of those costs while obeying the dynamics constraint

\[^{*}= _{}[c_{obs}()+c_{g}(, _{g})+c_{sm}()]}=f(,)(0)=_{0}. \]

For many manipulation tasks with high-DoF robots, this optimization problem is typically highly non-linear due to many complex objectives and constraints. Besides \(c_{obs}\), \(c_{sm}\) is crucial for finding smooth trajectories for better tracking control. Covariant Hamiltonian Optimization for Motion Planning (CHOMP)  designs a finite difference matrix \(\) resulting to the smoothness cost \(c_{sm}=^{}\). This smoothness cost can be interpreted as a penalty on trajectory derivative magnitudes. Mukadam et al.  generalizes the smoothness cost by incorporating a GP prior as cost via the planning-as-inference perspective [15; 21], additionally constraining the trajectories to be dynamically smooth. Recently, an emergent paradigm of multimodal trajectory optimization [22; 23; 13; 24] is promising for discovering different modes for non-convex objectives, thereby exhibiting robustness against bad local minima. Our work contributes to this momentum by proposing an efficient batch update-rule for vectorizing waypoint updates across timesteps and number of plans.

## 3 Sinkhorn Step

To address the problem of batch trajectory optimization in a gradient-free setting, we propose _Sinkhorn Step_--a zero-order update rule for a batch of optimization variables. Our method draws inspiration from the free-support barycenter problem , where the mean support of a set of empirical measures is optimized w.r.t. the OT cost. Consider an optimization problem with some objective function without easy access to function derivatives. This barycenter problem can be utilized as a parameter update mechanism, i.e., by defining a set of discrete target points (i.e., local search directions) and a batch of optimizing points as two empirical measures, the barycenter of these empirical measures acts as the updated optimizing points based on the objective function evaluation at the target points.

With these considerations in mind, we introduce _Sinkhorn Step_, consisting of two components: a polytope structure defining the unbiased search-direction bases, and a weighting distribution for evaluating the search directions. Particularly, the weighting distribution has row-column unit constraints and must be efficient to compute. Following the motivation of , the entropic-regularized OT fits nicely into the second component, providing a solution for the weighting distribution as an OT plan, which is solved extremely fast, and its solution is unique . In this section, we formally define Sinkhorn Step and perform a preliminary theoretical analysis to shed light on its connection to _directional-direct search_ methods [26; 27], thereby motivating its algorithmic choices and practical implementation proposed in this paper.

### Problem formulation

We consider the batch optimization problem

\[_{X}f(X)=_{X}_{i=1}^{n}f(_{i}), \]

where \(X=\{_{i}\}_{i=1}^{n}\) is a set of \(n\) optimizing points, \(f:^{d}\) is non-convex, differentiable, bounded below, and has \(L\)-Lipschitz gradients.

**Assumption 1**.: _The objective \(f\) is \(L\)-smooth with \(L>0\)_

\[\| f()- f()\| L\|-\|, \;,^{d}\]

_and bounded below by \(f() f_{*},\;^{d}\)._

Throughout the paper, we assume that function evaluation is implemented batch-wise and is cheap to compute. Function derivatives are either expensive or impossible to compute. At the first iteration, we sample a set of initial points \(X_{0}_{0}\), with its matrix form \(_{0}^{n d}\), from some prior distribution \(_{0}\). The goal is to compute a batch update for the optimizing points, minimizing the objective function. This problem setting suits trajectory optimization described in Section 4.

### Sinkhorn Step formulation

Similar to directional-direct search, Sinkhorn Step typically evaluates the objective function over a search-direction-set \(D\), ensuring descent with a sufficiently small stepsize. The search-direction-set is typically a vector-set requiring to be a _positive spanning set_, i.e., its conic hull is \(^{d}=\{_{i}w_{i}_{i},\;_{i} D,\;w_{i} 0\}\), ensuring that every point (including the extrema) in \(^{d}\) is reachable by a sequence of positive steps from any initial point.

**Regular Polytope Search-Directions**. Consider a \((d-1)\)-unit hypersphere \(S^{d-1}=\{^{d}:\|\|=1\}\) with the center at zero.

**Definition 1** (Regular Polytope Search-Directions).: _Let us denote the regular polytope family \(=\{,\;,\;\}\). Consider a \(d\)-dimensional polytope \(P\) with \(m\) vertices, the search-direction set \(D^{P}=\{_{i}\;|\;\|_{i}\|=1\}_{i=1}^{m}\) is constructed from the vertex set of the regular polytope \(P\) inscribing \(S^{d-1}\)._

The \(d\)-dimensional regular polytope family \(\) has all of its dihedral angles equal and, hence, is an unbiased sparse approximation of the circumscribed \((d-1)\)-sphere, i.e., \(_{i}_{i}=0,\|_{i}\|=1\, i\). There also exist other regular polytope families. However, the regular polytope types in \(\) exist in every dimension (cf. ). Moreover, the algorithmic construction of general polytope is not trivial . Vertex enumeration for \(\) is straightforward for vectorization and simple to implement, which we found to work well in our settings-see also Appendix F. We state the connection between regular polytopes and the positive spanning set in the following proposition.

**Proposition 1**.: \( P,\;D^{P}\) _forms a positive spanning set._

This property ensures that any point \(^{d},\;=_{i}w_{i}_{i},\;w_{i} 0,\; _{i} D^{P}\) can be represented by a positively weighted sum of the set of directions defined by the polytopes.

**Batch Update Rule**. At an iteration \(k\), given the current optimizing points \(X_{k}\) and their matrix form \(_{k}^{n d}\), we first construct the direction set from a chosen polytope \(P\), and denote the direction set \(^{P}^{m d}\) in matrix form. Similar to , let us define the prior histograms reflecting the importance of optimizing points \(_{n}\) and the search directions \(_{m}\), then the constraint space \(U(,)\) of OT is defined. With these settings, we define Sinkhorn Step.

**Definition 2** (Sinkhorn Step).: _The batch update rule is the barycentric projection (Remark 4.11, ) that optimizes the free-support barycenter of the optimizing points and the batch polytope vertices_

\[_{k+1}&=_{k}+_{k},\; _{k}=_{k}()^{-1}_{}^{*}^{P}\\ _{}^{*}&=_{ U(,)}(,)- H(), \]

_with \(_{k}>0\) as the stepsize, \(^{n m},\;_{i,j}=f(_{i}+_{k}_ {j}),\;_{i} X_{k},_{j} D^{P}\) is the local objective matrix evaluated at the linear-translated polytope vertices._

Observe that the matrix \(()^{-1}_{}^{*}\) has \(n\) row vectors in the simplex \(_{m}\). The batch update _transports_\(\) to a barycenter shaping by the polytopes with weights defined by the optimal solution \(_{}^{*}\). However, in contrast with the barycenter problem , the target measure supports are constructed locally at each optimizing point, and, thus, the points are transported in accordance with their local search directions. By Proposition 1, \(D^{P}\) is a positive spanning set, thus, \(_{}^{*}\) forms a _generalized barycentric coordinate_, defined w.r.t. the finite set of polytope vertices. This property implies any point in \(^{d}\) can be reached by a sequence of Sinkhorn Steps. For the \(d\)-simplex case, any point inside the convex hull can be identified with a unique barycentric coordinate , which is not the case for \(d\)-orthoplex or \(d\)-cube. However, coordinate uniqueness is not required for our analysis in this paper, given the following assumption.

**Assumption 2**.: _At any iteration \(k>0\), the prior histogram on the optimizing points and the search-direction set is uniform \(==_{n}/n\), having the same dimension \(n=m\). Additionally, the entropic scaling approaches zero \( 0\)._

Assuming uniform prior importance of the optimizing points and their search directions is natural since, in many cases, priors for stepping are unavailable. However, our formulation also suggests a conditional Sinkhorn Step, which is interesting to study in future work. This assumption allows performing an analysis on Sinkhorn Step on the original OT solution.

With these assumptions, we can state the following theorem for each \(_{k} X_{k}\) separately, given that they follow the Sinkhorn Step rule.

**Theorem 1** (Main result).: _If Assumption 1 and Assumption 2 hold and the stepsize is sufficiently small \(_{k}=\) with \(0<<2_{P}/L\), then with a sufficient number of iterations_

\[K k():=_{0})-f_{*}}{(_{P}- )}-1, \]

_we have \(_{0 k K}\| f(_{k})\|,\,_{k}  X_{k}\)._

Note that we do not make any additional assumptions on \(f\) besides the smoothness and boundedness, and the analysis is performed on non-convex settings. Theorem 1 only guarantees that the gradients of some points in the sequence of Sinkhorn Steps are arbitrarily small, i.e., in the proximity of local minima. If in practice, we implement the sufficient decreasing condition \(f(_{k})-f(_{k+1}) c_{k}^{2}\), then \(f(_{K}) f(_{i}),\,\| f(_{i})\|\) holds. However, this sufficient decrease check may waste some iterations and worsen the performance. We show in the experiments that the algorithm empirically exhibits convergence behavior without this condition checking. If \(L\) is known, then we can compute the optimal stepsize \(=_{P}/L\), leading to the complexity bound \(k()=_{0})-f_{*})}{_{P}^{2}^{2}}-1\). Therefore, the complexity bounds for \(d\)-simplex, \(d\)-orthoplex and \(d\)-cube are \(O(d^{2}/^{2})\), \(O(d/^{2})\), and \(O(1/^{2})\), respectively. The \(d\)-cube case shows the same complexity bound \(O(1/^{2})\) as the well-known gradient descent complexity bound on the L-smooth function . These results are detailed in Appendix A. Generally, we perform a preliminary study on Sinkhorn Step with Assumption 1 and Assumption 2 to connect the well-known directional-direct search literature [26; 27], as many unexplored theoretical properties of Sinkhorn Step remain in practical settings described in Section 4.

## 4 Motion Planning via Optimal Transport

Here, we introduce MPOT - a method that applies _Sinkhorn Step_ to solve the batch trajectory optimization problem, where we realize waypoints in a set of trajectories as optimizing points. Due to Sinkhorn Step's properties, MPOT does not require gradients propagated from cost functions over long kinematics chains. It optimizes trajectories by solving a sequence of strictly convex linear programs with a maximum entropy objective (cf. Definition 2), smoothly transporting the waypoints according to the local polytope structure. To promote smoothness and dynamically feasible trajectories, we incorporate the GP prior as a cost via the planning-as-inference perspective.

### Planning As Inference With Empirical Waypoint Distribution

Let us consider general discrete-time dynamics \(=F(_{0},)\), where \(=[_{0},,_{T}]\) denotes the states sequence, \(=[_{0},...,_{T}]\) is the control sequence, and \(_{0}\) is the start state. The target distribution over control trajectories \(\) can be defined as the posterior 

\[q()=(- E())q_{0}(), \]

with \(E()\) the energy function representing control cost, \(q_{0}()=(,)\) a zero-mean normal prior, \(\) a scaling term (temperature), and \(Z\) the normalizing scalar.

Assuming a first-order trajectory optimization1, the control sequence can be defined as a time-derivative of the states \(=[}_{0},...,}_{T}]\). The _target posterior distribution_ over both state-trajectories and their derivatives \(=(,)=\{_{t}^{d}:_{t}=[ _{t},}_{t}]\}_{t=0}^{T}\) is defined as

\[q^{*}()=- c()q_{F}(), \]which is similar to Eq. (6) with the energy function \(E=c F(_{0},)\) being the composition of the cost \(c\) over \(\) and the dynamics \(F\). The dynamics \(F\) is also now integrated into the prior distribution \(q_{F}()\). The absorption of the dynamics into the prior becomes evident when we represent the prior as a zero-mean constant-velocity GP prior \(q_{F}()=(,)\), with a constant time-discretization \( t\) and the time-correlated trajectory covariance \(\), as described in Appendix B.

Now, to apply Sinkhorn Step, consider the trajectory we want to optimize \(=\{_{t}\}_{t=1}^{T}\), we can define the _proposal trajectory distribution_ as a waypoint empirical distribution

\[p(;)=_{t=1}^{T}p(t)p(|t)=_{t=1}^{T}n_{t}_{ _{t}}(), \]

with the histogram \(=[n_{1},,n_{T}]\), \(p(t)=n_{t}=1/T\), and \(_{_{t}}\) the Dirac on waypoints at time steps \(t\). In this case, we consider the model-free setting for the proposal distribution. Indeed, this form of proposal trajectory distribution typically assumes no temporal or spatial (i.e., kinematics) correlation between waypoints. This assumption is also seen in  and can be applied in a wide range of robotics applications where the system model is fully identified. We leverage this property for batch-wise computations and batch updates over all waypoints. The integration of model constraints in the proposal distribution is indeed interesting but is deferred for future work.

Following the planning-as-inference perspective, the motion planning problem can be formulated as the minimization of a Kullback-Leibler (KL) divergence between the proposal trajectory distribution \(p(;)\) and the target posterior distribution Eq. (7) (i.e., the I-projection)

\[^{*} =*{argmin}_{}\{(p( ;)\,||\,q^{*}())=_{p}[ q^{*}()]-H(p)\} \] \[=*{argmin}_{}_{p}[ c( {})+\|\|_{}^{2}- Z]\] \[=*{argmin}_{}_{t=0}^{T-1} {c(_{t})}_{}+\|_{ t,t+1}_{t}-_{t+1}\|_{_{t,t+1}^{2}}^{2}}_{},\]

with \(_{t,t+1}\) the state transition matrix, and \(_{t,t+1}\) the covariance between time steps \(t\) and \(t+1\) originated from the GP prior (cf. Appendix B), and the normalizing constant of the target posterior \(Z\) is absorbed. Note that the entropy of the empirical distribution is constant \(H(p)=-_{^{d}}_{t=1}^{T}_{_{ t}}() p(;)= T\). Evidently, KL objective Eq. (9) becomes a standard motion planning problem Eq. (2) with the defined waypoint empirical distributions. Note that this objective is not equivalent to Eq. (3) due to the second coupling term. However, we demonstrate in Section 5.2 that MPOT still exhibits convergence. Indeed, investigating Sinkhorn Step in a general graphical model objective  is vital for future work. We apply Sinkhorn Step to Eq. (9) by realizing the trajectory as a batch of optimizing points \(^{T d}\). This realization also extends naturally to a batch of trajectories described in the next section.

The main goal of this formulation is to naturally inject the GP dynamics prior to MPOT, benefiting from the GP sparse Markovian structure resulting in the second term of the objective Eq. (9). This problem formulation differs from the moment-projection objective , which relies on importance sampling from the proposal distribution to perform parameter updates. Contrarily, we do not encode the model in the proposal distribution and directly optimize for the trajectory parameters, enforcing the model constraints in the cost.

### Practical considerations for applying Sinkhorn Step

For the practical implementation, we make the following realizations to the Sinkhorn Step implementation for optimizing a trajectory \(\). First, we define a set of probe points for denser function evaluations (i.e., cost-to-go for each vertex direction). We populate equidistantly _probe_ points along the directions in \(D^{P}\) outwards till reaching a _probe radius_\(_{k}_{k}\), resulting in the _probe set_\(H^{P}\) with its matrix form \(^{P}^{m h d}\) with \(h\) probe points for each direction (cf. Fig. 2). Second, we add stochasticity in the search directions by applying a random \(d\)-dimensional rotation \( SO(d)\) to the polytopes to promote local exploration (computation of \( SO(d)\) is discussed in Appendix G). Third, to further decouple the correlations between the waypoints updates, we sample the rotation matrices in batch and then construct the direction sets from the rotated polytopes, resulting in the tensor \(^{P}^{T m d}\). Consequently, the _probe set_ is also constructed in batch for every waypoint \(^{P}^{T m h d}\). The Sinkhorn Step is computed with the _einsum_ operation along the second dimension (i.e., the \(m\)-dimension) of \(^{P}\) and \(^{P}\). In intuition, the second and third considerations facilitate random permutation of the rows of the OT cost matrix.

With these considerations, the element of the \(t^{}\)-waypoint and \(i^{}\)-search directions in the OT cost matrix \(^{T m}\) is the mean of probe point evaluation along a search direction (i.e., cost-to-go)

\[_{t,i}=_{j=1}^{h}\,c(_{t}+_{t,i,j})+ {1}{2}\|_{t,t+1}_{t}-(_{t+1}+_{t+1,i,j})\|_{_ {t,t+1}^{-1}}^{2}, \]

with the probe point \(_{t,i,j} H^{P}\). Then, we ensure the cost matrix positiveness for numerical stability by subtracting its minimum value. With uniform prior histograms \(=_{T}/T\), \(=_{m}/m\), the problem \(^{*}=*{argmin}_{}(,)\) is instantiated and solved with the log-domain stabilization version [35; 36] of the Sinkhorn algorithm. By setting a moderately small \(=0.01\) to balance between performance and blurring bias, the update does not always collapse towards the vertices of the polytope, but to a conservative one inside the polytope convex hull. In fact, the Sinkhorn Step defines an _explicit trust region_, which bounds the update inside the polytope convex hull. More discussions of log-domain stabilization and trust region properties are in Appendix E and Appendix D. In the trajectory optimization experiments, we typically do not assume any cost structure (e.g., non-smooth, non-convex). In MPOT, Assumption 2 is usually violated with \(T m\), but MPOT still works well due to the soft assignment of Sinkhorn distances. We observe that finer function evaluations, randomly rotated polytopes, and moderately small \(\) increase the algorithm's robustness against practical conditions. Note that these implementation technicalities do not incur much overhead due to the efficient batch computation of modern GPU.

### Batch trajectory optimization

We leverage our Sinkhorn Step to optimize multiple trajectories in parallel, efficiently providing many feasible solutions for multi-modal planning problems. Specifically, we implement MPOT using PyTorch  for vectorization across different motion plans, randomly rotated polytope constructions, and _probe set_ cost evaluations. For a problem instance, we consider \(N_{p}\) trajectories of horizon \(T\), and thus, the trajectory set \(=\{_{1},,_{N_{p}}\}\) is the parameter to be optimized. We can flatten the trajectories into the set of \(N=N_{p} T\) waypoints. Now, the tensors of search directions and _probe set_\(^{P}^{N m d}\), \(^{P}^{N m h d}\) can be efficiently constructed and evaluated by the state cost function \(c()\), provided that the cost function is implemented with batch-wise processing (e.g., neural network models in PyTorch). Similarly, the model cost term in Eq. (9) can also be evaluated in batch by vectorizing the computation of the second term in Eq. (10).

At each iteration, it is optional to anneal the stepsize \(_{k}\) and _probe radius_\(_{k}\). Often we do not know the Lipschitz constant \(L\) in practice, so the optimal stepsize cannot be computed. Hence, the Sinkhorn Step might oscillate around some local minima. It is an approximation artifact that can be mitigated by reducing the radius of the ball-search over time, gradually changing from an exploratory to an exploitative behavior. Annealing the ball search radius while keeping the number of probe points increases the chance of approximating better ill-conditioned cost structure, e.g., large condition number locally.

To initialize the trajectories, we randomly sample from the discretized GP prior \(^{0}(_{0},_{0})\), where \(_{0}\) is a constant-velocity, straight-line trajectory from start-to-goal state, and \(_{0}^{(T d)(T d)}\) is a large GP covariance matrix for exploratory initialization [38; 39] (cf. Appendix B). In execution, we select the lowest cost trajectory \(^{*}^{*}\). For collecting a trajectory dataset, all collision-free trajectories \(^{*}\) are stored along with contextual data, such as occupancy map, goal state,

Figure 2: Graphical illustration of Sinkhorn Step with practical considerations. In this point-mass example, we zoom-in one part of the discretized trajectory. The search-direction sets are constructed from randomly rotated \(2\)-cube vertices at each iteration, depicted by the gray arrows and the green points. The gray numbers are the averaged costs over the red probe points in each vertex direction. Note that for clarity, we only visualize an occupancy obstacle cost. The red arrows describe the updates that transport the waypoints gradually out of the obstacles, depending on the (solid inner) polytope circumcircle \(_{k}\) and (dotted outer) probe circle \(_{k}\).

etc. See Algorithm 1 for an overview of MPOT. Further discussions on batch trajectory optimization are in Appendix C.

## 5 Experiments

We experimentally evaluate MPOT in PyBullet simulated tasks, which involve high-dimensional state space, multiple objectives, and challenging costs. First, we benchmark our method against strong motion planning baselines in a densely cluttered 2D-point-mass and a 7-DoF robot arm (Panda) environment. Subsequently, we study the convergence of MPOT empirically. Finally, we demonstrate the efficacy of our method on high-dimensional mobile manipulation tasks with TIAGo++. Additional ablation studies on the design choices of MPOT, and gradient approximation capability on a smooth function of Sinkhorn Step w.r.t. different hyperparameter settings are in the Appendix J.

### Experimental setup

In all experiments, all planners optimize first-order trajectories with positions and velocities in configuration space. The batch trajectory optimization dimension is \(N T d\), where \(d\) is the full-state concatenating position and velocity.

For the _point-mass_ environment, we populate \(15\) square and circle obstacles randomly and uniformly inside x-y limits of \([-10,10]\), with each obstacle having a radius or width of \(2\) (cf. Fig. 1). We generate \(100\) environment-seeds, and for each environment-seed, we randomly sample \(10\) collision-free pairs of start and goal states, resulting in \(1000\) planning tasks. We plan each task in parallel \(100\) trajectories of horizon \(64\). A trajectory is considered successful if it is collision-free.

For the _Panda_ environment, we also generate \(100\) environment-seeds. Each environment-seed contains randomly sampled \(15\) obstacle-spheres having a radius of \(10\)cm inside the x-y-z limits of \([[-0.7,0.7],[-0.7,0.7],[0.1,1.]]\), ensuring that the Panda's initial configuration has no collisions (cf. Appendix I). Then, we sample \(5\) random collision-free (including self-collision-free) target configurations, resulting in \(500\) planning tasks, and plan in parallel \(10\) trajectories containing \(64\) timesteps.

In the last experiment, we design a realistic high-dimensional mobile manipulation task in PyBullet (cf. Fig. 4). The task comprises two parts: the _fetch_ part and _place_ part; thus, it requires solving two planning problems. Each plan contains \(128\) timesteps, and we plan a single trajectory for each planner due to the high-computational and memory demands. We generate \(20\) seeds by randomly spawning the robot in the room, resulting in \(20\) tasks.

The motion planning costs are the \(SE(3)\) goal, obstacle, self-collision, and joint-limit costs. The state dimension (configuration position and velocity) is \(d=4\) for the point-mass experiment, \(d=14\) for the Panda experiment, and \(d=36\) (\(3\) dimensions for the base, \(1\) for the torso, and \(14\) for the two arms) for the mobile manipulation experiment. As for polytope settings, we choose a \(4\)-cube for the point-mass case, a \(14\)-othorplex for Panda, and a \(36\)-othorplex for TIAGo++. Further experiment details are in Appendix I.

Baselines.We compare MPOT to popular trajectory planners, which are also straightforward to implement and vectorize in PyTorch for a fair comparison (even if the vectorization is not mentioned in their original papers). The chosen baselines are gradient-based planners: CHOMP  and GPMP2 (no interpolation) ; sampling-based planners: RRT\({}^{*}\) and its informed version I-RRT\({}^{*}\), Stochastic Trajectory Optimization for Motion Planning (STOMP) , and the recent work Stochastic Gaussian Process Motion Planning (SGPMP) . We implemented all baselines in PyTorch except for RRT\({}^{*}\) and I-RRT\({}^{*}\), which we plan with a loop using CPU.2 We found that resetting the tree, rather than reusing it, is much faster for generating multiple trajectories; hence, we reset RRT\({}^{*}\) and I-RRT\({}^{*}\) when they find their first solution.

[MISSING_PAGE_FAIL:9]

### Mobile manipulation experiment

We design a long-horizon, high-dimensional whole-body mobile manipulation planning task to stress-test our algorithm. This task requires designing many non-convex costs, e.g., signed-distance fields for gradient-based planners. Moreover, the task space is huge while the \(SE(3)\) goal is locally small (i.e., the local grasp-pose, while having hyper-redundant mobile robot, meaning the whole-body IK solution may be unreliable); hence, it typically requires long-horizon configuration trajectories and a small update step-size. Notably, the RRTs fail to find a solution, even with a very high time budget of 1000 seconds, signifying the environment's difficulty. These factors also add to the worst performance of GPMP2 in planning time (Table 2). Notably, CHOMP performs worse than GPMP2 and takes more iterations in a cluttered environment in Table 1. However, CHOMP beats GPMP2 in runtime complexity, in this case due to its simpler update rule. STOMP exploration mechanism is restrictive, and we could not tune it to work in this environment. MPOT achieves much better planning times by avoiding the propagation of gradients in a long computational chain while retaining the performance with the efficient Sinkhorn Step, facilitating individual waypoint exploration. However, due to the sparsity of the \(36\)-othorplex (\(m=72\)) defining the search direction bases in this high-dimensional case, it becomes hard to balance success rate and smoothness when tuning the algorithm, resulting in worse smoothness than the baselines.

**Limitations.** MPOT is backed by experimental evidence that its planning time scales distinctively with high-dimensional tasks in the parallelization setting while optimizing reasonably smooth trajectories. Our experiment does not imply that MPOT should replace prior methods. MPOT has limitations in some aspects. First, the entropic-regularized OT has numerical instabilities when the cost matrix dimension is huge (i.e., huge number of waypoints and vertices). We use log-domain stabilization to mitigate this issue . However, in rare cases, we still observe that the Sinkhorn scaling factors diverge, and MPOT would terminate prematurely. Normalizing the cost matrix, scaling down the cost terms, and slightly increasing the entropy regularization \(\) helps. Second, on the theoretical understanding, we only perform preliminary analysis based on Assumption 2 to connect directional-direct search literature. Analyzing Sinkhorn Steps in other conditions for better understanding, e.g., Sinkhorn Step gradient approximation analysis with arbitrary \(>0\), Sinkhorn Step on convex functions for sharper complexity bounds, etc., is desirable. Third, learning motion priors  can naturally complement MPOT to provide even better initializations, as currently, we only use GP priors to provide random initial smooth trajectories.

## 6 Conclusions and Broader Impacts

We presented MPOT--a gradient-free and efficient batch motion planner that optimizes multiple high-dimensional trajectories over non-convex objectives. In particular, we proposed the Sinkhorn Step--a zero-order batch update rule parameterized by a local optimal transport plan with a nice property of cost-agnostic step bound, effectively updating waypoints across trajectories independently. We demonstrated that in practice, our method converges, scales very well to high-dimensional tasks, and provides practically smooth plans. This work opens multiple exciting research questions, such as investigating further polytope families that can be applied for scaling up to even more high-dimensional settings, conditional batch updates, or different strategies for adapting the step-size. Furthermore, while classical motion planning considers single planning instance for each task, which under-utilizes the modern GPU capability, this work encourages future work that benefits from vectorization in the algorithmic choices, providing multiple plans and covering several modes, leading to execution robustness or even for dataset collection for downstream learning tasks. At last, we foresee potential applications of Sinkhorn Step to sampling methods or variational inference.

   & TP[\(\)] & SUC[\(\)] & S & PL \\   RRT* & \(1000 0.00\) & 0 & - & - \\ I-RRT* & \(1000 0.00\) & 0 & - & - \\   STOMP & & & & \\ SGMP & \(27.75 0.29\) & 25 & \(\) & \(\) \\ CHMP & \(16.74 0.21\) & 40 & \(0.015 0.001\) & \(8.60 0.73\) \\ GPMP2 & \(10.41 0.08\) & 40 & \(0.012 0.015\) & \(8.63 0.53\) \\
**MPOT** & \(\) & \(\) & \(0.022 0.003\) & \(10.43 0.62\) \\  

Table 2: Mobile fetch & place. TP[\(s\)] depicts the planning time for achieving first successful solution. The average S and PL are evaluated on successful trajectories only. RRT* fails to recover a solution with a very high time budget of 1000 seconds, signifying the environment difficulty.

Figure 4: A TIAGo++ robot has to fetch a cup from a table in a room, then put the cup back on the red shelf while avoiding collisions with the chairs.