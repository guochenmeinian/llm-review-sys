# A Neural Collapse Perspective on Feature Evolution in Graph Neural Networks

Vignesh Kothapalli

New York University

&Tom Tirer

Bar-Ilan University

&Joan Bruna

New York University

Correspondence to: Vignesh Kothapalli (vk2115@nyu.edu)

###### Abstract

Graph neural networks (GNNs) have become increasingly popular for classification tasks on graph-structured data. Yet, the interplay between graph topology and feature evolution in GNNs is not well understood. In this paper, we focus on node-wise classification, illustrated with community detection on stochastic block model graphs, and explore the feature evolution through the lens of the "Neural Collapse" (NC) phenomenon. When training instance-wise deep classifiers (e.g. for image classification) beyond the zero training error point, NC demonstrates a reduction in the deepest features' within-class variability and an increased alignment of their class means to certain symmetric structures. We start with an empirical study that shows that a decrease in within-class variability is also prevalent in the node-wise classification setting, however, not to the extent observed in the instance-wise case. Then, we theoretically study this distinction. Specifically, we show that even an "optimistic" mathematical model requires that the graphs obey a strict structural condition in order to possess a minimizer with exact collapse. Interestingly, this condition is viable also for heterophilic graphs and relates to recent empirical studies on settings with improved GNNs' generalization. Furthermore, by studying the gradient dynamics of the theoretical model, we provide reasoning for the partial collapse observed empirically. Finally, we present a study on the evolution of within- and between-class feature variability across layers of a well-trained GNN and contrast the behavior with spectral methods.

## 1 Introduction

Graph neural networks  employ message-passing mechanisms to capture intricate topological relationships in data and have become de-facto standard architectures to handle data with non-Euclidean geometric structure . However, the influence of topological information on feature learning in GNNs is yet to be fully understood .

In this paper, we study the feature evolution in GNNs in a node-wise supervised classification setting. In order to gain insights into the role of topology, we focus on the controlled environment of the prominent stochastic block model (SBM) . The SBM provides an effective framework to control the level of sparsity, homophily, and heterophily in the random graphs and facilitates analysis of GNN which relies solely on structural information . While inductive supervised learning on graphs is a relatively more difficult problem than transductive learning, it aligns with practical scenarios where nodes need to be classified in unseen graphs , and is also amenable to training GNNs that are deeper than conventional shallow Graph Convolution Network (GCN) models .

The empirical and theoretical study of GNNs' feature evolution in this paper employs a "Neural Collapse" perspective . When training Deep Neural Networks (DNNs) for classification, itis common to continue optimizing the networks' parameters beyond the zero training error point [9; 28; 39], a stage that was referred to in  as the "terminal phase of training" (TPT). Papyan, Han, and Donoho [25; 48] have empirically shown that a phenomenon, dubbed Neural Collapse (NC), occurs during the TPT of plain DNNs2 on standard instance-wise classification datasets. NC encompasses several simultaneous properties: (NC1) The within-class variability of the deepest features decreases (i.e., outputs of the penultimate layer for training samples from the same class tend to their mean); (NC2) After subtracting their global mean, the mean features of different classes become closer to a geometrical structure known as a simplex equiangular tight frame; (NC3) The last layer's weights exhibit alignment with the classes' mean features. A consequence of NC1-3 is that the classifier's decision rule becomes similar to the nearest class center in the feature space. We refer to  for a review on this topic.

The common approach to theoretically study the NC phenomenon is the "Unconstrained Features Model" (UFM) [31; 43]. The core idea behind this "optimistic" mathematical model is that the deepest features are considered to be freely optimizable. This idea has facilitated a recent surge of theoretical works in an effort to understand the global optimality conditions and gradient dynamics of these features and the last layer's weights in DNNs [43; 54; 55; 56; 57; 58; 59; 61; 71; 54]. In our work, we extend NC analysis to settings where relational information in data is paramount, and creates a tension with the 'freeness' associated with the UFM model. In essence, we highlight the key differences when analyzing NC in GNNs by identifying structural conditions on the graphs, under which the global minimizers of the training objective exhibit full NC1. Interestingly, the structural conditions that we rigorously establish in this paper are aligned with the neighborhood conditions on heterophilic graphs that have been empirically hypothesized to facilitate learning by Ma et al. .

Our main contributions can be summarized as follows:

* We conduct an extensive empirical study that shows that a decrease in within-class variability is prevalent also in the deepest features of GNNs trained for node classification on SBMs. However, not to the extent observed in the instance-wise setting.
* We propose and analyze a graph-based UFM to understand the role of node neighborhood patterns and their community labels on NC dynamics. We prove that even this optimistic model requires a strict structural condition on the graphs in order to possess a minimizer with exact variability collapse. Then, we show that satisfying this condition is a rare event, which theoretically justifies the distinction between observations for GNNs and plain DNNs.
* Nevertheless, by studying the gradient dynamics of the graph-based UFM, we provide theoretical reasoning for the partial collapse during GNNs training.
* Finally, we study the evolution of features across the layers of well-trained GNNs and contrast the decrease in NC1 metrics along depth with a NC1 decrease along power iterations in spectral clustering methods.

## 2 Preliminaries and Problem Setup

We focus on supervised learning on graphs for _inductive_ community detection. Formally, we consider a collection of \(K\) undirected graphs \(\{_{k}=(_{k},_{k})\}_{k=1}^{K}\), each with \(N\) nodes, \(C\) non-overlapping balanced communities and a node labelling ground truth function \(y_{k}:_{k}\{_{1},,_{C}\}\). Here, \( c[C],_{c}^{C}\) indicates the standard basis vector, where we use the notation \([C]=\{1,,C\}\). The goal is to learn a parameterized GNN model \(_{}(.)\) which minimizes the empirical risk given by:

\[_{}_{k=1}^{K}(_{}(_{ k}),y_{k}(_{k}))+\|\|_{F}^{2},\] (1)

where \(\|\|_{F}\) represents the Frobenius norm, \(\) is the loss function that is invariant to label permutations , and \(>0\) is the penalty parameter. We choose \(\) based on the mean squared error (MSE) as:

\[(_{}(_{k}),y_{k})=_{ S_{C}}\|_{}(_{k})-(y_{k}( _{k}))\|_{2}^{2},\] (2)

where \(\) belongs to the permutation group over \(C\) elements. Using the MSE loss for training DNN classifiers has become increasingly popular recently. For example, Hui and Belkin  have performed an extensive empirical study that shows that training with MSE loss yields performance that is similar to (and sometimes even better than) training with CE loss. This choice also facilitates theoretical analyses [25; 55; 71].

### Data model

We employ the Symmetric Stochastic Block Model (SSBM) to generate graphs \(\{_{k}=(_{k},_{k})\}_{k=1}^{K}\). Stochastic block models (originated in ) are classical random graph models that have been extensively studied in statistics, physics, and computer science. In the SSBM model that is considered in this paper, each graph \(_{k}\) is associated with an adjacency matrix \(_{k}^{N N}\), degree matrix \(_{k}=(_{k})^{N N}\), and a random node features matrix \(_{k}^{d N}\), with entries sampled from a normal distribution. Formally, if \(^{C C}\) represents a symmetric matrix with diagonal entries \(p\) and off-diagonal entries \(q\), a random graph \(_{k}\) is considered to be drawn from the distribution \((N,C,p,q)\) if an edge between vertices \(v_{i},v_{j}\) is formed with probability \(()_{y_{k}(v_{i}),y_{k}(v_{j})}\)3. We choose the regime of exact recovery [1; 2; 3; 45] in sparse graphs where \(p=,q=\) for parameters \(a,b 0\) such that \(|-|>\). The need for exact recovery (information-theoretically) stems from the requirement that \(_{}\) should be able to reach TPT (Appendix B).

### Graph neural networks

Inspired by the widely studied model of higher-order GNNs by Morris et al. , we design \(_{}\) based on a family of graph operators \(=\{,}_{k}\}, k[K]\), and denote it as \(_{}^{}\). Formally, for a GNN \(_{}^{}\) with \(L\) layers, the node features \(_{k}^{(l)}^{d_{l} N}\) at layer \(l[L]\) is given by:

\[_{k}^{(l)} =_{1}^{(l)}_{k}^{(l-1)}+_{2}^{(l)} _{k}^{(l-1)}}_{k},\] (3) \[_{k}^{(l)} =(_{k}^{(l)}),\]

where \(_{k}^{(0)}=_{k}\), and \(()\) represents a point-wise activation function such as ReLU. \(_{1}^{(l)},_{2}^{(l)}^{d_{l} d_{l-1}}\) are the weight matrices and \(}_{k}=_{k}_{k}^{-1}\) is the normalized adjacency matrix, also known as the random-walk matrix. We also consider a simpler family without the identity operator \(^{}=\{}_{k}\}, k[K]\) and analyze the GNN \(_{}^{^{}}\) with only graph convolution functionality. Formally, the node features \(_{k}^{(l)}^{d_{l} N}\) for \(_{}^{^{}}\) is given by:

\[_{k}^{(l)} =_{2}^{(l)}_{k}^{(l-1)}}_ {k},\] (4) \[_{k}^{(l)} =(_{k}^{(l)}).\]

Here, the subscript for the weight matrix \(_{2}^{(l)}\) is retained to highlight that it acts on \(_{k}^{(l-1)}}_{k}\). Finally, we employ the training strategy of Chen et al.  and apply instance-normalization  on \((_{k}^{(l)}), l\{1,,L-1\}\) to prevent training instability.

### Tracking neural collapse in GNNs

In our setup, reaching zero training error (TPT) implies that the network perfectly classifies all the nodes (up to label permutations) in all the training graphs. To this end, we leverage the NC metrics introduced in [48; 55; 56; 74] and extend them to GNNs in an inductive setting. To begin with, let us consider a single graph \(_{k}=(_{k},_{k}),k[K]\) with a normalized adjacency matrix \(}_{k}\). Additionally, we denote \(_{k}^{(l)}^{d_{l} N}\) as the output of layer \(l[L-1]\), irrespective of the GNN design. Now, by dropping the subscript and superscript for notational convenience, we define the class means and the global mean of \(\) as follows:

\[}_{c}:=_{i=1}^{n}_{c,i}\ \,  c[C],\ \ }_{G}:=_{c=1}^{C}_{i=1}^{n}_{ c,i},\] (5)

where \(n=N/C\) represents the number of nodes in each of the \(C\) balanced communities, and \(_{c,i}\) is the feature vector (a column in \(\)) associated with \(v_{c,i}\), i.e., the \(i^{th}\) node belonging to class \(c[C]\). Next, let \((v_{c,i})\) denote all the neighbors of \(v_{c,i}\) and let \(_{c^{}}(v_{c,i})\) denote only the neighbors of \(v_{c,i}\) that belong to class \(c^{}[C]\). We define the class means and global mean of \(}\), which is unique to the GNN setting as follows:

\[}_{c}^{}:=_{i=1}^{n}_{ c,i}^{}\, c[C],}_{G}^{}:=_{c=1}^{C}_{i=1}^{n}_{c,i}^{},\] (6)

where \(_{c,i}^{}=(_{v_{c,j}_{c}(v_{c,i}) }_{c,j}+_{v_{c^{},j}_{c^{},j} (v_{c,i})}_{c^{},j})/|(v_{c,i})|\).

\(\)**Variability collapse in features** H: For a given features matrix \(\), let us define the within- and between-class covariance matrices, \(_{W}()\) and \(_{B}()\), as:

\[_{W}() :=_{c=1}^{C}_{i=1}^{n}(_{c,i}- }_{c})(_{c,i}-}_ {c})^{},\] (7) \[_{B}() :=_{c=1}^{C}(}_{c}- }_{G})(}_{c}-}_{G})^{}.\] (8)

To empirically track the within-class variability collapse with respect to the between-class variability, we define two NC1 metrics:

\[_{1}()=(_{W}()_{B}^{}()), }_{1}()= (_{W}())}{(_ {B}())},\] (9)

where \({}^{}\) denotes the Moore-Penrose pseudo-inverse and \(()\) denotes the trace of a matrix. Although \(_{1}\) is the original NC1 metric used by Papyan et al. , we consider also \(}_{1}\), which has been proposed by Tirer et al.  as an alternative metric that is more amenable to theoretical analysis.

\(\)**Variability collapse in neighborhood-aggregated features**\(}\): Similarly to the above, we track the within- and between-class variability of the "neighborhood-aggregated" features matrix \(}\) by \(_{W}(})\) and \(_{B}(})\) (computed using \(}_{c}^{}\) and \(}_{G}^{}\)), as well as \(_{1}(})\) and \(}_{1}(})\). (See Appendix C for formal definitions.) Finally, we follow a simple approach and track the mean and variance of \(_{1}(),}_{1}( ),_{1}(}), }_{1}(})\) across all \(K\) graphs in our experiments. As the primary focus of our paper is the analysis of feature variability during training and inference, we defer the definition and examination of metrics based on NC2 and NC3 to Appendix C, H.

## 3 Evolution of penultimate layer features during training

In this section, we explore the evolution of the deepest features of GNNs during training. In Section 3.1, we present empirical results of GNNs in the setup that is detailed in Section 2, showing that a decrease in within-class feature variability is present in GNNs that reach zero training error, but not to the extent observed with plain DNNs. Then, in Section 3.2, we theoretically study a mathematical model that provides reasoning for the empirical observations.

### Experiments

**Setup.** We focus on the training performance of GNNs \(_{}^{},_{}^{^{}}\) on sparse graphs and generate a dataset of \(K=1000\) random SSBM graphs with \(C=2,N=1000,p=0.025,q=0.0017\). The networks \(_{}^{},_{}^{^{}}\) are composed of \(L=32\) layers with graph operator, ReLU activation, and instance-normalization functionality. The hidden feature dimension is set to \(8\) across layers. They are trained for \(8\) epochs using stochastic gradient descent (SGD) with a learning rate \(0.004\), momentum \(0.9\), and a weight decay of \(5 10^{-4}\). During training, we track the NC1 metrics for the penultimate layer features \(_{k}^{(L-1)}\), by computing their mean and standard deviation across \(k[K]\) graphs after every epoch. To measure the performance of the GNN, we compute the 'overlap'  between predicted communities and ground truth communities (up to permutations):

\[(,y):=_{ S_{C}}(_{i=1}^{N} _{(v_{i}),(y(v_{i}))}-)/(1-)\] (10)where \(\) is the node labelling function based on GNN design and \(_{i=1}^{N}_{(v_{i}),(y(v_{i}))}\) is the training accuracy (\(\) denotes the Kronecker delta). The overlap allows us to measure the improvements in performance over random guessing while retaining the indication that the GNN has reached TPT. Formally, when \(_{i=1}^{N}_{(v_{i}),(y(v_{i}))}=1\) (zero training error), then \((,y)=1\). We illustrate the empirical results in Figures 1 and 2, and present extensive experiments (showing similar behavior) along with infrastructure details in Appendix H4.

**Observation:** The key takeaway is that \(_{1}(_{k}^{(L-1)})\), \(}_{1}(_{k}^{(L-1)})\) tend to reduce and plateau during TPT in \(_{}^{}\) and \(_{}^{^{}}\). Notice that even though we consider a controlled SSBM-based setting, the \(_{1}\) values observed here are higher than the values observed in the case of plain DNNs on real-world instance-wise datasets . Additionally, we can observe that trends for \(_{1}(_{k}^{(L-1)}}_{k})\), \(}_{1}(_{k}^{(L-1)}}_{k})\) are similar to those of \(_{1}(_{k}^{(L-1)})\), \(}_{1}(_{k}^{(L-1)})\).

### Theoretical analysis

In this section, we provide a theory for this empirical behavior. Most, if not all, of the theoretical papers on NC, adopt the UFM approach, which treats the features as free optimization variables - disconnected from data . Here, we consider a graph-based adaptation of this approach, that we dubbed as gUFM. We consider GNNs of the form of \(_{}^{^{}}\), which is more tractable for mathematical analysis. Formally, by considering \(\) to be the MSE loss, treating \(\{_{k}^{(L-1)}\}_{k=1}^{K}\) as freely optimizable variables, and representing \(_{2}^{(L)}^{C d_{L-1}},_{k}^{(L-1)} ^{d_{L-1} N}\) as \(_{2},_{k}\) (for notational convenience), the empirical risk based on the gUFM can be formulated as follows:

\[}^{^{}}(_{2},\{ _{k}\}_{k=1}^{K}):=_{k=1}^{K}(\| _{2}_{k}}_{k}-\|_{F}^{ 2}+}}{2}\|_{k}\|_{F}^{2})+ }}{2}\|_{2}\|_{F}^{2}\] (11)

where \(^{C N}\) is the target matrix, which is composed of one-hot vectors associated with the different classes, and \(_{W_{2}},_{H_{k}}>0\) are regularization hyperparameters. To simplify the analysis, let us assume that \(=_{C}_{n}^{}\), where \(\) denotes the Kronecker product. Namely, the training data is balanced (a common assumption in UFM-based analyses in literature) with \(n=N/C\) nodes per class in each graph and (without loss of generality) organized class-by-class. Note that for \(K=1\) (which allows omitting the graph index \(k\)) and no graphical structure, i.e., \(}=\) (since \(=\)), (11) reduces to the plain UFM that has been studied in . In this case, it has been shown that any minimizer \((_{2}^{*},^{*})\) is _collapsed_, i.e., its features have _exactly zero_ within-class variability:

\[_{c,1}^{*}==_{c,n}^{*}=}_{c}^{ *}, c[C],\] (12)

which implies \(_{W}(^{*})=\). We will show now that the situation in gUFM is significantly different.

Considering the \(K=1\) case, we start by showing that, to have minimizers of (11) that possess the property in (12), the graph must obey a strict structural condition. For \(K>1\), having a minimizer \((_{2}^{*},\{_{k}^{*}\})\) where, for some \(j[K]\), \(_{j}^{*}\) is collapsed directly follows from having the structural condition satisfied by the \(j\)-th graph (as shown in our proof, the sufficiency of the condition does not depend on the shared weights \(_{2}\)). On the other hand, generalizing the necessity of the structural condition to the case of \(K>1\) is technically challenging (see the appendix for details). For that reason, we state the condition in the following theorem only for \(K=1\). Note also that, showing that the condition is unlikely to be satisfied per graph is enough for explaining the plateaus above zero of NC metrics (computed over multiple graphs), which are demonstrated in Section 3.1.

**Theorem 3.1**.: _Consider the gUFM in (11) with \(K=1\) and denote the fraction of neighbors of node \(v_{c,i}\) that belong to class \(c^{}\) as \(s_{cc^{},i}=_{c^{}}(v_{c,i})|}{|(v_{ c,i})|}\). Let the condition \(\) based on \(s_{cc^{},i}\) be given by:_

\[(s_{c1,1},,s_{cC,1})==(s_{c1,n},,s_{cC,n}), c [C].\] ( \[\] )

_If a graph \(\) satisfies condition \(\), then there exist minimizers of the gUFM that are collapsed (satisfying (12)). Conversely, when either \(_{W_{2}}}=0\), or \(_{W_{2}}}>0\) and \(\) is regular (so that \(}=}^{}\)), if there exists a collapsed non-degenerate minimizer5 of gUFM, then condition \(\) necessarily holds._

**Conjecture 3.1**.: _Consider the gUFM in (11) with \(K=1\) and condition \(\) as stated in theorem 3.1. The minimizers of the gUFM are collapsed (satisfying (12)) iff the graph \(\) satisfies condition \(\)._

Let us dwell on the implication of Theorem 3.1. The stated condition \(\) essentially holds when any node \(i[n]\) of a certain class \(c\) obeys \((s_{c1,i},,s_{cC,i})=(s_{c1},,s_{cC})\) for some \((s_{c1},,s_{cC})\), a tuple of the ratio of neighbors \((_{c^{}=1}^{C}s_{cc^{}}=1)\) independent of \(i\). That is, \((s_{c1},,s_{cC})\) must be the same for nodes within the same class but can be different for nodes belonging to different classes. For example, for a plain UFM this condition trivially holds, as \(}=\). Under the SSBM distribution, it is also easy to see that \(}\) satisfies this condition. However, for more practical graphs, such as those _drawn_ from SSBM, the probability of having a graph that obeys condition \(\) is negligible. This is shown in the following theorem.

**Theorem 3.2**.: _Let \(=(,)\) be drawn from SSBM\((N,C,p,q)\). For \(N>>C\), we have_

\[()<(_{t=0}^{n} [q^{t}(1-q)^{n-t}]^{n})^{}.\] (13)

The proof is presented in Appendix E. It is not hard to see that as the number of per-class nodes \(n\) increases, the probability of satisfying condition \(\) decreases,6 as numerically exemplified below.

**Numerical example.** Let's consider a setting with \(C=2,N=1000,a=3.75,b=0.25\). This gives us \(n=N/C=500,p=0.025,q=0.0017\), for which \(()<2.18 10^{-188}\).

In Appendix E we further show by exhaustive computation of \(()\) that its value is negligible even for smaller scale graphs. Thus, the probability of sampling a graph structure for which the gUFM minimizers exhibit exact collapse is practically 0.

gUFM experiments.** For a better understanding of these results, we present small-scale experiments using the gUFM model on graphs that satisfy and do not satisfy condition **C**. By training the gUFM (based on \(_{}^{^{}}\)) on \(K=10\) graphs that satisfy condition **C**, we can observe from Figure 3 that NC1 metrics on \(,}\) reduce significantly. On the other hand, these metrics plateau after sufficient reduction when the graphs fail to satisfy condition **C**, as shown in Figure 4. In both the cases, the SSBM parameters are \(C=2,N=1000,p=0.025,q=0.0017\), and the gUFM is trained using plain gradient descent for \(50000\) epochs with a learning rate of \(0.1\) and L2 regularization parameters \(_{W_{1}}=_{W_{2}}=_{H}=5 10^{-3}\). Extensive experiments with varying choices of \(N,C,p,q\), feature transformation based on \(_{}^{}\) and additional NC metrics are provided in Appendix H. (The additional NC metrics measure the alignment of the classes' mean features with simplex Equiangular Tight Frame (ETF) and Orthogonal Frame (OF) structures.)

**Remark.** Note that previous papers consider UFM configurations for which the minimizers possess exact NC, typically without any condition on the number of samples or on the hyperparameters of the settings. As the UFMs are "optimistic" models, in the sense that they ignore all the limitations on modifying the features that exist in the training of practical DNNs, such results can be understood as "zero-order" reasoning for practical NC behavior. On the other hand, here we show that even the optimistic gUFM will not yield perfectly collapsed minimizers for graph structures that are not rare. This provides a pure understanding of the gaps in GNNs' features from exact collapse and why these gaps are larger than for plain DNNs. We also highlight the observation that _condition **C** applies to homophilic as well as heterophilic graphs_, as the constraint on neighborhood ratios is independent of label similarity. Thus providing insights on the effectiveness of GNNs on highly heterophilic graphs as empirically observed by Ma et al. .

**Gradient flow:** By now, we have provided a theory for the distinction between the deepest features of GNNs and plain DNNs. Next, to provide reasoning for the partial collapse in GNNs, which is observed empirically, we turn to study the gradient dynamics of our gUFM.

We consider the \(K=1\) case and, following the common practice , analyze the gradient flow along the "central path" -- i.e., when \(_{2}=_{2}^{*}()\) is the optimal minimizer of \(}^{^{}}(_{2},)\)

Figure 4: gUFM for \(_{}^{^{}}\): Illustration of loss, overlap, and \(_{1}\) plots for \(,}\) during training on \(10\) SSBM graphs which do not satisfy condition **C**.

Figure 3: gUFM for \(_{}^{^{}}\): Illustration of loss, overlap, and \(_{1}\) plots for \(,}\) during training on \(10\) SSBM graphs satisfying condition **C**.

w.r.t. \(_{2}\), which has a closed-form expression as a function of \(\). The resulting gradient flow is:

\[_{t}}{dt}=-}^{F^{}}(_{2}^{*}(_{t}),_{t}).\] (14)

Similarly to [25; 56], we aim to gain insights on the evolution of \(_{W}(_{t})\) and \(_{B}(_{t})\) (in particular, their traces) along this flow. Yet, the presence of the structure matrix \(}\) significantly complicates the analysis compared to existing works (which are essentially restricted to \(}=\)). Accordingly, we focus on the case of two classes, \(C=2\), and adopt a perturbation approach, analyzing the flow for a graph \(}=}+\), where the expectation is taken with respect to the SSBM distribution and \(\) is a sufficiently small perturbation matrix. Our results are stated in the following theorem.

**Theorem 3.3**.: _Let \(K=1\), \(C=2\) and \(_{W_{2}}>0\). There exist \(>0\) and \(E>0\), such that for \(0<_{H}<\) and \(0<\|\|<E\), along the gradient flow stated in (14) associated with the graph \(}=}+\), we have that: (1) \((_{W}(_{t}))\) decreases, and (2) \((_{B}(_{t}))\) increases. Accordingly, \(}_{1}(_{t})\) decreases._

The proof is presented in Appendix F. The importance of the theorem comes from showing that even graphs that do not satisfy condition \(\) (in the context of the analysis: perturbations around \(}\)) exhibit reduction in the within-class covariance and increase in the between-class covariance of the features. This implies a reduction of NC1 metrics (to some extent), which is aligned with the empirical results in Section 3.1. Additionally, we highlight that since an increase in \((_{B}(_{t}))\) and decrease in \((_{W}(_{t}))\) is desirable for NC, this behavior of the penultimate layer's features can potentially serve as a remedy for the over-smoothing problem in GNNs (more details in Appendix A).

## 4 Feature separation across layers during inference

Till now, we have analyzed the feature evolution of the deepest GNN layer during training. In this section, we use these well-trained GNNs to classify nodes in unseen SSBM graphs and explore the depthwise evolution of features. In essence, we take an NC perspective on characterizing the weights of these well-trained networks that facilitate good generalization. To this end, we present empirical results demonstrating a gradual decrease of NC1 metrics along the network's depth. The observations hold a resemblance to the case with plain DNNs (shown empirically in [20; 55] and more recently in , and theoretically in ). To gain insights into this depthwise behavior we also compare it with the behavior of spectral clustering methods along their projected power iterations.

### Experiments

**Setup.** We consider the \(32-\)layered networks \(_{}^{F},_{}^{F^{}}\) which have been designed and trained as per the setup in section 3.1 and have reached TPT. These networks are now tested on a dataset of \(K=100\) unseen random SSBM graphs with \(C=2,N=1000,p=0.025,q=0.0017\). Additionally, we perform spectral clustering using projected power iterations on the Normalized Laplacian (NL) and Bethe-Hessian (BH) matrices  for each of the test graphs. The motivation behind this approach is to obtain an approximation of the Fiedler vector of NL/BH that sheds light on the hidden community structure [1; 4; 67; 46]. Formally, for a test graph \(=(,)\), the NL and BH matrices are given by:

\[()=-^{-1/2}^{-1/2},\] (15)

\[(,r)=(r^{2}-1)-r+,\] (16)

where \(r\) is the BH scaling factor. Now, by treating \(\) to be either NL or BH matrix, a projected power iteration to estimate the second largest eigenvector of \(}=\|\|\,-\) is given by:

\[^{(l)}=}^{(l-1)},^{(l-1)}=^{(l-1)}-^{(l-1)}, }{\|^{(l-1)}-^{(l-1 )},\|_{2}},\] (17)

with the vector \(^{N}\) denoting the largest eigenvector of \(}\). Thus, we start with a random normal vector \(^{0}^{N}\) and iteratively compute the feature vector \(^{(l)}^{N}\), which represents the 1-D feature for each node after \(l\) iterations7.

### Towards understanding depthwise behavior

From Figure 5, we can observe that the rate of decrease in NC1 metrics is much higher in \(_{}^{}\) and \(_{}^{^{}}\) (avg test overlap \(=1\)) when compared to the baseline spectral approaches (avg test overlap NL\(=0.04\), BH\(=0.15\)) with random normal feature initialization. For \(_{}^{}\) and \(_{}^{^{}}\), the NC1 metrics and traces of covariance matrices are tracked after each of the components of a layer: graph operator, ReLU and instance normalization. For spectral methods, the components are: the operator \(}\) and the normalization. Interestingly, this rate seems to be relatively higher in \(_{}^{^{}}\) than in \(_{}^{}\), and the variance of metrics tends to reduce significantly across all the test graphs after a certain depth in \(_{}^{^{}}\) and \(_{}^{}\). Intuitively, the presence of \(_{1}\) in \(_{}^{}\) seems to delay this reduction across layers. On the other hand, owing to the non-parametric nature of the spectral approaches, observe that the ratios \((_{B}(^{(l)}))/(_{ B}(^{(l-1)})),(_{W}(^{(l)}))/( _{W}(^{(l-1)}))\) tend to be constant throughout all iterations. However, the GNNs behave differently as \((_{B}(^{(l)}))/(_{B} (^{(l-1)}))\), \((_{W}(^{(l)}))/(_{ W}(^{(l-1)}))\) tend to decrease across depth (Figure 6).

For a better understanding of this phenomenon, we consider the case of \(C=2\) (without loss of generality) and assume that the \((l-1)^{th}\)-layer features \(^{(l-1)}\) of nodes belonging to class \(c=1,2\) are drawn from distributions \(_{1},_{2}\) respectively. We do not make any assumptions on the nature of the distributions and simply consider \(_{1}^{(l-1)},_{2}^{(l-1)}^{d_{l-1}}\) and \(_{1}^{(l-1)},_{2}^{(l-1)}^{d_{l-1}  d_{l-1}}\) as their mean vectors and covariance matrices, respectively. In the following theorem, we present bounds on the ratio of traces of feature covariance matrices after the graph operator is applied.

**Theorem 4.1**.: _Let \(C=2,_{i}(),_{-i}()\) indicate the \(i^{th}\) largest and smallest eigenvalue of a matrix, \(_{1}=,_{2}=,_{3}=+q^{2} }{n(p+q^{2})}\), and denote_

\[_{W}=_{1}^{*(l)}_{1}^{*(l)}+_{2}[ _{2}^{*(l)}_{1}^{*(l)}+_{1}^{*(l)} _{2}^{*(l)}]+_{3}_{2}^{*(l)}_{2}^ {*(l)},\]

\[_{B}=(_{1}^{*(l)}+_{1}_{2}^{*(l)} )^{}(_{1}^{*(l)}+_{1}_{2}^{*(l)} ).\]

_Then, the ratios of traces \((_{B}(^{(l)}))}{(_{B}(^{(l-1)}))},( _{W}(^{(l)}))}{(_{W} (^{(l-1)}))}\) for layer \(l\{2,,L\}\) of a network \(_{}^{}\) are bounded as follows:_

\[^{d_{l-1}}_{-i}(_{B}(^{(l -1)}))_{i}(_{B})}{_{i=1}^{d_{l-1}} _{i}(_{B}(^{(l-1)}))}(_{B}(^{(l)}))}{( _{B}(^{(l-1)}))}^{d_{l-1}} _{i}(_{B}(^{(l-1)}))_{i} (_{B})}{_{i=1}^{d_{l-1}}_{i}(_{B}(^{(l-1)}))},\]

The proof is presented in Appendix G. To understand the implications of this result, first observe that by setting \(_{1}^{*}=\) and modifying \(_{W}=_{3}_{2}^{*(l)}_{2}^{*(l)}, _{B}=_{1}^{2}_{2}^{*(l)}_{2}^{*(l)}\), we can obtain a similar bound formulation for \(_{}^{^{}}\). To this end, as \(_{W},_{B}\) depend on the spectrum of \(_{2}^{*(l)}\), the ratios \((_{B}(^{(l)}))}{(_{B}(^{(l-1)}))},( _{W}(^{(l)}))}{(_{W} (^{(l-1)}))}\) are highly dependent on \(_{1},_{3}\). Notice that since \(_{1}^{*(l)}_{1}^{*(l)}\) in \(_{W}\) is not scaled by any factor that is inversely dependent on \(n\), it tends to act as a spectrum controlling mechanism and the reduction in within-class variability of features in \(_{}^{}\) is relatively slow when compared to \(_{}^{^{}}\). Thus, justifying the empirical behavior that we observed in subplots 6c and 6d in Figure 6.

## 5 Conclusion

In this work, we studied the feature evolution in GNNs for inductive node classification tasks. Adopting a Neural Collapse (NC) perspective, we analyzed both empirically and theoretically the within- and between-class variability of features along the training epochs and along the layers during inference. We showed that a partial decrease in within-class variability (and NC1 metrics) is present in the GNNs' deepest features and provided theory that indicates that greater collapse is not expected when training GNNs on practical graphs (as it requires strict structural conditions). We also showed a depthwise decrease in variability metrics, which resembles the case with plain DNNs. Especially, by leveraging the analogy of feature transformation across layers in GNNs with spectral clustering along projected power iterations, we provided insights into this GNN behavior and distinctions between two GNN architectures.

Interestingly, the structural conditions on graphs for exact collapse, which we rigorously established in this paper, are aligned with those that have been empirically hypothesized to facilitate GNNs learning in  (outside the context of NC). As a direction for future research, one may try to use this connection to link NC behavior with the generalization performance of GNNs. Moreover, note that a reduction in NC1 metrics of the deepest features implies not only that the within-class variability decreases but also that the between-class variability is bounded from below. Therefore, methods that are based on promoting NC (e.g., by utilizing the established structural conditions) can potentially mitigate the over-smoothing problem in GNNs. See Appendix A for a formal statement on the relation of NC and over-smoothing and additional discussions on the potential usage of graph rewiring strategies for this goal.