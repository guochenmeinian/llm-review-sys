# Comparing the local information geometry

of image representations

David Lipshutz\({}^{1,}\)1

Jenelle Feather\({}^{1,}\)1

Sarah E. Harvey\({}^{1}\)

Alex H. Williams\({}^{1,2}\)

Eero P. Simoncelli\({}^{1,2}\)

\({}^{1}\) Center for Computational Neuroscience, Flatiron Institute

\({}^{2}\) Center for Neural Science, New York University

{dlipshutz,jfeather,sharvey}@flatironinstitute.org,

{alex.h.williams,eero.simoncelli}@nyu.edu

Equal contribution

###### Abstract

We propose a framework for comparing a set of image representations (artificial or biological) in terms of their sensitivities to local distortions. We quantify the local geometry of a representation using the Fisher information matrix (FIM), a standard statistical tool for characterizing the sensitivity to local distortions of a stimulus, and use this as a substrate for a metric on the local geometry of representations in the vicinity of a base image. This metric may then be used to optimally differentiate a set of models, by optimizing for a pair of distortions that maximize the variance of the models under this metric. We use the framework to compare a set of simple models of the early visual system, identifying a novel set of image distortions that allow immediate comparison of the models by visual inspection. In a second example, we show that the method can reveal distinctions between standard and adversarially trained object recognition networks.

## 1 Introduction

Biological and artificial neural networks transform sensory stimuli into internal representations that support downstream tasks. Often, similarity between representations is quantified by measuring the alignment of their _global_ geometric structure . However, systems with similar global geometry can have strikingly different _local_ geometries. The well-known occurrence of adversarial examples  in object recognition systems provides an example: Even for systems that are broadly similar to each other and in agreement with human perception, carefully targeted experiments reveal small image distortions that are imperceptible to humans but result in reliable misclassification by a model.

How can we quantify and compare the local geometry of different image representations? A brute-force comparison clearly is prohibitive: the space of images is extremely high-dimensional, and the set of potential distortions equally high-dimensional. Estimating the local geometry of representations over a moderately dense sampling of this full set is impractical, and estimating human sensitivity to such a set is essentially impossible. As such, it is worthwhile to develop a method for judicious selection of stimulus distortions that can be used when comparing a set of models.

We take inspiration from Zhou et al. . For a pair of models and a base image, they synthesize distortions along which the two models' sensitivities maximally disagree. This bears conceptual similarity to other methods that construct stimuli to optimally distinguish models , and builds on earlierwork that examined "eigen-distortions" along which individual models are maximally/minimally sensitive . Specifically, they measure the local sensitivity of a model in terms of its Fisher Information matrix (FIM) , a classical tool from statistical estimation theory, and choose the pair of "generalized eigen-distortions" that maximize/minimize the ratio of the two models' sensitivities. Once these image distortion have been computed, they may be added in varying amounts to a base image to determine the level at which they become visible to a human. These measured human sensitivities can then be compared to those of the models, with the goal of identifying which model is better aligned with the local geometry of the human visual system. However, when comparing more than two models, there is no principled method for selecting the distortions.

Here we define a novel metric for comparing model representations in terms of their relative sensitivities to a pair of local image distortions. We then use this metric to generate a pair of distortions that maximize the variance of two or more models. In analogy with principal component analysis, we refer to these as "principal distortions". We apply our method to a nested set of hand-crafted models of the early visual system, and to a set of standard and adversarially-trained visual neural network models. In both cases, we illustrate how the method generates novel distortions that highlight differences between models. For additional details and results, see the full paper version of this extended abstract .

## 2 Problem statement and methods

Given a collection of stochastic image representations, our goal is to develop a method for comparing the local geometry in the vicinity of image \(\) across these image representations. We assume that each representation has an associated conditional density \(p(|)\), where \(^{K}\) is a vector of image pixels and \(\) is a stochastic response (e.g., neuronal firing rates or deterministic model responses with additive response noise, see Fig. 1A). Associated with the conditional density is the Fisher-Rao

Figure 1: Comparing the local geometry of image representations. **A)** Each model maps a stimulus \(\) to a distribution \(p(|)\) in representation space (biological neurons are noisy while deterministic models can be made stochastic by assuming additive Gaussian response noise). Classical signal detection theory posits that the sensitivity \(d()\) of the representation to a distortion \(\) depends on how much overlap there is between \(p(|)\) and \(p(|+)\), with less overlap indicating higher sensitivity . **B)** Distortion sensitivity of each model may be mapped back to the stimulus domain via the FIM, which has been used previously to generate optimal stimuli for comparison to human perception. Specifically, the eigenvectors of a model FIM may be used to examine most/least model-sensitive stimuli , and the generalized eigenvectors of the ratio of model FIMs may be used to generate stimuli that best distinguish the sensitivities of two models . Here, we show that these models have interpretations in terms of the log ratios of model sensitivities, and develop a generalized method that allows comparison of an arbitrary number of models, by selecting two stimulus distortions that maximize the variance of the log-ratio of sensitivities over models.

metric [15; 16] (Fig. 1B), a Riemannian metric on the stimulus space defined in terms of the Fisher information matrix (FIM) 

\[():=_{ p(|)}[ _{} p(|)_{} p(| )^{}].\]

The _sensitivity_ of the representation to distortions of stimulus \(\) in the direction \(\) can be expressed as:

\[d()=d(;):=^{}()}.\] (1)

A comprehensive comparison of the local geometries of two or more image representations is impractical. Therefore, it is useful to develop a method for optimally choosing image distortions along which to compare image representations. Berardino et al.  proposed computing the extremal eigenvectors of model FIMs (termed "eigen-distortions", Fig. 1B) and comparing them to human visual sensitivities. However, if the eigen-distortions of two models are similar, they will not be useful in distinguishing the models, since they will be insensitive to differences in the non-extremal eigenvectors.

Comparing two image representationsZhou et al.  proposed comparing two image representations \(A\) and \(B\) along distortions in which their local sensitivities maximally differ. Specifically, they chose distortions to extremize the generalized Rayleigh quotient:

\[_{1}=*{arg\,max}_{} ^{}_{A}()}{^{}_{B}( )}, _{2}=*{arg\,min}_{}^{}_{A}()}{^{} _{B}()}.\]

Since these distortions correspond to the extremal eigenvectors of the generalized eigenvalue problem \(_{A}()=_{B}()\), we refer to them as "generalized eigen-distortions" (Fig. 1B). However, this method is limited to comparisons of pairs of models, or a single model to the average of other models.

Comparing many image representationsThe generalized eigenvalue problem induces a metric between image representations, which can be used to optimally choose image distortions for distinguishing more than two models. Specifically, up to permutation, we can express the pair of generalized eigen-distortions as the solution to the following optimization problem (Appx. A):

\[\{_{1},_{2}\}=*{arg\,max}_{,^{}}m_{,^{}}(A,B ), m_{,^{}}(A,B):=| ()}{d_{A}(^{})}- ()}{d_{B}(^{})}|.\] (2)

For any pair of distortions \(,^{}\), the function \(m_{,^{}}(,)\) defines a _metric_ on the local geometry of image representations: it is non-negative, symmetric, and obeys the triangle inequality. The extremal distortions have several appealing properties: (i) they are invariant to arbitrary rescaling of the FIM (\(() c()\) for any \(c>0\)), of either model; (ii) they are invariant to permutations (\(^{}\)); (iii) when \(,^{}\) are the generalized eigen-distortions, the metric is an approximation of the Fisher-Rao distance between mean-zero Gaussian distributions with covariances \(_{A}()\) and \(_{B}()\) (Appx. B); and (iv) the metric compares stochastic representations back in stimulus space, which avoids the problem of having to align two representational spaces via a nuisance transformation .

We can generalize the result to optimize a pair of image distortions for distinguishing \(N>2\) image representations \(A_{1},,A_{N}\). In particular, we choose \(_{1},_{2}\) to maximize the sum of the squares of all pairwise differences between the log sensitivity ratios, which is equivalent to maximizing the _variance_ of the image representations' log sensitivity ratios:

\[\{_{1},_{2}\}=*{arg\,max}_{,^{}}_{n=1}^{N}|}()}{d_{A_{n}}(^{})}-_{m=1}^{N} }()}{d_{A_{m}}(^{})}|^{2}\]

We refer to \(\{_{1},_{2}\}\) as the "principal distortions" of the models, analogous to principal component analysis (Fig. 1B). For a gradient-based optimization algorithm, see Appx. C.

## 3 Experiments

As a demonstration of our method, we generated principal distortions for computational models previously proposed to capture aspects of the human visual system. All models were implemented in PyTorch and simulations were performed on a NVIDIA RTX A6000 GPU. As the models are deterministic, we follow the assumptions of  and calculate the FIM by assuming the network output is corrupted by additive Gaussian noise, in which case \(()=_{f}()^{}_{f}()\), where \(_{f}()\) is the Jacobian of the model \(()\) at \(\).

Early visual modelsWe generated principal distortions for a nested family of models designed to capture the early visual structure and computations (Fig. 2A,B). The full model (LGN) contains two parallel cascades representing ON and OFF channels, rectification, and both luminance and contrast gain control nonlinearities. The other models are reduced versions of this model. LGG removes the OFF channel, LG additionally removes the contrast gain control, and LN removes both gain controls. The filter size, amplitude, and normalization values were previously fit separately for each model to predict human distortion ratings .

To provide a qualitative comparison of each model's sensitivities to human distortion sensitivity, we adjusted the relative scaling of the principal distortion so as to be equally detectable by that model, while constraining the sum of the norms of the two distortions to be 100 (Fig. 2C). If a model's thresholds are comparable to human thresholds, then these rescaled distortions should be equally detectable when added to the image \(\). Visual inspection of these images reveals that both distortions are visible when rescaled for the LGN model and the LN model, suggesting that these models are closest to human distortion thresholds. For LG, the scaled \(_{2}\) distortion is not visible, while the scaled \(_{1}\) distortion is immediately apparent, suggesting a strong mismatch with human observer thresholds. The same is true of the LGG model, with the roles of the two distortions swapped. These qualitative observations are consistent with the results of , in which experiments on eigen-distortions suggested that the LGN model was the best of these models in terms of consistency with human distortion sensitivity. Formal perceptual experiments could be performed in the future to explicitly quantify the visibility of the principal distortions arising from our analysis. Crucially, measurements of human perceptual sensitivity are costly and our proposed method only requires measuring sensitivity to two distortions (in contrast to eight eigen-distortions).

Deep neural networksDeep Neural Networks (DNNs), originally developed for object recognition, have also been examined as models of the primate visual system . A plethora of models, varying in architecture and training techniques, have been proposed, but many of these models perform quite similarly on behavioral tasks or neural benchmarks . This situation offers a well-aligned opportunity for our principal distortion method. As a demonstration of the method, we measured the FIM of a set of layers from two different architectures (AlexNet  and ResNet50 ) and two different training procedures (standard vs. adversarial training, AT) with \(_{2}\)-norm perturbations , for a total of \(N=28\) different model representations. AT networks were initially developed for engineering purposes to reduce the vulnerability of the models to adversarial examples , but previous work has also found that representations in AT networks are more aligned with those of biological systems . As adversarial examples are constrained to be very small perturbations, it seems plausible that the local geometry for AT models would differ from their standard counterparts.

Figure 2: Principal distortions of a set of early visual models. **A)** Log sensitivity ratios of principal distortions and two random distortions for each of the four models. Principal distortions (filled circles) separate the log ratios, while random distortions (hollow circles) do not. **B)** Natural image \(\) and corresponding optimized principal distortions \(\{_{1},_{2}\}\). **C)** Natural image corrupted by principal distortions, with each pair scaled so as to be equally detectable by the corresponding model. Models are ordered by the log ratio of their sensitivities (panel A). If a model’s thresholds are comparable to human thresholds, the two scaled distortions should be equally visible in the top and bottom images. Note: Distorted images are best viewed at high resolution.

We show an example principal distortion generated for the set of layers from the four DNNs (Fig. 3). The hierarchical structure of the models is reflected in the log ratios of the sensitivities, where early layers of the models (smaller dots) are closer together in the metric space, and later layers of the models (larger dots) are pushed further away. Overall, most layers of the standard networks are more sensitive to the distortion that appears as unstructured noise, while most layers of the AT networks are more sensitive to the structured distortion. This qualitative example provides a demonstration that our method can be used to separate collections of similar models, and points to its utility in probing complex high-level representations.

## 4 Discussion

We introduced a metric for image representations that captures the local geometry, and used it to synthesize "principal distortions" that maximize the variance of this metric over a set of models. When applied to hand-engineered models of the early visual system and to standard and AT DNNs, our approach produced novel distortions for distinguishing the corresponding models.

The relation to the Fisher-Rao metric (Appx. B) suggests an extension for synthesizing more than two distortions. Additionally, there is a natural extension to continuous families of models. We plan to explore these directions in future work.

These distortions provide an efficient method for comparing computational models with human observers, for whom the experimental time for acquiring responses to stimuli is generally severely limited. The optimized distortions are a parsimonious choice of stimuli, that can be readily incorporated into psychophysics experiments, whose results can guide further model development.