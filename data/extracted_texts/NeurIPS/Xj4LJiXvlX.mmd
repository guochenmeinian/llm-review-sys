# Batch Bayesian Optimization for

Replicable Experimental Design

 Zhongxiang Dai\({}^{1}\), Quoc Phong Nguyen\({}^{2}\), Sebastian Shenghong Tay\({}^{1,4}\), Daisuke Urano\({}^{5}\), Richalynn Leong\({}^{5}\), Bryan Kian Hsiang Low\({}^{1}\), Patrick Jaillet\({}^{2,3}\)

\({}^{1}\)Department of Computer Science, National University of Singapore

\({}^{2}\)LIDS and \({}^{3}\)EECS, Massachusetts Institute of Technology

\({}^{4}\)Institute for Infocomm Research (I2R), A*STAR, Singapore

\({}^{5}\)Temasek Life Sciences Laboratory, Singapore

dzx@nus.edu.sg, qphongmp@gmail.com, sebastian.tay@u.nus.edu, {daisuke, richalynn}@tll.org.sg, lowkh@comp.nus.edu.sg, jaillet@mit.edu

###### Abstract

Many real-world experimental design problems _(a)_ evaluate multiple experimental conditions in parallel and _(b)_ replicate each condition multiple times due to large and heteroscedastic observation noise. Given a fixed total budget, this naturally induces a trade-off between _evaluating more unique conditions while replicating each of them fewer times_ vs. _evaluating fewer unique conditions and replicating each more times_. Moreover, in these problems, practitioners may be risk-averse and hence prefer an input with both good average performance and small variability. To tackle both challenges, we propose the _Batch Thompson Sampling for Replicable Experimental Design_ (BTS-RED) framework, which encompasses three algorithms. Our BTS-RED-Known and BTS-RED-Unknown algorithms, for, respectively, known and unknown noise variance, choose the number of replications _adaptively_ rather than deterministically such that an input with a larger noise variance is replicated more times. As a result, despite the noise heteroscedasticity, both algorithms enjoy a theoretical guarantee and are _asymptotically no-regret_. Our Mean-Var-BTS-RED algorithm aims at risk-averse optimization and is also asymptotically no-regret. We also show the effectiveness of our algorithms in two practical real-world applications: precision agriculture and AutoML.

## 1 Introduction

_Bayesian optimization_ (BO), which is a sequential algorithm for optimizing black-box and expensive-to-evaluate functions [14; 15], has found application in a wide range of experimental design problems . Many such applications which use BO to accelerate the scientific discovery process  fall under the umbrella of AI for science (_AI4Science_). Many real-world experimental design problems, such as precision agriculture, share two inherent characteristics: _(a)_ multiple experimental conditions are usually evaluated in parallel to take full advantage of the available experimental budget; _(b)_ the evaluation of every experimental condition is usually _replicated_ multiple times  because every experiment may be associated with a large and heteroscedastic (i.e., input-dependent) observation noise, in which case replication usually leads to better performances [2; 33; 43]. Replicating each evaluated experimental condition is also a natural choice in experimental design problems in which it incurs considerable setup costs to test every new experimental condition. This naturally induces an interesting challenge regarding the trade-off between input selection and replication: in every iteration of BO where we are given a fixed total experimental budget, should we _evaluate more unique experimental conditions and replicate each of them fewer times_ or _evaluate fewer unique conditions and replicate each more times_? Interestingly, this trade-off is also commonly found inother applications such as automated machine learning (AutoML), in which parallel evaluations are often adopted to exploit all available resources  and heteroscedasticity is a prevalent issue . Furthermore, these experimental design problems with large and _heteroscedastic noise_ are often faced with another recurring challenge: instead of an input experimental condition (e.g., a hyperparameter configuration for an ML model) that produces a good performance (e.g., large validation accuracy) on average, some practitioners may be _risk-averse_ and instead prefer an input that both yields a good average performance and has small variability. As a result, instead of only maximizing the mean of the black-box function, these risk-averse practitioners may instead look for inputs with both a large mean function value and a small noise variance [26; 33].

In this work, we provide solutions to both challenges in a principled way by proposing the framework of _Batch Thompson Sampling for Replicable Experimental Design_ (BTS-RED). The first challenge regarding the trade-off between input selection and replication is tackled by the first two incarnations of our framework: the BTS-RED-Known (Sec. 3.1) and BTS-RED-Unknown (Sec. 3.2) algorithms, which are applicable to scenarios where the noise variance function is known or unknown, respectively. For batch selection, we adopt the Thompson sampling (TS) strategy because its inherent randomness makes it particularly simple to select a batch of inputs . Moreover, previous works on BO have shown that the use of TS both allows for the derivation of theoretical guarantees [16; 28] and leads to strong empirical performances [16; 20]. For replication selection, instead of the common practice of replicating every queried input a fixed number of times, we _choose the number of replications adaptively depending on the observation noise_. Specifically, in every iteration, both algorithms repeat the following two steps until the total budget is exhausted: _(a)_ choose an input query following the TS strategy, and then _(b)_ adaptively choose the number of replications for the selected input such that _an input with a larger noise variance is replicated more times_. Of note, in spite of the noise heteroscedasticity, our principled approach to choosing the number of replications ensures that the _effective noise variance_\(R^{2}\) of every queried input is the same (Sec. 3.1). This allows us to derive an upper bound on their cumulative regret and show that they are _asymptotically no-regret_. Our theoretical guarantee formalizes the impact of the properties of the experiments, i.e., our regret upper bound becomes better if the total budget is increased or if the overall noise level is reduced. Importantly, our theoretical result provides a guideline on the choice of the effective noise variance parameter \(R^{2}\), which is achieved by minimizing the regret upper bound and allows \(R^{2}\) to automatically adapt to the budgets and noise levels of different experiments (Sec. 3.1.2).

To handle the second challenge of risk-averse optimization, we propose the third variant of our BTS-RED framework named Mean-Var-BTS-RED (Sec. 4), which is a natural extension of BTS-RED-Unknown. Mean-Var-BTS-RED aims to maximize the mean-variance objective function, which is a weighted combination of the mean objective function and negative noise variance function (Sec. 2). We prove an upper bound on the mean-variance cumulative regret of Mean-Var-BTS-RED (Sec. 4) and show that it is also _asymptotically no-regret_.

In addition to our theoretical contributions, we also demonstrate the practical efficacy of our algorithms in two real-world problems (Sec. 5). Firstly, in real-world precision agriculture experiments, plant biologists usually _(a)_ evaluate multiple growing conditions in parallel, and _(b)_ replicate each condition multiple times to get a reliable outcome . Moreover, plant biologists often prefer more replicable conditions, i.e., inputs with small noise variances. This is hence an ideal application for our algorithms. So, we conduct an experiment using real-world data on plant growths, to show the effectiveness of our algorithms in precision agriculture (Sec. 5.2). Next, we also apply our algorithms to AutoML to find hyperparameter configurations with competitive and _reproducible_ results across different AutoML tasks (Sec. 5.3). The efficacy of our algorithms demonstrates their capability to improve the reproducibility of AutoML tasks which is an important issue in AutoML .

## 2 Background

We denote by \(f:\) the objective function we wish to maximize, and by \(^{2}:^{+}\) the input-dependent noise variance function. We denote the minimum and maximum noise variance as \(^{2}_{}\) and \(^{2}_{}\). For simplicity, we assume that the domain \(\) is finite, since extension to compact domains can be easily achieved via suitable discretizations . After querying an input \(\), we observe a noisy output \(y=f()+\) where \((0,^{2}())\). In every iteration \(t\), we select a batch of \(b_{t} 1\) inputs \(\{_{t}^{(b)}\}_{b=1,,b_{t}}\), and query every \(_{t}^{(b)}\) with \(n_{t}^{(b)} 1\) parallel processes. We denote the _total budget_ as \(\) such that \(_{b=1}^{b_{t}}n_{t}^{(b)}, t 1\). We model the function using a _Gaussian process_ (GP) : \(((),k(,))\), where \(()\) is a mean function which we assume w.l.o.g. \(()=0\) and \(k(,)\) is a kernel function for which we focus on the commonly used _squared exponential_ (SE) kernel. In iteration \(t\), we use the observation history in the first \(t-1\) iterations (batches) to calculate the GP posterior \((_{t-1}(),^{2}_{t-1}(,))\), in which \(_{t-1}()\) and \(^{2}_{t-1}(,)\) represent the GP posterior mean and covariance functions (details in Appendix A). For BTS-RED-Unknown and Mean-Var-BTS-RED (i.e., when \(^{2}()\) is unknown), we use another GP, denoted as \(^{}\), to model \(-^{2}()\) (Sec. 3.2), and denote its posterior as \(^{}(^{}_{t-1}(),^{ 2}_{t-1}(, ))\).

In our theoretical analysis of BTS-RED-Known and BTS-RED-Unknown where we aim to maximize \(f\), we follow previous works on batch BO [18; 11; 35] and derive an upper bound on the _batch cumulative regret_\(R_{T}=_{t=1}^{T}_{b[b_{t}]}[f(^{*})-f(^{(b)}_{t})]\), in which \(^{*}*{arg\,max}_{}f()\) and we have used \([b_{t}]\) to denote \(\{1,,b_{t}\}\). We show (Sec. 3) that both BTS-RED-Known and BTS-RED-Unknown enjoy a sub-linear upper bound on \(R_{T}\), which suggests that as \(T\) increases, a global optimum \(^{*}\) is guaranteed to be queried since the _batch simple regret_\(S_{T}=_{t[T]}_{b[b_{t}]}[f(^{*})-f(^{(b)}_{t})]  R_{T}/T\) goes to \(0\) asymptotically. We analyze the batch cumulative regret because it allows us to show the benefit of batch evaluations, and our analysis can also be modified to give an upper on the sequential cumulative regret of \(R^{}_{T}=_{t=1}^{T}_{b=1}^{b_{t}}[f(^{*})-f(^{(b)}_{ t})]\) (Appendix D). Our Mean-Var-BTS-RED aims to maximize the _mean-variance objective function_\(h_{}()= f()-(1-)^{2}()= f( )+(1-)g()\), in which we have defined \(g()-^{2}(),\). The user-specified weight parameter \(\) reflects our relative preference for larger mean function values or smaller noise variances. Define the _mean-variance batch cumulative regret_ as \(R^{}_{T}=_{t=1}^{T}_{b[b_{t}]}[h_{}(^{*}_{ })-h_{}(^{(b)}_{t})]\) where \(^{*}_{}*{arg\,max}_{}h_{ }()\). We also prove a sub-linear upper bound on \(R^{}_{T}\) for Mean-Var-BTS-RED (Sec. 4).

## 3 BTS-RED-Known and BTS-RED-Unknown

Here, we firstly introduce BTS-RED-Known and its theoretical guarantees (Sec. 3.1), and then discuss how it can be extended to derive BTS-RED-Unknown (Sec. 3.2).

### BTS-RED with Known Noise Variance Function

#### 3.1.1 BTS-RED-Known

```
1:for\(t=1,2,,T\)do
2:\(b=0,n^{(0)}_{t}=0\)
3:while\(_{b^{}=0}^{b}n^{(b^{})}_{t}<\)do
4:\(b b+1\)
5: Sample a function \(f^{(b)}_{t}\) from the GP posterior of \((_{t-1}(),^{2}_{t}^{2}_{t-1}(,))\) (Sec. 2)
6: Choose \(^{(b)}_{t}=*{arg\,max}_{}f^{(b)}_{t}( )\) and \(n^{(b)}_{t}=^{2}(^{(b)}_{t})/R^{2}\)
7:\(b_{t}=b-1\)
8:for\(b[b_{t}]\), query \(^{(b)}_{t}\) with \(n^{(b)}_{t}\) parallel processes
9:for\(b[b_{t}]\), observe \(\{y^{(b)}_{t,n}\}_{n[n^{(b)}_{t}]}\). Calculate their empirical mean \(y^{(b)}_{t}=(1/n^{(b)}_{t})_{n=1}^{n^{(b)}_{t}}y^{(b)}_{t,n}\)
10: Use \(\{(^{(b)}_{t},y^{(b)}_{t})\}_{b[b_{t}]}\) to update posterior of \(\) ```

**Algorithm 1** BTS-RED-Known.

BTS-RED-Known (Algo. 1) assumes that \(^{2}()\) is known. In every iteration \(t\), to sequentially select every \(^{(b)}_{t}\) and its corresponding \(n^{(b)}_{t}\), we repeat the following process until the total number of replications has consumed the total budget \(\) (i.e., until \(_{b^{}=1}^{b}n^{(b^{})}_{t}\), line 3 of Algo. 1):

* **line 5**: sample a function \(f^{(b)}_{t}\) from \((_{t-1}(),^{2}_{t}^{2}_{t-1}(,))\) (\(_{t}\) will be defined in Theorem 3.1);
* **line 6**: choose \(^{(b)}_{t}=*{arg\,max}_{}f^{(b)}_{t}( )\) by maximizing the sampled function \(f^{(b)}_{t}\), and choose \(n^{(b)}_{t}=^{2}(^{(b)}_{t})/R^{2}\), where \(\) is the ceiling operator and \(R^{2}\) is the _effective noise variance_.

After the entire batch of \(b_{t}\) inputs have been selected, every \(^{(b)}_{t}\) is queried with \(n^{(b)}_{t}\) parallel processes (line 8), and the empirical mean \(y^{(b)}_{t}\) of these \(n^{(b)}_{t}\) observations is calculated (line 9).

Finally, \(\{(_{t}^{(b)},y_{t}^{(b)})\}_{b[b_{t}]}\) are used to update the posterior of \(\) (line 10). Of note, since the observation noise is assumed to be Gaussian-distributed with a variance of \(^{2}(_{t}^{(b)})\) (Sec. 2), after querying \(_{t}^{(b)}\) independently for \(n_{t}^{(b)}\) times, the empirical mean \(y_{t}^{(b)}\) follows a Gaussian distribution with noise variance \(^{2}(_{t}^{(b)})/n_{t}^{(b)}\). Next, since we select \(n_{t}^{(b)}\) by \(n_{t}^{(b)}=^{2}(_{t}^{(b)})/R^{2}\) (line 6), \(^{2}(_{t}^{(b)})/n_{t}^{(b)}\) is guaranteed to be upper-bounded by \(R^{2}\). In other words, _every observed empirical mean \(y_{t}^{(b)}\) follows a Gaussian distribution with a noise variance that is upper-bounded by the effective noise variance \(R^{2}\)_. This is crucial for our theoretical analysis since it ensures that the effective noise variance is \(R\)-sub-Gaussian and thus preserves the validity of the GP-based confidence bound .

In practice, since our BTS-RED-Known algorithm only aims to maximize the objective function \(f\) (i.e., we are not concerned about learning the noise variance function), some replications may be wasted on undesirable input queries (i.e., those with small values of \(f()\)) especially in the initial stage when our algorithm favours exploration. To take this into account, we adopt a simple heuristic: we impose a maximum number of replications denoted as \(n_{}\), and set \(n_{}=/2\) in the first \(T/2\) iterations and \(n_{}=\) afterwards. This corresponds to favouring exploration of more inputs (each with less replications) initially and preferring exploitation in later stages. This technique is also used for BTS-RED-Unknown (Sec. 3.2) yet not adopted for Mean-Var-BTS-RED (Sec. 4) since in mean-variance optimization, we also aim to learn (and minimize) the noise variance function.

Due to our stopping criterion for batch selection (line \(3\)), in practice, some budgets may be unused in an iteration. E.g., when \(=50\), if \(_{b^{}=1}^{b-1}n_{t}^{(b^{})}=43\) after the first \(b-1\) selected queries and the newly selected \(n_{t}\) for the \(b^{}\) query \(_{t}^{(b)}\) is \(n_{t}^{(b)}=12\), then the termination criterion is met (i.e., \(_{b^{}=1}^{b}n_{t}^{(b^{})}\)) and only \(43/50\) of the budgets are used. So, we adopt a simple technique: in the example above, we firstly evaluate the last selected \(_{t}^{(b)}\) for \(7\) times, and in the next iteration \(t+1\), we start by completing the unfinished evaluation of \(_{t}^{(b)}\) by allocating \(12-7=5\) replications to \(_{t}^{(b)}\). Next, we run iteration \(t+1\) with the remaining budget, i.e., we let \(=50-5=45\) in iteration \(t+1\).

#### 3.1.2 Theoretical Analysis of BTS-RED-Known

Following the common practice in BO , we assume \(f\) lies in a _reproducing kernel Hilbert space_ (RKHS) induced by an SE kernel \(k\): \(\|f\|_{_{k}} B\) for some \(B>0\) where \(\|\|_{_{k}}\) denotes the RKHS norm. Theorem 3.1 below gives a regret upper bound of BTS-RED-Known (proof in Appendix B).

**Theorem 3.1** (BTS-RED-Known).: _Choose \((0,1)\). Define \(_{t-1}_{t^{}=1}^{t-1}b_{t^{}}\), and define \(_{t} B+R}+1+(2/))}\) where \(_{_{t-1}}\) denotes the maximum information gain about \(f\) from any \(_{t-1}\) observations. With probability of at least \(1-\) (\(}\) ignores all log factors),_

\[R_{T}=}e^{C}// ^{2}}{R^{2}}-1}}}( +}}).\]

\(C\) _is a constant s.t. \(_{A,|A|}(f;_{A}|_{ 1:t-1}) C, t 1\). \((f;_{A}|_{1:t-1})\) is the information gain from observations \(_{A}\) at inputs \(A\), given observations \(_{1:t-1}\) in the first \(t-1\) iterations._

It has been shown by  that by running uncertainty sampling (i.e., choosing the initial inputs by sequentially maximizing the GP posterior variance) as the initialization phase for a finite number (independent of \(T\)) of iterations, \(C\) can be chosen to be a constant independent of \(\) and \(T\). As a result, the regret upper bound from Theorem 3.1 can be simplified into \(R_{T}=}/(/^{2}}{R^{2}}-1)}}}(1+}})\). Therefore, for the SE kernel for which \(_{T}=(^{d+1}(T))\), our regret upper bound is sub-linear, which indicates that our BTS-RED-Known is _asymptotically no-regret_. Moreover, the benefit of a larger total budget \(\) is also reflected from our regret upper bound since it depends on the total budget \(\) via \(}((^{d+1}(T)+^{(d+1)/2}(T))/ })\), which is decreasing as the total budget \(\) increases. In addition, the regret upper bound is decreased if \(_{}^{2}\) becomes smaller, which implies that the performance of our algorithm is improved if the overall noise level is reduced. Therefore, Theorem 3.1 formalizes the impacts of the experimental properties (i.e., the total budget and the overall noise level) on the performance of BTS-RED-Known.

**Homoscedastic Noise.** In the special case of homoscedastic noise, i.e., \(^{2}()=_{}^{2},\), then \(n_{t}=_{}^{2}/R^{2} n_{}\) and \(b_{t}=/n_{} b_{0}, t[T]\). That is, our algorithm reducesto standard (synchronous) batch TS proposed in  where the batch size is \(b_{0}\) and every query is replicated \(n_{}\) times. In this case, the regret upper bound becomes: \(R_{T}=}(R}}}}(1+ }}))\) (Appendix B.1).

**Theoretical Guideline on the Choice of \(R^{2}\).** Theorem 3.1 also provides an interesting insight on the choice of the effective noise variance \(R^{2}\). In particular, our regret upper bound depends on \(R^{2}\) through the term \(/[/(_{}^{2}/R^{2}+1)-1]}\).1 By taking the derivative of this term w.r.t. \(R^{2}\), we have shown (Appendix C) that the value of \(R^{2}\) that minimizes this term is obtained at \(R^{2}=_{}^{2}(}+1)/(-1)\). In other words, \(R^{2}\) should be chosen as a fraction of \(_{}^{2}\) (assuming \(>4\) s.t. \((}+1)/(-1)<1\)). In this case, increasing the total budget \(\) naturally encourages more replications. Specifically, increasing \(\) reduces \((}+1)/(-1)\) and hence decreases the value of \(R^{2}\), which consequently encourages the use of larger \(n_{t}\)'s (line 6 of Algo. 1) and allows every selected input to be replicated more times. For example, when the total budget is \(=16\), \(R^{2}\) should be chosen as \(R^{2}=_{}^{2}/3\); when \(=100\), then we have \(R^{2}=_{}^{2}/9\). We will follow this theory-inspired choice of \(R^{2}\) in our experiments in Sec. 5 (with slight modifications).

**Improvement over Uniform Sample Allocation.** For the naive baseline of uniform sample allocation (i.e., replicating every input a fixed number \(n_{0}\) of times), the resulting effective observation noise would be \((_{}/})\)-sub-Gaussian. This would result in a regret upper bound which can be obtained by replacing the term \(/(/^{2}}{R^{2}}-1)}\) (Theorem 3.1) by \(_{}/}\) (for simplicity, we have ignored the non-integer conditions, i.e., the ceiling operators). Also note that with our optimal choice of \(R^{2}\) (the paragraph above), it can be easily verified that the term \(/(/^{2}}{R^{2}}-1)}\) (Theorem 3.1) can be simplified to \(_{}/}\). Therefore, given that \(n_{0}\), our regret upper bound (with the scaling of \(_{}/}\)) is guaranteed to be no worse than that of uniform sample allocation (with the scaling of \(_{}/}\)).

### BTS-RED with Unknown Noise Variance Function

Here we consider the more common scenario where the noise variance function \(^{2}()\) is unknown by extending BTS-RED-Known while preserving its theoretical guarantee.

#### 3.2.1 Modeling of Noise Variance Function

We use a separate GP (denoted as \(^{}\)) to model the negative noise variance function \(g()=-^{2}()\) and use it to build a high-probability upper bound \(U_{t}^{^{2}}()\) on the noise variance function \(^{2}()\).2 After this, we can modify the criteria for selecting \(n_{t}^{(b)}\) (i.e., line 6 of Algo. 1) to be \(n_{t}^{(b)}= U_{t}^{^{2}}(_{t}^{(b)})/R^{2}\), which ensures that \(U_{t}^{^{2}}(_{t}^{(b)})/n_{t}^{(b)} R^{2}\). As a result, the condition of \(^{2}(_{t}^{(b)})/n_{t}^{(b)} R^{2}\) is still satisfied (with high probability), which implies that _the observed empirical mean at every queried \(_{t}^{(b)}\) is still \(R-\)sub-Gaussian_ (Sec. 3.1.1) and theoretical guarantee of Theorem 3.1 is preserved. To construct \(^{}\), we use the (negated) unbiased empirical noise variance \(_{t}^{(b)}\) as the noisy observation:

\[_{t}^{(b)}=-1/(n_{t}^{(b)}-1)_{n_{t}^{(b)}}^{n_{t} ^{(b)}}(y_{t,n}^{(b)}-y_{t}^{(b)})^{2}=g(_{t}^{(b)})+^{}\] (1)

where \(g(_{t}^{(b)})=-^{2}(_{t}^{(b)})\) is the negative noise variance at \(_{t}^{(b)}\), and \(^{}\) is the noise. In BTS-RED-Unknown, we use pairs of \(\{(_{t}^{(b)},_{t}^{(b)})\}\) to update the posterior of \(^{}\). We impose a minimum number of replications \(n_{} 2\) for every queried input to ensure reliable estimations of \(_{t}^{(b)}\).

#### 3.2.2 Upper Bound on Noise Variance Function

**Assumptions.** Similar to Theorem 3.1, we assume that \(g\) lies in an RKHS associated with an SE kernel \(k^{}\): \( g_{_{k^{}}} B^{}\) for some \(B^{}>0\), which intuitively assumes that _the (negative) noise variance _varies smoothly across the domain \(\)._ We also assume that the noise \(^{}\) is \(R^{}\)-sub-Gaussian and justify this below by showing that \(^{}\) is bounded (with high probability).

\(^{}\) **is \(R^{}\)-sub-Gaussian.** Since the empirical variance of a Gaussian distribution (1) follows a Chi-squared distribution, we can use the concentration of Chi-squared distributions to show that with probability of \( 1-\), \(^{}\) is bounded within \([L_{},U_{}]\), where \(L_{}=_{}^{2}(_{n_{}-1,/2}^{2}/(n_{}-1)-1),U_ {}=_{}^{2}(_{n_{}-1,1-/2}^{2}/(n_{}-1)-1)\). Here \(_{n_{}-1,}^{2}\) denotes \(^{}\)-quantile of the Chi-squared distribution with \(n_{}-1\) degrees of freedom (\(=/2\) or \(1-/2\)). By choosing \(=/(4T)\) (\(\) is from Theorem 3.1), we can ensure that with probability of \( 1-/4\), \(^{}\) is bounded within \([L_{},U_{}]\) for all \(_{i}^{[b]}\). In other words, with probability of \( 1-/4\), the noise \(^{}\) in (1) is zero-mean and bounded within \([L_{},U_{}]\), which indicates that \(^{}\) is \(R^{}\)-sub-Gaussian with \(R^{}=(U_{}-L_{})/2\). More details are given in Appendix E. Note that the value of \(R^{}\) derived here is expected to be overly pessimistic, so, we expect smaller values of \(R^{}\) to be applicable in practice.

**Upper Bound Construction.** With the assumptions of \(\|g\|_{_{k^{}}} B^{}\) and \(^{}\) is \(R^{}\)-sub-Gaussian, we can construct the upper bound \(U_{t}^{^{2}}()\). Denote by \(^{}_{_{t-1}}\) the maximum information gain about \(g\) from any \(_{t-1}=_{t^{}=1}^{t-1}b_{t^{}}\) observations, define \(^{}_{t} B^{}+R^{}_{ _{t-1}}+1+(4/))}\), and represent the GP posterior mean and standard deviation for \(^{}\) as \(^{}_{t-1}()\) and \(^{}_{t-1}()\). Then we have that

\[|^{}_{t-1}()-g()|^{}_{t}^{}_{ t-1}(),,t[T]\] (2)

with probability of \( 1-/2\). The error probabilities come from applying Theorem 2 of  (\(/4\)) and assuming that \(^{}\) is \(R^{}\)-sub-Gaussian (\(/4\)). This implies that \(-^{2}()=g()^{}_{t-1}()-^{}_{t} ^{}_{t-1}()\), and hence \(^{2}()-^{}_{t-1}()+^{}_{t}^{ }_{t-1}(),,t[T]\). Therefore, we can choose the upper bound on the noise variance (Sec. 3.2.1) as \(U_{t}^{^{2}}()=-^{}_{t-1}()+^{}_{t} ^{}_{t-1}()\).

**BTS-RED-Unknown Algorithm.** To summarize, we can obtain BTS-RED-Unknown (Algo. 3, Appendix F) by modifying the selection criterion of \(n_{t}\) (line 6 of Algo. 1) to be \(n_{t}^{(b)}=(-^{}_{t-1}(^{(b)}_{t})+^{}_{t} ^{}_{t-1}(^{(b)}_{t}))/R^{2}\). As a result, BTS-RED-Unknown enjoys the same regret upper bound as Theorem 3.1 (after replacing \(\) in Theorem 3.1 by \(/2\)). Intuitively, using an upper bound \(U_{t}^{^{2}}(^{(b)}_{t})\) in the selection of \(n_{t}\) implies that if we are uncertain about the noise variance at some input location \(^{(b)}_{t}\) (i.e., if \(^{}_{t-1}(^{(b)}_{t})\) is large), we choose to be _conservative_ and use a large number of replications \(n_{t}\).

## 4 Mean-Var-BTS-RED

We extend BTS-RED-Unknown (Sec. 3.2) to maximize the mean-variance objective function: \(h_{}()= f()-(1-)^{2}()\), to introduce Mean-Var-BTS-RED (Algo. 2). In contrast to BTS-RED-Unknown, Mean-Var-BTS-RED chooses every input query \(^{(b)}_{t}\) by maximizing the weighted combination of two functions sampled from, respectively, the posteriors of \(\) and \(^{}\) (lines 5-6 of Algo. 2), while \(n_{t}\) is chosen (line 7 of Algo. 2) in the same way as BTS-RED-Unknown. This naturally induces a preference for inputs with both large values of \(f\) and small values of \(^{2}()\), and hence allows us to derive an upper bound on \(R^{}_{T}\) (proof in Appendix G):

**Theorem 4.1** (Mean-Var-BTS-RED).: _With probability of at least \(1-\),_

\[R^{}_{T}=}}{/}^{2}}{R^{2}}-1}} R }}(}}+)+(1-)R ^{}_{T}}(_{T}}+).\]

\(C\) _is a constant s.t. \(_{A,|A|}(f;_{A}|_{1: t-1}) C\), \(_{A,|A|}(g;}_{A}| }_{1:t-1}) C\)._

Note that \(_{T}\) and \(^{}_{T}\) may differ since the SE kernels \(k\) and \(k^{}\), which are used to model \(f\) and \(g\) respectively, may be different. Similar to Theorem 3.1, if we run uncertainty sampling for a finite number (independent of \(T\)) of initial iterations using either \(k\) or \(k^{}\) (depending on whose lengthscale is smaller), then \(C\) can be chosen to be a constant independent of \(\) and \(T\). Refer to Lemma G.6 (Appendix G) for more details. As a result, the regret upper bound in Theorem 4.1 is also sub-linear since both \(k\) and \(k^{}\) are SE kernels and hence \(_{T}=(^{d+1}(T))\) and \(^{}_{T}=(^{d+1}(T))\). The regret upper bound can be viewed as a weighted combination of the regrets associated with \(f\) and \(g\). Intuitively, if \(\) is larger (i.e., if we place more emphasis on maximizing \(f\) than \(g\)), then a larger proportion of the regrets is incurred due to our attempt to maximize the function \(f\).

```
1:for\(t=1,2,,T\)do
2:\(b=0,n_{t}^{(0)}=0\)
3:while\(_{b^{}=0}^{b}n_{t}^{(b^{})}<\)do
4:\(b 0\) + \(t\) ```
5: Sample \(f_{t}^{(b)}\) from \((_{t-1}(),_{t}^{2}_{t-1}^{2}(,))\), and \(g_{t}^{(b)}\) from \(^{}(_{t-1}^{}(),{_{t}^{}}^{2}{ _{t-1}^{}}^{2}(,))\)
6:\(_{t}^{(b)}=_{}[ f_{t}^{(b)}()+(1- )g_{t}^{(b)}()]\)
7:\(n_{t}^{(b)}=[(-_{t-1}^{}(_{t}^{(b)})+_{t}^{} _{t-1}^{}(_{t}^{(b)}))/R^{2}\)
8:\(b_{t}=b-1\)
9:for\(b[b_{t}]\), query \(_{t}^{(b)}\) with \(n_{t}^{(b)}\) parallel processes
10:for\(b[b_{t}]\), observe \(\{y_{t,n}^{(b)}\}_{n[n_{t}^{(b)}]}\). Calculate their mean \(y_{t}^{(b)}\) and (negated) variance \(_{t}^{(b)}\) (1)
11: Use \(\{(_{t}^{(b)},y_{t}^{(b)})\}_{b[b_{t}]}\) to update posterior \(\), \(\{(_{t}^{(b)},_{t}^{(b)})\}_{b[b_{t}]}\) to update posterior \(^{}\) ```

**Algorithm 2** Mean-Var-BTS-RED.

## 5 Experiments

For BTS-RED-Known and BTS-RED-Unknown which only aim to maximize the objective function \(f\), we set \(n_{}=/2\) in the first \(T/2\) iterations and \(n_{}=\) subsequently (see Sec. 3.1.1 for more details), and set \(n_{}=\) in all iterations for Mean-Var-BTS-RED. We set \(n_{}=2\) unless specified otherwise, however, it is recommended to make \(n_{}\) larger in experiments where the overall noise variance is large (e.g., we let \(n_{}=5\) in Sec. 5.2). We use random search to select the initial inputs instead of the uncertainty sampling initialization method indicated by our theoretical results (Sec. 3.1.2) because previous work  and our empirical results show that they lead to similar performances (Fig. 8 in App. H.1). We choose the effective noise variance \(R^{2}\) by following our theoretical guideline in Sec. 3.1.2, i.e., \(R^{2}=_{}^{2}(}+1)/(-1)\) which minimizes the regret upper bound in Theorem 3.1.3 However, in practice, this choice may not be optimal because we derived it by minimizing an upper bound which is potentially loose (e.g., we have ignored all log factors). So, we introduce a tunable parameter \(>0\) and choose \(R^{2}\) as \(R^{2}=_{}^{2}(}+1)/(-1)\). As a result, we both enjoy the flexibility of tuning our preference for the overall number of replications (i.e., a smaller \(\) leads to larger \(n_{t}\)'s in general) and preserve the ability to automatically adapt to the total budget (via \(\)) and the overall noise level (via \(_{}^{2}\)). When the noise variance is unknown (i.e., \(_{}^{2}\) is unknown), we approximate \(_{}^{2}\) by the maximum observed empirical noise variance and update our approximation after every iteration. To demonstrate the robustness of our methods, we only use two values of \(=0.2\) and \(=0.3\) in all experiments. Of note, our methods with \(=0.3\) perform the best in almost all experiments (i.e., green curves in all figures), and \(=0.2\) also consistently performs well.

Following the common practice of BO , we plot the (batch) simple regret or the best observed function value up to an iteration. In all experiments, we compare with the most natural baseline of batch TS with a fixed number of replications. For mean optimization problems (i.e., maximize \(f\)), we also compare with standard sequential BO algorithms such as GP-UCB and GP-TS, but they are significantly outperformed by both our algorithms and batch TS which are able to exploit batch evaluations (Secs. 5.1 and 5.2). Therefore, we do not expect existing _sequential_ algorithms to achieve comparable performances to our algorithms due to their inability to exploit batch evaluations. For mean-variance optimization, we additionally compare with the recently introduced Risk-Averse Heteroscedastic BO (RAHBO)  (Sec. 6), which is the state-of-the-art method for risk-averse BO with replications. Some experimental details are postponed to Appendix H.

### Synthetic Experiments

We sample two functions from two different GPs with the SE kernel (defined on a discrete 1-D domain within \(\)) and use them as \(f()\) and \(^{2}()\), respectively. We use \(=50\).

**Mean Optimization.** The mean and noise variance functions used here are visualized in Fig. 0(a). This synthetic experiment is used to simulate real-world scenarios where practitioners are _risk-neutral_ and hence only aim to select an input with a large mean function value. After every iteration (batch) \(t\), an algorithm reports the selected input with the largest empirical mean from its observation history, and we evaluate the _simple regret_ at iteration \(t\) as the difference between the objective function values at the global maximum \(^{*}\) and at the reported input. To demonstrate the consistency of our performance, we also tested an alternative reporting criteria which reports the input with the larger LCB value in every iteration, and the results (Fig. 7b in Appendix H.1) are consistent with our main results (Fig. 1c). Fig. 1b plots the average \(n_{t}\) (vertical axis) chosen by BTS-RED-Unknown for every queried input (horizontal axis), which shows that larger \(n_{t}\)'s are selected for inputs with larger noise variances in general and that a smaller \(=0.2\) indeed increases our preference for larger \(n_{t}\)'s.

The results (simple regrets) are shown in Fig. 1c. As can be seen from the figure, for Batch TS with a fixed \(n_{t}\), smaller values of \(n_{t}\) such as \(n_{t}=5\) usually lead to faster convergence initially due to the ability to quickly explore more unique inputs, however, their performances deteriorate significantly in the long run due to inaccurate estimations; in contrast, larger \(n_{t}\)'s such as \(n_{t}=20\) result in slower convergence initially yet lead to better performances (than small fixed \(n_{t}\)'s) in later stages. Of note, Batch TS with \(n_{t}=1\) (gray curve) represents standard batch TS (\(=50\)) without replications , which underperforms significantly and hence highlights the importance of replications in experiments with large noise variance. Moreover, our BTS-RED-Known and BTS-RED-Unknown (especially with \(=0.3\)) consistently outperform Batch TS with fixed \(n_{t}\). We also demonstrate our robustness against \(\) in this experiment by showing that our performances are consistent for a wide range of \(\)'s (Fig. 7a in App. H.1). In addition, we show that sequential BO algorithms (i.e., GP-TS, GP-UCB, and GP-UCB with heteroscedastic GP) which cannot exploit batch evaluations fail to achieve comparable performances to batch TS, BTS-RED and BTS-RED-Unknown (Fig. 5 in App. H.1).

**Mean-variance Optimization.** Here we evaluate our Mean-Var-BTS-RED. We simulate this scenario with the synthetic function in Fig. 6a (App. H.1), for which the global maximums of the mean and mean-variance (\(=0.3\)) objective functions are different (Fig. 6b). After every iteration (batch) \(t\), we report the selected input with the largest empirical mean-variance value (i.e., weighted combination of the empirical mean and variance), and evaluate the _mean-variance simple regret_ at iteration \(t\) as the difference between the values of the mean-variance objective function \(h_{}\) at the the global maximum \(^{*}_{}\) and at the reported input. The results (Fig. 1d) show that our Mean-Var-BTS-RED (again especially with \(=0.3\)) outperforms other baselines. Since RAHBO is sequential and uses a fixed number of replications, we use \(=50\) replications for every query for a fair comparison. RAHBO underperforms here which is likely due to its inability to leverage batch evaluations.

### Real-world Experiments on Precision Agriculture

Plant biologists often need to optimize the growing conditions of plants (e.g., the amount of different nutrients) to increase their yield. The common practice of manually tuning one nutrient at a time is considerably inefficient and hence calls for the use of the sample-efficient method of BO. Unfortunately, plant growths are usually (a) time-consuming and (b) associated with large and heteroscedastic noise. So, _according to plant biologists, in real lab experiments,_ (a) _multiple growing conditions are usually tested in parallel_ and (b) _every condition is replicated multiple times to get a reliable outcome_. This naturally induces a trade-off between evaluating more unique growing conditions vs. replicating every condition more times, and is hence an ideal application for our algorithms. We tune the pH value (in \([2.5,6.5]\)) and ammonium concentration (denoted as NH3, in \(\) uM). in order to _maximize the leaf area and minimize the tipburn area_ after harvest. We perform _real lab experiments_ using the input conditions from a regular grid within the 2-D domain, and then use the collected data to learn two separate heteroscedastic GPs for, respectively, leaf area and tipburn area. Each learned GP can output the predicted mean and variance (for leaf area or tipburn area) at every input in the 2-D domain, and can hence be used as the _groundtruth_ mean \(f()\) and noise variance \(^{2}()\) functions. We perform two sets of experiments, with the goal of maximizing (a) the

Figure 1: (a) Synthetic function for mean optimization (Sec. 5.1). (b) Average number of replications \(n_{t}\) for BTS-RED-Unknown. Results for (c) mean and (d) mean-variance optimization.

leaf area and (b) a weighted combination of the leaf area (\( 0.8\)) and negative tipburn area (\( 0.2\)). For both experiments, we run BTS-RED-Unknown and Mean-Var-BTS-RED to maximize the mean and mean-variance objectives (\(=0.975\)), respectively. We set \(=50\), \(n_{}=5\) and \(n_{}=50\).

Fig. 2 shows the results for maximizing the leaf area (a,b) and weighted combination of leaf area and negative tipburn area (c,d). Our BTS-RED-Unknown and Mean-Var-BTS-RED with \(=0.2\) and \(=0.3\) consistently outperform Batch TS, as well as RAHBO in Figs. 1(b) and d. For mean optimization, we also compare with sequential BO methods (Fig. 10 in Appendix H.2), which again are unable to perform comparably with other algorithms that exploit batch evaluations. Figs. 2(a) and b visualize the groundtruth mean and noise variance functions for the leaf area, including the locations of some queried inputs (the selected inputs after every \(4\) iterations) and their corresponding \(n_{t}\)'s. Similarly, Figs. 1(a) and b (Appendix H.2) show the queried inputs and the \(n_{t}\)'s of Mean-Var-BTS-RED (\(=0.975\)), illustrated on heat maps of the mean-variance objective (a) and noise variance functions (b). These figures demonstrate that most of our input queries fall into regions with large (either mean or mean-variance) objective function values (Figs. 2(a) and 1(a)) and that \(n_{t}\) is in general larger at those input locations with larger noise variance (Figs. 2(b) and 1(b)). We have included GIF animations for Figs. 2 and 1(a) in the supplementary material. Our results here showcase the capability of our algorithms to improve the efficiency of real-world experimental design problems.

### Real-World Experiments on AutoML

Reproducibility is an important desiderata in AutoML problems such as hyperparameter tuning , because the performance of a hyperparameter configuration may vary due to a number of factors such as different datasets, parameter initializations, etc. For example, some practitioners may prefer hyperparameter configurations that consistently produce well-performing ML models for different datasets. We adopt the EMNIST dataset which is widely used in multi-task learning [10; 15]. EMNIST consists of images of hand-written characters from different individuals, and each individual corresponds to a separate image classification _task_. Here we tune two SVM hyperparameters: the penalty and RBF kernel parameters, both within \([0.0001,2]\). We firstly construct a uniform 2-D grid of the two hyperparameters and then evaluate every input on the grid using \(100\) tasks (i.e., image classification for \(100\) different individuals) to record the observed mean and variance as the groundtruth mean and variance. Refer to Figs. 0(a), b and c (Appendix H.3) for the constructed mean, variance and mean-variance (\(=0.2\)) functions. Fig. 2(c) and d plot the results (\(=50\)) for mean (c) and mean-variance (d) optimization. Our BTS-RED-Unknown and Mean-Var-BTS-RED with both \(=0.2\) and \(0.3\) perform competitively (again especially \(=0.3\)), which shows their potential to improve the efficiency and reproducibility of AutoML. RAHBO underperforms significantly (hence omitted from Fig. 2(d)), which is likely due to the small noise variance (Fig. 0(b)) which favors methods with small \(n_{t}\)'s. Specifically, methods with small \(n_{t}\)'s can obtain reliable estimations (due to small

Figure 3: (a) Mean and (b) noise variance functions for leaf area, with some selected queries (stars) and their \(n_{t}\)â€™s. (c) Mean and (d) mean-variance optimization for hyper. tuning of SVM (Sec. 5.3).

Figure 2: (a) Mean and (b) mean-variance optimization for the leaf area. (c) Mean and (d) mean-variance optimization for the weighted combination of leaf area and negative tipburn area.

noise variance) while enjoying the advantage of evaluating a large number \(b_{t}\) of unique inputs in every iteration. This makes RAHBO unfavorable since it is a sequential algorithm with \(b_{t}=1\).

**Experiments Using Different Budgets \(\).** Here we test the performances of our algorithms with different budgets (i.e., different from the \(=50\) used in the main experiments above) using the AutoML experiment. The results (Fig. 12 in App. H.3) show that the performance advantages of our algorithms (again especially with \(=0.3\)) are still consistent with a larger or smaller budget.

**Additional Experiments with Higher-Dimensional Inputs.** To further verify the practicality of our proposed algorithms, here we adopt two additional experiments with higher-dimensional continuous input domains. Specifically, we tune \(d=12\) and \(d=14\) parameters of a controller for a Lunar-Lander task and a robot pushing task, respectively, and both experiments have widely used by previous works on high-dimensional BO [16; 20] (more details in App. H.4). In both experiments, the heteroscedastic noises arise from random environemntal factors. The results (Fig. 13 in App. H.4) show that our algorithms, again especially with \(=0.3\), still consistently achieve compelling performances.

## 6 Related Works

BO has been extended to the batch setting in recent years [9; 11; 19; 22; 38; 44; 47]. The work of  proposed a simple batch TS method by exploiting the inherent randomness of TS. Interestingly, as we discussed in Sec. 3.1.2, the method from  is equivalent to a reduced version of our BTS-RED-Known with homoscedastic noise, and our Theorem 3.1 provides a theoretical guarantee on its frequentist regret (in contrast to the Bayesian regret analyzed in ). The work of  aimed to adaptively choose whether to explore a new query or to replicate a previous query. However, their method requires additional heuristic techniques to achieve replications and hence has no theoretical guarantees, in stark contrast to our simple and principled way for replication selection (Sec. 3). Moreover, their method does not support batch evaluations, and is unable to tackle risk-averse optimization. Recently,  proposed to select a batch of queries while balancing exploring new queries and replicating existing ones. However, unlike our simple and principled algorithms, their method requires complicated heuristic procedures for query/replication selection and batch construction, and hence does not have theoretical guarantees. Moreover, their method also only focuses on standard mean optimization and cannot be easily extended for risk-averse optimization.

The work of  used a heteroscedastic GP  as the surrogate model for risk-averse optimization. The works of [6; 26; 36; 37; 42] considered risk-averse BO, however, these works require the ability to observe and select an environmental variable, which is usually either not explicitly defined or uncontrollable in practice (e.g., our experiments in Sec. 5). The recent work of  modified BO to maximize the mean-variance objective and derived theoretical guarantees using results from . Their method use a heteroscedastic GP as the surrogate model and employs another (homoscedastic) GP to model the observation noise variance, in which the second GP is learned by replicating every query for a fixed predetermined number of times. Importantly, all of these works on risk-averse BO have focused only on the sequential setting without support for batch evaluations. Replicating the selected inputs in BO multiple times has also been adopted by the recent works of [7; 13], which have shown that replication can lead to comparable or better theoretical and empirical performances of BO.

## 7 Conclusion

We have introduced the BTS-RED framework, which can trade-off between evaluating more unique conditions vs. replicating each condition more times and can perform risk-averse optimization. We derive theoretical guarantees for our methods to show that they are no-regret, and verify their empirical effectiveness in real-world precision agriculture and AutoML experiments. A potential limitation is that we use a heuristic (rather than principled) technique to handle unused budgets in an iteration (last paragraph of Sec. 3.1.1). Another interesting future work is to incorporate our technique of using an adaptive number of replications (depending on the noise variance) into other batch BO algorithms [18; 22] to further improve their performances. Moreover, it is also interesting to combine our method with the recent line of work on neural bandits [16; 17], which may expand the application of our method to more AI4Science problems.