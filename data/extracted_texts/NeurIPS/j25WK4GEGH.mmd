# Generalizable Person Re-identification via

Balancing Alignment and Uniformity

 Yoonki Cho  Jaeyoon Kim  Woo Jae Kim  Junsik Jung  Sung-Eui Yoon

KAIST

###### Abstract

Domain generalizable person re-identification (DG re-ID) aims to learn discriminative representations that are robust to distributional shifts. While data augmentation is a straightforward solution to improve generalization, certain augmentations exhibit a polarized effect in this task, enhancing in-distribution performance while deteriorating out-of-distribution performance. In this paper, we investigate this phenomenon and reveal that it leads to sparse representation spaces with reduced uniformity. To address this issue, we propose a novel framework, Balancing Alignment and Uniformity (BAU), which effectively mitigates this effect by maintaining a balance between alignment and uniformity. Specifically, BAU incorporates alignment and uniformity losses applied to both original and augmented images and integrates a weighting strategy to assess the reliability of augmented samples, further improving the alignment loss. Additionally, we introduce a domain-specific uniformity loss that promotes uniformity within each source domain, thereby enhancing the learning of domain-invariant features. Extensive experimental results demonstrate that BAU effectively exploits the advantages of data augmentation, which previous studies could not fully utilize, and achieves state-of-the-art performance without requiring complex training procedures. The code is available at https://github.com/yoonkicho/BAU.

## 1 Introduction

Person re-identification (re-ID) aims to match a person with the same identity as a given query across disjoint camera views and different timestamps . Thanks to the discriminative features learned from deep neural networks, significant achievements have been made in this task . However, these learned feature spaces rely on the assumption of independent and identically distributed (_i.i.d._) training and testing data, which leads to substantial performance degradation in unseen domains with distributional shifts. To address this issue, domain generalizable person re-ID (DG re-ID) has emerged, focusing on learning representations that are robust to domain shifts .

Existing DG re-ID methods often leverage advanced network architectures, such as feature normalization modules , domain-specific designs , and the integration of transformers . Alternatively, some approaches employ domain adversarial training  or meta-learning strategies  to learn domain-invariant representations across source domains. Although these studies have shown promising results, they often involve complex training procedures that require significant engineering effort or are prone to training instability .

On the other hand, data augmentation is a straightforward solution to enhance generalization capability by simulating diverse data variations during training. Due to its simplicity and effectiveness, numerous efforts have been made to adopt this approach for various DG tasks . However, in the context of DG re-ID, some data augmentations have been observed to exhibit a polarized effect - improving performance in the source domain while potentially degrading it in thetarget domain. A notable example is Random Erasing , a technique widely used in person re-ID, which has been shown to deteriorate cross-domain re-ID performance [34; 56; 94]. Despite this observation, the underlying causes and potential solutions for this phenomenon remain underexplored.

In this paper, we first investigate the polarized effect of data augmentations in DG re-ID. Recent studies have shown that alignment and uniformity in the representation space are closely related to feature generalizability [21; 49; 57; 65; 80; 81]. Building upon this, we reveal that data augmentations can induce sparse representation spaces with less uniformity, which may be detrimental to the open-set nature of the re-ID task, where learning diverse visual information is crucial for generalization [7; 12; 58; 87]. Based on our analysis, we propose a simple yet effective framework, Balancing Alignment and Uniformity (BAU), which alleviates the polarized effect of data augmentations by maintaining a balance between alignment and uniformity. Specifically, it regularizes the representation space by applying alignment and uniformity losses to both original and augmented images. Additionally, we introduce a weighting strategy that considers the reliability of augmented samples to improve the alignment loss. We further propose a domain-specific uniformity loss to promote uniformity within each source domain, enhancing the learning of domain-invariant features. Consequently, BAU effectively exploits the advantages of data augmentation, which previous studies could not fully utilize, and achieves state-of-the-art performance on various benchmarks.

In summary, our contributions are as follows:

* We investigate the polarized effect of data augmentations in DG re-ID and reveal that they can lead to sparse representation spaces, which are detrimental to generalization.
* We propose a novel BAU framework that mitigates the polarized effect of data augmentations by balancing alignment and uniformity in the representation space. Additionally, we introduce a domain-specific uniformity loss to enhance the learning of domain-invariant representations.
* Through extensive experiments on various benchmarks and protocols, we demonstrate that BAU achieves state-of-the-art performance, even without complex training procedures.

## 2 Related Work

Generalizable Person Re-identification.Domain generalizable person re-identification (DG Re-ID) focuses on learning discriminative representations for person retrieval that are robust across unseen domains with distributional shifts. Significant efforts have been made in this task [2; 4; 17; 52; 60; 71; 82] due to its practicality, as it does not require additional model updates for target data, unlike domain adaptation approaches [19; 22; 23; 54; 102]. Given that learned feature statistics can be biased toward the source domain [5; 24; 47; 76], various feature normalization methods [10; 27; 34; 35; 107] have been proposed to mitigate this domain bias. For instance, SNR  eliminates style bias through feature disentanglement, and GDNorm  refines feature statistics using a Gaussian process. To achieve domain-invariant representations, several studies [10; 61; 71; 90] leverage domain-adversarial training [20; 41] or meta-learning [18; 40]. DDAN  utilizes domain-wise adversarial feature learning to reduce domain discrepancies for domain invariance. M\({}^{3}\)L  employs meta-learning to simulate the train-test process of domain generalization with multi-source datasets. There have also been attempts [50; 51] that explore advanced matching strategies between query and gallery images for retrieval to improve interpretability and generalization performance. Recently, Mixture-of-Experts (MoE) based approaches [12; 33] have emerged, where multiple domain-specific experts are trained and applied to the target domain, with META  alleviating the model scalability issue by domain-specific batch normalization . In contrast, we effectively utilize the diversity provided by data augmentations to enhance generalization without relying on advanced network architectures or encountering training instability associated with adversarial or meta-learning [3; 62; 66].

Alignment and Uniformity.Wang and Isola  proposed that contrastive learning encompasses two main objectives: alignment, which aims to learn similar representations for positive pairs, and uniformity, which strives to distribute representations uniformly on the unit hypersphere. This framework has significantly influenced representation learning by potentially indicating the feature generalizability [49; 57; 63; 65; 77; 80]. For instance, the concepts of alignment and uniformity have been extensively studied to learn robust representations for improved generalizability across various downstream tasks [21; 57; 77] or domains [65; 80]. This approach has also proven effective when applied to multiple data modalities, including images and text [49; 63]. Despite these advances, the potential of alignment and uniformity in addressing the challenge of DG re-ID remains largely unexplored. In this work, we address this gap by applying alignment and uniformity to person re-ID, balancing feature discriminability and generalizability to learn domain-invariant representations.

## 3 Method

Problem Formulation.Given a set of \(K\) source domains, \(_{S}=\{_{k}\}_{k=1}^{K}\), each domain \(_{k}=\{(x_{i},y_{i})\}_{i=1}^{N_{k}}\) consists of images \(x_{i}\) and corresponding identity labels \(y_{i}\), where \(N_{k}\) denotes the number of images in a source domain \(_{k}\). Using these source domains, we train a model \(f_{}\), parameterized by \(\), to extract person representations \(_{i}=f_{}(x_{i})^{d}\) from the image \(x_{i}\), where \(d\) is the dimensionality of the representation space. The trained model is then evaluated on a target domain \(_{T}\), which is unseen during training. While a general _homogeneous_ DG task has a consistent label space across source and target domains within a closed-set setting, generalizable person re-ID is a _heterogeneous_ DG problem, where each domain has a disjoint label space from the others . Consequently, it is an open-set retrieval task where trained models need to identify unseen classes.

### Polarized Effect of Data Augmentation on In- and Out-of-Distribution

Data augmentations, which apply random transformations to input data, are widely used across various tasks to improve training efficiency and model robustness . In the DG re-ID task, however, certain augmentations have shown _a polarized effect: they enhance retrieval performance on in-distribution data while potentially degrading it on out-of-distribution data_. For instance, Random Erasing , which selectively erases pixels from parts of input images, has been shown to deteriorate cross-domain re-ID performance . As a result, most DG re-ID methods  have simply discarded this technique despite its usefulness in standard re-ID settings. Nonetheless, the underlying phenomenon of this polarized effect remains underexplored.

To investigate the polarized effect on re-ID performance between in-distribution (ID) and out-of-distribution (OOD) scenarios, we conduct experiments1 using varying augmentation probabilities (_i.e.,_ the probability of applying data augmentation to input images). For data augmentations, we employ the widely used RandAugment , known for its effectiveness across various vision tasks, which randomly applies transformations sampled from a predefined set, including comprehensive geometric manipulations and color variations. Considering the fine-grained domain characteristics of person re-ID, we exclude transformations that cause severe color distortion, such as Invert and Solarize, from the predefined set, and additionally utilize Random Erasing . We train models with varying augmentation probabilities using a standard training pipeline that employs cross-entropy and batch-hard triplet loss . Following the existing DG re-ID protocol , the training set of MSMT17 (MS) , CUHK03 (C3) , and CUHK-SYSU (CS)  are used for model training as source domains, and Market-1501 (M)  as the target domain.

Fig. 0(a) compares the performance on the Market-1501 dataset of two models: one trained on the same dataset (ID) and the other trained on MS+CS+C3 (OOD). While data augmentation improves ID performance, OOD performance consistently deteriorates as the augmentation probability increases.

Figure 1: **Analysis on polarized effect of data augmentations on in-distribution (ID) and out-of-distribution (OOD).** (a) mAP (%) on Market-1501 of models trained on the same dataset (ID) and MS+CS+C3 (OOD) with varying augmentation probabilities. (b) Alignment (\(_{}\)) and uniformity (\(_{}\)) of OOD scenarios (MS+CS+C3 \(\) M). Counterintuitively, augmentations lead to more alignment but less uniformity, indicating that the model fails to sufficiently preserve the diverse information from the data distribution. (c) Uniformity (\(-_{}\)) vs. augmentation probability for the source and target datasets in MS+CS+C3 \(\) M. Higher probabilities result in less uniformity, especially under distribution shifts, indicating an insufficiency in representing OOD data.

This discrepancy highlights the polarized effect of data augmentations in the open-set nature of person re-ID. In closed-set recognition tasks, strong class invariance learned through augmentations can enhance generalization. However, in open-set retrieval tasks, where the model needs to handle unseen classes, learning diverse visual information becomes more crucial for generalization [58; 87]. Although augmentations improve model robustness within training distributions, they can also lead the model to focus on dominant visual information that is easily invariant to augmentations, as shown in Fig. 2. Consequently, this can result in _sparse_ representation spaces, where the model focuses on learning dominant features while neglecting subtle cues that can be generalized to other domains.

To further explore the effect of data augmentations on the representation space, we leverage the concepts of _alignment_ and _uniformity_, which are key properties of feature distributions on the unit hypersphere. Alignment is defined as the expected distance between positive pairs:

\[_{}_{ }}{}[\|_{i}-_{j}\|_{2}^{2}],\] (1)

where \(_{}\) is the distribution of positive pairs. Uniformity, on the other hand, is defined by the logarithm of average pairwise Gaussian potential:

\[_{}_{ }}{}[e^{-2\|_{i}-_{j}\|_{2}^{2}}],\] (2)

where \(_{}\) is the distribution of given data. These two properties reflect that positive pairs are close to each other (alignment) while the overall distribution of embeddings is uniformly spread on the hypersphere (uniformity). Several studies have demonstrated that both are essential for generalization, ensuring that the representation space achieves feature discriminability while preserving maximal information from the data [21; 65; 80].

Fig. 0(b) illustrates the alignment and uniformity of representations in OOD scenarios (Market-1501 for MS+CS+C3 \(\) Market-1501) for models trained with varying augmentation probabilities. As depicted, the use of augmentations leads to more alignment, thereby enhancing intra-class invariance compared to models trained without augmentation. Conversely, in terms of uniformity, higher augmentation probabilities result in less uniform embeddings, indicating that the model fails to sufficiently preserve the diverse information from the data. However, to achieve generalizability in the open-set re-ID task, learning diverse information (_i.e., more uniformity_) is crucial [7; 12; 58]. Furthermore, as shown in Fig. 0(c), the feature embeddings become increasingly less uniform with higher probabilities, and this becomes more evident as distributional shifts occur, as indicated by the red plot in the same figure. It suggests that simple training with data augmentations causes the model to become dominated by specific in-distribution data and fail to learn diverse visual cues, leading to degraded generalization performance with a sparse representation space with less uniformity.

Our analysis highlights the polarized effect of data augmentations in person re-ID, showing that while they enhance in-distribution performance, they can deteriorate out-of-distribution performance by leading to a sparse representation space. Nevertheless, data augmentations remain a promising technique to improve generalization by increasing both the diversity and robustness of training data. In the following subsection, we present a method to mitigate this effect by incorporating alignment and uniformity, using both original and augmented images to balance feature discriminability and generalizability.

### Balancing Alignment and Uniformity

We introduce a simple yet effective framework, Balancing Alignment and Uniformity (BAU), which mitigates the polarized effect of data augmentations by maintaining a balance between alignment and uniformity. The overview is illustrated in Fig. 3. Given an input batch, we generate augmented views of the images, \(=t(x)\), where \(t\) denotes augmentations sampled from the distribution \(\). Our model then extracts features from both the original and augmented images, denoted as \(_{i}=f_{}(x_{i})\) and \(}_{i}=f_{}(_{i})\), respectively. Since simple training with augmented images can lead to polarized effects (Sec. 3.1), we apply both alignment and uniformity losses to the features of the augmented images to achieve both feature discriminability and generalizability simultaneously. Specifically, the alignment loss enhances feature discriminability by promoting invariance to diverse augmentations, while the uniformity loss encourages generalizability by striving for a uniform distribution of features on the hypersphere, thereby preserving diverse visual information from the data.

Figure 2: Grad-CAM  across different probabilities of data augmentations.

Alignment Loss.We reformulate the alignment loss to minimize the expected feature distance of positive pairs between original and augmented images, defined as:

\[_{}=_{}|}_{(i,j) _{}}\|}_{i}-_{j}\|_{2}^{2},\] (3)

where \(_{}=\{(i,j) y_{i}=y_{j}\}\) is the index set for the positive pairs within a mini-batch, and \(||\) denotes the cardinality of the set. With alignment loss, the model can learn invariance to various transformations introduced by data augmentations, thereby enhancing feature discriminability. However, some augmented samples may suffer from significant corruption due to aggressive augmentations, and learning invariance with these samples can potentially degrade the training process.

To address this issue, we introduce a weighting strategy for the alignment loss that considers the reliability of augmented samples. Based on studies that handle noisy samples by leveraging the relationship with nearest neighbors , we compute the weight as the Jaccard similarity of \(k\)-reciprocal nearest neighbors between the augmented sample and the original sample, defined by:

\[w_{ij}=_{k}(}_{i})_{k}( _{j})|}{|_{k}(}_{i})_{k} (_{j})|},\] (4)

where \(_{k}(_{i})\) is the set of indices for \(k\)-reciprocal nearest neighbors within a mini-batch of the feature \(_{i}\). Intuitively, a low weight implies that the augmented feature \(}_{i}\) and the original feature \(_{j}\) are not strongly correlated, indicating that learning invariance between them can provide unreliable information to each other. We reformulate the alignment loss in Eq. (3) with weights \(w\), computed as:

\[_{}=_{(i,j)_{}}_{ ij}\|}_{i}-_{j}\|_{2}^{2},\] (5)

where \(=_{}}w_{ij}}\) is the normalized weight. This strategy allows the alignment loss to focus on reliable pairwise relationships between the original and augmented images without noisy samples.

Uniformity Loss.Following Wang and Isola , we compute the uniformity loss to balance feature discriminability and generalizability as:

\[_{}=(_{}| }_{(i,j)_{}}e^{-2\|_{i}-_{j} \|_{2}^{2}})+(_{}|}_{(i,j) _{}}e^{-2\|}_{i}-} _{j}\|_{2}^{2}}),\] (6)

where \(_{}=\{(i,j) i j\}\) is the index set of all distinct pairs within a mini-batch. By incorporating the uniformity loss, the learned representations can be uniformly distributed on the

Figure 3: **Overview of the proposed framework. In (b) and (c), each color represents a different identity and domain, respectively.** (a) With original and augmented images, we apply alignment and uniformity losses to balance feature discriminability and generalization capability. We further introduce a domain-specific uniformity loss to mitigate domain bias. (b) \(_{}\) pulls positive features closer, while \(_{}\) pushes all features apart to maintain diversity. (c) \(_{}\) uniformly distributes each domainâ€™s features and prototypes, reducing domain bias and thus enhancing generalization.

hypersphere, maintaining the diversity of the feature space. This feature diversity is crucial for the generalization capability, as it prevents the model from overfitting to sparse dominant representations and encourages learning subtle cues that can be generalized across different domains.

Domain-specific Uniformity Loss.While the uniformity loss within a mini-batch can improve the diversity of the feature space, batched samples may not fully capture the global structure of the entire representation space. Additionally, high uniformity alone does not guarantee domain invariance, since features from the same domain may still cluster together, as illustrated in Fig. 3 (c). To address these issues, we employ a feature memory bank, \(=\{_{1},...,_{N}\}^{N d}\) with class prototypes \(^{d}\), where \(N\) is the number of classes in the given datasets. Each class prototype represents the feature vector for its respective class and is updated continuously during training using the momentum strategy [23; 28] as:

\[+(1-),\] (7)

where \(\) is the extracted features of original images with the same class label as \(\), and \(\) is the momentum coefficient. To mitigate the inherent domain bias in simple uniformity, we additionally apply a domain-specific uniformity loss, which enhances the uniformity between the features and prototypes within their corresponding domain as follows:

\[_{}=(_{j (_{i})}e^{-2\|_{i}-_{j}\|_{2}^{2}}}{_{i}N} )+(_{j(}_{i})}e ^{-2\|}_{i}-_{j}\|_{2}^{2}}}{_{i}N}),\] (8)

where \(()\) is the index set of _nearest prototypes of \(\) that are from the same source domain but different class_, and \(N\) is the number of nearest prototypes, which is set to match the size of the mini-batch. This loss attempts to uniformly distribute the features of each domain, reducing domain bias for domain-invariant representation space. Furthermore, by using a memory bank to compute uniformity with nearest prototypes, we can efficiently consider the overall structure of the representation space.

Overall Training Objective.The overall loss function of BAU is then given by:

\[_{}=_{}+_{ }+_{}+_{}+ _{},\] (9)

where \(_{}\) and \(_{}\) are the cross-entropy loss and triplet loss, respectively, applied only to the original images. Here, \(\) is the weighting parameter for the alignment loss. By ensuring alignment and uniformity with both original and augmented images, BAU effectively mitigates the detrimental effect of data augmentations while simultaneously exploiting the diversity they introduce. Moreover, BAU is a simple yet effective framework that directly regularizes the representation space without the need for advanced network architectures or complex training procedures.

## 4 Experiments

### Datasets and Evaluation Protocols

We conduct experiments using the following datasets: Market-1501 , MSMT17 , CUHK02 , CUHK03 , CUHK-SYSU , PRID , GRID , VIPeR , and iLIDs , with dataset statistics shown in Table 1. For simplicity, we denote Market-1501, MSMT17, CUHK02, CUHK03, and CUHK-SYSU as M, MS, C2, C3, and CS, respectively. Evaluation metrics include mean average precision (mAP) and cumulative matching characteristic (CMC) at Rank-1.

Following previous studies [71; 86; 90; 94], we evaluate the proposed method across three protocols, as detailed in Table 2. For Protocol-1, we utilize all images from M, C2, C3, and CS, including both training and testing data, for model training. We then evaluate the model on four small-scale re-ID datasets, specifically PRID, GRID, VIPeR, and iLIDs. The final performance on these small-scale

   Dataset & \#ID & \#Image & \#Camera \\  Market1501 (M)  & 1,501 & 32,217 & 6 \\ MSMT17 (MS)  & 4,101 & 126,441 & 15 \\ CUHK02 (C2)  & 1,816 & 7,264 & 10 \\ CUHK03 (C3)  & 1,467 & 14,096 & 2 \\ CUHK-SYSU (CS)  & 11,934 & 34,574 & 1 \\ PRID  & 200 & 1,134 & 2 \\ GRID  & 250 & 1,275 & 8 \\ VIPeR  & 632 & 1,264 & 2 \\ iLIDs  & 119 & 476 & 2 \\   

Table 1: Statistics of the used datasets.

   Setting & Training Data & Testing Data \\  Protocol-1 & Full-(M+C2+C3+CS) & 
 PRID, GRID, \\ VIPeR, iLIDs \\  \\  Protocol-2 & M+MS+CS & C3 \\ Protocol-3 & MS+CS+C3 & M \\  Protocol-3 & Full-(M+MS+CS) & C3 \\ Protocol-3 & Full-(M+CS+C3) & MS \\  Protocol-4 & M \\   

Table 2: Evaluation protocols.

datasets is obtained by averaging the results of 10 repeated random splits of the query and gallery sets. For Protocol-2 and Protocol-3, we follow a leave-one-out evaluation setting with four large-scale datasets: M, MS, C3, and CS. Three datasets are used as the source domain, and the remaining one is used as the target domain. Protocol-2 uses only the training data from the source domains for model training, whereas Protocol-3 utilizes both the training and testing data from the source domains. Since CUHK-SYSU (CS) is a person search dataset with a single camera view, it is only used for training.

### Implementation Details

Following previous studies [34; 50; 51; 86; 90], we use ResNet-50  pre-trained on ImageNet  with instance normalization layers as our backbone. All images are resized to \(256 128\). For each iteration, we sample 256 images, consisting of 64 identities with 4 instances for each identity. The total batch size during training is 512, including both original and augmented images. Random flipping, cropping, erasing , RandAugment , and color jitter are used for data augmentation. We train the model for 60 epochs using Adam  with a weight decay of \(5 10^{-4}\). The initial learning rate is set to \(3.5 10^{-4}\) and is decreased by a factor of 10 at the 30th and 50th epochs. A warmup strategy is applied during the first 10 epochs. The momentum \(\) is set to 0.1. We empirically set the weighting parameter \(\) to 1.5 and \(k\) for the weighting strategy to 10. We implement our framework in PyTorch  and utilize two RTX-3090 GPUs for training.

### Comparison with State-of-the-Arts

We compare our method with state-of-the-art DG re-ID methods on Protocol-1, with the results presented in Table 3. We also report the results of previous studies that use DukeMTMC-reID  for training, denoted as D in the table, while we exclude this dataset from training since it has been

    &  &  &  &  &  \\  & & mAP & Rank-1 & mAP & Rank-1 & mAP & Rank-1 & mAP & Rank-1 \\   & SNR  & 8.9 & 8.9 & 6.8 & 19.9 & 34.6 & 62.7 & 16.8 & 30.5 \\  & QAConv\({}_{50}\) & 25.4 & 24.8 & 16.4 & 45.3 & 63.1 & 83.7 & 35.0 & 51.3 \\  & M\({}^{3}\)L  & 34.2 & 34.4 & 16.7 & 37.5 & 61.5 & 82.3 & 37.5 & 51.4 \\  & MetaBIN  & 28.8 & 28.1 & 17.8 & 40.2 & 57.9 & 80.1 & 34.8 & 49.5 \\  & META  & 36.3 & 35.1 & 22.5 & 49.9 & 67.5 & 86.1 & 42.1 & 57.0 \\  & ACL  & 41.2 & 41.8 & 20.4 & 45.9 & 74.3 & 89.3 & 45.3 & 59.0 \\  & **BAU (Ours)** & **42.8** & **43.9** & **24.3** & **50.9** & **77.1** & **90.4** & **48.1** & **61.7** \\   & SNR  & 17.5 & 17.1 & 7.7 & 22.0 & 52.4 & 77.8 & 25.9 & 39.0 \\  & QAConv\({}_{50}\) & 32.9 & 33.3 & 17.6 & 46.6 & 66.5 & 85.0 & 39.0 & 55.0 \\  & M\({}^{3}\)L  & 35.7 & 36.5 & 17.4 & 38.6 & 62.4 & 82.7 & 38.5 & 52.6 \\   & MetaBIN  & 43.0 & 43.1 & 18.8 & 41.2 & 67.2 & 84.5 & 43.0 & 56.3 \\   & META  & 47.1 & 46.2 & 24.4 & 52.1 & 76.5 & 90.5 & 49.3 & 62.9 \\   & ACL  & 49.4 & 50.1 & 21.7 & 47.3 & 76.8 & 90.6 & 49.3 & 62.7 \\   & **BAU (Ours)** & **50.6** & **51.8** & **26.8** & **54.3** & **79.5** & **91.1** & **52.3** & **65.7** \\   

Table 4: Comparison with state-of-the-art methods on Protocol-2 and Protocol-3.

    &  &  &  &  &  &  \\  & & mAP & Rank-1 & mAP & Rank-1 & mAP & Rank-1 & mAP & Rank-1 & mAP & Rank-1 & mAP & Rank-1 \\   & DIMN  & 52.0 & 39.2 & 41.1 & 29.3 & 60.1 & 51.2 & 78.4 & 70.2 & 57.9 & 47.5 \\  & DualNorm  & 64.9 & 60.4 & 45.7 & 41.4 & 58.0 & 53.9 & 78.5 & 74.8 & 61.8 & 57.6 \\  & SNR  & 66.5 & 52.1 & 47.7 & 40.2 & 61.3 & 52.9 & 89.9 & 84.1 & 66.4 & 57.3 \\ M+D & DDMAN  & 67.5 & 62.9 & 50.9 & 46.2 & 60.8 & 56.5 & 81.2 & 78.0 & 65.1 & 60.9 \\  +C2+C3 & Radio  & 67.3 & 57.7 & 54.2 & 46.8 & 64.6 & 56.6 & 90.2 & 85.0 & 62.0 & 61.5 \\  +CS & DMG-Net  & 68.4 & 60.6 & 56.6 & 51.0 & 60.4 & 53.9 & 83.9 & 79.3 & 67.3 & 61.2 \\  & GDNorm  & 79.9 & 72.6 & 63.8 & 55.4 & 74.1 & 66.1 & 87.2 & 81.3 & 76.3 & 68.9 \\  & DTIN  & 79.7 & 71.0 & 60.6 & 51.8 & 70.7 & 62.9 & 87.2 & 81.8 & 74.6 & 66.9 \\  & SVCon  & 78.9 & 71.0 & 60.4 & 50.7 & 74.4 & 66.8 & 86.9 & 80.7 & 75.2 & 67.3 \\   & QAConv\({}_{50}\) & 62.2 & 52.3 & 57.4 & 48.6 & 66.3 & 57.0 & 81.9 & 75.0 & 67.0 & 58.2 \\  & M\({}^{3}\)L  & 65.3 & 55.0 & 50.5 & 40.0 & 68.2 & 60.8 & 74.3 & 65.0 & 64.6 & 55.2 \\   & MetaBIN  & 70.8 & 61.2 & 57.9 & 50.2 & 64.3 & 55.9 & 82.7 & 74.7 & 68.9 & 60.5 \\   & META  & 71.7 & 61.9 & 60.1 & 52.4 & 68.4 & 61.5 & 83.5 & 79.2 & 70.9 & 63.8 \\   & ACL  & 73.4 & 63.0 & 65.7 & 55.2 & **75.1** & **66.4** & 86.5 & 81.8 & 75.2 & 66.6 \\   & StyCon  & 78.1 & 69.7 & 62.1 & 53.4 & 71.2 & 62.8 & 84.8 & 78.0 & 74.1 & 66.0 \\   & **BAU (Ours)** & **77.2** & **68.4** & **68.1** & **59.8** & 74.6 & 66.1 & **88.7** & **83.7** & **77.2** & **69.5** \\   

Table 3: Comparison with state-of-the-art methods on Protocol-1taken down. As shown in the table, although our method utilizes fewer datasets for training, it surpasses prior state-of-the-art methods in average mAP/Rank-1 performance across the four datasets. Comparisons of the proposed method with state-of-the-art methods on Protocol-2 and Protocol-3 are presented in Table 4. The results demonstrate that our method outperforms other methods, confirming the generalization capability of BAU on large-scale datasets. Specifically, we achieve higher average mAP scores across three datasets than the previous state-of-the-art ACL , with improvements of +2.7% and +3.4% on protocol-2 and protocol-3, respectively.

It is also noteworthy that our method achieves state-of-the-art performance without employing advanced feature normalization modules [10; 35; 36; 48; 53] or domain-specific network architectures [12; 86; 90]. Specifically, BAU is a simple yet effective framework that regularizes the representation space by ensuring alignment and uniformity between original and augmented images, without relying on domain-adversarial  training or meta-learning [4; 94] strategies.

### Ablation Study and Analysis

To evaluate the effectiveness of each component in BAU and validate our design choices, we conduct extensive ablation studies and analyses on Protocol-3, the most scalable setting in our experiments.

Ablation study of loss functions for augmented images.We first analyze the impact of applying different loss functions to the augmented images, as shown in Table 5. The baseline model, trained using cross-entropy and triplet losses without any augmented images (when \(p=0\) of Sec. 3.1), serves as a reference point. Applying only the cross-entropy loss \(_{}\) to the augmented images leads to a performance drop, aligning with our analysis in Sec. 3.1 that naive training with augmented images can degrade generalization performance. This result also aligns with studies demonstrating that cross-entropy loss can easily overfit to biases and noise in the data [25; 59; 92]. When applying the proposed alignment loss \(_{}\), the performance improves, surpassing the baseline. Further incorporating the uniformity loss \(_{}\) significantly boosts the performance, confirming the importance of balancing both alignment and uniformity to achieve better generalization. Finally, integrating the domain-specific uniformity loss \(_{}\) achieves the best performance, with notable improvements of +10.2%/+8.0% in average mAP/Rank-1 over the baseline. This validates that mitigating domain bias by uniformly distributing features within each domain is effective. In summary, these results highlight that while simply training with augmentations can be detrimental, carefully regularizing the representation space through alignment and uniformity allows the model to benefit from the augmented data, leading to improved generalization.

Ablation study of weighting strategy and domain-specific uniformity loss.We conduct an ablation study to validate the effectiveness of the proposed weighting strategy for the alignment loss and the domain-specific uniformity loss, as shown in Table 6. Without the weighting strategy in Eq. 3, the performance drops compared to the full BAU model, demonstrating the benefit of focusing on reliable pairs between original and augmented images to learn robust features. To investigate the importance of the domain-specific uniformity loss, we apply a simple uniformity loss with a feature memory bank without considering each domain (_i.e.,_ modifying Eq. (8) with nearest prototypes in

    Weighting \\ Strategy of \(_{}\) \\  } &  &  &  &  &  \\  & mAP & Rank-1 & mAP & Rank-1 & mAP & Rank-1 & mAP & Rank-1 & mAP & Rank-1 \\   Baseline (w/o augmented images) \\  } &  39.2 \\ \(_{}\) \\  } &  38.9 \\ \(_{}\) \\  } &  18.9 \\ \(_{}\) \\  } &  44.8 \\ \(_{}\) \\  } &  68.3 \\ \(_{}\) \\  } &  66.3 \\ \(_{}\) \\  } &  66.3 \\ \(_{}\) \\  } &  63.2 \\ \(_{}\) \\  } &  66.7 \\ \(_{}\) \\  } &  90.0 \\ \(_{}\) \\  } &  48.9 \\ \(_{}\) \\  } &  62.0 \\ \(_{}\) \\  } \\  & & & & & & & & & & \\   

Table 5: Ablation study of loss functions for augmented images.

the entire domain, not intra-domain). The performance decreases, highlighting the effectiveness of promoting uniformity within each domain for learning domain-invariant features. When both the weighting strategy and domain-specific prototypes are removed, the performance drops further, showing that each component provides complementary benefits, and integrating both in the BAU framework results in better generalization. This analysis validates the effectiveness of the proposed techniques, enabling BAU to achieve strong performance in the DG re-ID task by focusing on reliable pairs in alignment and promoting uniformity within each domain.

Analysis of alignment and uniformity.To further validate the effect of our proposed method on the learned representation space, we analyze the alignment and uniformity properties of the baseline and BAU. Fig. 3(a) illustrates these properties for the representations on the testing data of Market-1501 when MS+CS+C3 \(\) M under Protocol-3. When data augmentations are applied, the representations of the baseline become less uniform, resulting in decreased generalization performance, as discussed in Sec. 3.1. In contrast, BAU consistently maintains better alignment and uniformity compared to the baseline across all augmentation probabilities. Notably, even when data augmentation is not applied (_i.e._, \(p=0\)), BAU still outperforms the baseline. This demonstrates that in addition to preventing the polarizing effect of data augmentation, alignment and uniformity are important factors for generalization, aligning with recent studies . In summary, by explicitly regularizing the representation space with both original and augmented images, BAU achieves better generalization performance by balancing feature discriminability and generalizability, confirming that it effectively leverages the diversity from data augmentations.

Analysis of weighting strategy and domain-specific uniformity loss.To explore the effect of the domain-specific uniformity loss, we visualize the t-SNE  plot of the training data when MS+CS+C3 \(\) M under Protocol-3, with and without the domain-specific uniformity loss \(_{}\). As shown in Fig. 3(b), without \(_{}\), the learned features exhibit domain-specific clusters, indicating a lack of domain invariance. On the other hand, applying \(_{}\) results in a more uniform distribution of features across domains, as evidenced by the increased uniformity values for each domain (reported in parentheses). This demonstrates the effectiveness of promoting uniformity within each domain to learn domain-invariant representations.

To further analyze the proposed weighting strategy for the alignment loss, we conduct quantitative comparisons across varying augmentation probabilities, with and without the weighting strategy. As shown in Fig. 4(a), our weighting strategy consistently improves performance across different augmentation probabilities, with the gap becoming more pronounced at higher probabilities where severe corruption from augmentations is more likely. Specifically, at an augmentation probability of 0.5, the weighting strategy improves the mAP from 78.3% to 79.5%, and at a probability of 1.0, the improvement is even more substantial, from 66.1% to 76.1%. These results demonstrate that BAU effectively enables learning invariance with reliable augmented samples, thanks to the proposed weighting strategy, which focuses on reliable pairs between original and augmented images.

For qualitative analysis, Fig. 4(b) illustrates the weight scores \(w\) in Eq. (4) for the alignment loss. The top row shows the original images, while the bottom row represents their augmented versions

Figure 4: **Analysis of alignment and uniformity.** (a) Alignment (\(_{}\)) and uniformity (\(_{}\)) on Market-1501 when MS+CS+C3 \(\) M under Protocol-3 with varying augmentation probabilities. (b) T-SNE visualization with and without the domain-specific uniformity loss \(_{}\). The values in parentheses in each legend label indicate the uniformity of the corresponding domain.

with corresponding weight scores. As \(w\) progressively increases from left to right, the augmented images exhibit less distortion, indicating more reliable samples with informative augmentations. The weighting strategy allows the alignment loss to focus on augmented samples that are semantically similar to the original images, facilitating invariance learning from informative augmentations.

## 5 Discussion

Although our method has shown promising results, it still has limitations to overcome. As a straightforward approach primarily based on data augmentations for given input data, our method could face challenges under very large domain shifts. While we adopt standard image-level augmentations, we do not incorporate more advanced techniques such as adversarial data augmentations [69; 75; 99; 104] or feature-level augmentations [37; 46; 106], both of which have shown promise for generalization. Integrating these techniques with the proposed BAU framework could potentially further enhance generalization performance and would be an interesting direction for future research.

Despite these limitations, our work is the first to thoroughly investigate and address the polarized effect of data augmentations in DG re-ID. It demonstrates the significant potential of balancing alignment and uniformity to improve generalization in person re-identification. We believe that our findings could inspire further research aimed at advancing generalization capabilities in this field.

## 6 Conclusion

In this paper, we investigated the polarized effect of data augmentations in domain generalizable person re-identification. Our findings revealed that while augmentations enhance in-distribution performance, they can also lead to sparse representation spaces and deteriorate out-of-distribution performance. To address this issue, we proposed a simple yet effective framework, Balancing Alignment and Uniformity (BAU), which regularizes the representation space by maintaining a balance between alignment and uniformity. Comprehensive experiments on various benchmarks and protocols demonstrated that BAU achieves state-of-the-art performance without requiring advanced network architectures or complex training procedures. Furthermore, our extensive ablation studies and analyses validated the effectiveness of each component in BAU, emphasizing the importance of balancing alignment and uniformity to achieve robust generalization in person re-identification.