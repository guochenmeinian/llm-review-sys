# \(\epsilon\)-Softmax: Approximating One-Hot Vectors for

# \(\)-Softmax: Approximating One-Hot Vectors for

Mitigating Label Noise

Jialiang Wang\({}^{1}\)1

Xiong Zhou\({}^{1}\)1

Deming Zhai\({}^{1}\)

Junjun Jiang\({}^{1}\)

Xiangyang Ji\({}^{2}\)

Xianming Liu\({}^{1}\)\({}^{}\)

\({}^{1}\)Faculty of Computing, Harbin Institute of Technology

\({}^{2}\)Department of Automation, Tsinghua University

cswjl@stu.hit.edu.cn\({}^{*}\), cszx@hit.edu.cn\({}^{*}\), csxm@hit.edu.cn\({}^{}\)

Equal contribution \({}^{}\)Corresponding author

###### Abstract

Noisy labels pose a common challenge for training accurate deep neural networks. To mitigate label noise, prior studies have proposed various robust loss functions to achieve noise tolerance in the presence of label noise, particularly symmetric losses. However, they usually suffer from the underfitting issue due to the overly strict symmetric condition. In this work, we propose a simple yet effective approach for relaxing the symmetric condition, namely \(\)-\(\), which simply modifies the outputs of the softmax layer to approximate one-hot vectors with a controllable error \(\). Essentially, \(\)-\(\)_not only acts as an alternative for the softmax layer, but also implicitly plays the crucial role in modifying the loss function_. We prove theoretically that \(\)-\(\) can achieve noise-tolerant learning with controllable excess risk bound for almost any loss function. Recognizing that \(\)-\(\)-enhanced losses may slightly reduce fitting ability on clean datasets, we further incorporate them with one symmetric loss, thereby achieving a better trade-off between robustness and effective learning. Extensive experiments demonstrate the superiority of our method in mitigating synthetic and real-world label noise. The code is available at https://github.com/cswjl/eps-softmax.

## 1 Introduction

In recent years, deep neural networks (DNNs) have achieved remarkable advancements across various machine learning tasks [1; 2]. Despite its significant success, the prevalence of noisy labels in real-world datasets is a pervasive issue, often stemming from human bias or a lack of relevant professional knowledge . The application of supervised learning methods directly to data with noisy labels consistently results in a decline in model performance . Moreover, the ability to generalize from weak learners plays a pivotal role in the alignment of large language models . Consequently, the pursuit of noise-tolerant learning has emerged as a compelling and significant challenge within the domain of weakly supervised learning, garnering increased attention in recent years [5; 6; 7; 8].

The literature presents several strategies for remedying this issue, with the design of robust loss functions standing out as a particularly popular approach due to its simplicity and broad applicability. Some previous works [9; 10; 5] theoretically proved that a loss function is noise-tolerant to label noise under mild conditions if it is symmetric:

\[_{k=1}^{K}L(f(),k)=C,, f \] (1.1)

where \(k[K]\) is the label corresponding to each class, \(C\) is a constant, and \(\) is the hypothesis class.

Furthermore, Asymmetric Loss Functions (ALFs)  are proposed as an extension of symmetric losses, which are designed for clean-label-dominant noise. However, both symmetric and asymmetriclosses, such as Mean Absolute Error (MAE)  and Asymmetric Unhinged Loss (AUL) , encounter the underfitting problem and prove challenging to optimize [5; 6; 7]. The fitting ability of existing symmetric loss functions is constrained by the overly strict symmetric condition in Equation 1.1. Some approaches aim to improve the classical symmetric loss MAE by incorporating the robustness of the MAE and the rapid convergence of the Cross Entropy (CE). Examples include Generalized Cross Entropy (GCE) , Symmetric Cross Entropy (SCE) , and Jensen-Shannon Divergence Loss (JS) . However, these loss functions often mechanically select an intermediate value between the derivatives of CE and MAE, essentially representing a trade-off between fitting ability and robustness. This prompts a crucial question: _How can we simultaneously achieve both robustness and effective learning?_

Zhou et al.  proposed an alternative approach to achieve the symmetric condition, diverging from the development of a new robust loss function. By restricting the hypothesis class \(\), which restricts the outputs of the prediction function \(f\) to one-hot vectors, any loss function can inherently become symmetric, i.e., \(_{k=1}^{K}L(f(),k)=C,, L \). However, a notable challenge arises from the fact that directly mapping outputs to one-hot vectors constitutes a non-differentiable operation. Accordingly, the crux of the matter lies in formulating an effective method to constrain the outputs to one-hot vectors. Previous attempts, such as temperature-dependent softmax , sparseness constraint , sparse regularization , and variance enlargement , have aimed to approximate one-hot vectors through the application of regularization methods. Nevertheless, these methods lack predictability, fail to achieve a quantitative approximation to one-hot vectors, and exhibit limited effectiveness, particularly at higher noise rates. Up to this point, a reliable approach for rigorously enforcing one-hot vector outputs remains elusive. Addressing this gap continues to pose a significant challenge in realizing the symmetric condition.

In this paper, we present a simple yet effective and theoretically sound approach for approximating outputs to one-hot vectors, which we term \(\)-\(\). This method serves as a valuable alternative to the conventional softmax function in mitigating label noise. The distinctive attribute of \(\)-\(\) lies in its guarantee to possess a controllable approximation error \(\) to one-hot vectors, thus achieving perfect constraint for the hypothesis class. This approach is universally applicable across diverse models and loss functions, as it only needs to implement a simple layer resembling softmax. Specifically, the process of applying our \(\)-\(\) is outlined as follows:

\[}&(|) (h()),\\ &p_{t} p_{t}+m,t=_{k[K]}p_{k} \\ &(|)(| )/(m+1).\]

Herein, \((|)\) represents the prediction probabilities, \(p_{k}\) denotes the \(k\)-th element of the vector \((|)\), and \(h()\) denotes the logits. Step 1 obtains the original predictions by the softmax function. Step 2 involves a hyperparameter \(m 0\) to amplify the maximum term in the predictions with a controllable approximation error to one-hot vectors. Step 3 performs a normalization to make predictions sum to one, which also reduces the values of non-maximum terms.

The above description underscores that \(\)-\(\) as a plug-and-play module applicable to any classifier incorporating a softmax layer. Through the adjustment of the parameter \(m\), our approach allows for the quantitative approximation of output to one-hot vectors, and thus owns the ability for mitigating label noise in classification. The main contributions of our work are highlighted as follows:

* We propose a simple yet effective scheme, \(\)-\(\), for mitigating label noise. This scheme operates as a plug-and-play module, seamlessly integrating with any classifier that incorporates a softmax layer through just two additional lines of code.
* We offer rigorous theoretical analyses, which indicate that \(\)-\(\) is capable of controllably approximating one-hot vectors. Consequently, \(\)-\(\)-enhanced loss functions can achieve noise-tolerant learning and Bayes optimal top-\(k\) error.
* We develop practical loss functions that enhance noise-tolerant learning. These include integration with MAE, achieving a better trade-off between robustness and effective learning. Extensive experimental results demonstrate the superiority of our method.

## 2 Preliminary

Problem Formulation.In a typical supervised classification scenario, let \(^{d}\) represent the \(d\)-dimensional input space, and \(=[K]=\{1,2,...,K\}\) is the label space, where \(K\) is the number of classes. We are provided with a labeled dataset \(=\{(_{n},y_{n})\}_{n=1}^{N}\), where each \((_{n},y_{n})\) is drawn \(i.i.d.\) from an underlying distribution \(\) over \(\). The classifier \(f\) is a mapping from the sample space to the label space, the prediction label \(=_{k}f()_{h}\). Here, the prediction function \(f:_{K}\) estimates the probability \((|)\), and \(_{K}=\{^{K}:^{}=1\}\) represents the probability simplex. Typically, the function \(f\) is expressed as \(f= h\), where \(h\) denotes the logits input to the softmax layer. In the context of deep learning, \(h\) is commonly a neural network. The objective or loss function is defined as a measure of distance \(L:_{K}_{K}\). For a classification problem, the loss function is characterized by \(L(,_{y})\), where \(_{y}\) represents the one-hot vector with its \(y\)-th element set to 1. In this study, we consider the loss functional \(\), where \( L\), \(L(,)=_{k=1}^{K}(u_{k},v_{k})\) with a basic loss function \(\). For brevity, we slightly abuse notation by defining \(L(,k)=L(,_{k})\).

Label Noise Model.In the context of learning with noisy labels, the accessible training set is the noisy counterpart \(}=\{(_{n},_{n})\}_{n=1}^{N}\) rather than the clean set \(\). We characterize the noise corruption process as the flipping of the clean label of \(\) into its noisy version \(\) with a probability denoted as \(_{,}=p(|,y)\). \(_{}=_{k y}_{,k}\) denotes the noise rate for \(\). Our focus is on two prevalent types of label noise [6; 7] :

- _Symmetric or uniform noise:_\(_{,y}=1-\) and \(_{,k y}=\),

- _Asymmetric or class-conditional noise:_\(_{,y}=1-_{y}\) and \(_{k y}_{,k}=_{y}\),

where \(_{}=\) for symmetric noise, \(_{}=_{y}\) denotes the noise rate for the \(y\)-th class, and \(_{,i}\) is not necessarily equal to \(_{,j}\), \(i j\) for asymmetric noise.

We also empirically consider learning with human-annotated noisy labels.

Expected Risk and Noise Tolerance.In learning with clean labels, given a loss function \(L\) and a prediction function \(f\), the expected risk with respect to \(f\) is defined as: \(_{L}(f)=_{(,y)}[L(f(),y)]\). The objective is to learn an optimal classifier \(f^{*}\) that minimizes the expected risk, i.e., \(f^{*}_{f}_{L}(f)\).

In the case of learning with noisy labels, the corresponding noisy expected risk with respect to \(f\) is defined as:

\[_{L}^{}(f)=_{}(1-_{} )L(f(),y)+_{k y}_{,k}L(f(),k),\] (2.1)

where \(_{k y}_{,k}L(f(),k)\) is the noisy part that usually poses challenges in training accurate DNNs.

A loss function \(L\) is claimed to be _noise-tolerant_ if the global minimizer \(f_{}^{*}\) of \(_{L}^{}(f)\) also minimizes \(_{L}(f)\), that is, \(f_{}^{*}_{f}_{L}(f)\).

All-\(k\) Consistency.Consistency is an important property of a loss function. A standard consistency is for achieving Bayes optimal top-1 error. We consider much stronger consistency for achieving Bayes optimal top-\(k\) error for any \(k[K]\). To this end, we introduce some definitions about top-\(k\) consistency [17; 8].

For any vector \(^{K}\), we let \(r_{k}()\) denote a top-\(k\) selector that selects the \(k\) indices of the largest entries of \(\) by breaking ties arbitrarily. Given a data \((,y)\), its top-\(k\) error is defined as \(_{k}(f,,y)=(y r_{k}(f()))\). The goal of a classification algorithm under the top-\(k\) error metric is to learn a predictor \(f\) that minimizes the \(_{k}\) expected risk: \(_{_{k}}(f)=_{(,y)}[ _{k}(f,,y)]\).

For a fixed \(k[K]\), a loss function \(L\) is top-\(k\) consistent if for any sequence of measurable functions \(f:_{K}\), we have the global minimizer \(f^{*}\) of \(_{L}(f)\) also minimizes \(_{_{k}}(f)\), that is, \(f^{*}_{f}_{_{k}}(f)\). If the above holds for all \(k[K]\), it is referred to as _All-\(k\) consistency_.

Methodology and Theoretical Investigation

The symmetry condition in Equation 1.1, theoretically ensures that a symmetric loss function can be noise-tolerant . Existing methods primarily focus on designing new loss functions. Those derived based on this design principle exhibit drawbacks, such as being challenging to optimize [5; 6] and prone to encounter the gradient explosion problem . In this work, we take an alternative approach by proposing to constrain the hypothesis class \(\) such that any loss functions will be approximately symmetric thereby rendering them robust to label noise.

### Robustness

We introduce \(\)**-softmax**x to make the output \(f()\) approximate one-hot vectors. The implementation of \(\)**-softmax**x is easy to follow, as outlined in the gray box of the Introduction Section 1, requiring just two additional lines of code alongside the standard softmax layer. This underscores that \(\)**-softmax**x is a plug-and-play module applicable to any classifier that incorporates a softmax layer. In this following, we investigate in theory how \(\)**-softmax**x realizes the controllable approximation of outputs to one-hot vectors, thereby enhancing the noise tolerance of any loss function.

Approximating One-Hot Vectors.We first introduce the concept of \(\)-relaxation for a hypothesis class and then prove \(\)**-softmax**x can strictly approximate outputs to one-hot vectors with a controllable error.

**Definition 1** (\(\)-relaxation).: _Given a fixed vector \(\) and its permutation set \(}}\)1, the \(\)-relaxation of \(}}\) is defined as the hypothesis class \(,}}\), in which any hypothesis \(f,}}\) outputs vectors in the \(\)-ball of \(}}\), i.e., \(,}}=\{f:_{}}}\|f()-\|_{2},\}\)._

Without loss of generality, we consider \(\) as a one-hot vector, which is common in machine learning, to facilitate the implementation and analysis. We then denote the permutation set of the one-hot vector as \(_{1}}}\), where all elements are also one-hot vectors. In accordance with Definition 1, we can further derive that:

**Lemma 1**.: \(\)**-softmax** _can achieve \(\)-relaxation for one-hot vectors:_

\[_{_{1}}}}\|f()-\| _{2}=}{m+1},\] (3.1)

_where \(f()=\)**-softmax**x \( h()\)._

Lemma 1 suggests that \(\)**-softmax**x effectively enables \(f()\) to approximate one-hot vectors with a controllable error \(}{m+1}\).

Robustness Guarantee.We then establish theoretical guarantees for the robustness in mitigating label noise, where the constrained hypothesis class \(_{1},}}\) is considered.

Zhou et al.  established the excess risk bound  under symmetric noise, which holds when outputs fall within an \(\)-relaxation of a permutation set. We prove a more comprehensive conclusion by considering asymmetric noise, of which symmetric noise is a special case.

**Theorem 1** (Excess Risk Bound under Asymmetric Noise).: _In a multi-class classification problem, if the loss function \(L\) satisfies \(|_{k=1}^{K}(L(_{1},k)-L(_{2},k))|\) when \(\|_{1}-_{2}\|_{2}\), and \( 0\) as \( 0\), then for asymmetric label noise \(_{,k}<(1-_{y}), k y\), if \(_{L}(f^{*})=0\), the excess risk bound for \(f,}}\) can be expressed as_

\[_{L}(f^{*}_{}) 2+,\] (3.2)

_where \(c=_{}(1-_{y})\), \(a=_{,k}(1-_{y}-_{,k})\), \(f^{*}_{}\) and \(f^{*}\) denote the global minimum of \(^{}_{L}(f)\) and \(_{L}(f)\), respectively._

Theorem 1 demonstrate that under mild conditions for symmetric and asymmetric label noise, any loss function can be made noise-tolerant when the function \(f()\) increasingly approximates a permutation set \(}}\) (i.e., \( 0\) as \( 0\)).

\(\)-Softmax-Enhanced Loss Functions.Lemma 1 enable \(f()=\)-\( h()\) in closely approximating a one-hot vector, aligns with the principle outlined in Theorem 1 within the framework of the hypothesis class \(_{_{1},}\). Hence, \(\)-\(\) progressively enhances the noise tolerance of any loss function as the hyperparameter \(m\) approaches infinity (\( 0\) as \(m\) and the discrepancy \( 0\)).

In this paper we consider CE loss and Focal loss (FL) . We combine them with \(\)-\(\), denoted as CE\({}_{}\) and FL\({}_{}\). \(\)-\(\) approach is effective in adapting them to become more resilient to noise, ensuring better performance in the presence of label noise.

### Consistency

Fundamentally, \(\)-\(\)_not only acts as an alternative for the softmax layer, but also plays the crucial role in modifying the loss function_. Consistency is an important property of a loss function. A standard consistency is for achieving Bayes optimal top-1 error. We show much stronger consistency for achieving Bayes optimal top-\(k\) error for any \(k[K]\) of the CE loss when combined with \(\)-\(\). To establish the All-\(k\) consistency, we first introduce some existing results of sufficient condition of top-\(k\) consistency by top-\(k\) calibration [17; 8].

Let \(P_{k}(,)\) denote that \(\) is top-\(k\) preserving with respect to the underlying label distribution \(\), i.e., if for all \(l[K],q_{l}>q_{[k+1]} f_{l}>f_{[k+1]}\), and \(q_{l}<q_{[k]} f_{l}<f_{[k]}\). Here, \(q_{[k]}\) denotes he \(k\)-th greatest entry of \(\). For example, if \(=[0.2,0.4,0.4]\), then \(q_{}=0.4,q_{}=0.4,q_{}=0.2\).

**Definition 2** (All-\(k\) calibrated).: _For a fixed \(k[K]\), a loss function \(L\) is called top-\(k\) calibrated if for all \(_{K}\) it holds that:_

\[_{f^{K}: P_{k}(f,)}_{L}(f)>_{f ^{K}}R_{L}(f).\] (3.3)

_A loss function is called All-\(k\) calibrated if the loss function \(L\) is top-\(k\) calibrated for all \(k[K]\)._

Yang and Koyejo  demonstrate that suppose \(L\) is a nonnegative top-\(k\) calibrated loss function, then \(L\) is top-\(k\) consistent. Furthermore, Zhu et al.  show that if \(f^{*}=_{f}R_{L}(f)\) is rank preserving with respect to \(\), then \(L\) is All-\(k\) calibrated. \(\) is called rank preserving w.r.t \(\), i.e., if for any pair \(q_{i}<q_{j}\) it holds that \(f_{i}<f_{j}\).

Then we establish comprehensive All-\(k\) consistency for CE\({}_{}\) as follows:

**Lemma 2**.: _For one-hot label \(_{y}\), CE\({}_{}\) is All-\(k\) calibrated and All-\(k\) consistency._

**Theorem 2**.: _For any label \(_{K}\), let \(y=_{k[K]}q_{k}\) and \(t=_{k[K]}p_{k}\), if \(t=y\) and \(q_{y}-_{k y}q_{k}>\), CE\({}_{}\) is All-\(k\) calibrated and All-\(k\) consistency._

Lemma 2 and Theorem 2 mean that CE\({}_{}\) performs well not only on the top-1 prediction, but also on the top-\(k\) predictions for any \(k[K]\). We show the All-\(k\) consistency property of different losses in Table 1, the consistency of other losses refer to .

### Gradient Analysis of \(\)-Softmax.

To provide a comprehensive understanding of \(\)-\(\) in mitigating label noise, we further analyze the gradient of the CE loss when combined with \(\)-\(\). The gradient of \(L_{_{}}(f(),y)\) with respect to the model \(h()\) can be derived as follows:

\[_{}}(f(),y)}{ h()}=\{ -+m}}{  h()},& t=y\\ -}}{ h()},& t  y.,\] (3.4)

where \(f=\)-\( h\), \(()=(h())\) denotes the probabilities by standard softmax, and \(t=_{k[K]}p_{k}\) is the class with the largest value in prediction probabilities.

Remark.The gradient in Equation 3.4 shows that CE\({}_{}\) will be equivalent to the standard CE if the maximum prediction is not the target class (i.e., \(t y\)), in which the division of \(m+1\) in probabilities

   Loss & CE & MAE & NCE & GCE & SCE & AUL & AGCE & AEL & LDR-KL & CE\({}_{}\) \\  All-\(k\) Consistency & ✓ & ✗ & ✗ & ✓ & ✓ & ✗ & ✗ & ✗ & ✓ & ✓ \\   

Table 1: All-\(k\) consistency between different loss functions.

is omitted due to the partial deviation. Conversely, when the prediction class \(t\) matches the target class \(y\), the gradient undergoes dynamic scaling by \(}{p_{}+m}\). This scaling results in smaller gradients, akin to a form of soft early-stopping , which facilitates the mitigation of overfitting to noisy labels. Such a characteristic enables Deep Neural Networks (DNNs) to efficiently fit clean samples in the early phases of training [21; 20], while simultaneously preventing the overfitting of noisy labels in the later stages of the training process. As illustrated in Figure 1, \(_{}\) achieves a stable test accuracy curve, even in the challenging scenario with 0.8 symmetric label noise, without overfitting to noisy labels. On the contrary, CE with the standard softmax tends to rapidly overfit to noisy labels after the early phase of training, leading to poor performance.

### Better Trade-off between Robustness and Effective Learning

It can be noted that the incorporation of \(\)-\(\) somewhat sacrifices the fitting ability of the CE loss on clean datasets, as shown in Figure 1(a). Therefore, we need to enhance the fitting ability using additional techniques. Inspired by the Active Passive Loss , we propose to accommodate with the symmetric loss MAE. For instance, we formulate the combination of \(_{}\) and MAE (a.k.a., \(_{}\)+MAE) as follows

\[L_{_{}+}= L_{_{}}+  L_{},\] (3.5)

ditto for \(_{}\)+MAE.

**Lemma 3**.: _For any loss function \(L_{}\) with \(\)-\(\) and symmetric loss function \(L_{}\) defined in Equation 1.1, the excess risk bound of \( L_{}+ L_{}\) is equivalent to that of \( L_{}\)._

Lemma 3 suggests that the \(\)-\(\)-enhanced loss function \(L_{}\) can be seamlessly integrated with any symmetric loss function while not modifying the inherent robustness. As can be noticed in Figure 1(c) and Figure 1(d), \(_{}\)+MAE not only depicts strong fitting capabilities but also achieves better noise tolerance. More interestingly, the test accuracy on clean datasets obtained by \(_{}\)+MAE even exceeds that of the standard CE loss.

Strict Convexity of \(_{}\)+MAE.To elaborate on how the combination of \(_{}\) and MAE can overcome the underfitting issue, we conduct an in-depth analysis from the optimization perspective. When the prediction \(t=y\), the gradients of \(_{}\), CE and MAE w.r.t. \(p_{y}(0,1]\), are \(-+m}\), \(-}\) and \(-2\), respectively. As can be seen, CE and \(_{}\) are strictly convex, while MAE exhibits linearity. Moreover, CE has stronger convexity compared to \(_{}\) (specifically, the gradient of CE changes more rapidly as \(1/p_{y}^{2}>1/(p_{y}+m)^{2}\)), rendering CE more susceptible to overfitting noisy labels while \(_{}\) suffering from underfitting for large \(m\), as illustrated in Figure 1(a) and Figure 1(b). Conversely, owing to the linearity, MAE treats every sample equally, making it robust to label noise but leading to more training time for convergence . Hence, the combination of \(_{}\) and MAE, which notably forms a strictly convex function (where the convexity can be controlled by \(m\)), can provide better trade-off between robustness and effective learning.

Association with APL.Additionally, our proposed \(_{}\)+MAE coincides with the concept of active and passive losses in . Specifically, for a loss function denoted as \(L(f(),y)=_{1}(f(),y)+_{k y}_{2}(f(),k)\), \(L\) is active if \(_{2}(f(),k)=0\) for any \(k y\), and \(L\) is passive if \(_{2}(f(),k) 0\) for some \(k y\). Active losses only explicitly maximize the target probability \(f()_{y}\), while passive losses also explicitly minimize non-target probabilities \(\{f()_{k}\}_{k y}\). For example, CE is an active loss, while MAE is passive. Based on these two loss terms, Ma et al.  proposed to combine a robust active loss and a robust passive loss into an "Active Passive Loss" (APL) framework for improving

Figure 1: Test accuracies on CIFAR-10 under symmetric noise with different \(m\), where the red box represents the zoomed-in accuracies of the last 20 epochs. (a) and (b) illustrate \(_{}\) with 0 (clean) and 0.8 noise rates, respectively. (c) and (d) illustrate \(_{}\)+MAE (\(=0.01,=5\)) similarly.

sufficient learning with underfitting losses. Note that CE\({}_{}\) is also active, thus CE\({}_{}\)+MAE coincides with the APL framework and further mitigates the underfitting issue.

To further validate CE\({}_{}\)+MAE, we incorporate it with sample selection, pseudo-label prediction , and MixUp , culminating in a semi-supervised learning algorithm we term CE\({}_{}\)+MAE (Semi). The algorithm details can be found in the Appendix C. In our experiments, we use "CE\({}_{}\)+MAE (Semi)" to ensure a fair comparison with other hybrid methods with sample selection and semi-supervised learning (SSL). No additional techniques are utilized for "CE\({}_{}\)+MAE".

## 4 Experiments

In this section, we conduct extensive experiments to validate the superiority of \(\)-**softmax** in mitigating label noise. Complete experimental setting and results can be found in the Appendix D and E.

### Evaluation on Benchmark Datasets

We evaluate our proposed methods on benchmark datasets CIFAR-10 / CIFAR-100  with synthetic label noise, following [6; 7].

Baselines.We consider several baseline methods for comparison, including Standard CE and FL ; MAE; GCE ; NLNL ; SCE ; APL , including NCE+MAE, NCE+RCE, and NFL+RCE; AFLs , including NCE+AEL, NCE+AGCE, and NCE+AUL; LDR-KL ; and LogitClip , including CE+LC.

  &  &  &  \\  & & 0.2 & 0.4 & 0.6 & 0.8 & 0.1 & 0.2 & 0.3 & 0.4 \\  CE & 90.50u.35 & 75.47u.02.7 & 58.46u.01.2 & 39.16u.00.3 & 18.95u.03.8 & 65.98u.03.1 & 83.82u.004 & 79.35u.06.7 & 75.28u.05 \\ FL & 89.70u.24 & 74.50u.18 & 58.23u.04.0 & 38.69u.06 & 19.47u.7u.4 & 86.64u.01.2 & 83.08u.07 & 79.34u.03.7 & 74.68u.03.1 \\ GCE & 89.42u.21 & 86.87u.06 & 82.24u.25 & 68.43u.26 & 25.82u.1 & 83.84u.30 & 26.17u.02 & 80.72u.02.4 & 74.01u.53 \\ NLNL & 90.73u.20 & 73.70u.05 & 63.90u.04.4 & 50.68u.40 & 27.95u.34.5 & 88.54u.02.5 & 84.74u.00.8 & 81.26u.04.3 & 76.97u.05 \\ SCE & 91.30u.08 & 87.58u.05 & 79.47u.04 & 59.14u.07 & 25.88u.09 & 89.87u.02 & 86.48u.02.5 & 81.30u.18 & 74.99u.01 \\ NCE+MAE & 89.02u.20 & 86.79u.23 & 86.04u.14 & 75.93u.44 & 46.96u.07 & 88.80u.02.7 & 85.53u.08 & 81.10u.02.5 & 74.98u.08 \\ NCE+RCE & 91.03u.28 & 88.41u.26 & 85.13u.36 & 79.20u.06 & 55.28u.21.6 & 90.25u.08 & 88.11u.02.3 & 83.53u.08.18 & **79.43u.21** \\ NFL+RCE & 91.08u.29 & 89.00u.02.3 & 85.90u.10 & 79.79u.52 & 55.47u.23 & 89.99u.03.5 & 88.33u.02.6 & 85.27u.01.3 & 79.05u.05 \\ NCE+AUL & 91.06u.24 & 89.11u.07 & 85.79u.10 & 76.75u.20 & 57.59u.84 & 9.01u.82.02 & 88.30u.04 & 85.28u.04 & 79.14u.36 \\ NCE+AEGCE & 91.13u.11 & 89.00u.28 & 85.91u.10 & **80.36u.30** & 48.99u.84 & 89.99u.09 & 89.36u.01 & 88.57u.31u.2 & **79.28u.37** \\ NCE+AEL & 88.43u.25 & 88.64u.03 & 83.06u.27 & 75.15u.3 & 43.22u.46 & 87.59u.38 & 85.89u.04 & 82.87u.04.16 & 77.58u.12 \\ LDR-KL & 91.38u.35 & 89.01u.09 & 85.46u.01 & 74.93u.34 & 37.8u.80 & 90.24u.18 & 88.38u.02 & 85.03u.16 & 77.68u.07 \\ CE+LC & 90.06u.41 & 85.66u.02 & 79.18u.57 & 53.87u.05 & 21.04u.07 & 87.99u.06 & 84.01u.00 & 79.71u.51 & 74.34u.03 \\ 
**CE\({}_{}\)+MAE** & 91.40u.12 & **89.29u.04** & **85.93u.10** & 79.52u.14 & **58.96u.70** & **90.30u.01** & **88.62u.18** & **85.66u.12** & 78.91u.02 \\
**FL\({}_{}\)+MAE** & 91.11u.03 & **89.13u.25** & **86.15u.29** & **79.81u.27** & **58.02u.12** & **90.39u.15** & **88.40u.07** & 85.31u.17 & 79.04u.010 \\    
  &  &  &  \\  & & 0.2 & 0.4 & 0.6 & 0.8 & 0.1 & 0.2 & 0.3 & 0.4 \\  CE & 70.79u.58 & 56.21u.04 & 39.31u.74 & 22.38u.74 & 7.33u.10 & 16.51u.00.74 & 58.26u.31 & 49.99u.04.54 & 41.15u.04 \\ FL & 70.58u.34 & 56.32u.41 & 40.83u.52 & 22.44u.54 & 7.68u.03 & 65.0u.04.6 & 58.12u.04 & 51.16u.32 & 41.46u.38 \\ GCE & 70.57u.25 & 64.55u.36 & 56.60u.61 & 45.19u.02 & 19.85u.08 & 63.94u.28 & 60.89u.06 & 53.36u.54 & 40.82u.05 \\ NLNL & 68.72u.06 & 46.99u.31 & 30.29u.61 & 16.60u.90 & 11.01u.24 & 29.5u.12 & 59.5u.12 & 59.10u.96 & 42.81u.13 & 35.10u.02 \\ SCE & 70.41u.20 & 52.53u.76 & 40.23u.29 & 21.44u.52 & 7.63u.04 & 64.54u.30 & 57.62u.00 & 75.71u.09 & 41.01u.04 \\ NCE+MAE & 67.69u.05 & 63.21u.04 & 57.91u.05 & 45.26u.04 & 32.72u.99 & 65.70u.04 & 62.87u.04 & 55.82u.19 & 41.86u.02 \\ NCE+RCE & 67.89u.47 & 64.60u.02 & 58.64u.10 & 45.25u.50 & 24.87u.05 & 62.02u.08 & 63.18u.03 & 55.05u.32 & 41.21u.06 \\ NPL+RCE & 68.28u.30 & 64.57u.03 & 57.66u.8u.04 & 47.45u.70 & 42.5u.32 & 40.51u.86 & 53.63u.00 & 55.33u.05 & 40.82u.07 \\ NCE+AUL & 69.55u.06Results.Table 2 presents the test accuracy of various loss functions under symmetric and asymmetric label noise. As can be seen, our proposed \(\)-**softmax**-enhanced loss functions, CE\({}_{}\)+MAE and FL\({}_{}\)+MAE, demonstrate remarkable performance, ranking among the top-2 in most cases across both datasets. These methods consistently outperform others such as GCE, SCE, NLNL, NCE+MAE and LDR-KL, regardless of the noise rates. In scenarios of clean labels, CE\({}_{}\)+MAE and FL\({}_{}\)+MAE also exhibit strong fitting abilities, outperforming NCE+RCE and NCE+AGCE. In particular, on CIFAR-100 with 0.4 asymmetric noise, most robust loss functions have no effect, but our methods achieve over 48% accuracy, significantly outperforming all other methods. These findings underscore the robustness and effectiveness of \(\)-**softmax**-enhanced loss functions, delivering their excellent performance in various noise scenarios.

Ablation Experiments.We perform detailed ablation experiments to further explore the role of each component and hyperparameter \(m\) in our CE\({}_{}\)+MAE, experimental results are shown in Table 3. We can observe that CE will severely fit the noise label, and the symmetric loss MAE is difficult to optimize. CE+MAE (i.e., \(m=0\)) is a trade-off between robustness and fitting ability, increasing noise tolerance at the cost of reducing fitting ability on clean labels, consistent with previous works . In particular, our CE\({}_{}\)+MAE shows remarkable properties. As the parameter \(m\) experiences a moderate increase, CE\({}_{}\)+MAE not only achieves noise tolerance for symmetric and asymmetric noise, but also achieves effective learning for the clean scenario. Additionally, the experimental results suggest that strict constraints are better suited for symmetric noise, while looser constraints are more effective for asymmetric noise.

Visualization.We conduct a further analysis to compare the effectiveness of CE\({}_{}\)+MAE and traditional CE in learning representations. We train models with different label noise and use the trained models to extract feature representations of the test set by t-SNE . The visualizations for CIFAR-10 symmetric noise are depicted in Figure 2. Notably, the embeddings generated by CE show evident overfitting to label noise, as seen in the blending of embeddings from distinct classes. In sharp contrast, embeddings from the CE\({}_{}\)+MAE method consistently form clear, well-separated clusters, demonstrating its superior ability to learn robust and distinct representations under noisy label conditions.

### Evaluation on Human-Annotated Datasets

We further conduct comparison studies on human-annotated datasets CIFAR-10N/CIFAR-100N , following the experiment setting in .

    &  &  &  \\  & & 0.4 & 0.8 & 0.4 \\  CE & 70.79±0.58 & 39.31±0.74 & 73.33±0.10 & 41.15±1.04 \\ MAE & 5.31±1.19 & 2.78±1.68±1.23±0.98 & 3.11±0.26 \\ CE\({}_{}\)+MAE (\(m=0\)) & 69.3±0.51 & 37.00±0.49 & 11.65±0.18 & 41.53±0.97 \\ CE\({}_{}\)+MAE (\(m=1e2\)) & 70.55±0.47 & 39.39±0.77 & 13.05±0.58 & **48.51±0.36** \\ CE\({}_{}\)+MAE (\(m=1e4\)) & 70.83±0.18 & **59.20±0.42** & **26.30±0.46** & 40.36±0.96 \\ CE\({}_{}\)+MAE (\(m=1e5\)) & 67.72±0.88 & 56.41±0.22 & 22.14±0.56 & 7.56±1.10 \\   

Table 3: Ablation experiments on CIFAR-100. The results “mean\(\)std” are reported over 3 random runs and the best results are **boldfaced**. If \(m=0\), CE\({}_{}\)+MAE equals CE+MAE.

Figure 2: Visualizations of learned representations on CIFAR-10 with symmetric label noise. The x-axis and y-axis represent the first and second dimensions of the 2D embeddings, respectively.

[MISSING_PAGE_FAIL:9]

Results.In Table 5, we showcase the accuracies achieved on WebVision, ILSVRC12 and Clothing1M by various leading methods. Notably, our CE\({}_{}\)+MAE method outshines others, achieving the highest results on all real-world datasets. It surpasses CE by approximately 5.5% on WebVision and 6.5% on ILSVRC12. For Clothing1M, we finetune a pretrained ResNet-50, so the differences between the methods are relatively small, but our method still achieves the best accuracy. These results underline the robustness and efficacy of the \(\)-**softmax**-enhanced loss function in real-world scenarios.

## 5 Conclusion

In this paper, we introduced \(\)-**softmax**ax, a simple yet effective and theoretically sound scheme for noise-tolerant learning. Our method is not only easy to implement but also can be seamlessly integrated with any softmax-based DNNs, requiring just two additional lines of code. Our rigorous and comprehensive theoretical analysis reveals that \(\)-**softmax** effectively alleviates the common issue of overfitting to noisy labels. Furthermore, we propose to incorporate \(\)-**softmax**-enhanced loss functions with MAE, achieving better trade-off between effective learning and robustness. Extensive experimental results demonstrate the superior performance of our method in mitigating label noise.

## Broader Impacts

This work has the potential to advance the development of machine learning methods that can be deployed in contexts where it is costly to gather accurate annotations. This is an important issue in applications such as medicine, where machine learning has great potential societal impact. This work will not have negative social impacts.