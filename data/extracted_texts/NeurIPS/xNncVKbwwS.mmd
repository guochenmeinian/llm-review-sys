# Universal Online Convex Optimization

with \(\) Projection per Round

 Wenhao Yang\({}^{1,2}\), Yibo Wang\({}^{1,2}\), Peng Zhao\({}^{1,2}\), Lijun Zhang\({}^{1,2,}\)

\({}^{1}\)National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China

\({}^{2}\)School of Artificial Intelligence, Nanjing University, Nanjing, China

{yangwh, wangyb, zhaop, zhanglj}@lamda.nju.edu.cn

Lijun Zhang\({}^{1,2,}\)

\({}^{1}\)National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China

\({}^{2}\)School of Artificial Intelligence, Nanjing University, Nanjing, China

{yangwh, wangyb, zhaop, zhanglj}@lamda.nju.edu.cn

Lijun Zhang\({}^{1,2,}\)

\({}^{1}\)National Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, China

\({}^{2}\)School of Artificial Intelligence, Nanjing University, Nanjing, China

{yangwh, wangyb, zhaop, zhanglj}@lamda.nju.edu.cn

###### Abstract

To address the uncertainty in function types, recent progress in online convex optimization (OCO) has spurred the development of universal algorithms that simultaneously attain minimax rates for multiple types of convex functions. However, for a \(T\)-round online problem, state-of-the-art methods typically conduct \(O( T)\) projections onto the domain in each round, a process potentially time-consuming with complicated feasible sets. In this paper, inspired by the black-box reduction of Cutkosky and Orabona (2018), we employ a surrogate loss defined over simpler domains to develop universal OCO algorithms that only require \(1\) projection. Embracing the framework of prediction with expert advice, we maintain a set of experts for each type of functions and aggregate their predictions via a meta-algorithm. The crux of our approach lies in a uniquely designed expert-loss for strongly convex functions, stemming from an innovative decomposition of the regret into the meta-regret and the expert-regret. Our analysis sheds new light on the surrogate loss, facilitating a rigorous examination of the discrepancy between the regret of the original loss and that of the surrogate loss, and carefully controlling meta-regret under the strong convexity condition. With only \(1\) projection per round, we establish optimal regret bounds for general convex, exponentially concave, and strongly convex functions simultaneously. Furthermore, we enhance the expert-loss to exploit the smoothness property, and demonstrate that our algorithm can attain small-loss regret for multiple types of convex and smooth functions.

## 1 Introduction

Online convex optimization (OCO) stands as a pivotal online learning framework for modeling many real-world problems (Hazan, 2016). OCO is commonly formulated as a repeated game between the learner and the environment with the following protocol. In each round \(t[T]\), the learner chooses a decision \(_{t}\) from a convex domain \(^{d}\); after submitting this decision, the learner suffers a loss \(f_{t}(_{t})\), where \(f_{t}\) is a convex function selected by the environment. The goal of the learner is to minimize the cumulative loss over \(T\) rounds, i.e., \(_{t=1}^{T}f_{t}(_{t})\), and the standard performance measure is the _regret_(Cesa-Bianchi and Lugosi, 2006):

\[_{T}=_{t=1}^{T}f_{t}(_{t})-_{ }_{t=1}^{T}f_{t}(),\] (1)

which quantifies the difference between the cumulative loss of the online learner and that of the best decision chosen in hindsight.

Although there are plenty of algorithms to minimize the regret of convex functions, including general convex, exponentially concave (abbr. exp-concave) and strongly convex functions (Zinkevich, 2003; Shalev-Shwartz et al., 2007; Hazan et al., 2007), most of them can only handle one specific function type, and need to estimate the moduli of strong convexity and exp-concavity. The demand for prior knowledge motivates the development of _universal_ algorithms for OCO, which aim to attain minimax optimal regret guarantees for multiple types of convex functions simultaneously (Bartlett et al., 2008; van Erven and Koolen, 2016; Wang et al., 2019; Mhammedi et al., 2019; Zhang et al., 2022). State-of-the-art methods typically adopt a two-layer structure following the prediction with expert advice (PEA) framework (Cesa-Bianchi and Lugosi, 2006). Specifically, they maintain \(O( T)\) expert-algorithms with different configurations to handle the uncertainty of functions and deploy a meta-algorithm to track the best one. While this two-layer framework has demonstrated effectiveness in endowing algorithms with universality, it raises concerns regarding the computational efficiency. Since each expert-algorithm needs to execute one projection onto the feasible domain \(\) per round, standard universal algorithms perform \(O( T)\) projections in each round, which can be time-consuming in practical scenarios particularly when projecting onto complicated domains.

In the literature, there indeed exists an effort to reduce the number of projections required by universal algorithms tailored for _exp-concave functions_(Mhammedi et al., 2019). This is achieved by applying the black-box reduction of Cutkosky and Orabona (2018), which reduces an OCO problem on the original (but can be complicated) feasible domain to a more manageable one on a simpler domain, such as an Euclidean ball. Deploying an existing universal algorithm (van Erven and Koolen, 2016) on the reduced problem enables us to attain optimal regret for exp-concave functions, crucially, with only _one_ single projection per round and no prior knowledge of exp-concavity required. However, this black-box approach _cannot_ be extended to strongly convex functions (see Section 3.1 for technical discussions). Therefore, it is still unclear on how to reduce the number of projections of universal algorithms to \(1\), and at the same time ensure optimal regret for strongly convex functions (as well as general convex and exp-concave functions).

In this paper, we affirmatively solve the above question by introducing an efficient universal OCO algorithm. Our solution employs the black-box reduction Cutkosky (2020) to cast the original problem on the constrained domain \(\) to an alternative one in terms of the surrogate loss on a simpler domain \(\). Specifically, we construct multiple experts updated in domain \(\), each optimizing a expert-loss specialized for a distinct function type. Then, we combine their predictions by a meta-algorithm, and perform the _only projection_ onto the feasible domain \(\). The meta-algorithm chooses the linearized surrogate loss to measure the performance of experts, and is required to yield a second-order regret (Zhang et al., 2022). The key novelty of our algorithm lies in the uniquely designed _expert-loss for strongly convex functions_, which is motivated by an innovative decomposition of the regret into the meta-regret and the expert-regret. To effectively deal with strongly convex functions, we _explore the domain-converting surrogate loss in depth and illuminate its refined properties_. Our new insights tighten the regret gap in terms of original loss and surrogate loss, and further exploit strong convexity to compensate the meta-regret, thus achieving the optimal regret for strongly convex functions. Section 3.2 provides a formal description of our key ideas. With only 1 projection

    &  &  &  \\    & & cvx & exp-concave & str-cvx \\   & van Erven and Koolen (2016) & \(O()\) & \(O(d T)\) & \(O(d T)\) & \(O( T)\) \\  & Mhammedi et al. (2019) & \(O()\) & \(O(d T)\) & \(O(d T)\) & \(1\) \\  & Wang et al. (2019) & \(O()\) & \(O(d T)\) & \(O( T)\) & \(O( T)\) \\  & Zhang et al. (2022) & \(O()\) & \(O(d T)\) & \(O( T)\) & \(O( T)\) \\   & Theorem 1 of this work & \(O()\) & \(O(d T)\) & \(O( T)\) & \(1\) \\  ()\) is smooth} & Wang et al. (2020) & \(O(})\) & \(O(d L_{T})\) & \(O( L_{T})\) & \(O( T)\) \\  & Zhang et al. (2022) & \(O(})\) & \(O(d L_{T})\) & \(O( L_{T})\) & \(O( T)\) \\    & Theorem 2 of this work & \(O(})\) & \(O(d L_{T})\) & \(O( L_{T})\) & \(1\) \\   

Table 1: A summary of our universal algorithms and previous studies over \(T\) rounds \(d\)-dimensional functions, where \(L_{T}\) denotes the small-loss quantity. Abbreviations: cvx \(\) convex, exp-concave \(\) exponentially concave, str-cvx \(\) strongly convex, # PROJ \(\) number of projections per round.

per round, our algorithm attains \(O()\), \(O( T)\), and \(O( T)\) regret for general convex, \(\)-exp-concave, and \(\)-strongly convex functions, respectively.

We further establish _small-loss regret_ for universal OCO with _smooth_ functions. The small-loss quantity \(L_{T}=_{}_{t=1}^{T}f_{t}()\) is defined as the cumulative loss of the best decision chosen from the domain \(\), which is at most \(O(T)\) under standard OCO assumptions and meanwhile can be much smaller in benign environments. To achieve small-loss regret bounds, we design an enhanced expert-loss for smooth and strongly convex functions and integrate it into our two-layer framework, which finally leads to a universal OCO algorithm achieving \(O(})\), \(O( L_{T})\), and \(O( L_{T})\) small-loss regret for three types of convex functions, respectively. Notably, all those bounds are _optimal_ and the algorithm only requires _one_ projection per iteration. We summarize our results and compare with previous studies of universal algorithms in Table 1.

Organization.The rest of the paper is organized as follows. Section 2 presents the preliminaries and reviews several mostly related works. Section 3 illuminates the technical challenges and describes our key ideas. Section 4 provides the overall algorithms and regret analysis. We finally conclude the paper in Section 5. All the proofs and omitted details are deferred to appendices.

## 2 Preliminaries and related works

In this section, we first present preliminaries for OCO, and then review several most related works to our paper, including universal algorithms and projection-efficient algorithms.

### Preliminaries

We introduce two typical assumptions of online convex optimization (Hazan, 2016).

**Assumption 1** (bounded domain): _The feasible domain \(^{d}\) contains the origin \(\), and the diameter is bounded by \(D\), i.e., \(\|-\| D\) holds for any \(,\)._

**Assumption 2** (bounded gradient norms): _The norm of the gradients of all online functions over the domain \(\) is bounded by \(G\), i.e., \(\| f_{t}()\| G\) holds for all \(\) and \(t[T]\)._

Throughout the paper we use \(\|\|\) for \(_{2}\)-norm in default. Owing to Assumption 1, we can always construct an Euclidean ball \(=\{\|\| D\}\) containing the original feasible domain \(\).

Next, we state definitions of strong convexity and exp-concavity (Hazan, 2016), and introduce an important property of exp-concave functions (Hazan et al., 2007, Lemma 3).

**Definition 1** (strongly convex functions): _A function \(f:\) is called \(\)-strongly convex, if the condition \(f() f()+ f(),- +\|-\|^{2}\) holds for all \(,\)._

**Definition 2** (exponentially-concave functions): _A function \(f:\) is called \(\)-exponentially-concave, if the function \((- f())\) is concave over the feasible domain \(\)._

**Lemma 1**: _For an \(\)-exp-concave function \(f:\), if the feasible domain \(\) has a diameter \(D\) and \(\| f()\| G\) holds for \(\), then we have_

\[f() f()+ f(),- + f(),- ^{2},\] (2)

_for all \(,\), where \(=\{,\}\)._

There are many efforts devoted to minimizing regret, including general convex, \(\)-exp-concave, and \(\)-strongly convex functions. For general convex functions, online gradient descent (OGD) with step size \(_{t}=O(1/)\), attains an \(O()\) regret (Zinkevich, 2003). For \(\)-exp-concave functions, online Newton step (ONS) is equipped with an \(O( T)\) regret (Hazan et al., 2007). For \(\)-strongly convex functions, OGD with step size \(_{t}=O(1/[ t])\), achieves an \(O( T)\) regret (Shalev-Shwartz et al., 2007). These regret bounds are proved to be minimax optimal (Ordentlich and Cover, 1998; Abernethy et al., 2008). Furthermore, tighter bounds are attainable when the loss functionsenjoy additional properties, such as smoothness (Shalev-Shwartz, 2007; Luo and Schapire, 2015; Srebro et al., 2010; Orabona et al., 2012; Chiang et al., 2012; Yang et al., 2014; Mohri and Yang, 2016; Zhang et al., 2019; Zhao et al., 2020, 2024; Chen et al., 2024) and sparsity of gradients (Duchi et al., 2010; Tieleman and Hinton, 2012; Mukkamala and Hein, 2017; Kingma and Ba, 2015; Reddi et al., 2018; Loshchilov and Hutter, 2019; Wang et al., 2020a). We discuss _small-loss_ regret below.

For general convex and smooth functions, Srebro et al. (2010) prove that OGD with constant step size attains an \(O()\) regret bound, where \(L\) is the upper bound of \(L_{T}\). The limitation of their method is that it requires to know \(L\) beforehand. To address this limitation, Zhang et al. (2019) propose scale-free online gradient descent (SOGD), which is a special case of scale-free mirror descent algorithm (Orabona and Pal, 2018), and establish an \(O(})\) small-loss regret bound without the prior knowledge of \(L_{T}\). For \(\)-exp-concave and smooth functions, ONS attains an \(O( L_{T})\) small-loss regret bound (Orabona et al., 2012). For \(\)-strongly convex and smooth functions, a variant of OGD, namely S\({}^{2}\)OGD, is introduced to achieve an \(O( L_{T})\) small-loss regret bound (Wang et al., 2020b). Such bounds reduce to the minimax optimal bounds in the worst case, but could be much tighter when the comparator has a small loss, i.e., \(L_{T}\) is small.

### Universal algorithms

Most existing online algorithms can only handle one type of convex function and need to know the moduli of strong convexity and exp-concavity beforehand. Universal online learning aims to remove such requirements of domain knowledge. The first universal OCO algorithm is adaptive online gradient descent (AOGD) (Bartlett et al., 2008), which achieves \(O()\) and \(O( T)\) regret bounds for general convex and strongly convex functions, respectively. However, the algorithm still needs to know the modulus of strong convexity and does not support exp-concave functions.

An important milestone is the multiple eta gradient (MetaGrad) algorithm (van Erven and Koolen, 2016), which adapt to general convex and exp-concave functions without knowing the modulus of exp-concavity. MetaGrad constructs multiple expert-algorithms with various learning rates and combines their predictions by a meta-algorithm called Tilted Exponentially Weighted Average (TEWA). To avoid prior knowledge, each expert minimizes the expert-loss parameterized by a learning rate \(\),

\[^{}_{t,}()=- f_{t}(_{t }),_{t}-+^{2} f_{t}(_{t }),_{t}-^{2}.\] (3)

MetaGrad maintains \(O( T)\) experts to minimize (3), and attains \(O()\) and \(O( T)\) regret for general convex and \(\)-exp-concave functions, respectively. To further support strongly convex functions, Wang et al. (2019) propose a new type of expert-losses defined as

\[^{}_{t,}()=- f_{t}(_{t }),_{t}-+^{2}G^{2}\|_{t}-\| ^{2}\] (4)

where \(G\) is the gradient norm upper bound, and introduce an expert-loss for general convex functions

\[^{}_{t,}()=- f_{t}(_{t }),_{t}-+^{2}G^{2}D^{2}\] (5)

where \(D\) is the upper bound of the diameter of \(\). Their algorithm, named as Maler, obtains \(O()\), \(O( T)\) and \(O( T)\) regret for general convex, \(\)-strongly convex functions, and \(\)-exp-concave functions, respectively. Later, Wang et al. (2020b) extend Maler by replacing \(G^{2}\) in (4) and (5) with \(\| f_{t}(_{t})\|^{2}\), thereby enabling their algorithm to deliver small-loss regret bounds. Under the smoothness condition, their algorithm achieves \(O(})\), \(O( L_{T})\) and \(O( L_{T})\) regret for general convex, \(\)-strongly convex, and \(\)-exp-concave functions, respectively.

MetaGrad and its variants require the carefully designed expert-losses. Zhang et al. (2022) propose a different universal strategy that avoids the construction of losses. The basic idea is to let each expert handle original functions and deploy a meta-algorithm over _linearized loss_. Importantly, the meta-algorithm is required to yield a second-order regret (Gaillard et al., 2014) to exploit strong convexity and exp-concavity. By incorporating existing online algorithms as experts, their approach inherits the regret of any expert designed for strongly convex functions and exp-concave functions, and also obtains minimax optimal regret (and small-loss regret) for general convex functions.

Although state-of-the-art universal algorithms can adapt to multiple function types, they create \(O( T)\) experts per round. As a result, they need to perform \(O( T)\) projections in each round, which can be time-consuming in practical scenarios with complicated domains. To address this limitation, we aim to develop projection-efficient algorithms for universal OCO.

### Projection-efficient algorithms

In the studies of parameter-free online learning, Cutkosky and Orabona (2018) propose a black-box reduction technique from constrained online learning to unconstrained online learning. To avoid regret degeneration, they design the _domain-converting surrogate loss_\(_{t}:\) defined as,

\[_{t}()= f_{t}(_{t}), +\| f_{t}(_{t})\| S_{}()\] (6)

where \(S_{}()=\|-_{}[]\|\) is the distance function to the feasible domain \(\). Then, we can employ an unconstrained online learning algorithm that minimizes (6) to obtain the prediction \(_{t}\), and output its prediction on domain \(\), i.e., \(_{t}=_{}[_{t}]\). Cutkosky and Orabona (2018, Theorem 3) have proved that the above surrogate loss satisfies \(\|_{t}(_{t})\|\| f_{t}(_{t})\|\), and

\[ f_{t}(_{t}),_{t}- 2 _{t}(_{t})-_{t}()  2_{t}(_{t}),_{t}-\] (7)

for all \(t[T]\) and any \(\). Based on this fact, we know that the regret of the unconstrained problem directly serves as an upper bound for that of the original problem, hence reducing the original problem to an unconstrained surrogate problem and retaining the order of regret.

Subsequently, Cutkosky (2020) introduces a new surrogate loss \(g_{t}:\) defined as,

\[g_{t}()= f_{t}(_{t}),- _{\{ f_{t}(_{t}),_{t}<0\} } f_{t}(_{t}),_{t} S_{}()\] (8)

where \(_{t}=_{t}-_{t}}{\|_{t}-_{t}\|}\) is the unit vector of the projection direction. As depicted in the following lemma, this surrogate loss avoids the multiplicative constant \(2\) on the right-hand side of (7).

**Lemma 2** (Theorem 2 of Cutkosky (2020)): _The function defined in (8) is convex, and it satisfies \(\| g_{t}(_{t})\|\| f_{t}(_{t})\|\). Furthermore, for all \(t\) and all \(\), we have_

\[ f_{t}(_{t}),_{t}- g_{ t}(_{t})-g_{t}() g_{t}(_{t}), _{t}-.\] (9)

While the black-box reduction is proposed for the constrained-to-unconstrained conversion, it also facilitates the conversion to another constrained problem (i.e., \(^{d}\)). This enables us to transform OCO problem on a complicated domain into another on simpler domains such that the projection is much easier. Building on this idea, Mhammedi et al. (2019) introduce an efficient implementation of MetaGrad (van Erven and Koolen, 2016), which only conducts \(1\) projection onto the original domain in each round, and keeps the order of regret bounds. However, as detailed in the following section, the black-box reduction does not adequately extend to strongly convex functions. We also mention that Zhao et al. (2022) recently employ the technique to non-stationary OCO with non-trivial modifications to develop efficient algorithms for minimizing dynamic regret and adaptive regret. However, they focus on the convex functions and do not involve the considerations of exp-concave and strongly convex functions as concerned in our paper.

## 3 Technical challenge and our key ideas

In this section, we elaborate on the technical challenges and our key ideas.

### Technical challenge

As mentioned, Mhammedi et al. (2019) exploit the black-box reduction scheme of (Cutkosky and Orabona, 2018) to improve the projection efficiency of MetaGrad (van Erven and Koolen, 2016). We summarize their algorithm in Algorithm 1. In the following, we will demonstrate its effectiveness for exp-concave functions and explain why it fails for strongly convex functions.

Success in exp-concave functions.By applying the black-box reduction as described in Section 2.3, Mhammedi et al. (2019) utilize MetaGrad to minimize the surrogate loss \(_{t}()\) in (6) over an Euclidean ball \(\). The projection operations inside MetaGrad are over \(\) and thus negligible. Notice that Algorithm 1 demands only \(1\) projection onto \(\) in Step 4. According to regret bound of MetaGrad, Algorithm 1 enjoys a second-order bound (Mhammedi et al., 2019; Theorem 10),

\[_{t=1}^{T}_{t}(_{t}),_{t}-  O(^{T} _{t}(_{t}),_{t}-^{2}+d T }).\] (10)

[MISSING_PAGE_FAIL:6]

An important caveat is that our expert-loss (14) evaluates the performance of the expert (associated with strongly convex functions) based on the distance between its output \(\) and the _actual_ decision \(_{t}\), as opposed to the unprojected intermediate one \(_{t}\) in (15).

In fact, this design of expert-loss (14) stems from a novel regret decomposition as explained below. First, by strong convexity of \(f_{t}\) and the property of the domain-converting surrogate loss, we have

\[&_{t=1}^{T}f_{t}(_{t})-_{t=1}^{T}f_{t}( )}{}_{t=1}^{T} g_{t}( _{t}),_{t}--_{t=1}^ {T}\|_{t}-\|^{2}\\ =&_{t=1}^{T} g_{t}(_{t}),_{t}-_{t}^{i}+_{t=1}^{T} g_{t}( _{t}),_{t}^{i}--_{t =1}^{T}\|_{t}-\|^{2}\] (16)

where \(_{t}^{i}\) denotes the decision of the \(i\)-th expert. The first term of the above bound is the meta-regret in terms of linearized surrogate loss. Then, we reformulate the remaining two terms as follows

\[&_{t=1}^{T} g_{t}(_{t}),_{t}^{i}--_{t=1}^{T}\| _{t}-\|^{2}=_{t=1}^{T}( g_{t}( _{t}),_{t}^{i}+\|_{t}- _{t}^{i}\|^{2})\\ -&_{t=1}^{T}( g_{t}(_{t}),+\|_{t}-\|^{2})- _{t=1}^{T}\|_{t}-_{t}^{i}\|^{2}, \] (17)

where the expert-loss in (14) naturally arises. Combining (16) with (17), we arrive at

\[_{t=1}^{T}f_{t}(_{t})-_{t=1}^{T}f_{t}() {_{t=1}^{T}(_{t}^{}(_{t}^{i})-_{t}^{}())}_{}+^{T}  g_{t}(_{t}),_{t}-_{t}^{i}}_ {}-_{t=1}^{T}\|_{t}-_{t}^{i}\|^{2}.\] (18)

Theoretical analysis.For the expert-regret, since expert-loss (14) is \(\)-strongly convex and its gradients are bounded (see Lemma 6), we can use OGD to achieve an optimal \(O( T)\) regret. Following Zhang et al. (2022), we require the meta-algorithm to yield a second-order regret bound

\[_{t=1}^{T} g_{t}(_{t}),_{t}-_{ t}^{i} O(^{T} g_{t}(_{t}),_{t}-_{t}^{i}^{2}}).\] (19)

Notably, the upper bound of (19) and the negative term in (18) cannot be canceled due to the dismatch between \(_{t}-_{t}^{i}\) and \(_{t}-_{t}^{i}\). To resolve this discrepancy, we demonstrate that the surrogate loss defined in (8) enjoys the following two important improved properties.

**Lemma 3**: _In addition to enjoying all the properties outlined in Lemma 2, the surrogate loss function \(g_{t}:\) defined in (8) satisfies_

\[ f_{t}(_{t}),_{t}-  g_{t}(_{t}),_{t}-- _{\{ f_{t}(_{t}),_{t} 0 \}} f_{t}(_{t}),_{t}-_{t},\] (20)

_for all \(t\) and all \(\). Furthermore, we also have_

\[\{ g_{t}(_{t}),_{t}- _{t}=0,& f_{t}(_{t}),_{t}<0,\\  g_{t}(_{t}),_{t}-_{t} 0,& ..\] (21)

**Remark 1**: We highlight the improvements of Lemma 3 over Lemma 2. First, we provide a tighter connection between the linearized original function and the surrogate loss in (20). Second, we analyze the difference between the actual decision \(_{t}\) and the intermediate decision \(_{t}\), along the direction \( g_{t}(_{t})\) in (21). As shown later, both of them are crucial for controlling the meta-regret. \(\)

Utilizing (20) in Lemma 3, we refine the decomposition in (18) to establish a tighter bound

\[_{t=1}^{T}f_{t}(_{t})-_{t=1}^{T}f_{t}(),,}{}(T)+_{t=1}^ {T} g_{t}(_{t}),_{t}-_{t}^{i}- _{t=1}^{T}\|_{t}-_{t}^{i}\|^{2}- _{T}\] (22)where \((T)\) is the expert-regret, and \(_{T}=_{t=1}^{T}_{\{ f_{t}(_{t}), _{t} 0\}} f_{t}(_{t}), _{t}-_{t} 0\) is the negative term introduced in the surrogate loss. Compared to (18), the new upper bound (22) enjoys an additional negative term \(-_{T}\), which is essential to achieve a favorable regret bound in the analysis.

To utilize the negative quadratic term \(-_{t=1}^{T}\|_{t}-_{t}^{i}\|^{2}\) in (22) for compensating the second-order bound in (19), we need to convert \(_{t}\) to \(_{t}\), a place where (21) comes into play. From (19) and (21), we prove that for any \((0,]\) it holds that (see Lemma 8 for details):

\[_{t=1}^{T} g_{t}(_{t}),_{t}-_{ t}^{i} O(}{2})+} _{t=1}^{T} g_{t}(_{t}),_{t}-_{ t}^{i}^{2}+_{T}.\] (23)

Substituting (23) into (22), the additional term \(_{T}\) is automatically _canceled out_, and we have

\[_{t=1}^{T}f_{t}(_{t})-_{t=1}^{T}f_{t}() (T)+O(}{2})+}_{t=1}^{T} g_{t}(_{t}),_{t}- _{t}^{i}^{2}-_{t=1}^{T}\|_{t} -_{t}^{i}\|^{2}\] \[(T)+O(}{2})+( {}{2}-)_{t=1}^{T}\|_{t}-_ {t}^{i}\|^{2}=O( T)\]

where the final regret bound is because we set \(=\{,\}\).

**Remark 2**: Section 2.3 describes two kinds of surrogate loss, as specified in (6) and (8). Indeed, they _both_ are suitable for parameter-free online learning (Cutkosky, 2020) and non-stationary online learning (Zhao et al., 2022). However, it is essential to adopt the new surrogate loss in our purpose: as established in Lemma 3, both negative terms and the mild difference between \(_{t}\) and \(_{t}\) are exploited in our regret analysis. By contrast, the old surrogate loss (6) lacks these advanced properties. \(\)

## 4 Efficient algorithm for universal online convex optimization

In this section, we present our efficient algorithms for universal OCO. To reduce the cost of projections, we deploy multiple experts on a ball \(=\{\ |\ \|\| D\}\) enclosing domain \(\). After combining their decisions, we project the solution in \(\) onto \(\), which is the only projection onto \(\) per round.

### Efficient algorithm for minimax universal regret

To handle unknown parameters of strong convexity and exp-concavity, we construct two finite sets, i.e., \(_{}\) and \(_{}\), to approximate their values (Zhang et al., 2022). Taking \(\)-strongly convex functions as an example, we assume the unknown modulus \(\) is bounded by \([1/T,1]^{2}\), and set \(_{}=\{1/T,2/T,,2^{N}/T\}\), where \(N=_{2}T\). In this way, for any \([1/T,1]\), there exists a \(_{}\) such that \( 2\). Moreover, we design three types of expert-losses. For general convex functions, we construct the expert-loss as

\[_{t}^{}()= g_{t}(_{t}), -_{t},\] (24)

where \(g_{t}()\) is defined in (8). Since \(_{t}^{}()\) is convex, we use OGD as the expert-algorithm to minimize it. To handle exp-concave functions, we construct the expert-loss for each \(_{}\) as

\[_{t,}^{}()= g_{t}(_{t}),-_{t}+}{2}  g_{t}(_{t}),-_{t}^{2},\] (25)

where \(=\{,\}\). It is easy to verify that \(_{t,}^{}()\) is \(}{4}\)-exp-concave, so we use ONS as the expert-algorithm. For strongly convex functions, we construct the expert-loss for each \(_{}\) as

\[_{t,}^{}()= g_{t}(_{t}),-_{t}+}{2}\|- _{t}\|^{2}.\] (26)

Since \(_{t,}^{}()\) is \(\)-strongly convex, we use OGD with step size \(_{t}=1/[t]\) as the expert-algorithm. Finally, we deploy a meta-algorithm to track the best expert on the fly. Following Zhang et al.

, we use the linearized surrogate loss to measure the performance of the experts, and choose Adapt-ML-Prod [Gaillard et al., 2014] as the meta-algorithm to yield a second-order bound.

Our efficient algorithm for universal OCO is summarized in Algorithm 2. From Steps 2 to 9, it creates a set of experts by running multiple online algorithms over the ball \(\), each specialized for a distinct function type. Then, it maintains a set \(\) consisting of all experts, and the \(i\)-th expert is denoted by \(E^{i}\). In the \(t\)-th round, it computes the weight \(p_{t}^{i}\) of each expert \(E^{i}\) in Step 11 according to Adapt-ML-Prod. After receiving all the predictions from the experts in Step 12, it aggregates them based on their weights to attain \(_{t}\) in Step 13. Next, it conducts the _only_ projection onto the original domain \(\) to obtain the actual decision \(_{t}\) in Step 14. In Step 15, it evaluates the gradient \( f_{t}(_{t})\) to construct the expert-losses in (24), (25), and (26). In Step 16, it sends the corresponding expert-loss to each expert so that it can make predictions for the next round.

Finally, we elucidate how our algorithm determines the weight of the \(i\)-th expert \(E^{i}\). We measure the performance of expert \(E^{i}\) by the linearized surrogate loss, i.e., \(l_{t}^{i}= g_{t}(_{t}),_{t}^{i}-_ {t}\). According to Lemma 2, we have \(|l_{t}^{i}|\| g_{t}(_{t})\|\|_{t}^{i}- _{t}\| 2GD\). Since Adapt-ML-Prod requires the loss to fall within the range of \(\), we normalize \(l_{t}^{i}\) to construct the meta-loss as \(_{t}^{i}=( g_{t}(_{t}),_{t}^{i}-_{t})/(4GD)+\). The loss of the meta-algorithm in the \(t\)-th round is \(_{t}=_{i=1}^{||}p_{t}^{i}_{t}^{i}\), which is a constant \(\) due to its construction and Step 13. For each expert \(E^{i}\), its weight is updated by:

\[p_{t}^{i}=^{i}w_{t-1}^{i}}{_{j=1}^{||}_{t- 1}^{i}w_{t-1}^{j}},\;\;w_{t-1}^{i}=w_{t-2}^{i}(1+_{t-2}^{i} (_{t-1}-_{t-1}^{i}))^{^{i}}{ _{t-2}}}\] (27)

where \(_{t-1}^{i}=\{,|)/(1+_{s=1}^ {t-1}(_{s}-_{s}^{i})^{2})}\}\). In the first round, we set \(w_{0}^{i}=1/||\).

```
1:Input: The modulus set \(_{}\) and \(_{}\), the expert set \(=\), the number of experts \(k=0\)
2:\(k k+1\), create an expert \(E^{1}\) by running OGD with loss (24) over \(\)
3:for all\(_{}\)do
4:\(k k+1\), create an expert \(E^{k}\) by running ONS with loss (25) and parameter \(\) over \(\)
5:endfor
6:for all\(_{}\)do
7:\(k k+1\), create an expert \(E^{k}\) by running OGD with loss (26) and parameter \(\) over \(\)
8:endfor
9: Add all the experts to the set: \(=\{E^{1},E^{2},,E^{k}\}\)
10:for\(t=1\)to\(T\)do
11: Compute the weight \(p_{t}^{i}\) of each expert \(E^{i}\) by (27)
12: Receive the decision \(_{t}^{i}\) from each expert \(E^{i}\) in \(\)
13: Aggregate all the decisions by \(_{t}=_{i=1}^{||}p_{t}^{i}_{t}^{i}\)
14: Submit the decision \(_{t}=_{}[_{t}]\)\(\) The only step projects onto domain \(\) per round.
15: Suffer the loss \(f_{t}(_{t})\) and observe the gradient \( f_{t}(_{t})\)
16: Construct the expert-loss \(_{t}^{}()\), \(_{t}^{}()\) or \(_{t}^{}()\) and sent it to corresponding expert in \(\)
17:endfor ```

**Algorithm 2** Efficient Algorithm for Universal OCO

**Remark 3** While the surrogate loss in (8) involves the projection operation, our proposed meta-loss and expert-losses only access \(g_{t}()\) through \( g_{t}(_{t})\), which is given by Cutkosky ,

\[ g_{t}(_{t})= f_{t}(_{t})-_{\{  f_{t}(_{t}),_{t}<0\}} f _{t}(_{t}),_{t}_{t}\]

where \(_{t}=_{t}-_{t}}{\|_{t}- _{t}\|}\). According to its formulation, the gradient can be directly computed from \(_{t}\) and \(_{t}\), which means no additional projections are needed. Therefore, in each round, our algorithm requires only \(1\) projection onto domain \(\). \(\)

Due to page limit, we provide the expert-algorithms, as well as all the proofs, in Appendix B. The theoretical guarantee of Algorithm 2 is given below.

**Theorem 1**: _Under Assumptions 1 and 2, Algorithm 2 attains \(O()\), \(O( T)\) and \(O( T)\) regret for general convex functions, \(\)-exp-concave functions with \([1/T,1]\), and \(\)-strongly convex functions with \([1/T,1]\), respectively._

**Remark 4**: Similar to previous studies (Wang et al., 2019; Zhang et al., 2022), our universal algorithm also achieves the minimax optimal regret, but only requires \(1\) projection. \(\)

### Efficient algorithm for small-loss universal regret

Furthermore, we consider the small-loss regret for smooth and non-negative online functions. To this end, an additional assumption is required (Srebro et al., 2010).

**Assumption 3**: _All the online functions are non-negative, and \(H\)-smooth over \(\)._

To exploit the smoothness, we enhance the expert-loss for strongly convex functions in (26) as

\[_{t,}^{}()=  g_{t}(_{t}),-_{t}+}{2G^{2}}\| g_{t}(_{t})\|^{2}\|- _{t}\|^{2}.\] (28)

Since \(_{t,}^{}()\) is strongly convex and smooth, we use S\({}^{2}\)OGD (Wang et al., 2020b) as the expert-algorithm. For general convex and exp-concave functions, we reuse (24) and (25) as the expert-losses, and employ ONS (Orabona et al., 2012) and SOGD (Zhang et al., 2019) as the expert-algorithms. The meta-algorithm remains unchanged. In this way, we obtain the following regret guarantee.

**Theorem 2**: _Under Assumptions 1, 2 and 3, the improved version of Algorithm 2 attains \(O(})\), \(O( L_{T})\) and \(O( L_{T})\) regret for general convex functions, \(\)-exp-concave functions with \([1/T,1]\), and \(\)-strongly convex functions with \([1/T,1]\), respectively, where the small-loss quantity \(L_{T}=_{}_{t=1}^{T}f_{t}()\) is the cumulative loss of the best decision from the domain \(\)._

**Remark 5**: With only \(1\) projection in each round, our universal algorithm is able to deliver _optimal_ small-loss regret bounds for multiple types of convex functions simultaneously. In contrast, Wang et al. (2020b) and Zhang et al. (2022) take \(O( T)\) projections to achieve the small-loss regret. \(\)

## 5 Conclusion and future work

In this paper, we propose a projection-efficient universal algorithm that achieves minimax optimal regret for three types of convex functions with only \(1\) projection per round. Furthermore, we enhance our algorithm to exploit the smoothness property and demonstrate that it attains small-loss regret for convex and smooth functions. To demonstrate the effectiveness of our proposed method, we also conduct empirical experiments, and the results are presented in Appendix E.

There are several directions for future research. First, one potentially unfavorable characteristic of our work is the requirements of domain and gradient boundedness. Motivated by the recent developments in parameter-free online learning for unbounded domains and gradients (Orabona, 2014; Orabona and Pal, 2016; Cutkosky and Boahen, 2016, 2017; Foster et al., 2017; Luo et al., 2022; Jacobsen and Cutkosky, 2022, 2023), we will investigate whether our algorithms can further avoid these prior knowledge in the future. Second, in addition to the small-loss bound, another important type of problem-dependent guarantee is the _gradient-variation regret bound_(Zhao et al., 2020, 2024), which has been actively studied recently due to its profound relationship to games and stochastic optimization. In the literature, recent studies (Yan et al., 2023, 2024; Xie et al., 2024; Wang et al., 2024a) achieve almost-optimal gradient-variation regret in universal online learning, but also suffer high projection complexity. Therefore, it remains challenging and important to develop a projection-efficient universal algorithm with optimal gradient-variation regret guarantees. Third, to deal with changing environments, adaptive regret has been proposed to minimize the regret over every interval in various setting of online learning (Hazan and Seshadhri, 2007; Daniely et al., 2015; Wan et al., 2021a; Wang et al., 2024b). Existing universal algorithms (Zhang et al., 2021; Yang et al., 2024) typically conduct \(O(^{2}T)\) projections per round. In the future, we will investigate whether we can reduce the projection complexity of universal algorithms for adaptive regret.