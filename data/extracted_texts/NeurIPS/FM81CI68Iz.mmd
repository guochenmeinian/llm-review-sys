# FedL2P: Federated Learning to Personalize

Royson Lee\({}^{1,2}\)1, Minyoung Kim\({}^{2}\), Da Li\({}^{2}\)

**Xinchi Qiu\({}^{1}\), Timothy Hospedales\({}^{2,3}\), Ferenc Huszar\({}^{1}\), Nicholas D. Lane\({}^{1,4}\) \({}^{1}\) University of Cambridge, UK \({}^{2}\) Samsung AI Center, Cambridge, UK \({}^{3}\) University of Edinburgh, UK \({}^{4}\) Flower Labs**

###### Abstract

Federated learning (FL) research has made progress in developing algorithms for distributed learning of global models, as well as algorithms for local personalization of those common models to the specifics of each client's local data distribution. However, different FL problems may require different personalization strategies, and it may not even be possible to define an effective one-size-fits-all personalization strategy for all clients: depending on how similar each client's optimal predictor is to that of the global model, different personalization strategies may be preferred. In this paper, we consider the federated meta-learning problem of learning personalization strategies. Specifically, we consider meta-nets that induce the batch-norm and learning rate parameters for each client given local data statistics. By learning these meta-nets through FL, we allow the whole FL network to collaborate in learning a customized personalization strategy for each client. Empirical results show that this framework improves on a range of standard hand-crafted personalization baselines in both label and feature shift situations.2

## 1 Introduction

Federated learning (FL) is an emerging approach to enable privacy-preserving collaborative learning among clients who hold their own data. A major challenge of FL is to learn from differing degrees of statistical data heterogeneity among clients. This makes it hard to reliably learn a global model and also that the global model may perform sub-optimally for each local client. These two issues are often dealt with respectively by developing robust algorithms for learning the global model  and then offering each client the opportunity to personalize the global model to its own unique local statistics via fine-tuning. In this paper, we focus on improving the fine-tuning process by learning a personalization strategy for each client.

A variety of approaches have been proposed for client personalization. Some algorithms directly learn the personalized models , but the majority obtain the personalized model after global model learning by fine-tuning techniques such as basic fine-tuning , regularised fine-tuning , and selective parameter fine-tuning . Recent benchmarks  showed that different personalized FL methods suffer from lack of comparable evaluation setups. In particular, dataset- and experiment-specific personalization strategies are often required to achieve state-of-the-art performance. Intuitively, different datasets and FL scenarios require different personalization strategies. For example, scenarios with greater or lesser heterogeneity among clients, would imply different strengths of personalization are optimal. Furthermore, exactly how that personalization should be conducted might depend on whether the heterogeneity is primarily in marginal label shift, marginal feature shift, or conditional shift. None of these facets can be well addressed by a one size fits all personalization algorithm. Furthermore, we identify a previously understudied issue: evenfor a single federated learning scenario, heterogeneous clients may require different personalization strategies. For example, the optimal personalization strategy will have client-wise dependence on whether that client is more or less similar to the global model in either marginal or conditional data distributions. Existing works that learn personalized strategies through the use of personalized weights are not scalable to larger setups and models [55; 14]. On the other hand, the few studies that attempt to optimize hyperparameters for fine-tuning do not sufficiently address this issue as they either learn a single set of personalization hyperparameters [65; 22] and/or learn a hyperparameter distribution without taking account of the client's data distribution .

In this paper, we address the issues above by considering the challenge of federated meta-learning of personalization strategies. Rather than manually defining a personalization strategy as is mainstream in FL [27; 9], we use hyper-gradient meta-learning strategies to efficiently estimate personalized hyperparameters. However, apart from standard centralised meta-learning and hyperparameter optimization (HPO) studies which only need to learn a single set of hyperparameters, we learn meta-nets which inductively map from local client statistics to client-specific personalization hyperparameters. More specifically, our approach FedL2P introduces meta-nets to estimate the extent in which to utilize the client-wise BN statistics as opposed to the global model's BN statistics, as well as to infer layer-wise learning rates given each client's metadata.

Our FedL2P thus enables per-dataset/scenario, as well as per-client, personalization strategy learning. By conducting federated meta-learning of the personalization hyperparameter networks, we simultaneously allow each client to benefit from its own personalization strategy, (e.g., learning rapidly, depending on similarity to the global model), and also enable all the clients to collaborate by learning the overall hyperparameter networks that map local meta-data to local personalization strategy. Our FedL2P generalizes many existing frameworks as special cases, such as FedBN , which makes a manual choice to normalize features using the client BN's statistics, and various selective fine-tuning approaches [37; 48; 11; 2], which make manual choices on which layers to personalize.

## 2 Related Work

Existing FL works aim to tackle the statistical heterogeneity of learning personalized models by either first learning a global model [46; 39; 32; 48; 29] and then fine-tuning it on local data or directly learning the local models, which can often be further personalized using fine-tuning. Many personalized FL approaches include the use of transfer learning between global  and local models , model regularization , Moreau envelopes , and meta-learning [15; 10]. Besides algorithmic changes, many works also proposed model decoupling, in which layers are either shared or personalized [2; 11; 64; 48; 37; 17; 54] or client clustering, which assumes a local model for each cluster [42; 44; 53; 7]. These methods often rely on or adopt a fixed personalization policy for local fine-tuning in order to adapt a global model or further improve personalized performance. Although there exists numerous FL approaches that propose adaptable personalization policies [55; 40; 14], these works are memory intensive and do not scale to larger setups and models. On the other hand, our approach has a low memory footprint (Appendix C) and is directly applicable and complementary to existing FL approaches as it aims to solely improve the fine-tuning process.

Another line of work involves HPO for FL (or FL for HPO). These methods either learn one set of hyperparameters for all clients [22; 30; 65] or random sample from learnt hyperparameter categorical distributions which does not take into account of the client's meta-data . Moreover, some of these methods [22; 65] search for a set of hyperparameters based on the local validation loss given the initial set of weights prior to the federated learning of the model [22; 65], which might be an inaccurate proxy to the final performance. Unlike previous works which directly learn hyperparameters, we deploy FL to learn meta-nets that take in, as inputs, the client meta-data to generate personalized hyperparameters for a given pretrained model. A detailed positioning of our work in comparison with existing literature can be found in Appendix B.

## 3 Proposed Method

### Background & Preliminaries

**Centralized FL.** A typical centralized FL setup using FedAvg  involves training a global model \(_{g}\) from \(C\) clients whose data are kept private. At round \(t\), \(_{g}^{t-1}\) is broadcast to a subset of clients selected, \(\), using a fraction ratio \(r\). Each selected client, \(i\), would then update the model usinga set of hyperparameters and its own data samples, which are drawn from its local distribution \(P_{i}\) defined over \(\) for a compact space \(\) and a label space \(\) for \(e\) epochs. After which, the learned local models, \(_{i}^{t-1}\), are sent back to the server for aggregation \(_{g}^{t}=_{i}^{}}{_{i^{}}N_{i^{ }}}_{i}^{t-1}\) where \(N_{i}\) is the total number of local data samples in client \(i\) and the resulting \(_{g}^{t}\) is used for the next round. The aim of FL is either to minimize the global objective \(_{(x,y) P}(_{g};x,y)\) for the global data distribution \(P\) or local objective \(_{(x,y) P_{i}}_{i}(_{i};x,y)\) for all \(i C\) where \(_{i}(;x,y)\) is the loss given the model parameters \(\) at data point \((x,y)\). As fine-tuning is the dominant approach to either personalize from a high-performing \(_{g}\) or to optimize \(_{i}\) further for each client, achieving competitive or state-of-the-art results in recent benchmarks , we focus on the collaborative learning of meta-nets which generates a personalized set of hyperparameters used during fine-tuning to further improve personalized performance without compromising global performance.

**Non-IID Problem Setup.** Unlike many previous works, our method aims to handle both common label and feature distribution shift across clients. Specifically, given features \(x\) and labels \(y\), we can rewrite the joint probability \(P_{i}(x,y)\) as \(P_{i}(x|y)P_{i}(y)\) and \(P_{i}(y|x)P_{i}(x)\) following . We focus on three data heterogeneity settings found in many realistic settings: both label & distribution skew in which the marginal distributions \(P_{i}(y)\) & \(P_{i}(x)\) may vary across clients, respectively, and concept drift in which the conditional distribution \(P_{i}(x|y)\) may vary across clients.

### FedL2P: FL of Personalization Strategies

We now present our proposed method, FedL2P, to tackle collaborative learning of personalization strategies under data heterogeneity. Our main motivation is that the choice of the hyperparameters for the personalized fine-tuning, such as the learning rates and feature mean and standard deviations (SD) statistics of the batch normalization  (BN) layers, is very crucial. Although existing FL-HPO approaches aim to learn these hyperparameters _directly2_, we aim to do it in a meta learning or hypernetwork-like fashion: learning a neural network (dubbed _meta-net_) that takes certain profiles of client data (e.g., summary statistics of personalized data) as input and outputs near-optimal hyperparameters. The meta-net is learned collaboratively in an FL manner without sharing local data. The returned hyperparameters from the meta-net are then deployed in client's personalized fine-tuning. The main advantage of this meta-net approach over the direct HPO is that a brand new client needs not do time-consuming HPO, but just gets their optimal hyperparameters by a single feed-forward pass through the meta-net. Our idea is visualized in Fig. 1. For each FL round, the latest meta-net is distributed to the participating clients; each client then performs meta learning to update the meta-net; the local updated meta-nets are sent to the server for aggregation. Details of our algorithm are described below.

Hyperparameter Selection.There is a wide range of local training hyperparameters that can be optimized, some of which were explored in previous FL works . As local training is often a costly process, we narrowed it down to two main sets of hyperparameters based on previous works that showed promising results in dealing with non-IID data: _BN hyperparameters_ and _selective update hyperparameters_.

Batch Normalization Hyperparameters.The first set of hyperparameters involves BN and explicitly deals with feature shift. Notably, FedBN  proposed keeping the BN layers local and the other layers global to better handle feature shift across clients; BN has found success at mitigating domain

Figure 1: FedL2P’s workflow. For each client, the meta-net (parameterized by \(\)) takes the client meta-data (e.g., local data profile) and outputs hyperparameters. We update \(\) by optimizing the meta objective which is the validation loss of the model finetuned with the hyperparameters returned by the meta-net. The updated personalization strategies \(^{*}\) from clients are collected/aggregated (via FedAvg) in the server for the next round.

shifts in various domain adaptation tasks  and can be formulated as follows:

\[g(x)=}{^{2}+}}*+ \]

where \(g\) is a BN layer, \(x\) is its input features, (\(\), \(^{2}\)) are the estimated running mean, variance, and \(\) is used for numerical stability. During training, the batch statistics \(E(x)\) and \(Var(x)\) are used instead, keeping running estimates of them, \(\) and \(^{2}\). During inference, these estimates are used3. Both \(\) and \(\) are learnable parameters used to scale and shift the normalized features.

Although deploying local BN layers is useful to counteract the drawbacks of feature shift, using global BN layers is often beneficial for local fine-tuning in cases where the feature shift is minimal as it helps speed-up convergence and reduces overfitting. Hence, we propose learning a hyperparameter \(\) for each BN layer as follows:

\[=(1-)*_{pt}+*_{i},^{2}= (1-)*^{2}_{pt}+*^{2}_{i} \]

where \(_{pt}\) and \(^{2}_{pt}\) are the estimated running mean and variance by the given pretrained model; \(_{i}\) and \(^{2}_{i}\) are the running mean and variance estimated by the client. When \(\!\!0\), the client solely uses pretrained model's BN statistics and when \(\!\!1\), it uses its local statistics to normalize features. Thus \(\) indicates the degree in which the client should utilize its own BN statistics against pretrained model's, to handle the feature shift in its local data distribution.

```
0: Pretrained global model \(_{g}\) with \(M\) layers and \(B\) BN layers, each has \(J\) input channels. Fraction ratio \(r\). Total no. of clients \(C\). No. of update iterations \(K\). Training loss \(_{T}\) and validation loss \(_{V}\). \(\) is the learning rate for \(\).
1: initialize \(=\{_{bn},_{lr},}\}\)
2:for round \(t=1,,T\)do
3:\(\) Random sample \(Cr\) clients
4:for client \(i\)do
5: send \(_{j}\), \(\) to client
6: Forward pass of local dataset to compute
1: \(E(x_{m}),SD(x_{m})\) for \(1 m M-1\)
2: \(_{b,j},^{2}_{b,j}\) for \(b=1,,B\) and \(j=1,,J\).
7: Compute \(_{b}\) for \(b=1,,B\) using Eq. 3
8:for iteration \(k=1,,K\)do
9:\(_{i}\) Finetune \(_{g}\) using \(_{T}\) for \(e\) epochs
10:\(-\) Hypergradient(\(_{V}\), \(_{T}\), \(\), \(_{i}\))
11:endfor
12: send \(\) and num of data samples \(N\) to server
13:endfor
14:\(_{i}^{}}{ N_{i}}_{i}\)
15:endfor
16:\(\)
```

**Algorithm 1** FedL2P: FL of meta-nets for Personalization Hyperparameters

#### Selective Update Hyperparameters

A variety of recent personalized FL works achieved promising results by manually selecting and fine-tuning a sub-module of \(_{g}\) during personalization , (_e.g._, the feature extractor or the classifier layers), while leaving the remaining modules in \(_{g}\) frozen. It is beneficial because it allows the designer to manage over- vs under-fitting in personalization. _e.g._, if the per-client dataset is small, then fine-tuning many parameters can easily lead to overfitting, and thus better freezing some layers during personalization. Alternatively, if the clients differ significantly from the global model and/or if the per-client dataset is larger, then more layers could be beneficially personalised without underfitting. Clearly the optimal configuration for allowing model updates depends on the specific scenario and the specific client. Furthermore, it may be beneficial to consider a more flexible range of hyperparameters that control a continuous degree of fine-tuning strength, rather than a binary frozen/updated decision per module.

To automate the search for good personalization strategies covering a range of wider and more challenging non-IID setups, we consider layer-wise learning rates, \(\) for all learnable weights and biases. This parameterization of personalization encompasses all the previous manual frozen/updated split approaches as special cases. Furthermore, while these approaches have primarily considered heterogeneity in the marginal label distribution, we also aim to cover feature distribution shift between clients. Thus we also include the learning rates for the BN parameters, \(\) and \(\), allowing us to further tackle feature shift by adjusting the means and SD of the normalized features.

```
0: Validation Loss \(_{V}\) and training Loss \(_{T}\). Learning rate \(\) and no. of iterations \(Q\). Fixed point \((^{{}^{}},^{*}(^{{}^{}}))\).
1:\(p=v=_{t}_{V}|_{(^{{}^{}},^{*}(^{{}^{ }}))}\)
2:for iteration \(1,,Q\)do
3:\(v v-\ v\ ^{2}_{^{*}}_{T}\)
4:\(p p+v\)
5:endfor
6:\(_{}_{V}|_{(^{{}^{}},^{*}(^{ {}^{}}))}-p\ _{}_{T}|_{(^{{}^{}}, ^{*}(^{{}^{}}))}\)
```

**Algorithm 2** Hypergradient

#### Selective Update Hyperparameters

We propose a novel learning strategy for personalized FL. We propose a novel learning strategy for personalized FL.

Hyperparameter Inference for Personalization.We aim to estimate a set of local hyperparameters that can best personalize the pretrained model for each client given a group of clients whose data might not be used for pretraining. To accomplish this, we learn to estimate hyperparameters based on the degree of data heterogeneity of the client's local data with respect to the data that the model is pretrained on. There are many ways to quantify data heterogeneity, such as utilizing the earth mover's distance between the client's data distribution and the population distribution for label distribution skew  or taking the difference in local covariance among clients for feature shift . In our case, we aim to distinguish both label and feature data heterogeneity across clients. To this end, we utilize the client's local input features to each layer with respect to the given pretrained model. Given a pretrained model with \(M\) layers and \(B\) BN layers, we learn \(=_{1},,_{2M}\)4 and \(=_{1},,_{B}\), using two functions, each of which is parameterized as a multilayer perceptron (MLP), named meta-net, with one hidden layer due to its ability to theoretically approximate almost any continuous function . We named the meta-net that estimates \(\) and the meta-net that estimates \(\) as BNNet and LRNet respectively. Details about the architecture can be found in Appendix. E.

To estimate \(\), we first perform a forward pass of the local dataset on the given pretrained model, computing the mean and SD of each channel of each input feature for each BN layer. We then measure the distance between the local feature distributions and the pretrained model's running estimated feature distributions of the \(b\)-th BN layer as follows:

\[_{i,b}=_{j=1}^{J}D_{KL}(P_{j}||Q _{j})+D_{KL}(Q_{j}||P_{j}), \]

where \(P_{j}=(_{i,b,j},_{i,b,j}^{2})\), \(Q_{j}=(_{pt,b,j},_{pt,b,j}^{2})\), \(D_{KL}\) is the KL divergence and \(J\) is the number of channels of the input feature. \(\) is then used as an input to BNNet, which learns to estimate \(\) as shown in Eq. 4.

Similarly, we compute the mean and SD of each input feature per layer by performing a forward pass of the local dataset on the pretrained model and use it as an input to LRNet. Following best practices from previous non-FL hyperparameter optimization works , we use a learnable post-multiplier \(}=_{1},,_{2M}\) to avoid limiting the range of the resulting learning rates (Eq 4).

\[ =(_{bn};_{1},_{2},,_{B-1},_{B}) \] \[ =(_{lr};E(x_{0}),SD(x_{0}),E(x_{1}),SD(x_{1}) ,E(x_{M-1}),SD(x_{M-1}))}\]

where \(\) is the Hadamard product, \(x_{m-1}\) is the input feature to the \(m\)-th layer, and \(_{bn}\) and \(_{lr}\) are the parameters of BNNet and LRNet respectively. \(\) is used to compute the running mean and variance in the forward pass for each BN layer as shown in Eq. 2 and \(\) is used as the learning rate for each weight and bias in the backward pass. We do not restrict \(}\) to be positive as the optimal learning rate might be negative .

**Federated Hyperparameter Learning.** We deploy FedAvg  to federatedly learn a set of client-specific personalization strategies. Specifically, we learn the common meta-net \(=\{_{bn},_{lr},}\}\) that generates client-wise personalization hyperparameters \(\{_{i},_{i}\}\), such that a group of clients can better adapt a pre-trained model \(_{g}\) by fine-tuning to their local data distribution. So we solve:

\[_{}(,_{g}) =_{i=1}^{C}}{_{i^{}}N_{i^{}}} _{i,V}(_{i}^{*}(),)\] s.t. \[_{i}^{*}() =*{arg\,min}_{_{i}}_{i,T}(_{ i},) \]

where \(_{i}^{*}\) is the set of optimal personalized model parameters after fine-tuning \(_{g}\) for \(e\) epochs on the local dataset, \(_{i,V}(,)=_{(x,y) V_{i}}_{i}( ,;x,y)\) and \(V_{i}\) is the validation set (samples from \(P_{i}\)) for the client \(i\) - similarity for \(L_{i,T}\).

For each client \(i\), the validation loss gradient with respect to \(\), known as the hypergradient, can be computed as follows:

\[d_{}_{V}(^{*}(),)=_{} _{V}(^{*}(),)+_{^{*}()} _{V}(^{*}(),)\;_{}^{*}() \]

To compute \(_{}^{*}\) in Eq. 6, we use the implicit function theorem (IFT):\[_{}^{*}|_{^{}}=-(_{}^{2}_ {T}(,))^{-1}._{}_{T}(, )|_{^{},^{*}(^{})} \]

The full derivation is shown in Appendix A. We use Neumann approximation and efficient vector-Jacobian product as proposed by Lorraine et al.  to approximate the Hessian inverse in Eq. 7 and compute the hypergradient, which is further summarized in Algorithm 2. In practice, \(^{*}\) is approximated by fine-tuning \(_{g}\) on \(_{T}\) using the client's dataset. Note that unlike in many previous works [38; 47] where \(_{}_{V}\) is often \(0\) as the hyperparameters often do not directly affect the validation loss, in our case \(_{_{bn}}_{V} 0\).

Algorithm 1 summarizes FedL2P. Given a pretrained model and a new group of clients to personalize, we first initialize \(\) (line 1). For every FL round, we sample \(Cr\) clients and send both the parameters of the pretrained model and \(\) to each client (lines 3-5). Each client then performs a forward pass of their local dataset to compute the mean (E) and standard deviation (SD) of the input features to each layer and the statistical distance between the local feature distributions and the pretrained model's running estimated feature distributions for each BN layer (lines 6-7). \(\) is then trained for \(K\) iterations; each iteration optimizes the pretrained model on \(_{T}\) for \(e\) epochs, applying \(\) and \(\) computed using Eq. 4 (lines 8-9) at every forward and backward pass respectively. Each client then computes the hypergradient of \(\) as per Algorithm. 2 and update \(\) at the end of every iteration (line 10). Finally, after \(K\) iterations, each client sends back the updated \(\) and its number of data samples, which is used for aggregation using FedAvg  (lines 12-14). The resulting \(\) is then used for personalization: each client finetunes the model using its training set and evaluates it using its test set.

### Adapting the Losses for IFT

In the IFT, we solve the following problem:

\[_{}\ _{V}(^{*}(),)\ \ \ \ ^{*}()=_{}_{T}(,). \]

For the current \(\), we first find \(^{*}()\) in (8) by performing several SGD steps with the training loss \(_{T}\). Once \(^{*}()\) is obtained, we can compute the hypergradient \(d_{}_{V}(^{*}(),)\) by the IFT, which is used for updating \(\). As described in (6) and (7), this hypergradient requires \(_{}_{T}(,)\), implying that the training loss has to be explicitly dependent on the hyperparameter \(\). As alluded in Lorraine et al. , it is usually not straightforward to optimize the learning rate hyperparameter via the IFT, mainly due to the difficulty of expressing the dependency of the training loss on learning rates. To address this issue, we define the training loss as follows:

\[_{T}(,)=_{(x,y) P_{T}}CE(f_{ ^{},()}(x),y)\ \  \] \[^{}=-()_{}_{(x,y) P_{T}}CE(f_{,()}(x),y). \]

Here \(f_{,}(x)\) indicates the forward pass with network weights \(\) and the batch norm statistics \(\), and \(CE()\) is the cross-entropy loss. Note that in (10), we can take several (not just one) gradient update steps to obtain \(^{}\). Now, we can see that \(_{T}(,)\) defined as above has explicit dependency on the learning rates \(()\). Interestingly, the stationary point \(^{*}()\) of \(_{T}(,)\) coincides with \(^{}\), that is, \(^{*}()=^{}\), which allows for a single instance of inner-loop iterations as Line 9 in Alg. 1. Finally, the validation loss is defined as:

\[_{V}(,)\!=\!_{(x,y) P_{V}}CE(f_{, ()}(x),y),\]

showing clear dependency on BNNet parameters through \(()\) as discussed in the previous section.

## 4 Evaluation

### Experimental Setup

Experiments are conducted on image classification tasks of different complexity. We use ResNet-18  for all experiments and SGD for all optimizers. All details of the pretrained models can be found in Appendix. D. Additionally, the batch size is set to \(32\) and the number of local epochs, \(e\), is set to \(15\) unless stated otherwise. The learning rate (\(\)) for \(=\{_{bn},_{lr},}\}\) is set to {\(10^{-3}\),\(10^{-3}\),\(10^{-4}\)}, respectively. The hypergradient is clipped by value

   \)} &  & \)/\(\)/\(\)/\(\)/\(\)/\(\)/\(\)**} \\ 
**1000** & FedAvg & 63,048.02 & 65,136.02 \\ (\(\) Isotropic) & PerdAvg\(\) & 34,384.01 & 47,588.01 \\  & FedLab\(\) & 60,004.07 & 66,940.01 \\ 
**1.0** & FedAvg & 61,428.10 & 65,766.31 \\  & FedLab\(\) & 64,384.02 & 50,761.26 \\  & FedLab\(\) & 68,291.10 & 71,710.28 \\ 
**0.5** & FedAvg & 64,340.14 & 60,484.50 \\  & PerdAvg\(\) & 62,340.16 & 56,506.53 \\  & FedLab\(\) & 72,766.01 & 72,872.04 \\ 
**0.1** & FedAvg & 71,580.00 & 30,258.007 \\ (\(\) Isotropic) & PerdAvg\(\) & 77,731.00 & 77,686.01 \\  & FedLab\(\) & 79,508.08 & 79,386.04 \\   

Table 1: FedL2P complements existing FL methods by improving on the finetuning process. Experiments on CIFAR10 (\(e=15\)).

[MISSING_PAGE_FAIL:7]

to the same set of clients via fine-tuning. To this end, given the CIFAR-10 dataset partitioned among a group of clients, we pretrained \(_{g}\) following best practices from  using FedAvg and finetune it on the same set of clients. Table 2 shows the personalized accuracy of the various fine-tuning baselines (Section 4.1.2) and FedL2P using \(e=58\)\(\)\(15\) local epochs on groups of clients with varying label distribution, \(P_{i}(y)\); \(=1000\) represents the IID case and \(=1.0,0.5,0.1\) represents more heterogeneous case. As observed in many previous works [48; 27], increasing label heterogeneity would result in a better initial global model at a expense of personalized performance. Our method instead retains the initial global performance and focuses on improving personalized performance.

We also show that in many cases, especially for clients with limited local compute budget \(e=5\), utilizing the pretrained model's BN statistics result (**BN G**) can be more beneficial as CIFAR-10 consists of images from the same natural image domain; in contrast, previous works mainly use either the client's BN statistics (**BN C**) or the incoming feature batch statistics (**BN I**) to normalize the features. This strategy is discovered by FedL2P, as illustrated in Fig. 1(a) where the learned \(\) is \(0\) for all BN layers of all clients. For the IID case in particular, FedL2P learns a sparsity6 of \(1.0\), learning rate \(=0\), for all layers in all clients, forgoing fine-tuning and using the initial global model as the personalized model. For \(=1.0\) and \(0.1\), FedL2P learns highly sparse models similar to recent works that proposed fine-tuning only a subset of hand-picked layers [48; 17; 11; 2; 37] to obtain performance gains. Lastly, L2P performs worse than some standard fine-tuning baselines as it meta-overfits on each client's validation set, highlighting the benefits of FL over local HPO.

**FedL2P's Complementability with previous FL works.** As our proposed FedL2P learns to improve the FT process, it is complementary, not competing, with other FL methods that learn shared model(s). Hence, besides FedAvg, we utilize FedL2P to better personalize \(_{g}\) pretrained using PerFedAvg(HF)  and FedBABU  as shown in Table. 1, where we compare FedL2P against the most commonly used FT approach, **BN C**. Our results show that applying FedL2P to all three FL methods can lead to further gains, in most cases outperforming FT in each respective method. This performance improvement can also bridge the performance gap between different methods. For instance, while FedAvg+FT has worse performance than FedBABU+FT in all cases, FedAvg+FedL2P obtained comparable or better performance than FedBABU+FT for \(=1000\) & \(0.1\).

### Personalizing to Unseen Clients

**Unseen during Pretraining.** We evaluate the performance of FedL2P on CIFAR-10-C starting from the pretrained model trained using FedAvg on CIFAR-10 in the IID setting \(=1000\) (Section. 4.2) as

  \(\) & Dataset & \(\)**(BN C)** & \(\)**(BN G)** & \(\)**(BN I)** & \(\)**(BP)** & \(\)**(EdL2P)** \\ 
**1000** & CIFAR-10-C & 59,584,003,008 & 57,034,008 & 55,774,012 & 58,800,130 & **59,994,22** \\ (\(\) heterogeneity) & Caltech-10 & 80,972,033 & 36,022,251 & 81,432,16 & 75,523,83 & **88.85\(\)0.89** \\  & Dominant & 52,711,155 & 30,554,017,047,088 & 4,504,516 & **54,388,405** \\ 
**1.0** & CIFAR-10-C & 6,374,008 & 6,540,033 & 6,356,007 & 6,634,099 & **683,485,15** \\  & DomainNet & 62,274,058 & 44,150,11 & 59,440,7 & 5,750,120 & **63,770,44** \\ 
**0.5** & CIFAR-10-C & 74,924,008 & 75,254,017 & 7,338,010 & 74,488,060 & **76,780,22** \\  & DomainNet & 71,394,097 & 49,811,98 & 66,944,70 & 6,380,780 & **72,640,33** \\ 
**0.1** & CIFAR-10-C & 87,254,006 & 88,540,002 & 83,934,004 & 87,934,301 & **89.23\(\)0.15** \\ (\(\) heterogeneity) & DomainNet & 86,034,047 & 69,414,195 & 85,354,14 & 83,934,102 & **86,360,45** \\  

Table 3: Personalized test accuracies of CIFAR-10-C, Office-Caltech-10, Dominant (\(e=15\)).

Figure 2: Locality, spread, and skewness of FedL2P’s learned hyperparameters, \(\) and \(\), of different layers across clients and the model’s sparsity of all clients for each personalization scenario.

[MISSING_PAGE_FAIL:9]

discretization approach proposed in  to assign labels on the normalized Laplacian embedding. We then compute the _Adjusted Rand Index_ (ARI)  between the estimated clusters and the clusters partitioned by the different data domains as shown in Table. 6. We also visualize the alignment between the estimated clusters and the true domains in Fig. 3, where each block \((j,k)\) represents the _normalized_ average Euclidean distance between all pairs of clients in domain \(j\) and \(k\). Specifically, we divide the mean distance between domain \(j\) and \(k\) by the within-domain mean distances and take the log scale for better visualization: \((})\) where \(d(j,k)\) is the mean Euclidean distance between \(j\) and \(k\). Thus, a random clustering has distance close to 0 and \(>0\) indicates better alignment between the clustering and the true domains.

As shown, for DomainNet, both BNNet and LRNet consistently preserve the cluster information found in their inputs, \(\) & \(\), respectively. However, perfect clustering is not achieved due to the inherent difficulty. For instance, the _real_ and _painting_ domains share similar features, resulting in similar hyperparameters; the cross-domain distance between _real_ and _painting_ is \( 0\) in log-scale in Fig. 3 and hence indistinguishable from their true domains. In contrast, the clients' features and resulting hyperparameters of the Office-Caltech-10 dataset are perfectly clustered (ARI=1) as visualized in Fig. 2(a) and Appendix. F.

### Ablation Study

To elucidate the individual impact of BNNet & LRNet, we run an ablation study of all of the datasets used in our experiments and present the results in Table. 5, where CIFAR10 adopts the pretrained model trained using FedAvg. As BNNet learns to weight between client's BN statistics (**BN C**) and pretrained model's BN statistics (**BN G**), running FedL2P with BNNet alone leads to either better or similar performance to the better performing baseline. Running LRNet as a standalone, on the other hand, can result in further gains, surpassing the use of both BNNet and LRNet on some benchmarks. Nonetheless, it requires prior knowledge of the data feature distribution of the client in order to set a suitable \(\), of which \(=1\) uses **BN C** and \(=0\) uses **BN G**. Our approach assumes no knowledge of the client's data and learns an estimated \(\) per-scenario and per-client using BNNet.

## 5 Conclusion

In this paper, we propose FedL2P, a framework for federated learning of personalization strategies specific to individual FL scenarios and datasets as well as individual clients. We learned meta-nets that use clients' local data statistics relative to the pretrained model, to generate hyperparameters that explicitly target the normalization, scaling, and shifting of features as well as layer-wise parameter selection to mitigate the detrimental impacts of both marginal and conditional feature shift and marginal label shift, significantly boosting personalized performance. This framework is complementary to existing FL works that learn shared model(s) and can discover many previous hand-designed heuristics for sparse layer updates and BN parameter selection as special cases, and learns to apply them where appropriate according to the specific scenario for each specific client. As a future work, our approach can be extended to include other hyperparameters and model other forms of heterogeneity, e.g. using the number of samples as an expert input feature to a meta-net.