# Neural Embeddings Rank: Aligning 3D latent dynamics with movements

Chenggang Chen, Zhiyu Yang, Xiaoqin Wang

Department of Biomedical Engineering, Johns Hopkins University

cheng-gang.chen@jhu.edu

###### Abstract

Aligning neural dynamics with movements is a fundamental goal in neuroscience and brain-machine interfaces. However, there is still a lack of dimensionality reduction methods that can effectively align low-dimensional latent dynamics with movements. To address this gap, we propose Neural Embeddings Rank (NER), a technique that embeds neural dynamics into a 3D latent space and contrasts the embeddings based on movement ranks. NER learns to regress continuous representations of neural dynamics (i.e., embeddings) on continuous movements. We apply NER and six other dimensionality reduction techniques to neurons in the primary motor cortex (M1), dorsal premotor cortex (PMd), and primary somatosensory cortex (S1) as monkeys perform reaching tasks. Only NER aligns latent dynamics with both hand position and direction, visualizable in 3D. NER reveals consistent latent dynamics in M1 and PMd across sixteen sessions over a year. Using a linear regression decoder, NER explains 86% and 97% of the variance in velocity and position, respectively. Linear models trained on data from one session successfully decode velocity, position, and direction in held-out test data from different dates and cortical areas (64%, 88%, and 90%). NER also reveals distinct latent dynamics in S1 during consistent movements and in M1 during curved reaching tasks. The code is available at https://github.com/NeuroscienceAI/NER.

## 1 Introduction

It has long been thought that individual neurons in the motor and premotor cortex, similar to those in the sensory cortex, are tuned to specific movement parameters such as direction. However, this static and receptive field-based neural representation fails to explain movement trajectories during simple tasks like reaching. Recent studies have found that the activities of multiple simultaneously recorded neurons, which fire spikes in a time-dependent manner, encode reaching movements . Unlike the one-dimensional dynamics from a single neuron, understanding how movements are represented by these high-dimensional neural dynamics is challenging. In systems neuroscience and brain-machine interfaces, there is significant motivation to reduce these high-dimensional neural dynamics to low-dimensional latent dynamics for at least three reasons:

_First, visualizing neural dynamics._ This involves a trade-off between dimensionality and explained variance. To explain a complex reaching task, at least six dimensions are typically required. For example, in an eight-direction center-out reaching task,  selects fifteen dimensions for the PMd, ten for the M1, and eight for the S1. Therefore, we need to further reduce the dimensionality of these "low-dimensional" latent dynamics. Currently, we still lack a method that can directly explain enough variance within three dimensions. _Second, comparing movements-related latent dynamics_. After dimensionality reduction, we can visualize the trajectories of latent dynamics over time. For instance,  reveals rotational latent dynamics during reaching tasks using principal component analysis (PCA).  found that animals performing similar tasks exhibit similar latent dynamics.

However, these trajectories do not align precisely with the reaching movements: when the hand reaches in eight directions, the trajectories of latent dynamics are neither in eight distinct directions nor well-separated, often appearing entangled. _Third, decoding movements using latent dynamics_. Decoders trained on individual neural activities are commonly used to predict movements . However, a drawback of using individual neural activities is that when the identities of neurons change during long-term recordings, the decoding performance deteriorates . Additionally, it is infeasible to decode movements from different brain areas or animals. Decoders trained on latent dynamics facilitate long-term and cross-animal decoding [9; 25]. Since latent dynamics do not fully capture neural dynamics, decoding performance is often suboptimal with linear decoders, necessitating the use of nonlinear decoders or deep neural networks . Thus, decoding movements using a linear decoder without hyperparameters remains a significant challenge.

As our goal is to extract latent dynamics that are most informative about movements, we chose to train the latent dynamics using movements as the target. Several recent studies have trained latent dynamics to **classify** different movement directions or positions using variational autoencoders (VAE)  or contrastive learning . In this paper, _we are inspired by the fact that many features, including movements, are continuous, and that the function of many biological neurons is not classification but regression._ For example, neurons exhibit monotonic tuning to light intensity and sound levels . Even for discrete features like faces, face cells exhibit ramp-shaped tuning to different features. Additionally, 75% of faces could be correctly decoded using a linear regression decoder. Thus, we trained latent dynamics to regress movement by minimizing the ranking loss.

We are motivated by the fact that **CEBRA treats continuous labels as many discrete classes, which cannot be well separated in low-dimensional space. These classes are also highly imbalanced, with many more near-zero classes** (Fig. 1a).

Our two main contributions are as follows:

We introduce Neural Embeddings Rank (NER), a dimensionality reduction method that contrasts paired samples in the embedding space and ranks neural embeddings to align them with continuous movement labels (Fig. 1b). _Without introducing additional hyperparameters and using the same inputs, NER addresses the high dimensionality and class imbalance issues present in CEBRA._

We demonstrate that NER reveals behavior-aligned latent dynamics in all twenty sessions from three different brain areas in three monkeys. The trajectories of latent dynamics vary across different behaviors. We show that all movement parameters (directions, velocities, and positions) can be decoded using linear decoders trained on data from one session, tested on data from different dates over one year, and across different brain areas and hemispheres.

Figure 1: **a** Top: Hand velocities of X-Y coordinates across three trials. Note that the distribution of velocities is highly imbalanced, with many near-zero values. Bottom: Real (X-axis) versus predicted (Y-axis) Y-coordinate hand velocities using a linear regressor. The predicted velocities in CEBRA are much smaller than those in NER, as CEBRA mispredicts infrequent large velocities as frequent small velocities. **b** Batch size is three (in real experiments, it is 512), with two batches (one for \(v_{i}\) and one for \(v_{j}\) and \(v_{k}\)) combined in NER. Both models use embeddings within a specific time offset (e.g., 10 ms) of the anchor as the augmented embedding, which shares the same label/color as the anchor.

## 2 Related work

There are at least five categories of dimensionality reduction methods: **Linear** methods, such as PCA, jPCA , demixed PCA (dPCA) , and preferential subspace identification (PSID) . PCA captures the majority of variance in the data, jPCA reveals rotational dynamics in monkey reaching, dPCA highlights task-related components, and PSID extracts latent dynamics that predict motion during reach versus return epochs. **Nonlinear** methods like uniform manifold approximation and projection (UMAP)  and t-distributed stochastic neighbor embedding (tSNE)  are extensively used in biological data, such as for identifying neuron cell types . These methods reveal identities but often collapse temporal dynamics that resemble neural trajectories. UMAP with labels has been applied for dimensionality reduction in recent studies [27; 32]. **Generative** methods using recurrent neural networks or Transformers, such as latent factor analysis via dynamical systems (LFADS) , AutoLFADS , RADICal , and Neural Data Transformer (NDT) . These methods model single-trial variability in neural spiking activity better than PCA, though they often require explicit assumptions about underlying data statistics. **Label-guided generative** methods using VAEs, including Poisson identifiable VAE (piVAE) , SwapVAE , and targeted neural dynamical modeling (TNDM) . For example, piVAE uses both discrete and continuous labels to shape embeddings, revealing well-separated but less movement-aligned embeddings. **Contrastive** learning methods, introduced to learn robust, generalizable representations of neural population dynamics,

Figure 2: NER aligns 3D latent dynamics with movements and enabling cross sessions movement decoding. **a** Top: The monkey performs a center-out reaching task in eight directions using a planar manipulandum. Hand velocity is computed from hand position. Bottom: The monkey moves the cursor to outer targets to receive rewards (image from ). **b** Top: Neural dynamics are recorded using a 96-channel Utah array in two monkeys. Monkey C has implants in the M1 of the right hemisphere first and in M1 and PMd of the left hemisphere second. Monkey L has an implant in area 2 of the S1 of the left hemisphere (image from brainmuseum.org). During the task, all monkeys use the hand contralateral to the implanted hemisphere. Bottom: Spiking activities from multiple neurons (44 to 211) are recorded during multiple trials (168 to 1038) of the behavioral task. Dimensionality reduction reduces 200-dimensional neural dynamics to 3D latent dynamics. **c** Top: Neural dynamics from 190 dimensions (neurons) in the PMd are reduced to 3D latent dynamics. Bottom: Trial-averaged latent dynamics. Data is from Monkey C (date: 2016-10-14). **d** Top: Linear and logistic regression decoders are trained on the same independent variables (latent dynamics) but different dependent variables (hand velocities and directions) using 80% of train data. Bottom: The trained decoder from 80% of train data is used to predict movements on the 20% held-out test data. The model trained on one day predicts movements across one year, in the contralateral M1, and ipsilateral PMd. **e** Top: Two linear decoders trained from **c** decode hand velocities (positions) and directions with R-squared accuracy of 86% (96%) and peak accuracy of 97%, respectively, on the 20% held-out test data. Bottom: Decoders trained on the same day (diagonal) have much better decoding performance than models trained on different conditions (off-diagonal) using previous dimensionality reduction methods, whereas our method has higher and consistent decoding performance.

such as CEBRA  and Mine Your Own view (MYOW) . Compared to piVAE, AutoLFADS, and UMAP, CEBRA provides more identifiable latent dynamics corresponding to different hand directions in S1, although these latent dynamics trajectories do not correlate well with movements.

## 3 Model

NER is inspired by previous studies  and uses the same data sampling and neural feature encoder as CEBRA  to extract neural embeddings. Fig. 1b illustrates the difference between NER and CEBRA. CEBRA treats each embedding in a batch as a discrete class. For an anchor, it contrasts with its augmented embedding as a positive pair and three randomly sampled embeddings as negative pairs. NER, on the other hand, ranks six embeddings according to their continuous labels. It contrasts an anchor with its augmented or first embedding as a positive pair and the remaining four embeddings as negative pairs. NER continues by contrasting the second embedding as a positive pair and the remaining three embeddings as negative pairs. This process repeats until all embeddings have been positively contrasted with the anchor. _NER learns a regression-aware representation that orders all embeddings in a batch._

Mathematically, we define \(x\) as the high-dimensional neural dynamics, \(f\) as the feature encoder, and \(v=f(x)\) as the low-dimensional neural embeddings. The batch size \(N\) is set to 512, and the temperature \(\) is fixed at 1. Data augmentation in both CEBRA and NER is achieved by selecting embeddings whose labels fall within a specific offset (e.g., 10 ms) of the anchor's label. Note that we did not fine-tune the temperature and offset, as the only difference between CEBRA and NER is the loss function. The selection of these hyperparameters will have a similar effect on both models.

In each iteration, CEBRA receives one batch of anchors \(v_{i}\), one batch of embeddings \(v_{j}\) that will positively contrast with the anchors, and a third batch of randomly sampled embeddings \(v_{n}\) that will negatively contrast with the anchors. The anchor loss \(l\) in CEBRA is:

\[l^{(i)}_{CEBRA}=-log,v_{j})/)}{ N_{n=1}exp(sim(v_{i },v_{n})/)}\]

where \(sim(,)\) represents the similarity between two neural embeddings (e.g., negative \(L2\)).

In each iteration, NER receives one batch of anchors \(v_{i}\), one batch of augmented embeddings \(v_{j}\), \(v_{k}\) that will either positively or negatively contrast with an anchor, and a third batch of labels \(y\). The anchor loss \(l\) in NER is:

\[l^{(i)}_{NER}= 2N_{j=1,j i}-log,v_{j} )/)}{_{v_{k} S_{i,j}}exp(sim(v_{i},v_{k})/)}\]

There are two key differences from CEBRA. First, batches of \(v_{i}\) and \(v_{j}\), \(v_{k}\) are merged, and labels \(y\) are duplicated, resulting in a batch of \(2N\) for both embeddings and labels. This ensures that each anchor and its augmented embedding exist within the same batch. Second, we introduce \(S_{i,j}:=\{v_{k}\ |\ k i,d(y_{i},y_{k}) d(y_{i},y_{j})\}\) to denote the set of embeddings \(v_{k}\) that are of lower ranks than \(v_{j}\) in terms of label distance relative to \(v_{i}\), where \(d(,)\) is the distance measure between two labels (e.g., \(L1\)). Intuitively, for an anchor \(v_{i}\), any other embedding \(v_{j}\) in the batch is positively contrasted with it, enforcing the similarity between \(v_{i}\) and \(v_{j}\) to be greater than that between \(v_{i}\) and any other embedding \(v_{k}\) in the batch if the label distance between \(y_{i}\) and \(y_{k}\) is larger than that of \(y_{i}\) and \(y_{j}\). Minimizing \(l^{(i)}_{NER}\) aligns the order of embeddings with their corresponding label orders relative to the anchor.

By ranking all the embeddings within a batch, NER also addresses the class imbalance issue and effectively represents infrequent classes (Fig. 1a). In each batch, a small percentage (e.g., 5%) of embeddings may come from infrequent classes, such as large velocities. In CEBRA, only a single augmented embedding is positively contrasted with its anchor, so only 5% of anchors have access to these infrequent embeddings. In NER, all \(2N-1\) embeddings can contrast with an anchor, allowing 100% of anchors to access the 5% of infrequent embeddings.

## 4 Results

To fairly evaluate our dimensionality reduction method against related approaches, we selected six representative methods from various categories: PCA, dPCA, UMAP (with and without labels),piVAE, and CEBRA. To avoid bias from a single session in a specific brain area, where piVAE and CEBRA were previously tested, we conducted experiments across M1, PMd, and S1, covering a total of twenty sessions (Table 1). Statistical results for each comparison are provided (Table 2). Figure 2 illustrates the pipeline of this study. We primarily used linear decoders, and additionally included nonlinear k-nearest neighbors (kNN) decoder. To maintain consistency with movement decoding in the original CEBRA paper, we used a 16-dimensional (16D) CEBRA model, which has a stronger representation capacity and demonstrates better performance than the 3D model in kNN decoder.

### Movement-aligned latent dynamics were consistent over years in M1

Across all ten sessions in the left and right hemispheres of M1, NER consistently revealed neural embeddings that aligned with movement (Fig.3a, Fig.9a). Notably, during the initial movement stage, the latent dynamics converged on the same starting points, forming a pinwheel structure resembling the ground truth movements. Furthermore, we observed nearly identical neural embeddings in both hemispheres, even when data collection was separated by over a year.

CEBRA was the second-best method, uncovering comparable latent dynamics with both directions and positions roughly aligned with movements for both single and averaged embeddings (Fig.3b, Fig.9b). However, CEBRA had two limitations: the movement starting points were widely separated,

Figure 3: NER reveals consistent, movement-aligned latent dynamics in M1. **a** Single-trial (top) and averaged (bottom) latent dynamics from six sessions across one year in two hemispheres. Latent dynamics are rotated with reference to the 2016-10-14 session, using one of the eight reaching directions. **b-c** Similar to **a** but using CEBRA and piVAE. Fig. 9 shows the latent dynamics from the remaining four sessions for the same monkey. Fig. 10 displays single-trial and/or averaged latent dynamics revealed by five other methods. Fig. 11 shows trial-averaged latent dynamics before rotation. Fig. 12 presents the entangled neural embeddings using PCA and the time-stimulus components revealed by dPCA.

differing from ground truth movements, and its latent dynamics were less consistent across sessions. For example, it only revealed connected latent dynamics at movement starting points in two sessions. piVAE ranked third, displaying direction-aligned latent dynamics in different directions with relatively separated single-trial neural embeddings (Fig.3c, Fig.9c). However, while correlated with movements, the latent dynamics were not aligned with them and were less consistent across sessions. UMAP with labels showed clearly clustered neural embeddings corresponding to different angles, while UMAP without labels produced extended, less clustered latent dynamics (Fig. 10). Both methods failed to generate aligned and consistent latent dynamics. PCA and dPCA also generated identifiable latent dynamics (Fig.10), with dPCA revealing both time and stimulus components. However, a major limitation of both methods was the mixing of single-trial neural embeddings (Fig.10).

In summary, NER proved to be the best method for revealing movement-aligned latent dynamics. We further evaluated its performance in PMd and S1, leveraging these aligned latent dynamics to decode movements within and across sessions and to explore movement-specific latent dynamics.

### Explained variance of movements using linear decoders in M1, PMd, and S1

Five dimensionality reduction methods were used to reveal single-trial latent dynamics that depended on movements. We then used these latent dynamics as independent variables to explain the variance of dependent variables, namely, hand velocities, directions, and positions.

Fig. 4a shows the ground truth and predicted hand movement trajectories using latent dynamics revealed by NER in PMd. A linear regression decoder explained 90% and 98% of the variance in hand velocities and positions, respectively.

In both M1 and PMd (Fig.4b, Fig.13a), a logistic regression decoder revealed the tuning of directional accuracy from the start of the go cue to the end of the animal's reach. This tuning curve was highly

Figure 4: Explained variance of movements in M1, PMd, and S1. **a** Left: Hand movement trajectories. Right: Predicted trajectories by two decoders. Data collected from PMd on 2016-10-14. The explained variance for velocities and positions is 90% and 98%, respectively. **b** Hand direction classification accuracy using a logistic regression decoder. Shaded areas represent the standard deviation across six sessions from M1. **c** Explained variance of hand velocities using a linear regression decoder on latent dynamics revealed by five dimensionality reduction methods (indicated by different colors and shapes). The X-axis shows session dates. Left: Ten sessions from the M1 of Monkey C. Right: Six sessions from PMd of Monkey C and four sessions from S1 of Monkey H. **d** Similar to **c** but for hand positions. Fig. 13 provides the direction tuning curve in PMd, the correlation between tuning curves and velocities, and explained variance for directions.

correlated with hand velocities in the latent dynamics extracted by NER but not by CEBRA (M1: 0.93 vs. 0.28, PMd: 0.93 vs. 0.13; Fig. 13b).

NER outperformed the four other methods in all sessions for explaining the variance of both hand velocities and positions (Fig. 4c, d). For example, across ten sessions in M1, NER explained 86% of the variance in velocities, while the next best model, piVAE, explained only 35%. Similar findings were observed in PMd (89% vs. 32%) and S1 (86% vs. 47%).

In summary, combined with linear decoders, NER demonstrated the clearest velocity-dependent direction tuning and explained the largest variance in velocities and positions.

### Long-term and cross-hemisphere decoding in M1

NER explains the largest variance in both hand velocities and positions in the 80% training data. Next, we tested the trained model on the remaining 20% of test data. In addition to decoding test data from the same session on a single day, we also evaluated its performance on data from different sessions. We first conducted comparisons in M1 (Fig.5), followed by PMd (Fig.6) and S1 (Fig. 7).

Fig.5a shows velocity decoding performance using a linear regression decoder across three dimensionality reduction methods. Interestingly, the linear decoder could not decode hand velocities from latent dynamics generated by CEBRA (all variances were negative) and piVAE (only four positive). In contrast, all variances with NER were positive (minimum: 0.24), with performance across different sessions comparable to within-session performance (0.64 vs. 0.71). A kNN decoder (Fig.5b) achieved high performance for CEBRA and piVAE only with within-session latent dynamics.

NER outperformed CEBRA and piVAE by a substantial margin in position decoding across all conditions (Fig.5c). While the kNN decoder did not improve NER's performance relative to the linear decoder, it enhanced within-session performance for CEBRA and piVAE over NER (Fig.5d). However, this came at the cost of cross-session decoding performance (0.89 vs. 0.18 and 0.13). Fig.5e shows direction decoding accuracy, where NER still outperformed CEBRA and piVAE. Similar results were observed using a kNN decoder (Fig.5f).

Figure 5: Decoding within and across time and brain hemispheres over years in M1. **a-d** Three methods are applied to neural dynamics from ten sessions. Linear and logistic regression decoders (**a**, **c**, **e**) or a nonlinear k-nearest neighbors (kNN) decoder (**b**, **d**, **f**) are trained on 80% of the data and used to decode velocities, positions, and directions on the remaining 20% within-session (diagonal) and cross-session (off-diagonal). Brighter colors indicate higher decoding performance. **a** Same-session, cross-session, and cross-hemisphere velocity decoding using a linear regression decoder. **b** Similar to **a** but using the nonlinear kNN decoder. Note that CEBRAâ€™s latent dynamics are represented in sixteen dimensions instead of three. **c-d** Similar to **a-b** but with hand positions as the decoding variable. **e-f** Similar to **a-b** but with hand directions as the decoding variable.

In summary, compared to CEBRA and piVAE, NER consistently achieved higher performance across all sessions with a linear decoder and outperformed in cross-session decoding with the nonlinear decoder.

### Latent dynamics in PMd and decoding between M1 and PMd

Next, we turned our attention to PMd. Surprisingly, NER revealed similar latent dynamics in this higher-order motor area (Fig.6a). Two other dimensionality reduction methods also identified comparable latent dynamics, but these were less consistent and did not align well with movements (Fig.14). Fig. 6b shows within- and cross-session velocity decoding using a linear regression decoder (left) and a kNN decoder (right). Consistent with M1, in PMd, we observed that (1) both CEBRA and piVAE underperformed with linear regression, while NER achieved stable performance across all conditions, regardless of within- or cross-session contexts; (2) NER demonstrated robustness across decoders, whereas the performance of CEBRA and piVAE varied substantially, ranging from very low to occasionally outperforming NER in within-session decoding with the kNN decoder; and (3) even with the kNN decoder, CEBRA and piVAE failed in cross-session decoding, whereas NER maintained similar performance.

We also evaluated position and direction decoding and found that NER continued to outperform the other two methods (Fig.6c, Fig.15). Overall, NER reveals consistent latent dynamics in PMd and can effectively decode movements across PMd and M1.

### Same movements but different latent dynamics in S1

Lastly, we examined the latent dynamics and movement decoding in S1. NER revealed consistent latent dynamics in S1 (Fig.7a, b). After rotating the latent dynamics with reference to the target shown in Fig.3, they exhibit a consistent yet distinct shape compared to the latent dynamics observed in M1 and PMd. Velocity decoding using a linear regression decoder was only successful when the latent dynamics were extracted by NER (Fig.7c, d). While all three methods performed adequately for position decoding, NER outperformed both CEBRA and piVAE across all nine conditions (Fig.7e). Although S1 displays different latent dynamics than M1 and PMd, NER remains the most effective method for decoding movement both within and across sessions in S1.

Figure 6: Latent dynamics in PMd and decoding across brain areas. **a** Trial-averaged latent dynamics in PMd revealed by NER, with the rotation reference set to the same session as in Fig. 3 (i.e., 2016-10-14). **b** Previously used latent dynamics from M1 are added. Same-date, cross-date, and cross-brain area velocity decoding using a linear regression decoder (left) and a kNN decoder (right) on latent dynamics revealed by the three methods. **c** Similar to **b**. Fig. 14 shows the single-trial and averaged latent dynamics revealed by CEBRA and piVAE. Fig. 15 shows hand direction decoding performance using a logistic regression decoder.

### Straight and curved hand movements have different latent dynamics in M1

Lastly, we applied both NER and CEBRA in a new experiment where a monkey performed both straight and curved hand movements in different directions while neural recordings were simultaneously collected in M1 (Fig. 8a).

We first examined the latent dynamics when the monkey performed straight hand movements in six different directions (Fig.8b). Surprisingly, both single and averaged latent dynamics aligned well with the movements (Fig.8c) and displayed a shape similar to the previously observed latent dynamics in M1. Next, we selected three hand directions, each involving both straight and curved hand movements (Fig.8e). When we trained both NER and CEBRA on individual directions, only NER revealed clearly separated latent dynamics corresponding to straight and curved movements (Fig.8f). The difference between the two methods became even more pronounced when they were trained on all three directions combined: NER displayed latent dynamics for straight movements that were surrounded by those formed by curved movements. The explained variance achieved by NER was also higher than that of CEBRA across all three angles, especially on the combined angles (Fig. 17c). Finally, we tested a more challenging condition where all six reaching movements were curved (Fig.8g). In the latent space, two curved movements in the same direction produced close but distinct latent dynamics (Fig.8h). While CEBRA performed comparably on single directions, it struggled with combined directions (Fig.17e). NER consistently achieved higher explained variance than CEBRA (Fig.17f).

Overall, NER not only aligns latent dynamics with straight movements but also effectively differentiates curved hand movements from straight ones, demonstrating its robustness across various movement types.

## 5 Discussion

A benchmark comparison of NER and six other dimensionality reduction methods across multiple brain areas and two movement tasks highlights NER's superior performance in uncovering latent dynamics. We believe the primary advantage of our method is its ability to extract nearly identical latent dynamics across brain areas and over extended time periods. This capability opens new avenues for both fundamental neuroscience research and brain-machine interfaces (BMI). Previous studies [9; 25] used PCA to discover preserved latent dynamics across time and in animals performing similar behaviors. In contrast, the latent dynamics revealed by NER are significantly more informative than those uncovered by PCA. We believe NER will aid neuroscientists in probing the stability of latent

Figure 7: Distinct latent dynamics with the same movement in S1. **a** Trial-averaged latent dynamics revealed by NER, using the same reference target session as in Fig. 3. **b** Latent dynamics with the reference target set to the first session in S1. **c** Left: On 80% held-in trials, the explained variance by linear and logistic regression decoders is 91% and 97%, respectively. Right: On 20% held-out test trials, the trained linear decoder predicts velocities and positions with performances of 71% and 90%, respectively. Data collected on 2017-12-01. **d** Same- and cross-date velocity decoding performance using the linear regression decoder with three dimensionality reduction methods. **e** Similar to **d** but for positions. Fig. 16 shows latent dynamics revealed by CEBRA and piVAE.

dynamics under various conditions. For BMI applications, we demonstrate that NER, combined with a simple linear decoder, can predict hand movements across years, brain areas, and hemispheres. This capability enables training on latent dynamics within and between subjects, allowing for movement prediction in different subjects. The linear decoder's lack of hyperparameters is also an advantage.

The application of NER is not limited to hand movements using neurophysiological recordings. This includes latent dynamics in the hippocampus representing the body position of running rats and latent dynamics in the visual cortex representing embedded video features . Similarly, recording modalities are not limited to single-neuron electrophysiology; other methods, such as calcium imaging, local-field potentials, and EEG, can also be used.

In our final experiments with curved movements, we manually selected three pairs of reaching tasks that involved curved trajectories. Both NER and CEBRA failed when all 108 movement conditions were trained simultaneously. Furthermore, beyond the straight and curved movements examined here in macaque monkeys, more complex movements, such as handwriting  and speech , exist primarily in humans. These movements are also continuous but may require more than a 3D latent space for effective representation, and ranking the distances of complex movements adds further challenges. Nevertheless, uncovering the latent dynamics underlying these complex movements, which has yet to be achieved, could greatly advance BMI applications .