# Federated Learning from Vision-Language Foundation Models: Theoretical Analysis and Method

Bikang Pan

ShanghaiTech University

panbk2023@shanghaitech.edu.cn &Wei Huang

RIKEN Center for Advanced Intelligence Project

wei.huang.vr@riken.jp &Ye Shi

ShanghaiTech University

shiye@shanghaitech.edu.cn

Corresponding author.

###### Abstract

Integrating pretrained vision-language foundation models like CLIP into federated learning has attracted significant attention for enhancing generalization across diverse tasks. Typically, federated learning of vision-language models employs prompt learning to reduce communication and computational costs, i.e., prompt-based federated learning. However, there is limited theoretical analysis to understand the performance of prompt-based federated learning. In this work, we construct a theoretical analysis framework for prompt-based federated learning via feature learning theory. Specifically, we monitor the evolution of signal learning and noise memorization in prompt-based federated learning, demonstrating that performance can be assessed by the ratio of task-relevant to task-irrelevant coefficients. Furthermore, we draw an analogy between income and risk in portfolio optimization and the task-relevant and task-irrelevant terms in feature learning. Leveraging inspiration from portfolio optimization that combining two independent assets will maintain the income while reducing the risk, we introduce two prompts: global prompt and local prompt to construct a prompt portfolio to balance the generalization and personalization. Consequently, we showed the performance advantage of the prompt portfolio and derived the optimal mixing coefficient. These theoretical claims have been further supported by empirical experiments. Our code is available at: https://github.com/PanBikang/PromptFolio.git.

## 1 Introduction

Federated learning (FL)  stands out as a powerful framework that enables machine learning over decentralized data while maintaining data privacy and reducing reliance on centralized data repositories. Despite its advantages, the intensive computational and communication demands during the training phase often constrain the scalability of the models utilized. A transformative advancement in this field is the integration of prompt-based learning within the federated framework .

Prompt learning adapts models such as Contrastive Language-Image Pretraining (CLIP)  through minimal modifications, typically in the form of prompts or cues, guiding the model's predictions. As an emerging idea in machine learning, it has shown significant promise in various applications by allowing models to perform specialized tasks without undergoing complete retraining. Prompts effectively adjust pre-trained models for new tasks or datasets, which is particularly valuable in federated environments where data privacy and bandwidth constraints often limit conventionaltraining methods. A prominent example is CoOp , with its streamlined federated version known as PromptFL .

Despite the empirical success of prompt-based federated learning [28; 17; 16], theoretical analysis in this area remains limited. In this paper, we use feature learning theory  to propose an analytical framework for prompt-based federated learning with vision-language foundation models. Feature learning theory divides data into task-relevant and task-irrelevant features, allowing learnable weights to be expressed as a linear combination of these features. By introducing feature alignment across bimodal pretrained models, we demonstrate the relationship between learnable prompts and the features in latent space. To understand the process of signal learning and noise memorization, we use a two-stage analysis to examine the dynamics of coefficients for task-relevant and task-irrelevant features. Leveraging these coefficients, we demonstrate that prompt learning can be evaluated by comparing the ratio of task-relevant to task-irrelevant coefficients. In this way, we establish a theoretical foundation for prompt-based federated learning.

Additionally, we treat task-relevant coefficients and task-irrelevant coefficients as income and risk in investment portfolios [31; 32]. Inspired by investment portfolios, where combining two independent assets can reduce risk, we introduce two learnable prompts: a global prompt and a local prompt, and simply mix them to form a prompt portfolio to balance generalization and personalization. By mixing them to create a prompt portfolio, we balance the generalization and personalization under severe data heterogeneity. Leveraging the analysis framework we proposed, we prove the performance advantage of this mixed algorithm and derive the optimal coefficient. Besides, we use comprehensive experiments to support our theoretical results.

In this paper, our primary contributions are threefold:

* We present an analytical framework for prompt-based federated learning using vision-language foundation models. This framework aligns text and image features into a shared latent feature space and utilizes a two-stage analysis to understand the dynamics of prompt learning. By tracking the progression of signal learning and noise memorization, we show that the effectiveness of prompt-based federated learning can be measured by the ratio of task-relevant to task-irrelevant coefficients.
* Additionally, we introduce a prompt portfolio mechanism to address severe data heterogeneity and balance generalization and personalization. Within our proposed analytical framework, we draw an intuitive analogy between task-relevant features and income in portfolio optimization, as well as task-irrelevant features and risk. Consequently, we demonstrate that the combination of prompts performs better than using a single prompt, and we provide the optimal mixing ratio.
* The theoretical result has been empirically validated through rigorous experiments. Our results not only align with theoretical predictions but also consistently demonstrate the practical superiority of our approach in real-world scenarios.

## 2 Related Work

In this section, we examine prior research that serves as the basis for our study. Our investigation is divided into two primary areas: prompt-based federated learning and feature learning theory. Together, these fields create a complete context for our contributions.

### Prompt-based federated learning

Prompt learning, initially developed in the field of natural language processing, has expanded its reach to vision language models. Examples include the CLIP model , which originally utilized manually engineered templates. However, more recent advancements have shifted towards developing prompts within a continuous embedding space. Innovations like CoOp  have refined the CLIP model by introducing continuous prompt vectors, sparking a surge of studies aimed at enhancing the efficiency of prompt learning and providing a solid foundation for further investigation .

To enhance the integration of global data and address challenges in scenarios with limited user data, FedPrompt  and PromptFL  have effectively integrated the concept of prompt learning with federated learning [4; 5; 27; 37; 23]. To tackle the statistical heterogeneity often found in client data,pFedPrompt  introduces a non-parametric approach, providing each client with a personalized attention module. This module is designed to refine spatial visual features to better align with the unique characteristics of local data. Concurrently, pFedPG  introduces a novel prompt generator located at the server, which customizes prompts for each client, thus enhancing the personalization of the federated learning process. Additionally, a recent study, FedOTP , leverages optimal transport theory to improve the balance between achieving global consensus and allowing for local customization through a strategic combination of global and local prompts.

However, there is limited theoretical analysis of federated prompt learning. For instance, the theoretical examination of the CLIP model by  enhances prompt learning theory by exploring how CLIP learns transferable representations across various modalities and improves zero-shot transfer performance with a recently developed regularization technique. However, to the best of our knowledge, no research analyzes prompt learning within a federated setting that elucidates the cooperation between prompts. In this paper, we analyze how different prompts interact with feature learning theory and demonstrate the provable benefits of cooperation between global and local prompts.

### Feature learning theory

Feature learning theory  has revolutionized our understanding of how machine learning models learn and represent information. Unlike other theories, feature learning accommodates substantial weight updates during gradient descent, enabling the network to uncover complex patterns in data. Feature learning theory has been successfully applied to various neural network architectures, including convolutional neural networks [6; 24], graph neural networks , and vision transformers [22; 26]. Moreover, feature learning theory has been used to analyze different training algorithms, such as Adam , momentum , out-of-distribution learning , and Mixup [44; 10]. Notably,  have analyzed the convergence and generalization in general federated learning. Despite progress in feature learning theory, the study of federated prompt learning is sparse. Our work uniquely addresses this gap by analyzing feature learning under prompt-based federated learning, providing crucial insights for their effective adaptation and optimization in such contexts.

## 3 Preliminary

NotationIn our notation, vectors are represented by lowercase bold letters, matrices by uppercase bold letters, and scalars by regular, non-bold letters. The \(_{2}\)-norm of a vector \(\) is indicated as \(||_{2}\). The spectral norm of a matrix \(\) is denoted by \(||_{2}\), and its Frobenius norm by \(||_{F}\). To compare the growth or decline of two sequences, we use standard asymptotic symbols like \(O()\), \(o()\), \(()\), and \(()\), which describe their behavior as they approach infinity. We introduce notations \(()\), \(()\), and \(()\) to obscure logarithmic factors within these expressions. Notably, \(()\) represents the indicator function. Lastly, we represent sequences of integers as \([n]=\{1,2,,n\}\) and sequences of elements such as vectors can also be represented similarly \(_{[n]}=\{_{1},_{2},,_{n}\}\).

### Prompt-based federated learning

In this part, we demonstrate how to fine-tune a learnable text prompt under a vision language pre-trained model. Here, we consider the classification task, where we assume that we have an image \(\). The objective is to correctly classify the image into class \(y[C]\), where the total number of classes is \(C\). From the vision language pre-trained model, we expect that the latent spaces of the text encoder and image encoder are aligned. Thus, when we input different prompts, the text feature generated by the correct prompt will have the highest similarity with the image feature. We input a learnable prompt \(\) and a fixed class prompt \(_{c}\{_{1},,_{C}\}\), which correspond to the classes, into the text encoder \(h\). This process generates the text feature for class \(c\): \(_{c}=h(,_{c})\). On the other hand, the image feature \(\) is generated by the image encoder \(g\): \(_{k,i}=g(_{k,i})^{m}\). We define the similarity function between the image feature \(\) and the text feature \(\) as \(:=[_{c}]=(,_{c})\). The training process mirrors traditional classification tasks, where the objective loss \((,_{y})\) is the distance between the similarity vector and the actual label \(y\). Here, \(\) represents the loss function that measures the distance between two vectors, and \(_{y}\) is the one-hot vector derived from the ground truth label \(y\).

To illustrate the prompt-based federated learning framework, consider a federated system with a central server and \(K\) clients. Assume client \(k\) has \(n_{k}\) training samples: \(\{_{k,i},y_{k,i}\}_{i=1}^{n_{k}}\). The learnable prompt in client \(k\) is denoted as \(_{k}\) and the learnable prompt is aggregated at each communication round.

## 4 Analysis Framework for Prompt-based Federated Learning

In this subsection, we present the analysis framework for prompt-based federated learning from vision-language pre-trained models. The central concept of this framework is the alignment of features between text and image encoders in the vision-language pre-trained model. To achieve this, we link the text encoder and image encoder through a shared latent feature space, described as follows.

**Feature representation and client distribution** Inspired by [6; 24; 19], we expect that the latent feature space will contain task-relevant and task-irrelevant features. In federated learning settings, the task-relevant features can be categorized into global task-relevant features \(_{G}\) and local task-relevant features \(_{1},,_{S}\), where \(S\) is the length of local task-relevant features. Additionally, the task-irrelevant features can be listed as \(_{1},,_{L}\), where \(L\) is the length of task-irrelevant features. Here, we assume that the dimension of the latent space is \(m\) and these features \(_{()},_{()}\), and \(_{()}\) are elements of \(^{m}\). For simplicity, we assume that these features are orthogonal to each other. In our theoretical examination, we address a binary classification scenario with \(y_{k,i}\{+1,-1\}\). We consider a scenario with \(K\) clients, each linked to a distribution \(_{k}, k[K]\). Initially, we choose the signal vector \(_{k}\) for client \(k\) by sampling from \(P(_{1},_{2},,_{S})\), where \(P\) represents a discrete distribution that assigns probabilities to each local task-relevant feature vector \(_{k}:=_{s},s[S]\).

**Text encoder** Here, we suggest coupling the learnable prompt and the class prompt and propose the structure of the text encoder. By adopting a similar setting as , we suppose the generation of the text feature can be written as follows:

\[_{k,i}=h(_{k},_{y_{k,i}})=( _{k}+_{y_{k,i}})-(- _{k}+_{y_{k,i}}),\] (1)

where \(^{m m_{p}}\) is the weight matrix, and \(_{y_{k,i}}^{m_{p}}\) is the prompt linked to a ground truth class. In this definition, the introduction of \(_{y_{k,i}}\) introduces nonlinearity between the trainable prompt and the class prompt while keeping the overall function nonlinear. Note that for a binary classification problem, the vector \(_{y_{k,i}}\) takes \(_{1}\) when \(y_{k,i}=1\) and \(_{-1}\) when \(y_{k,i}=-1\). To reveal the properties of the text encoder in the pre-trained model, we assume that the weight matrix \(\) is composed of the following rows:

\[=[_{G},_{1},,_{s},, _{S},_{1},,_{L}]^{T}\,.\] (2)

The assumption of the weight matrix is inspired by , and the evidence of this assumption is listed in the Appendix D. In our analysis framework, we adapt FedAvg  as our prompt aggregation algorithm, which is named PrompFL . The aggregation formula is given by:

\[_{G}^{(t+1)}_{k=1}^{K}}{n} _{G,k}^{(t)},\] (3)

where \(n:=_{k}n_{k}\) denotes the total number of data samples across all clients.

**Image encoder** Let us consider the image network, represented as \(_{k,i}=g(_{k,i})^{m}\). We assume that the image encoder also aligns the feature space of the text encoder within the pre-trained model. As a result, we assume the image feature generated by data \(_{k,i}\) in client \(i\) can be expressed as follows:

\[_{k,i}=g(_{k,i})=[y_{k,i},_{(s-1)},y_{k,i},_{(S-s)},x_{k,i,1},,x_{k,i,L}]^{T}\] (4)

where \(x_{k,i,l}(0,_{p}^{2}), l[L]\) represents the coefficient of task-irrelevant terms in the data, and \(_{p}^{2}\) is the variance. This assumption implies that task-relevant features vary based on whether the label is positive or negative, whereas task-irrelevant features persist as arbitrary and unrelated to the label's polarity. The similarity score between an image \(_{k,i}\) and class \(y_{k,i}\) is expressed as \((_{k,i},_{k,i})=_{k,i},_{ k,i}\). Moreover, the objective of the training loss is designed to enhance the resemblance between the image feature \(g(_{k,i})\) and the text feature created by the ground truth prompt \(_{y_{k,i}}\).

**Signal-noise decomposition** Based on the above model, we introduce the signal-noise decomposition of the learnable prompt here. Note that the proofs of the following lemmas and theorems are listed in the appendix.

**Lemma 4.1** (**Feature Representation**).: _At the \(t\)-th iteration, the learnable prompt \(_{k}^{(t)}\) for client \(k\) and the aggregated prompt \(}^{(t)}\) can be rewritten as a linear combination of features and prompt initialization:_

\[_{k}^{(t)} =_{k}^{(t)}||_{G}||_{2}^{-2}_{G}+_{k^{}=1}^{K}(_{k,k^{}}^{(t)}_{k^{ }}^{(0)}+_{k,k^{}}^{(t)}||_{k^{}}||_{2}^{-2} _{k^{}})+_{l=1}^{L}_{k,l}^{(t)}||_{l}||_{2}^{-2}_{l},\] \[}^{(t)} =^{(t)}||_{G}||_{2}^{-2} _{G}+_{k=1}^{K}(_{k}^{(t)} _{k}^{(0)}+_{k}^{(t)}||_{k}||_{2}^ {-2}_{k})+_{l=1}^{L}_{l}^{(t)}|| {}_{l}||_{2}^{-2}_{l}.\] (5)

_where \(_{,}^{(t)}\) are the coefficients of initialization, \(_{,}^{(t)}\) is the coefficient of global task-relevant features, \(_{,}^{(t)}\) is the coefficient of local task-relevant features, \(_{,}^{(t)}\) are the coefficients of task-irrelevant features, and the overlined coefficients are the averaged versions of the original coefficients._

Here, since the learnable prompts can be written as a linear combination of the features, we can analyze the dynamics of these coefficients to understand the learning progress of the prompts. The normalized factor such as \(||_{G}||_{2}^{-2}\) is used to make the coefficient similar to the inner product of the prompts and the features, \(_{k}^{(t)}_{k}^{(t)},_{G}\).

**Coefficient dynamics** Inspired by previous studies , we employ a two-phase analysis to track the dynamics of coefficients in prompt-based federated learning from vision-language foundation models. By analyzing the dynamics of the coefficients, we can obtain the feature learning procedure during training. This two-stage analysis allows us to establish the order of coefficients and explore how they are affected by the mixing parameter \(\). For the theorem and proof of this analysis, please refer to Appendix F.

**Theorem 4.2** (**Training Dynamics**).: _There exists a total number of local updates \(T_{1}=R_{1}E=O(^{-1}Kn_{p}^{2}_{L}^{2})\) such that_

\[^{(T_{1})}=(K_{G}^{2}),\;\;\; _{k}^{(T_{1})}=(_{k}_{k}^{2} ),\;\;\;_{l}^{(T_{1})}=O(1) k[K],l[L].\] (6)

_Here, \(=_{k}n_{k}/K\) is the average number of data in each client, and \(_{G}=||_{G}||/(_{p})\), \(_{k}=||_{k}||/(_{p})\) denote the signal-to-noise ratio between the task-relevant feature and task-irrelevant feature. We define \(_{k}=_{k^{}=1}^{K}_{k},_{ k^{}}/||_{k}||_{2}^{2}\)._

**Test performance evaluation with coefficients** Here, we suppose the classification output of the \(i\)-th data in client \(k\) is the class corresponding to the highest similarity between the text feature and image feature, denoted as \(_{k,i}\). To assess the algorithm's performance, we evaluate the error rate in the test procedure as our test loss \(L_{}\):

\[L_{}(})=_{k=1}^{K}_{i=1}^{n_{ k}}(_{k,i}=y_{k,i}).\] (7)

The following theorem demonstrates that the test loss can be considered as the probability that a Gaussian random variable falls below zero, with the mean and variance influenced by the task-relevant and task-irrelevant coefficients.

**Theorem 4.3** (**Test Loss**).: _The expectation of test loss \(L_{}\) of an algorithm can be treated as the probability_

\[[L_{}]:=P(z<0), z(, ^{2}),\] (8)

_where \(\) and \(\) are functions of task-relevant and task-irrelevant coefficients, as defined in AppendixDrawing from this theorem and the properties of Gaussian distributions, an algorithm's performance can be evaluated by the ratio \(/\). This ratio highlights the influence of task-relevant and task-irrelevant features on test loss. Specifically, a higher task-relevant coefficient coupled with a lower task-irrelevant coefficient typically leads to better performance.

**Connection with portfolio optimization** The Markowitz mean-variance model is a famous framework for assembling a portfolio of assets such that the expected return is maximized for a given level of risk [31; 32]. This model characterizes assets by their expected returns and risks. It claims that the return of the whole portfolio is a proportionally weighted combination of the assets' returns, and the risk of the whole portfolio is a function of the correlations of the component assets. According to the properties of task-relevant and task-irrelevant coefficients, the task-relevant coefficient can be directly added, and the task-irrelevant feature follows the additive property of Gaussian random variables. Thus, we connect the task-relevant coefficient to the return and the task-irrelevant feature to the risk. This connection provides insight that the combination of prompts, i.e., a prompt portfolio, will lead to a higher ratio of task-relevant features to task-irrelevant features.

## 5 PromptFolio: Global-Local Prompt Portfolio for Federated Learning

Building on the significant connection between the feature learning process and portfolio optimization, we treat the prompt trained by CoOp and the prompt trained by PromptFL as the two prompt assets and propose a simple yet powerful mixing algorithm, PromptFolio 2. For simplicity, we refer to the prompt trained by CoOp as the local prompt \(_{L}\) and the prompt trained by PromptFL as the global prompt \(_{G}\).

```
1:Initialize \(_{G}\) and \(_{L,k}\) for all clients \(k\)
2:\(t 0\)\(\) Initialization of the iteration counter
3:while not converged do
4:for each client \(k\) in parallel do
5: Send \(_{G}^{(t)}\) to client \(k\), \(_{G,k}^{(t)}_{G}^{(t)}\)
6:for each sample \((_{k,i},y_{k,i})\) in client \(k\)'s data do
7: Compute \(_{k,i} g(_{k,i})\)
8:for\(c 1\) to \(C\)do
9: Compute \(_{k,i,c}(1-) h(_{G,k}^{(t)},_{c})+ h(_{L,k}^{(t)},_{c})\)
10: Compute similarity \(_{k,i,c}(_{k,i},_{k,i,c})\)
11:endfor
12: Update \(_{G,k},_{L,k}\) by minimizing train loss \((_{k,i},_{y_{k,i}})\)
13:endfor
14: Send \(_{G,k}^{(t+1)}\) to server
15:endfor
16: Update \(_{G}^{(t+1)}_{k=1}^{K}}{n}_{G,k}^ {(t+1)}\)\(\) FedAvg to aggregate global prompt
17:\(t t+1\)
18:endwhile
19:return\(_{G}\), \(_{L,k}\) for all \(k\) ```

**Algorithm 1** (PromptFolio) Global-Local Prompt Portfolio

### PromptFolio Method

The local learning process generates the local feature by including a specific local prompt, whereas the global learning process adopts a similar strategy but also uses FedAvg to compile learnable prompts from various clients. We enhance cooperation between the local and global learning processes by merging both local and global features to create the final text feature. The text feature is produced as follows:

\[_{k,i,c}=(1-) h(_{G},_{c})+  h(_{L,k},_{c}),\] (9)where \(\) serves as a coefficient to balance the mix of the two features, which addresses the balancing between personalization and generalization. The variation in the parameter \(\) influences the outcomes of the inference. Specifically, when \(=0\), the algorithm reverts to PrompFL , whereas at \(=1\), it shifts to CoOp . Our approach consists of combining these features and using the resulting mixed feature to determine their similarity. This feature is subsequently utilized to evaluate the similarity between text and image features. Note that this algorithm differs from typical personalized algorithms  as it focuses on integrating text features instead of adjusting training weights. The framework of PromptFolio is described in Algorithm 1.

### Analysis for PromptFolio

In this part, we offer a theoretical demonstration of the performance advantage of PromptFolio and the selection of the optimal mixing coefficient \(\). According to Theorem 4.3, each algorithm can be regarded as a Gaussian random variable. The test performance correlates with the ratio of task-relevant features to task-irrelevant features. This ratio enables us to analyze the test results of various learning algorithms.

Suppose that the coefficients of the prompt via local training at step \(k\) are \(_{k},_{k}\) and \(_{k}\), and the coefficients of the global prompt at step \(k\) are \(_{k},_{k}\) and \(_{k}\). We define the mean and variance of the Gaussian variable corresponding to the local prompt as \(_{k}\) and \(_{k}\), and the mean and variance of the Gaussian variable corresponding to the global prompt as \(_{k}\) and \(_{k}\). Let \(=(1/k)\) be the correlation between the Gaussian of the local prompt and the global prompt. Here, we define \(a:=}{_{k}}=(+_{k}}{_{k}+ _{k}})=(_{G}+K_{k}}{K_{G}+ _{k}_{k}})\) and \(b:=}{_{k}}=O(}{_{k}})=O(K)\) as the ratio of different coefficients. Here, the order of \(a\) and \(b\) depends on the coefficient derived in Lemma F.3. As a result, we have the following theorem, and the proof can be referred to in Appendix E.3.

**Theorem 5.1** (PromptFolio Advantage).: _The mixed PromptFolio algorithm has a lower test loss than the mixing test loss of CoOp and PromptFL:_

\[L_{}((1-)_{G}+_{L}) (1-)L_{}(_{G})+ L_{}( _{L})\] (10)

\[\ [0,}(-C_{c}}{2 C_{a}})],\ C_{a}=(b-a)(b^{2}+2 b+1)\\ C_{b}=(a+b)(b^{2}-1)-4b( b-1)\\ C_{c}=(b-1)(b+1)^{2}-8ab^{2}(+1)^{2}}.\]

Figure 1: The image demonstrates the framework of the PromptFolio algorithm. The algorithm updates the global prompt and local prompt while keeping the weights of the fixed vision-language pretrained model unchanged. Additionally, it aggregates the global prompts from each client. The right side of the image intuitively demonstrates the advantages of global-local cooperation for performance when global and local are treated as two assets.

The results discussed demonstrate how combining global and local text features enhances performance and illustrate the optimal way to balance personalization with generalization. Here, \(a\) and \(b\) are the ratio of coefficients and reveal how the global feature and local feature interact. Drawing on principles from portfolio optimization, which involves blending two assets that are not perfectly correlated, we can construct a portfolio that maximizes returns while minimizing risk. Given the characteristics of Gaussian random variables, we intuitively correlate the coefficient of task-relevant features with returns and the coefficient of task-irrelevant features with risk. Thus, the first part of Theorem 5.1 provides a rationale that a well-balanced portfolio of prompt features can significantly improve performance.

Similar to the portfolio optimization problem, we can also derive the optimal mixing coefficient \(\).

**Theorem 5.2** (**Optimal Mixing Coefficient**).: _The optimal mixing coefficient \(^{}\) follows_

\[^{}=}()- b(a+1)}).\] (11)

Theoretically, if we further simplify the mixing coefficient with the order of \(a\), \(b\) and \(\), then we get that

\[^{}=()_{k}}{(K^{ 2}-1)(K_{G}+_{k}_{k})}).\] (12)

In this theorem, we note that a lower \(_{k}\) indicates greater data heterogeneity, which lead to a higher \(^{}\). This observation aligns with the intuition that, due to the non-i.i.d. distribution of data, the model should incorporate more local information, thereby making the optimal \(\) closer to 1.

## 6 Experiments

In this section, we conduct experiments with the CLIP model to empirically demonstrate the performance advantages of PromptFolio. Specifically, the image network \(g\) and the text network \(h\) are components of a pre-trained CLIP model. By evaluating results obtained using various mixing coefficients across different datasets, data distribution, and client number, we align theory with practice. We use the Dirichlet distribution to manage data heterogeneity and employ FedAvg as the aggregation strategy. The experiment is conducted on the CIFAR-100 dataset by default, with the model trained for 10 epochs locally and the results evaluated over 100 communication rounds.

### Performance evaluation on various datasets

In this section, we observe that the combination of global and local algorithms outperforms both the prompt-based federated learning with FedAvg and individual prompt learning approaches. Under the CLIP model setting, the global and local prompt learning algorithm degenerates to PromptFL and CoOp, respectively. To explore why this global-local collaboration is more effective than either approach alone, we evaluate the accuracy of various mixing coefficients \(\) across different datasets. We use CIFAR-100 , DomainNet , Office-Caltech10 , OxfordPets , and DTD , adopting \(=0.2\) as the general mixing coefficient for our algorithm. The quantitative results are shown in Table 1. From this table, it is evident that blending global and local prompts consistently leads to enhanced accuracy, with the accuracy curve also showing a peak. Further performance evaluations can be found in Appendix A.

### Performance evaluation under various data heterogeneity

We then conduct the experiment over different data distributions. By varying the parameters of the Dirichlet distribution exponentially from 0.01 to 10, we controlled the heterogeneity of the data. A

   & **Cifar100** & **DomainNet** & **Office-Cal10** & **OxfordPets** & **DTD** \\  CoOp & 76.88 \(\) 0.07 & 91.83 \(\) 0.13 & 97.10 \(\) 0.20 & 87.85 \(\) 0.32 & 56.39 \(\) 0.48 \\ PromptFL & 78.16 \(\) 0.16 & 92.72 \(\) 0.16 & 95.51 \(\) 2.62 & 88.91 \(\) 0.72 & 70.99 \(\) 0.32 \\ PromptFolio & **80.17 \(\) 0.05** & **93.04 \(\) 0.09** & **97.24 \(\) 0.11** & **92.17 \(\) 0.32** & **71.32 \(\) 0.49** \\  

Table 1: Accuracy of CoOp, PromptFL, PromptFolio on different datasets.

larger \(\) indicates that the data is closer to an i.i.d. distribution. Using 10 users, we performed our experiments, and the results are shown in Figure 2(a).

From Figure 2(a), we observe that hybrid approaches outperform solitary methods, consistent with our theoretical analysis. Additionally, higher \(\) values, indicating a more uniform distribution, generally result in a superior global model compared to local models tailored for specific users. This finding supports our conclusion that a more IID distribution leads to \(_{k}\) being higher and closer to \(K\), resulting in a higher task-relevant to task-irrelevant coefficient ratio, and thus better performance. Conversely, in scenarios where data is highly non-IID, there is a preference for using more local models to maintain high accuracy, which aligns with our analysis of the optimal mixing coefficient \(^{}\).

### Performance evaluation with different client number

Furthermore, we conducted experiments with different numbers of users on the CIFAR-100 dataset, keeping the Dirichlet distribution parameter fixed at \(=0.01\), which represents a pathological non-i.i.d. distribution. The number of users varies from 5 to 100, and the results are shown in Figure 2(b). From these results, we observe that the trend of the mixing strategy outperforming the independent global and local algorithms remains consistent, regardless of the number of users. As the number of users increases, the optimal \(\) shifts closer to zero, indicating that with more users, each client's information becomes less significant, necessitating more global information. Additionally, the accuracy first increases and then decreases with the number of users, suggesting that there is an optimal number of users, consistent with theoretical results.

## 7 Conclusion

This work presents a thorough theoretical and empirical exploration of prompt-based federated learning, integrating vision-language foundation models such as CLIP. By developing an analytical framework based on feature learning theory, we have examined the dynamics of signal learning and noise memorization specific to federated settings, providing a robust mechanism to evaluate the effectiveness of prompt-based learning strategies. Notably, our introduction of PromptFolio, which combines global and local prompts into a prompt portfolio, offers an approach to balancing generalization with personalization, drawing an innovative parallel with portfolio optimization in

Figure 2: The x-axis represents the mixing coefficients, which range from 0 to 1, and the y-axis shows the accuracy of the test set after training. The left figure depicts the result under different data distributions, and the right figure reveals the result under different users.

finance. This approach balances generalization with personalization, supported by an optimal mixing coefficient from our theoretical framework to tailor adaptability in various federated settings. Empirical tests confirm our method's superiority, aligning with theoretical insights and outperforming traditional federated learning approaches. Limitations include a simplified text model with a single activation function, suggesting future work with more complex models to better capture deep network behaviors in federated environments.