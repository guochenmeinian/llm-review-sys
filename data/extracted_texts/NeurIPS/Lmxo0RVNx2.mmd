# Individualized Dosing Dynamics

via Neural Eigen Decomposition

 Stav Belogolovsky

stav.belo@gmail.com

&Ido Greenberg

gido@campus.technion.ac.il

Department of Electrical and Computer Engineering, Technion--Israel Institute of Technology, Haifa, Israel

Department of Physiology and Biophysics, Faculty of Medicine, Technion--Israel Institute of Technology, Haifa, Israel

Danny Eytan

biliary.colic@gmail.com

&Shie Mannor

shie@ee.technion.ac.il

Nvidia Research

###### Abstract

Dosing models often use differential equations to model biological dynamics. Neural differential equations in particular can learn to predict the derivative of a process, which permits predictions at irregular points of time. However, this temporal flexibility often comes with a high sensitivity to noise, whereas medical problems often present high noise and limited data. Moreover, medical dosing models must generalize reliably over individual patients and changing treatment policies. To address these challenges, we introduce the Neural Eigen Stochastic Differential Equation algorithm (**NESDE**). NESDE provides individualized modeling (using a hypernetwork over patient-level parameters); generalization to new treatment policies (using decoupled control); tunable expressiveness according to the noise level (using piecewise linearity); and fast, continuous, closed-form prediction (using spectral representation). We demonstrate the robustness of NESDE in both synthetic and real medical problems, and use the learned dynamics to publish simulated medical gym environments.

## 1 Introduction

Sequential forecasting in irregular points of time is required in many real-world problems, such as modeling dosing dynamics of various medicines (pharmacodynamics). Consider a patient whose physiological or biochemical state requires continuous monitoring, while blood tests are only available with a limited frequency. Pharmacodynamics models often rely on an ordinary differential equation models (ODE) for forecasting. Additional expressiveness can be obtained via customized learned models, such as neural-ODE, which learns to predict the derivative of the process (Chen et al., 2018; Liu et al., 2019). By predicting the _derivative_, neural-ODE can make irregular predictions at flexible time-steps, unlike regular models that operate in constant time-steps (e.g., Kalman filter, Kalman (1960) and recurrent neural networks, Rumelhart et al. (1986)).

However, real-world forecasting remains a challenge for several reasons. First, the variation between patients often requires personalized modeling. Second, neural-ODE methods are often data-hungry: they aggregate numerous derivatives provided by a non-linear neural network, which is often sensitive to noise. Training over a large dataset may stabilize the predictions, but data is often limited. Third, most neural-ODE methods only provide a point-estimate, while uncertainty estimation is often critical in medical settings. Fourth, for every single prediction, the neural-ODE runs a numeric ODE solver,along with multiple neural network calculations of the derivative. This computational overhead in inference may limit latency-sensitive applications.

A fifth challenge comes from control. In the framework of retrospective forecasting, a control signal (drug dosage) is often considered part of the observation (De Brouwer et al., 2019). However, this approach raises difficulties if the control is observed at different times or more frequently than other observations. If the control is part of the model output, it may also bias the train loss away from the true objective. Finally, by treating control and observations together, the patterns learned by the model may overfit the control policy used in the data - and generalize poorly to new policies.

Generalization to out-of-distribution control policies is essential when the predictive model supports decision-making, as the control policy may be affected by the model. Such decision-making is an important use-case of sequential prediction: model-based reinforcement learning and control problems require a reliable model (Moerland et al., 2020; Angermueller et al., 2019), in particular in risk-sensitive control (Yu et al., 2021; Greenberg et al., 2022; Greenberg and Mannor, 2021).

Section 4 introduces the Neural Eigen-SDE algorithm (**NESDE**) for continuous forecasting, which is designed to address the challenges listed above. NESDE uses a hypernetwork to provide an individualized stochastic differential equation (SDE), regularized to be piecewise-linear and represented in spectral form. The SDE derives a probabilistic model similar to Kalman filtering, which provides uncertainty estimation. Finally, the SDE decouples the control signal from other observations, to discourage the model from learning control patterns that may be violated under out-of-distribution control policies. Table 1 summarizes all these features.

Section 5 tests NESDE against both neural-ODE methods and recurrent neural networks. NESDE demonstrates robustness to both noise (by learning from little data) and out-of-distribution control policies. In Appendix E.5, the SDE model of NESDE is shown to enable potential domain knowledge and provide interpretability - via the predicted SDE eigenvalues. Appendix E.4 demonstrates the disadvantage of discrete methods in continuous forecasting.

In Section 6, NESDE demonstrates high prediction accuracy in two medical forecasting problems with noisy and irregular real-world data: (1) blood coagulation prediction given Heparin dosage, and (2) prediction of the Vancomycin (antibiotics) levels for patients who received it.

**Contribution:**

* We characterize the main challenges in continuous forecasting for medication dosing control.
* We design the novel Neural Eigen-SDE algorithm (NESDE), which addresses the challenges as summarized in Table 1 and demonstrated empirically in Sections 5 and 6.
* We use NESDE to improve modeling accuracy in two medication dosing processes. Based on the learned models, we simulate gym environments for future research of healthcare control.

  
**Challenge** & **Solution** & **Experimental evaluation** \\   & Hyper-network with & Hyper-network ablation \\  & high-level features input & (Appendix E.1) \\  & Regularized dynamics: & Varying train size \\   Sample efficiency & piecewise-linear with & (Section 5, Appendix E.2); \\  & complex eigenvalues & varying sparsity (Appendix E.3) \\   Uncertainty estimation & Probabilistic Kalman & NLL evaluation (Sections 5,6) \\   Fast continuous inference & Spectral representation & Time flexibility (Appendix E.4); \\  & with closed-form solution & interpretability (Appendix E.5) \\   Control generalization & Decoupling control & Out of distribution control \\    & from other inputs & (Section 5, Appendix E.6) \\   

Table 1: A summary of the features of NESDE. In Sections 5,6, NESDE is tested on synthetic and real medical data. In addition, each component of NESDE is studied experimentally as specified.

### Related Work

**Classic filtering:** Classic models for sequential prediction in time-series include ARIMA models (Moran and Whittle, 1951) and the Kalman filter (KF) (Kalman, 1960). The KF provides probabilistic distributions and in particular uncertainty estimation. While the classic KF is limited to linear dynamics, many non-linear extensions have been suggested (Krishnan et al., 2015; Coskun et al., 2017; Revach et al., 2021; Greenberg et al., 2021). However, such models are typically limited to a constant prediction horizon (time-step). Longer-horizon predictions are often made by applying the model recursively (Herrera et al., 2007; Bontempi et al., 2013), This poses a significant challenge to many optimization methods (Kolen and Kremer, 2001), as also demonstrated in Appendix E.4.

Limited types of irregularity can also be handled by KF with intermittent observations (Park and Sahai, 2011; Sinopoli et al., 2004) or periodical time-steps (Li et al., 2008).

**Recurrent neural networks:** Sequential prediction is often addressed via neural network models, relying on architectures such as RNN (Rumelhart et al., 1986), LSTM (Hochreiter and Schmidhuber, 1997) and transformers (Vaswani et al., 2017). LSTM, for example, is a key component in many SOTA algorithms for non-linear sequential prediction (Neu et al., 2021). LSTM can be extended to a filtering framework to alternately making predictions and processing observations, and even to provide uncertainty estimation (Gao et al., 2019). However, these models are typically limited to constant time-steps, and thus suffer from the limitations discussed above.

**Neural-ODE models:** Parameterized ODE models can be optimized by propagating the gradients of a loss function through an ODE solver (Chen et al., 2018; Liu et al., 2019; Rubanova et al., 2019). By predicting the process _derivative_ and using an ODE solver in real-time, these methods can choose the effective time-steps flexibly. Uncertainty estimation can be added via process variance prediction (De Brouwer et al., 2019). However, since neural-ODE methods learn a non-linear dynamics model, the ODE solver operates numerically and recursively on top of multiple neural network calculations. This affects running time, training difficulty and data efficiency as discussed above. While neural-ODE models have been studied for medical applications with irregular data (Lu et al., 2021), simpler models are commonly preferred in practice. For example, the effects of Heparin on blood coagulation is usually modeled by either using discrete models (Nemati et al., 2016) or manually based on domain knowledge (Delavenne et al., 2017).

Our method uses SDE with piecewise linear dynamics (note this is _different_ from a piecewise linear process). The linear dynamics per time interval permit efficient and continuous closed-form forecasting of both mean and covariance. Schirmer et al. (2022) also rely on a linear ODE model, but only support operators with real-valued eigenvalues (which limits the modeling of periodic processes), and do not separate control signal from observations (which limits generalization to out-of-distribution control). Our piecewise linear architecture, tested below against alternative methods including De Brouwer et al. (2019) and Schirmer et al. (2022), is demonstrated to be more robust to noisy, sparse or small datasets, even under out-of-distribution control policies.

## 2 Preliminaries: Linear SDE

We consider a particular case of the general linear Stochastic Differential Equation (SDE):

\[dX(t)=[A X(t)+(t)]+dW(t)\] (1)

where \(X:^{n}\) is a time-dependent state; \(A^{n n}\) is a fixed dynamics operator; \(:^{n}\) is the control signal; and \(dW:^{n}\) is a Brownian motion vector with covariance \(Q^{n n}\).

General SDEs can be solved numerically using the first-order approximation \( X(t) t dX(t)\), or using more delicate approximations (Wang and Lin, 1998). The linear SDE, however, and in particular Eq. (1), can be solved analytically (Herzog, 2013):

\[X(t)=(t)((t_{0})^{-1}X(t_{0})+~{}_{t_{0}}^{t}()^{-1} ()d+_{t_{0}}^{t}()^{-1}dW())\] (2)

where \(X(t_{0})\) is an initial condition, and \((t)\) is the eigenfunction of the system. More specifically, if \(V\) is the matrix whose columns \(\{v_{i}\}_{i=1}^{n}\) are the eigenvectors of \(A\), and \(\) is the diagonal matrixwhose diagonal contains the corresponding eigenvalues \(=\{_{i}\}_{i=1}^{n}\), then

\[(t)=Ve^{ t}=|&|&|&|&|\\ v_{1} e^{_{1}t}&&v_{i} e^{_{i}t}&&v_{n} e^ {_{n}t}\\ |&|&|&|&|\] (3)

If the initial condition is given as \(X(t_{0}) N(_{0},_{0})\), Eq. (2) becomes

\[ X(t)& N((t),(t))\\ (t)&=(t)((t_{0})^{-1}_{0}+_{t_{0}}^{t} ()^{-1}()d),\ (t)=(t)^{}(t)(t)^{} \] (4)

where \(^{}(t)=(t_{0})^{-1}_{0}((t_{0})^{-1})^{}+_{t _{0}}^{t}()^{-1}Q(()^{-1})^{}d\).

Note that if \( i:_{i}<0\) and \( 0\), we have \((t)[t]{t}0\) (stable system). In addition, if \(\) is complex, Eq. (4) may produce a complex solution; Appendix C explains how to use a careful parameterization to only calculate the real solutions.

## 3 Problem Setup: Sparsely-Observable SDE

We focus on online sequential prediction of a process \(Y(t)^{m}\). To predict \(Y(t_{0})\) at a certain \(t_{0}\), we can use noisy observations \((t)\) (at given times \(t<t_{0}\)), as well as a control signal \(u(t)^{k}\)\(( t<t_{0})\); offline data of \(Y\) and \(u\) from other sequences; and one sample of contextual information \(C^{d_{c}}\) per sequence (capturing properties of the whole sequence). **The dynamics of \(Y\) are unknown and may vary between sequences**. For example, sequences may represent different patients, each with its own dynamics; \(C\) may represent patient information; and the objective is "zero-shot" learning upon arrival of a sequence of any new patient. In addition, **the observations within a sequence are both irregular and sparse**: they are received at arbitrary points of time, and are sparse in comparison to the required prediction frequency (i.e., continuous forecasting, as illustrated in Fig. 1).

To model the problem, we assume the observations \(Y(t)\) to originate from an unobservable latent process \(X(t)^{n}\) (where \(n>m\) is a hyperparameter). More specifically:

\[dX(t)=F_{C}X(t),u(t),\ Y(t)=X(t)_{1:m},\ (t)=Y(t)+_{C}(t)\] (5)

where \(F_{C}\) is a stochastic dynamics operator (which may depend on the context \(C\)); \(Y\) is simply the first \(m\) coordinates of \(X\); \(\) is the corresponding observation; and \(_{C}(t)\) is its i.i.d Gaussian noise with zero-mean and (unknown) covariance \(R_{C}^{m m}\) (which may also depend on \(C\)). Our goal is to predict \(Y\), where the dynamics \(F_{C}\) are unknown and the latent subspace of \(X\) is unobservable. In cases where data of \(Y\) is not available, we measure our prediction accuracy against \(\). The control \(u(t)\) is modeled separately from \(\), is not part of the prediction objective, and does not depend on \(X\).

## 4 Neural Eigen-SDE Algorithm

**Model:** In this section, we introduce the Neural Eigen-SDE algorithm (NESDE, shown in Algorithm 1 and Fig. 2). NESDE predicts the signal \(Y(t)\) of Eq. (5) continuously at any required point of time \(t\). It relies on a piecewise linear approximation which reduces Eq. (5) into Eq. (1):

\[ t_{i}:\ dX(t)=[A_{i}(X(t)-)+B u(t)]+dW(t)\] (6)

where \(_{i}=(t_{i},t_{i+1})\) is a time interval, \(dW\) is a Brownian noise with covariance matrix \(Q_{i}\), and \(A_{i}^{n n},B^{n k},Q_{i}^{n  n},^{n}\) form the linear dynamics model corresponding to the

Figure 1: Samples of sparsely observed SDEs: the Brownian noise and the sparse observations pose a major challenge for learning the underlying SDE dynamics. Efficient learning from external trajectories data is required, as the current trajectory often does not contain sufficient observations.

interval \(_{i}\). In terms of Eq. (1), we substitute \(A A_{i}\) and \( Bu-A_{i}\). Note that if \(A_{i}\) is a stable system and \(u 0\), the asymptotic state is \((t)\). To solve Eq. (6) within every \(_{i}\), NESDE has to learn the parameters \(\{A_{i},Q_{i}\}_{i},,B\).

The end of \(_{i-1}\) typically represents one of two events: either an update of the dynamics \(A\) (allowing the piecewise linear dynamics), or the arrival of a new observation. A new observation at time \(t_{i}\) triggers an update of \(X(t_{i})\) according to the conditional distribution \(X(t_{i})|(t_{i})\) (this is a particular case of Kalman filtering, as shown in Appendix A). Then, the prediction continues for \(_{i}\) according to Eq. (6). Note that once \(X(t_{0})\) is initialized to have a Normal distribution, it remains Normally-distributed throughout both the process dynamics (Eq. (4)) and the observations filtering (Appendix A). This allows NESDE to efficiently capture the distribution of \(X(t)\), where the estimated covariance represents the uncertainty.

**Eigen-SDE solver (ESDE) - spectral dynamics representation:** A key feature of NESDE is that \(A_{i}\) is only represented implicitly through the parameters \(V,\) defining its eigenfunction \((t)\) of Eq. (3) (we drop the interval index \(i\) with a slight abuse of notation). The spectral representation allows Eq. (4) to solve \(X(t)\) analytically for any \(t_{i}\) at once: the predictions are not limited to predefined times, and do not require recursive iterations with constant time-steps. This is particularly useful in the sparsely-observable setup of Section 3, as it lets numerous predictions be made _at once_ without being "interrupted" by a new measurement.

The calculation of Eq. (4) requires efficient integration. Many SDE solvers apply recursive numeric integration (Chen et al., 2018; De Brouwer et al., 2019). In NESDE, however, thanks to the spectral decomposition, the integration only depends on known functions of \(t\) instead of \(X(t)\) (Eq. (4)), hence recursion is not needed, and the computation can be paralleled. Furthermore, if the control \(u\) is constant over an interval \(_{i}\) (or has any other analytically-integrable form), Appendix B shows how to calculate the integration _analytically_. Piecewise constant \(u\) is common, for example, when the control is updated along with the observations.

In addition to simplifying the calculation, the spectrum of \(A_{i}\) carries significant meaning about the dynamics. For example, negative eigenvalues correspond to a stable solution, whereas imaginary ones indicate periodicity, as demonstrated in Fig. 4. Note that the (possibly-complex) eigenvalues must be constrained to represent a real matrix \(A_{i}\). The constraints and the calculations in the complex space are detailed in Appendix C.

Note that if the process \(X(t)\) actually follows the piecewise linear model of Eq. (6), and the model parameters are known correctly, then the Eigen-SDE solver trivially returns the optimal predictions. The complete proposition and proof are provided in Appendix D.

**Proposition 1** (Eigen-SDE solver optimality).: If \(X(t)\) follows Eq. (6) with the same parameters used by the Eigen-SDE solver, then under certain conditions, the solver prediction at any point of time optimizes both the expected error and the expected log-likelihood.

Proof Sketch.: If the process \(X(t)\) follows Eq. (6), the Eigen-SDE solver output corresponds to the true distribution \(X(t) N((t),(t))\) for any \(t\). Thus, both the expected error and the expected log-likelihood are optimal. 

**Updating solver and filter parameters:** NESDE provides the parameters \(V,,Q,B,\) to the Eigen-SDE solver, as well as the noise \(R\) to the observation filter. As NESDE assumes a _piecewise_ linear model, it separates the time into intervals \(_{i}=(t_{i},t_{i+1})\) (the interval length is a hyperparameter), and uses a dedicated model to predict new parameters at the beginning \(t_{i}\) of every interval.

The model receives the current state \(X(t_{i})\) and the contextual information \(C\), and returns the parameters for \(_{i}\). Specifically, we use Hypernet : one neural network \(g_{1}\) with network parameters \(\), returns the weights of a second network \(g_{2}\), i.e., \(W=g_{1}(C;)\). Then, \(g_{2}\) maps the current state estimation to a set of dynamics parameters: \((V,,Q,B,,R)=g_{2}(X;W)=g_{2}(X;g_{1}(C;))\) (Fig. 3). The dynamics \(g_{2}(X;W)\) may be updated more often than the individualized weights \(W=g_{1}(C;)\), as the context \(C\) may change with a lower frequency. For the initial state, where \(X\) is unavailable, we learn a _state prior_ from \(C\) by a dedicated network; this prior helps NESDE to function as a "zero-shot" model.

The Hypernet module implementation gives us control over the non-linearity and non-stationarity of the model. The importance of the Hypernet module for individualized modeling is demonstrated in an ablation test in Appendix E.1. In our current implementation, only \(V,,Q\) are renewed every time interval. \(\) (asymptotic signal) and \(R\) (observation noise) are only predicted once per sequence, as we assume they are independent of the state. The control mapping \(B\) is assumed to be a global parameter.

**Training:** The learnable parameters of NESDE are the control mapping \(B\) and Hypernet's parameters \(\) (which in turn determine the rest of the parameters). To optimize them, the training relies on a dataset of sequences of control signals \(\{u_{seq}(t_{j})\}_{seq,j}\) and (sparser and possibly irregular) states and observations \(\{(Y_{seq}(t_{j}),_{seq}(t_{j}))\}_{seq,j}\) (if \(Y\) is not available, we use \(\) instead as the training target).

The latent space dimension \(n\) and the model-update frequency \( t\) are determined as hyperparameters. Then, we use the standard Adam optimizer  to optimize the parameters with respect to the loss \(NLL(j)=- P(Y(t_{j})|(t_{j}),(t_{j}))\) (where \(,\) are predicted by NESDE sequentially from \(u,\)). Each training iteration corresponds to a batch of sequences of data, where the \(NLL\) is aggregated over all the samples of the sequences. Note that our supervision for the training is limited to the times of the observations, even if we wish to make more frequent predictions in inference.

Figure 4: Sample trajectories with different types of dynamics (and random control signal that is not displayed). As demonstrated in Appendix E.5, NESDE directly estimates the dynamics \(\) and reveals their type.

As demonstrated below, the unique architecture of NESDE provides effective regularization and data efficiency (due to piecewise linearity), along with tunable expressiveness (neural updates with controlled frequency). Yet, it is important to note that the piecewise linear SDE operator does limit the expressiveness of the model (e.g., in comparison to other neural-ODE models). Further, NESDE is only optimal under a restrictive set of assumptions, as specified in Proposition 1.

## 5 Synthetic Data Experiments

In this section, we test three main aspects of NESDE: (1) prediction from partial and irregular observations, (2) robustness to out-of-distribution control (OOD), and (3) sample efficiency. We experiment with data of a simulated stochastic process, designed to mimic partially observable medical processes with indirect control.

The simulated data includes trajectories of a 1-dimensional signal \(Y\), with noiseless measurements at random irregular times. The goal is to predict the future values of \(Y\) given its past observations. However, \(Y\) is mixed with a latent (unobservable) variable, and they follow linear dynamics with both decay and periodicity (i.e., complex dynamics eigenvalues). In addition, we observe a control signal that affects the latent variable (hence affects \(Y\), but only indirectly through the dynamics). The control negatively correlated with the observations: \(u_{t}=b_{t}-0.5Y_{t}\), \(b_{t} U[0,0.5]\) is a piecewise constant additive noise (changing 10 times per trajectory).

As baselines for comparison, we choose recent SDE-based methods that provide Bayesian uncertainty estimation: **GRU-ODE**-Bayes (De Brouwer et al., 2019) and **CRU**(Schirmer et al., 2022) (despite terminology, both implement an SDE rather than ODE). In these methods, concatenating the control signal to the observation results in poor learning, as the control becomes part of the model output and dominates the loss function. To enable effective learning for the baselines, we mask-out the control from the loss. Additionally, we design a dedicated **LSTM** model that supports irregular predictions, as described in Appendix F.2.

**Out-of-distribution control (OOD):** We simulate two benchmarks - one with _complex_ eigenvalues and another with _real_ eigenvalues (no periodicity). We train all models on a dataset of 1000 random trajectories, and test on a separate dataset - with different trajectories that follow the _same distribution_. In addition, we use an _OOD_ test dataset, where the control is positively correlated with the observations: \(u_{t}=b_{t}+0.5 Y_{t}\). This can simulate, for example, forecasting of the same biochemical process after changing the medicine dosage policy.

Table 2 and Fig. 4(a) summarize the prediction errors. Before changing the control policy, NESDE achieves the best accuracy in the complex dynamics, and is on par with GRU-ODE-Bayes in the real dynamics. Notice that CRU, which relies on a real-valued linear model in latent space, is indeed sub-optimal under the complex dynamics, compared to NESDE and GRU-ODE-Bayes. The LSTM presents high errors in both benchmarks.

    &  &  \\   & **MSE** & **OOD MSE** & **MSE** & **OOD MSE** \\ 
**LSTM** & \(0.23 0.001\) & \(0.589 0.02\) & \(0.381 0.002\) & \(2.354 0.84\) \\
**GRU-ODE-Bayes** & \(0.182 0.0004\) & \(0.361 0.044\) & \(\) & \(0.355 0.005\) \\
**CRU** & \(0.233 0.0054\) & \(0.584 0.009\) & \(0.231 0.001\) & \(0.541 0.026\) \\
**NESDE (ours)** & \(\) & \(\) & \(0.222 0.0005\) & \(\) \\   

Table 2: Test errors in the irregular synthetic benchmarks, estimated over 5 seeds and 1000 test trajectories per seed, with standard deviation calculated across seeds.

Figure 5: MSE vs. number of observations so far in the trajectory, in the complex dynamics setting, for: (a) standard test set, and (b) test set with out-of-distribution control policy. 95% confidence intervals are calculated over 5 seeds.

Once the control changes, all models naturally deteriorate. Yet, NESDE presents the smallest deterioration and best accuracy in the OOD test datasets - for both complex and real dynamics. In particular, NESDE provides a high prediction accuracy after mere 2 observations (Fig. 4(b)), making it a useful zero-shot model. The robustness to the modified control policy can be attributed to the model of NESDE in Eq. (6), which decouples the control from the observations.

In a similar setting in Appendix E.6, the control \(u\) used in the training data has continuous knowledge of \(Y\). Since the model only observes \(Y\) in a limited frequency, \(u\) carries additional information about \(Y\). This results in extreme overfitting and poor generalization to different control policies - for all methods except for NESDE, which maintains robust OOD predictions in this challenging setting.

**Sample efficiency:** We train each method over datasets with different number of trajectories. Each model is trained on each dataset separately until convergence. As shown in Fig. 6, NESDE achieves the best test accuracy for every training dataset, and learns reliably even from as few as 100 trajectories. The other methods deteriorate significantly in the smaller datasets. Note that in the real dynamics, LSTM fails regardless of the amount of data, as also reflected in Table 2.

GRU-ODE-Bayes achieves the best sample efficiency among the baselines. In Appendix E.2, we use **a benchmark from the study of GRU-ODE-Bayes itself**(De Brouwer et al., 2019), and demonstrate the superior sample efficiency of NESDE in that benchmark as well. Appendix E.3 extends the notion of sample efficiency to sparse trajectories: for a constant number of training trajectories, it reduces the number of observations per trajectory. NESDE demonstrates high robustness to the amount of data in that setting as well.

**Regular LSTM:** Appendix E.4 extends the experiments for regular data with constant time-steps. In the regular setting, LSTM provides competitive accuracy when observations are dense. However, if the signal is not observed every time-step, LSTM deteriorates significantly in unobserved time-steps (Fig. 11(c)), possibly because gradients have to be propagated over many steps. Hence, even in regular settings, LSTM struggles to provide predictions more frequent than the measurements.

## 6 Medication Dosing Regimes

As discussed in Section 1, many medical applications could potentially benefit from ODE-based methods. Specifically, we address medication dosing problems, where observations are often sparse, the dosing is a control signal, and uncertainty estimation is crucial. We test **NESDE** on two such domains, against the same baselines as in Section 5 (**GRU-ODE-Bayes**, **CRU** and an irregular **LSTM**). We also add a **naive** model with "no-dynamics" (predicts the last observed value).

The benchmarks in this section were derived from the MIMIC-IV dataset (Johnson et al., 2020). Typically to electronic health records, the dataset contains a vast amount of side-information (e.g., weight and heart rate). We use some of this information as an additional input - for each model according to its structure (context-features for the hyper-network of NESDE, covariates for GRU-ODE-Bayes, state variables for CRU, and embedding units for the LSTM). Some context features correspond to online measurements and are occasionally updated. In both domains, we constraint the process eigenvalues \(\) to be negative, to reflect the stability of the biophysical processes. Indeed, the spectral representation of NESDE provides us with a natural way to incorporate such domain knowledge, which often cannot be used otherwise. For all models, in both domains, we use a 60-10-30 train-validation-test data partition. See more implementation details in Appendix F.

### Unfractionated Heparin Dosing

Unfractionated Heparin (UH) is a widely used anticoagulant drug. It may be given in a continuous infusion to patients with life-threatening clots and works by interfering with the normal coagulation cascade. As the effect is not easily predicted, the drug's actual activity on coagulation is traditionally

Figure 6: Test MSE vs. train data size. 95% confidence intervals are calculated over 1000 test trajectories.

monitored using a lab test performed on a blood sample from the patient: activated Partial Thromplastin Time (aPTT) test. The clinical objective is to keep the aPTT value in a certain range. The problem poses several challenges: different patients are affected differently; the aPTT test results are delayed; monitoring and control are required in higher frequency than measurements; and deviations of the aPTT from the objective range may be fatal. In particular, underdosed UH may cause clot formation and overdosed UH may cause an internal bleeding [Landefeld et al., 1987]. Dosage rates are manually decided by a physician, using simple protocols and trial-and-error over significant amounts of time. Here we focus on continuous prediction as a key component for aPTT control.

Following the preprocessing described in Appendix F.1, the MIMIC-IV dataset derives \(5866\) trajectories of a continuous UH control signal, an irregularly-observed aPTT signal (whose prediction is the goal), and \(42\) context features. It is known that UH does not affect the coagulation time (aPTT) directly (but only through other unobserved processes, Delavenne et al. ); thus, we mask the control mapping \(B\) to have no direct effect on the aPTT metric, but only on the latent variable (which can be interpreted as the body UH level). The control (UH) and observations (aPTT) are one-dimensional (\(m=1\)), and we set the whole state dimension to \(n=4\).

### Vancomycin Dosing

Vancomycin (VM) is an antibiotic that has been in use for several decades. However, the methodology of dosing VM remains a subject of debate in the medical community [Rybak et al., 2009], and there is a significant degree of variability in VM dynamics among patients [Marsot et al., 2012]. The dosage of VM is critical; it could become toxic if overdosed [Filippone et al., 2017], and ineffective as an antibiotic if underdosed. The concentration of VM in the blood can be measured through lab test, but these tests are often infrequent and irregular, which fits into our problem setting.

Here, the goal is to predict the VM concentration in the blood at any given time, where the dosage and other patient measurements are known. Following the preprocessing described in Appendix F.1, the dataset derives \(3564\) trajectories of VM dosages at discrete times, blood concentration of VM (\(m=1\)) at irregular times, and similarly to Section 6.1, \(42\) context features. This problem is less noisy than the UH dosing problem, as the task is to learn the direct dynamics of the VM concentration, and not the effects of the antibiotics. The whole state dimension is set to \(n=2\), and we also mask the control mapping \(B\) to have no direct effect on the VM concentration, where the latent variable that directly affected could be viewed as the amount of drug within the _whole body_, which in turn affects the actual VM concentration in the _blood_.

### Results

Fig. 7 displays sample trajectories predicted by NESDE in both domains. As summarized in Table 3, NESDE outperforms the other baselines in both UH and VM dosing tasks, in terms of both square errors (MSE) and likelihood (NLL). For the UH dosing problem, Fig. 8 also presents the errors

   &  &  \\   & **MSE** & **NLL** & **MSE** & **NLL** \\ 
**Naive** & \(613.3 13.48\) & \(-\) & \(112.2 16.4\) & \(-\) \\
**LSTM** & \(482.1 6.52\) & \(-\) & \(92.89 11.3\) & \(-\) \\
**GRU-ODE-Bayes** & \(491 6.88\) & \(4.52 0.008\) & \(80.54 11.8\) & \(6.38 0.12\) \\
**CRU** & \(450.4 8.27\) & \(4.49 0.012\) & \(76.4 12.8\) & \(3.87 0.2\) \\
**NESDE (ours)** & \(\) & \(\) & \(\) & \(\) \\  

Table 3: Test mean square errors (MSE) and negative log-likelihood (NLL, for models that provide probabilistic prediction) in the medication-dosing benchmarks.

Figure 7: A sample of patients from (a) the UH dosing dataset, and (b) the VM dosing dataset. The lower plots correspond to medication dosage (UH in (a) and VM in (b)). The upper plots correspond to the continuous prediction of NESDE (aPTT levels in (a) and VM concentration in (b)), with 95% confidence intervals. In both settings, the prediction at every point relies on all the observations up to that point.

vs. prediction horizon (the time passed since the last observation). Evidently, **NESDE provides the best accuracy in all the horizons**. Its smoothness allows NESDE to obtain high accuracy in short horizons, and its robustness allows **generalization to out-of-distribution horizons**: while most of the data corresponds to horizons of 5-7 hours (see Fig. 14 in the appendix), NESDE provides reliable prediction at other horizons as well. By contrast, LSTM and GRU-ODE-Bayes have difficulty with short horizons; they only become competitive with the _naive_ model after 6 hours. CRU provides more robust predictions, but is still outperformed by NESDE.

Despite the large range of aPTT levels in the data (e.g., the top 5% are above \(100s\) and the bottom 5% are below \(25s\)), 50% of all the predictions have errors lower than \(12.4s\) - an accuracy level that is considered clinically safe. Fig. 8 shows that indeed, up to 3 hours after the last lab test, the average error is smaller than \(10s\).

**Running time**: All Heparin and Vancomycin experiments were run on a single Ubuntu machine with eight i9-10900X CPU cores and Nvidia's RTX A5000 GPU. A single training process of NESDE required 8-24 hours (with variance mostly attributed to early stopping criterion). LSTM required similar running times (6-24 hours), whereas GRU-ODE-Bayes and CRU required 36-72 hours to train.

## 7 Conclusion

Motivated by medical forecasting and control problems, we characterized a set of challenges in modeling continuous dosing dynamics: sample efficiency, uncertainty estimation, personalized modeling, continuous inference and generalization to different control policies. To address these challenges, we introduced the novel NESDE algorithm, based on a stochastic differential equation with spectral representation. We demonstrated the reliability of NESDE in a variety of synthetic and real data experiments, including high noise, little training data, contextual side-information and out-of-distribution control signals. In addition, NESDE demonstrated high prediction accuracy after as few as 2 observations, making it a useful zero-shot model.

We applied NESDE to two real-life high-noise medical problems with sparse and irregular measurements: (1) blood coagulation forecasting in Heparin-treated patients, and (2) Vancomycin levels prediction in patients treated by antibiotics. In both problems, NESDE significantly improved the prediction accuracy compared to alternative methods. This demonstrates NESDE's advantage in continuous forecasting of controlled SDE systems, which include medication dosing and controlled chemical and biological processes.

As demonstrated in the experiments, NESDE provides robust, reliable and uncertainty-aware continuous _forecasting_. This paves the way to development of _decision making_ in continuous high-noise decision processes, including medical treatment, finance and operations management. Future research may address medical optimization via both control policies (e.g., to control medication dosing) and sampling policies (to control measurements timing, e.g., of blood tests).

**Acknowledgements:** This research was supported by VATAT Fund to the Technion Artificial Intelligence Hub (Tech.AI).

Figure 8: aPTT prediction errors in the UH problem, vs. the time passed since the last aPTT test.