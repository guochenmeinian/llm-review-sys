# GenPose: Generative Category-level Object Pose Estimation via Diffusion Models

Jiyao Zhang\({}^{1,2,3}\), Mingdong Wu\({}^{1,3}\), Hao Dong\({}^{1,3}\)

\({}^{1}\) Center on Frontiers of Computing Studies, School of Computer Science, Peking University

\({}^{2}\) Beijing Academy of Artificial Intelligence

\({}^{3}\) National Key Laboratory for Multimedia Information Processing,

School of Computer Science, Peking University

jiyaozhang@stu.pku.edu.cn, {wmingd, hao.dong}@pku.edu.cn

###### Abstract

Object pose estimation plays a vital role in embodied AI and computer vision, enabling intelligent agents to comprehend and interact with their surroundings. Despite the practicality of category-level pose estimation, current approaches encounter challenges with partially observed point clouds, known as the _multi-hypothesis issue_. In this study, we propose a novel solution by reframing category-level object pose estimation as conditional generative modeling, departing from traditional point-to-point regression. Leveraging score-based diffusion models, we estimate object poses by sampling candidates from the diffusion model and aggregating them through a two-step process: filtering out outliers via likelihood estimation and subsequently mean-pooling the remaining candidates. To avoid the costly integration process when estimating the likelihood, we introduce an alternative method that trains an energy-based model from the original score-based model, enabling end-to-end likelihood estimation. Our approach achieves state-of-the-art performance on the REAL275 dataset and demonstrates promising generalizability to novel categories sharing similar symmetric properties without fine-tuning. Furthermore, it can readily adapt to object pose tracking tasks, yielding comparable results to the current state-of-the-art baselines. Our checkpoints and demonstrations can be found at https://sites.google.com/view/genpose.

## 1 Introduction

Object pose estimation is a fundamental problem in the domains of robotics and machine vision, providing a high-level representation of the surrounding world. It plays a crucial role in enabling intelligent agents to understand and interact with their environments, supporting tasks such as robotic manipulation, augmented reality, and virtual reality [1; 2; 3]. In the existing literature, category-level object pose estimation [4; 5; 6] has emerged as a more practical approach compared to instance-level pose estimation since the former eliminates the need for a 3D CAD model for each individual instance. The main challenge of this task is to capture the general properties while accommodating the intra-class variations, _i.e._, variations among different instances within a category [7; 5; 8].

Figure 1: _Multi-hypothesis issue_ in category-level object pose estimation comes from (a) symmetric objects and (b) partial observation.

To address this task, previous studies have explored regression-based approaches. These approaches involve either recovering the object pose by predicting correspondences between the observed point cloud and synthesized canonical coordinates [4; 7], or estimating the pose in an end-to-end manner [9; 6]. The former approaches leverage category prior information, such as the mean point cloud, to handle intra-class variations. As a result, they have demonstrated strong performance across various metrics. On the other hand, the latter approaches do not rely on the coordinate mapping process, which inherently makes them faster and amenable to end-to-end training.

Despite the promising results of previous approaches, a fundamental issue inherent to regression-based training persists. This issue, known as the _multi-hypothesis problem_, arises when dealing with a partially observed point cloud. In such cases:

_Multiple feasible pose hypotheses can exist, but the network can only be supervised for a single pose due to the regression-based training._

Figure 1(a) illustrates this problem by showcasing the feasible ground truth poses of symmetric objects (_e.g._, bowls). Moreover, partially observed point clouds of an object may appear similar from certain views (_e.g._, a mug with an obstructed handle may look the same from certain views, as shown in Figure 1(b)), further exacerbating the multiple hypothesis issue. Previous studies have proposed ad-hoc solutions to tackle this issue, such as designing special network architectures [10; 11] or augmenting the ground truth poses [4; 5] for symmetric objects. However, these approaches cannot fundamentally resolve this issue due to the lack of generality. Consequently, an ideal object pose estimator should model a pose distribution instead of regressing a single pose when presented with a partially observed point cloud.

To this end, we formulate category-level object pose estimation as conditional generative modeling that inherently models the distribution of multiple pose hypotheses conditioned on a partially observed point cloud. To model the conditional pose distribution, we employ score-based diffusion models, which have demonstrated promising results in various conditional generation tasks . Specifically, we estimate the score functions, _i.e._, the gradients of the log density, of the conditional pose distribution perturbed by different noise levels. These trained gradient fields can provide guidance to iteratively refine a pose, making it more compatible with the observed point cloud. In the testing phase, we estimate the object pose of a partial point cloud by sampling from the conditional pose distribution using an MCMC process incorporated with the learned gradient fields. As a result, our method can propose multiple pose hypotheses for a partial point cloud, thanks to stochastic sampling.

However, it is essential to note that a sampled pose might be an outlier of the conditional pose distribution, meaning it has a low likelihood, which can severely hurt the performance. To address this issue, we sample a group of pose candidates and then filter out the outliers based on the estimated likelihoods. Unfortunately, estimating the likelihoods from score-based models requires a highly time-consuming integration process , rendering this approach impractical. To overcome this challenge, we propose an alternative solution that trains an energy-based model from the original score-based model for likelihood estimation. Following training, the energy network is guaranteed to estimate the log-likelihood of the original data distribution up to a constant. By ranking the candidates according to the energy network's output, we can filter out candidates with low ranks (_e.g._, the last 40%). Finally, the output pose is aggregated by mean-pooling the remaining pose candidates.

Our experiments demonstrate several superiorities over the existing methods. Firstly, without any ad-hoc network or loss design for symmetry objects, our method achieves state-of-the-art performance and surpasses 50% and 60% on the strict \(5^{}2\)cm and \(5^{}5\)cm metrics, respectively, on the REAL275 dataset. Besides, our method can directly generalize to novel categories without any fine-tuning to some degree due to its prior-free nature. Our methods can be easily adapted to the object pose tracking task with few modifications and achieve comparable performance with the SOTA baselines.

Our contributions are summarized as follows:

* We study a fundamental problem, namely _multi-hypothesis issue_, that has existed in category-level object pose estimation for a long time and introduce a generative approach to address this issue.
* We propose a novel framework that leverages the energy-based diffusion model to aggregate the candidates generated by the score-based diffusion model for object pose estimation.
* Our framework achieves exceptionally state-of-the-art performance on existing benchmarks, especially on symmetric objects. In addition, our framework is capable of object pose tracking and can generalize to objects from novel categories sharing similar symmetric properties.

Related Works

### Category Level Object Pose Estimation

Category-level object pose estimation [4; 14; 5; 15] aims to predict pose of various instances within the same object category without requiring CAD models. To this end, NOCS  introduce normalized object coordinate space for each object category and predicts the corresponding object shape in canonical space. Object pose is then calculated by pose fitting using the Umeyama  algorithm. CASS , DualPoseNet , and SSP-Pose  end-to-end regress the pose and simultaneously reconstruct the object shape in canonical space to improve the precision of pose regression. SARNet  and GPV-Pose  specifically design symmetric-aware reconstruction to enhance the performance of predicting the translation and size of symmetrical objects while regressing the object pose. However, direct regression of pose or object coordinates in canonical space fail when there is considerable intra-class variation. To overcome this, FS-Net  introduces an online box-cage-based 3D deformation augmentation method, and RBP-Pose  proposes a nonlinear data augmentation method. On the other hand, SPD , SGPA , CR-Net , and DPDN  introduce category-level object priors (_e.g_., mean shape) and learn how to deform the prior to get the object coordinates in canonical space. These methods have demonstrated strong performance. Overall, the existing category-level object pose estimation methods are regression-based. However, considering symmetric objects (_e.g_., bowls, bottles, and cans) and partially observed objects (_e.g_., mugs without visible handles), there are multiple plausible hypotheses for object pose. Therefore, the problem of object pose estimation should be formulated as a generation problem rather than a regression problem.

### Score-based Generative Models

In the realm of estimating the gradient of the log-likelihood pertaining to specified data distribution, a pioneering approach known as the score-based generative model [21; 22; 23; 24; 25; 13; 26] was originally introduced by . In an effort to provide a feasible substitute objective for score-matching, the denoising score-matching (DSM) technique has further put forward a viable proposition. To enhance the scalability of the score-based generative model,  has introduced a sliced score-matching objective, which involves projecting the scores onto random vectors prior to their comparison. They have also presented annealed training for denoising score matching and have introduced improved training techniques to complement these methods . Additionally, they have extended the discrete levels of annealed score matching to a continuous diffusion process, thereby demonstrating promising results in the domain of image generation . Recent studies have delved further into exploring the design choices of the diffusion process , maximum likelihood training , and deployment on the Riemann manifold . These advancements have showcased encouraging outcomes when applying score-based generative models to high-dimensional domains, thus fostering their broad utilization across various fields, such as object rearrangement , medical imaging , point cloud generation , scene graph generation , point cloud denoising , depth completion , and human pose estimation . These studies have formulated perception-related problems as either conditional generative modeling or in-painting tasks, thereby harnessing the power of score-based generative models to tackle these challenges. In contrast to these approaches, we incorporate the score-based diffusion model with an additional energy-based diffusion model [36; 37] for filtering out the outliers so as to improve the performance by aggregating the remaining candidates.

## 3 Method

**Task Description:** In this work, we aim to estimate 6D object pose from the partially observed point cloud. The learning agent is given a training set with paired object poses and point clouds \(=\{(_{i},O_{i})\}_{i=1}^{n}\), where \(_{i}(3)\) and \(O_{i}^{3 N}\) denote a 6D pose and a partially observed 3D point cloud with \(N\) points respectively. Given an unseen point cloud \(O^{*}\), the goal is to recover the corresponding ground-truth pose \(^{*}\).

**Overview:** We formulate the object pose estimation as a conditional generative modeling problem and train a score-based diffusion model \(_{}\) using the dataset \(\). Further, an energy-based diffusion model \(_{}\) is trained from the score-based model \(_{}\) for likelihood estimation. During test time, given an unseen point cloud \(O^{*}\), we first sample a group of pose candidates \(\{}_{1},}_{2},...}_{K}\}\) via the score-based diffusion model \(_{}\). Then we sort the candidates \(\{}_{i}\}_{i=1}^{K}\) in descending order according to the energy outputs and filter out the last \(1-\)% candidates (_e.g._, \(=60\%\)). Finally, we aggregate the remaining candidates by mean-pooling to obtain the estimated pose \(}\).

### Sampling Pose Candidates via Score-based Diffusion Model

To address the multi-hypothesis issue, an ideal pose estimator should be capable of being trained on multiple feasible ground truth poses given the same point cloud. Also, the ideal pose estimator should be able to output all possible pose hypotheses of the given point cloud during inference.

To this end, we propose to tackle object pose estimation in a conditional generative modeling paradigm. We assume dataset \(\) is sampled from an implicit joint distribution \(=\{(_{i},O_{i}) p_{}(,O)\}\). We aim to model the conditional pose distribution \(p_{}(|O)\) during training, and sample pose hypotheses of an unseen point cloud \(O^{*}\) from \(p_{}(|O^{*})\) during test-time.

Specifically, we employ a score-based diffusion model [24; 23; 13] to estimate the conditional distribution \(p_{}(|O)\). We adopt Variance-Exploding (VE) Stochastic Differential Equation (SDE) proposed by  to construct a continuous diffusion process \(\{(t)\}_{t=0}^{1}\) indexed by a time variable \(t\) where \((0) p_{}(|O)\) denotes the ground truth pose of the point cloud \(O\). As the \(t\) increases from 0 to 1, the time-indexed pose variable \((t)\) is perturbed by the following SDE:

\[d=(t)]}{dt}}d,\;(t)=_{ }(}}{_{}})^{t}\] (1)

where \(_{}=0.01\) and \(_{}=50\) are hyper-parameters.

During training, we aim to estimate the _score function_ of the perturbed conditional pose distribution \(_{} p_{t}(|O)\) of all \(t\), where the \(p_{t}(|O)\) denotes the marginal distribution of \((t)\):

\[p_{t}((t)|O)=((t);(0),^{2}(t) ) p_{0}((0)|O)\;d(0)\] (2)

Notably, when \(t=0\), \(p_{0}((0)|O)=p_{}((0)|O)\) is exactly the data distribution.

Thanks to the Denoising Score Matching (DSM) , we can obtain a guaranteed estimation of \(_{}p_{t}(|O)\) by training a score network \(_{}:^{||}^{1}^{3 N}^{||}\) via the following objective:

\[()=_{t(,1)}\{ (t)_{(0) p_{}( (0)|O),\\ (t)((t)|(0),^{2}(t))}[ \|_{}((t),t|O)-(0)-(t)}{(t )^{2}}\|_{2}^{2}]\}\] (3)

where \(\) is a hyper-parameter that denotes the minimal noise level. When minimizes the objective in Eq. 3, the optimal score network satisfies \(_{}(,t|O)=_{} p_{t}(|O)\) according to .

Figure 2: Overview. **(I)** A score-based diffusion model \(_{}\) and an energy-based diffusion model \(_{}\) is trained via denoising score-matching. **(II)** a) We first generate pose candidates \(\{}_{i}\}_{i=1}^{K}\) from the score-based model and then b) compute the pose energies \(_{}(}_{i},|O^{*})\) for candidates via the energy-based model. c) Finally, we rank the candidates with the energies and then filter out low-ranking candidates. The remaining candidates are aggregated into the final output by mean-pooling.

After training, we can approximately sample pose candidates \(\{}_{i}\}_{i=1}^{K}\) from \(p_{}(|O)\) by sampling from \(p_{}(|O)\), as \(_{ 0}p_{}(|O)=p_{}(|O)\). To sample from \(p_{}(|O)\), we can solve the following _Probability Flow_ (PF) ODE  where \((1)(,_{}^{2})\), from \(t=1\) to \(t=\):

\[}{dt}=-(t)(t)_{} p_{t}(|O)\] (4)

where the score function \( p_{t}(|O)\) is empirically approximated by the estimated score network \(_{}(,t|O)\) and the ODE trajectory is solved by RK45 ODE solver .

In practice, the score network \(_{}(,t|O)\) is implemented without any ad-hoc design for the symmetric objects: The point cloud \(O\) is encoded into a global feature by PointNet++ , the input pose \(\) is encoded by feed-forward MLPs and the time variable \(t\) is encoded by a commonly used projection layer following . The pose \(\) is represented as a 9-D variable \([R|T]\), where \(R^{6}\) and \(T^{3}\) denote rotation and translation vectors, respectively. Due to the discontinuity of quaternions and Euler angles in Euclidean space, we employ the continuous 6-D rotation representation \([R_{x}|R_{y}]\) following[6; 40]. We defer full details into Appendix A.

### Aggregating Pose Candidates via Energy-based Diffusion Model

Though we can sample pose candidates \(\{}_{i}\}_{i=1}^{K}\) from the conditional pose distribution \(p_{}(|O)\) via the learned score model \(_{}\), we still need to determine a final output estimation \(}(3)\). In other words, the pose candidates need to be aggregated into a single estimation.

An initial approach to aggregating candidates is mean pooling. However, when sampling candidates from \(p_{}(|O)\), there is no guarantee that the sampled candidates will have a high likelihood. This means that outlier poses in low-density regions are still likely to be included in the mean-pooled pose, which can negatively impact its performance. Therefore, we propose estimating the data likelihoods \(\{p_{}(}_{i}|O)\}_{i=1}^{K}\) to rank the candidates and then filter out low-ranking candidates.

Unfortunately, estimating likelihood via the score model itself requires a time-consuming integration process , which is impractical for real-time applications:

\[ p_{}(|O) p_{}(|O)= p_{1}( (1)|O)-_{}^{1}(t)]}{dt}_{}((t),t|O)dt\] (5)

where \(\{(t)\}_{t}\) is the same forward diffusion process as in Eq. 1.

To this end, we propose to train an energy-based model \(_{}:^{||}^{1}^{3 N}^{1}\) that enables an end-to-end surrogate estimation of the data likelihood by supervising the energy-induced gradient \(_{}_{}(,t|O)\) with the denoising score-matching objective in Eq. 3:

\[()=_{t(,1)}\{(t) _{(0) p_{0}(|O),\\ (1) p_{0}((t)||O),}[\|_{ (t)}_{}((t),t|O)-(0)-(t)}{(t )^{2}}\|_{2}^{2}]\}\] (6)

In this way, the optimal energy model holds \(_{}_{}^{*}(,t|O)=_{} p_{t}( {p}|O)\), or equivalently, \(_{}^{*}(,t|O)= p_{t}(|O)+C\) where \(C\) is a constant. Although the optimal energy model and the ground truth likelihood differ by a constant \(C\), this does not prevent it from functioning as a good surrogate likelihood estimator for ranking the candidates:

\[_{}^{*}(_{i},|O)>_{}^{*}(_{j}, |O) p_{}(_{i}|O)> p_{}(_{j}|O)\] (7)

Nevertheless, training an energy-based diffusion model from Eq. 6 is known to be difficult and time-inefficient due to the need to calculate the second-order derivations in the objective function. Following , we parameterize the energy-based model as \(_{}(,t|O)=,_{}(,t|O)\) to alleviate the training burden. We defer the full training details to Appendix A.

With the trained energy model, we sort the candidates into a sequence \(}_{_{1}}}_{_{2}}...}_{_ {K}}\) where:

\[}_{_{i}}}_{_{j}}_{}(}_{_{i}},|O)>_{}(}_{_{j}}, |O)\] (8)

Subsequently, we filter out the last \(1-\)% candidates and obtain \(}_{_{1}}}_{_{2}}...}_{_ {M}}\) where \((0,1)\) is a hyper parameter and \(M= K\).

Finally, we aggregate the remaining candidates \(\{}_{_{i}}=(_{_{i}},_{_{i}})\}_{i=1}^{M}\) by averaging the rotations \(\{_{_{i}}\}_{i=1}^{M}\) and the translations \(\{_{_{i}}\}_{i=1}^{M}\) respectively, to obtain the output pose \(}}=(,)\). In specific, the translations are pooled by vanilla averaging \(=^{M}_{_{i}}}{M}\). To obtain the averaged rotation, we initially translate the rotations into quaternions \(\{}_{_{i}}\}_{i=1}^{M}\). Following , the average quaternion can then be found by the following maximization procedure:

\[}=*{arg\,max}_{ SO(3)}^{T}(^{M}A(}_{_{i}})}{M}),\ A(}_{ _{i}})=}_{_{i}}}_{_{i}}^{T}\] (9)

By definition, the solution of Eq. 9 is the eigenvector of the \(4 4\) matrix \(^{M}A(_{_{i}})}{M}\) corresponding to the maximum eigenvalue, which can be efficiently solved by QUEST algorithm .

### Discussion

Despite addressing the multi-hypothesis issue, our method offers several additional advantages:

**No Ad-hoc Design:** Unlike previous approaches, we do not incorporate any ad-hoc designs or tricks into the network architecture for symmetric objects. Both the score and energy models are implemented using commonly used feature extractors (_e.g._, PointNet++) and feed-forward MLPs. Surprisingly, our method performs exceptionally well in handling symmetric objects (refer to Sec 4.4) and achieves state-of-the-art (SOTA) performance on existing benchmarks (refer to Sec 4.2).

**Prior-Free:** Our method eliminates the requirement of category-level canonical prior, freeing us from designing a shape-deformation module to incorporate the canonical prior. This also provides the potential to generalize our method to objects from unseen categories sharing similar symmetric properties. In Sec 4.4, we present experiments to demonstrate this potential.

**Capable of Pose Tracking:** Thanks to the closed-loop generation process of the diffusion models, we can adapt the single-frame pose estimation framework to pose tracking tasks by warm-starting from the previous predictions. The adapted object pose tracking framework differs from the single-frame estimation framework only in the candidates' sampling. For each frame that receives the point cloud observation \(O_{}\), we initialize the PF-ODE in Eq.4 with \((0.1)(}_{},^{2}(0.1))\), where \(}_{}(3)\) denotes the estimated pose of the previous frame. Subsequently, we solve this modified PF-ODE from \(t=0.1\) to \(t=\) using the gradient fields \(_{}(,t|O_{})\) to sample candidates for pose tracking. By following the same aggregation procedure, we can obtain the pose estimation \(}_{}\) for the current frame. We summarise the tracking framework in Appendix D. In Sec.4.5, our adapted pose-tracking method outperforms the state-of-the-art object pose-tracking baseline in most metrics.

## 4 Experiments

### Experimental Setup

**Datasets.** Our method is trained and evaluated on two common category-level object pose estimation datasets, namely CAMERA and REAL275 , following the NOCS  convention for splitting the data into training and testing sets. These datasets include 6 daily objects: bottle, bowl, camera, can, laptop, and mug. CAMERA dataset is a synthetic dataset generated using mixed-reality methods. It comprises real background images with synthetic rendered foreground objects and consists of 275K training images and 25K test images. REAL275 dataset is a real-world dataset that employs the same 6 object categories as the CAMERA dataset. It includes 3 unique instances per category in both the training and test sets and consists of 7 scenes for training with 4.3K images and 6 scenes for testing with 2.75K images. Each scene in the REAL275 dataset contains more than 5 objects.

**Metrics.** Following NOCS , we report the mean Average Precision (mAP) in \(n^{}\) and \(m\) cm to evaluate the accuracy of object pose estimation. Here, \(n\) and \(m\) denote the prediction error of rotation and translation, respectively, where the predicted rotation error is less than \(n^{}\) and the predicted translation error is less than \(m\) cm. Specifically, we use \(5^{}2cm\), \(5^{}5cm\), \(10^{}2cm\), and \(10^{}5cm\) as our evaluation metrics. Similar to NOCS, for symmetric objects (bottles, bowls, and cans), we ignore the rotation error around the symmetry axis. For the "mug" category, we consider it a symmetric object when the handle is not visible and a non-symmetric object when the handle is visible.

**Implementation Details.** For a fair comparison, we employed the instance mask generated by MaskRCNN  during the inference phase, which was identical to the one used in previous work. Both the Energy-based diffusion model for pose ranking and the score-based diffusion model for pose generation shared the same network structure. The input pointcloud consisted of 1024 points. During the training phase, we used the same data augmentation techniques as FS-Net , which are widely adopted in category-level object pose estimation tasks. All experiments were conducted on a single RTX3090 with a batch size of 192. All the experiments are implemented using PyTorch .

### Comparison with State-of-the-Art Methods

Table 1 provides a comprehensive comparison between our method and the state-of-the-art approaches on the REAL275  dataset, highlighting a significant advancement in performance. In Table 1, "Ours" represents the aggregated pose using \(K\) as 50 and \(\) as 60%. "Ours(\(K\)=10)" and "Ours(\(K\)=50)" indicate that we set \(K\) as 10 and 50, respectively, and select a pose from candidates with the minimum distance to ground truth pose for evaluation. We deal with all categories by a single model.

As shown in Table 1, our approach demonstrates a remarkable improvement over the current SOTA method, GPV-Pose, exceeding it by more than 20% in both the rigorous \(5^{}2cm\) and \(5^{}5cm\) evaluation metrics. Significantly, for the first time, we achieve results on the REAL275 dataset, surpassing the impressive thresholds of 50% and 60% in the \(5^{}2cm\) and \(5^{}5cm\) metrics, respectively. These exceptional outcomes further support the efficacy of our approach.

Even when compared to methods that take RGB-D data and category prior as input, our method maintains a notable advantage. Without relying on any additional information, our method achieves a performance boost of over 10% in the metric of \(5^{}5cm\), surpassing the SOTA method, DPDN .

In addition, the results that evaluate the pose nearest to the ground truth indicate that condition generative models exhibit tremendous potential for category-level object pose estimation. Another crucial metric is the number of learnable parameters of the network, which significantly impacts the feasibility of model deployment. Table 1 reveals that our method achieves a remarkable accuracy for predicting poses with the fewest network parameters, further improving its deployability.

   &  & Prior & \(5^{}2\)cm\(\) & \(5^{}5\)cm\(\) & \(10^{}2\)cm\(\) & \(10^{}5\)cm\(\) & Parameters(M)\(\) \\   & NOCS  & RGB-D & \(\) & - & 9.5 & 13.8 & 26.7 & - \\  & CASS  & RGB-D & \(\) & 19.5 & 23.5 & 50.8 & 58.0 & 47.2 \\  & DualPoseNet  & RGB-D & \(\) & 29.3 & 35.9 & 50.0 & 66.8 & 67.9 \\  & SPD  & RGB-D & \(\) & 19.3 & 21.4 & 43.2 & 54.1 & 18.3 \\  & CR-Net  & RGB-D & \(\) & 27.8 & 34.3 & 47.2 & 60.8 & - \\  & SGPA  & RGB-D & \(\) & 35.9 & 39.6 & 61.3 & 70.7 & - \\  & DPDN  & RGB-D & \(\) & 46.0 & 50.7 & 70.4 & 78.4 & - \\   & FS-Net  & D & \(\) & 19.9 & 33.9 & - & 69.1 & 41.2 \\  & GPV-Pose  & D & \(\) & 32.0 & 42.9 & 55.0 & 73.3 & - \\  & SAR-Net  & D & \(\) & 31.6 & 42.3 & 50.4 & 68.3 & 6.3 \\  & SSP-Pose  & D & \(\) & 34.7 & 44.6 & - & 77.8 & - \\  & RBP-Pose  & D & \(\) & 38.2 & 48.1 & 63.1 & 79.2 & - \\    & Ours & D & \(\) & **52.1** & **60.9** & **72.4** & **84.0** & **4.4** \\  & Ours(\(K\)=10) & D & \(\) & 71.5 & 75.9 & 85.2 & 90.8 & 2.2 \\   & Ours(\(K\)=50) & D & \(\) & 82.0 & 84.5 & 92.8 & 95.9 & 2.2 \\  

Table 1: **Quantitative comparison of category-level object pose estimation on REAL275 dataset.** We summarize the results reported in the original paper for the baseline method. \(\) represents a higher value indicating better performance, while \(\) represents a lower value indicating better performance. **Data** refers to the format of the input data used by the method, and **Prior** indicates whether the method requires category prior information. ‘-’ indicates that the metrics are not reported in the original paper. **K** represents the number of hypotheses.

### Ablation Studies

**Number of Pose Candidates and Proportion of Selected Poses.** Using the \(10^{}2cm\) metric, Table 2 demonstrates the impact of two factors on performance: the number of generated pose candidates \(M\), and the proportion \(\) of selected poses out of the total pose candidates.

The results show a notable improvement when \(M\) increases from 10 to 50. This enhancement can be attributed to the increasing number of sampling times, resulting in a pose candidate set that aligns more closely with the predicted distribution. However, the improvement becomes marginal when \(M\) is further increased from 50 to 100. This can be attributed to the predictions that approach the upper limit of the aggregation approach. After considering the trade-off between performance and overhead, we ultimately decided to adopt \(K=50\). In view of the inherent challenge in training an energy model that precisely aligns with the actual distribution, it becomes apparent that employing a small delta value, as demonstrated in Table 2, does not yield an optimal outcome. Consequently, we regard the energy model primarily as a detector for outliers. The most successful results of this paper were achieved using a delta value of 60%, which effectively mitigated the presence of relatively insignificant noise originating from the sampling process.

**Effectiveness of the Energy-based Likelihood Estimator \(_{}\).** In this part, we report the results of three distinct ranking methodologies, namely "Random", "Energy", and "GT", employed to sort pose candidates \(\{}_{i}\}_{i=1}^{K}\). "Random" applies a stochastic shuffling to \(\{}_{i}\}_{i=1}^{K}\), providing a baseline approach. "Energy" uses our trained energy model to rank \(\{}_{i}\}_{i=1}^{K}\). "GT" ranks \(\{}_{i}\}_{i=1}^{K}\) in ascending order of the distances to the ground truth pose, serving as an upper limit for all ranking methods.

The absence of mean pooling in Table 3 implies that one pose candidate is chosen randomly for evaluation. We observe that utilizing an energy-based likelihood estimator as a sampler enhances the sorting of pose candidates and effectively eliminates outliers. This improvement is significant compared to random sampling. Although doesn't reach the upper bound, we offer a novel and practical approach for ranking and aggregating poses sampled from estimated distribution and demonstrate its potential.

To better understand the energy model's impact, we further investigated the correlation between pose error and energy output. As depicted in Figure 3, there is a general negative correlation between the output and the error of the energy model. However, the energy model excels at distinguishing poses with significant error differences but performs poorly when distinguishing poses with low errors. For instance, the energy model assigns similar values (_e.g._, translation, <2\(cm\)) or even incorrect values (_e.g._, rotation, <10\({}^{}\)) for poses with low errors. Additionally, the energies associated with low-error poses (_e.g._, <10\({}^{}\), <2\(cm\)) are higher than those of high-error poses (_e.g._, >20\({}^{}\), >4\(cm\)).

   Ranking & Mean pooling & \(5^{}2\)cm & \(5^{}5\)cm & \(10^{}2\)cm & \(10^{}5\)cm \\  Random & \(\) & 13.5 & 49.1 & 21.5 & 76.3 \\ Random & ✓ & 49.4 & 58.6 & 68.5 & 80.7 \\ Energy & ✓ & **52.1** & **60.9** & **72.4** & **84.0** \\ GT(upper bound) & ✓ & 62.1 & 66.8 & 80.9 & 86.9 \\   

Table 3: Effectiveness of the energy-based likelihood estimator \(_{}\).

Figure 3: **Energy-Error Correlation Analysis. Points for raw scatters plot, curves for mean error.**

   \(K\)\(\) & 20\% & 40\% & 60\% & 80\% & 100\% \\ 
10 & 65.3 & 67.7 & 67.9 & 67.7 & 65.0 \\
50 & 70.2 & 71.8 & 72.4 & 71.9 & 69.7 \\
100 & **70.8** & **72.2** & **72.6** & **72.5** & **70.2** \\   

Table 2: Ablation on number of pose candidates \(K\) and proportion of selected poses \(\).

### Analysis on Symmetric Objects

**Performance.** Our approach outperforms the state-of-the-art method RBP-Pose , especially for symmetrical objects, as shown in Table 4. Importantly, our method does not rely on specific network structures or loss designs for these categories. Notably, for'mug' category, where asymmetry is present when the handle is visible and symmetry when it is not, our method effectively addresses this challenge and achieves significant performance improvements compared to previous methods. To visually depict the disparity between symmetric and asymmetric objects, Figure 4 visually demonstrates the accuracy of our method in predicting rotation distributions for both symmetric and asymmetric objects.

**Toward Cross-category Object Pose Estimation.** Our method demonstrates a surprisingly cross-category generalizability, as it directly predicts the distribution of object poses, eliminating the reliance on object category prior. Table 5 verifies the remarkable ability of our approach to generalize across categories sharing similar symmetric properties.

Our approach demonstrates consistent and robust performance when tested on unseen categories with similar symmetrical attributes, whereas the baseline performance exhibits a significant decline. We hypothesize that the specific out-of-distribution (OOD) generalization ability of our method arises from the learned feature space of the point cloud. For example, although the bowl category is considered OOD, the extracted features from point clouds in the bowl category may exhibit similarities or closeness to seen categories, to some extent. In other words, a bowl may share visual characteristics with items such as cans, bottles, or mugs, as identified by the PointNet++ of the

    &  & 2\)cm} & 5\)cm} \\   & & RBP-Pose & Ours & RBP-Pose & Ours \\  camera & & 1.3 & **2.9** & 1.5 & **3.2** \\ laptop & \(\) & 41.3 & **63.4** & 75.2 & **91.4** \\ average & & 21.3 & **32.2(11.91)** & 38.4 & **47.3(3.91)** \\  bottle & & 38.7 & **52.6** & 43.5 & **60.9** \\ bowl & & 75.4 & **85.4** & 81.7 & **92.6** \\ can & ✓ & 53.5 & **72.5** & 67.1 & **80.4** \\ average & & 55.9 & **70.2(14.31)** & 64.1 & **78.0(13.91)** \\  mug & - & 18.9 & **35.7(16.81)** & 19.4 & **36.4(17.41)** \\   

Table 4: Per-category results of our method and RBP-Pose.

Figure 4: **The predicted conditional rotation distribution of symmetric and asymmetric objects.** The left figure is an example from the REAL275 dataset, while the right figure shows the distribution of the generated rotations for the symmetrical bottle and the asymmetric laptop. The rotation distribution is visualized by plotting yaw as latitude, pitch as longitude, and roll as the color, following the approach inspired by [45; 46]. The ground truth is represented by the center of the open circle, and the dot shows the result of generating rotations 50 times.

   Category & Method & \(5^{}2\)cm & \(5^{}5\)cm & \(10^{}2\)cm & \(10^{}5\)cm \\   & SAR-Net & 58.1/36.4 & 66.0/47.3 & 83.7/59.4 & 93.6/81.5 \\  & RBP-Pose & 75.4/0.0 & 81.7/6.9 & 92.1/0.1 & 100.0/30.7 \\  & Ours & **85.4/64.5** & **92.6/72.5** & **93.1/87.2** & **100.0/98.6** \\   & SAR-Net & 43.5/11.7 & 54.0/23.0 & 61.3/33.6 & 79.8/68.0 \\  & RBP-Pose & 38.7/4.3 & 43.5/58.7 & **76.4/24.7** & 89.8/29.7 \\   & Ours & **52.6/39.0** & **60.9/53.2** & **81.4/73.6** & **92.9/49.6** \\   & SAR-Net & 32.2/7.3 & 62.2/52.3 & 52.5/12.1 & 92.9/87.9 \\   & RBP-Pose & 53.5/0.8 & 67.1/21.0 & 78.8/2.6 & 96.3/61.7 \\   & Ours & **72.5/62.5** & **80.4/74.0** & **88.8/81.6** & **99.8/99.7** \\   

Table 5: **Cross category evaluation on REAL275.** The left and right sides of ‘/’ respectively indicate the performance when the testing category is seen and unseen in training data.

ScoreNet. To validate this hypothesis, we conducted a t-SNE  analysis on the point cloud feature space of the ScoreNet. Specifically, we extracted features from the point clouds of objects in the seen and unseen test set and visualized the t-SNE results. As shown in Figure 5, the results demonstrate that features from cans and bottles tend to intermingle, aligning with the accurate observation that both cans and bottles exhibit symmetrical cylindrical shapes. Meanwhile, features from the bowl category show proximity to features from mugs.

### Category-level Object Pose Tracking

Table 6 shows the performance of category-level object pose tracking of our tracking method and baselines on REAL275 datasets. For the first frame, we utilized a perturbed ground truth pose as the initial object pose, following CAPTRA  and CATRE . Despite being directly transferred from a single-image prediction method, our approach has achieved performance comparable to the state-of-the-art method, CATRE. Remarkably, we significantly outperform CATRE in the metrics of \(5^{}5cm\) and mean rotation error. This highlights the expansibility of our pose estimation method for more nuanced downstream tasks. Despite our lower FPS compared to CATRE, our method still adequately fulfills usage requirements, particularly for robot operations.

## 5 Conclusion and Discussion

In this work, we study a fundamental problem, namely the _multi-hypothesis issue_, that has existed in category-level object pose estimation for a long time. To overcome this issue, we propose a novel object pose estimation framework that initially generates the pose candidates via a score-based diffusion model. To aggregate the candidates, we leverage an energy-based diffusion model to filter out the outliers, which avoids the costly integration process of the score-based model. Our framework achieves exceptionally state-of-the-art performance on existing benchmarks, especially on symmetric objects. In addition, our framework is capable of object pose tracking and can generalize to objects from novel categories sharing similar symmetric properties.

**Limitations and Future Works:** Although our framework achieves real-time object pose tracking at approximately 17 FPS, the efficiency of single-frame object pose estimation is still limited by the costly sampling process of the score-based model. In the future, we may leverage the recent advances in accelerating the sampling process of the diffusion models to speed up the inference [52; 53]. In addition to passively filtering out the outliers, we may incorporate reinforcement learning to train an agent that actively increases the likelihood of the estimated pose .

**Boarder Impact:** This work opens the door to leveraging energy-based diffusion models to improve the generation results, which might facilitate more research in border communities.

   Method & Oracle ICP & 6-PACK & iCaps & CAPTRA & CATRE & Ours \\  Input & RGBD & RGBD & RGBD & D & D & D \\ Init. & GT. & GT. Pert. & Det. and Seg. & GT. Pert. & GT. Pert. & GT. Pert. \\  Speed(FPS)\(\) & - & 10 & 1.84 & 12.66 & **89.21** & 17.18 \\ \(5^{}5\)cm\(\) & 0.7 & 33.3 & 31.6 & 62.2 & 57.2 & **71.5** \\ \(R_{err}(^{})\)\(\) & 40.3 & 16.0 & 9.5 & 5.9 & 6.8 & **4.2** \\ \(t_{err}\)(cm)\(\) & 7.7 & 3.5 & 2.3 & 7.9 & **1.2** & 1.5 \\   

Table 6: **Results of category-level object pose tracking on REAL275.** The results are averaged over all 6 categories. The best performance is in **bold** and the second best is underscored.

Figure 5: **Visualization of the features. ‘w/o’ denotes the unseen category during training process.**