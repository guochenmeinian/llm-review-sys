# Universal Online Learning with Gradient Variations:

A Multi-layer Online Ensemble Approach

 Yu-Hu Yan, Peng Zhao, Zhi-Hua Zhou

National Key Laboratory for Novel Software Technology,

Nanjing University, Nanjing 210023, China

{yanyh, zhaop, zhouzh}@lamda.nju.edu.cn

Correspondence: Peng Zhao <zhaop@lamda.nju.edu.cn>

###### Abstract

In this paper, we propose an online convex optimization approach with two different levels of adaptivity. On a higher level, our approach is agnostic to the unknown types and curvatures of the online functions, while at a lower level, it can exploit the unknown niceness of the environments and attain problem-dependent guarantees. Specifically, we obtain \(( V_{T})\), \((d V_{T})\) and \(}(})\) regret bounds for strongly convex, exp-concave and convex loss functions, respectively, where \(d\) is the dimension, \(V_{T}\) denotes problem-dependent gradient variations and the \(}()\)-notation omits \( V_{T}\) factors. Our result not only safeguards the worst-case guarantees but also directly implies the small-loss bounds in analysis. Moreover, when applied to adversarial/stochastic convex optimization and game theory problems, our result enhances the existing universal guarantees. Our approach is based on a multi-layer online ensemble framework incorporating novel ingredients, including a carefully designed optimism for unifying diverse function types and cascaded corrections for algorithmic stability. Notably, despite its multi-layer structure, our algorithm necessitates only one gradient query per round, making it favorable when the gradient evaluation is time-consuming. This is facilitated by a novel regret decomposition equipped with carefully designed surrogate losses.

## 1 Introduction

Online convex optimization (OCO) is a versatile model that depicts the interaction between a learner and the environments over time (Hazan, 2016; Orabona, 2019). In each round \(t[T]\), the learner selects a decision \(_{t}\) from a convex compact set \(^{d}\), and simultaneously the environments choose a convex loss function \(f_{t}:\). Subsequently, the learner incurs a loss \(f_{t}(_{t})\), obtains information about the online function, and updates the decision to \(_{t+1}\), aiming to optimize the game-theoretical performance measure known as _regret_(Cesa-Bianchi and Lugosi, 2006):

\[_{T}_{t=1}^{T}f_{t}(_{t})-_{}_{t=1}^{T}f_{t}(),\] (1.1)

which represents the learner's excess loss compared to the best fixed comparator in hindsight.

In OCO, the type and curvature of online functions significantly impact the minimax regret bounds. Specifically, for convex functions, online gradient descent (OGD) can achieve an \(()\) regret guarantee (Zinkevich, 2003). For \(\)-exp-concave functions, online Newton step (ONS), with prior knowledge of the curvature coefficient \(\), attains an \((d T)\) regret (Hazan et al., 2007). For \(\)-strongly convex functions, OGD with prior knowledge of the curvature coefficient \(\) and a different parameter configuration enjoys an \(( T)\) regret (Hazan et al., 2007). Note that the abovealgorithms require the function type and curvature beforehand and does not consider the niceness of environments. Recent studies further strengthen the algorithms and results with _two levels of adaptivity_. The higher-level adaptivity requires an algorithm to be agnostic to the unknown types and curvatures of the online functions. And the lower-level adaptivity requires an algorithm to exploit the unknown niceness of the environments within a specific function family. In the following, we delve into an extensive discussion on these two levels of adaptivity.

### High Level: Adaptive to Unknown Curvature of Online Functions

Traditionally, the learner needs to know the function type and curvature in advance to select suitable algorithms (and parameter configurations), which can be burdensome in practice. _Universal_ online learning (van Erven and Koolen, 2016; Wang et al., 2019; Zhang et al., 2022) aims to develop a single algorithm agnostic to the specific function type and curvature while achieving the same regret guarantees as if they were known. The pioneering work of van Erven and Koolen (2016) proposed a single algorithm called MetaGrad that achieves an \(()\) regret for convex functions and an \((d T)\) regret for exp-concave functions. Later, Wang et al. (2019) further obtained the optimal \(( T)\) regret for strongly convex functions. Notably, these approaches are efficient regarding the gradient query complexity, by using only one gradient within each round.

However, the above approaches are not flexible enough since they have to optimize a group of heterogeneous and carefully-designed surrogate loss functions, which can be cumbersome and challenging. To this end, Zhang et al. (2022) introduced a simple framework that operates on the original online functions with the same optimal results at the expense of \(( T)\) gradient queries.

### Low Level: Adaptive to Unknown Niceness of Online Environments

Within a specific function family, the algorithm's performance is also substantially influenced by the niceness of environments. This concept is usually captured through _problem-dependent_ quantities in the literature. Therefore, it becomes essential to develop adaptive algorithms with problem-dependent regret guarantees. Specifically, we consider the following problem-dependent quantities:

\[F_{T}_{}_{t=1}^{T}f_{t}(),V_{T}_{t=2}^{T}_{}\|  f_{t}()- f_{t-1}()\|^{2},\]

where the small loss \(F_{T}\) represents the cumulative loss of the best comparator (Srebro et al., 2010; Orabona et al., 2012) and the gradient variation \(V_{T}\) characterizes the variation of the function gradients (Chiang et al., 2012). In particular, the gradient-variation bound demonstrates its fundamental importance in modern online learning from the following three aspects: _(i)_ it safeguards the worst-case guarantees in terms of \(T\) and implies the small-loss bounds in analysis directly; _(ii)_ it draws a profound connection between adversarial and stochastic convex optimization; and _(iii)_ it is crucial for fast convergence rates in game theory. We will explain the three aspects in detail in the next part.

### Our Contributions and Techniques

In this paper, we consider the two levels of adaptivity simultaneously and propose a novel universal approach that achieves \(( V_{T})\), \((d V_{T})\) and \(}(})\) regret bounds for strongly convex,

   &  & **Gradient** \\   & Strongly Convex & Exp-concave & Convex & **Query** \\  van Erven and Koolen (2016) & \((d T)\) & \((d T)\) & \(()\) & \(1\) \\  Wang et al. (2019) & \(( T)\) & \((d T)\) & \(()\) & \(1\) \\  Zhang et al. (2022) & \((\{ V_{T}, F_{T}\})\) & \((d\{ V_{T}, F_{T}\})\) & \((})\) & \(( T)\) \\  
**Ours** & \((\{ V_{T}, F_{T}\})\) & \((d\{ V_{T}, F_{T}\})\) & \(}(\{},}\})\) & \(1\) \\  

Table 1: Comparison with existing results. The second column presents the regret bounds for various kinds of functions, where \(V_{T}\) and \(F_{T}\) are problem-dependent quantities that are at most \((T)\) and can be much smaller in nice environments. The \(}()\)-notation omits logarithmic factors on \(V_{T}\) and \(F_{T}\). The third column shows the gradient query complexity. All problem-dependent bounds require the smoothness of online functions.

exp-concave and convex loss functions, respectively, using only one gradient query per round, where \(}()\)-notation omits factors on \( V_{T}\). Table 1 compares our results with existing ones. In summary, relying on the basic idea of online ensemble (Zhao et al., 2021), our approach primarily admits a _multi-layer online ensemble_ structure with several important novel ingredients. Specifically, we propose a carefully designed optimism, a hyper-parameter encoding historical information, to handle different kinds of functions universally, particularly exp-concave functions. Nevertheless, it necessitates careful management of the stability of final decisions, which is complicated in the multi-layer structure. To this end, we analyze the negative stability terms in the algorithm and propose cascaded correction terms to realize effective collaboration among layers, thus enhancing the algorithmic stability. Moreover, we facilitate a novel regret decomposition equipped with carefully designed surrogate losses to achieve only one gradient query per round, making our algorithm as efficient as van Erven and Koolen (2016) regarding the gradient complexity. Our result resolves an open problem proposed by Zhang et al. (2022), who have obtained partial results for exp-concave and strongly convex functions and asked whether it is possible to design designing a single algorithm with universal gradient-variation bounds. Among them, the convex case is particularly important because the improvement from \(T\) to \(V_{T}\) is polynomial, whereas logarithmic in the other cases.

Next, we shed light on some applications of our approach. First, it safeguards the worst-case guarantees (van Erven and Koolen, 2016, Wang et al., 2019) and directly implies the small-loss bounds of Zhang et al. (2022) in analysis. Second, gradient variation is shown to play an essential role in the stochastically extended adversarial (SEA) model (Sachs et al., 2022, Chen et al., 2023), an interpolation between stochastic and adversarial OCO. Our approach resolves a major open problem left in Chen et al. (2023) on whether it is possible to develop a single algorithm with universal guarantees for strongly convex, exp-concave, and convex functions in the SEA model. Third, in game theory, gradient variation encodes the changes in other players' actions and can thus lead to fast convergence rates (Rakhlin and Sridharan, 2013; Syrgkanis et al., 2015; Zhang et al., 2022). We demonstrate the universality of our approach by taking two-player zero-sum games as an example.

Technical Contributions.Our first contribution is proposing a multi-layer online ensemble approach with effective collaboration among layers, which is achieved by a _carefully-designed optimism_ to unify different kinds of functions and _cascaded correction terms_ to improve the algorithmic stability within the multi-layer structure. The second contribution arises from efficiency. Although there are multiple layers, our algorithm only requires one gradient query per round, which is achieved by a _novel regret decomposition_ equipped with carefully designed surrogate losses. Two interesting byproducts rises in our approach. The first one is the negative stability term in the analysis of MsMwC (Chen et al., 2021), which serves as an important building block of our algorithm. And the second byproduct contains a simple approach and analysis for the optimal worst-case universal guarantees, using one gradient query within each round.

Organization.The rest of the paper is structured as follows. Section 2 provides preliminaries. Section 3 proposes our multi-layer online ensemble approach for universal gradient-variation bounds. Section 4 further improves the gradient query complexity. Due to page limits, the applications of our proposed algorithm are deferred to Appendix A. All the proofs can be found in the appendices.

## 2 Preliminaries

In this section, we introduce some preliminary knowledge, including our assumptions, the definitions, the formal problem setup, and a review of the latest progress of Zhang et al. (2022).

To begin with, we list some notations. Specifically, we use \(\|\|\) for \(\|\|_{2}\) in default and use \(_{t}\), \(_{k}\), \(_{i}\) as abbreviations for \(_{t[T]}\), \(_{k[K]}\) and \(_{i[N]}\). \(a b\) represents \(a(b)\). \(}()\)-notation omits logarithmic factors on leading terms. For example, \(}()\) omits the dependence of \( V\).

**Assumption 1** (Boundedness).: For any \(,\) and \(t[T]\), the domain diameter satisfies \(\|-\| D\), and the gradient norm of the online functions is bounded by \(\| f_{t}()\| G\).

**Assumption 2** (Smoothness).: All online functions are \(L\)-smooth: \(\| f_{t}()- f_{t}()\| L\|- \|\) for any \(,\) and \(t[T]\).

Both assumptions are common in the literature. Specifically, the boundedness assumption is common in OCO (Hazan, 2016). The smoothness assumption is essential for first-order algorithms to achieve gradient-variation bounds (Chiang et al., 2012). Strong convexity and exp-concavity are defined as follows. For any \(\), \(\), a function \(f\) is \(\)-strongly convex if \(f()-f() f(),--\|-\|^{2}\), and is \(\)-exp-concave if \(f()-f() f(),- - f(),- ^{2}\). Note that the formal definition of \(\)-exp-concavity states that \((- f())\) is concave. Under Assumption 1, \(\)-exp-concavity leads to our definition with \(=\{,\}\)(Hazan, 2016, Lemma 4.3). For simplicity, we use it as an alternative definition for exp-concavity.

In the following, we formally describe the problem setup and briefly review the key insight of Zhang et al. (2022). Concretely, we consider the problem where the learner has no prior knowledge about the function type (strongly convex, exp-concave, or convex) or the curvature coefficient (\(\) or \(\)). Without loss of generality, we study the case where the curvature coefficients \(,[}{{T}},1]\). This requirement is natural because if \(\) (or \(\)) \(<}{{T}}\), even the optimal regret is \((T)\)(Hazan et al., 2007), which is vacuous. Conversely, functions with \(\) (or \(\)) \(>1\) are also 1-exp-concave (or 1-strongly convex). Thus using \(\) (or \(\)) \(=1\) will only worsen the regret by a constant factor, which can be omitted. This condition is also used in previous works (Zhang et al., 2022).

A Brief Review of Zhang et al. (2022).A general solution to handle the uncertainty is to leverage a two-layer framework, which consists of a group of base learners exploring the environments and a meta learner tracking the best base learner on the fly. To handle the unknown curvature coefficients \(\) and \(\), the authors discretize them into the following candidate pool:

\[\{}{{T}},}{{T}},}{{T}},,1\},\] (2.1)

where \(|| T\). Consequently, they design three groups of base learners:

1. about \( T\) base learners, each of which runs the algorithm for strongly convex functions with a guess \(_{i}\) of the strong convexity coefficient \(\);
2. about \( T\) base learners, each of which runs the algorithm for exp-concave functions with a guess \(_{i}\) of the exp-concavity coefficient \(\);
3. \(1\) base learner that runs the algorithm for convex functions.

Overall, they maintain \(N T+ T+1\) base learners. Denoting by \(_{t}(p_{t,1},,p_{t,N})\) the meta learner's weights and \(_{t,i}\) the \(i\)-th base learner's decision, the learner submits \(_{t}=_{i}p_{t,i}_{t,i}\).

In the two-layer framework, the regret (1.1) can be decomposed into two terms:

\[_{T}=[_{t=1}^{T}f_{t}(_{t})-_{t=1}^{T}f_{t} (_{t,i^{*}})]+[_{t=1}^{T}f_{t}(_{t,i^{*}})- _{}_{t=1}^{T}f_{t}()],\] (2.2)

where the _meta regret_ (first term) assesses how well the algorithm tracks the best base learner, and the _base regret_ (second term) measures the performance of it. The best base learner is the one which runs the algorithm matching the ground-truth function type with the most accurate guess of the curvature -- taking \(\)-exp-concave functions as an example, there must exist a base learner indexed by \(i^{}\), whose coefficient \(_{i^{*}}\) satisfies \(_{i^{*}} 2_{i^{*}}\).

A direct benefit of the above decomposition is that the meta regret can be bounded by a _constant_\((1)\) for exp-concave and strongly convex functions, allowing the algorithm to perfectly inherit the gradient-variation bound from the base learner. Taking \(\)-exp-concave functions as an example, by definition, the meta regret can be bounded by \(_{t}r_{t,i^{}}-_{t}r_{t,i^{}}^{2}\), where the first term \(r_{t,i} f_{t}(_{t}),_{t}-_{t,i}\) denotes the linearized regret, and the second one is a negative term from exp-concavity. Choosing Adapt-ML-Prod (Gaillard et al., 2014) as the meta algorithm bounds the first term \(_{t}r_{t,i^{}}\) by \(((r_{t,i^{}})^{2}})\), which can be canceled by the negative term, leading to an \((1)\) meta regret. Due to the meta algorithm's benefits, their approach can inherit the gradient-variation guarantees from the base learner. Similar derivation also applies to strongly convex functions. However, their approach is not favorable enough in the convex case and is not efficient enough in terms of the gradient query complexity. We will give more discussions about the above issues in Section 3.1 and Section 4.

## 3 Our Approach

This section presents our multi-layer online ensemble approach with universal gradient-variation bounds. Specifically, in Section 3.1, we provide a novel optimism to unify different kinds of functions. In Section 3.2, we exploit two types of negative terms to cancel the positive term caused by the optimism design. We summarize the overall algorithm in Section 3.3. Finally, in Section 3.4, we present the main results and list several applications of our approach.

### Universal Optimism Design

In this part, we propose a novel optimism that simultaneously unifies various kinds of functions. We start by observing that Zhang et al. (2022) does not enjoy gradient-variation bounds for convex functions, where the main challenge lies in obtaining an \((})\) meta regret for convex functions while simultaneously maintaining an \((1)\) regret for exp-concave and strongly convex functions. In the following, we focus on the meta regret because the base regret optimization is straightforward by employing the optimistic online learning technique (Rakhlin and Sridharan, 2013, 2013) in a black-box fashion. Optimistic online learning is essential in our problem since it can utilize the historical information, e.g., \( f_{t-1}()\) for our purpose due to the definition of the gradient variation.

Shifting our focus to the meta regret, we consider upper-bounding it by a second-order bound of \(((r_{t,i^{*}}-m_{t,i^{*}})^{2}})\), where \(r_{t,i}= f_{t}(_{t}),_{t}-_{t,i}\) and the optimism \(m_{t,i^{*}}\) can encode historical information. Such a second-order bound can be easily obtained using existing prediction with expert advice algorithms, e.g., Adapt-ML-Prod(Wei et al., 2016). Nevertheless, as we will demonstrate in the following, designing an optimism \(m_{t,i}\) that effectively unifies various function types is not straightforward, thereby requiring novel ideas in the optimism design.

To begin with, a natural impulse is to choose the optimism as \(m_{t,i}= f_{t-1}(_{t-1}),_{t,i}-_ {t}\),2 which yields the following second-order bound:

\[_{t=1}^{T}(r_{t,i^{*}}-m_{t,i^{*}})^{2}\{ &_{t}\|_{t}-_{t,i^{*}}\|^{2},& \\ &_{t}\| f_{t}(_{t})- f_{t-1}(_{t-1})\|^{2},&.\]

where the inequality is due to the boundedness assumption (Assumption 1). This optimism design handles the strongly convex functions well since the bound can be canceled by the negative term imported by strong convexity (i.e., \(-\|_{t}-_{t,i^{*}}\|^{2}\)). Moreover, it is quite promising for convex functions because the bound essentially consists of the desired gradient variation and a positive term of \(\|_{t}-_{t-1}\|^{2}\) (we will deal with it later). However, it fails for exp-concave functions because the negative term imported by exp-concavity (i.e., \(- f_{t}(_{t}),_{t}-_{t,i^{*}} ^{2}\)) cannot be used for cancellation due to the mismatch of the formulation.

To unify various kinds of functions, we propose a _novel optimism design_ defined by \(m_{t,i}=r_{t-1,i}\). This design aims to secure a second-order bound of \(((r_{t,i^{*}}-r_{t-1,i^{*}})^{2}})\), which is sufficient to achieve an \((1)\) meta regret for exp-concave functions (with strong convexity being a subcategory thereof) while maintaining an \((})\) meta regret for convex functions. The high-level intuition behind this approach is as follows: although the bound cannot be canceled exactly by the negative term imported by exp-concavity (i.e., \(-r_{t,i^{*}}^{2}\)) within each round, it becomes manageable when aggregated _across the whole time horizon_ as \(_{t}(r_{t,i^{*}}-r_{t-1,i^{*}})^{2} 4_{t}r_{t,i^{*}}^{2}\), because \(r_{t,i^{*}}\) and \(r_{t-1,i^{*}}\) differs by merely a single time step. In the following, we propose the key lemma of the universal optimism design and defer the proof to Appendix B.1.

**Lemma 1** (Key Lemma).: _Under Assumptions 1 and 2, if the optimism is chosen as \(m_{t,i}=r_{t-1,i}= f_{t-1}(_{t-1}),_{t-1}- _{t-1,i}\), it holds that_

\[_{t=1}^{T}(r_{t,i^{*}}-m_{t,i^{*}})^{2}\{ &_{t=1}^{T} f_{t}( _{t}),_{t}-_{t,i^{*}}^{2},& \\ & V_{T}+_{t=2}^{T}\|_{t,i^{*}}-_{t-1,i^{* }}\|^{2}+_{t=2}^{T}\|_{t}-_{t-1}\|^{2}.& .\]

Moreover, the second part of Lemma 1 shows that the bound for convex functions is also controllable by being further decomposed into three terms. The first term is the desired gradient variation. The second one measures the base learner stability, which can be canceled by optimistic algorithms (Rakhlin and Sridharan, 2013a). We provide a self-contained analysis of the stability of optimistic online mirror descent (OMD) in Appendix E.2. At last, if the stability term of the final decisions (i.e., \(\|_{t}-_{t-1}\|^{2}\)) can be canceled, an \((})\) meta regret for convex functions is achievable.

To this end, we give the positive term \(\|_{t}-_{t-1}\|^{2}\) a more detailed decomposition, due to the fact that the final decision is the weighted combination of base learners' decisions (i.e., \(_{t}=_{i}p_{t,i}_{t,i}\)). A detailed proof is deferred to Lemma6. Specifically, it holds that

\[\|_{t}-_{t-1}\|^{2}\|_{t}-_{t-1}\|_{1 }^{2}+_{i=1}^{N}p_{t,i}\|_{t,i}-_{t-1,i}\|^{2},\] (3.1)

where the first part represents the meta learner's stability while the second one is a weighted version of the base learners' stability. In Section3.2, we cancel the two parts respectively.

### Negative Terms for Cancellation

In this part, we propose negative terms to cancel the two parts of (3.1). Specifically, Section3.2.1 analyzes the _endogenous_ negative stability terms of the meta learner to handle the first part, and Section3.2.2 proposes artificially-injected cascaded corrections to cancel the second part _exogenously_.

#### 3.2.1 Endogenous Negativity: Stability Analysis of Meta Algorithms

In this part, we aim to control the meta learner's stability, measured by \(\|_{t}-_{t-1}\|_{1}^{2}\). To this end, we leverage the two-layer meta algorithm proposed by Chen et al. (2021), where each layer runs the MsMwC algorithm (Chen et al., 2021) but with different parameter configurations. Specifically, a single MsMwC updates via the following rule:

\[_{t}=*{arg\,min}_{_{d}}\;\{_{t},+_{_{t}}(,}_{t})\}, }_{t+1}=*{arg\,min}_{_{d}}\; \{_{t}+_{t},+_{_{t}}( ,}_{t})\},\] (3.2)

where \(_{d}\) denotes a \(d\)-dimensional simplex, \(_{t}()=_{i=1}^{d}_{t,i}^{-1}p_{i} p_{i}\) is the weighted negative entropy regularizer with time-coordinate-varying step size \(_{t,i}\), \(_{_{t}}(,)=_{t}()-_{t}()- _{t}(),-\) is the induced Bregman divergence for any \(,_{d}\), \(_{t}\) is the optimism, \(_{t}\) is the loss vector and \(_{t}\) is a bias term.

It is worth noting that MsMwC is based on OMD, which is well-studied and proved to enjoy negative stability terms in analysis. However, the authors omitted them, which turns out to be crucial for our purpose. In Lemma2 below, we extend Lemma1 of Chen et al. (2021) by explicitly exhibiting the negative terms in MsMwC. The proof is deferred to AppendixB.2.

**Lemma 2**.: _If \(_{t[T],i[d]}\{|_{t,i}|,|m_{t,i}|\} 1\), then MsMwC (3.2) with time-invariant step sizes (i.e., \(_{t,i}=_{i}\) for any \(t[T]\))2 enjoys the following guarantee if \(_{i}}{{32}}\)_

\[_{t=1}^{T}_{t},_{t}-_{t=1}^{ T}_{t,i^{*}}}}_{1,i^{*}}}+ _{i=1}^{d}_{1,i}}{_{i}}-8_{t=1}^{T}_{i=1}^{d} _{i}p_{t,i}(_{t,i}-m_{t,i})^{2}\] \[+16_{i^{*}}_{t=1}^{T}(_{t,i^{*}}-m_{t,i^{*}})^{2}-4 _{t=2}^{T}\|_{t}-_{t-1}\|_{1}^{2}.\]

The two-layer meta algorithm is constructed by MsMwC in the following way. Briefly, both layers run MsMwC, but with different parameter configurations. Specifically, the top MsMwC (indicated by MsMwC-Top) connects with \(K=( T)\) MsMwCs (indicated by MsMwC-Mid), and each MsMwC-Mid is further connected with \(N\) base learners (as specified in Section2). The specific parameter configurations will be illuminated later. The two-layer meta algorithm is provable to enjoy a regret guarantee of \(( V_{}})\) (Theorem5 of Chen et al. (2021)), where \(V_{}\) is analogous to \(_{t}(_{t,i^{*}}-m_{t,i^{*}})^{2}\), but within a multi-layer context (a formal definition will be shown later). By choosing the optimism as \(m_{t,i}=_{t},_{t}\),4, it can recover the guarantee of Adapt-ML-Prod,although up to an \(( V_{})\) factor (leading to an \(}(})\) meta regret), but with additional negative terms in analysis. Note that single MsMwC enjoys an \(( T})\) bound, where the extra \( T\) factor would ruin the desired \(( V_{T})\) bound for exp-concave and strongly convex functions. This is the reason for choosing a second-layer meta algorithm, overall resulting in a _three-layer_ structure.

For clarity, we summarize the notations of the three-layer structure in Table 2. Besides, previous notions need to be extended analogously. Specifically, instead of (2.2), regret is now decomposed as

\[_{T}=[_{t=1}^{T}f_{t}(_{t})-_{t=1}^{T}f_{t} (_{t,k^{},i^{}})]+[_{t=1}^{T}f_{t}(_{t,k^{},i^{}})-_{}_{t=1}^{T}f_{t}( )].\]

The quantity \(V_{}\) is defined as \(V_{}_{t}(_{t,k^{},i^{}}-m_{t,k^{},i^{ }})^{2}\), where \(_{t,k,i}= f_{t}(_{t}),_{t,k,i}\) and \(m_{t,k,i}= f_{t}(_{t}),_{t}-  f_{t-1}(_{t-1}),_{t-1}-_{t-1,k,i}\) follows the same sprit as Lemma 1.

At the end of this part, we explain why we choose MsMwC as the meta algorithm. Apparently, a direct try is to keep using Adapt-ML-Prod following Zhang et al. (2022). However, it is still an open problem to determine whether Adapt-ML-Prod contains negative stability terms in the analysis, which is essential to realize effective cancellation in our problem. Another try is to explore the titled exponentially weighted average (TEWA) as the meta algorithm, following another line of research (van Erven and Koolen, 2016), as introduced in Section 1.1. Unfortunately, its stability property is also unclear. Investigating the negative stability terms in these algorithms is an important open problem, but beyond the scope of this work.

#### 3.2.2 Exogenous Negativity: Cascaded Correction Terms

In this part, we aim to deal with the second term in (3.1) (i.e., \(_{i}p_{t,i}\|_{t,i}-_{t-1,i}\|^{2}\)). Inspired by the work of Zhao et al. (2021) on the gradient-variation dynamic regret in non-stationary online learning,5 we incorporate exogenous correction terms for cancellation. Concretely, we inject _cascaded correction terms_ to both top and middle layers. Specifically, the loss \(_{t}\) and the optimism \(_{t}\) of MsMwC-Top are chosen as

\[_{t,k} f_{t}(_{t}),_{t,k,i} +_{1}\|_{t,k}-_{t-1,k}\|^{2},m_{t,k} }_{t,k,i}+_{2}\|_{t,k,i}- _{t-1,k,i}\|^{2},\] (3.4)

where \(}_{t,k}(_{t,k,1},,_{t,k,N})\) and \(_{t,k,i}= f_{t}(_{t}),_{t} - f_{t-1}(_{t-1}),_{t-1}-_{t -1,k,i}\) denotes our optimism, which uses the same idea as Lemma 1 in Section 3.1.

To see how the correction term works, consider a simpler problem with regret \(_{t}_{t},_{t}-_{t}_{t,k^{}}\). If we instead optimize the corrected loss \(_{t}+_{t}\) and obtain a regret bound of \(R_{T}\), then moving the correction terms to the right-hand side, the original regret is at most \(R_{T}-_{t}_{k}q_{t,k}b_{t,k}+_{t}b_{t,k^{}}\), where the negative term of \(-_{t}_{k}q_{t,k}b_{t,k}\) can be leveraged for cancellation. Meanwhile, the algorithm is required to handle an extra term of \(_{t}b_{t,k^{}}\), which only relies on the \(k^{}\)-th dimension. In the next part, we will discuss about how cascaded corrections and negative stability terms of meta algorithms realize effective collaboration for cancellation in the multi-layer online ensemble.

It is noteworthy that our work is the _first_ to introduce correction mechanisms to universal online learning, whereas prior works use it for different purposes, such as non-stationary online learn

  
**Layer** & **Algorithm** & **Loss** & **Optimism** & **Decision** & **Output** \\  Top (Meta) & MsMwC & \(_{t}\) & \(_{t}\) & \(_{t}_{K}\) & \(_{t}=_{k}q_{t,k}_{t,k}\) \\  Middle (Meta) & MsMwC & \(_{t,k}\) & \(_{t,k}\) & \(_{t,k}_{N}\) & \(_{t,k}=_{i}p_{t,k,i}_{t,k,i}\) \\  Bottom (Base) & Optimistic OMD & \(f_{t}()\) & \( f_{t-1}()\) & \(_{t,k,i}\) & \(_{t,k,i}\) \\   

Table 2: Notations of the three-layer structure. The first column presents the index of layers. The rest columns illuminate the notations for the algorithms, losses, optimisms, decisions and outputs of each layer.

ing (Zhao et al., 2021) and the multi-scale expert problem (Chen et al., 2021). Distinctively, different from the conventional two-layer algorithmic frameworks seen in prior studies, deploying this technique to a three-layer structure necessitates a comprehensive use and extensive adaptation of it.

### Overall Algorithm: A Multi-layer Online Ensemble Structure

In this part, we conclude our _three-layer online ensemble_ approach in Algorithm 1. In Line 3, the decisions are aggregated from bottom to top for the final output. In Line 4, the learner suffers the loss of the decision, and the environments return the gradient information of the loss function. In Line 5, the algorithm constructs the surrogate losses and optimisms for the two-layer meta learner. In Line 6-11, the update is conducted from top to bottom. Note that in Line 8, our algorithm requires multiple, concretely \((^{2}T)\), gradient queries per round since it needs to query \( f_{t}(_{t,k,i})\) for each base learner, making it inefficient when the gradient evaluation is costly. To this end, in Section 4, we improve the algorithm's gradient query complexity to 1 per round, corresponding to Line 10-11, via a novel regret decomposition and carefully designed surrogate loss functions.

```
0: Curvature coefficient pool \(\), MsMwc-Mid number \(K\), base learner number \(N\)
1:Initialize: Top layer: \(^{}\) -- MsMwc-Top with \(_{k}=(C_{0} 2^{k})^{-1}\) and \(_{1,k}=_{k}^{2}/_{k=1}^{K}_{k}^{2}\)
2: Middle layer: \(\{^{}_{k}\}_{k[K]}\) -- MsMwc-Mid with step size \(2_{k}\) and \(_{1,k,i}=}{{N}}\)
3: Bottom layer: \(\{_{k,i}\}_{k[K],i[N]}\) -- base learners as specified in Section 2
4:for\(t=1\)to\(T\)do
5: Receive \(_{t,k,i}\) from \(_{k,i}\), obtain \(_{t,k}=_{i}p_{t,k,i}_{t,k,i}\) and submit \(_{t}=_{k}q_{t,k}_{t,k}\)
6: Suffer \(f_{t}(_{t})\) and observe the gradient information \( f_{t}()\)
7: Construct \((_{t},_{t})\) (3.3) for \(^{}\) and \((_{t,k},_{t,k})\) (3.4) for \(^{}_{k}\)
8:\(^{}\) updates to \(_{t+1}\) and \(^{}_{k}\) updates to \(_{t+1,k}\)
9: Multi-gradient feedback model:
10: Send gradient \( f_{t}()\) to \(_{k,i}\) for update \((^{2}T)\) gradient queries
11: One-gradient feedback model:
12: Construct surrogates \(h^{}_{t,i}()\), \(h^{}_{t,i}()\), \(h^{}_{t,i}()\) using only \( f_{t}(_{t})\)
13: Send the surrogate functions to \(_{k,i}\) for update \(\) Only one gradient query
14:endfor ```

**Algorithm 1** Universal OCO with Gradient-variation Guarantees

In Figure 1, we illustrate the detailed procedure of the collaboration in our multi-layer online ensemble approach. Specifically, we aim to deal with the positive term of \(\|_{t}-_{t-1}\|^{2}\), which stems from the universal optimism design proposed in Section 3.1. Since \(_{t}=_{k}q_{t,k}_{t,k}\), the positive term can be further decomposed into two parts: \(\|_{t}-_{t-1}\|_{1}^{2}\) and \(_{k}q_{t,k}\|_{t,k}-_{t-1,k}\|^{2}\), which can be canceled by the negative and correction terms in MsMwc-Top, respectively. Note that the correction comes at the expense of an extra term of \(\|_{t,k^{*}}-_{t-1,k^{*}}\|^{2}\), which can be decomposed similarly into two parts: \(\|_{t,k^{*}}-_{t-1,k^{*}}\|_{1}^{2}\) and \(_{i}p_{t,k^{*},i}\|_{t,k^{*},i}-_{t-1,k^{*},i}\|^{2}\) because of \(_{t,k}=_{i}p_{t,k,i}_{t,k,i}\). The negative term and corrections in the middle layer (specifically, the \(k^{*}\)-th MsMwc-Mid) can be leveraged for cancellation. This correction finally generate \(\|_{t,k^{*},i^{*}}-_{t-1,k^{*},i^{*}}\|^{2}\), which can be handled by choosing optimistic OMD as base algorithms.

As a final remark, although it is possible to treat the two-layer meta algorithm as a single layer, its analysis will become much more complicated than that in one layer and is unsuitable for extending to more layers. In contrast, our layer-by-layer analytical approach paves a systematic and principled way for analyzing the dynamics of the online ensemble framework with even more layers.

### Universal Regret Guarantees

In this part, we conclude our main theoretical result and provide several implications and applications to validate its importance and practical potential. Theorem 1 summarizes the main result, universal regret guarantees in terms of the gradient variation. The proof is deferred to Appendix B.4.

**Theorem 1**.: _Under Assumptions 1 and 2, Algorithm 1 obtains \(( V_{T})\), \((d V_{T})\) and \(}(})\) regret bounds for strongly convex, exp-concave and convex functions, respectively._Theorem 1 improves the results of Zhang et al. (2022) by not only maintaining the optimal rates for strongly convex and exp-concave functions but also taking advantage of the small gradient variation for convex functions when \(V_{T} F_{T}\). For example, if \(f_{1}==f_{T}=f\) and \(_{}f()=1\), our bound is much better since \(V_{T}=0\) while \(F_{T}=T\). Moreover, Algorithm 1 also provably achieves universal _small-loss_ guarantees _without_ any algorithmic modification and thus safeguards the case when \(F_{T} V_{T}\). We conclude the result below and provide the proof in Appendix B.5.

**Corollary 1**.: _Under Assumptions 1 and 2, if \(f_{t}() 0\), Algorithm 1 obtains \(( F_{T})\), \((d F_{T})\) and \(}(})\) regret bounds for strongly convex, exp-concave and convex functions._

Due to the connection of the gradient-variation with _stochastic and adversarial OCO_(Sachs et al., 2022) and _game theory_(Syrgkanis et al., 2015), our results can be immediately applied and achieve best known universal guarantees therein. Due to page limits, we defer applications to Appendix A.

## 4 Improved Gradient Query Complexity

Though achieving favorable theoretical guarantees in Section 3, one caveat is that our algorithm requires \((^{2}T)\) gradient queries per round since it needs to query \( f_{t}(_{t,k,i})\) for all \(k[K],i[N]\), making it computational-inefficient when the gradient evaluation is costly, e.g., in nuclear norm optimization (Ji and Ye, 2009) and mini-batch optimization (Li et al., 2014). The same concern also appears in the approach of Zhang et al. (2022), who provided small-loss and worst-case regret guarantees for universal online learning. By contrast, traditional algorithms such as OGD typically work under the _one-gradient_ feedback setup, namely, they only require one gradient \( f_{t}(_{t})\) for the update. In light of this, it is natural to ask whether there is a universal algorithm that can maintain the desired regret guarantees while using only one gradient query per round.

We answer the question affirmatively by reducing the gradient query complexity to \(1\) per round. To describe the high-level idea, we first consider the case of _known_\(\)-strong convexity within a two-layer structure, e.g., adaptive regret minimization for strongly convex functions (Wang et al., 2018). The regret can be upper-bounded as \(_{T}[_{t}h_{t}(_{t})-_{t}h_{t}(_{ t,i^{*}})]+[_{t}h_{t}(_{t,i^{*}})-_{t}h_{t}(^{*})]\), where \(^{*}*{arg\,min}_{}_{t} f_{t}()\) and \(h_{t}() f_{t}(_{t}), +\|-_{t}\|^{2}/2\) is a second-order surrogate of the original function \(f_{t}\). This yields a _homogeneous_ surrogate for both meta and base algorithms -- the meta algorithm uses the same evaluation function across all the base learners, who in turn use this function to update their base-level decisions.

In the universal online learning (i.e., _unknown_\(\)), a natural adaptation would be a _heterogeneous_ surrogate \(h_{t,i}() f_{t}(_{t}), +_{i}\|-_{t}\|^{2}/2\) for the \(i\)-th base learner, where \(_{i}\) is a guess of the true curvature \(\) from the candidate pool \(\) (2.1). Consequently, the regret decomposition with respect to this surrogate becomes \(_{T}[_{t}h_{t,i^{*}}(_{t})-_{t}h_{t,i^{*}}( _{t,i^{*}})]+[_{t}h_{t,i^{*}}(_{t,i^{*}})-_{t}h_{t,i^{*}}(^{*})]\), where \(i^{}\) denotes the index of the best base learner whose strong convexity coefficient satisfies \(_{i^{*}} 2_{i^{*}}\). This admits _heterogeneous_ surrogates for both meta and base regret, which

Figure 1: Decomposition of the positive term \(\|_{t}-_{t-1}\|^{2}\) and how it is handled by the multi-layer online ensemble via endogenous negativity from meta algorithm and exogenous negativity from cascaded corrections.

necessitates designing expert-tracking algorithms with heterogeneous inputs for different experts as required in MetaGrad (van Erven and Koolen, 2016), which is not flexible enough.

To this end, we propose a novel regret decomposition that admits _homogeneous_ surrogates for the meta regret, making our algorithm as flexible as Zhang et al. (2022), and _heterogeneous_ surrogate for the base regret, making it as efficient as van Erven and Koolen (2016). Specifically, we remain the heterogeneous surrogates \(h_{t,i}()\) defined above for the base regret. For the meta regret, we define a homogeneous linear surrogate \(_{t}() f_{t}(_{t}),\) such that the meta regret is bounded by \(_{t}_{t}(_{t})-_{t}_{t}(_{t,i^{*}})- _{i^{*}}_{t}\|_{t}-_{t,i^{*}}\|^{2}/2\). As long as we can obtain a second-order bound for the regret defined on this surrogate loss, i.e., \(_{t}_{t}(_{t})-_{t}_{t}(_{t,i^{*}})\), it can be canceled by the negative term from strong convexity. Overall, we decompose the regret in the following way:

\[_{T}[_{t=1}^{T}_{t}(_{t})-_{t=1}^{ T}_{t}(_{t,i^{*}})-}}{2}_{t=1}^{T}\| _{t}-_{t,i^{*}}\|^{2}]+[_{t=1}^{T}h_{t,i^{* }}(_{t,i^{*}})-_{t=1}^{T}h_{t,i^{*}}(^{*})].\]

For clarity, we denote this surrogate for strongly convex functions by \(h_{t,i}^{}()\). Similarly, we define the surrogates \(h_{t,i}^{}() f_{t}(_{t}), +_{i} f_{t}(_{t}),- _{t}^{2}/2\) and \(h_{t,i}^{}() f_{t}(_{t}), \) for \(\)-exp-concave and convex functions, respectively. These surrogates require only _one_ gradient \( f_{t}(_{t})\) within each round, thus successfully reducing the gradient query complexity.

Note that the base regret optimization requires controlling the algorithmic stability, because the empirical gradient variation \( h_{t,i}^{}(_{t,i})- h_{t-1,i}^{}( _{t-1,i})= f_{t}(_{t})+_{i}(_{t,i} -_{t})- f_{t-1}(_{t-1})-_{i}(_{t-1,i}-_{t-1})\) not only contains the desired gradient variation, but also includes the positive stability terms of base and final decisions. Fortunately, as discussed earlier, these stability terms can be effectively addressed through our cancellation mechanism within the multi-layer online ensemble. This stands in contrast to previous two-layer algorithms with worst-case regret bounds (Zhang et al., 2018; Wang et al., 2018), where the algorithmic stability is not examined.

The efficient version is concluded in Algorithm 1 with Line 10-11, which uses only one gradient \( f_{t}(_{t})\). The only algorithmic modification is that base learners update on the carefully designed surrogate functions, not the original one. We provide the regret guarantee below, which achieves the same guarantees as Theorem 1 with only one gradient per round. The proof is in Appendix C.2.

**Theorem 2**.: _Under Assumptions 1 and 2, efficient Algorithm 1 enjoys \(( V_{T})\), \((d V_{T})\) and \(}(})\) for strongly convex, exp-concave and convex functions, using only one gradient per round._

As a byproduct, we show that this idea can be used to recover the optimal worst-case universal guarantees using one gradient with a simpler approach and analysis, with proof in Appendix C.1.

**Proposition 1**.: _Under Assumption 1, using the above surrogate loss functions for base learners, and running Adapt-ML-Prod as the meta learner guarantees \(( T)\), \((d T)\) and \(()\) regret bounds for strongly convex, exp-concave and convex functions, using one gradient per round._

## 5 Conclusion

In this paper, we obtain universal gradient-variation guarantees via a multi-layer online ensemble approach. We first propose a novel optimism design to unify various kinds of functions. Then we analyze the negative terms of the meta algorithm MsMwC and inject cascaded correction terms to improve the algorithmic stability to realize effective cancellations in the multi-layer structure. Furthermore, we provide a novel regret decomposition combined with carefully designed surrogate functions to achieve one gradient query per round. Finally, we deploy the our approach into two applications, including the stochastically extended adversarial (SEA) model and two-player zero-sum games, to validate its effectiveness, and obtain best known universal guarantees therein. Due to page limits, the applications are deferred to Appendix A. Two byproducts rise in our work. The first one is negative stability terms in the analysis of MsMwC. And the second one contains a simple approach and analysis for the optimal worst-case universal guarantees, using one gradient per round.

An important open problem lies in optimality and efficiency. In the convex case, our results still exhibit an \(( V_{T})\) gap from the optimal \((})\) result. Moreover, our algorithm necessitates \((^{2}T)\) base learners, as opposed to \(( T)\) base learners in two-layer structures. Whether it is possible to achieve the optimal results for all kinds of functions (strongly convex, exp-concave, convex) using a two-layer algorithm remains as an important problem for future investigation.