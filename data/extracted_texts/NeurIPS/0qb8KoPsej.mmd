# Accelerating Matroid Optimization through Fast Imprecise Oracles

Franziska Eberle

Technical University of Berlin

Germany

f.eberle@tu-berlin.de &Felix Hommelsheim

University of Bremen

Germany

fhomnels@uni-bremen.de &Alexander Lindermayr

University of Bremen

Germany

linderal@uni-bremen.de &Zhenwei Liu

University of Bremen

Germany

zhenwei@uni-bremen.de &Nicole Megow

University of Bremen

Germany

nmegow@uni-bremen.de &Jens Schloter

Centrum Wiskunde & Informatica

The Netherlands

jens.schloter@cwi.nl

###### Abstract

Querying complex models for precise information (e.g. traffic models, database systems, large ML models) often entails intense computations and results in long response times. Thus, weaker models that give imprecise results quickly can be advantageous, provided inaccuracies can be resolved using few queries to a stronger model. In the fundamental problem of computing a maximum-weight basis of a matroid, a well-known generalization of many combinatorial optimization problems, algorithms have access to a _clean_ oracle to query matroid information. We additionally equip algorithms with a fast but _dirty_ oracle. We design and analyze practical algorithms that only use few clean queries w.r.t. the quality of the dirty oracle, while maintaining robustness against arbitrarily poor dirty oracles, approaching the performance of classic algorithms for the given problem. Notably, we prove that our algorithms are, in many respects, best-possible. Further, we outline extensions to other matroid oracle types, non-free dirty oracles and other matroid problems.

## 1 Introduction

We study the power of a _two-oracle_ model  for fundamental _matroid_ optimization problems, which generalize many problems in combinatorial optimization.

The two-oracle model is an emerging technique for augmenting a problem where algorithms access information via _oracles_. The idea is to abstract from subroutines, such as Neuronal Network (NN) inference or graph algorithms, which compute required information from underlying models. Already today the size of such models can be arbitrarily large, and they are expected to grow further in the near future. Thus, computing _precise_ results for each oracle query can be (too) expensive. To mitigate these costs, we assume to have access to a second oracle that is _less expensive_ but gives _possibly imprecise_ answers. Such an oracle can be an efficient heuristic or a smaller NN. The goal is to leverage this fast _dirty_ oracle to obtain enough information in order to query the expensive _clean_ oracle as little as possible. This model has been successfully applied to, e.g., clustering , sorting , priority queues , or data labeling .

We study this model in the context of matroid optimization. Matroids play a central and unifying role in combinatorial optimization as numerous classic problems can be framed as matroid basis problems, e.g., problems in resource allocation and network design. A _matroid_\(=(E,)\) is adownward-closed set system with a certain augmentation property. It is represented by a ground set \(E\) of elements and a family \( 2^{E}\) of _independent_ sets. A _basis_ is an inclusion-wise maximal independent set, and all bases of a matroid have the same size, which is the _rank_ of the matroid; we give formal definitions later. A prominent matroid is the _graphic_ matroid in which, given an undirected graph, every subset of edges that induces an acyclic subgraph is independent.

Since \(||\) can be exponential in \(n:=|E|\), algorithms operating on matroids are given access to oracles. The _independence oracle_ answers for a query \(S E\) whether \(S\). Given a weight \(w_{e} 0\) for every \(e E\), a classic goal in matroid optimization is to find a basis of \(\) of maximum total weight. In his seminal work, Edmonds  showed that the _greedy algorithm_, which greedily adds elements in order of non-increasing weight, solves this problem using an optimal number of \(n\) oracle calls, and, vice versa, that matroids are the most general downward-closed set systems for which this algorithm is correct. For graphic matroids, this greedy algorithm corresponds to the classic algorithm of Kruskal  for computing a minimum-weight spanning tree in an edge-weighted graph, which is commonly taught in undergraduate algorithm classes.

To motivate the two-oracle model for matroid optimization, we continue with the special case of computing a minimum spanning tree in a large network. This problem arises, e.g., to ensure connectivity in a telecommunication network or as a subroutine to approximate a cheap tour between certain points of interest in a road network. Here, the elements \(E\) correspond to the edges of the network. The clean oracle for this graphic matroid has to decide whether a set of edges is cycle-free. While this is doable in time linear in the query size, it can be prohibitively expensive for huge queries. However, there are several ways to design a dirty oracle of reasonable quality:

* Networks, especially telecommunication networks, often evolve over time. In this case, the dirty oracle could quickly return cached results of the previous (now outdated) network.
* If the network is clustered into many highly connected components that are only loosely connected to each other, such as road networks are clustered around big cities, the dirty oracle can check the query for each (city) component individually. Since there may only be few highways between the cities, this can be quite close to the clean answer.
* The dirty oracle could operate in a sparsified subnetwork, e.g., by restricting it to only major roads or data links.

We initiate the study of the following two-oracle model for general matroid problems: In addition to the clean oracle of a given matroid \(=(E,)\), an algorithm has access to a fast dirty oracle. For simplicity, we assume that this oracle belongs to a matroid \(_{d}=(E,_{d})\) and answers for a query \(S\) whether \(S_{d}\). In fact, the former assumption is not necessary, and we will adapt our results to weaker dirty-oracle variants such as arbitrary downward-closed set systems. We emphasize that the algorithm has no knowledge about the relationship between the dirty oracle and the true matroid \(\). Finally, we assume for now that calling the dirty oracle is free and discuss mitigations later. Since calling the dirty oracle is free, our goal is to minimize the number of clean-oracle calls required to solve the underlying matroid problem.

Our work neatly aligns with the celebrated framework of _learning-augmented algorithms_, which is receiving tremendous attention . Here, an algorithm has access to a problem-specific _prediction_ and yields a good performance when the prediction is accurate (_consistency_) and does not perform too bad when given arbitrary predictions (_robustness_). Ideally, the performance degrades gracefully with the prediction's quality, measured by an _error_ function (_smoothness_). The type of performance thereby depends on the problem, and could be, e.g., a quality guarantee of the computed solution of an optimization problem, or the running time of an algorithm. The latter is intricately related to the goal of the two-oracle model: the overall running time highly depends on the number of clean-oracle calls. From this perspective, the _consistency_ of an algorithm in the two-oracle model is the worst-case number of clean-oracle calls it uses when the dirty oracle is perfect, i.e., \(=_{d}\), while the _robustness_ is the worst-case number of clean oracles independent of the quality of the dirty oracle.

More generally, we can interpret algorithms for one model also in the other model and vice versa: On the one hand, our two-oracle model fits into the learning-augmented algorithm framework by considering an optimal solution w.r.t. the dirty oracle as a possibly imprecisely predicted solution. On the other hand, a predicted solution \(B_{d} E\) can be used to construct the dirty oracle \(_{d}=(E,2^{B_{d}})\). Thus, our main results are also applicable in the learning-augmented setting.

### Our results

In this paper, we design optimal algorithms in the two-oracle model for the problem of finding a maximum-weight basis (defined later) of a matroid.

1. **Two-oracle algorithms:** For any integer \(k 1\), there is an algorithm which computes a maximum-weight basis of a matroid \(\) using at most \[\{n-r+k+_{A}(k+1)+_{R}(k+1)_{2}r_{d},(1+)n\}\] many oracle calls to \(\) (see Theorem 3.8).

Here, \(r\) is the rank of the matroid, i.e., the size of any basis, and \(r_{d}\) the rank of \(_{d}\). In terms of learning-augmented algorithms, our algorithm has a consistency of at most \(n-r+k\) and a robustness of at most \((1+)n\). Moreover, the bound of our algorithm smoothly degrades w.r.t. the quality of the dirty oracle, measured by our error measures \(_{A}\) and \(_{R}\) (the _prediction errors_). Intuitively, \(_{A}\) and \(_{R}\) denote the number of elements that have to be added to and removed from a maximum-weight basis of \(_{d}\), respectively, to reach a maximum-weight clean basis; we give a formal definition later. Our algorithm has a tuning parameter \(k\) to regulate the level of robustness against a dirty oracle of bad quality; a beneficial feature when the quality of the dirty oracle can be roughly estimated. In Section 2, we present slightly improved bounds for the case of unit weights.

Observe that, given a dirty oracle of reasonable quality, our algorithm significantly improves upon the greedy algorithm whenever the rank \(r\) is not too small (due to the dependence on \(n-r\)), which is always the case for, e.g., graphic matroids in sparse networks like road or telecommunication networks. We further show that this dependence is best possible for any deterministic algorithm for _any_ rank \(r\). Moreover, our algorithm is optimal w.r.t. to the dependence on \(_{A}\) and \(_{R}\):

1. **Tight lower bounds:** For every rank \(r\), every deterministic algorithm requires at least \(n-r+_{A}\) and at least \(n-r+_{R}_{2}r_{d}\) clean-oracle calls to compute a basis of a matroid (Appendix B).

Yet we present an algorithm which bypasses the dependence on \(n-r\) by leveraging the slightly more powerful clean rank oracle (see Section 4.1 for the definition). Note that any algorithm requires at least \(n\) clean rank oracle calls in the traditional setting for this problem in the worst case.

1. **Rank oracles:** There is an algorithm which computes a basis of a matroid \(\) using at most \(2+_{A}_{2}(n-r_{d})+_{R}_{2}r_{d}\) and at most \(n+1\) calls to the rank oracle of \(\) (Section 4.1).

Finally, we initiate the study of extensions, with which we hope to foster future research.

1. **Costly oracles:** In this model, every dirty-oracle call incurs cost 1, and every clean-oracle call costs \(p>1\). We are interested in minimizing the total cost. We illustrate that this model requires new algorithmic techniques compared to our main setting (see Section 4.2).
2. **Matroid intersection:** We give two different approaches on how our techniques can be incorporated in textbook algorithms for reducing the number of clean-oracle calls in the fundamental matroid intersection problem using dirty oracles (see Section 4.3).

All omitted proofs are deferred to the appendix.

### Further related work

Noisy oracles, two-oracle model, imprecise predictions.Optimization in the presence of imprecise oracles is a fundamental problem and has been studied extensively, also for submodular optimization [25; 26; 27; 28; 35], which is connected to matroid optimization via the submodularity of rank functions. The majority of previous work assumes access only to a _single noisy_ oracle, where the noise usually is of stochastic nature. Only recently, a two-oracle model as in our work has been studied from a theoretical perspective. Bai and Coester  consider sorting with a clean and a dirty comparison operator. They minimize the number of clean-comparison-operator calls and give guarantees that smoothly degrade with the number of wrong dirty-comparison answers. Similar strong and weak oracles have also been considered by Bateni et al.  for the Minimum SpanningTree problem and clustering, and by Benomar and Coester  in the context of priority queues. In contrast to our model, they consider oracles for accessing the distance between two points and not for deciding cycle freeness (graphic matroid). Besides these explicit results on two-oracle models, explorable uncertainty with predictions [20; 21] can also be interpreted as such a model.

**Two- and multistage problems.** All algorithms presented in this paper also solve the following two-stage problem: Given a maximum-weight basis \(B_{d}\) for a first-stage matroid \(_{d}\) (dirty matroid), compute a maximum-weight basis \(B\) for a second stage matroid \(\) (clean matroid) with minimum \(|B_{d} B|\), where \(B_{d} B\) denotes the symmetric difference of \(B_{d}\) and \(B\), and minimize the number of oracle calls to \(\). Two- (or multi-) stage problems of this type have been studied extensively, mostly for graph problems [2; 3; 12; 13; 19; 22; 23; 33] but also for matroids [8; 9; 14; 24]. Most of these works consider a combined objective optimizing the quality of the second stage solution _and_ the distance between the first- and second-stage solutions. In contrast, we insist on an optimal second-stage solution and minimize the number of clean-oracle calls. Furthermore, to our knowledge, all previous work on matroid problems in these models assumes that the matroid stays the same for all stages but the weights of the elements change, whereas we assume the opposite. Blikstad et al.  consider the somewhat similar problem of dynamically maintaining a basis of a matroid, but in a different oracle model.

### Preliminaries

Matroids.A _matroid_\(\) is a tuple \((E,)\) consisting of a finite ground set \(E\) of \(n\) elements and a family of _independent sets_\( 2^{E}\) with \(\) that satisfy the following properties: (i) \(\) is downward-closed, i.e., \(A\) implies \(B\) for all \(B A\) and (ii) if \(A,B\) with \(|A|>|B|\), then there exists \(a A B\) s.t. \(B+a\). (We write \(X+e\) when we add \(e E X\) to \(X E\) and \(X-e\) when we remove \(e X\) from \(X E\).) An important notion _are bases_, which are the (inclusion-wise) maximal elements of \(\); for a fixed matroid, we denote the set of bases by \(\). For a dirty matroid \(_{d}\), we refer to the set of bases by \(_{d}\). A _circuit_ is a minimal dependent set of elements. The main results of this paper consider the problem of finding a maximum-weight basis, i.e., given matroid \(=(E,)\) and weights \(w_{e}\) for all \(e E\), the goal is to find a basis \(B\) maximizing \(_{e B}w_{e}\). The _greedy algorithm_ solves this problem by iteratively adding elements in non-increasing order of their weight to the solution if possible, i.e., if the solution stays independent in \(\). Given a weighted ground set, we always assume that the elements of \(E=\{e_{1},,e_{n}\}\) are indexed according to the weight order, i.e., \(i j\) implies \(w_{e_{i}} w_{e_{j}}\), with ties broken arbitrarily. Given that, for any \(i\) and \(S E\) we define \(S_{ i}=\{e_{j} S j i\}\) (\(S_{ i}\) analogously).

**Requirements on algorithms and optimal solutions.** For all considered problems, we require algorithms to execute clean queries (oracle calls) until the answers to these queries reveal sufficient information to solve the given problem, e.g., find a maximum-weight basis for the clean matroid. More precisely, the queries executed by the algorithm together with the answers must be a _certificate_ that a third party with only access to the clean matroid and without any additional knowledge can use in order to find a provable solution. In particular, an optimal algorithm that knows the answers to all clean queries upfront has to execute queries in order to satisfy the certificate requirement.

We refer to the _robustness_ of an algorithm, when bounding the maximum number of clean-oracle calls the algorithm needs for any input instance, independently of the quality of the dirty oracle.

**Definition of our error measure.** We define an error measure that quantifies the quality of the dirty oracle w.r.t. the clean oracle. We define the error measure for the case that the dirty oracle is a matroid and describe in the next section how this extends to arbitrary downward-closed set systems. Let \(^{*}\) be the set of maximum-weight bases of \(\) and \(^{*}_{d}\) be the set of maximum-weight bases of \(_{d}\). (In the unweighted case, \(^{*}=\) and \(^{*}_{d}=_{d}\).) We first define for every \(S^{*}_{d}\) the sets \(A(S),R(S)\) as any cardinality-wise smallest set \(A E S\) and \(R S\), respectively, such that \(S A B\) and \(S R B^{}\) for some \(B,B^{}^{*}\).

These sets describe the smallest number of additions/removals necessary to transform \(S\) into a superset/subset of some maximum-weight basis of \(\). We call \(|A(S)|+|R(S)|\) the _modification distance_ from \(S\) to \(^{*}\). Our final error measure is defined as the largest modification distance of any maximum-weight basis of \(_{d}\), that is, \(_{A}=_{S^{*}_{d}}|A(S)|\) and \(_{R}=_{S^{*}_{d}}|R(S)|\).

Assume both oracles are matroids. It follows from standard matroid properties that, for any dirty basis \(B_{d}\), there are modification sets \(A,R\) with \(|A|=|A(B_{d})|,|R|=|R(B_{d})|\) and \(B_{d} R A\)Hence \(r=r_{d}+_{A}-_{R}\). Also, for all \(S_{1},S_{2}_{d}\), \(|A(S_{1})||A(S_{2})|\) if and only if \(|R(S_{1})||R(S_{2})|\).

### Discussion of the model

Computing a dirty basis upfront.For all our results on computing a (maximum-weight) basis, it suffices to first compute a (maximum-weight) dirty basis and afterwards switch to exclusively using the clean oracle. A similar observation can be made for the results of Bai and Coester  on sorting, where it would be possible to initially compute a tournament graph for the dirty comparator and afterwards switch to only using the clean comparator without increasing the number of clean-comparator calls. In Section 4, we observe that separating the usage of the dirty and clean oracles in this way does not work anymore if dirty-oracle calls also incur costs.

Counting wrong answers as error measure.Bai and Coester  use the number of wrong dirty-comparator answers as error measure. While this is a meaningful error measure for sorting, a similar error measure for our problem does not seem to accurately capture the quality of the dirty oracle. Consider an instance with unit weights, where we have \(_{d}\). This can lead to an exponential number of wrong dirty oracle answers, but the dirty oracle still allows us to compute a clean basis. For this reason, we use the modification distance as error measure instead.

Relaxing requirements on the dirty oracle.We illustrate how to extend the error definition of Section 1.3 to arbitrary downward-closed set systems in the unweighted case: For every _inclusion-wise maximal set_\(S\) of the dirty oracle we compute \(A(S)\) and \(R(S)\) as before. The addition and removal error are then defined analogously by replacing \(_{d}^{*}\) with the set of all inclusion-wise maximal independent sets (instead of all maximum sets in the unweighted case). Then, all our results in this paper also carry over to this more general setting. Using an error definition with respect to some greedy algorithm on weighted downward-closed set systems, one can also obtain the same result for arbitrary _weighted_ downward-closed set systems. However, for clarity, we only prove our statements for the case that the dirty oracle is a matroid.

### Organization of the paper

We begin in Section 2 with a gentle introduction to our techniques and algorithms by studying the simpler problem of computing any basis of a matroid. Then, we extend these ideas in Section 3 and present our main algorithmic results. Finally, in Section 4, we demonstrate how to generalize and adapt our approach to other settings and problems. Many proofs for these sections are deferred to the appendix. In Appendix B, we also included a detailed section on our lower bounds.

## 2 Warm-up: computing an unweighted basis

The goal of this section is to give a gentle introduction to our algorithmic methods, which we extend in the next sections. Consider the basic problem of finding any basis of a matroid. Note that without the dirty oracle, we need exactly \(n\) clean-oracle calls to find and verify any basis in the worst-case.

In the following, we assume that we are given an arbitrary basis \(B_{d}\) of the dirty matroid \(_{d}\), which can be computed without any call to the clean oracle. We first analyze the so-called _simple algorithm_: If \(B_{d}\), we set \(B\) to \(B_{d}\). Otherwise, we set \(B\) to the empty set. Next, for each element \(e E B\), we add it to \(B\) if \(B+e\) and output \(B\) at the end.

The idea of the simple algorithm is to only use the dirty basis \(B_{d}\) if it is independent in the clean matroid, as we then can easily augment it to a clean basis. Otherwise, we abandon it and effectively run the classic greedy algorithm. Formalizing this sketch proves the following lemma.

**Lemma 2.1**.: _The simple algorithm computes a clean basis using at most \(n+1\) clean-oracle calls. Further, if \(B_{d}\), it terminates using at most \(n-r+1\) clean-oracle calls._

Surprisingly, in Appendix B, we will see that this simple algorithm achieves a best-possible trade-off between optimizing the cases \(B_{d}\) and \(B_{d}\) at the same time.

### An error-dependent algorithm

The simple algorithm discards the dirty basis \(B_{d}\) if it is not independent in \(\). This approach may be wasteful, especially if removing just one element from \(B_{d}\), such as in the case of a circuit, leads to independence. This seems particularly drastic if the clean and dirty oracle are relatively "close", i.e., the error measured by the modification distance is small. This suggests a refinement with a more careful treatment of the dirty basis \(B_{d}\). We propose a binary search strategy to remove elements from \(B_{d}\) until it becomes independent. A key feature is that this allows for an error-dependent performance guarantee bounding the number of clean-oracle calls by \(_{A}\) and \(_{R}\), the smallest numbers of elements to be added and removed to turn a dirty basis into a basis of the clean matroid.

We define the _error-dependent algorithm_: First, set \(B\) to \(B_{d}\) and fix an order of the elements in \(B\). Repeatedly use binary search to find the smallest index \(i\) s.t. \(B_{ i}\) and remove \(e_{i}\) from \(B\) until \(B\). Then add each element \(e E B_{d}\) to \(B\) if \(B+e\) and output the final set \(B\).

**Lemma 2.2**.: _The error-dependent algorithm computes a clean basis using at most \(n-r+1+_{A}+_{R}_{2}r_{d}\) clean-oracle calls._

Proof.: The algorithm simulates finding a maximal independent subset of \(B_{d}\) w.r.t. the clean matroid, and augments the resulting set to a clean basis. Hence, the correctness follows from matroid properties. We remove \(|R(B_{d})|_{R}\) elements from \(B_{d}\). Hence, the removal loop is executed \(|R(B_{d})|\) times. In each iteration, we use at most \(1+_{2}r_{d}\) clean queries (one for checking \(B\) and at most \(_{2}r_{d}\) for the binary search). Thus, the removing process uses at most \(|R(B_{d})|(1+_{2}r_{d})\) clean queries. Augmenting \(B\) uses \(n-r_{d}\) clean queries. Combined, our algorithm uses at most \(|R(B_{d})|(1+_{2}r_{d})+n-r_{d}+1\) oracle calls. We conclude using \(|R(B_{d})|_{R}\) and \(r=r_{d}-_{R}+_{A}\). 

### An error-dependent and robust algorithm

The error-dependent algorithm has a good bound on the number of clean-oracle calls (less than \(n\)) when \(_{A}\) and \(_{R}\) are small. However, in terms of _robustness_--i.e., the maximum number of oracle calls for any instance, regardless of the dirty-oracle quality--this algorithm performs asymptotically worse than the gold standard \(n\), achieved by the classic greedy algorithm. This is the case when the dirty basis is equal to \(E\), but the clean matroid is empty: the error-dependent algorithm executes \(n\) binary searches over narrowing intervals, using \(_{2}(n!)(n n)\) clean-oracle calls. By looking closer at the error-dependent algorithm, the special structure of this example can be explained because queries charged to \(n-r+_{A}\) are essentially also done by the greedy algorithm. Hence, they are in a sense already robust. Motivated by the greedy algorithm, another extreme variant of the removal process would be to go linearly through \(B_{d}\) and greedily remove elements. This gives an optimal robustness, but is clearly bad if \(_{R}\) is small.

For our main result in the unweighted setting, we combine both extremes into a robustification framework and achieve a trade-off using the following key observation. If we have to remove many elements (\(_{R}\) is large), some elements must be close to each other. In particular, if the next removal is close to the last one (in terms of the fixed total order), a linear search costs less than a binary search. Based on this, after a removal, we first check the next \(((r_{d}))\) elements of \(B_{d}\) linearly for other removals before executing a binary search. This bounds the number of binary searches by \((}{(r_{d})})\), each incurring a cost of \(_{2}(r_{d})\). However, the linear search also incurs some cost. Thus, we further parameterize this idea (see Algorithm 3), and obtain the following main result.

**Theorem 2.3**.: _For every \(k_{+}\), there is an algorithm that, given a dirty matroid \(_{d}\) of rank \(r_{d}\) with unknown \(_{A}\) and \(_{R}\), computes a basis of a matroid \(\) of rank \(r\) with at most \(\{n-r+k+_{A}+_{R}(k+1)_{2}r_{d},(1+)n\}\) oracle calls to \(\)._

## 3 Computing a maximum-weight basis

Consider the weighted setting. Recall that \(_{d}^{*}\) and \(^{*}\) denote the sets of maximum-weight bases of the dirty and clean matroid, respectively. We assume that we are given a maximum-weight basis \(B_{d}_{d}^{*}\), which can be computed without any clean-oracle calls. The main difficulty compared to the unweighted setting is as follows: In the unweighted setting, the error-dependent algorithm firstcomputes an _arbitrary_ maximal independent set \(B^{} B_{d}\) and then easily augments \(B^{}\) to a clean basis. In the weighted setting, however, there clearly can be independent sets \(B^{} B_{d}\) that are not part of any maximum-weight basis; hence we need to be more careful. Finding such a special independent subset of \(B_{d}\) only by removing elements from \(B_{d}\) and testing its independence seems difficult: \(B_{d}\) itself could be independent, but not part of any maximum-weight basis. However, even in this case, \(B_{d}\) can be very close to a maximum-weight basis w.r.t. \(_{A}\) and \(_{R}\). Therefore, we cannot avoid carefully modifying \(B_{d}\) since strategies like the greedy algorithm would use too many queries.

Thus, we alternatingly add and remove elements to and from \(B_{d}\). Intuitively, we want to ensure, as the greedy algorithm, that we do not miss adding elements with large weight. Thus, we try to add them as soon as possible. However, even if they are part of every basis in \(^{*}\), this might result in a _dependent_ current solution unless we now remove elements, which were not detectable before. An example of such a situation is given in Figure 1. This observation rules out simple two-stage algorithms as used in the unweighted case.

We now present our algorithm. Its full description is shown in Algorithm 1. Given elements \(E=\{e_{1},,e_{n}\}\) in non-decreasing order of their weight, it maintains a preliminary solution, which initially is set to the dirty basis \(B_{d}\). It modifies this solution over \(n\) iterations and tracks modifications in the variable sets \(A E B_{d}\) (_added_ elements) and \(R B_{d}\) (_removed_ elements). In every iteration \(\), the algorithm selects elements to add and remove such that _at the end_ of iteration \(\) its preliminary solution \((B_{d} R) A\) satisfies two properties, which we define and motivate now.

Property \((i)\) requires that the preliminary solution \((B_{d} R) A\) up to \(e_{}\) should be a _maximal_ subset of some maximum-weight basis. For the sake of convenience, we introduce the matroid \(^{*}=(E,^{*})\), where \(^{*}\) is the set of all subsets of \(^{*}\). Then, we can use the following definition.

**Definition 3.1**.: A set \(S\) is \(k\)-_safe_ if \(S_{ k}^{*}\) and for every \(e E_{ k} S_{ k}\) it holds that \(S_{ k}+e^{*}\).

In other words, a set \(S\) is \(k\)-safe if it is a basis of the truncated matroid of the \(k\)th prefix of \(E\). Using this definition, Property \((i)\) requires that at the end of iteration \(\), the current solution \((B_{d} R) A\) is \(\)-safe. Establishing this property in every iteration will give us that the final solution is \(n\)-safe, and, thus, a maximum-weight basis of \(\). This works because the algorithm does not modify its solution for the \(\)th prefix of \(E\) after the \(\)th iteration.

To establish Property \((i)\) after every iteration without using too many clean queries, it also maintains Property \((ii)\): at the end of every iteration the current solution is independent, i.e., \((B_{d} R) A\).

We now give some intuition on how our algorithm achieves this. Initially, say for \(=0\), before Line 2 Property \((i)\) is fulfilled trivially. For Property \((ii)\), before Line 5 the algorithm greedily adds minimum-weight elements of \(B_{d}\) to \(R\) that close a circuit in the smallest prefix of \((B_{d} R) A\) (Lines 2-4). This subroutine can be implemented via binary search. To guarantee both properties at the end of iteration \(\), first observe that Property \((ii)\) holds as long as \(A\) and \(R\) have not changed in this iteration. However, this might be necessary to establish Property \((i)\). Intuitively, our algorithm wants to act like the classic greedy algorithm to ensure \(\)-safeness. Thus, it checks whether \(e_{}\) should be in the solution by considering its solution for \(E_{}\). Clearly, if \(e_{} B_{d} R\) or \(e_{} R\), there is nothing to modify (Line 6), because the current solution is independent due to Property \((ii)\) for the previous iteration. Similarly, if \(e_{} B_{d}\) and the current solution for \(E_{}\) together with \(e_{}\) is independent, we add \(e_{}\) to our solution (Lines 6-7). However, by adding an element, Property \((ii)\) can become false due to an introduced circuit, which we have to break (Lines 8-10). Finally, there might be the situation that \(e_{} B_{d}\) has been added to \(R\) in an earlier iteration, so \(e_{} R\). In this

Figure 1: A matroid with elements \(e_{1},,e_{9}\) (displayed as circles) ordered left-to-right by non-increasing weight. The elements of the maximum-weight dirty basis \(B_{d}\) are filled.

case, we clearly do not want to even consider adding \(e_{}\) again, as queries for verifying this addition cannot be bounded by our error measure. Indeed, removing and re-adding an element cannot be part of any minimal modification distance. Thus, our algorithm skips such elements (Line 6). To justify this, we prove that removing element \(e_{}\) is always necessary, in the sense that there always is a circuit that \(e_{}\) breaks and that cannot be broken by removing elements in _later_ iterations by Lines 8-10. This follows from classic matroid properties for circuits. Formally, we prove in Appendix C:

**Lemma 3.2** (Property (ii)).: _At the start (end) of each iteration of Line 5, it holds \((B_{d} R) A\)._

**Lemma 3.3** (Property (i)).: _At the end of every iteration \(\) of Line 5, \((B_{d} R) A\) is \(\)-safe._

Since there are at most \(n\) elements in \(R\), the algorithm clearly terminates, and we conclude as follows.

**Corollary 3.4**.: _Algorithm 1 terminates with an \(n\)-safe set._

It remains to bound the number of clean queries. Fix \(A\) and \(R\) to their final sets. Assume that elements are non-increasingly ordered by their weight; among elements of _equal weight_, elements of \(B_{d}\) come _before_ elements of \(E B_{d}\). For such an ordering, the algorithm modifies \(B_{d}\) to a closest basis of \(^{*}\).

**Lemma 3.5**.: _It holds that \(|A|_{A}\) and \(|R|_{R}\)._

To conclude, we use a charging scheme and Lemma 3.5 to derive the following bound; for details, we refer to Appendix C.

**Lemma 3.6**.: _Algorithm 1 computes a max-weight basis with at most \(n-r+1+2_{A}+_{R}_{2}(r_{d})\) clean queries._

We complement this algorithmic result by a lower bound. It proves that our error-dependent guarantees in the unweighted case are not possible in the weighted case. Hence, it separates both settings.

**Lemma 3.7**.: _Every deterministic algorithm for finding a maximum-weight basis executes strictly more than \(n-r+_{A}+_{R}_{2}(r_{d})+1\) clean-oracle calls in the worst-case._

Application of the robustification framework.As in the unweighted case, our algorithm may perform poorly when the dirty oracle is of low quality, i.e., \(_{A}\) and \(_{R}\) are large. We extend the ideas for robustifying the error-dependent algorithm (cf. Section 2.2) and combine them with the concepts developed above. The key idea for robustifying Algorithm 1 is to start a binary search only after a sufficient number of linear search steps. However, as observed above (cf. Figure 1), we cannot remove all blocking elements in one iteration. While the simple argument that the linear search partitions \(B_{d}\) still holds, it does not cover the total removal cost, because a later addition can create a removal at a previously checked position. To overcome this, we observe that in Algorithm 1, immediate removal of every detected element from the current solution is not necessary; we just need to decide whether in iteration \(\) element \(e_{}\) should be part of the solution.

In our robustified algorithm (Algorithm 2) we exploit this as follows. While in Algorithm 1 we linearly check prefixes of \(E B_{d}\) for additions, we now linearly check prefixes of \(E\) for additions (Lines 4-5) _and_ removals (Lines 6-8). However, for the sake of a good error-dependency, we count these removal checks (cf. increment counter \(q\) in Line 7) and execute a binary search only if we checked enough elements in \(B_{d}\) linearly (Lines 10-12). Then, we can again bound the total cost for the binary searches using a density argument. Whenever we remove an element, we charge the previous cost of the linear searches to this removal error and reset \(q\), which re-activates the linear search. However, if the current solution is already independent, we do not want to search for removal errors at all (cf. Lines 2 and 8 in Algorithm 1). Unfortunately, doing such a check after every addition and removal already rules out a robustness close to \(n\). Thus, we slightly delay this check w.r.t. the counter \(q\), and stop the removal search accordingly (Line 9). Finally, whenever an element is added, we make sure that the linear search is running or that we start it again (Line 5), as a new circuit could have been introduced in our solution. Formalizing this sketch proves our main theorem.

``` Input: dirty basis \(B_{d}\), matroid \((E,)\), integer \(k 1\)
1\(A;R\); \(d_{}_{e_{i} B_{d}}i\)
2\(q 0;\) {linear search counter / flag}
3for\(=1\) to \(n\)do
4if\(e_{} B_{d}\)then
5if\(((B_{d} R) A+e_{})_{}\)then\(A A+e_{}\) and \(\)
6elseif\(e_{} B_{d} R\) and \(=\)then
7\(q q+1\)
8if\(((B_{d} R) A)_{}\)then\(R R+e_{}\) and \(q 0\)
9if\(=d_{}\) or (\(q=k-1\) and \((B_{d} R) A\))then\(q 0\) and \(\)
10elseif\(q=k_{2}r_{d}\)then
11 Find the smallest index \(i\) s.t. \(((B_{d} R) A)_{ i}\) via binary search
12\(R R+e_{i}\) and \(q 0\)
13
14return\((B_{d} R) A\) ```

**Algorithm 2**Find a maximum-weight basis (robustified)

**Theorem 3.8**.: _For any \(k_{+}\), there is an algorithm that, given a dirty matroid \(_{d}\) of rank \(r_{d}\) with unknown \(_{A}\) and \(_{R}\), computes a maximum-weight basis of a matroid \(\) of rank \(r\) with at most \(\{n-r+k+_{A}(k+1)+_{R}(k+1)_{2}r_{d},(1+ )n\}\) oracle calls to \(\)._

## 4 Extensions and future work

### Rank oracles

Another common type of matroid oracles is the rank oracle: Given any \(S E\), a rank oracle returns the cardinality of a maximum independent set contained in \(S\), denoted by \(r(S)\). Since \(r(S)=|S|\) if and only if \(S\), our algorithmic results for independence oracles directly transfer. Moreover, for the unweighted setting, we can even reduce the number of oracle calls using a rank oracle, implying that some lower bounds do not translate. For example, given \(B_{d}\) we can compute its rank \(r(B_{d})\) to obtain \(_{R}=|B_{d}|-r(B_{d})\) and decide whether to remove elements via binary search or immediately switch to the greedy algorithm. Further, we can improve the dependency on \(_{A}\) if \(_{A}\) is small as we can find the elements to be added via a binary search. Hence, we get the following result.

**Proposition 4.1**.: _There is an algorithm that computes a clean basis with at most \(\{n+1,\,2+_{R}_{2}r_{d}+\{_{A }_{2}(n-r_{d}),\,n-r_{d}\}\}\) clean rank-oracle calls._

The full discussion on rank oracles can be found in the appendix. For future work it would be interesting to see if the error-dependency and the worst-case bound can be improved, and if rank oracles can be used to improve the results for the weighted setting.

### Dirty independence oracle with cost

We consider the generalized setting where a dirty-oracle call has cost 1 and a clean-oracle call has cost \(p>1\) with the objective to minimize the total cost. Lemma B.1 translates to this setting, giving a lower bound \(p(n-r+1)\). Note that the previous results assume that \(p 1\) in this setup.

The main takeaway of this generalization is that it can be beneficial for an algorithm to delay dirty-oracle calls for clean-oracle calls, depending on \(p\) and \(r\). This contrasts the previous sections, where we can meet lower bounds by computing a dirty basis upfront.

To see this, we consider two algorithms and assume for simplicity that \(_{d}=\). The first algorithm starts with \(E\) and removes elements via binary search until it reaches an independent set. It only uses clean-oracle calls of total cost \(p(n-r)_{2}(n)+p\). The second algorithm computes a dirty basis and verifies it, incurring a total cost of \(n+p(n-r+1)\), as \(_{d}=\). Thus, for small \(p\) and large \(r\), the first algorithm incurs less cost than the second algorithm, which is optimal among the class of algorithms which only initially use dirty-oracle calls. Specifically, having access to rank oracles, one can compute the value of \(r\) upfront using one clean-oracle call and, thus, select the better algorithm.

### Matroid intersection

In the _matroid intersection problem_, we are given two matroids \(^{1}=(E,^{1})\) and \(^{2}=(E,^{2})\), and we seek a maximum set of elements \(X E\) that is independent in both matroids, i.e., \(X^{1}^{2}\).

The textbook algorithm for finding such a maximum independent set is to iteratively increase the size of a solution one by one using an augmenting-path type algorithm until no further improvement is possible. This algorithm has a running time of \(O(r^{2}n)\). There are faster algorithms known for matroid intersection, which run in time \(O(nr^{3/4})\) and in time \(O(n^{1+o(1)})\) for the special case of two partition matroids . (In a _partition matroid_\(=(E,)\), the elements are partitioned into _classes_\(C_{i}\) with capacities \(k_{i}\), and a set \(S E\) is independent if and only if \(|C_{i} S| k_{i}\) holds for each \(C_{i}\).) Here, we focus on improving the running time of the simple textbook algorithm by (i) using dirty oracles calls in each of the augmentation steps and (ii) by computing a warm-start solution using an optimal dirty solution, i.e., a feasible solution of a certain size dependent on the error.

**Matroid intersection via augmenting paths.** Our error measure is as follows: We define \(_{1}=\{F^{1}_{d}\ |\ F^{1}\}\) and \(_{2}=\{F^{2}_{d}\ |\ F^{2}\}\) to be the number of different sets which are independent in the dirty matroid but not independent in the clean matroid. In order to simplify the setting, we assume here that (i) the dirty matroids are supersets of the clean matroids, i.e., \(^{1}^{1}_{d}\) and \(^{2}^{2}_{d}\), and (ii) that the clean matroids are partition matroids. We note that in general the intersection of two partition matroids can be reduced to finding a maximum \(b\)-matching.

**Proposition 4.2**.: _There is an algorithm that computes an optimum solution for matroid intersection using at most \((r+1)(2+(_{1}+_{2})(_{2}(n)+2))\) clean-oracle calls._

**Matroid intersection via warm-starting.** We show how to exploit the dirty matroids to obtain a good starting solution that is independent in both clean matroids. The idea of warm-starting using predictions has been used for other prediction models in  for problems like weighted bipartite matching or weighted matroid intersection. These results are tailored to the weighted setting and do not directly translate to improvements in the unweighted case. As error measure we adjust the removal error for matroid intersection: Let \(s^{*}_{d}=_{S_{d}^{1}_{d}^{2}_{d}\ |S_{d}|}\) and define \(^{*}_{d}=\{S_{d}^{1}_{d}^{2}_{d}\ |\ |S_{d}|=s^{*}_{d}\}\) to be the set of optimum solutions to the dirty matroid intersection problem. We define \(_{r}=_{S_{d}^{*}_{d}}_{S_{c}^{1} ^{2}}\{|S_{d} S_{c}|:S_{c} S_{d}\}\).

Our algorithm computes an optimal solution to the dirty matroid, then greedily removes elements until we obtain a feasible solution for the clean matroid. By observing that this reverse greedy algorithm is a \(2\)-approximation in the number of elements to be removed, \(_{r}\), we obtain the following result.

**Proposition 4.3**.: _There is an algorithm that computes a feasible solution \(S^{}_{c}^{1}^{2}\) of size \(|S^{}_{c}| s^{*}_{d}-2_{r}\) using at most \(2+2_{r}(1+_{2}(n))\) clean-oracle calls._