# Localized Adaptive Risk Control

Matteo Zecchin Osvaldo Simeone

Centre for Intelligent Information Processing Systems

Department of Engineering

King's College London

London, United Kingdom

{matteo.1.zecchin,osvaldo.simeone}@kcl.ac.uk

###### Abstract

Adaptive Risk Control (ARC) is an online calibration strategy based on set prediction that offers worst-case deterministic long-term risk control, as well as statistical marginal coverage guarantees. ARC adjusts the size of the prediction set by varying a single scalar threshold based on feedback from past decisions. In this work, we introduce Localized Adaptive Risk Control (L-ARC), an online calibration scheme that targets statistical localized risk guarantees ranging from conditional risk to marginal risk, while preserving the worst-case performance of ARC. L-ARC updates a threshold function within a reproducing kernel Hilbert space (RKHS), with the kernel determining the level of localization of the statistical risk guarantee. The theoretical results highlight a trade-off between localization of the statistical risk and convergence speed to the long-term risk target. Thanks to localization, L-ARC is demonstrated via experiments to produce prediction sets with risk guarantees across different data subpopulations, significantly improving the fairness of the calibrated model for tasks such as image segmentation and beam selection in wireless networks.

## 1 Introduction

Adaptive risk control (ARC), also known as online risk control, is a powerful tool for reliable decision-making in online settings where feedback is obtained after each decision (Gibbs and Candes, 2021; Feldman et al., 2022). ARC finds applications in domains, such as finance, robotics, and health, in which it is important to ensure reliability in forecasting, optimization, or control of complex systems (Wisniewski et al., 2020; Lekeufack et al., 2023; Zhang et al., 2023; Zecchin et al., 2024). While providing worst-case deterministic guarantees of reliability, ARC may distribute such guarantees _unevenly_ in the input space, favoring a subpopulation of inputs at the detriment of another subpopulation.

As an example, consider the tumor segmentation task illustrated in Figure 1. In this setting, the objective is to calibrate a pre-trained segmentation model to generate masks that accurately identify tumor areas according to a user-defined reliability level (Yu et al., 2016). The calibration process typically involves combining data from various datasets, such as those collected from different hospitals. For an online setting, as visualized in the figure, ARC achieves the desired long-term reliability in terms of false negative ratio. However, it does so by prioritizing certain datasets, resulting in unsatisfactory performance on other data sources. Such behavior is particularly dangerous, as it may result in some subpopulations being poorly diagnosed. This paper addresses this shortcoming of ARC by proposing a novel _localized_ variant of ARC.

### Adaptive Risk Control

To elaborate, consider an online decision-making scenario in which inputs are provided sequentially to a pre-trained model. At each time step \(t 1\), the model observes a feature vector \(X_{t}\), and based on a bounded _non-conformity scoring function_\(s:[0,S_{}]\) and a threshold \(_{t}\), it outputs a prediction set

\[C_{t}=C(X_{t},_{t})=\{y:s(X_{t},y)_{t}\}, \]

where \(\) is the domain of the target variable \(Y\). After each time step \(t\), the model receives feedback in the form of a loss function

\[L_{t}=(C_{t},Y_{t}) \]

that is assumed to be non-negative, upper bounded by \(B<\) and non-increasing in the predicted set size \(|C_{t}|\). A notable example is the miscoverage loss

\[(C,y)=\{y C\}. \]

Accordingly, for an input-output sequence \(\{(X_{t},Y_{t})\}_{t=1}^{T}\) the performance of the set predictions \(\{C_{t}\}_{t=1}^{T}\) in (1) can be gauged via the cumulative risk

\[(T)=_{t=1}^{T}(C_{t},Y_{t})=_{ t=1}^{T}L_{t}. \]

For a user-specified loss level \(\) and a learning rate sequence \(\{_{t}\}_{t=1}^{T}\), ARC updates the threshold \(_{t}\) in (1) as 

\[_{t+1}=_{t}+_{t}(L_{t}-), \]

where \(L_{t}-\) measures the discrepancy between the current loss (2) and the target \(\). For step size decreasing as \(_{t}=_{1}t^{-1/2}\) for \(a(0,1)\) and an arbitrary \(_{1}>0\), the results in  imply that the update rule (5) guarantees that the cumulative risk (4) for the miscoverage loss (3) converges to target level \(\) for _any_ data sequence \(\{(X_{t},Y_{t})\}_{t 1}\) as

\[(T)-}+_{1}B}{}, \]

thus offering a worst-case deterministic long-term guarantee. Furthermore when data are generated i.i.d. as \((X_{t},Y_{t}) P_{XY}\) for all \(t 1\), in the special case of the miscoverage loss (3), the set predictor produced by (5) enjoys the asymptotic _marginal_ coverage guarantee

\[_{T}[Y C_{T}], \]

where the probability is computed with respect to the test sample \((X,Y) P_{XY}\), which is independent of the sequence of samples \(\{(X_{t},Y_{t})\}_{t=1}^{T}\), and the convergence is in probability with respect to the sequence \(\{(X_{t},Y_{t})\}_{t 1}\). Note that in , a stronger version of (7) is provided, in which the limit holds almost surely.

Figure 1: Calibration of a tumor segmentation model via ARC  and the proposed localized ARC, L-ARC. Calibration data comprises images from multiple sources, namely, the Kvasri data set  and the ETIS-LaribPolypDB data set . Both ARC and L-ARC achieve worst-case deterministic long-term risk control in terms of false negative rate (FNR). However, ARC does so by prioritizing Kvasri samples at the detriment of the Larib data source, for which the model has poor FNR performance. In contrast, L-ARC can yield uniformly satisfactory performance for both data subpopulations.

### Conditional and Localized Risk

The convergence guarantee (7) for ARC is marginalized over the covariate \(X\). Therefore, there is no guarantee that the conditional miscoverage \([Y C_{T}|X=x]\) is smaller than the target \(\). This problem is particularly relevant for high-stakes applications in which it is important to ensure a homogeneous level of reliability across different regions of the input space, such as across subpopulations. That said, even when the set predictor \(C(X|_{})\) is obtained based on an offline calibration data set \(_{}\) with i.i.d. data \((X,Y) P_{XY}\), it is generally impossible to control the conditional miscoverage probability as

\[[Y C(X|_{})|X=x]\,x \]

without making further assumptions about the distribution \(P_{XY}\) or producing uninformative prediction sets (Vovk, 2012; Foygel Barber et al., 2021).

A relaxed marginal-to-conditional guarantee was considered by Gibbs et al. (2023), which relaxed the marginal miscoverage requirement (8) as

\[_{X,Y,_{}}[_{X}[w(X )]}\{Y C(X|_{})\}]w(), \]

where \(\) is a set of non-negative reweighting functions, and the expectation is taken over the joint distribution of the calibration data \(_{}\) and the test pair \((X,Y)\). Note that with a singleton set \(\) encompassing a single constant function, e.g., \(w(x)=1\), the criterion (9) reduces to marginal coverage. Furthermore, as illustrated in Figure 2, depending on the degree of localization of the functions in set \(\), the criterion (9) interpolates between marginal and conditional guarantees.

At the one extreme, a marginal guarantee like (7) is recovered when the reweighting functions are constant. Conversely, at the other extreme, conditional guarantees as in (8) emerge when the reweighting functions are maximally localized, i.e., when \(=\{w(x)=(x-):\}\), where \((x)\) denotes the Dirac delta function. In between these two extremes, one obtains an intermediate degree of localization. For example, this can be done by considering reweighting functions such as

\[=\{w(x)\!=\!_{i=1}^{}_{i}(( -\|^{2}}{l})+1)\!:_{X}[w(X) ]>0,w(x) 0\; x\}, \]

where \(l 0\) is a fixed length scale, \( 0\) is a fixed scaling parameter, and \(\|\|\) denotes the Euclidean norm. Furthermore, function \(w(x)\) may also depend on the output of the pre-trained model, supporting calibration requirements via constraints of the form (9) (Zhang et al., 2024).

In Gibbs et al. (2023), the authors demonstrated that it is possible to design _offline_ set predictors \(C(X|_{})\) that _approximately_ control risk (9), with an approximation gap that depends on the degree of localization of the family \(\) of weighting functions.

Figure 2: The degree of localization in L-ARC is dictated by the choice of the reweighting function class \(\) via the marginal-to-conditional guarantee (9). At the leftmost extreme, we illustrate constant reweighting functions, for which marginal guarantees are recovered. At the rightmost extreme, reweighting with maximal localization given by Dirac delta functions for which the criterion (9) corresponds to a conditional guarantee. In between the two extremes lie function sets \(\) with an intermediate level of localization yielding localized guarantees.

### Localized Risk Control

Motivated by the importance of conditional risk guarantees, we propose Localized ARC (L-ARC), a novel online calibration algorithm that produces prediction sets with localized statistical risk control guarantees as in (9), while also retaining the worst-case deterministic long-term guarantees (6) of ARC. Unlike Gibbs et al. (2023), our work focuses on _online_ settings in which calibration is carried out sequentially based on feedback received on past decisions.

The key technical innovation of L-ARC lies in the way set predictions are constructed. As detailed in Section 2, L-ARC prediction sets replace the single threshold in (1) with a threshold function \(g()\) mapping covariate \(X\) to a localized threshold value \(g(X)\). The threshold function is adapted in an online fashion within a reproducing kernel Hilbert space (RKHS) family \(\) based on an input data stream and loss feedback. The choice of the RKHS family determines the family \(\) of weighting functions in the statistical guarantee of the form (9), thus dictating the desired level of localization.

The main technical results, presented in Section 2.3, are as follows.

* In the case of i.i.d. sequences, \((X_{t},Y_{t}) P_{XY}\) for all \(t 1\), L-ARC provides localized statistical risk guarantees where the reweighting class \(\) corresponds to all non-negative functions \(w\) with a positive mean under distribution \(P_{XY}\). More precisely, given a target loss value \(\), the time-averaged threshold function \[_{T}()=_{t=1}^{T}g_{t}(),\] (11) ensures that for any function \(w\), the limit \[_{T}_{X,Y}[_{X}[w(X)]} (C(X,_{T}),Y)]+A(,w)\] (12) holds, where convergence is in probability with respect to the sequence \(\{(X_{t},Y_{t})\}_{t 1}\) and the average is over the test pair \((X,Y)\). The gap \(A(,w)\) depends on both the RKHS \(\) and function \(w\); it increases with the level of localization of the functions in the RKHS \(\); and it equals zero in the case of constant threshold functions, recovering (7) for the special case of the miscoverage loss.
* Furthermore, for an arbitrary sequence \(\{(X_{t},Y_{t})\}_{t 1}\) L-ARC has a cumulative loss that converges to a neighborhood of the nominal reliability level \(\) as \[|_{t=1}^{T}(C(X_{t},g_{t}),Y_{t})-| )}{}+C(),\] (13) where \(B()\) and \(C()\) are terms that increase with the level of localization of the function in the RKHS \(\). The quantity \(C()\) equals zero in the case of constant threshold functions, recovering the guarantee (6) of ARC.

In Section 3 we showcase the superior conditional risk control properties of L-ARC as compared to ARC for the task of electricity demand forecasting, tumor segmentation, and beam selection in wireless networks.

## 2 Localized Adaptive Risk Control

### Setting

Unlike the ARC prediction set (1), L-ARC adopts prediction sets that are defined based on a threshold function \(g_{t}:\). Specifically, at each time \(t 1\) the L-ARC prediction set is obtained based on a non-conformity scoring function \(s:\) as

\[C_{t}=C(X_{t},g_{t}):=\{y:s(X_{t},y) g_{t}(X_{t})\}. \]

By (14), the threshold \(g_{t}(X_{t})\) is localized, i.e., it is selected as a function of the current input \(X_{t}\). In this paper, we consider threshold functions of the form

\[g_{t}()=f_{t}()+c_{t}, \]where \(c_{t}\) is a constant and function \(f_{t}()\) belongs to a reproducing kernel Hilbert space (RKHS) \(\) associated to a kernel \(k(,):\) with inner product \(,_{}\) and norm \(_{}\). Note that the threshold function \(g_{t}()\) belongs to the RKHS \(\) determined by the kernel \(k^{}(,)=k(,)+1\).

We focus on the online learning setting, in which at every time set \(t 1\), the model observes an input feature \(X_{t}\), produces a set \(C_{t}\), and receives as feedback the loss \(L_{t}=(C_{t},Y_{t})\). Note that label \(Y_{t}\) may not be directly observed, and only the loss \((C_{t},Y_{t})\) may be recorded. Based on the observed sequence of features \(X_{t}\) and feedback \(L_{t}\), we are interested in producing prediction sets as in (14) that satisfy the reliability guarantees (12) and (13), with a reweighting function set \(\) encompassing all non-negative functions \(w()\) with a positive mean \(_{X}[w(X)]\) under distribution \(P_{X}\), i.e.,

\[=\{w():\ _{X}[w(X)]>0,w(x) 0x\}. \]

Importantly, as detailed below, the level of localization in guarantee (12) depends on the choice of the kernel \(k(,)\).

### L-Arc

Given a regularization parameter \(>0\) and a learning rate \(_{t} 1/\), L-ARC updates the threshold function \(g_{t}()=f_{t}()+c_{t}\) in (14) based on the recursive formulas

\[c_{t+1} =c_{t}-_{t}(-L_{t}) \] \[f_{t+1}() =(1-_{t})f_{t}()-_{t}(-L_{t})k(X_{t}, ), \]

with \(f_{1}()=0\) and \(c_{1}=0\). In order to implement the update (17)-(18), it is useful to rewrite the function \(g_{t+1}()\) as

\[g_{t+1}()=_{i=1}^{t}a_{t+1}^{i}k(X_{i},)+c_{t+1}, \]

where the coefficients \(\{a_{t+1}^{i}\}_{i=1}^{t}\) are recursively defined as

\[a_{t+1}^{t} =-_{t}(-L_{t}) \] \[a_{t+1}^{i} =(1-_{t})a_{t}^{i},i=1,2,,t-1. \]

Accordingly, if the loss \(L_{t}\) is larger than the long-term target \(\), the update rule (20)-(21) increases the function \(g_{t+1}()\) around the current input \(X_{t}\), while decreasing it around the previous inputs \(X_{1},,X_{t-1}\). Intuitively, this change enhances the reliability for inputs in the neighborhood of \(X_{t}\).

It is important to note that, at any time \(t\), computing the threshold function (19) requires storing the coefficients \(\{a_{t}^{i}\}_{i=1}^{t-1}\) and \(c_{t}\), as well as the input data \(\{X_{t}\}_{i=1}^{t}\). Consequently, L-ARC has a linear memory requirement in \(t\), which is a known limitation of non-parametric learning in online settings (Koppel et al., 2020). Previous research has explored methods that trade memory efficiency for accuracy (Kivinen et al., 2004). In Appendix C.3, we build on these approaches to present a memory-efficient variant of L-ARC that allows for a trade-off between localized risk control and memory requirements.

### Theoretical Guarantees

In this section, we formalize the theoretical guarantees of L-ARC, which were informally stated in Section 1.3 as (12) and (13).

**Assumption 1** (Stationary and bounded kernel).: _The kernel function is stationary, i.e., \(k(x,x^{})=( x-x^{})\), for some non-negative function \(()\), which is \(\)-Lipschitz for some \(>0\), upper bounded by \(<\), and coercive, i.e., \(_{z}(z)=0\)._

Many well-known stationary kernels, such as the radial basis function (RBF), Cauchy, and triangular kernels, satisfy Assumption 1. The smoothness parameter \(\) and the maximum value of the kernel function \(\) determine the localization of the threshold function \(g_{t}()\). For example, the set of functions \(\) defined in (10) corresponds to the function class (16) associated with the RKHS defined by the raised RBF kernel \(k(x,x^{})=(- x-x^{}^{2}/l)+1\), with length scale \(l=2e(/)^{2}\). As illustrated in Figure 2, by increasing \(\) and \(\), we obtain functions with an increasing level of localization, ranging from constant functions to maximally localized functions.

**Assumption 2** (Bounded non-conformity scores).: _The non-conformity scoring function is non-negative and bounded, i.e., \(s(x,y) S_{}<\) for any pair \((x,y)\)._

**Assumption 3** (Bounded and monotone loss).: _The loss function is non-negative; bounded, i.e., \((C,Y) B<\) for any \(C\) and \(Y\); and monotonic, in the sense that for prediction sets \(C^{}\) and \(C\) such that \(C^{} C\), the inequality \((C,Y)(C^{},Y)\) holds for any \(Y\)._

#### 2.3.1 Statistical Localized Risk Control

To prove the localized statistical guarantee (12) we will make the following assumption.

**Assumption 4** (Strictly decreasing loss).: _For any fixed threshold function \(g()\), the loss \(_{Y}[(C(X,g),Y)|X=x]\) is strictly decreasing in the threshold \(g(x)\) for any \(x\)._

**Assumption 5** (Left-continuous loss).: _For any fixed threshold function \(g()\), the loss \((C(x,g+h),y)\) is left-continuous in \(h\) for any \((x,y)\)._

**Theorem 1**.: _Fix a user-defined target reliability \(\). For any regularization parameter \(>0\) and any learning rate sequence \(_{t}=_{1}t^{-1/2}<1/\) for some \(_{1}>0\), given a sequence \(\{(X_{t},Y_{t})\}_{t=1}^{T}\) of i.i.d. samples from \(P_{XY}\), the time-averaged threshold function (11) satisfies the limit_

\[_{T}_{X,Y}[_{X}[w(X)]}(C(X,_{T}),Y)]}{{}}+ B\|_{}}{ _{X}[w(X)]}, \]

_for any weighting function \(w()=f_{w}()+c_{w}\) where the expectation is with respect to the test sample \((X,Y)\)._

Proof.: See Appendix A. 

By (22), the average localized loss converges in probability to a quantity that can be bounded by the target \(\) with a gap \(A(,w)\) that increases with the level of localization \(\).

#### 2.3.2 Worst-Case Deterministic Long-Term Risk Control

**Theorem 2**.: _Fix a user-defined target reliability \(\). For any regularization parameter \(>0\) and any learning rate sequence \(_{t}=_{1}t^{-1/2}<1/\) with \(_{1}>0\), given any sequence \(\{(X_{t},Y_{t})\}_{t=1}^{T}\) with bounded input \(\|X_{t}\| D<\), \(L\)-ARC produces a sequence of threshold functions \(\{g_{t}()\}_{t=1}^{T}\) in (19) that satisfy the inequality_

\[|_{t=1}^{T}(C(X_{t},g_{t}),Y_{t})- |}(}}{_{1}}+ }{_{1}}+2B(2+1))+ B. \]

Proof.: We defer the proof to Appendix B. 

Formalizing the upper bound in (13), Theorem 2 states that the difference between the long-term cumulative risk and the target reliability level \(\) decreases with a rate \(B()T^{-1/2}\) to a value \(C()= B\) that is increasing with the maximum value of the kernel \(\). In the special case, \(=0\) which corresponds to no localization, the right-hand side of (23) vanishes in \(T\), recovering ARC long-term guarantee (6).

## 3 Experiments

In this section, we explore the worst-case long-term and statistical localized risk control performance of L-ARC as compared to ARC. Firstly, we address the task of electricity demand forecasting, utilizing data from the Elec2 dataset (Harries et al., 1999). Next, we present an experiment focusing on tumor segmentation, where the data comprises i.i.d. samples drawn from various image datasets (Jha et al., 2020; Bernal et al., 2015, 2012; Silva et al., 2014; Vazquez et al., 2017). Finally, we study a problem in the domain of communication engineering by focusing on beam selection, a key task in wireless systems (Ali et al., 2017). A further example concerning applications with calibration constraints can be found in Appendix C.2. Unless stated otherwise, we instantiate L-ARC with the RBF kernel\(k(x,x^{})=(-\|x-x^{}\|^{2}/l)\) with \(=1\), length scale \(l=1\) and regularization parameter \(=10^{-4}\). With a smaller length scale \(l\), we obtain increasingly localized weighting functions. All the experiments are conducted on a consumer-grade Mac Mini with an M1 chip. The simulation code is available at [https://github.com/kclip/localized-adaptive-risk-control.git](https://github.com/kclip/localized-adaptive-risk-control.git).

### Electricity Demand

The Elec2 dataset comprises \(T=45312\) hourly recordings of electricity demands in New South Wales, Australia. The data sequence \(\{Y_{t}\}_{t=1}^{T}\) is subject to distribution shifts due to fluctuations in demand over time, such as between day and night or between weekdays and weekends. We adopt a setup akin to that of Angelopoulos et al. (2024), wherein the even-time data samples are used for online calibration while odd-time data samples are used to evaluate coverage after calibration. At time \(t\), the observed covariate \(X_{t}\) corresponds to the past time series \(Y_{1:t-1}\), and the forecasted electricity demand \(_{t}\) is obtained based on a moving average computed from demand data collected within the preceding 24 to 48 hours. We produce prediction sets \(C_{t}\) based on the non-conformity score \(s(X_{t},Y_{t})=|_{t}-Y_{t}|\) and we target a miscoverage rate \(=0.1\) using the miscoverage loss (3). Both ARC and L-ARC use the learning rate \(_{t}=t^{-1/2}\). L-ARC is instantiated with the RBF kernel \(k(x,x^{})=(-\|(x)-(x^{})\|^{2}/l)\), where \((x)\) is a 7-dimensional feature vector corresponding to the daily average electricity demand during the past 7 days.

In the left panel of Figure 3, we report the cumulative miscoverage error of ARC and L-ARC for different values of the localization parameter \(l\). All algorithms converge to the desired coverage level of 0.9 in the long-term. The right panel of Figure 3, displays the average miscoverage error on the hold-out dataset at convergence. We specifically evaluate both the marginalized miscoverage rate and the conditional miscoverage rate separately over weekdays and weekends. L-ARC is shown to reduce the weekend coverage error rate as compared to ARC providing balanced coverage as the length scale \(l\) decreases.

Figure 4: Long-term FNR (left), average FNR across different data sources (center), and average mask size across different data sources (right) for ARC and L-ARC with varying values of the localization parameter \(l\) for the task of tumor segmentation (Fan et al., 2020).

Figure 3: Long-term coverage (left) and average miscoverage error (right), marginalized and conditioned on weekdays and weekends. for ARC and L-ARC with varying values of the localization parameter \(l\) on the Elec2 dataset.

### Tumor Image Segmentation

In this section, we focus on the task of calibrating a predictive model for tumor segmentation. Here, the feature vector \(X_{t}\) represents a \(d_{} d_{}\) image, while the label \(Y_{t}\) identifies a subset of the image pixels \(=\{(1,1),,(d_{},d_{})\}\) that encompasses the tumor region. As in Angelopoulos et al. (2022), the dataset is a compilation of samples from several open-source online repositories: Kvasir, CVC-300, CVC-ColonDB, CVC-ClinicDB, and ETIS-LaribDB. We reserve 50 samples from each repository for testing the performance post-calibration, while the remaining \(T=2098\) samples are used for online calibration. Predicted sets are obtained by applying a threshold \(g(X_{t})\) to the pixel-wise logits \(f(p_{},p_{})\) generated by the PraNet segmentation model (Fan et al., 2020), with the objective of controlling the false negative ratio (FNR) \((C_{t},Y_{t})=1-|C_{t} Y_{t}|/|Y_{t}|\). Both ARC and L-ARC are run using the same decaying learning rate \(_{t}=0.1t^{-1/2}\). L-ARC is instantiated with the RBF kernel \(k(x,x^{})=(-\|(x)-(x^{})\|^{2}/l)\), where \((x)\) is a 5-dimensional feature vector obtained via the principal component analysis (PCA) from the last hidden layer of the ResNet model used in PraNet.

In the leftmost panel of Figure 4, we report the long-term FNR for varying values of the localization parameter \(l\), targeting an FNR level \(=0.1\). All methods converge rapidly to the desired FNR level, ensuring long-term risk control. The calibrated models are then tested on the hold-out data, and the FNR and average predicted set size are separately evaluated across different repositories. In the middle and right panels of Figure 4, we report the average FNR and average prediction set size averaged over 10 trials.

The model calibrated via ARC has a marginalized FNR error larger than the target value \(\). Moreover, the FNR error is unevenly distributed across the different data repositories, ranging from \(=0.08\) for CVC-300 to \(=0.32\) for ETIS-LaribPolyDB. In contrast, L-ARC can equalize performance across repositories, while also achieving a test FNR closer to the target level. In particular, as illustrated in the rightmost panel, L-ARC improves the FNR for the most challenging subpopulation in the data by increasing the associated prediction set size, while maintaining a similar size for subpopulations that already have satisfactory performance.

### Beam Selection

Motivated by the importance of reliable uncertainty quantification in engineering applications, we address the task of selecting location-specific beams for the initial access procedure in sixth-generation wireless networks (Ali et al., 2017). Further details regarding the engineering aspects of the problem and the simulation scenario are provided in Appendix C.1.1. In the beam selection task, at each time \(t\), the observed covariate corresponds to the location \(X_{t}=[p_{},p_{}]\) of a receiver within the network deployment, where \(p_{}\) and \(p_{}\) represent the geographical coordinates. Based on the observed covariate, the transmitter chooses a set, denoted as \(C_{t}[1,,B_{}]\), consisting of a subset of the \(B_{}\) available communication beams.

Each communication beam \(i\) is associated with a wireless link characterized by a signal-to-noise ratio \(Y_{t,i}\), which follows an unknown distribution depending on the user's location \(X_{t}\). We represent the vector of signal-to-noise ratios as \(Y_{t}=[Y_{t,1},,Y_{t,B_{}}]^{B_{}}\). For a set \(C_{t}\), the transmitter sweeps over the beam set \(C_{t}\), and the performance is measured by the ratio between the SNR obtained

Figure 5: Long-term risk (left-top), average beam set size (left-bottom), and SNR level across the deployment area (right) for ARC, Mondrian ARC, and L-ARC. The transmitter is denoted as a green circle and obstacles to propagation are shown as grey rectangles.

on the best beam in set \(C_{t}\) and the best SNR on all the beams, i.e.,

\[(C_{t},Y_{t})=L_{t}=1-_{t}}Y_{t,i}}{_{ i\{1,,B_{}\}}Y_{t,i}}. \]

Given an SNR predictor \(_{t}=f_{}(X_{t})\) for all beams at location \(X_{t}\), we consider sets that include only beams with a predicted SNR exceeding a threshold \(g_{t}(X_{t})\) as

\[C(X_{t},g_{t})=\{i[1,,B_{}]:_{t,i}>g_{t}(X_{t})\}. \]

In this setting, localization refers to the fair provision of service across the entire deployment area. As a benchmark, we thus also consider an additional calibration strategy that divides the deployment area into two regions: one encompassing all locations near the transmitter, which are more likely to experience high SNR levels, and the other including locations far from the transmitter. For each of these regions, we run two separate instances of ARC algorithms. Inspired by the method introduced in Bostrom et al. (2021) for offline settings, we refer to this baseline approach as Mondrian ARC.

In the left panels of Figure 5, we compare the performance of ARC, Mondrian ARC, and L-ARC with an RBF kernel with \(l=10\), using a calibration data sequence of length \(T=25000\). All methods achieve the target long-term SNR regret, but L-ARC achieves this result while selecting sets with smaller sizes, thus requiring less time for beam sweeping. Additionally, as illustrated on the right panel, thanks to the localization of the threshold function, L-ARC ensures a satisfactory communication SNR level across the entire deployment area. In contrast, both ARC and Mondrian ARC produce beam-sweep sets with uneven guarantees over the network deployment area.

## 4 Related Work

Our work contributes to the field of adaptive conformal prediction (CP), originally introduced by Gibbs and Candes (2021). Adaptive CP extends traditional CP (Vovk et al., 2005) to online settings, where data is non-exchangeable and may be affected by distribution shifts. This extension has found applications in reliable time-series forecasting (Xu and Xie, 2021; Zaffran et al., 2022), control (Lekeufack et al., 2023; Angelopoulos et al., 2024a), and optimization (Zhang et al., 2023; Deshpande et al., 2024). Adaptive CP ensures that prediction sets generated by the algorithm contain the response variable with a user-defined coverage level on average across the entire time horizon. Recently, Bhatnagar et al. (2023) proposed a variant of adaptive CP based on strongly adaptive online learning, providing coverage guarantees for any subsequence of the data stream. While their approach offers localized guarantees in time, L-ARC provides localized guarantees in the covariate space. More similar to our work is (Bastani et al., 2022), which studies group-conditional coverage. Our work extends beyond coverage guarantees to a more general risk definition, akin to Feldman et al. (2022). Angelopoulos et al. (2024a) studied the asymptotic coverage properties of adaptive conformal predictions in the i.i.d. setting; and our work extends these results to encompass covariate shifts. Finally, the guarantee provided by L-ARC is similar to that of Gibbs et al. (2023), albeit for an offline conformal prediction setting.

## 5 Conclusion and Limitations

We have presented and analyzed L-ARC, a variant of adaptive risk control that produces prediction sets based on a threshold function mapping covariate information to localized threshold values. L-ARC can guarantee both worst-case deterministic long-term risk control and statistical localized risk control. Empirical analysis demonstrates L-ARC's ability to effectively control risk for different tasks while providing prediction sets that exhibit consistent performance across various data sub-populations. The effectiveness of L-ARC is contingent upon selecting an appropriate kernel function. Furthermore, L-ARC has memory requirements that grow with time due to the need to store the input data \(\{X_{t}\}_{t>1}\) and coefficients (20)-(21). These limitations of L-ARC motivate future work aimed at optimizing online the kernel function based on hold-out data (Kiyani et al., 2024) or in an online manner (Angelopoulos et al., 2024a), and at studying the statistical guarantees of memory-efficient variants of L-ARC (Kivinen et al., 2004).

Acknowledgments

This work was supported by the European Union's Horizon Europe project CENTRIC (101096379). The work of Osvaldo Simeone was also supported by the Open Fellowships of the EPSRC (EP/W024101/1) by the EPSRC project (EP/X011852/1), and by Project REASON, a UK Government funded project under the Future Open Networks Research Challenge (FONRC) sponsored by the Department of Science Innovation and Technology (DSIT). We would also like to express our gratitude to Anastasios Angelopoulos for valuable insights on the technical content of the paper.