# Discrete-Smoothness in

Online Algorithms with Predictions

 Yossi Azar

Tel Aviv University

azar@tau.ac.il &Debmalya Panigrahi

Duke University

debmalya@cs.duke.edu &Noam Touitou

Amazon

noamtux@gmail.com

This paper does not relate to the author's work at Amazon.

###### Abstract

In recent years, there has been an increasing focus on designing online algorithms with (machine-learned) predictions. The ideal learning-augmented algorithm is comparable to the optimum when given perfect predictions (_consistency_), to the best online approximation for arbitrary predictions (_robustness_), and should interpolate between these extremes as a smooth function of the prediction error. In this paper, we quantify these guarantees in terms of a general property that we call _discrete-smoothness_ and achieve discrete-smooth algorithms for online covering, specifically the facility location and set cover problems. For set cover, our work improves the results of Bamas, Maggiori, and Svensson (2020) by augmenting consistency and robustness with smoothness guarantees. For facility location, our work improves on prior work by Almanza et al. (2021) by generalizing to nonuniform costs and also providing smoothness guarantees by augmenting consistency and robustness.

## 1 Introduction

The field of _learning-augmented online algorithms_ has gained rapid prominence in recent years. The basic premise is to provide an online algorithm with additional (machine-learned) predictions about the future to help bypass worst-case lower bounds. Since machine-learned predictions can be noisy in general, a key desideratum of the model is that the _competitive ratio_ of the online algorithm should degrade gracefully with prediction error. In particular, the cost of the algorithm should be bounded against that of the predicted solution (called _consistency_) or that of an online algorithm without predictions (called _robustness_) and should smoothly interpolate between the two with increase in prediction error (called _smoothness_). (The terms consistency and robustness were originally coined by Purohit, Svitkina, and Kumar .) While robustness and consistency are problem-independent notions, smoothness depends on prediction error which has been defined in a problem-specific manner. In this paper, we introduce a novel, problem-independent notion of smoothness called _discrete-smoothness_ that applies to any combinatorial problem. As illustrative applications of this new framework, we design discrete-smooth (learning-augmented) algorithms for two classic problems, _facility location_ and _set cover_, which improve and generalize previous results for these problems due to Almanza et al. (NeurIPS '21 ) and Bamas et al. (NeurIPS '20 ).

First, we introduce discrete-smoothness. Suppose we are given a problem instance of size \(n\). Let OPT be a solution for this instance. (The reader may think of OPT as an optimal solution, although our guarantees will hold for any feasible solution.) Let the predicted solution be \(S\). Ideally, \(S=\); therefore, in general, OPT comprises two parts: the predicted part \(|_{S}:= S\) and the unpredicted part \(|_{}:= S\). On the predicted part \(|_{S}\), the algorithm has a meaningful signal from the prediction but the noise in the signal is given by the overprediction \(s_{}:=|S|\). Naturally, the competitive ratio of the algorithm on this part will degrade with increase in this noise. On the unpredicted part \(|_{}\), the algorithm does not have any signal from the prediction andcannot hope for a better competitive ratio than that of an online algorithm without prediction. Slightly abusing notation, we use \(|_{S},|_{}\) to denote both the aforementioned sets of items and their total cost; putting the two together, a learning-augmented algorithm ALG should satisfy

\[ O(f(s_{}))|_{S}+O(f(n))|_{},\] (1)

where \(O(f())\) is the competitive ratio without prediction. We call the property of Equation (1) _discrete-smoothness_.

Let us first argue that Equation (1) recovers consistency and robustness. Consistency follows from setting \(S=\); then, Equation (1) demands a constant approximation to \(\). Similarly, robustness follows from the fact that for any \(S\), the right hand side of Equation (1) is at most \(O(f(n))\).

Next, we show that the two terms \(f(s_{})\) and \(f(n)\) in Equation (1) are the best possible. For the first term, consider a prediction \(S\) comprising the entire instance (of size \(n\)); in this case, we cannot hope for the better than \(f(n)\)-competitive algorithm; thus, \(f(s_{})\) is necessary in the first term. And, for the second term, consider an empty prediction \(S=\), in which case we again cannot hope for a better than \(f(n)\)-competitive algorithm; thus, \(f(n)\) is necessary in the second term. Note that the asymmetry between these two terms is necessary: specifically, \(f(n)\) cannot be replaced by \(f(| S|)\) since that would imply an \(f()\)-competitive online algorithm when \(S=\). This is impossible, e.g., for the set cover problem.

A technical subtlety of the definition of discrete-smoothness (Equation (1)) is that given a fixed prediction \(S\), the minimum value of the right hand side might actually be a solution \(\) that is different from an optimal solution to the problem instance. So, although the solution \(\) is intuitively an optimal solution, we require that a discrete-smooth algorithm satisfy Equation (1) for _all_ feasible solutions \(\), and not just optimal solutions.

### Our Results

We apply discrete-smoothness to the classic problems of online facility location and set cover. For these problems, we obtain results that improve on prior work. We describe these next.

Online Facility Location with Predictions.In the online facility location problem, we are given offline a metric space \((X,)\) of \(m:=|X|\) points, where each point \(v X\) has an associated facility opening cost \(o_{v} 0\). On receiving an online request for a client at some location \(x X\), the online algorithm must connect the client to an open facility at some location \(v X\) incurring connection cost \((x,v)\). At any time, the algorithm is also allowed to open a facility at any location \(v X\) by incurring the opening cost \(o_{v}\). (Note that a client cannot update her connection even if a closer facility is opened later.) The total cost of the algorithm is the sum of opening costs of opened facilities and connection costs of clients.

The first result for the online facility location problem is due to Meyerson  who obtained a randomized algorithm with a competitive ratio of \(O( n)\) for \(n\) requests. This result was first derandomized , and later the competitive ratio slightly improved to \(O()\), by Fotakis. This latter bound is asymptotically tight. More recently, the online facility location problem has been considered in the context of machine-learned _predictions_ (OFLP) by several papers [20; 1; 22]. Of these, the work of Almanza et al.  is the closest to our work (the other papers use metric error measures that are incomparable to our results). In , the offline input additionally contains a predicted solution of facilities \(S X\), where we denote \(|S|=s\). By restricting the available facilities to the predicted set, they obtained an \(O( s)\)-competitive algorithm for uniform facility opening costs, under the condition that \( S\).

We improve and generalize the Almanza et al. work by giving a discrete-smooth algorithm for the OFLP problem, i.e., an algorithm ALG that satisfies Equation (1):

**Theorem 1.1**.: _There is an algorithm ALG for online (nonuniform) facility location with a predicted solution \(S\) that satisfies for every solution \(\)_

\[ O( s_{})|_{S}+O( n) |_{},\] (2)

_where \(s_{}\) is the number of facilities in \(S\) and \(n\) is the number of online requests. Here, \(|_{S}\) (resp., \(|_{}\)) represents the sum of opening costs of facilities in \( S\) (resp., \( S\)) and connection costs of all clients connecting to facilities in \( S\) (resp., \( S\))._This generalizes and improves the Almanza et al. result in three ways:

* The result is generalized from uniform facility opening costs to arbitrary (nonuniform) costs. In fact, even for the online facility location problem (without prediction), we get an \(O( m)\)-competitive algorithm for arbitrary (nonuniform) facility opening costs -- previously, Almanza et al. only established this for uniform costs.
* The assumption that \( S\), i.e., the prediction contains the entire solution, is no longer required.
* If \( S\) (i.e., under the assumption of the Almanza et al. result), the competitive ratio improves from \(O( s)\) to \(O( s_{})\). That is, the dependence is only on the prediction error and not the entire prediction.

In some situations, the length of the request sequence \(n\) can exceed the size of the metric space \(m\). To address this situation, we show that \(n\) can be replaced by \(m\) in the above result:

**Theorem 1.2**.: _There is an algorithm \(\) for online (nonuniform) facility location with a predicted solution \(S\) that satisfies for every solution \(\)_

\[ O( s_{})|_{S}+O(  m)|_{},\] (3)

_where \(m\) is the number of facilities in the metric space overall._

Online Set Cover with Predictions.In the online set cover problem, we are given offline a universe of elements \(E\) and \(m\) sets defined on them \(U 2^{E}\) with nonnegative costs. In each online step, we get a new element \(e E\). If \(e\) is not already covered by the current solution, then the algorithm must add a new set from \(U\) that contains \(e\) to its solution. The total cost of the algorithm is the sum of costs of all sets in its solution.

Alon et al.  gave the first algorithm for the online set cover problem by introducing the online primal dual method, and obtained a competitive ratio of \(O( m n)\) where \(n\) denotes the number of requests. They also proved an almost matching lower bound of \(()\). Bamas, Maggiori, and Svensson  extended their work to online set cover _with predictions_ (OSCP), where the offline input additionally contains a predicted solution of sets \(S U\). They established consistency and robustness bounds for this problem by adapting the online primal dual method to use the predicted solution. The cost of their algorithm is bounded by the minimum of \(O( n)\) times the cost of the prediction and \(O( m n)\) times the optimal cost. However, one cannot achieve smoothness through their work without choosing a trust parameter correctly in advance of the input.

We obtain a discrete-smooth algorithm for the OSCP problem, thereby giving the first algorithm for OSCP that goes beyond only consistency and robustness and achieves a smoothness guarantee:

**Theorem 1.3**.: _There is an algorithm \(\) for online set cover with a predicted solution \(S\) that satisfies for every solution \(\)_

\[ O( s_{} n)|_{S}+O ( m n)|_{},\] (4)

_where \(s_{}\) is the number of sets in \(S\). Here, \(|_{S}\) (resp., \(|_{}\)) represents the sum of costs of sets in \( S\) (resp., \(\))._

### Our Techniques: A Framework for Discrete-Smooth Algorithms

At a high level, our framework merges two online algorithms to obtain a discrete-smooth algorithm. The algorithms differ in the guarantees they provide. The first algorithm \(_{1}\) gets a sharper competitive ratio of \(O(f(s))\) but against the optimal solution restricted to the prediction \(S\). The second algorithm \(_{2}\) has the standard competitive ratio of \(O(f(n))\) but against the unconstrained optimum \(\). The main challenge in the combiner algorithm (call it \(\)) is to decide how to route online requests to the two algorithms. The natural choice would be to decide this based on whether \(|_{S}\) or \(_{}\) serves the request in \(\): in the first case, the request should be routed to \(_{1}\) and in the second case, it should be routed to \(_{2}\). But, of course, we do not know \(\) and therefore don't know \(|_{S}\) and \(|_{}\).

Before we describe the combiner strategy, consider the properties that these algorithms need to satisfy.

* First, consider the _subset_ of requests served by \(|_{S}\). Intuitively, \(_{1}\) should be competitive on these requests, which means that we need a stronger property from \(_{1}\) that its cost on any subset of requests is competitive against the optimal solution for this subset. We call this property _subset competitiveness_.2 Symmetrically, subset competitiveness of \(_{2}\) ensures that it is competitive on the requests in \(|_{}\). * Next, we need a guarantee on the cost of \(_{1}\) on \(|_{}\), and symmetrically, of \(_{2}\) on \(|_{S}\). For this, we first augment \(_{1},_{2}\) to address the _prize-collecting_ version of the original problem, where each online request can be ignored at a _penalty cost_. (Note that this is more general than the original problem where every online request must be served, since the latter can be recovered by setting the penalties to be infinitely large.) Setting the penalties appropriately, we ensure that the total penalty of the requests in \(|_{S}\) is bounded against the cost of \(_{1}\) on those requests (similarly for \(|_{}\)).
* Finally, we require that the cost of \(_{1},_{2}\) on any set of requests is bounded against the total penalty of the requests. We call this strengthened competitiveness w.r.t. penalties the _Lagrangian property_3. Note that this ensures that the cost of \(_{1},_{2}\) on \(|_{},|_{S}\) are respectively bounded. 
Now, we give the formal definition of Lagrangian subset-competitiveness that we motivated above. We use \((Q^{}|Q)\) to refer to the total cost of \(\) incurred when addressing a subset \(Q^{} Q\) as part of running on an input \(Q\). For any prize collecting solution SOL for input \(Q\), we separate its total cost into \(^{b}(Q)\) (buying cost) and \(^{p}(Q)\) (penalty cost). We formalize the Lagrangian subset-competitiveness property below:

**Definition 1.4** (Lagrangian subset-competitive algorithm).: Let \(\) be a randomized prize-collecting algorithm running on an input \(Q\). For any competitive ratio \(\), we say that \(\) is Lagrangian \(\)-subset-competitive if for every subset \(Q^{} Q\) we have

\[[(Q^{}|Q)]^{b}(Q^{ })+O(1)^{p}(Q^{})\] (5)

If in the equation above we replace the unconstrained optimum (OPT) by the optimal solution that can only use the prediction \(S\), we say that \(\) is Lagrangian \(\)-subset-competitive w.r.t. \(S\).

We now give the combiner algorithm:

```
1 Let \(_{1},_{2}\) be two prize-collecting Lagrangian subset-competitive algorithms.
2Event Function\((q)\)
3 Let \(\) be the minimum penalty such that releasing \((q,)\) to \(_{1},_{2}\) would result in the request being served in either \(_{1}\) or \(_{2}\). (The value of \(\) can be determined by a standard "guess-and-double".)
4 Release \((q,)\) to both \(_{1}\) and \(_{2}\). Buy the items bought by \(_{1},_{2}\) as a result of this step. ```

**Algorithm 1** Smooth merging framework (The combiner algorithm)

The algorithm is simple: for a new online request \(q\), the framework chooses the minimum penalty \(\) which ensures that at least one of the two constituent algorithms \(_{1},_{2}\) would actually serve \(q\) (instead of paying the penalty). \((q,)\) is then presented as a (prize-collecting) request to both algorithms. (Recall that the combined algorithm is for the non-prize-collecting problem, but the individual algorithms \(_{1},_{2}\) are for the prize-collecting problem.) At this stage, one of the algorithms serves the request (due to the choice of \(\)) while the other may choose to pay the penalty. The combiner algorithm now simply buys all items bought by either algorithm.

Finally, we state the guarantees of the combiner algorithm informally. (For a formal description, see Appendix C.)

**Theorem 1.5**.: _(Informal) If \(_{1},_{2}\) are Lagrangian \(\)-subset-competitive algorithms for \(=f(s)\), \(f(n)\) respectively, then Algorithm 1 satisfies the discrete-smoothness property (Equation (1)._

**Applications of Theorem 1.5:** Section 3 and Appendix B give Lagrangian subset-competitive algorithms for facility location, and Section 4 gives a Lagrangian subset-competitive algorithm for set cover. Given these constituent algorithms, we use Theorem 1.5 to prove Theorem 1.1 and Theorem 1.2 for facility location and Theorem 1.3 for set cover. These proofs are given in Appendix D.

Related Work.There is a growing body of work in online algorithms with predictions in the last few years (see, e.g., the surveys [35; 36]). This model was introduced by Lykouris and Vassilvitskii for the caching problem  and has since been studied for a variety of problem classes: rent or buy [27; 25; 21; 41; 5; 39], covering , scheduling [27; 41; 10; 28; 34; 30; 8], caching [31; 40; 24; 13], matching [29; 16; 7; 23], graph problems [6; 22; 1; 14; 4; 20; 9], and so on. Prior works on online facility location with predictions either do not consider prediction error  or use continuous notions of error [22; 20], such as functions of the distances between predicted and optimal facilities. Our discrete notion of error refers only to whether an optimal item is predicted. Similarly, prior work on online set cover with predictions [11; 4] also does not consider prediction error. Finally, we note that discrete prediction error (similar to this paper) as well as hybrids between discrete and continuous error have also been considered [42; 9; 14] but the prediction here is on the input rather than the solution.

## 2 The Framework

We now describe some of the concepts of the framework in more detail.

**Reduction from \(s_{}\) to \(s\).** Recall that we seek discrete-smooth algorithms, i.e., satisfying Equation (1). Our first step is to give a generic reduction that allows us to slightly weaken the guarantee to the following:

\[ O(f(s))|_{S}+O(f(n))|_{ },\] (6)

where \(O(f())\) is the competitive ratio without predictions. We give a reduction from an algorithm that satisfies Equation (6) to one that satisfies Equation (1):

**Theorem 2.1**.: _Given an algorithm \(^{}\) such that \(^{} O(f(s))|_{S}+O(g)| _{}\), there exists an algorithm \(\) such that \( O(f(s_{}))|_{S}+O(g)|_{S}\)._

The proof of this theorem, in Appendix E, is roughly the following: for every integer \(i\), once the cost of the algorithm exceeds \(2^{i}\), we buy the cheapest predicted items of total cost at most \(2^{i}\), and then remove them from the prediction. While \(2^{i}<\), the total cost is \(O(1)\); once \(2^{i}\) exceeds OPT, the size of the prediction is at most \(s_{}\), and Equation (6) implies Equation (1).

**Monotonicity.** An additional, natural property that we demand from a constituent algorithm in our smooth combination framework is that increasing the penalty of input requests does not decrease the cost incurred by the algorithm. This is stated formally in the following definition.

**Definition 2.2**.: We say that a prize-collecting algorithm \(\) is _monotone_ if, fixing the input request prefix \(((q_{i},_{i}))_{i=1}^{k-1}\) and current request \((q_{k},_{k})\), then increasing \(_{k}\) does not decrease \((q_{k},_{k})\).

**Online amortization.** Our framework extends to the case where Lagrangian subset-competitiveness and monotonicity are satisfied by _amortized_ costs instead of actual costs. This is important because for some problems, the actual cost expressly prohibits subset competitiveness. For example, consider facility location: given an input of multiple, identical requests with very small penalty, the algorithm should eventually stop paying penalties and open a facility. However, for the specific request upon which the facility is opened, the cost of the algorithm is much larger than the penalty for that request, the latter being optimal for just that request. To overcome this complication, we allow the cost for a request to be amortized over previous requests, and call this _online amortization_.

First, we define online amortization of costs, and define a "monotone" online amortization which can be used in our framework.

**Definition 2.3** (online amortization).: Let \(Q=((q_{1},_{1}),,(q_{n},_{n}))\) be an online input given to \(\). An _online amortization_ or \(\) is a number sequence \(((q,))_{(q,) Q}\) such that:

1. \((Q)_{(q,) Q}(q,)\).
2. \((q_{i},_{i})\) is only a function of \((q_{1},_{1}),,(q_{i},_{i})\), and can thus be calculated online.

When considering the amortized cost of an algorithm, we use similar notation to the actual cost: on an input \(Q\), we use \((Q)\) to denote the total amortized cost. We also use \((Q^{}|Q)\) to denote the total amortized cost incurred on a request subset \(Q^{} Q\). In addition, for a request \((q,)\) in the input \(Q\), we use \((q,)\) to refer to the amortized cost of \((q,)\); here the input \(Q\) is clear from context.

**Definition 2.4** (monotone online amortization).: We call an online amortization \(\)_monotone_ if **(a)** fixing previous requests, increasing the penalty of request \((q,)\) never decreases \((q,)\), and **(b)** when the algorithm pays penalty for \((q,)\) then \((q,)\).

The Main TheoremWe are now ready to state the main theorem of our algorithmic framework. We use \(_{1}\) and \(_{2}\) to denote the competitive ratios of \(_{1}\) and \(_{2}\); the reader should think of \(_{1}\) as \(O(f(s))\) and \(_{2}\) as \(O(f(n))\), i.e., \(_{2}_{1}\).

**Theorem 2.5**.: _Consider any online covering problem with predictions \(\). Let \(_{1},_{2}\) be two algorithms for the prize-collecting version of \(\) with monotone (online amortized) costs \(_{1},_{2}\) respectively such that **(a)**\(_{1}\) is Lagrangian \(_{1}\)-subset-competitive using \(_{1}\) w.r.t. the prediction \(S\), and **(b)**\(_{2}\) is Lagrangian \(_{2}\)-subset-competitive using \(_{2}\) (against general \(\))._

_Then there exists \(\) for \(\) such that for every partition of the input \(Q\) into \(Q_{1},Q_{2}\) we have_

\[(Q) O(_{1})_{S}(Q_{1})+O(_{2}) (Q_{2})\]

We later show that Theorem 2.5 implies Equation (6) for facility location and set cover.

## 3 Online Facility Location

In this section, we consider metric, nonuniform facility location with predictions and present a novel prize-collecting algorithm TreeProxy. This algorithm is Lagrangian \(O(|S|)\)-subset-competitive w.r.t. the prediction \(S\) of possible facilities; thus, it is used in our framework to prove Theorems D.2 and D.3, which in turn imply Theorems 1.1 and 1.2, respectively. In addition, TreeProxy is a result independent of our framework/predictions: the competitiveness guarantee shown for TreeProxy also achieves \(O( m)\) competitiveness where \(m=|X|\) is the size of the metric space. We prove the following theorem:

**Theorem 3.1**.: _For facility location with predictions, there exists a randomized prize-collecting algorithm \(\) with a monotone online amortization \(\) which is Lagrangian \(O(|S|)\)-subset competitive using \(\) w.r.t. \(S\)._

### The Algorithm

**Weighted hierarchically-separated trees (HSTs).** The algorithm starts by embedding the metric space into the leaves of a weighted \(3\)-HST, a metric space in which edge weights decrease at least exponentially as one descends from the root.

**Definition 3.2**.: For \(>1\), a rooted tree with weights \(c\) to the edges is a _weighted \(\)-HST_ if for every two edges \(e_{1},e_{2}\) such that \(e_{2}\) is a parent edge of \(e_{1}\), it holds that \(c(e_{2}) c(e_{1})\).

The following result is often used for embedding general metric spaces into weighted HSTs; it involves composing the embeddings of Fakcharoenphol et al.  and Bansal et al. .

**Theorem 3.3** (Due to  and ).: _For every metric space \((X,)\) and constant \(\), there exists a distribution \(\) over weighted \(\)-HSTs of depth \(O(|X|)\) in which the points in \(X\) are the leaves of the HST, such that for every two points \(x_{1},x_{2} X\) we have:_

1. \((x_{1},x_{2})_{T}(x_{1},x_{2})\) _for every_ \(T\) _in the support of_ \(\)_._
2. \(_{T}[_{T}(x_{1},x_{2})] O(|X| )(x_{1},x_{2})\)_._

The algorithm starts by embedding the induced metric space of \(S\) into a weighted HST using Theorem 3.3; \(T\) denotes the resulting tree, and \(r\) denotes its root. For each edge \(e T\), we denote by \(c(e)\) the cost of the edge \(e\). Denote the set of leaves in the subtree rooted at \(v\) by \(L(v)\); note that \(L(r)=S\). Denote the distance between two nodes \(u,v\) in the tree by \(_{T}(u,v)\). For every point \(u X\), define \(p(u):=_{u^{} S}(u,u^{})\); that is, \(p(u)\) is the closest predicted point to \(u\) (abusing notation, we similarly define \(p(q)\) for request \(q\)).

**Proxy list.** After embedding \(S\) into the leaves of a tree, the algorithm must open facilities on those leaves to serve requests. Intuitively, at any point the algorithm considers some (possibly internal) node \(v T\), and considers connecting the current request through \(v\) to a facility in \(L(v)\). Choosing from \(L(v)\) introduces a tradeoff between the cost of opening the facility and its distance from \(v\). For every \(v\), we identify the leaves in \(L(v)\) which offer the best points in this tradeoff (i.e., a Pareto frontier), and only allow the algorithm to choose from these leaves. This subset is called the _proxy list_ of \(v\), and denoted \(P(v) L(v)\).

We now define the proxy list \(P(v)\). For ease of notation, define the logarithmic class operator \((x):= x\). For node \(v T\), we construct the proxy list \(P(v) L(v)\) as follows:

1. Start with \(V L(v)\).
2. While there exist distinct \(v_{1},v_{2} V\) such that \((o_{v_{1}})(o_{v_{2}})\) and \((_{T}(v,v_{1}))(_{T}(v,v_{2}))\), remove \(v_{1}\) from \(V\).
3. Output \(V\) as \(P(v)\).

We denote by \(k(v)\) the size of the proxy list \(P(v)\). We order the proxy list of \(v\) by increasing facility cost, thus writing \(P(v)=(s_{1}^{v},,s_{k(v)}^{v})\). For every \(v,i\), we use the shorthands \(o_{i}^{v}:=o_{s_{i}^{v}}\) and \(_{i}^{v}:=_{T}(v,s_{i}^{v})\). Slightly abusing notation, for every node \(v T\) we define \(c(v):=c(e_{v})\) where \(e_{v}\) is the edge connecting \(v\) to its parent node (for \(r\), we define \(c(r)=\)). For a more streamlined notation, for every node \(v T\) we define \(_{0}^{v}:=c(v)\) and \(o_{k(v)+1}^{v}:=\).

**Observation 3.4**.: _For every node \(v T\), the proxy list \(P(v)\) satisfies:_

1. _For every_ \(u L(v)\)_, there exists index_ \(i\) _such that_ \((o_{i}^{v})(o_{u})\) _and_ \((_{t}^{v})(_{T}(v,u))\)_._
2. _For every distinct_ \(1 i<j k(v)+1\)_, it holds that_ \((o_{i}^{v})<(o_{j}^{v})\)_._
3. _For every distinct_ \(0 i<j k(v)\)_, it holds that_ \((_{i}^{v})>(_{j}^{v})\)_._

When \(i=0\), the third item in Observation 3.4 uses the fact that \(T\) is a weighted \(3\)-HST; thus, the cost of an edge is at least twice the distance from the child node of that edge to any descendant leaf.

**Counters.** For every node \(v\) and every \(i\{1, k(v)+1\}\), we define a counter \((v,i)\) of size \(o_{i}^{v}\).

**Algorithm description.** The algorithm for facility location with predictions is given in Algorithm 2. Initially, the algorithm embeds the metric space induced by \(S\) into a weighted \(3\)-HST \(T\), using Theorem 3.3; upon each node in this \(T\) the proxy lists are computed, and the corresponding counters are assigned. Upon the release of a request \((q,)\), the function UponRequest is triggered. Upon receiving \((q,)\), it maps the request to the closest point \(p(q)\) in \(S\) (that is, a leaf of the HST). Then, the algorithm attempts to solve the request on the HST through a process of increasing counters, which we soon describe. (While the described algorithm raises these counters continuously, the process can easily be discretized, replacing the continuous growth with jumping discretely to the next event.) The algorithm keeps track of (some measure of) the cost involved; if during UponRequest that amount exceeds the penalty \(\), the algorithm pays the penalty instead (see Line 9).

When solving the request on \(u=p(q)\), the algorithm climbs up the branch of \(u\), until a facility is found (or opened) to connect \(u\). At each ancestor \(v\) of \(u\), the algorithm invests a growing amount \(_{v}\) in advancing the proxy list of \(v\) (i.e., buying a facility in \(P(v)\) closer to \(v\)). It raises the counter for the next item on the proxy list until full, at which point the relevant proxy facility is opened, and the next counter in the proxy list begins to increase. (Note that the same facility can be "opened" more than once due to being on multiple proxy lists.) Once \(_{v}\) reaches the cost of connecting \(v\) to an open proxy, the algorithm stops increasing counters and makes the connection. When no proxy in \(P(v)\) is open, it could be that \(_{v}\) exceeds the cost of moving from \(v\) to its parent \(p(v)\); in this case, we ascend the branch and explore proxies for \(p(v)\). Note that the function UponRequest of Algorithm 2 also returns a value; this return value is the online amortization cost of the request, to be used in the analysis of the algorithm. (See Figure 1 for an example.)

The analysis of Algorithm 2, and the proof of Theorem 3.1, appear in Appendix A.

## 4 Online Set Cover

In this section, we present and analyze an algorithm for prize-collecting fractional set cover which uses the well-known multiplicative updates method, and show that it is Lagrangian subset-competitive. Using this algorithm together with Algorithm 1 yields Theorem 1.3 (the proof appears in Appendix C).

Preliminaries.In prize-collecting fractional set cover, we are given a universe with elements \(E\) and sets \(U\); we define \(m:=|U|\). A solution may fractionally buy sets, according to a cost function \(c\). Requests then arrive online, where each request is for covering some element \(e E\), which is contained in some subfamily of sets from \(U\). To cover an element, an algorithm must hold fractions of sets containing \(e\) which sum to at least 1. Observe that fractional set cover with predictions conforms to the definition of an online covering problem with predictions; in this problem, the items are the sets. For prize-collecting fractional set cover, we prove the following theorem.

**Theorem 4.1**.: _There exists a deterministic algorithm \(\) for prize-collecting fractional set cover that \(\) is Lagrangian \(O( m)\)-subset-competitive_

Theorem 4.1 implies that, in the framework of Algorithm 1, our algorithm can be used as the general component, independent of the prediction. But, given a prediction \(S U\), we can simply restrict the

Figure 1: A possible state of Algorithm 2, immediately before connecting a request \(q\). Here, \(q\) has been mapped to \(u\), which is the closest point in \(S\). The variable \(v\), an ancestor of \(u\), is shown, as is its proxy list \(s_{1}^{v},s_{2}^{v},s_{3}^{v}\). The counters of the proxy list are also shown: \((v,1)\) is full (and a facility thus exists in \(s_{1}^{v}\)), and \((v,2)\) is partial (the last counter to be raised handling \(q\)). At some point, the growth in the counters of \(v\) exceeded the distance from \(v\) to \(s_{1}^{v}\), and thus the connection of \(q\) to \(s_{1}^{v}\) is made.

family of sets used by the algorithm to the given prediction, yields an algorithm competitive against \(_{S}\). Thus, Theorem 4.1 immediately yields the following corollary.

**Corollary 4.2**.: _There exists a deterministic algorithm \(\) for prize-collecting fractional set cover such that \(\) is Lagrangian \(O( m^{})\)-subset-competitive w.r.t. prediction \(S U\), where \(|S|=m^{}\)._

The Algorithm.The algorithm for prize-collecting set cover is given in Algorithm 3. The algorithm follows the standard multiplicative updates method: while the pending request is uncovered, sets containing that request are bought at an exponential rate (see ). However, in this prize-collecting version, the algorithm never lets its cost for a specific request exceed its penalty. For ease of notation, define \(U(q)\) to be the collection of sets containing \(q\); that is, \(U(q):=\{s U|q s\}\).

**Analysis.** Where the input \(Q\) is fixed, and for \((q,) Q\), we use \((q,)\) as a shorthand for \((\{(q,)\}|Q)\); i.e., the cost of \(\) when handling the request \((q,)\) as part of \(Q\). We prove the two following lemmas:

**Lemma 4.3**.: _For every \((q,) Q\), it holds that \((q,) 3\)._

**Lemma 4.4**.: _For every subset \(Q^{} Q\), we have \((Q^{}|Q) O( m)(})\), where \(}\) is the non-prize-collecting input formed from \(Q^{}\)._

These two lemmas imply _penalty-robust subset competitiveness_, a property shown in Proposition C.2 to be equivalent to Lagrangian subset-competitiveness. Thus, we focus on proving these lemmas; note that the proof of Lemma 4.4 appears in Appendix F.

**Proposition 4.5**.: _In every iteration of \((q,)\), it holds that the total buying cost is at most \(2y_{q}\), where \(y_{q}\) is the final value of the variable of the same name._

Proof.: Consider each time \(y_{q}\) is incremented. The total cost of buying sets is the following.

\[_{s U(q)}c_{s}(x_{s}}+ })=1+_{s U(q)}x_{s} 2\]

where the inequality is due to the fact that \(_{s U(q)}x_{s} 1\). Thus, each time \(y_{q}\) is incremented by \(1\), the cost of buying sets is at most \(2\), completing the proof. 

Proof of Lemma 4.3.: Consider \((q,)\). If it returned through Line 11, it holds that \(y_{q}\); Proposition 4.5 shows that the total buying cost was thus at most \(2\), and this cost is also \((q,)\). Otherwise, the function returned through Line 8; in this case, since \(y_{q}\) was incremented immediately before comparing \(y_{q}\) to \(\), the argument from the proof of Proposition 4.5 implies that the total buying cost is at most \(2(y_{q}-1)\) (using the final value of \(y_{q}\)). In turn, this is at most \(2\). In addition, the algorithm paid the penalty of \(\); overall, \((q,) 3\). 

Proof of Theorem 4.1.: Lemma 4.3 and Lemma 4.4 show that the algorithm is \(O( m)\)-PRSC; Proposition C.2 then yields that the algorithm is Lagrangian \(O( m)\)-subset-competitive. 

## 5 Experiments

Input Generation.Our set cover instances contain \(100\) elements. (The number of sets will vary in the experiments.) Every set contains every element with some constant probability \(\) (we choose \(=0.02\)); that is, the input is represented by a random bipartite graph in which each edge manifests independently. Since this may not cover every element, we also add singleton sets for all elements. We generate random costs for the sets, independently drawn from a log-normal distribution (\(=0,=1.6\)). For a given input, we generate a prediction in the following way:

1. Using an LP solver, we obtain an optimal fractional solution to the problem instance.
2. We randomly round the solution, such that every set appears in the prediction with probability proportional to its value in the fractional solution.
3. We apply noise to the prediction, of two types: false-positive noise, in which every set is added to the prediction with some probability \(p\); and false-negative noise, in which every set is removed from the prediction with some probability \(q\). (The reader should think of \(p\) and \(q\) as the classification error where the predictions were generated using a classifier.)4. Finally, we add the singleton sets to the prediction, to ensure that the prediction covers all elements.

Baselines and evaluation.We evaluate our algorithm described in Section 4, denoted SmoothMerge, against three baselines: the standard online algorithm without predictions, denoted On; the online algorithm restricted to predicted sets, denoted PredOn; and the standard merging BaseMerge of those two algorithms, which alternates between On and PredOn whenever the overall cost doubles. For every choice of parameters, we measure the costs of the four algorithms; these costs are then averaged over 300 different random inputs. We then measure the expected competitive ratio of each algorithm. Our experiments were run on an AWS EC2 r5.16xlarge machine.

We ran the following experiments: (a) we vary the false-positive rate \(p\) and the false-negative rate \(q\) keeping the number of sets fixed at 10000 (Table 1), and (b) we vary the number of sets in the input, fixing \(p=0.005,q=0.15\) (Figure 2).

Experimental Results.We ran two sets of experiments. In the first experiment, we varied the false-positive rate \(p\) and the false-negative rate \(q\) keeping the number of sets fixed at 10000. The results are reported in Table 1. We note that our algorithm SmoothMerge outperforms the standard merging algorithm BaseMerge and the online algorithm without predictions On consistently across all values of \(p,q\). SmoothMerge also outperforms PredOn, the online algorithm restricted to the prediction, except when there are no false negatives, i.e., \(q=0\). This is to be expected because \(q=0\) implies that there is a good solution contained in the prediction. When \(q>0\), PredOn fails miserably and our algorithm SmoothMerge obtains a competitive ratio that is an order of magnitude better than PredOn. This demonstrates the lack of robustness of PredOn because it is specifically tuned to correct predictions.

In the second set of experiments, we varied the number of sets in the input fixing the noise rates \(p=0.005,q=0.15\). The results are reported in Figure 2. Our algorithm SmoothMerge consistently outperforms all the baseline algorithms. In particular, it is able to utilize predictions to outperform On, which the standard merging BaseMerge is unable to achieve. Moreover, as the number of sets in the input grows, the gap between the two merging solutions increases.

## 6 Discussion

In this paper, we presented a novel framework for smooth interpolation between robustness and consistency guarantees in learning-augmented online algorithms, and applied it to set cover and facility location. More broadly, predictions for online algorithms are of two forms: prediction of the input and that of the solution. The notion of discrete-smoothness applies to any online combinatorial problem in the latter category, i.e., where a solution is provided in the form of a prediction to the algorithm. Many problems have been considered in this model including rent or buy problems, scheduling, matching, graph problems, etc. For all of these problems, the discrete-smoothness framework alleviates the need for problem-specific notions of prediction error and instead gives a common framework for arguing about the gradual degradation of solution quality with increase in prediction error. We hope that the current work will streamline the desiderata for learning-augmented online algorithms by adding this problem-independent notion of smoothness to the established (and also problem-independent) properties of consistency and robustness.