# The Well: a Large-Scale Collection of Diverse

Physics Simulations for Machine Learning

Ruben Ohana \({}^{1,2,}\), Michael McCabe \({}^{1,*}\), Lucas Meyer \({}^{1}\), Rudy Morel \({}^{1,2}\),

Fruzsina J. Agocs \({}^{2,3,}\), Miguel Beneitez \({}^{4,}\), Marsha Berger \({}^{2,5,}\), Blakesley Burkhart \({}^{2,6,}\),

Stuart B. Dalziel \({}^{4,}\), Drummond B. Fielding \({}^{2,7,}\), Daniel Fortunato \({}^{2,}\),

Jared A. Goldberg \({}^{2,}\), Keiya Hirashima \({}^{1,2,8,}\), Yan-Fei Jiang \({}^{2,}\), Rich R. Kerswell \({}^{4,}\),

Suryanarayana Maddu \({}^{2,}\), Jonah Miller\({}^{9,}\), Payel Mukhopadhyay \({}^{10,}\), Stefan S. Nixon \({}^{4,}\),

Jeff Shen \({}^{11,1}\), Romain Watteaux \({}^{12,}\), Bruno Regaldo-Saint Blancard \({}^{1,2}\),

Francois Rozet\({}^{1,13}\), Liam H. Parker\({}^{1,2,10}\), Miles Cranmer \({}^{1,4}\), Shirley Ho

\({}^{1}\) Polymathic AI \({}^{2}\) Flatiron Institute \({}^{3}\) University of Colorado, Boulder \({}^{4}\) University of Cambridge

\({}^{5}\) New York University \({}^{6}\) Rutgers University \({}^{7}\) Cornell University \({}^{8}\) University of Tokyo

\({}^{9}\) Los Alamos National Laboratory \({}^{10}\) University of California, Berkeley

\({}^{11}\) Princeton University \({}^{12}\) CEA DAM \({}^{13}\) University of Liege

Equal contribution. Contact: {rohana, mmccabe}@flatironinstitute.orgDomain expert, alphabetical order.

###### Abstract

Machine learning based surrogate models offer researchers powerful tools for accelerating simulation-based workflows. However, as standard datasets in this space often cover small classes of physical behavior, it can be difficult to evaluate the efficacy of new approaches. To address this gap, we introduce _the Well_: a large-scale collection of datasets containing numerical simulations of a wide variety of spatiotemporal physical systems. The Well draws from domain experts and numerical software developers to provide 15TB of data across 16 datasets covering diverse domains such as biological systems, fluid dynamics, acoustic scattering, as well as magneto-hydrodynamic simulations of extra-galactic fluids or supernova explosions. These datasets can be used individually or as part of a broader benchmark suite. To facilitate usage of the Well, we provide a unified PyTorch interface for training and evaluating models. We demonstrate the function of this library by introducing example baselines that highlight the new challenges posed by the complex dynamics of the Well. The code and data is available at [https://github.com/PolymathicAI/the_well](https://github.com/PolymathicAI/the_well).

## 1 Introduction

Simulation is one of the most ubiquitous and important tools in the modern computational science and engineering toolbox. From forecasting , to optimization , to parameter inference , practitioners lean heavily on simulation to evaluate how physical systems will evolve over time in response to varying initial conditions or stimuli. For many physical phenomena, this evolution can be described by systems of _partial differential equations_ (PDEs) which model fundamental physical behavior aggregated to the continuum level under different material assumptions. Unfortunately, finding analytical solutions is infeasible for all but restricted classes of PDEs . As a result, _numerical methods_ which solve discretized versions of these equations with well-understood convergence and approximation properties have become the preeminent approach in this space. However, in some cases, numerical methods can provide accuracy in excess of what is needed for applications at significant computational cost while lower resolution direct simulation may not resolve key features of the dynamics. This has spurred the development of faster, simplified models referred to as _surrogate models_ that resolve only the essential features for a given scale of simulation .

It is this surrogate modeling space where deep learning is poised to make a significant impact [11; 12; 13] with tangible results already demonstrated across diverse sets of fields and applications [3; 14; 15; 16; 17; 18]. Yet despite these successes, deep learning based surrogates face significant challenges in reaching broader adoption. One reason for this is the gap between the complexity of problems of practical interest and the datasets used for evaluating these models today. Scaling analysis has shown that deep learning-based surrogates can require large amounts of data to reach high accuracy [19; 20]. Meanwhile, even at resolutions accessible to modern machine learning architectures, high-quality scientific simulation can require the combination of specialized software, domain expertise, and months of supercomputer time . On the other hand, from the perspective of scientists running these simulations, even just storing the frequent snapshots necessary for conventional off-line deep learning training is a significant and unnecessary expense [22; 23; 24]).

To address this gap, we introduce _the Well_, a diverse 15 TB collection of high quality numerical simulations produced in close collaboration with domain experts and numerical software developers. The Well is curated to provide challenging learning tasks at a scale that is approachable to modern machine learning but where efficiency remains an important concern. It contains 16 datasets ranging across application domains, scales, and governing equations from the evolution of biological systems to the growth of galaxies. Each dataset contains temporally coarsened snapshots from simulations of a particular physical phenomenon across multiple initial conditions or physical parameters, while providing a sufficiently large number of snapshots to explore simulation stability. Furthermore, the Well provides machine learning researchers with complex, demanding benchmarks that will inform the development of the next generation of data-driven surrogates.

## 2 Related Work

Modern machine learning relies on massive, curated and diverse datasets [25; 26; 27; 28]. Natural language processing is built on internet-scale datasets [29; 30; 31; 32], while vision models have grown to utilize sets containing billions of text-images pairs . These datasets are sufficiently diverse that model improvement can be derived from sophisticated filtering approaches [34; 32; 35].

On the other hand, datasets designed for physical dynamics prediction are still growing. Early datasets featured a variety of common reference simulations [36; 37; 38]. While these datasets have seen rapid adoption, the broader trend has moved towards more complex but specialized simulation datasets [39; 40; 41; 42; 43; 44; 45]. These have opened new application areas for deep learning but have typically been limited to a small number of tasks. Other datasets have tackled more ambitious high-resolution problems [46; 47; 48], but the limited number of snapshots and scale of individual samples often restricts their usage. New datasets which offer complexity, volume, and diversity simultaneously are necessary for holistic evaluation of individual models and for the emerging trend of multiple physics foundation models [49; 50; 51; 52; 53; 54]. The Well provides unified access to a collection of physical scenarios and benchmarking tools that are both diverse and challenging.

## 3 Diving into the Well

While the Well can be used for many tasks, several of which are highlighted in Appendix D, the one we focus on is _surrogate modeling_. Surrogate models estimate a solution function \((x,t)\) to a partial differential equation from some basic inputs, most commonly initial conditions \(U(x,0)\) and/or boundary conditions. This is often, but not always, cast as an autoregressive prediction problem where time is discretized into samples at \(t\!\!\{t_{1},\!t_{2},\!...,\!t_{T}\}\) and model \(f\) is then trained to predict:

\[(x,\!t_{i+1})\!=\!f((x,\!t_{i}))\]

where \((x,\!0)\!=\!U(x,\!0)\) until the solution estimate has been generated for all \(t\). We note that for 2D data with a uniform spatial discretization, this process closely resembles video generation.

**Format.** The Well is composed of 16 datasets totaling 15TB of data with individual datasets ranging from 6.9GB to 5.1TB. The data is provided on uniform grids and sampled at constant time intervals. Data and associated metadata are stored in self-documenting HDF5 files . All datasets use a shared data specification described in the supplementary materials and a PyTorch  interface is provided. These files include all available state variables or spatially varying coefficients associated with a given set of dynamics in numpy  arrays of shape (n_traj, n_steps, coord1, coord2, (coord3)) in single precision fp32. We distinguish between scalar, vector, and tensor-valued fields due to their different transformation properties. Each file is randomly split into training/testing/validation sets with a respective split of 0.8/0.1/0.1 * n_traj. Details of individual datasets are given in Table 1.

**Extensibility.** The PyTorch interface can process any data file following the provided specification without any additional modification to the code base. Scripts are provided to check whether HDF5 files are formatted correctly. This allows users to easily incorporate third-party datasets into pipelines using the provided benchmarking library.

### Contents of the Well

This section provides physical intuition and background for the scenarios contained in the datasets along with visualizations in Figures 1-5. Technical details on the underlying physics, fields, physical parameters, and the generating processes for the datasets are given in Appendix C.

#### 3.1.1acoustic_scattering

Acoustic scattering possesses simple linear dynamics that are complicated by the underlying geometry. In this dataset, we model the propagation of acoustic waves through a domain consisting of substrata with sharply variable density in the form of maze-like walls (Figure 1, top) or pockets with vastly differing compositions. These simulations are most commonly seen in inverse problems including source optimization and inverse acoustic scattering in which sound waves are used to probe the composition of the domain.

#### 3.1.2active_matter

Active matter systems are composed of agents, such as particles or macromolecules, that transform chemical energy into mechanical work, generating active forces or stresses. These forces are transmitted throughout the system via direct steric interactions, cross-linking proteins, or long-range hydrodynamic interactions, leading to complex spatiotemporal dynamics (Figure 1, middle). These simulations specifically focus on active particles suspended in a viscous fluid leading to orientation-dependent viscosity with significant long-range hydrodynamic and steric interactions.

#### 3.1.3convective_envelope_rsg

Massive stars evolve into red supergiants (RSGs), which have turbulent and convective envelopes. Here, 3D radiative hydrodynamic (RHD) simulations model these convective envelopes, capturing inherently 3D processes like convection (Figure 1, bottom). The simulations give insight into a variety of phenomena: the progenitors of supernovae (SN) explosions and the role of the 3D gas distribution in early SN ; calibrations of mixing-length theory (used to model convection in 1D ); the granulation effects caused by large-scale convective plumes and their impacts on interferometric and photometric observations .

   Dataset & CS & Resolution (pixels) & n\_steps & n\_traj \\  acoustic\_scattering & (\(x\),\(y\)) & \(256\!\!256\) & \(100\) & \(8000\) \\ active\_matter & (\(x\),\(y\)) & \(256\!\!256\) & \(81\) & \(360\) \\ convective\_envelope\_rsg & (\(r\),\(\),\(\)) & \(256\!\!128\!\!256\) & \(100\) & \(29\) \\ euler\_multi\_ quadrants & (\(x\),\(y\)) & \(512\!\!512\) & \(100\) & \(10000\) \\ gray\_scott\_reaction\_diffusion & (\(x\),\(y\)) & \(128\!\!128\) & \(1001\) & \(1200\) \\ helmholtz\_staircase & (\(x\),\(y\)) & \(1024\!\!256\) & \(50\) & \(512\) \\ MHD & (\(x\),\(y\),\(z\)) & \(64^{3}\) and \(256^{3}\) & \(100\) & \(100\) \\ planetswe & (\(\),\(\)) & \(256\!\!512\) & \(1008\) & \(120\) \\ post\_neutron\_star\_merger & (\(\),\(\),\(\)) & \(192\!\!128\!\!66\) & \(181\) & \(8\) \\ rayleigh\_benard & (\(x\),\(y\)) & \(512\!\!128\) & \(200\) & \(1750\) \\ rayleigh\_taylor\_instability & (\(x\),\(y\),\(z\)) & \(128\!\!128\) & \(120\) & \(45\) \\ shear\_flow & (\(x\),\(y\)) & \(256\!\!512\) & \(200\) & \(1120\) \\ supernova\_explosion & (\(x\),\(y\),\(z\)) & \(64^{3}\) and \(128^{3}\) & \(59\) & \(1000\) \\ turbulence\_gravity\_cooling & (\(x\),\(y\),\(z\)) & \(64\!\!64\!\!64\) & \(50\) & \(2700\) \\ turbulent\_radiative\_layer\_2D & (\(x\),\(y\)) & \(128\!\!384\) & \(101\) & \(90\) \\ turbulent\_radiative\_layer\_3D & (\(x\),\(y\),\(z\)) & \(128\!\!128\!\!256\) & \(101\) & \(90\) \\ viscoelastic\_instability & (\(x\),\(y\)) & \(512\!\!512\) & variable & \(260\) \\   

Table 1: Dataset description: coordinate system (CS), resolution of snapshots, n_steps (number of time-steps per trajectory), n_traj (total number of trajectories in the dataset).

[MISSING_PAGE_EMPTY:4]

#### 3.1.8 planetswe

The shallow water equations approximate incompressible fluid flows where the horizontal length scale is significantly larger than the vertical as a depth-integrated two-dimensional problem. They have played an important roll in the validation of dynamical cores for atmospheric dynamics as seen in the classical Williamson problems . These simulations can be seen as a refinement of Williamson 7 as they are initialized from the hPa500 level of the ERA5 reanalysis dataset  with bathymetry corresponding to the earth's topography and featuring forcings with daily and annual periodicity (Figure 3, middle).

Figure 3: Top to bottom row: snapshots at \(t=\{0,\,,\,,\,T\}\) of MHD, planetswe and post_neutron_star_merger.

Figure 2: Top to bottom row: snapshots at \(t=\{0,\,,\,,\,T\}\) of euler_multi_quadrants, gray_scott_reaction_diffusion, and helmholtz_staircase

#### 3.1.9 post_neutron_star_merger

After the in-spiral and merger of two neutron stars, a hot dense remnant is formed. These events, central to gamma ray bursts and heavy element formation, produce a reddening glow called a _kilonova_. Accurate predictions require modeling neutrino interactions, which convert neutrons to protons and vice versa. These simulations model the accretion disk driving the gamma ray burst and the hot neutron-rich wind causing the kilonova (Figure 3, bottom).

#### 3.1.10 rayleigh_benard

Rayleigh-Benard convection  is a phenomenon in fluid dynamics encountered in geophysics (mantle convection , ocean circulation , atmospheric dynamics ), in engineering (cooling systems , material processing ), in astrophysics (interior of stars and planets ). It occurs in a horizontal layer of fluid heated from below and cooled from above. This temperature difference creates a density gradient that can lead to the formation of convection currents, where warmer, less dense fluid rises, and cooler, denser fluid sinks (Figure 4, top).

#### 3.1.11 rayleigh_taylor_instability

The Rayleigh-Taylor instability  is comprised of two fluids of different densities initially at rest. The instability arises from any perturbation that will displace a parcel of heavier fluid below a parcel of lighter fluid (Figure 4, middle). Pressure forces are then not aligned with density gradients and this generates vorticity, increasing the amplitude of the perturbations. Eventually, these amplitudes become so large that non-linear turbulent mixing develops.

#### 3.1.12 shear_flow

Shear flow phenomena  occurs when layers of fluid move parallel to each other at different velocities, creating a velocity gradient perpendicular to the flow direction (Figure 4, bottom). This can lead to various instabilities and turbulence, which are fundamental to many applications in engineering (e.g., aerodynamics ), geophysics (e.g., oceanography ), and biomedicine (e.g. biomechanics ).

### supernova_explosion_64 and supernova_explosion_128

Supernova explosions happen at the end of the lives of some massive stars. These explosions release high energy into the interstellar medium (ISM) and create blastwaves. The blastwaves accumulate in the ISM and form dense, sharp shells, which quickly cool down and can be new star-forming regions (Figure 5, top). These small explosions have a significant impact on the entire galaxy's evolution.

Figure 4: Top to bottom row: snapshots at \(t=\{0,\ ,\ ,\ T\}\) of rayleigh_benard, rayleigh_taylor_instability and shear_flow.

### turbulence_gravity_cooling

Within the interstellar medium (ISM), turbulence, star formation, supernova explosions, radiation, and other complex physics significantly impact galaxy evolution. This ISM is modeled by a turbulent fluid with gravity. These fluids make dense filaments (Figure 5, second row), leading to the formation of new stars. The timescale and frequency of making new filaments vary with the mass and length of the system.

#### 3.3.1 turbulent_radiative_layer_2D and turbulent_radiative_layer_3D

In astrophysical environments, cold dense gas clumps move through a surrounding hotter gas, mixing due to turbulence at their interface. This mixing creates an intermediate temperature phase that cools rapidly by radiative cooling, causing the mixed gas to join the cold phase as photons escape and energy is lost (Figure 5, third row). Simulations and theories show that if cooling is faster (slower) than mixing, the cold clumps will grow (shrink) . These simulations  describe the competition between turbulent mixing and radiative cooling at a mixing layer. These simulations are available in 2D and 3D.

#### 3.3.2 viscoelastic_instability

In two-dimensional dilute polymer solutions, the flow exhibits four coexistent attractors: the laminar state, a steady arrowhead regime (SAR), a chaotic arrowhead regime (CAR), and a (recently discovered) chaotic regime of elasto-inertial turbulence (EIT). SAR corresponds to a simple traveling wave, while CAR and EIT are visually similar but differ by a weak polymer arrowhead structure across the mid-plane in CAR. These simulations  are snapshots (Figure 5, bottom) of the four attractors and two edge states. Edge

Figure 5: Top to bottom row: snapshots at \(t=\{0,,,T\}\) of supernova_explosion, turbulence_gravity_cooling turbulent_radiative_layer_2D and viscoelastic_instability.

states exist on the boundary between two basins of attraction and have a single unstable direction, marking the boundary between different flow behaviors.

## 4 Benchmark

To showcase the dataset and the associated benchmarking library, we provide a set of simple baselines time-boxed to 12 hours on a single NVIDIA H100 to demonstrate the effectiveness of naive approaches on these challenging problems and motivate the development of more sophisticated approaches. These baselines are trained on the forward problem - predicting the next snapshot of a given simulation from a short history of 4 time-steps. The models used here are the Fourier Neural Operator [97, FNO], Tucker-Factorized FNO [98, TFNO], U-net  and a modernized U-net using ConvNext blocks [100, CNextU-net]. The neural operator models are implemented using neuralop .

We emphasize that these settings are not selected to explore peak performance of modern machine learning, but rather that they reflect reasonable compute budgets and off-the-shelf choices that might be selected by a domain scientist exploring machine learning for their problems. Therefore we focus on popular models using settings that are either defaults or commonly tuned. Full training and hyperparameter details are included in Appendix E.1.

**Results.** Table 2 reports the one-step Variance Scaled Root Mean Squared Error (VRMSE) - defined in Section E.3 - averaged over all physical fields. Table 3 reports VRMSE averaged over time windows in longer rollouts. We report VRMSE over the more common Normalized RMSE (NRMSE) - also defined in the appendix - as we feel the centered normalization is more appropriate for non-negative fields such as pressure or density whose mean is often bounded away from zero. NRMSE, whose denominator is the 2-norm, down-weights errors with respect to these fields even if they have very little variation. We report evaluation on the test set of each model with hyperparameters performing best on the validation set.

**Analysis.** In the next-step prediction setting, the CNextU-net architecture outperforms the others on 8 of the 17 experiments. However, what is very interesting is that there is a noticeable split between problems which favor spatial domain handling and those which prefer the spectral approach. At the one-step level, 9/17 favor U-net type models while 8 favor spectral models. While in some cases, the results are close, in others, one class of models has a clear advantage. The reason for this is not immediately clear. Boundary conditions would be a natural hypothesis as the boundary condition are handled naively according to model defaults which vary between the U-net and FNO-type models, but there is no clear trend in this direction. This performance gap holds if we instead look at the time-averaged losses for different windows of multi-step autoregressive rollouts in Table 3, though we see notably worse performance overall even

    &  \\   & FNO & TFNO & U-net & CNextU-net \\  acoustic\_scattering(maze) & 0.5062 & 0.5057 & 0.0351 & **0.0153** \\ active\_matter & 0.3691 & 0.3598 & 0.2489 & **0.1034** \\ convective\_envelope\_rsg & **0.0269** & 0.0283 & 0.0555 & 0.0799 \\ euler\_multi\_quadrants (periodic b.c.) & 0.4081 & 0.4163 & 0.1834 & **0.1531** \\ gray\_scott\_reaction\_diffusion & **0.1365** & 0.3633 & 0.2252 & 0.1761 \\ helmholtz\_staircase & **0.00046** & 0.00346 & 0.01931 & 0.02758 \\ MHD\_64 & 0.3605 & 0.3561 & 0.1798 & **0.1633** \\ planet\& 0.1727 & **0.0853** & 0.3620 & 0.3724 \\ post\_neutron\_star\_merger & 0.3866 & **0.3793** & — & — \\ rayleigh\_benard & 0.8395 & **0.6566** & 1.4860 & 0.6699 \\ rayleigh\_taylor\_instability (At = 0.25) & \(>\)10 & \(>\)10 & \(>\)10 & \(>\)10 \\ shear\_flow & 1.189 & 1.472 & 3.447 & **0.8080** \\ supernova\_explosion\_64 & 0.3783 & 0.3785 & **0.3063** & 0.3181 \\ turbulence\_gravity\_cooling & 0.2429 & 0.2673 & 0.6753 & **0.2096** \\ turbulent\_radiative\_layer\_2D & 0.5001 & 0.5016 & 0.2418 & **0.1956** \\ turbulent\_radiative\_layer\_3D & 0.5278 & 0.5187 & 0.3728 & **0.3667** \\ viscoelastic\_instability & 0.7212 & 0.7102 & 0.4185 & **0.2499** \\   

Table 2: **Model Performance Comparison: VRMSE metrics on test sets (lower is better). Best results are shown in **bold**. VRMSE is scaled such that predicting the mean value of the target field results in a score of 1.

on these relatively short rollouts indicating the difficulty of performing autoregressive rollouts from one-step training alone. The performance gap between these model classes suggests that one-model-fits-all approaches in this space may be difficult.

Furthermore, there are two observations that may be unexpected to the reader in Table 3. First, loss sometimes decreases in later windows. This can be explained by the problem physics. Dissipative solutions become smoother or better mixed as time progresses and thus easier to predict. Though in the cases where we observe this happening, the normalized loss is typically quite large in either case. The second trend is that losses in Table 2 do not always line up with Table 3. This is due to a difference in experiment setup. Longer rollouts are always initiated from the beginning of the simulation while one-step evaluation occurs on sliding windows sampled from the ground truth. Thus the difficulty of the two settings can vary depending on the behavior of the ground truth physics.

### Evaluation Metrics

The benchmark library comes equipped with a variety of metrics to inform architecture design in physically meaningful ways. Often, we are interested in more granular analysis than single-valued metrics. For instance, in Figure 6, we explore turbulent_radiative_layer_2D using per-field metrics. We can see that loss varies significantly by field and is concentrated in the pressure (P) field. Similarly, looking at one-step performance, it appears that CNextU-net has a sizable advantage, but when we look at longer time horizons, this advantage quickly dissipates and all models apart from the original U-net become largely interchangeable. The binning of this error over frequency bins provides further insight as we see all models effectively predict low frequency modes in the long run, but high frequency modes diverge more quickly. The full collection of metrics available in the included library is described in Appendix E.3

### Moving Beyond the Baselines

The baseline models employed here are powerful but naive models employed en masse without accounting for the specific physical characteristics of the datasets. These are just a starting point for analysis with the Well. Areas for further exploration include:

**Physical constraints.** Conservation laws and boundary conditions are both key physical properties that can often be directly controlled by a model . The Well features a variety of conserved quantities and diverse boundary conditions that can vary within a single dataset, making it well-suited to advance such research.

   Dataset &  &  &  &  \\   & 6:12 & 13:30 & 6:12 & 13:30 & 6:12 & 13:30 & 6:12 & 13:30 \\  acoustic\_scattering(maze) & 1.06 & 1.72 & 1.13 & 1.23 & **0.56** & 0.92 & 0.78 & 1.13 \\ active\_matter & 10 & 10 & 7.52 & 4.72 & 2.53 & 2.62 & **2.11** & 2.71 \\ convective\_envelope\_rsg & **0.28** & 0.47 & 0.32 & 0.65 & 0.76 & 2.16 & 1.15 & 1.59 \\ euler\_multi\_quadrants & 1.13 & 1.37 & 1.23 & 1.52 & **1.02** & 1.63 & 4.98 & 10 \\ gray\_scott\_reaction\_diffusion & 0.89 & 10 & 1.54 & 10 & 0.57 & 10 & **0.29** & 7.62 \\ helmholtz\_staircase & **0.002** & 0.003 & 0.011 & 0.019 & 0.057 & 0.097 & 0.110 & 0.194 \\ MHD\_64 & **1.24** & 1.61 & 1.25 & 1.81 & 1.65 & 4.66 & 1.30 & 2.23 \\ planeswise & 0.81 & 2.96 & **0.29** & 0.55 & 1.18 & 1.92 & 0.42 & 0.52 \\ post\_neutron\_star\_merger & 0.76 & 1.05 & **0.70** & 1.05 & — & — & — & — \\ rayleigh\_benard & 10 & 10 & 10 & 10 & 10 & 10 & 10 & 10 \\ rayleigh\_taylor\_instability & 10 & 10 & **6.72** & 10 & 10 & 10 & 2.84 & 10 & 7.43 \\ shear\_flow & 10 & 10 & 10 & 10 & 10 & 10 & **2.33** & 10 \\ supernova\_explosion\_64 & 2.41 & 10 & 1.86 & 10 & **0.94** & 1.69 & 1.12 & 4.55 \\ turbulence\_gravity\_cooling & 3.55 & 5.63 & 4.49 & 6.95 & 7.14 & 4.15 & **1.30** & 2.09 \\ turbulent\_radiative\_layer\_2D & 1.79 & 3.54 & 6.01 & 10 & 0.66 & 1.04 & **0.54** & 1.01 \\ turbulent\_radiative\_layer\_3D & 0.81 & 0.94 & 10 & 10 & 0.95 & 1.09 & **0.77** & 0.86 \\ viscoelastic\_instability & 4.11 & — & 0.93 & — & 0.89 & — & **0.52** & — \\   

Table 3: **Time-Averaged Losses by Window:** VRMSE metrics on test sets (lower is better) averaged over time windows (6-12) and (13-30). Best results are shown in **bold** for (6-12) and underlined for (13-30). VRMSE is scaled such that predicting the mean value of the target field results in a score of 1.

**Long-term stability.** Several prior studies have highlighted the difficulty and importance of stable surrogate models [20; 49; 107; 108]. The Well is designed with these studies in mind with most datasets including at least 50 snapshots per trajectory while some include a thousand or more.

**Further challenges.** While our example baselines target the forward problem, the Well can be used for a variety of other tasks. Several datasets, such as acoustic_scattering and helmholtz_staircase are well-suited for inverse scattering tasks. Others like MHD are coarsened representations of high resolution simulations and could be used for studies of super-resolution. Many contain wide parameter ranges valuable for generalization studies.

We discuss these and other challenges on a per-dataset basis in Appendix D.

## 5 Conclusion

**Limitations.** These datasets are not without their limitations. They focus largely on uniformly sampled domains at manageable resolutions while many engineering problems require higher resolutions and more complicated meshes than most conventional architectures can feasibly process. These resolution limits often push the use of 2D simulation data while real-world applications are almost always 3D, particularly for turbulent instabilities. Additionally, the Well is primarily a data-focused release. Other works acknowledged in Section 2 explore metrics and analysis more thoroughly. Our focus here is on providing challenging, easily-accessible benchmark problems that can be used in a variety of ways. As available VRAM increases or more efficient architectures are developed, the current version of the Well may no longer be challenging and new datasets may be needed to push the community forward.

Nonetheless, the Well is an important step forward in the development of datasets for physical dynamics prediction. Historically, new challenges have been necessary to push the machine learning community forward. The Well has been developed in collaboration with domain experts to identify problems that provide such unique challenges in more ways than just computational cost. As a collection of datasets containing 15 TB and 16 individual physical scenarios representing physical phenomena of interest to a range of scientific fields, the Well provides the community with a valuable combination of complexity, volume, and diversity that we hope will inspire both new developments in surrogate modeling and perhaps unlock new workflows not yet foreseen.

Figure 6: The benchmark library included with the Well includes both coarse and fine level metrics. On the left, we can see the model’s performance in VRMSE across state variables. On the right, we divide the isotropic power spectrum into three bins whose boundaries are evenly distributed in log space and evaluate the growth of RMSE per bin normalized by the true bin energy to examine the model’s ability to consistently resolve the problem scales.