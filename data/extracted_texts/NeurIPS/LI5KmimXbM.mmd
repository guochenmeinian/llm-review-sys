# Association Pattern-aware Fusion for

Biological Entity Relationship Prediction

 Lingxiang Jia\({}^{1}\) Yuchen Ying\({}^{1}\) Zunlei Feng\({}^{1,2}\) Zipeng Zhong\({}^{1}\) Shaolun Yao\({}^{1}\)

Jiacong Hu\({}^{1}\) Mingjiang Duan\({}^{1}\) Xingen Wang\({}^{1,3}\) Jie Song\({}^{1}\) Mingli Song\({}^{1,2}\)

\({}^{1}\)State Key Laboratory of Blockchain and Data Security, Zhejiang University

\({}^{2}\)Hangzhou High-Tech Zone (Binjiang) Institute of Blockchain and Data Security

\({}^{3}\)Bangsheng Technology Co, Ltd.

Correspondence to zunleifeng@zju.edu.cn

###### Abstract

Deep learning-based methods significantly advance the exploration of associations among triple-wise biological entities (e.g., drug-target protein-adverse reaction), thereby facilitating drug discovery and safeguarding human health. However, existing researches only focus on entity-centric information mapping and aggregation, neglecting the crucial role of potential association patterns among different entities. To address the above limitation, we propose a novel association pattern-aware fusion method for biological entity relationship prediction, which effectively integrates the related association pattern information into entity representation learning. Additionally, to enhance the missing information of the low-order message passing, we devise a bind-relation module that considers the strong bind of low-order entity associations. Extensive experiments conducted on three biological datasets quantitatively demonstrate that the proposed method achieves about 4%-23% hit@1 improvements compared with state-of-the-art baselines. Furthermore, the interpretability of association patterns is elucidated in detail, thus revealing the intrinsic biological mechanisms and promoting it to be deployed in real-world scenarios. Our data and code are available at https://github.com/hry98kki/PatternBERP.

## 1 Introduction

Exploring potential associations among triple-wise biological entities (e.g., drug-target protein-adverse reaction)  holds significant implications for elucidating underlying biological mechanisms and advancing personalized therapies , thus promoting pharmaceutical innovation and ensuring human health. Recent deep learning-based methods have propelled auxiliary prediction tasks concerning biological entity relationship, with most focusing on binary associations (e.g., drug-target protein), while only a few methods offer insights for more complex triple-wise associations. Existing solutions for the association prediction task can be broadly categorized into three types: (1) non-graph methods ; (2) graph-based methods ; (3) hypergraph-based methods .

As illustrated in Figure 1, non-graph methods typically concatenate the features of different entities, which are independently mapped by their respective entity encoders, to serve as representations. Graph-based methods adopt nodes and edges of the graph to represent entities and their relationships, and leverage the graph structure for feature propagation, thereby achieving effective representation learning of entity nodes. Similar yet distinct, hypergraph-based methods employ the hypergraph structure to obtain entity representations using the complex feature aggregation strategy. However, none of the aforementioned methods consider the significance of path patterns in the graph structure, which contain a vast amount of crucial information including hidden context and co-occurrence.

To this end, we introduce a novel association pattern-aware message propagation strategy as shown in Figure 1(d). The module leverages the potential relationships, such as commonality and diversity, of association patterns as the rule for facilitating message passing among entity features, which can efficiently expand the potential for representing complex interactions within the perspective of both basic graph structure and intrinsic biological mechanisms. Specifically, the related patterns within the graph structure are sampled through the pre-defined distance relation for each entity node. The message passing is driven by the interaction of its assigned patterns, i.e., the feature of the entity node is subsequently updated through feature fusion using adaptive coefficients that capture pattern commonality, generated during the pattern interaction stage. This process is followed by the acquisition of potential common patterns with genuine biological significance for various entities.

In this paper, we propose a novel Association **Pattern**-aware Fusion method for **B**iological **E**ntity **R**elationship **P**rediction, namely _Pattern-BERP_. First, we devise an association pattern-aware strategy to solve the limitation caused by entity-centric feature mapping and aggregation. The strategy utilizes the association patterns related to each entity node within the graph to extract the common feature based on the attention mechanism for these patterns, thus expanding the ability to represent hidden complex interactions. In addition, to preserve the information interaction of different entities, a hypergraph-based block is incorporated with the association pattern-aware fusion module, thereby enhancing the model ability to capture relationships among various types of entities. Furthermore, to explore low-order associations of biological bind relations, we introduce a bind-relation enhancement module which can reconstruct missing feature of bind-relation entities and thus generate harder negative sample than random selection. Experimental results conducted on different biological datasets show that the proposed method achieves superior performance compared to advanced baselines, demonstrating its effectiveness and robustness in handling various biological entity relationships. More importantly, the obtained association patterns for the relationship of drug, microbe, and disease are quantitatively visualized with the following biological verification in detail.

Our main contributions are summarized as follow:

* We propose a novel association pattern-aware fusion method for biological entity relationship prediction. The introduce of association pattern-aware strategy can enhance the representation of complex interactions by aggregate features with potential association patterns.
* A bind-relation enhancement module is devised to acquire low-order associations that reveal the biological bind relations, which is essential for reconstructing missing bind-relation entity features and generating challenging negative triplets to enhance the model training.
* Extensive experiments are conducted to verify the superiority of Pattern-BERP, demonstrating its robustness for various biological scenarios. Uniquely compared to the other methods, the interpretability of association patterns is explained to reveal intrinsic biological mechanisms.

Figure 1: Comparisons of feature update strategy among non-graph methods, graph-based methods, hypergraph-based methods, and the proposed association pattern-aware method. Unlike existing methods that map or aggregate node features, the proposed method mines and then fuses association patterns for each target entity node in the graph to enhance the model’s representative ability.

Related Work

In this section, we elaborate on the related work from two distinct yet interconnected perspectives: Biological Entity Relationship Prediction and Network Search and Mining. Each perceptive represents a fundamental aspect of our research, addressing specific challenges and methodologies in applying machine learning techniques to the prediction task.

Biological Entity Relationship Prediction.The latest advancements in artificial intelligence have motivated researchers to employ deep learning methodologies for predicting triple-wise biological entity associations. Hypergraph neural network (HGNN)-based methods [17; 18; 19; 20; 21; 22] have become the mainstream research direction in this field. Tu et al.  proposed a deep hyper-network embedding model to preserve both local and global proximities in the embedding space. Building upon this, Jiang et al.  incorporated a dynamic hypergraph construction strategy to capture the hidden and important relations in data structures. Zhang et al.  developed a self-attention-based graph neural network applicable to homogeneous and heterogeneous hypergraphs with variable hyperedge sizes. Liu et al.  proposed a multi-way relation-enhanced hypergraph representation learning method to predict anti-cancer drug synergy. Liu et al.  proposed a multi-view contrastive learning-enhanced hypergraph model for drug-microbe-disease association prediction. In addition, Chen and Li  attempted to adopt the tensor decomposition strategy to predict which target a drug binds to when administered to a disease, and further proposed a neural tensor network model  that seamlessly combines tensor algebra and deep neural networks to effectively capture the complex nonlinear dependencies among drugs, targets, and diseases.

Network Search and Mining.Network search and mining techniques, particularly those utilizing path information including random walks [25; 26; 27; 28] and meta-path [29; 30; 31; 32], have been widely employed to extract local structural information from networks. These methods have found applications in areas such as content recommendation and community detection [33; 34; 35; 36; 37]. Brin and Page  introduced a classic ranking algorithm PageRank to determine the importance of web pages based on their link structure. Jeh and Widom  adopted a similarity measure based on pairwise random walk, which can capture the structural similarity between nodes, and further extended PageRank with a personalized version . Perozzi et al.  proposed Deepwalk that leverages local random walk information to learn vertex latent representations based on deep learning techniques. These above methods are applicable to homogeneous networks and cannot fully utilize the rich semantic information in heterogeneous networks. To address the limitation, Sun et al.  introduced a meta path-based similarity framework for heterogeneous information networks, which can capture the subtle semantics of similarity among objects of the same type. Dong et al.  proposed a deep learning-based heterogeneous network representation learning method that automatically learns hidden meta-path semantics, generating general node embedding representations. Wang et al.  introduced a graph-based fraud detection method that addresses the issue of low homophily by integrating label information to generate distinguishable neighborhood information. Furthermore within the bioinformatics field, Chen et al.  proposed a computational algorithm that performs random walks on an integrated network to infer potential relations between proteins and ADRs.

In line with the above methods, Pattern-BERP utilizes path information for triple-wise heterogeneous biological network mining. By leveraging the fusion of association patterns, it facilitates message passing among various biological entities, which will be described comprehensively in Section 4.2.

## 3 Problem Formulation

Given three distinct entity types in biological networks, termed as \(=\{a_{1},a_{2},,a_{i},,a_{||}\}\), \(=\{b_{1},b_{2},,b_{j},,b_{||}\}\), and \(=\{c_{1},c_{2},,c_{m},,c_{||}\}\), their Cartesian product \(=\) is a set of all possible triple-wise biological entity associations. For simplicity, the relation \(\)-\(\)-\(\) is used to represent complex relational semantics for biological entities, such as "drug-microbe-disease", "synergistic drug-drug-cell line" or "drug-target protein-adverse reaction".

For each triplet \((a_{i},b_{j},c_{m})\), we assign a label \(p\{0,1\}\). A label of \(p=1\) indicates that the existence of certain association has been confirmed, while \(p=0\) represents an unknown association which denotes that the association is not yet known and could potentially exist. The objective is to develop a credible model that can predict these potential associations from unknown ones.

## 4 Pattern-BERP

To enhance the ability to represent complex interactions, we propose the first association pattern-aware method, termed as _Pattern-BERP_ to extract the rich semantic information embedded within the intricate structures of biological networks. As illustrated in Figure 2, the section is divided into four parts: First, these entity relationships are represented in hypergraph and bipartite graph structures for subsequent module input. Next, the association pattern-aware fusion module is proposed to update entity node feature through association pattern-aware interaction. In addition, the bind-relation enhancement module is introduced to reconstruct bind-relation feature and thus generate hard negative samples. Finally, the detailed summary of loss function and complexity analysis is provided.

### Graph Construction

Given the adjacency relationships among entity nodes, the hypergraph and bipartite graph structures are constructed to facilitate the subsequent extraction of structural information and relational association patterns within the respective graphs, which serve for association pattern-aware fusion module and bind-relation enhancement module.

The attributes of each entity are initialized as node features on the graphs with the domain knowledge of bio-entities through its own type. Finally, the initialized node attributes of \(^{|| d}\) consist of features \(_{}\), \(_{}\) and \(_{}\), where \(d\) denotes the feature dimensional of initialized entity attributes. Details about entity attribute are provided at Appendix A.1.

**Hypergraph Construction.** Triple-wise biological entity associations can be modeled as a hypergraph \(=(,)\), which includes a vertex set \(=\) and a hyperedge set \(\) that represents all known associations. Technically, \(\) is further formulated as an attributed hypergraph with node attributes \(^{|| d}\) and an incidence matrix \(\{0,1\}^{||||}\), which is defined as:

\[h(v,e)=1,&v e\\ 0,&v e.\] (1)

**Bipartite Graph Construction.** The premise of constructing the bind-relation module is to decompose the original triple-wise associations to separately obtain pairwise relations of different types of entities. Since the original triplet is in the form of \((a_{i},b_{j},c_{m})\), and generally the interaction relationships between the three entities are hierarchical (e.g. drug \(a_{i}\) acts on protein \(b_{j}\), and the activated \(b_{j}\) then leads to certain adverse reaction \(c_{m}\)). Hence in this paper, we construct two bipartite

Figure 2: Overall framework of Pattern-BERP. First, entity attributes are initialized with different types of bio-encoders. Then, these existing associations are constructed into one hypergraph \(\) and two bipartite graphs \(_{,}\), \(_{,}\). After that, the hypergraph is encoded with Association Pattern-aware Fusion module based on the pattern commonality, thereby affecting target entity representation. In addition, the bipartite graphs are encoded to output the missing bind-relation feature and thus generate hard negative samples. Finally, the integrated entity feature are used for final association prediction.

graphs: \(_{,_{1}}\) for entity \(\)\(\) entity \(_{1}\)2, \(_{_{2},}\) for entity \(_{2}\)\(\) entity \(\). Then the edge sets of the bipartite graphs can be formulated as:

\[_{,_{1}} =\{(a,b) a,b_{1},\,e a,b e\},\] (2) \[_{_{2},} =\{(b,c) b_{2},c,\,e b,c e\}.\] (3)

Note that, the relationship of \(\)\(\)\(\) is not under consideration due to there is no direct connection in this context. The constructed bipartite graphs \(_{,_{1}},_{_{2},}\) serve as input for bind-relation module.

### Association Pattern-aware Fusion

To comprehensively account for the feature interactions within association patterns, the proposed Association Pattern-aware Fusion (APF) method comprises two fundamental components: Firstly, Association Pattern Sampling (APS) block is designed to sample association patterns by utilizing the distance tokens relevant to target nodes. Secondly, Association Pattern-aware Interaction (API) block is introduced to update node features by message interaction within the sampled association patterns and mine the intrinsic pattern commonality with biological support.

#### 4.2.1 Association Pattern Sampling

**Definition 1**.: Given certain entity node, the distance token between the node and one hyperedge or association pattern is defined as _u-hop_. Here, _1-hop_ patterns represent the hyperedges directly covering the node, _2-hop_ patterns represent the hyperedges directly covering all the _1-hop_ neighbor nodes of the node, and the relation continues for higher hop counts. If the node is unreachable when \(u\) reaches the max step \(U\), we define these patterns as no-relation and set the distance to \(-\).

Based on the above definition3, we generate the distance tokens between each node and all hyperedges, ultimately obtaining a distance matrix \(^{||||}\), defined as follows:

\[d(v,e)=u,&\\ -,&\] (4)

where \(d(v,e)\) represents the defined distance from node \(v\) to pattern \(e\); \(u\) indicates the number of hops from node \(v\) to pattern \(e\).

To represent an entity node with association patterns, the general principle is to prioritize and retain patterns that are closer for each node based on the distance tokens, with a total of \(N\) patterns sampled. Formally, given an entity node \(v\), let \(_{v}^{N}\) and \(_{v}^{N 3d}\) represent the distance tokens and feature vectors of the selected sampled patterns, where each sampled pattern consists of three entity nodes and the \(d\)-dimensional feature embeddings of each node are defined within the initial node embeddings \(\). Then, the output pattern feature \(z_{v}\) for node \(v\) considers the relative position of these related patterns, which is thus formulated as \(_{v}=_{v}+(_{v}),\) where \(()\) denotes the position encoding layer that maps from \(^{N}^{N(3d)}\). Finally, the integrated embedding \(_{v}^{N 3d}\) with distance information is produced for use in the subsequent API block.

#### 4.2.2 Association Pattern-aware Interaction

Before put into the API block, we adopt a hypergraph convolution layer implemented by  on the constructed hypergraph \(\) to facilitate neighbor-based information propagation among different entities. Then the updated node feature \(^{*}\) after hypergraph convolutions is used to construct the feature of patterns mentioned in the APS block, thereby yielding \(_{v}\) for the information interaction of these sampled patterns. Details of hypergraph convolution are provided at Appendix.

**Pattern Interaction.** The API block is designed to search for and extract commonalities among different sampled patterns related to a specific entity node, and thus consists of a composition of Transformer layers . Each Transformer layer has two modules: a multi-head self-attention mechanism (MHA) and a position-wise feed-forward network (FFN). For simplicity, we consider the single-head setting, and the extension to multi-head attention is standard and straightforward. Specifically, let \(^{(0)}=[_{1}^{(0)},,_{||}^{(0)}] ^{|| N(3d)}\) denotes the input of the self-attention module where \(_{v}^{N(3d)}\) is the representation for node \(v\). The input \(_{v}\) is projected by three matrices \(_{Q}^{(3d) d_{K}}\), \(_{K}^{(3d) d_{K}}\), and \(_{V}^{(3d) d_{V}}\) to obtain the corresponding query, key, and value representations \(_{v}\), \(_{v}\), and \(_{v}\) for node \(v\):

\[_{v}=_{v}_{Q},_{v}=_{v} _{K},_{v}=_{v}_{V},_{v}= _{v}_{v}^{}}{}},( _{v})=(_{v})_{v},\] (5)

where \(_{v}^{N N}\) is a matrix capturing the similarity between queries and keys; \(d_{K}\), \(d_{V}\) denotes the feature dimensional of the key representations \(_{v}\) and the value representations \(_{v}\)4. Then we will get the output of the self-attention module \(_{v}^{}^{N(3d)}\). To summarize the process of transformer layer, the output of association pattern-aware attention block is computed as:

\[^{}(l)=((^{(l-1)}))+^{(l-1)},^{(l)}=((^{}(l)))+ ^{}(l),\] (6)

where \(\) denotes layer normalization, and \(^{(l)}\) is the output of the current transformer layer. After \(L_{1}\)-layer transformers, we get the encoding output \(^{(L_{1})}=[_{1}^{(L_{1})},,_{| |}^{(L_{1})}]^{|| N(3d)},\) and then apply the mean function to similar entities in \(N\) association patterns for each node \(v\) to obtain the learned embedding \(_{v}^{d}\).

**Pattern Commonality.** To mine the commonality of \(N\) sampled patterns, a score is defined to represent the quantitative relation of these association patterns, termed by _Pattern Commonality Coefficient_, based on the attention scores \(_{v}\) of trained API block, which is formulated as follows:

\[}_{v}=(_{v}),_{v}= {1}{N}_{n=1}^{N}}_{v}[n,:],\] (7)

where \(_{v}^{N}\) and \(_{v}[n](0,1)\) indicates the commonality coefficient of the \(n\)-th pattern. Patterns with relatively high commonality coefficients tend to share the same or similar pathways, while showing significant differences in response compared to low commonality patterns. Corresponding biological validations are presented in the Section 5.3.

### Bind-relation Enhancement

In the context of multi-entity relationships, there often exist strong pairwise bind relation between entities, such as drug Aspirin to treat common cold [41; 42]. To mitigate the weakening or overlooking of low-order bind relation, a Bind-relation Enhancement (BE) module is designed to effectively reconstruct the missing feature by capturing these important pairwise associations. Additionally, the module can generate confident and challenging negative samples to aid the training.

**Bind-relation Feature Reconstruction.** To efficiently learn entity representations in pairwise bind relations, we introduce an edge prediction classification task on the bipartite graphs \(_{,},_{,}\) with the initial embeddings \(_{}^{(0)}=_{},_{_{1}}^{(0)}=_{_{2}}^{(0)}=_{}, _{}^{(0)}=_{}.\) Specifically, a \(L_{2}\)-layer self-supervised BGNN model  is employed to learn node features on the bipartite graphs, followed by the Multi-layer Perception (MLP)  layer to output association probabilities, which is defined as:

\[_{}^{(l+1)},_{_{1}}^{(l+1)}=(_{}^{(l)},_{_{1}}^{(l)}, _{,_{1}}),_{_{2}}^{(l+1)},_{}^{(l+1)}=(_{_{2}}^{( l)},_{}^{(l)},_{_{2},}),\] (8) \[_{(a,b_{1})}=(_{a}^{(L_{2})} _{b_{1}}^{(L_{2})}),_{(b_{2},c)}=(_{b_{ 2}}^{(L_{2})}_{c}^{(L_{2})}),\] (9)

where \(_{}^{(l)},_{_{1}}^{(l)},_{ _{2}}^{(l)},_{}^{(l)}\) represent the node features at layer \(l\); \(_{}^{(L_{2})},_{b_{1}}^{(L_{2})},_{b_{2}}^{( L_{2})},_{c}^{(L_{2})}\) denote the final learned representations of entity \(a,b_{1},b_{2},c\) respectively; \(_{(a,b_{1})}\), \(_{(b_{2},c)}\) represent the estimated probability of association between entities \(a,b_{1}\) and entities \(b_{2},c\) respectively. After that, the loss of the supervised prediction task can be formulated as:

\[_{,_{1}}/_{_{2},}=-_{,_{1}}|/|_{ _{2},}|}_{e_{,_{1}} /_{_{2},}}(p_{e}_{e}+(1-p_{e}) (1-_{e})).\] (10)

The loss \(_{BE}\) of bind-relation task is defined as \(_{BE}=_{,_{1}}+(1-) _{_{2},},\) where \(\) is the balancing coefficient for the two losses.

**Hard Negative Sampling.** Based on the above bind-relation task, negative samples are adaptively generated for triple-wise associations, instead of randomly selecting from the vast sample space. Moreover, the generated negative samples are challenging, which contributes to efficient learning. As illustrated in Figure 2, three kinds of negative samples are considered as follows:

\[_{}=\{(a,b^{},c)(p_{(a,b^{})}<)(p_{ (b^{},c)}<)\},\] (11)

where \(b^{}\) represents another entity with random selection that differs from entity \(b\) in the original triplet to form the negative sample \((a,b^{},c)\); \(_{}\) is the set of generated negative triplets; \(\) represents the threshold for the prediction probability to determine whether the association exists.

### Total Loss

Base on the above modules, \(_{v}\) of node \(v\) learned by the APF module is updated with reconstructed features \(_{v}\) from the BE module according to the entity type, thereby generate the enhanced embedding of \(v\) with \(_{v}^{*}=_{v}+_{v}\) for the association predictor network. Hence, for the triple-wise association prediction, we utilize the learned embeddings \(_{a}^{*}\), \(_{b}^{*}\), and \(_{c}^{*}\) of entity \(a\), \(b\), \(c\) to output the probability of the association \(\) through a scoring function \(_{(a,b,c)}=(_{a}^{*}_{b}^{*} _{c}^{*})\). The loss of the association prediction task for true sample set \(\) and negative sample set \(_{}\) can be formulated as:

\[_{APF}=-_{}|}_{e (_{})}(p_{e}_{e}+(1-p_{e}) (1-_{e}))\,.\] (12)

Hence, the total loss \(\) is computed through an alternating training strategy of the two modules, where the BE module is trained for the first 4 epochs of every 5-epoch cycle, followed by the APF module, which is trained for the final epoch of each cycle. During the training of each module, the parameters of the other one are frozen. The equation for \(\) is defined as follows:

\[(o)=_{BE}(o)(1-)+_{APF}(o),\] (13)

where \(o\) represents the current epoch; \(\) denotes floor function; \(\) denotes modulo operation.

### Complexity Analysis

Considering the significantly higher complexity of the APF module in comparison to other network components, we only consider APF which aggregates multiple patterns across various entity nodes. Specifically, for one entity node with \(N\) sampled patterns from the APS module, the input and hidden features in the MHA layers are of dimension \(f_{M}\), and hidden features in the FFN layers are \(f_{F}\). In APF, the query, key, and value matrices are derived from the same input sequence and share length \(N\). The primary operations for APF include scaled dot-product attention, multiplication of attention weights and values, MHA linear transformation, and FFN linear projection. The time complexity is expressed as \((N^{2} f_{M}+N f_{M}^{2}+N f_{M} f_{F})\). Hence, for the entire graph, the total complexity is \((||(N^{2} f_{M}+N f_{M}^{2}+N f _{M} f_{F}))\), where \(||\) is the number of entity nodes.

## 5 Experiment

### Experimental Settings

**Datasets.** In this paper, we adopt three biological entity association datasets with significant biological meaning, namely DMD (Drug-Microbe-Disease), DDC (synergistic Drug-Drug-Cell line) and DPA (Drug-target Protein-Adverse reaction), among which DPA dataset is directly constructed. In line with DMD and DDC, we utilize preprocessing tools provided by  to deal with the original data from ADReCS-Target , and collect a total of 1,079 triplets that are structured into the data schema <drug, protein, adr>. Appendix Table 3 presents the statistics and characteristics of these datasets.

**Baselines.** To verify the effectiveness of Pattern-BERP, we compare it with three kinds of methods: (1) Non-graph methods. Following the work from , five non-graph methods are adopted including Random Forest (**RF**) , **MLP**, **CP**, **Tucker**, **CoSTCo**; (2) Graph-based methods. We select four classical architectures of graph neural network, including **GCN**, **GraphSAGE**, **GAT**, **GIN**; (3) Hypergraph-based methods. Recent hypergraph learning methods to address triple-wise biological entities associations or similar tasks are considered as the baselines, including **DHNE**, **HyperSAGNN**, **HGSynergy**, **MCHNN**.

**Implementation Details.** To accurately evaluate model performance and prevent overfitting, 5-fold cross-validation is used to evaluate the performance. Specifically, we randomly split the dataset into a 90% cross-validation set and a 10% independent test set. On the cross-validation set, the 5-fold cross-validation is implemented. Moreover, the independent testing, in which the model is trained on the cross-validation set and tested on the independent test set, is conducted to obtain the prediction results. In the training stage, Binary Cross Entropy loss is adopted to measure model performance and Adam optimizer is adopted to optimize all of model parameters with a learning rate of 0.0015.

**Evaluations.** To evaluate the prediction performance on the triplet associations, hit ratio (hit@n) and normalized discounted cumulative gain (ndcg@n), which are widely used in recommendation tasks , are employed for model ability to provide a comprehensive assessment for the task.

### Performance Comparison with Advanced Baselines

Table 1 summarizes the prediction performances of Pattern-BERP in comparison with other baselines across the DMD, DDC and DPA datasets. It is evident that Pattern-BERP significantly surpasses the previous state-of-the-art baselines, including non-graph, graph-based, and hypergraph-based methods, across all three datasets by a large margin, with a particularly notable hit@1 improvement of approximately 23.6% on the DPA dataset (from 33.24 to 43.52). The results underscore the broad accuracy and applicability of the proposed method in various biological association scenarios.

A salient observation is that hypergraph-based methods achieve superior performance than those of the other two types. This phenomenon empirically demonstrates the advantages of utilizing high-order structure information over the other methods that we compare. Additionally, we observe that graph-based methods exceed non-graph methods for DMD and DDC datasets. The relatively large number of associations and proportion of DMD and DDC datasets, as shown in Appendix Table 3, indicate a higher density and stronger interconnectivity within the underlying entity relationships. Hence, graph-based methods acquire abundant information of entity interactions based on the graph structure. Furthermore, hypergraph-based methods acquire high-order structure information, ultimately leading to better performance. In contrast, for the DPA dataset, non-graph methods outperform graph-based methods, even demonstrating competitive performance compared to hypergraph-based methods. This can be attributed to the fact that the association proportion within the DPA dataset is conspicuously low (around 0.002%), indicating a relatively sparse graph structure. Under such conditions, the non-graph methods are able to obtain more robust association information compared to graph-based models, which may struggle to capture meaningful patterns from the limited graph connectivity.

    &  &  &  \\  Methods & hits@1 & hits@3 & hits@5 & hits@1 & hits@3 & hits@5 & hits@1 & hits@3 & hits@5 \\  RF & 34.06 & 57.28 & 68.31 & 8.93 & 18.63 & 28.29 & 26.62 & 37.45 & 44.95 \\ MLP & 42.72 & 65.40 & 75.33 & 13.27 & 27.98 & 39.88 & 27.55 & 40.65 & 48.80 \\ CP & 44.73 & 66.74 & 76.47 & 13.71 & 28.67 & 41.03 & 31.30 & 45.46 & 54.03 \\ Tucker & 45.27 & 66.54 & 76.98 & 13.24 & 28.55 & 39.77 & 28.80 & 43.10 & 50.74 \\ CoSTCo & 38.69 & 60.38 & 71.77 & 10.93 & 22.95 & 33.60 & 31.06 & 41.95 & 47.87 \\  GCN & 62.66 & 76.57 & 79.74 & 25.86 & 47.06 & 58.27 & 18.38 & 30.56 & 38.66 \\ GraphSAGE & 56.98 & 73.52 & 77.42 & 22.23 & 41.73 & 52.98 & 12.36 & 23.84 & 31.48 \\ GAT & 47.13 & 67.90 & 75.24 & 21.60 & 43.91 & 54.41 & 21.53 & 33.24 & 41.53 \\ GIN & 40.08 & 60.93 & 69.29 & 12.68 & 28.41 & 37.52 & 16.44 & 30.05 & 39.12 \\  DHNE & 81.86 & 93.66 & 96.02 & 43.42 & 62.61 & 72.01 & 32.64 & 47.69 & 56.30 \\ HyperSAGNN & 87.04 & 93.99 & 96.09 & 41.31 & 66.38 & 76.29 & 33.24 & 49.58 & 58.38 \\ HGSynergy & 88.68 & 92.10 & 94.51 & 41.07 & 60.74 & 70.76 & 28.19 & 40.36 & 48.44 \\ MCHNN & 90.04 & 93.92 & 95.19 & 41.91 & 61.12 & 72.10 & 32.27 & 43.29 & 50.32 \\  Pattern-BERP & **93.94** & **97.53** & **98.24** & **48.01** & **68.40** & **76.39** & **43.52** & **57.36** & **63.89** \\ \(\) & +3.90 & +3.54 & +2.15 & +4.59 & +2.02 & +0.10 & +10.28 & +7.78 & +5.51 \\   

Table 1: Performance comparison on three datasets of different biological entity associations. Each result of these methods is from the average of 5-fold cross-validation experiments with four scenarios. The best result for each dataset and metric is marked in **bold**. All the presented hits scores are in %.

### Association Pattern Interpretability

In order to investigate the potential relation among different association patterns, we visualize the pattern commonality coefficients of Cefadroxil (drug #53) and S-(2-Thienyl)-L-cysteine (drug #207) in DMD dataset, as shown in Figure 3. Larger pattern commonality coefficients contribute more to the original drug pathway, whereas smaller coefficients often relate to different biological mechanisms. It can be observed that:

* For Cefadroxil (drug #53), the common patterns consisted by Chlorhexidine acetate (drug #76) , Hetacillin (drug #132) , and Econazole (drug #102) [50; 51] are considered more similar as the mechanism  that actives on the cell wall and envelope leading the change of microbe physiological activities, thus treating the diseases. Instead, Tobramycin (drug #227) inhibits mRNA be translated into protein and thus promotes microbe cell death [53; 54].
* For S-(2-Thienyl)-L-cysteine (drug #207), the common patterns consisted by Diphenyl Disulfide (drug #100) [55; 56], Salicylic Acid (drug #209) , and Chrysophanic Acid (drug #78) [58; 59] are considered more similar as the mechanism that [60; 61; 62] inducts oxidative stress in bacteria and thus damage all components of the microbe cell. Instead, Moxifloxacin (drug #160) inhibits DNA gyrase and topoisomerase IV enzymes to separate bacterial DNA, thereby inhibiting cell replication [63; 64].

In summary, the analyzed cases illustrate the high-commonality patterns derived from Pattern-BERP, demonstrating how these small molecule drugs influence microbial activities to treat diseases, generally following a consistent physiological route. These cases indicate that our method can discover potential common patterns through the API block, and obtain larger pattern coefficients through the attention mechanism, which drives the nodes to learn these important common interactions and acquire more expressive representations. Details about additional cases can be found at Appendix B.3.2.

Figure 3: The interpretability cases of \(N\)=100 association patterns related to drug #53 and #207 in DMD dataset. The pattern commonality coefficients are represented in the form of a percentage to indicate the contribution for visualization, with each pattern typically assigned a default value of 1%. Larger pattern commonality coefficients indicate a more significant contribution to the target drugs, and these patterns frequently exhibit similar or even identical biological pathways. Conversely, smaller commonality coefficients suggest a lack of relevance to these drugs.

### Ablation Study

To investigate the necessity of each component in Pattern-BERP, we conduct several comparisons between Pattern-BERP and its variants on the test set. As illustrated in Table 2, when basic components of Pattern-BERP have been removed, the performances of corresponding variants on DDC dataset significantly decline, indicating that these components all contribute to the performance. Besides, we have other observations: (1) when only DE module is removed, the performance is inferior to the one removing the entire APA module containing DE, demonstrating that inaccurate entity distance information has a more detrimental impact on the prediction performance; (2) eliminating HNS module results in a significant drop in the performance, highlighting its crucial role in enhancing the model's robustness and discrimination capability and thus indicating that the proposed negative sampling strategy contributes to efficient learning; (3) when removing HC module leads to a slight performance degradation, the impact is relatively limited which suggests that the capability of HC module in representing complex associations is relatively modest for the highly dense-association DDC dataset, but it still provides some beneficial effects towards the final performance improvement.

To verify the affect of hyperparameter settings to model performance, we first conduct ablation experiments on the three main parameters of the APF module, namely number of attention heads, number of max pattern distance, and number of sampled association patterns. As illustrated in Appendix Figure 5, when the three hyperparameters are increased, the prediction performance on DDC dataset exhibits an overall upward trend, suggesting that increasing these hyperparameters helps the model better capture the complex association patterns, thereby improving the final performance. Additionally, we conduct experiments on the loss-balanced coefficient \(\) and the bind-relation prediction probability threshold \(\), both adjusted from 0.1 to 0.9. Results in Appendix Figure 6 show that setting \(\) and \(\) to 0.5 yields the best performance. Specifically, for \(\), since the final prediction task involves predicting the associations among entity \(\), \(\), and \(\), the two tasks of \(\) and \(\) are intuitively of equal importance, therefore the balanced coefficient \(\) set to 0.5; for \(\), bind-relation prediction is fundamentally a binary classification task, thus the threshold \(\) is set to 0.5. Details about ablation experiments are presented at Appendix B.3.3.

## 6 Conclusion

In this work, we propose a novel association pattern-aware fusion method Pattern-BERP for biological entity relationship prediction, which effectively combines the related association pattern information into entity representation learning. In addition, to enhance the missing information of the low-order message passing, we devise a bind-relation module that considers the strong bind of low-order entity associations. The evaluation on three biological datasets quantitatively demonstrate that the proposed method consistently achieve superior performance over the competing baselines. Moreover, the interpretability explanations of association patterns reveal the intrinsic biological mechanisms and thus promote the method to be deployed in real-world scenarios.

Due to the domain-specific task, Pattern-BERP focuses on the fixed-length association patterns. Extending the approach to capture variable-length pathways could further enhance the representational power. Additionally, exploring the applicability of the method in other domains beyond biology, such as general knowledge graph completion, would help evaluate its broader generalizability.

   w/o BFR & w/o HNS & w/o HC & w/o DE & w/o API & hits@1 & hits@3 & hits@5 & ndcg@1 & ndcg@3 & ndcg@5 \\  ✓ & ✓ & - & - & - & - & 44.76 & 64.74 & 73.08 & 44.76 & 56.42 & 59.85 \\ ✓ & - & - & - & - & 45.03 & 65.86 & 74.97 & 45.03 & 57.19 & 60.95 \\ - & ✓ & - & - & - & 42.81 & 64.48 & 74.02 & 42.81 & 55.41 & 59.33 \\ - & - & - & ✓ & - & 40.29 & 62.87 & 72.44 & 40.29 & 53.41 & 57.35 \\ - & - & - & ✓ & ✓ & 44.69 & 65.17 & 74.51 & 44.69 & 56.62 & 60.45 \\ - & - & ✓ & - & - & 47.11 & 66.56 & 74.89 & 47.11 & 58.47 & 61.90 \\ - & - & - & - & - & **48.01** & **68.40** & **76.39** & **48.01** & **59.84** & **63.13** \\   

Table 2: Ablation study results on DDC dataset with different module designs. “BFR” denotes Bind-relation Feature Reconstruction; “HNS” denotes Hard Negative Sampling; “HC” denotes Hypergraph Convolution block; “DE” denotes Distance Embedding; “API” denotes Association Pattern-aware Interaction block. All the presented scores are in %, and the best result is marked in **bold**.