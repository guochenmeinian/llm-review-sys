# Conjugated Semantic Pool Improves OOD Detection

with Pre-trained Vision-Language Models

 Mengyuan Chen

MAIS, Institute of Automation, CAS

School of Artificial Intelligence, UCAS

chenmengyuan2021@ia.ac.cn &Junyu Gao

MAIS, Institute of Automation, CAS

School of Artificial Intelligence, UCAS

junyu.gao@nlpr.ia.ac.cn &Changsheng Xu

MAIS, Institute of Automation, CAS

School of Artificial Intelligence, UCAS

Pengcheng Laboratory

csxu@nlpr.ia.ac.cn

Corresponding authors

###### Abstract

A straightforward pipeline for zero-shot out-of-distribution (OOD) detection involves selecting potential OOD labels from an extensive semantic pool and then leveraging a pre-trained vision-language model to perform classification on both in-distribution (ID) and OOD labels. In this paper, we theorize that enhancing performance requires expanding the semantic pool, while increasing the expected probability of selected OOD labels being activated by OOD samples, and ensuring low mutual dependence among the activations of these OOD labels. A natural expansion manner is to adopt a larger lexicon; however, the inevitable introduction of numerous synonyms and uncommon words fails to meet the above requirements, indicating that viable expansion manners move beyond merely selecting words from a lexicon. Since OOD detection aims to correctly classify input images into ID/OOD class groups, we can "make up" OOD label candidates which are not standard class names but beneficial for the process. Observing that the original semantic pool is comprised of unmodified specific class names, we correspondingly construct a conjugated semantic pool (CSP) consisting of modified superclass names, each serving as a cluster center for samples sharing similar properties across different categories. Consistent with our established theory, expanding OOD label candidates with the CSP satisfies the requirements and outperforms existing works by 7.89% in FPR95. Codes are available in https://github.com/MengyuanChen21/NeurIPS2024-CSP.

## 1 Introduction

The efficacy of machine learning models typically diminishes on out-of-distribution (OOD) data, thereby underscoring the significance of flagging OOD samples for caution. Traditional visual OOD detection methods are typically driven by a single image modality, leaving the rich information in textual labels untapped . As pre-trained vision-language models (VLMs) develop, employing textual information in visual OOD detection has become a burgeoning paradigm . A straightforward pipeline  is to select potential OOD labels from a semantic pool and leverages the text-image alignment ability of a pre-trained VLM. Specifically, potential OOD labels are selected from WordNet  based on their similarities to the In-distribution (ID) label space, and then CLIP  is employed to classify input images into ID/OOD class groups.

In this paper, we establish a mathematic model to describe the performance of the above pipeline. Specifically, the activation status of selected OOD labels, aka whether the similarities between OOD labels and an input image exceed an implicit threshold, can be modeled as a series of independent Bernoulli random variables . Depending on the class group of the input image, we refer these as ID and OOD Bernoulli variables for short. As the proportion of selected OOD labels in the semantic pool increases, our theory indicates an inverted-V performance variation trend, which aligns with the actual observation. We further derive that the peak performance is positively correlated with two factors: the size of the semantic pool and the average expectation of the OOD Bernoulli variables. Considering the mutual influence between factors, a clear strategy for enhancing performance involves concurrently enlarging these two factors while maintaining low mutual dependence among the Bernoulli variables. As a result, with an existing semantic pool, what we need to do is to _expand it with additional OOD labels which have higher and independent probabilities of being activated by OOD images_.

A straightforward manner of semantic pool expansion is to adopt larger lexicons. However, simple lexicon expansion fails to yield consistent satisfactory outcomes, and we conclude that the inefficacy is attributed to the following reasons: On the one hand, larger lexicons bring numerous uncommon words, whose expected probabilities of being activated by OOD images are minimal, thus resulting in a reduction of the average expectation of the OOD Bernoulli variables. On the other hand, larger lexicons introduce plenty of (near-)synonyms for existing OOD label candidates, leading to a high degree of functional overlap and little benefit. The corresponding Bernoulli random variables for (near-)synonyms are highly mutual dependent, which severely violates the independence assumption required by Lyapunov central limit theorem , thus failing to achieve the expected enhancement.

The above analysis suggests that viable strategies for semantic pool expansion require moving beyond the paradigm of simply selecting labels from larger lexicons. Since the goal of OOD detection is to correctly classify input images into ID/OOD class groups, we can freely "make up" OOD label candidates which are not standard class names but beneficial for the process. Inspired by the fact that the original semantic pool is comprised of **unmodified specific class names** (_e.g., "cat", "wallet", "barbershop"_), each of which serves as a cluster center for samples from the same category but with varying properties, we correspondingly construct a conjugated semantic pool (CSP) consisting of **specifically modified superclass names** (_e.g., "white creature", "valuable item", "communal place"_), each of which serves as a cluster center for samples sharing similar properties across different categories. Expanding OOD label candidates with the CSP satisfies the requirements of our theoretical scheme. Specifically, since superclasses used in constructing the CSP include broad semantic objects, the property clusters encompass samples from numerous potential OOD categories. Therefore, these cluster centers, serving as OOD labels, have much higher expected probabilities of being activated by OOD samples, thus increasing the average expectation of the OOD Bernoulli variables. Furthermore, the distribution of these property cluster centers in the feature space is distinctly different from that of the original category cluster centers, resulting in a relatively low mutual dependence between the new and original labels. Consistent with the established theory, our method outperforms the SOTA method NegLabel  with an improvement of 7.89% in FPR95, which underscores the efficacy of our method. Our contributions include:

* A theoretical scheme for improving OOD detection with pre-trained VLMs (Section 3.1). We derive that an unequivocal strategy for performance enhancement requires concurrently increasing the semantic pool size and the expected activation probability of OOD labels and ensuring low mutual dependence among the activations of selected OOD labels.
* An analysis of the inefficacy of simple lexicon expansion (Section 3.2). We attribute the inefficacy to the introduction of numerous uncommon words and (near-)synonyms, which respectively reduces the expected activation probabilities of OOD labels and brings severe mutual dependence, thereby failing to achieve theoretical enhancement.
* An expansion manner beyond selecting labels from existing lexicons (Section 3.3). We construct an additional conjugated semantic pool (CSP), consisting of modified superclass names, each serving as a cluster center for samples with similar properties across different categories. Consistent with our established theory, expanding OOD label candidates with the CSP satisfies the requirements and achieves satisfactory performance improvements.
* Extensive experiments and related analysis on multiple OOD detection benchmarks with state-of-the-art performances (Section 5), which demonstrate the effectiveness of our method.

Proof and derivations, visualizations, additional experiment results and details are given in Appendix.

## 2 Preliminaries

**Task setup.** OOD detection leveraging pre-trained vision-language models (VLMs), also termed as zero-shot OOD detection [15; 12; 40; 58; 64; 43; 29], aims to identify OOD images from ID ones with only natural-language labels of ID classes available. Formally, given the testing image set \(=^{}^{}\), where \(^{}^{}=\), and ID label (class name) set \(^{}=\{y_{1},,y_{K}\}\), where \(K\) is the number of ID classes, our target is to obtain an OOD detector \(G(x;^{}):\{,\}\), where \(x\) denotes a test image. It is noteworthy that the zero-shot setting does not require that there be no overlap between the pre-training data of VLMs and the testing data \(\), but only stipulates that no ID images are available for model fine-tuning. In other words, the split of ID and OOD data completely depends on how users manually preset the ID label set \(_{}\).

**OOD detection with a pre-trained VLM and a semantic pool.** A straightforward pipeline of this task is to select potential OOD labels from a semantic pool and leverages the text-image alignment ability of a pre-trained VLM to perform zero-shot OOD detection . Specifically, there are three steps: (1) Fetching numerous words from a semantic pool like WordNet  as OOD label candidates; (2) Selecting a portion of OOD label candidates most dissimilar to the entire ID label space; (3) Employing a pre-trained VLM like CLIP  to obtain similarities between testing images and ID/OOD labels and then performing OOD detection with a designed OOD score.

The OOD detection performance of this pipeline can be modeled as follows . Given the selected OOD label set \(^{}=\{z_{1},,z_{m}\}\), \(0<m M\), where \(m\) is the number of selected OOD labels, and \(M\) is the size of the semantic pool. By applying a threshold \(\), we can naturally define \(p_{i}^{}=P(s_{i}|f,z_{i},^{})\) as the probability of classifying ID input images \(x^{}\) as positive for the given label \(z_{i}\), where \(s_{i}=(f(x),f(z_{i}))\) is the similarity score given by the pre-trained model \(f\). To derive an analytic form for the model's OOD detection performance, we employ a straightforward OOD score function \(S(x)\), aka the total positive count across categories for a sample \(x\). Specifically, \(S(x^{})=_{i}s_{i}^{}\), where \(s_{i}^{}\) is a Bernoulli variable with parameter \(p_{i}^{}\), _i.e._, the probability of \(s_{i}^{}=1\) is \(p_{i}^{}\) and the probability of \(s_{i}^{}=0\) is \(1-p_{i}^{}\). Consequently, \(S(x^{})\) follows a Poisson binomial distribution with parameters \(\{p_{1}^{},...,p_{m}^{}\}\). \(p_{i}^{}\) and \(S(x^{})\) are defined similarly. Based on the Lyapunov central limit theorem (CLT) , we can obtain the following lemma:

**Lemma 1**.: _Given independent Bernoulli random variables \(\{s_{1},...,s_{m}\}\) with parameters \(\{p_{1},...,p_{m}\}\), where \(0<p_{i}<1\), as \(m\) goes to infinity, the Poisson binomial random variable \(C=_{i=1}^{m}s_{i}\) converges in distribution to a normal random variable with distribution \((_{i=1}^{m}p_{i},_{i=1}^{m}p_{i}(1-p_{i}))\)._

According to Lemma 1, proved in Appendix A.1, the distribution of \(C^{}\) can be approximated as \(C^{}(_{i=1}^{m}p_{i}^{},_{i=1}^ {m}p_{i}^{}(1-p_{i}^{})),\) and the distribution of \(C^{}\) can be approximated similarly. By denoting \(q_{1}=_{i}[p_{i}^{}]\), \(v_{1}=_{i}[p_{i}^{}]\), \(q_{2}=_{i}[p_{i}^{}]\), \(v_{2}=_{i}[p_{i}^{}]\), we have

\[C^{}(mq_{1},mq_{1}(1-q_{1})-mv_{1}),C^{ }(mq_{2},mq_{2}(1-q_{2})-mv_{2}).\] (1)

Thereafter, with the derivation provided in Appendix A.2, we can obtain the closed-form expression of one of the most commonly adopted OOD performance metric, aka the false positive rate (FPR) when the true positive rate (TPR) is \(\), denoted by \(_{}\), as

\[_{}=+((1-q_{1})-v_{1}}{q_{2}(1-q_{2})-v_{2}}}^{-1}(2-1) +(q_{1}-q_{2})}{(1-q_{2})-2v_{2}}}),\] (2)

where \((x)=}_{0}^{x}e^{-t^{2}}dt\). However, contrary to the monotonic trend suggested by Eqn. 2, the actual performances in experiments exhibit an inverted-V trend as the ratio of selected OOD labels in the semantic pool increases. Therefore, we further optimize the mathematic model by incorporating finer-grained variable relationships, seeking theoretical guidance for performance enhancement.

## 3 Methodology

### A Theoretical Scheme for Performance Enhancement

Since selecting OOD labels is typically based on the reverse-order of similarities to the ID label space to minimize semantic overlap, _i.e._, the most dissimilar OOD label candidates are most likelyto be selected, the expected probability, \(q_{1}\), of OOD labels being activated by ID images is not static. Specifically, as the ratio of selected OOD labels \(r=m/M\) increases, the expected activation probability \(q_{1}=_{i}[p_{i}^{n}]\) of existing OOD labels for ID images will monotonically increase, since more OOD labels with higher affinities to ID labels are selected. When all labels in the semantic pool are finally selected, \(q_{1}\) will achieve \(q_{2}\), which means the expected probabilities of OOD labels being activated by ID and OOD images are close. Meanwhile, \(q_{2}\) is considered as a constant when the semantic pool is fixed and the ratio \(r\) varies, since whether an element in the pool (excluding ID labels) corresponds to a potential OOD sample is independent of its similarity to the ID label space. Formally, defining \(q_{0}\) as the lower bound of \(q_{1}\), we model the accumulated increase in \(q_{1}\) as the ratio \(r\) increases from zero with the function \(u(r)\), which exhibits following properties:

\[u(r)=q_{1}(r)-q_{0},\,u(r=0|q_{0},q_{2})=0,\,u(r=1|q_{0},q_{2})=q_{2}-q_{0}>0, \,u^{}(r) 0.\] (3)

Besides, we assume that the absolute value of the curvature of \(u\) is constrained within a specific range, thereby preventing abrupt changes in the trend of \(u\), which facilitates subsequent analysis. With \(u(r)\), we set \(=0.5\) in Eqn. 2 for convenience and then explore the properties of

\[_{0.5}=+( }-q_{2}+u(r|q_{0},q_{2})}{(1-q_{2})-v_{2}}}).\] (4)

Denote \(z=}-q_{2}+u}{(1-q_{2})-v_{2}}}\), from Eqn. 4, we can derive that the first-order derivative of \(_{0.5}\), denoted as \(G(r)\), can be expressed as

\[G(r|q_{0},q_{2},u,M)=_{0.5}}{ r}=}}{2}-q_{2}+u+2ru^{}}{( 1-q_{2})-v_{2}}},\] (5)

which can be further proved to monotonically increase over the interval \((0,1]\) with respect to \(r\) with the above assumptions. Besides, according to Eqn. 5, we can obtain that

\[_{r 0^{+}}G(r)=_{r 0^{+}}-q_{2})}{2}=- ,_{r 1}G(r)= u^{}(r=1) 0,\] (6)

Since \(_{0.5}(r)\) is a continuous function within our framework and satisfies Eqn. 6, it can be deduced that there exists a value \(r_{0}(0,1]\) where \(_{0.5}\) reaches its minimum. Furthermore, \(_{0.5}\) monotonically decreases over the interval \((0,r_{0}]\) and increases over the interval \([r_{0},1]\). Since \(_{}\) is a smooth continuous function with respect to \(\), we deduce that \(_{}\) and \(_{0.5}\) share similar trends as the parameter \(r\) varies, which aligns with the actual results presented in Fig. 1. A more detailed calculation process from Eqn. 4 to Eqn. 6 is provided in Appendix A.3.

Subsequently, we delve deeper into the factors influencing the optimal value of the OOD detection performance evaluated by \(_{0.5}(r)\). When \(r\) reaches the critical point \(r_{0}\), the expected performance improvement resulting from "OOD samples being correctly identified due to the addition of new OOD labels" will be equal to the performance degradation caused by "ID samples being misclassified due to the addition of new OOD labels". As a result, the model performance achieves its peak. Specifically, from Eqn. 5, it can be inferred that \(r_{0}\) satisfies

\[q_{0}-q_{2}+u(r_{0}|q_{0},q_{2})+2r_{0}u^{}(r_{0}|q_{0},q_{2})=0.\] (7)

Given the complex interdependencies among the variables in the above equation, it is challenging to derive any definitive conclusions with the undefined form of the function \(u\). Consequently, we simplify by assuming that the function \(u(r)\) is linear. Under this assumption, by substituting Eqn. 7 into Eqn. 4, we obtain that the optimal value of \(_{0.5}\) can be expressed as

\[_{0.5}(r_{0})=+(-}r_{0}^{}(q_{2}-q_{0})}{(1-q_{2})-v_{2}}} ),\] (8)

Figure 1: Model performances evaluated by FPR50 and FPR95 (lower is better) of our method and NegLabel against the ratio \(r\), which exhibit a trend of initial decline followed by an increase. Detailed results can be found in Table 8.

where the variables \(M\) and \(q_{2}\), aka the semantic pool size and the expected probability of OOD labels being activated by OOD samples, are the predominant factors influencing the right side of the equation. The other variables \(q_{0}\), \(r_{0}\), and \(v_{2}\) remain nearly constant with a sufficiently large semantic pool (refer to Appendix A.4 for analysis), thus exerting marginal impact.

If we disregard the interdependencies among the variables, the impact of \(M\) and \(q_{2}\) on the optimal value of \(_{0.5}\) is straightforward: (1) With \(q_{2}\) fixed, it can be easily observed that \(_{0.5}(r_{0})\) monotonically decreases with \(M\). (2) With \(M\) fixed, and denoting the input to the \(()\) function as \(\), it can be derived from Eqn. 8 that,

\[_{0.5}(r_{0})}{ q_{2}}=()}{}}=-^{3}}{2}}}(q_{2}+q_{0}-2q_ {0}q_{2}-2v_{2})}{(q_{2}(1-q_{2})-v_{2})^{}} 0\] (9)

holds in almost all practical cases (see Appendix A.5 for analysis), thus \(_{0.5}(r_{0})\) also monotonically decreases with respect to \(q_{2}\). However, in real-world scenarios, the complex interactions between \(M\) and \(q_{2}\) prevent either variable from being adjusted in isolation. For instance, utilizing a larger lexicon to expand the size \(M\) of the semantic pool may cause a decline in \(q_{2}\) (see Section 3.2). Conversely, discarding candidates with lower activation probabilities to elevate \(q_{2}\) leads to a reduction of \(M\). The variable changes in both strategies exert opposing effects, ultimately leading to minimal improvements or even degradation in model performance. Besides, the Lyapunov central limit theorem (CLT) used in proof of Lemma 1 requires that the activations of selected OOD labels are independent. Although complete independence is impossible to achieve in real-world scenarios, it is essential to maintain a relatively low level of mutual dependence to reduce the errors in theoretical derivations. Therefore, an unequivocal strategy for performance enhancement is **concurrently increasing the variables \(M\) and \(q_{2}\) and ensuring that there is no strong dependence among the activations of selected OOD labels**. With an existing semantic pool, what we need to do is to expand it with additional OOD labels which have higher and independent probabilities of being activated by OOD images.

### A Closer Look at the Inefficacy of Simple Lexicon Expansion

Therefore, it is time to consider how to expand the original semantic pool, which already includes most common words, while ensuring the increase of \(q_{2}\) and low mutual dependence. The most straightforward strategy for expansion, adopting larger existing lexicons, fails to consistently yield satisfactory outcomes, as shown in Fig. 2. Subsequently, we analyze that the inefficacy of simple lexicon expansion is attributed to the following reasons.

On the one hand, larger lexicons bring numerous **uncommon words**, whose expected probability of being activated by OOD images are minimal, thus **resulting in a reduction of \(}\)**. As derived in Section 3.1, the decrease of \(q_{2}\) attenuates the performance improvements yielded by enlarging \(M\). There are two potential reasons for the activation probability \(p_{i}^{}\) of an uncommon OOD label \(z_{i}\) being minimal: (1) Pre-trained VLMs lack semantic matching capability for label \(z_{i}\). This issue is particularly pronounced when \(z_{i}\) pertains to concepts such as highly abstract notions (e.g., _"idealism", "metaphysics"_), complex mathematical concepts (e.g., _"Lyapunov condition", "central limit theorem"_), or specific knowledge of individuals (e.g., personal names excluding celebrities). Pre-trained VLMs are unable to recognize the corresponding content of these text inputs, resulting in \(p_{i}^{}\) remaining close to zero. (2) The set \(^{}\) lacks testing samples similar to label \(z_{i}\). For instance, when the test dataset primarily consists of images of everyday items, new labels constructed from astronomical terms are likely to maintain \(p_{i}^{}\) close to zero. 2 The above scenarios are much more prevalent in lexicons of uncommon terms than those of common words. Thereafter, a larger proportion of labels with minimal activation probability \(p_{i}^{}\) will diminish \(q_{2}=_{i}[p_{i}^{}]\), thus attenuating the performance improvement.

On the other hand, larger lexicons introduce plenty of **synonyms and near-synonyms** for existing OOD label candidates, leading to a high degree of functional overlap with little additional benefit.

Figure 2: Model performances evaluated by FPR95 (lower is better) with lexicons of different sizes. Detailed results can be found in Table 9.

For example, the common word _"smartphone"_ can be expanded by adding synonyms such as _"mobile phone"_ and _"cellphone"_. However, the selection results for these words are consistent due to their similar meanings, and if they are selected, the activation of these labels still depends solely on the presence of a smartphone in the input image. This demonstrates a high level of mutual dependency and provides little additional benefit compared to only including _"smartphone"_ in the semantic pool. Despite no reduction in \(q_{2}\), the corresponding Bernoulli random variables for synonyms, representing whether they are activated by an input OOD image, severely **violate the independent assumption** required by Lemma 1. Although the Lyapunov CLT used in proof of Lemma 1 relaxes the requirement for random variables to have strictly identical distributions as mandated by the traditional CLT, it still requires that the variables maintain mutual independence. Despite the random variables corresponding to semantically dissimilar labels are not strictly independent, the intensity of their mutual dependency is generally much lower than that observed in (near-)synonyms. Contrarily, synonyms and near-synonyms lead to significant bias in the approximation of Eqn. 1 and the conclusions derived, thereby failing to achieve the theoretical enhancement.

### Expanding Label Candidates with Conjugated Semantic Pool

The above analysis suggests that viable strategies for semantic pool expansion require moving beyond the paradigm of simply selecting labels from a lexicon. Since the goal of OOD detection is to correctly classify input images into ID/OOD class groups, we can freely "make up" OOD label candidates which are not standard class names but beneficial for the process. Inspired by the fact that the original semantic pool is comprised of **unmodified specific class names**, each of which serves as a cluster center for samples from the same category but with varying properties, we correspondingly construct a conjugated semantic pool (CSP) consisting of **specifically modified superclass names**, each of which serves as a cluster center for samples sharing similar properties across different categories.

We notice that a class name inherently encompasses a broad semantic range. As shown in the bottom right of Fig. 3, when an image is attached with the class label _"cat"_, it actually depicts one of various more specific situations, such as a _"white cat"_, _"tabby kitten"_, _"gray cat"_, _"yawning cat"_, or _"cat on a mat"_, etc. Considering all feature points that correspond to more specific descriptions of cats as a cluster within the feature space, the feature point of _"cat"_ can be regarded as its cluster center.

In an ideal scenario, each input image in the feature space would be closest (most similar) to the cluster center that corresponds to its category, thereby achieving perfect OOD identification. However, the following issues impair the ideal case: (1) Due to the limited capabilities of pre-trained VLMs, some OOD images, such as _"white polar bear"_ in Fig. 3, are closer to incorrect cluster centers than to the correct ones. (2) Owing to the limited scope of lexicons and the inaccuracy of label selection, the category name corresponding to an OOD image, such as _"white pearcock"_ in Fig. 3, may not exist in selected labels, resulting in the absence of an appropriate cluster center. To summarize briefly: not every input OOD image locates close to a correct OOD cluster center.

Thereafter, it naturally occurs to us that we should construct more suitable cluster centers to attract such "homeless" OOD images. This is why we expand the original semantic pool by constructing the CSP as follows: Instead of specifying concrete category names (_e.g._, _"cat"_, _"wallet"_, _"barbershop"_), we utilize superclass names to encompass a wider range of categories (_e.g._, _"creature"_, _"item"_, _"place"_); Instead of leaving category names uncoorated, we using adjectives from a lexicon as modifiers to attract objects sharing similar properties. As a result, we obtain numerous label candidates of random combinations of adjectives and superclasses (_e.g._, _"white creature"_, _"valuable item"_, _"communal place"_). As Fig. 3 shows, in the feature space, _"white creature"_ can be considered as the cluster center of all feature points corresponding to creatures modified by _"white"_, such as _"white cat"_, _"white butterfly"_, _"white polar bear"_, etc. Note that the semantic scopes of label candidates in the CSP may

Figure 3: An illustrative diagram of an element in the conjugated semantic pool (CSP). Category names can be regarded as the centers of category clusters. Similarly, elements in CSP can be considered as cluster centers of superclass objects with similar properties.

overlap with ID categories. For example, when _"Cat"_ or _"Butterfly"_ in Fig. 3 are included in ID classes, the label candidate _"White Creature"_ in the CSP may not be selected as an OOD label.

Consistent with our established theory, our proposed method achieves satisfactory performance improvements by concurrently enlarging the semantic pool size \(M\) and the expected activation probability \(q_{2}\) of OOD labels and ensuring that there is no severe mutual dependence among the activations of selected OOD labels. Firstly, when we expand the original semantic pool with the CSP, the enlargement of \(M\) is obvious. Then, since the superclasses used in constructing the CSP typically include broad semantic objects, the property clusters encompass samples from numerous potential OOD categories. Therefore, their centers have much higher expected probabilities of being activated by OOD samples, which brings an increase in \(q_{2}\). Furthermore, the distribution of these property cluster centers in the feature space is distinctly different from that of the original category cluster centers. As a result, the mutual dependence between the new and original labels is relatively low, and the functions of labels from the CSP will not be overshadowed, enhancing the likelihood that an OOD image locates close to a correct OOD cluster center. Experiment results and analysis which support the above claims are provided in Appendix C.1.

## 4 Related works

**Traditional visual OOD detection.** Traditional visual OOD detection methods, driven by the single image modality, can be broadly categorized into four distinct types: (1) Output-based methods, which aims to obtain improved OOD scores from network output, can be further classified into post-hoc methods [21; 34; 25; 54; 55; 44; 38] and training-based ones [10; 23; 57; 26; 71; 65; 30]. (2) Density-based methods [37; 49; 53; 67; 11] explicitly model the ID data with probabilistic models and identify test data located in regions of low density as OOD. (3) Distance-based methods [32; 51; 63; 56; 41; 7; 70; 59; 24; 18] originate from the core idea that OOD samples should be relatively far away from ID prototypes or centroids. (4) Reconstruction-based methods [76; 69; 28; 33], which employ an encoder-decoder framework trained on ID data, leverage the performance discrepancies between ID and OOD samples as indicators for anomaly detection. Furthermore, numerous studies [52; 72; 14; 42; 6] offer theoretical contributions.

**OOD detection leveraging pre-trained VLMs.** By adopting pre-trained VLMs, employing textual information in visual OOD detection has become a burgeoning paradigm with remarkable performance [15; 12; 40; 58; 64; 43; 29]. Fort _et al._ propose to feed the names of potential outlier classes to image-text pre-trained transformers like CLIP  for OOD detection. ZOC  extends CLIP with a text-based image description generator to output OOD label candidates for testing. MCM  simply adopts maximum predicted softmax value as the OOD score, which is an effective and representative post-hoc OOD detection method based on vision-language pre-training. Based on MCM, NPOS  generates artificial OOD training data and facilitates learning a reliable decision boundary between ID and OOD data. CLIPN  trains a text encoder to teach CLIP to comprehend negative prompts, effectively discriminating OOD samples through the similarity discrepancies between two text encoders and the frozen image encoder. Also based on CLIP, LSN  constructs negative classifiers by learning negative prompts to identify images not belonging to a given category. NegLabel  proposes a straightforward pipeline, that is, selecting potential OOD labels from an extensive semantic pool like WordNet , and then leveraging a pre-trained VLM like CLIP to classify input images into ID/OOD class groups. In this study, we explore the theoretical requirements for performance enhancement in this pipeline, and thus construct a conjugated semantic pool to expand OOD label candidates, which achieves performances improvements as expected.

**Further discussion about NegLabel.** NegLabel  undertakes a rudimentary theoretical analysis of the correlation between OOD detection performance and the quantity of adopted potential labels, concluding that an increase in selected labels correlates with enhanced performance. However, this conclusion contradicts the observed actual trend. The contradiction arises from that  simply assume a constant higher similarity between OOD labels and OOD images compared to ID images, neglecting that this similarity discrepancy originates from the strategy of reverse-order selection of OOD labels based on their similarity to the ID label space. As the set of selected OOD labels transitions from _"a small subset of labels with the lowest similarity to the entire ID label space"_ to _"the whole semantic pool, which is unrelated to the setting of ID and OOD labels"_, the discrepancy in similarity of ID images to OOD labels versus OOD images to OOD labels will progressively diminish until it disappears. Incorporating the above dynamic to optimize the mathematic model, we focus on the correlation between OOD detection performance and the ratio of selected OOD labels in the semantic pool, seeking theoretical guidance for performance enhancement.

## 5 Experiments

### Experiment Setup

**Benchmarks.** We mainly evaluate our method on the widely-used ImageNet-1k OOD detection benchmark . This benchmark utilizes the large-scale ImageNet-1k dataset as the ID data, and select samples from iNaturalist , SUN , Places , and Textures  as the OOD data. The categories of the OOD data have been manually selected to prevent overlap with ImageNet-1k. Furthermore, we conduct experiments on hard OOD detection tasks, or with various ID datasets. Besides, we access whether our method generalizes well to different VLM architectures, including ALIGN , GroupViT , EVA , etc. More details of datasets can be found in Appendix B.

**Implementation details.** Unless otherwise specified, we employ the CLIP ViT-B/16 model as the pre-trained VLM and WordNet as the lexicon. The superclass set for constructing the conjugated semantic pool is {_area, creature, environment, item, landscape, object, pattern, place, scene, space, structure, thing, view, vista_}, which nearly encompasses all real-world objects. The ablation in Appendix C.5 shows that numerous alternative selections can also yield significant performance improvements. All hyper-parameters are directly inherited from  without any modification, including the ratio \(r\) which is set to \(15\%\). Additionally, we adopt the same NegMining algorithm, OOD score calculation method, and grouping strategy as described in . All experiments are conducted using GeForce RTX 3090 GPUs.

**Prompt ensemble.** We use the following prefixes to construct prompts for labels in the original semantic pool: _the, the good (nice), a photo of (with) the nice, a good (close-up) photo of the nice_. For labels in the conjugated semantic pool, we apply the prefixes: _a nice (good, close-up) photo of_. The baseline results reported in the ablation study (see Table 3) also utilize this technique.

**Computational cost.** The prompt ensemble is constructed over the embedding space to avoid any additional inference cost. Similar to NegLabel, our method is a post hoc OOD detector with negligible extra computational burden, which introduces \(<1\%\) network forward latency.

**Evaluation metrics.** Following previous works [40; 29; 64], we adopt the following metrics: the area under the receiver operating characteristic curve (AUROC), and the false positive rate of OOD data when the true positive rate of ID data is 95% (FPR95) .

### Evaluation on OOD detection benchmarks

**Evaluation on ImageNet-1k OOD detection benchmark.** We compare our method with existing OOD detection methods on the ImageNet-1k benchmark organized by  in Table 1. The methods

    &  &  \\   &  &  &  &  &  \\   & AUROC\(\) & FPR95\(\) & AUROC\(\) & FPR95\(\) & AUROC\(\) & FPR95\(\) & AUROC\(\) & FPR95\(\) & AUROC\(\) & FPR95\(\) \\  MSP  & 87.44 & 58.36 & 79.73 & 73.72 & 79.67 & 74.41 & 79.69 & 71.93 & 81.63 & 69.61 \\ ODIN  & 94.65 & 30.22 & 87.17 & 54.04 & 85.54 & 55.06 & 87.85 & 51.67 & 88.80 & 47.75 \\ Energy  & 95.33 & 26.12 & 92.66 & 35.97 & 91.41 & 39.87 & 86.76 & 57.61 & 91.54 & 39.89 \\ GradNorm  & 72.56 & 81.50 & 72.86 & 82.00 & 73.70 & 80.41 & 70.26 & 79.36 & 72.35 & 80.82 \\ ViM  & 93.16 & 32.19 & 87.19 & 54.01 & 83.75 & 60.67 & 87.18 & 53.94 & 87.82 & 50.20 \\ KNN  & 94.52 & 29.17 & 92.67 & 35.62 & 91.02 & 39.61 & 85.67 & 64.35 & 90.97 & 42.19 \\ VOS  & 94.62 & 28.99 & 92.57 & 36.88 & 91.23 & 38.39 & 86.33 & 61.02 & 91.19 & 41.32 \\  ZOC  & 86.09 & 87.30 & 81.20 & 81.51 & 83.39 & 73.06 & 76.46 & 98.90 & 81.79 & 85.19 \\ MCM  & 94.59 & 32.20 & 92.25 & 38.80 & 90.31 & 46.20 & 86.12 & 58.50 & 90.82 & 43.93 \\ NFOS  & 96.19 & 16.58 & 90.44 & 43.77 & 89.44 & 45.27 & 88.80 & 46.12 & 91.22 & 37.93 \\ CoOp  & 94.89 & 29.47 & 93.36 & 31.34 & 90.07 & 40.28 & 87.58 & 54.25 & 91.47 & 38.83 \\ CoCoOp  & 94.73 & 30.74 & 93.15 & 31.18 & 90.63 & 38.75 & 87.92 & 53.84 & 91.61 & 38.63 \\ CLIPN  & 95.27 & 23.94 & 93.93 & 26.17 & 92.28 & 33.45 & 90.93 & 40.83 & 93.10 & 31.10 \\ LSN  & 95.83 & 21.56 & 94.35 & 26.32 & 91.25 & 34.48 & 90.42 & 38.54 & 92.96 & 30.22 \\ NegLabel  & 99.49 & 1.91 & 95.49 & 20.53 & 91.64 & 35.59 & 90.22 & 43.56 & 94.21 & 25.40 \\ Ours & **99.60** & **1.54** & **96.66** & **13.66** & **92.90** & **29.32** & **93.86** & **25.52** & **95.76** & **17.51** \\   

Table 1: Comparative performance of OOD detection across baseline methods utilizing CLIP ViT-B/16 architecture with ImageNet-1k as ID data. Performance metrics are presented as percentages.

[MISSING_PAGE_FAIL:9]

**Analysis of different CLIP architectures.** Table 4 shows that our proposed method consistently outperforms the baseline method NegLabel by a large margin with differernt CLIP architectures, which demonstrates our effectiveness.

**Ablation of different superclass sets.** Refer to Appendix C.5 for details.

## 6 Conclusion

**Summary.** In this paper, we propose that enhancing the performance of zero-shot OOD detection theoretically requires: (1) concurrently increasing the semantic pool size and the expected activation probability of selected OOD labels; (2) ensuring low mutual dependence among the label activations. Furthermore, we analyze that the inefficacy of simply adopting larger lexicons is attributed to the introduction of numerous uncommon words and (near-)synonyms, thus failing to meet the above requirements. Observing that the original semantic pool is comprised of unmodified specific class names, we correspondingly construct a conjugated semantic pool consisting of specifically modified superclass names, each serving as a cluster center for samples sharing similar properties across different categories. Consistent with the established theory, expanding OOD label candidates with the conjugated semantic pool satisfies the requirements and achieves considerable improvements.

**Limitations and Future directions.** Our method has following limitations worth further exploration: (1) The effectiveness of CSP depends on the implicit assumption that the OOD samples exhibit a variety of distinct visual properties. When this assumption does not hold, _i.e._, OOD samples most share similar visual properties, such as the plant images in iNaturalist, the addition of CSP results in a slight performance decline, since most newly added labels are not likely to be activated. Reducing dependency on this assumption is a valuable direction for future research. (2) In this work, we primarily focus on analyzing and optimizing the activation status of OOD labels while making no modification to the ID label set. However, there is a possibility that selecting additional labels from the semantic pool, including the CSP, to expand the ID label set could enhance the identification of difficult ID samples. We consider this a promising direction for future exploration.