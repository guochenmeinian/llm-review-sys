# A Unified Generalization Analysis of Re-Weighting and Logit-Adjustment for Imbalanced Learning

Zitai Wang\({}^{1,2}\) Qianqian Xu\({}^{3}\) Zhiyong Yang\({}^{4}\)

**Yuan He\({}^{5}\) Xiaochun Cao\({}^{6}\) Qingming Huang\({}^{4,3,7}\)1 SKLOIS, Institute of Information Engineering, CAS \({}^{2}\) School of Cyber Security, University of Chinese Academy of Sciences \({}^{3}\) Key Lab. of Intelligent Information Processing, Institute of Computing Tech., CAS \({}^{4}\) School of Computer Science and Tech., University of Chinese Academy of Sciences \({}^{5}\) Alibaba Group \({}^{6}\) School of Cyber Science and Tech., Shenzhen Campus of Sun Yat-sen University \({}^{7}\) BDKM, University of Chinese Academy of Sciences wangzitai@iie.ac.cn xuqiangian@ict.ac.cn yangzhiyong21@ucas.ac.cn heyuan.hy@alibaba-inc.com caoxiaochun@mail.sysu.edu.cn qmhuang@ucas.ac.cn

###### Abstract

Real-world datasets are typically imbalanced in the sense that only a few classes have numerous samples, while many classes are associated with only a few samples. As a result, a naive ERM learning process will be biased towards the majority classes, making it difficult to generalize to the minority classes. To address this issue, one simple but effective approach is to modify the loss function to emphasize the learning on minority classes, such as re-weighting the losses or adjusting the logits via class-dependent terms. However, existing generalization analysis of such losses is still coarse-grained and fragmented, failing to explain some empirical results. To bridge this gap, we propose a novel technique named data-dependent contraction to capture how these modified losses handle different classes. On top of this technique, a fine-grained generalization bound is established for imbalanced learning, which helps reveal the mystery of re-weighting and logit-adjustment in a unified manner. Furthermore, a principled learning algorithm is developed based on the theoretical insights. Finally, the empirical results on benchmark datasets not only validate the theoretical results but also demonstrate the effectiveness of the proposed method.

## 1 Introduction

In recent years, machine learning has achieved great success with the help of well-collected datasets, where the number of samples is artificially balanced among classes . However, the real-world datasets are generally imbalanced in the sense that only a few classes have numerous samples (_i.e._, the majority ones), while the others are associated with only a few samples (_i.e._, the minority ones) . Owing to this issue, a naive Empirical Risk Minimization (ERM) learning process will be biased towards the majority classes, and the generalization on the minority ones becomes challenging. Hence, the imbalanced learning problem has attracted increasing attention in recent years .

One simple yet effective approach for imbalanced learning is to modify the naive loss function, such that the learning process can pay more attention to the minority classes (Please refer to Appendix A for more orthogonal approaches). In this direction, existing approaches generally fall into two categories: re-weighting  and logit-adjustment . The former category assigns larger weights tothe losses of the minority classes. Although intuitive, this approach might lead to difficulties and instability in optimization [11; 12; 17]. To tackle this issue, Cao et al.  propose an effective scheme named Deferred Re-Weighting (DRW), where the re-weighting approach is applied only during the terminal phase of training. The latter category adjusts the logits by class-dependent terms. For example, the Label Distribution Aware Margin (LDAM) loss enforces larger margins for minority classes to achieve strong regularization . The Logit-Adjustment (LA) loss  and the Class-Dependent Temperatures (CDT) loss  utilize additive and multiplicative terms to adjust the logits, respectively. Most recently, Kini et al.  combine the two types of terms and proposes a unified loss named Vector-Scaling (VS) for imbalanced learning.

Although existing loss-modification methods have achieved promising performance, the theoretical insights are still fragmented and coarse-grained. To be specific, Cao et al.  and Ren et al.  utilize the classic margin theory to explain the necessity of the additive terms in the LDAM loss. However, the theory fails to explain the significant improvement induced by the DRW scheme. Menon et al.  analyzes the Fisher consistency property  of the additive terms in the LA loss, while providing no further generalization analysis. Kini et al.  provides a generalization analysis of the VS loss, but the results can only explain the role of the multiplicative terms under the assumption that a linear model is trained on linearly separable data. Besides, we find that the VS loss is rather incompatible with the DRW scheme, which is also out of the scope of existing theory. Hence, a gap still exists between the theory and the practice of the loss-modification approaches.

To bridge this gap, this paper provides a systematical and fine-grained analysis of loss-modification approaches. After revisiting prior arts, we find that the only property of the loss function utilized in existing proofs is the classic Lipschitz continuity [19; 20]. However, this property is global in nature such that the whole analysis provides no insight into how the losses handle different classes. Inspired by this observation, we extend the classic Lipschitz continuity with a local technique. In this way, the local Lipschitz constants on different classes exactly correspond to the class-dependent terms of the modified loss functions. And a fine-grained generalization bound is established by a novel technique named data-dependent contraction. By applying this bound to the VS loss, the mystery of re-weighting and logit-adjustment is finally uncovered. Last but not least, a principled learning algorithm is proposed based on our theoretical insights.

To sum up, the main contributions of this paper are listed as follows:

* **New technique.** We extend the classic Lipschitz continuity and propose a novel technique named data-dependent contraction to obtain a fine-grained generalization bound for imbalanced learning.
* **Theoretical insights.** Based on the fine-grained bound, a systematical analysis succeeds in explaining the role of re-weighting and logit-adjustment in a unified manner, as well as some empirical results that are out of the scope of existing theories.
* **Principled Algorithm.** A principled algorithm is proposed based on the insights, where the re-weighting term is aligned with the generalization bound, and the multiplicative logit-adjustment term is removed during the DRW phase to avoid the incompatibility between terms.
* **Empirical Validation.** The empirical results on multiple benchmark datasets not only validate the theoretical results, but also demonstrate the superiority of the proposed method.

## 2 Preliminary

We first introduce the basic notations and the imbalanced learning problem in Sec.2.1. Then, we briefly review existing generalization analysis for imbalanced learning in Sec.2.2.

### Notations and Problem Definition

We assume that the samples are drawn _i.i.d._ from a product space \(=\), where \(\) is the input space and \(=\{1,,C\}\) is the label space. Let \(=\{(^{(n)},y^{(n)})\}_{n=1}^{N}\) be the imbalanced training set sampled from the imbalanced distribution \(\) defined on \(\), \(_{y}=\{(,y)\}\) be the set of samples from the class \(y\), \(N_{y}:=|_{y}|\) denote the size of \(_{y}\), and \(_{y}:=N_{y}/N\). Without loss of generality, we assume that \(N_{1} N_{2} N_{C}\).

Let \(_{}\) be the balanced distribution defined on \(\). Specifically, a class \(y\) is first uniformly sampled from \(\), and then the input \(\) is sampled from the class-conditional distribution \(_{y}:=[ y]\).

Then, our task is to learn a score function \(f:^{C}\) to minimize the risk defined on the balanced distribution:

\[_{}(f):=_{y=1}^{C}_{y}(f)=_{y=1}^{C}}_{_{y}}[M(f( ),y)],\] (1)

where \(_{y}\) is the risk defined on the class \(y\), and \(M:^{C}_{+}\) is the measure that evaluates the model performance at \(\). For example, one of the most popular choices is to check whether the top-1 prediction is right: \(M(f(),y)=[y_{y^{}}f( )_{y^{}}]\), where \([]\) is the indicator function. Since \(M\) is generally non-differential and thus hard to optimize, one has to select a differential surrogate loss \(L:^{C}_{+}\), which induces the following surrogate risk:

\[_{}^{L}(f):=_{y=1}^{C}_{y}^{L}( f)=_{y=1}^{C}}_{_{y}}[L(f( ),y)].\] (2)

Let \(:=\{L f:f\}\) denote the hypothesis set. Next, we consider a family of loss functions named Vector-Scaling (VS) :

\[L_{}(f(),y)=-_{y}(f()_{y }+_{y}}}{_{y^{}}e^{_{y^{}}f()_{y^{}}+ _{y^{}}}}).\] (3)

The advantage behind this loss family is two-fold. On one hand, the VS loss generalizes popular re-weighting and logit-adjustment methods. For example, when \(_{y}=1,_{y}=1,_{y}=0\), it becomes the traditional CE loss . When \(_{y}=1,_{y}=0\), re-weighting terms \(_{y}=_{y}^{-1}\) and \(_{y}=(1-p)/(1-p^{N_{y}}),p(0,1)\) recover the classic balanced loss  and Class-Balanced (CB) loss , respectively. \(_{y}=1,_{y}=1,_{y}=_{y},>0\) yield the LA loss . When \(_{1}=1,_{y}=(N_{y}/N_{1})^{},_{y}=0,>0\), we can deduce the CDT loss . On the other hand, an ideal surrogate loss should be Fisher consistent such that minimizing \(_{}^{L}(f)\) not only can put more emphasis on minority classes, but also helps bound \(_{bal}(f)\)[19; 21]. Fortunately, prior arts  have shown that a subset of the VS loss family satisfies such a property:

\[L_{}(f(),y):=}{_{y}}[1+_{y^{ } y}}}{_{y}}e^{f()_{y^{}} -f()_{y}}],\] (4)

where \(_{y}\) is an arbitrary positive constant.

### Existing Generalization Analysis for Imbalanced Learning

In balanced learning, we can directly minimize the empirical balanced risk defined on the balanced datasets \(_{}\) sampled from \(_{}\):

\[}_{}^{L}(f):=_{(,y) _{}}L(f(),y).\] (5)

Then, the generalization guarantee is available by traditional concentration techniques . However, in imbalanced learning, we can only minimize the empirical risk on the imbalanced dataset \(\):

\[}^{L}(f):=_{(,y)}L(f( ),y).\] (6)

To handle this issue, Cao et al.  and Ren et al.  aggregate the class-wise generalization bound directly with a union bound over class-wise results :

**Proposition 1** (Union bound for Imbalanced Learning ).: _Given the function set \(\) and a loss function \(L:^{C}[0,M]\), then for any \((0,1)\), with probability at least \(1-\) over the training set \(\), the following generalization bound holds for all \(g\):_

\[_{}^{L}(f)=_{y=1}^{C}_{y}^{L}(f) _{y=1}^{C}(}_{y}^{L}(f)+ }_{_{y}}()+3M}} ),\] (7)

_where \(}_{y}^{L}(f)\) is the empirical risk on \(_{y}\): \(}_{}():=}_{}[ _{g}_{n=1}^{N}^{(n)}g(^{(n)})]\) denotes the empirical complexity of the function set \(\), and \(:=(^{(1)},^{(2)},,^{(N)})\) are sampled from independent distributions such as the uniform distribution with \(\{1,-1\}\); \(\) denotes the asymptotic notation that omits undominated terms, that is, \(f(t) g(t)\) a constant \(C>0,f(t) C g(t)\)._To further bound the complexity term \(}_{_{y}}()\), Cao et al.  assume that the loss function \(L\) satisfies the Lipschitz continuity and applies the traditional contraction lemma :

**Definition 1** (Lipschitz Continuity).: _Let \(\|\|\) denote the 2-norm. Then, we say the loss function \(L(f,y)\) is Lipschitz continuous with constant \(\) if for any \(f,f^{}\), \(\),_

\[|L(f,y)-L(f^{},y)|\|f()-f^{}()\|.\] (8)

**Lemma 1** (Contraction Lemma).: _Assume that the loss function \(L(f,)\) is Lipschitz continuous with a constant \(\). Then, the following inequality holds:_

\[}_{}()}_{ }().\] (9)

Finally, the standard margin-based generalization bound  is directly applied to obtain the upper bound of \(}_{_{y}}()\). However, this union bound has the following limitations:

* Theoretically, this generalization bound is coarse-grained and not sharp enough. To be specific, the differences among different loss functions lie in the choice of \(_{y},_{y},_{y}\). However, the Lipschitz continuity, which is the only property of \(L\) utilized in the proof, is global in nature and thus obscures these differences. Although the margin theory can provide some theoretical insights into the role of \(_{y}\), the roles of \(_{y},_{y}\) are still a mystery. Besides, since \[(^{L}_{}(f))=( _{y}^{L}_{y}(f))_{y}( ^{L}_{y}(f)),\] (10) a sharper bound might be available if we can bound \(^{L}_{}(f)\) directly.
* Empirically, although the induced LDAM loss outperforms the CE loss, the improvement is not so significant. Fortunately, when combining the Deferred Re-Weighting (DRW) technique , where \(_{y}=(1-p)/(1-p^{N_{y}}),p(0,1)\) during the terminal phase of training, the improvement becomes much more impressive. However, Eq.(7) fails to explain this phenomenon.

Recently, Kini et al.  provide a generalization analysis for the VS loss. However, the results, which only hold for linear models with linearly separable data, can only explain the roles of \(_{y}\). For the role of \(_{y}\), they resort to analyzing the gradient of the VS loss and provide a coarse-grained analysis.

To sum up, existing generalization analysis for imbalanced learning is coarse-grained and fragmented. Next, we aim to build a more fine-grained and systematical generalization bound that can unify the roles of both re-weighting and logit-adjustment.

## 3 Fine-Grained Generalization Analysis for Imbalanced Learning

In Sec.3.1, we first establish a sharp generalization bound based on a novel technique named data-dependent contraction. Then, in Sec.3.2, we apply this generalization bound to the VS loss to provide a series of theoretical insights. Finally, in Sec.3.3, a principled algorithm is proposed based on the theoretical insights.

### Generalization Bound Induced By Data-Dependent Contraction

Different from Eq.(7), we hope to build a direct bound between \(^{L}_{}(f)\) and \(}^{L}(f)\). To this end, our analysis is based on the following lemma, whose proof can be found in Appendix B:

**Lemma 2**.: _Given the function set \(\) and a loss function \(L:^{C}[0,M]\), then for any \((0,1)\), with probability at least \(1-\) over the training set \(\), the following generalization bound holds for all \(g\):_

\[^{L}_{}(f)(L,)+} }_{}(),\] (11)

_where \((L,):=}[}^{L}(f)+3M}]\) contains the empirical risk on \(\) and the \(\) term._

**Remark 1**.: _Recall that \(_{C}:=N_{C}/N,N_{1} N_{2} N_{C}\). Hence, this lemma reveals how the model performance depends on the imbalance degree of the data._As shown in Sec.2.2, the fine-grained analysis is unavailable due to the global nature of the classic Lipschitz continuous property. In view of this, we extend this traditional definition with a local technique :

**Definition 2** (Local Lipschitz Continuity).: _We say the loss function \(L(f,y)\) is local Lipschitz continuous with constants \(\{_{y}\}_{y=1}^{C}\) if for any \(f,f^{},y\), \(_{y}\),_

\[|L(f,y)-L(f^{},y)|_{y}\|f()-f^{}()\|.\] (12)

Then, the following data-dependent contraction inequality helps us obtain a sharper bound, whose proof is given in Appendix C.

**Assumption 1**.: _Next, we assume that \(}_{}()(1/)\). Note that this result holds for kernel-based models with traditional techniques  and neural networks with the latest techniques . And the prior arts also adopt this assumption ._

**Lemma 3** (Data-Dependent Contraction).: _Assume that the loss function \(L(f,)\) is local Lipschitz continuous with constants \(\{_{y}\}_{y=1}^{C}\). Then, the following inequality holds under Asm.1:_

\[}_{}()}_{ }()_{y=1}^{C}_{y}},\] (13)

Combining Lem.2 and Lem.3, we have the following theorem:

**Theorem 1** (Data-Dependent Bound for Imbalanced Learning).: _Given the function set \(\) and a loss function \(L:^{C}[0,M]\), for any \((0,1)\), with probability at least \(1-\) over the training set \(\), the following generalization bound holds for all \(f\):_

\[^{L}_{}(f)(L,)+}_{}()}{C_{C}}_{y=1}^{C}_{y}}.\] (14)

At the first glance, Eq.(14) seems a little loose since \(_{y=1}^{C}}>1\). In fact, this intuition holds when local Lipschitz continuity degenerates to Def.1. However, when \(_{y}\) is decreasing _w.r.t._\(_{y}\), a shaper bound might be available. To build an intuitive understanding, we present the following proposition, whose proof can be found in Appendix D.

**Proposition 2**.: _Assume that \(_{y} N_{y}^{-},>0\). Then, when \(>1\), the data-dependent bound presented in Thm.1 is sharper than the union bound defined in Prop.1._

### Application to the VS Loss

Next, we apply Thm.1 to the VS loss to reveal the role of both re-weighting and logit-adjustment. To this end, it is necessary to analyze the local Lipschitz property of the VS loss, whose proof is presented in Appendix E.

**Lemma 4**.: _Assume that the score function is bounded. Then, the VS loss is local Lipschitz continuous with constants \(\{_{y}\}_{y=1}^{C}\), where_

\[_{y}=_{y}_{y}[1-(_{y}B_{y}( f)+_{y})],\] (15)

\(_{y}:=^{2}+(_{y^{} y}_{y^{ }})^{2}}\)_; softmax \(()\) denotes the softmax function; \(B_{y}(f)\) denotes the minimal prediction on the ground-truth class \(y\), i.e., \(B_{y}(f):=_{ S_{y}}f()_{y}\)._

**Remark 2**.: \(B_{y}(f)\) _is closely related to the minimal margin defined by \(_{y}^{}:=_{ S_{y}}(f()_{y}-_{j y }f()_{j})\). It is not difficult to check that \(B_{y}(f)-_{y}^{}_{ S_{y},j y}f( {x})_{j}\). Hence, as we improve the model performance on class \(y\), the RHS of the above inequality, i.e., the gap between \(B_{y}(f)\) and \(_{y}^{}\) will decrease, and both the minimal margin and \(B_{y}(f)\) will increase._

Then, combining Thm.1 and Lem.4, we have the following proposition, which reveals how the existing loss-oriented methods improve generalization performance by exploiting the data priors.

**Proposition 3** (Data-Dependent Bound for the VS Loss).: _Given the function set \(\) and the VS loss \(L_{}\), for any \((0,1)\), with probability at least \(1-\) over the training set \(\), the following generalization bound holds for all \(f\):_

\[^{L}_{}(f)(L_{},)+}_{}()}{C_{C}}_{y=1}^{C}_{y} _{y}}[1-(_{y}B_{y}(f)+ _{y})].\] (16)

From Eq.(16), we have the following insights, whose empirical validation can be found in Sec.4.2.

**(In1) Why re-weighting and logit-adjustment are necessary?** Due to the term \(}\) and \(B_{y}(f)\), the generalization bound is also imbalanced among classes. Both re-weighting and logit-adjustment can obtain a sharper generalization bound by assigning different weights to the classes with different \(}\) and \(B_{y}(f)\). In this process, \(_{y}\) mainly rebalances the generalization performance among classes, _i.e._, \(}\), while \(_{y}\) and \(_{y}\) focus on adjusting the imbalance of the terms \(B_{y}(f)\) among classes.

**(In2) Why the deferred scheme is necessary?** As pointed out in [11; 17], weighting up the minority classes will cause difficulties and instability in optimization, especially when the distribution is extremely imbalanced. To fix this issue, Cao et al.  develops a deferred scheme, where \(_{y}=1\) and \((1-p)/(1-p^{N_{y}}),p(0,1)\) during the initial and terminal phase of training, respectively. Although this scheme shows significant improvement, there is still a lack of theoretical explanation.

Fortunately, Prop.3 can give us some inspiration. Specifically, although a weighted loss can boost the optimization on the minority classes, it is harmful to the further improvement on the majority classes, as shown in Fig.3. Hence, the majority/minority classes will have relatively small/large \(B_{y}(f)\) respectively, and the generalization bound becomes even looser. By contrast, in the DRW scheme, we have \(_{y}=1\) during the initial phase of training. Such a warm-up phase will encourage the model to focus on the majority classes and induce a small \(B_{y}(f)\) for both majority and minority classes after weighting up the minority classes. On top of this, the generalization bound can become sharper, which explains the effectiveness of the deferred scheme.

**(In3) How does our result explain the design of existing losses?** On one hand, for re-weighting losses, \(_{y}\) should decrease as \(_{y}\) increases, which is consistent with the balanced loss with \(_{y}=_{y}^{-1}\) and \(_{y}=(1-p)/(1-p^{N_{y}}),p(0,1)\). On the other hand, from the insight **(In2)**, we know that when \(_{y}=1\), \(B_{y}(f)\) will be increasing _w.r.t._\(_{y}\). Hence, for logit-adjustment losses, both \(_{y}\) and \(_{y}\) should increase as \(_{y}\) increases. This insight is consistent with the LDAM loss (\(_{y}-N_{y}^{-1/4}\)) , the logit-adjusted loss (\(_{y}=_{y}\)) , and the CDT loss (\(_{y}=(N_{y}/N_{1})^{}\)) .

**(In4) Are re-weigting and logit-adjustment fully compatible?** **(a)** Unfortunately, the answer is negative. To be specific, the re-weighting term \(_{y}\) is decreasing _w.r.t._\(_{y}\), whereas the multiplicative logit-adjustment term \(_{y}\) is increasing _w.r.t._\(_{y}\). As a result, \(_{y}\) will weaken the effect of \(_{y}\). **(b)** Fortunately, \(_{y}\) is compatible with the additive logit-adjustment term \(_{y}\) since both terms can induce a sharper generalization bound.

### Principled Learning Algorithm induced by the Theoretical Insights

In this part, we present a principled learning algorithm induced by the theoretical insights in Sec.3.2. First, according to **(In1)-(In3)**, it is crucial to comprehensively utilize re-weighting, logit-adjustment, and the DRW scheme, as they all contribute to improving the generalization bound. Second, according to **(In4)**, we propose a Truncated Logit-Adjustment (TLA) scheme to avoid the conflict between \(_{y}\) and \(_{y}\). In this scheme, \(_{y}\) still increases _w.r.t._\(_{y}\) during the initial phase of training but is truncated to \(1\) during the terminal phase of training. Third, we set \(_{y}_{y}^{-},>0\) to align \(_{y}\) with \(}\), which we name Aligned DRW (ADRW). Note that such a re-weighting scheme also follows the Fisher consistency property presented in . Finally, the overall algorithm is summarized in Alg.1, where the logit-adjustment methods mentioned in Sec.2.1 are all reasonable options for \(_{y},_{y}\) in the line 5 and \(_{y}\) in the line 7.

```
0: Training set \(=\{(x_{i},y_{i})\}_{i=1}^{N}\) and a model \(f\) parameterized by \(\).
1: Initialize the model parameters \(\) randomly.
2:for\(t=1,2,,T\)do
3:\(\) SampleMiniBatch\((,m)\)\(\) A mini-batch of \(m\) samples
4:if\(t<T_{0}\)then
5: Set \(=1,_{y},_{y}\)\(\) Adjust logits during the initial phase
6:else
7: Set \(_{y}_{y}^{-},_{y}=1,_{y},>0\)\(\) TLA and ADRW
8:endif
9:\(L(f,)_{(,y)}L_{}(f(),y)\)\(\) Calculate the loss
10:\(-_{}L(f,)\)\(\) One SGD step
11: Optional: anneal the learning rate \(\). \(\) Required when \(t=T_{0}\)
12:endfor ```

**Algorithm 1**Principel Learning Algorithm induced by the Theoretical Insights

## 4 Experiments

### Experiment Protocols

Here, we briefly introduce the experiment protocols, and more details can be found in Appendix F.

**Datasets.** We conduct the experiments on four popular benchmark datasets for imbalanced learning. **(a) CIFAR-10 and CIFAR-100**: Following the protocol in [26; 11; 12], we consider two types of imbalance: long-tailed imbalance (LT) and step imbalance (Step). For both imbalance types, we

Figure 1: The balanced accuracy of the CE loss and the LDAM loss _w.r.t._\(_{y}_{y}^{-}\) on the CIFAR datasets, where the imbalance ratio \(=100\). Both re-weighting and logit-adjustment boost the model performance, which is consistent with the theoretical insight **(In1)** and **(In4-b)**.

Figure 2: Sensitivity analysis of VS+ADRW _w.r.t._\(_{y}_{y}^{-}\) and \(_{y}=_{y}\) on the CIFAR-10 dataset, where the imbalance ratio \(=100\). Both re-weighting and logit-adjustment boost the model performance, which is consistent with the theoretical insights **(In1)** and **(In4-b)**.

report the balanced accuracy averaged over 5 random seeds with an imbalance ratio \(:=N_{1}/N_{C}\{10,100\}\). **(b) ImageNet-LT and iNaturalist**: We use the long-tailed version of the ImageNet dataset2 proposed by , and iNaturalist3 is a real-world long-tailed dataset.

**Baselines and Competitors.** For the CIFAR datasets, we aim to validate the theoretical results and the performance gain induced by the proposed method. Hence, we select the following baselines: the CE loss (CE) , the LDAM loss (LDAM) , LDAM+DRW , and the VS loss (VS)  that generalizes the LA loss  and the CDT loss . We tune all the hyperparameters according to the suggestions in the original papers. For the ImageNet-LT and iNaturalist datasets, we select state-of-the-art methods, listed in Tab.2, as the competitors to validate the effectiveness of the method.

**Implementation Details.** We implement three instances of the proposed learning algorithm: the CE loss equipped with the ADRW scheme (**CE+ADRW**), the LDAM loss equipped with the ADRW scheme (**LDAM+ADRW**), and the VS loss equipped with the TLA and the ADRW scheme (**VS+TLA+ADRW**). We tune the hyperparameter \(\), and the other hyperparameters follow those used in the baselines. In addition, we incorporate the Sharpness-Aware Minimization (SAM) technique  to facilitate the optimization of the minority classes, allowing them to escape saddle points and converge to flat minima .

### Theory Validation

In this part, we aim to validate our theoretical insights presented in Sec.3.2 on the CIFAR datasets. Some more empirical results can be found in Appendix G.

Figure 4: The balanced accuracy of the VS loss _w.r.t._\(_{y}=(N_{y}/N_{1})^{}\) on the CIFAR datasets, where the imbalance ratio \(=10\). We can find that VS+DRW performs inferior to VS+None, especially when \(\) is large, which is consistent with the theoretical insight **(In4-a).**

Figure 3: (a) Training accuracy of CE+DRW (\(T_{0}=160\)) and the CB loss _w.r.t._ training epoch. (b) \(_{}/_{}\)_w.r.t._ the DRW epoch \(T_{0}\), where \(_{}\) and \(_{}\) denote the training accuracy of the best model on the minority/majority classes, respectively. (c) The test accuracy of the best model _w.r.t._ the DRW epoch \(T_{0}\). We can find that the DRW scheme balances the training accuracy between the majority classes and the minority classes and thus improves the model performance on the test set, which is consistent with the theoretical insight **(In2)**.

[MISSING_PAGE_FAIL:9]

Such performance gains validate the effectiveness of the proposed methods (2) Both re-weighting and logit-adjustment can improve the model performance, which is consistent with the theoretical insight **(In1)** and **(In4-b)**. (3) When \(=10\) or on the CIFAR-100 dataset, VS+DRW performs inferior to VS. Fortunately, when equipped with the proposed TLA scheme, VS+TLA+DRW outperforms both VS and VS+DRW. These results again validate our theoretical insight **(In4-a)**. (4) When \(=10\), CE+ADRW outperforms LDAM+ADRW, and similar counter-intuitive phenomena are also observed in . We conjecture that in this case, re-weighting is enough to rebalance the generalization bound, and the additional LDAM loss might induce other issues such as inconsistency.

We present the overall balanced accuracy on the ImageNet-LT and iNaturalist datasets in Tab.2, where SAM and Ours denotes LDAM+DRW+SAM and VS+TLA+ADRW+SAM, respectively. These results demonstrate that the proposed learning algorithm outperforms the competitors, especially the one-stage ones, which again confirms the effectiveness of the proposed learning algorithm.

## 5 Conclusion and Future Work

In this work, with the proposed local Lipschitz property and the data-dependent contraction technique, we present a unified generalization analysis of the loss-modification approaches for imbalanced learning. Benefiting from this fine-grained analysis, we not only reveal the role of both re-weighting and logit-adjustment approaches but also explain some empirical phenomena that are out of the scope of existing theories. Moreover, a principled learning algorithm is proposed based on the theoretical insights. Finally, extensive experimental results on benchmark datasets validate our theoretical analysis and the effectiveness of the proposed method.

Theoretically, one important future work is to provide a systematical Fisher consistency analysis for the VS loss, providing more insights to design re-weighting and logit-adjustment terms. Methodologically, it might be a promising direction to design an adaptive scheme that can automatically determine the hyperparameters of the learning algorithm.