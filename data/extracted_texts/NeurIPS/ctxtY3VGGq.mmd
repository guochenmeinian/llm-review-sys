# Online Weighted Paging with Unknown Weights

Orin Levy

Tel-Aviv University

orinlevy@mail.tau.ac.il &Noam Touitou

Amazon Science

noamtux@gmail.com &Aviv Rosenberg

Google Research

avivros007@gmail.com

Research conducted while the author was an intern at Amazon Science.Research conducted while the author was at Amazon Science.

###### Abstract

Online paging is a fundamental problem in the field of online algorithms, in which one maintains a cache of \(k\) slots as requests for fetching pages arrive online. In the weighted variant of this problem, each page has its own fetching cost; a substantial line of work on this problem culminated in an (optimal) \(O( k)\)-competitive randomized algorithm, due to Bansal, Buchbinder and Naor (FOCS'07).

Existing work for weighted paging assumes that page weights are known in advance, which is not always the case in practice. For example, in multi-level caching architectures, the expected cost of fetching a memory block is a function of its probability of being in a mid-level cache rather than the main memory. This complex property cannot be predicted in advance; over time, however, one may glean information about page weights through sampling their fetching cost multiple times. We present the first algorithm for online weighted paging that does not know page weights in advance, but rather learns from weight samples. In terms of techniques, this requires providing (integral) samples to a fractional solver, requiring a delicate interface between this solver and the randomized rounding scheme; we believe that our work can inspire online algorithms to other problems that involve cost sampling.

## 1 Introduction

**Online weighted paging.** In the online weighted paging problem, or OWP, one is given a cache of \(k\) slots, and requests for pages arrive online. Upon each requested page, the algorithm must ensure that the page is in the cache, possibly evicting existing pages in the process. Each page \(p\) also has a weight \(w_{p}\), which represents the cost of fetching the page into the cache; the goal of the algorithm is to minimize the total cost of fetching pages. Assuming that the page weights are known, this problem admits an \(O( k)\)-competitive randomized online algorithm, due to Bansal, Buchbinder, and Naor (2010, 2012); This is optimal, as there exists an \(( k)\)-competitiveness lower bound for randomized algorithms due to Fiat et al. (1991) (that holds even for the unweighted case).

However, all previous work on paging assumes that the page weights are known _in advance_. This assumption is not always justified; for example, the following scenario, reminiscent of real-world architectures, naturally gives rise to unknown page weights. Consider a multi-core architecture, in which data can be stored in one of the following: a local "L1" cache, unique to each core; a global "L2" cache, shared between the cores; and the (large but slow) main memory. As a specific core requests memory blocks, managing its L1 cache can be seen as an OWP instance. Suppose the costsof fetching a block from the main memory and from the L2 cache are \(1\) and \( 1\), respectively. Then, when a core demands a memory block, the expected cost of fetching this block (i.e., its weight) is a convex combination of \(1\) and \(\), weighted by the probability that the block is in the L2 cache; this probability can be interpreted as the demand for this block by the various cores. When managing the L1 cache of a core, we would prefer to evict blocks with low expected fetching cost, as they are more likely to be available in the L2 cache. But, this expected cost is a complicated property of the computation run by the cores, and estimating it in advance is infeasible; however, when a block is fetched in the above example, we observe a stochastic cost of either \(1\) or \(\). As we sample a given block multiple times, we can gain insight into its weight.

**Multi-armed bandit.** The above example, in which we learn about various options through sampling, is reminiscent of the multi-armed bandit problem, or MAB. In the cost-minimization version of this problem, one is given \(n\) options (or arms), each with its own cost in \(\). At each time step, the algorithm must choose an option and pay the corresponding cost; when choosing an option \(p\), rather than learning its cost \(w_{p}\), the algorithm is only revealed a sample from some distribution whose expectation is \(w_{p}\). In this problem, the goal is to minimize the **regret**, which is the difference between the algorithm's total cost and the optimal cost (which is to always choose the cheapest option). Over \(T\) time steps, the best known regret bound for this problem is \(()\), achieved through multiple techniques. (See, e.g., Slivkins et al. (2019); Lattimore and Szepesvari (2020)).

### Our Results

We make the first consideration of OWP where page weights are not known in advance, and show that the optimal competitive ratio of \(O( k)\) can still be obtained. Specifically, we present the problem of OWP-UW (Online Weighted Paging with Unknown Weights), that combines OWP with bandit-like feedback. In OWP-UW, every page \(p\) has an arbitrary distribution, whose expectation is its weight \(0<w_{p} 1\). Upon fetching a page, the algorithm observes a random, independent sample from the distribution of the page. We present the following theorem for OWP-UW.

**Theorem 1.1**.: _There exists a randomized algorithm_ ON _for_ OWP-UW _such that, for every input \(Q\),_

\[[(Q)] O( k)(Q)+( ),\]

_where \((Q)\) is the cost of_ ON _on \(Q\),_ OPT\((Q)\) _is the cost of the optimal solution to \(Q\), and the expectation is taken over both the randomness in_ ON _and the samples from the distributions of pages._

Note that the bound in Theorem 1.1 combines a competitive ratio of \(O( k)\) with a regret (i.e., additive) term of \(()\). To motivate this type of bound, we observe that OWP-UW does not admit sublinear regret without a competitive ratio. Consider the lower bound of \(( k)\) for the competitive ratio of paging; stated simply, one of \(k+1\) pages of weight \(1\) is requested at random. Over a sequence of \(T\) requests, the expected cost of any online algorithm is \((T/k)\); meanwhile, the expected cost of the optimal solution is at most \(O(T/(k k))\). (The optimal solution would be to wait for a maximal phase of requests containing at most \(k\) pages, whose expected length is \((k k)\), then change state at constant cost.) Without a competitive ratio term, the difference between the online and offline solutions is \((T/k)\), i.e., linear regret. We note that this kind of bound appears in several previous works such as Basu et al. (2019); Foussoul et al. (2023). As OWP-UW generalizes both standard OWP and MAB, both the competitive ratio and regret terms are asymptotically tight: a competitiveness lower bound of \(( k)\) is known for randomized algorithms for online (weighted) paging (Fiat et al., 1991), and a regret lower bound of \(()\) is known for MAB (Lattimore and Szepesvari, 2020).

### Our Techniques

**Interface between fractional solution and rounding scheme.** Randomized online algorithms are often built of the following components:

1. A deterministic, \(\)-competitive online algorithm for a fractional relaxation of the problem.
2. An online randomized rounding scheme that encapsulates any online fractional algorithm, and has expected cost \(\) times the fractional cost.

Combining these components yields an \(\)-competitive randomized online (integral) algorithm.

For our problem, it is easy to see where this common scheme fails. The fractional algorithm cannot be competitive without sampling pages; but, pages are sampled by the rounding scheme! Thus, the competitiveness of the fractional algorithm is not independent of the randomized rounding, which must provide samples. One could think of addressing this by feeding any samples obtained by the rounding procedure into the fractional algorithm. However, as the rounding is randomized, this would result in a non-deterministic fractional algorithm. As described later in the paper, this is problematic: the rounding scheme demands a globally accepted fractional solution against which probabilities of cache states are balanced.

Instead, we outline a sampling interface between the fractional solver and the rounding scheme. Once the total fractional eviction of a page reaches an integer, the fractional algorithm will pop a sample of the page from a designated sampling queue, and process that sample. On the other side of the interface, the rounding scheme fills the sampling queue and ensures that when the fractional algorithm demands a sample, the queue will be non-empty with probability 1.

**Optimistic fractional algorithm, pessimistic rounding scheme.** When learning from samples, one must balance the exploration of unfamiliar options and the exploitation of familiar options that are known to be good. A well-known paradigm for achieving this balance in multi-armed bandit problems is _optimism under uncertainty_. Using this paradigm to minimize total cost, one maintains a lower confidence bound (LCB) for the cost of an option, which holds with high probability, and tightens upon receiving samples; then, the option with the lowest LCB is chosen. As a result, one of the following two cases holds: either the option was good (high exploitation); or, the option was bad, which means that the LCB was not tight, and henceforth sampling greatly improves it (high exploration).

Our fractional algorithm for weighted paging employs this method. It optimistically assumes that the price of moving a page is cheap, i.e., is equal to some lower confidence bound (LCB) for that page. It then uses multiplicative updates to allocate servers according to these LCB costs. The optimism under uncertainty paradigm then implies that the fractional algorithm learns the weights over time.

However, the rounding scheme behaves very differently. Unlike the fractional algorithm, the (randomized) rounding scheme is not allowed to use samples to update the confidence bounds; otherwise, our fractional solution would behave non-deterministically. Instead, the rounding scheme takes a pessimistic view: it uses an _upper_ confidence bound (UCB) as the cost of a page, thus assuming that the page is expensive. Such pessimistic approaches are common in scenarios where obtaining additional samples is not possible (e.g., offline reinforcement learning (Levine et al., 2020)), but rarely appear as a component of an online algorithm as we suggest in this paper.

### Related Work

The online paging problem is a fundamental problem in the field of online algorithms. In the unweighted setting, the optimal competitive ratio for a deterministic algorithm is \(k\), due to Sleator and Tarjan (1985). Allowing randomization improves the best possible competitive ratio to \(( k)\)(Fiat et al., 1991). As part of a line of work on weighted paging and its variants (e.g., Young (1994), Manasse et al. (1990), Albers (2003), Irani (2002), Fiat and Mendel (2000), Bansal et al. (2008), Irani (1997)), the best competitive ratios for weighted paging were settled, and were seen to match the unweighted setting: \(k\)-competitiveness for deterministic algorithms, due to Chrobak et al. (1991); and \(( k)\)-competitiveness for randomized algorithms, due to Bansal et al. (2012).

Online (weighted) paging is a special case of the \(k\)-server problem, in which \(k\) servers exist in a general metric space, and must be moved to address requests on various points in this space; the cache slots in (weighted) paging can be seen as servers, moving in a (weighted) uniform metric space. The \((k)\) bound on optimal competitiveness in the deterministic for paging also extends to general \(k\)-server (Manasse et al., 1990; Koutsoupias and Papadimitriou, 1995). However, allowing randomization, a recent breakthrough result by Bubeck et al. (2023) was a lower bound of \((^{2}k)\)-competitiveness for \(k\)-server, diverging from the \(O( k)\)-competitiveness possible for paging.

Multi-Armed Bandit (MAB) is one of the most fundamental problems in online sequential decision making, often used to describe a trade-off between exploration and exploitation. It was extensively studied in the past few decades, giving rise to several algorithmic approaches that guarantee optimal regret. The most popular methods include Optimism Under Uncertainty (e.g., the UCB algorithm (Lai and Robbins, 1985; Auer et al., 2002a)), Action Elimination (Even-Dar et al., 2006), ThompsonSampling (Thompson, 1933; Agrawal and Goyal, 2012) and Exponential Weights (e.g., the EXP3 algorithm (Auer et al., 2002b)). For a comprehensive review of the MAB literature, see Slivkins et al. (2019); Lattimore and Szepesvari (2020).

## 2 Preliminaries

In OWP-UW, we are given a memory cache of \(k\) slots. A sequence of \(T\) page requests then arrives in an online fashion; we denote the set of requested pages by \(P\), define \(n:=|P|\), and assume that \(n>k\). Each page \(p\) has a corresponding weight \(0<w_{p} 1\); the weights are not known to the algorithm. Moreover, every page \(p\) has a distribution \(_{p}\) supported in \((0,1]\), such that \(_{x_{p}}[x]=w_{p}\).

The online scenario proceeds in \(T\) rounds.3 In each round \(t\{1,2,,T\}\):

* A page \(p_{t} P\) is requested.
* If the requested page is already in the cache, then it is immediately served.
* Otherwise, we experience a cache miss, and we must fetch \(p_{t}\) into the cache; if the cache is full, the algorithm must evict some page from the cache to make room for \(p_{t}\).
* Upon evicting any page \(p\) from the cache, the algorithm receives an independent sample from \(_{p}\).

The algorithm incurs cost when evicting pages from the cache: when evicting a page \(p\), the algorithm incurs a cost of \(w_{p}\)4. Our goal is to minimize the algorithm's total cost of evicting pages, denoted by ON, and we measure our performance by comparison to the total cost of the optimal algorithm, denoted by OPT. We say that our algorithm is \(\)-competitive with \(\) regret if \([]+\).

## 3 Algorithmic Framework and Analysis Overview

We present an overview of the concepts and algorithmic components we use to address OWP-UW. We would like to follow the paradigm of solving a fractional problem online, and then randomly rounding the resulting solution; however, as discussed in the introduction, employing this paradigm for OWP-UW requires a well-defined interface between the fractional solver and the rounding procedure. Thus, we present a fractional version of OWP-UW that captures this interface.

**Fractional OWP-UW.** In fractional OWP-UW, one is allowed to move fractions of servers, and a request for a page is satisfied if the total server fraction at that point sums to 1. More formally, for every page \(p P\) we maintain an amount \(y_{p}\) which is the fraction of \(p\)_missing_ from the cache; we call \(y_{p}\) the fractional **anti-server** at \(p\). (The term anti-server comes from the related \(k\)-server problem.) The feasibility constraints are:

1. At any point in the algorithm, it holds that \(_{p P}y_{p} n-k\). (I.e., the total number of pages in the cache is at most \(k\).)
2. After a page \(p\) is requested, it holds that \(y_{p}=0\). (I.e., there exists a total server fraction of 1 at \(p\).)

Evicting an \(\) server fraction from \(p\) (i.e., increasing \(y_{p}\) by \(\)) costs \( w_{p}\).

_Sampling._ The fractional algorithm must receive samples of pages over time in order to learn about their weights. An algorithm for fractional OWP-UW receives a sample of a page \(p\) whenever the total fraction of \(p\) evicted by the algorithm reaches an _integer_. In particular, the algorithm obtains the first sample of \(p\) (corresponding to 0 eviction) when \(p\) is first requested in the online input.

**Algorithmic components.** We present the fractional algorithm and randomized rounding scheme.

_Fractional algorithm._ In Section 4, we present an algorithm \(\) for fractional \(\)-\(\). Fixing the random samples from the pages' weight distributions, the fractional algorithm \(\) is deterministic. For every page \(p P\), the fractional algorithm maintains an upper confidence bound \(_{p}\) and a lower confidence bound \(_{p}\). These confidence bounds depend on the samples provided for that page; we define the _good event_\(\) to be the event that at every time and for every page \(p P\), it holds that \(_{p} w_{p}_{p}\). We later show that \(\) happens with high probability, and analyze the complementary event separately5. Thus, we henceforth focus on the good event.

The following lemma bounds the cost of \(\) subject to the good event. In fact, it states a stronger bound, that applies also when the cost of evicting page \(p\) is the upper confidence bound \(_{p} w_{p}\).

**Lemma 3.1**.: _Fixing any input \(Q\) for fractional \(\)-\(\), and assuming the good event, it holds that_

\[(Q)}(Q) O( k)( Q)+()\]

_where \(}\) is the cost of the algorithm on the input where the cost of evicting a page \(p\) is \(_{p} w_{p}\)._

_Randomized rounding._ In Section 5 we present the randomized algorithm \(\) for (integral) \(\)-\(\). It maintains a probability distribution over integral cache states by holding an instance of \(\), to which it feeds the online input. For the online input to constitute a valid _fractional_ input, the randomized algorithm ensures that samples are provided to \(\) when required. In addition, the randomized algorithm makes use of \(\)'s exploration of page weights; specifically, it uses the UCBs calculated by \(\).

**Lemma 3.2**.: _Fixing any input \(Q\) for (integral) \(\)-\(\), assuming the good event \(\), it holds that_

\[[(Q)] O(1)}(Q)+n\]

_where \(}(Q)\) is the cost of the algorithm on \(Q\) such that the cost of evicting a page \(p\) is \(_{p} w_{p}\)._

Figure 1 provides a step-by-step visualization of the interface between the fractional algorithm and the rounding scheme over the handling of a page request.

## 4 Algorithm for Fractional \(\)-\(\)

We now describe our algorithm for the fractional relaxation of \(\)-\(\), proving Lemma 3.1. Our fractional algorithm, presented in Algorithm 1 below, uses samples provided by the rounding scheme to learn the weights. A new sample for page \(p\) is provided and processed whenever the sum of fractional movements (in absolute value) \(m_{p}\) hits a natural number. (At this point the number of samples \(n_{p}\) is incremented.) The algorithm calculates non-increasing UCBs and non-decreasing LCBs that will be specified later in Section C and guarantee with high probability, for every page \(p P\) and time step \(t[1,T]\), \(_{p} w_{p}_{p}\).

At each time step \(t\), upon a new page request \(p_{t}\), the algorithm updates its feasible fractional cache solution \(\{y_{p}\}_{p P}\). The fractions are computed using optimistic estimates of the weights, i.e., the LCBs, in order to induce exploration and allow the true weights to be learned over time. After serving page \(p_{t}\) (that is, setting \(y_{p_{t}}=0\)), the algorithm continuously increases the anti-servers of all the other pages in the cache until feasibility is reached (that is, until \(_{p P}y_{p}=n-k\)). The fraction \(y_{p}\) for some page \(p\) in the cache is increased proportionally to \(+}{_{p}}\), which is our adaption of the algorithmic approach of Bansal et al. (2010) to the unknown-weights scenario. Finally, to fulfil its end in the interface, the fractional algorithm passes its feasible fractional solution to the rounding scheme together with pessimistic estimates of the weights, i.e, the UCBs.

### Analysis

In this analysis section, our goal is to bound the amount \(}\) with respect to the UCBs and LCBs calculated by the algorithm; i.e., to prove Lemma 4.1. Lemma C.1 and Lemma C.2 from Appendix C then make the choice of confidence bounds concrete, such that combining it with Lemma 4.1 yields the final bound for the fractional algorithm, i.e., Lemma 3.1.

**Lemma 4.1**.: _Fixing any input \(Q\) for fractional \(\), and assuming the good event, it holds that_

\[}(Q) O( k)(Q)+_{ p P}_{i=1}^{n_{p}}_{p,i}-_{p,i} +2(1+1/)\,_{p P}_{p}.\]

_where **(a)**\(}\) is the cost of the algorithm on the input such that the cost of evicting a page \(p\) is \(_{p} w_{p}\), and **(b)**\(_{p,i},_{p,i}\) are the values of \(_{p}\) and \(_{p}\) calculated by the procedure \(\) (found in Appendix C) immediately after processing the \(i\)'th sample of \(p\), and **(c)**\(_{p}\) is the value after the last sample of page \(p\) was processed._

Proof sketch.: We prove the lemma using a potential analysis. In Bansal et al. (2010), a potential function was introduced that encodes the discrepancy between the state of the optimal solution and the state of the algorithm. In our case, we require an additional term which can be viewed as a fractional exploration budget. This budget is "recharged" upon receiving a sample; the cost of this recharging goes into a regret term.

Figure 1: Visualization of the interface between the fractional and integral algorithms

## 5 Randomized Rounding

This section describes a randomized algorithm for (integral) OWP-UW, which uses Algorithm 1 for fractional OWP-UW to maintain a probability distribution over valid integral cache states, while obtaining and providing page weight samples to Algorithm 1. The method in which the randomized algorithm encapsulates and tracks the fractional solution is inspired by Bansal et al. (2012), which maintains a balanced property over weight classes of pages. However, as the weights are unknown in our case, the classes are instead defined using the probabilistic bounds maintained by the fractional solution (i.e., the UCBs). But, these bounds are dynamic, and change over the course of the algorithm; the imbalance caused by these discrete changes increases exponentially during rebalancing, and thus requires a more robust rebalancing procedure.

Following the notation in the previous sections, we identify each cache state with the set of pages _not_ in the cache. Observing the state of the randomized algorithm at some point in time, let \((S)\) be the probability that \(S P\) is the set of pages missing from the cache, also called the _anti-cache_. For the algorithm to be a valid algorithm for OWP-UW, the cache can never contain more than \(k\) pages; this is formalized in the following property.

**Definition 5.1** (valid distribution).: A probability distribution \(\) is valid, if for any set \(S P\) with \((S)>0\) it holds that \(|S| n-k\).

Instead of maintaining the distribution's validity, we will maintain a stronger property that implies validity. This property is the _balanced_ property, involving the UCBs calculated by the fractional algorithm.

For every page \(p\), we define the \(i\)'th UCB class to be \(P_{i}:=\{p P:6^{i}_{p}<6^{i+1}\}\). (Note that \(_{p}(0,1]\).) We also define \(P_{ j}:=_{i j}P_{j}\), the set of all pages that their UCB is at least \(6^{j}\).

Let \(\{y_{p}\}_{p P}\) be the fractional solution. The balanced property requires that, for every set \(S\) such that \((S)>0\) and every index \(j\), the number of pages in \(S\) of class at least \(j\) is the same as in the fractional solution, up to rounding. Formally, we define the balanced property as follows.

**Definition 5.2** (balanced distribution).: A probability distribution \(\) has the balanced subsets property with respect to \(y\), if for any set \(S P\) with \((S)>0\), the following holds for all \(j\):

\[_{i j}_{p P_{i}}y_{p}_{i j}_{p  P_{i}}[p S]_{i j}_{p P_{i}}y_{p} .\]

Figure 2: Example of a rebalancing step```
1Initialization
2 Let ONF be an instance of Algorithm 1, that maintains a fractional anti-server allocation \(\{y_{P}\}_{p P}\). Define \(\) to be a distribution over cache states, initially containing the empty cache state with probability 1. For every \(p P\), let \(s_{p}\).
3Event FunctionUponRequest(\(p\))// called upon a request for page \(p\) pass the request for \(p\) to ONF.
4whileONF is handling the request for \(p\)do// loop of Line 4 in Alg. 1
5ifONF increases \(y_{P^{}}\) by \(\), for some \(p^{} P\)then
6 add \(p^{}\) to the anti-cache in an \(\)-measure of states without \(p^{}\).
7 callRebalanceSubsets.
8
9ifONF decreases \(y_{P^{}}\) by \(\), for some \(p^{} P\)then
10 remove \(p^{}\) from the anti-cache in an \(\)-measure of states with \(p^{}\).
11 callRebalanceSubsets.
12
13ifONF samples a page \(p^{} P\)then// sample due to Line 6 of Alg. 1
14 provide \(s_{P^{}}\) as a sample to ONF, and set \(s_{P^{}}\).
15 callRebalanceSubsets. // rebalance due to change in \(_{p^{}}\).
16
17if\(s_{p}=\)then evict and re-fetch \(p\) to obtain weight sample \(_{p}\), and set \(s_{p}_{p}\).
18ifONF requests a sample of \(p\)then// sample due to Line 11 of Alg. 1
19 provide \(s_{p}\) as a sample to ONF, and set \(s_{p}\).
20 callRebalanceSubsets. // rebalance due to change in \(_{p}\). ```

**Algorithm 2**Randomized rounding algorithm for OWP-UW

```
1FunctionRebalanceSubsets
2 let \(j_{}\) be the maximum class that is not balanced. let \(j_{}:=(_{})\), where \(_{}:=_{p P}_{p}\). for every class \(j\), let \(P_{j}:=\{p P[(_{p})=j\}\). for\(j\) from \(j_{}\) down to \(j_{}\)do
3 let \(P_{ j}:=_{j^{} j}P_{j^{}}\). let \(Y_{j}:=_{p P_{ j}}Y_{p}\). while\( S\) s.t. \((S)>0\) and \(|S P_{ j}|\{ Y_{j}, Y_ {j}\}\)do// iteratively eliminate imbalanced states choose such \(S\) that maximizes \( m-Y_{j}\), where \(m:= S P_{ j}\). if\(m Y_{j}+1\)then
4 Match the \((S)\) measure of \(S\) with an identical measure of anti-cache states with at most \( Y_{j}-1\) pages from \(P_{ j}\). foreach anti-cache state \(S^{}\) matched with \(S\) at measure \(x(S)\)do
5 identify a page \(p P_{j}\) such that \(p S S^{}\). remove \(p\) from the anti-cache in the \(x\) measure of \(S^{}\), and insert it into the anti-cache in the \(x\) measure of \(S\). if\(m Y_{j}-1\)then
6 Match the \((S)\) measure of \(S\) with an identical measure of anti-cache states with at least \( Y_{j}+1\) pages from \(P_{ j}\). foreach anti-cache state \(S^{}\) matched with \(S\) at measure \(x_{S^{}}(S)\)do
7 identify a page \(p P_{j}\) such that \(p S^{} S\). remove \(p\) from the anti-cache in the \(x\) measure of \(S^{}\), and insert it into the anti-cache in the \(x\) measure of \(S\). ```

**Algorithm 3**Rebalancing procedure for randomized algorithm

Choosing the minimum UCB class in Definition 5.2, and noting that \(_{p P}y_{P} n-k\) through feasibility, immediately yields the following remark.

_Remark 5.3_.: Every balanced probability distribution is also a valid distribution.

To follow the fractional solution, we also demand that the distribution \(\) is _consistent_ with the fractional solution, meaning, the marginal probability in \(\) that any page \(p\) is missing from the cache must be equal to \(y_{P}\).

**Definition 5.4** (consistent distribution).: A probability distribution \(\) on subsets \(S P\) is consistent with respect to a fractional solution \(y_{P}}_{p P}\) if for every page \(p\) it holds that \(_{S P p S}(S)=y_{P}\).

In the following we describe the online maintenance of the distribution \(\), that yields a distribution satisfying all of the above.

**Algorithm overview.** The randomized algorithm for OWP-UW is given in Algorithm 2. The algorithm encapsulates an instance of Algorithm 1 for fractional OWP-UW, called ONF. Upon a new page request \(p_{t}\) at round \(t\), the algorithm forwards this requests to ONF. As ONF makes changes to its fractional solution, the algorithm modifies its probability distribution accordingly to remain consistent and balanced (and hence also valid).

Upon any (infinitesimally small) change to a fractional variable, the algorithm first changes its distribution to maintain consistency: when the fractional algorithm ONF increases the variable \(y_{P^{}}\) of any page \(p^{}\) by an \(\)-measure, the algorithm identifies an \(\)-measure of cache states \(S P\) in which there is no anti-server at \(p^{}\) and adds anti-server at \(p^{}\). The case in which the fractional algorithm decreases a variable is analogous.

However, this procedure may invalidate the balanced property. Specifically, for some class \(j\), letting \(Y_{j}\) be the total anti-server fraction of pages of at least class \(j\) in ONF, there might now be states with \(Y_{j}+1\) or \(Y_{j}-1\) such pages in the anti-cache. Thus, the algorithm makes a call to RebalanceSubsets, which restores the balanced property class-by-class, in a descending order. For every class \(j\), the procedure repeatedly identifies a violating state \(S\) where the number of pages of class \( j\) in the anti-cache is not in \(Y_{j},Y_{j}}\); suppose it identifies such a state with more than \(Y_{j}\) such pages (the case of less than \(Y_{j}\) pages is analogous). The procedure seeks to move a page of class \(j\) from this state to another state in a way that does not increase the "imbalance" in class \(j\). Thus, the procedure identifies a matching measure of anti-cache states that contain at most \(Y_{j}-1\) such pages, and moves a page of class \(j\) from \(S\) to \(S^{}\), for every \(S^{}\) in the matched measure; a visualization of the procedure is given in Figure 2. (The existence of this matching measure, as well as a page to move, are shown in the analysis.) In particular, note that the probability of every page being in the anti-cache remains the same, and thus RebalanceSubsets does not impact consistency.

Regarding samples, the algorithm can maintain a sample \(s_{p}\) for every page \(p\). A sample for \(p\) is obtained upon a request for \(p\) after \(p\) is fetched with probability \(1\) into the cache, if no such sample already exists (i.e., \(s_{p}=\)). Whenever ONF requests a sample for a page \(p\), the randomized algorithm provides the sample \(s_{p}\), and sets the variable \(s_{p}\) to be Null (we show that \(s_{p}\) is never Null when ONF samples \(p\)). A fine point is the sampling of a new page in Line 11 of Algorithm 1; this happens after Line 17 of Algorithm 2.

## 6 Conclusions

In this paper, we presented the first algorithm for online weighted paging in which page weights are not known in advance, but are instead sampled stochastically. In this model, we were able to recreate the best possible bounds for the classic online problem, with an added regret term typical to the multi-armed bandit setting. This unknown-costs relaxation makes sense because the problem has recurring costs; that is, the cost of evicting a page \(p\) can be incurred multiple times across the lifetime of the algorithm, and thus benefits from sampling.

We believe this paper can inspire future work on this problem. For example, revisiting the motivating case of managing a core-local L1 cache, the popularity of a page among the cores can vary over time; this would correspond to the problem of non-stationary bandits (see, e.g., Auer et al. (2019, 2019), Chen et al. (2019)), and it would be interesting to apply techniques from this domain to OWP-UW.

Finally, we hope that the techniques outlined in this paper could be extended to additional such problems. Specifically, we believe that the paradigm of using optimistic confidence bounds in lieu of actual costs could be used to adapt classical online algorithms to the unknown-costs setting. In addition, the interface between the fractional solver and rounding scheme could be used to mediate integral samples to an online fractional solver, which is a common component in many online algorithms.