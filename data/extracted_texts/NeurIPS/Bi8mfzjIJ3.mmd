# SimVAE: Narrowing the gap between Discriminative & Generative Representation Learning

Alice Bizeul

Carl Allen

Department of Computer Science, ETH Zurich and ETH AI Center

{alice.bizeul, carl.allen}@ai.ethz.ch

###### Abstract

Self-supervised representation learning is a powerful paradigm that leverages the relationship between semantically similar data, such as augmentations, extracts of an image or sound clip, or multiple views/modalities. Recent methods, e.g. SimCLR, CLIP and DINO, have made significant strides, yielding representations that achieve state-of-the-art results on multiple downstream tasks. Though often intuitive, a comprehensive theoretical understanding of their underlying mechanisms or _what_ they learn eludes. Meanwhile, generative approaches, such as variational autoencoders (VAEs), fit a specific latent variable model and have principled appeal, but lag significantly in terms of performance. We present a theoretical analysis of self-supervised discriminative methods and a graphical model that reflects the assumptions they implicitly make and unifies these methods. We show that fitting this model under an ELBO objective improves representations over previous VAE methods on several common benchmarks, narrowing the gap to discriminative methods, and can also preserve information lost by discriminative approaches. This work brings new theoretical insight to modern machine learning practice.

## 1 Introduction

Self-supervised learning (SSL) has become a prominent approach to unsupervised representation learning. Under this paradigm, a model is trained on an auxiliary task without annotated labels and representations of the data are learned in the process. Recently, _contrastive_ SSL has achieved remarkable performance, exemplified by SimCLR (3), SWaV (2) and CLIP (18). However, the success of contrastive SSL predominantly relies on heuristic strategies and intuitive but ad hoc design choices. A theoretical mechanism underlying their impressive performance remains unclear, limiting confidence in their reliability, restricting their interpretability and inhibiting their improvement.

To address these challenges, we consider the relationship between discriminative and generative representation learning and how an _encoder_, that maps data samples to representations, corresponds to the posterior distribution of a generative model, which it effectively reverses. We consider the implicit latent structure learned by several discriminative self-supervised algorithms, including the widely used InfoNCE loss function adopted by numerous other SSL models (e.g. 3; 18). We show that these methods reflect a common hierarchical latent variable model, but do not fit its posterior due to their discriminative nature. Instead, representations of semantically related data "collapse" together, losing the (typically _stylistic_) information that distinguishes them, despite its potential use in downstream tasks. By prioritising some properties of the data over others, this effectively pre-supposes the set of downstream tasks and limits the generality of representations. We propose _SimVAE_, a _generative_ alternative that explicitly models the latent structure implied by discriminative methods (Figure 2), introducing the implicit latent structure of SimCLR (3) into the variational auto-encoder (VAE) (13).

Generative methods are inherently more challenging than their discriminative counterparts, and we should not necessarily expect to bridge the performance gap in one step. Encouragingly, SimVAE is competitive with, or outperforms, several discriminative methods on simple datasets, but is less competitive on more complex datasets, suggesting the need for further research. Importantly, SimVAE significantly outperforms (\(>\)\(10\%\) on some metrics) previous VAE-based generative methods, narrowing the gap to discriminative SSL.

## 2 Background and Related Work

InfoNCE (17) extends the Word2Vec (16) approach to other domains where pairs (\(x\), \(x^{}\)) can be extracted "close by" or at random (e.g. image patches or sound clips). The InfoNCE loss for a data sample \(x\), positive sample \(x^{+}\) and \(L\) negative samples \(X^{-}\!=\{x_{l}^{-}\}_{l=1}^{L}\) is given by:

\[(x,x^{+}\!,X^{-})=-(z,z^{+})\}}{\{ (z,z^{+})\}+_{x^{} X^{-}}\{(z,z^{}) \}},\] (1)

where \(z\) is the representation of \(x\) and \((,)\) is a _similarity function_, e.g.

dot product. A similar loss is proposed by (20). Many works use the InfoNCE loss, e.g. using synthetic augmentations (3) or other modalities (18) of \(x\) as \(x^{+}\); taking representations from different encoder layers (11); or propose alternatives to negative sampling, e.g. MoCo (8), VicReg (1).

## 3 Representation Learning

Representations learning approaches are either discriminative or generative, with many recent self-supervised approaches being the former. _Discriminative_ approaches tend to train the encoder under a loss function that induces geometric properties in the representation space that are intuitively desirable, e.g. for representations of related data samples to be "close" relative to random samples. A _generative_ model \(p(x)=_{z}p(x|z)p(z)\) can be interpreted as sampling a latent variable \(z\!\!p()\) that defines the underlying characteristics of a data point; then sampling \(x\!\!p(|z)\) to produce a manifestation of those properties. The posterior \(p(z|x)\) effectively _reverses the generative process_ to infer a distribution over \(z\) and thus the underlying semantic properties of \(x\), reflecting uncertainty and providing a semantically meaningful representation of \(x\).

In fact, the **generative and discriminative paradigms are two sides of the same coin** since any encoder \(f\) defines a posterior delta distribution \(p(z|x)=_{z-f(x)}\) (with zero uncertainty); and for any \(z\!\!\), a distribution \(p(|z)\) is implicitly defined by the probabilities of samples mapping to it \(\{x\!\!\,|\,f(x)\!=\!z\}\). Generative approaches are more challenging but offer a principled, interpretable basis for representation learning, an uncertainty estimate over representations (i.e. the posterior), the ability to generate synthetic data, and insight into the information captured by representations from their regenerations.

We investigate the latent structure imposed by several discriminative methods, including InfoNCE (17), which underpins other methods such as SimCLR and CLIP. We posit a latent variable model (figure 2) to describe the latent structure those methods implicitly induce and propose a principled approach to learning it under an ELBO objective.

Figure 1: Qualitative assessment of representation information: images reconstructed from representations learned by unsupervised learning (VAE), generative SSL (our SimVAE) and discriminative SSL (SimCLR, VicReg). Datasets: MNIST (\(l\)), Fashion MNIST (\(r\)), original images in left columns.

Figure 2: Graphical model for SSL; \(J\) related samples;

### Discriminative Self-Supervised Learning

**Instance Discrimination (ID)** (5; 23) trains a classifier using the sample index \(i\!\![1,N]\) as a "label" for each sample and its augmentations (if any). The softmax cross-entropy loss can be viewed from a latent perspective (VC, SS2) for the latent variable model i \(\) z \(\) x (_cf_ Figure 2):

\[ p(i|x_{i}^{j})_{z}q_{}(z|x_{i}^{j}) p(i|z)\] (2)

where \(j\) indexes an augmentation (inc. identity). By maximising Equation 2, representations of each "class" collapse together rather than fit any meaningful posterior giving _style-invariant_ representations.

**Deep Clustering (DC)** (2) repeatedly identifies a large number of clusters in the latent space (by K-means) and uses temporary cluster assignments as pseudo-labels for discriminative training similar to ID. This induces similar latent structure as ID, and representations of each cluster collapse together.

**InfoNCE-based Contrastive Learning** approximates the softmax of ID, reducing memory/computational cost: (1) Under softmax cross entropy loss all representations of a class \(y\) converge to class parameter \(w_{y}\). In expectation, \(z^{}z^{}\), for stochastically sampled \(z^{}\) of the same class, approximates \(z^{}w_{y}\), without the need to store \(w_{y}\). (2) The softmax denominator is sampled, meaning optimal representations now satisfy \((z,z^{})\!=\!(x,x^{})+c(x)\) (17). However, using _bounded_ cosine similarity \((z,z^{})\!=\!z^{}}{|z|\!|z^{}|}\! \![-1,1]\) restricts that equality. Optimal representations are the same for related samples and maximally dispersed otherwise, comparable to those learned by softmax.

Summary: these different discriminative SSL methods _correspond to a common hierarchical latent variable model_ (Figure 2). Being discriminative, they do not reflect a meaningful posterior, instead representations of semantically related data collapse together losing information that differentiates them (e.g. _style_), that downstream tasks may require. By preserving "class" at the expense of other information, **contrastive methods may _over-fit_ representation learning to style-agnostic tasks**.

### Generative Self-Supervised Learning (SimVAE)

Towards avoiding the pitfalls of discriminative approaches, we propose _SimVAE_, a generative approach to learn representations under the latent variable model posited from discriminative methods (Figure 2). Let x\(\!=\!\{x^{j}\}\), z\(\!=\!\{z^{j}\}\) with \(j[1,J]\). The ELBO for _J semantically related_ samples is given by:

\[ p()_{j}\!_{z^{j}}\!\!q(z^{j}|x^{j})|z^{j})}{q(z^{j}|x^{j})}+_{}\!\!q(|)_{y }q(y|)_{j}|y)}{q(y|z^{j})}+ p(y) \] (3)

where \(q(|)_{j}q(z^{j}|x^{j})\). Note, we can choose _any_\(J\) to process multiple related samples.

## 4 Results

We focus on image cropping and color jitter (for natural images only) (3) to construct related samples. We perform standard evaluation of the learned representations (see appendix A.4 for details). Table 1 reports downstream supervised classification (using linear, MLP, KNN probes) and unsupervised (GMM) clustering accuracy across SSL methods and datasets. SimVAE is comparable to or outperforms disciminative and generative baselines on simple datasets, and significantly outperforms all VAE methods on natural images, including the self-supervised CRVAE. While a significant gap remains between SimVAE and disciminative methods on natural images, we significantly reduce the deficit compared to previous VAE-based methods.

**Diversity of Encoded Information** Figure 1 shows image reconstructions, using decoders trained post-hoc for discriminatively learned representations. This illustrates that style information (e.g., position and scale) is lost by discriminative SSL but preserved by generative methods. We quantitatively evaluate the ability to predict Celeb-A attributes, beyond gender classification shared in table 1, given that some relate to the augmentation strategy, e.g. hair color prediction requires color information. Table 2 shows that SimVAE outperforms other generative and all discriminative methods when style information is needed.

    & LP-CA & MP-CA \\  Random & \(52.9 0.4\) & \(51.2 0.1\) \\  SimCLR & \( 0.1\) & \( 1.2\) \\ VicReg & \(62.7 0.3\) & \(63.8 0.5\) \\  VAE & \(75.4 0.4\) & \(67.4 0.4\) \\ SimVAE & \( 0.5\) & \( 0.3\) \\   

Table 2: Celeb-A hair color CA. Mean accuracy and std error (3 random seeds)

## 5 Discussion

We introduce the SimVAE training objective, based on the ELBO for a graphical model that embodies the assumptions implicit in several discriminative self-supervised methods. Our results validate this latent assumption and show the efficacy of SimVAE relative to previous VAE approaches, including CRVAE that aims for comparable latent structure. SimVAE demonstrably reduces the performance gap to discriminative SSL objectives, including those based on the popular InfoNCE objective.

SimVAE offers a more principled approach to modeling _sets_ a of semantically related observations, facilitating the simultaneous representation of both content and style information, and taking a positive step towards fully task-agnostic representations. Additionally, the posterior provides an estimate of uncertainty, which may be important for critical downstream tasks, and the prior allows for explicit design choices, offering the prospect of separating latent factors to achieve disentangled representations.

While we consider SimVAE to be a positive advancement in representation learning, challenges remain in bridging the gap between generative and discriminative methods. Previous research shows that leveraging more complex model architectures, e.g. NVAE (22), StyleGAN (12), and CRVAE (19), can significantly enhance the ability of generative models. In this work, we hold the model architecture constant for fair comparison of the loss functions, but the additional complexity of generative methods and the increased information that representations are required to retain, may require more expressive architectures (e.g. (6)). Further, we note that increased variability of augmentations tend to improve discriminative methods but increase the challenge for generative approaches (e.g. see appendix A.5), suggesting a further direction for future investigation.

    & & & LP-CA & MP-CA & KNN-CA & GMM-CA \\   &  & \(51.2 0.6\) & \(49.8 0.8\) & \(66.5 0.4\) & \(48.6 0.2\) \\  &  & \(\) & \(\) & \(\) & \(\) \\  &  & \(70.7 0.9\) & \(72.6 0.6\) & \(76.0 0.2\) & \(57.7 0.8\) \\  &  & \(65.0 1.3\) & \(71.2 0.1\) & \(76.9 0.2\) & \(56.6 1.1\) \\  &  & \(77.0 0.5\) & \(80.2 0.3\) & \(83.7 0.2\) & \(57.9 0.8\) \\  &  & \(77.2 0.1\) & \(79.7 0.2\) & \(83.5 0.4\) & \(57.5 0.2\) \\  &  & \(77.7 0.4\) & \(80.1 0.1\) & \(\) & \(67.5 1.2\) \\  &  & \(\) & \(\) & \(\) & \(\) \\   &  & \(64.4 0.9\) & \(65.3 1.0\) & \(62.0 0.9\) & \(59.2 0.3\) \\  &  & \(94.2 0.2\) & \(92.7 0.4\) & \(92.0 0.3\) & \(\) \\  &  & \(\) & \(\) & \(\) & \(53.9 0.2\) \\   &  & \(81.5 1.0\) & \(87.7 0.5\) & \(79.6 0.7\) & \(\) \\  &  & \(81.9 0.2\) & \(86.7 0.4\) & \(79.8 0.1\) & \(\) \\  &  & \(81.6 0.3\) & \(87.7 0.4\) & \(79.6 0.6\) & \(\) \\  &  & \(\) & \(\) & \(\) & \(\) \\   &  & \(15.7 0.9\) & \(16.3 0.4\) & \(13.1 0.6\) & \(28.2 0.2\) \\  &  & \(65.2 0.2\) & \(67.8 0.2\) & \(65.2 0.2\) & \(49.8 2.8\) \\  &  & \(\) & \(\) & \(\) & \(\) \\  &  & \(53.3 1.3\) & \(56.4 1.6\) & \(54.0 2.0\) & \(35.0 2.8\) \\   &  & \(24.7 0.4\) & \(30.3 0.4\) & \(25.6 0.5\) & \(23.4 0.7\) \\  &  & \(24.4 0.4\) & \(29.8 0.2\) & \(25.1 0.4\) & \(23.8 0.4\) \\  &  & \(24.7 0.4\) & \(30.4 0.1\) & \(25.4 0.4\) & \(23.9 0.8\) \\  &  & \(\) & \(\) & \(\) & \(\) \\   

Table 1: Top-1% self-supervised CA (\(\)) for FashionMNIST, CIFAR10, and Celeb-A (i.e., gender classification) using a linear probe (LP), MLP probe (MP), k-Nearest Neighbors (KNN), and Gaussian Mixture Model (GMM) classification methods; Scores report the average and standard error across three random seeds; Bold numbers highlight the best scores with-in each method sub-group namely generative, ©, and discriminative methods, ©.