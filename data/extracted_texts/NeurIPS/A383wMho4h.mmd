# Oracle Complexity of Single-Loop Switching Subgradient Methods for Non-Smooth Weakly Convex Functional Constrained Optimization

Oracle Complexity of Single-Loop Switching Subgradient Methods for Non-Smooth Weakly Convex Functional Constrained Optimization

 Yankun Huang

Department of Business Analytics

University of Iowa

Iowa City, IA 52242

yankun-huang@uiowa.edu &Qihang Lin

Department of Business Analytics

University of Iowa

Iowa City, IA 52242

qihang-lin@uiowa.edu

###### Abstract

We consider a non-convex constrained optimization problem, where the objective function is weakly convex and the constraint function is either convex or weakly convex. To solve this problem, we consider the classical switching subgradient method, which is an intuitive and easily implementable first-order method whose oracle complexity was only known for convex problems. This paper provides the first analysis on the oracle complexity of the switching subgradient method for finding a nearly stationary point of non-convex problems. Our results are derived separately for convex and weakly convex constraints. Compared to existing approaches, especially the double-loop methods, the switching gradient method can be applied to non-smooth problems and achieves the same complexity using only a single loop, which saves the effort on tuning the number of inner iterations.

## 1 Introduction

Continuous optimization with nonlinear constraints arises from many applications of machine learning and statistics. Examples include Neyman-Pearson classification  and learning with fairness constraints . In this paper, we consider the following general nonlinear constrained optimization

\[f^{*}_{}f()  g() 0,\] (1)

where \(^{d}\) is a closed convex set that allows a computationally easy projection operator, \(f\) is weakly-convex, \(g\) is either convex or weakly convex, and functions \(f\) and \(g\) are not necessarily smooth. When \(g()_{i=1,,m}g_{i}()\), (1) is equivalent to an optimization problem with multiple nonlinear constraints \(g_{i}() 0\) for \(i=1,,m\).

A weakly convex function can be non-convex, so computing an optimal solution of (1) is challenging in general even without constraints. For this reason, theoretical analysis for gradient-based algorithms for non-convex problems mostly focuses on an algorithm's (oracle) complexity for finding an \(\)-stationary solution for (1). When a problem is non-smooth, finding an \(\)-stationary solution is generally difficult even if the problem is convex . Hence, in this paper, we consider finding a nearly \(\)-stationary solution for (1), whose definition will be stated later in Definition 3.2.

In the past decade, there have been many studies on non-convex constrained optimization. However, most of the existing algorithms and their theoretical complexity analysis are developed by assuming \(f\) and \(g_{i}\)'s are all smooth or can be written as the sum of a smooth and a simple non-smooth functions. A non-exhaustive list of the works under such an assumption includes . Their results cannot be applied to (1) due to non-smoothness in the problem.

Non-smoothness is common in optimization in machine learning, e.g., when a non-smooth loss function is applied, but there are much fewer studies on non-smooth non-convex constrained optimization. Under the weak-convexity assumption, an effective approach for solving a non-smooth non-convex problem with theoretical guarantees is the (inexact) proximal point method, where a quadratic proximal term is added to objective and constraint functions to construct a strongly convex constrained subproblem and then a sequence of solutions can be generated by solving this subproblem inexactly and updating the center of the proximal term. Oracle complexity for this method to find a nearly \(\)-stationary has been established by [13; 54; 39] under different constraint qualifications.

The inexact proximal point method is a _double-loop_ algorithm where the inner loop is another optimization algorithm for solving the aforementioned strongly convex subproblems. The complexity results in [13; 54; 39] require the inner loop solves each subproblem to a targeted optimality gap. However, the optimality gap is hard to evaluate and thus cannot be used to terminate the inner loop. Although the number of inner iterations needed to achieve the targeted gap can be bounded theoretically, the bound usually involves some constants that are unknown or can only be estimated conservatively. Hence, using the theoretical iteration bound to stop the inner loop usually leads to significantly more inner iterations than needed, making the whole algorithm inefficient. In practices, users often need to tune the number of inner iterations to improve algorithm's efficiency, which is an inconvenience common to most double-loop methods.

On the contrary, a _single-loop_ algorithm is usually easier to implement as it does not require tuning the number of inner iterations. Therefore, the **main contribution** of this paper is showing that a single-loop first-order algorithm can find a nearly \(\)-stationary point of (1) with oracle complexity \(O(1/^{4})\), which matches state-of-the-art results obtained only by the double-loop methods [13; 54; 39]. The algorithm we study is the classical _switching subgradient_ (SSG) method proposed by Polyak  in 1967, which is intuitive and easy to implement but has only been analyzed before in the convex case. We first show that the SSG method has complexity complexity \(O(1/^{4})\) when \(g\) is convex. Then, we show that the same complexity result holds when \(g\) is weakly convex and appropriate constraint qualification holds. We also present some practical examples where all of our assumptions hold, including a fair classification problem subject to the demographic parity constraint . Our **technical novelty** is inventing a _switching stepzize rule_ to accompany the switching subgradient. In particular, we use a fixed stepsize when the solution is updated by the objective's subgradient while use an adaptive Polyak's stepsize [33; 60] when the solution is updated by the constraint's subgradient. This allows us to leverage the local error bound of the constraint function to keep the solution nearly feasible during the algorithm, which prevents the solution from being trapped at an infeasible stationry point. To the best of our knowledge, this paper is the first to establish the complexity of a single-loop first-order method for weakly convex non-smooth nonlinear constrained optimization. In the appendix, we also extend our algorithms and complexity analysis to the stochastic setting.

## 2 Related work

Non-convex constrained optimization has a long history [36; 16; 29; 17; 30; 6; 18] and the interest on this subject has been still growing in the machine learning community because of its new applications such as learning with fairness constraints (see e.g., ).

In recent literature, the prevalent classes of algorithms for non-convex constrained optimization include the augmented Lagrangian method (ALM), the penalty method [37; 79; 80; 81; 38; 42; 55; 44; 45; 69; 43; 52; 63; 53; 50; 40; 51], and the sequential quadratic programming method [11; 34; 12; 22; 10; 9; 8; 21]. Besides, an inexact projected gradient method is developed by  and a level conditional gradient method is developed by . However, these works all focus on the case where \(g\) is smooth and \(f\) is either smooth or equals \(f_{1}+f_{2}\), where \(f_{1}\) is smooth and non-convex while \(f_{2}\) is non-smooth and convex and has a simple structure that allows a closed-form solution for the proximal mapping \(_{}\{f_{2}()+\|-\|^ {2}\}\) for any \(\). There are relatively fewer works on non-convex non-smooth constrained problems. An alternating direction method of multipliers (ADMM) and an ALM are studied by  and , respectively, for non-convex non-smooth problems with linear constraints while our study considers nonlinear non-smooth constraints. The methods by  and  can be extended to a structured non-smooth case where \(f=f_{1}+f_{2}\) with \(f_{1}\) being smooth non-convex and \(f_{2}=_{}\{^{}A-()\}\) with a convex \(\), and \(g\) has a similar structure. The method by  can handle a specific non-smooth non-convex constraint, i.e., \(g()=\|\|_{1}-h()\)where \(h\) is a convex and smooth. Compared to these works, our results apply to a more general non-smooth problem without those structure assumptions.

When \(f\) and \(g\) in (1) are weakly convex and non-smooth, the inexact proximal point method has been studied by  under different constraint qualifications and different notions of stationarity. Their complexity analysis utilizes the relationship between the gradient of the Moreau envelope of (1) and the near stationarity of a solution, which is originally used to analyze complexity of subgradient methods for weakly convex non-smooth unconstrained problems . Our analysis utilizes a similar framework. The methods  are double-loop while our algorithm only uses a single loop and achieves the same complexity of \(O(1/^{4})\) as them under similar assumptions.

The SSG algorithm is first proposed by Polyak . It has been well-studied for convex problems  and quasi-convex problems . This paper provides the first complexity analysis for the SSG method under weak convexity assumption. Non-smooth non-convex optimization has also been studied without weak convexity assumption by . These works analyze the complexity of first-order methods for computing an \((,)\)-Goldstein approximate stationary point, which is a more general stationarity notation than what we consider here. However, these works only focus on unconstrained problems.

## 3 Algorithm and near stationarity

Let \(\|\|\) be the \(_{2}\)-norm. For \(h:^{d}\{+\}\), the subdifferential of \(h\) at \(\) is

\[ h()=\{^{d}\,\,h( ^{}) h()+,^{ }-+o(\|^{}-\|),\;^ {}\},\]

and \( h()\) is a subgradient of \(h\) at \(\). We say \(h\) is \(\)_-strongly convex_ (\( 0\)) on \(\) if

\[h() h(^{})+,-^{}+\|-^{}\|^ {2}\]

for any \((,^{})\) and any \( h(^{})\). We say \(h\) is \(\)_-weakly convex_ (\( 0\)) on \(\) if

\[h() h(^{})+,-^{}-\|-^{}\| ^{2}\]

for any \((,^{})\) and any \( h(^{})\). We denote the normal cone of \(\) at \(\) by \(_{}()\) and the relative interior of \(\) by relint(\(\)). We say a point \(\) is \(\)-feasible if \(\) and \(g()\). Let \(_{}()\) be the zero-infinity characteristic function of set \(\), \(_{}()\) be the projection mapping to \(\), and \((,):=_{}\| -\|\) for set \(\).

We make the following assumptions on (1) throughout the paper.

**Assumption 3.1**.: Functions \(f\) and \(g\) are continuous with \( f()\) and \( g()\) on \(\), and there exists \(M\) such that \(\|_{f}\| M\) and \(\|_{g}\| M\) for any \(\), \(_{f} f()\) and \(_{g} g()\).

Since (1) is non-convex, finding an \(\)-optimal solution is intractable in general. For a non-convex problem, the target is typically to find a _stationary_ point of (1), which is a point \(^{*}\) that satisfies the following Karush-Kuhn-Tucker (KKT) conditions:

\[_{f}^{*}+^{*}_{g}^{*}-_{}(^{*}),^{*}g(^{*})=0, g( ^{*}) 0,^{*} 0,\]

where \(^{*}\) is a Lagrangian multiplier, \(_{f}^{*} f(^{*})\) and \(_{g}^{*} g(^{*})\). Typically, an exact stationary point can only be approached by an algorithm at full convergence, which may require infinitely many iterations. Within a finite number of iterations, an algorithm can only generate an \(\)_-stationary_ point , which is a point \(}\) satisfying

\[(}_{f}+}_{g},-_{}(}) ),|g(})| ^{2}, g(})^{2}, 0,\] (2)

where \(\) is a Lagrangian multiplier, \(}_{f} f(})\) and \(}_{g} g(})\). However, because \(f\) and \(g\) are non-smooth, computing an \(\)-stationary point is still challenging even for an unconstrained problem. Nevertheless, under the weak convexity assumption, it is possible to compute a _nearly \(\)-stationary point_, which we will introduce next.

Given \( 0\), \( 0\) and \(\), we define a quadratically regularized problem of (1) as \[()_{}f( )+}{2}\|-\|^{2},\;s.t.\;g()+}{2}\|-\|^{2} 0},\] (3) \[}()*{arg\,min}_{ }f()+}{2}\| -\|^{2},\;s.t.\;g()+}{2}\|- \|^{2} 0}.\] (4)

Following the literature on weakly convex optimization [24; 27; 23; 13; 54; 39], we use the value of \(\|}()-\|\) as a measure of the quality of a solution \(\) because it can be interpreted as a stationarity measure. For the purpose of illustration, we assume for now that \(}()\) is uniquely defined and there exists a Lagrangian multiplier \(\) such that the following KKT conditions of (4) holds.

\[_{f}+(}()- )+(_{g}+( {}()-))-_{}( }()),\] (5) \[(g(}())+ {}{2}\|}()-\|^{2})= 0, g(}())+}{2}\| {}()-\|^{2} 0, 0,\]

where \(_{f} f(}())\) and \(_{g} g(}())\). Therefore, as long as \(\|}()-\|\), we have

\[(_{f}+_ {g},-_{}(}()))( +),|g( }())|=^{2}/ 2, g(}()) 0.\] (6)

This means \(}()\) is an \(O()\)-stationary point of the original problem (1) in the sense of (2). Since \(\) is within an \(\)-distance from \(}()\), we call such an \(\) a _nearly \(\)-stationary point_ of (1). We formalize this definition as follows.

**Definition 3.2**.: Suppose \(}()\) is defined in (4) with \( 0\). A (stochastic) point \(\) is a (stochastic) nearly \(\)-stationary point of (1) if \([\|}()-\|]\).

Of course, we can claim \(}()\) is an \(O()\)-stationary point of (1) based on (6) only when \(\) in (5) exists and does not go to infinity as \(\) approaches zero. Fortunately, we can show in Lemmas 4.2 and 5.2 that this is true under some constraint qualifications, which justifies Definition 3.2.

We present the SSG method in Algorithm 1 for finding a nearly \(\)-stationary point of (1). At iteration \(t\), we check if the current solution \(^{(t)}\) is nearly feasible in the sense that \(g(^{(t)})_{t}\) for a pre-determined tolerance of infeasibility \(_{t}\). If yes, the algorithm performs a subgradient step along the subgradient of \(f\). Otherwise, the algorithm switches the updating direction to the subgradient of \(g\). The algorithm records the iteration indexes of the nearly feasible solutions in set \(I\) and other indexes in set \(J\). The final output is randomly sampled from the iterates in \(I\) or \(I J\) with a distribution weighted by the stepsizes \(_{t}\)'s. An index \(S\) is set so the algorithm only starts to record \(I\) and \(J\) when \(t S\). We study the theoretical _oracle complexity_ of Algorithm 1 for finding a nearly \(\)-stationary point, which is defined as the total number of times for which the algorithm queries the subgradient or function value of \(f\) or \(g\). Our results are presented separately when \(g\) is convex and when \(g\) is weakly convex.

## 4 Convex constraints

In this section, we first consider a relatively easy case where \(f\) is weakly convex but \(g\) is convex. In particular, we make the following assumptions in addition to Assumption 3.1 in this section.

**Assumption 4.1**.: The following statements hold:

1. \(f()\) is \(\)-weakly convex on \(\) and \(g()\) is convex on \(\).
2. (Slater's condition) There exists \(_{}()\) such that \(g(_{})<0\).
3. There exists \(D\) such that \(\|-^{}\| D\) for any \(\) and \(^{}\) in \(\).

In this section, we choose parameters in (3) such that

\[>=0.\] (7)

Under Assumption 4.1, (7) guarantees that (3) is strictly feasible, its objective function is \((-)\)-strongly convex and its constraint function is convex, so \(}()\) in (4) is unique and \(\) in (5) exists. We first present an upper bound of \(\) that is independent of \(\). The proof is in Section A.1.

**Lemma 4.2**.: _Suppose Assumptions 3.1 and 4.1 hold. Given any \(\), let \(}()\) be defined as in (4) with \((,)\) satisfying (7) and \(\) be the associated Lagrangian multiplier satisfying (5). We have_

\[:=(MD+D^{2})/(-g(_{})).\] (8)

For simplicity of notation, we denote \(}(^{(t)})\) defined in (4) by \(}^{(t)}\). Let \(_{r}[]\) be the expectation taken only over the random index \(\) when the algorithms stop. We present the convergence properties of Algorithm 1 when \(_{t}\) and \(_{t}\) are static and diminishing. The proof is provided in Section A.4.

**Theorem 4.3**.: _Suppose Assumptions 3.1 and 4.1 hold and \(\) is as in (8). Let \(}(^{(t)})\) be defined as in (4) with \((,)\) satisfying (7) and \(^{()}\) is generated by Output I. Algorithm 1 guarantees \(_{}[\|}^{()}-^{()}\|]\) and \(_{}[g(^{()})](- )}{1+}\) in either of the following cases._

_Case I:_ \(S=0\)_,_ \(_{t}=(-)}{1+}\)_,_ \(_{t}=(-)}{5(1+)M^{2}}\) _and_ \(TD^{2}(1+)^{2}}{4^{4}(-)^{2}}=O( 1/^{4})\)_._

_Case II:_ \(S=T/2\)_,_ \(_{t}=}\)_,_ \(_{t}=}\) _and_ \(TD^{2}(1+)^{2}}{^{4}(-)^{2}}=O( 1/^{4})\)_._

Algorithm 1 is single-loop with \(O(1)\) oracle complexity per iteration, so its total complexity is just \(T=O(1/^{4})\), which matches the start-of-the-art complexity by [13; 54; 39]. This result can be generalized to the case where there exist additional linear equality constraints \(=\). See the extension of Lemma 4.2 in Section A.1 and Remark A.2.

Assumption 4.1C can be relaxed to only require that the feasible set, i.e., \(=\{ g() 0\}\), is bounded instead of \(\). The same complexity can be achieved by Algorithm 1 by using a switching step size rule similar to \(_{t}\) in Proposition 5.5. This result is provided in Section A.8 but we recommend interested readers to read Section 5 first to get introduced to this special step size.

_Remark 4.4_.: Property \(_{}[g(^{()})](-)} {1+}\) in the theorems above is not required by Definition 3.2. By Assumption 3.1A, \(_{}[g(^{()})]_{}[g(}^{()})]+M_{}[\|}^{()}- ^{()}\|] M\), which means a nearly \(\)-stationary point must be \(O()\)-feasible by definition. Property \(_{}[g(^{()})](- )}{1+}\) implies \(O(^{2})\)-feasibility for the output, which is even better.

When \(g\) is \(\)-strongly convex with \(>0\), we can show that the complexity of Algorithm 1 is still \(O(1/^{4})\) but one can simply set \(_{t}=0\), which makes \(_{t}\) the only tuning parameter. This makes this single-loop method even more attractive. Due to space limit, we include this result in Section A.5. We also extend our result to the stochastic case in Section A.6 and A.7.

## 5 Weakly convex constraints

Next we consider the case where both \(f\) and \(g\) are weakly convex but not necessarily convex. Let

\[g_{+}()=\{g(),0\},=\{  g()=0\}=\{ g() 0\}.\]

We make the following assumptions in addition to Assumption 3.1 in this section.

**Assumption 5.1**.: The following statements hold:* \(f()\) and \(g()\) are \(\)-weakly convex on \(\).
* There exist \(>0\), \(>0\) and \(>\) such that, for any \(^{2}\)-feasible solution \(\), there exists \(()\) such that \(g()+}{2}\|-\|^{2}-\).
* \(:=_{}f()>-\).

Assumption 5.1B is called the uniform Slater's condition by . We will present two real-world examples in Section B.1 that satisfy this assumption, including a fair classification problem under demographic parity constraint, which is one of the applications in our numerical experiments in Section 6.2. In this section, we choose parameters in (3) such that

\[=>.\] (9)

Under Assumption 5.1, (9) guarantees that (3) is uniformly strictly feasible for any \(^{2}\)-feasible \(\), and the objective and constraint functions of (3) are both \((-)\)-strongly convex, so \(}()\) is uniquely defined and \(\) in (5) exists. In addition, Assumption 5.1 has the following three implications that play important roles in our complexity analysis.

First, \(\) in (5) can be bounded by a constant independent of \(\) and \(\) as long as \(\) is \(^{2}\)-feasible with \(\). This result is similar to Lemma 1 by Ma et al.  except that they require \(\) to be bounded but we do not. The proof is given in Section B.2.

**Lemma 5.2**.: _Suppose Assumptions 3.1 and 5.1 hold. Given any \(^{2}\)-feasible \(\) with any \(\), let \(}()\) defined as in (4) satisfying (9) and \(\) is the associated Lagrangian multiplier satisfying (5). We have_

\[\|}()-\| M/^{}:=2M/-)}.\] (10)

Second, the subgradient of the constraint function \(g()+_{}()\) on \(\) is uniformly away from the origin. The proof is provided in Section B.2.

**Lemma 5.3**.: _Suppose Assumptions 3.1 and 5.1 hold. It holds for any \(\) that_

\[_{_{g} g(),_{}()}\|_{g}+\|:= -)}.\] (11)

Lastly, note that \(\) is the optimal set of \(_{}g_{+}()\), which is a \(\)-weakly convex non-smooth optimization problem with an optimal value of zero. Lemma 5.3 implies that \(g_{+}()\) is sharp near the boundary of \(\), meaning that \(g_{+}()\) satisfies a linear error bound in an \(O(1)\)-neighborhood of \(\). A similar result for a convex \(g_{+}\) is given in Lemma 1 in . In the lemma below, we extend their result for a weakly convex \(g_{+}\). The proof is in Section B.2 and the second conclusion is directly from .

**Lemma 5.4**.: _Suppose Assumptions 3.1 and 5.1 hold. It holds for any \(\) satisfying \((,)\) that_

\[(/2)(,) g_{+}().\] (12)

_Moreover, \( 2M\) and \(_{}g_{+}()\) has no stationary point satisfying \(0<(,)<\)._

Since \(g\) is non-convex, Algorithm 1 may not even find a nearly feasible solution if \(^{(t)}\) is trapped at a stationary point of \(g\) with \(g()>0\), that is, a sub-optimal stationary point of \(_{}g_{+}()\). Fortunately, the second conclusion of Lemma 5.4 indicates that this situation can be avoided by keeping \((^{(t)},)=O(^{2})\) during the algorithm. To do so, we start with \(^{(0)}\) and use \(_{t}=O(^{2})\) in Algorithm 1. Moreover, we apply a switching stepsize rule that sets \(_{t}=O(^{2})\) when \(t I\) and \(_{t}=g(^{(t)})/\|_{g}^{(t)}\|^{2}\) when \(t J\), the latter of which is known by the Polyak's stepsize . This way, when \(g(^{(t)})_{t}\), (12) ensures \((^{(t)},)=O(^{2})\). When \(g(^{(t)})>_{t}\), (12) ensures \((^{(t)},)\) Q-linearly converges to zero , which also guarantees \((^{(t)},)=O(^{2})\). As a result, we have \(g(^{(t)})^{2}\) for any \(t\), so problem (3) with \(=^{(t)}\) and \((,)\) satisfying (9) will be strictly feasible according to Assumption 5.1B. This finding is given in the proposition below with its proof in Section B.3.

**Proposition 5.5**.: _Suppose Assumptions 3.1 and 5.1 hold and \(\). Also, suppose \(^{(t)}\) is generated by Algorithm 1 using \(^{(0)}\), \(_{t}=\{^{2}/M,/(4)\}\) and_

\[_{t}=\{}\{^{2}/M, /(4)\}&t I\\ g(^{(t)})/\|_{g}^{(t)}\|^{2}&t J..\]_Then \((^{(t)},)^{2}/M,/(4) }\) and \(g(^{(t)})^{2}\) for any \(t 0\). As a consequence, \(^{(t)}\) is \(^{2}\)-feasible to (3) where \(=^{(t)}\) and \((,)\) satisfies (9)._

Let \(}^{(t)}\) be \(}(^{(t)})\) defined in (4) with \((,)\) satisfying (9). The complexity result for the case of weakly convex constraints is as follows. The proof can be found in Section B.3.

**Theorem 5.6**.: _Under the same assumptions as Proposition 5.5, Algorithm 1 guarantees \(_{}[\|}^{()}-^{()}\|] C\) and \(_{}[g(^{()})]^{2}\), where \(C:=2}{-}}\), if we use Output II and set_

\[S=0T(f(^{(0)})-+3 M^{2}/(2))}{(1+^{})^{2} \{^{2}/M,/(4)\}}=O(1/^{4}).\]

This theorem indicates that Algorithm 1 finds a nearly \((C)\)-stationary point with complexity \(O(1/^{4})\). To obtain a nearly \(\)-stationary point with \(\), one only needs to replace \(\) in \(_{t}\), \(_{t}\) and \(T\) in this theorem above by \(/\{C,1\}\). This will only change the constant factor in the \(O(1/^{4})\) complexity. This complexity matches the start-of-the-art complexity by [13; 54; 39].

## 6 Numerical experiments

We demonstrate the performance of the SSG method on two fairness-aware classification problems, which are instances of (1) with convex and weakly convex \(g\)'s, respectively. We compare with two different double-loop inexact proximal point (IPP) methods [13; 54; 39]. The IPP method approximately solves a strongly convex constrained subproblem in each outer iteration, and we use the SSG method in this paper and the ConEx method in  as the solvers (inner loop) because they both have the best theoretical complexity for that subproblem. We use IPP-SSG and IPP-ConEx to denote these two implementations of the IPP method. All experiments are conducted using MATLAB 2022b on a computer with the CPU 3.20GHz x Intel Core i7-8700 and 16GB memory.

### Classification problem with ROC-based fairness

Given a feature vector \(^{d}\) and a class label \(b\{1,-1\}\), the goal in a binary linear classification problem is to learn a model \(^{d}\) to predict \(b\) based on the score \(^{}\). Let \(=\{(_{i},b_{i})\}_{i=1}^{n}\) be a training set and \(()\) be a convex non-increasing loss function. Model \(\) can be learned by solving

\[L^{*}=_{}L():=_ {i=1}^{n}(b_{i}^{}_{i})},\] (13)

where \(=\{^{d}\|\| r\}\). Solving (13) may ensure good classification performance of \(\) but not its fairness. Suppose there exist two additional datasets. One contains the feature vectors of a protected group, denoted by \(_{p}=\{_{i}^{p}\}_{i=1}^{n}\), and the other one contains the feature vectors of an unprotected group, denoted by \(_{u}=\{_{i}^{u}\}_{i=1}^{n}\). We want to enhance the fairness of \(\) between these two groups using the ROC-based fairness metric proposed by . Suppose we set a threshold \(\) and classify data \(\) as positive if \(^{}\) and as negative otherwise. The ROC-based fairness measure and its continuous approximation are defined as

\[_{}}_{i=1}^{n_{p}} (^{}_{i}^{p})-}_ {i=1}^{n_{u}}(^{}_{i}^{u})\] \[ R():= _{}}_{i=1}^{n_{p}} (^{}_{i}^{p}-)-}_{i=1}^{n_ {u}}(^{}_{i}^{u}-),\] (14)

where \((z)=(z)/(1+(z))\) is the sigmoid function and \(\) is a finite set of thresholds. If the value of this measure is small, model \(\) produces similar predicted positive rates for the protected and unprotected groups on various \(\)'s, indicating the fairness of the model. To obtain a fair \(\), we balance (13) and (14) by solving

\[_{}R()L() L^{*}+,\] (15)where \(\) is a slackness parameter indicating how much we are willing to increase the classification loss in order to reduce \(R()\) to obtain a more fair model. Problem (15) is an instance of (1) satisfying Assumptions 3.1 and 4.1 with \(=\) where \(\) is defined in (77) in Section B.1.

We solve (15) on three datasets: _a9a_, _bank_ and _COMPAS_. The information of these datasets is given in Table 1. We split each dataset into two subsets with a ratio of \(2:1\). The larger set is used as \(\) in the constraint and the smaller set is further split into \(_{p}\) and \(_{u}\) based on a binary group variable listed in Table 1.

In our experiments, we choose \((z)=(1-z)_{+}\) and first solve (13) using the subgradient method with a large enough number of iterations to obtain \(L^{*}\) and a solution \(_{}\). Then we set \(=0.001L^{*}\) and \(r=5\|_{}\|\), and let \(\) consist of \(400\) points equally spaced between \(_{i}_{}^{}_{i}-0.5(_{i}_{ }^{}_{i}-_{i}_{}^{} _{i})\) and \(_{i}_{}^{}_{i}+0.5(_{i}_{ }^{}_{i}-_{i}_{}^{} _{i})\).

All methods are initialized at \(_{}\). We implemented the SSG method with both static and diminishing stepsizes. For the static stepsize, we select \(_{t}\) from \(\{10^{-6},2 10^{-6},5 10^{-6},10^{-5}\}\) and \(_{t}\) from \(\{2 10^{-4},5 10^{-4},10^{-3},2 10^{-3}\}\). For the diminishing stepsize, we set \(_{t}=}{}\) and \(_{t}=}{}\) and select \(E_{1}\) from \(\{5 10^{-5},10^{-4},2 10^{-4},5 10^{-4}\}\) and \(E_{2}\) from \(\{0.02,0.05,0.1,0.2\}\). We

   Datasets & \(n\) & \(d\) & Label & Groups \\  a9a & 48,842 & 123 & Income & Gender \\ Bank & 41,188 & 54 & Subscription & Age \\ COMPAS & 6,172 & 16 & Recidivism & Race \\   

Table 1: Information of the datasets. Groups are males VS females in a9a, users with age within \(\) VS outside \(\) in bank, and caucasian VS non-caucasian in COMPAS.

Figure 1: Performances vs number of iterations on classification problems with ROC-based fairness.

select the best set of parameters that produces the smallest objective value after 5000 iterations. For IPP, we select \(\) from \(\{,1\}\{1,1.5,2\}\) for all three datasets, and the proximal point subproblem is approximately solved by SSG and ConEx both with \(100\) iterations. For IPP-SSG, we apply a static stepsize with \(_{t}\) and \(_{t}\) tuned in the same way as SSG. For IPP-ConEx, following the notation in , we set \(_{t}=\), \(_{t}=c_{1}(t+1)\) and \(_{t}=}{t+1}\), and select \(c_{1}\) from \(\{20,50,100,200\}\) and \(c_{2}\) from \(\{0.002,0.005,0.01,0.02\}\) by the same procedure adopted by SSG.

We report the performances versus number of iterations of all methods on each dataset in Figure 1. The performances versus the used CPU time will be given in Section C in the Appendix. For SSG, the \(x\)-axis represents the total number of iterations while, for IPP, it represents the total number of inner iterations across all outer iterations. The \(y\)-axis in each row represents the objective value, infeasibility and near stationarity achieved at each iteration, respectively. To measure near stationarity, we solve (3) with \(=^{(t)}\) and parameters (7) using the SSG method with \(2500\) iterations and use the last iterate as an approximation of \(}(^{(t)})\). We make sure that the change of \(\|}(^{(t)})-^{(t)}\|\) is less than 1% if the number of iterations is increased to \(5000\). Then we plot \(\|}(^{(t)})-^{(t)}\|\) as near stationarity in Figure 1. Since computing \(}(^{(t)})\) with a high precision for each \(t\) is time-consuming, we only report near stationarity at \(100\) equally spaced iterations.

According to Figure 1, the SSG method with a diminishing stepsize has the best performance on all three datasets in the sense that it reduces the objective value and the (approximate) near stationarity measure faster than others while keeping the solutions nearly feasible. However, the SSG method with a static stepsize is not always better than the IPP methods. This is consistent with our theoretical finding that the SSG and IPP methods have the same oracle complexity.

### Classification problem with demographic parity

Following the notation in the previous subsection, we consider a binary classification problem with a constraint enforcing demographic parity . The measure of demographic parity and its continuous approximation are

\[}_{i=1}^{n_{p}}(^{ }_{i}^{p} 0)-}_{i=1}^{n_{u}}( ^{}_{i}^{u} 0) R_{0}():= }_{i=1}^{n_{p}}(^{}_{i }^{p})-}_{i=1}^{n_{u}}(^{}_{i }^{u}).\] (16)

Fairness measure \(R_{0}()\) is a special case of \(R()\) with \(=\{0\}\). If \(R_{0}()\) is small, model \(\) produces similar predicted positive rates for the protected and unprotected groups. To obtain a fair \(\), we balance (13) and (16) by solving

\[ L()+()R_{0}() .\] (17)

Different from (15), the fairness measure is used as the constraint in (17) while the objective function becomes the empirical hinge loss plus the smoothly clipped absolute deviation (SCAD) regularizer  for promoting a sparse solution. Here, \(\) is a regularization parameter and

\[():=_{i=1}^{d}s(x_{i}), s(x_{i})= \{2|x_{i}|&0|x_{i}| 1\\ -x_{i}^{2}+4|x_{i}|+1&1<|x_{i}| 2\\ 3&2<|x_{i}|..\] (18)

We prove in Section B.1 that (17) is an instance of (1) satisfying Assumptions 3.1 and 5.1 with \(=\{2,\}\) where \(\) is defined in (77) in Section B.1.

We set \(=0.2\) for all datasets and set \(=0.005\), \(0.02\) and \(0.02\) for _a9a_, _bank_ and _COMPAS_, respectively. For SSG, we select \(_{t}\) from \(\{10^{-6},2 10^{-6},5 10^{-6},10^{-5}\}\) and select \(_{t}\) from \(\{10^{-4},2 10^{-4},5 10^{-4},7.5 10^{-4}\}\) for \(t I\) while set \(_{t}=g(^{(t)})/\|_{g}^{(t)}\|^{2}\) for \(t J\). We select the best set of parameters that produces the smallest objective value after \(50000\) iterations. For IPP, we select \(\) from \(\{,1\}\{1,1.5,2\}\) and the proximal point subproblem is approximately solved by SSG and ConEx both with \(600\) iterations. For IPP-SSG, we apply a static stepsize with \(_{t}\) and \(_{t}\) tuned in the same way as SSG. For IPP-ConEx, following the notation in , we set \(_{t}=\), \(_{t}=c_{1}(t+1)\) and \(_{t}=}{t+1}\) and select \(c_{1}\) from \(\{20,50,100,200\}\) and \(c_{2}\) from \(\{0.002,0.005,0.01,0.02\}\) by the same procedure adopted by SSG. Due to the limit of space, we present the performances vs number of iterations and CPU runtime of all methods in Figure 3 and Figure 4 respectively in Section C in the Appendix.

Conclusion

We study the oracle complexity of the switching subgradient (SSG) method for finding a nearly \(\)-stationary point of a non-smooth weakly convex constrained optimization problem. We show that the complexity of the SSG method matches the best result in literature that is achieved only by double-loop methods. On the contrary, the SSG method is single-loop and easier to implement with reduced tuning effort. This is the first complexity result for a single-loop first-order method for a weakly-convex non-smooth constrained problem.