# Graph Learning for Numeric Planning

Dillon Z. Chen\({}^{1,2}\) &Sylvie Thiebaux\({}^{1,2}\)

\({}^{1}\)LAAS-CNRS, University of Toulouse \({}^{2}\)The Australian National University

{dillon.chen,sylvie.thiebaux}@laas.fr

###### Abstract

Graph learning is naturally well suited for use in symbolic, object-centric planning due to its ability to exploit relational structures exhibited in planning domains and to take as input planning instances with arbitrary numbers of objects. Numeric planning is an extension of symbolic planning in which states may now also exhibit numeric variables. In this work, we propose data-efficient and interpretable machine learning models for learning to solve numeric planning tasks. This involves constructing a new graph kernel for graphs with both continuous and categorical attributes, as well as new optimisation methods for learning heuristic functions for numeric planning. Experiments show that our graph kernels are vastly more efficient and generalise better than graph neural networks for numeric planning, and also yield competitive coverage performance compared to domain-independent numeric planners. Code is available at https://github.com/DillonZChen/goose

## 1 Introduction

Planning requires long range reasoning over combinatorially large state spaces. Numeric planning is an extension of classical planning in which states have numeric variables and the underlying transition system is built from inequality conditions and assignments over arithmetic expressions of such variables. It was formalised in PDDL 2.1  and is undecidable in the general case  which makes it more difficult than classical planning which is PSPACE-complete . Numeric planning is a well-established problem in the symbolic AI community and exhibits significant research effort , but this expressivity result implies that building a general, scalable numeric planner is a challenging problem.

Learning for Planning (L4P) is a research direction which focuses on learning to solve problems from a specified domain in an automated supervised manner . Planning tasks in L4P are assumed to exhibit a factored, symbolic representation, which allow us to generate training data in a matter of seconds from easy to solve tasks with a domain-independent planner. We can then learn domain knowledge in a supervised manner that scales planners to significantly larger planning tasks.

This is in contrast to Reinforcement Learning where agents do not require access to well-defined models but spend significant amounts of time exploring and learning from rewards . Regardless, several works have showed that encoding or learning symbolic models for sequential decision making reasoning and embodied AI tasks  provided better performance and transparency over end-to-end reinforcement learning methods. Furthermore, it was shown recently that classical ML methods are much better suited for L4P than deep learning methods for symbolic planning  as they (1) can generalise well from small training data, (2) are orders of magnitude more efficient to train and evaluate than deep learning methods, which is important in time sensitive tasks such as planning, and (3) have interpretable features to understand what is being learned.

In this paper we study whether this fact carries over to Learning for Numeric Planning (L4NP)  which now requires reasoning over logic and arithmetic. It is reasonable to think that because neural networks are function approximators, they may offer better reasoning capabilities over numbers thanjust symbols alone. In this paper, we describe the GOOSE1 framework with classical ML and deep learning configurations for learning heuristic or value functions for use with search in L4NP. Fig. 1 illustrates the GOOSE framework and we outline our contributions as follows.

* We introduce a new graph representation of numeric planning tasks for use with classical and deep graph learning methods, namely graph kernels and graph neural networks, respectively.
* We extend the WL kernel [SSVL\({}^{+}\)11] to handle graphs with both continuous and categorical attributes in a meaningful way which we call the ccWL kernel.
* We introduce new ranking formulations  for learning heuristic or value functions with linear programs.

The structure of the remainder of the paper is as follows. In Sec. 2, we provide the necessary formalism and background for numeric planning, as well as relevant notation. In Sec. 3, we introduce a new graph encoding \(\)LIG and ccWL kernel for generating features for numeric planning tasks. In Sec. 4, we introduce a deep learning architecture for L4NP using graph neural networks. In Sec. 5, we describe optimisation methods for L4NP, involving a new ranking formulation for learning heuristic functions. In Sec. 6, we describe our experimental setup and results. Related work is discussed in Sec. B in the appendix. We conclude the paper with final comments in Sec. 8.

## 2 Background

**Numeric Planning Task.** A numeric planning task can be viewed as a compact representation of a deterministic, goal-conditioned Markov Decision Process with the use of predicate logic and relational numeric variables. A majority of the remainder of this section formalises the necessary components of a numeric planning task we use in the paper.

A numeric planning task  is given by a tuple \(= X_{p},X_{n},A,s_{0},G\) where \(X_{p}\) is a finite set of propositional variables with domain \(\{,\}\) and \(X_{n}\) is a finite set of numeric variables with domain \(\). Let \(X=X_{p} X_{n}\) denote the set of state variables, where a state is a total assignment of values the propositional and numeric variables. The variables implicitly induce a possibly infinite set of states \(S\), where \(s_{0}\) is the initial state.

A propositional condition is a positive (resp. negative) literal \(x=\) (resp. \(\)) for some propositional variable \(x X_{p}\), and a numeric condition has the form \( 0\) where \(\) is an arithmetic expression over numeric variables and \(\{,>,=\}\). We write \([x]^{s}\) (resp. \([]^{s}\)) for the value of a state variable \(x\) (resp. expression \(\)) in state \(s\), and \(V()\) for the set of numeric state variables in \(\). A state \(s\) satisfies a set of conditions (i.e. a set of propositional and numeric conditions) if each condition in the set evaluates to true given the values of the state variables in \(s\). The goal \(G\) is a set of conditions and we write \(G_{p}\) (resp. \(G_{n}\)) for the subset of propositional (resp. numeric) goal conditions.

Figure 1: The GOOSE framework for learning heuristic functions for numeric planning. Cyan colours indicate components that are influenced by the training phase. (a) A numeric planning state and goal condition is encoded into a graph \(\) via the \(\)ILG representation defined in Defn. 3.1. (b) Graphs are either embedded into vectors \(\) in Euclidean space with the ccWL kernel from Sec. 3 or transformed into a graph \(^{}\) with a real-valued matrix representing node features as inputs into GNNs described in Sec. 4. (c) Features \(\) are fed into a linear model, whereas transformed graphs \(^{}\) are fed into GNNs. (d) Linear models are either trained by the ranking formulation in Eq. 1 or by Support Vector Regression (SVR) with a linear kernel. GNN models are either trained by the ranking formulation in Eq. 2 or by backpropagation minimising the mean squared error (MSE) loss.

The set \(A\) contains a finite number of actions, each consisting of preconditions and effects. Action preconditions \((a)\) are sets of conditions, and action effects assign Boolean values to propositional variables and assign the value of an arithmetic expression to numeric variables. An action \(a\) is applicable in a state \(s\) if \(s\) satisfies \((a)\), in which case its successor \(a(s)\) is the state where the effects \((a)\) are applied to the state variables in \(s\). If \(a\) is not applicable in \(s\), we set \(a(s)=s_{} S\). Each action \(a\) has a cost \(c(a)\) given by an arithmetic expression.

A plan for a numeric planning task is a sequence of actions \(=a_{1},,a_{n}\) such that \(s_{i}=a_{i}(s_{i-1}) s_{}\) for all \(1 i n\) and \(s_{n}\) satisfies \(G\); we call \(s_{0},s_{1},,s_{n}\) the plan trace of the plan. The plan length \(||\) and the plan cost are the number of actions in the plan, and the sum of their cost, respectively. A plan is optimal if it has the minimum cost among all plans. A numeric planning task is solvable if there exists a plan for it, and is unsolvable otherwise. A state \(s\) is a deadend if the task with the initial state replaced with \(s\) is unsolvable. Satisficing planning refers to the problem of finding a plan if it exists, or proving that the problem is unsolvable. Optimal planning refers to the problem of finding an optimal plan if it exists, or proving that the problem is unsolvable.

**Lifted representation.** Numeric planning tasks can be compactly encoded in a lifted representation \(,_{p},_{f},_{a},,s_{0},G\) whereby state variables are derived from a set of predicates, functions, and objects. Formally \(_{p}\) and \(_{f}\) are sets of predicate and function symbols, respectively. Each symbol \(_{p}_{f}\), has an arity \(n_{}\{0\}\) which depends on \(\). Predicates and functions take the form \(p(x_{1},,x_{n_{p}})\) and \(f(x_{1},,x_{n_{f}})\), respectively, where the \(x_{i}\)s are their arguments. Given the set \(\) of objects, the propositional and numeric variables are obtained by substituting objects for the arguments of the predicates and functions, resulting in the grounded form \(p(o_{1},,o_{n_{p}})\) and \(f(o_{1},,o_{n_{f}})\), respectively, where the \(o_{i}\)s are objects. Similarly, actions can be represented in a lifted form via a set \(_{a}\) of action symbols and a set \(\) of action schemata mapping action symbols to their lifted precondition and effect definitions in terms of predicates and functions. Grounding the set of action schemata results in the set of actions \(A\) of the planning task. Details are not needed to understand this paper. A domain is a set of numeric planning tasks sharing the same set of \(_{p}\), \(_{f}\), \(_{a}\), and \(\), and may have constant objects, objects which are shared across all tasks in the domain.

**Example: Capacity Constrained Blocksworld.** To help digest some of the definitions of numeric planning, we provide an example with a planning domain we call _Capacity Constrained Blocksworld_ (ccBlocksworld). It is an extension of the original Blocksworld domain in which state consists of towers of blocks and the objective is to stack and unstack blocks to achieve a goal configuration. It is also a special case of the Hydraulic Blocksworld domain for planning with state constraints, in which blocks are placed on top of pistons which rise or fall depending on the configurations of other pistons .

In ccBlocksworld, we have a maximum number of tower locations, and each tower has a base limited by the number of blocks it can hold. To model this domain in the lifted representation, we retain the predicate \((x,y)\) from the original Blocksworld, which indicates block \(x\) is on another block or base \(y\). Next, we also introduce the function \((z)\) which denotes the remaining number of blocks that are allowed to be placed on base \(z\). The numeric variables instantiated from \(\) may increase or decrease depending on whether blocks are unstacked from the tower or stacked on top of it. Action schemata preconditions constrain whether a block can be placed on a tower with base that has reached its capacity limit or not. The leftmost figure in Fig. 2 illustrates an example of a ccBlocksworld problem with an initial state and goal condition. We refer to the Sec. A of the appendix for the complete state representation of the problem as well as its PDDL encoding.

**Heuristics and Greedy Best First Search.** State-of-the-art methods for both satisficing and optimal numeric planning  employ some variant of heuristic search. A heuristic function maps a state \(s\) to \(\{\}\) representing an estimate of the cost to reach the goal from the current state, where a value of \(\) estimates that \(s\) is a deadend. The optimal heuristic \(h^{*}\) maps a state to the cost of an optimal plan if it exists, and \(\) otherwise. The Greedy Best First Search (GBFS) algorithm consists of a priority queue initialised with the initial state as the only element, and a main loop which performs the following steps while the queue is non-empty: (1) pop a state \(s\) with the lowest heuristic value and some tie-breaking criterion from the queue, (2) generate the successors of \(s\) via all applicable actions, and (3) check if a successor \(s^{}\) is a goal, in which case terminate with the plan traced back from \(s^{}\), and otherwise add \(s^{}\) to the queue if it has not been seen before. The algorithm determines a problem is unsolvable if the main loop completes, in which case the problem has finitely many states of which all have been seen.

Graph and other notations.Let \(=,,_{},_{},\) denote a graph with nodes \(\), undirected edges \(}{2}\), categorical node features \(_{}:_{}\) where \(_{}\) is a finite set, continuous node features \(_{}:^{d}\) with \(d\), and edge labels (categorical edge features) \(:_{}\) where \(_{}\) is a finite set. The neighbourhood of a node \(u\) in a graph with respect to an edge label \(\) is defined by \(_{}(u)=\{v e,e= u,v= v,u(e)=\}.\) We use \(\|\) to denote the concatenation operator for vectors, and \( N\) to denote \(\{1,,N\}\).

## 3 Relational features for numeric planning

In this section, we describe an automatic method for generating embeddings for numeric planning tasks that may be used for any downstream inference model. The method is an extension of the feature generation method for classical planning  and consists of two main steps: (1) generating a graph representation of a planning task, and (2) running a variant of the WL-algorithm for generating features for the graph . Extending the first step of the method is simple as it is easy to extend the graph encoding to capture numeric information of the task. This is done in Sec. 3.1 where we introduce the Numeric Instance Learning Graph (\(\)ILG) representation for numeric planning tasks. The second step is more difficult as we require constructing a WL-algorithm variant that can handle both categorical and continuous nodes features in a meaningful way for numeric planning. This is where we introduce the ccWL algorithm in Sec. 3.2 that handle such node features. Thus, we can generate features for numeric planning tasks by first converting them into the \(\)ILG representation, and then running the ccWL algorithm on them.

### Graph encoding of numeric planning tasks

We begin by describing our graph encoding of a planning task, namely the Numeric Instance Learning Graph (\(\)ILG). Similarly to the classical case, the graph representation does not encode the transition model of the planning task nor requires grounding all possible variables in the planning task. Thus, our encoding only requires a first-order representation of states, and therefore applies to problems whose transition model is unknown such as in model-free reinforcement learning.

We begin with a descriptive definition of the graph with an example Fig. 2 illustrating a subgraph of the \(\)ILG representation of the example ccBlocksworld problem. In the figure, the nodes in the graph represent the objects (light blue), propositional variables true in the state (green), numeric variables (red), propositional goals (yellow) and numeric goals (not present in the example) of the problem. Blue (resp. orange) edges connect object nodes to goal and variable nodes where the object is instantiated in the first (resp. second) argument of the corresponding node variable or condition.

We provide the formal definition below. Let \(X_{p}(s)\) denote the set of propositional variables that are true in \(s\), \(X_{n}(s)\) the set of numeric variables, and \(X(s)=X_{p}(s) X_{n}(s)\).

**Definition 3.1** (Numeric Instance Learning Graph).: The _Numeric Instance Learning Graph_ (\(\)ILG) of a numeric planning task in the lifted representation \(=,_{p},_{f},_{a},,s_{0},G\) is a graph \(=,,_{},_{ },\) with

* nodes \(= X(s_{0}) G\), where we assume w.l.o.g. that \(V(g) X(s_{0})\) for all \(g G_{n}\),
* edges \(=_{p=(o_{1},,o_{n_{g}}) X(s_{0}) G_{p}} \{ p,o_{i} i n_{}\}_{  0 G_{n}}\{,v v V(g)\}\),
* categorical node features \(_{}:_{}\) with \(_{}(u)=\) \[(u)&u\\ (u)&u X_{n}(s_{0})\\ ((u),(u))&u G_{n}((u),)&u X_{p}(s_{0}) G_{p}\\ ((u),)&u G_{p} X_{p}(s_{0})\\ ((u),)&u X_{p}(s_{0}) G_{p}\] where \((u)=u\) if \(u\) is a constant object and \(\) otherwise, \((u)/(u)\) returns the predicate/function symbol from which a proposition/fluent was instantiated from, \((u)\{,>,=\}\) encodes the comparator type of the numeric goal condition \(u\), and \((u)\{\}\) encodes whether \(s_{0}\) satisfies \(u\),
* continuous node features \(_{}:\) where \(_{}(u)=[u]^{s_{0}}\) for nodes \(u X_{n}(s_{0})\), \(_{}(u)=[]^{s_{0}}\) for nodes \(u= 0 G_{n}\) with \([]^{s_{0}} 0\), and \(_{}(u)=0\) otherwise, and
* edge labels \(:_{}\) where for edges of the form \(e= p,o_{i}\), we have \((e)=i\), and otherwise for edges \(e=,v\), we have \((e)=0\).

In general, given a domain with predicate and function symbols \(_{p}\) and \(_{n}\), we have that there are \(|_{}|=5+3\,|_{p}|+|_{n}|+||\) categorical node features representing the semantics of a node. Continuous node features indicate the value of numeric variables and the error of the expression in \(s_{0}\) of unachieved numeric goals, and are set to zero for any other node.

### The ccWL algorithm for numeric planning

The WL algorithm  has been adapted to computing features for graphs with categorical node attributes by . A variant of the WL algorithm for graphs with continuous node attributes has been proposed by  for the purpose of computing kernels with the Wasserstein distance between graph embeddings. However, the graph embeddings themselves are not invariant to the order of graphs in the nodes. Furthermore, from , non-linear kernels result in poorer generalisation compared to linear models in the context of L4P due to overfitting to the range of training targets. Morris et al.  constructed kernels for continuous node attributes by hashing Euclidean embeddings into categorical features but such a method loses the semantic meaning of numbers. Thus, we propose a new variant of the WL algorithm for graphs with both categorical and continuous node attributes for generating graph embeddings (ccWL algorithm). This algorithm is summarised in Alg. 1 and also depicted in Fig. 3.

``` Data: A graph \(=,,_{},_{ },\) with continuous and categorical attributes, a deterministic and injective hash function, allowed colours \(=\), a pooling function pool, and number of ccWL iterations \(L\). Result: Feature vector of size \(^{(1+d)||}\).
1\(^{0}(v)_{}(v), v\) for\(j L\)dofor\(v\)do
2\(^{j}(v)(^{j-1}(v),_{i _{p}}\{(^{j-1}(u),) u_{}(v)\})\) \(_{j\{0\} L} ^{j}(v) v\) \(_{}[(,c_{1}),, (,c_{||})]\) \(_{i}=\{v v j\{0\} L,^{j}(v)=c_{i}\},  i\) \(_{}[(1)\,\|\|\,(| |)],\ (i)=_{v_{i}}(_{}(v))\) return\(_{}\,\|\,_{}\) ```

**Algorithm 1**ccWL algorithm

Lines 1-3 of Alg. 1 are the original steps of the WL algorithm for generating graph embeddings by iteratively refining categorical node features, which we call colours, with two differences. Firstly, we replaced the multi-set with a set in the input of the hashing function. This is because in planning, unseen colours arise from graphs with increasing degrees which occur for out-of-distribution testing problems of increasing size. This problem is limited by relaxing the hash input with a set, which trades expressivity for generalisation. Secondly, we make use of edge labels in the hashing function.

Lines 4-5 collect the counts of allowed colours \(\) seen during the main loop of the algorithm to generate the categorical feature vector in the form of a histogram. We assume by relabelling colours that \(=\). Lines 6-7 generate features from pooling the continuous attributes from different

Figure 2: An example ccBlocksworld task where each base has capacity 3 (left), a subgraph of its ILG representation (middle), and the matrix representation of the node features of the ILG (right).

groups of nodes. More specifically, for each colour \(c\), we find the set of nodes which have been assigned the colour \(c\) some time during the refinement process and pool the continuous attributes of these nodes. Thus, we have \(||\) pooled continuous feature vectors which we concatenate together. We note that this pooling and concatenation process is invariant to the order of nodes in a graph in contrast to the intermediate graph embeddings generated for Wasserstein WL graph kernels by Togninalli et al. . The algorithm returns the concatenation of the categorical and continuous feature vectors as the final feature vector output for the graph in Line 8. We note that \(d=1\) when running ccWL on the \(\)ILG representation of a numeric planning task.

We note that a drawback of the algorithm is that continuous attributes are not refined directly. This could be done by introducing one or more aggregation functions as parameters to the algorithm and refining continuous attributes by concatenating the aggregations of their neighbouring attributes. However, this method introduces an increase in the size of the continuous feature vector exponential in the number of layers, with base equal to the number of aggregation functions chosen. Moreover, we noted from informal experiments that this method led to overfitting of models to a large number of blended continuous features that do not have an obvious relation to the learning target.

Assuming a constant time hashing function, the complexity of the ccWL algorithm is \(O(nL(+d))\) where \(n=|V|\) of the input graph, \(=_{u}_{i}|_{i}(u)|\) is the degree of the graph, \(d\) is the dimension of the continuous node attributes, and \(L\) is the number of layers. The main computation comes from Line 3 which is performed \(nL\) times and the hashing function takes an input of size \(\). Collecting the categorical feature vector takes the same time, while collecting the continuous feature vector takes \(O(nLd)\) time. For reasonably sized \(d\), as in the case of \(\)ILG where \(d=1\), this is the same complexity as the original WL algorithm for generating graph features, which is \(O(nL)\).

## 4 Relational neural networks for numeric planning

Deep learning architectures such as graph neural networks (GNNs)  benefit in generating latent representations automatically with backpropagation when trained end-to-end . GNNs also benefit from being able to train and evaluate on arbitrary sized graphs. However, it is generally understood that the expressive power of GNNs is limited by the WL-algorithm and counting logics with two variables . This result translates to the impossibility result of GNNs not being able to learn features that can work well for arbitrary planning domains . Nevertheless, their application to numeric planning tasks, in which both logical and numeric reasoning is required, is less well understood. Thus, we still propose GNNs as an additional baseline for L4NP and empirically evaluate their performance for numeric planning in Sec. 6.

For our GNN architecture, we perform a transformation on the node features of the \(\)ILG from 3.1 as input for GNNs that can handle edge labels. More specifically, given a \(\)ILG \(=,,_{}: _{},_{}, \), we construct a new graph \(^{}\) with continuous node attributes \(:^{|_{}|+2}\) defined by \((u)=(_{}(u))\|[r_{1},r_{2}]\), where \((_{}(u))\{0,1\}^{|_{}|} ^{|_{}|}\) denotes a one-hot encoding of the categorical node feature of \(u\), and \(r_{1}\) denotes the numerical value of numeric variable nodes defined by \(r_{1}=[u]^{s_{0}}\) if \(u X_{n}(s_{0})\) and \(r_{1}=0\) otherwise, and \(r_{2}\) denotes the goal error for numeric goal nodes defined by \(r_{2}=[u]^{s_{0}}\) if \(u G_{n}\) and \(r_{2}=0\) otherwise. We denote the \(\)ILG for GNNs by \(,,,\) with notation for categorical features removed. Thus, we can use this graph encoding of numeric planning tasks as input into any downstream GNN that can handle edge labels or features.

Fig. 2 illustrates the node feature matrix representation of the \(\)ILG encoding of a ccBlocksworld task for input to a GNN. Each row represents a node in the graph, with columns representing the semantics of the node as well as the value of the numeric variables in the state and error of numeric goal nodes. We note however, that the ccBlocksworld example does not have any numeric goals and thus the last column is zero for all entries.

## 5 Optimisation formulations for learning heuristic functions

In this section, we describe two optimisation methods used for learning heuristic functions from training data, namely by minimising cost-to-go estimate error and ranking estimate error. Fig. 4 illustrates examples of learned heuristic functions on states of a planning task when trained to zero loss with both the cost-to-go and ranking formulations. We assume that training data for our models consist of a set of numeric planning tasks \(_{1},,_{n}\) with corresponding optimal plans \(_{1},,_{n}\)We note that a numeric planning task can offer more training data by generating additional tasks and plans from different states in the state space of the task. Each plan is denoted \(_{i}=a_{1}^{(i)},,a_{|_{i}|}^{(i)}\) with plan trace \(s_{0}^{(i)},s_{1}^{(i)},,s_{|_{i}|}^{(i)}\). Each state \(s\) in a plan trace induces a new planning task by replacing \(s_{0}\) with \(s\) of the original task, with which we can construct graph or vector representations from our aforementioned models.

**Heuristic functions from cost-to-go estimates.** We can use planning tasks and corresponding optimal plans as training data for learning a heuristic function representing the estimated cost-to-go to the plan. Each task and corresponding plan \(_{i}\) contributes training data \(s_{j}^{(i)}\) with targets \(h^{*}(s_{j}^{(i)})\) for each state \(s_{j}^{(i)}\) in the plan trace of \(_{i}\). Then given an estimator \(\), we may try to find weights that minimise the mean squared error (MSE) \(L()=_{i=1}^{n}_{j=0}^{|_{i}|}h^{*}(s_{j}^{ (i)})-_{}(s_{j}^{(i)})^{2}\) where \(N\) is the normalisation constant and \(_{}\) denotes the estimator with weights \(\).

**Heuristic functions from ranking estimates.** The MSE loss is a simple but naive method for training a heuristic function. Various researchers have instead proposed to use the concept of ranking to learn heuristic functions . However, a drawback of the formulation of the ranking optimisation of previous works is that a state in a plan trace is marked as strictly better as its siblings when it could be the case that the siblings may have the same \(h^{*}\) value. Furthermore, the formulation in  scales quadratically in the plan trace. We offer a novel ranking optimisation criterion that (1) fixes the problem of siblings being misclassified and (2) also results in a sparse model.

We also offer a corresponding differentiable loss function for use with any end-to-end model.

Our first ranking formulation requires solving an LP as the optimisation problem, similarly to  but only using states from the plan trace, whereas the latter work uses states from the entire state space of the problem. It can also be viewed as an LP encoding of the formulation by Garrett et al.  but fixing the problem of misrepresented siblings and learning sparse weights. Let \((s)\) denote the set of successors of the state \(s\) in a planning task by applying all applicable actions at \(s\). Hence the set of siblings of state \(s_{j}^{(i)}\) in \(_{i}\)'s state space is \((s_{j}^{(i)})=(s_{j-1}^{(i)})\{s_{j}^ {(i)}\}\). Let \(\) denote our feature generation function with \((s)^{d}\) for any state \(s\). Then we can define our optimisation problem as a linear program defined by

\[_{,}_{i,j,k}_{i,j,k}+\| \|_{1}_{i,j,k} 0,  i,j,k\] (1) \[^{}((s_{j-1}^{(i)})-(s_{j}^{(i)})) (a_{j}^{(i)})-_{i,j,0}  i n,j|_{i}|\] \[^{}((s_{})-(s_{j}^{(i)})) -_{i,j,} i n ,j|_{i}|,s_{}(s_ {j}^{(i)}).\]

The vector \(\) represents the weights our linear model aims to learn, and the nonnegative slack variables \(\) model the soft inequality constraints representing the ranking of states. The optimisation problem is to minimise the the slack variables corresponding to the error of the constraints, and the \(_{1}\) norm of the weights to encourage sparsity.

We next offer a differentiable loss function version of the previous model which we can use as a fair comparison when combining it with our GNN architecture in Sec. 4 compared to combining (1) with features generated in Sec. 3. The idea is to replace the slack variables with the \(\) function:

\[L()=_{i,j}0,_{}(s_{j}^{(i)})- _{}(s_{j-1}^{(i)})+c(a_{j}^{(i)})+-14.226378pt _{s_{}(s_{j}^{(i)})}0,_{ }(s_{j}^{(i)})-_{}(s_{}).\] (2)

Figure 4: Examples of heuristic functions that achieve \(0\) loss when optimising cost-to-go (left) and ranking (right) on an optimal plan. Coloured nodes indicate states on the optimal plan with the goal state indicated by a double circle. Edges indicate successors of a node. A cost-to-go heuristic can achieve 0 loss on the plan trace but may not generalise correctly to state successors. A ranking heuristic does not need represent correct cost-to-go values and only need to satisfy ranking constraints. GBFS will return a plan in linear time for the ranking heuristic here but not for the cost-to-go heuristic.

## 6 Experiments

### Numeric planning benchmarks

We take 8 domains out of 10 domains from the International Planning Competition 2023 Learning Track (IPC-LT)  and either convert them to equivalent numeric formulations, or introduce numeric variables to model extra features such as capacity constraints. The two domains from the IPC-LT that we do not convert into numeric domains are Floortile and Sokoban which do not have any benefit from compilation to a numeric representation nor exhibit any interesting features that can be modelled with numeric variables. The domains we considered from the IPC-LT are summarised in Fig. 5 alongside the sizes of training and testing tasks, and time to generate training data. Each domain consists of 90 testing problems and at most 99 small training problems for which the median time for generating an optimal training plan is less than a second and a few outliers taking more than a minute. We refer to the appendix for further details on the domains.

### Experimental setup

**Training.** As discussed in Sec. 5, we only consider optimal plans from small problems as training data. We compute them with the Numeric Fast Downward planner  using A\({}^{*}\) search and the admissible \(h^{}\) heuristic , with a 30 minute timeout and 8GB main memory.

We consider 4 model configurations. Firstly, we use ccWL features from Sec. 3 with Support Vector Regression and the linear dot product kernel to learn a linear model for cost-to-go estimation (\(h^{}_{}\)). Next, we use ccWL features in optimisation problem in (1) with CPLEX version 22.11 and a timeout of 600 seconds for ranking estimation (\(h^{}_{}\)). Both \(h^{}_{}\) and \(h^{}_{}\) models have allowed colours \(\) in Alg. 1 given by all the refined colours seen during training. We also have cost-to-go (\(h^{}_{}\)) and ranking (\(h^{}_{}\)) estimation models using GNNs operating on \(\)ILG representations of planning tasks and optimised with the MSE loss function and (2), respectively. For the backbone GNN, we use a Relational Graph Convolution Network  but replacing the mean aggregation function with the element-wise max operator in the message-passing update step: \(^{(l+1)}_{u}=(_{0}^{(l)}_{u}+_{i _{}}_{v_{i}(u)}^{(l)}_{i}^{ (l)}_{v}),\) where \(l\) denotes the GNN layer, \(\) is implemented with the leaky ReLU function, and \(_{0}\) and \(^{(l)}_{i}\) are learnable weight matrices. Each GNN has a hidden dimension of 64, and is trained with the Adam optimiser  with an initial learning rate of \(10^{-3}\) and batch size of 16. A scheduler reduces the training loss by a factor of 10 if loss does not improve after 10 epochs. Training then terminates if the learning rate falls below \(10^{-5}\). Let \(L\) denote the iterations hyperparameter for ccWL models and number of layers for GNN models.

**Evaluation.** We consider several numeric planners as baselines for benchmarking the effectiveness of learning. We first include \(h^{}\) as the only optimal planner baseline as it is also the training data generator but solves a more difficult problem of optimal planning compared to satisficing planning. We consider the Metric-FF planner (m-FF) , and the \(h^{}}\), \(h^{}}\), \(h^{}}+\) and \((3h\|3n)\) configurations in the ENHSP planner . We have that \(h^{}}\) and \(h^{}}\) are planners that perform GBFS with a single heuristic only, while \(h^{}}+\) and M\((3h\|3n)\) use additional techniques (macro actions, multiple queues, and novelty heuristics) to boost planning performance. Our ccWL and GNN models are all used in single-queue GBFS with the learned heuristic function, with Numeric Fast Downward as the backend search implementation. All baselines and models are run on a single Intel Xeon Platinum 8268 (2.90 GHz) core with a 5 minute timeout for search and

Figure 5: Number of objects in training and testing problems (left) and distributions of training data generation time with number of training problems (right) per domain. Note the log scales.

8GB of main memory. Tab. 1 summarises the coverage results of all considered planners on the benchmarks, with more details provided in the appendix.

**How do learning approaches compare to domain-independent numeric planners?** From Tab. 1, we note that our best performing model with \(L=1\) is \(h_{}^{}\) and outperforms all domain-independent planners for satisficing planning on 4 out of 8 domains. Increasing \(L\) to 2 brings \(h_{}^{}\) to achieve the best coverage on Blocksworld. The domains which learners fall behind on are Rovers, Satellite and Transport, even when taking the best hyperparameter configuration. The former two are difficult as they require features more expressive than those generated by graph learning approaches to capture the semantics of reasoning required to solve the problems , while the latter requires path finding which is not possible for learners with finite receptive fields . These results hold for classical planning and thus also for our extension to numeric planning. Generally the best performing planner on a domain expands fewer nodes than the other planners. With regards to plan length, \(h_{}^{}\) performs best for Blocksworld but is marginally worse than the best of the domain-independent numeric planners for Rovers, Satellite and Spanner.

**How do ccWL models compare to GNN models?** From Tab. 1, we see that the ccWL models always have similar or better performance than the corresponding GNN models, when comparing cost-to-go and ranking estimates. The performance of a planners which use GBFS and a heuristic depend on the heuristic evaluation speed, in which more search can be done in the time limit, or the quality of the heuristic, in which search can be more informed. Fig. 8 in the appendix shows that GNN are generally at least an order of magnitude slower than ccWL models for heuristic evaluation due to performing intensive matrix operations. We note that GNN models are evaluated on CPUs and could be sped up with access GPUs. Fig. 5(a) illustrates the number of node expansions of GNN and ccWL models and we note that there is no clear winner between the two approaches across all domains, with the exception of \(h_{}^{}\) generalising perfectly on Childsnack where other models could not. Thus, we can conclude with respect to planning efficiency that ccWL models generally outperform their GNN counterparts due to faster heuristic evaluation speeds, while generally both models have similar generalisation performance.

**How do ranking models compare to cost-to-go models?** From Tab. 1, ranking models outperform cost-to-go models in total coverage. However, their performance is incomparable across domains even when looking at Fig. 5(b) with the exception of ccWL being able to achieve perfect performance on Childsnack. Nevertheless, on 8 domain-model pairs for \(L=1\), ranking models achieve strictly better coverage, while the converse is only true for 4 domain-model pairs. This suggests a bias favouring ranking models which can be explained by their advantages covered in Sec. 5, namely that

they implicitly use more training data by considering successor states of plan trace states, and have a larger solution space as they are not restricted to predicting an exact value.

**What is the effect of number of iterations for ccWL models and layers for GNNs?** The hyperparameter \(L\), which denotes the number of iterations (resp. layers) for ccWL (resp. GNN) models, generally plays an important role in planning performance. This is because increasing \(L\) improves model expressivity and reasoning capabilities, but comes at the cost of heuristic evaluation time and increased possibility of overfitting to the training data. From Tab. 2 in the appendix, we note that surprisingly for most domains and models \(L=0\) or \(L=1\) provides the best coverage, while increasing \(L\) rarely improves coverage. This suggests that heuristic evaluation time plays an important role in planning performance for domains that cannot be solved with the learner's expressivity.

## 7 Limitations

The setup of our work is limited to the assumption that the problems being solved can be explicitly represented in a symbolic language such as PDDL. The assumption of the existence of PDDL encodings of planning problems allows us to generate training data quickly with domain-independent numeric planners for supervised training. Furthermore, experiments and theoretical insights also show that our proposed techniques have room for improvement as there are still classes of numeric planning tasks with which our models cannot learn and generalise well in.

## 8 Conclusion

We have proposed a new graph embedding algorithm, the ccWL algorithm, and optimisation criterion for learning heuristic functions for numeric planning. Planning tasks are encoded as Numeric Instance Learning Graphs (\(\)ILG) on which we run our ccWL algorithm for generating features. Our numeric planning features are interpretable and efficient to generate. Experimental results show the effectiveness of our approach by achieving competitive performance over both deep learning architectures and domain-independent numeric planners. Furthermore, we have identified future work by improving the expressivity of our algorithms for capturing more complex numeric domains. Lastly, one can learn forms of domain knowledge different from heuristic functions with our new numeric planning features and graph representations such as policies , portfolios  and detecting relevant objects .

Figure 6: Plot comparisons of expanded nodes and plan length of selected pairs of models with \(L=1\). A point (\(x\), \(y\)) represents the metric of the models indicated on the \(x\) and \(y\) axis on the domain. Points on the top left (resp. bottom right) triangle favour the model on the \(x\)-axis (resp. \(y\)-axis).