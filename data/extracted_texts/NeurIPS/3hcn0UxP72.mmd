# Topological obstruction to the training of shallow ReLU neural networks

Marco Nurisso

Politecnico di Torino & CENTAI Institute

Torino, 10100 - ITALY

marco.nurisso@polito.it

Pierrick Leroy

Politecnico di Torino

Torino, 10100 - ITALY

pierrick.leroy@polito.it

Francesco Vaccarino

Politecnico di Torino

Torino, 10100 - ITALY

francesco.vaccarino@polito.it

###### Abstract

Studying the interplay between the geometry of the loss landscape and the optimization trajectories of simple neural networks is a fundamental step for understanding their behavior in more complex settings. This paper reveals the presence of topological obstruction in the loss landscape of shallow ReLU neural networks trained using gradient flow. We discuss how the homogeneous nature of the ReLU activation function constrains the training trajectories to lie on a product of quadric hypersurfaces whose shape depends on the particular initialization of the network's parameters. When the neural network's output is a single scalar, we prove that these quadrics can have multiple connected components, limiting the set of reachable parameters during training. We analytically compute the number of these components and discuss the possibility of mapping one to the other through neuron rescaling and permutation. In this simple setting, we find that the non-connectedness results in a topological obstruction, which, depending on the initialization, can make the global optimum unreachable. We validate this result with numerical experiments.

## 1 Introduction

Training a neural network consists of navigating the complex geometry of the loss landscape to reach one of its deepest valleys. Gradient descent and its variants are, by far, the most commonly used algorithms to perform this task. While technically correct, the standard picture of the parameter space as Euclidean space with the trajectory rolling down the loss's surface in the steepest direction towards a minimum is slightly misleading because different choices of parameters can be _observationally equivalent_ i.e. encode the same function . The observational equivalence of parameters shape the loss landscape by imposing specific geometric structures on the parameter space. Minima are not isolated points but high-dimensional manifolds with complex geometry [17; 9; 42] and the loss function's gradients and Hessian are constrained to obey some specific laws [46; 27]. Gradient-based optimization methods, where the parameters are updated by performing discrete steps in the gradient's direction, are thus very much dependent on the symmetry-induced geometry [12; 29].

In this work, we provide a topological perspective on the constraints induced by some groups of network symmetries on the optimization trajectories. Topology is a field of mathematics that studies the properties of a space that are preserved under continuous deformations. Our main goal is to find and quantify in topological terms the impossibility of the training trajectories to freely explore the parameter space and get from any initialization to an optimal parameter. This idea is formalized inthe topological notion of _connectedness_ and, in particular, with the 0-th _Betti number_, which counts the number of _connected components_ the space is composed of. The presence, or the absence, of topological _obstructions_ in the parameter space does not depend on the particular loss function or the training data but is intrinsic to the interplay between the geometry and the topology of the parameter space under the action of groups of symmetries inducing observationally equivalent networks.

Main contributions.Our main contributions are the following.

1. We find that, for two-layer neural networks, the gradient flow trajectories lie on an invariant set, which can be factored as the product of quadric hypersurfaces.
2. We analytically compute its Betti numbers, i.e., the number of connected components, holes, and higher-dimensional cavities.
3. We find that the invariant set can be disconnected when the network's output dimension is 1, leading to a clear topological obstruction.
4. We find that the obstruction is caused by "pathological" neurons that cannot change the sign of their output weights when trained with gradient flow.
5. We discuss the relation between the invariant set and the network's symmetries, finding that if we consider permutations, the number of effective connected components scales linearly in the number of pathological neurons.
6. We perform numerical validations on controlled toy scenarios, displaying the effect of obstruction in practice.

## 2 Related work

A large body of work studies gradient flow and gradient descent optimization of one hidden layer networks with homogeneous activations. Convergence properties have been found for wide networks [37; 43] with bounded density at initialization . The implicit regularization provided is studied under various assumptions on: orthogonal input data , initialization scale [30; 4], wide (overparameterized regime) and infinitely wide , linearly separable data [30; 45]. Deeper linear networks  have also been studied.

These works focus on proving convergence and understanding which (optimal) solution is found, whereas our work investigates the shape of the optimization space and focuses on cases where the optimum might not be reachable from a given initialization.

Closer to our work, Safran et al.  studies two-layer ReLU binary classifiers with single input and output, counting the number of their piecewise-linear components after training. Eberle et al.  focuses on the differential challenge posed by the ReLU activation function and studies properties like the uniqueness of the solution of a gradient flow differential equation for a given initialization.

ReLU activation is a nonnegative homogeneous function, meaning that particular weight rescalings do not change the neural network's function. This is at the heart of the counterargument to flatness measures made by Dinh et al. , which shows that the Hessian eigenvalues can be made arbitrarily large in this way. Neyshabur et al.  explores the effect such rescalings can have on the gradient, proposing a rescaling-invariant regularization, and Pittorino et al.  employs them to define invariant flatness measures. Generally speaking, neural networks possess symmetries , and symmetries influence the geometry of training. Du et al.  studies how symmetry leads ReLU networks to automatically balance the neurons' weights. Kunin et al. , Zhao et al.  study how it constrains the gradient and Hessian matrix, leading to conservation laws w.r.t. gradient flow and Tanaka et al.  leverages it to propose a network pruning scheme. Ziyin  studies general mirror-reflect symmetries of the loss function and their effect on the weights of the trained network. Other conserved quantities stem from batch normalization's scale invariance [23; 47]. The transition from gradient flow to finite step size gradient descent breaks the conservation laws, resulting in altered trajectories [14; 2; 27; 44].

Numerous works have explored the geometry and topology of the loss landscape to obtain insight into a neural network's training behavior. Motivated by the striking experimental observation that low loss points can be connected by simple curves [11; 18] or line segments [40; 16; 15], a large body of literature tries to understand this phenomenon of mode connectivity under the topological lens of the connectedness of the loss function's sublevel sets [17; 35; 26], especially for overparameterized neural networks [9; 8; 42]. Another line of work approaches the connectivity of minima from another point of view, studying the presence [50; 38; 48] or absence  of spurious minima, i.e. minima which are not global. Bucarelli et al.  analytically derives bounds on the sum of the Betti numbers of the loss landscape's sublevel set. Topological data analysis methods have also been exploited to numerically study the shape of the loss landscape [1; 22].

## 3 Setup and preliminaries

### One-hidden layer neural network

Unless otherwise stated, all vectors are column vectors, that is, \(x=(x_{1},,x_{d})^{}^{d}^{d 1}\). Let us consider a two-layer neural network \(f(,):^{d}^{e}\) specified by the function

\[f(x;)=W^{(2)}(W^{(1)}x),\] (1)

where \(x^{d}\) is the input, \(=(W^{(1)},W^{(2)})\) with \(W^{(1)}^{l d}\) and \(W^{(2)}^{e l}\) are the parameters, \(:\) is the component-wise activation function and \(l\) is the number of neurons in the hidden layer. Notice that we consider a network with no biases, as it allows us a discussion with lighter notation. The case with biases is discussed in Appendix E.

In this work, following , we focus on the case where \(\) is _homogeneous_, namely \((x)=^{}(x) x\) for every \(x\) and for every element of the sub-differential \(^{}(x)\) if \(\) is non-differentiable at \(x\). The commonly used ReLU (\((z)=\{z,0\}\)) and Leaky ReLU (\((z)=\{z,\}\) with \(0 1\)) activation functions satisfy this property.

We call _parameter space_ the vector space \(=\{=(W^{(1)},W^{(2)}) W^{(1)}^{l d},W ^{(2)}^{e l}\}\).

It will also be convenient to examine the single hidden neurons and their associated parameters for the following discussions.

**Proposition 1**.: _For the two-layer neural network defined in Equation (1). Let \(k=1,,l\), let \((e_{11},e_{12},,e_{ll})\) be the canonical basis of \(^{l l}\) and \(_{k}=\{_{k}=(e_{kk}W^{(1)},W^{(2)}e_{kk})(W^{(1)},W^{(2) })\}\), then \(=_{1}_{l}\)._

Details of the proof are provided in Appendix A. Fixing \(k\{1,,l\}\), we can consider \(_{k}\) as the parameter space of the \(k\)-th hidden neuron, which consists of the inputs and output weights of neuron \(k\), namely the rows and columns of \(W^{(1)}\) and \(W^{(2)}\), respectively. For simplicity, when we work in \(_{k}\), we write \(W^{(1)}_{k}:=e_{kk}W^{(1)}\) and \(W^{(2)}_{k}:=W^{(2)}e_{kk}\). Interestingly, the decomposition of Proposition 1 only holds for two-layer neural networks and will be crucial to the formulations of this paper's results.

### Symmetries and observationally equivalent networks

It is well known that the properties of the activation function heavily influence the geometry of the parameter space \(\). The activation function's commutativity with some classes of transformations can result in the latter having no effect on the function implemented by the neural network. This means that, in general, the mapping from the parameter space to the hypothesis class of functions is not injective. Following the terminology in Dinh et al. , we say that two parameters \(_{1},_{2}\) are _observationally equivalent_, if they encode the same function \(f(;_{1})=f(,_{2})\) and write \(_{1}_{2}\).

In the case of homogeneous activations (ReLU or Leaky ReLU), we describe two kinds of transformations that send a parameter \(\) into an observationally equivalent one.

Neuron rescaling.The input weights of a hidden neuron can be rescaled by a positive scalar \(>0\) provided that its output weights are rescaled by the inverse \(^{-1}\) (top panel of Figure 0(a)). We formalize this as the action of the group \(_{+}\) of positive real numbers on \(_{k}\):

\[T_{+}_{k} _{k}\] (2) \[(,_{k})  T_{}(_{k})=( W^{(1)}_{k},  W^{(2)}_{k}).\]

This action can be naturally extended to the space of all parameters by considering the possibility of rescaling all hidden neurons simultaneously by different factors. If \(=(_{1},,_{l})_{+}^{l}\)

\[T_{}()=(()W^{(1)},W^{(2)}()^ {-1}).\] (3)Given that \((az)=a(z)\) when \(a_{+}\), we see how \( T_{}()\).

We write \(T()\) to denote the orbit of a parameter \(\) under the action of \(T\), i.e. the set of all parameters obtained from \(\) by arbitrarily rescaling the neurons \(T()=T_{}():\ _{+}^{l}}\).

Permutations of the neurons.Besides rescaling, we can obtain an observationally equivalent network by permuting the hidden neurons in such a way as to preserve their input and output weights (bottom panel of Figure 1a).

Given the symmetric group on \(l\) elements \(_{l}\) of the permutations of \(\{1,,l\}\), we write the action

\[P_{l} \] (4) \[(,)  P_{}()=(R_{}W^{(1)},W^{(2)}R_{}^{}).\]

where \(R_{}\) is the \(l l\) row-permutation matrix associated to the permutation \(\).

Given that the activation function \(\) is applied component-wise, we have that it commutes with \(R_{}\), namely

\[f(x;P_{}())=W^{(2)}R_{}^{}(R_{}W^{(1)}x)=W^{(2) }R_{}^{}R_{}(W^{(1)}x)=W^{(2)}(W^{(1)}x)=f(x;)\]

and thus \(P_{}()\) because \(R_{}^{}=(R_{})^{-1}\).

Having defined these two actions, we say that \(\) and \(^{}\) are _observationally equivalent by rescalings and permutations_ if \(^{}\) can be obtained from \(\) by a finite sequence of actions of \(T\) and \(P\) or, equivalently thanks to Lemma 3 in the Appendix, if there exists a rescaling \(\) and a permutation \(\) such that \(^{}=P_{} T_{}()\). In this case, we write \(}{}^{}\).

### Conserved quantities and the invariant hyperquadrics

The presence of symmetries in the neural network's parameter-function map results in a specific geometric structure in the loss landscape. Let indeed \(D=(x_{i},y_{i})^{d}^{e}}_{i=1}^{N}\) be a training set of \(N\) input-output pairs and fix a loss function \(L:\) which depends on the parameters only through the output of the neural network (1), that is

\[L()=_{i=1}^{N}(f(x_{i};),y_{i})\] (5)

where \(:^{e}^{e}\) is differentiable. In this work, as empirical risk minimization, we consider the continuous time version of the gradient descent (GD) algorithm (with learning rate \(h>0\))

\[_{t+1}=_{t}-h_{}L(_{t})\] (6)

Figure 1: **a.** Depiction of the two group actions acting on the space of the network’s parameters: the neuron rescaling of Equation (2) (top) and the neuron permutation of Equation (4) (bottom). **b.** Depiction of the geometry of the parameter space induced by the rescaling invariance of ReLU networks. The dotted lines denote the orbits \(T()\) while the solid lines represent the invariant sets \((c)\) associated with \(\) and the one associated with its rescaled version \(^{}\). Notice how the gradient of the loss \(g()\) is tangent to \((c)\) and orthogonal to \(T()\).

named _gradient flow_ (GF), and defined as

\[}{t}(t)-_{}L((t)):=-g ((t))\] (7)

where \(_{}L((t))\) is the Clarke sub-differential  which takes into account the parameters \(\) where \(L()\) is non-differentiable. Given that the loss function \(L\) depends on the parameters only through \(f\), its value at \(\) must be constant over the orbit \(T()\). This, together with the fact that the gradient of a differentiable function at a point is orthogonal to the level set at that point, means that

\[g() T()\] (8)

at any parameter \(\) where \(L()\) is differentiable, as represented in Figure 0(b). This orthogonality condition constrains the possible values of the gradient and, by extension, the possible gradient flow trajectories. In particular, as proven in Liang et al. , Tanaka et al. , Equation (8) is equivalent to

\[_{i=1}^{d}W^{(1)}_{ki}g^{(1)}_{ki}-_{j=1}^{e}W^{(2)}_{jk}g^{(2)}_{jk}= 0\ \  k=1,,l.\] (9)

For convenience of notation, we define, for \(k=1,,l\), the following bilinear forms on \(\), which help us describe the geometry induced by the rescaling symmetry. If \(=(W^{(1)},W^{(2)})\) and \(=(V^{(1)},V^{(2)})\), we define

\[\!,\!_{k}=_{i=1}^{d}W^{(1)}_{ki}V^{ (1)}_{ki}-_{j=1}^{e}W^{(2)}_{jk}V^{(2)}_{jk}\] (10)

which, notice, only depends on the \(k\)-th row of \(W^{(1)}\) and \(k\)-th column of \(W^{(2)}\) meaning that we can equivalently see it as a bilinear form on \(_{k}\). \(_{k}\), together with \(\!,\!_{k}\) is a _pseudo-Euclidean space_.

With the notation given by Equation (10), we see that Equation (9) can be simply rewritten as \(\!,g()\!_{k}=0\) for every neuron \(k\). This condition, akin to orthogonality w.r.t. the bilinear form of Equation (10), implies that, under gradient flow optimization,

\[}{t}\!,\!_{ k}=2\!,\!_{k}=-2\! g (),\!_{k}=0\ \  k=1,,l.\] (11)

This result, first obtained in Saxe et al.  for linear networks and discussed in Du et al. , Liang et al. , Kunin et al. , tells us that the rescaling symmetry results in the quantities \(\!,\!_{k}\) being conserved. This means that the difference between the Euclidean norm of the inputs and the outputs is constant for each neuron throughout the GF training trajectory. Moreover, under the condition of homogeneity of the activation function, Du et al.  proves that Equation (11) holds even at non-differentiable points of \(L\) and in the case of multiple layers.

Invariant sets.Assume that at the initialization \(_{0}\) we have \(\!_{0},_{0}\!_{k}=c_{k}\), for all \(k\), then Equation (11) implies that the GF trajectory will lie on the set characterized by the system of equations \(\!,\!_{k}=c_{k}\) for \(k=1,,l\). This subset is mapped to itself under the GF dynamics by Equation (11) (see Figure 0(b)) and constitutes the main object of our study.

**Definition 1** (Invariant set).: _Given \(c=(c_{1},,c_{l})\), we call invariant set the subset \((c)\) given by the equations \(\!,\!_{k}=c_{k}\  k=1,,l\)._

If we look at each single equation (i.e. to each hidden neuron), we see that Equation (11) can be written as

\[_{i=1}^{d}(W^{(1)}_{ki})^{2}-_{j=1}^{e}(W^{(2)}_{jk} )^{2}=c_{k}\] (12)

which corresponds to a _hyperquadric_ (or quadric hypersurface) in \(_{k}\). We denote with \((c_{k})_{k}\) this hypersurface and call it the _invariant hyperquadric_ associated to the \(k\)-th hidden neuron.

Here \(c_{k}\) takes the role of a label associated with the \(k\)-th hidden neuron, which, we see in the next section, plays a key role in specifying the shape of \((c_{k})\). Figure 1(a) shows how, for \(d=2\) and \(e=1\), \((c_{k})\) is an hyperboloid with 1 sheet (connected) if \(c_{k}>0\) and 2 sheets if \(c_{k}<0\).

Topology of the invariant set

As we discussed above, Equation (11) tells us that gradient flow trajectories can't explore the whole space \(\) but are constrained to lie on the invariant set \((c)\). The values of \(c\), in turn, depend on the initialization and, we see from Equation (12), quantify the balance between the norms of input and output weights in every hidden neuron.

The goal of this section is to provide a topological characterization of \((c)\) that can tell us something about the presence or absence of fundamental _obstructions_ to the network's training process. With obstruction, we mean the impossibility of a GF trajectory to travel freely from one point to the other in \((c)\). We refer the reader to Appendix B for an essential overview of some of the topological concepts that we rely on in the next paragraphs.

Counting high-dimensional holes.Our topological characterization will be framed using _Betti numbers_. Betti numbers are well-known topological invariants given by a sequence of natural numbers that intuitively encode the number of higher-dimensional holes and cavities present in space. In particular, the 0-th Betti number of a space \(X\), \(_{0}(X)\) corresponds to the number of connected components of \(X\) and thus will be fundamental for our goal of identifying obstructions.

The invariant set \((c)\) is given as the set of solutions of \(l\) polynomial equations of degree 2 sharing no variables. Furthermore, in the setting of two-layer neural networks, we can leverage the fact that the parameter space can be decomposed into the parameter spaces of the hidden neurons. This, in turn, allows us to decompose the invariant set as the product of the neurons' invariant hyperquadrics, greatly simplifying our study.

**Lemma 1**.: _In a two-layer ReLU neural network, the invariant set \((c)\) is homeomorphic to the Cartesian product of the hidden neurons' invariant hyperquadrics, that is_

\[(c)(c_{1})(c_{l}).\] (13)

Lemma 1 tells us that we can understand the topology of \((c)\) by studying independently its factors. Moreover, the hyperquadrics we encounter here are well-studied objects for which the next proposition (proven in Appendix D.2) gives a topological characterization.

**Proposition 2**.: _If \(c_{k}>0\), \((c_{k})\) is a topological manifold homeomorphic to \(^{e} S^{d-1}\). If \(c_{k}<0\), \((c_{k})\) is a topological manifold homeomorphic to \(^{d} S^{e-1}\). If \(c_{k}=0\), \((0)\) is a contractible space._

Leveraging the decomposition of Lemma 1 and the characterization of the factors given by Proposition 2, we can explicitly compute all the Betti numbers of the invariant set. We give the next result in terms of the _Poincare polynomial_ of \((c)\), namely the polynomial whose coefficients are the Betti numbers (see Appendix B).

**Theorem 1**.: _Let \(l_{+},l_{-},l_{0}\) be the number of positive, negative, and zero components of \(c\), respectively. The Poincare polynomial of \((c)\) is given by_

\[p_{(c)}(x)=(1+x^{d-1})^{l_{+}}(1+x^{e-1})^{l_{-}}.\] (14)

This result, which is proven in Appendix D.3, contains a wealth of topological information as it gives us the exact number of holes and cavities of any order, depending on the network's hyperparameters (\(d,e\)) and initialization (\(l_{+},l_{-}\)). In the rest of this work, we focus only on the 0-th Betti number as the non-connectedness of \((c)\) provides a clear obstruction to the GF trajectories.

Connectedness of the invariant set.With regard to the connectedness of \((c)\), we can leverage Theorem 1 to obtain the exact number of connected components.

**Corollary 1**.: _The \(0\)-th Betti number \(_{0}\) of \((c)\), corresponding to the number of its connected components, is given by_

\[_{0}=1&d,e>1\\ 2^{l_{+}}&d=1,e>1\\ 2^{l_{-}}&d>1,e=1\\ 2^{l_{+}+l_{-}}&d=1,e=1\] (15)

Proof.: This can be directly obtained from the coefficient of degree 0 of the Poincare polynomial obtained through Theorem 1.

What we see in Equation (15) is that in most cases, the invariant set is connected, and gradient flow has no topological limitations in exploring the whole of \((c)\). Instead, when the hidden neurons have only one input or only one output, the space is fragmented into several components whose number scales exponentially in \(l_{+}\) or \(l_{-}\), respectively.

Let us focus on the more interesting case where \(d>1\) and \(e=1\).

**Corollary 2**.: _If the output of a two-layer ReLU neural network is a single scalar \(e=1\), its input has dimension \(d>1\), and the initial parameter \(_{0}\) is such that \(\!_{0},_{0}\!_{k}<0\) for \(l_{-}>0\) hidden neurons, then the set \((c)\) is disconnected and has \(2^{l_{-}}\) connected components._

This means that neurons initialized with the norm of their outgoing weight strictly greater than their incoming weights' norm are responsible for disconnecting the space. We now precisely identify which connected component a parameter \(\) belongs to and clarify the meaning of the obstruction.

**Proposition 3**.: _Let \(e=1,d>1\), and \((c)\) with \(c\) such that \(c_{k_{1}},,c_{k_{l_{-}}}<0\) while \(c_{k} 0\) for all other \(k\). Let \(W_{-}^{(2)}:=(W_{k_{1}}^{(2)},,W_{k_{l_{-}}}^{(2)})^{1 l _{-}}\) be the row vector whose components are the components of \(W^{(2)}^{1 l}\) associated to \(c_{k}<0\). Then the vector \(s()=((W_{k_{1}}^{(2)}),,(W_ {k_{l_{-}}}^{(2)}))\) identifies uniquely the component \(\) belongs to, namely: \(\) and \(^{}\) belong to the same connected component of \((c)\) if and only if \(s()=s(^{})\)._

Proposition 3, proven in Appendix D.4, implies that \(s()\) does not change when we move in \(C\) on a continuous curve such as the one given by gradient flow. This gives us an interesting interpretation of the topological obstruction: gradient flow cannot change the signs of the outgoing weights of the hidden neurons \(k\) such that \(c_{k}<0\) (see Appendix G for an intuitive explanation of the phenomenon). This same observation is also mentioned in Boursier and Flammarion . Proposition 3 extends one of the results of Boursier et al.  which proves that the same also holds when \(c_{k}=0\) (balanced initialization).

By also considering Corollary 1, one obtains that a clever initialization of the parameters given by \(\!_{0},_{0}\!_{k}=c_{k}>0\)\( k=1,,l\) can prevent the issue by ensuring the connectedness of the invariant set. We also find that under common initialization schemes such as Xavier  and Kaiming  the probability of having pathological neurons is negligible when the input dimension and number of hidden neurons is high (see Appendix F).

## 5 Taking symmetries into account

Corollary 2 states that neurons \(k\) such that \(c_{k}<0\) are "pathological", in the sense that they are responsible for disconnecting the invariant set into several components, whose number scales exponentially in the number of those neurons. This result gives us a grim picture of the possibility of actually

Figure 2: **a.** The invariant hyperquadric \((c_{k})\) of a neuron with two inputs (\(d=2\)) and one output (\(e=1\)) in the cases where \(c_{k}<0\) (left) and \(c_{k}>0\) (right). **b.** Depiction of the invariant set \((c)\) in the case where \(l_{-}=2\) so that there are \(2^{l_{-}}=4\) connected components. \(C_{}\) denotes the connected component such that \(s=( 1, 1)\). The blue lines separate the different effective components of \((c)\).

optimizing the neural network: if the initial parameter \(_{0}\) is in a particular connected component and the global optimum \(_{*}\) lies in another, then any gradient flow trajectory will not be able to reach \(_{*}\) because it will be constrained in its connected component.

This result, however, provides us only with a partial picture of the parameter space's geometry. It is a priori possible that the training trajectory, moving in its connected component, reaches a parameter \(\), which itself is optimal as it is observationally equivalent to \(_{*}\) (\(_{*}\)). In this case, the topological obstruction given by the non-connectedness would be only apparent.

To take this fact into account, we define the following notion.

**Definition 2** (Effective component).: _Let \((c)\) and \(C()\) be its connected component therein. We define its effective component \(()\) as the union of the connected component of all \(^{}\) such that \(^{}}}{{}}\). So that \(():=_{^{}}}{{}}}C(^{})\)._

Figure 1(b) gives a picture which clarifies the definition, showing a space with 4 connected components that has only 3 effective components. If the optimum \(_{*}\) belongs to the same effective component as the initialization, then it is possible to reach a parameter that is observationally equivalent to it (through permutations and rescalings).

We present a useful result which tells us that the action of rescaling of Equation (3) can take any non-degenerate parameter \((c)\) to any other invariant set \((c^{})\) for every \(c^{}^{l}\). This means that any invariant set can realize all the neural network's functions.

**Proposition 4**.: _For every \(c_{k}\) and for every \(_{k}_{k}\) such that \(W_{k}^{(1)},W_{k}^{(2)} 0\), there exists a unique \(_{k}_{+}\) such that \(T_{_{k}}(_{k})(c_{k})\). If \(W_{k}^{(1)}=0\) and \(W_{k}^{(2)} 0\), then the same holds for every \(c_{k}<0\), while, if \(W_{k}^{(1)} 0\) and \(W_{k}^{(2)}=0\), it holds for every \(c_{k}>0\)._

The proof can be found in Appendix D.5 with the formula of the specific \(\) which realizes the rescaling.

The following theorem leverages the power of Proposition 4 to give necessary and sufficient conditions for \(\) and \(^{}\) to belong to the same effective component.

**Theorem 2**.: _Let \(d>1\) and \(e=1\). Let \(c^{l}\) and \(l_{-}\) be the number of neurons such that \(c_{k}<0\). Assume that \(l_{-} 1\). Let \(C,C^{}(c)\) be two distinct connected components of \((c)\) such that \(s()=s\), \( C,\) and \(s(^{})=s^{}\), \(^{} C^{}\). Then, the following statements are equivalent:_

1. _for every_ \( C\) _there exists_ \(^{} C^{}\) _such that_ \(}}{{}}^{}\)_;_
2. \(_{i=1}^{l_{-}}s_{i}=_{i=1}^{l_{-}}s_{i}^{}\)__

The theorem, proven in Appendix D.6, tells us that, while connected components are identified by \(s\), the effective components are identified only by the values of \(_{i}s_{i}\) or, equivalently, by the distribution of \( 1\) in \(s\). Therefore, we find that the number of effective components scales much slower than the exponential growth of the number of connected components given by Corollary 1.

**Corollary 3**.: _The number of effective components of \((c)\) is given by \(1+l_{-}\)._

Proof.: Theorem 2 tells us that two connected components \(C,C^{}\) belong to the same effective component if and only if their associated sign vectors \(s,s^{}\{-1,1\}^{l_{-}}\) have the same sum. The number of effective components will thus equal the number of different values that the sum \(_{i=1}^{l_{-}}s_{i}\) can have. If \(s_{i}=1\)\( i\) then \(_{i=1}^{l_{-}}s=l_{-}\). Each switch of a component to \(-1\) decreases the sum's value by \(2\) until it reaches the minimum \(-l_{-}\). Therefore, the total number of values of the sum will be \(1+l_{-}\). 

## 6 Empirical Validation

Task, dataset, and model setup.We display here a toy example, showing how the initialization of the model can cause a topological obstruction, making the optimum unreachable.

We consider the function \(F(x_{1},x_{2})=-(x_{1}+x_{2})\), which will be our ground-truth. Next, we generate a dataset of 8000 points (\(x_{i},F(x_{i})\)) by sampling \(x_{i} U([0,1]^{2})\). Our model, depicted in Figure 2(a)is a one hidden layer neural network with 2 hidden neurons, ReLU activations and no biases. All the weights are initialized by independently sampling from \(U([-,])\). From the task and the network's architecture, it is clear that at least one of the output weights has to be negative to approximate \(F\) correctly.

To standardize our results, we apply the rescaling of Proposition 4 and relocate the initial parameters to an observationally equivalent one in the invariant set \((c)\) with \(c_{k}\{-0.1,0.1\}\), controlling the sign of the weights on the last layer. We allow ourselves to do these two manipulations to control the experiments while only marginally modifying the network initialization, avoiding the introduction of massively unbalanced weights, which could change the dynamics, as shown in Neyshabur et al. . Finally, we train the network using gradient descent on the MSE loss with a small learning rate of \(h=0.01\). This limits the variations of \(c_{k}\) values to less than one percent along training, giving us a good approximation of gradient flow.

Results.We initialize different models and collect all states and losses. First, when we initialize the model with an "unlucky" configuration, namely \(c=(-0.1,-0.1)\) (the space has 4 connected components) and \(s()=(+1,+1)\), we find that the trajectories are confined to the positive region of their invariant hyperquadric, resulting in a poor approximation of \(F\), as we can see in Figure 3b (top) and in the loss of Figure 3c. Instead, with an initial configuration such that \(c=(-0.1,+0.1)\) (2 connected components) and \(s()=(+1,+1)\), the model can leverage the connectedness of \((c_{2})\) to learn \(F\) by flipping the sign of the second neuron's output weight (Figure 3b bottom right).

A more realistic experiment.We present here a further experiment to show how the topological obstruction can be a hindrance in a more realistic setting. We consider a simple binary classification task on the well-known _breast cancer_ dataset , which we try to solve by fitting a one-layer ReLU neural network trained to minimize the BCE loss. We vary the number of hidden neurons \(l\) and, for each \(l\), we change the number of non-pathological neurons \(l_{+}\) (neurons with \(c_{k}>0\)) from 0 to \(l\). We repeat the experiment with 100 different random initializations and show how the model's average performance changes when the degree of disconnectedness of its invariant set is varied. The result, on the left panel of Figure 4, clearly shows the presence of a "gradient" in performance, where increasing the number of non-pathological neurons decreases the average value of the test loss after training. The right panel of Figure 4, moreover, shows how the impact of the obstruction depends on the number of non-pathological neurons and not on their fraction over the total number of hidden neurons.

Figure 3: Visualization of the experimental setup described in Section 6. **a.** The small 2-layer neural network architecture considered. **b.** The hidden neurons’ parameter spaces, together with the invariant hyperquadrics associated with hidden neurons 1 (left) and 2 (right), for an initialization with topological obstruction (top) and without it (bottom). The colored curves represent the gradient descent trajectories from initialization \(_{k}(0)\) up to \(t_{*}=500\) optimization steps. **c.** The loss curves for the bad (obstructed) and good initializations.

## 7 Conclusions

In this paper, we have given analytical results that clarify the nature of the constraints imposed by gradient flow on the parameter space of a two-layer neural network with homogeneous activations. In the case of a single scalar output, which appears in tasks such as binary classification and scalar regression, we identified initial conditions that lead to a topological obstruction in the form of the parameter space's fragmentation into multiple connected components. This is caused by pathological neurons whose output weights cannot change their sign during training. Moreover, if one also considers the network's symmetries under permutations of the hidden neurons, we find that most of the connected components are equivalent. The number of effective components of the resulting space scales linearly with the number of pathological neurons, contrasting with the exponential growth of the number of connected components obtained without considering the permutation symmetries.

As shown in the last numerical experiment, the lack of non-pathological neurons hinders learning, even when the network's width is scaled. Our probabilistic analysis outlined in Appendix F, however, shows that with common initialization schemes, the probability of creating a pathological neuron decreases rapidly with increased inner layer width. Therefore, the combination of specific initialization schemes and a large number of hidden neurons (beyond the minimum required to solve a task) appears to make this obstruction unlikely in practice. This work describes a simple safeguard to avoid obstructions, which can, for instance, discourage the usage of initialization schemes that result in the proliferation of pathological neurons.

## 8 Limitations

The main limitation of the work is the network's architecture, which is limited to only one hidden layer. Considering multiple layers, we can still define rescalings and permutations and find invariant hyperquadrics for each hidden neuron. The issue emerges in the fact that these hyperquadrics are not "independent" anymore, and the invariant set cannot be factored into the product of the \((c_{k})\). This intuitively results from the fact that in the multi-layer case, each weight in the hidden layers is shared by two neurons.

The second limitation is that our study focuses on gradient flow optimization. This idealized situation doesn't take into account the fact that moderate step size of gradient descent and stochastic gradient descent can break the conservation of \(\!,\!_{k}\) and make the parameters drift away from the invariant set . Moreover, popular optimizers like ADAM  update the parameters employing the gradients at previous iterations so their trajectories will not be constrained to lie on \((c)\) as we defined it.

The inclusion of regularization terms in the loss function, such as \(_{p}\) regularizations, also breaks the invariance to rescalings.

Figure 4: **Left.** Average test BCE loss of a two-layer ReLU neural network trained on the _breast cancer_ dataset over 100 different initializations for each pair (\(l,l_{+}\)), \(l=2,,9\) and \(l_{+} l\), of numbers of hidden neurons and non-pathological neurons. **Right.** the y-axis displays the percentage of non-pathological neurons.