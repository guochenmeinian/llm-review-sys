# Neural Collapse Inspired Feature Alignment for Out-of-Distribution Generalization

Zhikang Chen\({}^{1}\) Min Zhang\({}^{2}\) Sen Cui\({}^{5}\) Haoxuan Li\({}^{4}\)\({}^{3}\) Gang Niu\({}^{4}\)

Mingming Gong\({}^{6,8}\) Changshui Zhang\({}^{5}\) Kun Zhang\({}^{7,8}\)

\({}^{1}\) Tsinghua University \({}^{2}\) East China Normal University \({}^{3}\) Peking University \({}^{4}\) RIKEN

\({}^{5}\) Institute for Artificial Intelligence, Tsinghua University (THUAI)

Beijing National Research Center for Information Science and Technology (BNRist)

Department of Automation, Tsinghua University

\({}^{6}\) The University of Melbourne \({}^{7}\) Carnegie Mellon University

\({}^{8}\) Mohamed bin Zayed University of Artificial Intelligence (MBZUAI)

###### Abstract

The spurious correlation between the background features of the image and its label arises due to that the samples labeled with the same class in the training set often co-occurs with a specific background, which will cause the encoder to extract non-semantic features for classification, resulting in poor out-of-distribution generalization performance. Although many studies have been proposed to address this challenge, the semantic and spurious features are still difficult to accurately decouple from the original image and fail to achieve high performance with deep learning models. This paper proposes a novel perspective inspired by neural collapse to solve the spurious correlation problem through the alternate execution of environment partitioning and learning semantic masks. Specifically, we propose to assign an environment to each sample by learning a local model for each environment and using maximum likelihood probability. At the same time, we require that the learned semantic mask neurally collapses to the same simplex equiangular tight frame (ETF) in each environment after being applied to the original input. We conduct extensive experiments on four datasets, and the results demonstrate that our method significantly improves out-of-distribution performance.

## 1 Introduction

The out-of-distribution (OOD) problem refers to the fact that the training dataset and the test dataset have different distributions in different environments, after the training process is completed, what we want is to have correlation between semantic features and label, however, the presence of spurious feature(environmental information) can make false correlation between environmental information and labels. The semantic feature in an image refers to the object of the class, while the spurious feature in an image refers to the background or the environment. As shown in Figure 1, the background color for digits 0 and 2 is predominantly orange, while the background color for digit 1 is predominantly green. In this figure, the semantic feature includes digits 0, 1 and 2, whereas the spurious feature includes orange and green backgrounds.

Recently, many OOD methods have been proposed to learn invariant representations for different environments by introducing various regularization methods . Although these methods achieve good OOD performance on test data withenvironment variations from the training dataset, on the one hand, they require a well-partitioned environment in advance, but real datasets usually do not have environment labels; on the other hand, under cross-environment conditions, these methods do not align feature prototypes well between the test environments and the training environments. In this paper, we equate semantic features with invariant features and spurious features with variable features.

We first explored the limitations of previous OOD learning methods from a new perspective and conducted a toy example experiment, as shown in Figure 1. The digits 0 and 2 are associated with orange background, and the digit 1 is associated with green background. The phenomenon of neural collapse, which means that after sufficient training, the categories will collapse to a simplex ETF such that the angles between the feature prototypes of two neighboring categories are equidistant, Thus, in Figure 1, after the training is completed, the feature prototypes of the digits 0, 1 and 2 occur in three equal parts. Here, to measure the extent of neural collapse, we propose to compute the Frobenius norm (F-norm) of the difference between the feature prototypes and the standard simplex ETF. A smaller F-norm indicates a closer proximity to the standard simplex ETF. The ERM approach (Vapnik et al., 1998) that leads to the failure of OOD generalization is due to the endogenous nature of the class features not being able to align the class prototypes after training is complete in different environments. Although IRM-based methods (Arjovsky et al., 2019) theoretically learn a feature representation such that the last layer of the feature extractor is similar across environments, we empirically found that IRM-based methods are not aligned very well, which motivates using neural collapse to align feature for OOD generation.

In this paper, in order to bridge this gap, we believe that a feature extractor for OOD generalization across environments should ensure that semantic features are aligned to the same simplex ETF, and we have verified from our experiments that better alignment can significantly improve OOD performance. Specifically, our method can be applied both with and without environment labels. In the absence of environment labels, we can automatically partition the environments and assign local models to different environments. By predicting the variable components of the input, we take the logits corresponding to the label (one-hot encoding) from the predictions of the local models in different environments, form a vector, and select the maximum value of the vector. The corresponding environment of this maximum value is assigned as the new environment for the input. When the new environment shows minimal changes compared to the old environment, we consider the environment partitioning to be complete. In Figure 3, we provide a detailed example to illustrate our environment partitioning method. When environment labels are available, we learn masks to extract semantic components, we firstly fix a simplex ETF classifier, and in different environments, for semantic features, we pull them all to the corresponding position of the same class prototypes, thus realizing the alignment operation.

The main contributions of this paper are summarized as follows:

* We explore the OOD problem from a new perspective, namely the use of neural collapse to guide feature alignment for OOD generalization.
* We explore the separation of semantic features and spurious features under conditions without environment labels, as well as with given environment labels.
* We conduct extensive experiments on four publicly available datasets to validate the effectiveness of the proposed methods.

## 2 Related Work

**Out-of-Distribution Generalization.** Out-of-distribution (OOD) generalization has been a topic of significant interest in the field of machine learning and computer vision. Researchers have explored various approaches and techniques to improve the robustness and generalization capabilities of models on unseen target domains. These OOD methods use different strategies to update the model, mainly including metalearning (Li et al., 2018; Zhang et al., 2023), domain alignment (Ajakan et al., 2014; Li et al., 2018), regularized training (Zhang et al., 2021; Krueger et al., 2021; Shi et al., 2021; Xu and Jaakkola, 2021), causal learning (Ahuja et al., 2021; Krueger et al., 2021; Koyama and Yamaguchi, 2020), etc. For example, IRM (Arjovsky et al., 2019), a representative OOD method, learns invariant representations with a classifier optimal to domain changes as a regularization term. SANDMask (Shahtalebi et al., 2021) regularizes model training by updating the parameters in the direction where the gradient components have consistent signs across domains. Although these OOD methods have theoretically and experimentally demonstrated their effectiveness in learning domain-invariant features, most of them require the use of environment labels, which does not meet the requirements of real-world applications. Furthermore, we empirically found that the information extracted by the last layer of the feature extractor based on the IRM-based method in different environments cannot be well-aligned. In this paper, taking a step forward, we propose a novel method that aligns the semantic features extracted by the OOD feature extractor to the same simplex ETF under neural collapse. Note that our method can be applied both with and without environment labels.

**Neural Collapse.** The phenomenon known as neural collapse, first identified by , refers to the observation that when the number of training samples across different classes is balanced, both the feature vectors in the final layer and the classifier vectors tend to converge to the simplex ETF upon the completion of training. Recently, several studies  have utilized this phenomenon to guide the training process in imbalanced data sets. Among them, Yang et al.  involves pre-allocating a fixed number of classes in a simplex ETF for continual learning, guiding the learning of minority classes in subsequent incremental steps, thereby ensuring convergence of intra-class features to specified positions and maximizing and uniformly separating inter-class features. Xie et al.  addresses class imbalance by designing a novel loss function, namely the attraction-rejection balanced loss. Li et al.  apples neural collapse into federated learning scenarios. Under distributed conditions, neural collapse is used to guide the alignment direction of each client, and the personality of each client model is maintained through fine-tuning. The aforementioned methods only consider collapsing the same class onto a single point in a fixed simplex ETF without accounting for the impact of intra-class spurious correlations. We are the first to utilize the concept of neural collapse to address spurious correlations within classes, thereby enhancing out-of-distribution (OOD) performance.

## 3 Preliminaries

### Out-of-Distribution Generalization

In the given dataset \(D:=(,)=\{(_{i},_{i})\}_{i=1}^{N}\), typically, during the training process, the data set \(D\) is divided into a training set \(D^{tr}\) and a test set \(D^{te}\), where \(D^{tr}\) is sampled from the training distribution \(_{tr}(,)\), and \(D^{te}\) is sampled from the test distribution \(_{te}(,)\). There is a model that can be divided into a feature extractor \(f(;_{f})\) and a classifier \(g(;_{g})\). For out-of-distribution (OOD) scenarios, the training distribution is not observable, and the training distribution differs from the test distribution, i.e., \(_{tr}(,)_{te}(,)\). Specifically, according to previous work, we have multiple environments in the training set, that is, \(=\{e_{1},e_{2},...,e_{E}\}\). In different environments, for

Figure 1: **Left Figure: A comparison between our approach and previous methods(conclude ERM and IRM-based methods). (a): The comparison of our method, the ERM method, and the IRM method based on the F-norm metric. (b): The comparison of our method, the ERM method, and the IRM method in terms of OOD accuracy (%).**

\(X\) in the training set, we can divide it into semantic parts and spurious parts, the correlation between these two is unstable, thus it is prone to generating spurious correlations.

### Neural Collapse

Neural collapse refers to a phenomenon observed during the final stages of training on balanced data (post-zero training error) . It reveals a simplex ETF structure formed by the last-layer features and the classifier, which can be defined as:

**Definition 1** (Simplex Equiangular Tight Frame).: _A simplex Equiangular Tight Frame (ETF) refers to a matrix that is composed of \(K\) vectors \(}\)\(R^{d}\), \(d K-1\) and satisfies:_

\[=}(_{K}- _{K}_{K}^{T}),\] (1)

_where \(=[_{1},_{2},...,_{K}] R^{d K}\), \( R^{d K}\) allows a rotation and satisfies \(^{T}=_{K}\), \(}\) represents identity matrix, and \(}\) stands for all one matrix._

_For any \(_{i},i[1,K]\) and satisfies:_

\[_{i}^{T}_{j}=_{i,j}-,  i,j[1,K],\] (2)

_where \(_{i,j}\) equals to 1 when \(i=j\), otherwise it is equal to 0, for all \(_{i} V,i=[1,K]\), there is the same L2 norm, and the inner product between any two vectors is \(-\)._

**Neural Collapse.** The phenomenon of neural collapse is guaranteed by the following four findings: variability collapse (**NC1**), convergence to the simplex equiangular tight frame (**NC2**), convergence to self-duality (**NC3**), and simplification to the nearest class center (**NC4**).

**NC1**: During the final stages of model training, the final layer feature vectors of the same class will collapse to the class mean, i.e., for all \(k\), \(_{W}^{k} 0\). \(_{W}^{k}=}_{i=1}^{n_{k}}(_{k,i}- _{k})(_{k,i}-_{k})^{T}\), where \(n_{k}\) represents the number of samples in class \(k\), \(_{k,i}\) denotes the feature obtained from the i-th sample of class \(k\), \(_{k}\) represents the mean feature of class \(k\).

**NC2**: The class means of all classes will converge to the vertices of a simplex ETF centered on the global mean, as defined in Definition 1, \(}_{k}=(_{k}-_{G})/\| _{k}-_{G}\|\), where \(_{G}=_{k=1}^{K}_{i=1}^{N_{k}}_{k,i}\) represents the global mean of the feature.

**NC3**: The feature prototypes centered on the global mean will align with the corresponding classifier weights, which means that the classifier weights converge to the same simplex ETF, i.e, \(}_{k}=_{k}/\|_{k}\|\), where \(_{k}\) represents the classifier weight for class \(k\).

**NC4**: Through the above points, it can be ensured that the network classifier converges to the nearest class center, i.e, \(_{k},_{k}=_{k} \|-_{k}\|\), where \(\) represents the features of the sample.

Figure 2: The overall framework of our method. **Left Figure:** Input information, including figure, label and environment. **Middle Figure:** In the scenario of unknown environments, the process of partitioning the environment. **Right Figure:** Utilizing neural collapse to guide learning of masks for extracting invariant components.

Methodology

In this section, we delve into a comprehensive discussion of our proposed method, NCFAL, along with its specific implementation. Section 4.1 outlines the framework of the proposed method for out-of-distribution based on neural collapse. We use a fixed ETF classifier to guide the alignment of invariant features across different environments, facilitating better learning of masks to separate invariant and variable features. In Section 4.2, we provide a detailed explanation of how environments are partitioned. In Section 4.3, we elaborate on how a fixed ETF classifier is used to guide mask learning. In Section 4.4, after obtaining invariant features using the trained mask, we input them into the neural network for subsequent training until convergence.

### The framework of proposed method

Neural collapse reveals the optimal geometric structure of the classifier and feature prototypes after sufficient training (i.e., the simplex ETF). It inspires us to use a simplex ETF as a fixed classifier from the beginning, guiding the alignment of invariant components across different environments. Therefore, we propose a novel algorithm for the OOD generation inspired by neural collapse, NCFAL. Specifically, as described in Section 4.2, in real-world scenarios, environment information is often unknown. Hence, we need to automatically partition environments, and when certain conditions are satisfied, we consider the environment to be sufficiently well-partitioned. As described in Section 4.3, to improve model generalization, after obtaining environment information, we guide the alignment of invariant components across environments using a fixed ETF classifier. Given that class imbalance is likely across different environments, we employ a loss function to mitigate the impact of this imbalance. We alternate between Section 4.2 and Section 4.3, enabling the model to learn improved masks for partitioning invariant components. In Section 4.4, after learning the mask, we obtain semantic features for subsequent training of the predictive model.

Specifically, as shown in Figure 2, our methodological framework is illustrated. Initially, when \(\) is input, it passes through \(-\) for the separation of variable components, allowing for prediction using corresponding models in different environments. Subsequently, an environment selection process assigns the input to a designated environment, yielding a new environment label. When the difference between the new environment label and the previous one is less than a given threshold or a specified number of partitioning iterations is reached, the mask learning process begins. In this phase, \(\) from different environments is input. Since invariant features are extracted, they should collapse onto the same simplex ETF in any environment. This approach guides the alignment of invariant features across variable environments.

### The implementation of environment partitioning

This chapter focuses on environment partitioning in scenarios where environment labels are unknown. The partitioning process relies on the intermediate module depicted in Figure 2, which takes the input information and outputs a new set of environments \(\), where each environment reflects a type of spurious correlation present in the input. We divide the input \(\) into semantic and spurious features, using the invariant mask \(\) to distinguish between them, resulting in semantic features \(()\) and spurious features \(()\): \(()=\), \(()=(-)\). Subsequently, the variable features \(()\) are input into local models, which are associated with the environments, for identification. We designed a two-stage partitioning method to iterative partition environments until convergence.

**Environment Local Model Learning Stage:** Let \(_{e}^{tr}\) be the interaction set in environment \(e\). We aim to use local model to represent the environment \(e\). Intuitively, the primary distinction between different environments lies in their interpretation of spurious correlations. Therefore, we model environments based on these spurious correlations. Specifically, for the interactions in environment \(e\), we predict using a variable representation learning model \(^{(e)}\). In other words, to describe environment \(e\), we learn the predictive model as follows:

\[_{_{e}}(^{(e)}(,|_{e})| _{e}^{tr}),\] (3)

where \(_{e}^{tr}\) represents the training data \(\) corresponding to environment \(e\), \(_{e}\) represents model parameters corresponding to environment \(e\).

Environment Partitioning Stage:In this stage, we have already developed environment models that can be used to assess the spurious correlations in different environments. Consequently, interactions should be separated based on these spurious correlations. To distinguish environments and the interactions within the input, we employ the following formula, which determines that an interaction belongs to the environment with the highest probability of identifying it. Note that predictions are based on the variable component \(()\), which represents spurious information. The maximum value of this tensor is selected, indicating that the variable features of the input are more distinguishable in the environment corresponding to the maximum value. Thus, the input is assigned to that environment.

\[e()=_{e}^{(e)}(,|_{e }),\] (4)

where for any environment \(e\), we select the one with the maximum logit as the corresponding environment for input \(\).

We illustrate this environment selection process with an example in Figure 3. Considering a logit 0 with orange background, when it is inputted into different environment models, the corresponding predictions are [0.5, 0.3, 0.2] in environment 1 and [0.4, 0.5, 0.1] in environment 2. By extracting the logits at the positions corresponding to the labels(one hot encoding), we obtain vectors [0.5, 0.4]. Taking the maximum value, we can determine the corresponding environment as environment 1.

### The implementation of learning masks

This chapter primarily addresses OOD generalization by learning masks to separate invariant representations when environment labels are known. Our approach is guided by the perspective of neural collapse to align invariant representations across environments to a pre-fixed simplex ETF. As shown in Figure 3, once a suitable environment partitioning mask is learned, we apply it to the input x to obtain the invariant components. Thus, in different environments, for the semantic features \(()\) in all \(e_{i},e_{j} supp()\), we have: \(^{e_{i}}(|())=^{e_{j}}(|())\).

In different environments, we use corresponding models to align the invariant features. First, we fix a standard simplex ETF as the alignment direction. Given the potential issue of the number of different classes imbalance across different environments, we use a balanced loss to assign weights proportional to the quantity of each class for the training process:

\[_{mask}=-^{}(_{y}^{ T})}{_{k}n_{e,k}^{}(_{k}^{T} )},k K,e,\] (5)

\[=}/\|}\|,}=P(,_{p}),=f((),_{f}),\]

where \(n_{e,k}\) represents the number of samples of class \(k\) in environment \(e\), \(_{k}\) represents the feature vector corresponding to class \(k\) on the fixed simplex ETF \(\), \(f\) represents the normalized feature \(}\) obtained after projection mapping the original feature \(\), \(\) represents the learnable temperature, \(\) represents the sample balancing parameter, \(_{f}\) represents the parameters of the feature extraction module in the model, \(_{p}\) represents the parameters of the mapping layer in the model. When learning the mask, we add some random noise to initialize the mask:

\[m_{i}=\{0,\{1,m_{i}+\}\}, N(0,^{2}),m_{i} .\]

Figure 3: A comprehensive elucidation of Figure 2 is provided herein. **Middle Figure:** An illustrative example is presented to demonstrate the process of environment partitioning. **Right Figure:** An in-depth exposition of the process of learning invariant masks is provided.

After completing the above training steps Eq.(5), we perform a clipping operation on the mask to fix the range of \(m_{i}\):

\[m_{i}=\{0,\{1,m_{i}+\}\},m_{i}.\]

### The implementation of learning predictive model

In this chapter, we apply the environment partitioning and mask learning in Sections 4.2 and 4.3 respectively to the input data to extract semantic features. These features are then fed into the predictive neural network for training until the network converges:

\[_{^{*}}(^{*}(,|^{*})| ^{tr}),\] (6)

where \(^{*}\) represents the parameters of the final predictive model.

Summarily, the overall training process is presented in Algorithm 1. The two steps in the **Splitting environments** process correspond to Section 4.2, while the **Learning mask** process corresponds to Section 4.3. After convergence, semantic features are used to train the predictive model, corresponding to Section 4.4, thereby achieving better OOD generalization.

``` Data:\(X^{tr}\) for splitting environments, learning mask and training process. Result: Predictive Model \(^{*}(^{*},)\) for the final predictive process. for\(i 1\) to \(T\)do /* Splitting environments if\(\) is unknownthen do for\(e\)do  Optimize \(^{(e)}\) via the local model training process on \(_{e}^{tr}\) in Eq. (3);  end for for\(e\)do  Compute \(_{e}^{tr}\) via the highest probability of identification as Eq. (4);  end whileConverged;  end for /* Learning mask */  do  Learn m via aligning feature prototypes to the fixed simplex ETF in Eq. (5); whileConverged;  end for /* Training process */  Optimize \(^{*}(^{*},)\) with semantic components \(()\) via Eq. (6); ```

**Algorithm 1** The overall training process.

## 5 Experiments

### Experiment Setup

**Datasets.** Following the work , we evaluate our method with baselines on benchmark datasets, using four datasets, namely ColoredMNIST, ColoredCOCO, COCOPlaces and NICO. **ColoredMNIST** is colorized on the MNIST dataset. The image dimensions were set to , the digits  are designated as category 0, while the digits  are designated as category 1. **ColoredCOCO** dataset is derived from the COCO dataset, which includes a selection of ten categories. Background color alterations were applied using ten different colors. All images are configured with dimensions of (3, 64, 64). **COCOPlaces** employs the same classes and settings as ColoredCOCO, with the distinction that we sample images from Places as spurious information. **NICO** dataset is a real-world dataset, including 10 subclasses for animals and 9 subclasses for vehicles. In total, our split consists of 4,080 samples of dimension (3, 224, 224) and 2 classes of the classification task. More details can be found in Appendix A.1. For each dataset, we partition it into two subsets, \(d_{1}\) and \(d_{2}\), based on the environment, with the ratio of sample quantities between \(d_{1}\) and \(d_{2}\) being 9:1. Subset \(d_{1}\) from the training environment is used for model training, while \(d_{2}\) is employed for testing the models within the training environment. In the testing environment, \(d_{1}\) is utilized to assess the out-of-distribution (OOD) performance of the models, while \(d_{2}\) is utilized according to DomainBed standards for selecting the best model.

**Architecture.** On ColorMNIST, training is conducted using a 4-layer convolutional neural network. For the ColoredCOCO and COCOPDaces datasets, we adhere to the setup outlined in Ahmed et al. (2020), Gulrajani and Lopez-Paz (2020), employing ResNet8 for training. On the NICO dataset, training is performed using ResNet18.

**Baselines.** In order to demonstrate the advantages and effectiveness of our approach, we conduct comparative tests against different OOD learning methods. including (1) IID learning: ERM (Vapnik et al., 1998) (2) OOD learning ( sixteen methods): IRM (Arjovsky et al., 2019), VREx (Krueger et al., 2021), ARM (Zhang et al., 2021), GroupDRO (Sagawa et al., 2020), MLDG (Li et al., 2018), MMD (Li et al., 2018), IGA (Koyama and Yamaguchi, 2020), SANDMask (Shahtalebi et al., 2021), Fish (Shi et al., 2021), CDANN (Li et al., 2018), TRM (Xu and Jaakkola, 2021), IB_ERM (Ahuja et al., 2021), IB_IRM (Ahuja et al., 2021), CondCAD (Ruan et al., 2021), CausIRL_CORAL (Chevalley et al., 2022), MAP (Zhang et al., 2023).

### The comparison of OOD accuracy (%) between our method and other approaches.

Table 1 presents a comparison between our method, the ERM algorithm, and 16 other OOD algorithms. It is evident that our approach outperforms all methods under the given environmental conditions. Moreover, in situations where the environment is unknown, our method demonstrates adaptive capabilities in partitioning the environment, achieving superior OOD performance. The reason behind this phenomenon, we believe, lies that sometimes manually partitioning the environment may not be optimal for neural networks to identify and discern spurious correlations, however, Utilizing neural networks to partition the environment based on predictions might be more adapt at separating semantic and spurious features. Particularly for COCOPDaces, due to the complexity of backgrounds, manual partitioning may not always achieve appropriate segmentation. Therefore, from the results, when the environment is known, the OOD accuracy is 33.3%; however, using our method for environment partitioning yields a result of 36.7%.

### Ablation Studies

**The comparison between other methods employing masking techniques and our method.** Table 2 presents the effectiveness of our proposed method for learning masks, we conducted comparisons with the IRM and REx methods, which incorporate regularization to facilitate learning of the mask through the gradient or variance. In contrast, our approach leverages the phenomenon of neural collapse to guide the optimization direction for semantic feature enhancement instead of regularization. Simultaneously, we compared our method with the ERM approach, confirming the superiority of using masks to acquire the invariant parts.

   & ColoredMNIST & ColoredCOCO & COCOPDaces & NICO \\  ERM (Vapnik et al., 1998) & \(51.5 0.1\) & \(45.4 0.9\) & \(20.1 0.7\) & \(73.6 1.9\) \\ IRM (Arjovsky et al., 2019) & \(60.3 2.8\) & \(49.2 0.3\) & \(27.1 0.9\) & \(75.8 2.0\) \\ VREx (Krueger et al., 2021) & \(52.9 1.2\) & \(48.8 0.7\) & \(26.2 0.7\) & \(76.9 0.7\) \\ GroupDRO (Sagawa et al., 2020) & \(38.5 1.5\) & \(49.1 0.6\) & \(26.9 0.6\) & \(74.6 2.4\) \\ MLDG (Li et al., 2018) & \(29.4 0.6\) & \(11.9 0.8\) & \(14.6 0.5\) & \(68.4 2.7\) \\ MMD (Li et al., 2018) & \(50.6 0.1\) & \(50.4 0.8\) & \(26.3 1.7\) & \(78.2 1.2\) \\ IGA (Koyama and Yamaguchi, 2020) & \(50.5 0.1\) & \(11.0 0.6\) & \(10.8 0.3\) & \(48.1 1.3\) \\ SANDMask (Shahtalebi et al., 2021) & \(58.6 6.5\) & \(49.2 1.2\) & \(25.9 1.4\) & \(72.8 1.5\) \\ Fish (Shi et al., 2021) & \(28.0 1.5\) & \(41.7 0.5\) & \(19.3 2.1\) & \(77.0 1.2\) \\ CDANN (Li et al., 2018) & \(41.7 3.5\) & \(38.4 1.5\) & \(19.4 1.0\) & \(72.8 1.8\) \\ TRM (Xu and Jaakkola, 2021) & \(44.2 5.0\) & \(47.5 0.6\) & \(24.8 1.1\) & \(73.0 0.9\) \\ IB_ERM (Ahuja et al., 2021) & \(50.2 0.2\) & \(45.4 1.1\) & \(20.2 1.0\) & \(77.7 1.9\) \\ CausIRL_CORAL (Chevalley et al., 2022) & \(28.7 1.3\) & \(51.5 1.1\) & \(26.1 1.1\) & \(75.7 0.9\) \\ CondCAD (Ruan et al., 2021) & \(49.2 0.5\) & \(41.2 0.7\) & \(20.8 0.3\) & \(73.9 1.4\) \\ IB_IRM (Ahuja et al., 2021) & \(53.8 1.8\) & \(33.9 0.6\) & \(14.8 2.3\) & \(70.2 2.2\) \\ ARM (Zhang et al., 2021) & \(28.1 0.0\) & \(33.0 0.6\) & \(25.1 0.2\) & \(76.4 1.6\) \\ MAP (Zhang et al., 2023) & \(52.6 0.5\) & \(50.9 1.3\) & \(26.9 1.0\) & \(76.8 1.4\) \\
**Ours** & **66.4 \(\) 0.2** & **58.0 \(\) 0.2** & **33.3 \(\) 1.7** & **85.4 \(\) 0.6** \\
**Ours (w/o env)** & **66.9 \(\) 2.4** & **56.9 \(\) 1.1** & **36.7 \(\) 0.9** & **85.9 \(\) 0.2** \\  

Table 1: Average accuracy (%) of OOD on three toy and one real datasets using different methods.

**The comparison between mask is applied at the pixel level and the feature level.** To validate the generality of our method, we conducted comparative experiments at both the pixel level and the feature level in Table 3. It was observed that sometimes extracting invariant features at the feature level could yield better results. In particular, improved performance was observed on the ColoredCOCO and COCOPlaces datasets. This phenomenon primarily stems from the fact that feature-level information is high-dimensional, capturing relationships that are difficult to discern.

**The comparison between randomly and using maximum likelihood probability method to split environments.** Compared with random environment splits in Figure 4(a), our method, which involves assigning different models to distinct environments and selecting maximum likelihood probabilities outputted by the models, was found to effectively partition environments.

**The comparison between different number of environment divisions.** Compared with different number of environment splits in Figure 4(b), we can find that when the number of divided environments is closer to the actual number of given environments, better performance is achieved, thereby validating the effectiveness of our environment division method.

## 6 Conclusion

We explore a new perspective to understand the inherent limitations of ERM and IRM-based methods, which fail due to the inability to align semantic features across environments, resulting in reduced generalization performance. By leveraging the phenomenon of neural collapse to guide the alignment of semantic features across environments. Compared to other OOD methods, we have significantly improved OOD performance. Moreover, in real-world scenarios where environment labels are unknown, our method addresses this by training local models to different environments, automatically achieving environment partitioning. This method greatly reducing the cost of manual annotation and expanding the applicability of our method. Additionally, we will investigate and improve more

   & ColoredMNIST & ColoredCOCO & COCOPlaces \\ 
**Ours** & **66.4 \(\) 0.2** & **58.0 \(\) 0.2** & **33.3 \(\) 1.7** \\
**Ours (w/o env)** & **66.9 \(\) 2.4** & **56.9 \(\) 1.1** & **36.5 \(\) 0.8** \\ REx & \(61.3 3.0\) & \(56.0 0.2\) & 27.4 \(\) 1.3 \\ REx (w/o env) & \(57.9 2.0\) & \(52.9 1.1\) & 28.2 \(\) 1.7 \\ IRM & \(64.4 0.2\) & \(51.8 0.8\) & 32.2 \(\) 0.8 \\ IRM (w/o env) & \(65.2 0.4\) & \(52.8 0.4\) & 30.7 \(\) 1.7 \\ ERM & \(51.5 0.1\) & \(45.4 0.9\) & \(20.1 0.7\) \\  

Table 2: The OOD accuracy (%) of our method and other regularization methods on three datasets.

Figure 4: Comparative experiments for randomly and the different number of divided environments.

effective and efficient environment partitioning techniques in future work. We can also explore applying this method in other domains, such as segmentation or few-shot spurious correlation issues.