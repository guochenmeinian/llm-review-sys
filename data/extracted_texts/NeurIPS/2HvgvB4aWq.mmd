# Differentiable Task Graph Learning:

Procedural Activity Representation and Online

Mistake Detection from Egocentric Videos

Luigi Seminara Giovanni Maria Farinella Antonino Furnari

Department of Mathematics and Computer Science, University of Catania, Italy

luigi.seminara@phd.unict.it,{giovanni.farinella,antonino.furnari}@unict.it

###### Abstract

Procedural activities are sequences of key-steps aimed at achieving specific goals. They are crucial to build intelligent agents able to assist users effectively. In this context, task graphs have emerged as a human-understandable representation of procedural activities, encoding a partial ordering over the key-steps. While previous works generally relied on hand-crafted procedures to extract task graphs from videos, in this paper, we propose an approach based on direct maximum likelihood optimization of edges' weights, which allows gradient-based learning of task graphs and can be naturally plugged into neural network architectures. Experiments on the CaptainCook4D dataset demonstrate the ability of our approach to predict accurate task graphs from the observation of action sequences, with an improvement of +16.7% over previous approaches. Owing to the differentiability of the proposed framework, we also introduce a feature-based approach, aiming to predict task graphs from key-step textual or video embeddings, for which we observe emerging video understanding abilities. Task graphs learned with our approach are also shown to significantly enhance online mistake detection in procedural egocentric videos, achieving notable gains of +19.8% and +7.5% on the Assembly101-O and EPIC-Tent-O datasets. Code for replicating the experiments is available at https://github.com/fpv-iplab/Differentiable-Task-Graph-Learning.

## 1 Introduction

Procedural activities are fundamental for humans to organize tasks, improve efficiency, and ensuring consistency in the desired outcomes, but require time and effort to be learned and achieved effectively. This makes the design of artificial intelligent agents able to assist users to correctly perform a task appealing . Achieving these abilities requires building a flexible representation of a procedure, encapsulating knowledge on the partial ordering of key-steps arising from the specific context at hand. For example, a virtual assistant needs to understand that it is necessary to break eggs before mixing them or that the bike's brakes need to be released before removing the wheel. Importantly, for a system to be scalable, this representation should be automatically learned from observations (e.g., humans making a recipe many times) rather than explicitly programmed by an expert.

Previous approaches focused on directly tackling tasks requiring procedural knowledge such as action anticipation  and mistake detection  without developing explicit representations of the procedure. Other works proposed neural models able to develop implicit representations of the procedure by learning how to recover missing actions , discover key-steps , or grounding them to video . A different approach  consists in representing the structure of a procedure in the form of a _task graph_, i.e., a Directed Acyclic Graph (DAG) in which nodes represent key-steps, and directed edges impose a partial ordering over key-steps,encoding dependencies between them (see Figure 1(a)).1 Graphs provide an explicit representation which is readily interpretable by humans and easy to incorporate in downstream tasks such as detecting mistakes or validating the execution of a procedure. While graphs have been historically used to represent constraints in complex tasks and design optimal sub-tasks scheduling , graph-based representations mined from videos , key-step sequences [39; 20] or external knowledge bases  have only recently emerged as a powerful representation of procedural activities able to support downstream tasks such as key-step recognition or forecasting [3; 44]. Despite these efforts, current methods rely on meticulously crafted graph mining procedures rather than setting graph generation in a learning framework, limiting the inclusion of task graph representations in end-to-end systems.

In this work, we propose a novel approach to learn task graphs from demonstrations in the form of sequences of key-steps performed by real users in a video while executing a procedure. Given a directed graph represented as an adjacency matrix and a set of key-step sequences, we provide an estimate of the likelihood of observing the set of sequences given the constraints encoded in the graph. We hence formulate task graph learning under the well-understood framework of Maximum Likelihood (ML) estimation, and propose a novel differentiable Task Graph Maximum Likelihood (TGML) loss function which can be naturally plugged into any neural-based architecture for direct optimization of task graph from data. Intuitively, our TGML loss generates positive gradients to strengthen the weights of directed edges \(B A\) when observing the \(<,A,,B,>\) structure, while pushing down the weights of all other edges in a contrastive manner (see Figure 1(b)). To evaluate the effectiveness of the proposed framework, we propose two approaches to task graph learning. The first approach, called "Direct Optimization (DO)", uses the proposed TGML loss to directly optimize the weights of the adjacency matrix, which constitute the only parameters of the model. The output of the optimization procedure is the learned graph. The second approach, termed Task Graph Transformer (TGT) is a feature-based model which uses a transformer encoder and a relation head to predict the adjacency matrix from either text or video key-step embeddings.

We validate the ability of our framework to learn meaningful task graphs on the CaptainCook4D dataset . Comparisons with state-of-the-art approaches show superior performance of both proposed approaches on task graph generation, with boosts of up to \(+16.7\%\) over prior methods. On the same dataset, we show that our feature-based approach implicitly gains video understanding abilities on two fundamental tasks : pairwise ordering and future prediction. We finally assess the usefulness of the learned graph-based representation on the downstream task of online mistake detection in procedural egocentric videos. To tackle this task, we observe that procedural errors mainly arise from the execution of a given key-step without the correct execution of its pre-conditions. We hence design an approach which uses the learned graph to check whether pre-conditions for the current action are satisfied, signaling a mistake when they are not, obtaining significant gains of +19.8% and +7.5% in the online mistake detection benchmark recently introduced in  on Assembly101  and EPIC-Tent , showcasing the relevance and quality of the learned graph-based representations.

Figure 1: (a) An example task graph encoding dependencies in a “mix eggs” procedure. (b) We learn a task graph which encodes a partial ordering between actions (left), represented as an adjacency matrix \(Z\) (center), from input action sequences (right). The proposed Task Graph Maximum Likelihood (TGML) loss directly supervises the entries of the adjacency matrix \(Z\) generating gradients to maximize the probability of edges from past nodes (\(K_{3},K_{1}\)) to the current node (\(K_{2}\)), while minimizing the probability of edges from past nodes to future nodes (\(K_{4},K_{5}\)) in a contrastive manner.

The contributions of this work are the following: 1) We introduce a novel framework for learning _task graphs_ from action sequences, which relies on maximum likelihood estimation to provide a differentiable loss function which can be included in end-to-end models and optimized with gradient descent; 2) We propose two approaches to task graph learning based on direct optimization of the adjacency matrix and processing key-step text or video embeddings, which offer significant improvements over previous methods in task graph generation and shows emerging video understanding abilities; 3) We showcase the usefulness of task graphs in general, and the learned graph-based representations in particular, on the downstream task of online mistake detection from video, where we improve over competitors. The code to replicate the experiments is available at https://github.com/fpv-iplab/Differentiable-Task-Graph-Learning.

## 2 Related Work

Procedure UnderstandingPrevious investigations considered different tasks related to procedure understanding, such as inferring key-steps from video in an unsupervised way [45; 47; 12; 4; 5; 11], grounding key-steps in procedural video [25; 9; 10; 27], recognizing the performed procedure , inferring key-step orderings [4; 5; 25; 10; 43], and procedure structure verification . Recently, task graphs, mined from video or external knowledge such as WikiHow articles, have been investigated as a powerful representation of procedures and proved advantageous for learning representations useful for downstream tasks such as key-step recognition and forecasting [44; 3].

Differently from previous works [28; 43], we aim to develop an explicit and human readable representation of the procedure which can be directly plugged in to enable downstream tasks , rather than an implicit representation obtained with pre-training objective [44; 28]. As a departure from previous paradigms which carefully designed task graph construction procedures [3; 44; 39; 20], we frame task prediction in a general learning framework, enabling models to learn task graphs directly from input sequences, and propose a differentiable loss function based on maximum likelihood.

Task Graph ConstructionA line of works investigated the construction of task graphs from natural language descriptions of procedures (e.g., recipes) using rule-based graph parsing [36; 10], defining probabilistic models , fine-tuning language models , or proposing learning-based approaches  involving parsers and taggers trained on text corpora of recipes [8; 42]. While these approaches do not require any action sequence as input, they depend on the availability of text corpora including procedural knowledge, such as recipes, which often fail to encapsulate the variety of ways in which the procedure may be executed . Other works proposed hand-crafted approaches to infer task graphs observing sequences of actions depicting task executions [20; 39]. Recent work designed procedures to mine task graphs from videos and textual descriptions of key-steps  or cross-referencing visual and textual representations from corpora of procedural text and videos .

Differently from previous efforts, we rely on action sequences, grounded in video, rather than natural language descriptions of procedures or recipes [35; 10] and frame task graph generation as a learning problem, providing a differentiable objective rather than resorting to hand-designed algorithms and task extraction procedures [20; 39; 3; 44].

Online Mistake Detection in Procedural VideosDespite the interest in procedural learning, mistake detection has been systematically investigated only recently. Some methods considered fully supervised scenarios in which mistakes are explicitly labeled in video and mistake detection is performed offline [37; 41; 30]. Other approaches considered weak supervision, with mistakes being labeled only at the video level . Finer-grade spatial and temporal annotations are exploited in  to build knowledge graphs, which are then leveraged to perform mistake detection. Recently, the authors of  proposed an online mistake detection benchmark incorporating videos from the Assembly101  and EPIC-Tent  datasets, as well as PREGO, an approach to online mistake detection in procedural egocentric videos.

Rather than addressing online mistake detection with implicit representations  or carefully designed knowledge bases , we design a simple approach which relies on learned explicit task graph representations. As we show in the experiments, this leads to obtain significant performance gains over previous methods, even when the predicted graphs are suboptimal, while best results are obtained with task graphs learned within the proposed framework.

Technical Approach

### Task Graph Maximum Likelihood Learning Framework

**Preliminaries** Let \(=\{K_{0}=S,K_{1},,K_{n},K_{n+1}=E\}\) be the set of key-steps involved in the procedure, where \(S\) and \(E\) are placeholder "start" and "end" key-steps denoting the _start_ and _end_ of the procedure. We define the task graph as a directed acyclic graph, i.e., a tuple \(G=(,,)\), where \(\) is the set of nodes (the key-steps), \(=\) is the set of possible directed edges indicating ordering constraints between pairs of key-steps, and \(:\) is a function assigning a score to each of the edges in \(\). An edge \((K_{i},K_{j})\) (also denoted as \(K_{i} K_{j}\)) indicates that \(K_{j}\) is a _pre-condition_ of \(K_{i}\) (for instance \(\)) with score \((K_{i},K_{j})\). We assume normalized weights for outgoing edges, i.e., \(_{j}w(K_{i},K_{j})=1 i\). We also represent the graph \(G\) as the adjacency matrix \(Z^{(n+2)(n+2)}\), where \(Z_{ij}=(K_{i},K_{j})\). For ease of notation, we will denote the graph \(G=(,,)\) simply with its adjacency matrix \(Z\) in the rest of the paper. We assume that a set of \(N\) sequences \(=\{y^{(k)}\}_{k=1}^{N}\) showing possible orderings of the key-steps \(\) is available, where the generic sequence \(y\) is defined as a set of indexes to key-steps \(\), i.e., \(y=<y_{0},,y_{t},,y_{m+1}>\), with \(y_{t}\{0,,n+1\}\). We further assume that each sequence starts with key-step \(S\) and ends with key-step \(E\), i.e., \(y_{0}=0\) and \(y_{m+1}=n+1\)2 and note that different sequences \(y^{(i)}\) and \(y^{(j)}\) have in general different lengths. Since we are interested in modeling key-step orderings, we assume that sequences do not contain repetitions.3 We frame task graph learning as determining an adjacency matrix \(\) such that sequences in \(\) can be seen as topological sorts of \(\). A principled way to approach this problem is to provide an estimate of the likelihood \(P(|Z)\) and choose the maximum likelihood estimate \(=*{arg\,max}_{Z}P(|Z)\).

Modeling Sequence Likelihood for an Unweighted GraphLet us consider the special case of an unweighted graph, i.e., \(\{0,1\}^{(n+2)(n+2)}\). We wish to estimate \(P(y|Z)\), the likelihood of the generic sequence \(y\) given graph \(Z\). Formally, let \(Y_{t}\) be the random variable related to the event "key-step \(K_{y_{t}}\) appears at position \(t\) in sequence \(y\)". We can factorize the conditional probability \(P(y|Z)\) as:

\[P(y|Z)=P(Y_{0},,Y_{|y|}|Z)=P(Y_{0}|Z) P(Y_{1}|Y_{0},Z)  P(Y_{|y|}|Y_{0},,Y_{|y|-1},Z).\] (1)

We assume that the probability of observing a given key-step \(K_{y_{t}}\) at position \(t\) in \(y\) depends on the previously observed key-steps (\(K_{y_{t-1}},,K_{y_{0}}\)), but not on their ordering, i.e., the probability of observing a given key-step depends on whether its pre-conditions are satisfied, regardless of the order in which they have been satisfied. Under this assumption, we write \(P(Y_{t}|Y_{t-1},,Y_{0},Z)\) simply as \(P(K_{y_{t}}|K_{y_{t-1}},,K_{y_{0}},Z)\). Without loss of generality, in the following, we denote the current key-step as \(K_{i}=K_{y_{t}}\), the indexes of key-steps _observed_ at time \(t\) as \(=(y,t)=\{y_{t-1},,y_{0}\}\), and the corresponding set of observed key-steps as \(K_{}=\{K_{i}|i\}\). Similarly, we define \(}=(y,t)}=\{0,,n+1\} (y,t)\) and \(K_{}\) as the sets of indexes and corresponding key-steps _unobserved_ at position \(t\), i.e., those which do not appear before \(y_{t}\) in the sequence. Given the factorization above, we are hence interested in estimating the general term \(P(K_{y_{t}}|K_{y_{t-1}},,K_{y_{0}})=P(K_{i}|K_{})\). We can estimate the probability of observing key-step \(K_{i}\) given the set of observed key-steps \(K_{}\) and the constraints imposed by \(\), following Laplace's classic definition of probability  as "the ratio of the number of favorable cases to the number of possible cases". Specifically, if we were to randomly sample a key-step from \(\) following the constraints of \(\), and having observed key-steps \(K_{}\), sampling \(K_{i}\) would be a favorable case if all pre-conditions of \(K_{i}\) were satisfied, i.e., if \(_{j}}Z_{ij}=0\) (there are no pre-conditions in unobserved key-steps \(K_{}\)). Similarly, sampling a key-steps \(K_{h}\) is a "possible case" if \(_{j}}Z_{hj}=0\). We can hence define the probability of observing key-step \(K_{i}\) after observing all key-steps \(K_{}\) in a sequence as follows:

\[P(K_{i}|K_{},)=}{}=(_{j}}_{ij}=0)}{_{h}}(_{j}}_{hj}=0)}\] (2)

where \(()\) denotes the indicator function, and in the denominator, we are counting the number of key-steps that have not appeared yet are "possible cases" under the given graph \(Z\). Likelihood \(P(y|Z)\) can be obtained by plugging Eq. (2) into Eq. (1).

Modeling Sequence Likelihood for a Weighted GraphTo enable gradient-based learning, we consider the general case of a continuous adjacency matrix \(Z^{(n+2)(n+2)}\). We generalize the concept of "possible cases" discussed in the previous section with the concept of "feasibility of sampling a given key-step \(K_{i}\), having observed a set of key-steps \(K_{}\), given graph \(Z\)", which we define as the sum of all weights of edges between observed key-steps \(K_{}\) and \(K_{i}\): \(f(K_{i}|K_{},Z)=_{j}Z_{ij}\). Intuitively, if key-step \(k_{i}\) has many satisfied pre-conditions, we are more likely to sample it as the next key-step. We hence define \(P(K_{i}|K_{},Z)\) as "the ratio of the feasibility of sampling \(K_{i}\) to the sum of the feasibilities of sampling any unobserved key-step":

\[P(K_{i}|K_{},Z)=|K_{},Z)}{_{h }}f(K_{h}|K_{},Z)}=}Z_ {ij}}{_{h}}_{j}Z_{hj}}\] (3)

Figure 2 illustrates the computation of the likelihood in Eq. (3). Plugging Eq. (3) into Eq. (1), we can estimate the likelihood of a sequence \(y\) given graph \(Z\) as:

\[P(y|Z)=P(S|Z)_{t=1}^{|y|}P(K_{y_{t}}|K_{(y,t)},Z)=_{t=1}^ {|y|}(y,t)}Z_{y_{t}j}}{_{h(y,t)}}_{j(y,t)}Z_{hj}}.\] (4)

Where we set \(P(K_{y_{0}}|Z)=P(S|Z)=1\) as sequences always start with the start node \(S\).

Task Graph Maximum Likelihood Loss FunctionAssuming that sequences \(y^{(i)}\) are independent and identically distributed, we define the likelihood of \(\) given graph \(Z\) as follows:

\[P(|Z)=_{k=1}^{||}P(y^{(k)}|Z)=_{k=1}^{| |}_{t=1}^{|y^{(k)}|}(y^{(k)},t)}Z_ {y_{t}j}}{_{h(y^{(k)},t)}_{j(y^{(k)},t)}Z _{hj}}.\] (5)

We can find the optimal graph \(Z\) by maximizing the likelihood in Eq. (5), which is equivalent to minimizing the negative log-likelihood \(- P(,Z)\), leading to formulating the following loss:

\[(,Z)=-_{k=1}^{|Y|}_{t=1}^{|y^{(k)}|} (y^{(k)},t)}{}Z_{y_{t}j}- {h(y^{(k)},t)\\ j(y^{(k)},t)}{}Z_{hj}\] (6)

where \(\) is a hyper-parameter. We refer to Eq. (6) as the _Task Graph Maximum Likelihood (TGML)_ loss function. Since Eq. (6) is differentiable with respect to all \(Z_{ij}\) values, we can learn the adjacency matrix \(Z\) by minimizing the loss with gradient descent to find the estimated graph \(=_{Z}(,Z)\). Eq. (6) works as a contrastive loss in which the first logarithmic term aims

Figure 2: Given a sequence \(<S,A,B,D,C,E>\), and a graph \(G\) with adjacency matrix \(Z\), our goal is to estimate the likelihood \(P(<S,A,B,D,C,E>|Z)\), which can be done by factorizing the expression into simpler terms. The figure shows an example of computation of probability \(P(D|S,A,B,Z)\) as the ratio of the “feasibility of sampling key-step D, having observed key-steps S, A, and B” to the sum of all feasibility scores for unobserved symbols. Feasibility values are computed by summing weights of edges \(D X\) for all observed key-steps \(X\).

to _maximize_, at every step \(t\) of each input sequence, the weights \(Z_{y_{i}j}\) of edges \(K_{y_{t}} K_{j}\) going from the current key-step \(K_{y_{t}}\) to all previously observed key-steps \(K_{j}\), while the second logarithmic term (contrastive term) aims to _minimize_ the weights of edges \(K_{h} K_{j}\) between key-steps yet to appear \(K_{h}\) and already observed key-steps \(K_{j}\). The hyper-parameter \(\) regulates the influence of the summation in the contrastive term which, including many more addends, can dominate gradient updates. As in other contrastive learning frameworks [29; 33], our approach only includes positives and negatives and it does not explicitly consider anchor examples.

### Models

Direct Optimization (DO)The first model aims to directly optimize the parameters of the adjacency matrix by performing gradient descent on the TGML loss (Eq. (6)). We define the parameters of this model as an edge scoring matrix \(A^{(n+2)(n+2)}\), where \(n\) is the number of key-steps, plus the placeholder start (\(S\)) and end (\(E\)) nodes, and \(A_{ij}\) is a score assigned to edge \(K_{i} K_{j}\). To prevent the model from learning edge weights eluding the assumptions of directed acyclic graphs, we mask black cells in Figure 2 with \(-\). To constrain the elements of \(Z\) in the \(\) range and obtain normalized weights, we softmax-normalize the rows of the scoring matrix to obtain the adjacency matrix \(Z=softmax(A)\). Note that elements masked with \(-\) will be automatically mapped to \(0\) by the softmax function similarly to . We train this model by performing batch gradient descent directly on the score matrix \(A\) with the proposed TGML loss. We train a separate model per procedure, as each procedure is associated to a different task graph. As many applications require an unweighted graph, we binarize the adjacency matrix with the threshold \(\), where \(n\) is the number of nodes. We also employ a post-processing stage in which we remove redundant edges, loops, and add obvious missing connections to \(S\) and \(E\) nodes.4

Task Graph Transformer (TGT)Figure 3 illustrates the proposed model, which is termed Task Graph Transformer (TGT). The proposed model can take as input either \(D\)-dimensional embeddings of textual descriptions of key-steps or \(D\)-dimensional video embeddings of key-step segments extracted from video. In the first case, the model takes as input the same set of embeddings at each forward pass, while in the second case, at each forward pass, we randomly sample a video embedding per key-step from the training videos (hence each key-step embedding can be sampled from a different video). We also include two \(D\)-dimensional learnable embeddings for the \(S\) and \(E\) nodes. All key-step embeddings are processed by a transformer encoder, which outputs \(D\)-dimensional vectors enriched with information from other embeddings. To prevent representation collapse, we apply a regularization loss encouraging distinctiveness between pairs of different nodes. Let \(X\) be the matrix of embeddings produced by the transformer model. We L2-normalize features, then compute

Figure 3: Our Task Graph Transformer (TGT) takes as input either \(D\)-dimensional text embeddings extracted from key-step names or video embeddings extracted from key-step segments. In both cases, we extract features with a pre-trained EgoVLPv2 model. For video embeddings, multiple embeddings can refer to the same action, so we randomly select one for each key-step (RS blocks). Learnable start (S) and end (E) embeddings are also included. Key-step embeddings are processed using a transformer encoder and regularized with a distinctiveness cross-entropy to prevent representation collapse. The output embeddings are processed by our relation head, which concatenates vectors across all \((n+2)^{2}\) possible node pairs, producing \((n+2)(n+2) 2D\) relation vectors. These vectors are then processed by a relation transformer, which progressively maps them to an \((n+2)(n+2)\) adjacency matrix. The model is supervised with input sequences using our proposed Task Graph Maximum Likelihood (TGML) loss.

pairwise cosine similarities \(Y=X X^{T}(T)\) as in . To prevent the transformer encoder from mapping distinct key-step embeddings to similar representations, we enforce the values outside the diagonal of \(Y\) to be smaller than the values in the diagonal. This is done by encouraging each row of the matrix \(Y\) to be close to a one-hot vector with a cross-entropy loss. Regularized embeddings are finally passed through a relation transformer head which considers all possible pairs of embeddings and concatenates them in a \((n+2)(n+2) 2D\) matrix \(R\) of relation vectors. For instance, \(R[i,j]\) is the concatenation of vectors \(X[i]\) and \(X[j]\). Relation vectors are passed to a transformer layer which aims to mine relationships among relation vectors, followed by a multilayer perceptron to reduce dimensionality to \(16\) units and another pair of transformer layer and multilayer perceptron to map relation vectors to scalar values, which are reshaped to size \((n+2)(n+2)\) to form the score matrix \(A\). We hence apply the same optimization procedure as in the DO method to supervise the whole architecture.

## 4 Experiments and Results

### Graph Generation

**Problem Setup** We evaluate the ability of our approach to learn task graph representations on CaptainCook4D , a dataset of egocentric videos of 24 cooking procedures performed by 8 volunteers. Each procedure is accompanied by a task graph describing key-steps constraints. We tackle task graph generation as a weakly supervised learning problem in which models have to generate valid graphs by only observing labeled action sequences (weak supervision) rather than relying on task graph annotations (strong supervision), which are not available at training time. All models are trained on videos that are free from ordering errors or missing steps to provide a likely representation of procedures. We use the two proposed methods in the previous section to learn \(24\) task graph models, one per procedure, and report average performance across procedures.

**Compared Approaches** We compare our methods with previous approaches to task graph generation, and in particular with MSGI  and MSG\({}^{2}\), which are approaches for task graph generation based on Inductive Logic Programming (ILP). We also consider the recent approach proposed in  which generates a graph by counting co-occurrences of matched video segments. Since we assume labeled actions to be available at training time, we do not perform video matching and use ground truth segment matching provided by the annotations. This approach is referred to as "Count-Based". Given the popularity of large language models as reasoning modules, we also consider a baseline which uses a large language model5 to generate a task graph from key-step descriptions, without any access to key-step sequences.6 We refer to this model as "LLM".

**Graph Generation Results** Results in Table 1 highlight the complexity of the task, with classic approaches based on inductive logic, such as MSGI, achieving poor performance (\(12.8\)\(F_{1}\)), language models and count-based statistics reconstructing only basic elements of the graph (\(55.0\) and \(60.6\)\(F_{1}\) for LLM and Count-Based respectively), and even more recent methods based on inductive logic and heuristics only partially predicting the graph (\(71.1\)\(F_{1}\) of \(MSG^{2}\)). The proposed Direct Optimization

   Method & Precision & Recall & F\({}_{1}\) \\  MSGI  & 11.9 & 14.0 & 12.8 \\ LLM & 52.9 & 57.4 & 55.0 \\ Count-Based  & 66.7 & 55.6 & 60.6 \\ MSG\({}^{2}\) & 70.9 & 71.6 & 71.1 \\  TGT-text (Ours) & 79.9 \(\)8.8 & 81.9 \(\)6.9 & 80.8 \(\)8.0 \\ DO (Ours) & **86.4 \(\)1.5** & **89.7 \(\)1.5** & **87.8 \(\)1.5** \\ Improvement & +15.5 & +18.1 & +16.7 \\   

Table 1: Task graph generation results on CaptainCook4D. Best results are in **bold**, second best results are underlined, best results among competitors are highlighted. Confidence interval bounds computed at \(90\%\) conf. for \(5\) runs.

   Method & Ordering & Fut. Pred. \\  Random & 50.0 & 50.0 \\  TGT-video & **77.3** & **74.3** \\ Improvement & +27.3 & +24.3 \\   

Table 2: We compare the abilities of our TGT model trained on visual features to generalize to two fundamental video understanding tasks, i.e., pairwise ordering and future prediction. Despite not being explicitly trained for these tasks, our model exhibits video understanding abilities, surpassing the baseline.

[MISSING_PAGE_FAIL:8]

highlights that the main failure modes are due to large imbalances between precision and recall. For instance, the Count-Based method achieves a precision of only \(4.8\) with a recall of \(85.7\) in predicting correct segments on Assembly101-O. In contrast, the proposed approach obtains balanced precision and recall values in detecting correct segments in Assembly101-O (\(98.2\)/\(83.4\)) and EPIC-Tent-O (\(94.1\)/\(93.5\)), and detecting mistakes in EPIC-Tent-O (\(33.3\)/\(5.7\)), while the prediction of mistakes on Assembly101-O is more skewed (\(46.7\)/\(90.4\)). Results based on action sequences predicted from video (bottom part of Table 3) highlight the challenging nature of the task when considering noisy action sequences (see Figure 4). While the explicit task graph representation may not accurately reflect the predicted noisy action sequences, we still observe improvements over previous approaches of \(+7.3\) and \(+1.3\) in average \(F_{1}\) score in Assembly101-O and EPIC-Tent-O. Remarkably, best competitors are still graph-based methods, such as \(MSG^{2}\) and the Count-Based approach, with significant improvements over the implicit representation of the PREGO model (\(32.5\) average \(F_{1}\) versus \(53.5\) of the proposed DO model). Also, in this case, we observe that graph-based methods tend to be skewed towards detecting correct action sequences. In this regard, our TGT model only achieves \(38.2\) in mistake \(F_{1}\) score, a drop in \(5.7\) points over the best performer, the Count-Based method, which, on the other hand, only achieves an \(F_{1}\) score of \(2.6\) when predicting correct segments.

## 5 Limitations

The proposed approach requires the availability of key-step sequences, a common assumption of works addressing other video understanding tasks [6; 22; 19; 17; 18]. While our method is applicable to any fully supervised video understanding dataset, future works should focus on overcoming such limitation and taking advantage of the vast amount of unlabeled video and textual data sets. While the proposed TGT method has shown promising results when trained directly on video features, the investigation of task graph learning in the absence of labeled key-step sequences is beyond the scope of this paper. We noted a reduced ability of our approach to work with noisy action sequences and a tendency to hallucinate pre-conditions, likely due to the limited expressivity of key-step sequences arising from videos showing the most common ways to perform a procedure. The performance of our designed system to detect mistakes is influenced by the quality of action recognition (see Figure 4). If the action recognition module fails to detect an action, the method may incorrectly signal a missing pre-condition. Conversely, if an action is falsely detected as performed, the method may fail to signal an actual mistake. Future improvements in online action recognition will enhance the robustness of our method. Furthermore, our approach does not explicitly model "optional"

    &  &  \\   & Avg &  &  &  &  &  \\  Method & F\({}_{1}\) & F\({}_{1}\) & Prec & Rec & F\({}_{1}\) & Prec & Rec & F\({}_{1}\) & F\({}_{1}\) & Prec & Rec & F\({}_{1}\) & Prec & Rec \\  Count-Based\({}^{*}\) & 26.0 & 9.2 & 4.8 & 85.7 & 42.8 & 97.8 & 27.4 & 56.6 & 92.5 & 92.8 & 92.2 & 20.7 & 20.0 & 21.4 \\ LLM\({}^{*}\) & 29.3 & 15.1 & 8.3 & 87.2 & 43.4 & 96.7 & 27.9 & 47.7 & 86.3 & 82.4 & 90.6 & 9.1 & 13.3 & 6.9 \\ MSGI\({}^{*}\) & 33.1 & 22.7 & 13.1 & 84.4 & 43.5 & 93.4 & 28.3 & 44.5 & 66.9 & 51.6 & 95.2 & 22.0 & 73.3 & 12.9 \\ PREGO\({}^{*}\) & 39.4 & 32.6 & 89.7 & 19.9 & 46.3 & 30.7 & 94.0 & 32.1 & 45.0 & 95.7 & 29.4 & 19.1 & 10.7 & 86.7 \\ MSG\({}^{2*}\) & 56.1 & 63.9 & 51.5 & 84.2 & 48.2 & 73.6 & 35.8 & 54.1 & 92.9 & 94.1 & 91.7 & 15.4 & 13.3 & 18.2 \\ 
**TGT-text (Ours)\({}^{*}\)** & 62.8 & 69.8 & 56.8 & 90.6 & 55.7 & 84.1 & 41.7 & **64.1** & **93.8** & 94.1 & 93.5 & **34.5** & 33.3 & 35.7 \\ DO (Ours)\({}^{*}\) & **75.9** & **90.2** & 98.2 & 83.4 & **61.6** & 46.7 & 90.4 & 58.3 & 93.5 & 94.8 & 92.4 & 23.1 & 200.0 & 27.3 \\ Improvement\({}^{*}\) & +19.8 & +26.3 & & & +13.4 & & & +7.5 & +0.9 & & & +12.5 & & \\  Count-Based\({}^{+}\) & 23.2 & 2.6 & 1.3 & 66.7 & **43.9** & 98.4 & 28.2 & 40.4 & 59.2 & 42.9 & 95.5 & 21.6 & 80.0 & 12.5 \\ LLM\({}^{+}\) & 28.1 & 15.1 & 7.8 & 65.5 & 42.3 & 89.5 & 27.7 & 35.9 & 61.6 & 46.7 & 90.4 & 10.2 & 40.0 & 5.8 \\ MSGI\({}^{+}\) & 28.4 & 14.0 & 7.8 & 67.9 & 42.7 & 90.7 & 28.0 & 40.4 & 59.2 & 42.9 & 95.5 & 21.6 & 80.0 & 12.5 \\ PREGO\({}^{+}\) & 32.5 & 23.1 & 68.8 & 13.9 & 41.8 & 27.8 & 84.1 & 29.4 & 41.6 & 97.9 & 26.4 & 17.2 & 9.5 & 93.3 \\ MSG\({}^{2+}\) & 46.2 & 59.1 & 51.2 & 70.0 & 33.2 & 44.5 & 26.5 & 45.2 & 67.5 & 52.4 & 95.1 & 22.9 & 73.3 & 13.6 \\  TGT-text (Ours)\({}^{+}\) & 53.0 & 67.8 & 62.3 & 74.5 & 38.2 & 46.2 & 32.6 & 43.8 & **69.5** & 55.8 & 92.1 & 18.2 & 53.3 & 11.0 \\ DO (Ours)\({}^{+}\) & **53.5** & **78.9** & 85.0 & 73.5 & 28.1 & 22.5 & 37.3 & **46.5** & 69.3 & 54.4 & 95.2 & **23.7** & 73.3 & 14.1 \\ Improvement\({}^{+}\) & +7.3 & +19.8 & & & -5.7 & & & +1.3 & +1.2 & & & +1.2 & & \\   

Table 3: Online mistake detection results. Results obtained with ground truth action sequences are denoted with \({}^{*}\), while results obtained on predicted action sequences are denoted with \({}^{+}\).

key-steps, which can lead to incorrect error signaling if optional steps are treated as mandatory. This issue could potentially be addressed through the integration of specialized modules capable of detecting optional nodes. Another limitation of task graph representations, both in this work and in prior approaches [3; 44; 39; 20], is their inability to explicitly model repeatable key-steps. Recent advancements such as  have introduced a "repeatable" node attribute to task graphs, but this extension is based on manual annotations, and the automatic learning of such attributes from data remains an open problem. Despite this limitation, the proposed error detection model demonstrates an ability to handle cases where key-steps may recur (e.g., spreading peanut butter). At test time, pre-conditions of key-steps are verified via the predicted task graph, even if a key-step has appeared earlier in the sequence. Nevertheless, more effective modeling of repeatable key-steps, especially in contexts where specific repetitions are required (e.g., "cut three slices of bread"), remains an important area for future research. Future work should explore methods for incorporating these requirements into task graph learning frameworks. Our method follows the setup of PREGO , which defines the Assembly101-O and EPIC-Tent-O datasets as curated versions of their originals to account for open-set procedural errors such as "order", "omission", "correction", and "repetition" mistakes. These are procedural mistakes, as distinguished from "proficiency errors" described in prior works . The proposed method focuses on procedural mistakes at the abstract level of executed actions, and thus, would not be directly applicable to proficiency error detection. In real-world systems, this limitation could be mitigated by integrating subsystems that specialize in detecting different types of errors. Developing an integrated approach that addresses both procedural and proficiency errors is a promising direction for future research.

## 6 Conclusion

We considered the problem of learning task graph representations of procedures from video demonstrations. Framing task graph learning as a maximum likelihood estimation problem, we proposed a differentiable loss which allows direct optimization of the adjacency matrix through gradient descent and can be plugged into more complex neural network architectures. Experiments on three datasets show that the proposed approach can learn accurate task graphs, develop video understanding abilities, and improve the downstream task of online mistake detection surpassing state of the art methods. We release our code at the following URL: https://github.com/fpv-iplab/Differentiable-Task-Graph-Learning.

Figure 4: To further investigate the effect of noise, we conducted an analysis based on the controlled perturbation of ground truth action sequences, with the aim to simulate noise in the action detection process. At inference, we perturbed each key-step with a probability \(\) (the “perturbation rate”), with three kinds of perturbations: insert (inserting a new key-step with a random action class), delete (deleting a key-step), or replace (randomly changing the class of a key-step). The plots show the trend of the F1 score (Average, Correct, and Mistake) as the perturbation rate increases in the case of Assembly101-O (left) and EPIC-Tent-O (right). Results suggest that the proposed approach can still bring benefits even in the presence of imperfect action detections, with the average F1 score dropping down \(10-15\) points with a moderate noise level of \(20\%\).

Acknowledgments

This research is supported in part by the PNRR PhD scholarship "Digital Innovation: Models, Systems and Applications" DM 118/2023, by the project Future Artificial Intelligence Research (FAIR) - PNRR MUR Cod. PE0000013 - CUP: E63C22001940006, and by the Research Program PIAno di inCEntivi per la Ricerca di Ateneo 2020/2022 -- Linea di Intervento 3 "Starting Grant" EVIPORES Project - University of Catania.

We thank the authors of  and in particular Alessandro Flaborea and Guido D'Amely for sharing the code to replicate experiments in the PREGO benchmark.