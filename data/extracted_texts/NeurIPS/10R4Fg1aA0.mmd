# Decoding the Enigma: Benchmarking Humans and

AIs on the Many Facets of Working Memory

 Ankur Sikarwar

Mengmi Zhang

Deep NeuroCognition Lab, Institute for Infocomm Research (I2R), A*STAR, Singapore

Center for Frontier AI Research (CFAR), Agency for Science, Technology, and Research (A*STAR), Singapore

School of Computer Science and Engineering, Nanyang Technological University, Singapore

Address correspondence to mengmi@i2r.a-star.edu.sg

###### Abstract

Working memory (WM), a fundamental cognitive process facilitating the temporary storage, integration, manipulation, and retrieval of information, plays a vital role in reasoning and decision-making tasks. Robust benchmark datasets that capture the multifaceted nature of WM are crucial for the effective development and evaluation of AI WM models. Here, we introduce a comprehensive **W**orking **M**emory (**W**or**M) benchmark dataset for this purpose. WorM comprises 10 tasks and a total of 1 million trials, assessing 4 functionalities, 3 domains, and 11 behavioral and neural characteristics of WM. We jointly trained and tested state-of-the-art recurrent neural networks and transformers on all these tasks. For comparison, we also include human behavioral benchmarks. Note that all computational models were never trained with any human data or behavioral biases; yet, these models remarkably replicate some characteristics of WM in biological brains, such as primacy and recency effects. Moreover, we performed neural population analysis on these models and identified neural clusters specialized for different domains and functionalities of WM. Not all computational models exhibit a strong alignment with all human behaviors. Our experimental results also reveal several limitations in existing models to match with working memory capabilities of humans. This dataset serves as a valuable resource for communities in cognitive psychology, neuroscience, and AI, offering a standardized framework to compare and enhance WM models, investigate WM's neural underpinnings, and develop WM models with human-like capabilities. Our source code and data are available at: link.

## 1 Introduction

Working memory (WM) defines a core cognitive process enabling temporary storage, integration, manipulation, and recall of information. It is vital for many downstream tasks involving reasoning , decision-making , and language comprehension . Understanding and modeling WM has significant implications for both neuroscience and AI research. In neuroscience and cognitive science, extensive investigations have been conducted to unravel the underlying mechanisms of WM. The non-exhaustive list of works involves (1) identifying brain regions such as the prefrontal cortex , hippocampus , and parietal cortex  as key players in WM processes; (2) exploring the role of WM capacity in cognitive processes such as selective attention , and executive control ; and (3) investigating how WM abilities differed in individuals of different ages , intelligence levels , and neurological disorders .

However, despite significant progress in individual subdomains, there remains a notable gap in the broader study of WM and its relevance for the AI community. To date, research efforts in neuroscience, and cognitive science have mostly focused on specific aspects of WM or individualmemory tasks. There is a lack of systematic, integrative, and quantitative exploration that covers multiple tasks, encompasses various functionalities and domains of WM, and provides a systematic benchmark for evaluating both humans and AI models in these memory tasks.

In this work, we aim to address this gap by establishing a general framework to study WM. To capture the multifaceted nature of WM due to its complexity, flexibility, and variability, we include 10 WM tasks and curate 1 million trials. Each of the state-of-the-art recurrent neural networks and transformer models is jointly trained and tested on these tasks with the following goals: (1) to assess model behaviors, such as set size effect and retention interval; (2) to investigate neural populations, such as task-specialized neural clusters and neural correlates of executive control; and (3) to examine and compare performance across multiple WM models when performing different memory functions: storage, integration, manipulation, and supervision. We include human performance on the WM tasks for behavioral comparison with AI models. In the experiments, we observe that AI models replicate some human-like characteristics of WM; however, we also identify several limitations in the existing WM models, such as disparities between human and model behaviors and inferior model performances in tasks that humans excel at. Through this interdisciplinary exploration, we strive to enhance our understanding of WM processes, uncover novel insights into the cognitive architecture of human WM, and propel the development of AI systems with more robust and human-like WM capabilities.

Main contributions are highlighted:

**1.** We introduce WorM, a comprehensive large-scale WM benchmark dataset, covering 10 WM tasks and containing 1 million trials, encompassing 4 functionalities and 3 domains of WM.

**2.** We introduce evaluation metrics for all our tasks and establish a general methodology to jointly train, study, and benchmark WM models on all tasks.

**3.** We explore 8 WM behavioral benchmarks and find that recurrent neural networks are more closely aligned with humans, while transformers exhibit limitations in replicating human behavior.

**4.** We examine the neural population of WM models. Our analysis reveals task-specialized neural clusters and uncovers neural correlates of executive control in WM models.

## 2 Related Works

Working memory (WM) has been a topic of interest in cognitive psychology and neuroscience for decades. Numerous studies [40; 24; 39; 35; 61; 3; 8] have investigated different behavioral effects and their underlying mechanisms and neural correlates. There has also been an interest [14; 42; 36; 43] in developing computational models of WM that can explain and approximate human behavior on WM tasks. Several WM tasks [16; 54; 13; 35; 41; 31] have been proposed to evaluate WM performance of humans. For example, the N-back task is a widely used WM task that requires participants to remember a sequence of stimuli and respond when a stimulus matches the one presented N trials earlier. It is important to emphasize that the majority of these prior works have typically focused on isolated aspects of working memory or evaluated a single working memory model with a restricted range of working memory tasks. In contrast, our contribution involves the development of a comprehensive and quantitative benchmark that encompasses 10 distinct working memory tasks, spanning four functionalities and three domains of working memory, for the evaluation of both human performance and AI models.

In the field of AI, WM has also attracted considerable attention. AI researchers have aimed to develop computational models that can emulate and augment human-like WM capabilities. Various memory architectures [10; 27; 25; 62; 56] have been proposed, such as neural networks with memory cells, recurrent neural networks, and memory-augmented neural networks. These models have demonstrated promising results in specific WM tasks, such as copying, sorting, and memory recalls, as well as real-world applications [22; 33], such as navigation in naturalistic environments, video recognition, and language processing.

Recently,  established a comprehensive working memory (WM) benchmark to aid in the development of WM theories by collecting empirical findings from previous human studies in a wide range of WM tasks. Different from their work, in this paper, we present a large-scale WMbenchmark dataset to bridge the gap between cognitive psychology and the AI field, allowing modern AI models to be trained on such WM tasks for direct behavioral and neural comparison.

## 3 Psychophysics Experiments in WorM

**Phase definitions in WM experiments.** In this section, we refer to our 10 WM tasks as 10 experiments. A WM experiment often consists of several but not necessarily all phases (**Fig. 1**) described below: *** Presentation phase (P\({}_{present}\))**: A sequence of stimuli to remember is presented sequentially. *** Retention phase (P\({}_{reent}\))**: A grey blank image is presented for a period of time, during which the remembered patterns in P\({}_{present}\) have to be maintained in the memory. *** Probing phase (P\({}_{probe}\))**: Responses to a series of questions asking to recall certain aspects of the memory content are required. Sometimes, there will be no questions but free recalls are required. *** Distractor phase (P\({}_{distractor}\))**: A series of other distracting tasks are presented in this phase to interfere with the original WM experiments. *** Memory updating phase (P\({}_{update}\))**: A series of instructions to update the memory content are given. *** Task switching phase (P\({}_{switch}\))**: A cue image is presented to signal the transition between a pair of tasks.

**Time steps in WM experiments.** The time duration of each phase in human psychophysics experiments is often measured in milliseconds (**ms**). However, computational WM models do not have the notion of time. We establish a mapping between the time step \(t\) in WM models and **ms** in human psychophysics experiments for all the phases of all the experiments (see **Appendix A2.2** for mapping details). For consistency, we describe all the main text with time steps \(t\). We introduce \(T\) to denote the total time steps for each experiment and \(T_{phase}\) to denote the total time steps of each phase, where \(phase\) could be from any of the phases introduced above. For example, \(T_{present}=3\)

Figure 1: **Schematic illustration of all 10 working memory tasks. Each panel illustrates the schematic for a different task. In each panel, the arrow pointing from left to right denotes the progression of time. Overlapping frames indicate multiple time steps whereas single frames represent a single time step in the trial. In F, we further divide the task into four types. Two types are shown here. See Sec. 3 for a detailed description of each task.**

indicates that there are 3 time steps for the presentation phase and t\({}_{present}=1\) indicates the first time step of the presentation phase.

**Nomenclatures in cognitive science and neuroscience.** In human psychophysics experiments , researchers often use **"length list"**, denoted as \(L\), to indicate the total number of stimuli presented during each P\({}_{present}\), and **"serial position"** to indicate the position of the \(l\)th stimulus in \(L\). For WM models, each stimulus is presented at each time step of P\({}_{present}\). Thus, \(L=T_{present}\) and t\({}_{present}=l\) denotes the \(l^{th}\) serial position during \(P_{present}\). Following psychology and neuroscience literature , we also define **"set size"**, denoted as \(S\), to be the total number of items that need to be held and manipulated in working memory at a given time step. For all the experiments, we use these terms interchangeably, and we also use "agents" to indicate that the test subjects can be both humans and computational WM models.

**Introduction to ten psychophysics experiments**

We introduce 10 psychophysics experiments on Working Memory (WM) from cognitive science and neuroscience . To facilitate comparisons with computational models, we directly copy the human behavioral data collected from these existing works to our paper. Based on WM functionalities these experiments entail (**Fig. 2b**), we categorize them into four functional groups: **(A)** memory storage, **(B)** memory integration, **(C)** memory manipulation, and **(D)** memory supervision. We also show the overview of the three WM domains (visual, spatial, and temporal) that each experiment involves in **Fig. 2a**. See **Appendix A1** for experimental details.

**Experiment A1 - Spatial Free Recall (SFR)  (Fig. 1A)**. At every t\({}_{present}\), a randomly chosen square on a green grid of size 10\(\)10 turns red. In P\({}_{probe}\), a blank grey image is shown. The task for the agent is to remember all the previous spatial locations where the squares turned red and provide a 100-way multi-label classification response.

**Experiment A2 - Change Detection (CD)  (Fig. 1B)**. In P\({}_{present}\), a memory array is shown, consisting of \(S\) bars with varying attributes such as color, orientation, size, and the presence/absence of a gap in each bar. Followed by a sequence of blank grey images in P\({}_{reten}\), the agents are tested with a probe array in P\({}_{probe}\), which can be identical to the memory array or have a single bar that differs along one feature dimension. The task for the agents is to make a binary prediction about whether there is a change or not given the test array.

**Experiment A3 - Visual Item Recognition (VIR)  (Fig. 1C)**. In P\({}_{present}\), a sequence of distinct \(6 6\) matrix patterns is displayed. In P\({}_{reten}\), a series of blank grey images is shown. In P\({}_{probe}\), a probe image is presented, consisting of two patterns side-by-side. One pattern matches a previously shown pattern, while the other is a distractor. The agents must perform a binary classification task, where \(0\) represents the left pattern and 1 represents the right pattern.

**Experiment A4 - Visual Serial Recall (VSR)  (Fig. 1D)**. In P\({}_{present}\), a sequence of \(L\) matrix patterns is sequentially presented. These patterns consist of a \(6 6\) grid with half of the cells filled in green. In P\({}_{probe}\), a probe image is displayed, containing all \(L\) patterns presented during P\({}_{present}\). Agents perform a 9-way classification task at each t\({}_{probe}\), recalling the matrix patterns seen at t\({}_{present}\) in a serial order. See **Appendix A3.1** for a language-based variant of this experiment.

Figure 2: **WorM covers a wide spectrum of working memory (WM) tasks encompassing 3 domains, 4 functionalities, and 11 characteristics. For all ten tasks, we categorize them based on their objectives in studying different (a) memory domains, and (b) memory functions. See Fig. 1 for task acronyms. In (c), we present word clouds representing the studied memory characteristics. Larger fonts indicate that more tasks (the exact number in brackets) produce results in this category.**

**Experiment A5 - Visual Serial Recognition (VSRC)  (Fig. 1E)**. P\({}_{present}\) is exactly the same as P\({}_{present}\) in the VSR experiment. Differences were introduced during P\({}_{probe}\). At each t\({}_{probe}\), a target pattern from P\({}_{present}\) and a distractor pattern were presented together. Distractor patterns were distinct from the initially presented matrix patterns and differed from the target pattern by \(n\) cells, where \(n\) denotes the pattern-distractor difference. Agents performed a binary classification task, with 0 indicating the left pattern and 1 indicating the right pattern.

**Experiment A6 - Complex Span (CS)  (Fig. 1F)**. The experiment includes two types of P\({}_{present}\) and P\({}_{probe}\), as well as two types of P\({}_{distractor}\). (I) The first type involves memorizing visual patterns and recalling them in order (visual). (II) The second type involves memorizing spatial patterns of ball movements and recalling their directions (spatial). Two types of P\({}_{distractor}\) are introduced to interfere with memory. (III) color discrimination tasks (visual) and (IV) spatial symmetry discrimination tasks (spatial) are used as distractors. Four variations of experiment conditions are considered: visual storage + visual distractor, spatial storage + visual distractor, visual storage + spatial distractor, and spatial storage + spatial distractor.

**Experiment B1 - Spatial Coordination (SC)  (Fig. 1G)**. P\({}_{present}\) involves a \(10 10\) grid where one cell is highlighted in green at each t\({}_{present}\). In P\({}_{probe}\), agents are presented with a blank gray image and asked to perform a binary discrimination task to determine whether the pattern formed by integrating all the patterns in P\({}_{present}\) is symmetric about the vertical axis or not.

**Experiment B2 - Spatial Integration (SI)  (Fig. 1H)**. P\({}_{present}\) involves sequentially presenting partial line drawings on a \(4 4\) grid, eventually completing a multi-segment figure. The number of line segments in the partial drawings determines the number of integration operations required, also equivalent to \(L\). In P\({}_{probe}\), agents perform a binary classification task to determine if the given figure matches the mentally integrated figure from P\({}_{present}\).

**Experiment C1 - Spatial Memory Updating (SMU)  (Fig. 1I)**. In P\({}_{present}\), a stimulus with green squares is presented, each containing a red marker in one of the nine possible locations on a 3\(\)3 grid. P\({}_{update}\) involves arrows indicating the direction for mentally updating the marker's location. In P\({}_{probe}\), agents perform a 9-way classification task to recall the marker's location in the highlighted square.

**Experiment D1 - Spatial Task Switching (STS)  (Fig. 1J)**. In P\({}_{switch}\), a cue image indicates the discrimination task for subsequent P\({}_{probe}\). There are two tasks across which to switch: top-versus-bottom and left-versus-right. At every P\({}_{probe}\), a red marker appears in a \(2 2\) grid, and agents switch between the two tasks based on cues presented during P\({}_{switch}\).

**Experimental trial splits for computational WM models.** For every WM psychophysics experiment introduced above, we generate 86,400 trials for training, 9,600 trials for validation, and 9,600 trials for testing by following a ratio of 9:1:1. These trials are distributed uniformly among various experimental conditions for individual experiments.

## 4 Computational Models of Working Memory

**Joint training and testing regime.** There exist multiple approaches to train and evaluate computational working memory (WM) models using our dataset, such as "train on many; test on one" and "train on one; test on one". However, our aim here is not to exhaustively benchmark WM models across all possible training and testing regimes. Instead, we aim to lay the foundation for a systematic and quantitative methodology to comprehensively study the multi-facets of WM. In this regard, we propose a joint learning paradigm where we simultaneously train and test different models on all conditions of all ten WM tasks. This approach allows us to explore the intricate interactions and inter-dependencies among the different WM tasks, capturing the complex nature of WM performance. For comparisons with the joint training regime, we also conduct single-task training on the VSR task. See **Appendix A3.3** for more details.

**Architectures for working memory models.** We investigate several state-of-the-art variations of recurrent neural networks, including vanilla recurrent neural networks (RNNs), Gated Recurrent Units (GRUs), and Long Short-Term Memory (LSTM) networks [10; 27]. Furthermore, considering the recent success of Transformers , we also include vanilla transformer-based encoders (TRF). Below, we introduce details of our model architectures (**Fig. 3**).

**Feature Extraction.** At each time step \(t\) of a trial, the visual stimulus \(I_{t}\) comes as a \(32 32 3\) tensor which is then fed to a 4-layer 2D-convolutional network (2D-ConvNet). See **Appendix A2.1** for the 2D-ConvNet architecture. The output feature maps from 2D-ConvNet are then flattened to a vector of dimension \(K\) and linearly projected to a feature representation \(F_{t}\) of dimension \(D\) using weight matrix \(^{K D}\). Different trials can be of different lengths, therefore we pad all the trials with blank images to ensure that all trials have a consistent length of 20.

**Task embeddings.** In addition to extracting stimuli features, we also introduce learnable task-specific embeddings \(M^{14 14}\), informing the network about the task identity during the joint training. At every \(t\) of each task, the corresponding task embedding is concatenated with the stimulus feature representation \(F_{t}\) from \(I_{t}\), resulting in a (14+D)-dimensional representation \(A_{t}\). \(A_{t}\) is further fed to various WM models introduced below for further processing. See **Appendix A2.1** for details.

**Encoding Time-dependent Representations.** As we have RNN-based networks and transformer-based networks to process stimuli sequences, we introduce their model designs separately. For RNNs, GRUs, and LSTMs, we use only one recurrent layer. The recurrent networks take (14+D)-dimensional representation \(A_{t}\) above as inputs for each \(t\). We define the capacity of these models \(C\) as the number of hidden units in this recurrent layer. At every \(t\), the recurrent networks output a hidden representation \(h_{t}\) of dimension C used for predicting task-specific responses.

For TRFs, we introduce extra learnable positional embeddings \(P^{20(14+D)}\) which is shared across all tasks. Each row of \(P\) indicates a "time step". At \(t^{th}\) time step, \(P_{t}\) is incorporated into \(A_{t}\) via element-wise addition. We denote this positional embedding-modulated stimulus feature representation as \(A_{TRF,t}\) which is then fed to the TRF. We include two standard transformer encoder blocks in TRF. We define the model's capacity \(C_{TRF}\) as the dimension \(14+D\) of the stimulus feature vector \(A_{t}\). Additionally, to simulate a more realistic scenario where the TRF model can only rely on past context to make predictions, we apply masking in the self-attention mechanism to prevent the model from accessing future information. We take the output \(h_{t,TRF}\) of TRF corresponding to the \(t^{th}\) time step and use it for predicting task-specific responses at \(t\).

**Response Generation.** The output of a WM network \(h_{t}\) or \(h_{t,TRF}\) is fed to a task-specific linear classifier with weight matrix \(O_{task}^{(14+D) U_{task}}\) for generating final probability distributions over a fixed set of all possible response choices in the corresponding task. Note that \(O_{task}\) is shared across all \(T\) time steps within the same task, but it is independent over different tasks. For example, in the VSR task, during P\({}_{probe}\), the WM model has to predict which pattern among the 9 shown patterns is the target pattern. In this case, \(U_{task}=9\), and the linear classifier outputs a probabilistic distribution of dimension 9, and the choice with the largest probability is the final response selected by the model.

Figure 3: **Overview of Working Memory (WM) models.** All WM models take a batch of stimuli in sequences from \(I_{t=1}\) to \(I_{t=T}\) as inputs and predict the task-specific responses at every single time step \(t\). These responses are compared against the batched and masked ground truths with classification losses. The gradients are only back-propagated based on the actual target values. For time steps without responses required (denoted as “NaN”), the predicted responses from the linear classifiers are not computed, and thus, no gradients are back-propagated. See legends for box notations. “shared” refers to learnable parameters shared jointly over tasks except for “task-specific shared” in linear classifiers, which refers to learnable weight parameters shared across time steps within the same task but different over tasks. See **Sec. 4** for model details.

**Training Details.** Practically, the WM models output responses for all \(T\) steps. However, training supervision with corresponding losses is only applied on the set of time steps where actual responses are required. All model parameters, including the feature extractors and WM networks, are initialized using Xavier initialization and trained from scratch. See **Appendix A2.1** for more training details and **Tab. A1** for hyper-parameter configurations.

**Comparison with humans.** To quantitatively compare computational models and humans on behavioral benchmarks, we introduce two types of scores: the slope difference score (\(A\)) and the average accuracy difference score (\(B\)). We presented the experimental details and the results in **Appendix A2.3**. We conducted statistical tests on the results. We found that the majority of the models are more consistent with humans than the chance model; however, there still exists performance discrepancies among different models and performance gaps between these models and humans.

## 5 Results and Analysis

We analyze multiple memory characteristics (**Fig. 2c**) individually for the corresponding tasks for different WM models. We use "model-\(C\)" to refer to the WM model of memory capacity \(C\). For example, LSTM-128 refers to the model with LSTM of memory capacity \(C=128\) as the backbone. As benchmarks, we copy the exact human performances here from [13; 35; 29; 4; 60; 41; 52; 44; 38] for direct comparison with WM models. Importantly, the WM models were not trained on human data or influenced by human biases. Therefore, our focus is not on comparing absolute performance disparities between humans and WM models. Instead, we aim to examine their qualitative trends across different conditions. Due to the extensive combinations of models and tasks, we present a condensed selection of results for some models in this section. See **Appendix A4** for the expanded result analysis with all model variations in these experiments. For fair comparisons among different model architectures in terms of overall WM performance, we compare different architectures with either the same memory capacity sizes \(C\) or the same number of network parameters. In both comparisons, we observe that recurrent networks like LSTMs and GRUs perform better than transformers on different working memory tasks (refer **Appendix A4** for more details).

**A. Primacy and recency effect across list lengths is an emergent phenomenon.** We report the top-1 accuracy as a function of serial positions across various list lengths \(L\) for LSTM-256 in the VSR task (**Sec. 3**, **Fig. 4A**). We make several observations. Firstly, as \(L\) increases, the memory load in WM also increases, resulting in a decrease in overall accuracy across different list lengths (indicated by the varying colors of the lines, from blue to brown). Secondly, our findings in WM models align with the well-known cognitive science and neuroscience phenomena of the primacy and recency effects. These effects demonstrate that items presented at the beginning (primacy) and end (recency)

Figure 4: **Performance benchmarks and behavioral analysis for working memory models and humans. We present the behavioral accuracy as a function of (A) list lengths \(L\) for LSTM-256 in VSR task, (B) retention interval in VIR task, (C) memory domain conflicts for LSTM-1024 in CS task, (D) set sizes \(S\) in SMU task, (E) memory resolution \(n\) in VSRC task, and (F) number of features or conjunctions of features per item in CD task. See Sec. 3 for all the task introductions. See Sec. 5 for the analysis of these results.**of a trial are better retained than those presented in the middle. This pattern holds true across different \(L\) values, indicating that the primacy and recency effects are an emergent phenomenon in our WM model. Thirdly, we observed an asymmetry in the strength of the primacy and recency effects, with the primacy effect being more prominent than the recency effect. This is evident when comparing accuracy at positions 1 and 9 for \(L\) = 9. Furthermore, the primacy and recency effects become more pronounced with longer list lengths \(L\), suggesting that these effects are more prominent when the memory load is high. For instance, the effects are minimal for \(L\) = 3 but become significant for \(L\) = 7. Fifthly, we compared the behaviors of WM models with humans and found that, though the models were never trained on human data, they approximate human-like qualitative trends in the primacy and recency effects across different serial positions and \(L\) values.

Furthermore, we conduct three ablations on VSR task to validate if these findings generalize across modalities, longer list lengths, and training paradigms. First, we report results for LSTM-256 in the Language Serial Recall (LSR) task, which is a language-based variant of the VSR task (**Appendix A3.1**, **Fig. A2B**). Secondly, we experiment with the LSR task containing trials with even longer list lengths (**Appendix A3.2**, **Fig. A2C**). Thirdly, instead of a joint training regime on all the tasks, we conduct individual training of a model only on the VSR task (**Appendix A3.3**, **Fig. A2A**). In all ablations, we observe similar primacy and recency effects suggesting that these findings are general across different modalities, longer list lengths, and various training paradigms. To further explore the underpinning mechanism attributing to intriguing and emergent primacy and recency behaviors in computational models, we expanded our discussions in **Appendix A4.2**.

**B. Short retention intervals have minimal effects on working memory.** We report the accuracy as a function of serial positions under the conditions of different retention intervals in the VIR task (**Sec. 3**, **Fig. 4B**). Aligning with human results, we observe that short retention intervals have minimal effects on WM performances, as indicated by the small performance gap between \(T_{reentent}\) of 0 and 5 (blue versus orange lines). It is possible that the effect might be more dramatic with longer retention intervals. Moreover, same as **Fig. 4A**, here, we noted that there also exists a small recency effect for both models and humans. In particular, the effect is slightly stronger in \(T_{reentent}=5\) than \(T_{reentent}=0\). However, this effect is less prominent than the ones observed in **Fig. 4A**, probably due to the short \(T_{reentent}=5\) or the small list length.

Moreover, we experimented on retention intervals of 2, 4, and 6 (shown in **Appendix A3.5**). We observed similar results as **Fig. 4B** with no significant performance differences across various short retention intervals (**Fig. A3**).In addition to the duration of retention intervals, we also studied the effect of the stimulus complexity during P\({}_{reentent}\) on the working memory performances. We introduced a variant of the Change Detection (CD) task where we replaced gray images with random noise images (see **Appendix A3.4** for more details).

**C. Domain conflicts and increased cognitive loads impair working memory performances.** To investigate whether domain conflicts would impair WM performance, we report accuracy in the CS task as a function of cognitive loads in different conditions involving combinations of visual and spatial domains (**Sec. 3**, **Fig. 4C**). In humans, regardless of the domain of the distractor task, we observe a monotonic decrease in accuracy with increasing cognitive load. This suggests that WM performance is impaired due to the cognitive load imposed by the distractor tasks, rather than the specific domain of the distractor task itself. However, in the WM model, we observe a decrease in accuracy only when the distractor task is of the spatial domain, implying that our spatial distractor task introduces a higher cognitive load than the visual distractor task, thereby hurting WM performance.

**D. Monotonic decrease in accuracy with increasing set size.** We report the agent's accuracy as a function of set sizes \(S\) in SMU task (**Sec. 3**) in **Fig. 4D**. For recurrent models, the recall accuracy monotonically decreases with increasing set sizes. For different recurrent backbones with the same memory capacities, GRU outperforms LSTMs and RNNs (compare GRU-96 vs RNN-96 vs LSTM-96). Moreover, for the same recurrent backbone, larger memory capacity enhances overall recall accuracy across all set sizes (RNN-96 vs RNN-256). Humans show a similar qualitative set size effect as recurrent models. In contrast, TRF-96 shows an opposite trend to humans and recurrent models, with increased accuracy as a function of increasing set size initially. Also, note that TRF-96 outperforms other RNN models in recall accuracy at set size 8 even with smaller memory capacity (e.g. RNN-256).

**E. Working memory stores fine-grained details of visual patterns.** We report the accuracy as a function of serial positions over various pattern-distractor differences \(n\) in VSRec (**Sec. 3**, **Fig. 4E**).

Intuitively, as it becomes easier to discern the differences between the correct pattern and the distractor, the more accurate it is to recall the correct patterns. Indeed, we see an increase in overall accuracy for bigger \(n\). This trend is similar to human results. Moreover, as also observed in **Fig. 4A**, we see a primacy effect on both WM models and humans, where the accuracy is highest at position 1 and slowly decreases over subsequent positions. Interestingly, despite the difficulty of VSRec, for both humans and the models, the accuracy of recalling 36 cells correctly from the distractors with only 2 cell differences is still way above chance. This suggests that both humans and WM models are very good at memorizing fine-grained details of complex patterns.

**F. Memory capacity is independent of the features or conjunctions of features.** We study the capacity for storing different features and conjunctions in the CD task based on the agent's accuracy over set sizes under different feature conditions (**Sec. 3**, **Fig. 4F**). Humans display minimal accuracy differences across feature conditions, suggesting that memory capacity is independent of specific features or feature combinations. Similarly, WM models exhibit comparable accuracy regardless of feature conditions. However, caution is advised in interpreting model results, as accuracy saturates at 100% regardless of set size, likely due to overfitting. To draw stronger conclusions, further investigation in a low-data regime using our trials is needed.

**G. Neural population carries active task representation in task-switching experiment.** In STS task (**Sec. 3**), we present the visualization results of clusters based on neural activation of all hidden units across all trials and all conditions for LSTM-1024 in **Fig. 5A**. Specifically, we first take the hidden representation during P\({}_{probe}\) for all the trials within the task and then perform t-SNE  to project the hidden representation to 2D. On the left panel in **Fig. 5A**, we color-code the points based on the ground truth at that particular t\({}_{probe}\). In this case, we did not observe distinct colored clusters whereas when we color-coded the points based on the task that was supposed to be performed at t\({}_{probe}\), we observe two distinct colored clusters. In other words, the neural representations in the recurrent model encode task identities within a task-switching paradigm, thus playing a supervisory role. See **Appendix A4.3** for more details.

**H. Responses from neural populations reveal task selectivity during joint training.** To study the task-specialized neural clusters in recurrent models, we present the visualization results in **Fig. 5B-D**. See **Appendix A4.4** for the steps to obtain and interpret the visualization results. From **Fig. 5B, C**, we observed 8 distinct neural clusters and each neural cluster is selective to a different set of tasks.

Figure 5: **Visualization of neural correlates and task-specialized neural clusters** (A) For LSTM-1024 in STS task, the visualization results of neural clusters based on response behaviors (left) and task identities (right) are presented. See **Sec. 5G** for details. In (B), we present the t-SNE visualization of neural clusters based on Task Variance (TV) of all hidden units in LSTM-256 over all 10 tasks. In (C), we present the neural selectivity of all hidden units for all the tasks. The neural selectivity is defined as TV values. All hidden units from left to right are sorted based on the clusters in (B). See the colorbar for TV values. In (D), we present the matrix of histogram plots for any pairs of tasks, where each histogram indicates the number of hidden units more selective to one task over the other. The selectivity for each hidden unit over a pair of tasks is defined as the fractional task variance (FTV). The x-axis and the y-axis of the histogram denote the FTV and the frequency of hidden units respectively. See **Sec. 5H** for details.

For example, cluster 4 specializes in the SFR task, while cluster 6 is active in temporal domain tasks like VSR and VSRec. We also note that clusters of neurons mostly emerge in networks of lower capacity with memory constraints. From **Fig. 5D**, we show diverse neural populations where some have preferences for one task over the other, while some are equally active in both tasks. For instance, the entry in row 1, and column 5 indicates that the majority of hidden units are more selective to SC task compared with STS, as the distribution of neural population shifts to the right with the majority of the neurons having FTV = 1. Additionally, we conduct experiments where we lesion specific neural clusters to investigate causal evidence. As expected, we observe the corresponding performance drops in the accuracy of specific tasks depending on the neural cluster that has been lesioned (shown in **Fig. A6**). See **Appendix A4.5** for details.

## 6 Discussion

Despite significant research progress in studying individual aspects of working memory (WM), there remains a huge gap in the broader study of WM. We take initial steps in this direction by establishing a systematic and quantitative methodology to study the multi-facets of WM. However, it is important to recognize that we are still at the preliminary stage in a broader exploration of WM. The complexity, flexibility, and variability of WM present numerous avenues for future research. These avenues may involve refining the temporal alignment between human performance and model predictions, fine-tuning task difficulty across experiments by introducing variations in experimental parameters, experimenting with different training and testing methods, investigating the models' generalization abilities across a broader spectrum of tasks and modalities, and extending benchmarking experiments to include bio-inspired working memory models.

In our work, we introduce a comprehensive benchmark dataset consisting of 10 tasks, and 1 million trials covering 4 functionalities and 3 domains of WM. Moreover, we benchmark WM models and humans on the 10 tasks and compare their 11 memory characteristics at the behavioral, performance, and neural levels with a set of newly introduced evaluation metrics. We obtained insights about the underlying mechanism of WM from these tasks and identified the limitations in existing WM models.

It is worth noting that all the models were never trained with any human data or behavioral biases. Yet, these models still remarkably exhibit interesting alignments with human behaviors, such as in dependency on set sizes, pattern similarities, and primacy and recency effects. We report the top-1 accuracy for each condition in all the experiments; however, caution is needed when comparing the absolute performances between WM models and humans for multiple reasons: (1) differences in the concept of time, with humans perceiving time continuously in seconds while AI operates in discrete time steps; (2) varied learning mechanisms, including Hebbian learning in biological systems and back-propagation in AI; (3) distinct neuronal mechanisms between artificial and biological neurons, such as synaptic plasticity and structural plasticity; (4) disparities in the visual diets fed to humans and AI models, with humans exposed to video streams and AI models working with random static images; and (5) constraints on memory capacity varying between humans and AI models.

Our work contributes a suite of tools with detailed documentation for stimulus synthesis and parameter configurations in psychophysics experiments, training and testing state-of-the-art working memory models, evaluating model behaviors and neural responses, and comparing behavioral consistency between humans and models. This methodology serves as a valuable resource for comprehensive investigations into working memory, fostering advancements in both biological and artificial intelligence systems.