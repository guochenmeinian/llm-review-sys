# 3D Equivariant Pose Regression via Direct Wigner-D Harmonics Prediction

Jongmin Lee

The current affiliation of Jongmin Lee is with LG AI Research. Contact: jongminlee@lgresearch.ai.

Minsu Cho

Pohang University of Science and Technology (POSTECH), South Korea

{ljm1121, mscho}@postech.ac.kr

http://cvlab.postech.ac.kr/research/3D_EquiPose

###### Abstract

Determining the 3D orientations of an object in an image, known as single-image pose estimation, is a crucial task in 3D vision applications. Existing methods typically learn 3D rotations parametrized in the spatial domain using Euler angles or quaternions, but these representations often introduce discontinuities and singularities. SO(3)-equivariant networks enable the structured capture of pose patterns with data-efficient learning, but the parametrizations in spatial domain are incompatible with their architecture, particularly spherical CNNs, which operate in the frequency domain to enhance computational efficiency. To overcome these issues, we propose a frequency-domain approach that directly predicts Wigner-D coefficients for 3D rotation regression, aligning with the operations of spherical CNNs. Our SO(3)-equivariant pose harmonics predictor overcomes the limitations of spatial parameterizations, ensuring consistent pose estimation under arbitrary rotations. Trained with a frequency-domain regression loss, our method achieves state-of-the-art results on benchmarks such as ModelNet10-SO(3) and PASCAL3D+, with significant improvements in accuracy, robustness, and data efficiency.

## 1 Introduction

Predicting the 3D pose of objects, i.e., position and orientation, in 3D space from an image is crucial for numerous applications, including augmented reality , robotics [4; 5; 63; 69], autonomous vehicles [21; 50], and cryo-electron microscopy . Estimating 3D orientation is particularly challenging due to rotational symmetries and the non-linear nature of rotations. In addition, unlike translations, rotations introduce unique challenges such as gimbal lock and the requirement for continuous, singularity-free representations. Existing methods often learn 3D rotations using spatial domain parameterizations like Euler angles, quaternions, or axis-angle representations, as illustrated in Figure 1. However, these parameterizations suffer from issues such as discontinuities and singularities [54; 58; 80], which can hinder the performance and reliability.

Figure 1: **Types of representations for 3D rotation prediction.** Existing methods consider predicting 3D rotations in the spatial domain. Our method predicts Wigner-D coefficients in the frequency domain, to obtain accurate pose in continuous space using an SO(3)-equivariant network.

SO(3)-equivariance enables accurate 3D pose estimation and improves generalization to unseen rotations. It ensures that outputs consistently change with the 3D rotation of the input, maintaining rotational consistency between the input and output across network layers. Despite its importance, many existing methods [3; 44; 52; 75; 80] often design networks without considering SO(3)-equivariance, resulting in suboptimal performance when dealing with 3D rotations. In addition, in the context of spherical CNNs [9; 10; 12; 16; 17; 18; 36] for efficient SO(3)-equivariant operations, the 3D rotation parametrization in the spatial domain is inadequate because these SO(3)-equivariant networks operate in the frequency domain.

To address these challenges, we propose an SO(3)-equivariant pose harmonics regression network that directly predicts Wigner-D coefficients in the frequency domain for 3D rotation regression. Building on prior work [28; 35], our method leverages the properties of spherical CNNs , which operate in the frequency domain, to guarantee SO(3)-equivariant output representation. By directly regressing Wigner-D matrix coefficients, our approach eliminates the need to convert outputs into spatial representations during training, ensuring alignment with the operations of spherical CNNs. This design allows us to bypass the limitations inherent in traditional spatial parameterizations--such as discontinuities and singularities [54; 58; 80]--resulting in more precise and continuous pose estimation. We further introduce a frequency-domain MSE loss to enable continuous training of 3D rotations, with the flexibility to incorporate distributional losses  for effectively capturing rotational symmetries in objects. Our method achieves state-of-the-art performance on standard single object pose estimation benchmarks, including ModelNet10-SO(3) and PASCAL3D+, demonstrating high sampling efficiency and strong generalization to unseen 3D rotations.

## 2 Related Work

**SO(3) pose regression.** The choice of rotation representation is a fundamental aspect of the current SO(3) pose estimation methods. In the early stages of deep learning, methods for SO(3) pose regression choose the rotation representation by direct cosine matrices [29; 73], Euler angles [37; 48; 49; 60; 61], quaternions [5; 13; 31; 32; 70; 78], and axis-angles [14; 20; 62]. However, according to , for any representation \(R\) in a Euclidean space of dimension \(d 4\), such as Euler angles and quaternions, \(R\) is discontinuous and unsuitable for deep learning. In addition, Euler angles can cause gimbal lock, which restricts certain rotations, whereas quaternions avoid this issue but their double representation of rotations in SO(3) can lead to complications such as local minima in optimization problems. As an alternative, a continuous 6D representation with Gram-Schmidt orthonormalization  and 9D representation with singular value decomposition (SVD) [8; 41] have been proposed, and  proposes manifold-aware gradient layer to facilitate the learning of rotation regression. Denoising diffusion models are employed in the context of SO(3) pose regression , or for solving pose estimation by aggregating rays . In contrast to existing SO(3) pose regression methods that formulate rotation representations in the spatial domain, we define the Wigner-D coefficients as the output of the network in the frequency domain, using SO(3)-equivariant networks.

**Pose estimation with a parametric distribution.** To model rotation uncertainty, parametric distributions on the rotation manifold are employed in a probabilistic manner.  predicts parameters of a mixture of von Mises distributions over Euler angles using Biterion networks. [5; 13; 23] utilize the Bingham distribution over unit quaternions to generate multiple hypotheses of rotations. [51; 74] leverage the matrix Fisher distribution  to construct a probabilistic model for SO(3) pose estimation. Additionally,  propose the Rotation Laplace distribution for rotation matrices on SO(3) to suppress outliers, and the Quaternion Laplace distribution for quaternions on \(^{3}\). Nevertheless, parametric models rely on predefined priors. In contrast, our model uses non-parametric modeling during inference to capture more complex pose distributions.

**Pose estimation with a non-parametric distribution.** Probabilistic pose estimation can also be achieved by predicting non-parametric distributions. IPDF  introduces the estimation of arbitrary, non-parametric distributions on SO(3) using implicit functions with MLPs, and HyperPosePDF  uses hypernetworks to predict implicit neural representations by Fourier embedding. ExtremeRotation  predicts discretized distributions over \(N\) bins for relative 3D rotations trained with cross-entropy loss. RelPose [43; 77] uses an energy-based formulation to represent distributions over the discretized space of SO(3) relative rotation. Several SO(3)-equivariant modeling methods construct non-parametric distributions by utilizing icosahedral group convolution , projecting image features orthographically onto a sphere , and satisfying consistency properties of SO(3)by translating them into an SO(2)-equivariance constraint . RotationNormFlow  uses discrete normalizing flows to directly generate rotation distributions on SO(3). These non-parametric methods, which are trained with loss functions in discretized distributions, such as cross-entropy and negative log-likelihood, tend to lose precision in rotation prediction. In contrast, our method predicts continuous SO(3) transformations through regression, eliminating the need to approximate SO(3) poses within a discretized space and enabling our model to achieve accurate 3D rotations.

## 3 Preliminary

### Representations of Rotations

**Rotation representation in spatial domain.** In 3D rotation, Euler angles are a common SO(3) representation but suffer from non-uniqueness and gimbal lock, making them less suitable for neural network predictions. Quaternions offer a solution by preventing gimbal lock, but their non-unique representation (q and -q) can complicate certain optimization processes. The axis-angle representation is intuitive but can encounter singularities. The 6D and 9D representations provide newer approaches that simplify optimization in deep networks by avoiding non-linear constraints and ensuring orthogonality. However, they also introduce complexities in maintaining constraints during the learning process. Thus, choosing an appropriate rotation representation is crucial for accurate pose estimation in various computational applications. For a detailed explanation, please refer to Sec. A.1 and an overview of learning 3D rotations in [54; 58].

**Rotation representation in frequency domain.** In the frequency domain, 3D rotation is managed by manipulating spherical harmonics coefficients. Spherical harmonics, denoted as \(Y_{m}^{l}(,)\), are functions defined on the surface of a sphere using polar (\(\)) and azimuthal (\(\)) angles. These harmonics are characterized by their degree \(l\) and order \(m\), truncated to a maximum degree \(L\) for computational feasibility. The rotation of spherical harmonics is represented by the shift theorem , where a rotation operator \(_{g}\) acts on spherical harmonics, transforming them via a matrix \(D_{mn}^{l}(g)\):

\[_{g}Y_{m}^{l}(x)=_{|n| l}D_{mn}^{l}(g)Y_{n}^{l}(x).\] (1)

This matrix, part of the irreducible unitary representation of SO(3), expresses how each harmonic changes under rotation, summing over all orders \(n\) from \(-l\) to \(l\), called Wigner-D matrix. The Wigner-D rotation representation is not limited to a specific case of 3D rotations but can be converted from any 3D rotation representation, such as Euler angles, quaternions, and 3D rotation matrices. Our SO(3) equivariant network predicts the Wigner-D representation in the frequency domain instead of predicting rotations in the spatial domain. For a detailed explanation, please refer to Sec. A.2.

### SO(3)-Equivariance

**Equivariance.** Equivariance is a useful property to have because transformations \(T\) applied to the input produce predictable and consistent output of the features through transformations \(\), enhancing both interpretability and data efficiency. For example, a feature extractor \(\) is equivariant to a transformation if applying the transformation to the input and then applying the extractor produces the same output as applying the extractor first and then the transformation:

\[(T_{g}(x))=T_{g}^{}((x))\] (2)

where \(T_{g}\) and \(T_{g}^{}\) represent transformations acting on a group \(g G\) of the input and output spaces, respectively. This ensures that the network's output remains consistent with transformations applied to the input. For translation groups, convolution inherently maintains this property. For rotations, additional rotation-equivariant layers are integrated into the network design.

Group-equivariant convolutional networks  extend this concept to complex groups like rotations or other symmetries. By designing convolutions that are equivariant to these group actions, these networks can handle a broader range of transformations. This can be mathematically described as:

\[[h*](g)=_{y X}h(y)(g^{-1}y)\] (3)

where \(h\) is the input function over space \(X\), \(\) is the filter or kernel, and \(g G\) is an element of the group. The term \(g^{-1}y\) represents the transformation of \(y\) by the inverse of \(g\). This operation ensures that the network remains equivariant to the actions of the group \(G\), allowing it to handle inputs transformed by any element of this symmetry group.

On the sphere in 3D, however, there is no straightforward way to implement a convolution in the spatial domain due to non-uniform samplings . This challenge arises because traditional convolution operations rely on uniform grid structures, which are not applicable to spherical data. To address this, specialized methods such as spherical convolutions or graph-based approaches are employed to handle the unique structure and sampling patterns of spherical data, thereby ensuring effective feature extraction and equivariance on spherical surfaces.

**Spherical convolutions for \(SO(3)\)-equivariance.** To effectively analyze complex spatial data, such as for volumetric rendering and 3D pose estimation, it is necessary to develop functions with equivariance to the \(SO(3)\) group. Early methods for spherical convolution were defined by computing Fourier transforms and convolution on the 2-sphere . However, the output of these spherical convolutions is a function on the sphere, not on \(SO(3)\). Spherical CNNs  extended this approach to effectively convolve on the \(SO(3)\) group. Using the truncated Fourier transform, signals on \(S^{2}\) are modeled with spherical harmonics \(Y_{n}^{l}\), and on \(SO(3)\) with Wigner-D matrix coefficients \(D_{mn}^{l}\).

To efficiently compute the \(S^{2}\) and \(SO(3)\) convolution, generalized fast Fourier transforms (GFFTs) demonstrate optimized computation . The GFFTs show robustness and efficiency in spherical signal processing, where the spectral group convolutions become simpler element-wise multiplications in the Fourier domain. Specifically, for \(S^{2}\), the process uses vectors of spherical harmonic coefficients, forming a block diagonal matrix analogous to \(SO(3)\) convolution. Both convolutions on \(S^{2}\) and \(SO(3)\) generate output signals that reside on \(SO(3)\).

## 4 SO(3)-Equivariant Pose Harmonics Predictor

The goal of our network is to accurately predict the SO(3) pose of an object in an image. To achieve, we employ spherical CNNs  to obtain SO(3)-equivariant representation, and our model is trained with frequency-domain supervision using Wigner-D coefficients. This approach enhances data efficiency by capturing patterns with fewer training samples and ensures precise SO(3) pose estimation by aligning the parametrization of 3D rotations with the Wigner-D matrices in the frequency domain.

Figure 2 provides an overview of our SO(3)-equivariant pose estimation network. In Sec. 4.1, we explain the steps for obtaining the Wigner-D representation, following the method described in . In Sec. 4.2, we introduce a frequency-domain regression loss, where we train the network using MSE loss between the predicted representation and the ground truth (GT) Wigner-D coefficients. Finally, in Sec. 4.3, we describe the inference process by constructing an SO(3) grid for evaluation.

### SO(3)-Equivariant Pose Estimation Network

In this subsection, we explain our SO(3)-equivariant pose estimation network, highlighting that its key components are shared with the architecture of .

Figure 2: **Overall architecture.** Our network for SO(3)-equivariant pose estimation consists of four parts: feature extraction, spherical mapper, Fourier transformer, and SO(3)-equivariant layers. First, we extract a feature map using a pre-trained ResNet. Next, the spherical mapper orthogonically projects the extracted feature map onto a spherical surface. The Fourier transformer converts this spatial information into the frequency domain. We utilize spherical convolutions to obtain the final Wigner-D harmonics coefficients \(\) which represent SO(3) rotations of spherical harmonics, where \(M\) denotes the total number of Wigner-D matrix coefficients.

**Image feature extraction.** We first apply a feature extractor to obtain an image feature map that encodes semantic and geometric information: \(F=(I)\), where \(F^{C H^{} W^{}}\) and \(\) denotes ResNet. We utilize a ResNet feature extractor that is pre-trained on ImageNet same to . We then perform dimensionality reduction on the image feature \(F\) to match the input dimension of the subsequent spherical feature using a 1x1 convolution: \(F^{}=_{1 1}(F)\), where \(F^{}^{C^{} H^{} W^{}}\).

**Spherical mapper.** To begin, we lift the image features to the 2-sphere using orthographic projection . This involves mapping the 2D feature \(F^{}\) to a spherical feature \(^{C^{} p}\), where \(p\) denotes the number of points on the sphere. The orthographic projection links pixels in the image space to points on the sphere by orthogonally mapping \(S^{2}\) coordinates to the image plane, thereby preserving the spatial information of the dense 2D feature map.

Initially, we model spherical coordinates using an \(S^{2}\) HEALPix  grid over a hemisphere. Within this hemisphere, the set \(\{x_{i}\} S^{2}\) represents the vertices of the grid. Each vertex \(x_{i}\) is mapped to a position \(P(x_{i})\) on the image plane. Formally, the orthographic projection \(P\) maps 3D coordinates on the hemisphere to 2D coordinates on the image plane as \(P(x,y,z)=(x,y)\).

Due to the fixed perspective, only one hemisphere of the sphere is visible, resulting in a localized signal \((x)=F^{}(P(x))\) supported over this hemisphere. The value of \((x_{i})\) is obtained by interpolating \(F^{}\) at the pixels near \(P(x_{i})\) in the image space using an interpolation function \(\), so \((x_{i})=(F^{},P(x_{i}))\). Figure 3 illustrates the processes of the spherical mapper, and the following frequency domain conversion and spherical convolution for SO(3)-equivariance.

**Convert to the frequency domain.** The transition of the spherical feature \(\) into the frequency domain is achieved using the fast Fourier transform (FFT) adapted for spherical topology. By employing the FFT, we efficiently convert \(\) to spherical signals \(\), represented as a sum of spherical harmonics. This transformation allows us to capture and manipulate the spatial frequencies inherent to the spherical surface. Specifically, the transition to the frequency domain enables the derivation of Wigner-D coefficients, which effectively model the \(SO(3)\). The Fourier series of \(\) is truncated at frequency \(L\), expressed as: \((x)_{l=0}^{L}_{m=-l}^{l}c_{m}^{l}Y_{m}^{l}(x),\) where \(^{C^{} N}\), \(N\) is the total number of spherical harmonics determined by the maximum frequency \(L\), and \(Y_{m}^{l}(x)\) are the spherical harmonics. Operating in the frequency domain facilitates the effective convolution of signals on the sphere (\(S^{2}\)) and within the 3D rotation group (\(SO(3)\)), preserving the geometric properties of input features through spherical equivariance.

To address sampling errors from approximating the Fourier series via truncation, we apply two techniques proposed in . First, to prevent discontinuities on the 2-sphere, we gradually decrease the magnitude of projected features near the image edge: \(^{}(x_{i})=w(x_{i})(x_{i})\). Second, for each projection, we randomly select a subset of grid points on the \(S^{2}\) HEALPix grid as a dropout.

**Spherical convolution for SO(3)-equivariance.** We aim to predict 3D rotations while preserving SO(3)-equivariance using the projected features on sphere. First, the spherical signal \(\) is processed with an \(S^{2}\)-equivariant convolutional layer . Unlike conventional convolutions with local filters, \(S^{2}\) convolution uses globally supported filters, offering a global receptive field. This allows for a shallower network, which is important due to the high computational and memory demands of spherical convolutions at a high bandlimit \(L\).

Figure 3: **Illustration of spherical mapper and spherical convolution for SO(3)-equivariance.** This structure allows for the prediction of 3D rotations while preserving the SO(3)-equivariance of the input structure. Predicting the Wigner-D harmonics \(\) enables continuous 3D rotation modeling, without discretizing the group actions.1In this stage, we obtain SO(3) representations inherent to spherical CNNs . The output of \(S^{2}\) convolutions lies in the SO(3) domain because \(S^{2}\) convolutions replace translations with rotations, and the space of 3D rotations forms the SO(3) group. Consequently, we obtain feature results sized in \(^{C^{} M}\), where \(C^{}\) is the hidden dimension of the SO(3) features, and \(M\) is the total number of Wigner-D matrix coefficients, given by \(M=_{l=0}^{L}(2l+1)(2l+1)\), created by SO(3) irreps.

We apply non-linearities between convolutional layers by transforming the signal to the spatial domain, applying a ReLU, and then transforming back to the frequency domain, following the approach of spherical CNNs . This method can be extended to FFT-based approximate non-linearity  and equivariant non-linearity for tensor field networks [55; 71].

Subsequent to the \(S^{2}\)-equivariant convolutional layer, we perform an SO(3)-equivariant group convolution [11; 35] using a locally supported filter to refine the SO(3) pose space. Unlike typical spherical CNNs, we bypass the inverse fast Fourier transform (iFFT) and instead use the output harmonics of Wigner-D prediction. This approach, unlike that of , improves the efficiency of our method. The final output of the equivariant network is the Wigner-D matrix coefficients \(^{M}\).

### Frequency-Domain Regression Loss

The output of the SO(3)-equivariant convolutional layers is a linear combination of Wigner-D matrices, represented as a flattened vector of the Wigner-D coefficients. The output \(\) indicates specific object orientations in an image. To generate the ground-truth (GT) Wigner-D coefficients, we convert the GT 3D rotations from Euler angles using the \(ZYZ\) sequence of rotation \(R\), expressed as \(R=R_{z}()R_{y}()R_{z}()\) to the Wigner-D matrices \(D^{l}_{mn}(,,)\), where \(D\) represents an action of the rotation group SO(3). We calculate the Mean Squared Error (MSE) loss as follows:

\[(,^{ GT})=_{l=0}^{L}_{m=-l}^{l}w_{l}(_{lm}-_{lm}^{ GT})^{2},\] (4)

where \(w_{l}\) are weights assigned to each harmonic frequency level \(l\), normalizing the output Wigner-D matrices for a frequency-domain specific MSE loss. This loss function enables continuous prediction of SO(3) poses using SO(3)-equivariant networks, whereas the previous methods [28; 35; 52] predicted outputs in a discretized distribution, leading to degradation in prediction precision. With this re-parametrization in the frequency domain, we use Euclidean distance because it is simple yet effective for pose prediction. It allows straightforward calculation while considering both the direction and magnitude of the vectors. Many distance metrics defined in the spatial domain [2; 25; 30; 58] may not be directly appropriate for the frequency domain without adaptation. For example, cosine and angular distances ignore magnitude, where the amplitude of frequency components carries significant information. Chordal and geodesic distances require normalization, can be less intuitive, and often involve more complex computations.

### Inference

For evaluation, the output Wigner-D representation \(\) is converted to an SO(3) pose in the spatial domain. Figure 4 illustrates the inference process inspired by [35; 52]. Specifically, we map the predicted Wigner-D coefficients \(\) from the frequency domain to a 3x3 rotation matrix \(R\) by querying \(\) on a predefined SO(3) grid. To achieve this mapping, we calculate the similarities between the output vector \(\) and the SO(3) grid \(P( I)\). These similarities are then normalized using a softmax function to produce a non-parametric categorical distribution \(P(R I)\). The final 3D rotation matrix \(\) is determined either by taking the argmax of this distribution or by applying gradient ascent .

To generate the SO(3) equivolumetric grids, we utilize the hierarchical equal area isolatitude pixelation of the sphere (HEALPix) [24; 26], consistent with methods used in [28; 35; 44; 52; 75]. To lift the \(S^{2}\) HEALPix to \(SO(3)\) HEALPix, we create equal-area grids on the 2-sphere and cover \(SO(3)\) by threading great circles through each point using the Hopf fibration from .

This inference scheme effectively models objects with ambiguous orientations or symmetries by employing multiple hypotheses, thereby overcoming the limitations of single-modality predictions . In addition to joint training with distributional cross-entropy loss , our network can model the non-parametric and multi-modal distribution in pose space to address pose ambiguity and aid in modeling 3D symmetry.

## 5 Experiment

### Implementation Details

We input a 2D RGB image \(I^{3 224 224}\). A ResNet backbone, pretrained on ImageNet, extracts feature maps of shape \(F^{2048 7 7}\). We then perform dimension reduction using a 1x1 convolution to obtain \(F^{}^{512 7 7}\). In the spherical mapper, the features are mapped onto an \(S^{2}\) grid generated by recursion level 2 of HEALPix on half of the sphere, and then sampled at 20 points, resulting in \(^{512 20}\). By converting \(\) to the frequency domain, the spherical signals \(^{512 49}\) are obtained. The Wigner-D representation is implemented in a flattened form across different frequency levels. For example, the matrix coefficients at a frequency level \(l\) are represented as a flattened vector of size \((2l+1)(2l+1)\). We use a maximum frequency level of \(L=6\), resulting in a total size of \(M=455\), computed as \(_{l=0}^{6}(2l+1)(2l+1)\). These coefficients are then flattened into a single vector for the Wigner-D prediction. The spherical convolution on the \(S^{2}\) kernel uses an 8-dimensional hidden layer with global support to obtain intermediate SO(3) features in \(^{8 455}\). After nonlinear activation, we finally obtain the 1-dimensional output \(^{1 455}\) using an SO(3) convolution with a locally supported filter to handle rotations up to 22.5\({}^{}\). At inference, we employ a recursive level 5 of SO(3) HEALPix grid with 2.36 million points, achieving a precision of 1.875\({}^{}\), as in [28; 35].

### Benchmarks

**ModelNet10-SO(3)** is a common dataset for estimating a 3D rotation from a single image. The images are created by rendering CAD models from the ModelNet10 dataset . The dataset includes 4,899 objects across 10 categories, each image is labelled with a single 3D rotation. The rotations are uniformly sampled from each CAD model. From a single CAD model, the training set comprises 100 3D rotations on SO(3), while the test set includes 4 unseen 3D rotations.

**PASCAL3D+** is a widely-used benchmark for evaluating pose estimation in images captured in real-world settings. It includes 12 categories of everyday objects, which were created by manually aligning 3D models with their corresponding 2D images. This dataset presents challenges due to the significant variation in object appearances, the high variability of natural textures, and the presence of novel object instances in the test set. To be consistent with the baselines, we conduct training data augmentation using synthetic renderings .

**ModelNet10-SO(3) Few-shot Views** is used to evaluate the data efficiency of pose estimation models. Unlike the original ModelNet10-SO(3) , we have expanded this to evaluate various amounts of training data, by setting the number of training views per CAD model to 3, 5, 10, 20, 30, 40, 50, 70, 90, and 100. This benchmark verifies the sampling efficiency of our equivariant networks. We use the same test dataset as that of ModelNet10-SO(3).

**Evaluation Metrics.** We calculate the angular error, measured in degrees using geodesic distance, between the network-predicted SO(3) pose and the ground-truth rotation matrix: \(_{}(R,)=^{-1}(( R) -1}{2})\), and \( R=R^{T}\). We adopt two commonly used metrics: the median rotation error (MedErr) and the accuracy within specific rotation error thresholds (Acc@15\({}^{}\)and Acc@30\({}^{}\)).

Figure 4: **Inference time.** We query the output vector of Wigner-D coefficients \(\) against the predefined SO(3) HEALPix grid with a resolution of \(Q\) points. We finally obtain the SO(3) probability distribution \(P(R I)\), where each position represents the probability of a specific SO(3) pose.2

[MISSING_PAGE_FAIL:8]

### Ablation Studies & Design Choices

#### 5.5.1 SO(3) Parmetrizations

Table 3 shows results validating design choices on ModelNet10-SO(3) with 20-shot training views, using a ResNet-50 backbone. First, we compare the effects of different rotation parametrizations on model performance by changing the prediction head and ground-truth rotations, to verify our proposed Wigner-D compared to other rotation representations. For all cases, we retained the backbone networks and SO(3)-equivariant layers. The only modifications were the output prediction dimension size and the ground-truth rotation representation. Our Wigner-D parametrization outperforms Euler angles (3 dim.), quaternions (4 dim.), axis-angle (4 dim.), and rotation matrices (9 dim.). This demonstrates that frequency domain rotation re-parametrization enables accurate 3D rotations when used with the SO(3)-equivariant spherical CNNs in the frequency domain.

#### 5.5.2 Loss Functions

Table 4 compares various loss functions trained on ModelNet10-SO(3) with 20-shot learning using a ResNet-50 backbone. While Huber and L1 losses are alternatives, they do not perform as well as MSE in our context. Cosine loss measures only angle distances between vectors, ignoring magnitude, which is an essential factor in frequency-domain applications. Geodesic loss in the frequency domain is ineffective because it requires separate calculations for each frequency level of the Wigner-D matrix, potentially losing the precision of the original 3D rotation, as we truncate the Fourier basis at a frequency level of 6. Therefore, we choose MSE regression loss for our design choice given its simplicity and effectiveness.

#### 5.5.3 Ablation Studies

In Table 5, we experiment with replacing SO(3)-equivariant layers with conventional convolutional layers. Specifically, we use two-layer 1x1 convolutional layers with ReLU activation and a final linear layer with 455 output channels. The results indicate that CNNs without equivariant layers perform poorly, especially in terms of median error, suggesting that using the equivariant networks generalize better to unseen samples. Additionally, the Wigner-D prediction should be paired with an SO(3)-equivariant network to enable reliable 3D rotation prediction in the frequency domain.

Lastly, we evaluate the impact of different SO(3) grids by switching from a HEALPix grid to a random SO(3) grid and super-Fibonacci spirals , which use the same number of SO(3) rotations. Our Wigner-D harmonics predictor performs consistently, regardless of the SO(3) grid sampling type at inference time.

  
**Loss Function** & **Acc@15\({}^{}\)** & **Acc@30\({}^{}\)** & **Rot Err.** \\  MSE Loss & **0.6807** & **0.6956** & 22.27\({}^{}\) \\ L1 loss & 0.6796 & 0.6933 & 22.12\({}^{}\) \\ Huber loss & 0.6710 & 0.6873 & **19.26\({}^{}\)** \\ Cosine loss & 0.4414 & 0.4978 & 64.29\({}^{}\) \\ Geodesic loss & 0.0009 & 0.0071 & 132.65\({}^{}\) \\   

Table 4: **Comparison of different loss functions.** To validate our choice of MSE loss, we experiment with various distance functions between the predicted output and the ground truth.

  
**Method** & **Acc@15\({}^{}\)** & **Acc@30\({}^{}\)** & **Rot Err.** \\  Wigner (ours) & **0.6807** & **0.6956** & **22.27\({}^{}\)** \\ Euler & 0.0010 & 0.0072 & 132.56\({}^{}\) \\ Quaternion & 0.0510 & 0.1629 & 75.95\({}^{}\) \\ Axis-Angle & 0.0124 & 0.0815 & 88.66\({}^{}\) \\ Rotmat & 0.3909 & 0.5682 & 37.54\({}^{}\) \\   

Table 3: **Comparison of different parametrizations of 3D rotations.** To validate our Wigner-D representation in the frequency domain, we train using various output rotation representations.

    & **Acc@15\({}^{}\)** & **Acc@30\({}^{}\)** & **Rot Err.** \\  ours & **0.6807** & **0.6956** & **22.27\({}^{}\)** \\ w.o equivConv & 0.1056 & 0.1308 & 149.25\({}^{}\) \\  Random SO(3) & 0.6797 & 0.6946 & 22.16\({}^{}\) \\ SuperFibonacci & 0.6785 & 0.6932 & 22.15\({}^{}\) \\   

Table 5: **Comparison of results without the SO(3)-equivariant module and with different SO(3) grids at inference.** The first group shows the results using conventional convolution instead of equivariant convolution. The second group presents the results with different SO(3) grids at inference time. ‘ours’ denotes the proposed model architecture.

### Results on SYMSOL

Table 6 shows symmetric object modeling on the SYMSOL datasets . Compared to the first row and second row , our model with only the Wigner-D regression loss derives on sharp modalities, which can be less effective than  for symmetric objects in SYMSOL I.

For clearly defined pose cases (e.g., SphereX in SYMSOL II), our Wigner-D loss alone performs well. However, in other SYMSOL II scenarios, the sharp distributions produced by our model can lead to low average log likelihood scores. This metric is particularly harsh on models with sharp peaks, making them vulnerable to very low scores in some failure cases.

In the third row, joint training of our method with the distribution loss [35; 52] achieves better performance than the baseline , demonstrating its ability to model symmetric objects. These results highlight the potential of our method in handling complex symmetries and predicting multiple hypotheses. Figure 6 shows the visualization of pose distribution on the SYMSOL I and II datasets.

Most real-world objects have unique, unambiguous poses, validating our single pose regression method (e.g., ModelNet10-SO(3), PASCAL3D+). If the task needs to cover symmetric cases, our model can be modeled with distribution loss [35; 52].

## 6 Conclusion

In this paper, we proposed a novel method for 3D rotation estimation by predicting Wigner-D coefficients directly in the frequency domain using SO(3)-equivariant networks. Our approach effectively overcomes the limitations of existing spatial domain parameterizations of 3D rotations, such as discontinuities and singularities, by aligning the rotation representation with the operations of spherical CNNs. By leveraging frequency-domain regression, our method ensures continuous and precise pose predictions and demonstrates state-of-the-art performance across benchmarks like ModelNet10-SO(3) and PASCAL3D+. Additionally, it offers enhanced data efficiency and generalization to unseen rotations, validating the robustness of SO(3)-equivariant architectures. Our method also supports the modeling of 3D symmetric objects by capturing rotational ambiguities, with further accuracy improvements achievable through joint training with distribution loss. Future work can build on this foundation to explore frequency-domain representations in 3D vision tasks, develop more effective rotation representations for 3D space, and further optimize computational efficiency.

    &  &  \\   & avg & cone & cyl & tet & cube & icosa & avg & sphereX & cylO & tetX \\  \(_{}\) & 2.54 & 2.42 & 2.68 & 2.93 & 2.67 & 1.99 & -8.88 & 4.51 & -7.64 & -23.52 \\ \(_{}\) & 3.41 & 3.75 & 3.10 & 4.78 & 3.27 & 2.15 & 4.84 & 3.74 & 5.18 & 5.61 \\ \(_{}\)+\(_{}\) & **4.11** & **4.43** & **3.76** & **5.59** & **3.93** & **2.85** & **6.20** & **6.66** & **5.85** & **6.11** \\   

Table 6: **Results on SYMSOL I and II .** We report the average log likelihood on both parts of the SYMSOL datasets. \(_{}\) denotes the results obtained with our Wigner-D regression loss. \(_{}\) denotes the results using the distribution loss from I-PDF , which are the same as the results of I2S . The third row presents the results of joint training using both our regression loss and the distribution loss.

Figure 6: **Visualization of pose distribution on SYMSOL.** The results are obtained by joint training with both our regression loss and the cross-entropy distribution loss [35; 52].