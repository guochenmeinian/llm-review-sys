# Marginal Causal Flows for Validation and Inference

Daniel de Vassimon Manela

University of Oxford

manela@stats.ox.ac.uk

&Laura Battaglia

University of Oxford

battaglia@stats.ox.ac.uk

&Robin J. Evans

University of Oxford

evans@stats.ox.ac.uk

Equal Contribution

###### Abstract

Investigating the marginal causal effect of an intervention on an outcome from complex data remains challenging due to the inflexibility of employed models and the lack of complexity in causal benchmark datasets, which often fail to reproduce intricate real-world data patterns. In this paper we introduce Frugal Flows, a novel likelihood-based machine learning model that uses normalising flows to flexibly learn the data-generating process, while also directly inferring the marginal causal quantities from observational data. We propose that these models are exceptionally well suited for generating synthetic data to validate causal methods. They can create synthetic datasets that closely resemble the empirical dataset, while automatically and exactly satisfying a user-defined average treatment effect. To our knowledge, Frugal Flows are the first generative model to both learn flexible data representations and also _exactly_ parameterise quantities such as the average treatment effect and the degree of unobserved confounding. We demonstrate the above with experiments on both simulated and real-world datasets.

## 1 Introduction

Simulating realistic datasets such that the marginal causal effect is constrained to take a specific form is a significant challenge in causal inference. Many methods for inferring these effects exist, but simulating from them is a significant challenge (Young et al., 2008; Havercroft and Didelez, 2012; Keogh et al., 2021). In particular, it is difficult to simulate complex benchmarks from generative models in such a way that a custom marginal effect exactly holds.

The _frugal parameterisation_(Evans and Didelez, 2024) provides a solution to this problem by constructing a joint distribution that explicitly parameterises the marginal causal effect and builds the rest of the model around it. Frugal models typically represent the dependency between an outcome and pretreatment covariates using copulae. Standard multivariate copulae are parametric, leading to potential model misspecification.

In this paper we show how one can construct frugally parameterised marginal causal models using normalising flows (NFs, Rezende and Mohamed, 2015; Dinh et al., 2016) to target the causal margin of the distribution (a conditional univariate marginal density of an outcome conditioned on a treatment). We name the resulting model a _Frugal Flow_ (FF). To the best of our knowledge, FFs offer the first likelihood-based framework for learning a marginal causal effect while modelling the outcome and propensity nuisance parameters using flexible generative models.

FFs are exceptionally well suited for generating benchmark datasets for causal method validation. Since FFs enable direct parameterisation of the causal margin, they provide a framework for generating causal benchmark datasets which resemble real-world datasets, but which also allow users to encode causal properties in order to validate novel inference models. FFs can be used to generate benchmarks with customisable degrees of unobserved confounding. This can aid in the validationof model robustness under conditions where the assumption of conditional ignorability does not hold. Here, conditional ignorability (or conditional exchangeability) means that marginal distribution of the potential outcomes is independent of the value of treatment, conditional on the observed covariates (Pearl, 2009).

FFs offer marked improvements over current benchmarking generation methods, which use soft constraint optimisation to enforce the desired causal restrictions (Kendall, 1975; Parikh et al., 2022). As a result, _post hoc_ checks are required to see whether these conditions are present in the synthetic data. FFs do not require this second step, as relevant conditions are explicitly encoded in the underlying likelihood. Finally, FFs allow for outcomes to be sampled from marginal logistic and probit models, making them the first generative benchmarking model to facilitate the simulation of binary outcomes with a choice of user specified risk differences, risk ratios, or odds ratios.

## 2 Background

In this paper we consider a static treatment model with an outcome \(Y\) and \(T\) a binary treatment in \(=\{0,1\}\). Let the set of measured pretreatment covariates be \(^{D}\). Additionally, we will use the notation of Pearl (2009) where intervened distributions are indicated by the presence of a "\(()\)" operator, with its absence indicating that the distribution is from the observational regime.

### Marginal Causal Models

Causal inference methods are generally developed to estimate the average effect of a treatment \((T)\) on an outcome \((Y)\) for a population defined by a set of pretreatment covariates \(()\)(Hernan and Robins, 2020). Let the variables be distributed according to \((,T,Y) P_{TY}\) with density \(p_{TY}\). We make the standard assumptions of a stable unit treatment value (commonly referred to as SUTVA), positivity, and conditional ignorability (equivalent to conditional exchangability) outlined in Pearl (2009). Additionally, the covariate set \(\) must only include pretreatment covariates. The conditional distribution of \(Y\) and \(\) after an intervention on \(T\) is equal to

\[p_{Y|(T)}(,\ y t)=p_{}() p_{Y| ,(T)}(y,\ t).\]

Causal practitioners are often interested in the marginal effect of \(T\) on \(Y\) on the intervened system, sometimes referred to as the marginal outcome distribution (MOD), \(p_{Y|(T)}\):

\[p_{Y|(T)}(y t)=_{}d\;p_{Y|,(T)}(y,t)\;p_{}().\] (1)

The difference between the means of \(Y\) under this margin between different values of \(T\) is called the average treatment effect (ATE), \(\) where, \(=[Y(T=1)]-[Y(T=0)]\). Models which target this marginal quantity are known as _marginal structural models_(MSMs, Robins, 1998) and are frequently used in epidemiological and medical domains to account for time-varying confounding. In particular, they are effective at quantifying the effect of an intervention over a population, where the specific relationships between the outcome and (possibly high dimensional) pretreatment covariates are not relevant, and are modelled as nuisance parameters. The semiparametric question of estimating finite dimensional quantities in the presence of high dimensional nuisance parameters has a long history (Robins et al., 1995; Robins and Rotnitzky, 1995), but has undergone a renaissance since the development of methods such as targeted maximum likelihood estimation (van der Laan and Rose, 2011) and double machine learning (Chernozhukov et al., 2018), which allow for general machine learning algorithms to flexibly describe the nuisance models and still have valid inference on a low-dimensional treatment effect.

### Frugal Parameterisations

Frugally parameterised distributions consist of three distinct components: the distribution of the 'past,' \(_{ZT}\); the intervened causal quantity of interest, \(_{Y|(T)}\); and an intervened dependency measure between \(Y\) and \(\) conditional on \(T\), \(_{Y|(T)}\). The key idea is to explicitly parameterise the marginal causal effect, and build the rest of the model around it. In this paper we encode all the dependence among covariates in the copula, so 'the past' is really just the propensity for treatment (also called the propensity score) and the product of the univariate margins (Evans and Didelez, 2024). Figure 1 provides an illustrative summary of our framework, and outline which models are used to parameterise each component of a frugal model.

Variation IndependenceAny smooth and regular 'dependency measure' can be chosen for parameterising \(_{Y|(T)}\); this is defined as a quantity which, when combined with the marginal distributions, smoothly parameterises the joint distribution. It is desirable that the three parameter sets \((_{T},_{Y|(T)},_{Y|(T)})\) are _variation independent_(Barndorff-Nielsen, 2014) of each other; such parameterisations have the benefit of allowing the measure \(_{Y|(T)}\) to be freely specified without restricting the rest of the model. Copulae are an example of such a dependency measure, and are a natural choice for frugally modelling dependencies in continuous and mixed datasets. For further detail we refer the reader to Appendix A.

### Copulae

A multivariate copula, denoted by \(C:^{d}\) is a multivariate cumulative distribution function (CDF) defined over a set of \(d\) uniform margins, with an associated density \(c()\) if it is continuous with respect to its arguments (Sklar, 1959; Joe, 2014). Copulae are often used to parameterise the dependency structure of a joint distribution independent of its univariate margins. Large, complex dependency structures are often modelled by pair-copula constructions (PCCs) or vine copulae (Czado and Nagler, 2022; Joe and Kurowicka, 2011). These methods factorise the dependency structure into a set of non-overlapping bivariate copulae. However, these approaches typically impose the constraints of a finite dimensional parameterisation on the dependency structure in the bivariate copulae used. A more comprehensive introduction to copulae can be found in Appendix B.

Copulae in Machine LearningMore complex ML models have been developed to more flexibly learn copula distributions. Several alternatives have been proposed, some targeting specific copula classes (Ling et al., 2020; Wilson and Ghahramani, 2010), and others constraining a neural network-based architecture to estimate valid copulae, though often with limited scalability (Zeng and Wang, 2022; Chilinski and Silva, 2020) or using variational approximations (Letizia and Tonello, 2022). However, the most active research area in this field makes use of normalising flows, leveraging their likelihood-based, composable and invertible nature to chain transformations of marginal quantities to the fitting of the copula density.

Paper MotivationA key motivation for this paper is the search for a flexible parameterisation of the copula

\[_{Y|(T)}(,y t)=c(F_{Y|(T )}(y t),F_{Z_{1}}(z_{1}),,F_{Z_{D}}(z_{D}))\] (2)

Figure 1: A visual abstract outlining the different components of a frugal model, and how each specific component is parameterised. Univariate CDFs are denoted by \(F\), and copula distribution functions are denoted by \(C\). The marginal causal effect, \(_{Y|(T)}\), is modelled with a univariate normalising flow, which we denote by \(\) (see Section 2.4). The intervened dependency measure, \(_{Y|(T)}\), is modelled with a copula flow which we denote by \(\) (see Section 2.5). The past, \(_{ZT}\), is modelled by the combination of univariate normalising flows (for the univariate pretreatment covariate distributions) and a copula flow (for the propensity of treatment).

between the probability integral transforms of the univariate pretreatment covariates and a conditional univariate quantity which parameterises the causal margin. Evans and Didelez (2024) show that this can be done using parametric copulae, and also prove that it targets the marginal causal rather than the conditional distribution when \(_{Y|(T)}\) is parameterised by a multivariate copula. Consider the multivariate copula for the distribution of \(\) and \(Y\) conditional on \(T\):

\[c(F_{Y|T},F_{Z_{1}|T},,F_{Z_{D}|T}).\]

For an intervened distribution, all pretreatment covariates \(\) are marginally independent of \(T\), and so the intervened joint density becomes

\[p_{Y|(T)}=p_{Y|(T)} c(F_{Y| (T)},F_{Z_{1}},,F_{Z_{D}}),\]

where \(p_{Y|(T)}\) is the marginal causal effect of \(T\) on \(Y\). The final propensity score density \(p_{X|}\) does not affect the marginal densities in the observational model as there is a parameter cut between \(p_{T|}\) and \(p_{Y|(T)}\)(Barndorff-Nielsen, 2014). However, \(_{Y|(T)}\) and \(_{Y|(T)}\) are functions of \(p_{Y|(T)}\) and thus should be estimated jointly. If \(p_{Y|(T)}\) is estimated separately from the copula, the marginal _conditional_ effect will be inferred rather than the marginal _causal_ effect.

Generative ML methods allow for estimating more flexible and general copulae, but have struggled so far to learn copulae together with conditional univariate quantities. We resolve this problem and design a NF-based copula inference method that allows for these quantities to be estimated jointly as required by the frugal parametrisation (see Section 2.5). The model is then trained on real-world data and used for generating customised causal benchmarks which closely resemble the original dataset.

### Normalising Flows

Normalising flows (NFs) (Tabak and Turner, 2013; Rezende and Mohamed, 2015; Dinh et al., 2016) allow for density estimation via learning a diffeomorphic transformation \(\) that maps the unknown target distribution \(p_{}()\), \(^{D}\) to a simple and known base distribution \(p_{}()\), \(^{D}\), so that when \( p_{}\) and \( p_{}\) then \(=^{-1}()\).

\(\) is usually a composition of invertible and differentiable transformations \(_{i}\) parametrised by neural networks, and is often trained by maximising the log-likelihood of observed \(\{_{i}\}_{i=1}^{N}\). This can be conveniently done in closed form exploiting the change of variable formula

\[p_{}()=p_{}(^{-1}())| (^{-1}())}{}) |,\] (3)

provided that the chosen model for \(\) allows for efficient computation of the Jacobian determinant \(((^{-1}())/)\). The implementation of \(^{-1}\) then allows for density evaluation, whereas \(\) can be used for sampling from the joint.

As for the choice of \(\), the literature has explored a number of implementations that retain invertibility while allowing for computational tractability of the determinant. See Papamakarios et al. (2021) for an introduction and overview. Our implementation relies on neural spline flows (NSF, Durkan et al., 2019), a particular type of autoregressive flows that will be further illustrated in Section 2.5.

### Copula Flows

Our Frugal Flow approach builds upon the copula-based flow model proposed by Kamthe et al. (2021) for synthetic data generation. The authors start by considering a copula \(C(F_{X_{1}},,F_{X_{D}})\) defined over the marginal probability integral transforms \(F_{X_{1}},,F_{X_{D}}\) of a random vector \(=[X_{1},,X_{D}]\). Assuming the copula density exists, the joint density of \(\) can be written as

\[p_{}(x_{1},,x_{d})=c_{}(F_{X_{1}}(x_{1}),,F_{X_{ D}}(x_{D}))[_{d=1}^{D}p_{X_{d}}(x_{d})],\] (4)

where \(p_{X_{d}}\) is the marginal density of \(X_{d}\). This factorisation of the density can be similarly induced by a NF that composes \(D\) flows \(_{1},,_{D}\) for the marginal quantities and a flow \(_{}\) for the copula.

For the rest of this paper, we will let \(^{D}\) represent a vector of _independent_ uniforms, and let \( C\) represent a vector of _dependent_ uniforms as a multivariate copula \(C\). The generative procedure for this NF takes samples \(\) from a base distribution of independent uniforms and first pushes them through the copula flow \(_{}\), obtaining correlated uniform samples \(=_{}()\). Then \(\) is mapped through the marginal flows \(_{}=[_{X_{1}},,_{X_{D}}]\) to obtain the random vector \(=_{}()\).

The composed flow \(=_{}(_{}())\) is also a valid flow, and via the change of variable formula as in eq. (3) it induces a specific factorisation of the density of \(\) Here, we quote the result from Kamthe et al. (2021):

\[p_{} =p_{}(_{}^{-1}())| (_{}^{-1}()}{})|\] \[=|(_{}^{-1}( _{}^{-1}())}{_{}^{-1}()})||_{d=1}^{D}(_{X_{d}} ^{-1}(X_{d})}{ X_{d}})|.\] (5)

As the univariate mapping from a uniform to a random variable is uniquely defined by the CDF, the flows \(_{}^{-1}=[_{X_{1}}^{-1},,_{X_{D }}^{-1}]\) target the marginal CDFs \(F_{X_{1}},,F_{X_{D}}\). Note how eq. (5) factorises the density of \(\) into a copula density and a product of marginal densities as in eq. (4).

\(_{}\) is estimated with a NSF, a NF of the autoregressive flow class. Autoregressive flows (Papamakarios et al., 2017; Huang et al., 2018) factorise \(_{}\) as a recursive sequence of univariate conditional flows:

\[V_{1}:=_{1}(U_{1}) V_{d}:=_{d|1 d-1}(U_{d} V_{1},,V_{d-1}) 2 d D.\] (6)

In principle, since the input \(\) is a vector of independent uniforms, the conditional flows would approximate the inverse of the Rosenblatt transform (Rosenblatt, 1952) and thus be universal approximators if the flows were sufficiently expressive (Papamakarios et al., 2021). The Rosenblatt transform sequentially maps each component \(S_{d}\) of any random vector \(\) with strictly positive density through its corresponding conditional CDF \(F_{S_{d}|S_{1},,S_{d-1}}\), obtaining a vector \(\) of independent uniforms. It is known to be a diffeomorphism, so its inverse bears the same structure as eq. (6)), but uses inverse conditional CDFs \(C_{d|1,,d-1}^{-1}\) for each \(V_{d}\). We use the notation \(C^{-1}\) to emphasise that in the copula flow case we are dealing with inverse _copula_ CDFs, whose codomain is also uniform.

Autoregressive flows estimate each univariate conditional flow \(_{d|1 d-1}\) with a strictly monotone function whose parameters are only allowed to depend on dimensions \(1,,d-1\). The monotonicity of the function ensures invertibility, while the autoregressive structure in the function parameter dependence gives a triangular Jacobian whose determinant is tractable. Kamthe et al. (2021) use a NSF, where the monotone function is given by a monotone rational quadratic spline, whose knot parameters are provided by a neural network where weights are appropriately masked to ensure the autoregressive structure. The univariate marginal flows \(_{}\) are estimated with separate NSFs before training the copula flow using the transformed data \(\).

While a NSF can constrain the support of both the base and target distributions, it cannot control the form of the marginal distribution. If marginal and copula flows are learned simultaneously, neither will be correctly inferred due to the infinite possible combinations of \((_{},_{})\) which yield the same composite flow \(=_{}_{}\). These flows must be learned sequentially if \(\) is to model a copula.

In our application, we wish to infer a multivariate copula which models the joint dependence between univariate pretreatment covariates and conditional univariate quantities such that the latter parameterises the causal margin. Inferring the MOD separately from the copula, as copula-based flows do, will target the conditional causal effect rather than the marginal causal effect. We propose a solution in the form of Frugal Flows, which we introduce in Section 3.1.1. Moreover, for discrete variables we use a decquantised form of the empirical CDF rather than a NSF adaptation (see Appendix B.2 for further details).

### Validating and Benchmarking Causal Methods

Methods for validating causal models can be broadly categorised into two groups. The first comprises auxiliary analyses conducted after fitting a causal model and estimating a treatment effect. These include but are not limited to sensitivity analyses (Imai et al., 2010), subgroup analyses (Cochran and Chambers, 1965), placebo tests (Eggers et al., 2023), and negative controls (Shi et al., 2020).

The second set of validation methods is where we see FFs having a significant impact. These methods are used to construct synthetic datasets while allowing the causal practitioner to customise specific features of the data-generating process. For example, when validating an inference method which estimates an ATE under certain confounding assumptions, it is crucial that generated data follow the "ground truth" ATE and confounding assumptions one wishes to measure. However, synthetic data risk being oversimplified and contrived, failing to reflect the complexity of real world datasets.

To mitigate this, generative models are trained on real-world data and calibrated to generate samples with modifiable causal constraints. Such constraints include the average causal treatment effect, unobserved confounding, and positivity. To our knowledge, the FF framework proposed in this paper is the first method to allow all of these conditions to adjusted by the user. Existing methods (Neal et al., 2020; Athey et al., 2021; Parikh et al., 2022) encode these effects through soft optimisation constraints, hence there is no guarantee that the constraints are satisfied. Enforcing these constraints too strongly may negatively impact model optimisation, and may affect the reconstructive ability of the underlying model. Furthermore, since these approaches do not explicitly parameterise the causal effect, samples from trained models must be tested _post hoc_ to ensure the desired constraints are present in the sampled data. A key benefit of frugal models is that the marginal causal effect is directly parameterised by the user through the likelihood. As a result, synthetic data samples will exactly satisfy these constraints.

## 3 Method

### Building the Joint Distribution

In this section we parameterise the full observational joint using FFs. Section 3.1.1 outlines how the FF is constructed; we first learn the probability integral transforms of the pretreatment covariates, and then infer the causal margin jointly with an extended copula flow, the Frugal Flow. To infer the causal margin, this is sufficient. Nevertheless, the propensity score is needed to complete the joint in order to generate benchmarks which are confounded in a similar fashion to the original real-world dataset. We describe the fitting of the propensity score in Section 3.1.2

#### 3.1.1 Constructing Frugal Flows

The first step involves learning the margins for the pretreatment covariates \(\). This is done in a similar fashion to that of Kamthe et al. (2021)'s copula-based flows, as described in Section 2.5. The outcome, treatment, and the inferred ranks \(}\) of the pretreatment covariates are then used to train the Frugal Flow (see bottom part of Figure 2) that models \(^{-1}_{Y|(T)}\) together with the copula flow. This is required in order to learn the causal marginal \(p_{Y|(T)}\) rather than the conditional \(p_{Y|T}\).

The Frugal Flow of dimension \(D+1\) transforms the joint input of \((Y,\ }(T))\) into a random vector \(\) which we set to be distributed according to an independent uniform base distribution. In the first subflow of the composition, \(Y\) is pushed through a univariate flow \(^{-1}_{Y|(T)}\) conditioned on \(T\) to obtain \(V_{Y|(T)}\), while the \(}\) remain untransformed. Subsequently, \(V_{Y|(T)}\) is kept fixed, while a copula is learnt over \(}\) conditional on \(V_{Y|(T)}\) via an NSF. Importantly, a specific ordering of the variables is imposed, such that the causal margin is ranked first. In this way, we ensure that \(U_{1}\) and \(V_{Y|(T)}\) have the same distribution, and \(V_{Y|(T)}\) is therefore constrained to be uniform. The marginal flow \(^{-1}_{Y|(T)}\) thus targets the CDF of the marginal causal effect, \(F_{Y|(T)}\).

In summary, we construct a flow \(^{-1}:(Y,V_{Z_{1}},,V_{Z_{D}} T)\) as a composition of a marginal flow \(^{-1}_{Y|(T)}\) and conditional copula distribution \(^{-1}(v_{Y|(T)},v_{Z_{1}},,v_{Z_{D}})=C(v_{Z_{1}}, ,v_{Z_{D}} v_{Y|(T)})\). More on the implementation details can be found in Appendix C.

#### 3.1.2 Learning the Propensity Flow

We constructed the conditional distribution of \(Y\) and \(\) after an intervention on \(T\) in Section 3.1.1:

\[p_{Y|(T)}(,y t)=[_{i=1}^{D}p_{Z_{i}}(z_{i })] p_{Y|(T)}(y,t) c_{Y|(T)}(v_{ Y|(T)},v_{Z_{1}},,v_{Z_{D}}).\]Inferring the above is sufficient for identifying the causal margin. However, to generate realistic samples for causal method validation, one also needs to learn the propensity score, \(p_{T|}=p_{T} c_{T|}\). By decoupling the marginal treatment density \(p_{T}\) from the conditional copula \(c_{T|}\), one can modify the marginal treatments while retaining the dependence of the original data. We therefore learn an approximate probability integral transform of the discrete treatment \(T\) (see Appendix B.2.1 for further details), followed by the conditional copula flow of \(T\) on \(,\ _{T|}^{-1}:V_{T} V_{T|}\).

One could directly model \(p_{T|}\) using a normalising flow, which would also constitute a valid frugal model. We instead choose to model the conditional copula using a flow, \(C_{T|}=_{T|}^{-1}\), allowing users to encode a degree of unobserved confounding in the generated data by sampling the ranks \(V_{T|}\) and \(V_{V|(T)}\) from a non-independence copula. Assuming ignorability, these ranks would be independent. However, unobserved confounders imply dependence between these ranks. Sampling them from a copula can replicate this effect, as demonstrated in the far-right plots in Figures 3 and 4.

The above section describes how one can estimate the propensity of treatment from a real-world dataset. However, we remark that one can choose any custom propensity score function to generate treatments conditional on the pretreatment covariates via inverse probability integral transforms on \(V_{T|}\). Hence, one can fully control the overlap/positivity of FF generated benchmark datasets.

### Generating Synthetic Benchmarks

Data generated from a fitted FF can be customised with a range of properties, allowing for model validation against a range of customisable causal assumptions. We describe these below.

Modifying the Causal MarginThe central output of the Frugal Flow is a method for sampling ranks for each of the margins in \(P_{Y|(T)},P_{Z_{1}},,P_{Z_{d}}\). Any causal marginal density \(q_{Y|(T)}\) can be used to generate samples of \(Y\) via inverse probability integral transforms. Since the Frugal Flow returns ranks for the intervened causal effect, these can be inverse transformed by any valid CDF. Unlike other methods, this constraint is strictly enforced by the the frugal likelihood.

Simulating from Discrete OutcomesSince FFs return \(V_{Y|(T)}\) ranks, one can sample from any custom causal margin. This extends to both continuous and discrete causal margins. One can simulate from a logistic marginal effect \(Y(T)(p=( T+c))\) or probit model \(Y(T)(p=( T+c))\) where \(()\) is a univariate standard Gaussian CDF. This is non-trivial, because logistic regression is not _collapsible_, meaning that if (for example) \(Y T=t,=z\) is a logistic regression, then \(Y(T=t)\) generally will not be. Hence it is infeasible for a fully conditional method of simulation to produce outcomes where the causal margin uses a logistic link. For experimental results see Appendix D.2.1.

Modifying the Degree of Unobserved ConfoundingOne can sample data from FFs as if the outcome is affected by unobserved confounding. The variables \(V_{Y|(T)}\) and \(V_{T|}\) are independent of each other if no unobserved confounding is assumed. Introducing a dependence between these ranks replicates the effect of unobserved confounding. This can be achieved by sampling \((V_{Y|(T)},V_{T|})\) from a Gaussian bivariate copula, \(c(v_{Y|(T)},v_{T|};)\), where \(\) quantifies the degree of unobserved confounding in the sampled data.

Figure 2: Structure for learning a Frugal Flow. The top line outlines the process for learning the univariate marginal flows of the pretreatment covariates \(\). The bottom transform illustrates the Frugal Flow, which learns the conditional copula \(c(} v_{Y|(T)})\) jointly with the causal marginal flow \(_{Y|(T)}\) by enforcing \(V_{Y|(T)}\) to be marginally uniform.

Customising Treatment Effect HeterogeneityConsider a stationary treatment with pretreatment covariate set \(=(,})\) where \(\) with \(||=D\), \(||=d\), and \(|}|=D-d\). We proceed considering the case where \(0<d<D\). Interest may lie in the causal treatment margin **conditional** on the subset of variables \(\):

\[p_{Y|,(T)}(y,t)=_{}}d {}\ p_{Y|,(T)}(y,},t)\ p_{ }|}(})\] (7)

We propose a method to exactly parameterise heterogeneous treatment effects using a subset of pretreatment covariates, \(\). FFs offer exact parameterisation of \(p_{Y|,(T)}\), allowing for customisation of heterogeneity while capturing complex dependencies between other covariates. Specifically, the model infers the conditional treatment margin, \(p_{Y|,(T)}(y,t)\), ensuring proper inference of the joint pretreatment covariate distribution, \(p_{}()\). Thus, one may simulate data where causal effects are conditional on a selected subset of variables, offering flexible and precise control over treatment heterogeneity. Further details may be found in Appendix D.2.2.

Customising the Propensity ScoreSince the propensity score is variation independent from the rest of the model, one has complete flexibility on how to parameterise the propensity score. Any distribution \(P_{Y|}\) can be used to generate treatments with varying degrees of overlap in a manner that is completely customisable by the user.

## 4 Experiments

The following section discusses our experiments and results, which aim to i) demonstrate that FFs accurately infer the true MOD for confounded data, and ii) show how a trained FF can generate synthetic datasets that meet user specified causal margins and unobserved confounding.

### Inference

We generate simulated data from three models. The first two are parameterised by four pretreatment covariates \(=\{Z_{1},,Z_{4}\}\) with a binary treatment \(T\), a linear Gaussian causal margin \(Y(T)(=T+1,=1)\), and a copula dependence measure \(c(v_{Y|T},v_{Z_{1}},,v_{Z_{4}})\). In the first model \(M_{1}\), all four covariates follow a gamma distribution. In the second \(M_{2}\), the data is generated from an even split of gamma and binary covariates. Additionally, we generate data from model \(M_{3}\) with ten pretreatment covariates comprising five gamma and five binary variables. A more quantitative description of the simulated data generating process and hyperparameter values are presented in Appendix D.1.

We generated datasets with a sample size of \(N=25{,}000\) across \(B=25\) different runs. Frugal Flows (FFs) were compared against outcome regression (OR), traditional causal propensity score matching (Stuart, 2010), and state-of-the-art causal normalising flows (CNFs) (Javaloy et al., 2024). Further details on the methods can be found in Appendix D.3.3. A default set of hyperparameters was used for all models. The estimated ATEs are shown in Table 4. OR models, which estimate the _conditional_ rather than the _marginal_ effect of \(T\) on \(Y\), consistently exhibited bias, pulling the

   Model & True ATE & \(D\) & Frugal Flow & OR & Matching & CNF \\  \(M_{1}\) & \(1\) & 4 & \(\) & \(1.28 0.06\) & \(\) & \(0.73 0.16\) \\ \(M_{1}\) & \(5\) & 4 & \(\) & \(5.29 0.04\) & \(\) & \(4.23 0.20\) \\ \(M_{2}\) & \(1\) & 4 & \(\) & \(1.46 0.07\) & \(\) & \(\) \\ \(M_{2}\) & \(5\) & 4 & \(\) & \(5.44 0.05\) & \(\) & \(\) \\ \(M_{3}\) & \(1\) & 10 & \(\) & \(1.13 0.06\) & \(\) & \(\) \\ \(M_{3}\) & \(5\) & 10 & \(\) & \(5.13 0.26\) & \(\) & \(\) \\   

Table 1: Mean and \(2\) confidence interval of the inferred ATE, bootstrapped over 25 different runs and with a data size of \(N=25{,}000\). The number of pretreatment covariates in each model is denoted by \(D\). Bold confidence intervals contain the true ATE. OR quotes the results obtained by linear outcome regression, and CNF reports the ATE estimted by causal normalising flows.

estimates away from the true value. In contrast, FFs achieved the lowest error in identifying the true ATE, outperforming both statistical matching and CNFs.

Our results demonstrate that Frugal Flows can correctly identify causal relationships under ideal conditions, confirming that they are a valid, efficient way to parameterise a causal model using deep learning architectures. A drawback of FFs is that they need large datasets to accurately infer causal margins. Additionally, the complexity of data dependencies might require careful hyperparameter tuning to prevent the copula from overfitting, which could bias the inference of the causal relationships. Because of these challenges, we do not recommend using FFs on real-world datasets for statistically inferring treatment effect sizes, as causal benchmark datasets are usually small.

### Benchmarking and Validation

In this section we present the results of multiple causal inference methods on data generated from FFs trained on two real-world datasets. The first is the Lalonde data, taken from a randomised control trial to study the effect of a temporary employment program in the US on post intervention income level (LaLonde, 1986). The second is an observational dataset used to quantify the effect of individuals' 401(k) eligibility on their accumulated net assets, in the presence of several relevant covariates (Abadie, 2003). Both datasets have a binary treatment and continuous outcome. Appendix D.3 can be referred to for a more comprehensive description of the data. In addition, we present diagnostics on the quality of the model fit in Appendix D.3.6, and the loss optimization for both datasets is presented in Appendix D.3.7.

FFs were fitted to both datasets and used to simulate data with an ATE of \(1000\). We simulate 50 datasets of size \(N=1000\) from three different cases each: i) no confounding, ii) with confounding according to the propensity flow inferred in the model fitting, and iii) with propensity flow confounding **and** unobserved confounding introduced via a Gaussian copula. A variety of causal inference methods (see Appendix D.3.4 for a more detailed description) were fit to the data sets, including a difference of means (DoMs) estimate which is an unbiased estimator of the treatment effect for randomised data. The inferred ATEs across all runs are presented in Figure 3 and Figure 4.

In both cases, all inference methods demonstrate no bias when fitted to unconfounded data. With real-world confounding, most methods estimate the correct ATE in Figure 4, whereas the DoMs shows a substantial bias from the ground truth. In Figure 3 however, all methods infer the correct ATE including DoMs. This is not surprising as the original data was randomised; the propensity flow here appears to simply add more noise to the outcomes. Finally, we note that all causal inference methods show confounding bias in the far right hand plots, demonstrating that FFs can simulate data with replicate the effects of hidden confounding.

Figure 3: Boxplot of ATE estimates from 10 inference methods, estimated across 50 different samples from a FF trained on the Lalonde dataset. The dotted red line represents the customized ATE of samples generated from the trained Frugal Flow.

## 5 Conclusions

We introduce Frugal Flows, a novel likelihood-based model that leverages NFs to flexibly learn the data-generating process while directly targeting the marginal causal quantities inferred from observational data. Our proposed model addresses the limitations of existing methods by explicitly parameterising the causal margin. FFs offer significant improvements in generating benchmark datasets for validating causal methods, particularly in scenarios with customizable degrees of unobserved confounding. To our knowledge, FFs are the first generative model that allows for exact parameterisation of causal margins, including binary outcomes from logistic and probit margins.

### Limitations and Future Work

Our experiments validated the empirical effectiveness of FFs, showing that they can infer the correct form of causal margins on confounded data simulations. Despite these promising results, FFs come with certain limitations that need to be addressed in future research. NFs require extensive hyperparameter tuning, which can be computationally intensive and time-consuming. Moreover, we see that FFs perform better in inference tasks with larger datasets. Future work could explore alternative ML copula methods and architectures that may be more effective for smaller datasets. Fortunately, this is less problematic for simulation as specification of the exact causal margin is left to the user. Additionally, the dequantising mechanism used by FFs implicitly shuffles the order of discrete samples, potentially losing some inherent structure in the data, making FFs less suitable for categorical datasets without implicit ordering.

In summary, Frugal Flows offer a novel approach to causal inference and model validation that combines flexibility with exact parameterisation of causal effects. Future work will refine the inference capabilities and extend the applicability of FFs to a wider range of data types and sizes.

Figure 4: Boxplot of ATE estimates from 10 inference methods, estimated across 50 different samples from a FF trained on the e401(k) dataset. The dotted red line represents the customized ATE of samples generated from the trained Frugal Flow.