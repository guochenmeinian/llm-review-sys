# Doob's Lagrangian: A Sample-Efficient Variational Approach to Transition Path Sampling

Yuanqi Du\({}^{*}\)\({}^{1}\) &Michael Plainer\({}^{*}\)\({}^{2,3,4,5}\) &Rob Brekelmans\({}^{*}\)\({}^{6}\) &Chenru Duan \({}^{7,8}\)

Frank Noe \({}^{4,9,10}\) &Carla P. Gomes \({}^{1}\) &Alan Aspuru-Guzik \({}^{6,11}\) &Kirill Neklyudov \({}^{12,13}\)

\({}^{1}\)Cornell University \({}^{2}\)Zuse School ELIZA \({}^{3}\)Technische Universitat Berlin

\({}^{4}\)Freie Universitat Berlin \({}^{5}\)Berlin Institute for the Foundations of Learning and Data

\({}^{6}\)Vector Institute \({}^{7}\)Massachusetts Institute of Technology \({}^{8}\)Deep Principle, Inc.

\({}^{9}\)Rice University \({}^{10}\)Microsoft Research AI4Science \({}^{11}\)University of Toronto

\({}^{12}\)Universite de Montreal \({}^{13}\)Mila Quebec AI Institute

Equal contribution. Correspondence: k.necludov@gmail.com (Kirill Neklyudov)

###### Abstract

Rare event sampling in dynamical systems is a fundamental problem arising in the natural sciences, which poses significant computational challenges due to an exponentially large space of trajectories. For settings where the dynamical system of interest follows a Brownian motion with known drift, the question of conditioning the process to reach a given endpoint or desired rare event is definitively answered by Doob's \(h\)-transform. However, the naive estimation of this transform is infeasible, as it requires simulating sufficiently many forward trajectories to estimate rare event probabilities. In this work, we propose a variational formulation of Doob's \(h\)-transform as an optimization problem over trajectories between a given initial point and the desired ending point. To solve this optimization, we propose a simulation-free training objective with a model parameterization that imposes the desired boundary conditions by design. Our approach significantly reduces the search space over trajectories and avoids expensive trajectory simulation and inefficient importance sampling estimators which are required in existing methods. We demonstrate the ability of our method to find feasible transition paths on real-world molecular simulation and protein folding tasks.

## 1 Introduction

Conditioning a stochastic process to obey a particular endpoint distribution, satisfy desired terminal conditions, or observe a rare event is a problem with a long history (Schrodinger, 1932; Doob, 1957) and wide-ranging applications from generative modeling (De Bortoli et al., 2021; Chen et al., 2021; Liu et al., 2022, 2023; Somnath et al., 2023) to molecular simulation (Anderson, 2007; Wu et al., 2022; Plainer et al., 2023; Holdijk et al., 2023), drug discovery (Kirmizialtin et al., 2012, 2015; Dickson, 2018), and materials science (Xi et al., 2013; Selli et al., 2016; Sharma et al., 2016).

**Transition Path Sampling.** In this work, we take a particular interest in the problem of _transition path sampling_ (TPS) in computational chemistry (Dellago et al., 2002; Weinan and Vanden-Eijnden, 2010), which attempts to describe how molecules transition between local energy minima or metastable states under random fluctuations or the influence of external forces. Understanding such transitions has numerous applications for combustion, catalysis, battery, material design, and protein folding (Zeng et al., 2020; Klucznik et al., 2024; Blau et al., 2021; Noe et al., 2009; Escobedo et al., 2009).

While the TPS problem is often framed as finding the'most probable path' transitioning between states (Durr and Bach, 1978; Vanden-Eijnden and Heymann, 2008), we build upon connections between TPS and Doob's \(h\)-transform (Das et al., 2019, 2021, 2022; Koehl and Orland, 2022; Singh and Limmer, 2023) and seek to match the _full_ posterior distribution over conditioned processes.

**Doob's \(h\)-Transform.** For Brownian motion diffusion processes, conditioning is known to be achieved by Doob's \(h\)-transform (Doob, 1957; Sarkka and Solin, 2019). However, solving this problem amounts to estimating rare event probabilities or matching a complex target distribution. Approaches which involve simulation of trajectories to construct Monte Carlo expectations or importance sampling estimators (Papaspiliopoulos and Roberts, 2012; Schauer et al., 2017; Yan et al., 2022; Holdijk et al., 2023) can be extremely inefficient if the target event is rare or endpoint distribution is difficult to match. Recent methods based on score matching (Heng et al., 2021) or nonlinear Feynman-Kac formula (Chopin et al., 2023) still require simulation during optimization.

**Variational Formulation of Doob's \(h\)-Transform.** In this work, we propose a variational formulation of Doob's \(h\)-transform as the solution to an optimization on the space of paths of probability distributions. We focus on solving for the Doob transform conditioning on a particular terminal point, which is natural in the TPS setting (see Fig. 1). Taking inspiration from recent bridge matching methods (Peluchetti, 2021, 2023; Liu et al., 2022; Lipman et al., 2022; Shi et al., 2023; Liu et al., 2023a), we propose a parameterization with the following attractive features.

1. **Every Sample Matters.** In contrast to most existing approaches, our training method is _simulation-free_, thereby avoiding computationally wasteful simulation methods to estimate rare-event probabilities and inefficient importance or rejection sampling. We thus refer to our approach as being _sample-efficient_.
2. **Optimization over Sampling.** We propose an expressive variational family of approximations to the conditioned process, which are tractable to sample and can be optimized using neural networks with end-to-end backpropagation.
3. **Problem-Informed Parameterization.** Our parameterization enforces the boundary conditions _by design_, thereby reducing the search space for optimization and efficiently making use of the conditioning information.

We begin by linking the problem of transition path sampling to the Doob's \(h\)-transform and recalling background results in Sec. 2. We present our variational formulation in Sec. 3.1 and detail our optimization algorithm throughout Sec. 3.2. We demonstrate the ability of our approach to achieve comparable performance to Markov Chain Monte Carlo (MCMC) methods with notably improved efficiency on synthetic, and real-world molecular simulation tasks in Sec. 5.

## 2 Background

### Transition Path Sampling

Consider a forward or reference stochastic process with states \(x_{t}\) and the density of transition probability \(_{t+dt}(y|x_{t}=x)(x_{t+dt}=y\,|\,x_{t}=x)\). Starting from an initial point \(x_{0}=A\), the probability density of a discrete-time path is given as

\[(x_{T},,x_{dt}\,|\,x_{0}=A)=_{t=dt}^{T-dt}(x_{t+dt}\,|\,x_{ t})(x_{dt}\,|\,x_{0}=A).\] (1)

The problem of rare event sampling aims to condition this reference stochastic process on some event at time \(T\), for example, that the final state belongs to a particular set \(x_{T}\). We are interested in

Figure 1: Given reference dynamics, transition path sampling seeks to capture the conditional or posterior distribution over paths which reach a terminal set \(x_{T}\). However, simulating the reference dynamics (blue) can be wasteful since we rarely obtain paths (orange) which reach (the vicinity of) the terminal set \(\). This is a major challenge for techniques based on importance sampling or Monte Carlo estimation, even when adding a control term to the reference dynamics. By contrast, our approach optimizes a tractable variational distribution over transition paths with a parameterization which satisfies the initial and terminal conditions by design.

sampling from the entire _transition path_, namely the posterior distribution over intermediate states

\[(x_{T-dt},,x_{dt}\,|\,x_{0}=A,x_{T})= ,x_{T-dt}\,,x_{dt}\,|\,x_{0}=A)}{(x_{T}\,|\,x _{0}=A)}.\] (2)

Moving to continuous time, we focus on the transition path sampling problem in the case where the reference process is given by a Brownian motion. In particular, we are motivated by applications in computational chemistry (Dellago et al., 2002; Weinan and Vanden-Eijnden, 2010), where the reference process is given by molecular dynamics following either overdamped Langevin dynamics,

\[dx_{t}=-( M)^{-1}_{x}U(x_{t}) dt+( M)^{- }{{2}}}} dW_{t}\,,\] (3)

or the second-order Langevin dynamics with spatial coordinates \(_{t}\) and velocities \(_{t}\),

\[d_{t}\,=_{t} dt\,, d_{t}\,=-M^{-1} _{x}U(_{t})-_{t} dt+M^{-}{ {2}}}} dW_{t}\,.\] (4)

for a potential energy function \(U\), where \(W_{t}\) denotes the Wiener process. Note that \(k_{B}\) is the Boltzman constant times temperature, \(M\) is the mass matrix, and \(\) is the friction coefficient.

### Doob's \(h\)-transform

Doob's \(h\)-transform addresses the question of conditioning a reference Brownian motion to satisfy a terminal condition such as \(x_{T}\), thereby providing an avenue to solve the transition path sampling problem described above. Without loss of generality, and to provide a unified treatment of the dynamics in (3)-(4), we consider the forward or reference stochastic differential equation (SDE),

\[^{}_{0:T}: dx_{t}=b_{t}(x_{t})  dt+_{t}\ dW_{t}\,, x_{0}_{0}\,,\] (5)

with drift vector field \(b_{t}:^{N}^{N}\) and diffusion coefficient matrix \(_{t}^{N N}\) such that \(G_{t}:=_{t}_{t}^{T}\) is positive definite.2

\[x_{t}=_{t}\\ _{t},\ b_{t}(x_{t})=_{t}\\ -M^{-1}_{x}U(_{t})-_{t},\ G_{t}= 0\\ 00\\ M^{-}{{2}}}}.\]

 We denote the induced path measure as \(^{}_{0:T}(([0,T]^{N}))\), i.e. a measure over continuous functions from time to \(^{N}\).

Remarkably, Doob's \(h\)-transform (Doob, 1957; Sarkka and Solin, 2019, Sec. 7.5) shows that conditioning the reference process (5) on \(x_{T}\) results in another Brownian motion process.

**Proposition 1**.: [Jamison (1975, Thm. 2)] _Let \(h_{}(x,t)_{T}(x_{T}\,|\,x_{t}=x)\) denote the conditional transition probability of the reference process in (5). Then,_

\[^{*}_{0:T}: dx_{t|T}=b_{t}(x_{t|T})+2G_{t} _{x} h_{}(x_{t|T},t) dt+_{t}\ dW_{t} x _{0}_{0}\] (6)

_where we use \(x_{t|T}\) to denote a conditional process. The SDE in (6) is associated with the following transition probabilities for \(s<t<T\),_

\[_{t}(y\,|\,x_{s}=x,x_{T})=}(y,t)}{h_{ }(x,s)}_{t}(y\,|\,x_{s}=x),\] (7)

_Note that all of our subsequent results hold for the case when \(\) is a point-mass, with the only change being that the \(h\)-function becomes a density, \(h_{B}(x,t)=_{T}(B\,|\,x_{t}=x)\)._

See App. A.1 for proof, and note that (7) is simply an application of Bayes rule \(_{t}(y\,|\,x_{s}=x,x_{T})=_{T}(x_{T}|x_{t}= y)_{t}(y\,|\,x_{s}=x)/_{T}(x_{T}|x_{s}=x)\) with the unconditioned or reference transition probability as the prior. Furthermore, the conditioned transition probabilities in (7) allow us to directly construct the transition path (2). Using Bayes rule, we have

\[(x_{T-dt},,x_{dt}\,|\,x_{0}=A,x_{T})=}(x_{T-dt},T-dt)}{h_{}(A,0)}(x_{T-dt},x_{dt}\,|\,x_{0}=A)\]

after telescoping cancellation of \(h\)-functions and rewriting the denominator in (2) as \(h_{}(A,0)\) Thus, we can solve the TPS problem by exactly solving for the \(h\)-function and simulating the SDE in (6).

Finally, the \(h\)-process and temporal marginals \(_{t}(x|x_{0}=A,x_{T})\) of the conditioned process satisfy the following forward and backward Kolmogorov equations, which will be useful in deriving our variational objectives in the next section. Note, we use \(_{x},=()\) for the divergence operator, and we use \(_{t|0,T}\) to indicate the dependence on both \(x_{0}=A\) (via the initial condition of (8a)) and \(x_{T}\) (via the \(h\)-transform \(h_{}\)). See App. A.1 for the proof.

**Proposition 2**.: _The following PDEs are obeyed by (a) the density of the conditioned process \(_{t|0,T}(x)_{t}(x\,|\,x_{0}=A,x_{T})\) and (b) the \(h\)-function \(h_{}(x,t)\),_

\[(x)}{ t}+_{x },_{t|0,T}(x)b_{t}(x)+2G_{t}_{x} h_{}(x,t) -_{ij}(G_{t})_{ij}}{ x_{i}  x_{j}}_{t|0,T}(x)=0\,,\] (8a) \[}(x,t)}{ t}+ _{x}h_{}(x,t),b_{t}(x)+_{ij}(G_{t})_{ij} }{ x_{i} x_{j}}h_{}(x,t)=0\,.\] (8b)

_Reparameterizing (8b) in terms of \(s_{B}(x,t) h_{}(x,t)\), we can also write_

\[}(x,t)}{ t}+  s_{}(x,t),G_{t} s_{}(x,t)+  s_{}(x,t),b_{t}(x)+_{ij}(G_{ t})_{ij}}{ x_{i} x_{j}}s_{}(x,t)=0.\] (8c)

## 3 Method

We first present a novel variational objective whose minimum corresponds to the Doob \(h\)-transform in Sec. 3.1, and then propose an efficient parameterization to solve for the \(h\)-transform in Sec. 3.2.

### Doob's Lagrangian

Consider reference dynamics given in the form of either (3) or (4), with known drift \(b_{t}\) or energy \(U\). We will restrict our attention to conditioning on a terminal rare event of reaching a given endpoint \(x_{T}=B\), along with an initial point \(x_{0}=A\). We approach solving for Doob's \(h\)-transform via a _least action principle_ where, in the following theorem, we define a Lagrangian action whose minimization yields the optimal \(q_{t|0,T}^{*}(x)=_{t|0,T}(x)\) and \(v_{t|0,T}^{*}(x)=_{x} h_{B}(x,t)\) from Prop. 1 and 2.

**Theorem 1**.: _The following Lagrangian action functional has a unique solution which matches the Doob \(h\)-transform in Prop. 2,_

\[= _{q,v}_{0}^{T}dt\  dx\ q_{t|0,T}(x)v_{t|0,T}(x ),G_{t}\ v_{t|0,T}(x)\,,\] (9a) \[ (x)}{ t}=-_{x },q_{t|0,T}(x)b_{t}(x)+2G_{t}\ v_{t|0,T}(x)+_{ ij}(G_{t})_{ij}}{ x_{i} x_{j}}q_{t|0,T}(x),\] (9b) \[q_{0}(x)=(x-A), q_{T}(x)=(x-B)\,.\] (9c)

_The optimal \(q_{t|0,T}^{*}(x)\) obeys (8a), and \(v_{t|0,T}^{*}(x)=_{x} h_{B}(x,t)=_{x}s_{B}(x,t)\) obeys (8b)-(8c)._

This objective will form the basis for our computational approach, with proof of Thm. 1 deferred to App. A.2. We proceed briefly to contextualize our variational objective and highlight several optimization challenges which will be solved by our proposed parameterization in Sec. 3.2.

**Unconstrained Dual Objective.** Introducing Lagrange multipliers to enforce the constraints in (9b)\(\)(9c) and eliminating \(v_{t|0,T}\), we obtain an alternative, unconstrained version of (9a).

**Corollary 1**.: _The Lagrangian objective in Thm. 1 which solves Doob's \(h\)-transform is equivalent to_

\[=_{q_{t|0,T}}_{z}\ s_{B}(B,T)-s_{B}(A,0)-_{0}^{T}\!\!dt \!dx\ q_{t|0,T}}{ t}+  s_{B},G_{t} s_{B}+ s_{B},b_{t} +,G_{t} s_{B}\]

_if \(q_{t|0,T}\) satisfies (9c). Note \(v_{t|0,T}(x)=_{x}s_{B}(x,t)\), with \(s_{B}^{*}(x,t)= h_{B}(x,t)\) at optimality. 3_

This objective is similar to the objectives optimized by Action Matching methods (Neklyudov et al., 2023, 2024). Notably, the objective in Cor. 1 is expressed _directly_ in terms of the (log) of the \(h\)-function for fixed conditioning information \(x_{T}=B\). We also note that the Hamilton Jacobi-style quantity, whose expectation appears in the final term, is zero at optimality in (8c) of Prop. 2.

**Path Measure Perspective.** We next relate our variational objective in Thm.1 to a KL divergence optimization over path measures. Let \(^{}_{0:T}\) denote the law of the reference SDE in (5) with fixed \(^{}_{0}=(x_{0}-A)\). Let \(^{v}_{0:T}\) denote the law of a controlled process similar to (6), but with a variational \(v_{t|0,T}\) in place of \(_{x} h_{}\),

\[^{v}_{0:T}: dx_{t}=(b_{t}(x_{t|T})+2G_{t}\;v_{t|0,T}(x_{ t|T})) dt+_{t}\;dW_{t}\,, x_{0}=A.\] (10)

Note that the density \(q_{t|0,T}\) of \(^{v}_{0:T}\) evolve according to the Fokker-Planck equation in (9b)(Sarkka and Solin, 2019, Sec. 5.2). Using the Girsanov Theorem, the objective in (9a) can then be viewed as a KL divergence minimization over path measures \(^{v}_{0:T}\) which satisfy the boundary constraints.

**Corollary 2**.: _The following Schrodinger Bridge (SB) problem_

\[_{^{v}_{0:T}^{v}_{0}=_{A},^{v}_{T}=_{B}}D_{KL}[ ^{v}_{0:T}:^{}_{0:T}]\] (11)

_yields the path measure \(^{*}_{0:T}\) associated with the SDE in (6) as its unique minimizing argument. The temporal marginals of \(^{*}_{0:T}\) are equal to those which optimize the Lagrangian objective in Thm.1._

Our Lagrangian action minimization thus corresponds to the solution of an SB problem (Schrodinger, 1932; Leonard, 2014) with Dirac delta functions as the endpoint measures. Our objective in (9a) particularly resembles optimal control formulations of SB (Chen et al., 2016, 2021b, Prob. 4.4, 5.3). While it is well-known that the Doob \(h\)-transform (and large deviation theory more generally) plays a role in the solution to SB problems (Jamison, 1975; Leonard, 2014), our interest in the transition path sampling problem leads to specific computational decisions below. See Sec.4 for further discussion.

**Challenges of Optimizing (9a).** We highlight several distinctive features of our problem which inform the development of new computational methods in Sec.3.2.

1. First, we perform optimization over the _first_ argument of the KL divergence in (11), indicating that we need to be able to efficiently sample from the conditioned process in (10) or \(q_{t|0,T}\) in (9). This appears challenging due to the nonlinearity of both the reference and variational drifts, \(b_{t}\) and \(v_{t|0,T}\).
2. For a given \(q_{t|0,T}\), it can be difficult to solve for \(v_{t|0,T}\) which satisfies the Fokker-Planck equation in (9b) or \( s\) which solves the inner optimization in Cor.1.
3. Finally, we would like to strictly enforce the boundary constraints on \(q_{t|0,T}\) or \(^{v}_{0:T}\) to avoid simulating or wasting computation on trajectories for which \(x_{T} B\).

In fact, our parameterization of \(q_{t|0,T}\) in Sec.3.2 will _completely avoid_ simulation of the SDE in (10) during training (Challenge 1), provide _analytic_ solutions for \(v_{t|0,T}\) satisfying (9b) with a given \(q_{t|0,T}\) (Challenge 2), and _exactly_ enforce the boundary constraints (Challenge 3).

### Computational Approach

We now propose a family of Gaussian (mixture) path parameterizations \(q_{t|0,T}\) which overcome the computational challenges posed in the previous section, while still maintaining expressivity. We present all aspects of our proposed method in the context of the first-order dynamics (3) in Sec.3.2.1, before presenting extensions to mixture paths and the second-order setting (4) in Sec.3.2.2-3.2.3.

#### 3.2.1 First-Order Dynamics and General Approach

**Tractable Drift \(v_{t|0,T}\) for Variational Doob Objective.** We begin by considering a modification of the Fokker-Planck constraint in (9b), with all drift terms absorbed into a single vector field \(u_{t|0,T}\),

\[(x)}{ t}=-_{x},q_{t|0,T}(x )\;u_{t|0,T}(x)+_{ij}(G_{t})_{ij}}{  x_{i} x_{j}}q_{t|0,T}(x).\] (12)

For arbitrary \(q_{t|0,T}\), solving for _any_\(u_{t|0,T}(x)\) satisfying (12) can be a difficult optimization problem, whose solution is not unique without some cost-minimizing assumption (Neklyudov et al., 2023).

To sidestep this optimization, and address Challenge2, we restrict attention to variational families of \(q_{t|0,T}\) where it is _analytically tractable_ to calculate a vector field \(u^{(q,)}_{t|0,T}\) which satisfies (12). We first consider the family of Gaussian paths \(_{G}\), in similar fashion to (conditional) flow matching methods (Lipman et al., 2022; Tong et al., 2023; Liu et al., 2023a), with proof in App.B.

**Proposition 3**.: _For the family of endpoint-conditioned marginals \(q_{t|0,T}(x)=(x\,|\,_{t|0,T},_{t|0,T})\),_

\[u_{t|0,T}^{(q,)}(x)}{  t}+}{ t}_ {t|0,T}^{-1}-G_{t}\;_{t|0,T}^{-1}x-_{t|0,T}\] (13)

_satisfies the Fokker-Planck equation (12) for \(q_{t|0,T}\) and diffusion coefficients \(G_{t}=_{t}_{t}^{T}\)._

Given \(u_{t|0,T}^{(q,)}\) corresponding to \(q_{t|0,T}\), we can simply solve for the \(v_{t|0,T}\) satisfying the Fokker-Planck equation in (9b) in our variational Doob objective (Thm. 1). Since \(G_{t}\) was assumed to be invertible and the base drift \(b_{t}\) is known, we have

\[v_{t|0,T}^{(q,)}(x)=(G_{t})^{-1}u_{t|0,T}^{(q,) }(x)-b_{t}(x).\] (14)

We may now evaluate terms involving \(v_{t|0,T}\) in our Lagrangian objective in (9) using (14) directly, without spending effort to solve an inner minimization over \(v_{t|0,T}\) (thus addressing Challenge 2).

**Optimization over \(q_{t|0,T}\) satisfying Boundary Constraints.** Given the ability to evaluate \(v_{t|0,T}^{(q,)}\) for a given \(q_{t|0,T}_{G}\) as above, our variational Doob objective in (9a) reduces to a single optimization over the marginals \(q_{t|0,T}\) of a conditioned process which satisfies the boundary conditions (9c).

We consider parameterizing the mean \(_{t|0,T}\) and covariance \(_{t|0,T}\) of our Gaussian path \(q_{t|0,T}\) using a neural network. For simplicity, we consider a diagonal parameterization \(_{t|0,T}=(\{_{t|0,T,d}^{2}\}_{d=1}^{D})\). We parameterize a neural network \(_{}:[0,T]^{D}^{D} ^{D}^{D}\) which inputs time \(t\) and boundary conditions \(x_{0}=A,x_{T}=B\), and outputs vectors of mean perturbations and per-dimension variances. Finally, using index notation to separate the output, we construct

\[x_{t|0,T} =_{t|0,T}^{()}+_{t|0,T}^{()}\;, (0,_{D}).\] (15a) \[_{t|0,T}^{()} =1-A+\;B+1- _{}(t,A,B)_{[:D]}\] (15b) \[_{t|0,T}^{()} =1- _{}(t,A,B)_{[D:]}+_{}^{2} _{D}.\] (15c)

Crucially, our Gaussian parameterization addresses Challenge 1, in that we can easily draw samples \(x_{t|0,T} q_{t|0,T}\) from our variational conditioned process (9b) _without simulating_ the corresponding SDE with nonlinear drift (10). Further, the coefficients in (15b) and (15c) ensure that, as \(t 0\) or \(t T\), our parameterization satisfies the (smoothed) boundary conditions by design (Challenge 3). Although we add \(_{}^{2}\) to ensure invertibility of \(_{t|0,T}\) (see (13)), we preserve \(q_{0}(x_{0})=(x_{0}\,|\,A,_{}^{2}_{D}) (x_{0}-A)\) and \(q_{T}(x_{T})=(x_{T}\,|\,B,_{}^{2}_{D}) (x_{T}-B)\).

**Reparameterization Gradients.** Having shown that our parameterization satisfies the constraints (9b)-(9c) by design, we can finally optimize our variational Doob objective with respect to \(q_{t|0,T}_{G}\) using the reparameterization trick (Kingma and Welling, 2013; Rezende et al., 2014). In particular, for the expectation at each \(t\) in (9a), we rewrite

\[_{}_{q_{t|0,T}^{()}(x)}v_{t|0,T }^{(q,)}(x),G_{t}\;v_{t|0,T}^{(q,)}(x)=_{(|0,1_{D})}_{}v_{t|0,T}^{(q, )}g(t,;),G_{t}\;v_{t|0,T}^{(q,)} g(t,;),\]

where \(x=g(t,;)\) is the mapping in (15) and \(v_{t|0,T}^{(q,)}\) depends on \(\) via \(_{t|0,T}^{()}\), \(_{t|0,T}^{()}\) in (13)-(14).

**Full Training Algorithm.** In practice, we sample a batch of times \(\{t_{i}\}_{i=1}^{M}\) uniformly from the interval \(t[0,T]\). For each time point, we approximate the gradient using a single-sample estimate of the expectation above (or (9)), which yields a simulation-free training procedure. The full training algorithm is outlined in Alg. 1.

**Sampling of Trajectories.** While we sample directly from \(q_{t|0,T}^{()}\) during training, we can sample full trajectories which obey this sequence of marginals at test time (Alg. 2). In particular, we simulate SDE trajectories with drift \(u_{t|0,T}^{(q,)}(x)\) and diffusion coefficient \(G_{t}\) using an appropriate solver. Note that this generation scheme sidesteps computationally expensive evaluation of the force field or base drift \(b_{t}(x_{t})\). We visualize example sampling trajectories in Fig. 2.

#### 3.2.2 Second-Order Dynamics

To handle the case of the second-order dynamics in (4), we can adapt our recipe from the previous section with minimal modifications by extending the state space \(x^{D}\) to include velocities \(\), with \(x=(,)^{2D}\). However, note that the dynamics in (4) are no longer stochastic in the spatial coordinates \(\). To ensure invertibility of \(G_{t}\) and existence of the \(h\)-transform, we add a small nonzero diffusion coefficient in the coordinate space \(\), so that the reference process in Eq. (5) is given by

\[x_{t}=_{t}\\ _{t}, b_{t}(x_{t})=_{t}\\ -M^{-1}_{x}U(_{t})-_{t},_{t}= _{}_{D}&0\\ 0&M^{-}{{2}}}T}.\] (16)

All steps in our algorithm proceed in similar fashion to Sec. 3.2.1. We now parameterize \(q_{t|0,T}(,)\) using \(_{}:[0,T]^{2D}^{2D} ^{2D}^{2D}\), which outputs mean perturbations and per-dimension variances to calculate \(u_{t|0,T}^{}\) and \(_{t|0,T}^{}\), \(_{t|0,T}^{}\) and sample \((,)\), as in (15). Note that we parameterize \(_{t|0,T}^{},_{t|0,T}^{}\) separately, matching the block diagonal form of (16). We calculate \(v_{t|0,T}^{(q)}(,)[v_{t|0,T}^{(q)},v_{t|0,T}^{ (q)}]\) from \(u_{t|0,T}^{(q)}(,)=[u_{t|0,T}^{(q)},u_{t|0,T}^{(q)}]\) as in (13)-(14), with \(G_{t}^{-1}=(_{t}_{t}^{T})^{-1}\) given by (16). The Lagrangian objective in (9) minimizes the norm of the concatenated vector \(v_{t|0,T}^{(q)}(,)\), which depends on the reference drift \(b_{t}(,)\) in (16).

#### 3.2.3 Gaussian Mixture Paths

Note that the true Doob \(h\)-transform may not yield marginal distributions which are unimodal Gaussians as in the previous section. To increase the expressivity of our variational family of conditioned processes, we now extend our parameterization to mixtures of Gaussians, \(q_{t|0,T}_{}^{K}\). Given a set of \(K\) mixture weights \(\{w^{k}\}_{k=1}^{K}\) and component Gaussian paths \(\{q_{t|0,T}^{k}\}_{k=1}^{K}\), the following identity allows us to obtain the drift \(u_{t|0,T}^{(q,)}\) of the corresponding mixture distribution \(q_{t|0,T}\).

**Proposition 4**.: _Given a set of processes \(q_{t|0,T}^{k}(x)\) and mixtures weights \(w^{k}\), the vector field satisfying the Fokker-Planck equation in (12) for the mixture \(q_{t|0,T}(x)=_{k}w^{k}q_{t|0,T}^{k}(x)\) is given by_

\[u_{t|0,T}^{(q,)}(x)=_{k=1}^{K}q_{t|0,T}^{k}(x)}{_{j=1 }^{K}w^{j}q_{t|0,T}^{j}(x)}u_{t|0,T}^{(q,k)}(x)\,,\] (17)

_where \(u_{t|0,T}^{(q,k)}(x)\) satisfies the Fokker-Planck equation in (12) for \(q_{t|0,T}^{k}(x)\). This identity holds for both first-order dynamics in spatial coordinates only or second-order dynamics in \(x=(,)\)._

Finally, we can calculate \(v_{t|0,T}^{(q,)}(x)\) by comparing \(u_{t|0,T}^{(q,)}(x)\) for the mixture of Gaussian path \(q_{t|0,T}_{}^{K}\) to the reference drift \(b_{t}(x)\) as in (14), and proceed to minimize its norm as in (9). In practice, we use Gumbel softmax reparameterization gradients (Maddison et al., 2016; Jang et al., 2017) to optimize the mixture weights \(\{w^{k}\}_{k=1}^{K}\) alongside the neural network parameters \(\{^{k}\}_{k=1}^{K}\) for each Gaussian component \(\{_{t|0,T}^{()},_{t|0,T}^{()}\}_{k=1}^{K}\) and either first- or second-order dynamics.

## 4 Related Work

**(Aligned) Schrodinger Bridge Matching Methods.** Many existing 'bridge matching' approaches (Shi et al., 2023; Peluchetti, 2021, 2023; Liu et al., 2022; Lipman et al., 2022; Liu et al., 2023b) for SB and generative modeling rely on convenient properties of Brownian bridges and would require calculating \(h\)-transforms to simulate bridges for general reference processes. Our conditionalGaussian path parameterization is similar to Liu et al. (2023); Neklyudov et al. (2024), where analytic bridges are not available for SB problems with nonlinear reference drift or general costs.

Somnath et al. (2023); Liu et al. (2023) attempt to solve the SB problem given access to aligned data \(x_{0},x_{T} q_{0,T}^{}\) assumed to be drawn from an optimal coupling. While the method in Somnath et al. (2023) involves approximating an \(h\)-transform, their goal is to obtain an unconditioned vector field \(v_{t}\) to simulate a Markov process. However, De Bortoli et al. (2023) use Doob's \(h\)-transform to argue the learned Markov process will not preserve the empirical coupling unless \(q_{0,T}^{}\) is the optimal coupling for the SB problem, and show that an 'augmented' \(v_{0,t}\) which conditions on \(x_{0}\) can correct this issue.

After training on a dataset of \(x_{0},x_{T} q_{0,T}^{}\) pairs using our method, we could consider using an (augmented) bridge matching objective (Shi et al., 2023; De Bortoli et al., 2023) to distill our learned \(v_{t|0,T}^{(q)}\) into a vector field \(v_{t}\) or \(v_{0,t}\) which does not condition on the endpoint. Our use of a Gaussian path parameterization with samples from a fixed endpoint coupling and no Markovian step corresponds to a simplified version of the conditional optimal control step in Liu et al. (2023).

**Transition Path Sampling.** We refer to the surveys of Dellago et al. (2002); Weinan and Vanden-Eijnden (2010); Bolhuis and Swenson (2021) for an overview of the TPS problem. Least action principles for TPS have a long history, building upon the Freidlin-Wentzell (Freidlin and Wentzell, 1998) and Onsager-Machlup (Onsager and Machlup, 1953; Durr and Bach, 1978) Lagrangian functionals in the zero-noise limit and finite-noise cases. In particular, the Onsager-Machlup functional relates maximum a posteriori estimators or'most probable (conditioned) paths' to the minimizers of an action functional similar to Thm. 1, where example algorithms include (Vanden-Eijnden and Heymann, 2008; Sheppard et al., 2008). By contrast, our approach targets the _entire_ posterior over transition paths using an expressive variational family. While Lu et al. (2017) provide analysis for the Gaussian family, we draw connections with Doob's \(h\)-transform and extend to mixtures of Gaussians.

Shooting methods are among the most popular for sampling the posterior of transition paths. From a path that satisfies the boundary conditions (obtained, e.g., using high-temperature simulations), shooting picks points and directions to propose alterations, then simulates new trajectories and accepts or rejects using Metropolis-Hastings (MH) (Juraszek and Bolhuis, 2008; Borrero and Dellago, 2016; Jung et al., 2017; Falkner et al., 2023; Jung et al., 2023). While the MCMC corrections yield theoretical guarantees, shooting methods involve expensive molecular dynamics (MD) simulations and need to balance high rejection rates with large changes in trajectories. One-way shooting methods sample paths efficiently but yield highly correlated samples. Two-way shooting methods, which we compare to in Sec. 5, are more expensive but typically sample diverse paths faster. Recent machine learning approaches (e.g. Plainer et al. (2023); Lelievre et al. (2023)) aim to reduce the need for MD.

Finally, various related methods rely on iterative simulation of SDE in (10) during training to learn the control drift term. Yan et al. (2022); Holdijk et al. (2023) are motivated from the perspective of stochastic optimal control, while Das et al. (2021); Rose et al. (2021) develop actor-critic methods using closely-related ideas from soft reinforcement learning. The variational method in Das et al. (2019) optimizes the rate function quantifying the probability of the rare events, while Singh and Limmer (2023) solves the Kolmogorov backward equation to learn the Doob's \(h\)-transform. However, all of these methods may be inefficient if the desired terminal state is sampled infrequently.

## 5 Experiments

We investigate the capabilities of our approach across a variety of different settings. We first illustrate features of our method on toy potentials before continuing to real-world molecular systems, including a commonly-used benchmark system, alanine dipeptide, and a small protein, Chignolin. The code behind our method is available at https://github.com/plainerman/variational-doob. Before diving into the experiments, we introduce the evaluation procedure and baseline methods.

**Evaluation metrics.** In our evaluation, we emphasize two key quantities: accuracy and efficiency. Efficiency is evaluated by the number of calls to the potential energy function, which requires extensive computation and dominates the runtime of larger molecules. For accuracy, we evaluate the log-likelihood of each sampled path and the maximum energy point (saddle point/transition state) along each sampled path. A good method samples many probable paths (i.e., high log-likelihood) and an accurate transition state (i.e., small maximum energy). See App. D for further details.

**Baselines.** We compare our approach against the MCMC-based two-way shooting method with uniform point selection with variable or fixed length trajectories. We found that two-way shooting produced the most diverse path ensembles among possible baselines, although the acceptance probability can be relatively low for systems dominated by diffusive dynamics (Brotzakis and Bolhuis, 2016) and might be improved by better shooting point selection. This baseline gives theoretical guarantees about the ensemble and thus can be considered as a proxy for the ground truth. In that sense, our goal is not to beat two-way shooting but to approximate it with fewer potential evaluations.

### Synthetic Datasets

**Muller-Brown Potential.** The Muller-Brown potential is a popular benchmark to study transition path sampling between metastable states. It consists of three local minima, and we aim to sample transition paths connecting state \(A\) and state \(B\) with a circular state definition. In Fig. 3, we visualize the potential and the sampled paths and can see that the same ensemble is sampled for both our method and two-way shooting. Our method exhibits a slightly reduced variance for unlikely transitions. In Table 1, we can observe that MCMC-based methods require many potential evaluations to achieve a good result, which comes from the low acceptance rate (especially when fixing the lengths of trajectories). Our method requires fewer energy evaluations (1 million vs. 1 billion) while finding paths with similar energy and likelihood. Note that the likelihood for variable approaches has been omitted, as it is governed by the number of steps in the trajectory and cannot be compared directly.

**Gaussian Mixture.** We further consider a potential in which the states are separated by a symmetric high-energy barrier that allows for two distinct reaction channels. In Fig. 3, we observe that a single Gaussian path cannot model a system with multiple modes of transition paths. Nevertheless, this issue can be resolved using a mixture of Gaussian paths, with slightly increased computational cost.

**The Case for Neural Networks.** According to our empirical study, the neural network parameterization of the Gaussian distribution statistics \(_{\,t\,|0,T},_{\,t\,|0,T}\) is an invaluable part of our framework. As an ablation, we consider parameterizing \(_{\,t\,|0,T},_{\,t\,|0,T}\) as piecewise linear splines whose intermediate points are updated using the same gradient-based optimizer as used for neural network training. In App. D.3, we report results comparing the W1 distance of learned marginals using neural network versus spline parameterizations, observing that splines yield inferior results even after an order of magnitude more potential function evaluations. We thus conclude that spline parameterizations are not competitive for learning transition paths and continue to focus on our neural-network approach.

### Second-order Dynamics and Molecular Systems

**Experiment Setup.** We evaluate our methods on real-world high-dimensional molecular systems governed by the second-order dynamics (4): _alanine dipeptide_ and _Chignolin_. Alanine dipeptide is a well-studied system of 22 atoms (66 total degrees of freedom), where the molecule can be described by two collective variables (CV): the dihedral angles \(\), \(\). Chignolin is a larger system consisting of 10 residues with 138 atoms (414 total degrees of freedom) that cannot be summarized as easily. We use an AMBER14 force field (Maier et al., 2015) implemented in OpenMM (Eastman et al., 2017) but use DMFF (Wang et al., 2023) to backpropagate through the energy evaluations.

   Method & \# Evaluations (\(\)) & Max Energy (\(\)) & MinMax Energy (\(\)) & Log-Likelihood (\(\)) & Max Log-Likelihood (\(\)) \\  MCMC (variable) & 3.53M & -13.77 \(\) 16.43 & -40.75 & - & - \\ MCMC & 1.03B & -17.80 \(\) 14.77 & -40.21 & 866.56 \(\) 17.00 & 907.15 \\ Ours & **1.28M** & -14.81 \(\) 13.73 & -40.56 & 858.50 \(\) 17.61 & 909.74 \\   

Table 1: Transition path sampling experiment for Müller-Brown potential. We report the number of potential evaluations needed to sample 1,000 paths, as well as the maximum energy and the likelihood of each path (including mean and standard deviation). The methods marked with ‘variable’ use a variable length setting. MinMax energy reports the lowest maximum energy across all paths (i.e., energy of lowest transition state).

**Alanine Dipeptide.** In Table 2, we report results for four variants of our models, which either predict Cartesian coordinates or internal coordinates in the form of bond lengths and dihedral angles (compare App. D.4), either with or without Gaussian mixture. For our method, operating in internal coordinates yields better results compared to Cartesian coordinates, where the internal coordinates are distributed similarly to Gaussians and our network does need not learn equivariances (Du et al., 2022). Similarly, Gaussian mixture paths perform slightly better than a single Gaussian path due to the additional expressiveness. We note that paths sampled with Gaussian mixture exhibit a larger variance in max energy as they represent multiple reaction channels.

We find that prior-informed definitions of the desired initial and target states (i.e., CV) are necessary for MCMC to work efficiently with fixed-length trajectories. Finding these CVs in practice is challenging and only possible in this instance because the molecule is small and well-studied. For the larger system size in Table 2, it becomes intractable to use MCMC to connect precise states \(A,B\) ('exact') instead of larger regions ('relaxed'), even with a single trajectory. Variable length MCMC with relaxed endpoint conditions with CV perform well on this task, but our method is competitive using fewer evaluations and more strict boundary conditions. Fixed-length MCMC, even with prior-informed knowledge, can only find 100 trajectories while needing 50 times more potential evaluations compared to variable length.

**Chignolin.** The folding dynamics of Chignolin already pose a challenge and have not yet been well-studied compared to alanine dipeptide. We illustrate the qualitative experimental results for this system in Fig. 4. Operating in Cartesian space, our model samples a feasible transition within 25.6M potential energy evaluation calls and a transition with a duration of \(T=1ps\).

## 6 Conclusion, Limitations and Future Work

In this paper, we propose an efficient computational framework for transition path sampling with Brownian dynamics. We formulate the transition path sampling problem by using Doob's \(h\)-transform to condition a reference stochastic process, and propose a variational formulation for efficient optimization. Specifically, we propose a simulation-free training objective and model parameterization that imposes boundary conditions as hard constraints. We compare our method with MCMC-based baselines and show comparable accuracy with lower computational costs on both synthetic datasets and real-world molecular systems. Our method is currently limited by rigidly defining states A and B to be a point mass with Gaussian noise instead of any arbitrary set. Finally, our method might be improved by accommodating variable length paths.

  Method & States & \# Evaluations (\(\)) & Max Energy (\(\)) & MinMax Energy (\(\)) \\  MCMC (variable length) & CV & 21.02M & 740.0 + 695.79 & 52.37 \\ MCMC* & CV & 1.29B* & 288.46 + 128.31 & 60.52 \\  MCMC (variable length) & relaxed & 187.54M & 412.65 + 334.70 & 26.97 \\ MCMC & relaxed &  10B & N/A & N/A \\  MCMC (variable length) & exact &  10B & N/A & N/A \\ MCMC & exact &  10B & N/A & N/A \\ Ours (Cartesian) & exact & **38.40M** & 726.40 + 0.07 & 726.18 \\ Ours (Cartesian, 2 Mixtures) & exact & 51.20M & 709.38 + 162.37 & 513.72 \\ Ours (Cartesian, 5 Mixtures) & exact & 51.20M & 541.26 + 278.20 & 247.96 \\ Ours (Internal) & exact & **38.40M** & -14.62 + 0.02 & -14.67 \\ Ours (Internal, 2 Mixtures) & exact & 51.20M & -15.38 + 0.14 & -15.54 \\ Ours (Internal, 5 Mixtures) & exact & 51.20M & -15.50 + 0.31 & **-15.95** \\  

Table 2: Transition path sampling for alanine dipeptide. For MCMC methods, we compare different state definitions of \(,\): ‘CV’ uses \(,\) angles. ‘Exact’ uses a very small threshold of aligned root-mean-square deviation (RMSD) around reference states \(A,B\) (as in Ours). ‘Relaxed’ uses a larger threshold of RMSD around \(A,B\). The method marked with a * only samples 100 paths due to computational limitations, while others sample 1,000. Fields with N/A are intractable as a single trajectory requires more than 1 billion potential evaluations.

Figure 4: Transition path for the protein Chignolin. The energy plot a transition path in which the protein folds in \(T=1,000\) fs, and passes a high energy barrier at \(460fs\) with about \(3,000\) kJ/mol.