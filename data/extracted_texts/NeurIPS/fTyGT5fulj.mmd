# Curriculum Learning for Graph Neural Networks:

Which Edges Should We Learn First

 Zheng Zhang\({}^{}\) Junxiang Wang\({}^{}\) Liang Zhao\({}^{}\)

\({}^{}\)Emory University, Atlanta, GA \({}^{}\)NEC Labs America, Princeton, NJ

{zheng.zhang,liang.zhao}@emory.edu

{junxiang.wang}@alumni.emory.edu

###### Abstract

Graph Neural Networks (GNNs) have achieved great success in representing data with dependencies by recursively propagating and aggregating messages along the edges. However, edges in real-world graphs often have varying degrees of difficulty, and some edges may even be noisy to the downstream tasks. Therefore, existing GNNs may lead to suboptimal learned representations because they usually treat every edge in the graph equally. On the other hand, Curriculum Learning (CL), which mimics the human learning principle of learning data samples in a meaningful order, has been shown to be effective in improving the generalization ability and robustness of representation learners by gradually proceeding from easy to more difficult samples during training. Unfortunately, existing CL strategies are designed for independent data samples and cannot trivially generalize to handle data dependencies. To address these issues, we propose a novel CL strategy to gradually incorporate more edges into training according to their difficulty from easy to hard, where the degree of difficulty is measured by how well the edges are expected given the model training status. We demonstrate the strength of our proposed method in improving the generalization ability and robustness of learned representations through extensive experiments on nine synthetic datasets and nine real-world datasets. The code for our proposed method is available at https://github.com/rollingstonezz/Curriculum_learning_for_GNNs.

## 1 Introduction

Inspired by cognitive science studies [8; 33] that humans can benefit from the sequence of learning basic (easy) concepts first and advanced (hard) concepts later, curriculum learning (CL)  suggests training a machine learning model with easy data samples first and then gradually introducing more hard samples into the model according to a designed pace, where the difficulty of samples can usually be measured by their training loss . Many previous studies have shown that this easy-to-hard learning strategy can effectively improve the generalization ability of the model [2; 19; 15; 11; 35; 46], and some studies [19; 15; 11] have shown that CL strategies can also increase the robustness of the learned model against noisy training samples. An intuitive explanation is that in CL settings noisy data samples correspond to harder samples, and CL learner spends less time with the harder (noisy) samples to achieve better generalization performance and robustness.

Although CL strategies have achieved great success in many fields such as computer vision and natural language processing, existing methods are designed for independent data (such as images) while designing effective CL methods for data with dependencies has been largely underexplored. For example, in a citation network, two researchers with highly related research topics (e.g. machine learning and data mining) are more likely to collaborate with each other, while the reason behind a collaboration of two researchers with less related research topics (e.g. computer architecture and social science) might be more difficult to understand. Prediction on one sample impacts that of another, forming a graph structure that encompasses all samples connected by their dependencies. There aremany machine learning techniques for such graph-structured data, ranging from traditional models like conditional random field , graph kernels , to modern deep models like GNNs [29; 30; 52; 38; 49; 12; 53; 42]. However, traditional CL strategies are not designed to handle the curriculum of the dependencies between nodes in graph data, which are insufficient. Handling graph-structured data require not only considering the difficulty in individual samples, but also the difficulty of their dependencies to determine how to gradually composite correlated samples for learning.

As previous CL strategies indicated that an easy-to-hard learning sequence on data samples can improve the generalization and robustness performance, an intuitive question is whether a similar strategy on data dependencies that iteratively involves easy-to-hard edges in learning can also benefit. Unfortunately, there exists no trivial way to directly generalize existing CL strategies on independent data to handle data dependencies due to several unique challenges: (1) **Difficulty in quantifying edge selection criteria**. Existing CL studies on independent data often use supervised computable metrics (e.g. training loss) to quantify sample difficulty, but how to quantify the difficulties of understanding the dependencies between data samples which has no supervision is challenging. (2) **Difficulty in designing an appropriate curriculum to gradually involve edges**. Similar to the human learning process, the model should ideally retain a certain degree of freedom to adjust the pacing of including edges according to its own learning status. As existing CL methods for graph data typically use fixed pacing function to involve samples, they can not provide this flexibility. Designing an adaptive pacing function for handling graph data is difficult since it requires joint optimization of both supervised learning tasks on nodes and the number of chosen edges. (3) **Difficulty in ensuring convergence and a numerical steady process for CL in graphs**. Discrete changes in the number of edges can cause drift in the optimal model parameters between training iterations. How to guarantee a numerically stable learning process for CL on edges is challenging.

In order to address the aforementioned challenges, in this paper, we propose a novel CL algorithm named **R**elational **C**urriculum **L**earning (**RCL**) to improve the generalization ability and robustness of representation learners on data with dependencies. To address the first challenge, we propose an approach to select the edges by quantifying their corresponding difficulties in a self-supervised learning manner. Specifically, for each training iteration, we choose \(K\) easiest edges whose corresponding relations are most well-expected by the current model. Second, to design an appropriate learning pace for gradually involving more edges in training, we present the learning process as a concise optimization model, which automatically lets the model gradually increase the number \(K\) to involve more edges in training according to its own status. Third, to ensure convergence of optimizing the model, we propose an alternative optimization algorithm with a theoretical convergence guarantee and an edge reweighting scheme to smooth the graph structure transition. Finally, we demonstrate the superior performance of RCL compared to state-of-the-art comparison methods through extensive experiments on both synthetic and real-world datasets.

## 2 Related Works

Curriculum Learning (CL).Bengio et al. pioneered the concept of Curriculum Learning (CL) within the machine learning domain, aiming to improve model performance by gradually including easy to hard samples in training the model. Self-paced learning  measures the difficulty of samples by their training loss, which addressed the issue in previous works that difficulties of samples are generated by prior heuristic rules. Therefore, the model can adjust the curriculum of samples according to its own training status. Following works [18; 17; 55] further proposed many supervised measurement metrics for determining curriculums, for example, the diversity of samples  or the consistency of model predictions . Meanwhile, many empirical and theoretical studies were proposed to explain why CL could lead to generalization improvement from different perspectives. For example, studies such as MentorNet  and Co-teaching  empirically found that utilizing CL strategy can achieve better generalization performance when the given training data is noisy.  provided theoretical explanations on the denoising mechanism that CL learners waste less time with the noisy samples as they are considered harder samples. Some studies [2; 35; 46; 13; 24] also realized that CL can help accelerate the optimization process of non-convex objectives and improve the speed of convergence in the early stages of training.

Despite great success, most of the existing designed CL strategies are for independent data such as images, and there is little work on generalizing CL strategies to handle samples with dependencies. Few existing attempts on graph-structured data [26; 21; 28], such as [44; 5; 45; 28], simply treat nodes as independent samples and then apply CL strategies on independent data, which ignore the fundamental and unique dependency information carried by the structure in data, and thus can not well handle the correlation between data samples. Furthermore, these models are mostly based on heuristic-based sample selection strategies [5; 45; 28], which largely limit the generalizability of these methods.

Graph structure learning.Another stream of existing studies that are related to our work is _graph structure learning_. Recent studies have shown that GNN models are vulnerable to adversarial attacks on graph structure [7; 48]. In order to address this issue, studies in _graph structure learning_ usually aim to jointly learn an optimized graph structure and corresponding graph representations. Existing works [9; 4; 20; 54; 31] typically consider the hypothesis that the intrinsic graph structure should be sparse or low rank from the original input graph by pruning "irrelevant" edges. Thus, they typically use pre-deterministic methods [7; 56; 9] to preprocess graph structure such as singular value decomposition (SVD), or dynamically remove "redundant" edges according to the downstream task performance on the current sparsified structure [4; 20; 31]. However, modifying the graph topology will inevitably lose potentially useful information lying in the removed edges. More importantly, the modified graph structure is usually optimized for maximizing the performance on the training set, which can easily lead to overfitting issues.

## 3 Preliminaries

Graph neural networks (GNNs) are a class of methods that have shown promising progress in representing structured data in which data samples are correlated with each other. Typically, the data samples are treated as nodes while their dependencies are treated as edges in the constructed graph. Formally, we denote a graph as \(G=(,)\), where \(=\{v_{1},v_{2},,v_{N}\}\) is a set of nodes that \(N=||\) denotes the number of nodes in the graph and \(\) is the set of edges. We also let \(^{N b}\) denote the node attribute matrix and let \(^{N N}\) represent the adjacency matrix. Specifically, \(A_{ij}=1\) denotes that there is an edge connecting nodes \(v_{i}\) and \(v_{j}\), otherwise \(A_{ij}=0\). A GNN model \(f\) maps the node feature matrix \(\) associated with the adjacency matrix \(\) to the model predictions \(}=f(,)\), and get the loss \(L_{}=L(},)\), where \(L\) is the objective function and \(\) is the ground-truth label of nodes. The loss on one node \(v_{i}\) is denoted as \(l_{i}=L(},y_{i})\).

## 4 Methodology

As previous CL methods have shown that an easy-to-hard learning sequence of independent data samples can improve the generalization ability and robustness of the representation learner, the goal of this paper is to develop an effective CL method on data with dependencies, which is extremely difficult due to several unique challenges: (1) Difficulty in designing a feasible principle to select

Figure 1: The overall framework of RCL. (a) The _Incremental Edge Selection_ module first extracts the latent node embedding by the GNN model given the current training structure, then jointly learns the node prediction label \(\) and reconstructs the input structure by a decoder. A small residual error on an edge indicates the corresponding dependency is well expected and thus can be added to the refined structure for the next iteration. (b) The iterative learning process of RCL. The model starts with an empty structure and gradually includes more edges until the training structure converges to the input structure.

edges by properly quantifying their difficulties. (2) Difficulty in designing an appropriate pace of curriculum to gradually involve more edges in training based on model status. (3) Difficulty in ensuring convergence and a numerical steady process for optimizing the CL model.

In order to address the above challenges, we propose a novel CL method named **R**elational **C**urriculum **L**earning (**RCL**). The sequence, which gradually includes edges from easy to hard, is called _curriculum_ and learned in different grown-up stages of training. In order to address the first challenge, we propose a self-supervised module _Incremental Edge Selection (IES)_, which is shown in Figure 1(a), to select the \(K\) easiest edges at each training iteration that are mostly expected by the current model. The details are elaborated in Section 4.1. To address the second challenge, we present a joint optimization framework to automatically increase the number of selected edges \(K\) given its own training status. The framework is elaborated in Figure 1(b) and details can be found in Section 4.2. Finally, to ensure convergence of optimization and steady the numerical process, we propose an EM-style alternative optimization algorithm with a theoretical convergence guarantee in Section 4.2 Algorithm 1 and an edge reweighting scheme to smooth the discrete edge incrementing process in Section 4.3.

### Incremental Edge Selection by Quantifying Difficulties of Sample Dependencies

Here we propose a novel way to select edges by first quantifying their difficulty levels. Existing works on independent data typically use supervised metrics such as training loss of samples to quantify their difficulty level, but there exists no supervised metrics on edges. To address this issue, we propose a self-supervised module _Incremental Edge Selection (IES)_. We first quantify the difficulty of edges by measuring how well the edges are expected from the currently learned embeddings of their connected nodes. Then the most well-expected edges are selected as the easiest edges for the next iteration of training. As shown in Figure 1(a), given the currently selected edges at iteration \(t\), we first feed them to the GNN model to extract the latent node embeddings. Then we restore the latent node embeddings to the original graph structure through a decoder, which is called the reconstruction of the original graph structure. The residual graph \(\), which is defined as the degree of mismatch between the original adjacency matrix \(\) and the reconstructed adjacency matrix \(^{(t)}\), can be considered a strong indicator for describing how well the edges are expected by the current model. Specifically, a smaller residual error indicates a higher probability of being a well-expected edge.

With the developed self-supervised method to measure the difficulties of edges, here we formulate the key learning paradigm of selecting the top \(K\) easiest edges. To obtain the training adjacency matrix \(^{(t)}\) that will be fed into the GNN model \(f^{(t)}\), we introduce a learnable binary mask matrix \(\) with each element \(_{ij}\{0,1\}\). Thus, the training adjacency matrix at iteration \(t\) can be represented as \(^{(t)}=^{(t)}\). To filter out the edges with \(K\) smallest residual error, we penalize the summarized residual errors over the selected edges, which can be represented as \(_{i,j}_{ij}_{ij}\). Therefore, the learning objective can be presented as follows:

\[&}{}L_{}+ _{i,j}_{ij}_{ij},\\ & s.t.\|\|_{1} K,\] (1)

where the first term \(L_{}=L(f(,^{(t)};),)\) is the node-level predictive loss, e.g. cross-entropy loss for the node classification task. The second term \(_{i,j}_{ij}_{ij}\) aims at penalizing the residual errors over the edges selected by the mask matrix \(\). \(\) is a hyperparameter to tune the balance between terms. The constraint is to guarantee only the most \(K\) well-expected edges are selected.

More concretely, the value of a residual edge \(}_{ij}^{(t)}\) can be computed by a non-parametric kernel function \((_{i}^{(t)},_{j}^{(t)})\), e.g. the inner product kernel. Then the residual error \(_{ij}\) between the input structure and the reconstructed structure can be defined as \(\|}_{ij}^{(t)}-_{ij}\|\), where \(\|\|\) is commonly chosen to be the squared \(_{2}\)-norm.

### Automatically Control the Pace of Increasing Edges

In order to dynamically include more edges into training, an intuitive way is to iteratively increase the value of \(K\) in Equation 1 to allow more edges to be selected. However, it is difficult to determine an appropriate value of \(K\) with respect to the training status of the model. Besides, directly solvingEquation 1 is difficult since \(\) is a binary matrix where each element \(_{ij}\{0,1\}\), optimizing \(\) would require solving a discrete constraint program at each iteration. To address this issue, we first relax the problem into continuous optimization so that each \(_{ij}\) can be allowed to take any value in the interval \(\). Note that the inequality \(||||_{1} K\) in Eqn. 1 is equivalent to the equality \(||||_{1}=K\). This is because the second term in the loss function would always encourage fewer selected edges by the mask matrix \(\), as all values in the residual error matrix \(\) and mask matrix \(\) are nonnegative. Given this, we can incorporate the equality constraint as a Lagrange multiplier and rewrite the loss function as \(=L_{GNN}+_{i,j}_{ij}_{ij}-(|| ||_{1}-K)\). Considering that \(K\) remains constant, the optimization of the loss function can be equivalently framed by substituting the given constraint with a regularization term denoted as \(g(;)\). As such, the overall loss function can be reformulated as:

\[_{,}L_{}+_{i,j}_{ij} _{ij}+g(;),\] (2)

where \(g(;)=\|-\|\) and \(\|\|\) is commonly chosen to be the squared \(_{2}\)-norm. Since the training adjacency matrix \(^{(t)}=^{(t)}\), as \(\), more edges in the input structure are included until the training adjacency matrix \(^{(t)}\) converges to the input adjacency matrix \(\). Specifically, the regularization term \(g(;)\) controls the learning scheme by the _age parameter_\(\), where \(=(t)\) grows with the number of iterations. By monotonously increasing the value of \(\), the regularization term \(g(;)\) will push the mask matrix gradually converge to the input adjacency matrix \(\), resulting in more edges automatically involved in the training structure.

**Optimization of learning objective.** In optimizing the objective function in Equation 2, we need to jointly optimize parameter \(\) for GNN model \(f\) and the mask matrix \(\). To tackle this, we introduce an EM-style optimization scheme (detailed in Algorithm 1) that iteratively updates both. The algorithm uses the node feature matrix \(\), the original adjacency matrix \(\), a step size \(\) to control the age parameter \(\) increase rate, and a hyperparameter \(\) for regularization adjustments. Post initialization of \(\) and \(\), it alternates between: optimizing GNN model \(f\) (Step 3), extracting latent node embeddings and reconstructing the adjacency matrix (Steps 4 & 5), refining the mask matrix using the reconstructed matrix and regularization, and results in more edges are gradually involved (Step 6), updating the training adjacency matrix (Step 7), and incrementing \(\) when the training matrix \(^{(t)}\) differs from input matrix \(\), incorporating more edges in the next iteration.

**Theorem 4.1**.: _We have the following convergence guarantees for Algorithm 1: \(\) Avoidance of Saddle Points. If the second derivatives of \(L(f(,^{(t)};),)\) and \(g(;)\) are continuous, then for sufficiently large \(\), any bounded sequence \((^{(t)},^{(t)})\) generated by Algorithm 1 with random initializations will not converge to a strict saddle point of \(F\) almost surely. \(\) Second Order Convergence. If the second derivatives of \(L(f(,^{(t)};),)\) and \(g(;)\) are continuous, and \(L(f(,^{(t)};),)\) and \(g(;)\) satisfy the Kurdyka-Lojasiewicz (KL) property , then for sufficiently large \(\), any bounded sequence \((^{(t)},^{(t)})\) generated by Algorithm 1 with random initialization will almost surely converge to a second-order stationary point of \(F\)._

The detailed proof can be found in Appendix B.

### Smooth Structure Transition by Edge Reweighting

Note that in the Algorithm 1, the optimization process requires iteratively updating the parameters \(\) of the GNN model \(f\) and current adjacency matrix \(^{(t)}\), where \(^{(t)}\) varies discretely between iterations. However, GNN models mostly work in a message-passing fashion, which computes node representations by iteratively aggregating information along edges from neighboring nodes. Discretely modifying the number of edges will result in a great drift of the optimal model parameters between iterations. In Appendix Figure, we demonstrate that a shift in the optimal parameters of the GNN results in a spike in the training loss. Therefore, it can increase the difficulty of finding optimal parameters and even hurt the generalization ability of the model in some cases. Besides the numerical problem caused by discretely increasing the number of edges, another issue raised by the CL strategy in Section 4.1 is the trustworthiness of the estimated edge difficulty, which is inferred by the residual error on the edges. Although the residual error can reflect how well edges are expected in the ideal case, the quality of the learned latent node embeddings may affect the validity of this metric and compromise the quality of the designed curriculum by the CL strategy.

To address both issues, we propose a novel edge reweighting scheme to (1) smooth the transition of the training structure between iterations, and (2) reduce the weight of edges that connect nodes with low-confidence latent embeddings. Formally, we use a smoothed version of structure \(}^{(t)}\) to substitute \(^{(t)}\) for training the GNN model \(f\) in step 3 of Algorithm 1, where the mapping from \(^{(t)}\) to \(}^{(t)}\) can be represented as:

\[}^{(t)}_{ij}=^{(t)}_{ij}^{(t)}_{ij},\] (3)

where \(^{(t)}_{ij}\) is the weight imposed on edge \(e_{ij}\) at iteration \(t\). \(^{(t)}_{ij}\) is calculated by considering the counted occurrences of edge \(e_{ij}\) until the iteration \(t\) and the confidence of the latent embedding for the connected pair of nodes \(v_{i}\) and \(v_{j}\):

\[^{(t)}_{ij}=(e_{ij})(v_{i})(v_{j}),\] (4)

where \(\) is a function that reflects the number of edge occurrences and \(\) is a function to reflect the degree of confidence for the learned latent node embedding. The details of these two functions are described as follow.

**Smooth the transition of the training structure between iterations.** In order to obtain a smooth transition of the training structure between iterations, we take the learned curriculum of selected edges into consideration. Formally, we model \(\) by a smooth function of the edge selected occurrences compared to the model iteration occurrences before the current iteration:

\[(e_{ij})=t(e_{ij})/t,\] (5)

where \(t\) is the number of current iterations and \(t(e_{ij})\) represents the counting number of selecting edge \(e_{ij}\). Therefore, we transform the original discretely changing training structure into a smoothly changing one by taking the historical edge selection curriculum into consideration.

**Reduce the influence of nodes with low confidence latent embeddings.** As introduced in our Algorithm 1 line 6, the estimated structure \(\) is inferred from the latent embedding \(\), which is extracted from the trained GNN model \(f\). Such estimated latent embedding may possibly differ from the true underlying embedding, which results in the inaccurately reconstructed structure around the node. In order to alleviate this issue, we model the function \(\) by the training loss on nodes, which indicates the confidence of their learned latent embeddings. This idea is similar to previous CL strategies on inferring the difficulty of data samples by their supervised training loss. Specifically, a larger training loss indicates a low confident latent node embedding. Mathematically, the weights \((v_{i})\) on node \(v_{i}\) can be represented as a distribution of their training loss:

\[(v_{i}) e^{-l_{i}}\] (6)

where \(l_{i}\) is the training loss on node \(v_{i}\). Therefore, a node with a larger training loss will result in a smaller value of \((v_{i})\), which reduces the weight of its connecting edges.

## 5 Experiments

In this section, the experimental settings are introduced first in Section 5.1, then the performance of the proposed method on both synthetic and real-world datasets are presented in Section 5.2. We further present the robustness test on our CL method against topological structure noise in Section 5.3.

[MISSING_PAGE_FAIL:7]

[MISSING_PAGE_FAIL:8]

out of 43 cases with a significance \(p<0.05\). Such statistical significance results can demonstrate that our proposed method can consistently perform better than the baseline models in both scenarios.

### Robustness Analysis Against Topological Noise

To further examine the robustness of the RCL method on extracting powerful representation from correlated data samples, we follow previous works [20; 31] to randomly inject fake edges into real-world graphs. This adversarial attack can be viewed as adding random noise to the topological structure of graphs. Specifically, we randomly connect \(M\) pairs of previously unlinked nodes in the real-world datasets, where the value of \(M\) varies from 10% to 100% of the original edges. We then train RCL and all the comparison methods on the attacked graph and evaluate the node classification performance. The results are shown in Figure 2, we can observe that RCL shows strong robustness to adversarial structural attacks by consistently outperforming all compared methods on all datasets. Especially, when the proportion of added noisy edges is large (\(>50\%\)), the improvement becomes more significant. For instance, under the extremely noisy ratio at 100%, RCL outperforms the second best model by 4.43% and 2.83% on Cora dataset, and by 6.13%, 3.47% on Citeseer dataset, with GCN and GIN backbone models, respectively.

### Ablation Study

To investigate the effectiveness of our proposed model with some simpler heuristics, we deploy a series of ablation analysis. We first train the model with node classification task purely and select the top K expected edges as suggested by the reviewer. Specifically, we follow previous works [43; 45] using two classical selection pacing functions as follows:

\[ K_{}(t)=|E|;\ \   K_{}(t)=}|E|,\]

where \(t\) is the number of current iterations and \(T\) is the number of total iterations, and \(|E|\) is the number of total edges. We name these two variants Curriculum-linear and Curriculum-root, respectively. In addition, we also remove the edge difficulty measurement module and use random selection instead. Specifically, we gradually incorporate more edges into training in random order to verify the effectiveness of the learned curriculum. We name two variants as Random-linear and Random-root with the above two mentioned pacing functions, respectively.

In order to further investigate the impact of the proposed components of RCL. We also first consider variants of removing the edge smoothing components mentioned in Section 4.3. Specifically, we

Figure 2: Node classification accuracy (\(\%\)) on Cora and Citeseer under random structure attack. The attack edge ratio is computed versus the original number of edges, where \(100\%\) means that the number of inserted edges is equal to the number of original edges.

   & **Synthetic1** & **Synthetic2** & **Citeseer** & **CS** & **Computers** \\  Full & **73.98\(\)0.55** & **79.42\(\)0.17** & **79.79\(\)0.55** & **94.66\(\)0.22** & **90.23\(\)0.23** \\ Curriculum-linear & 70.93\(\)0.54 & 95.19\(\)0.19 & 79.04\(\)0.38 & 94.14\(\)0.26 & 89.28\(\)0.21 \\ Curriculum-root & 70.13\(\)0.72 & 95.50\(\)0.18 & 78.27\(\)0.54 & 94.47\(\)0.34 & 89.27\(\)0.15 \\ Random-linear & 58.76\(\)0.46 & 89.78\(\)0.11 & 77.43\(\)0.49 & 92.76\(\)0.14 & 88.67\(\)0.18 \\ Random-root & 61.04\(\)0.20 & 91.04\(\)0.09 & 76.81\(\)0.35 & 92.92\(\)0.15 & 88.81\(\)0.28 \\ w/o edge appearance & 70.70\(\)0.43 & 57.77\(\)0.16 & 77.77\(\)0.65 & 43.92\(\)0.21 & 89.56\(\)0.30 \\ w/o node confidence & 72.38\(\)0.41 & 69.86\(\)0.17 & 78.72\(\)0.72 & 94.34\(\)0.13 & 90.03\(\)0.62 \\ w/o pre-trained model & 72.56\(\)0.69 & 93.89\(\)0.14 & 78.28\(\)0.77 & 94.50\(\)0.14 & 89.80\(\)0.55 \\  

Table 3: Ablation study. Here “Full” represents the original method without removing any component. The best-performing method on each dataset is highlighted in bold.

consider two variants _w/o EC_ and _w/o NC_, which remove the smoothing function of the edge occurrence ratio and the component to reflect the degree of confidence for the latent node embedding in RCL, respectively. In addition to examining the effectiveness of edge smoothing components, we further consider a variant _w/o pre-trained model_ that avoids using a pre-trained model to initialize model, which is mentioned in Section 5.1, to initialize the training structure by a pre-trained model and instead starts with inferred structure from isolated nodes with no connections.

We present the results of two synthetic datasets (_homophily coefficient\(=0.3,0.6\)_) and three real-world datasets in Table 3. We summarize our findings from the above table as below: (i) Our full model consistently outperforms the two variants Curriculum-linear and Curriculum-root by an average of 1.59% on all datasets, suggesting that our pacing module can benefit model training. It is worth noting that these two variants also outperform the baseline vanilla GNN model Vanilla by an average of 1.92%, which supports the assumption that even a simple curriculum learning strategy can still improve model performance. (ii) We observe that the performance of the two variants Random-linear and Random-root on all datasets drops by 3.86% on average compared to the variants Curriculum-linear and Curriculum-root. Such behavior demonstrates the effectiveness of our proposed edge difficulty quantification module by showing that randomly involving edges into training cannot benefit model performance. (iii) We can observe a significant performance drop consistently for all variants that remove the structural smoothing techniques and initialization components. The results validate that all structural smoothing and initialization components can benefit the performance of RCL on the downstream tasks.

### Visualization of Learned Edge Selection Curriculum

Besides the effectiveness and robustness of the RCL method on downstream classification results, it is also interesting to verify whether the learned edge selection curriculum satisfies the rule from easy to hard. Since real-world datasets do not have ground-truth labels of difficulty on edges, we conduct visualization experiments on synthetic datasets, where the difficulty of each edge can be indicated by its formation probability. Specifically, we classify edges into three balanced categories according to their difficulty: easy, medium, and hard. Here, we define all homogenous edges that connect nodes with the same class as easy, edges connecting nodes with adjacent classes as medium, and the remaining edges connecting nodes with far away classes as hard. We report the proportion of edges selected for each category during training in Figure 3. We can observe that RCL can effectively select most of the easy edges at the early stage of training, then more easy edges and most medium edges are gradually included during training, and most hard edges are left unselected until the end stage of training. Such edge selection behavior is highly consistent with the core idea of designing a curriculum for edge selection, which verifies that our proposed method can effectively design curriculums to select edges according to their difficulty from easy to hard.

## 6 Conclusion

This paper focuses on developing a novel CL method to improve the generalization ability and robustness of GNN models on learning representations of data samples with dependencies. The proposed method **R**elational **C**urriculum **L**earning (**RCL**) effectively addresses the unique challenges in designing CL strategy for handling dependencies. First, a self-supervised learning module is developed to select appropriate edges that are expected by the model. Then an optimization model is presented to iteratively increment the edges according to the model training status and a theoretical guarantee of the convergence on the optimization algorithm is given. Finally, an edge reweighting scheme is proposed to steady the numerical process by smoothing the training structure transition. Extensive experiments on synthetic and real-world datasets demonstrate the strength of RCL in improving the generalization ability and robustness.

Figure 3: Visualization of edge selection process during training.