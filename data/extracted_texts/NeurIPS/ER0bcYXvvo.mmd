# Byzantine-Tolerant Methods for Distributed

Variational Inequalities

 Nazarii Tupitsa

MBZUAI, MIPT

Abdulla Jasem Almansoori

MBZUAI

Yanlin Wu

MBZUAI

Martin Takac

MBZUAI

Karthik Nandakumar

MBZUAI

Samuel Horvath

MBZUAI

Eduard Gorbunov

MBZUAI

Corresponding author: eduard.gorbunov@mbzuai.ac.ae

###### Abstract

Robustness to Byzantine attacks is a necessity for various distributed training scenarios. When the training reduces to the process of solving a minimization problem, Byzantine robustness is relatively well-understood. However, other problem formulations, such as min-max problems or, more generally, variational inequalities, arise in many modern machine learning and, in particular, distributed learning tasks. These problems significantly differ from the standard minimization ones and, therefore, require separate consideration. Nevertheless, only one work (Adibi et al., 2022) addresses this important question in the context of Byzantine robustness. Our work makes a further step in this direction by providing several (provably) Byzantine-robust methods for distributed variational inequality, thoroughly studying their theoretical convergence, removing the limitations of the previous work, and providing numerical comparisons supporting the theoretical findings.

## 1 Introduction

Modern machine learning tasks require to train large models with billions of parameters on huge datasets to achieve reasonable quality. Training of such models is usually done in a distributed manner since otherwise it can take a prohibitively long time (Li, 2020). Despite the attractiveness of distributed training, it is associated with multiple difficulties not existing in standard training.

In this work, we focus on one particular aspect of distributed learning - _Byzantine tolerance/robustness_ - the robustness of distributed methods to the presence of _Byzantine workers_2, i.e., such workers that can send incorrect information (maliciously or due to some computation errors/faults) and are assumed to be omniscient. For example, this situation can appear in collaborative training, when several participants (companies, universities, individuals) that do not necessarily know each other train some model together (Kijsipongse et al., 2018; Diskin et al., 2021) or when the devices used in training are faulty (Ryabinin et al., 2021). When the training reduces to the distributed _minimization_ problem, the question of Byzantine robustness is studied relatively well both in theory and practice (Karimireddy et al., 2022; Lyu et al., 2020).

However, there are a lot of problems that cannot be reduced to minimization, e.g., adversarial training (Goodfellow et al., 2015; Madry et al., 2018), generative adversarial networks (GANs) (Goodfellow et al., 2014), hierarchical reinforcement learning (Wayne and Abbott, 2014; Vezhnevets et al., 2017), adversarial examples games (Bose et al., 2020), and other problems arising in game theory, control theory, and differential equations (Facchinei and Pang, 2003). Such problems lead to min-maxor, more generally, variational inequality (VI) problems (Gidel et al., 2018) that have significant differences from minimization ones and require special consideration (Harker and Pang, 1990; Ryu and Yin, 2022). Such problems can also be huge scale, meaning that, in some cases, one has to solve them distributedly. Therefore, similarly to the case of minimization, the necessity in Byzantine-robust methods for distributed VIs arises.

The only existing work addressing this problem is (Adibi et al., 2022), where the authors propose the first Byzantine-tolerant distributed method for min-max and VI problems called Robust Distributed Extragradient (RDEG). However, several interesting directions such as application of \((,c)\)-robust aggregation rules, client momentum (Karimireddy et al., 2021), and checks of computations (Gorbunov et al., 2022b) studied for minimization problems are left unexplored in the case of VIs. Moreover, (Adibi et al., 2022) prove the convergence to the solution's neighborhood that can be reduced only via increasing the batchsize and rely on the assumption that the number of workers is sufficiently large and the fraction of Byzantine workers is smaller than \(}{{16}}\), which is much smaller than for SOTA results in minimization case. _Our work closes these gaps in the literature and resolves the limitations of the results from (Adibi et al., 2022)._

### Setting

To make the further presentation precise, we need to introduce the problem and assumptions we make. We consider the distributed unconstrained variational inequality (non-linear equation) problem3:

\[\ ^{*}^{d}\ \ F(^{*})=0,\ \ F():=_{i}F_{i}(), \]

where \(\) denotes the set of regular/good workers and operators \(F_{i}\) have an expectation form \(F_{i}():=_{_{i}}[_{i}(;_{i})]\). We assume that \(n\) workers connected with a server take part in the learning/optimization process and \([n]=\), where \(\) is the set of _Byzantine workers_ - the subset \(\) of workers \([n]\) that can deviate from the prescribed protocol (send incorrect information, e.g., arbitrary vectors instead of stochastic estimators) either intentionally or not and are _omniscient4_, i.e., Byzantine workers can know the results of computations on regular workers and the aggregation rule used by the server. The number of Byzantine workers \(B=||\) is assumed to satisfy \(B n\), where \(<}{{2}}\) (otherwise Byzantines form a majority and the problem becomes impossible to solve). The number of regular workers is denoted as \(G=|G|\).

Assumptions.Here, we formulate the assumptions related to the stochasticity and properties of operators \(\{F_{i}\}_{i}\).

**Assumption 1**.: _For all \(i\) the stochastic estimator \(_{i}(,_{i})\) is an unbiased estimator of \(F_{i}()\) with bounded variance, i.e., \(_{_{i}}[_{i}(,_{i})]=F_{i}()\) and for some \( 0\)_

\[_{_{i}}[\|_{i}(,_{i})-F_{i}( )\|^{2}]^{2}. \]

The above assumption is known as the bounded variance assumption. It is classical for the analysis of stochastic optimization methods (Nemirovski et al., 2009; Juditsky et al., 2011) and is used in the majority of existing works on Byzantine robustness with theoretical convergence guarantees.

Further, we assume that the data heterogeneity across the workers is bounded.

**Assumption 2**.: _There exists \( 0\) such that for all \(^{d}\)_

\[_{i Q} F_{i}()-F()^{2}^{2}. \]

Condition (3) is a standard notion of data heterogeneity in Byzantine-robust distributed optimization (Wu et al., 2020; Zhu and Ling, 2021; Karimireddy et al., 2022; Gorbunov et al., 2023a). It is worth mentioning that without any kind of bound on the heterogeneity of \(\{F_{i}\}_{i}\), it is impossible to tolerate Byzantine workers. In addition, homogeneous case (\(=0\)) is also very important and arises in collaborative learning, see (Kijispongse et al., 2018; Diskin et al., 2021).

Finally, we formulate here several assumptions on operator \(F\). Each particular result in this work relies only on a subset of listed assumptions.

**Assumption 3**.: _Operator \(F:^{d}^{d}\) is \(L\)-Lipschitz, i.e.,_

\[\|F()-F()\| L\|-\|,\ , ^{d}.\] (Lip)

**Assumption 4**.: _Operator \(F:^{d}^{d}\) is \(\)-quasi strongly monotone, i.e., for \( 0\)_

\[ F(),-^{*}\|-^{*}\|^{2}, \ ^{d}.\] (QSM)

**Assumption 5**.: _Operator \(F:^{d}^{d}\) is monotone, i.e.,_

\[ F()-F(),- 0,\ ,^{d}.\] (Mon)

**Assumption 6**.: _Operator \(F:^{d}^{d}\) is \(\)-star-cocoercive, i.e., for \( 0\)_

\[ F(),-^{*}\|F()\|^{2},\ ^{d}.\] (SC)

Assumptions 3 and 5 are quite standard for the literature on VIs. Assumptions 4 and 6 can be seen as structured non-monotonicity assumptions. Indeed, there exist examples of non-monotone (and even non-Lipschitz) operators such that Assumptions 4 and 6 holds (Loizou et al., 2021). However, Assumptions 3 and 5 imply neither (QSM) nor (SC). It is worth mentioning that Assumption 4 is also known under different names, i.e., strong stability (Mertikopoulos and Zhou, 2019) and strong coherent (Song et al., 2020) conditions.

Robust aggregation.We use the formalism proposed by Karimireddy et al. (2021, 2022).

**Definition 1.1** (\((,c)\)-Ragg(Karimireddy et al., 2021, 2022)).: _Let there exist a subset \(\) of random vectors \(\{_{1},,_{n}\}\) such that \(G(1-)n\) for some \(<}{{2}}\) and \(\|_{i}-_{j}\|^{2}^{2}\) for any fixed pair \(i,j\) and some \( 0\). Then, \(}=(_{1},,_{n})\) is called \((,c)\)-robust aggregator if for some constant \(c 0\)_

\[[\|}-}\|^{2}] c ^{2}, \]

_where \(}=_{i}y_{i}\). Further, if the value of \(\) is not used to compute \(}\), then \(}\) is called agnostic \((,c)\)-robust aggregator and denoted as \(}=(_{1},,_{n})\)._

The above definition is tight in the sense that for any estimate \(}\) the best bound one can guarantee is \([\|}-}\|^{2}]=( ^{2})\)(Karimireddy et al., 2021). Moreover, there are several examples of \((,c)\)-robust aggregation rules that work well in practice; see Appendix B.

Another important concept for Byzantine-robust learning is the notion of permutation invariance.

**Definition 1.2** (Permutation invariant algorithm).: _Define the set of stochastic gradients computed by each of the \(n\) workers at some round \(t\) to be \([}_{1,t},,}_{n,t}]\). For a good worker \(i\), these represent the true stochastic gradients whereas for a bad worker \(j\), these represent arbitrary vectors. The output of any optimization algorithm \(\) is a function of these gradients. A permutation-invariant algorithm is one which for any set of permutations over \(t\) rounds \(\{_{1},,_{t}\}\), its output remains unchanged if we permute the gradients._

\[[}_{1,1},...,}_{n,1}],\\...\\ [}_{1,t},...,}_{n,t}]= [}_{_{1}(1),1},...,}_{_{1}(n),1}], \\...\\ [}_{_{1}(1),t},...,}_{_{t}(n),t}]\]

As Karimireddy et al. (2021) prove, any permutation-invariant algorithm fails to converge to any predefined accuracy of the solution (under Assumption 1) even if all regular workers have the same operators/functions, i.e., even when \(=0\).

### Our Contributions

Now we are ready to describe the main contributions of this work.

\(\)**Methods with provably robust aggregation.** We propose new methods called Stochastic Gradient Descent-Ascent and Stochastic Extragradient with Robust Aggregation (SGDA-RA and SEG-RA) - variants of popular SGDA  and SEG . We prove that SGDA-RA and SEG-RA work with any \((,c)\)-robust aggregation rule and converge to the desired accuracy _if the batchsize is large enough_. In experiments, we observe that SGDA-RA and SEG-RA outperform RDEG in several cases.

\(\)**Client momentum.** As the next step, we add client momentum to SGDA-RA and propose Momentum SGDA-RA (M-SGDA-RA). As it is shown by , client momentum helps to break the permutation invariance of the method and ensures convergence to any predefined accuracy with any batchsize for _non-convex minimization problems_. In the case of star-cocoercive quasi-strongly monotone VIs, we prove the convergence to the neighborhood of the solution; the size of the neighborhood can be reduced via increasing batchsize only - similarly to the results for RDEG, SGDA-RA, and SEG-RA. We discuss this limitation in detail and point out the non-triviality of this issue. Nevertheless, we show in the experiments that client momentum does help to achieve better accuracy of the solution.

\(\)**Methods with random checks of computations.** Finally, for homogeneous data case (\(=0\)), we propose a version of SGDA and SEG with random checks of computations (SGDA-CC, SEG-CC and their restarted versions - R-SGDA-CC and R-SEG-CC). We prove that the proposed methods converge _to any accuracy of the solution without any assumptions on the batchsize_. This is the first result of this type on Byzantine robustness for distributed VIs. Moreover, when the target accuracy of the solution is small enough, the obtained convergence rates for R-SGDA-CC and R-SEG-CC are not worse than the ones for distributed SGDA and SEG derived in the case of \(=0\) (no Byzantine workers); see the comparison of the convergence rates in Table 1. In the numerical experiments, we consistently observe the superiority of the methods with checks of computations to the previously proposed methods.

   Setup & Method & Citation & Metric & Complexity & BS \\   & SGDA-RA & Cor. 1 & & \(+}\) & \(}{^{2}}\) \\  & M-SGDA-RA & Cor. 4 & & \(^{2}+}}{^{2}^{2}}\) & \(+^{2}}{^{2}^{2}}+^{2}^{2}}{^{2}^{2}}\) & 1 \\  & SEG-CC & Cor. 6 & & \(+^{2}}{^{2}}+^{2}^{2}}{^{2}^{2}^{2}}\) & 1 \\  & R-SGDA-CC & Cor. 8 & & \(+}{^{2}}+^{2}}{ }\) & 1 \\   & SEG-RA & Cor. 3 & & & \(}{^{2}}+}+^{2}}{^{2}^{2}}+^{2}}{ ^{2}^{2}}+^{2}^{2}}{^{2} ^{2}^{2}^{2}^{2}^{2}^{2}^{2}^{2}}\) & \(+}{^{2}}+^{2}}{ ^{2}^{2}^{2}^{2}^{2}^{2}^{2}}\) & 1 \\  & R-SEG-CC & Cor. 11 & & & \(+}{^{2}}+^{2}}{ ^{2}}\) & 1 \\   & RDEG & Adibi et al. \(\|^{T}-^{*}\|^{2}\) & \(\) & \(^{2}R^{2}}{L^{2}^{2}}\) \\   & & & & & \\    \({}^{(1)}\) consider only homogeneous case (\(=0\)).

Table 1: Summary of known and new complexity results for Byzantine-robust methods for distributed variational inequalities. Column “Setup” indicates the varying assumptions. By the complexity, we mean the number of stochastic oracle calls needed for a method to guarantee that Metric \(\) (for RDEG \(\{\} 1-_{}\), \(_{}(0,1]\)) and “Metric” is taken from the corresponding column. For simplicity, we omit numerical and logarithmic factors in the complexity bounds. Column “BS” indicates the minimal batch-size used for achieving the corresponding complexity. Notation: \(c,\) are robust aggregator parameters; \(\) = momentum parameter; \(\) = ratio of inner and outer stepsize in SEG-like methods; \(n\) = total numbers of peers; \(m\) = number of checking peers; \(G\) = number of peers following the protocol; \(R\) = any upper bound on \(\|^{0}-^{n}\|\); \(\) = quasi-strong monotonicity parameter; \(\) = star-cocoercivity parameter; \(L\) = Lipschitzness parameter; \(^{2}\) = bound on the variance. The definition \(x^{T}\) can vary; see corresponding theorems for the exact formulas.

### Related Work

Byzantine-robust methods for minimization problems.Classical distributed methods like Parallel SGD cannot tolerate even one Byzantine worker. The most evident vulnerability of such methods is an aggregation rule (averaging). Therefore, many works focus on designing and application of different aggregation rules to Parallel SGD-like methods . However, this is not sufficient for Byzantine robustness: there exist particular attacks  that can bypass popular defenses.  formalize the definition of robust aggregation (see Definition 1.1), show that many standard aggregation rules are non-robust according to that definition, and prove that any permutation-invariant algorithm with a fixed batchsize can converge only to the ball around the solution with algorithm-independent radius. Therefore, more in-depth algorithmic changes are required that also explain why RDEG, SGDA-RA, and SEG-RA are not converging to any accuracy without increasing batchsize.

One possible way to resolve this issue is to use client momentum  that breaks permutation-invariance and allows for convergence to any accuracy. It is also worth mentioning a recent approach by , who propose an alternative definition of robust aggregation to the one considered in this paper, though to achieve the convergence to any accuracy in the homogeneous case  apply client momentum like in . Another line of work achieves Byzantine robustness through the variance reduction mechanism . Finally, for the homogeneous data case, one can apply validation test  or checks of computations . For the summary of other advances, we refer to .

Methods for min-max and variational inequalities problems.As mentioned before, min-max/variational inequalities (VIs) problems have noticeable differences with standard minimization. In particular, it becomes evident from the differences in the algorithms' behavior. For example, a direct analog of Gradient Descent for min-max/VIs - Gradient Descent-Ascent (GDA)  - fails to converge for a simple bilinear game. Although GDA converges for a different class of problems (cocoercive/star-cocoercive ones) and its version with alternating steps works well in practice and even provably converges locally , many works focus on Extragradient (EG) type methods  due to their provable convergence for monotone Lipschitz problems and beyond . Stochastic versions of GDA and EG (SGDA and SEG) are studied relatively well, e.g., see  for the recent advances.

On the results from .In the context of Byzantine robustness for distributed min-max/VIs, the only existing work is . The authors propose a method called Robust Distributed Extragradient (RDEG) - a distributed version of EG that uses a univariate trimmed-mean estimator from  for aggregation. This estimator satisfies a similar property to (4) that is shown for \(<}{{16}}\) and large enough \(n\) (see the discussion in Appendix B). In contrast, the known \((,c)\)-robust aggregation rules allow larger \(\), and do not require large \(n\). Despite these evident theoretical benefits, such aggregation rules were not considered in prior works on Byzantine robustness for distributed variational inequalities/min-max problems.

## 2 Main Results

In this section, we describe three approaches proposed in this work and formulate our main results.

### Methods with Robust Aggregation

We start with the Stochastic Gradient Descent-Accent with \((,c)\)-robust aggregation (SGDA-RA):

\[^{t+1}=^{t}-(_{1}^{t},,_{n}^{t} ),\ \ \ _{i}^{t}=_{i}(^{t},_{i}^{t})\ \ \ i\ \ \ \ _{i}^{t}=*\ \ \ i,\]

where \(\{_{i}^{t}\}_{i}\) are sampled independently. The main result for SGDA-RA is given below.

**Theorem 1**.: _Let Assumptions 1, 2, 4 and 6 hold. Then after \(T\) iterations_ SGDA-RA _(Algorithm 1) with \((,c)\)_-Ragg and \(\) outputs \(^{T}\) such that_

\[^{T}-^{*}^{2}1- ^{T}^{0}-^{*}^{2}+}{ G}++12^{2})}{ }++12^{2})}{^{2}}.\]

The first two terms in the derived upper bound are standard for the results on SGDA under Assumptions 1, 4, and 6, e.g., see (Beznosikov et al., 2023). The third and the fourth terms come from the presence of Byzantine workers and robust aggregation since the existing \((,c)\)-robust aggregation rules explicitly depend on \(\). The fourth term cannot be reduced without increasing batchsize even when \(=0\) (homogeneous data case). This is expected since SGDA-RA is permutation invariant. When \(=0\) (regular workers compute full operators), then SGDA-RA converges linearly to the ball centered at the solution with radius \((/)\) that matches the lower bound from (Karimireddy et al., 2022). In contrast, the known results for RDEG are derived for homogeneous data case (\(=0\)). The proof of Theorem 1 is deferred to Appendix D.1.

Using a similar approach we also propose a version of Stochastic Extragradient method with \((,c)\)-robust aggregation called SEG-RA:

\[}^{t} =^{t}-_{1}(_{_{t}}^{t},, _{_{n}}^{t}),\ \ \ _{_{t}}^{t}=_{i}(^{t}, _{i}^{t}),\ \ \ i\ \ _{_{t}}^{t}=*\ \ \ i,\] \[^{t+1} =^{t}-_{2}(_{_{1}}^{t}, ,_{_{n}}^{t}),\ \ \ _{_{i}}^{t}=_{i}(}^{t},_{i}^{t}),\ \ \ i\ _{_{i}}^{t}=*\ \ \ i,\]

where \(\{_{_{i}}^{t}\}_{i}\) and \(\{_{_{i}}^{t}\}_{i}\) are sampled independently. Our main convergence result for SEG-RA is presented in the following theorem; see Appendix D.2 for the proof.

**Theorem 2**.: _Let Assumptions51, 2, 3 and 4 hold. Then after \(T\) iterations_ SEG-RA _(Algorithm 2) with \((,c)\)_-Ragg, \(_{1}\) and \(=}}{{_{1}}}}{{4}}\) outputs \(^{T}\) such that_

\[^{T}-^{*}^{2}\ (1-}{4})^{T}^{0}-^{*} ^{2}+^{2}}{ G}+8c(24^{2}+12 ^{2})}{}+}.\]

Similar to the case of SGDA-RA, the bound for SEG-RA has the term that cannot be reduced without increasing batchsize even in the homogeneous data case. RDEG, which is also a modification of SEG, has the same linearly convergent term, but SEG-RA has a better dependence on the batchsize, needed to obtain the convergence to any predefined accuracy, that is \((^{-1})\) versus \((^{-2})\) for RDEG; see Cor. 3.

In heterogeneous case when \(=0\), SEG-RA also converges linearly to the ball centered at the solution with radius \((/)\) that matches the lower bound.

### Client Momentum

Next, we focus on the version of SGDA-RA that utilizes worker momentum \(_{i}^{t}\), i.e.,

\[^{t+1}=^{t}-(_{1}^{t},,_{n}^{t} ),\ \ \ _{i}^{t}=(1-)_{i}^{t-1}+_{i}^{t},\]

where \(_{i}^{t}=_{i}(^{t},_{i}^{t}),\ \ i\) and \(_{i}^{t}=*\ \ i\) and \(\{_{_{i}}^{t}\}_{i}\) are sampled independently. Our main convergence result for this version called M-SGDA-RA is summarized in the following theorem.

**Theorem 3**.: _Let Assumptions 1, 2, 4, and 6 hold. Then after \(T\) iterations_ M-SGDA-RA _(Algorithm 3) with \((,c)\)_-Ragg outputs \(}^{T}\) such that_

\[}^{T}-^{*}^{2} ^{0}-^{*}^{2}}{ W_{T}}+ +12^{2})}{^{2}}+}{^{2}G}++12^{2})}{^{2} ^{2}}.\]

_where \(}^{T}=}_{t=0}^{T}w_{t}}^{t}\), \(}^{t}=}_{j=0}^{t}(1-)^ {t-j}^{j}\), \(w_{t}=1-^{-t-1}\), and \(W_{T}=_{t=0}^{T}w_{t}\)._Despite the fact that M-SGDA-RA is the first algorithm (for VIs) non-invariant to permutations, it also requires large batches to achieve convergence to any accuracy. Even in the context of minimization, which is much easier than VI, the known SOTA analysis of Momentum-SGD relies **in the convex case** on the unbiasedness of the estimator that is not available due to a robust aggregation. Nevertheless, we prove6 the convergence to the ball centered at the solution with radius \(}}{{(}}{{ }})}}/}}{{}}\); see Appendix D.3. Moreover, we show that M-SGDA-RA outperforms in the experiments other methods that require large batches.

### Random Checks of Computations

We start with the Stochastic Gradient Descent-Accent with Checks of Computations (SGDA-CC). At each iteration of SGDA-CC, the server selects \(m\) workers (uniformly at random) and requests them to check the computations of other \(m\) workers from the previous iteration. Let \(V_{t}\) be the set of workers that verify/check computations, \(A_{t}\) are active workers at iteration \(t\), and \(V_{t} A_{t}=\). Then, the update of SGDA-CC can be written as

\[^{t+1}=^{t}-}^{t},\ \ \ \ }^{t}=|}_{i A_{t}}_{i}(^{t},_{i}^{t})\ \ ,\]

where \(\{_{i}(^{t},_{i}^{t})\}_{i}\) are sampled independently.

The acceptance (of the update) event occurs when the condition \(}^{t}-_{i}(^{t},_{i}^{t})  C\) holds for the majority of workers. If \(}^{t}\) is rejected, then all workers re-sample \(_{i}(^{t},_{i}^{t})\) until acceptance is achieved. The rejection probability is bounded, as per (Gorbunov et al., 2022b), and can be adjusted by choosing a constant \(C=(1)\). We assume that the server knows the seeds for generating randomness on workers, and thus, verification of computations is possible. Following each aggregation of \(_{i}(^{t},_{i}^{t})_{i}\), the server selects uniformly at random \(2m\) workers: \(m\) workers check the computations at the previous step of the other \(m\) workers. For instance, at the \((t+1)\)-th iteration, the server asks a checking peer \(i\) to compute \(_{j}(^{t},_{j}^{t})\), where \(j\) is a peer being checked. This is possible if all seeds are broadcasted at the start of the training. Workers assigned to checking do not participate in the training while they check and do not contribute to \(}^{t}\). Therefore, each Byzantine peer is checked at each iteration with a probability of \(}{{n}}\) by some good worker (see the proof of Theorem 4). If the results are mismatched, then both the checking and checked peers are removed from training.

This design ensures that every such mismatch, whether it is caused by honest or Byzantine peers, eliminates at least one Byzantine peer and at most one honest peer (see details in Appendix E.1). It's worth noting that we assume any information is accessible to Byzantines except when each of them will be checked. As such, Byzantine peers can only reduce their relative numbers, which leads us to the main result for SGDA-CC, which is presented below.

**Theorem 4**.: _Let Assumptions 1, 4 and 6 hold. Then after \(T\) iterations SGDA-CC (Algorithm 5) with \(\) outputs \(^{T}\) such that_

\[^{T+1}-^{*}^{2}1-^{T+1}^{0}-^{*}^{2}+}{(n-2B-m)}+nB}{m}+^{2},\]

_where \(q=2C^{2}+12+\); \(q=(1)\) since \(C=(1)\)._

The above theorem (see Appendix E.1 for the proof) provides the first result that does not require large batchsizes to converge to any predefined accuracy. The first and the second terms in the convergence bound correspond to the SOTA results for SGDA (Loziov et al., 2021). Similarly to the vanilla SGDA, the convergence can be obtained by decreasing stepsize, however, such an approach does not benefit from collaboration, since the dominating term \(nB}{ m}\) (coming from the presence of Byzantine workers) is not inversely dependent on \(n\). Moreover, the result is even worse than for single node SGDA in terms of dependence on \(n\).

To overcome this issue we consider the restart technique for SGDA-CC and propose the next algorithm called R-SGDA-CC. This method consists of \(r\) stages. On the \(t\)-th stage R-SGDA-CC runs SGDA-CC with \(_{t}\) for \(K_{t}\) iterations from the starting point \(}^{t}\), which is the output from the previous stage, and defines the obtained point as \(}^{t+1}\) (see details in Appendix E.2). The main result for R-SGDA-CC is given below.

**Theorem 5**.: _Let Assumptions 1, 4 and 6 hold. Then, after \(r=_{2}}{}-1\) restarts_

\[\] _(Algorithm 6) with \[_{t}=\{,}{6^{2}2^{t }K_{t}}},R^{2}}{72q^{2}2^{t}B^{2}n^{2}}}\}\] and \[K_{t}=\{,t}{(n-2B-m) ^{2}R^{2}},t^{2}}}{m R}\}\], where \[R\|^{0}-^{*}\|\], outputs \[}^{r}\] such that \[\|}^{r}-^{*}\|^{2}\]. Moreover, the total number of executed iterations of SGDA-CC is_ \[_{t=1}^{r}K_{t}=(^{2}}{ }+}{(n-2B-m)}+}). \]

The above result implies that R-SGDA-CC also converges to any accuracy without large batch-sizes (see Appendix E.2 for details). However, as the accuracy tends to zero, the dominant term \(}{(n-2B-m)}\) inversely depends on the number of workers. This makes R-SGDA-CC benefit from collaboration, as the algorithm becomes more efficient with an increasing number of workers. Moreover, when \(B\) and \(m\) are small the derived complexity result for R-SGDA-CC matches the one for parallel SGDA [Loziou et al., 2021], which is obtained for the case of no Byzantine workers.

Next, we present a modification of Stochastic Extragradient with Checks of Computations (SEG-CC):

\[}^{t} =^{t}-_{1}_{}^{t}, \ \ _{}^{t}=|}_{ i A_{t}}_{i}(^{t},_{i}^{t})\ \ ,\] \[^{t+1} =^{t}-_{2}_{}^{t}, \ \ _{}^{t}=|} _{i A_{t}}_{i}(}^{t},_{i}^{t})\ \ ,\]

where \(\{_{i}(^{t},_{i}^{t})\}_{i G}\) and \(\{_{i}(}^{t},_{i}^{t})\}_{i G}\) are sampled independently. The events of acceptance \(_{}^{t}\ _{}^{t}\) happens if

\[\|^{t}-_{i}(^{t},_{i}^{t})\| C \ (\|_{}^{t}-_{i}( }^{t},_{i}^{t})\| C)\]

holds for the majority of workers. An iteration of SEG-CC actually represents two subsequent iteration of SGDA-CC, so we refer to the beginning of the section for more details. Our main convergence results for SEG-CC are summarized in the following theorem; see Appendix E.3 for the proof.

**Theorem 6**.: _Let Assumptions 1, 3 and 4 hold. Then after \(T\) iterations SEG-CC (Algorithm 7) with \(_{1}\) and \(=}}{{_{1}}}}{{4}}\) outputs \(^{T}\) such that_

\[^{T}-^{*}^{2}(1-}{4})^{T}^{0}-^{*}^{2}+2^{ 2}}{^{2}(n-2B-m)}+qnB}{m} ,\]

_where \(q=2C^{2}+12+\); \(q=(1)\) since \(C=(1)\)._

Similarly to SGDA-CC, SEG-CC does not require large batchsizes to converge to any predefined accuracy and does not benefit of collaboration, though the first two terms correspond to the SOTA convergence results for SEG under bounded variance assumption [Juditsky et al., 2011]. The last term appears due to the presence of the Byzantine workers. The restart technique can also be applied; see Appendix E.4 for the proof.

**Theorem 7**.: _Let Assumptions 1, 3, 4 hold. Then, after \(r=_{2}}{}-1\) restarts_

\[\] _(Algorithm 8) with \[_{1_{t}}=\{,}{16^{2} ^{t}K_{t}}},}{8q^{2}2^{t}Bn}}\}\], \[_{2_{t}}=\{,R^{2}}{64q ^{2}R^{2}B^{2}n^{2}}},}{64^{2}K_{t}}}\}\] and \[K_{t}=\{,}}{m  R},^{t}}{(G-B-m)^{2}R^{2}}\}\], where \[R\|^{0}-^{*}\|\] outputs \[}^{r}\] such that \[\|}^{r}-^{*}\|^{2}\]. Moreover, the total number of executed iterations of SEG-CC is_ \[_{t=1}^{r}K_{t}=(^{2}}{ }+}{(n-2B-m)}+}). \]The above result states that \(SEGCC}\) also converges to any accuracy without large batchsizes; see Appendix E.4. But with accuracy tending to zero (\( 0\)) the dominating term \(}{(n-2B-m) e}\) inversely depends on the number of workers, hence \(SEGCC}\) benefits from collaboration. Moreover, when \(B\) and \(m\) are small the derived complexity result for \(SEGCC}\) matches the one for parallel/mini-batched SEG[Juditsky et al., 2011], which is obtained for the case of no Byzantine workers.

## 3 Numerical Experiments

Quadratic game.To illustrate our theoretical results, we conduct numerical experiments on a quadratic game

\[_{y}_{z}_{i=1}^{s}y^{}_{1,i}y+ y^{}_{2,i}z-z^{}_{3,i}z+b_{1,i}^{}y -b_{2,i}^{}z.\]

The above problem can be re-formulated as a special case of (1) with \(F\) defined as follows:

\[F()=_{i=1}^{s}_{i}+b_{i},\ \ \ =(y^{},z^{})^{},\ b_{i}=(b_{1,i}^{},b_{2,i}^{})^{}, \]

with symmetric matrices \(_{j,i}\) s.t. \(_{j,i}\), \(_{i}^{d d}\) and \(b_{i}^{d}\); see Appendix F for the detailed description.

We set \(=100\), \(=0.1\), \(s=1000\) and \(d=50\). Only one peer checked the computations on each iteration (\(m=1\)). We used RFA (geometric median) with bucketing as an aggregator since it showed the best performance. For approximating the median we used Weiszfeld's method with \(10\) iterations and parameter \(=0.1\)[Pillutla et al., 2022]. RDEG[Adibi et al., 2022] provably works only if \(n 100\), so here we provide experiments with \(n=150\), \(B=20\), \(=2e-5\). We set the parameter \(=0.1\) for \(SS the first methods in this setting that provably converge to any predefined accuracy in the case of homogeneous data. We believe this is an important step towards building a strong theory of Byzantine robustness in the case of distributed VIs.

However, our work has several limitations. First of all, one can consider different/more general assumptions about operators (Beznosikov et al., 2023; Gorbunov et al., 2022; Gorbunov et al., 2022; Gorbunov et al., 2022) in the analysis of the proposed methods. Next, as we mention in the discussion after Theorem 3, our result for M-SGDA-RA requires large batchsizes, and it remains unclear to us whether this requirement can be removed. Finally, the only results that do not require large batchsizes are derived using the checks of computations that create (although small) computation overhead. Obtaining similar results without checks of computations remains an open problem. Addressing these limitations is a prominent direction for future research.

Figure 1: Error plots for quadratic games experiments under different Byzantine attacks. The first row shows the outperformance of M-SGDA-RA over methods without checks of computations. The second row illustrates advantages of SGDA-CC and SEG-CC.

Figure 2: Error plots for the robust neural network experiment on MNIST under different byzantine attacks (BF, LF, IPM, and ALIE). Each algorithm is shown with a consistent choice of color and style across plots, as indicated in the legends.