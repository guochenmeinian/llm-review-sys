# AdaPKC: PeakConv with Adaptive Peak Receptive Field for Radar Semantic Segmentation

Teng Li\({}^{2}\) Liwen Zhang\({}^{1}\)\({}^{}\) Youcheng Zhang\({}^{1}\) Zijun Hu\({}^{1}\)

**Pengcheng Pi\({}^{1}\) Zongqing Lu\({}^{2}\) Qingmin Liao\({}^{2}\) Zhe Ma\({}^{1}\)**

\({}^{1}\)Intelligent Science and Technology Academy of CASIC

\({}^{2}\)Shenzhen International Graduate School, Tsinghua University

liteng21@mails.tsinghua.edu.cn\({}^{}\) lwzhang9161@126.com\({}^{}\) liaqom@tsinghua.edu.cn\({}^{}\) Equal contribution. \({}^{}\)Corresponding author. This research is supported by Young Science Foundation of National Natural Science Foundation of China (No.62206258).

###### Abstract

Deep learning-based radar detection technology is receiving increasing attention in areas such as autonomous driving, UAV surveillance, and marine monitoring. Among recent efforts, PeakConv (PKC) provides a solution that can retain the peak response characteristics of radar signals and play the characteristics of deep convolution, thereby improving the effect of radar semantic segmentation (RSS). However, due to the use of a pre-set fixed peak receptive field sampling rule, PKC still has limitations in dealing with problems such as inconsistency of target frequency domain response broadening, non-homogeneous and time-varying characteristic of noise/clutter distribution. Therefore, this paper proposes an idea of **ad**aptive peak receptive field, and upgrades **PKC** to **AdaPKC** based on this idea. Beyond that, a novel fine-tuning technology to further boost the performance of AdaPKC-based RSS networks is presented. Through experimental verification using various real-measured radar data (including publicly available low-cost millimeter-wave radar dataset for autonomous driving and self-collected Ku-band surveillance radar dataset), we found that the performance of AdaPKC-based models surpasses other SoTA methods in RSS tasks. The code is available at https://github.com/lihua199710/AdaPKC.

## 1 Introduction

As a common remote sensing device, radar exhibits superior robustness in complex environments (_e.g._, varying weather and lighting conditions) compared to cameras, and it is more cost-effective and resilient in extreme weather scenarios compared to LiDARs. Benefiting from the physical advantages of radar sensors and the powerful capabilities of deep learning techniques, modern deep learning-based radar signal interpretation has become a hot research topic in the field of radio frequency detection technology. It has been extensively explored in autonomous driving , UAV surveillance , sea monitoring , etc. Considering the similar dense representations between radar frequency maps and optical images, most of these works directly transfer convolution networks or modules developed for optical signals to radar perception tasks, such as radar object detection (ROD) and radar semantic segmentation (RSS), and they have achieved impressive performance. Nevertheless, without specific design for the inherent characteristics of radar signals, these approaches fail to fully liberate the potential of deep learning techniques.

Recently, PKCIn-Net  introduced an innovative convolution operator named PeakConv (PKC), tailored for the efficient analysis of radar signals, and this operator seamlessly integrates the advantages of classic radar detectors  with common convolution networks [19; 6]. For radar signals, the frequency responses of objects comprise target echoes and interference, and share a distinct peak-shaped pattern, thus most classic radar detection methods [22; 10; 25; 23] build peak detection algorithms upon constant false alarm rate (CFAR) criteria. Extending from cell averaging-CFAR (CA-CFAR) , PKC explicitly embeds a similar band-pass peak enhancement mechanism in a standard convolution operator for better characterising target signatures in radar signals. Concretely, following the guard-reference policy of CA-CFAR, it first estimates interfering signals with the center unit/cell and reference units outside predefined guard bands. Then, with estimated interference, it finishes noise suppression for each cell under test (CUT) in feature space and enhances peak frequency response associated with objects of interest.

Despite its superior suitability for radar data than alternative convolution operators [31; 5; 33], there exists even greater potential for PKC to learn peak frequency response of radar signals. Research on CFAR detectors [10; 25; 23; 11] reveals that there exist significant variations in target signature and associated interference within radar signals, rendering the predefined reference cells in CA-CFAR inadequate for precisely locating interfering signals, and this limitation can also be observed in PKC. To provide a clearer depiction, let us delve deeper into these variations present within radar signals, as illustrated in Fig. 1. On the **target side**, since multi-dimensional radar tensors are generated through a sequence of cascading fast Fourier transformations (FFTs), target signatures along different dimensions exhibit distinct degrees of frequency response tailing (broadening). Additionally, the broadening degrees of different instances would also be influenced by target categories or states, _i.e._, the relative distances, azimuth or velocity from the radar. On the **interference side**, the noise or clutter distribution commonly exhibits non-homogeneous and time-varying characteristics. However, since the PKC kernel always gathers the reference units at fixed locations for noise estimation, _i.e._, the predefined peak receptive field (PRF), the dynamic variations in both targets and interference degrade its performance. In short, **the fixed PRF essentially limits the learning ability of PKC**, thus, it hinders the RSS model from obtaining better performance.

Motivated by the adaptive selection of reference cells in classic CFAR detectors [10; 25; 23], in this work we introduce two novel data-adaptive band-pass filtering mechanisms aimed at **upgrading PKC to adaptively adjust its PRF for each CUT** in a data-driven manner, namely **adap**ptive **Peak**Conv (AdaPKC). Concretely, both versions of AdaPKC first measure the correlation between CUT and its

Figure 1: The illustration of variations in target signature and interfering signals in radar frequency map. The first row illustrates the variations of the same target across temporally consecutive frames in the range-Doppler (RD)-amplitude 3D representation. The second row demonstrates the disparities of different targets in the same frame, as well as the same target across different frames, in the range-angle (RA) 2D representation. Cyan and yellow rectangles represent target areas, illustrating the variations of target signature with dimensions, categories, and time, etc. Red ellipses indicate prominent interfering clutter, while purple ellipses represent clutter undergoing significant changes.

alternative reference units in high-dimensional feature representations, then select proper reference units and integrate them seamlessly with PKC to effectively take care of the fluctuating dynamics of radar signals. The main contributions of our work are:

* We present the first attempt specially tailored for radar signal processing to dynamically adjust the receptive field for convolution operators. Concretely, we propose a novel updated version of PKC, termed as AdaPKC, which can adaptively adjust the PRF (or reference units) at cell-level granularity. And two different implementation versions are provided, which both exhibit enhanced flexibility and robustness in handling fluctuating radar signals compared to original PKC.
* To better release the learning ability of AdaPKC, a fine-tuning technology with a thresholding on-line switch is presented. With such technology, the same AdaPKC-based model can even achieve better performance with less computational cost.
* To verify the effectiveness of AdaPKCs, quantitative and qualitative experiments are conducted on various real-measured large scale radar datasets including CARRADA  collected from a low-cost FMCW (\( 77\)GHz) radar in autonomous driving scenario and self-collected dataset recorded from a Kurz-under (Ku) band (\( 17\)GHz) radar for UAV surveillance and sea monitoring. Results show that AdaPKC-based models achieve SoTA RSS performance and our fine-tuning strategy further brings visible improvements, verifying the scope of application of AdaPKCs.

## 2 Related Work

**Receptive field (RF) adjustment.** RF is crucial for modern deep convolution models, affecting the granularity of modeling primitives, computation architecture and their representation capabilities, etc. The rational use of RF can directly improve the representation ability of the models, _e.g_. enlarging the scope , multi-scale modeling , and dynamically changing shapes [5; 33]. Beyond that, the concept of RF has also been applied to Transformers [7; 16]. These methods are proposed for vision tasks and have achieved significant results. However, compared with conventional convolution, the improvement is not satisfactory enough on radar signals. Recently, by fully considering the characteristics of radar signals, the concept of PRF has been proposed, which makes the original convolution have the ability of band-pass filtering and noise suppression . However, the bandwidth of filtering is pre-set, which hinders the adaptive ability of PKC to radar data. To this end, this paper attempts to study a data-driven PRF adjustment method, and introduces the concept of adaptive PRF (AdaPRF), so as to further improve the RSS performance. Considering that the adaptive adjustment of the suppression (guard) bandwidth and the non-suppression (reference) units is essentially a dynamic adjustment of RF, and from this point of view, the content studied in this paper is related to deformable convolution (DefConv) [5; 33]. Unfortunately, the dynamic RF technology of DefConv cannot solve the problem in hand, for the following reasons: i) _Differences of signaling mechanism._ DefConv uses the visual prior information that the target is visually deformed geometrically, which cannot be directly corresponded to the radar signal. ii) _Mismatched prediction method._ DefConv generates new RF through prior prediction, _i.e_., the regular RF is still used to infer the sampling point outside regular RF. However, in radar signal, the interference (noise/clutter) with large entropy, is often difficult or even impossible to predict. At present, a better way is under the premise of observation, _i.e_., posterior measurement or statistics. iii) _Different mechanisms of representation_. Noise suppression is not required to be considered by DefConv, thus it does not need to distinguish between the center unit and surroundings during calculation. To this end, a novel adaptive RF adjustment method is required.

**Radar semantic segmentation.** Benefiting from the reliable perceptual capabilities, convolutional neural networks (CNNs) play an indispensable role in existing RSS networks for radar frequency maps processing, whether in pure CNN models [13; 8; 19; 32] or transformer-assisted CNN models [34; 12; 6]. RSS-Net  utilizes a fully convolutional neural network with encoder-decoder structure to recognize targets in radar scans, and it incorporates an atrous spatial pyramid pooling (ASPP)  module to gather multi-scale spatial information. RAMP-CNN  employs parallel branches to extract features from multiple views and adopts 3D convolutions to better capture temporal information. TMVA-Net  leverages these techniques to develop a multi-view RSS model, which is capable of making semantic predictions across multiple views simultaneously. T-RODNet  integrates Swin Transformer  modules into a CNN-based RSS model to strengthen its modeling capability. TransRSS  and TransRadar  introduce attention blocks into the multi-view feature fusion stage to enhance the fusion effectiveness. Recently, as the first fundamental convolution operator tailored for radar signal processing, PKC  is proposed. Compared to Dilated Convolution and Deformable ones [5; 33], PKC demonstrates superior RSS performance. However, it is inherently constrained by its fixed peak receptive field, posing challenges in achieving consistent interference (noise/clutter) suppression under the dynamic and time-varying nature of radar signals. By contrast, our AdaPKCs overcome this limitation well by implementing novel data-adaptive band-pass filtering mechanisms.

## 3 Method

In this section, the proposed two versions of AdaPKC with different AdaPRF mechanisms are first introduced in SS 3.1. Then, the proposed fine-tuning strategy to further uncover the potential of AdaPKC-based RSS models is presented in SS 3.2. We design these models using both multi-view [19; 32] and single-view frameworks, which are comprehensively described in Appendix A.2 and A.3 for saving space.

### AdaPKC

#### 3.1.1 AdaPKC\({}^{}\): PKC w/ Metric-based AdaPRF

To ensure the reliability of estimating the proper unit-level PRF, _i.e._, AdaPRF, for AdaPKC in radar signals, we establish the estimation process in a posterior way: we first define a set of candidate PRFs within the neighbourhood of the center unit, aligning with the local peak response of targets and the local scanning process of convolution, and then design a measuring criterion to evaluate these PRFs, estimating AdaPRF primarily occupied by interfering signals. Motivated by classic CFAR detectors [10; 25; 23], we first demonstrate how to estimate AdaPRF in an explicitly measuring way, referred to as metric-based AdaPRF (AdaPKC\({}^{}\)). To illustrate the mechanism of AdaPKC\({}^{}\), we begin by defining the search space of alternative PRFs. Reviewing the PRF definition in previous work  we can see that, the PRF for center unit \(_{c}\) encompasses \(_{c}\) itself and a set of sampled reference units \(\{_{r}^{(i)}\}_{i=1}^{N_{r}}\), and the area of reference units is governed by horizontal- and vertical-symmetry guard bandwidth \(^{}\{b_{x}^{},b_{y}^{}\}\) and reference bandwidth \(^{}\{b_{x}^{},b_{y}^{}\}\), as illustrated in Fig. 2-(a). Following this definition, the PRF adjustment corresponds precisely to the adjustment of the reference unit set, thus we can define the PRF search space by defining the candidate sets of reference units with the adjustment ranges for the guard bandwidth and reference bandwidth. Given that adjusting the reference bandwidth leads to a drastic change in the number of sampled reference units compared to adjusting the guard bandwidth, in AdaPKC\({}^{}\) we keep anytime-fixed \(^{}\{b_{x}^{}=1,\ b_{y}^{}=1\}\) and denote the set of \(K\) guard bandwidth candidates as \(^{}\{_{k}^{}\}_{k=1}^{K}=\{ ^{} b_{|x}^{} b_{x}^{}  b_{|x}^{},b_{|y}^{} b_{y}^{}  b_{|y}^{}\}\), generating \(K\) sets of reference units as \(\{\{_{r}^{(i)}\}_{k=1}^{N_{r}}\}_{k=1}^{K}\) correspondingly. As a result, AdaPRF estimation in AdaPKC\({}^{}\) is equivalent to selecting an appropriate reference unit set from these candidate sets for each CUT (or center unit), as illustrated in Fig. 2-(b).

For better explanation, we divide the observed radar signals into three subsets: i) signals reflected directly from a target, \(_{}\); ii) the target-interfering noise, _i.e._, the noise coupled with the signal that partially leaks out of the target, \(_{}\); and iii) the target-independent noise, \(_{}\). In practice, it is the part that from \(_{}\) really causes misjudgment. Therefore, classic CFAR detectors focus on filtering out such noise either by the extreme value [10; 25] or the median value  in amplitude domain of signals. Motivated by this idea, our AdaPKC\({}^{}\) centers its attention on collecting reference units predominantly occupied by such noise.

However, as a learnable module, AdaPKC\({}^{}\) needs to process the representation tensors of radar signals, implying that the measurement of the reference units should be conducted on feature space. For some CUT \(_{c}=(s;\ )\) and its candidate reference unit \(_{r}=(s^{};\ )\), where \(s_{}\), \(s^{}_{}_{} _{}\), and \((;\ )^{C}\) denotes a convolution layer with shared weights, \(\). Then, AdaPKC\({}^{}\) should be responsible for transforming these features into a metric space that explicitly delineates their correlation with the target. This transformation is achieved by utilizing the inner product of representations between CUT and its candidate reference unit, _i.e._, \(_{c}_{r}^{}\), sharing a similar spirit with the matched filter concept in conventional radar signal processing  and attention in .

Under this definition, these measures exhibit the following statistical properties,

\[(_{c}_{r}^{})=(\|(s;\ )\|_{2}^{2}),&s^{}_{}\\ (\|(s^{};\ )\|_{2}^{2}),&s^{} _{}\\ ,&s^{}_{},\] (1)

where, \(()\) is the expectation and \(\|\|_{2}\) denotes the \(L_{2}\) norm. From Eq. (1), we can see that the inner product transformation assigns three statistical boundaries to \(_{r}\) from \(_{}\), \(_{}\) and \(_{}\): for \(s^{}_{}\), the expectation \((_{c}_{r}^{})\) consistently exhibits smaller value than case for \(s^{}_{}\) and larger value than \(s^{}_{}\), with a notable separation between their respective magnitudes. This attribute significantly serves to facilitate the subsequent localization of reference units from target-interfering noise.

Then we elucidate the process of translating the \(K\) available sets of reference units (or PRFs) into the previously discussed metric space. Since different sets may comprise varying numbers of units, we uniformly sample \(N\) (\(16\) by default) units as representatives, as illustrated in Fig. 2-(b). For the center unit \(_{c}\) and its \(k^{th}\) reference unit set \(\{_{r|k}^{(i)}\}_{i=1}^{N}\), let \(_{k}=\{_{c},\{_{r|k}^{(i)}\}_{i=1}^{N}\}\) denote its corresponding PRF. Then the correlation value (or metric score), \(_{k}\) for the \(k^{th}\) PRF _w.r.t._\(_{c}\) is formulated as

\[_{k}=_{i=1}^{N}(_{c}_{r|k}^{( i)}/C),\] (2)

where, \(C\) is the feature dimension; \(()\) is the sigmoid function which normalizes \(_{k}\) to \((0,1)\).

With the correlation values \(=\{_{k}\}_{k=1}^{K}\) for all alternative PRFs, we can select the appropriate PRF \(^{}\), which effectively encompasses target-interfering noise. In view of the attribute presented in Eq. 1, we employ the maximum value of the first-order gradient of \(\) as the selection criterion and please refer to Appendix B.1 for the detailed analysis. Then, we have final selection strategy as follows,

\[^{}_{k} \{_{c}\}\{_{r|k}^{(i)}\}_{i=1}^{N},\ s.t.,\ k^{ }=_{k}\{g[()]\},\] (3)

where \(\) operator retrieves the index corresponding to the maximum value in \(g[()]\); \(g\) is the difference function; \(\) is the descending sort operator. After obtaining \(^{}\), AdaPKC performs a convolution operation similar to PeakConv, detailed in Appendix A.1.

#### 3.1.2 AdaPKC\({}^{}\): PKC w/ Learning-based AdaPRF

In AdaPKC\({}^{}\), a measuring criterion is established in Eq. 3 based on prior knowledge of radar signals, providing a non-parametric way to achieve AdaPRF. Differing from AdaPKC\({}^{}\), AdaPKC\({}^{}\) learns to

Figure 2: The illustration of AdaPRF in AdaPKC\({}^{}\). (a) illustrates the definition of PRF in PKC, whose area is governed by the reference bandwidth \(^{}\) and guard bandwidth \(^{}\); (b) describes the estimation process of AdaPRF in AdaPKC\({}^{}\), including denoting \(K\) candidate PRFs for each CUT, translating these PRFs into metric scores \(\{_{k}\}_{k=1}^{K}\), and finally selecting an appropriate PRF as the AdaPRF with these metric scores.

build the criterion in a task-driven manner, employing a small network to estimate AdaPRF, _i.e._, a parametric way. Thus, given center unit \(_{c}\) and its \(K\) candidate PRFs, \(\{_{k}\}_{k=1}^{K}\), the natural way to locate AdaPRF \(^{}\), is to define a function \(f(;\;)\) with learnable parameters \(\), which is used to produce the likelihood of each \(_{k}\) being \(^{}\), then we can have

\[^{}_{k^{}},k^{ }=_{k}\{\{f(_{k};\;)\}_{k=1}^{K} \}.\] (4)

At a rough glance, there is no obvious difference between Eq. 4 and Eq. 3. However, AdaPKC\({}^{}\) involves joint optimization of estimation network parameters (_i.e._, \(\)) and segmentation model parameters. The use of \(\) operation will lead to the loss of gradient information of \(\), as a result, the optimization of the estimation network cannot be driven by the segmentation task. To this end, we transform the discrete estimation problem into a continuous form. Firstly, following the setup of anytime-fixed \(^{}\{b_{x}^{}=1,\;b_{y}^{}=1\}\) in AdaPKC\({}^{}\), estimating \(^{}\) can be equivalently translated into estimating the optimal guard bandwidth \(^{}\). Subsequently, to ensure that the estimation of \(^{}\) retains gradient information, the estimation network is designed to generate the continuous-valued \(^{}\), instead of the likelihoods for alternative guard bandwidths. Finally, the derivable linear interpolation is used to associate the continuous-valued \(^{}\) with discrete spatial coordinates.

Concretely, given an input feature map \(^{C H W}\), our AdaPKC\({}^{}\) is responsible for obtaining an appropriate guard bandwidth \(^{}=\{^{}_{h,w}\}_{h=1,w=1}^{ H,W}^{4 H W}\). For enhancing the expressive capability of AdaPKC, the horizontal- and vertical-symmetry \(^{}\) design in the original PRF is extended to a quadruple form, \(^{}=\{b_{}^{},b_{}^{},b_{ }^{},b_{}^{}\}\), so that the shape of PRF would enjoy free change in four directions, _i.e._, _top_, _bottom_, _left_, _right_, as illustrated in Fig. 3-(a), resulting in more diverse band-pass filters. As shown in Fig. 3-(b), we use a small network with two paralleled conv blocks, \(g^{}():^{C H W} ^{2 H W}\) and \(g^{}():^{C H W}^{2  H W}\) to estimate \(^{}^{4}\) for each unit of \(\) in horizontal (\(\)-) and vertical (\(\)) directions, respectively. To ensure the directional consistency, the horizontal branch possesses kernels with a size of \(1(2b_{}^{}+1)\), and the kernel size of the vertical branch is \((2b_{}^{}+1) 1\), correspondingly. All four directions have the same lower bound, \(b_{}^{}=1\) and the same upper bound, \(b_{}^{}=3\) by default.

Then, for each \(_{c}\), its AdaPRF \(^{}=\{_{c},\;\{_{r}^{(i)}\}_{i=1 }^{N}\}\) (\(N=16\) by default) can be obtained by the following two steps:

**Step 1.** Guard bandwidth estimation:

\[^{}=(b_{}^{}-b_{}^{}) ((g^{}() g^{}()))+b_{}^{},\] (5)

Figure 3: The illustration of AdaPRF in AdaPKC\({}^{}\). (a) illustrates an example of candidate PRFs in AdaPKC\({}^{}\), where the guard bandwidth \(^{}\) is in a quadruple form; (b) describes the flowchart of the optimal guard bandwidth estimation network, which consists of two parallel branches that sample representative points in their corresponding directions and then automatically measure and select the optimal guard bandwidth.

where, each \(_{h,w}^{}\) in \(^{}\) is the learned guard bandwidth for \(_{c}\) of the spatial coordinate \((h,w)\); together with a constant \(b_{}^{}-b_{}^{}\), the sigmoid activation \(()\) can modulate the input values to \((0,\ b_{}^{}-b_{}^{})\); \(()\) and \(\) denotes the BatchNorm and Concat operator, respectively; \(^{4 H W}\) is an all-one cube.

**Step 2.** Reference unit sampling: for better illustration, we first define the default PRF with guard bandwidths equal to 1 in  as \(_{0}=\{_{c},\ \{_{r}^{(i)}\}_{i=1}^{N}\}\), which is shown in Fig. 2-(a). let \(_{c}=(h_{c},w_{c})\) and \(_{r}^{(i)}=(h_{r}^{(i)},w_{r}^{(i)})\) denote the spatial coordinate of the current center unit \(_{c}\) and one of its reference unit \(_{r}^{(i)}\) in \(_{0}\), respectively. Then we split \(\{_{r}^{(i)}\}_{i=1}^{N}\) into four subsets as \(\{_{r}^{(j)}\}_{j=1}^{M}\), \(\{_{r}^{(j)}\}_{j=1}^{M}\), \(\{_{r}^{(j)}\}_{j=1}^{M}\), \(\{_{r}^{(j)}\}_{j=1}^{M}\) and \(\{_{r}^{(j)}\}_{j=1}^{M}\), according to the four directions, where \(M=N/4\), as indicated by the braces drawn in Fig. 2-(a). By using \(^{}\) obtained from **Step 1**, we can sample \(^{}=\{_{c},\ \{_{r}^{(i)}\}_{i=1}^{N}\}\) through linear interpolation, as exemplified in Fig. 3-(a). Taking the top direction as an example, each \(_{r}^{(j)}\) can be obtained by

\[_{r}^{(j)}=[1-(b_{}^{ }- b_{}^{}) ]_{h_{r}^{(j)}- b_{}^{ }-1,w_{r}^{(j)}}+(b_{}^{} - b_{}^{})_{h_{r }^{(j)}- b_{}^{}-1,w_{r} ^{(j)}}.\] (6)

Sampling values for the rest directions and back-propagation of gradients in linear interpolation are demonstrated in Appendix B.2.

### Fine-tuning AdaPKC with Thresholding On-line Switch

To further release the learning ability of AdaPKC, a fine-tuning strategy is proposed. To improve interpretability, we focus mainly on optimizations for the explicit AdaPRF estimation version, _i.e._, AdaPKC\({}^{}\). The motivation comes from two perspectives. i) **Model confidence**: the representation ability and confidence of the model gradually improve with training, hence, during early training phase the less representative features may result in unreliable metric scores calculated in Eq. 2, consequently affecting the selection of AdaPRF and misleading the subsequent learning process. ii) **Data sparsity**: AdaPKC is responsible for the PRF adaptation for both background units (\(_{c}_{}\)) and target units (\(_{c}_{}\)). However, due to the sparsity of target occupation _w.r.t._ the radar detection range, most units in the input feature map are background units, thus the heavy class-imbalance hinders the model's concentration on target points and their AdaPRF optimization.

To address the above issues, we propose to **fine**-tune AdaPKC\({}^{}\) with a **th**resholding **on**-line **sw**itch (FiTOS), and please refer to Appendix C for a visual illustration. Firstly, a pre-trained PKC model with pre-defined PRFs is used to initialize the AdaPKC-based model to be optimized, so that AdaPKC can have a **warm-start before PRF adjustment**. Thus, the risk of obtaining unreliable metric scores is greatly reduced. Secondly, considering that the majority of background units are occupied by locally similar noise, _i.e._, their monotonic correlation/metric curves, \(()\), are relatively flat, FiTOS introduces **a confidence threshold \(\) to filter out these background units in spatial dimension on-the-fly**. Specifically, if the steepness of the metric curve, _i.e._, \(\{g[()]\}\), is below the threshold \(\), then the corresponding unit is considered a background unit, and we retain the initial PRF, _i.e._, switch off PRF adjustment. Otherwise, we adopt the newly estimated AdaPRF, _i.e._, switch on PRF adjustment. As a result, the PRF selection criterion in Eq. (3) is modified as follows,

\[^{} _{k}\{_{c}\}\{_{r}^{(i)}\}_{i=1 }^{N},\] (7) \[s.t.,\ k^{} =*{arg\,max}_{k}\{g[ ()]\}&,\{g[()]\}>\\ k_{0}&,,\]

where \(k_{0}\) denotes the index of pre-defined PRF in the pre-trained model.

## 4 Experiments

To verify the effectiveness of our methods, we conduct quantitative and qualitative experiments on two public multi-view radar datasets and our self-collected single-view radar dataset. For simplicity of notations, AdaPKC\({}^{}\)-based and AdaPKC\({}^{}\)-based multi-view RSS model is denoted as AdaPKC\({}^{}\)-Net and AdaPKC\({}^{}\)-Net, respectively. The proposed single-view baseline model is named KuRALS-Net. Additionally, we append _"FiT"_ in the upper right corner of the models to indicate the use of FiTOS.

### Datasets and Training Setups

**CARRADA** dataset is recorded by a low-cost FMCW radar in millimeter wave band (\( 77\)GHz). It comprises camera-radar synchronised multi-view radar recordings in various scenarios, and contains four categories of objects: _pedestrian_, _cyclist_, _car_ and _background_. The dimensions of provided range-angle-Doppler (RAD) tensors are \(256 256 64\) and support multi-view (RA and RD views) RSS task. The dataset splits are the same as in [32; 19]. **CARRADA-RAC** dataset is derived from CARRADA and mainly calibrates the original RA annotations, see Appendix D.1 for details.

**KuRALS** dataset is self-collected by a **Kur**z-under band (\( 17\)GHz) surveillance **R**adar, which is recorded in multiple scenarios, including Aerial vehicles, Land targets and ships on the Sea surface. Different from other public datasets, _e.g._, CARRADA  and CRUW , KuRALS aims at exploring the performance of deep models in the field of monitoring radar, hence offering a greater range field (\( 6.4\)km) and higher Doppler resolution (\( 0.198\)m/s). The comprised RD tensors are stored as \(2\)D matrices of size \(2048\) (range) by \(128\) (Doppler). This dataset contains \(9\) sequences of radar recordings and there exist four moving object categories: _UAV_, _pedestrian_, _vehicle_ and _ship_.

**Training Setups**. Following previous works, all models are evaluated with Intersection over Union (IoU) and Dice scores. These metrics are averaged across all classes on the test subset for model performance comparison, yielding mean IoU (mIoU) and mean Dice (mDice). **Implementation details** are presented in Appendix D.2.

### Investigation of AdaPKC Mechanism

To investigate the working mechanism of AdaPKCs, a series of comparison analysis is conducted on CARRADA benchmark. We first compare AdaPKCs with PeakConv and a manual PRF adjustment method. Results in Tab. 1 demonstrate that, both versions of AdaPKC exhibit significant enhancements in RSS performance compared to PeakConv, especially in the RA view, and they incur affordable additional computational complexity and inference speed overhead. Considering the severer signal tailing effect in RA view, this suggests that AdaPKC can better handle situations with frequency response ambiguity. For better illustration, we analyze the distribution of guard bandwidths in Appendix E.1. Additionally, since manually adjusting PRFs directly affects the RSS performance of PeakConv-based models, as discussed in , in this work we undertake a similar exploration experiment within a broader range of guard bandwidths. Specifically, different guard bandwidths in range dimension, \(b_{}^{}\{1,2,3,4,5\}\), are tested, while the guard bandwidths in angle and Doppler dimensions are fixed at \(1\) for controlling variables. To ensure consistent parameter counts under different bandwidth settings, we adopt the same strategy of uniform sampling as in AdaPKC\({}^{}\). As shown in Tab. 2, presetting a proper PRF globally in a hyper-parameter way can indeed help the PeakConv-based model achieve better performance. However, the manual adjustment way cannot cater to each unit, and the computational cost of traversing the guard bandwidth in all dimensions and directions is quite large. In contrast, AdaPKC completely automates the PRF adjustment, and the adjustment granularity reaches the unit-level. With this unit-level PRF adaptation capability, AdaPKCs demonstrate superior RSS performance compared to the manual adjustment way.

Furthermore, a comparative analysis between AdaPKCs and DefConvs (DefConv and DefConvV2) [5; 33] is conducted under the same RSS framework. Results in Tab. 3 show that, sharing the similar unit-level dynamic RF adjustment spirit with AdaPKC, DefConvs demonstrate better RSS performance than regular convolution (Conv). However, due to the three task-mismatched reasons discussed in SS 2, DefConvs exhibit inferior applicability compared to AdaPKC, highlighting AdaPKC's suitability for

    &  &  &  &  &  \\  & @Frames & & **mIoU** & & **mDice** & & \\ 
**PeakConv** & 6.3M@5 & 60.7\% & 72.6\% & 43.1\% & 53.7\% & **109.8** & **21.1** \\
**AdaPKC\({}^{}\)** & 6.3M@5 & 61.2\% & 73.1\% & **44.1\%** & **55.1\%** & **109.8** & 20.7 \\
**AdaPKC\({}^{}\)** & 6.3M@5 & **61.5\%** & **73.6\%** & 43.6\% & 54.5\% & 110.1 & 18.8 \\   

Table 1: Comparison between AdaPKCs and PeakConv. The best and secondary results are marked with **bold** and underline, correspondingly. Frame rate is calculated on a workstation with an Intel(R) Xeon(R) Platinum 8255C CPU and a Tesla V100-SXM2 GPU.

achieving adaptive receptive fields in radar signals. For supplementary purposes, we also show the comparison results between AdaPKC and dynamic CFAR detectors [10; 25; 23] in Appendix E.2.

As further explorations, we present an investigation into adaptive sampling strategies for reference band in Appendix E.3. Additionally, in Appendix E.4 we demonstrate a training strategy to enlarge the search space of alternative PRFs under fixed resource constraints for AdaPKC\({}^{}\).

### Comparison with State-of-The-Art (SoTA)

Our methods are further compared with fashionable visual segmentation models and existing SoTA RSS solutions. The **quantitative results** on the CARRADA benchmark are illustrated in Tab. 4 and the **qualitative comparisons** are presented in Appendix F.3. Both AdaPKC\({}^{}\)-Net and AdaPKC\({}^{}\)-Net outperform previous RSS models, including pure CNN models [13; 8; 19; 32] and transformer-assisted CNN models [12; 6]. Compared to the baseline model PKCIn-Net, AdaPKC\({}^{}\)-Net exhibits improvements in both RD and RA views, with a particularly notable enhancement in the RA view. AdaPKC\({}^{}\)-Net purely relies on task-driven PRF adjustment, achieving a better performance balance between two views. Additionally, without consuming extra training resources, our proposed FiTOS strategy further enhances RSS performance of AdaPKC\({}^{}\)-Net, achieving an overall superiority over AdaPKC\({}^{}\)-Net.

Results on CARRADA-RAC dataset are shown in Tab. 5. Similar to the trend on CARRADA, the evaluation results exhibit the superior performance of our methods than these RSS baseline models. AdaPKC\({}^{}\)-Net still shows a relatively balanced performance improvement in both views. AdaPKC\({}^{}\)-Net demonstrates a more pronounced improvement in the RD view, while

  
**Frameworks** & **\#Params** & **RD View** & **RA View** \\ 
**FCNN** & 134.3M@5 & 50.4\% & 59.4\% \\
**UN-Net** & 17.3M@5 & 52.4\% & 60.1\% \\
**DeepLabv3+** & 59.3M@5 & 52.6\% & 61.8\% \\ 
**KnRALS-Net** & 1.2M@5 & 56.0\% & 65.5\% \\
**KnRALS-Net** & 1.2M@5 & 56.7\% & 65.9\% \\
**KnRALS-Net** // AdaPKC\({}^{}\) & 1.2M@5 & 57.3\% & 67.2\% \\
**KnRALS-Net** // AdaPKC\({}^{}\) & 1.2M@5 & 57.8\% & **67.6\%** \\
**KnRALS-Net** // AdaPKC\({}^{}\) & 1.2M@5 & **58.2\%** & **67.6\%** \\   

Table 6: RSS performance comparison on CARRADA-RAC. Detailed results by category are presented in Appendix F.4.

   }^{}\)} &  &  \\   & **mIoU** & **mDice** & **mIoU** & **mDice** \\ 
1 & 60.7\% & 72.6\% & 43.1\% & 53.7\% \\
2 & **61.0\%** & **73.0\%** & **43.3\%** & **54.1\%** \\
3 & 60.7\% & 72.7\% & 42.5\% & 53.2\% \\
4 & 59.7\% & 71.5\% & 43.0\% & 53.8\% \\
5 & 60.4\% & 72.5\% & 42.7\% & 53.3\% \\   

Table 2: The effectiveness of manual PRF adjustment in PKC. \(b_{}^{}\) represents guard bandwidth in range dimension.

    & **\#Params** & **RD View** &  \\   & **\#Frames** & **mIoU** & **mDice** & **mIoU** & **mDice** \\ 
**TVA-Net** & 5.6M@5 & 59.7\% & 69.9\% & 46.6\% & 57.9\% \\
**PKCln-Net** & 6.3M@5 & 60.6\% & 72.4\% & 47.3\% & 58.7\% \\ 
**AdapPKC\({}^{}\)-Net** & 6.3M@5 & 61.6\% & **73.6\%** & 47.9\% & 59.3\% \\
**AdapPKC\({}^{}\)-Net** & 6.3M@5 & 60.7\% & 72.7\% & 48.1\% & 59.6\% \\
**AdapPKC\({}^{}\)-Net\({}^{}\)** & 6.3M@5 & 60.8\% & 72.7\% & **48.8\%** & **60.5\%** \\   

Table 5: Performance comparison on CARRADA-RAC.

    & **\#Params** & **RD View** &  \\   & **\#Frames** & **mIoU** & **mDice** & **mIoU** & **mDice** \\ 
**Conv** & 5.6M@5 & 56.1\% & 68.0\% & 37.7\% & 46.2\% \\
**DefConv** & 5.7M@5 & 58.0\% & 69.8\% & 39.1\% & 48.1\% \\
**DefConvV2** & 5.8M@5 & 58.8\% & 70.6\% & 39.3\% & 48.6\% \\
**AdapPKC\({}^{}\)** & 6.3M@5 & 61.2\% & 73.1\% & **44.1\%** & **55.1\%** \\
**AdapPKC\({}^{}\)** & 6.3M@5 & **61.5\%** & **73.6\%** & 43.6\% & 54.5\% \\   

Table 3: Comparison between AdaPKCs and DefConvs (DefConvV2).

AdaPKC\({}^{}\)-Net\({}^{FiT}\) shows a greater enhancement in the RA view. We speculate that this might be attributed to the collaborative training of different views in the multi-view segmentation task.

### RSS Performance on KuRALS

To verify the effectiveness of AdaPKCs in other application scenarios, we conduct comparative experiments on KuRALS dataset. **Quantitative results** are shown in Tab. 6 and the **qualitative comparisons** are presented in Appendix F.5. Compared to conventional visual segmentation models, our proposed KuRALS-Net offers a stronger baseline and AdaPKCs further boost the RSS performance of KuRALS-Net, validating their application potential in surveillance radar detection scenarios.

### Ablation Study for FiTOS

Since the threshold \(\) plays a vital role in FiTOS, we study the impact by testing different values of \(\) from \(0.1\) to \(0.9\). The summary results on mDice are shown in Fig. 4 and the corresponding mIoU results are presented in Appendix F.6. The optimal outcome for AdaPKC\({}^{}\)-Net\({}^{FiT}\) in RD and RA view is obtained with \(=0.6\) and \(0.7\), respectively. It is observed that the performance of AdaPKC\({}^{}\)-Net\({}^{FiT}\) declines when \(\) is either too large or too small. When \(\) goes larger, fewer target units adjust their PRFs during the fine-tuning stage, rendering AdaPKC\({}^{}\) less effective. Conversely, when \(\) is small, AdaPKC\({}^{}\) tends to focus on background units with random fluctuations, resulting in training confusion. Compared to PKCIn-Net, AdaPKC\({}^{}\)-Net\({}^{FiT}\) consistently demonstrates superiority under different \(\)s, highlighting the essentiality of PRF adaptation for the original PKC. When compared to AdaPKC\({}^{}\)-Net, AdaPKC\({}^{}\)-Net\({}^{FiT}\) exhibits superior performance with most values of \(\), demonstrating the efficacy of the fine-tuning strategy. Especially, in RD view, the RSS performance shows significant improvement within a broad range of \(\). Taking mDice as an example, it consistently surpasses \(73.5\%\) for \([0.5,0.8]\), indicating a strong level of robustness _w.r.t._\(\).

## 5 Conclusion

This work delves deeply into the convolution operator for radar signals, PKC, and improves upon it. Due to the design of PRF, PKC filters out the reference units corresponding to interfering signals in a band-pass filtering manner. Compared to other convolution operators in deep learning, PKC obtains a more robust representation by using the center unit and the reference unit to cancel each other out and then weighted fusion. However, the fixed suppression bandwidth (_i.e._, guard bandwidth) setting limits the adaptability of PKC to signal diversity. Based on this, we propose a method for adaptive adjustment of the PRF, and provide two effective solutions based on metrics and learning, _i.e._, AdaPKC\({}^{}\) and AdaPKC\({}^{}\). In addition, to further boost the learning ability of AdaPKC, a novel fine-tuning strategy is presented. To fully verify the effectiveness of AdaPKC, different real-measured radar datasets are used for experimental analysis. The results show the superior performance of AdaPKC in RSS tasks.

Figure 4: RSS performance of AdaPKC\({}^{}\)-Net\({}^{FiT}\) with different values of \(\{0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9\}\). AdaPKC\({}^{}\)-Net and PKCIn-Net actually corresponds to the case where \(\) of AdaPKC\({}^{}\)-Net\({}^{FiT}\) equals to \(0\) in whole training process and \(1\) in the fine-tuning stage, respectively.