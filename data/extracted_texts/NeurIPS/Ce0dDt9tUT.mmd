# Explore Positive Noise in Deep Learning

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

In computer vision, noise is conventionally viewed as a harmful perturbation in various deep learning architectures, such as convolutional neural networks (CNNs) and vision transformers (ViTs), as well as different tasks like image classification and transfer learning. However, this paper aims to rethink whether the conventional proposition always holds. We demonstrate that specific noise can boost the performance of various deep architectures under certain conditions. We theoretically prove the enhancement gained from positive noise by reducing the task complexity defined by information entropy and experimentally show the significant performance gain in large image datasets, such as the ImageNet. Herein, we use the information entropy to define the complexity of the task. We categorize the noise into two types, positive noise (PN) and harmful noise (HN), based on whether the noise can help reduce the complexity of the task. Extensive experiments of CNNs and ViTs have shown performance improvements by proactively injecting positive noise, where we achieve an unprecedented top 1 accuracy over 95\(\%\) on ImageNet. Both theoretical analysis and empirical evidence have confirmed that the presence of positive noise, can benefit the learning process, while the traditionally perceived harmful noise indeed impairs deep learning models. The different roles of noise offer new explanations for deep models on specific tasks and provide a new paradigm for improving model performance. Moreover, it reminds us to utilize noise rather than suppress noise.

## 1 Introduction

Noise, conventionally regarded as a hurdle in machine learning and deep learning tasks, is universal and unavoidable due to various reasons, e.g., environmental factors, instrumental calibration, and human activities . In computer vision, noise can be generated from different phases: (1) Image Acquisition: Noise can arise from a camera sensor or other imaging device . For example, electronic or thermal noise in the camera sensor can result in random pixel values or color variations that can be visible in the captured image. (2) Image Preprocessing: Noise can be introduced during preprocessing steps such as image resizing, filtering, or color space conversion . For example, resizing an image can introduce aliasing artifacts, while filtering an image can result in the loss of detail and texture. (3) Feature Extraction: Feature extraction algorithms can be sensitive to noise in the input image, which can result in inaccurate or inconsistent feature representations . For example, edge detection algorithms can be affected by noise in the image, resulting in false positives or negatives. (4) Algorithms: algorithms used for computer vision tasks, such as object detection or image segmentation, can also be sensitive to noise in the input data . Noise can cause the algorithm to learn incorrect patterns or features, leading to poor performance.

Since noise is an unavoidable reality in engineering tasks, existing works usually make the assumption that noise has a consistently negative impact on the current task . Nevertheless, is the above assumption always valid? As such, it is crucial to address the question of whether noise can everhave a positive influence on deep learning models. This work aims to provide a comprehensive answer to this question, which is a pressing concern in the deep learning community. We recognize that the imprecise definition of noise is a critical factor leading to the uncertainties surrounding the identification and characterization of noise. To address these uncertainties, an in-depth analysis of the task's complexity is imperative for arriving at a rigorous answer. By using the definition of task entropy, it is possible to categorize noise into two distinct categories: positive noise (PN) and harmful noise (HN). PN decreases the complexity of the task, while HN increases it, aligning with the conventional understanding of noise.

### Scope and Contribution

Our work aims to investigate how various types of noise affect deep learning models. Specifically, the study focuses on three common types of noise, i.e., Gaussian noise, linear transform noise, and salt-and-pepper noise. Gaussian noise refers to random fluctuations that follow a Gaussian distribution in pixel values at the image level or latent representations in latent space . Linear transforms, on the other hand, refer to affine elementary matrix transformations to the dataset of original images or latent representations, where the elementary matrix is row equivalent to an identity matrix . Salt-and-pepper noise is a kind of image distortion that adds random black or white values at the image level or to the latent representations .

This paper analyzes the impact of these types of noise on the performance of deep learning models for image classification and domain adaptation tasks. Two popular model families, Vision Transformers (ViTs) and Convolutional Neural Networks (CNNs), are considered in the study. Image classification is one of the most fundamental tasks in computer vision, where the goal is to predict the class label of an input image. Domain adaptation is a practically meaningful task where the training and test data come from different distributions, also known as different domains. By investigating the effects of different types of noise on ViTs and CNNs for typical deep learning tasks, the paper provides insights into the influences of noises on deep models. The findings presented in this paper hold practical significance for enhancing the performance of various types of deep learning models in real-world scenarios.

The contributions of this paper are summarized as follows:

* We re-examined the conventional view that noise, by default, has a negative impact on deep learning models. Our theoretical analysis and experimental results show that noise can be a positive support for deep learning models and tasks.
* We implemented extensive experiments with different deep models, such as CNNs and ViTs, and on different deep learning tasks. Empowered by positive noise, we achieved state-of-the-art (SOTA) results in all the experiments presented in this paper.
* Instead of operating on the image level, our injecting noise operations are performed in the latent space. We theoretically analyze the difference between injecting noise on the image level and in the latent space.
* The theory and framework of reducing task complexity via positive noise in this work can be applied to any deep learning architecture. There is great potential for exploring the application of positive noise in other deep-learning tasks beyond the image classification and domain adaptation tasks examined in this study.

### Related Work

**Positive Noise** In fact, within the signal-processing society, it has been demonstrated that random noise helps stochastic resonance improve the detection of weak signals . Noises can have positive support and contribute to less mean square error compared to the best linear unbiased estimator when the mixing probability distribution is not in the extreme region . Also, it has been reported that noise could increase the model generalization in natural language processing (NLP) . Recently, the perturbation, a special case of positive noise, has been effectively utilized to implement self-refinement in domain adaptation and achieved state-of-the-art performance . The latest research shows that by proactively adding specific noise to partial datasets, various tasks can benefit from the positive noise . Besides, noises are found to be able to boost brain power and be useful in many neuroscience studies .

**Deep Model** Convolutional Neural Networks have been widely used for image classification, object detection, and segmentation tasks, and have achieved impressive results . However, these networks have limitations in terms of their ability to capture long-range dependencies and extract global features from images. Recently, Vision Transformers has been proposed as an alternative to CNNs . ViT relies on self-attention mechanisms and a transformer-based architecture to enable global feature extraction and modeling of long-range dependencies in images . The attention mechanism allows the model to focus on the most informative features of the input image, while the transformer architecture facilitates information exchange between different parts of the image. ViT has demonstrated impressive performance on a range of image classification tasks and has the potential to outperform traditional CNN-based approaches. However, ViT currently requires a large number of parameters and training data to achieve state-of-the-art results, making it challenging to implement in certain settings .

## 2 Preliminary

In information theory, the entropy  of a random variable \(x\) is defined as:

\[H(x)=- p(x) p(x)dx&\\ -_{x}p(x) p(x)& \]

where \(p(x)\) is the distribution of the given variable \(x\). And the mutual information (MI) of two random discrete variables \((x,y)\) is denoted as :

\[MI(x,y)= D_{KL}(p(x,y) p(x) p(y)) \] \[= H(x)-H(x|y)\]

where \(D_{KL}\) is the Kullback-Leibler divergence , and \(p(x,y)\) is the joint distribution. The conditional entropy is defined as:

\[H(x|y)=- p(x,y) p(x|y) \]

The above definitions can be readily expanded to encompass continuous variables through the substitution of the sum operator with the integral symbol. In this work, the noise is denoted by \(\) if without any specific statement.

Before delving into the correlation between task and noise, it is imperative to address the initial crucial query of the mathematical measurement of a task \(\). With the assistance of information theory, the complexity associated with a given task \(\) can be measured in terms of the entropy of \(\). Therefore, we can borrow the concepts of information entropy to explain the difficulty of the task. For example, a smaller \(H()\) means an easier task and vice versa.

Since the entropy of task \(\) is formulated, it is not difficult to define the mutual information of task \(\) and noise \(\),

\[MI(,)=H()-H(|) \]

Formally, if the noise can help reduce the complexity of the task, i.e., \(H(|)<H()\) then the noise has positive support. Therefore, a noise \(\) is defined as **positive noise** (PN) when the noise satisfies \(MI(,)>0\). On the contrary, when \(MI(,) 0\), the noise is considered as the conventional noise and named **harmful noise** (HN). The positive noise can be perceived as an augmentation of information gain brought by \(\).

\[\{ MI(,)>0& \\ MI(,) 0&. \]

**Moderate Model Assumption**: The positive noise may not work for deep models with severe problems. For example, the model is severely overfitting where models begin to memorize the random fluctuations in the data instead of learning the underlying patterns. In that case, the presence of positive noise will not have significant positive support in improving the models' performance. Besides, when the models are corrupted under brute force attack, the positive noise also can not work.

## 3 Methods

The idea of exploring the influence of noise on the deep models is straightforward. The framework is depicted in Fig. 1. This is a universal framework where there are different options for deep models, such as CNNs and ViTs. Through the simple operation of injecting noise into a randomly selected layer, a model has the potential to gain additional information to reduce task complexity, thereby improving its performance. It is sufficient to inject noise into a single layer instead of multiple layers since it imposes a regularization on multiple layers simultaneously.

For a classification problem, the dataset \((,)\) can be regarded as samplings derived from \(D_{,}\), where \(D_{,}\) is some unknown joint distribution of data points and labels from feasible space \(\) and \(\), i.e., \((,) D_{,}\). Hence, given a set of \(k\) data points \(=\{X_{1},X_{2},...,X_{k}\}\), the label set \(=\{Y_{1},Y_{2},...,Y_{k}\}\) is regarded as sampling from \( D_{|}\). The complexity of \(\) on dataset \(\) is formulated as :

\[H(;)=-_{}p(|) p(|) \]

The operation of adding noise at the image level can be formulated as:

\[H(;+)=-_{}p (|+) p(|+)&$ is additive noise}\\ H(;)=-_{}p(|) p(|)&$ is multiplicative noise} \]

While the operation of proactively injecting noise in the latent space can be formulated as:

\[H(;+)}H( ;+)-H()&$ is additive noise}\\ H(;)}H(; )-H()&$ is multiplicative noise} \]

Step \(\) differs from the conventional definition of conditional entropy, as our method injects the noise into the latent representations instead of the original images. The Gaussian noise is additive, the linear transform noise is also additive, and the salt-and-pepper is a multiplicative noise.

**Gaussian Noise** The Gaussian noise is one of the most common additive noises that appeared in computer vision tasks. The Gaussian noise is independent and stochastic, obeying the Gaussian distribution. Without loss of generality, defined as \((,^{2})\). Since our injection happens in the latent space, therefore, the complexity of the task is:

\[H(;+) H(;+)- H(). \]

Figure 1: An overview of the proposed method. Above the black line is the standard pipeline for image classification. The deep model can be CNNs or ViTs. The noise is injected into a randomly chosen layer of the model represented by the blue arrow.

According to the definition in Equation 4, and making the distribution of \(\) and \(\) multivariate normal distribution , the mutual information with Gaussian noise is:

\[MI(,)= H(;)-H()-(H(;+)-H())\] \[= H(;)-H(;+)\] \[= _{}||_{}- _{X}_{}^{-1}_{}|}{|_{+}||_{}-_{X}_{}^{-1}_{}|} \] \[= ^{2}_{i=1}^{k} }^{2}})(1+_{i=1}^{k}^{2}(X_ {i},Y_{i})}{_{X_{i}}^{2}(_{X_{i}}^{2}_{Y_{i}}^{2}-^{2}(X_{i},Y_{i}))})}\]

where \(=^{2}}{1+_{i=1}^{k}}^{ 2}}}\), \(_{}^{2}\) is the variance of the Gaussian noise, \((X_{i},Y_{i})\) is the covariance of sample pair \(X_{i}\), \(Y_{i}\), \(_{X_{i}}^{2}\) and \(_{Y_{i}}^{2}\) are the variance of data sample \(X_{i}\) and data label \(Y_{i}\), respectively. The detailed derivations can be found in section 1.1.2 of the supplementary. Given a dataset, the variance of the Gaussian noise, and statistical properties of data samples and labels control the mutual information, we define the function:

\[f(_{}^{2})= 1-(1+_{}^{2}_{i=1}^{k}}^{ 2}})(1+_{i=1}^{k}^{2}(X_{i},Y_{i})}{_{X_{i} }^{2}(_{X_{i}}^{2}_{Y_{i}}^{2}-^{2}(X_{i},Y_{i}))}) \] \[= -_{}^{2}_{i=1}^{k}}^{2}}- _{}^{2}_{i=1}^{k}}^{2}} _{i=1}^{k}^{2}(X_{i},Y_{i})}{_{X_{i}}^{2}(_{ X_{i}}^{2}_{Y_{i}}^{2}-^{2}(X_{i},Y_{i}))}-_{i=1}^{k} ^{2}(X_{i},Y_{i})}{_{X_{i}}^{2}(_{X_{i}}^{2} _{Y_{i}}^{2}-^{2}(X_{i},Y_{i}))}\]

Since \(^{2} 0\) and \( 0\), \(_{X_{i}}^{2}_{Y_{i}}^{2}-^{2}(X_{i},Y_{i})=_{X_{ i}}^{2}_{Y_{i}}^{2}(1-_{X_{i}Y_{i}}^{2}) 0\), where \(_{X_{i}Y_{i}}\) is the correlation coefficient, the sign of \(f(_{}^{2})\) is negative. We can conclude that Gaussian noise injected into the latent space is harmful to the task. More details and the Gaussian noise added to the image level are provided in the supplementary.

**Linear Transform Noise** This type of noise is obtained by elementary transformation of the features matrix, i.e., \(=Q\), where \(Q\) is an elementary matrix. We name the \(Q\) the quality matrix since it controls the property of linear transform noise and determines whether positive or harmful. In the linear transform noise injection in the latent space case, the complexity of the task is:

\[H(;+Q)H(;+Q)-H( {X}) \]

The mutual information is then formulated as:

\[MI(,Q) H(;)-H()-(H(;+Q)-H()) \] \[= H(;)-H(;+Q)\] \[= _{}||_{}- _{}_{}^{-1}_{}|}{| _{(I+Q)}||_{}-_{} {}_{}^{-1}_{}|}\] \[= }\] \[= -|I+Q|\]

Since we want the mutual information to be greater than 0, we can formulate Equation 13 as an optimization problem:

\[_{Q}MI(,Q) \] \[s.t.\ rank(I+Q)=k\] \[Q I\] \[[I+Q]_{ii}[I+Q]_{ij},i j\] \[\|[I+Q]_{i}\|_{1}=1\]

where \(\) means the row equivalence. The key to determining whether the linear transform is positive noise or not lies in the matrix of \(Q\). The most important step is to ensure that \(I+Q\) is reversible,which is \(|(I+Q)| 0\). The third constraint is to make the trained classifier get enough information about a specific image and correctly predict the corresponding label. For example, for an image \(X_{1}\) perturbed by another image \(X_{2}\), the classifier obtained dominant information from \(X_{1}\) so that it can predict the label \(Y_{1}\). However, if the perturbed image \(X_{2}\) is dominant, the classifier can hardly predict the correct label \(Y_{1}\) and is more likely to predict as \(Y_{2}\). The fourth constraint is to maintain the norm of latent representations. More in-depth discussion and linear transform noise added to the image level are provided in the supplementary.

**Salt-and-pepper Noise** The salt-and-pepper noise is a common multiplicative noise for images. The image can exhibit unnatural changes, such as black pixels in bright areas or white pixels in dark areas, specifically as a result of the signal disruption caused by sudden strong interference or bit transmission errors. In the Salt-and-pepper noise case, the mutual information is:

\[MI(,) H(;)-H()-(H(;)-H()) \] \[= H(;)-H(;)\] \[= -_{}_{}p(, ) p(,)-_{}_{ }_{}p(,)  p(,)\] \[= [,)}]- [,)}]\] \[= [,)}]- [,)}]-[)}]\] \[= -H()\]

Obviously, the mutual information is smaller than 0, which indicates the complexity is increasing when injecting salt-and-pepper noise into the deep model. As can be foreseen, the salt-and-pepper noise is pure detrimental noise. More details and Salt-and-pepper added to the image level are in the supplementary.

## 4 Experiments

In this section, we conduct extensive experiments to explore the influence of various types of noises on deep learning models. We employ popular deep learning architectures, including both CNNs and ViTs, and show that the two kinds of deep models can benefit from the positive noise. We employ deep learning models of various scales, including ViT-Tiny (ViT-T), ViT-Small (ViT-S), ViT-Base (ViT-B), and ViT-Large (ViT-L) for Vision Transformers (ViTs), and ResNet-18, ResNet-34, ResNet-50, and ResNet-101 for ResNet architecture. The details of deep models are presented in the supplementary. Without specific instructions, the noise is injected at the last layer of the deep models. Note that for ResNet models, the number of macro layers is 4, and for each macro layer, different scale ResNet models have different micro sublayers. For example, for ResNet-18, the number of macro layers is 4, and for each macro layer, the number of micro sublayers is 2. The noise is injected at the last micro sublayer of the last macro layer for ResNet models. More experimental settings for ResNet and ViT are detailed in the supplementary.

### Noise Setting

We utilize the standard normal distribution to generate Gaussian noise in our experiments, ensuring that the noise has zero mean and unit variance. Gaussian noise can be expressed as:

\[(0,1) \]

For linear transform noise, we use a quality matrix of as:

\[Q=- I+ f(I) \]

where \(I\) is the identity matrix, \(\) represents the linear transform strength and \(f\) is a row cyclic shift operation switching row to the next row, for example, in a \(3 3\) matrix, \(f\) will move Row 1 to Row 2, Row 2 to Row 3, and Row 3 to Row 1. For salt-and-pepper noise, we also use the parameter \(\) to control the probability of the emergence of salt-and-pepper noise, which can be formulated as:

\[max(X)&p</2\\ min(X)&p>1-/2 \]where \(p\) is a probability generated by a random seed, \([0,1)\), and \(X\) is the representation of an image.

### Image Classification Results

We implement extensive experiments on large-scale datasets such as ImageNet  and small-scale datasets such as TinyImageNet  using ResNets and ViTs.

#### 4.2.1 CNN Family

The results of ResNets with different noises on ImageNet are in Table 1. As shown in the table, with the design of linear transform noise to be positive noise (PN), ResNet improves the classification accuracy by a large margin. While the salt-and-pepper, which is theoretically harmful noise (HN), degrades the models. Note we did not utilize data augmentation techniques for ResNet experiments except for normalization. The significant results show that positive noise can effectively improve classification accuracy by reducing task complexity.

#### 4.2.2 ViT Family

The results of ViT with different noises on ImageNet are in Table 2. Since the ViT-L is overfitting on the ImageNet , the positive noise did not work well on the ViT-L. As shown in the table, the existence of positive noise improves the classification accuracy of ViT by a large margin compared to vanilla ViT. The comparisons with previously published works, such as DeiT , SwinTransformer , DaViT , and MaxViT , are shown in Table 3, and our positive noise-empowered ViT achieved the new state-of-the-art result. Note that the JFT-300M and JFT-4B datasets are private and not publicly available , and we believe that ViT large and above will benefit from positive noise significantly if trained on larger JFT-300M or JFT-4B, which is theoretically supported in section 4.4.

### Ablation Study

We also proactively inject noise into variants of ViT, such as DeiT , Swin Transformer , BEiT , and ConViT , and the results show that positive noise could benefit various variants of ViT by improving classification accuracy significantly. The results of injecting noise to variants of ViT are reported in the supplementary. We also did ablation studies on the strength of linear transform noise and the injected layer. The results are shown in Fig. 2. We can observe that the deeper layer the positive noise injects, the better prediction performance the model can obtain. There are reasons behind this phenomenon. First, the latent features of input in the deeper layer have better

   Model & ResNet-18 & ResNet-34 & ResNet-50 & ResNet-101 \\  Vanilla & 63.90 (+0.00) & 66.80 (+0.00) & 70.00 (+0.00) & 70.66 (+0.00) \\ + Gaussian Noise & 62.35 (-1.55) & 65.40 (-1.40) & 69.62 (-0.33) & 70.10 (-0.56) \\ + Linear Transform Noise & **79.62 (+15.72)** & **80.05 (+13.25)** & **81.32 (+11.32)** & **81.91 (+11.25)** \\ + Salt-and-pepper Noise & 55.45 (-8.45) & 63.36 (-3.44) & 45.89 (-24.11) & 52.96 (-17.70) \\   

Table 1: ResNet with different kinds of noise on ImageNet. Vanilla means the vanilla model without noise. Accuracy is shown in percentage. Gaussian noise used here is subjected to standard normal distribution. Linear transform noise used in this table is designed to be positive noise. The difference is shown in the bracket.

   Model & ViT-T & ViT-S & ViT-B & ViT-L \\  Vanilla & 79.34 (+0.00) & 81.88 (+0.00) & 84.33 (+0.00) & 88.64 (+0.00) \\ + Gaussian Noise & 79.10 (-0.24) & 81.80 (-0.08) & 83.41 (-0.92) & 85.92 (-2.72) \\ + Linear Transform Noise & **80.69 (+1.35)** & **87.27 (+5.39)** & **89.99 (+5.66)** & **88.72 (+0.08)** \\ + Salt-and-pepper Noise & 78.64 (-0.70) & 81.75 (-0.13) & 82.40 (-1.93) & 85.15 (-3.49) \\   

Table 2: ViT with different kinds of noise on ImageNet. Vanilla means the vanilla model without injecting noise. Accuracy is shown in percentage. Gaussian noise used here is subjected to standard normal distribution. Linear transform noise used in this table is designed to be positive noise. The difference is shown in the bracket. Note ViT-L is overfitting on ImageNet .

representations than those in shallow layers; second, injection to shallow layers obtain less mutual information gain because of trendy replacing Equation 8 with Equation 7. More results on the small dataset TinyImageNet can be found in the supplementary.

### Optimal Quality Matrix

As shown in Equation 14, it is interesting to learn about the optimal quality matrix of \(Q\) that maximizes the mutual information while satisfying the constraints. This equals minimizing the determinant of the matrix sum of \(I\) and \(Q\). Here, we directly give out the optimal quality matrix of \(Q\) as:

\[Q_{optimal}=(-1,,-1)+ _{k k} \]

where \(k\) is the number of data samples. And the corresponding upper boundary of the mutual information as:

\[MI(,Q_{optimal})=(k-1) \]

   Model & Top1 Acc. & Params. & Image Res. & Pretrained Dataset \\  ViT-B  & 84.33 & 86M & 224 \(\) 224 & ImageNet 21k \\ DeiT-B  & 85.70 & 86M & 224 \(\) 224 & ImageNet 21k \\ SwinTransformer-B  & 86.40 & 88M & 384 \(\) 384 & ImageNet 21k \\ DaViT-B  & 86.90 & 88M & 384 \(\) 384 & ImageNet 21k \\ MaxViT-B  & 88.82 & 119M & 512 \(\) 512 & JFT-300M (Private) \\ ViT-22B  & 89.51 & 21743M & 224 \(\) 224 & JFT-4B (Private) \\  ViT-B+PN & **89.99** & 86M & 224 \(\) 224 & ImageNet 21k \\ ViT-B+PN & **91.37** & 86M & 384 \(\) 384 & ImageNet 21k \\   

Table 3: Comparison between Positive Noise Empowered ViT with other ViT variants. Top 1 Accuracy is shown in percentage. Here PN is the positive noise, i.e., linear transform noise.

Figure 2: The relationship between the linear transform noise strength and the top 1 accuracy, and between the injected layer and top 1 accuracy. Parts (a) and (b) are the results of the CNN family, while parts (c) and (d) are the results of the ViT family. For parts (a) and (c) the linear transform noise is injected at the last layer. For parts (b) and (d), the influence of positive noise on different layers is shown. Layers 6, 8, 10, and 12 in the ViT family are chosen for the ablation study.

The details are provided in the supplementary. We find that the upper boundary of the mutual information of injecting positive noise is determined by the number of data samples, i.e., the scale of the dataset. Therefore, the larger the dataset, the better effect of injecting positive noise into deep models. With the optimal quality matrix and the top 1 accuracy of ViT-B on ImageNet can be further improved to 95\(\%\), which is shown in Table 4.

### Domain Adaption Results

Unsupervised domain adaptation (UDA) aims to learn transferable knowledge across the source and target domains with different distributions . Recently, transformer-based methods achieved SOTA results on UDA, therefore, we evaluate the ViT-B with the positive noise on widely used UDA benchmarks. Here the positive noise is the linear transform noise identical to that used in the classification task. The positive noise is injected into the last layer of the model, the same as the classification task. The datasets include **Office Home** and **VisDA2017**. Detailed datasets introduction and experiments training settings are in the supplementary. The objective function is borrowed from TVT , which is the first work that adopts Transformer-based architecture for UDA. The results are shown in Table 5 and 6. The ViT-B with positive noise achieves better performance than the existing works. These results show that positive noise can improve model generality, therefore, benefit deep models in domain adaptation tasks.

## 5 Conclusion

This study presents a comprehensive investigation into the influence of various common noise types on deep learning models, including Gaussian noise, linear transform noise, and salt-and-pepper noise. We demonstrate that, under certain conditions, linear transform noise can have a positive effect on deep models. Our experiments show that injecting the positive noise in latent space can significantly enhance the prediction performance of deep models on image classification tasks, leading to new state-of-the-art results on ImageNet. The findings of this study have a broad impact on future research and may contribute to the development of more accurate models and their improved performance in real-world applications. Moreover, we are excited to explore the potential of positive noise in more deep learning tasks.

  Method & plane & bcycl & bus & car & horse & knife & mcycl & person & plant & sktbrd & train & truck & Avg. \\  ViT-B & 97.7 & 48.1 & 86.6 & 61.6 & 78.1 & 63.4 & 94.7 & 10.3 & 87.7 & 47.7 & 94.4 & 35.5 & 67.1 \\ TVT-B & 92.9 & 85.6 & 77.5 & 60.5 & 93.6 & 98.2 & 89.4 & 76.4 & 93.6 & 92.0 & 91.7 & 55.7 & 83.9 \\ CDTrans-B & 97.1 & 90.5 & 82.4 & 77.5 & 96.6 & 96.1 & 93.6 & **88.6** & **97.9** & 86.9 & 90.3 & 62.8 & 88.4 \\ SSRT-B  & **98.9** & 87.6 & **89.1** & **84.8** & 98.3 & **98.7** & **96.3** & 81.1 & 94.9 & 97.9 & 94.5 & 43.1 & 88.8 \\ ViT-B+PN & 98.8 & **95.5** & 84.8 & 73.7 & **98.5** & 97.2 & 95.1 & 76.5 & 95.9 & **98.4** & **98.3** & **67.2** & **90.0** \\  

Table 6: Comparison with various ViT-based methods on **Visda2017**.

  Method & Tap1 Acc. & Params. & Image Res. & Pretrained Dataset \\  ViT-B+Optimal Q & **93.87** & 86M & 224 \(\) 224 & ImageNet 21k \\  ViT-B+Optimal Q & **95.12** & 86M & 384 \(\) 384 & ImageNet 21k \\  

Table 4: Top 1 accuracy on ImageNet with the optimal quality matrix of linear transform noise.

  Method & Ar2CIAr2Pr & Ar2ReCI2Ar & Cl2Pr & Cl2RePr2Ar & Pr2ClPr2Re & Re2Ar & Re2ClRe2PrAvg. \\  ViT-B & 54.7 & 83.0 & 87.2 & 77.3 & 83.4 & 85.6 & 74.4 & 50.9 & 87.2 & 79.6 & 54.8 & 88.8 & 75.5 \\ TVT-B & 74.9 & 86.8 & 89.5 & 82.8 & 88.0 & 88.3 & 79.8 & 71.9 & 90.1 & 85.5 & 74.6 & 90.6 & 83.6 \\ CDTrans-B & 68.8 & 85.0 & 86.9 & 81.5 & 87.1 & 87.3 & 79.6 & 63.3 & 88.2 & 82.0 & 66.0 & 90.6 & 80.5 \\ SSRT-B  & 75.2 & 89.0 & 91.1 & 85.1 & 88.3 & 90.0 & 85.0 & 74.2 & 91.3 & 85.7 & 78.6 & 91.8 & 85.4 \\ ViT-B+PN & **78.3** & **90.6** & **91.9** & **87.8** & **92.1** & **91.9** & **85.8** & **78.7** & **93.0** & **88.6** & **80.6** & **93.5** & **87.7** \\  

Table 5: Comparison with various ViT-based methods on **Office-Home**.