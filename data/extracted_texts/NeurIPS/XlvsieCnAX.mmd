# Exact Representation of Sparse Networks with

Symmetric Nonnegative Embeddings

Sudhanshu Chanpuriya\({}^{1}\), Ryan A. Rossi\({}^{2}\), Anup Rao\({}^{2}\), Tung Mai\({}^{2}\),

Nedim Lipka\({}^{2}\), Zhao Song\({}^{2}\), and Cameron Musco\({}^{3}\)

\({}^{1}\)University of Illinois Urbana-Champaign, schariya@illinois.edu

\({}^{2}\)Adobe Research, {ryrossi,anuproa,tumai,lipka,zsong}@adobe.com

\({}^{3}\)University of Massachusetts Amherst, cmusco@cs.umass.edu

###### Abstract

Graph models based on factorization of the adjacency matrix often fail to capture network structures related to links between dissimilar nodes (heterophily). We introduce a novel graph factorization model that leverages two nonnegative vectors per node to interpretably account for links between both similar and dissimilar nodes. We prove that our model can exactly represent any graph with low _arboricity_, a property that many real-world networks satisfy; our proof also applies to related models but has much greater scope than the closest prior bound, which is based on low _max degree_. Our factorization also has compelling properties besides expressiveness: due to its symmetric structure and nonnegativity, fitting the model inherently finds node communities, and the model's link predictions can be interpreted in terms of these communities. In experiments on real-world networks, we demonstrate our factorization's effectiveness on a variety of tasks, including community detection and link prediction.

## 1 Introduction

Graphs data naturally arises in a variety of fields including sociology (Mason & Verwoerd, 2007), biology (Scott, 1988), and computer networking (Bonato, 2004). A key task in machine learning for graph data is forming models of graphs that can predict edges between nodes, form useful representations of nodes, and reveal interpretable structure in the graph, such as detecting clusters of nodes. Many graph models fall under the framework of edge-independent graph generative models, which output the probabilities of edges existing between any pair of nodes. The parameters of such models can be trained iteratively on the network, or some fraction of the network which is known, in the link prediction task, i.e., by minimizing a predictive loss. To choose among these models, one must consider two criteria: 1) whether the model can express structures of interest in the graph, 2) whether the model expresses these structures in an interpretable way.

Expressiveness of low-dimensional embeddingsAs real-world graphs are high-dimensional objects, graph models generally compress information about the graph. For example, dot product models associate each node with a real-valued "embedding" vector; the predicted probability of a link between two nodes increases with the similarity of their embeddings. These models can alternatively be seen as factorizing the graph's adjacency matrix to approximate it with a low-rank matrix. Recent work of Seshadhri et al. (2020) has shown that dot product models are limited in their ability to model common structures in real-world graphs, such as triangles incident only on low-degree nodes. In response, Chanpuriya et al. (2020) showed that with the logistic principal components analysis (LPCA) model, which has two embeddings per node (i.e., using the dot product of the 'left' embedding of one node and the 'right' embedding of another), not only can such structures be represented, but further, any graph can be exactly represented with embedding vectors whose lengths are linear in themax degree of the graph. There are two keys to this result. First is the presence of a nonlinear linking function in LPCA; since adjacency matrices are generally not low-rank, exact low-rank factorization is impossible without a linking function. Second is that having two embeddings rather than one allows for expression of non-positive semidefinite (PSD) matrices. As discussed in Peysakhovich & Bottou (2021), that the single-embedding models can only represent PSD matrices precludes representation of 'heterophilous' structures in graphs; heterophilous structures are those wherein dissimilar nodes are linked, in contrast to more intuitive 'homophilous' linking between similar nodes.

Interpretability and node clusteringBeyond being able to capture a given network accurately, it is often desirable for a graph model to form interpretable representations of nodes and to produce edge probabilities in an interpretable fashion. Dot product models can achieve this by restricting the node embeddings to be nonnegative. Nonnegative factorization has long been used to decompose data into parts (Donoho & Stodden, 2003). In the context of graphs, this entails decomposing the set of nodes of the network into clusters or communities. In particular, each entry of the nonnegative embedding vector of a node represents the intensity with which the node participates in a community. This allows the edge probabilities output by dot product models to be interpretable in terms of coparicipation in communities. Depending on the model, these vectors may have restrictions such as a sum-to-one requirement, meaning the node is assigned a categorical distribution over communities. The least restrictive and most expressive case is that of soft assignments to overlapping communities, where the entries can vary totally independently. In such models, which include the BigClam model of Yang & Leskovec (2013), the output of the dot product may be mapped through a nonlinear link function (as in LPCA) to produce a probability for each edge, i.e., to ensure the values lie in \(\).

Summary of contributionsThe key contributions of this work are as follows:

* We prove that LPCA admits exact low-rank factorizations of graphs with bounded _arboricity_, which is the minimum number of forests into which a graph's edges can be partitioned. By the Nash-Williams theorem, arboricity is a measure of a graph's density in that, letting \(S\) denote an induced subgraph and \(n_{S}\) and \(m_{S}\) denote the number of nodes and edges in \(S\), arboricity is the maximum over all \(S\) of \(}{n_{S}-1}\). Our result is more applicable to real-world graphs than the prior result of Chanpuruis et al. (2020) for graphs with bounded max degree, since sparsity is a common feature of real networks, whereas low max degree is not.
* We introduce a graph model that extends LPCA and is both highly expressive and interpretable. Our model incorporates two embeddings per node and a nonlinear linking function, and hence is able to express both heterophily and overlapping communities. At the same time, our model is based on symmetric nonnegative matrix factorization, so it outputs link probabilities that are interpretable in terms of the communities it detects. While prior graph factorizations incorporate some aspects of nonnegativity, heterophily, and/or nonlinearity, our proposed model lies at the intersection of all three.
* We show how any graph with a low-rank factorization in the LPCA model also admits a low-rank factorization in our community-based model. This means that the guarantees on low-rank representation for bounded max degree and arboricity also apply to our model.
* In experiments, we show that our method is competitive with and often outperforms other comparable models on real-world graphs in terms of representing the network, doing interpretable link prediction, and detecting communities that align with ground-truth.

## 2 Motivating Example

To demonstrate how heterophily can manifest in networks, as well as how models which assume homophily can fail to represent such networks, we provide a simple synthetic example involving a graph of matches between users of a dating app. Suppose that users of this app are generally seeking partners of a different gender (to simplify this example, we assume that each user of the app is either a man or a woman), and suppose that each user comes from one of ten cities. Members from the same city are likely to match with each other; this typifies homophily, wherein links occur between similar nodes. Furthermore, users having the same gender are unlikely to match with each other; this typifies heterophily. Figure 1 shows an instantiation of such an adjacency matrix with \(1000\) nodes, which are randomly assigned to man or woman and to one of the ten cities. We recreate this network with our proposed embedding model and with BigClam, which explicitly assumeshomophily. We also compare with the SVD of the adjacency matrix, which outputs the best (lowest Frobenius error) low-rank approximation that is possible without a nonlinear linking function. Since SVD lacks nonnegativity constraints on the factors, we do not expect intepretability. In Figure 2, we show how BigClam captures only the ten communities based on city, i.e., only the homophilous structure, and fails to capture the heterophilous distinction between men and women. We also plot the error of the reconstructions as the embedding length increases. There are \(10 2=20\) different kinds of nodes, meaning the expected adjacency matrix is rank-\(20\), and our model maintains the lowest error up to this embedding length; by contrast, BigClam is unable to decrease error after capturing city information with length-\(10\) embeddings. In Figure 3, we visualize the features generated by the three methods, i.e., the factors returned by each factorization. Our model's factors capture the relevant latent structure in an interpretable way. By contrast, SVD's factors are harder to interpret, and BigClam does not represent the heterophilous structure.

Figure 1: The motivating synthetic graph. The expected adjacency matrix (left) and the sampled matrix (right); the latter, which is passed to the training algorithms, is produced by treating the entries of the former as parameters of Bernoulli distributions and sampling. The network is approximately a union of ten bipartite graphs, each of which correspond to men and women in one of the ten cities.

Figure 3: Factors resulting from decomposition of the motivating synthetic graph of Figure 1 with the three models, using 12 communities or singular vectors. The top/bottom rows represent the positive/negative eigenvalues corresponding to homophilous/heterophilous communities (note that BigClam does not include the latter). The homophilous factors from BigClam and our model reflect the 10 cities, and the heterophilous factor from our model reflect men and women. The factors from SVD are harder to interpret. Note that the order of the communities in the factors is arbitrary.

Figure 2: Left: Reconstructions of the motivating synthetic graph of Figure 1 with SVD, BigClam, and our model, using 12 communities or singular vectors. Note the lack of the small diagonal structure in BigClam’s reconstruction; this corresponds to its inability to capture the heterophilous interaction between men and women. Right: Frobenius error when reconstructing the motivating synthetic graph of Figure 1 with SVD, BigClam, and our model, as the embedding length is varied. The error is normalized by the sum of the true adjacency matrix (i.e., twice the number of edges).

## 3 Community-Based Graph Factorization

Consider the set of undirected, unweighted graphs on \(n\) nodes, i.e., the set of graphs with symmetric adjacency matrices in \(\{0,1\}^{n n}\). We propose an edge-independent generative model for such graphs. Given nonnegative parameter matrices \(_{+}^{n k_{B}}\) and \(_{+}^{n k_{C}}\), we set the probability of an edge existing between nodes \(i\) and \(j\) to be the \((i,j)\)-th entry of matrix \(}\):

\[}:=(^{}-^{}),\] (1)

where \(\) is the logistic function. Here \(k_{B}\), \(k_{C}\) are the number of homophilous/heterophilous clusters. Intuitively, if \(_{i}_{+}^{k_{B}}\) is the \(i\)-th row of matrix \(\), then \(_{i}\) is the affinity of node \(i\) to each of the \(k_{B}\) homophilous communities. Similarly, \(_{i}_{+}^{k_{C}}\) is the affinity of node \(i\) to the \(k_{C}\) heterophilous communities. As an equivalent statement, for each pair of nodes \(i\) and \(j\), \(}_{i,j}:=(_{i}_{j}-_{i}_{j}^{})\). We will soon discuss the precise interpretation of this model, but the idea is roughly similar to the attract-repel framework of Peysakhovich & Bottou (2021). When nodes \(i\) and \(j\) have similar 'attractive' \(\) embeddings, i.e., when \(_{i}_{j}^{}\) is high, the likelihood of an edge between them increases, hence why the \(\) factor is homophilous. By contrast, the \(\) factor is'repulsive'/heterophilous since, when \(_{i}_{j}^{}\) is high, the likelihood of an edge between \(i\) and \(j\) decreases.

Alternate expressionWe note that the model above can also be expressed in a form that normalizes cluster assignments and is more compact, in that it combines the homophilous and heterophilous cluster assignments. Instead of \(\) and \(\), this form uses a matrix \(^{n k}\) and a diagonal matrix \(^{k k}\), where \(k=k_{B}+k_{C}\) is the total number of clusters. In particular, let \(_{B}\) and \(_{C}\) be the vectors containing the maximums of each column of \(\) and \(\). By setting

\[ =((_{B}^{-1});\; \;\;(_{C}^{-1}))\] (2) \[ =((+_{B}^{2};\;\;\;-_{C}^{2} )),\]

the constraint on \(\) is satisfied. Further, \(^{}=^{}-^{}\), so

\[}:=(^{}-^{})=( ^{}).\] (3)

Here, if \(_{i}^{k}\) is the \(i\)-th row of matrix \(\), then \(_{i}\) is the soft (normalized) assignment of node \(i\) to the \(k\) communities. The diagonal entries of \(\) represent the strength of the homophily (if positive) or heterophily (if negative) of the communities. For each entry, \(}_{i,j}=(_{i}_{j}^{})\). We use these two forms interchangeably throughout this work.

InterpretationThe edge probabilities output by this model have an intuitive interpretation. Recall that there are bijections between probability \(p\), odds \(o=[0,)\), and logit \(=(o)(-,+)\). The logit of the link probability between nodes \(i\) and \(j\) is \(_{i}^{}_{j}\), which is a summation of terms \(_{ic}_{jc}_{cc}\) over all communities \(c[k]\). If the nodes both fully participate in community \(c\), that is, \(_{ic}=_{jc}=1\), then the edge logit is changed by \(_{cc}\) starting from a baseline of \(0\), or equivalently, the odds of an edge is multiplied by \((_{cc})\) starting from a baseline odds of \(1\); if either of the nodes participates only partially in community \(c\), then the change in logit and odds is accordingly prorated. Homophily and heterophily also have a clear interpretation in this model: homophilous communities, which are expressed in \(\), are those with \(_{cc}>0\), where two nodes both participating in the community increases the odds of a link, whereas communities with \(_{cc}<0\), which are expressed in \(\), are heterophilous, and copparticipation decreases the odds of a link.

## 4 Related Work

Community detection via interpretable factorizationsThere is extensive prior work on community detection and node clustering (Schaeffer, 2007; Aggarwal & Wang, 2010; Nascimento & De Carvalho, 2011), perhaps the most well-known being the normalized cuts algorithm of Shi & Malik (2000), which produces a clustering based on the entrywise signs of an eigenvector of the graph Laplacian matrix. However, the clustering algorithms which are most relevant to our work are those based on non-negative matrix factorization (NMF) (Lee & Seung, 1999; Berry et al., 2007; Wang & Zhang, 2012; Gillis, 2020), many of which can be seen as integrating nonnegativity constraints intothe broader, well-studied _random dot product graph_ (RDPG) model (Young and Scheinerman, 2007; Scheinerman and Tucker, 2010; Athreya et al., 2017). One such algorithm is that of Yu et al. (2005), which approximately factors a graph's adjacency matrix \(\{0,1\}^{n n n}\) into two positive matrices \(\) and \(\), where \(_{+}^{n k}\) is left-stochastic and \(_{+}^{k k}\) is diagonal, such that \(^{}\). Here \(\) represents a soft clustering of the \(n\) nodes into \(k\) clusters, while the diagonal entries of \(\) represent the prevalence of edges within clusters. Note the similarity of the factorization to our model, save for the lack of a nonlinearity. Other NMF approaches include those of Ding et al. (2008); Yang et al. (2012); Kuang et al. (2012), and Kuang et al. (2015) (SymNMF).

Modeling heterophilyMuch of the existing work on graph models has an underlying assumption of network homophily (Johnson et al., 2010; Noldus and Van Mieghem, 2015). There has been significant recent interest in the limitations of graph neural network (GNN) models (Duvenaud et al., 2015; Kipf and Welling, 2017; Hamilton et al., 2017) at addressing network heterophily (NT & Maehara, 2019; Zhu et al., 2020; Zheng et al., 2022), as well as proposed solutions (Pei et al., 2020; Yan et al., 2021), but relatively less work for models applicable to clustering. Some existing NMF approaches to clustering do naturally model heterophilous structure in networks. The model of Nourbakhsh et al. (2014), for example, is similar to that of Yu et al. (2005), but allows the cluster affinity matrix \(\) to be non-diagonal; this allows for inter-cluster edge affinity to exceed intra-cluster edge affinity, so heterophily can arise in this model, though it is not a focus of their work. Another example is the model in Miller et al. (2009), which is similar to ours, though it restricts the cluster assignment matrix \(\) to be binary; additionally, their training algorithm is not based on gradient descent as ours is, and it does not scale to larger networks. More recently, Rubin-Delanchy et al. (2017) and Peysakhovich and Bottou (2021) propose simple decompositions which allow for representation of non-PSD adjacency matrices. The model in the latter work is a factorization of the form \(+^{}-^{}\), where \(^{n n}\) is diagonal and \(,^{n k}\) are low-rank; excluding the diagonal \(\) term, the model in the former work is algebraically identical. The authors discuss how, interestingly, this model separates the homophilous and heterophilous structure into different factors, namely \(\) and \(\), corresponding to positive and negative eigenvalues, respectively. Note that these decompositions do not include a nonlinear linking function, which is crucial to our exact factorization results, and the respective works do not investigate constraining the factors to be nonnegative.

Overlapping communities and exact embeddingsMany models discussed above focus on the single-label clustering task and thus involve highly-constrained factorizations (e.g., sum-to-one conditions). We are interested in the closely related but distinct task of multi-label clustering, also known as overlapping community detection (Xie et al., 2013; Javed et al., 2018), which involves less constrained, more expressive factorizations. The BigClam algorithm of Yang and Leskovec (2013) uses the following generative model for this task: the probability of a link between two nodes \(i\) and \(j\) is given by \(1-(-_{i}_{j})\), where \(_{i},_{j}_{+}^{k}\) represent the intensities with which the nodes participate in each of the \(k\) communities. Note that BigClam assumes strict homophily of the communities: two nodes participating in the same community always increases the probability of a link. However, this model allows for expression of very dense intersections of communities, which the authors observe is generally a characteristic of real-world networks. To ensure that output entries are probabilities, BigClam's factorization includes a nonlinear linking function (namely, \(f(x)=1-e^{x}\)), like our model and LPCA. Recent work outside clustering and community detection on graph generative models (Rendsburg et al., 2020; Chanpuriya et al., 2020) suggests that incorporating a nonlinear linking function can greatly increase the expressiveness of factorization-based graph models, to the point of being able to exactly represent a graph. This adds to a growing body of literature on expressiveness guarantees for embeddings on relational data (Sala et al., 2018; Bhattacharjee and Dasgupta, 2020; Boratko et al., 2021). Most relevant to our work, as previously discussed, Chanpuriya et al. (2020) provide a guarantee for exact low-rank representation of graphs with bounded max degree when using the LPCA factorization model. In this work, we provide a new such guarantee, except for bounded arboricity, which is more applicable to real-world networks, and extend these guarantees to our community-based factorization.

## 5 Theoretical Results

We first restate the main result from Chanpuriya et al. (2020) on exact representation of graphs with bounded max degree using the logistic principal components analysis (LPCA) model, which reconstructs a graph \(\{0,1\}^{n n}\) using logit factors \(,^{n k}\) via

\[(^{}).\] (4)

Note that unlike our community-based factorization, the factors of the LPCA model are not nonnegative, and the factorization does not reflect the symmetry of the undirected graph's adjacency matrix. Regardless of the model's interpretability, the following theorem provides a significant guarantee on its expressiveness. We use the following notation: given a matrix \(\), let \(H()\) denote the matrix resulting from entrywise application of the Heaviside step function to \(\), that is, setting all positive entries to \(1\), negative entries to \(0\), and zero entries to \(\).

**Theorem 5.1** (Exact LPCA Factorization for Bounded-Degree Graphs ).: _Let \(\{0,1\}^{n n}\) be the adjacency matrix of a graph \(G\) with maximum degree \(c\). Then there exist matrices \(,^{n(2c+1)}\) such that \(=H(^{})\)._

This corresponds to arbitrarily small approximation error in the LPCA model (Equation 4) because, provided such factors \(,\) for some graph \(\), we have that \(_{s}(s^{})=H(^{} )=\). That is, we can scale the factors larger to reduce the error to an arbitrary extent.

We expand on this result in two ways. First, give a new bound for exact embedding in terms of arboricity, rather than max degree. This increases the applicability to real-world networks, which often are sparse (i.e., low arboricity) and have right-skewed degree distributions (i.e., high max degree). Second, we show that any rank-\(k\) LPCA factorization can be converted to our model's symmetric nonnegative factorization with \(O(k)\) communities. This extends the guarantees on the LPCA model's power for exact representation of graphs, both the prior guarantee in terms of max degree and our new one in terms of arboricity, to our community-based model as well. In Appendix A.1, we also introduce a natural family of graphs - Community Overlap Threshold (COT) graphs - for which our model's community-based factorization not only exactly represents the graph, but also must capture some latent structure to do so with sufficiently low embedding dimensionality.

Arboricity bound for exact representationWe will use the following well-known fact: the rank of the entrywise product of two matrices is at most the product of their individual ranks, that is,

\[()()().\]

**Theorem 5.2** (Exact LPCA Factorization for Bounded-Arboricity Graphs).: _Let \(\{0,1\}^{n n}\) be the adjacency matrix of an undirected graph \(G\) with arboricity \(\). Then there exist embeddings \(,^{n(4^{2}+1)}\) such that \(=H(^{})\)._

Proof.: Let the undirected graph \(\) have arboricity \(\), i.e., the edges can be partitioned into \(\) forests. We produce a directed graph \(\) from \(\) by orienting the edges in these forests so that each node's edges point towards its children. Now \(=+^{}\), and every node in \(\) has in-degree at most \(\).

Let \(^{n 2}\) be the Vandermonde matrix with \(_{t,j}=t^{j-1}\). For any \(^{2}\), \([](t)=_{j=1}^{2}(j) t^{j-1}\), that is, \(^{n}\) is a degree-\((2)\) polynomial with coefficients \(\) evaluated at the integers \(t[n]=\{1,,n\}\). Let \(_{i}\) be the \(i^{}\) column of \(\). We seek to construct a polynomial such that for \(t\) with \(_{i}(t)=1\), \([_{i}](t)=0\), and \([_{i}](t)<0\) elsewhere; that is, when inputting an index \(t[n]\) such that the \(t^{}\) node is an in-neighbor of the \(i^{}\) node, we want the polynomial to output \(0\), and for all other indices in \([n]\), we want it to have a negative output. Letting \(N(i)\) denote the in-neighbors of the \(i^{}\) node, a simple instantiation of such a polynomial in \(t\) is \(-1_{j N(i)}(t-j)^{2}\). Note that since all nodes have in-degree at most \(\), this polynomial's degree is at most \(2\), and hence there exists a coefficient vector \(_{i}^{2}\) encoding this polynomial.

Let \(^{n 2}\) be the matrix resulting from stacking such coefficient vectors for each of the \(n\) nodes. Consider \(=^{n n}\): \(_{i,j}\) is \(0\) if \(_{i,j}=1\) and negative otherwise. Then \((^{})_{i,j}\) is \(0\) when either \(_{i,j}=1\) or \((^{})_{i,j}=1\) and positive otherwise; equivalently, since \(=+^{}\), \((^{})_{i,j}=0\) iff \(_{i,j}=1\). Take any positive \(\) less than the smallest positive entry of \(^{}\). Letting \(\) be an all-ones matrix, define \(=-(^{})\). Note that \(_{i,j}>0\) if \(=1\) and \(_{i,j}<0\) if \(=0\), that is, \(=H()\) as desired. Since \(()=1\) and \(() 2\), by the bound on the rank of entrywise products of matrices, the rank of \(\) is at most \((2)^{2}+1\).

Exact representation with community factorizationLPCA factors \(,^{n k}\) can be processed into nonnegative factors \(_{+}^{n k_{B}}\) and \(_{+}^{n k_{C}}\) such that \(k_{B}+k_{C}=6k\) and

\[^{}-^{}=(^{}+ ^{}).\] (5)

As a rough outline of the argument that follows, we will need \(6k\) columns in the new factors \(,\), up from the \(k\) columns in \(,\), because accounting for the possible asymmetry in \(^{}\) will double the required columns, and accounting for the nonnegativity of \(,\) will triple the required columns. Observe that the left-hand side can only represent symmetric matrices, but \(^{}\) is not necessarily symmetric even if \(H(^{})=\) for a symmetric \(\). For this reason, we use a symmetrization: let \(=(^{}+^{})\). Note that \(H()=H(^{})\), so if \(^{}\) constitutes an exact representation of \(\) in that \(H(^{})=\), so too both expressions for \(\) in Equation 5. Pseudocode for the procedure of constructing \(,\) given \(,\) is given in Algorithm 1. The concept of this algorithm is to first separate the logit matrix \(\) into a sum and difference of rank-\(1\) components via eigendecomposition. Each of these components can be written as \(+^{}\) or \(-^{}\) with \(^{n}\), where the sign depends on the sign of the eigenvalue. Each component is then separated into a sum and difference of three outer products of nonnegative vectors, via the following Lemma 5.3.

**Lemma 5.3**.: _Let \(:\) denote the ReLU function, i.e., \((z)=\{z,0\}\). For any vector \(\),_

\[^{}=2()()^{}+2(- )(-)^{}-||||^{}.\]

Proof.: Take any \(^{k}\). Then

\[^{} =(()-(-))(()^{ }-(-)^{})\] \[=+()()^{}+(-)(- )^{}-()(-)^{}-(-) ()^{}\] \[=+2()()^{}+2(-) (-)^{}-(()+(-))(()+(-))^{}\] \[=+2()()^{}+2(-) (-)^{}-||||^{},\]

where the first step follows from \(=()-(-)\), and the last step from \(||=()+(-)\). 

Algorithm 1 follows from Lemma 5.3 and constitutes a constructive proof of the following theorem:

**Theorem 5.4** (Exact Community Factorization from Exact LPCA Factorization).: _Given a symmetric matrix \(\{0,1\}\) and \(,^{n k}\) such that \(=H(^{})\), there exist nonnegative matrices \(_{+}^{n k_{B}}\) and \(_{+}^{n k_{C}}\) such that \(k_{B}+k_{C}=6k\) and \(=H(^{}-^{})\)._

**Input** logit factors \(,^{n k}\)

**Output**\(_{+}^{n k_{B}}\), \(_{+}^{n k_{C}}\) such that \(k_{B}+k_{C}=6k\)

and \(^{}-^{}=(^{}+ ^{})\)

```
1: Set \(^{n 2k}\) and \(^{2k}\) by truncated eigendecomposition such that \(()^{}=( ^{}+^{})\)
2:\(^{*}^{+}(^{ }})\), where \(^{}\), \(^{+}\) are the positive eigenvalues/vectors
3:\(^{*}^{-}(^{ -}})\), where \(^{-}\), \(^{-}\) are the negative eigenvalues/vectors
4:\(((^{*});(-^{*}); |^{*}|)\ \ \) and \(||\) are entrywise ReLU and absolute value
5:\(((^{*});(-^{*}); |^{*}|)\)
6:return\(,\) ```

**Algorithm 1** Converting LPCA Factors to Community Factors

As stated in the introduction to this section, Theorem 5.4 extends any upper bound on the exact factorization dimensionality from the LPCA model to our community-based model. That is, up to a constant factor, the bound in terms of max degree from Theorem 5.1 and the bound in terms of arboricity from Theorem 5.2 also apply to our model; for brevity, we state just the latter here.

**Corollary 5.5** (Exact Community Factorization for Bounded-Arboricity Graphs).: _Let \(\{0,1\}^{n n}\) be the adjacency matrix of an undirected graph \(G\) with arboricity \(\). Then there exist non-negative embeddings \(_{+}^{n k_{B}}\) and \(_{+}^{n k_{C}}\) such that \(k_{B}+k_{C}=6(4^{2}+1)\) and \(=H(^{}-^{})\)._Note that Corollary 5.5 is purely a statement about the capacity of our model; Theorem 5.2 stems from a constructive proof based on polynomial interpolation, and therefore so too does this corollary. We do not expect this factorization to be informative about the graph's latent structure. In the following Section 6, we will fit the model with an entirely different algorithm for downstream applications.

## 6 Experiments

We now present a training algorithm to fit our model, then evaluate our method on a benchmark of five real-world networks.

### Training Algorithm

Given an input graph \(\{0,1\}^{n n}\), we find low-rank nonnegative matrices \(\) and \(\) such that the model produces \(}=(^{}-^{})(0,1)^{n  n}\) as in Equation 1 which approximately matches \(\). In particular, we train the model to minimize the sum of binary cross-entropies of the link predictions over all pairs of nodes:

\[R=-_{ij}(_{ij}(}_{ij})+(1-_{ij}) (1-}_{ij})).\] (6)

We fit the parameters by gradient descent over this loss, as well as \(L_{2}\) regularization of the factors \(\) and \(\), subject to the nonnegativity of \(\) and \(\). This algorithm is fairly straightforward; pseudocode is given in Algorithm 2. This is quite similar to the training algorithm of Chanpuriya et al. (2020), but in contrast to that work, which only targets an exact fit, we explore the expression of graph structure in the factors and their utility in downstream tasks. Regularization of the factors is implemented to this end to avoid overfitting. Though in the main paper we outline and evaluate a non-stochastic version of the training algorithm, it can generalize straightforwardly to a more scalable stochastic version, e.g., by sampling links and non-links for the loss function and using projected SGD. In Appendix A.2, we discuss an industry application of our model to tabular dataset completion, for which we employ such stochastic training. Here, we use the simpler non-stochastic training to isolate the impact of model capacity, which is the focus of this work, as opposed to optimization.

```
0: adjacency matrix \(\{0,1\}^{n n}\), regularization weight \( 0\), # of iterations \(I\), # of homo/heterophilous communities \(k_{B}/k_{C}\)
0: fitted factors \(_{+}^{n k_{B}}\), \(_{+}^{n k_{C}}\) such that \((^{}-^{})\)
1: Initialize \(\), \(\) by setting entries to independent samples of \((0,}{{}}}),(0,}{{}}})\)
2:for\(i 1\) to \(I\)do
3:\(}(^{}-^{})\)
4:\(R-_{ij}(_{ij}(}_{ij})+(1-_{ij} )(1-}_{ij}))\)
5:\(R R+(\|\|_{F}^{2}+\|\|_{F}^{2})\)
6: Calculate \(_{,}R\), the gradient of \(R\) w.r.t. \(,\), via differentiation through Steps 2 to 4
7: Update \(,\) to minimize \(R\) using \(_{,}R\), subject to \(, 0\)
8:endfor
9:return\(,\) ```

**Algorithm 2** Fitting the Constrained Model

Implementation detailsOur implementation uses PyTorch (Paszke et al., 2019) for automatic differentiation and minimizes loss using the SciPy (Jones et al., 2001) implementation of the L-BFGS (Liu and Nocedal, 1989; Zhu et al., 1997) algorithm with default hyperparameters and up to a max of 200 iterations of optimization. We set regularization weight \(=10\) as in Yang and Leskovec (2013). We include code in the form of a Jupyter notebook (Perez and Granger, 2007) demo.

### Datasets

We use five fairly common mid-size datasets ranging from around 1K to 10K nodes. The selection of these five datasets is partly based on the presence of ground-truth multi-labels, which allows for evaluating the overlapping clustering methods. Statistics for these datasets, including the degeneracy of each network, are given in Table 1. Note that degeneracy is an upper bound on arboricity. We note that the mid-sized networks used in our empirical work actually underemphasize the significance of our theoretical arboricity bound: see, e.g., the real-world networks in Pashanasangi & Seshadhri (2021), which have up to tens of millions of nodes but still have degeneracies at most in the hundreds.

**Blog** is a social network of relationships between online bloggers; the node labels represent interests of the bloggers. Similarly, **YouTube** is a social network of YouTube users, and the labels represent groups that the users joined.

**POS** is a word co-occurrence network: nodes represent words, and there are edges between words which are frequently adjacent in a section of the Wikipedia corpus. Each node label represents the part-of-speech of the word. **PPI** is a subgraph of the protein-protein interaction network for Homo Sapiens. Labels represent biological states. Finally, **Amazon** is a co-purchasing network: nodes represent products, and there are edges between products which are frequently purchased together. Labels represent categories of products.

While social networks like the former two in this list are generally dominated by homophily (McPherson et al., 2001), the latter three should exhibit significant heterophily. For co-purchasing networks like Amazon, depending on the product, two of the same kind of product are generally not co-purchased, e.g., Pepsi and Coke, as discussed in Pepsakhovich & Bottou (2021). Though less intuitively accessible, there is also prior discussion of disassortativity in word adjacencies (Foster et al., 2010; Zweig, 2016), as well as in PPI networks (Newman, 2002; Hase et al., 2010).

### Results

ExpressivenessFirst, we investigate the expressiveness of our generative model, that is, the fidelity with which it can reproduce an input network. In Section 1, we used a simple synthetic network to show that our model is more expressive than others due to its ability to represent heterophilous structures in addition to homophilous ones. We now evaluate the expressiveness of our model on real-world networks. As with the synthetic graph, we fix the number of communities or singular vectors, fit the model, then evaluate the reconstruction error. In Figure 4, we compare the results of our model with those of SVD, BigClam (which is discussed in detail in Section 4), and SymNMF (Kuang et al., 2015). SymNMF simply factors the adjacency matrix as \(^{}\), where \(_{+}^{n k}\); note that, like SVD, SymNMF does not necessarily output a matrix whose entries are probabilities (i.e., bounded in \(\)), and hence it is not a natural graph generative model like ours and BigClam.

  
**Name** & **Reference** & **Nodes** & **Edges** & **Labels** & **Max Degree** & **Degeneracy** \\  Blog & Tang \& Liu (2009) & 10,312 & 333,983 & 39 & 3,992 & 114 \\ YouTube & Yang \& Leskovec (2015) & 5,346 & 24,121 & 5 & 628 & 19 \\ POS & Qiu et al. (2018) & 4,777 & 92,406 & 40 & 3,644 & 49 \\ PPI & Breitkreutz et al. (2007) & 3,852 & 76,546 & 50 & 593 & 29 \\ Amazon & Yang \& Leskovec (2015) & 794 & 2,109 & 5 & 29 & 6 \\   

Table 1: Statistics of datasets used in our experiments. As in Sun et al. (2019), for YouTube and Amazon, we take only nodes that participate in at least one of the largest \(5\) ground-truth communities.

Figure 4: Reconstruction error on real-world networks, relative to our model’s error.

For each method, we fix the number of communities or singular vectors at the ground-truth number. For this experiment only, we are not concerned with learning the latent structure of the graph; the only goal is accurate representation of the network with limited parameters. So, for a fair comparison with SVD, we do not regularize the training of the other methods. Our method consistently has the lowest reconstruction error, both in terms of Frobenius error and entrywise cross-entropy (Equation 6). We particularly highlight the improvement over BigCLam; the salient difference between these models, both of which are factorization-based, include a nonlinear link function, and assign node communities using nonnegative factors, is the presence of the heterophilous \(-^{}\) term in our model. Thus, the improvement directly reflects the value of incorporating heterophily into the model. Interestingly, we find the most significant improvement exactly on the three datasets which have been noted to exhibit significant heterophily: POS, PPI, and Amazon.

Similarity to ground-truth communitiesTo assess the interpretability of clusters generated by our method, we evaluate the similarity of these clusters to ground-truth communities (i.e., class labels), and we compare other methods for overlapping clustering. We additionally compare to another recent but non-generative approach, the vGraph method of Sun et al. (2019), which is based on link clustering; the authors found their method to generally achieve state-of-the-art results in this task. For all methods, we set the number of communities to be detected as the number of ground-truth communities. We report F1-Score as computed in Yang and Leskovec (2013). See Figure 5 (left): the performance of our method is competitive with SymNMF, BigCLam, and vGraph.

Interpretable link predictionWe assess the predictive power of our generative model on the link prediction task. As discussed in Section 3, the link probabilities output by our model are interpretable in terms of a clustering of nodes that it generates; we compare results with our method to those with other models which permit similar interpretation, namely BigCLAM and SymNMF. We randomly select 10% of node pairs to hold out, fit the models on the remaining 90%, then use the trained models to predict links between node pairs in the held out 10%. As a baseline, we also show results for randomly predicting link or no link with equal probability. See Figure 5 (right). The performance of our method is competitive with or exceeds those of the other methods in terms of F1 Score.

## 7 Conclusion

We introduce a community-based graph generative model based on symmetric nonnegative matrix factorization which can represent both homophily and heterophily. We add to a prior guarantee of exact representation for bounded degree graphs with a broader guarantee for bounded _arboricity_ graphs, and we show that both of these guarantees apply to our more interpretable graph model. We illustrate our model's capabilities with experiments on a synthetic motivating example. Experiments on real-world networks show its effectiveness on several key tasks. Broadly, our results suggest that incorporating heterophily into methods for networks can improve both theoretical grounding and empirical performance, while maintaining interpretability. Future directions include deeper understanding of the expressiveness of low-rank logit models and convergence of training algorithms.

Figure 5: Left: Similarity of recovered communities to ground-truth labels of real-world datasets. (Note: vGraph is omitted on Blog due to memory limitations.) Right: Accuracy of link prediction.