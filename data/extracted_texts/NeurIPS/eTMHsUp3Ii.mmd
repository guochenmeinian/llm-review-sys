# Double Randomized Underdamped Langevin with Dimension-Independent Convergence Guarantee

Yuanshi Liu\({}^{*}\), Cong Fang\({}^{*}\), Tong Zhang\({}^{}\)

\({}^{*}\) School of Intelligence Science and Technology, Peking University

\({}^{}\) Department of Computer Science \(\&\) Engineering, the Hong Kong University of Science and Technology

{liu_yuanshi, fangcong}@pku.edu.cn, tongzhang@tongzhang-ml.org

###### Abstract

This paper focuses on the high-dimensional sampling of log-concave distributions with composite structures: \(p^{*}()(-g()-f()) \). We develop a double randomization technique, which leads to a fast underdamped Langevin algorithm with a dimension-independent convergence guarantee. We prove that the algorithm enjoys an overall \(}((H))^{1/3}}{^{2/3}})\) iteration complexity to reach an \(\)-tolerated sample whose distribution \(p\) admits \(W_{2}(p,p^{*})\). Here, \(H\) is an upper bound of the Hessian matrices for \(f\) and does not explicitly depend on dimension \(d\). For the posterior sampling over linear models with normalized data, we show a clear superiority of convergence rate which is dimension-free and outperforms the previous best-known results by a \(d^{1/3}\) factor. The analysis to achieve a faster convergence rate brings new insights into high-dimensional sampling.

## 1 Introduction

Sampling from a high-dimensional distribution serves as one of the key components in statistics, machine learning, and scientific computing, and constitutes the foundation of the fields including Bayesian statistics and generative models (Liu and Liu, 2001; Brooks et al., 2011; Song et al., 2020). Recently, there is an emerging trend in designing provably faster Markov Chain Monte Carlo (MCMC) algorithms using techniques from first-order optimization (Dalalyan, 2017; Durmus et al., 2019; Cheng and Bartlett, 2018; Vempala and Wibisono, 2019; Chewi et al., 2021). One typical MCMC algorithm that allows following the idea is the Langevin-type algorithms, which are of the central interest of this paper.

Langevin-type algorithms originated in statistical physics discretize a stochastic differential equation with stationary distribution corresponding to the target. For Gibbs distribution \(p() e^{-U()}\), the standard overdamped Langevin algorithm uses Euler Maruyama scheme to discretize the diffusion process \(_{t}=- U(_{t})t+_{t}\). The algorithm iteratively performs the updates as for \(n=0,1,2,,\)

\[_{n+1}=_{n}-h U(_{n})+ _{n}, \]

where \(_{n}(0,I)\) follows the normal distribution and \(h>0\) is the step size.

This paper focuses on the dimension dependence of the convergence behavior of Langevin-type algorithms. Specifically, we consider sampling problems over potentially high-dimensional and strongly log-concave distributions with a composite structure: \(p e^{-U()}=e^{-g()-f()}\) where \(g()=\|\|^{2}\). Regarding \(p\) as a posterior distribution, \(e^{-g()}\) corresponds to a Gaussian prior and \(e^{-f()}\) corresponds to the likelihood. This structure also includes general \(m\)-strongly convexpotential functions \(U()\), which can be split into a strongly convex term \(g()=\|\|^{2}\) and a weakly convex one \(f()=U()-\|\|^{2}\).

The analysis of Langevin sampling from an optimization viewpoint may date back to Jordan et al. (1998). The viewpoint has led to a surge of works that establish quantitative convergence guarantees for overdamped Langevin algorithms to sample log-concave distributions (Dalalyan, 2017; Durmus and Moulines, 2016). It should be noted that these convergence guarantees always involve an extra \(d\) dimension dependence due to the injection of non-negligible Gaussian noise, whereas the convergence rates of first-order optimization are often dimension-free (Nesterov, 2003). Various accelerated methods have been proposed that can mitigate the dimension dependence and also achieve faster convergence. First, as the momentum acceleration of Langevin algorithms (Ma et al., 2021), underdamped Langevin Monte Carlo has a more stable trajectory and is known to exhibit a faster convergence rate (Cheng et al., 2018; Ma et al., 2021; Zhang et al., 2023). Apart from using a different trajectory, more stable discretization schemes of the same diffusion process also lead to better convergence (Shen and Lee, 2019; Wibisono, 2019; He et al., 2020; Li et al., 2019). However, the dimension dependence remains. To the best of our knowledge, the fastest randomized midpoint method for underdamped Langevin under Wasserstein distance achieves a \((}{^{2/3}})\) convergence rate and still has a \(d^{1/3}\) dimension dependence (Shen and Lee, 2019).

Recently another thread of works studies the convergence with weaker dimension dependence. Some researchers explore further general assumptions on the target distribution. The idea is by observing that some smoothness conditions can average out the dimension-dependent errors brought by the noise using Ito's formula. For example, Li et al. (2021) achieves a \(\) dimension dependence with a 3-rd order growth condition. Another approach investigates the curvature of the target distribution and illustrates that dimension often does not determine the complexity of the sampling problem. Vono et al. (2022) propose an ADMM-type splitting algorithm with a dimension-free convergence rate when the likelihood is separable. Along the same thread, Freund et al. (2022) study the convergence rate of Langevin algorithms with no explicit dependence on dimension and propose to characterize the convergence rate by the upper bound of Hessian matrices of \(f\). Specifically, by letting \(H\) be the upper bound of the Hessian matrices of \(f\), they show a variant of the overdamped Langevin algorithm achieves a convergence rate of \(((H)}{})\) in KL divergence. This result improves the rate under wide conditions because many high-dimensional sampling problems are intrinsically low-dimensional in the sense that \((H)=o(d)\), which frequently appears in machine learning. For example, when the potential function has a ridge separable structure with mild conditions, \((H)\) can be dimension-free (see Section 3.3 for more details).

Though these works succeed in obtaining a convergence rate of the Langevin algorithm with a weak dependence on the dimension, some important questions remain:

_" How to design provably faster algorithms with weak dependencies on dimension even for the log-concave sampling?"_

Such a question is significant for understanding high-dimensional sampling and already includes lots of applications in real practice.

In this paper, we follow the regime of Freund et al. (2022) to design provably faster Langevin algorithms, which answers the above question affirmatively. We propose a double-randomized algorithm showing that variants of underdamped algorithms inherit the lower dimensional dependence in overdamped Langevin and a special design of random stepsize can still keep the property when using more stable discretization.

Specifically, we develop a double randomization technique and obtain the Double-Randomized Underdamped Langevin (DRUL) algorithm. We consider an averaged contraction effect to avoid dimension dependence. We design two distributions to achieve the mid-point acceleration with a randomized stepsize. DRUL is proven to enjoy an overall \(}((H))^{1/3}}{^{2/ 3}})\) iteration and gradient complexity. For the posterior sampling over linear models, we show a clear superiority of DRUL, which achieves a dimension-free \(}(})\) convergence rate. The novel perspective of DRUL is introducing the random step size at each update. Such a random step size combined with a random midpoint point proposed by Shen and Lee (2019) reduces the discretization error and provides new insights into designing provably faster sampling algorithms.

In summary, the contributions of the paper are listed below:

* We propose the Double-Randomized technique and design the DRUL algorithm.
* We show the DRUL converges to the target distribution in Wasserstein distance in \(}((H)+\|_{}\|^{ 2})^{1/3}}{^{2/3}})\) iterations. For posterior sampling over generalized linear models, a dimension-free \(}(})\) complexity can be achieved.

## 2 Related works

There has been a surge of works investigating the asymptotic guarantees for the Langevin-type algorithms (Roberts and Tweedie, 1996; Mattingly et al., 2002). And a series of recent works establish the non-asymptotic quantitative analysis framework of the Langevin-type algorithms. For performance on strongly log-concave distributions, early works (Dalalyan, 2017; Durmus and Moulines, 2016) establish the non-asymptotic convergence rate in TV distance with Lipschitz gradients assumption for overdamped dynamics. Along the same setting, similar convergence rates are achieved in KL divergence using the Wasserstein gradient flow (Cheng and Bartlett, 2018; Durmus et al., 2019) or Wasserstein distance using the contractive property for overdamped Langevin. Underdamped Langevin accelerates the vanilla Langevin algorithms (Ma et al., 2021). With the same setting mentioned above, a faster convergence rate can be established (Cheng et al., 2018; Dalalyan and Riou-Durand, 2020; Shen and Lee, 2019; Zhang et al., 2023) for underdamped Langevin algorithms. Beyond the log Lipschitz-smooth setting, other examples also show better results can be achieved, such as Durmus and Moulines (2019); Li et al. (2019) for overdamped Langevin algorithms. Previous works also investigate the convergence rate without strongly log-convex assumptions, such as the log-Sobolev inequality (LSI) condition which is similar to the Polyak-Lojasiewicz condition in optimization. With target distributions satisfying LSI and log-Lipschitz-smooth, the results can be extended for both overdamped Langevin (Vempala and Wibisono, 2019) and underdamped Langevin (Ma et al., 2021; Zhang et al., 2023).

Another thread of works explores the dimension dependence of Langevin-type algorithms. Despite the great similarity between the analysis in Langevin algorithms and optimization, the convergence of Langevin-type algorithms depends on dimension in the log-concave setting whereas convex optimization algorithms can often achieve dimension-independent results. With general strongly log

  
**Method** & **Convergence Rate** & **Ridge-Separable Case** \\  Overdamped as Composite OptimizCRation & & \\ (Durmus et al., 2019) & \((})\) & \((})\) \\ (Proved in KL divergence) & & \\  Overdamped with EU & & \\ (Li et al., 2021) & \(}(}{})\) & \(}(}{})\) \\ (With an additional linear growth condition) & & \\  Underdamped with RMM & & \\ (Shen and Lee, 2019) & \(}(}{^{2/3}})\) & \(}(}{^{2/3}})\) \\  Overdamped as Composite Optimization & & \\ (Freund et al., 2022) & & \\ (Proved in KL divergence) & & \\ 
**DRUL (Ours)** & \(}((H)+\|_{}\|^{ 2})^{1/3}}{^{2/3}})\) & \(}(})\) \\   

Table 1: Comparison of the convergence rates for most related works. We consider the convergence in Wasserstein distance to a strongly log-concave and log-Lipschitz smooth target distribution (we summarize below the methods if additional assumptions are required). EU stands for Euler-Maruyama discretization and RMM stands for Randomized Midpoint discretization. ‘Ridge-Separable Case’ refers to the convergence rate when \(f\) admits a ridge-separable structure (see (3.2)). Note that some results are established in the KL divergence. We convert these convergence rates into the ones in Wasserstein distance using Talagrand’s inequality.

concave (or LSI) and log-Lipschitz-smooth condition, previous works establish a \((})\) convergence rate for overdamped algorithms (Durmus et al., 2019) and a \(}(}{})\) convergence rate for underdamped algorithms (Cheng et al., 2018) to ensure finding a solution \(x_{n}\) with \(W_{2}((_{n}),p)\) or \((_{n}),p)}\). With an additional linear growth condition on third-order derivative, Li et al. (2021) achieve a \(}(}{})\) convergence rate for overdamped Langevin. And for underdamped Langevin algorithms, Shen and Lee (2019) improve the dependence of dimension and obtains a \(}(}{^{2/3}})\) convergence rate. Recent work of Freund et al. (2022) characterizes the dimensional dependence of convergence rate by the upper bound of the Hessian matrix of \(f\). As discussed in Section 1, Freund et al. (2022) establish a \(((H)+\|_{n}\|^{2}}{})\) convergence rate in KL divergence, which implies a \(((H)+\|_{n}\|^{2}}{^{2}})\) convergence rate in Wasserstein distance. And when \(f\) admits a ridge-separable formula, Freund et al. (2022) obtain a dimension-free \((})\) convergence rate with some mild assumptions. We summarize the comparison of these most related works in Table 2.

## 3 Preliminary and problem setup

### Notations

We use the convention \(()\) and \(()\) to denote lower and upper bounds with a universal constant. \(}()\) ignores the polylogarithmic dependence. And use \(f g\) to denote \(f=(g)\). Use \(W_{2}(,)\) to denote the \(2\)-Wasserstein distance of distribution \(\) and \(\). Use \((X)\) to denote the distribution of the random variable \(X\). The Frobenius norm is denoted by \(\|\|_{F}\) while \(\|\|_{2}\) stands for operator \(2\)-norm for matrices.

### Sampling problem

We consider the distributions with a composite structure:

\[p()\{-U()\} =\{-g()-f()\}, \]

where \(g()=\|\|^{2}\) is a quadratic function. In the context of posterior sampling, the associated task is sampling from a distribution with a Gaussian prior. The composite structure also includes the general \(m\)-strongly convex function, which can be divided into \(g()=\|\|^{2}\) and the weakly convex function \(f()=U()-\|\|^{2}\). We make the following assumption on \(f\).

**Assumption 3.1**.: \(f^{2}\) is convex and has \(L\)-Lipschitz continuous gradients, i.e. \(^{2}f LI\).

It corresponds to making \(m\)-strongly convex and \(L+m\)-Lipschitz smooth assumptions on the potential function \(U\), which is a basic setting and widely studied in the Langevin sampling literature (see e.g. Dalalyan (2017), Cheng and Bartlett (2018), Cheng et al. (2018), Shen and Lee (2019)).

In addition to the previous assumption, we follow Freund et al. (2022) to characterize the convergence rate by a new factor \(H\) to avoid explicit dimension dependence.

**Definition 3.2**.: Let \(H\) be an upper bound of the Hessian matrices of \(f\), i.e. \(H^{2}f()\).

Note that the Lipschitz smooth condition in Assumption 3.1 provides a loose bound for \(H\) since we always have \(H LI\). This implies that \((H)\) will reach \(dL\) in the worst case, whereas this quantity can be much smaller than \(dL\) under wide conditions. One typical example is when \(f\) admits a so-called ridge separable structure shown below.

### Example: ridge separable functions

**Definition 3.3**.: \(f\) is said to admit the ridge separable form if

\[f()=_{i=1}^{n}_{i}(_{i}^{T}), \]

where \(_{i}\) are all univariate functions, and \(_{i}\) are given vectors in \(^{d}\).

Ridge separable functions contain many applications in machine learning, such as regression or classification over generalized linear models as well as (deep) neural networks in the neural tangent kernel regime (Gelman and Hill, 2006; Jacot et al., 2018). We follow the argument of Freund et al. (2022), showing realizable conditions that ensure \((H)\) to be dimension-free.

**Assumption 3.4**.: The function \(_{i}^{2}\) has a bounded second derivative, i.e. \(_{i}^{} L_{0}\) for all \(i[n]\).

**Assumption 3.5**.: For all \(i[n]\), then norm of \(_{i}\) is bounded by \(R\), i.e. \(\|_{i}\|^{2} R^{2}\).

When Assumptions 3.4 and 3.5 hold, the Hessian has the upper bound \(^{2}f()=_{i=1}^{n}^{}(_{i}^{T})_{i}_{i}^{T}}{n} _{i=1}^{n}_{i}_{i}^{T}\). Let \(H=}{n}_{i=1}^{n}_{i}_{i}^{T}\) and

\[(H)=(_{i=1}^{n}}{n}_{i} _{i}^{T})=}{n}_{i=1}^{n}\|_{i}\|^{2}  L_{0}R^{2},\]

thus illustrates that \((H)\) has a dimension-free \(L_{0}R^{2}\) upper bound. Meanwhile the Lipschitz constant of \( f\) can be bounded by

\[( f)\|H\|_{2}=\|}{n}_{i=1}^{n} _{i}_{i}^{T}\| L_{0}R^{2}.\]

It indicates that worst-case upper bounds of \((H)\) and \(( f)\) are the same.

Note that Assumptions 3.4 and 3.5 are easy to achieve in practice. For example, consider using posterior sampling to compute the Bayes estimator over a linear model, whose advantages against maximum a posterior estimator have been discussed broadly (see e.g. Audibert (2009)). Here, \(_{i}\) is associated with the data. So Assumption 3.5 can be realized by simply normalizing the data. Moreover, \(_{i}\) corresponds to the loss function and is only required to have a bounded second derivative by Assumption 3.4. Note that sampling from a ridge separable potential functions are extensively studied in related literature (see (Mou et al., 2021; Vono et al., 2022; Lee et al., 2018) as examples).

### Preliminary

**Overdamped Langevin.** The overdamped Langevin dynamics for target distribution (3.1) is a diffusion process that evolves along the following SDE

\[(t)=- g((t))t- f((t))t+_{t} \]

where \(_{t}\) is the standard Brownian motion. The overdamped Langevin algorithms simulate and discretize the SDE (3.3). Different algorithms vary mainly by different discretization methods.

**Underdamped Langevin** Underdamped Langevin algorithms accelerate the convergence rate of overdamped Langevin algorithms and instead discretize the following dynamics

\[(t) =(t)t, \] \[(t) =-u g((t))t-u f((t)) t-2(t)t+2_{t}.\]

The diffusion process has the stationary distribution \(p_{(,)}\{-\|\|^{2}- U()\}\).

**Contractive Property** One notable property that yields the convergence of Langevin dynamics is the contractive property (Cheng and Bartlett, 2018; Cheng et al., 2018), given as follows.

**Definition 3.6**.: A stochastic differential equation has contractive property if there exists a positive constant \(m\) and

\[\|(t)-(t)\|^{2}\|(0)- (0)\|^{2}(-mt), \]

for any pair of solutions \((t)\) and \((t)\) driven by the same Brownian motion.

**Remark 3.7**.: \(\|(t)-(t)\|^{2}\) is an upper bound of squared Wasserstein distance of \(((t))\) and \(((t))\), and thus (3.5) implies a geometric convergence of the Wasserstein distance.

Contractive property can be established for both underdamped and overdamped Langevin dynamics under suitable conditions. The convergence analysis for our proposed algorithms follows a similar argument as the contractive property.

```
Iteration \(N\), target function \(U=\|\|^{2}+f()\), initial point \((_{0},_{0})\), max step size \(h\), \(u=\) and \(=\). \((t)(-) t\) with support \([0,h]\). \(^{}(t)(e^{}- )t\) with support \([0,h]\). for\(n=1,2,,N\)do  Sample \(_{n}^{}\) and \(_{n}\).  Obtain the covariance matrix \((_{n},_{n})\).  Sample random vector \((G,H,W)\) from distribution \((0,)\). \(}_{n} A_{11}(_{n})_{n}+A_{12}( _{n})_{n}+u_{0}^{_{n}}A_{12}(s-_{n}) f( _{n})s+2H\).  Update \(_{n+1} A_{11}(_{n})_{n}+A_{12}(_{n}) _{n}+u_{0}^{_{n}}A_{12}(s-_{n}) f(}_{n})s+2G\).  Update \(_{n+1} A_{21}(_{n})_{n}+A_{22}(_{n}) _{n}+u_{0}^{_{n}}A_{22}(s-_{n}) f(}_{n})s+2W\). endfor
```

**Algorithm 1** Double-Randomized Underdamped Langevin (DRUL)

## 4 Double-randomized underdamped Langevin algorithm

In this section, we introduce our double-randomized sampling method and present our main result. We will illustrate our intuition in Section 5.

The proposed algorithm is built upon the following discretization scheme given a fixed point \(_{n}\)

\[_{n}(t) =_{n}(t)t, \] \[_{n}(t) =-u g(_{n}(t))t-u f(}_{n})t-2_{n}(t)t+2 _{t}.\]

The purpose of splitting the strongly convex part of \(U(x)\) is to avoid the \(md\) dimension dependence of \((H)\). Although \(m\) is reasonably small in practice, one cannot obtain a fully dimensional-free convergence rate if the term with respect to \(g\) is discretized.

Denote the solution of process (4.1) at time \(t\) given starting point \((_{n},_{n})\), Brownian motion \(\{_{t}\}_{0 t}\), step size \(\) and point \(_{n}\) by \((,}_{n};\{_{t}\}_{0 t },(_{n},_{n}))\). The double-randomized algorithm performs the following one-step update:

\[_{k+1}=(,(,_{n};\{ _{t}\}_{0 t},(_{n},_{n}));\{ _{t}\}_{0 t},(_{n},_{n})). \]

The algorithm introduces a random step size \((-)\) defined on \([0,h]\) other than deterministic \(h\). And let \(\) follows the distribution \(^{}(e^{}-)\) on \([0,h]\).

The analysis focuses on a Gaussian prior setting. Under a Gaussian prior, the following Lemma points out that \(\) is linear in starting point \((_{n},_{n})\) and has a decoupled Brownian motion, and thus the update (4.2) can be easily implemented.

**Lemma 4.1**.: Assume \(g()=\|\|^{2}\). If \(_{n}(t)\) follows the discretized Langevin diffusion process (4.1) with starting point \((_{n},_{n})\) and a given \(}_{n}\), for any \(t>0\), it satisfies the integral equation

\[_{n}(t)=(t,}_{n};\{ _{s}\}_{0 s t}, (_{n},_{n}))=A_{11}(t)_{n}+A_{12}(t )_{n} \] \[+u_{0}^{t}A_{12}(s-t) f(}_{n}) s+2_{0}^{t}A_{12}(s-t)_{s},\]

where

\[A_{11}(t)= -1}{2}e^{(-1-)t}++1}{2}e^{(-1+)t},\] \[A_{12}(t)= -}e^{(-1-)t}+}e^{(-1+)t}\]are deterministic functions of \(t\). Moreover, if \(_{n}^{*}(t)\) follows the exact Langevin process (3.4) with starting point \((_{n},_{n})\), then for any \(t>0\)

\[_{n}^{*}(t)=A_{11}(t)_{n}& +A_{12}(t)_{n}+u_{0}^{t}A_{12}(s-t) f(_{n}^{*}( s))s\\ &+2_{0}^{t}A_{12}(s-t)_{s}. \]

Given the integral formula (4.3), the algorithm can be summarized as Algorithm 1. In Algorithm 1, \(A_{21}\), \(A_{22}\) is deterministic scalar functions, and \(:^{2}^{3d 3d}\) is also deterministic. For the explicit formula, please refer to Appendix A. The distribution of \((H,G,W)\) is induced by the coupling between \(\{_{t}\}_{0 t}\) and \(\{_{t}\}_{0 t}\) in (4.2).

### Main theorem

The convergence guarantee of DRUL can be stated as the following theorem.

**Theorem 4.2** ( **Main theorem**, convergence of DRUL).: For any tolerance \((0,1)\), denote the minimizer of \(U()\) by \(_{*}\) and set the step size

\[h\{},}{(24C_{2} ((H)+\|_{*}\|^{2}))^{1/3}} \},\]

where \(C_{2} 1\) is a universal constant. With initial point \((_{0},_{0})\), define \(_{0}=_{ p,(0,u)}(\| _{0}-\|^{2}+\|_{0}+_{0}-- \|^{2})\). Then under Assumptions 3.1, when

\[n(_{0}}{^{ 2}}),\]

Algorithm 1 outputs \(_{n}\) such that \(W_{2}((_{n}),p)\).

Theorem 4.2 shows an overall \(}((H)+\|_{*}\|^{2} )^{1/3}}{^{2/3}})\) iteration and gradient complexity to find an \(\)-approximate sample in \(2\)-Wasserstein distance. By pre-finding \(_{*}\) using a convex optimization algorithm and linearly drifting the coordinates, we can assume \(_{*}=\) without loss of generality. DRUL admits the stepsize reaching \((}{((H))^{1/3}})\) and the overall complexity is \(}((H))^{1/3}}{ ^{2/3}})\).

Now we consider a realizable case where our result achieves better complexity on \(d\). The concrete example is that \(f\) admits a separable structure as discussed in Section 3.3. Corollary 4.3 below shows that when \(f\) admits a ridge separable structure, Algorithm 1 enjoys a dimension-free iteration and gradient complexity.

**Corollary 4.3**.: Follow the notations in Theorem 4.2. Further, if \(f()\) admits a ridge-separable form and satisfies Assumptions 3.4 and 3.5. Then if we set the step size

\[h\{},}{(24C_{2} (+\|_{*}\|^{2}))^{1/3}}\},\]

With initial point \((_{0},_{0})\) and \(_{0}=_{ p,(0,u)}( \|_{0}-\|^{2}+\|_{0}+_{0}-- \|^{2})\). Then when

\[n(_{0}}{^{ 2}}),\]

Algorithm 1 outputs \(_{n}\) such that \(W_{2}((_{n}),p)\).

**Discussion.** Theorem 4.2 establishes the convergence rate of DRUL with a weak dimension dependence. We shall note that for lots of high-dimensional sampling problems, the trace of the Hessian matrices for the potential function is much smaller than \(d\) times the largest eigenvalue because the eigenvalues often drop rapidly. In practice, this situation has been considered in lots of topics. For example, one defines the effective rank (e.g. Hsu et al. (2012)) to represent the acting dimension of the data on linear models. In distributed machine learning, one can show fewer bits are needed to be transmitted between machines when the eigenvalues decrease fast (e.g. Hanzely et al. (2018)). As shown in Figure 1(a), the Gram matrix of the MNIST dataset, which is also the Hessian of Bayesian ridge linear regression, has rapidly decreasing eigenvalues. Similar empirical results are observed on deep neural network models by Sagun et al. (2016), as in Figure 1(b). In fact, beyond the ridge separable case, there are many problems admitting \((H)=o(d)\), such as the concentrated posterior distributions with bounded gradients and neural networks with regularization. However, one may notice that the result of Theorem 4.2 is based on a uniform upper bound of the Hessian matrices. We think this is the basic case to show that our algorithm achieves convergence with an intrinsically low-dimension dependence. It is possible to relax the condition to the upper bound of the traces for local Hessian matrices with an additional Hessian smoothness assumption. Please see more discussions in Appendix E.

## 5 Intuition

In this section, we provide the intuitions of the algorithm design. For the simplicity of the notation, let \(}_{n}(s)=(s,_{n};\{_{t}\}_{0  t s},(_{n},_{n}))\) and \(_{n}(s)=(s,(,_{n};\{_{t}\}_{0 t},(_{n},_{n}));\{_{t }\}_{0 t s},(_{n},_{n}))\). Then given \(\) and \(\) in Algorithm 1, \(_{n}(s)=(s,}_{n}();\{_ {t}\}_{0 t},(_{n},_{n}))\) and \(_{n}()=_{n+1}\).

Our analysis tracks the dynamics of the distance to the stationary distribution. Specifically, we analysis the dynamics of \(_{n}(t)=\|_{n}(t)-_{n}^{*}(t)+ _{n}(t)-_{n}^{*}(t)\|^{2}+\|_{n}(t)- _{n}^{*}(t)\|^{2}\) and \(_{n}=_{n}(0)\), which upper bound the squared 2-Wasserstein distance \(W_{2}((_{n}(t)),p)^{2}\) and \(W_{2}((_{n}),p)^{2}\), respectively. Here, \((_{n}^{*}(t),_{n}^{*}(t))\) evolving along the exact Langevin diffusion (3.4) follows the stationary distribution and is synchronously coupled with \((_{n}(t),_{n}(t))\). One can find its formal definition in Appendix B. Via tracking the flow and using the contraction property of the process, the following Lemma characterizes the one-step discretization.

**Lemma 5.1**.: Let \(_{n}\) be the \(n\)-step output of Algorithm 1 and \(_{n}^{*}(t)\) be defined as above. Set \(u=\). Under Assumptions 3.1, given that \(_{n}\) and \(_{n}^{*}\) are coupled synchronously, we have for any \(h>0\)

\[_{n+1}=_{}_{n}() _{}e^{-}_{n}+  \]

where \(\) is

\[=2u_{^{}}_{ }_{0}^{}e^{}_{n}(s)- _{n}^{*}(s)+_{n}(s)-_{n}^{*}(s), f(_{n}(s))- f(}_{n}())s.\]

Lemma 5.1 indicates at each step, \(_{n}\) contracts with a local discretization error. Telescoping (5.1) and upper bounding the term \(\) yields the Theorem 4.2. To obtain the convergence rate in the

Figure 1: A demonstration of the eigenvalues of the Hessian matrix. (a) The eigenvalues of the Gram matrix of MNIST data. (b) Eigenvalues of a three-layer neural network from Sagun et al. (2016).

main theorem, we will show that Algorithm 1 guarantees an upper bound of \(\) which (1) achieves the state-of-the-art dependence on stepsize and (2) satisfies that the dimension dependence can be controlled by the contraction.

**Improved discretization error.** We accomplish the first goal by matching the expectation, which is detailed by Lemma 5.2.

**Lemma 5.2**.: Let \(\) be probability measure defined on \([0,h]\) satisfying \((t)(-)t\), and the probability measure \(^{}\) defined on \([0,h]\) satisfies \(^{}(t)(e^{}- )t\) on \([0,h]\). Then for measurable function \(F(t)\), \(\) and \(^{}\) satisfy that

1. There exists positive constant \(C_{1}\) such that \(_{t}_{0}^{t}e^{}F(t)s=C_{1}h _{t^{}}F(t)\).
2. There exists positive constant \(C_{2}\) such that \(_{t^{}}|F(t)| C_{t}|F(t)|\).

Claim (A) in Lemma 5.2 states that by choosing a random step size \(^{}\), we can leverage the low discretization error of the randomized midpoint method. Denote the random weight \(_{n}(s,)=_{n}(s)-_{n}^{*}(s)+_{n} (s)-_{n}^{*}(s)\). One can split \(_{n}(s,)\) into \((_{n}(s,)-_{n}(0,0))+_{n}(0,0)\). The former term can be bounded using the one-step move, and by claim (A), the dominating latter one is

\[2u_{^{}}_{ }_{0}^{}e^{}(0,0),  f(_{n}(s))- f(}_{n}()) s\] \[= 2uC_{1}h(0,0),_{s^{ }} f(_{n}(s))- f(}_{n}(s )),\]

which attains a low discretization error given that \(_{s^{}} f(}_{n}(s))\) is a low biased approximation to \(_{s^{}} f(_{n}(s))\).

**Averaged contraction can control the weight variance.** Then we consider the variation of the weight \(w_{n}(s,)\). The time difference of \(_{n}(s,)\) writes

\[(s,)-(_{n}-_{n}^{*}+ _{n}-_{n}^{*})=_{0}^{s}(_{n}(r) -_{n}^{*}(r)-um(_{n}(r)-_{n}^{*}(r)) \] \[-2(_{n}(r)-_{n}^{*}(r))-u f(}_{n}())+u f(_{n}^{*}(r)))r.\]

(5.2) indicates the variance \(_{s}((s,))\) is dimension dependent for nondegenerated distributions \(\) on \([0,h]\), since it will introduce the \(_{n}(r)\) whose difference to \(_{n}()\) or \(_{n}(0)\) is dimension dependent. We control the dimension dependence via the averaged contraction. And the randomized step size makes it possible to consider the averaged effect. We have the following Lemma to bound the variation of the weight.

**Lemma 5.3**.: Let \(_{n}(t),_{n}(t),_{n}^{*}(t)\) and \(_{n}^{*}(t)\) be defined as above and \(u=\). Under Assumption 3.1, for any \(t, h\), we have

\[\|_{n}(t)-_{n}-_{n}^{*}( t)+_{n}^{*}+_{n}(t)-_{n}-_{n}^{*}(t)+ _{n}^{*}\|^{2} \] \[ h^{2}_{t}_{n}(t)+h^{4} _{n}+u^{2}h^{4}(H)+h^{4}\|_{*}\|^{2}.\]

Now the dimension dependence of \(((s,))\) is contained in \(_{t}_{n}(t)\), which can be controlled using the averaged contraction under the stochastic step size.

## 6 Conclusion

This paper proposes a double-randomized technique and designs the DRUL algorithm. We prove that with strongly convex and Lipschitz smooth assumptions potentials, the algorithm converges to the target distribution in Wasserstein distance in \(}((H)+\|_{n}\|^{2})^{1/3 }}{^{2/3}})\) iterations. The result illustrates that many sampling tasks in machine learning can achieve a dimension-independent complexity. The proposed DRUL algorithm can be potentially much faster than existing algorithms for high-dimensional problems. As a concrete example, when the negative log-likelihood function admits a ridge-separable structure, under mild conditions, a dimension-free \(}(})\) iteration complexities can be obtained by DRUL. We hope our technique brings new insights for designing dimension-independent algorithms for high-dimensional sampling.

Acknowledgement

C. Fang was supported by National Key R\(\&\)D Program of China (2022ZD0114902), the NSF China (No. 62376008) and Wudao Foundation. T. Zhang was supported by the General Research Fund (GRF) of Hong Kong (No. 16310222).