# Meta-Referential Games to Learn Compositional Learning Behaviours

Anonymous Author(s)

###### Abstract

Human beings use compositionality to generalise from past to novel experiences, assuming that past experiences can be decomposed into fundamental atomic components that can be recombined in novel ways. We frame this as the ability to learn to generalise compositionally, and refer to behaviours making use of this ability as compositional learning behaviours (CLBs). Learning CLBs requires the resolution of a binding problem (BP). While it is another feat of intelligence that human beings perform with ease, it is not the case for artificial agents. Thus, in order to build artificial agents able to collaborate with human beings, we develop a novel benchmark to investigate agents' abilities to exhibit CLBs by solving a domain-agnostic version of the BP. Taking inspiration from the Emergent Communication, we propose a meta-learning extension of referential games, entitled Meta-Referential Games, to support our benchmark, the Symbolic Behaviour Benchmark (S2B). Baseline results and error analysis show that the S2B is a compelling challenge that we hope will spur the research community to develop more capable artificial agents.

## 1 Introduction

Defining compositional behaviours (CBs) as "the ability to generalise from combinations of **trained-on** atomic components to novel re-combinations of those very same components", we can define compositional learning behaviours (CLBs) as "the ability to generalise **in an online fashion** from a few combinations of never-before-seen atomic components to novel re-combinations of those very same components". We employ the term online here to imply a few-shot learning context (Vinyals et al., 2016; Mishra et al., 2018) that demands that agents learn from, and then leverage some novel information, both over the course of a single lifespan, or episode, in our case of few-shot meta-RL (see Beck et al. (2023) for a review of meta-RL). Thus, in this paper, we investigate artificial agents' abilities for CLBs, which involve a few-shot learning aspect that is not present in CBs.

**Compositional Learning Behaviours as Symbolic Behaviours.**Santoro et al. (2021) states that a symbolic entity does not exist in an objective sense but solely in relation to an "_interpret who treats it as such_", and it ensues that there exists a set of behaviours, i.e. _symbolic behaviours_, that are consequences of agents engaging with symbols. Thus, in order to evaluate artificial agents in terms of their ability to collaborate with humans, we can use the presence or absence of symbolic behaviours. Among the different characteristic of symbolic behaviours, this work will primarily focus on the receptivity and constructivity aspects. Receptivity aspects amount to the ability to receive new symbolic conventions in an online fashion. For instance, when a child introduces an adult to their toys' names, the adults are able to discriminate between those new names upon the next usage. Constructivity aspects amount to the ability to form new symbolic conventions in an online fashion. For instance, when facing novel situations that require collaborations, two human teammates cancome up with novel referring expressions to easily discriminate between different events occurring. Both aspects refer to abilities that support collaboration. Thus, this paper develops a benchmark to evaluate agents' abilities in receptive and constructive behaviours, with a primary focus on CLBs.

**Binding Problem & Meta-Learning.** Following Greff et al. (2020), we refer to the binding problem (BP) as the challenges in "dynamically and flexibly bind[/re-use] information that is distributed throughout the [architecture]" of some artificial agents (modelled with artificial neural networks here). We note that there is an inherent BP that requires solving for agents to exhibit CLBs. Indeed, over the course of a single episode (as opposed to a whole training process, in the case of CBs), agents must dynamically identify/segregate the component values from the observation of multiple stimuli, timestep after timestep, and then bind/(re-)use/(re-)combine this information (hopefully stored in some memory component of their architecture) in order to respond correctly to novel stimuli.Solving the BP instantiated in such a context, i.e. re-using previously-acquired information in ways that serve the current situation, is another feat of intelligence that human beings perform with ease, on the contrary to current state-of-the-art artificial agents. Thus, our benchmark must emphasise testing agents' abilities to exhibit CLBs by solving a version of the BP. Moreover, we argue for a domain-agnostic BP, i.e. not grounded in a specific modality such as vision or audio, as doing so would limit the external validity of the test. We aim for as few assumptions as possible to be made about the nature of the BP we instantiate (Chollet, 2019). This is crucial to motivate the form of the stimuli we employ, and we will further detail this in Section 3.1.

**Language Grounding & Emergence.** In order to test the quality of some symbolic behaviours, our proposed benchmark needs to query the semantics that agents (_the interpreters_) may extract from their experience, and it must be able to do so in a referential fashion (e.g. being able to query to what extent a given experience is referred to as, for instance, 'the sight of a red tomato'), similarly to most language grounding benchmarks. Subsequently, acknowledging that the simplest form of collaboration is maybe the exchange of information, i.e. communication, via a given code, or language, we argue that the benchmark must therefore also allow agents to manipulate this code/language that they use to communicate. This property is known as the metalinguistic/reflexive function of languages (Jakobson, 1960). It is mainly investigated in the current deep learning era within the field of Emergent Communication (Lazaridou and Baroni (2020), and see Brandizzi (2023) and Denamganai and Walker (2020) for further reviews), via the use of variants of the referential games (RGs) (Lewis, 1969). Thus, we take inspiration from the RG framework, where (i) the language domain represents a semantic domain that can be probed and queried, and (ii) the reflexive function of language is indeed addressed. Then, in order to instantiate different BPs at each episode, we propose a meta-learning extension to RGs, entitled Meta-Referential Games, and use this framework to build our benchmark. It results in our proposed Symbolic Behaviour Benchmark (S2B), which has the potential to test for many aspects of symbolic behaviours.

After review of the background (Section 2), we will present our contributions as follows: we propose the Symbolic Behaviour Benchmark to enables evaluation of symbolic behaviours in Section 3, presenting the Symbolic Continuous Stimulus (SCS) representation scheme which is able to instantiate a BP, on the contrary to common symbolic representations (Section 3.1), and our Meta-Referential Games framework, a meta-learning extension to RGs (Section 3.2);then we provide baseline results and error analysis in Section 4 showing that our benchmark is a compelling challenge that we hope will spur the research community.

## 2 Background

The first instance of an environment with a primary focus on efficient communication is the _signaling game_ or _referential game_ (RG) by Lewis (1969), where a speaker agent is asked to send a message to the listener agent, based on the _state/stimulus_ of the world that it observed. The listener agent then acts upon the observed message by choosing one of

Figure 1: Illustration of a _discriminative \(2\)-players_ / _L-signal_ / _N-round_ variant of a _RG_.

the _actions_ available to it. Both players' goals are aligned (it features _pure coordination/common interests_), with the aim of performing the 'best' _action_ given the observed _state_.In the recent deep learning era, many variants of the RG have appeared (Lazaridou and Baroni, 2020). Following the nomenclature proposed in Denamganaal and Walker (2020), Figure 1 illustrates in the general case a _discriminative \(2\)-players / \(L\)-signal / \(N\)-round / \(K\)-distractors / descriptive / object-centric_ variant, where the speaker receives a stimulus and communicates with the listener (up to \(N\) back-and-forth using messages of at most \(L\) tokens each), who additionally receives a set of \(K+1\) stimuli (potentially including a semantically-similar stimulus as the speaker, referred to as an object-centric stimulus). The task is for the listener to determine, via communication with the speaker, whether any of its observed stimuli match the speaker's. We highlight here features of RGs that will be relevant to how S2B is built, and then provide formalism used throughout the paper. The **number of communication rounds**\(N\) characterises (i) whether the listener agent can send messages back to the speaker agent and (ii) how many communication rounds can be expected before the listener agent is finally tasked to decide on an action. The basic (discriminative) _RG_ is **stimulus-centric**, which assumes that both agents would be somehow embodied in the same body, and they are tasked to discriminate between given stimuli, that are the results of one single perception'system'. On the other hand, Choi et al. (2018) introduced an **object-centric** variant which incorporates the issues that stem from the difference of embodiment (which has been later re-introduced under the name _Concept game_ by Mu and Goodman (2021)). The agents must discriminate between objects (or scenes) independently of the viewpoint from which they may experience them. In the object-centric variant, the game is more about bridging the gap between each other's cognition rather than just finding a common language. The adjective 'object-centric' is used to qualify a stimulus that is different from another but actually present the same meaning (e.g. same object, but seen under a different viewpoint). Following the last communication round, the listener outputs a decision (\(D_{i}^{L}\) in Figure 2) about whether any of the stimulus it is observing matches the one (or a semantically similar one, in object-centric RGs) experienced by the speaker, and if so its action index must represent the index of the stimulus it identifies as being the same. The **descriptive** variant allows for none of the stimuli to be the same as the target one, therefore the action of index \(0\) is required for success. The agent's ability to make the correct decision over multiple RGs is referred to as RG accuracy.

**Compositionality, Disentanglement & Systematicity.** Compositionality is a phenomenon that human beings are able to identify and leverage thanks to the assumption that reality can be decomposed over a set of "disentangle[d,] underlying factors of variations" (Bengio, 2012), and our experience is a noisy, entangled translation of this factorised reality. This assumption is critical to the field of unsupervised learning of disentangled representations (Locatello et al., 2020) that aims to find "manifold learning algorithms" (Bengio, 2012), such as variational autoencoders (VAEs (Kingma and Welling, 2013)), with the particularity that the latent encoding space would consist of disentangled latent variables (see Higgins et al. (2018) for a formal definition). As a concept, compositionality has been the focus of many definition attempts. For instance, it can be defined as "the algebraic capacity to understand and produce novel combinations from known components"(Loula et al. (2018) referring to Montague (1970)) or as the property according to which "the meaning of a complex expression is a function of the meaning of its immediate syntactic parts and the way in which they are combined" (Krifka, 2001). Although difficult to define, the commmunity seems to agree on the fact that it would enable learning agents to exhibit systematic generalisation abilities (also referred to as combinatorial generalisation (Battaglia et al., 2018)). While often studied in relation to languages, it is usually defined with a focus on behaviours. In this paper, we will refer to (linguistic) compositionality when considering languages, and interchangeably compositional behaviours or systematicity to refer to "the ability to entertain a given thought implies the ability to entertain thoughts with semantically related contents"(Fodor and Pylyshyn, 1988).

Compositionality can be difficult to measure. Brighton and Kirby (2006)'s _topographic similarity_ (**topsim**) which is acknowledged by the research community as the main quantitative metric (Lazaridou et al., 2018; Guo et al., 2019; Slowik et al., 2020; Chaabouni et al., 2020; Ren et al., 2020). Recently, taking inspiration from disentanglement metrics, Chaabouni et al. (2020) proposed the **posdis** (positional disentanglement) and **bosdis** (bag-of-symbols disentanglement) metrics, that have been shown to be differently 'opinionated' when it comes to what kind of compositionality they capture. As hinted at by Choi et al. (2018); Chaabouni et al. (2020) and Dessi et al. (2021), compositionality and disentanglement appears to be two sides of the same coin, in as much as emergent languages are discrete and sequentially-constrained unsupervisedly-learned representations. In Section 3.1, we bridge further compositional language emergence and unsupervised learning of disentangled representations by asking _what would an ideally-disentangled latent space look like?_ to build our proposed benchmark.

**Richness of the Stimuli & Systematicity.**Chaabouni et al. (2020) found that compositionality is not necessary to bring about systematicity, as shown by the fact that non-compositional languages wielded by symbolic (generative) RG players were enough to support success in zero-shot compositional tests (ZSCTs). They found that the emergence of a posdis-compositional language was a sufficient condition for systematicity to emerge. Finally, they found a necessary condition to foster systematicity, that we will refer to as richness of stimuli condition (Chaa-RSC). It was framed as (i) having a large stimulus space \(|I|=i_{val}{}^{i_{attr}}\), where \(i_{attr}\) is the number of attributes/factor dimensions, and \(i_{val}\) is the number of possible values on each attribute/factor dimension, and (ii) making sure that it is densely sampled during training, in order to guarantee that different values on different factor dimensions have been experienced together. In a similar fashion, Hill et al. (2019) also propose a richness of stimuli condition (Hill-RSC) that was framed as a data augmentation-like regularizer caused by the egocentric viewpoint of the studied embodied agent. In effect, the diversity of viewpoint allowing the embodied agent to observe over many perspectives the same and unique semantical meaning allows a form of contrastive learning that promotes the agent's systematicity.

## 3 Symbolic Behaviour Benchmark

The version of the S2B1 that we present in this paper is focused on evaluating receptive and constructive behaviour traits via a single task built around 2-players multi-agent RL (MARL) episodes where players engage in a series of RGs (cf. lines \(11\) and \(17\) in Alg. 5 calling Alg. 3). We denote one such episode as a meta-RG and detail it in Section 3.2. Each RG within an episode consists of \(N+2\) RL steps, where \(N\) is the _number of communication rounds_ available to the agents (cf. Section 2). At each RL step, agents both observe similar or different _object-centric_ stimuli and act simultaneously from different actions spaces, depending on their role as the speaker or the listener of the game. Stimuli are presented to the agent using the Symbolic Continuous Stimulus (SCS) representation that we present in Section 3.1. Each RG in a meta-RG follows the formalism laid out in Section 2, with the exception that speaker and listener agents speak simultaneously and observe each other's messages upon the next RL step. Thus, at step \(N+1\), the speaker's action space consists solely of a _no-operation_ (NO-OP) action while the listener's action space consists solely of the decision-related action space. In practice, the environment simply ignores actions that are not allowed depending on the RL step. Next, step \(N+2\) is intended to provide feedback to the listener agent as its observation is replaced with the speaker's observation (cf. line \(12\) and \(18\) in Alg. 5). Note that this is the exact stimulus that the speaker has been observing, rather than a **possible** object-centric sample. In Figure 3, we present SCS-represented stimuli, observed by a speaker over the course of a typical episode.

### Symbolic Continuous Stimulus representation

Building about successes of the field of unsupervised learning of disentangled representations (Higgins et al., 2018), to the question _what would an ideally-disentangled latent space look like?_, we propose the Symbolic Continuous Stimulus (SCS) representation and provide numerical evidence of it in Appendix D.2. It is continuous and relying on Gaussian kernels, and it has the particularity of enabling the representation of stimuli sampled from differently semantically structured symbolic spaces while maintaining the same representation shape (later referred as the _shape invariance property_), as opposed to the one-/multi-hot encoded (OHE/MHE) vector representation commonly used when dealing with symbolic spaces. While the SCS representation is inspired by vectorssampled from VAE's latent spaces, this representation is not learned and is not aimed to help the agent performing its task. It is solely meant to make it possible to define a distribution over infinitely many semantic/symbolic spaces, while instantiating a BP for the agent to resolve. Indeed, contrary to OHE/MHE representation, observation of one stimulus is not sufficient to derive the nature of the underlying semantic space that the current episode instantiates. Rather, it is only via a kernel density estimation on multiple samples (over multiple timesteps) that the semantic space's nature can be inferred, thus requiring the agent to segregated and (re)combine information that is distributed over multiple observations. In other words, the benchmark instantiates a domain-agnostic BP. We provide in Appendix D.1 some numerical evidence to the fact that the SCS representation differentiates itself from the OHE/MHE representation because it instantiates a BP. Deriving the SCS representation from an idealised VAE's latent encoding of stimuli of any domain makes it a domain-agnostic representation, which is an advantage compared to previous benchmark because domain-specific information can therefore not be leveraged to solve the benchmark.

In details, the semantic structure of an \(N_{dim}\)-dimensioned symbolic space is the tuple \((d(i))_{i[1;N_{dim}]}\) where \(N_{dim}\) is the number of latent/factor dimensions, \(d(i)\) is the **number of possible symbolic values** for each latent/factor dimension \(i\). Stimuli in the SCS representation are vectors sampled from the continuous space \([-1,+1]^{N_{dim}}\). In comparison, stimuli in the OHE/MHE representation are vectors from the discrete space \(\{0,1\}^{d_{OHE}}\) where \(d_{OHE}=_{i=1}^{N_{dim}}d(i)\) depends on the \(d(i)\)'s. Note that SCS-represented stimuli have a shape that does not depend on the \(d(i)\)'s values, this is the _shape invariance property_ of the SCS representation (see Figure 4(bottom) for an illustration).

In the SCS representation, the \(d(i)\)'s do not shape the stimuli but only the semantic structure, i.e. representation and semantics are disentangled from each other. The \(d(i)\)'s shape the semantic by enforcing, for each factor dimension \(i\), a partitioninga of the \([-1,+1]\) range into \(d(i)\) value sections. Each partition corresponds to one of the \(d(i)\) symbolic values available on the \(i\)-th factor dimension. Having explained how to build the SCS representation sampling space, we now describe how to sample stimuli from it. It starts with instantiating a specific latent meaning/symbol, embodied by latent values \(l(i)\) on each factor dimension \(i\), such that \(l(i)[1;d(i)]\). Then, the \(i\)-th entry of the stimulus is populated with a sample from a corresponding Gaussian distribution over the \(l(i)\)-th partition of the \([-1,+1\) range. It is denoted as \(g_{l(i)}(_{l(i)},_{l(i)})\), where \(_{l(i)}\) is the mean of the Gaussian distribution, uniformly sampled to fall within the range of the \(l(i)\)-th partition, and \(_{l(i)}\) is the standard deviation of the Gaussian distribution, uniformly sampled over the range \([,]\). \(_{l(i)}\) and \(_{l(i)}\) are sampled in order to guarantee (i) that the scale of the Gaussian distribution is large

Figure 2: Left: Sampling of the necessary components to create the i-th RG (\(RG_{i}\)) of a meta-RG. The target stimulus (red) and the object-centric target stimulus (purple) are both sampled from the Target Distribution \(TD_{i}\), a set of \(O\) different stimuli representing the same latent semantic meaning. The latter set and a set of \(K\) distractor stimuli (orange) are both sampled from a dataset of SCS-represented stimuli (**Dataset**), which is instantiated from the current episode’s symbolic space, whose semantic structure is sampled out of the meta-distribution of available semantic structure over \(N_{dim}\)-dimensioned symbolic spaces. Right: Illustration of the resulting meta-RG with a focus on the i-th RG \(RG_{i}\). The speaker agent receives at each step the target stimulus \(s^{i}_{0}\) and distractor stimuli \((s^{i}_{k})_{k[1;K]}\), while the listener agent receives an object-centric version of the target stimulus \(s^{ i}_{0}\) or a distractor stimulus (randomly sampled), and other distractor stimuli \((s^{i}_{k})_{k[1;K]}\), with the exception of the **Listener Feedback step** where the listener agent receives feedback in the form of the exact target stimulus \(s^{i}_{0}\). The Listener Feedback step takes place after the listener agent has provided a decision \(D^{l}_{i}\) about whether the target meaning is observed or not and in which stimuli is it instantiated, guided by the vocabulary-permutated message \(M^{S}_{i}\) from the speaker agent.

enough, but (ii) not larger than the size of the partition section it should fit in. Figure 3 shows an example of such instantiation of the different Gaussian distributions over each factor dimensions' \([-1,+1]\) range.

### Meta-Referential Games

Thanks to the _shape invariance property_ of the SCS representation, once a number of latent/factor dimension \(N_{dim}\) is choosen, we can synthetically generate many different semantically structured symbolic spaces while maintaining a consistent stimulus shape. This is critical since agents must be able to deal with stimuli coming from differently semantically structured \(N_{dim}\)-dimensioned symbolic spaces. In other words that are more akin to the meta-learning field, we can define a distribution over many kind of tasks, where each task instantiates a different semantic structure to the symbolic space our agent should learn to adapt to. Figure 2 highlights the structure of an episode, and its reliance on differently semantically structured \(N_{dim}\)-dimensioned symbolic spaces. Agents aim to coordinate efficiently towards scoring a high accuracy during the ZSCTs at the end of each RL episode. Indeed, a meta-RG is composed of two phases: a supporting phase where supporting stimuli are presented, and a querying/ZSCT phase where ZSCT-purposed RGs are played. During the querying phase, the presented target stimuli are novel combinations of the component values of the target stimuli presented during the supporting phase. Algorithms 4 and 5 contrast how a common RG differ from a meta-RG (in Appendix A). We emphasise that the supporting phase of a meta-RG does not involve updating the parameters/weights of the learning agents, since this is a meta-learning framework of the few-shot learning kind (compare positions and dependencies of lines \(21\) in Alg. 5 and \(6\) in Alg. 4). During the supporting phase, each RG involves a different target stimulus until all the possible component values on each latent/factor dimensions have been shown for at least \(S\) shots (cf. lines \(3-7\) in Alg. 5). While it amounts to at least \(S\) different target stimulus being shown, the number of supporting-phase RG played remains far smaller than the number of possible training-purposed stimuli in the current episode's symbolic space/dataset. Then, the querying phase sees all the testing-purposed stimuli being presented.Emphasising further, during one single RL episode, both supporting and querying RGs are played, without the agent's parameters changing in-between the two phases, since learning CLBs involve agents adapting in an online/few-shot learning setting. The semantic structure of the symbolic space is randomly sampled at the beginning of each episode (cf. lines \(2-3\) in Alg. 5) The reward function proposed to both agents is null at all steps except on the \(N+1\)-th step, being \(+1\) if the listener agent decided correctly or, during the querying phase only, \(-2\) if incorrect (cf. line \(21\) in Alg. 5).

**Vocabulary Permutation.** We bring the readers attention on the fact that simply changing the semantic structure of the symbolic space, is not sufficient to force MARL agents to adapt specifically to the instantiated symbolic space at each episode. Indeed, they can learn to cheat by relying on an episode-invariant (and therefore independent of the instantiated semantic structure) emergent

Figure 3: Visualisation of the SCS-represented stimuli (column) observed by the speaker agent at each RG over the course of one meta-RG, with \(N_{dim}=3\) and \(d(0)=5\), \(d(1)=5\), \(d(2)=3\). The supporting phase lasted for 19 RGs. For each factor dimension \(i[0;2]\), we present on the right side of each plot the kernel density estimations of the Gaussian kernels \((_{l(i)},_{l(i)})\) of each latent value available on that factor dimension \(l(i)[1;d(i)]\). Colours of dots, used to represent the sampled value \(g_{l(i)}\), imply the latent value \(l(i)\)’s Gaussian kernel from which said continuous value was sampled. As per construction, for each factor dimension, there is no overlap between the different latent values’ Gaussian kernels.

language (EL) which would encode the continuous values of the SCS representation like an analog-to-digital converter would. This cheating language would consist of mapping a fine-enough partition of the \([-1,+1]\) range onto a fixed vocabulary in a bijective fashion (see Appendix C for more details). Therefore, in order to guard the MARL agents from making a cheating language emerge, we employ a vocabulary permutation scheme (Cope and Schoots, 2021) that samples at the beginning of each episode/task a random permutation of the vocabulary symbols (cf. line \(1\) in Alg. 2).

**Richness of the Stimulus.** We further bridge the gap between Hill-RSC and Chaa-RSC by allowing the **number of object-centric samples**\(O\) and the **number of shots**\(S\) to be parameterized in the benchmark. \(S\) represents the minimal number of times any given component value may be observed throughout the course of an episode. Intuitively, throughout their lifespan, an embodied observer may only observe a given component (e.g. the value 'blue', on the latent/factor dimension 'color') a limited number of times (e.g. one time within a 'blue car' stimulus, and another time within a 'blue cup' stimulus). These parameters allow the experimenters to account for both the Chaa-RSC's sampling density of the different stimulus components and Hill-RSC's diversity of viewpoints.

## 4 Experiments

**Agent Architecture.** The architectures of the RL agents that we consider are detailed in Appendix B. Optimization is performed via an R2D2 algorithm(Kapturowski et al., 2018) augmented with both the _Value Decomposition Network_(Sunehag et al., 2017) and the _Simplified Action Decoder_ approach (Hu and Foerster, 2019). As preliminary results showed poor performance, we follow Hill et al. (2020) and add an auxiliary reconstruction task to promote agents learning to use their core memory module. It consists of a mean squared-error between the stimuli observed at a given time step and a prediction conditioned on the current state of the core memory module after processing the current stimuli.

### Learning CLBs is Out-Of-Reach to State-of-the-Art MARL

Playing a meta-RG, the speaker aims at each episode to make emerge a new language (constructivity) and the listener aims to acquire it (receptivity) as fast as possible, before the querying-phase of the episode comes around. Critically, we assume that both agents must perform in accordance with the principles of CLBs as it is the only resolution approach. Indeed, there is no success without a generalizing and easy-to-learn EL, or, in other words, a (linguistically) compositional EL (Brighton and Kirby, 2001; Brighton, 2002). Thus, we investigate whether agents are able to coordinate to learn to perform CLBs from scratch, which is tantamount to learning receptivity and constructivity aspects of CLBs in parallel.

**Evaluation & Results.** We report the performance and compositionality of the behaviours in the multi-agent context in Table 1, on 3 random seeds of an LSTM-based model in the task with \(N_{dim}=3\), \(V_{min}=2,V_{max}=5\), \(O=4\), and \(S=1\,\,2\). As we assume no success without emergence of a (linguistically) compositional language, we measure the linguistic compositionality profile of the emerging languages by, firstly, freezing the speaker agent's internal state (i.e. LSTM's hidden and cell states) at the end of an episode and query what would be its subsequent utterances for all stimuli in the latest episode's dataset (see Figure 2), and then compute the different compositionality metrics on this collection of utterances. We compare the compositionality profile of the ELs to that of a compositional language, in the sense of the **posdis** compositionality metric (Chaabouni et al., 2020) (see Figure 4(left) and Table 4 in Appendix B.2). This language is produced by a fixed, rule-based agent that we will refer to as the Posdis-Speaker (PS). Similarly, after the latest episode ends and the

    &  & PS \\  Metric & \(S=1\) & \(S=2\) & \\  \(Acc_{}\) & \(53.6 4.7\) & \(51.6 2.2\) & N/A \\ \(Acc_{}\) & \(50.6 8.8\) & \(50.6 5.8\) & N/A \\ topsim \(\) & \(29.6 16.8\) & \(21.3 16.6\) & \(96.7 0\) \\ posdis \(\) & \(23.7 20.8\) & \(13.8 12.8\) & \(92.0 0\) \\ obsdis \(\) & \(25.6 22.9\) & \(19.1 17.5\) & \(11.6 0\) \\   

Table 1: Meta-RG ZSCT and Ease-of-Acquisition (EoA) ZSCT accuracies and linguistic compositionality measures (\(\%\) s.t.d.) for the multi-agent context after a sampling budget of \(500k\). The last column shows linguist results when evaluating the Posdis-Speaker (PS).

speaker agent's internal state is frozen, we evaluate the EoA of the emerging languages by training a **new, non-meta/common listener agent** for \(512\) epochs on the latest episode's dataset with the frozen speaker agent using a _descriptive-only/object-centric_**common** RG and report its ZSCT accuracy (see Algorithm 3).Table 1 shows \(Acc_{}\) being around chance-level (\(50\%\)), thus the meta-RL agents fail to coordinate together, despite the simplicity of the setting, meaning that learning CLBs from scratch is currently out-of-reach to state-of-the-art MARL agents, and therefore show the importance of our benchmark. As the linguistic compositionality measures are very low compared to the PS agent, and since the chance-leveled \(Acc_{}\) implies that the emerging languages are not easy to learn, it leads us to think that the poor MARL performance is due to the lack of compositional language emergence.

### Single-Agent Listener-Focused RL Context

Seeing that the multi-agent benchmark is out of reach to state-of-the-art cooperative MARL agents, we investigate a simplification along two axises. Firstly, we simplify to a single-agent RL problem by instantiating a fixed, rule-based agent as the speaker, which should remove any issues related to agents learning in parallel to coordinate. Secondly, we use the Posdis-Speaker agent, which should remove any issues related to the emergence of assumed-necessary compositional languages, which corresponds to the constructivity aspects of CLBs. These simplifications allow us to focus our investigation on the receptivity aspects of CLBs, which relates to the ability from the listener agent to acquire and leverage a newly-encountered compositional language at each episode.

#### 4.2.1 Symbol-Manipulation Induction Biases are Valuable

Firstly, in the simplest setting of \(O=1\) and \(S=1\), we hypothesise that symbol-manipulation biases, such as efficient memory-addressing mechanism (e.g. attention) and greater algorithm-learning abilities (e.g. explicit memory), should improve performance, and propose to test the Emergent Symbol Binding Network (ESBN) (Webb et al., 2020), the Dual-Coding Episodic Memory (DCEM) (Hill et al., 2020) and compare to baseline LSTM (Hochreiter and Schmidhuber, 1997).

**Evaluation & Results.** We report in Table 2 the final ZSCT accuracies in the setting of \(N_{dim}=3\), \(V_{min}=2\), \(V_{max}=3\), with a sampling budget of \(10M\) observations and 3 random seeds per architecture. LSTM performing better than DCEM is presumably due to the difficulty of the latter in learning to use its complex memory scheme (preliminary experiments involving a Differentiable Neural Computer (DNC - Graves et al. (2016)), on which the DCEM is built, show it struggling to learn to use its memory compared to LSTM - cf Appendix D.3). On the other hand, we interpret the best performance of the ESBN as being due to it being built over the LSTM, thus allowing its complex memory scheme to be bypassed until it becomes useful. We validate our hypothesis but carry on experimenting with the simpler LSTM model in order to facilitate analysis.

### Receptivity Aspects of CLBs Can Be Learned Sub-Optimally

**Hypotheses.** The SCS representation instantiates a BP even when \(O=1\) (cf. Appendix D.1), and we suppose that when \(O\) increases the BP's complexity increases.Thus, it would stand to reason to expect performance to decrease when \(O\) increases (Hyp. 1). On the other hand, we would expect that increasing \(S\) would provide the learning agent with a denser sampling (in order to fulfill Chao-RSC (ii)), and thus performance is expected to increase as \(S\) increases (Hyp. 2). Indeed, increasing \(S\) amounts to giving more opportunities for the agents to estimate each Gaussian, thus relaxing the instantiated BP's complexity.

**Evaluation & Results.** We report in table 3 ZSCT accuracies on LSTM-based models (6 random seeds per settings) with \(N_{dim}=3\) and \(V_{min}=2,V_{max}=5\). The chance threshold is \(50\%\). When

    &  & ESBN & DCEM \\  \(Acc_{}\) & \(86.0 0.1\) & \(89.4 2.8\) & \(81.9 0.6\) \\   

Table 2: Meta-RG ZSCT accuracies (\(\%\) s.t.d.).

    &  \\  Samples & \(S=1\) & \(S=2\) & \(S=4\) \\  \(O=1\) & \(62.2 3.7\) & \(73.5 2.4\) & \(75.0 2.3\) \\ \(O=4\) & \(62.8 0.8\) & \(62.6 1.7\) & \(60.2 2.2\) \\ \(O=16\) & \(64.9 1.7\) & \(62.0 2.0\) &\(S=1\), increasing \(O\) is surprisingly correlated with non-significant increases in performance/systematicity. On the otherhand, when \(S>1\), accuracy distributions stay similar or decrease while \(O\) increases. Thus, overall, Hyp. 1 tends to be validated. Regarding Hyp. 2, when \(O=1\), increasing \(S\) (and with it the density of the sampling of the input space, i.e. Chaa-RSC (ii)) correlates with increases in systematicity. Thus, despite the difference of settings between common RG, in Chaabouni et al. (2020), and meta-RG here, we retrieve a similar result that Chaa-RSC promotes systematicity. On the other hand, our results show a statistically significant distinction between BPs of complexity associated with \(O>1\) and those associated with \(O=1\). Indeed, when \(O>1\), our results contradict Hyp.2 since accuracy distributions remain the same or decrease when \(S\) increases. Acknowledging the LSTMs' notorious difficulty with integrating/binding information from past to present inputs over long dependencies, we explain these results based on the fact that increasing \(S\) also increases the length of each RL episode, thus the 'algorithm' learned by LSTM-based agents might fail to adequately estimate Gaussian kernel densities associated with each component value.

## 5 Discussion

**Compositional Behaviours vs CLBs.** The learning of compositional behaviours (CBs) is one of the central study in language grounding with benchmarks like SCAN (Lake and Baroni, 2018) and gSCAN (Ruis et al., 2020), as well as in the subfield of Emergent Communication (see Brandizzi (2023), Boldt and Mortensen (2023) for reviews), but none investigates nor allow testing for CLBs. Thus, our benchmark aims to fill in this gap. Without making the nuance, Lake (2019) and Lake and Baroni (2023) actually use CLBs a training paradigm, where a meta-learning extension of the sequence-to-sequence learning setting (i.e. CLB training) is shown to enable human-like systematic CBs. Contrary to our work, they evaluate AI's abilities towards SCAN-specific CBs after SCAN-specific CLBs training. Given the demonstrated potential of CLBs, we leverage our proposed Meta-RG framework to propose a domain-agnostic CLB-focused benchmark for evaluation of CLBs abilities themselves, in order to address novel research questions around CLBs.

**Symbolic Behaviours & Binding Problem.** Following Santoro et al. (2021)'s definition of symbolic behaviours, our benchmark is the first specifically-principled benchmark to evaluate systematically artificial agents's abilities towards any symbolic behaviours. Similarly, while most challenging benchmark instantiates a version of the BP, as described by Greff et al. (2020), there is currently no principled benchmark that specifically investigates whether BP can be solved by artificial agents. Thus, not only does our benchmark fill that other gap, but it also instantiate a domain-agnostic version of the BP, which is critical in order to ascertain the external validity of conclusions that may be drawn from it. Indeed, domain-agnosticity guards us against confounders that could make the task solvable without fully solving the BP, e.g. by gaming some domain-specific aspects (Chollet, 2019).

**Limitations.** Our experiments only evaluated state-of-the-art RL models and algorithms in the simplest configuration of our benchmark, and we leave it to future works to investigate more complex configurations and evaluate other classes of models, such as neuro-symbolic models (Yu et al., 2023) or large language models (Brown et al., 2020).

In summary, we have proposed a novel benchmark to investigate artificial agents abilities at learning CLBs, by casting the problem of learning CLBs as a meta-reinforcement learning problem. It uses our proposed extension to RGs, entitled Meta-Referential Games, which contains an instantiation of a domain-agnostic BP. We provided baseline results for both the multi-agent tasks and the single-agent listener-focused tasks of learning CLBs in the context of our proposed benchmark. Our analysis of the behaviours in the multi-agent context highlighted the complexity for the speaker agent to invent a compositional language. But, when the language is already compositional, then a learning listener is able to acquire it and coordinate, albeit sub-optimally, with a rule-based speaker, in some of the simplest settings of our benchmark. Symbol-manipulation induction biases were found to be valuable, but, overall, our results show that our proposed benchmark is currently out of reach for current state-of-the-art artificial agents, and we hope it will spur the research community towards developing more capable artificial agents.