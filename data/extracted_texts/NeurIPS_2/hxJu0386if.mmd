# [MISSING_PAGE_EMPTY:1]

[MISSING_PAGE_EMPTY:1]

Hence there raises a natural question: is exhaustive support information extraction indispensable for query image segmentation?

We revisit the role of support information in few-shot segmentation through a pilot study. As shown in Table 1, we randomly erode support foreground features with varying proportions to explore how the support information completeness affects query segmentation accuracy. It can be observed that the performances do not degrade significantly or even surpass the complete one. We deem two main reasons contribute to the phenomenon: 1) Rough category guidance from support is sufficient to guide the accurate query image segmentation. 2) Forcing fine-grained support information may introduce redundancy, or even bias, which confuses the prediction of query images, particularly when intra-class diversities are prevalent. Motivated by the above insights, we adjust the direction and focus on the query branch. Building on the observation of intra-object similarity, _i.e._, pixels within the same object are more similar than those across different objects  (as shown in Figure 2 and Table 8, we argue that partially activated object regions can serve as cues to infer whole objects. In this paper, we construct a pseudo support image that has low intra-class variation with the query image by activating query image with a rough category-level support clue. Then we exploit the pseudo support feature to guide the query segmentation, forming a novel query-centric exploration strategy as illustrated in Figure 1.

We tackle query-centric FSS by applying three intuitive procedures. **(1) Discriminative region localization.** The holistic semantic clue from the labeled support image is utilized to roughly locate the most discriminative target area on the query image. **(2) Local to global expansion.** We utilize intra-object feature similarity to explore contextual information and then highlight the less discriminative object parts. **(3) Coarse to fine alignment.** The coarse activated region is further refined by eliminating the detailed difference with ground truth. Different from previous methods that focus on extracting fine-grained support information, Our method is less susceptible to intra-class diversity as only a rough holistic support guidance is needed in the first procedure to generate the pseudo support. More attention is paid to the last two query-focused procedures that enable growing incomplete local regions into accurate segmentations.

We propose an end-to-end Adversarial Mining Transformer(AMFormer) to couple procedures (2) and (3) and mutually enhance each other, which optimizes an object mining transformer \(G\) and a detail mining transformer \(D\) via an adversarial process. AMFormer aims at fully excavating the target area and aligning it in detail under the guidance of the pseudo support features. **To dig out the entire object**

Figure 1: Comparison between the previous methods and ours. (a) Most of the previous methods focus their efforts on extracting more support information. They condense support information into prototypes  or directly explore pixel-level support features . (b) The proposed AMFormer focus on the query features and exploits intra-object similarity to mining the complete target, forming a query-centric FSS method. Only rough category guidance from support is needed in our approach.

Figure 2: t-SNE visualization of the intra-class diversity and the intra-object similarity. As shown by the blue and green circles, different instances of the same category may be far apart in the feature space, _e.g._, dog. While pixels from the same object share high feature similarity, as shown by the three circles within the blue one.

**region**, in the \(G\), we conduct multi-scale pixel-level correlation between the query features and pseudo support features. The exploration of the intra- and inter-scale contextual information in \(G\) progressively highlights the latent target parts that share high intra-object similarities. **To effectively align the prediction details**, _e.g._, object boundaries, \(D\) models multiple detail proxies to accurately distinguish the subtle local differences between the ground truth and the prediction generated by \(G\). By means of adversarial training, \(G\) is optimized to predict more accurate segmentations to fool \(D\) and only the well-learned \(G\) is required to produce accurate predictions in the inference stage.

We evaluate our AMFormer on two widely used benchmarks COCO-\(20^{i}\) and Pascal-\(5^{i}\) with different backbones and the AMFormer consistently sets new state-of-the-art on different settings. Moreover, our query-centric approach does not reckon on elaborate support annotations. It achieves remarkable performance even with weak support labels such as scribbles or bounding boxes, formulating a more practical FSS model. We also hope that our work can inspire more research on query-centric FSS methods. **To recap**, our contributions are concluded as follows: (i) We re-evaluate the importance of support information in FSS and demonstrate that a coarse category hint suffices for accurate query segmentation. This motivated us to put forward a novel query-centric FSS method. (ii) We propose a novel Adversarial Mining Transformer (AMFormer) that optimizes an object mining transformer \(G\) and a detail mining transformer \(D\) for region expansion and detail alignment, respectively. (iii) Extensive experiments show that AMFormer significantly outperforms previous SOTAs. The conspicuous performance with weak support label also sheds light for future research of more general FSS models.

## 2 Related Work

### Semantic Segmentation

Semantic segmentation has been widely applied to autonomous driving, medical image processing [15; 16; 17] and so on. The aim of semantic segmentation is to assign each pixel within the given image to a predefined category label. The seminal FCN  sparked a wave of remarkable advances in semantic segmentation [18; 19; 20] based on convolutional neural networks (CNN). Various networks focus on better context exploration by enlarging the receptive field of CNN via dilated convolutions [21; 22], global pooling  and pyramid pooling [21; 24]. In addition to CNN-based models, the success of Vision Transformer (ViT)  encourages a series of transformer-based segmentation models [26; 27; 28; 29]. For instance, maskformer  adopts the transformer decoder  to conduct the mask classification based on a set prediction objective. Many subsequent works improve this framework [32; 33; 34; 35] and gradually formed a unified segmentation model that can address different image segmentation tasks. Despite the success, these methods cannot generalize to novel classes in the low-data regime.

### Few-Shot Semantic Segmentation

Few-shot segmentation (FSS)  is established to segment new category images (query images) with only a few labeled samples (support images). Owing to the reliable annotations in the support set, current FSS methods mainly focus on effectively excavating support information, which can be roughly divided into two categories: prototypical learning methods and affinity learning methods. Motivated by PrototypicalNet , many previous works condense the support information into single [37; 38; 39; 40; 6] or multiple prototypes [41; 42; 43; 5; 4; 44; 45; 46] and then conduct feature comparison or aggregation. For example, ASGNet  adopts superpixel-guided clustering to adaptively construct multiple prototypes, which are concatenated with the most relevant query features to guide the pixel classification. Differently, for the seek of fine-grained support guidance, affinity learning methods [47; 48; 49; 50; 13; 47] are designed to establish pixel-level associations between support and query features via attention mechanism [7; 9] or cost volume aggregation [48; 8]. For instance, CyCTR  introduces a cycle-consistent attention mechanism to equip query features with relevant support information. Though achieving promising results, these methods depend heavily on support information and are prone to segmentation errors in the presence of large intra-class variations. Some methods[11; 6] try to solve this problem by mining the class-specific representation from the

   
 Erosion Ratio (\%) \\  & 80 & 65 & 50 & 35 & 20 & \(0^{*}\) \\  PFENet  & 60.6 & 61.0 & **61.5** & 61.2 & 61.0 & 61.2 \\  HDMNet  & 69.3 & 70.0 & **70.5** & 70.4 & 69.9 & 70.2 \\   

Table 1: The performance (mIoU) under different support feature erosion ratios. We conduct this pilot study on \(1^{st}\) split of Pascal-\(5^{i}\) using ResNet-50 and 1-shot setting. \({}^{*}\) means reproduced results.

query branch but remain at relatively coarse prototype granularity. In this paper, we propose a novel query-centric approach that exploits intra-object similarity to probe query targets with only overall category-level guidance from support.

## 3 Method

### Problem Definition

Few-shot segmentation (FSS) tackles novel class object segmentation with only a few densely-annotated samples. Episodic meta-training  is widely used to enhance the generalization of FSS models. Specifically, the dataset is divided into the training set \(_{train}\) and the testing set \(_{test}\). The category sets of \(_{train}\) and \(_{test}\) are disjoint, _i.e._, \(_{train}_{test}=\). A series of episodes are sampled from \(_{train}\) to train the model, each of which is composed of a support set \(=\{I_{s}^{k},M_{s}^{k}\}_{k=1}^{K}\) and a query set \(=\{I_{q},M_{q}\}\) in the _K_-shot setting, where \(I\) and \(M\) denote the RGB image and corresponding binary masks, respectively. Under the supervision of \(M_{q}\), the model is trained to predict the query mask conditioned on the \(\) and \(I_{q}\). After that, the trained model is evaluated on the episodes sampled from \(_{test}\) without further optimization.

### Revisiting of Transformer-based Feature Aggregation

Transformer layers  are widely used in computer vision tasks for feature aggregation. The critical component of transformer layer is the attention mechanism that enables the long-range modeling capability. Specifically, the attention layer is first applied to compute the attention weight of the source feature sequence \(^{N_{1} C}\) and the target sequence \(^{N_{2} C}\), where the \(N_{1}\), \(N_{2}\) denote the length of sequences and \(C\) is the embedding dimension, formulaic as:

\[=(()^{}}{}}),=^{},=^{}, \]

in which \(^{}\) and \(^{}^{C d}\) are learnable linear projections and \(\) is the scaling factor. The source information is adaptively transported to the target sequence according to attention weight, and a feed-forward network (FFN) is further applied to transform the fused features:

\[}=(),= ^{}, \]

where the \(^{}\) is the linear linear projection and \(}\) is the enhanced target feature sequence. We can abbreviate the feature aggregation process as:

\[}=[,]. \]

Note that when \(=\), the \((,)\) explores contextual information within the feature sequence, _i.e._, acts as the self-attention mechanism. The above processes are implemented with the multi-head mechanism to enhance performance further.

### Adversarial Mining Transformer

#### 3.3.1 Overview

The proposed framework tailored for query-centric FSS consists of three procedures, _i.e._, 1) discriminative region localization, 2) local to global region expansion, 3) coarse to fine mask alignment. We roughly locate the object of novel class under a rough support guidance via nonparametric cosine similarity in procedure 1). The resulting incompleted region is expanded by the object miner \(G\) to cover the whole target in procedure 2). The detail miner \(D\) in procedure 3) is tasked with identifying local discrepancies between the ground truth and the expanded mask generated by \(G\), thereby aligning the coarse prediction in detail. We optimize the \(G\) and \(D\) via an adversarial process and forming the end-to-end AMNet as illustrated in Fig. 3. The details are as follows.

#### 3.3.2 Discriminative region localization

Considering the significant intra-class diversity between samples, we contend that support information is more suitable as overall guidance indicating the novel class rather than detailed reference. Giventhe support image features \(_{s}^{H W C}\) and corresponding mask \(_{s}^{H W}\), where \(H\) and \(W\) describe the feature size and \(C\) is the feature dim, we apply mask average pooling (MAP) to obtain the mean target feature \(_{h}^{1 C}\) that serves as the holistic support guidance, formally:

\[_{h}=(_{s},_{s}). \]

We exploit the \(_{h}\) to indicate the target region in the \(_{q}\) based on the cosine similarity:

\[_{q}=^{}(((_{},_{}))),^{}()=\{1,&x>\\ 0,&. \]

A relatively high threshold \(\) is set to locate the most class-relevant regions and suppress activation to backgrounds. In our experiment, \(\) is set to 0.7.

#### 3.3.3 Local to global region expansion

**Adaptive feature aggregation.** The high-confidence object regions \(_{q}^{H W}\) obtained by Eqn (5) are incomplete. We introduce the object mining transformer \(G\) to expand the local region to the entire target area based on the intra-object similarity. Specifically, \(G\) aims at aggregating the representative target features from the pseudo support to less discriminative object parts in the query, formally,

\[}_{q}=^{-1}([(_{}),(_{psd})]), \]

where the \(:^{H W C}^{HW C}\) is the spatial flatten operation. \(_{psd}\), which serve as the source sequence in Eqn (1), are essentially query features filtered by \(_{q}\):

\[_{psd}=_{q}_{q}. \]

Homogeneous feature guidance enables our aggregation to circumvent the effects of intra-class variance. Note that the original attention mechanism applies _Softmax_ activation along the source sequence dimension. Directly adopting this scheme in our aggregation makes the query background features inevitably attend to foreground features since all the non-zero features in the pseudo support belong to the foreground. Inspired by , we adjust to implement _Softmax_ along the axis of \(_{q}\). In this way, the discriminative object features are more likely to be aggregated target areas that share high intra-object similarities with \(_{psd}\).

**Cross-scale information transportation.** We observe that in many cases, the query image contains different objects with varying scales, which are to be segmented in other episodes. To handle this spatial inconsistency, we construct the \(G\) in a multi-scale form. Concretely, we follow  to establish the hierarchical query features \(\{_{q,l}\}_{l=1}^{L}\) with down-sampling and self-attention layers, in which

\[_{q}^{l}^{-l}-l}  C}, l=1,,L. \]

Figure 3: Illustration of the proposed AMForner. We approach the query-centric FSS with three procedures, _i.e._, discriminative region localization, local to global region expansion, and coarse to fine mask alignment. AMForner optimizes an object mining transformer and a detail mining transformer via an adversarial process to couple these procedures.

The corresponding pseudo support features\(\{_{psd,l}\}_{l=1}^{L}\) is obtained by the Hadamard product of \(\{_{q,l}\}_{l=1}^{L}\) and downsampled \(_{q}\). Then Eqn (6) is implemented independently in each scale to obtain the aggregated query features \(\{}_{q,l}\}_{l=1}^{L}\). Finally, we fuse the multi-scale aggregated query features in a top-down manner as down in , specifically,

\[}_{q,l}^{}=_{3 3}(_{1  1}(}_{q,l}+(}_{q,l+1 }))+(}_{q,l+1})). \]

The fused features from the last stage \(}_{q,1}^{}^{H W C}\) are exploited to predict the expanded target area \(_{e}^{H W}\) via a small convolution head. Benefiting from the adaptive feature aggregation and cross-scale information transportation in the object mining transformer \(G\), less discriminative target parts can be highlighted in the query image, forming the expanded object mask \(_{e}\).

#### 3.3.4 Coarse to fine mask alignment

Detail mining transformer \(D\) is designed to discriminate subtle differences between the ground truth \(_{gt}\) and the expanded object mask \(_{e}\) generated by \(G\), since \(_{e}\) adequately covers the object but still exhibits misalignments in fine-grained details, e.g., boundaries. By training \(G\) and \(D\) via an adversarial process, \(G\) is optimized to generate more accurate target masks approaching ground truth to fool \(D\), thus achieving coarse to fine prediction alignment.

To capture comprehensive details, \(D\) models multiple local proxies, each of which is tasked with exploring the object features respectively specified by \(_{e}\) and \(_{gt}\) to obtain a pair of local features. The most different pair is selected to output real/fake results. Concretely, we concatenate the learnable proxies as a feature sequence \(^{N C}\), where \(N\) denotes the number of proxies. We perform feature adaptive aggregation through the attention mechanism to construct local features, In specific,

\[_{f}=[,(_{}_{e})], \]

where the "fake" object features specified by predicted mask \((_{}_{e})\) serves as the source sequence of aggregation process. Note that the \(_{e}\) is not binarized. Similarly, local features originate from "real" object features are obtained by:

\[_{r}=[,(_{ }_{gt})]. \]

Finally, we calculate the cosine similarity among the real local features \(_{r}=\{_{f}^{i}\}_{i=1}^{N}\) and the fake ones \(_{f}=\{_{f}^{j}\}_{i=1}^{N}\). The most different pair \((_{f}^{k},_{r}^{k})\) is selected and fed into a fully-connected layer to predict the fake/real results for adversarial training. By this way, \(D\) is optimized to discriminate detailed local differences, while the \(G\) will generate more precise masks to fool \(D\) by adjusting itself.

Since there is no explicit supervision, different proxies may focus on the same object part. We impose a diversity loss to avoid this degradation by expanding the discrepancy among local features:

\[_{div}=_{i=1}^{N}_{j=1,i j}^{N}( _{f}^{i},_{f}^{j}}{_{f}^{i}_{2}_{f}^{j}_{2}}+_{r}^{i},_{r}^{j}}{_{ r}^{i}_{2}_{r}^{j}_{2}}). \]

The intuition of Eqn (12) is trivial. If different proxies focus on the same object region, \(_{div}\) will be large and adjust the learning of proxies.

#### 3.3.5 Training and Inference

**Training loss.** Our architecture consists of a generative part, _i.e._, object mining transformer \(G\) and a discriminative part, _i.e._, detail mining transformer \(D\). The \(D\) judges whether the mask is real (ground truth) or fake (generated by _G_) by mining the detailed features of the object framed by the masks. To fool \(D\), \(G\) is supposed to predict a more accurate mask approaching the ground truth. We alternately train two parts to achieve mutual promotion. When training \(D\), the parameters of \(G\) are frozen, and the loss function for \(D\) is formulated as:

\[_{d}=-((_{r}^{k}))-(1-( {}_{f}^{k}))+_{div}_{div}, \]

where the \(:\) denotes the fully-connected layers that output the real/fake results, and the \(_{r}^{k},_{f}^{k}\) denote the most different pair of local features from the object specified by ground truth \(_{gt}\) and the predicted mask \(_{e}\), respectively. \(_{div}\) denotes the weight of diversity loss and we 

[MISSING_PAGE_FAIL:7]

dataset  and additional annotations from SBD . Following previous works [14; 55], we equally divide the 20 categories into four splits, three of which for training and the rest one for testing. COCO-\(20^{i}\) is a larger benchmark based on MSCOCO dataset , the 80 categories of which are partitioned into four splits for cross-validation as down in . We randomly sampled 1000 episodes from the testing split for evaluation. Following common practices [37; 14; 55; 38], we adopt mean intersection-over-union (mIoU) and foreground-background intersection-over-union (FBIoU) as evaluation metrics.

### Implementation Details

We adopt ResNet-50 and ResNet-101  as the backbone network in our experiment. Following previous works [14; 7; 13], we concatenate the features from the \(3^{rd}\) and \(4^{th}\) blocks of backbone and exploit a \(1 1\) convolution layer to generate \(_{s}\) and \(_{q}\) of middle-level to avoid overfitting. The number of attention layers in the \(G\) and \(D\) are set to 1 and 2, respectively. We employ the same data augmentation setting as . Since the \(G\) and \(D\) of AMFormer are trained alternately, we increase the number of training epochs to 300 for Pascal-\(5^{i}\) and 75 for COCO-\(20^{i}\), and set the batch sizes as \(8\) and 4, respectively. AdamW  optimizer with poly learning rate decay is used to train both the \(G\) and \(D\). The initial learning rate is set to \(1e^{-4}\) and the weight decay is \(1e^{-2}\). It should be noted that we adopt a base learner to filter the categories that appear during the training process for a fair comparison with previous works [55; 13]. For more details please refer to the **Supplementary Material**. Our approach is implemented using PyTorch and all experiments are conducted on 4 NVIDIA GeForce RTX 3090 GPUs.

### Comparison with State-of-the-Art Methods

We present the comparison of our method with previous FSS methods on Pascal-\(5^{i}\) and COCO-\(20^{i}\) datasets in Table 2 and Table 3. It can be observed that the proposed AMFormer significantly outperforms previous advanced approaches and achieves new state-of-the-art results under all settings. Specifically, on Pascal-\(5^{i}\), our AMFormer achieves 70.4% and 73.2% mIoU when using ResNet-50 as the backbone for 1 -shot and 5-shot settings, surpassing the most competitive HDMNet  by 1.0% and 1.4%, respectively. With ResNet-101 backbone, our method outperforms the previous best results  by 2.8% (1-shot) and 1.6% (5-shot). We can obtain additional improvement when using larger backbone network, which demonstrates the scalability of the AMFormer. We attribute this performance gain to better intra-object similarity within the more informative features. As for the more complicated COCO-\(20^{i}\), our approach also exhibits superior performances compared to other methods, demonstrating its competitiveness on complex data. Besides, Table 4 gives the comparison with previous methods in terms of FBIoU on Pascal-\(5^{i}\) using ResNet-50 backbone. AMFormer also outperforms all of the previous works by a considerable margin. Qualitative results are shown in Figure 4, please refer to **Supplementary Material** for analysis.

   \#Part & 4 & 6 & 8 & 10 & 12 & 14 \\  mIoU & 70.7 & 71.0 & 71.2 & **71.3** & 71.2 & 71.2 \\   

Table 6: Performance comparison on \(1^{st}\) split of varying the number of local proxies.

\) with ResNet-101 backbone to analyze each component of the proposed AMFormer. Note that the first line of Table 5 is the result of our ablation baseline. The baseline adopts self-attention within the query features for feature parsing, and cross-attention to aggregate support information into query features as done in .

**Effectiveness of object mining transformer \(G\).** We first construct a naive single-scale \(G\) as the \(2^{n}d\) row of Table 5. We can observe a significant performance lift, _i.e._, 1.5% in mIoU. This improvement demonstrates the effectiveness of the proposed query-centric strategy, which is built upon intra-object similarity and thus is less affected by intra-class diversity. The multi-scale implementation of \(G\) further brings a 3.4% improvement in mIoU, and it already achieves a decent performance. It shows the importance of multi-scale feature aggregation in dealing with objects with dramatically changing scales in the query image.

**Effectiveness of detail mining transformer \(D\).** The comparison between the \(3^{rd}\) and the \(5^{th}\) row of Table 5 shows that the combination of \(D\) improves the performance by 1.2% mIoU on the basis of \(G\). We attribute this performance gain to the exploration and distinction of local features in the \(D\), which encourages \(G\) to pay more attention to these ambiguous regions, _e.g._, object boundaries. Compared with the pixel-level supervision given by Cross-entropy loss, the proposed part-level adversarial training can incorporate local region context information to guide accurate segmentation. Note that without \(_{div}\), the performance improvement brought by \(D\) drops to 0.2%. This phenomenon is reasonable because in the absence of \(_{div}\), local proxies tend to degrade to focus on the same region, leaving some details unexplored.

**Investigation of the local proxies.** We first visualize the region activated by the learnable proxies to analyze what they mainly focus on. As shown in Figure 5, we observe that the highlighted area mainly lies on the boundary of the target and different proxies correspond to different directions. It confirms that the local proxies can well capture the local misalignment of the relatively coarse prediction from \(G\), and then \(G\) is optimized to pay more attention to these ambiguous areas under the direction of \(D\). In addition, we investigate the impact of the number of proxies on performance. As reported in Table 6, using more proxies can gradually improve the performance until the number achieves 10. More proxies no longer bring additional improvement. This result is expected, as too many proxies would learn redundant patterns.

**Discussion on the query-centric FSS paradigm.** Since the FSS models are trained in the extremely low data regime

Figure 4: Qualitative results from different stages.

with the backbone not optimized, the feature space is not well aligned for novel classes. In this situation, the novel class data distribution usually has low coverage in the feature space, _i.e._, object features of the same category but different image instances may be far apart. On the contrary, as we can observe in Table 8, pixel features within the same object are closer to each other than those across objects. In a nutshell, intra-object similarity is more reliable than intra-category but inter-object similarity. As shown in Figure 6, we visualize the attention weight of query features between support target and pseudo support, respectively. It shows that support targets tend to mistakenly activate background categories, while the pseudo support can well excavate the full object attribute to intra-object similarity.

Owing to the reduced reliance on support information, query-centric FSS methods could achieve remarkable performance with more weak support annotations. Table 7 shows the results of the proposed AMFormer on the first split of Pascal-\(5^{i}\) with bounding boxes or scribbles as support labels. The promising results demonstrate the feasibility of more general FSS segmentation models.

### Broader Impact and Limitations.

We proposed a novel query-centric FSS paradigm that shifts the research focus from support to query features. This is a new perspective that may inspire the development of more general FSS models that can be adopted in different tasks such as video object segmentation  or open-vocabulary segmentation . Although our AMFormer achieves remarkable performance, the number of training epochs is larger than some of previous approaches since the \(G\) and \(D\) in the AMFormer are trained alternately.

## 5 Conclusion

In this paper, we propose a novel query-centric FSS method, _i.e._, Adversarial Mining Transformer (AMFormer), which can achieve accurate query segmentation with only rough support guidance. Extensive experimental results demonstrate the superiority of our method. The decent performance with weak support labels also demonstrates the potential of the query-centric FSS paradigm.

## 6 Acknowledgments

This work was partially supported by the National Defense Basic Scientific Research Program of China (Grant JCKY2021601B013).