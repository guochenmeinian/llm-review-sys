# On the Adversarial Robustness of Benjamini Hochberg

Louis L Chen

Operations Research Department

Naval Postgraduate School

Monterey, CA 93943

louis.chen@nps.edu

&Roberto Szechtman

Operations Research Department

Naval Postgraduate School

Monterey, CA 93943

rszechtm@nps.edu

&Matan Seri

Operations Research Department

Naval Postgraduate School

Monterey, CA 93943

matan.seri@gmail.com

website: [https://louislichen.github.io/](https://louislichen.github.io/)

###### Abstract

The Benjamini-Hochberg (BH) procedure is widely used to control the false detection rate (FDR) in multiple testing. Applications of this control abound in drug discovery, forensics, anomaly detection, and, in particular, machine learning, ranging from nonparametric outlier detection to out-of-distribution detection and one-class classification methods. Considering this control could be relied upon in critical safety/security contexts, we investigate its adversarial robustness. More precisely, we study under what conditions BH does and does not exhibit adversarial robustness, we present a class of simple and easily implementable adversarial test-perturbation algorithms, and we perform computational experiments. With our algorithms, we demonstrate that there are conditions under which BH's control can be significantly broken with relatively few (even just one) test score perturbation(s), and provide non-asymptotic guarantees on the expected adversarial-adjustment to FDR. Our technical analysis involves a combinatorial reframing of the BH procedure as a "balls into bins" process, and drawing a connection to generalized ballot problems to facilitate an information-theoretic approach for deriving non-asymptotic lower bounds.

## 1 Introduction

Multiple testing has broad applications in drug discovery, forensics, candidate screening, anomaly detection, and in particular, machine learning. Indeed, recent works , in nonparametric outlier detection, _out-of-distribution detection_ (OOD), and one-class classification have all adopted multiple testing methodology in developing principled decision rules with statistical guarantees. In fact, the Benjamini-Hochberg (BH) multiple testing procedure, widely used to control the _false detection rate_ (FDR), is either used or modified in all these recent methods. Considering this FDR control could be relied upon in some critical (safety/security) contexts, for which false positives incur costs, we investigate its adversarial robustness.

Adversarial corruption presents a challenge to statistical methodology, and is a modern-day concern due to not only the ease with which high volumes of data can now be accessed/processed but also the increasingly widespread use of statistical procedures. This threat poses vulnerabilities to machine learning tasks like OOD, which would aim to fortify security systems like fraud detection .

Manipulation of data and experimental results are common means by which incorrect conclusions can be reached. Worse, strategic perturbation can dramatically decrease the fidelity of the models and methods used. A burgeoning field of adversarial corruption has gained traction in recent years to meet this concern, most notably in the area of (deep) machine learning; see, for example, [27; 16; 20]. In this work we address adversarial corruption in hypothesis testing, specifically in the large-scale context in which the primary focus is on the aggregate metric: FDR.

BH  is one of the most widely used multiple testing procedures, which upon input of a collection of p-values, outputs a rejection region ensuring that the FDR is no greater than a user-defined threshold \(q(0,1)\). This control of FDR holds under independently generated p-values - as well as some restricted forms of dependency like _positive regression dependent on a subset_ (PRDS)  - but it generally holds without strong assumptions on the alternative distributions. This degree of distributional robustness, however, could be said to come at the cost of adversarial robustness, as we show in this work.

### Literature Review

Although OOD methods [23; 12; 21; 22] are often complex and not always supported by statistical guarantees, conformal inference has made possible the use of one-class classifiers to generate conformal p-values for which OOD can now be conducted via multiple testing. This has led to the adoption of the BH procedure in OOD. Indeed,  leverages the FDR control afforded by BH over conformal p-values (shown to be PRDS) to test for outliers. More precisely, given a test set of observations for which we wish to identify as inliers or outliers (out of distribution), a conformal p-value is generated for each observation, which is then processed by BH to decide which are likely outliers. We refer the reader to [18; 28] for other recent works along this vein.

In recent years, concerns have risen over the possibility of adversarial manipulation of statistical methodologies. This manipulation commonly occurs at the level of data collection and training, often invalidating the assumptions made regarding how data is drawn, but it can also occur at test time. There is a growing literature on _adversarial robustness_, which is concerned with securing statistical methods like (deep) machine learning [27; 16; 20], linear regression , M-estimation , and online learning [26; 17; 1]. In particular,  considers contamination models that incorporate (adaptive) adversarial perturbation of up to an \(-\) fraction of drawn data. Indeed, we adopt this modeling in our own study - see (c-Perturb). As well, a similar concept to the notion of adversarial robustness that we adopt in this paper is one the literature refers to as _perturbation resilience_. Generally speaking, a problem instance is called \(-\) perturbation resilient when despite a degree (parameterized by \(\)) of perturbation to the instance, the optimal solution does not change. First introduced in  for combinatorial optimization (in particular, MAX-CUT), the concept has since also inspired research into devising resilient unsupervised learning, particularly in clustering [4; 3; 2].

With respect to the hypothesis testing literature, there are recent adversarial robust studies focused on simple  and sequential hypothesis testing  from a game theoretic perspective, in which protection of statistical power, risk, or sample size from corruption is of chief concern. Complementing the adversarial robust perspective are several distributionally robust studies, in which the data-generating distribution is known only to lie in a parametric family. Recent works include [11; 24; 15] which focus on test risk in single and sequential hypothesis testing settings employing uncertainty sets of distributions of fixed distance (e.g. Wasserstein, phi-divergence) for the null and alternative hypotheses. In contrast to these works, this paper is focused on FDR, not individual test risk. Furthermore, distributional robustness is not equivalent to the perturbation-robustness that this paper and other adversarial robust studies seek in general. Indeed,  shows that the BH procedure's FDR control exhibits a distributional robustness to possible dependence between null and non-null hypotheses. On the other hand, our work would illustrate that, distributional robustness aside, BH can lack adversarial robustness.

### Preliminaries

Let \(:=\{1,,N\}\), where \(N_{+}\), be a finite set for which each member \(i\) denotes a binary hypothesis test deciding between a null and alternative hypothesis. Further, there exists a partitioning, \(=_{0}_{1}\), such that the correct decision for test \(i\) is either null if \(i_{0}\), or alternative if \(i_{1}\). Here, \(_{0}\) and \(_{1}\) are the (unknown) sets of null and alternative test indices, respectively;consequently, for any test \(i\), the correct decision (i.e. set membership) is unknown to the decision maker. In fact, while the number of tests \(N\) is known (and large, on the order of thousands), neither \(N_{0}:=|_{0}|\) nor \(_{0}:=}{N}\) is known to the decision maker, although \(_{0} 0.90\) "is reasonable in most large-scale testing situations" - (, p. 285).

For each test \(i\), p-value \(p_{i}\) is randomly generated (independent of all other \(p_{j}\), \(j i\)), which we model as a draw from either \(U(0,1)\) when \(i_{0}\) (\(p_{i}\) then referred to as a _null p-value_) or some alternative distribution \(^{1}_{i}\) on \(\) when \(i_{1}\) (\(p_{i}\) then referred to as an _alternative p-value_). A multiple-testing algorithm \(\) takes as input a randomly generated collection of p-values \(p=\{p_{i}\}_{i}\) and outputs for each test \(i\) a determination \((i)\{0,1\}\) with \((i)=1\) iff the determination is to reject the null hypothesis (i.e., claim \(i_{1}\)), or sometimes referred to as "make a discovery" for the \(i\)-th test. With \(a_{p}:=_{i_{0}}(i)\) denoting the number of false discoveries, and \(R_{p}:=|^{-1}(1)|\) denoting the number of rejections/discoveries made, we refer to \(FDP[;p]:=}{R_{p} 1}\) as the false detection proportion summarizing \(\)'s decisions on p-values \(p\), where \(x y\) is shorthand for \((x,y)\) for any \(x,y\). We refer to its expectation with respect to the random generation of \(p\) as the _false detection rate_, \(FDR():=_{p}FDP[;p]\).

In this work, we focus on the Benjamini Hochberg procedure, a widely-used multiple-testing algorithm.

### The Benjamini Hochberg (BH) Procedure

Given a collection of p-values \(p=\{p_{i}\}_{i}\) and desired control level \(q(0,1)\) to bound FDR, the BH procedure \(BH_{q}\) operates as follows:

1. The p-values are sorted in increasing order, \(p_{(1)} p_{(2)} p_{(N)}\).
2. The index \(i_{}:=i[0,N]_{}:p_{(i)} i}\) is identified, with \(p_{(0)}:=0\).
3. Reject the tests corresponding to the smallest \(i_{}\) p-values: \(p_{(1)},p_{(2)},,p_{(i_{})}\).

\(BH_{q}\) provides provable FDR control at the level of \(q\) without any assumptions on the alternative distributions \(\{^{1}_{i}\}_{i_{1}}\).

**Lemma 1.1** (Theorem 4.1 from ).: _If every null p-value is super-uniform, equiv., \(p_{i}^{0}_{i} U(0,1)\) for all \(i_{0},\) and the collection is jointly independent, then regardless of the collection of alternative distributions \(\{^{1}_{i}\}_{i_{1}}\),_

\[FDR(BH_{q})=_{0}q q,\ \ \ \  q(0,1). \]

_Remark 1.2_.: In fact, the assumption of joint independence of the null p-values can be relaxed to a form of dependency known as PRDS - see  for this generalization of Lemma 1.1.

### The Adversary and the c-Perturbation Problem

We model an (_omniscient_) adversary with knowledge of \(_{0}\), \(_{1}\), and that knows the decision maker's choice of control level \(q\). The adversary receives the p-values \(p=\{p_{i}\}_{i=1}^{N}\)_after_ they are generated but _before_ they are received by the decision maker, or before test time. Given the ability to perturb \(c 1\) p-values, the adversary solves

\[_{p^{}:|p-p^{}|_{0} c}FDP[BH_{q};p^{}],\] (c-Perturb)

where \(p^{}\) denotes the p-values derived from an adjusted collection of p-values \(p^{}=(p^{}_{i})_{i=1}^{N}\). In words, the adversary finds the perturbation of at most \(c\)-many p-values before the execution of \(BH_{q}\) so as to maximize the _adversarially-adjusted_ false detection proportion \(FDP[BH_{q},p^{}]\). Perturbation of p-values is implicitly the result of data perturbation, and we refer to both Remark 4.6 and Section 5.2 for examples and experiments involving direct perturbation of data.

While we assume omniscience for the adversary throughout, we will briefly address modifications in analysis for an _oblivious_ adversary that has no knowledge of \(_{0}\), nor \(_{1}\). Indeed, our algorithms to be presented can be modified naturally for implementation by an oblivious adversary (see comments in Section 3); further, there is nearly equivalent performance when \(_{0}\) is large, as is typical. Hence, it is for the sake of brevity that we omit explicit analysis of the oblivious adversary.

### Main Results

Intuitively, the effect of a small number of p-value perturbations becomes insignificant in settings where a large number of tests are rejected (see Theorem 3.2). This happens, for instance, when either the number of tests \(N\), or the control level \(q\), or the distance (e.g. KL-divergence) between the null and alternative distributions, is large. For this reason, we focus on results that are non-asymptotic in the number of tests \(N\).

In Section 3, we present the algorithm INCREASE-c that uses strategic increases to \(c\) null p-values to induce expansion of the BH rejection region. We also present an efficient, optimal algorithm MOVE-1 (Appendix Section 7.2) for the adversary's maximization of FDR with at most one (i.e. \(c=1\)) p-value perturbation.

In Section 4 we discuss the adversarial robustness of BH through study of the adversarial adjustments to FDR by the INCREASE-c algorithms, revealing where its control is and isn't adversarially robust.

In Section 5 we provide accompanying numerical experiments on i.i.d. as well as PRDS p-values.

## 2 BH as Balls into Bins

In this section we will establish important notation for the discussions to follow. We reduce the real line to a collection of \(N+1\) "bins". \(N_{0}\) and \(N_{1}\) balls will each be assigned to one of these bins independently of each other, from discrete distributions that are specified in the next subsection. The main motivation for this reduction is to facilitate discussion of effective perturbations in Section 3, and for the technical analysis in Section 4.

### The Balls into Bins System

We partition the segment \(\) into \(N\) equiprobable segments that will be referred to as _bins_. We define the \(i\)-th bin \(B_{i}:=\{p:(i-1) p<i\}\), for \(i=1,,N\). What remains forms bin \(N+1\), i.e., \(B_{N+1}:=\{p:1 p 1-q\}\). For shorthand, we write \(B_{1:i}:=_{i=1}^{i}B_{l}=\{p:0 p<i\}\), Finally, we write \(B_{i}^{0}:=|B_{i}\{p_{j}\}_{j_{0}}|\) and \(B_{i}^{}:=|B_{i}\{p_{j}\}_{j}|\) for bin \(i\)'s, respectively, _null-load_ and _total load_. The _alternative- load_\(B_{i}^{1}\) is defined analogously, as are \(B_{1i}^{0}\)\(B_{1i}^{}\), and \(B_{1i}^{1}\).

Rejection Count:Borrowing terminology from the classic _balls into bins_ problem of probability theory , this framework facilitates a re-interpretation of the random drawing of p-values as balls being randomly placed into an ordered collection of bins, enumerated 1 up to \(N+1\). Framed in this way, we see that \(BH_{q}\) operates by identifying the _rejection count_

\[=i[0,N]_{}:B_{1:i}^{}=i}, \]

which corresponds to the largest collection of consecutive bins \(1,,i\) that collectively contain precisely \(i\) balls, so that \(BH_{q}\) rejects all tests with p-values lying in the first \(\) bins. The case \(=0\) corresponds to rejecting no tests. In fact, \(\) is a stopping time under a filtration \(\) that we define next.

Filtration \(=\{_{i}\}_{i=0}^{N}\):Let \(:=^{N}\) be a sample space with the classical Borel \(\)- algebra \(\) and (with slight abuse of notation) probability measure \(:=(_{i_{0}}U(0,1))_{i _{1}}_{i}^{1}\). We define a filtration beginning with \(_{N}:=(B_{N+1}^{},B_{N+1}^{0})\), and continuing inductively (\(N\) towards \(0\)), let \(_{i}\) be the \(\)-algebra generated by \(\{B_{i}^{}\}_{i=i+1}^{N+1}\) and \(\{B_{i}^{0}\}_{i=i+1}^{N+1}\). In words, this filtration corresponds to what is cumulatively learned about the bin loads (null and total) upon examination of the bins in sequence starting with bin \(N+1\) and concluding with bin \(1\), assuming each observed p value comes with correct identification of whether or not \(i_{0}\).

We note the fact that for \(>i\), it follows that \(E^{0}}{i}_{}=E ^{0}}{i}^{0}}{}=^{0} }{}\) a.s., so that \(^{0}}{N},^{0}=1}{N-1},,^{0}}{1}\) form a martingale sequence adapted to the filtration. This fact will prove useful when combined with the optional stopping theorem to facilitate several results in this work.

Under this lens, the adversary's (algorithmic) task reduces to reshuffling p-values among the bins, and in Section 3 we demonstrate there are indeed simple, tractable ways of performing this to manipulateBH, with potentially great effect on FDR control. The key insight is that there exist alternative stopping times that present alternative rejection counts (/regions) that can break FDR control.

## 3 Adversarial Algorithm: INCREASE-c

Throughout this section, we don the role of the adversary and study the c-Perturb problem, in which we are given \(q(0,1)\), a realized collection \(p=\{p_{i}\}_{i}\) (along with the labels of null or alternative for each \(p_{i}\)), and a budget \(c 1\), and our task is to produce a perturbed collection \(p^{}\). Toward this, we focus on a procedure called INCREASE-c that despite its sub-optimality (see Appendix Section 7.2) is intuitive and simple to execute; further, as theoretical and empirical analysis in sections 4 and 5 respectively show, it has strong performance in expectation.

We begin by defining a random variable that is a stopping time adapted to \(\); given an integer \(c 1\), let

\[_{+c}:=\{i[c,N]_{}:B^{}_{1: i}=i-c\}&B^{0}_{N+1} c\\ &B^{0}_{N+1}<c, \]

and we choose to write \(_{+}\) in place of \(_{+1}\).

Increasing the Rejection CountThe interest in \(_{+c}\) is that if we moved any selection of \(c\) null p-values from bin \(N+1\) into bin \(_{+c}\) (in fact any bin \(i_{+c}\)), then \(BH_{q}\) would output a new, increased rejection count \(_{+c}\). We formally study this in Section 4. In the meantime, we comment on the increase \(_{+c}-\), which is a difference between two stopping times

It is easy to see that \(_{+c}- c\) whenever \(B^{0}_{N+1} c\); hence, the increase in the rejection count is at least \(c\), but possibly more. We provide a stronger lower bound on this increase by utilizing the ratio between the number \(B^{0}_{k+2:N}\) of nulls not rejected by \(BH_{q}\) and the number \(N-(+1)\) of bins left outside of the \(BH_{q}\) rejection region in the case of no corruption. Computational experiments indicate comparable performance of this bound with those of simulations presented in Section 5's Table 1.

**Theorem 3.1**.: _If \(c 1,\) then_

\[[_{+c}-\|B^{0}_{N+1} c][_{k+2:N}}{N-(k+1)}\ \ B^{0}_{N+1} c ]}+1 \]

_for any collection of alternative hypothesis distributions \(\{^{1}_{i}\}_{i_{1}}\)._

INCREASE-c runs as follows:

1. IF \(B^{0}_{N+1} c\), then move the largest \(c\) (ties broken arbitrarily) in the (N+1)-th bin to bin \(_{+c}\).
2. ELSE leave the p-values unperturbed.

It in fact suffices for the \(c\)-many p-values to be placed in any bin \(i_{+c}\). We remark that since an oblivious adversary cannot discern null-drawn from alternative-drawn in the collection \(p\), INCREASE-c as written is unimplementable in such a case. Hence, for the oblivious adversary, we modify INCREASE-c's criterion to \(B^{}_{N+1} c\) and have the oblivious adversary now take the \(c-\)many p-values uniformly at random from among the p-values in the \((N+1)\)-th bin. Intuitively, this modification for the oblivious adversary should yield nearly \(c\) null p-values being moved (on average) just as in the non-oblivious case, assuming the proportion of nulls among the \(B^{}_{N+1}\) - many p-values is high, as a typically large \(_{0}\) would entail.

We conclude this section with a characterization of the average increase in FDR, denoted \(_{c}\) that INCREASE-c induces.

**Theorem 3.2**.: _Given \(c 1,\) let \(p_{+c}\) denote the perturbed form of \(p\) that INCREASE-c produces. Then the adversarially-adjusted FDR induced by INCREASE-c is_

\[FDP[BH_{q};p_{+c}]=FDP[BH_{q};p]+_{c},\]

_for any collection of alternative distributions \(\{^{1}_{i}\}_{i_{1}}\), where_

\[_{c}:=[_{+c}};B^{0}_{N+1} c]. \]In Section 4 to follow, we provide analytical lower bounds for \(_{c}\) as part of a discussion on BH's adversarial robustness. Section 5 presents computational experiments (e.g. Table 1). We remark that INCREASE-c is not optimal for all instances of c-Perturb; indeed, for \(c=1\), we present a provably optimal algorithm MOVE-1 in Appendix Section 7.2, which in contrast to INCREASE-1 sometimes induces a reduced rejection count. However, INCREASE-c remains a formidable adversarial procedure, as the results of Section 5 demonstrate on not only i.i.d. p-values but also PRDS conformal p-values.

## 4 Theoretical Analysis: Performance Guarantees and Insights into Adversarial Robustness

BH's FDR control - Lemma 1.1 - is (distributionally) robust in the sense that it holds no matter the alternative distributions \(\{_{i}^{1}\}_{i_{1}}\). However, as Theorem 3.2 indicates, the degree to which this control can withstand data perturbations at test time, i.e., its adversarial robustness, very much depends on \(\{_{i}^{1}\}_{i_{1}}\).

Recalling Lemma 1.1, we may assume without loss of generality that no alternative distribution \(_{i}^{1}\) stochastically dominates \(U(0,1)\) (equiv., \(_{i}^{1} U(0,1)\)). That being said, the "degree" to which the alternative distributions \(\{_{i}^{1}\}_{i_{1}}\) are (stoch.) dominated by the null distribution \(U(0,1)\) (equiv., \(_{i}^{1} U(0,1)\)) is critical. We briefly preview two regimes of special interest for which each of the next two subsections cover.

**High sub-uniformity:** When the alternatives are sub-uniform \(_{i}^{1} U(0,1)\) for all \(i_{1}\), and highly so, such that for all \(i_{1}\) it holds that \(_{i}^{1}(p_{i}<) 1\) for some small \(>0\), then it follows that \(\) is large and \(B_{1:}\) should contain most alternative p-values. Consequently, in order for INCREAES-c to induce any sizeable increase to the FDR, the adversary will need to expand the BH rejection region significantly so as to introduce a commensurate number of nulls. Table 1 indicates \(c\) may need to be quite large to make a dent in FDR control. This message is made more precise in Theorem 4.1.

**Low sub-uniformity:** As we will see, when the alternative p-values are barely dominated by \(U(0,1)\), \(_{c}\) can be rather large. In fact, in the special case that there is no dominance such that \(_{i}^{1}=U(0,1)\) for all \(i_{1}\), a strikingly vulnerable state occurs with high probability. Indeed, in this case where nulls and alternatives are virtually indistinguishable, \(BH_{q}\) (in fact any \(\)) admits an FDR of \(_{0}\) whenever any rejections are made (i.e., \([FDP[BH_{q};p]]\| 1]=_{0}\)) so that \(BH_{q}\) accordingly compensates by making no rejections with high probability (\((=0)=1-q\)), which follows by the distributional robust control (1) from Lemma 1.1. But those times when \(=0\) is precisely when INCREASE-c's simultaneous expansion of the rejection region and injection of nulls into this region is most damaging. That this event and other similarly vulnerable events occurs with high probability is the fault of the distributional robustness. This message is made rigorous in the forthcoming Theorem 4.5.

### Case of High Sub-Uniformity in Alternatives \(\{_{i}^{1}\}_{i_{1}}\)

If \(_{i}^{1} U(0,1)\) for all \(i_{1},\) with \(_{i}^{1}(p_{i}<) 1\) for some small \(>0\), then it is clear that the number of alternatives rejected by \(BH_{q}\) should be nearly the maximum number \(N_{1}\) of correct rejections possible (i.e., \(B_{1:}^{1} N_{1}\)) with high probability, limiting any potential impact of INCREASE-c.

The following bounds are formulated to elaborate on such dynamics in this case of large separation between alternatives and nulls, for which the event \([B_{1:c}^{1}=N_{1}]\) has probability close to 1.

**Theorem 4.1**.: _If \(c 1,\) then_

\[_{c}(B_{1:c}^{1}=N_{1}) [+B_{1:N_{1}+c}^{0}}\|B_{N+1}^{0} c]+1-(B_{1:c}^{1}=N_{1})\]

_and_

\[[_{+c}\|B_{N+1}^{0} c] +c)(B_{1:c}^{1}=N_{1})}{1- [^{0}}{N}\|B_{1:N}^{0} N_{0}-c]}. \]In words, for fixed \(c\), as the alternative distributions concentrate more and more on \(0\), it follows that \((B^{1}_{1:c}=N_{1}) 1,\) so that the effect \(_{c}\) of INCREASE-c on BH's FDR is dampened. And this occurs despite the fact that the increase \(_{+c}-\) in rejection count produced by INCREASE-c consists of mostly the introduction of nulls, and tends to a magnification of \((N_{1}+c)\) by at least a factor of the inverse of \(1-[_{1:N}}{N}\|B^{0}_{1:N} N_{0}-c],\) which is straightforward to compute since \(B^{0}_{1:N} Binom(N_{0},q)\). We refer the reader to Section 5's Table 1 for simulations illustrating the above.

### Case of Low Sub-Uniformity in Alternatives \(\{^{1}_{i}\}_{i_{1}}\)

In the study of this regime, we aim to demonstrate that the adversarial increase \(_{c}\) can be rather large. We provide a lower bound \(L_{c}\) on \(_{c}\) that will be a function of parameters \(q,N,N_{0}\), as well as the alternative distributions \(\{^{1}_{i}\}_{i_{1}}\).

#### 4.2.1 Lower Bounding \(_{c}\)

In view of \(5\), the event \([_{+c}=c]\) is clearly of significance in the computation of \(_{c}\). In words, this event describes the case that the \(BH_{q}\) rejection region captures nothing, and yet when the adversary successfully executes INCREASE-c the rejection will now capture only nulls - generating a false detection proportion of 1. Hence, we lower bound the adjustment \(_{c}\) of Theorem 3.2 by lower-bounding the probability of this event.

Our strategy: (1) first, characterize this probability under the special case that \(^{1}_{i}=U(0,1)\) for all \(i_{1}\); (2) second, to handle when \(^{1}_{i} U(0,1)\) for some \(i_{1}\), we translate the KL divergence of the resulting discrete, bin-assignment distributions into a bound via Pinsker's Inequality.

The key to the first step will be to recognize that when \(^{1}_{i}=U(0,1)\) for all \(i_{1}\), the vector of total loads \((B^{}_{1},,B^{}_{N})\) is exchangeable (i.e., its law is invariant under permutations), given \(B^{}_{1:N}\). Indeed, exchangeability, combined with the generalized Ballot Theorem of  yields the following result:

**Corollary 4.2**.: _Let \(n 1\), \(p,\) and \(x\) a non-negative integer such that \(0 x n\). If \(=(_{1},,_{n}) Multinomialx,(p, ,p)\), then \(_{}(_{r=1}^{n}[_{i=1}^{r}_{i}<r ])=1-.\)_

Armed with Corollary 4.2, we can begin to estimate the probability laws of \(\) and \(_{+c}\).

**Corollary 4.3**.: _If \(^{1}_{i}=U(0,1)\) for all \(i_{1}\), then \((=)=(-q}{1-q +}})(B^{}_{1:}=)\) for \(=0,,N,\) where \(0^{0}=1\), and \((B^{}_{1:}=)=}{N}}{N-}^{N-}.\)_

_If \(B^{0}_{N+1} c\), then \((_{+c}=c\ \ B^{0}_{N+1})=(1-)^{N_{1}}(1-)^{N_{0}-B^{0}_{N+1}}(1- -B^{0}_{N+1}}{N-c}-q}{N-cq})\)._

Next, we carry out the second step of our plan. Towards this, we make the following assumption.

**Assumption 4.4**.: Suppose the alternative p-values are independent and identically distributed, with common distribution \(^{1}\), i.e., \(\{p_{i}\}_{i_{1}}^{1}\). We write \(:=(1-q)-^{1}(p_{i} B_{N+1})\), and \(_{j}:=^{1}(p_{i} B_{j})-\), and we assume that \(^{1}(p_{i} B_{j})>0\) for all \(j[N]\), as well as \(^{1}(p_{i} B_{E:N})>0\) for arbitrary \(<N\).

This assumption not only reduces the notational burden (otherwise documenting \(N_{1}\) many alternative distributions) but it also allows the leveraging of KL divergences between the different bin assignment distributions implied by the alternative \(^{1}\) versus the null \(U(0,1)\).

**Theorem 4.5**.: _Suppose Assumption 4.4. Then_

\[_{c} L_{c}(q,N,N_{0},^{1}):=(1--_{1: c})^{N_{1}}[1-^{N_{0}}(1-_{c}-V_{c} )M_{c}+Z_{c}]\]

_where \(_{c}(q,N,N_{0},^{1}):=+[B^{1}_{c+1:N} ]\|B^{1}_{1:c}=0}{N-cq-N_{1:c}},\)\([B^{1}_{c+1:N}]\|B^{1}_{1:c}=0=N_{1} }}{N-cq-N_{1:c}},\)\(V_{c}(q,N,N_{0},^{1}):=[B^{1}_{c+1:N}]\|B^{1}_{1:c}=0 D_{KL}(^{1},c),\)_\[M_{c}(q,N,N_{0}):=-[(1- )^{-B_{N+1}^{0}};B_{N+1}^{0} c-1],\] \[Z_{c}(q,N,N_{0}):=(B_{N+1}^{0} c)(1- )^{N_{0}-[B_{N+1}^{0}\|B_{N+1}^{0} c] }[B_{N+1}^{0}\|B_{N+1}^{0} c]}{N-c}\] \[D_{KL}(^{1},c):=_{j}log(^{c}(q/N+_{j})}{(N-c)(q/N+_{j})})\]

_Remark 4.6_.: For a more concrete application/example, consider when the p-values \(\{p_{i}\}_{i}\) are derived from z-scores \(\{z_{i}\}_{i}\) via \(p_{i}=(Z>z_{i})\), where \(Z N(0,1)\), with null z-scores \(\{z_{i}\}_{i_{0}}\) i.i.d. \(N(0,1)\) and alternative z-scores \(\{z_{i} N(_{1}^{i},1)\}_{i_{1}}\) (with all \(_{1}^{i} 0\)). Indeed, under this framework, we may view the \(_{1}^{i}\) as the distance between \(_{1}^{1}\) and \(U(0,1)\).

Towards satisfying Assumption 4.4, we can assume throughout that there exists a nonnegative parameter \(_{1}\) such that the alternative parameters \((_{1}^{i},^{i})=(_{1},1)\) for all \(i_{1}\). Indeed, if every member of the collection \(\{_{1}^{i}\}_{i_{1}}\) is in reality only close to zero, then the forthcoming estimates (lower bounds) would provide close, conservative estimates when setting \(_{1}=\{_{1}^{i}:i_{1}\}\).

When \(_{1}>0\), it follows that \((_{1}):=(1-q)-((1-q)-_{1}}{_{1}} )>0\). As well, \(_{j}(_{1}):=((1-)-_{1}}{ _{1}})-((1-j)-_{1}}{_ {1}})-\). Intuitively, BH is adversarially robust (\(_{c}\) small) when the alternative distributions are "far" (\(_{1}>>0\)) from the theoretical null, and the opposite holds when they are "close" (\(_{1}=0\)) - see Figures 2 and 3.

## 5 Simulations and Data Experiments

In this section, we provide computations (performed in R and Python on a Macbook Air-M2 chip, 8GB memory, with no experiment time exceeding 5 minutes) to demonstrate the performance of the adversarial algorithm INCREASE-c. We demonstrate its performance through simulation on synthetic data to make comparisons to the theoretical estimates provided in Section 4. We then demonstrate its performance on a real-data experiment in outlier detection.

### INCREASE-c Simulations on Synthetic Data

#### 5.1.1 INCREASE-c Simulations on i.i.d. p-values

Following the framework from Remark 4.6, we simulated \(10^{4}\) replications of the following experiment: (1) \(N=1000\) p-values are generated, with \(\{p_{i}\}_{i_{0}}}{{}}U(0,1)\), and each \(p_{i}\) among \(\{p_{i}\}_{i_{1}}\) generated via \(p_{i}=1-(-_{1}}{1})\), with \(\{z_{i}\}_{i_{0}}}{{}}N(_{1},1)\); (2) \(FDP[BH_{q};p]\) and \(FDP[BH_{q};p_{+c}]\) are calculated. In Figure 1 each of the \(10^{4}\)- many (\(FDP[BH_{q};p]\), \(FDP[BH_{q};p_{+c}]\)) pairs are plotted. As can be seen, the vast majority of the pairs satisfy \(FDP[BH_{q};p_{+c}]>FDP[BH_{q};p]\), and, further, all pairs lie above the horizontal line situated at the level of the BH control level \(_{0} q=.09\), i.e, \(FDP[BH_{q};p_{+c}]>_{0} q\).

In Table 1, we present the effectiveness of INCREASE-c over ranges of corruption budget \(c\) and \(_{1}\) from small to large. As can be seen, when \(_{1}=0\), any amount of corruption budget \(c\) yields large post-corruption FDR \(_{z}FDP[BH_{q};z_{+c}]\). When \(_{1}>0\) grows, however, the budget \(c\) must correspondingly grow in order for there to be nontrivial post-corruption FDR. Finally, we note that for any fixed \(c\), the increase in rejection count \(_{+c}-\) is on the average larger when \(_{1}\) is larger. For experiments on non- i.i.d., PRDS p-values, we refer the interested reader to Section 5.2 or Appendix Section 7.4.

#### 5.1.2 INCREASE-1 Simulations versus Theoretical Bounds Under Small \(_{1}\)

In Figures 2 and 3 we illustrate how well the insights discussed in Section 4.2 capture the sensitivity of BH to adversarial perturbations when \(_{1}\) is near 0. Specifically, for each \(q\) in the grid \(\{.01,.02,,.99\}\), we computed the difference \(FDP[BH_{q};p_{+}]-FDP[BH_{q};p]\) across \(10^{3}\) replications of the setup as in Section 5.1.1, with the average of this difference being an estimate of \(_{1}\). The plot of these \(_{1}\) estimates with respect to \(q\) is then compared with the plot of our lower bound \(L_{1}\) as a function of \(q\).

Figures 2 and 3 illustrate that the stricter the control, i.e., the smaller \(q\) is, the more effective INCREASE-c becomes. In fact, the bound indicates high vulnerability for the typical use case

[MISSING_PAGE_FAIL:9]

### Training

We begin by training an unsupervised decision-tree-based algorithm on a training set. From the set \(n_{0}\) of genuine transactions, we uniformly at random select a subset \(n_{train} n_{0}\) of size \(141,758\) to form a training set \(D^{train}:=\{X_{i}\}_{ien_{train}}\) upon which we train an isolation forest \(:^{30}_{+}\) using the R library isotree3, where, in principle, \((X_{i})\) returns an _isolation depth_ that is smaller if \(Y_{i}=1\) (i.e. is an outlier) and larger if \(Y_{i}=0\) (i.e. is an inlier)

### Calibration and (Adversarially-Perturbed) Testing

Then for each of \(10^{2}\) simulations, we uniformly at random selected a subset \(_{cal} n_{0} n_{train}\) of size \(141,657\) to form a calibration set \(^{cal}\{X_{i}\}_{i_{cal}}\) of strictly genuine transactions. As well, we uniformly at random selected a subset \(_{test,1} n_{1}\) of \(100\) fraudulent transactions to append to the \(900\) remaining genuine transactions comprising \(_{test,0} n_{0} n_{train}_{cal}\) to form a test set \(^{test}:=\{X_{i}\}_{i_{test}}\), where \(_{test}_{test,0}\ \ _{test,1}\). Finally, we transformed \(X_{i}_{i}(0,1)\) for each \(i_{test}\) via \(_{i}=_{cal}\{X_{i}\} S(X_{i})\}]}{| _{cal}|}\). The resulting collection of conformal p-values \(:=(_{i})_{i_{test}}\) is PRDS, as proven in , and hence the FDR control of Lemma 1.1 holds (see ). In contrast, upon executing INCREASE-c to generate a corresponding adversarially-perturbed collection \(_{+c}:=(_{+c,i})_{i_{test}}\), we obtain a collection for which BH's FDR control no longer holds.

### Experimental Results

We executed \(BH_{0.1}\), on both \(\) and \(_{+c}\), with an execution providing the decision for each \(i_{test}\) whether to report it as genuine (null) or fraudulent (alternative). We report the average (over the \(10^{2}\) simulations) false detection proportion (FDP) produced by \(BH_{0.1}\), i.e., both \(E[FDP[BH_{0.1};]]\) and \(E[FDP[BH_{0.1};_{+c}]]\) (for \(c=1,5,10\)). As well, we report the average number of alleged frauds \([]\) and \([_{+c}]\). As Table 2 indicates, although the method of  can ordinarily control the FDR below the explicit \(0.10\) level, INCREASE-c has the ability to push the FDR above this control level.

## 6 Conclusions

This is the first work to consider adversarial corruption of the popular Benjamini Hochberg multiple testing procedure to break its FDR control. While BH may exhibit robustness when the alternative distributions are "far" from the null, it exhibits great sensitivity in practical cases when the alternatives are "closer" to the null. In such cases, with the modification of few p-values (as few as one), the attacker can increase the expected FDR well past the guarantee stipulated by the BH procedure. This study suggests some caution may be necessary when using BH, especially in safety-security settings. Numerical experiments support the analytical results. Finally, BH is but one member of the family of step-up multiple testing procedures, which generally entail rejection regions decided via a stopping time, which since our paper shows can be manipulated in the case of BH, it means other step-up procedures can be similarly prone.

  \(c\) & \(E[FDP[BH_{0.1};]]\) & \(E[FDP[BH_{0.1};_{+c}]]\) & \(E[]\) & \(E[_{+c}]\) \\ 
1 &.09 &.10 & 60.21 & 60.21 \\
5 &.08 &.17 & 48.69 & 57.12 \\
10 &.09 &.23 & 56.39 & 72.85 \\
20 & 0.09 & 0.31 & 58.12 & 89.06 \\  

Table 2: Credit Card Fraud Detection Experiment