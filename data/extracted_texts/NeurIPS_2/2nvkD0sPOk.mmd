# DEL: Discrete Element Learner for Learning 3D

Particle Dynamics with Neural Rendering

 Jiaxu Wang1 Jingkai Sun1,2 Junhao He1 Ziyi Zhang1

Qiang Zhang1,2 Mingyuan Sun3 Renjing Xu1

1 Hong Kong University of Science and Technology, Guangzhou, China

2 Beijing Innovation Center of Humanoid Robotics Co. Ltd, Beijing, China

3 Northeastern University, Shenyang, China

{jwang457, qzhang749, jsun444}@connect.hkust-gz.edu.cn

mingyuansun@stumail.neu.edu.cn

{junhaohe, ziyizhang, renjingxu}@.hkust-gz.edu.cn

###### Abstract

Learning-based simulators show great potential for simulating particle dynamics when 3D groundtruth is available, but per-particle correspondences are not always accessible. The development of neural rendering presents a new solution to this field to learn 3D dynamics from 2D images by inverse rendering. However, existing approaches still suffer from ill-posed natures resulting from the 2D to 3D uncertainty, for example, specific 2D images can correspond with various 3D particle distributions. To mitigate such uncertainty, we consider a conventional, mechanically interpretable framework as the physical priors and extend it to a learning-based version. In brief, we incorporate the learnable graph kernels into the classic Discrete Element Analysis (DEA) framework to implement a novel mechanics-integrated learning system. In this case, the graph network kernels are only used for approximating some specific mechanical operators in the DEA framework rather than the whole dynamics mapping. By integrating the strong physics priors, our methods can effectively learn the dynamics of various materials from the partial 2D observations in a unified manner. Experiments show that our approach outperforms other learned simulators by a large margin in this context and is robust to different renderers, fewer training samples, and fewer camera views.

## 1 Introduction

Simulating complex physical dynamics and interactions of different materials is crucial in areas including graphics, robotics, and mechanical analysis. While conventional numerical tools offer plausible predictions, they are computationally expensive and need extra user inputs like material specifications. In contrast, learning-based simulators have recently garnered significant attention as they offer more efficient solutions. Previous works primarily simulate object dynamics in 2D. They either treat pixels as grids  or map the images into low latent space  and predict future latent states. However, these 2D-centric approaches possess limitations. The world is inherently 3D, and 2D methods struggle to reason about physical processes because they rely on view-dependent features, and are hard to understand real object geometries. To address these, researchers have incorporated multi-view 3D perceptions into simulations such as Neural Radiance Field (NeRF)  which is an implicit 3D-aware representation. Some studies extract view-invariant representations and 3D structured priors by NeRFs to learn 3D-aware dynamics . They either represent the whole scene as a single vector or learn compositional object features by foreground masks. However, they require heavy computational demands and struggle with objects with high degrees of freedom.

Particle-based learned simulators show impressive results in modeling 3D dynamics. The success is mainly attributed to the popularity of Graph Neural Networks (GNNs). In general, objects are represented as particles that are regarded as nodes in graphs, and their interactions are modeled by edges. Previous studies [7; 8] adapt GNN to predict particle tracks and achieve good results. Recent research has made strides in improving GNN simulators [9; 10]. They require particle correspondences across times for training. However, 3D positions of particles across time are not always accessible and learning dynamics solely from visual input is still a big challenge. The reasons can be summarized as follows. Determining particle positions from 2D observations leads to uncertainty since different particle distributions can produce similar 2D images. Moreover, previous GNN-based simulators aim to learn how to infer the entire dynamics, which are fully uninterpretable and result in hard optimization. Several studies [11; 12] reconstruct 3D from 2D images and then learn from it, but they are not directly trained end-to-end with pixel supervision. One feasible way is to employ inverse rendering. For example, [13; 14] use NeRF-based inverse rendering to learn dynamics from 2D images. However, they are either constrained to simulate specific material or incapable of dealing with the 2D-3D ambiguities, thereby damaging their generalization ability. Furthermore, existing approaches only evaluate their methods on simple datasets. Their synthetic dataset often contained a limited variety of materials (usually rigid bodies), rarely involved collisions between objects, and featured very regular initial shapes.

To address the above challenges, this work incorporates strong mechanical constraints in the learning-based simulation system to effectively learn the 3D particle dynamics from 2D observations. Discrete Element Analysis (DEA) , also known as Discrete Element Method , is a traditional numerical method to simulate particle dynamics in mechanical analysis. This method computes interaction forces between particles to predict how the entire assembly of particles behaves over time. However, traditional DEA heavily relies on the user-predefined mechanical relations between particles, such as constitutive mapping or dissipation modeling, which often involve several material-specific hyperparameters. Moreover, the results often deviate from the actual mechanical responses because the constitutive equations are overly idealized.

In this work, we combine GNNs with the DEA theory to implement a physics-integrated neural simulator, called the Discrete Element Learner (DEL), aiming to enhance the robustness, generalization, and interoperability of GNN architectures. In detail, we use GNNs as kernels to learn the mechanical operators in DEA rather than adopting user-define equations. On the other hand, the graph networks only need to fit some specific physical equations in the DEA framework instead of learning the whole evolution of dynamics, which largely reduces the optimization difficulties. Therefore, combining the conventional mechanical framework and GNN can reduce the 2D-to-3D uncertainty and alleviate the ill-posed nature. The main contributions of this work can be summarized as follows:

* We propose a novel physics-integrated neural simulation system called DEL which incorporates graph networks into the conventional Discrete Element Analysis framework to effectively learn the 3D particle dynamics from 2D observations in a physically constrained and interpretable manner.
* We design the network architecture under the guidance of the DEA theory. In detail, we use learnable GNN kernels to only fit several specific mechanical operators in the classic DEA framework, instead of learning the entire dynamics to make GNNs and the DEA mutually benefit from each other, significantly reducing the ill-posed nature of this task.
* We evaluate our method on synthetic datasets that contains various materials and complex initial shapes compared to existing ones. Extensive experiments show that our method surpasses all previous ones in terms of robustness and performance.

## 2 Related Work

### GNN-based particle dynamics simulator

There has been many works [17; 18; 9; 19; 20; 21] to develop GNN-based particle simulators to predict 3D dynamical systems. This is because representing 3D scenes as particles perfectly matches the graph structure via particles as nodes and interactions as edges. GNS  shows plausible simulations on multiple materials by multi-step message passing. DPI  adds one level of hierarchy to the rigid and predicts the rigid transformation via generalized coordinates. EGNN  maintains the quivariance of graphs by passing scalar and vector messages separately, and explicitly assumes the direction of vector message passing along with the edges. SGNN  proposes the subequivariant simulator, which has a strong generalization to long-term predictions. Most of them are black-box models and non-interpretable, thus complicating the optimization. There are some works incorporating basic physical priors into neural networks [22; 23; 24; 25; 26], whereas they perform well either on toy examples or specific topologies such as rigid hinges. All the above-mentioned learned simulators require full 3D particle tracks as labels for training. They cannot learn from pixel-level supervision because of the large solution spaces caused by the 2D-to-3D uncertainties, which we experimentally proved in Section 4. Our approach reduces ambiguities by integrating GNNs into a mechanical analysis framework. Our method not only yields impressive results supervised by 3D labels but also effectively learns realistic physics under 2D supervision.

### Learning dynamics from 2D images

Learning dynamics from merely visual observations is vital for many domains. Previous works [1; 3] map images into low dimensional space and learn dynamic models to infer the evolution of latent vectors. However, the general latent approach [27; 28; 2; 29; 30; 31; 32; 33] makes things like pixel-level video prediction rather than real physical inference . The biggest reason is the gap between 2D observations and 3D worlds . To address this challenge, recent works consider 3D-invariant representation to build latent states. NeRF is used by  to encode multiview images as view-independent features. But it serves the whole scene as a single vector, and cannot handle scenes with multiple objects.  encodes compositional multi-object environments into implicit neural scatter functions, while it only handles rigid objects. Similarly,  and  use compositional implicit representation, but cannot simulate objects with large deformations. Some other methods [36; 37; 38] need additional signals, such as Lidar data. The 3D-aware latent dynamics also lack generalizability to unobserved scenarios and cannot work with complex topologies and varying materials. Moreover, latent dynamics models are fully non-interpretable.

Very recently, with the development of differentiable neural rendering, a few studies have attempted to train 3D dynamic models from visions via inverse rendering [13; 14; 39]. They bridge images and 3D scenes with a differentiable renderer to minimize the renderings and groundtruth. However,  and  can only simulate fluids because they require fluid properties as input. VPD learns 3D particle dynamics directly from images and can simulate various solid materials. However, it requires jointly training its own particle renderer and latent simulator, which leads to a black-box nature and is hard to be adopted by other renderers. Conversely, our DEL can seamlessly integrate into any point-based renderers with satisfactory performance and is physically interpretable as well as can simulate various materials in a unified manner.

## 3 Methodology

### Preliminaries and Problem Statement

This task is formulated as inferring particle dynamics via inverse neural rendering. Similar to other inverse graphics, the scene can be represented by 3D primitives, and then the dynamical module infers the future state of these primitives. Once this future state is inferred, it can be effectively transformed into visual images by neural renderers. The dynamical module can be trained from

Figure 1: The paradigm of the dynamics learning via inverse rendering. (a) Particles Initialization Process. The scene is initialized as particles. (b)Recurrent Dynamic Inference Process. The generated particle set is fed into a dynamic predictor to infer the next state iteratively.

the error between the renderings and observations. Figure 1 illustrates the general paradigm. In this formula, 3D scenes should be represented as particles, and then, the renderer should be able to render particles into images with a given camera viewpoint. According to the above discussion, we choose the Generalizable Point Field  (GPF) as our renderer, which can represent a 3D scene as particles, change its content by moving particles, and render images with arbitrary views. Notably, other particle-based renderers such as [41; 13] or recently prevailing , can also be used arbitrarily as long as they are fully differentiable and represent objects as particles. The renderer module can iteratively produce updated images after the dynamic module moves particles at each timestamp.

The dynamical module operates as a graph network simulator. Consider a physical system with N particles to represent M objects, the simulator models its dynamics by mapping the current state to consequent future states, usually the positions of particles. Assume \(X_{i}^{t}\) are particle states at time t, \(X_{i}^{t}\) usually includes the coordinate \(_{i}^{t}\), the velocity \(_{i}^{t}\) and particle's intrinsic attributes \(_{i}\) such as the material type and mass. The learnable GNN simulator \(S\) considers particles as nodes and dynamically constructs connections at independent time steps when the distance between two particles is smaller than a threshold (\(E=\{i,j:||_{i}-_{j}||_{2}<=r\}\)). The GNN maps all the information at the current state to the positions at the next timestamp by passing messages on the graph, i.e. \(_{i}^{t+1}=S_{}(_{i}^{t},_{i}^{t},_{i},E)\). Different GNN simulators mainly lie in the different designs of message-passing networks. As we claim in Section 1, the \(S_{}\)s in most previous approaches aim to learn the entire dynamics process, which leads to hard optimization and the risk of overfitting. Moreover, they are non-interpretable black boxes. Therefore, the learning target would be very ill-posed because the solution space is very large when only visual supervisions are given.

We propose a mechanics-encoded architecture that combines the GNN with the typical DEA to reduce uncertainty and improve interpretability. In the following section, we first introduce the general DEA method and its potential to be enhanced by the learning-based kernels. Second, we present how we incorporate the graph networks into DEA to replace the traditional operators.

### The General Discrete Element Analysis Theory

In this section, we introduce the general framework of Discrete Element Analysis, also known as the Discrete Element Method, and its drawbacks which potentially can be enhanced by our learnable kernels. Here we only cover the general knowledge that we need to design our architecture, we recommend readers refer to [15; 43; 16] for deeper knowledge of DEA. In the framework, the whole scene is represented as particles and the DEA is used to simulate the behavior and interactions of these particles. Generally, in this framework, the movement of an individual particle is governed by the Newton-Euler motion equation:

\[m_{i}}{dt^{2}}=_{j=1}^{n}(_{ij}^{p}+_{ij}^{v})+_{i}^{g} \]

where \(\) is the movement vector, \(m_{i}\) is the mass of particle \(i\). \(F_{i}^{g}\) refers to the gravity. \(F_{ij}^{p}\) and \(F_{ij}^{v}\) are the interaction forces between particle \(i\) and \(j\), the former marks potential interaction force, and the latter marks dissipative (viscous) contributions. The potential interactions primarily arise from physical contact between elements . The dissipative contributions take into account kinetic energy dissipation mechanisms concerned with the dispersion of elastic waves (this dissipation is general for all materials) . Given this context, the potential contributions to interactions assume a significant role while the dissipative contribution merely influences the energy dissipation within the system. Therefore, the fundamental problem is to formulate a general form of potential interactions between particles, which would apply to materials with different features of mechanical responses.

Besides, \(_{ij}^{p}\) and \(_{ij}^{v}\) can be decomposed into the normal and tangential directions, which are represented by the superscript \(n\) and \(t\) in Equation 2.

\[_{ij}^{p}=_{ij}^{pn}+_{ij}^{pt}_{ij}^{v}=_{ij}^{vn}+_{ij}^{vt} \]

Substituting Equation 2 into Equation 1 and omitting the gravity terms for simplicity, we can derive:

\[m_{i}}{dt^{2}}=_{j=1}^{N}(_{ij}^{pn}+ _{ij}^{vn})+_{j=1}^{N}(_{ij}^{pt}+_{ij}^{vt}) \]where the first term is the normal constituent and the second term is the tangential constituent. Here we discuss the potential interaction forces within the two directions respectively. According to , The \(_{ij}^{pn}\) can be considered as the composition of contact force \(f_{ij}^{cn}\) and bond force \(f_{ij}^{bn}\). The contact forces are activated when two particles physically contact and collide. The bond forces mean if the two particles belong to the same object, they are connected by a bond that will provide attraction or repulsion based on their relative positions to maintain the fundamental properties of the material. We depict the mechanism in Figure 2. Furthermore, in DEA, a physical quantity called intrusion scalar is commonly used to compute the two forces:

\[ d_{n}=(r_{i}+r_{j})-\|}-}\|_{2} \]

where \(r_{i},r_{j}\) are the radius of particle \(},}\). \( d_{n}>0\) means they contact and vice versa. We use visual aid Fig. 2(a) to depict \( d_{n}\) intuitively. The red hard sphere intrudes into the blue soft sphere in the figure. The deformation length on the blue surface refers to the \( d_{n}\). The normal contact force \(f_{ij}^{cn}\) should be related to the \( d_{n}\) because the particle tends to recover its initial shape. In addition, the direction of \(f_{ij}^{cn}\) is the normal direction between \(i\) and \(j\). On the other side, as stated in Figure 2(b), \(f_{ij}^{bn}\) acts as a linkage between two particles belonging to the same object, akin to a bond. \(f_{ij}^{bn}\) also relates to \( d_{n}\). According to the above discussion, the total normal potential interaction forces can be formulated as:

\[_{ij}^{n}=\{(_{c}^{n}( d_{n },A_{ij})+_{b}^{n}( d_{n},A_{ij}))&i,j_{k},\\ _{c}^{n}( d_{n},A_{ij})&i,j_{k}. . \]

where \(_{c}^{n},_{b}^{n}\) are two functions to map the \( d_{n}\) and \(A_{ij}=[A_{i},A_{j}]\) to the contact and bond forces respectively. \(_{k}\) is the Object k. Here \(A_{*}\) is the material properties in the particles' small surrounding vicinity. \(=_{i}-_{j}}{\|_{j}-_{i}\|_{2}}\) is the normal unit vector. In DEA, the \(_{c}^{n},_{b}^{n},A_{i},A_{j}\) usually require to be specified by users, which are often simple linear or polynomial functions. For example, the most simple way to compute the total interaction force is the linear spring model \(_{c+b}^{n}=k_{n}\). Some more complex functions such as Hertz-Mindlin (Eq. 6) are also commonly used.

\[F_{c}^{n}( d_{n})=E d_{n},F_{b}^{n}( d_{n })=k_{b}^{n} d_{n} \]

In Eq. 6, \(E,R,k_{b}\) are human-defined material parameters. However, the above-introduced handcrafted mapping functions only roughly approximate real cases and always deviate from the realistic natures of materials, leading to inaccurate simulations of DEA. Likewise, the tangential interactions can be analogous to the above. Notably, the normal direction contributes mostly to the total potential interactions because the tangential deformation is small due to the friction constraints . Therefore, general DEA often approximates it by the instantaneous displacement within a timestamp \( t\), i.e. \( d_{t}=||_{ij}^{t} t||_{2}\). \(_{ij}^{t}\) is the tangential velocity of \(j\) relative to \(i\).

\[_{ij}^{t}=_{c}^{t}( d_{t},A_{ij},||_{ij}^ {n}||)+_{b}^{n}( d_{t},A_{ij},||_{ij}^{n} ||) \]

Similar to \(\), the \(=_{ij}^{t}/||_{ij}^{t}||\) is the tangential unit vector to determine the force direction. \(_{c}^{t},_{b}^{t}\) are the user-defined single functions. Furthermore, the tangential magnitude is also affected by the normal force  thus \(||_{ij}^{t}||\) is included. The DEA theory includes the dissipative contribution , also called the viscosity term , as it is only to simulate energy dissipation to prevent the system from exhibiting perpetual motion. In general, large velocities lead to large dissipation. In the general DEA, the term is often modeled by:

\[F_{vis}=- c_{crit} v_{rel} \]

where \(c_{crit}\) is a material properties called critical damping, \(v_{rel}\) refers to \(v_{n}\) (normal velocity), \(v_{t}\) (tangential velocity) correspondingly.

Based on the above discussion, DEA requires multiple user-specific mechanical operators including \(F_{c}^{n},F_{b}^{n},F_{vis}^{n},F_{c}^{t},F_{b}^{t},F_{vis}^{t}\), which would be inaccurate and fully different for various materials. Moreover, we cannot properly estimate the real properties of materials when only videos are available. This can be considered another impracticability of the DEA framework. On the contrary, the benefit of DEA is that we only need to solve the magnitudes of these decomposed forces because these directions are physically constrained in this framework. Therefore, we keep the advantages of the physical priors while remedying the defects of DEA by replacing these mechanical operators with trainable network kernels.

### Mechanics-informed Graph Network Architecture

This subsection introduces the proposed Discrete Element Learner which replaces these human-specific operators in DEA with learnable graph kernels. In other words, we integrate physics prior knowledge into the network design to make the entire AI system differentiable and can be optimized through image sequences. We visualize such mechanics-integrated network architecture in Fig. 3. Furthermore, our method implicitly encodes the material properties into embedding vectors during the unsupervised training. Similar to other GNN-based simulators, we first construct subgraphs by searching neighbors with a fixed radius, and each subgraph can be viewed as a collective of particles involved in interactions. Then we convert all physical variables including velocities and positions to each particle-centric coordinate system when analyzing associated particles.

We define the DEA-incorporated message-passing network as follows and the symbols previously used maintain their consistent meanings. First, we encode each particle attribute \(A_{i}\) such as material types into latent embedding \(h_{i} R^{200},[-1,1]\) via Eq. 9.

\[h_{i}=Norm((A_{i})) \]

Second, the following four equations in GNN are used to implement Eq. 5

\[n_{i},n_{j},e_{ij}=^{n}( d_{n},h_{i},h_{j}) \]

\[f_{ij}^{cn}=(_{c}(n_{i},n_{j},e_{ij})) \]

\[f_{ij}^{bn}=_{b}(n_{i},n_{j},e_{ij}) \]

\[f_{ij}^{n^{}}=f_{ij}^{cn}+f_{ij}^{bn} \]

where \(^{n}\) is a graph network kernel, \(n_{i},n_{j}\), and \(e_{ij}\) are node and edge features. \(n_{i,j}\) encode the properties of the small regions around particle \(i\), \(j\). \(e_{ij}\) encodes their interaction. \(_{c}\), and \(_{b}\) are two heads to regress the magnitude of the two forces. Due to the previous discussion, the contact force \(f_{ij}^{cn}\) can only act from \(j\) towards \(i\), it must be a positive value, therefore we apply ReLU activation. While the bond force \(f_{ij}^{nb}\) can be either positive or negative, thereby no activation is used. As for the dissipative effect, we consider the dissipation as a reduction coefficient rather than directly regress its value because it always diminishes the potential interaction force. In our network, we use an MLP \(^{n}\) activated by Sigmoid \(\) to model the normal dissipative phenomenon in Eq. 14.

\[_{ij}^{n}=(^{n}(\|v_{ij}^{n}\|_{2},e_{ij}))f_{ij}^{n^{ }} \]

Likewise, we apply another kernel \(^{t}\) (Eq. 15) to replace Eq. 7. A minor difference is that we omit the tangential bond force because when the particle undergoes very small relative displacement tangentially, the bond length remains nearly unchanged (\(_{ij}^{bt} 0\)). In this way, \(_{ij}^{t}=_{ij}^{ct}\).

\[f_{ij}^{t^{}},e_{ij}=^{t}(\|v_{ij}^{t}\|_{2},f_{ij}^{n^{}},e_{ ij},n_{i},n_{j}) \]

According to the discussion in the previous section, the quantity \(f_{ij}^{t^{}}\) relates to particle properties (\(n_{*}\)), the tangential relative displacement (\(||v_{ij}^{t}||_{2} t\)), and the precomputed normal pressure (\(f_{ij}^{n^{}}\)). Similar to \(^{n}\), \(^{t}\) models tangential dissipation in Eq. 16.

\[_{ij}^{t}=(^{t}(\|v_{ij}^{t}\|_{2},e_{ij}))f_{ij}^{t^{ }} \]

Figure 3: The main pipeline of message-passing network

[MISSING_PAGE_FAIL:7]

[MISSING_PAGE_FAIL:8]

examples of the Plasticine scenario. More results on other scenarios can be seen in the **Appendix**.

**Results in Particle View.** In this section, we report the simulation results generated by different approaches in the particle view. Table 2 and Figure 4 show the quantitative and qualitative comparisons respectively. It is observed from Table 2 that our method delivers the most satisfactory results across all scenarios. One interesting finding is that the EGNN\({}^{*}\) overall outperforms the SGNN\({}^{*}\), but in their respective original papers, the SGNN performs better than EGNN when 3D labels are available. The reason might be EGNN benefits from predefining message-passing directions, but SGNN simultaneously determines both directions and values, which is hard to optimize when only 2D images are given. From this figure, VPD, 3DImthphys, EGNN\({}^{*}\), and SGNN\({}^{*}\) cannot predict precise interactions while our method shows steady long-term simulation.

### Additional Comparisons and Analysis

**Comparisons with Neurofluid.** Neurofluid  is another unsupervised method for learning fluid dynamics. It uses the particle-based PhysNeRF as the renderer and employs DLF  as the dynamic modules. We compare our approach with it on the **Fluids**. The results are reported in Table 4 and Fig. 6. The results show that Neurofluid cannot work well on test data because its dynamic module

    &  &  \\ Method & CD\(\) & EMD\(\) & PSNR\(\) & SSIM\(\) & LPIPS\(\) \\  Neufluid & 10.7 & 11.0 & 25.36 & 0.930 & 0.175 \\ SGNN* & 11.87 & 11.32 & 27.68 & 0.946 & 0.182 \\ EGNN* & 10.76 & 9.78 & 29.01 & **0.962** & 0.108 \\ Ours & **4.18** & **2.97** & **30.02** & **0.962** & **0.104** \\   

Table 4: Quantitative results on Fluids scene

Figure 5: Qualitative Comparisons between neurofluid and ours.

    &  &  \\ Method & CD\(\) & EMD\(\) & CD\(\) & EMD\(\) \\  \(No/_{g}\) & 3.95 & 4.09 & 29.7 & 32.9 \\ \(No/_{lj}\) & 2.26 & 2.78 & 11.4 & 18.6 \\ \(No/\) & 3.15 & 3.04 & 16.5 & 13.3 \\ \(No/L_{n}^{r}\) & 2.65 & 2.91 & 10.27 & 12.38 \\ Full & 1.73 & 1.90 & 8.48 & 9.13 \\   

Table 3: Ablation studies of four components

Figure 6: Qualitative comparisons between neurofluid and ours.

lacks enough physical priors. Another reason is that it jointly trains the renderer and dynamics modules which makes them compensate for each other, causing overfitting of training data.

**Ablation Studies.** We evaluate some significant components of our method. First, we ablate the gradient loss (marked as \(No/_{g}\)). Second, we report the contribution of the tangential decomposition constituent \(_{ij}^{t}\) (\(No/_{ij}^{t}\)). Third, we make the graph network fully regress the direction and magnitude of the interaction forces (\(No/decomp\)) instead of using the priors encoded in the DEA framework, i.e. the output of the graph is a force vector. Next, we ablate the \(L_{n}^{r}\) loss term, further proving the significance of normal components. The quantitative results are listed in Table 3, which shows that the \(_{g}\) and \(_{n}^{r}\) contribute to simplifying the optimization. In addition, the mechanical decomposition is important as well. Even though the main direction of message passing is along the directions of edges, the tangential components indeed make the simulation results more realistic. Furthermore, we evaluate the effect of different renders, different training data sizes, different numbers of cameras used to capture scenes, and different points. We also test the Rollout MSE of the three methods when the 3D labels are available. Both of the results can be seen in our appendix, which shows that our method is satisfactory and robust under all the above ablation conditions.

## 5 Conclusion and Limitation

**Conclusion.** We propose the DEL which combines the Discrete Element Analysis framework with graph networks to effectively learn 3D particle dynamics from only 2D images with various materials. The main idea is to integrate strong physical priors to reduce 2D to 3D uncertainties. Existing GNN-based simulators, which are designed for learning from 3D particle correspondence, try to model the whole dynamics of particles. Differently, the DEL only adopts graph networks as learnable kernels to model some specific mechanical operators in the DEA framework, while keeping its mechanical priors, such as the direction of forces and decompositions of forces. We also evaluate our approach on synthetic data with various materials, initial shapes, and extensive interactions. The experiments show our method outperforms baselines when only 2D supervision is accessible. We also show the robustness of our methods to the renderers, training data sizes, and 3D labels.

**Limitation.** Currently, studies in this field, including this work, are conducted on synthetic datasets due to the impracticability of collecting multiview dynamic videos. Hence, "learning from few data" could potentially help address the problem of learning 3D dynamics from a single realistic video. We include them in our future work.