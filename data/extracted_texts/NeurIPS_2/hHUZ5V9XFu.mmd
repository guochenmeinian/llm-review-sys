# Equivariant Flow Matching with Hybrid Probability Transport for 3D Molecule Generation

Yuxuan Song\({}^{1,}\), Jingjing Gong\({}^{1,}\), Minkai Xu\({}^{2}\), Ziyao Cao\({}^{1}\)

**Yanyan Lan \({}^{1,3}\), Stefano Ermon\({}^{2}\), Hao Zhou\({}^{1}\),Wei-Ying Ma\({}^{1}\) \({}^{1}\)** Institute of AI Industry Research(AIR), Tsinghua University

\({}^{2}\) Computer Science Department, Stanford University

\({}^{3}\)Beijing Academy of Artificial Intelligence

{songyuxuan,gongjingjing}@air.tsinghua.edu.cn

Equal Contribution, Hao Zhou (zhouhao@air.tsinghua.edu.cn) is the corresponding author.

###### Abstract

The generation of 3D molecules requires simultaneously deciding the categorical features (atom types) and continuous features (atom coordinates). Deep generative models, especially Diffusion Models (DMs), have demonstrated effectiveness in generating feature-rich geometries. However, existing DMs typically suffer from unstable probability dynamics with inefficient sampling speed. In this paper, we introduce geometric flow matching, which enjoys the advantages of both equivariant modeling and stabilized probability dynamics. More specifically, we propose a hybrid probability path where the coordinates probability path is regularized by an equivariant optimal transport, and the information between different modalities is aligned. Experimentally, the proposed method could consistently achieve better performance on multiple molecule generation benchmarks with 4.75\(\) speed up of sampling on average.2

## 1 Introduction

Geometric generative models aim to approximate the distribution of complex geometries and emerge as an important research direction in various scientific domains. A general formulation of the geometries in scientific fields could be the point clouds where each point is embedded in the Cartesian coordinates and labeled with rich features. For example, the molecules are the atomic graphs in 3D  and the proteins could be seen as the proximity spatial graphs . Therefore, with the ability of density estimation and generating novel geometries, geometric generative models have appealing potentials in many important scientific discovery problems, _e.g._, material science , de novo drug design  and protein engineering .

With the advancements of deep generative modeling, there has been a series of fruitful research progresses achieved in geometric generative modeling, especially molecular structures. For example,  and  proposed data-driven methods to generate 3D molecules (in silico) with autoregressive and flow-based models respectively. However, despite great potential, the performance is indeed limited considering several important empirical evaluation metrics such as validity, stability, and molecule size, due to the insufficient capacity of the underlying generative models . Most recently, diffusion models (DMs) have shown surprising results on many generative modeling tasks which generate new samples by simulating a stochastic differential equation (SDE) to transform the prior density to the data distribution. With the simple regression training objective, several attempts  on applying DMs in this field have also demonstrated superior performance. However, existingDM-based methods typically suffer from unstable probability dynamics which could lead to an inefficient sampling speed also limit the validity rate of generated molecules.

In this work, we propose a novel and principled flow-matching objective, termed Equivariant Flow-Matching (EquiFM), for geometric generative modeling. Our method is inspired by the recent advancement of flow matching , a simulation-free objective for training CNFs that has demonstrated appealing generation performance with stable training and efficient sampling. Nevertheless, designing suitable geometric flow-matching objectives for molecular generation is non-trivial:

(1) the 3D skeleton modeling is sensitive, _i.e._, a slight difference in the atom coordinates could affect the formulation of some certain types of bonds; (2) the atomic feature space consists of various physical quantities which lies in the different data modality, _e.g._, charge, atom types, and coordinates are correspondingly discrete, integer, and continuous variables. To this end, we highlight our key innovations as follows:

* For stabling the 3D skeleton modeling, we introduce an Equivariant Optimal-Transport to guide the generative probability path of atom coordinates. The improved objective implies an intuitive and well-motivated prior, _i.e._ minimizing the coordinates changes during generation, and helps both stabilize training and boost the generation performance.
* Towards the modality inconsistency issues, we proposed to differ the generative probability path of different components based on the information quantity and thus introduce a hybrid generative path. The hybrid-path techniques distinguish different modalities without adding extra modeling complexity or computational load.
* The proposed model lies in the scope of continuous normalizing flow, which is parameterized by an ODE. We can use an efficient ODE solver during the molecule generation process to improve the inference efficiency upon the SDE simulation required in DMs.

A unique advantage of EquiFM lies in the framework enriching the flexibility to choose different probability paths for different modalities. Besides, the framework is very general and could be easily extended to various downstream tasks. We conduct detailed evaluations of the EquiFM on multiple benchmarks, including both unconditional and property-conditioned molecule generation. Results demonstrate that EquiFM can consistently achieve superior generation performance on all the metrics, and 4.75\(\) speed up on average. Empirical studies also show a significant improvement in controllable generation. All the empirical results demonstrate that the EquiFM enjoys a significantly higher modeling capacity and inference efficiency.

## 2 Related Work

**Flow Matching and Diffusion Models** Diffusion models have been studied in various research works such as [47; 12; 49], and have recently shown success in fields like high-dimensional statistics , language modeling , and equivariant representations . Loss-rescaling techniques for diffusion models have been introduced in , while enhancements to the architecture incorporating classifier guidance are discussed in . Noise schedule learning techniques have also been proposed in [33; 18]. Diffusion models suffer from unstable probability dynamics and inefficient sampling, which limits

Figure 1: Illustration of EquiFM. We define a hybrid path for generating molecules \(=,\), where \(\) is trained on an equivariant optimal transport path and \(\) is trained on a path whose information quantity is aligned with \(\)â€™s path. The sampling is conducted by solving an ODE, _i.e._\(_{0}=(_{1},v_{},1,0)\).

their effectiveness in some scenarios. Flow matching is a relatively new approach that has gained attention recently. Research works such as [26; 1; 28] have proposed this simulation-free objective for training continuous normalizing flow. It involves other probability paths besides the diffusion path and could potentially offer better sampling efficiency through ODE solving. Furthermore, the follow-ups [37; 50] proposed to use the OT couplings to straighten the marginal probability paths. However, the application of flow matching to geometric domains requires designing appropriate probability paths, which is an area that remains unexplored.

**3D Molecule Generation** Previous studies have primarily focused on generating molecules as 2D graphs [14; 27; 46], but there has been increasing interest in 3D molecule generation. G-Schnet and G-SphereNet [9; 30] have utilized autoregressive methods to construct molecules by sequentially attaching atoms or molecular fragments. These frameworks have also been extended to structure-based drug design [24; 35; 38]. However, this approach requires careful formulation of a complex action space and action ordering. Other approaches use atomic density grids that generate the entire molecule in a single step by producing a density over the voxelized 3D space . Nevertheless, these density grids lack the desirable equivariance property and require a separate fitting algorithm.

In the past year, the attention has shifted towards using DMs for 3D molecule generation [13; 52; 53], with successful applications in target drug generation , antibody design , and protein design [2; 51]. However, our method is based on the flow matching objective and hence lies in a different model family, _i.e._ continuous normalizing flow, which fundamentally differs from this line of research in both training and generation.

## 3 Backgrounds

### Flow Matching for Non-geometric Domains

In this section, we provide an overview of the general flow matching method to introduce the necessary notations and concepts based on . The data distribution is defined as \(q\), \(x_{0}\) represents a data point from \(q\) and \(x_{1}\) represents a sample from the prior distribution \(p_{1}\). The _time-dependent_ probability path is defined as \(p_{t}:^{d}_{>0}\), and the time-dependent vector field is defined as \(v_{t}:^{d}^{d}\). The vector field uniquely defines time-dependent flow \(_{t}:^{d}^{d}\) by the following ordinary differential equation (ODE):

\[}{t}_{t}(x)=v_{t}(_{t}(x)),_{1}(x)=x \]

 proposed to train the parameterized flow model \(_{t}\) called a continuous normalizing flow (CNF) with black-box ODE solvers. Such a model could reshape a simple prior distribution \(p_{1}\) to the complex real-world distribution \(q\). CNFs are difficult to train due to the need for numerical ODE simulations.  introduced flow matching, a simulation-free objective, by regressing the neural network \(v_{}(x,t)\) to some target vector field \(u_{t}(x)\):

\[_{}()=_{t,p_{t}(x)}\|v_{}(x,t )-u_{t}(x)\|^{2} \]

The objective \(_{}\) requires access to the vector field \(u_{t}(x)\) and the corresponding probability path \(p_{t}(x)\). However, these entities are difficult to define in practice. Conversely, the conditional vector field \(u_{t}(x x_{0})\) and the corresponding conditional probability path \(p_{t}(x x_{0})\) are readily definable.

The probability path can be marginalized from a mixture of conditional probability path \(p_{t}(x)= p_{t}(x x_{0})q(x_{0})x_{0}\), and the vector field \(u_{t}(x)\) can be marginalized from conditional vector field as \(u_{t}(x)=_{x_{0} q}(x x_{0})p_{t}(x x_{0})}{p_ {t}(x)}\). This illustrates how \(u_{t}(x)\) and \(p_{t}(x)\) are related to their conditional form, and  further proved that with the conditional vector field \(u_{t}(x x_{0})\) generating the conditional probability path \(p_{t}(x x_{0})\), the marginal vector field \(u_{t}(x)\) will generate the marginal probability path \(p_{t}(x)\). The observation inspires the new conditional flow matching (CFM) objective:

\[_{}()=_{t,q(x_{0}),p_{t}(x x_{0})} \|v_{}(x,t)-u_{t}(x x_{0})\|_{2}^{2} \]

The CFM objective enjoys the tractability for optimization, and optimizing the CFM objective is equivalent to optimizing Eq. 2, _i.e._, \(_{}_{}()=_{}_{ }()\). For the inference phase, ODE solvers could be applied to solve the Eq. 1, _e.g._, \(x_{0}=(x_{1},v_{},1,0)\). In this paper, we consider using the Gaussian conditional probability path, which lies in the form of \(p_{t}(x x_{0})=(x_{t}(x_{0}),_{t}(x_{0})^{2}I)\). We introduce two probability paths utilized in the following of paper:Conditional Optimal Transport PathWith the prior distribution \(p_{1}\) defined as a standard Gaussian distribution, the empirical data distribution \(p_{0}(x x_{0})\) is approximated with a peaked Gaussian centered in \(x_{0}\) with a small variance \(_{}\) as \((x x_{0},_{}^{2}I)\). The probability path is \(p_{t}(x x_{0})=(x(1-t)x_{0},(_{}+(1-_{ })t)^{2}I)\) and the corresponding flow is \(_{t}(x)=(_{}+(1-_{})t)x+(1-t)x_{0}\). Then the vector field could be obtained by Eq. 1 as: \(u_{t}(_{t}(x) x_{0})=t}_{t}(x)=-x_{0}+(1- _{})x\).

Put the above terms into Eq. 3, the reparameterized objective is as:

\[_{}^{}()=_{t,q(x_{0}),p_{1}( x_{1})}\|v_{}(_{t}(x_{1}),t)-(-x_{0}+(1-_{})x_{1}) \|^{2} \]

Intuitively, the conditional optimal transport objective tends to learn the transformation direction from noise to data sample in a straight line which could hold appealing geometric properties.

Variance Preserving PathThe variance-preserving (VP) path is defined as \(p_{t}(x x_{0})=(x_{t}x_{0},(1-_{t}^{2})I)\), where \(_{t}=e^{-T(t)}\) and \(T(t)=_{0}^{t}(s)ds\). Here \(\) is some noise schedule function. Following the Theorem. 3 in , the target conditional vector field of VP path could be derived as \(u_{t}(x x_{0})=^{}}{1-_{t}^{2}}(_{t}x-x_ {0})\). \(_{t}^{}\) denotes the derivative with respect to time. And the objective for VP conditional flow matching is as:

\[_{}^{}()=_{t,q(x_{0}),p_{t}( x|x_{0})}\|v_{}(x,t)-^{}}{1-_{t}^{2}}( _{t}x-x_{0})\|^{2} \]

The VP path is flexible to control the information dynamics, _e.g._ correlation changes towards \(x_{0}\) on the conditional probability path, by selecting different noise schedule functions.

## 4 Methodology

In this section, we formally describe the Equivariant Flow Matching (EquiFM) framework. The proposed method is inspired by the appealing properties of recent advancements in flow matching , but designing suitable probability paths and objectives for the molecular generation is however challenging . We address the challenges by specifying a hybrid probability path with equivariant flow matching. The overall framework is introduced in Section. 4.1. And then we elaborate on the design details of the hybrid probability path of the equivariant variable and invariant variable in Section. 4.2 and Section. 4.3 respectively. A high-level schematic is provided in Figure. 1.

### Equivariant Flow Matching

Recall molecule could be presented as the tuple \(=,\), where \(=(^{1},,^{N}) X\) is the atom coordinates matrix and \(=(^{1},,^{N})^{N d}\) is the node feature matrix, such as atomic type and charges. Here \(X=\{^{N 3}:_{i=1}^{N}^{i }=\}\) is the Zero Center-of-Mass (Zero CoM) space, which means the average of the \(N\) elements should be \(\). We introduce the general form of equivariant flow matching in the following.

SE(3) Invariant Probability PathFor modeling the density function in the geometric domains, it is important to make the likelihood function invariant to the rotation and translation transformations. We could always make the probability path of equivariant variable \(\) invariant to the translation by setting the prior distribution and vector field in the Zero CoM space, _i.e._\(_{i=1}^{N}v(x,t)^{i}=0\). Formally, the rotational invariance could be satisfied by making the parameterized vector field equivariant and the prior \(p_{1}\) invariant to the rotational transformations as shown in the following statement:

**Theorem 4.1**.: _Let \((v_{}^{}(,t),v_{}^{}(,t))= v_{}(,t)\), where \(v_{}^{}(,t)\) and \(v_{}^{}(,t)\) are the parameterized vector field for \(\) and \(\). If the vector field is equivariant to any rotational transformation \(\), i.e., \(v_{}(,,t)=((v_{ }^{}(,t)),v_{}^{}(,t))\). With an rotational invariant prior function \(p_{1}(,)\), i.e., \(p_{1}(,)=p_{1}(,)\), then the probability path \(p_{,t}\) generated by the vector field \(v_{}()\) is also rotational invariant._

To make the vector field satisfy the equivariance constraint, we parameterize it with an Equivariant Graph Neural Network (EGNN) . And more details can be found in Appendix C.

Hybrid Probability ModelingWe refer to the target conditional vector field on each part as \(u_{t}^{}(_{0})\) and \(u_{t}^{}(_{0})\) correspondingly, then we could get the objective in the following formulation:

\[_{}()=_{t,q(_{0}),p_{t}( |_{0})}[\|v_{}^{}(,t)-u_{t} ^{}(_{0})\|_{2}^{2}+\|v_{}^ {}(,t)-u_{t}^{}(_{0}) \|_{2}^{2}] \]

**Proposition 4.2**.: _There could be joint probability path \(p_{t}(|_{0})\) which satisfies that \(p_{t}(|_{0})=p_{t}(|_{0})p_{t}( |_{0})\), and the conditional vector field on \(\) and \(\) is independent: \(u_{t}^{}(_{0})=u_{t}(_{0}),u_{t}^{}(_{0})=u_{t}( _{0})\)._

The above Proposition 4.2 states a special property of conditional flow matching, _i.e._, in the multivariable setting the probability path of each variable could be designed independently. Such property is appealing in our setting, as \(\) and \(\) hold different data types and come from different manifolds, thus it is intuitive to use different probability paths for modeling and generating the two variables.

### Coordinates Matching with Equivariant Optimal Transport

We focus on the generation of coordinates variable \(\). The conditional OT path (Eq. 4) could be a promising candidate as it tends to move the atom coordinates directly towards the ground truth atom coordinates along a straight line. However, directly applying the objective could be problematic in 3D molecule generation. With \(_{0}\) as the point cloud from molecule distribution and \(_{1}\) from the prior distribution, the objective in Eq. 6 tends to move the atom based on a random alignment between the atoms. Optimizing the vector field toward such a direction could involve extra variance for training and lead to a twisted and unstable generation procedure as shown in molecule generation visualization Fig. 2(b) and Fig. 2(c).

To address the above-mentioned issue, we first introduce the concept of equivariant optimal transport (EOT) between two geometries as follows:

**Definition 4.3**.: Given two point clouds, \(=(^{1},,^{N})^{N 3}\) and \(=(^{1},,^{N})^{N 3}\). We define the equivariant optimal transport plan as

\[^{*},^{*}=}{}\|( ^{1},^{2},, ^{N})-(^{1},^{2},,^{N})\|_{2} \]

Here \(\) is a permutation of \(N\) elements and \(^{3 3}\) stands for a rotation matrix in the 3D space. With and lie in the zero of mass space, the mappings in Eq. 7 are optimal towards any E(3) equivariant operations on either side of the point clouds. Therefore, the mappings are referred to as equivariant optimal transport(EOT).

The equivariant optimal transport finds the minimum straight-line distance between the paired atom coordinates upon all the possible rotations and alignment. We could then build a probability path based on the EOT map which could minimize the movement distance of atom coordinates for the transformation between the molecule data from \(p_{0}\) and a sampled point cloud from \(p_{1}\) as:

\[p_{t}=[_{t}^{}]_{*}p_{1},_{t}^{}( )=(_{}+(1-_{})t)^{*}(^{*})+(1-t)_{0} \]

Figure 2: Generation route visualization of different models. Note that a lighter color indicates an earlier step of an atom and a denser color corresponds to a later step. A change of base color indicates a change of atom type. EquiFM generates molecules in a straightforward route as shown in 2(a). Vanilla flow matching method 2(b) on the other hand, takes a detour while generating molecules, resulting in a route inward then outward before converging to a molecule. The generation process in EDM 2(c) is rather chaotic until the last few steps before converging into a molecule.

**Proposition 4.4**.: _The probability path implied by the EOT map, i.e. Eq. 8, is also an \((3)\) invariant probability path._

The proposition could be proved following the Definition 4.3 and the Theorem 4.1. Combining the above terms, the final equivariant optimal transport based training objective is:

\[_{}^{}()=_{t,q(_{0 }),p_{1}(_{1})}\|v_{}(_{t}^{}(_ {1}),t)-(-_{0}+(1-_{})^{*}(^{*}_{1 }))\|^{2} \]

A good property of the objective with EOT is that the training characteristics are invariant to translation and rotation of initial \(_{1}\), and equivariant with respect to both sampled noise \(_{1}\) and data point \(_{0}\), which empirically contributes to more effective training.

Solving Equivariant Optimal TransportWe propose an iterative algorithm to obtain the equivariant optimal transport map. The algorithm first conducts the Hungarian algorithm  to align the atoms between the initial geometry from \(p_{1}\) and the ground truth geometry from \(p_{0}\); and then conducts the Kabsch algorithm  to solve the optimal rotation matrix based on the atom alignment. The proposed algorithm asymptotically converges to the optimal solution. Besides, the method holds a close relationship with the Iterative Closest Point (ICP)  algorithm, while our settings require the node alignment could only be one-one mapping. We leave the detailed description in Appendix C.

### Information Aligned Hybrid Probability Path

In this section, we address the challenges posed by the multi-modality nature of 3D molecular data. Specifically, we focus on the distinct generation procedures required for various modalities, such as coordinates and atom types, within the flow-matching framework. It is crucial to recognize that altering atom types carries a different amount of chemical information compared to perturbing coordinates. To better understand this intuition, we provide the following corner case:

**Example 1:**\(p_{t}(|_{0})=p_{0}(|_{0}), t< _{}\) and \(p_{t}(|_{0})=p_{1}(|_{0}), t _{}\).

We define the \(p_{t}(|_{0})\) similarly with a different parameter \(_{}\).Here we consider the corner case that \(_{} 0\) and \(_{} 1\), i.e. no noise for atom types from timestep 0 to timestep \(_{}\) and max noise level from \(_{}\) to timestep 1. (Reversely for \(_{}\) ) Under such a probability path, the model will be encouraged to determine and fix the node type at around \(_{h}\) step (very early step in the whole generation procedure), even if the coordinates are far from reasonable 3D structures. However, this particular case may not be optimal. The subsequent steps of updating the structure could alter the bonded connections between atoms, leading to a potential mismatch in the valency of the atoms with the early fixed atom types. Therefore, selecting a suitable inductive bias for determining the probability paths of different modalities is crucial for generating valid 3D molecules. In this paper, we utilize an information-theoretic inspired quantity as the measurement to identify probability paths for learning the flow matching model on 3D molecules.

**Definition 4.5**.: For distribution \(p_{0}\) on the joint space \(\), and two corresponding conditional probability path \(p_{t}(|_{0})\) and \(p_{t}(|_{0})\), we denote the \(I(_{t},_{t})\) as the mutual information for \(_{t}\) with distribution \( p_{t}(|_{0})p_{0}(_{0})_ {0}\) and \(_{t}\) with distribution \( p_{t}(|_{0})p_{0}(_{0}) _{0}\).

**Proposition 4.6**.: _For the independent conditional probability path \(p_{t}(|_{0})=p_{t}(|_{0})p_{t}(|_{0})\), when the conditional probability path of \(\) and \(\) lies in OT path or VP path, if \(I(_{0},_{0})>0\), then \( t(0,1),I(_{t},_{t})>0\) and \(I(_{t_{i}},_{t_{i}})>I(_{t_{j}},_{t_{j }}), t_{i}<t_{j}\)._

We use the quantity \(I_{t}(_{t},_{t})\) as the key property to distinguish different probability paths. Given the conditional probability path \(p_{t}(|_{0})\), it implies an information quantity change trajectory from \(I(_{1},_{1})=0\) to \(I(_{0},_{0})\) following \(I(_{t},_{0})\). Thus, one well-motivated probability path on \(\) is to align the information quantity changes by setting \(I(_{t},_{0})=I(_{t},_{0})\). Based on such intuition, we design our probability path on \(\). We follow the data representation in . This, for atom types, we represent it by one-hot encoding and charges are represented as integer variables. Empirically, the VP path involves a noise schedule function \(\) which could naturally adjust the information change by choosing different noise schedules, so we explore the probability path mainly on the VP path. For \(I(_{t},_{0})\), we decompose it as \(I(_{t},_{0})=H(_{0})-H(_{0}|_{t})\) where \(H(_{0})\) is constant and \(H(_{0}|_{t})\) is the conditional entropy towards \(_{0}\) with \(_{t}\) as the logits. Similarly, the difficulty of estimation \(I(_{t},_{0})\) lies in \(I(_{0}|_{t})\). Following the difference of entropy estimator in , we build prediction model \(p_{}(_{0}|_{t})\) to estimate \(I(_{0}|_{t})\) for selected time \(t\). More details can be found in Appendix C. We demonstrate \(20\) time steps for \(I(_{t},_{0})\), and \(I(_{t},_{0})\) for vanilla VP pathwith the linear schedule (VPlinear) on \(\), VP path with cosine schedules(VPcos)  and polynomial schedules(VPpoly) , and the OT path in Fig. 4.

We observe that the information quantity of \(I(_{t},_{0})\) does not change uniformly, this is, it stays stable at the start and drops dramatically after some threshold. It is in line with the fact that when the coordinates \(\) are away from the original positions to a certain extent, the paired distance between the bonded atoms could be out of the bond length range . In this case, the point cloud \(\) then loses the intrinsic chemical information. Reversely, the dynamics \(I(_{t},_{0})\) also implies a generation procedure where the coordinates \(\) transform first and the atom types \(\) is then determined when \(\) are relatively stable.

## 5 Experiments

In this section, we justify the advantages of the proposed EquiFM with comprehensive experiments. The experimental setup is introduced in Section 5.1. Then we report and analyze the evaluation results for the unconditional and conditional settings in Section 5.2 and 5.3. We provide detailed ablation studies in Section 5.4 to further gain insight into the effect of different probability paths. We leave more implementation details in Appendix B.4.

### Experiment Setup

**Evaluation Task.** With the evaluation setting following prior works on 3D molecules generation , we conduct extensive experiments of EquiFM on three comprehensive tasks against several state-of-the-art approaches. _Molecular Modeling and Generation_ assesses the capacity to learn the underlying molecular data distribution and generate chemically valid and structurally diverse molecules. _Conditional Molecule Generation_ focuses on testing the ability to generate molecules with desired chemical properties. Following , we retrain a conditional version EquiFM on the molecular data with corresponding property labels.

**Datasets** We choose _QM9_ dataset , which has been widely adopted in previous 3D molecule generation studies , for the setting of unconditional and conditional molecule generation. We also test the EquiFM on the _GEOM-DRUG_ (Geometric Ensemble Of Molecules) dataset for generating large molecular geometries. The data configurations directly follow previous work.

### Molecular Modeling and Generation

**Evaluation Metrics.** The model performance is evaluated by measuring the chemical feasibility of generated molecules, indicating whether the model can learn underlying chemical rules from data. Given molecular geometries, the bond types are first predicted (single, double, triple, or none) based on pair-wise atomic distances and atom types .

Next, we evaluate the quality of our predicted molecular graph by calculating both _atom stability_ and _molecule stability_ metrics. The atom stability metric measures the proportion of atoms that have a correct valency, while the molecule stability metric quantifies the percentage of generated molecules in which all atoms are stable. Additionally, we report _validity_ and _uniqueness_ metrics that indicate the

    &  &  \\  & Atom Sta (\%) & Mol Sta (\%) & Valid (\%) & Valid \& Unique (\%) & Atom Sta (\%) & Valid (\%) \\  Data & 99.0 & 95.2 & 97.7 & 97.7 & 86.5 & 99.9 \\  ENF & 85.0 & 4.9 & 40.2 & 39.4 & - & - \\ G-Schnet & 95.7 & 68.1 & 85.5 & 80.3 & - & - \\ GDM & 97.0 & 63.2 & - & - & 75.0 & 90.8 \\ GDM-aug & 97.6 & 71.6 & 90.4 & 89.5 & 77.7 & 91.8 \\ EDM & 98.7 & 82.0 & 91.9 & 90.7 & 81.3 & 92.6 \\ EDM-Bridge & 98.8 & 84.6 & 92.0* & 90.7 & 82.4 & 92.8* \\ 
**EquiFM** & \( 0.1\) & \( 0.3\) & \( 0.4\) & \( 0.3\) & \(\) & \(\) \\   

Table 1: Results of atom stability, molecule stability, validity, and validity\(\)uniqueness. A higher number indicates a better generation quality. The results marked with an asterisk were obtained from our own tests.

percentage of valid (determined by RDKit) and unique molecules among all generated compounds. Furthermore, we also explore the sampling efficiency of different methods.

**Baselines.** The proposed method is compared with several competitive baselines. _G-Schnet_ is the previous equivariant generative model for molecules, based on autoregressive factorization. Equivariant Normalizing Flows (_ENF_)  is another continuous normalizing flow model while the objective is simulation-based. Equivariant Graph Diffusion Models (_EDM_) with its non-equivariant variant (_GDM_)  are recent progress on diffusion models for molecule generation. Most recently,  proposed an improved version of EDM (_EDM-Bridge_), which improves upon the performance of EDM by incorporating well-designed informative prior bridges. To yield a fair comparison, all the model-agnostic configurations are set as the same as described in Sec. 5.1.

**Results and Analysis.** We generate \(10,000\) samples from each method to calculate the above metrics, and the results are reported in Table 1. As shown in the table, EquiFM outperforms competitive baseline methods on all metrics with an obvious margin. In the benchmarked 3D molecule generation task, the objective is to generate atom types and coordinates only. To evaluate stability, the bonds are subsequently added using a predefined module such as Open Babel following previous works. It is worth noting that this bond-adding process may introduce biases and errors, even when provided with accurate ground truth atom types and coordinates. As a result, the atom stability evaluated on ground truth may be less than 100%. Note the molecule stability is approximately the N-th power of the atom stability, N is the atom number in the molecule. Consequently, for large molecules in the GEOM-DRUG dataset, the molecule stability is estimated to be approximately 0%. Furthermore, as DRUG contains many more molecules with diverse compositions, we also observe that _unique_ metric is almost \(100\%\) for all methods. Therefore, we omit the _molecule stability_ and _unique_ metrics for the DRUG dataset. Overall, the superior performance demonstrates EquiFM's higher capacity to model the molecular distribution and generate chemically realistic molecular geometries. We provide visualization of randomly generated molecules Appendix F and the efficiency study in Appendix E.

### Controllable Molecule Generation

**Evaluation Metrics.** In this task, we aim to conduct controllable molecule generation with the given desired properties. This can be useful in realistic settings of material and drug design where we are interested in discovering molecules with specific property preferences. We test our conditional version of EquiFM on QM9 with 6 properties: polarizability \(\), orbital energies \(_{}\), \(_{}\) and their gap \(\), Dipole moment \(\), and heat capacity \(C_{v}\). For evaluating the model's capacity to conduct property-conditioned generation, we follow the  to first split the QM9 training set into two halves with \(50K\) samples in each. Then we train a property prediction network \(\) on the first half and train conditional models in the second half. Afterward, given a range of property values \(s\), we conditionally draw samples from the generative models and then use \(\) to calculate their property values as \(\). The _Mean Absolute Error (MAE)_ between \(s\) and \(\) is reported to measure whether generated molecules are close to their conditioned property. We also test the MAE of directly running \(\) on the second half QM9, named _QM9_ in Table 2, which measures the bias of \(\). A smaller gap with _QM9_ numbers indicates a better property-conditioning performance.

**Baselines.** We incorporate existing EDM as our baseline model. In addition, we follow  to also list two baselines agnostic to ground-truth property \(s\), named _Random_ and \(N_{}\). _Random_ means we simply do random shuffling of the property labels in the dataset and then evaluate \(\) on it. This operation removes any relation between molecule and property, which can be viewed as an upper bound of _MAE_ metric. \(N_{}\) predicts the molecular properties by only using the number of atoms in the molecule. The improvement over _Random_ can verify the method is able to incorporate conditional

   Property & \(\) & \(\) & \(_{}\) & \(_{}\) & \(\) & \(C_{v}\) \\ Units & Bohr\({}^{3}\) & meV & meV & meV & D & \(}\)K \\  QM9* & 0.10 & 64 & 39 & 36 & 0.043 & 0.040 \\  Random* & 9.01 & 1470 & 645 & 1457 & 1.616 & 6.857 \\ \(N_{}\) & 3.86 & 866 & 426 & 813 & 1.053 & 1.971 \\ EDM & 2.76 & 655 & 356 & 584 & 1.111 & 1.101 \\
**EquiFM** & **2.41** & **591** & **337** & **530** & **1.106** & **1.033** \\   

Table 2: Mean Absolute Error for molecular property prediction. A lower number indicates a better controllable generation result.

   Method & Atom Single (\%) & Mol Single (\%) \\  EquiFM\({}_{+,_{}}\) & **98.9\(\)0.1** & **88.3\(\)0.3** \\ EquiFM\({}_{+,_{}}\) & 98.7\(\)0.1 & 84.9\(\)0.4 \\ EquiFM\({}_{+,_{}}\) & 98.4\(\)0.1 & 81.6\(\)0.3 \\ EquiFM\({}_{+,_{}}\) & 98.7\(\)0.1 & 84.7\(\)0.2 \\ EquiFM\({}_{+,_{}}\) & 98.7\(\)0.1 & 83.4\(\)0.5 \\ EquiFM\({}_{+,_{}}\) & 97.3\(\)0.1 & 77.1\(\)0.4 \\   

Table 3: Ablation study, EquiFM models trained with different probability path, the effect of EOT is also evaluated.

property information into the generated molecules. And overcoming \(N_{}\) further indicates the model can incorporate conditioning into molecular structures beyond the number of atoms.

**Results and Analysis.** The visualizations of conditioned generation can be found in Appendix F. As shown in Table 2, for all the conditional generation tasks, our proposed EquiFM outperforms other comparable models with a margin. This further demonstrates the generalization ability of the proposed framework upon different tasks.

### Ablations On the Impacts of Different Probability Paths

In this section, we aim to answer the following questions: 1) how is the impact of the different probability paths on the coordinate variable \(\) and the categorical variable \(\)? 2) how does the equivariant optimal transport path boost the generation?

To answer these questions, we apply several different probability paths and compare them on the QM9 dataset, including the variance-preserving (VPLinear) path(Eq. 5), vanilla optimal transport (OT) path(Eq. 4), and the equivariant optimal(Eq. 9) transport path(EOT) on the coordinate variable \(\); And variance-preserving (VPLinear) path(Eq. 5), vanilla optimal transport (OT) (Eq. 4), the variance-preserving path with polynomial decay (VPPoly), variance preserving path with cosine schedule (VPLoss). The result is illustrated in Tab. 3. We notice that OT-based paths on coordinates in general show superior performance than the others due to the stability and simplicity of the training objective. Furthermore, regularizing the path with the equivariant-based prior, the EOT path could further boost the performance by a large margin. To gain a more intuitive understanding, we further provide the generation dynamic comparison in Fig. 2(b). As shown, the generation procedure trained with vanilla OT path, though more stable than the EDM generation procedure, also exits some twisted phenomenon, _i.e._, all atoms tend to first contract together and then expand; Such phenomenon disappears in the generation procedure of EOT path due to that the generation direction is well constrained. For the probability path on the categorical variable, we find the VP path, holds the superior performance due to the closest alignment with the information quantity changes. If there is a significant discrepancy in the information quantity dynamics, _e.g._, OT path, it may result in a substantial decline in performance.

### Sampling Efficiency

We also evaluate the sampling efficiency of our model, as shown in Fig. 3, the results of EquiFM with 4 different integrating algorithms converge to state-of-the-art results in much less NFE compared to baseline model EDM. Remarkably, the red triangle is the result of EquiFM with the Dopri5 integrating algorithm, it converges in approximately 210 NFE to achieve 0.883 model stability, while EDM takes 1000 NFE to achieve only 0.820. With simple non-adaptive step integration algorithms such as Eulers method and midpoint, the NFE required for convergence is much less than that of baseline models.

This indicates that our proposed model has learned a much better vector field, and takes a much shorter generation route during generation, this can be justified with visualization Fig. 2(a).

## 6 Conclusion and Future Work

We introduce the EquiFM, an innovative molecular geometry generative model that utilizes a simulation-free objective. While flow matching has demonstrated excellent properties in terms of stable training dynamics and efficient sampling in other domains, its application in geometric domains poses significant challenges due to the equivariant property and complex data modality. To address these challenges, we propose a hybrid probability path approach in EquiFM. This approach regularizes the probability path on coordinates and ensures that the information changes on each component of the joint path are appropriately matched. Consequently, EquiFM learns the underlying chemical constraints and produces high-quality samples. Through extensive experiments, we demonstrate that the EquiFM not only outperforms existing methods in modeling realistic molecules but also significantly improves sampling speed, achieving a speedup of \(\) compared to previous advancements. In future research, as a versatile framework, EquiFM can be extended to various 3D geometric generation applications, such as protein pocket-based generation and antibody design, among others.