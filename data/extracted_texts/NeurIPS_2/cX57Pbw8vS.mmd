# Benchmarking PtO and PnO Methods in the Predictive Combinatorial Optimization Regime

Haoyu Geng\({}^{1}\)\({}^{}\), Hang Ruan\({}^{1}\)\({}^{}\), Runzhong Wang\({}^{2}\), Yang Li\({}^{1}\), Yang Wang\({}^{3}\), Lei Chen\({}^{3}\), Junchi Yan\({}^{1}\)

\({}^{1}\)Dept. of CSE & School of AI & Moe Key Lab of AI, Shanghai Jiao Tong University

\({}^{2}\)Massachusetts Institute of Technology

\({}^{3}\)Finvolution Group

{gengahoyu98, zzrh01, yangiliy, yanjunchi}@sjtu.edu.cn

runzhong@mit.edu, {wangyang09, chenlei04}@xinye.com

Correspondence author. \(\) denotes equal contribution. This work was in part supported by NSFC 92370201, 72342023.

###### Abstract

Predictive combinatorial optimization, where the parameters of combinatorial optimization (CO) are unknown at the decision-making time, is the precise modeling of many real-world applications, including energy cost-aware scheduling and budget allocation on advertising. Tackling such a problem usually involves a prediction model and a CO solver. These two modules are integrated into the predictive CO pipeline following two design principles: "Predict-then-Optimize (PtO)", which learns predictions by supervised training and subsequently solves CO using predicted coefficients, while the other, named "Predict-and-Optimize (PnO)", directly optimizes towards the ultimate decision quality and claims to yield better decisions than traditional PtO approaches. However, there lacks a systematic benchmark of both approaches, including the specific design choices at the module level, as well as an evaluation dataset that covers representative real-world scenarios. To this end, we develop a modular framework to benchmark 11 existing PtO/PnO methods on 8 problems, including a new industrial dataset for combinatorial advertising that will be released. Our study shows that PnO approaches are better than PtO on 7 out of 8 benchmarks, but there is no silver bullet found for the specific design choices of PnO. A comprehensive categorization of current approaches and integration of typical scenarios are provided under a unified benchmark. Therefore, this paper could serve as a comprehensive benchmark for future PnO approach development and also offer fast prototyping for application-focused development. The code is available at [https://github.com/Thinklab-SJTU/PredictiveCO-Benchmark](https://github.com/Thinklab-SJTU/PredictiveCO-Benchmark).

## 1 Introduction

Predictive combinatorial optimization is a family of Combinatorial Optimization (CO) problems where the problem parameters are unknown during decision-making. Predictive CO models a wide range of real-world settings, including energy cost-aware scheduling , budget allocation for website information dissemination , portfolio optimization . In predictive CO, the optimization itself could be solved by readily available solvers (e.g. Gurobi ) once the problem parameters are predicted. However, due to the inherent uncertainty and noise from the real world, the prediction is never perfect, resulting in potentially misleading problem parameters. Even the optimal solution under these parameters could be a bad decision in the real world. As shown in Fig 1(a-b), job scheduling without considering energy price fluctuations may result in energy waste and higher costs.

Hence, there are important and practical needs to jointly consider both prediction and decision-making for predictive optimization (especially CO) problems . A basic solution for predictive CO is "**predict-then-optimize**"  (**PtO**, or called the two-stage approach), which first predicts coefficients of the optimization task through a predictive model trained under the supervision of ground truth coefficients and subsequently utilizes off-the-shelf solvers to obtain solutions. Intuitively, it is expected that a higher prediction accuracy would result in better decision quality. Nonetheless, as also evidenced by Figure 5(c-d), there often exists a gap between prediction objectives and ultimate decision goals, leading to suboptimal decisions by PtO models. Therefore, as shown in Fig 1(b), a recent series of studies  have proposed the new "**predict-and-optimize**" paradigm (**PnO**, or decision-focused learning  that learns to directly cater for the ultimate decision objectives. In cases where the quality of the final decision is paramount, joint prediction-and-optimization approaches may be more direct and beneficial. Though this can sometimes come at the expense of prediction accuracy (as is shown in Fig 5(c)), they exhibit notable improvement over PtO on several optimization tasks.

The main challenges towards predict-and-optimize for predictive CO lie in two aspects: (1) the solution's derivatives with respect to the optimization coefficients are not available. (2) the variables in the optimization problems are discrete. Both challenges lead to the blocking of gradients. To mitigate this issue, several approaches have been proposed, including designing proxy loss functions , gradient approximation , etc. However, there lacks a systematic categorization of existing methods, and it is not clear which methods are effective for specific problems and scenarios. Moreover, the experimental benchmarks are relatively fragmented, and the existing proposed models have not undergone comprehensive evaluation, impeding the community's progression. Though some implementations  are available for some methods, they only support linear or convex problems, while overlooking other non-linear and submodular problems. Moreover, the optimization datasets are limited in scale, and some of them use generated data for the prediction part, lacking an industrially large-scale real-world dataset for validating the PnO performance.

In this work, we systematically review existing methodologies and establish a benchmark to align each model. Based on empirical results, we then conduct a series of in-depth experiments to explore key factors for PnO model design, and find several useful tips for deployment of PnO models. Based on these findings, we provide a set of recommendations for practitioners on model selection when considering the applicability and practical performance. We anticipate that our open-source benchmark and new dataset will gain increased attention, thereby fostering advancements in both research and practical applications. Our contributions and conclusions are summarized as follows:

\(\) We systematically review current PnO approaches and categorize them into four categories according to how the problem is solved regarding the decision variables: discrete or continuous; and how the loss function is designed: (statistically) direct or surrogate. We also give a PnO model choice recommendation by analyzing the potential gains and challenges during the real-world deployment.

\(\) We develop a modular framework of 11 existing PtO/PnO methods on 8 problems, and multiple solvers for a fair benchmarking. We also include a new industrial dataset regarding the combinatorial advertising problem, formulated as an integer linear program with uncertain conversion rates.

\(\) Our benchmark results demonstrate PnO is better than PtO on 7 out of 8 predictive CO problems. However, **no silver bullet is found for specific design choices**, suggesting the necessity of trial-and

Figure 1: (a) Example of predictive CO in energy-cost aware scheduling. Factories deploy job schedules based on energy price predictions to reduce production costs. (b) Visualization of energy prices of the 200th test instance in SEMO dataset. PtO makes improper predictions, which further prescribes sub-optimal decisions. (c) PtO vs. PnO. PnO designs decision-oriented training approaches that emerged recently as a promising direction to tackle predictive CO.

error for various scenarios. Therefore, our comprehensive and modular-based benchmark covering mainstream PnOs could further help quick prototyping in application-focused development.

\(\) Our extensive benchmark discovers some key factors for PnO methodology design, suggesting future research directions. Specifically, we try to answer 3 research questions regarding **relationship between prediction accuracy and decision quality, impacts of prediction labels on PnO**, and **versatility of PnO across different settings**. The experiments indicate that leveraging decision information for more favorable trade-offs may be a key factor in how PnO works; pre-training with predicted labels can enhance certain PnO methods; the versatility of PnO in optimization parameters still needs improvement.

## 2 Problem Formulation

Consider a predictive combinatorial optimization with unknown coefficients \(\):

\[_{} f(,, )s.t.( ), \]

where \(f(,,)\) denotes the known and closed-formed optimization objective (abbreviated as \(f(,)\) below) with discrete variable \(\), and \(\) is collection of unknown optimization coefficients, \(\) are optimization parameters that are known and fixed, and decision variables \(\) obey the constraints \(()\). We assume that the coefficients of the constraints are known in line with the majority of literature . We denote the solution obtained through one solver call for a problem instance with coefficient \(\) as \(()\), and \(^{}()\) as the optimal solution. The solvers can be commercial solvers (e.g. Gurobi ), open-sourced solvers (e.g. cvxpy ), or neural solvers (e.g. submodular ).

Though coefficients \(\) are unknown, in many circumstances, they could be estimated by a predictive model using a collection of historical or pre-collected dataset \(=\{(_{i},_{i})\}\), where \(\) denotes relevant raw features. Therefore, the learning objective of the prediction step is:

\[_{}_{(_{i},_{i}) }[_{pred}(}_{i},_{i})] { }, \]

where \(_{pred}\) is a training loss specified by the prediction output, e.g. mean squared error (MSE). Suppose the prediction model \(\) serves as a mapping from the feature vector \(_{i}\) to coefficients \(}_{i}\), i.e. \(}_{i}=(_{i})\), the predictive optimization problem  is:

\[_{_{i}}_{(_{i},_{i})}[f(_{i}((_{i} )),(_{i}),)]. \]

The evaluation of the PtO could be critical. In many circumstances where the real coefficients of the test set are available, regret  is used to evaluate decision quality. Let the decision quality  of solution \(}\) be the objective under the ground-truth coefficient \(\):

\[(})=f(},, ). \]

Then the regret could be obtained by the difference of the decision quality with solutions under the estimated coefficient(\(^{}()\),) and ground-truth coefficients (\(^{}(})\)):

\[(},)=|f(^{ }(),,)-f(^{}(}),,)|. \]

However, in many cases (e.g. combinatorial advertising problem), the ground truth coefficients \(\) are not readily available or even impossible to obtain, so the evaluation of PtO becomes challenging. Online A/B testing may be one approach; however, it is associated with higher costs and risks in practice. Consequently, we propose using uplift, an offline controlled variable metric common in causal inference tasks, as an alternative evaluation elaborated in Appendix C.7.3.

## 3 Categorization of Existing Methods

As briefly introduced earlier, the major challenges of PnO lie in two aspects: (1) unavailable/non-informative gradients and (2) discrete variables. These two challenges both block the gradient backpropagation so that the prediction model cannot be updated by the final objective. Table 1 categorizes existing works into four groups by how the optimization is solved and how the gradient is obtained, where the gradient flow of these approaches is shown in Figure 2. We consider the **PtO** training as a baseline method while concurrently noting that the first challenge can be readily addressed if the solver is differentiable, such as neural solvers for top-k  or Sinkhorn algorithm  used in neural graph matching . The technical details are given in Appendix B.3.

### The Discrete Category

As discussed in , the gradient of decision variable \(\) with respect to coefficients \(\) revealed as piecewise constant functions (almost zero everywhere, and undefined otherwise). To address this issue, the "discrete" category solves the optimization with the original discrete solver in the forward pass, while in the backward pass, the gradients are estimated via designed interpolation functions, such as linear interpolation done by Blackbox . Representative models include **DFL**, **Blackbox**, **Perturb** and **I-MLE**, **Identity**, etc.

One advantage of this category is that the gradient interpolations work on the fly and do not require coefficient labels or additional optimization samples. Therefore, this class of methods requires the least additional resources. However, they are only adaptable to linear or convex optimization objectives, since gradients of more complex objectives are hard to estimate. Though a vanilla DFL method is agnostic to the optimization form, it is prone to have high variances  and our experiments also indicate such issues (shown in Figure 6). Besides, some methods require additional solver calls in the forward pass, like BlackBox, Perturb, and I-MLE, which adds a bit of computational overhead.

Figure 3: A modular code framework supporting 11 problems, 8 PtO/PnO models, multiple solvers, and various evaluations under configurable parameters. Users can easily customize their own problems, predictors, models, and solvers.

Figure 2: Gradient flow of existing PnO methods, where \(f\), \(\) and \(\) denote the original objective, learned objective by surrogate model, and the continuous relaxation of the original objective, respectively. The path of back propagation of the vanilla two-stage is \(\), while discrete/continuous categories use \(\), statistical one uses \(\), and surrogate one uses \(\). \(l_{surro}\) represents the surrogate losses to measure how the surrogate imitates the original optimization objective, while \(l_{rank}\) refers to the designed loss that encodes solution ranking—e.g., ensuring that the optimal solution is assigned a lower loss than suboptimal ones.

### The Continuous Category

The "continuous" category estimates the gradient of the relaxed version of the CO problem since continuous problems are implicitly differentiable in nature. In the forward pass, it generally solves the relaxed optimization problem, whereas in the backward pass, the gradients are obtained by automatic differentiation (of such as KKT conditions). Representative models include **OptNet**, **CPLayer** and more  for continuous PnOs and **QPTL**, **IntOpt**, SPO-relax  (short as SPO below), and more , for PnO on discrete problems.

The advantage of this category is that the gradient \( z/ y\) is readily available when the problem is relaxed to continuous. However, it necessitates tailored relaxations for each individual problem, and not every discrete problem has readily available or straightforward relaxations. Additionally, the application of KKT (or subgradient)-based differentiation is limited to convex (or linear) objectives, rendering it not suitable for all CO problems.

### The Statistical Category

The "statistical" category  designs loss for PnO considering the statistical relation between multiple solutions. The aim is to make coefficient predictions so that the decision quality (defined in Eq. (4)) of optimal solutions is superior to suboptimal solutions. Representative models include **NCE** and **LTR** (with 3 versions: pointwise-LTR, pairwise-LTR, and listwise-LTR).

The statistical category is usually agnostic to the problem type and solver. However, a solution cache of optimization samples is required before the training, which creates additional overhead. It is also not readily applicable to problem instances of varying variable sizes for solution cache in implementation.

### The Surrogate Category

Another branch besides "statistical" that bypasses gradient estimation is the "surrogate" category. It generally replaces the original optimization objective with a learned surrogate function and has emerged as effective in recent literature. It is inherently differentiable since the objective function is learned. Representative works include **LODL**, **EGL**, **LANCER**, **SurCO**, etc.

Similar to the statistical category, the surrogate category easily adapts to all problem and solver types. Furthermore, in cases where solving is slow or assessing solution quality is expensive, using the surrogate expedites the PnO training process. Nevertheless, they do necessitate an extra set of optimization instances and corresponding solutions to learn objective functions as initialization. Additionally, whether and how well they can learn complex nonlinear functions remains open.

### Takeaways for Practitioners' PnO Model Choice

**Remark on 4 categories of PnO methods**: As categorized in Table 1, while end-to-end training on PnO has emerged as a novel paradigm with promising potential to surpass the two-stage PtO paradigm, in practice, there does not currently exist a singular end-to-end model capable of outperforming all other methods: the discrete-category and continuous-category are efficient with fewer solver calls, while constrained by certain optimization forms (e.g. convex), while the latter two categories fit any optimization objectives but with high computational cost and requires additional optimization samples.

**PnO model choice guideline** As shown in Fig 4, we consider several key factors for the preferable model recommendation: requirement for _labeled prediction datasets_, _extra optimization samples_, and _overall performance_ (in both efficacy and efficiency). **Firstly**, the SPO  method is preferable for most linear or near-linear problems (Knapsack, energy-cost aware scheduling, budget allocation problem, etc.) as the first try, as long as there are labeled datasets for prediction tasks. SPO requires fewer labeled datasets and is generally

Figure 4: Choice guide of PnO models, which depends on optimization objective type, available resources. From top to bottom, it becomes harder to deploy PnO for harder optimization types and fewer available resources.

faster regarding additional solving, backward pass complexity, etc. **Secondly**, the LTR  method is a good choice for non-linear tasks (TopK, bipartite matching, Portfolio optimization) as long as there are extra optimization samples at hand (or corresponding solution cache), and LODL  for better performance if optimization solutions are easy to get (since it requires abundant samples and solutions). **Finally**, the discrete category (Blackbox /Identity ) is the last choice for linear/convex problems if there are no labeled datasets for prediction tasks, such as combinatorial advertising.

## 4 Benchmarks and Remarks

### Modular Framework Design

As shown in Figure 3, we implement the benchmark as a modular framework where each scenario is composed of problems, predictors, solvers, losses, and evaluations. This enables a comprehensive and convenient evaluation of current methods. Although we have not exhaustively addressed all CO problems, we have selected representative ones from real-world applications and introduced a real-world industrial dataset to contribute to the field's development.

### Problem Descriptions

In this section, we briefly introduce each task with the datasets in Table 2, where the background, practical scenarios, detailed "prediction" and "optimization" formulations are left in Appendix C.

#### 4.2.1 Benchmark on publicly available datasets

**Energy-cost Aware Scheduling (_SE_)** The energy cost-aware scheduling task adopted from , is to make machine production schedules based on the predicted energy prices.

**Knapsack (_KG_, _KE_)** We consider a knapsack problem with unknown item values used in . We provide two versions: the synthetic version (knapsack (gen), or "_KG_"), and a real energy dataset version  (knapsack (energy), or "_KE_").

**Budget Allocation (_BA_)**_BA_ has applications when agents intend to disseminate information  across multiple websites to reach a wider audience within a budget constraint, but the probability of each website reaching users is unknown.

**Cubic Top-K (_TK_)** The Top-k finds \(K\) largest numbers with unknown values following .

**Bipartite Matching (_BM_)** We consider a bipartite graph matching used in  where the edge connectivity is unknown and requires prediction.

**Portfolio Optimization (_PF_)** We introduce portfolio optimization  with unknown asset prices, which maximizes the immediate net profit of the securities while reducing risk. Though a continuous quadratic program, we bring it here since it is often regarded as a stress test  where the quadratic program naturally provides informative gradients by automatic differentiation .

#### 4.2.2 New dataset of combinatorial advertising for inclusive finance

Extending financial services to specific underserved populations within society is highly beneficial in mitigating wealth disparities and enhancing the living standards of low-income individuals. We introduce a new dataset of Combinatorial Advertising ("_CA_") of real industry advertising records, in which a fintech platform connects with financial institutions to provide low-interest loans to users.

   Name & Data & Variable & Train & Test & Optimization & Used & Prediction \\ Source & Size & Samples & Samples & Type & Solver & Loss \\  Energy scheduling & SEMO  & 48 & 650 & 139 & ILP & Gurobi  & MSE \\ Knapsack (Gen) & Generated  & 20 & 400 & 200 & ILP & Gurobi  & MSE \\ Knapsack (Energy) & SEMO  & 48 & 400 & 200 & ILP & Gurobi  & MSE \\ Cubic Top-k & Generated  & 50 & 250 & 400 & Top-K & Heuristic  & MSE \\ Budget allocation & Yahoo  & 100 & 400 & 200 & Submodular & Submodular  & BCE \\ Bipartite matching & Cora  & 50 & 20 & 6 & ILP & CVXPY  & BCE \\ Portfolio optimization & Quandl  & 50 & 400 & 200 & QP & CVXPY  & MSE \\ Combinatorial Advertising & Industrial & 2933(avg) & 23 & 6 & ILP & Ortools  & BCE \\   

Table 2: Dataset statistics. Short terms: integer linear program (ILP), quadratic program (QP).

**Dataset**: The advertisement takes place on a mobile application (APP) as a combination of various channels, including in-app notifications, text messages, telephones, etc. Historical data contains whether a user converted after being exposed to a specific marketing combination in the past; however, labels for other combinations remain unknown. The data can be accessed through the website2, and the processing and use terms are in Appendix C.7.

**Prediction**: Given user \(i\)'s feature \(^{i}\) (encrypted and processed personal features, app activity records, etc.), predict the user's conversion rate \(^{i,j}\) to the \(j\)-th combination of advertising channels.

**Optimization**: The goal is to allocate the advertiser's existing budget to offer each user a combination that enables broader access (higher conversions) of users to financial services.

It differs from the above _BA_ problem as _CA_ is based on personalized advertising while _BA_ is not. _CA_ is also more challenging than the multiple treatment setting  due to the exponential combination space of channels, where the latter refers to multiple levels of treatments of the same channel.

### Experimental Setup

We implement our framework based on the previous works . All experiments are carried out on a workstation with Intel(r) i9-7920X, NVIDIA(r) RTX 2080, and 128GB RAM.

For the predictive model, we use a two-layer MLP with 32 hidden units in each layer. Unless otherwise specified, we extract 20% from the training data set for validation. During training, we adopt the Adam Optimizer  and search by grid the learning rate in \(\{0.1,0.05,0.01,0.005,0.001\}\). In each run, each model is trained for 300 epochs and the training stops if no better regret is achieved for 50 epochs on the validation set. The epoch that reaches the lowest regret (or highest uplift) in validation is selected for testing. We elaborate on more details of the model design in Appendix B.

### Benchmark Results

We list the benchmarks, including relative regret (with respect to optimal objective) and average runtime for training and test in Table 3, and hyper-parameter sensitivity in Appendix D.3.

From the perspective of each method, methods in the discrete category do not perform as well as others, especially on non-linear optimization tasks (budget allocation, topk, portfolio, etc.). This is probably because the gradient interpolations are only designed for linear objectives and gradient estimations in the back-propagation may not be accurate in complex problems. The continuous-category method SPO performs well on linear problems with relatively short training time. We run CPLayer on the linear optimization problems and non-linear programs are omitted. For the statistical category, listwise-LTR achieves better results than others in most problems, probably because it

    &  &  &  &  &  \\   &  &  &  &  &  & SPO &  &  &  &  &  \\    } & Regret(\%) & 6.95 & 11.74 & 24.274 & 31.824 & 24.769 & 6.223 & 13.488 & 6.402 & 7.823 & **0.631** & 0.044 \\  & Train Time & 0.101 & 1.208 & 2.195 & 1.351 & 0.868 & 1.735 & 2.065 & 1.846 & 4.861 & 1.536 & 0.344 \\  & Test Time & 0.794 & 1.636 & 1.544 & 1.553 & 1.928 & 1.300 & 1.445 & 1.682 & 3.973 & 1.119 & 0.716 \\    } & Regret(\%) & 7.425 & 1.878 & 1.578 & 1.716 & 6.024 & 8.007 & 1.852 & 1.672 & **0.725** & **0.820** & **0.357** \\  & Train Time & 0.198 & 1.116 & 1.776 & 1.051 & 0.416 & 2.007 & 4.010 & 2.602 & 10.396 & 3.099 & 0.501 \\  & Test Time & 0.342 & 0.760 & 0.752 & 0.745 & 1.825 & 1.009 & 2.054 & 1.406 & 1.673 & 1.699 & 0.344 \\    } & Regret(\%) & 1.793 & 2.723 & 6.030 & 5.890 & - & 1.849 & 1.663 & 4.548 & 1.548 & 1.540 & 1.581 & 1.786 \\  & Train Time & 0.440 & 0.418 & 2.875 & 11.067 & 56.334 & - & 11.062 & 10.645 & 6.744 & 6.141 & 6.8173 & 0.582 \\  & Test Time & 1.159 & 2.186 & 2.799 & 26.920 & - & 4.418 & 37.904 & 25.900 & 21.200 & 26.945 & 21.055 \\    } & Regret(\%) & 3.232 & 3.597 & 2.609 & 24.799 & - & **- & **- & **- & **- & **- & **- \\  & Train Time & 0.102 & 4.019 & 3.999 & 21.234 & - & 4.0021 & 7.327 & 22.669 & 22.194 & 22.774 & 0.248 \\  & Test Time & 1.288 & 25.183 & 25.728 & 26.344 & - & 38.127 & 38.460 & 26.392 & 26.923 & 26.168 & 12.278 \\  & Train Time & 0.158 & 1.574 & 13.984 & 13.934 & - & 16.048 & 14.193 & 1.495 & 6.072 & 0.193 & 0.172 \\  & Train Time & 0.064 & 0.116 & 0.096 & 0.097 & - & 0.126 & 0.393 & 0.379 & 4.653 & 0.679 & 0.197 \\  & Test Time & 0.038 & 0.05 & 0.090 & 0.087 & - & 0.125 & 0.890 & 0.832 & 11.625 & 1.571 & 0.054 \\    } & Regret(\%) & 9.298 & **9.184** & 91.988 & 91.868 & 92.907 & 93.237 & 92.622 & **91.038** & 92.285 & 91.831 & 0.115 \\  & Train Time & 0.010 & 25.121 & 0.623 & 0.334 & 17.179 & 1.985 & 3.467 & 0.659 & 1.501 & 0.051 \\  & Test Time & 0.362 & 7.725 & 0.446 & 0.457 & 6.643 & 1.16 & 1.758 & 0.886 & 1.058 & 1.044 & 0.229 \\    } & Regret(\%) & 2.388 & 0.526 & 0.130 & 0.526 & 0.130 & 0.526 & 0.1307 & - & 0.132 & 0.559 & 0.526 \\  & Train Time & 0.204 & 0.754 & 3.762 & 2.018 & 1.121 & 3.446 & 11.082 & 3.382 & 16.383 & 3.564 & 0.198 \\   & Test Time & 1.187 & 3.547 & 2.251 & 3.115 & 3.504 & 3.121 & 8.071 & 3.829 & 17.087 & 3.919 & 1.182 \\   

Table 3: Results for 7 problems on 11 methods. The relative regret (w.r.t. optimal objective %) and average runtime of each epoch are reported. “-” means non-applicable and data generation time of LODL is not counted. Best three: **red**, **orange**, **blue**, **blue**.

captures the global relationships among multiple solutions. The surrogate method LODL achieves satisfactory results on half of the benchmarks. More analysis is left to Appendix D.1.

As for the training efficiency, one may observe that the two-stage approach is significantly faster than others in the training stage since it does not involve solving the optimization problem. CPLayer may take much longer time than others since the KKT differentiation may incur \(O(N^{3})\) time complexity for back-propagation. Statistical methods often come with higher training time since multiple solutions are required for model initialization. Though training on LODL is fast, the model preparation time (including collecting solutions for optimization samples and learning the surrogate models for objective functions) is not counted, and it could be time-consuming if the number of required samples is large and solving an optimization problem is slow. We used 5000 samples for LODL, and better LODL performance may occur with more samples (as well as more running time)

The result of the combinatorial advertising on discrete category is shown in Table 4, where other categories of methods that cannot run on-the-fly do not apply to this problem directly because they require additional coefficient labels/optimization samples that cannot be satisfied in this problem. We conclude applicability in Sec. 3.5 in the following. The PnO training significantly improves the uplift metric (using the discrete category). The identity model achieves the best result. The DFL and Blackbox approach also performs better than the two-stage approach, though with higher training time. Though the end-to-end PnO training takes higher training time, they do not incur additional runtime during the test stage.

**Remark of PnO methods by empirical results**: In the benchmark results, we observe that in line with analysis in Sec. 3, despite the immediate applicability of discrete-category methods without extra data or solving, their reliance on interpolated gradients often leads to inaccuracies during training, resulting in inferior performance compared to the two-stage methods in many scenarios. Statistical-category and surrogate-category methods exhibit better performance. However, it is noteworthy that they incur higher computational costs during data sample collection and forward-pass computations.

The above categorizations and benchmark suggest that _PnO methods lack a universally accepted standard, and in practical applications, each method has its own advantages and disadvantages_. Therefore, there is an urgent need for better approaches with respect to applicability, efficiency and performance. Hence, addressing the imperative challenge of attaining a more **universal**, **stable**, and **efficient** training model is essential to fully realize the potential of "PnO" in the real world.

### Key Factors for PnO Methodology Design

To investigate the key factors for future improvements of PnO, we propose to explore the following research questions: **(RQ1)** What is the relationship between prediction accuracy and decision quality in the PnO methods? **(RQ2)** To what extent do the prediction labels impact the PnO methods? **(RQ3)** Do the PnO methods demonstrate versatility across different settings?

**RQ1: Relationships of prediction accuracy and decision quality** In common sense, a better prediction would lead to a better subsequent decision. Besides a case study shown in , we explore

    & Two-stage & DFL & Blackbox & Identity \\  Uplift & 0.069 & 0.088 & 0.134 & 0.135 \\ Train Time & 0.170 & 10.670 & 10.053 & 10.120 \\ Test Time & 3.078 & 3.216 & 3.096 & 3.199 \\   

Table 4: Combinatorial advertising of “discrete” category.

Figure 5: (a–b) Results of fine-tuning (short as “FTN”) of the discrete category (BB, ID model). Compared to training PnO directly, “BB-FTN” and “ID-FTN” benefit by first pertaining by PtO and then fine-tuning by PnO on 4,5 over 7 datasets, respectively. (c–d) Learning curve on knapsack (gen) dataset for prediction loss and decision regret w.r.t. training epochs. PnO approaches (LTR, SPO) achieve lower regret than the PtO approach (Two-stage), though with higher prediction loss.

the prediction loss and decision objective in both PtO and PnO. We illustrate the learning curve on the real-world knapsack (energy) dataset by plotting the prediction loss (Mean-squared error) and evaluation results (regret) of one method for each category, shown in Figure 5(c d).

It is observed that PnO training methods like SPO, listwise-LTR, and LODL achieve lower regret than the vanilla PtO method. The prediction loss of LODL shares a similar pattern with PtO, while LTR's is different. This demonstrates despite higher prediction loss incurred in the end-to-end training, these PnO methods obtain better decisions by their own loss functions concerning the ultimate decision objectives. This might correspond to the proposition  that _PnO achieves better decision quality by finding better error trade-offs by information of decision objectives_. We show more qualitative analysis in Appendix D.5.

**RQ2: Impact of prediction labels on PnO** We explore the impacts of prediction labels specifically for discrete categories (Blackbox and Identity) since they inherently do not use label information. Without the true prediction label \(\), training from scratch by respective PnO loss could make it very slow to converge, as a possible reason for demonstrating inferior performance in Table 3. We attempt to expose the model with true prediction labels as a "warm-up" before the PnO training: we initially train for 150 epochs using a PtO MSE loss, followed by 150 epochs of fine-tuning using the PnO loss. The results are denoted as "BB-FTN" and "ID-FTN" respectively, where "FTN" is short for fine-tuning. It could be observed from Figure 5(a b) that this hybrid training on Blackbox and Identity method demonstrates improvements over trained directly by PnO across 4 and 5 over 7 datasets, respectively, and surpasses the two-stage method in some cases. This may indicate that _supervised PtO pretraining could be beneficial for PnO models, especially for the discrete category that inherently does not rely on prediction labels_ (see Table 1 for requirements for prediction labels).

**RQ3: Versatility of PnO under various parameters** We explore the versatility of PnO as follows. **(1)** Figure 6 examines the impact of varying constraint on the training of _KG_ dataset. We set the capacity of 30, 60, and 90. It was observed that as the constraints became more restrictive, the relative regrets became higher. This observation potentially indicates that constraint satisfaction is a prevalent factor constraining the performance of current PnO training methods. **(2)** Figure 7(V1-V2) show the performance when the number of decision variables increases to 40 and 60. With increasing variable size, the two-stage approach remains stable under different problem settings, though its final decision quality is inferior to some of the PnO training models. Conversely, some PnO models exhibited fluctuations and degradation, such as discrete-category methods and point-wise LTR. **(3)** Figure 7(G1-G2) show the generalizability when the PnO models are trained on one problem setting (e.g., constraint of capacity 30) and tested on the other (e.g., constraint of capacity 60 or 90). Similar performance degradation occurs in some PnO models, including discrete-category and statistical-category models, in this setting. This indicates _current PnO approaches may perform inadequately when facing more stringent constraints, larger decision variable sizes, and the need for generalization across diverse optimization parameters_. More details are shown in Appendix D.2.

Figure 6: Regret on knapsack (gen) problem. The decision degrades with tighter constraints.

Figure 7: Regret on knapsack (gen) problem. (V1)–(V2) demonstrates performance with different variable sizes, and (G1)\(\)(G2) generalizes the trained model on capacity 30 to 60, 90 on the test data. Most PnO models degrade when the test set distribution shifts and are less stable than the two-stage approach with different variable sizes. Detailed results in Table. 7.

Conclusion

Regarding predictive CO problems, we systematically review existing PtO/PnO methods, implement a framework for comprehensive assessment, and perform experiments to explore scenarios in which PnO methods could surpass the PtO approaches. Furthermore, we introduce a novel dataset, which will be publicly available along with the framework. We hope to facilitate the community and industry in swiftly reproducing, developing, and deploying new algorithms in the real world.