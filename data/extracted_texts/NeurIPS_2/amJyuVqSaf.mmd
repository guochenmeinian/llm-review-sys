# [MISSING_PAGE_FAIL:1]

[MISSING_PAGE_FAIL:1]

A standard solution to this problem is Markov chain Monte Carlo (MCMC) [12; 64], which relies on the construction of a Markov process which admits the target \(\) as its invariant distribution. One of the most broadly applicable and widely studied MCMC methods is the Metropolis-Hastings (MH) algorithm , which proceeds in two steps. First, given a current sample \(x\), a new sample \(y\) is proposed according to some proposal distribution \(q(|x)\). Then, this sample is accepted with probability \((x,y)=\{1,\}\). This strategy generates a Markov chain with the desired stationary distribution and, under mild conditions on the proposal and the target, also ensures that the Markov chain is ergodic . However, for high-dimensional, multi-modal settings, such methods can easily get stuck in local modes, and suffer from very slow mixing times [e.g., 48].

Naturally, the choice of proposal distribution \(q(|x)\) is critical to ensuring that MH MCMC algorithms explore the target distribution within a reasonable number of iterations. A key goal is to obtain proposal distributions with fast mixing times, which can be applied generically to any target distribution. This is particularly challenging in the face of complex, multi-modal (or metastable) distributions, which commonly arise in applications such as genetics , protein folding , astrophysics , and sensor network localization . On the one hand, local proposals, such as those employed in the Metropolis-Adjusted Langevin Algorithm (MALA)  or Hamiltonian Monte Carlo (HMC) [20; 56] struggle to transition between regions of high-probability, resulting in very long decorrelation times and few effective independent samples [e.g., 49]. On the other hand, global proposal distributions must be very carefully designed in order to avoid high rejection rates, particularly in high dimensions [17; 47].

Another popular approach to sampling is variational inference (VI) [10; 34; 61; 79], which obtains a parametric approximation \(_{^{*}}(x)(x)\) to the target by minimising the Kullback-Leibler (KL) divergence to the target over a parameterized family of distributions \(_{}=\{_{}:\}\). State-of-the-art VI methods use normalizing flows (NFs), which consist of a sequence of invertible transformations between a reference and a target distribution, to define a flexible variational family . There has also been growing interest in the use of continuous normalizing flows (CNFs), which define a path between distributions using ordinary differential equations [15; 27; 45]. CNFs avoid the need for strong constraints on the flow but, until recently, have been hampered by expensive maximum likelihood training.

In recent years, several works have sought hybrid methods which utilize NFs to enhance the performance of MCMC algorithms; see, e.g.,  for a recent review. For example, NFs have been successfully used to precondition complex Bayesian posteriors, significantly improving the performance of existing MCMC methods [e.g., 33; 39; 59; 68]. The synergy between local MCMC proposals and global, flow-informed proposals has also been explored, leading to enhanced mixing rates and effective estimation of multimodal targets [e.g., 24; 67].

Our contributionsIn this paper, we continue this promising line of work, introducing a new probabilistic inference scheme which integrates CNFs with MCMC sampling techniques. Our approach utilizes flow matching (FM), a scalable, simulation-free training objective for CNFs recently introduced by Lipman et al. . This enables, for the first time, the incorporation of CNFs into an adaptive MCMC algorithm. Concretely, our approach augments a local, gradient-based Markov transition kernel with a non-local, flow-informed transition kernel, defined using a CNF. This CNF, and the corresponding transition kernel, are adapted on-the-fly using samples from the chain, which are used to define the probability path for the FM objective. Our scheme also includes an adaptive tempering mechanism, which is essential for discovering multiple modes in complex target distributions. Under mild assumptions, we establish that the flow-network parameters output by our method converge to a local optimum of the FM objective. We then demonstrate empirically the performance of our approach on several synthetic and real-world examples, illustrating comparable or superior performance to other state-of-the-art sampling methods.

## 2 Preliminaries

Continuous Normalizing FlowsA continuous normalizing flow (CNF) is a continuous-time generative model which is trained to map samples from a base distribution \(p_{0}\) to a given target distribution . Let \(v_{t}\) be a time-dependent vector field that runs continuously in the unit interval. Under mild conditions, this vector field can be used to construct a time-dependent diffeomorphic map called a flow \(:^{d}^{d}\), defined via the ordinary differential equation (ODE):

\[}{t}_{t}(x)=v_{t}(_{t}(x)),_{0}(x)=x. \]

Given a reference density \(p_{0}:^{d}_{+}\), and the flow \(\), we can generate a probability density path \(p:^{d}_{+}\) as the pushforward of \(p_{0}\) under \(\), viz \(p_{t}:=[_{t}]_{}p_{0}\), for \(t\). This yields, via the instantaneous change-of-variables formula (e.g., )

\[ p_{t}(x_{t})= p_{0}(x)-_{0}^{t} v_{s}(x_{s})s, \]

where \(x_{s}:=_{s}(x)\), and where \(\) is the divergence operator, i.e. the trace of the Jacobian matrix. In modern applications, the vector field \(v_{t}\) is often parameterized using a neural network \(v_{t}^{}\), in which case the ODE in (2) is referred to as a neural ODE . In turn, this yields a deep parametric model \(_{t}^{}\) for the flow \(_{t}\), known as a CNF .

Flow MatchingOne would typically like to learn a CNF which maps between a given reference density \(p_{0}\) and a target density \(\). Given samples from the target, one approach is to maximize the log-likelihood \(_{x}[ p_{t}^{}(x)]\). In practice, however, maximum likelihood training is very slow as both sampling and likelihood evaluation require multiple network passes to solve the ODE in (2).

Flow Matching (FM) provides an alternative, simulation-free method for training CNFs . Let \(p_{t}(x)\) be a target probability density path such that \(p_{0}=p\) is a simple reference distribution, and \(p_{1}\) is approximately equal to the target distribution. Let \(v_{t}(x)\) be a vector field which generates this \(p_{t}(x)\). Then the FM objective for the CNF vector field \(v_{t}^{}(x)\) is defined as

\[(;)=_{t(0,1)}_{x p_ {t}}[\|v_{t}^{}(x)-v_{t}(x)\|_{2}^{2}]. \]

In practice, we do not have direct access to the target vector field, \(v_{t}(x)\), and so we cannot minimize (4) directly. However, as shown in Lipman et al. [45, Theorem 2], it is equivalent to minimize the conditional flow-matching (CFM) loss

\[(;)=_{t(0,1)}_{x_{1} }_{x p_{t}(|x_{1})}[\|v_{t}^{}(x)-v_{t}( x|x_{1})\|_{2}^{2}], \]

where \(p_{t}(|x_{1})\) is a conditional probability density path satisfying \(p_{0}(x|x_{1})=p_{0}\) and \(p_{1}(x|x_{1})_{x_{1}}\), and \(v_{t}(|x_{1}):^{d}^{d}\) is a conditional vector field that generates \(p_{t}(|x_{1})\). There are various choices for \(p_{t}(|x_{1})\) and \(v_{t}(|x_{1})\). For simplicity, we here assume that the conditional probability path is Gaussian, viz \(p_{t}(x|x_{1})=(x|m_{t}(x_{1}),s_{t}(x_{1})^{2}_{d})\), where \(m:^{d}^{d}\) denotes a time-dependent mean, and \(s:_{+}\) a time-dependent scalar standard deviation. For our experiments, we further adopt the optimal transport conditional probability path introduced in , setting \(m_{t}(x_{1})=tx_{1}\) and \(s_{t}(x_{1})=1-(1-_{})t\) for some \(_{} 1\). In this case, the conditional vector field assumes the particularly simple form \(v_{t}(x|x_{1})=-(1-_{})x}{1-(1-_{})t}\).

## 3 Markovian Flow Matching

In this section, we present our main contribution, an adaptive MCMC algorithm which combines a non-local, flow-informed transition kernel trained via FM; a local, gradient-based Markov transition kernel; and an adaptive annealing schedule. We begin by describing how CNFs can be used within a MH MCMC algorithm.

### MCMC with Flow Matching

Suppose, for now, that we have access to a CNF \((_{t}^{})_{t}\), trained (e.g.) via flow-matching, with corresponding vector field \((v_{t}^{})_{t}\), which generates a probability path \((p_{t}^{})_{t}\) between a reference density \(p_{0}\) and an approximation of the target density \(\). Given a point \(x_{0}^{d}\) on the reference space, we can evaluate the log-density of the pullback of the target distribution \(\) as

\[[_{1}^{}]^{}(x_{0})=(_{1}^{}(x_{0}))- _{1}^{0} v_{t}^{}(_{t}^{}(x_{0}))t. \]Under the assumption that the CNF approximately transports samples from \(p_{0}\) to \(\), we expect that \([_{1}^{}]_{i}p_{0}\) in the target space, and that \([_{1}^{}]^{} p_{0}\) in the reference space. Given that the reference distribution \(p_{0}\) is chosen such that it is easy to sample from, this suggests the following strategy, sometimes referred to as _neural trasport MCMC_ or _neutrinoMCMC_. First, transform initial positions \(x_{1}\) from the target space to the reference space by solving

\[x_{0}\\  p_{1}^{}(x_{1})- p_{0}(x_{0})=x_{1} \\ 0+_{1}^{0}v_{t}^{}(x_{t})\\ - v_{t}^{}(x_{t})t, \]

which integrates the combined dynamics of \(x_{t}\) and the log-density of the sample backwards in time. Then, generate MCMC proposals \(y_{0}\) in the reference space using any standard MCMC scheme which targets the pullback of the target distribution, as defined in (6). Finally, transform accepted proposals back to target space using the forward dynamics, viz

\[y_{1}\\  p_{1}^{}(y_{1})- p_{0}(y_{0})=y_{0} \\ 0+_{0}^{1}v_{t}^{}(y_{t})\\ - v_{t}^{}(y_{t})t. \]

This corresponds to using a transformation-informed proposal in a Markov transition step, an approach which has been successfully applied using (discrete) normalizing flows .

There are various possible choices for the proposal distribution on the reference space (see Appendix A). For example,  consider an independent MH (IMH) proposal, where i.i.d. samples are drawn from the reference distribution. Here we focus on a flow-informed random-walk, motivated largely by its superior empirical performance in numerical experiments. This proposal performs particularly well on high-dimensional problems, where overfitting of the CNF can be corrected with stochastic steps, while exacerbated by independent proposals . Concretely, our flow-informed random-walk transition kernel, summarized in Algorithm 2 (see Appendix A), can be written as

\[P(x,y;,)=(x,y)_{}(y|x)+(1-b(x)) _{x}(y), \]

where \(_{}(y|x)\) is the distribution defined by the transition

\[x_{0}=x+_{1}^{0}v_{t}^{}(_{t}^{}(x))t, y_{ 0}(x_{0},_{}^{2}), y=y_{0}+_{0}^{1} v_{t}^{}(_{t}^{}(y_{0}))t, \]

and \((x,y)=\{1,(x|y)}{(x)_{}( y|x)}\}\) and \(b(x)=_{^{d}}(x,y)_{}(y|x)\).

Training the CNFThus far, we have assumed that it is possible to train a CNF which maps samples from the reference distribution \(p_{0}\) to (an approximation of) the target distribution \(\). Clearly, however, the CFM objective is not immediately applicable in our setting, since we do not have access to samples from the target \(\).

Tong et al.  propose two alternatives in this case: (i) use an importance sampling reweighted objective function, or (ii) use samples from a long-run MCMC algorithm (e.g., MALA) as approximate target samples. Both of these approaches, however, have limitations. The former is unlikely to succeed when the proposal distribution differs significantly from the target distribution, while the latter will only perform well when the chosen MCMC method mixes well.

In this paper, we adopt a different approach, updating the parameters of a CNF based on a dynamic estimate of the CFM objective obtained via an adaptive MCMC algorithm. This is similar in spirit to other recent flow-informed MCMC algorithms , and the _Markovian score climbing_ algorithm in .

### Adaptive MCMC with Flow Matching

OverviewOur adaptive MCMC scheme combines a non-local, flow-informed transition kernel (e.g., a flow informed random-walk) and a local transition kernel (e.g., MALA), which generate new samples from a sequence of annealed target distributions. These new samples are used to define a new estimate of the CFM objective in (5), which is optimized to define a new CNF. These steps are repeated until the samples converge in distribution to the target \(\), and the flow-network parameters converge to a local minima of the flow matching objective (see Proposition 3.1). This scheme, which we refer to as _Markovian Flow Matching_ (MFM), is summarized in Algorithm 1.

SamplingThere is significant freedom regarding the choice of both the local and the non-local MCMC algorithms. In our experiments, we adopt the Metropolis-Adjusted Langevin Algorithm (MALA) as the local algorithm. Thus, the local Markov kernel \(Q\) is given by

\[Q(x,y;)=(x,y)q(y|x)+(1-b(x))_{x}(y), \]

where \(q(y|x)\) is given by

\[q(y|x)(-\|y-x-(x)\|^{ 2})y, \]

and where, as elsewhere, \((x,y)=\{1,\}\) and \(b(x)=_{^{d}}(x,y)q(y|x)\). In principle, however, other choices such as HMC could also be used.

Meanwhile, for the non-local MCMC algorithm, we adopt the flow-informed random walk with non-local Markov kernel \(P\) defined in (9). Together, assuming alternate local and non-local steps, these two kernels define a Markov chain with Markov transition kernel \(R:=P Q\), given explicitly by \(R(x,y;,)=_{}Q(x,z;)P(z,y;,)\). In practice, the balance between local and non-local moves is controlled by the hyperparameter \(k_{Q}\), which sets the number of local steps before a global step.

TrainingFollowing each MCMC step, the parameters of the flow-informed Markov transition kernel \(P\) are updated based on a new estimate of \((;)\). To be precise, suppose we write \(_{t}:=_{0}R^{k}(,;,)\) for the distribution of the Markov chain with kernel \(R(,;,)\) after \(k\) steps, starting from initialization \(_{0}\), where \(R^{k}=R R R\). Our objective function is then given by

\[(;_{k})=_{t(0,1)}_{x_{1 }_{k}}_{x p_{t}(|x_{1})}[||v_{t}^{}(x)-v_ {t}(x|x_{1})||_{2}^{2}]. \]

For our choice of conditional probability path (i.e., the optimal transport path), we can in fact rewrite this objective as [45, Section 4.1]

\[(;_{k},_{})=_{t(0,1)} _{x_{1}_{k}}_{x_{0} p_{0}}[||v_{ t}^{}(_{t}(x_{0}|x_{1}))-v_{t}(_{t}(x_{0}|x_{1})|x_{1})| |_{2}^{2}], \]

where \(v_{t}(x|x_{1})=-(1-_{})x}{1-(1-_{})t}\) and \(_{t}(x|x_{1})=(1-(1-_{}t)x+tx_{1}\). In practice, we will optimize a Monte Carlo estimate of this objective, namely,

\[(;\{x^{i}(k)\}_{i=1}^{N},_{})=_{i=1} ^{N}||v_{t_{i}}^{}(_{t_{i}}(x_{0}^{i}|x^{i}(k)))-v_{t_{i}} (_{t_{i}}(x_{0}^{i}|x^{i}(k))|x^{i}(k))||_{2}^{2}, \]

where \(_{t(0,1)}^{N}\) is the samples from \(N\) chains of our MCMC algorithm after \(k\) iterations, \(x_{0}^{i}}{{}}p_{0}\), and \(t_{i}(0,1)\). The use of \(N\) particles allow the state's mutation to \(N\) computing cores running in parallel at each iteration. Sampling steps can be run in parallel using modern vector-oriented libraries, before each particle is used to approximate the loss and update the parameters. Thus, the speedup gained by using more than one core scales linearly with the number of cores as long as there are as many cores as there are particles.

AnnealingFor complex (e.g., multimodal) target distributions, it can be challenging to learn a CNF that successfully maps between the reference \(p_{0}\) and the target \(\). For example, if the locations of the modes of the target are not known a priori, and the MCMC chains are initialized far from one or more of the modes, it is unlikely that the local MCMC kernel, and therefore the trained flow, will ever discover these modes [e.g., 24, Section IV.C]. To alleviate this problem, one approach is to iteratively target a sequence of annealed densities \(\{_{k}(x)\}_{k=0:K}\), which smoothly interpolate between a simple base distribution \(_{0}(x)\) (e.g., a standard Gaussian), and the target distribution \(_{K}(x):=(x)\). This idea is central to other Monte Carlo sampling methods such as Sequential Monte Carlo (SMC)  and Annealed Importance Sampling (AIS) , as well as sampling methods used in score-based generative modelling [e.g., 70]. In our case, the annealed targets act as intermediary steps within the flow-informed MCMC scheme.

A standard way in which to construct the sequence \(\{_{k}(x)\}_{k=0:K}\) is to use a geometric interpolation, defining

\[_{k}(x)=_{K}(x)^{_{k}}_{0}(x)^{1-_{k}}, \]where \(_{0:K}\) is a sequence of temperatures which satisfies \(0=_{0}<_{1}<<_{K}=1\) (e.g., 55). In practice, it can be difficult to choose a good sequence of temperatures that provides a smooth transition between densities. One heuristic for adaptively setting this sequence is based on the effective sample size (ESS). In particular, by setting the ESS to a user-specified percentage \(\) of the number of particles \(N\), the next temperature \(_{k}\) in the schedule can be determined by solving the recursive equation 

\[_{k}=_{k-1}< 1:_{i=1} ^{N}w_{i}^{_{k-1}}()^{2}}{_{i=1}^{N}w_{i}^{ _{k-1}}()^{2}}=}, \]

where \(w_{i}^{_{k-1}}()=_{K}(x^{i})^{}_{0}(x^{i})^{1- }\,\,_{K}(x^{i})^{_{k-1}}_{0}(x^{i})^{1-_{ k-1}}=[_{K}(x^{i})/_{0}(x^{i})]^{-_{k-1}}\) are new importance weights given the current temperature \(_{k-1}\). In practice, we find that the inclusion of this adaptive tempering scheme is essential in the presence of highly multimodal target distributions, enabling the discovery of modes which are not known _a priori_.

ConvergenceThe output of Algorithm 1 is a vector of parameters \(_{K}\) which defines a CNF \((_{t}^{_{K}})_{t}\). Under the assumption that the parameter estimate converges, that is, \(_{K}_{}^{*}\) as \(K\), where \(_{}^{*}=_{}(;)\) is the global minimizer of the CFM objective \((;)\) in (5), this CNF is guaranteed to generate a probability path \((p_{t}^{})_{t}\) which transports samples from the reference \(p_{0}\) to the true target \(\) (e.g., 45).

In practice, the objective \((;)\) is highly non-convex, and thus it is not possible to establish a convergence result of this type without imposing unreasonably strong assumptions on the vector field \((v_{t}^{})_{t}\). This being said, it is reasonable to ask whether \(_{K}\) converges to a local optimum of the CFM objective. We now answer this question in the affirmative. In particular, under mild regularity conditions, Proposition 3.1 guarantees that \(_{K}^{*}\) almost surely as \(K\), where \(^{*}\) denotes a local minimum of the CFM objective. This proposition closely mirrors (54, Proposition 1). Its proof, which relies on a classical result in (6, Theorem 3.17), is provided in Appendix B.

**Proposition 3.1**.: _Assume that Assumptions B.1 - B.6 hold (see Appendix B). Assume also that \((_{K})_{K}\) is a bounded sequence, which almost surely visits a compact subset of the domain of attraction of \(^{*}\) infinitely often. Then \(_{K}^{*}\) almost surely._

## 4 Related work

In recent years, a number of works have proposed algorithms which combine MCMC techniques with NFs; see, e.g., (2; 28) for recent surveys. Broadly speaking, these algorithms fall into two distinct categories. _NeutraMCMC_ methods leverage NFs as reparameterization maps which simplify the geometry of the target distribution, before running (local) MCMC samplers in the latent space. This technique was pioneered in the seminal paper , and since been investigated in a number of different works [e.g., 13, 33, 44, 54, 58, 68, 82, 84]. _Flow MCMC_ methods, meanwhile, utilize the pushforward of the base distribution through the NF as an (independent) proposal within an MCMC scheme. This approach was first studied by , and further extended in .

More recently,  have introduced adaptive MCMC schemes which combine local MCMC samplers (e.g., MALA or HMC), with a non-local, flow-informed proposal (IMH or i-SIR); see also . Our algorithm combines aspects of both _neutraMCMC_ and _flow MCMC_ methods and, unlike any existing approach, make use of a CNF (as opposed to a discrete NF), by leveraging the conditional flow matching objective. The use of NFs within other Monte Carlo algorithms has also been the subject of recent interest. For example,  consider augmenting SMC with NFs, while  use NFs (or diffusion models) within AIS.

Although less directly comparable to our own approach, several other recent works have proposed to use (controlled) diffusion processes to sample from unnormalized probability distributions. Such works include Zhang and Chen , who introduce the _path integral sampler_, Vargas et al. , who propose the _denoising diffusion sampler_, and Zhang et al. , who introduce _generative flow samplers_. Some other relevant contributions in this direction include .

## 5 Experiments

In this section, we evaluate the performance of MFM (Algorithm 1) on two synthetic and two real data examples. Our method is benchmarked against four relevant methods. The Denoising Diffusion Sampler [DDS; 75] is a VI method which approximates the reversed diffusion process from a reference distribution to an extended target distribution by minimizing the KL divergence. Adaptive Monte Carlo with Normalizing Flows [NF-MCMC; 24] is an augmented MCMC scheme which uses a mixture of MALA and adaptive transition kernels learned using discrete NFs. Flow Annealed Importance Sampling Bootstrap [FAB; 52] is an augmented AIS scheme minimizing the mass-covering \(\)-divergence with \(=2\). Finally, Adaptive Tempered SMC (AT-SMC), i.e. the SMC algorithm described in  using a MALA transition kernel and a sequence of annealed distributions chosen adaptively by solving (17).

For each experiment, all MALA kernels use the same step size, targeting an acceptance rate of close to 1 since we estimate expectations, e.g. in (14), using the current ensemble of particles, rather than a single long chain. Following , we parameterize the vector field as

\[^{*}(t;_{3})v_{t}^{}(x)=(x,t;_{1})+(t;_{2})(x), \]

where the neural networks are standard MLPs with 2 hidden layers, using a Fourier feature augmentation for \(t\), and where NN\({}^{*}\) outputs a real value that reweights the vector field output using the time component. This architecture is also used by DDS [75, Section 4]. Meanwhile, FAB and NF-MCMC use rational quadratic splines . Flows are trained using Adam  with a linear decay schedule terminating at \(_{K}=0\). We report results for all methods averaged over 10 independent runs with varying random seeds. Code to reproduce the experiments is provided at [https://github.com/albcab/mfm](https://github.com/albcab/mfm).

### 4-mode Gaussian mixture

Our first example is a mixture of four Gaussians, evenly spaced and equally weighted, in two-dimensional space. The four mixture components have means \((8,8)\), \((-8,8)\), \((8,-8)\), \((-8,-8)\), and all have identity covariance. This ensures that the modes are sufficiently separated to mean that jumping between modes requires trajectories over sets with close to null probability. Given the synthetic nature of the problem, we can measure approximation quality using the Maximum Mean Discrepancy (MMD) [e.g., 29]; see Appendix C.1 for details. We can also include, as a benchmark, the results for an approximation learned using FM with true target samples. Diagnostics for all models are presented in Table 1, and learned flow samples in Figure 1. Further algorithmic details and results are provided in Appendix C.2.

In this experiment, only our method (Figure 0(a)) and DDS (Figure 0(c)) learn the fully separated modes, reflecting the greater expressivity of CNFs in comparison to the discrete NFs used in, e.g., NF-MCMC(Figure 0(d)). It is worth noting that DDS provides a closer approximation to the real target than MFM and, notably, even FM trained using true target samples (top row). Given that both methods use the same network architecture but a different learning objective, this suggests a potential limitation with the FM objective, at least when using this network architecture. This being said, MFM is notably more efficient than DDS (as well as the other methods) in terms of total computation time. While this is not a critical consideration in this synthetic, low-dimensional setting, it is a significant advantage of MFM in higher-dimensional settings involving real data (e.g., Section 5.3 and Section 5.4).

### 16-mode Gaussian mixture

The second experiment is a mixture of bivariate Gaussians with 16 mixture components. This is a modification of the 4-mode example, with contrasting qualities that illustrate other characteristics of each of the presented methods. In this case, the modes are evenly distributed on \([-16,16]^{2}\), with random log-normal variances. The number of modes reduces the size of sets of (near) null probability between the modes, making jumping between them easier. To increase the difficulty of this model, all methods are initialized on a concentrated region of the sampling space. Diagnostics are presented in Table 1 and learned flow samples in Figure 2. Further details are provided in Appendix C.3.

In this example, DDS collapses to the modes closest to the initial positions while our method captures the whole target. Since the modes are no longer separated by areas of near-zero probability, the discrete NF methods are now able to accurately capture the target density. In this case, FAB marginally outperforms MFM as measured by the MMD, but this slight improvement in performance comes at the cost of a much higher run-time.

### Field system

Our first real-world example considers the stochastic Allen-Cahn model , used as a benchmark in , and described in Appendix C.5. This fundamental reaction-diffusion equation is central to the study of phase transitions in condensed matter systems. Incorporating random forcing terms or thermal fluctuations allows for a stochastic treatment of the dynamics, capturing the inherent randomness and uncertainties in physical systems. This model leads to a discretized target density

  &  &  \\    & MMD & seconds & MMD & seconds \\   FM w/ \(\) samples & \(3.69\)e-4\(\)1.84e-4 & \(22.3 0.64\) & \(1.35\)e-3\(\)6.66e-4 & \(22.4 1.01\) \\  MFM \(k_{Q}=K\) & \(2.37\)e-3\(\)2.29e-3 & \(27.9 1.27\) & \(1.88\)e-2\(\)3.67e-3 & \(28.2 2.84\) \\ MFM \(k_{Q}=10\) & \(8.13\)e-4\(\)4.41e-4 & \(117. 5.65\) & \(2.87\)e-3\(\)9.67e-4 & \(89.6 5.19\) \\ DDS & \(1.76\)e-4\(\)2.32e-4 & \(114. 0.68\) & \(1.02\)e-1\(\)4.10e-2 & \(115. 0.64\) \\ NF-MCMC & \(5.85\)e-3\(\)3.91e-3 & \(72.0 11.7\) & \(8.05\)e-3\(\)1.42e-2 & \(67.0 12.3\) \\ FAB & \(2.69\)e-4\(\)2.06e-4 & \(101. 3.24\) & \(1.51\)e-3\(\)1.06e-3 & \(102. 4.32\) \\ AT-SMC & \(3.95\)e-2\(\)2.90e-2 & \(2.18 0.26\) & \(1.73\)e-2\(\)5.30e-3 & \(2.19 0.21\) \\  

Table 1: Diagnostics for the two synthetic examples. MMD is the Maximum Mean Discrepancy between real samples from the target and samples generated from the learned flow. Results are averaged and empirical 95% confidence intervals over 10 independent runs.

Figure 1: Comparison between MFM, FAB, DDS, and NF-MCMC. Samples from the target density for the 4-mode Gaussian mixture example.

which takes the form

\[(x)=-_{i=1}^{d+1}(x_{i}-x_{i-1})^{2}+ _{i=1}^{d}(1-x_{i}^{2})^{2}, \]

with \( s=\), and boundary conditions \(x_{0}=x_{d+1}=0\). In our experiments, we take \(d=64\). Meanwhile, following , other parameter values are chosen to ensure bimodality at \(x= 1\): \(a=0.1\), \(b=1/a=10\), and \(=20\). The bimodality induced by the two global minima complicates mixing when using traditional MCMC updates. Learning the global geometry of the target and using that information to propose transitions facilitates movement between modes. Unlike previous work [e.g., 24], we deliberately choose not to employ an informed base measure. Instead, we opt for a standard Gaussian with no additional information, making the problem significantly more challenging. This choice illustrates the robustness of our approach.

Numerical diagnostics for each method are presented in Table 2. In this case, we use the Kernelized Stein Discrepancy (KSD) as a measure of sample quality [e.g., 26, 46]; see Appendix C.1 for details. While this is not a perfect metric, it does allow us to qualitatively compare the different methods considered.

In this case, the tempering mechanism of our method is crucial for ensuring that the learned flow does not collapse on one of the modes and instead explores both global minima. This is confirmed when plotting the samples generated in the grid in Figure 3. This experiment demonstrates the ability of our method to capture complex multi-modal densities, even without an informed base measure, at a _significantly_ lower computational cost (e.g., 10-25x faster) than competing methods. Indeed, while FAB was the best performing method in this experiment as measured by the KSD, it failed to capture both of the modes in the target distribution, and required a much greater total computation time (see Table 2).

It is worth noting that MFM (and the other two benchmarks, DDS and FAB) significantly outperformed NF-MCMC in this example, despite the similarities between MFM and NF-MCMC. While we tested various hyperparameter configurations for NF-MCMC, we were not able to find a setting that achieved comparable results in the absence of an informed base measure.

Figure 3: Comparison between MFM, FAB, DDS, and NF-MCMC. Representative samples from the target density for the Field system example.

Figure 2: Comparison between MFM, FAB, DDS, and NF-MCMC. Samples from the target density for the 16-mode Gaussian mixture example.

### Log-Gaussian Cox process

Bayesian inference for high-dimensional spatial models is known to be challenging. One such model is the log-Gaussian Cox process (LGCP) introduced in , which is used to model the locations of 126 Scots pine saplings in a natural forest in Finland. See Appendix C.6 for full details. The target space is discretized to a \(M=40 40\) regular grid, rendering the target dimension \(d=1600\). In Table 2, we report diagnostics for each algorithm.

In this case, the lack of multimodality in the target makes it a good fit for non-tempered schemes. Similar to the previous example, NF-MCMC is unable to obtain an accurate approximation to the target distribution. We suspect that this may be a result of non-convergence: due to memory issues, it was not possible to run NF-MCMC (or FAB) for more than \(K=10^{3}\) iterations. This also explains the (relatively) smaller run times of these algorithms in this example. By a small margin, DDS provides the best approximation of the target, slightly outperforming MFM and FAB. Meanwhile, MFM provides a good approximation to the target at a lower computational cost with respect to its competitors.

## 6 Conclusion

**Summary**. In this paper, we introduced Markovian Flow Matching, a new approach to sampling from unnormalized probability distributions that augments MCMC with CNFs. Our method combines a local Markov kernel with a non-local, flow-informed Markov kernel, which is adaptively learned during sampling using FM. It also incorporates an adaptive tempering mechanism, which allows for the discovery of multiple target modes. Under mild assumptions, we established convergence of the flow network parameters output by our algorithm to a local optimum of the FM objective. We also benchmarked the performance of our algorithm on several examples, illustrating comparable performance to other state-of-the-art methods, often at a fraction of the computational cost.

**Limitations and Future Work**. We highlight three limitations of our work. First, our theoretical result established convergence of the flow network parameters obtained via MFM to a _local_ minimum of the FM objective. Further work is required to understand how well these local minima generalize, in order to accurately quantify how accurately the corresponding CNF captures the target posterior. Second, we did not establish non-asymptotic convergence rates for our method. Finally, since it was not the main focus of this work, we did not explore in great detail other choices of architecture for the flow network. We expect that, for certain targets, this could have a significant impact on the performance of MFM. Indeed, a promising avenue for further research lies in developing tailored CNFs designed for particular posterior distributions. This approach would go beyond the current practice of including the gradient of the log-posterior and instead exploit unique characteristics intrinsic to each model when constructing the flow.