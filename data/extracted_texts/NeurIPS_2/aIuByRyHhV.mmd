# Rethinking Parity Check Enhanced

Symmetry-Preserving Ansatz

 Ge Yan, Mengfei Ran, Ruocheng Wang, Kaiseng Pan, Junchi Yan

Dept. of CSE & School of AI & Zhiyuan College, Shanghai Jiao Tong University

{yange98,rmf2021,Ignite,pks0813,yanjunchi}@sjtu.edu.cn

Correspondence author. This work was partly supported by NSFC (92370201, 62222607) and Shanghai Municipal Science and Technology Major Project under Grant 2021SHZDZX0102.

###### Abstract

With the arrival of the Noisy Intermediate-Scale Quantum (NISQ) era, Variational Quantum Algorithms (VQAs) have emerged to obtain possible quantum advantage. In particular, how to effectively incorporate hard constraints in VQAs remains a critical and open question. In this paper, we manage to seamlessly combine the Hamming Weight Preserving ansatz with a topological-aware parity check on physical qubits to enforce error mitigation and further hard constraints. We demonstrate such a combination significantly outperforms peer VQA methods on both quantum chemistry problems and constrained combinatorial optimization problems e.g. Quadratic Assignment Problem. Our extensive experimental results on both simulators and superconducting quantum processors verify that the combination of HWP ansatz with parity check is among the most promising candidates to show quantum advantages in the NISQ era to solve more realistic problems.

## 1 Introduction

Variational Quantum Algorithms (VQAs)  and their derivatives  have garnered increasing attention as numerous studies investigate their potential to achieve quantum supremacy. With the advent of the NISQ era  and the improved deployment capability , the exploration of new VQAs has accelerated, as these algorithms have shown promise in delivering quantum advantage on near-term quantum devices . However, despite their potential, commonly used VQAs such as the QAOA  for Quadratic Unconstrained Binary Optimization (QUBO) and UCCSD  for ground state energy estimation are not inherently designed to handle hard constraints. Typically, these constraints are modeled as soft penalty terms within the objective function, which may not be the most efficient approach. Addressing the natural incorporation of symmetries and hard constraints directly into VQAs remains an open and critical challenge for advancing the field.

In this paper, we investigate Hamming Weight preserving (HWP) ansatz  and parity check  as a novel approach for error mitigation and the imposition of hard constraints in quantum circuits, rather than modeling these constraints as penalty terms in the Hamiltonian, as is common in the literature . The HWP ansatz, operating in a constrained subspace, utilizes parameterized gates that maintain the number of non-zero elements in the quantum state. Recent work  has thoroughly analyzed the expressivity and trainability of the HWP ansatz, demonstrating its outstanding performance in capturing fundamental symmetries, such as total spin conservation. Meanwhile, quantum LDPC code  and surface code  have been widely widely adopted in quantum error correction through the use of stabilizers to detect and correct qubit errors. However, a significant challenge remains in identifying quantum ansatze that naturally facilitate error correction mechanisms. In response, we propose a combined framework that integrates the HWP ansatz with parity check operations. Since the HWP ansatz inherently preserves the number of non-zero elements in quantum states, it offers a promising foundation for enhancing parity check performance in mitigating errors. By employing parity checks as projective measurements, quantum states can beconstrained directly to the problem subspace, thereby introducing a robust mechanism for error mitigation while expanding the utility of parity checks beyond their conventional role. This approach allows for more effective error correction and constraint enforcement within quantum circuits.

In this paper, we first analyze the effect of utilizing parity check as an error mitigation method for HWP ansatz on popular quantum chemistry problems, whose (symmetry) constraints can be effectively addressed by HWP. The parity check block is constructed by a cascade of CNOT gates which only requires nearest neighbor connectivity of physical qubits. By repeatedly inserting parity check blocks in the quantum circuit we can mitigate the influence of unexpected bit-flip errors. The results on noiseless simulator demonstrate that the proposed universal HWP ansatz is able to exceed UCC ansatz with single, double, and even triple excitation. We also test the performance of parity checks with HWP ansatz against other symmetry verification (SV) methods [38; 70] with UCC ansatze. Under the simulated noise, we observe that only verifying the number of non-zero elements at the end of the circuit is not enough to determine whether there is an occurrence of error, so constantly parity checks in the circuit are essential for detecting bit-flip errors.

We then combine HWP ansatz and parity check to develop an efficient paradigm to incorporate additional hard constraints beyond the capability of HWP, to enable solving other constrained problems in classic computing, specifically Quadratic Assignment Problem (QAP) . This problem is known an NP-hard combinatorial optimization (CO) problem, as widely studied in literature in both classic machine learning (ML)  and quantum ML . It aims to find an optimal permutation matrix with each column and row having only one non-zero element. Specifically, we map the permutation matrix to the physical qubit lattice topology with each qubit connected to its four nearest neighbors. We then apply HWP layers on the rows to ensure a smaller subspace with parity checks on the columns appearing at intervals to further restrict the states to QAP subspace. The final loss is calculated with in-constraint states so that we can find the optimal solution within the constraints.

To further illustrate the capability and efficiency of the proposed approach, we conduct experiments on both simulators and superconducting quantum processors. We compare a wide range of baseline methods with soft constraints, e.g., HEA , QAOA , XY mixer , and we also add hard constraints to some of them with the proposed paradigm. The numerical results on the simulator demonstrate the outstanding performance of the proposed hard constraint paradigm. We also test our methods on the Traveling Salesman Problem (TSP) to illustrate the capability of our methods on other CO problems by reducing it into QAP. For the hardware experiments on a superconducting quantum processor, the proposed method also show promising performance, especially with the physical qubit topology (no SWAP gates required in the compilation). We move the related works and preliminaries to the Appendix. **The contributions of this paper are:**

1) We illustrate how to utilize parity check to mitigate quantum errors and incorporate further constraints for HWP ansatz. The combination of these two is among the most promising candidates to demonstrate quantum advantages in the NISQ era (for VQA) to solve more realistic problems.

2) We discuss the connection between HWP and UCC ansatze on quantum chemistry problems and further examine the efficiency of parity check as error mitigation on the simulator with noise. Results illustrate that universal two-qubit HWP gates exceed UCC with high-order excitation terms and parity check in between HWP gates can mitigate errors better than SV [38; 70].

3) We propose a novel hard-constraint VQA with parity check as further constraints for HWP. We map the permutation matrix in QAP to the physical qubit topology and enable the maximum utility of qubit connectivity. The superior performance over peer VQAs on both simulator and quantum processor shows the capability and efficiency of our method on constrained CO, e.g. QAP and TSP.

## 2 Parity Check as Error Mitigation for HWP

We first illustrate how to use parity check as error mitigation for HWP ansatz. The HWP ansatz maintains the number of non-zero elements in the whole unitary transformation, which makes it easy to detect any unexpected bit-flip. By constantly applying parity checks we can correct these errors.

### Ground State Energy Estimation

The ground state energy estimation problem, which is the very first step in computing the energetic properties of molecules and materials, has received intensive attention with various VQE approaches . The ground state of a molecule is the stationary state with the lowest allowed energy, which can be estimated given the types and relative coordinates of the atoms in the molecule and the number of orbitals and electrons. Providing a molecular Hamiltonian \(_{m}\), and a trial wave function \(\), the ground state energy \(E_{0}\) is bounded by :

\[E_{0}_{m}}{}, \]

where the equality holds if and only if the parameterized wavefunction \(\) is the ground state. To solve this problem on a quantum computer, we need to design the ansatz wavefunction, which is bound to be unitary operations since we are operating on a quantum computer and all the quantum gates are unitary transformations. We then describe the unitary parameterized ansatz as \(()\). The qubits are initialized as \(^{n}\) (abbreviated as \(}\)) with \(n\) as the number of orbitals under the Jordan-Wigner transformation . Notice that any quantum state is necessarily a normalized wavefunction, so the cost function of the VQE problem is :

\[E_{VQE}=_{}}^{}( )_{m}()}. \]

The molecular Hamiltonians often come with symmetry constraints, and we can utilize HWP ansatz to reduce the evolving space and draw support from parity check as an error mitigation method.

### HWP ansatz for Quantum Chemistry

We first introduce two basic models, namely the Fermi-Hubbard model  and Unitary Coupled Cluster model (UCC) , to show how HWP ansatz can be linked to quantum chemistry. Both models describe the hopping of electrons on orbitals (UCC model) or sites (Hubbard model) by creation and annihilation operators (see definition in Apx. B.2). We have the following observation:

_Remark 2.1_.: Both hopping terms in the UCC and Fermi-Hubbard model are HWP operators.

Recall the hopping term on adjacent sites \(i\) and \(j\) in the Fermi-Hubbard model is defined as:

\[_{FH}=a_{i}^{}a_{j}+a_{j}^{}a_{i}=( []{cccc}0&0&0&0\\ 0&0&1&0\\ 0&1&0&0\\ 0&0&0&0)=_{x}_{x}+_{y}_{y}. \]

where \(a\) and \(a^{}\) are the annihilation and creation operators, respectively (see detailed definition in Apx. B.2). Similarly, the cluster operator in the coupled cluster theory is \(T=a_{i}^{}a_{j}\). For the state transformation for UCC model, we follow the form \(=e^{T-T^{}}}\), where \(T-T^{}\) is an anti-Hermitian operator which makes it suitable for quantum computers since the exponential of an anti-Hermitian operator is a unitary operator. The Hamiltonian for the single excitation term is

\[_{UCC}=}(T-T^{})=}(0&0&0&0\\ 0&0&1&0\\ 0&-1&0&0\\ 0&0&0&0)=(0&0&0&0\\ 0&0&-&0\\ 0&&0&0\\ 0&0&0&0). \]

Both of the above Hamiltonian fits the definition of HWP (see Eq. 21 in Apx.B for the introduction of the preliminaries of HWP), so they are both HWP operators.

**Lemma 2.2**.: _The hopping terms in UCC and Fermi-Hubbard are not universal in the HWP subspace._

According to Theorem B.1 (see details in Apx. B), an HWP operator with a given connectivity is universal if and only if the dimension of the corresponding dynamical lie algebra (DLA) is \(d_{k}^{2}\) with \(d_{k}=\), where \(n\) and \(k\) is the number of orbitals and electrons, respectively. For nearest neighbor (NN) connectivity, we can derive the dimensions of DLA for operators in Eq. 3 and Eq. 4 as follows:

\[dim_{nn}(_{UCC})=n(n-1), dim_{nn}(_{ FH})=(n+1)(n-1)&n\\ n(n-1)&n \]

For fully connected (FC) connectivity, the dimensions of DLA for the two operators are:

\[dim_{fc}(_{UCC})=d_{k}(d_{k}-1), dim_{fc}( _{FH})=(d_{k}+1)(d_{k}-1)&n 2k\\ (d_{k}+2)(d_{k}-2)&n=2k \]

All of the dimensions do not meet the requirement of \(d_{k}^{2}\), so both Eq. 5 and Eq. 6 are not universal in the HWP subspace, which aligns with the fact that Eq. 3 and Eq. 4 are truncated hopping terms.

**Theorem 2.3**.: _An ansatz \(()\) can solve the ground state energy estimation problem without truncation if the ansatz is universal under the \(d_{k}\)-dimensional HWP subspace._

The detailed proof is provided in Apx. C. In contrast to the Fermi-Hubbard model that does not have higher-order hopping terms, the UCC model has double and triple excitation operators  able to improve the accuracy of the final ground states. However, the double and triple excitation operators require 4-qubit and 6-qubit gates respectively, which makes it unaffordable when decomposing them into basic gates. Thus, we seek two-qubit HWP gates (much easier to implement than double and triple excitation operators) that are universal under the HWP subspace with no truncation at all.

**Definition 2.4**.: We propose an HWP gate namely NBS with the Hamiltonian and dimension of DLA:

\[_{NBS}=(0&0&0&0\\ 0&1&&0\\ 0&-&1&0\\ 0&0&0&0),()=\{d _{k}^{2}&n 2k,\\ d_{k}^{2}/2-1&n=2k.. \]

NBS gate is very close to universal under NN connectivity and simpler than the one proposed in . Thus, we can use the NBS gate to construct an NN connected ansatz without any truncation (UCCSD ) or prior knowledge about quantum chemistry (adaptVQE ).

A common error mitigation technique in VQE for the UCC and Hubbard model is SV , which discards runs where the final and initial occupations do not match. This method leverages the fact that these VQE ansatze exhibit symmetries such as number conservation per spin sector and time-reversal symmetry. Specifically, when verifying the symmetry of total spins, one counts the number of non-zero elements in the final state to detect any unexpected bit-flip or readout errors that may alter the total spin count. However, SV only reflects symmetries in the final state and requires readout of all qubits (or at least an equal number of measurements), adding complexity. To simplify both the verification of final states and the intermediate states during computation, we propose utilizing parity checks, a technique commonly employed in classical and quantum error correction. Unlike SV, which counts the number of non-zero elements in the quantum state, parity checks only evaluate the parity of these non-zero elements. While a single parity check extracts less information than SV, applying parity checks continuously throughout the quantum circuit ensures that the final state retains the same Hamming Weight as the initial state (as long as the probability of multiple bit-flips occurring between two parity checks is sufficiently low). The HWP ansatz is an ideal complement to parity checks because it guarantees a constant HW for the intermediate states, allowing for the seamless integration of parity checks at any point in the ansatz. This approach not only mitigates errors but also simplifies the error detection process by embedding it directly into the circuit, as illustrated in Fig. 1.

### Simulated Experiments on State Preparation

**Dataset:** We select three well-studied molecules, i.e. Hydrogen (H\({}_{2}\)), Lithium Hydride (LiH), and Water (H\({}_{2}\)O). The molecular Hamiltonian is obtained from the Python package OpenFermion . The computational basis for all the molecules is STO-3G with Jordan-Wigner transformation. To simulate the circuit with noise on Qiskit, we utilize the Aer-simulator from Qiskit based on the density matrix which is time-consuming. Therefore, we freeze some of the inactive orbitals to reduce the problem size of the above molecules. The detailed molecular information is listed in Tab. 1

**Baselines:** To show the efficiency of the HWP ansatz and the superiority of combining HWP ansatz with parity check, we select the well-studied UCC ansatz as our baselines. To better illustrate that universal HWP ansatz is able to solve the state preparation problem without any truncation, we include single excitation (UCCS), double excitation (UCCSD), and triple ex

   Molecules & H\({}_{2}\) & LiH & H\({}_{2}\)O \\  \(n\) & 4 & 8 & 8 \\ \(k\) & 2 & 2 & 4 \\ \(d_{k}\) & 6 & 28 & 70 \\   

Table 1: Statistics of molecules. \(n\), \(k\), \(d_{k}\) is the number of orbitals, electrons, and HWP subspace dimension respectively.

Figure 1: The overall circuit structure for parity checks and HWP ansatz.

the ansatze are implemented with Qiskit-Nature  and initialized with Hartree-Fock state. The optimizer is SLSQP.

**Results on Simulators** The sensitivity analysis on the number of parity checks and hyperparameter settings are listed in Apx. E. We provide the results on the simulator with noise in Tab. 2. We first focus on the results of UCC ansatze with different excitation and the proposed HWP ansatz without noise. Notice that H\({}_{2}\) and LiH only have 2 active electrons so it is impossible to apply triple excitation in the ansatz. It is shown that adding high-order excitation terms in the UCC ansatz can improve the results, and the proposed universal HWP ansatz is able to solve the problem with no truncation at all which leads to energy with error less than \(1 10^{-10}\). The circuit depth of HWP ansatz is also much less than UCCSD and UCCSDT. Detailed comparisons of the circuit statistics are listed in Tab. 8

We make several important observations on the results with noise and error mitigation methods. 1) UCCS outperforms other methods with noise since it is extremely shallow. 2) SV with deep circuit is useless since the parity of the output state is approximate to \(0.5\), indicating the results for each qubit are close to a uniform superposition state. 3) More shots per Pauli string would be beneficial to better illustrate the performance of error mitigation methods. 4) Parity check can improve the results on deep ansatz. By combining other error mitigation approaches (such as readout error mitigation), we may further improve the accuracy. Therefore, we can conclude that parity check is an efficient error mitigation method for HWP ansatz, which can improve the result quality.

## 3 Parity Check as Further Constraints for QAP

Apart from the quantum chemistry problems, the HWP ansatz is proved to be able to serve as a hard constraint for combinatorial optimization problems . In this section, we will demonstrate how to utilize parity check to enforce additional hard constraints for HWP ansatz so that we are capable of solving more complicated constraints.

### Quadratic Assignment Problem

The Quadratic Assignment Problem (QAP) is a well-studied NP-hard problem dated back to . A typical QAP instance of size \(m\) is given by two matrices \(^{m m}\), \(^{m m}\), defining the flows between facilities and the distances between locations . Its objective with constraints is:

\[\;_{i,j=1}^{m}_{k,p=1}^{m}_{ij}_{kp}_{ik}_{jp}\;_{i=1}^{m}_{ij}=1,\; _{j=1}^{m}_{ij}=1,\;1 i,j m, \]

where \(\{0,1\}^{m m}\) is the permutation matrix illustrated in Fig. 2(a). The essence of QAP is to find the best permutation matrix which minimizes the objective function. Further, we define \(^{m^{2} m^{2}}\) as the energy matrix with \(=\), corresponding to the vector product form of the flow and distance matrices. The QUBO form of QAP is:

\[\;()^{}( )\;_{i=1}^{m}_{ij}=1,\;_{j=1}^{m }_{ij}=1,\;1 i,j m, \]

where \(()\{0,1\}^{m^{2} 1}\) denotes a vector by concatenating the columns of matrix \(\). We can further derive the Hamiltonian of the Ising form of QAP:

\[_{QAP}=_{i,j=1}^{m}_{k,p=1}^{m}_{ij} _{kp}(I-_{ik}^{z})(I-_{jl}^{z}), \]

    &  & _{k}\))} & _{k}\)} &  &  & _{k}\))} &  &  & _{k}\))} &  &  \\    & & & & & & & & & & & & \\   &  &  &  &  &  &  &  &  &  &  &  &  \\  & & & & & & & & & & & & \\  & & & & & & & & & & & \\  & & & & & & & & & & & \\   &  &  &  &  &  &  &  &  &  &  &  \\  & & & & & & & & & & & & \\  & & & & & & & & & & & \\  & & & & & & & & & & & \\  & & & & & & & & & & & \\   &  &  &  &  &  &  &  &  &  &  &  & _{GAP}^{2^{n} 2^{n}}\), and \(^{z}\) is the pauli-z matrix. Thus, we need \(n=m^{2}\) qubits to solve QAP.

### HWP ansatz for Combinatorial Optimization

The QAP can be seen as optimizing a matrix \(\{0,1\}^{m m}\) with each row and each column having only one non-zero element. We can easily map the permutation matrix to the topology of the superconducting qubits as illustrated in Fig. 2(b). The coupler denoted as \(c_{i}\) between two qubits stands for the allowance of two-qubit gates between the corresponding two qubits. It shows a commonly used topology  for superconducting quantum processors with each qubit connected to its four nearest neighbors through couplers. This kind of topology on the NISQ device can produce better connectivity than the nearest neighbor connectivity for logical qubits where each logical qubit is connected to only two nearest neighbors. Therefore, we aim to make full use of the qubit topology to provide an algorithm that is suitable for those existing superconducting quantum processors.

Notice that if we map each element in matrix \(\) to a qubit, we can easily adopt the HWP ansatz to meet the constraints of QAP. Each row and column of the qubits have exactly one \(|1\) with the rest as \(|0\), which can be converted to an HWP problem with dimension as \(d_{k}=\). Without loss of generality, we apply \(m\) independent HWP ansatz on the row and we utilize a projective measurement on the column to ensure the post-measurement states are feasible states for QAP. Here we will introduce how to use parity check circuit to implement the projective measurement with only one ancilla qubit for each column. Since each column has exactly one \(|1\), a sufficient and necessary condition for QAP is that the parity check results for all \(m\) columns are all odd.

A detailed circuit for parity check is illustrated in Fig. 2(c). HWP ansatz is applied on each row of physical qubits and parity check is applied on each column. We repeat the NN connected HWP layers for \(L\) times and then apply a parity check on each ancilla qubit. After measuring the ancilla qubits, we flip the working qubits back and reset the ancilla qubits as \(|0\). The whole block is repeated \(T\) times before we measure all the working qubits and calculate the loss. For the working qubits, the initial state should be a trivial state in the QAP subspace that can be easily prepared such as the identity permutation with qubit \(q_{ii}\) as \(|1\) and the rest as \(|0\). The overall parameterized evolution can be written in the following unitary transformation:

\[_{QAP}()=_{t=1}^{T} _{l=1}^{L}_{HWP}(_{t,l}), \]

where \(_{HWP}\) is the unitary of the HWP layer with \(_{t,l}\) as the parameters in block \(t\) layer \(l\), and \(\) denotes the projective measurement by parity check. We utilize a cascade of CNOT gates to transfer the parity information from working qubits to the ancilla qubits, which will not further include SWAP gates in execution. Note that the parity check measurement on the ancilla qubits will not destroy

Figure 2: (a) The QAP instance with four facilities \(\{A,B,C,D\}\) mapped to four locations \(\{0,1,2,3\}\). The permutation matrix encodes the mapping and satisfies the constraint that each facility is mapped to only one location and vice versa. (b) The topology of the physical qubits of superconducting quantum processor. For QAP with \(m=3\), we select \(n=m^{2}\) working qubits denoted as \(q_{ij}\) and \(m\) ancilla qubits denoted as \(a_{i}\) with the structure shown on the right. Each qubit \(q_{ij}\) maps to the element \(_{ij}\) in the permutation matrix and suffice the constraints that each row and column has only one \(|1\). (c) The overall circuit for QAP with all the working and ancilla qubits is named the same as in (b).

the in-constraint quantum states on the working qubits, so we are able to restrict the states without collapsing the whole quantum system. After measuring the ancilla qubits, we flip back all the working qubits and reset the ancilla qubits as \(\).

The parity checks can provide certain entanglement on the topological columns of qubits. The quantum states on the working qubits before the first parity check is \(m\) independent pure states denoted as \(}\) with \(i[0,m)\) on each row. The quantum state can be written as:

\[_{1}=^{ m}_{i=0}^{m-1}}_{i=0}^{m-1}}^{} ^{ m}, \]

where \(_{1}\) is a density matrix for block \(1\) before parity check. After the first parity check, the states on the working qubits are transformed from \(m\) independent quantum states on the rows to feasible states in the QAP subspace and other entangled states outside the subspace.

\[_{1}=_{i=0}^{2^{m}-1}_{1}(i) , \]

where \(_{1}\) is the density matrix for block \(1\) after parity check, and \(\) denotes the quantum states on the ancilla qubits. We can see that the measurement changes the basis of \(_{1}\) and \(_{1}\), resulting feasible states for QAP in \(_{1}\). Similarly, we denote the quantum state after the final parity check as

\[_{T}=_{i=0}^{2^{m}-1}_{T}(i) . \]

Since the quantum states on the working qubits are in QAP subspace if and only if the ancilla qubits are all measured as \(\), the feasible final state on the working qubits is \(_{T}(2^{m}-1)\). The loss is:

\[_{QAP}=\,_{QAP} _{T}(2^{m}-1), \]

where \(_{QAP}\) is the Hamiltonian of QAP with definition in Eq. 10. We only update the parameters based on those in-constraint states so that we are able to further find the optimal answer in the QAP subspace. The expectation value of obtaining \(_{T}(2^{m}-1)\) is

\[(p_{_{T}(2^{m}-1)})=}, \]

where \(p_{_{T}(2^{m}-1)}\) denotes the probability of obtaining \(_{T}(2^{m}-1)\) from all the possible states. We can further derive the equation using the Stirling's formula and we have

\[(p_{_{T}(2^{m}-1)})( {m}{})^{m}}{m^{m}}=}{^{m}}. \]

The expectation of obtaining feasible states decreases exponentially with \(m\). However, this order of the expectation value is acceptable as the Ising model for QAP requires \(n=m^{2}\) qubits. We will further show in the experiments that we generally have a better probability of obtaining feasible states and this is much better than using soft constraints.

### Simulated Experiments on Quadratic Assignment Problem

**Dataset:** We generated a dataset comprising random instances of QAPs, with 100 instances for each size \(m=\{3,4,5,6\}\). Each instance includes a \(m m\) distance matrix \(\) and a flow matrix \(\)

   constraint & method & \(dim\) & \(m=3\) & \(m=4\) & \(=5\) & \(m=6\) & \(m=3\) & \(m=4\) & \(m=5\) & \(m=6\) \\   & HEA  & \(2^{n}\) & 0.7000 & 0.0000 & — & 0.1746 & 0.0000 & — & — \\  & QAOA  & \(2^{n}\) & 0.4715 & 0.5491 & — & — & 0.2497 & 0.0000 & — & — \\  & XYMixer-NN  & \(n\\ m\) & 0.5672 & 0.6927 & — & — & 0.1998 & 0.0999 & — & — \\  & XYMixer-FC  & \(n\\ m\) & 0.9957 & 0.4707 & — & — & 0.8738 & 0.1196 & — & — \\  & NBS-NN & \(n\\ m\) & 0.7969 & 0.6046 & — & — & 0.5495 & 0.0500 & — & — \\  & NBS-FC & \(n\\ m\) & 0.9975 & 0.4517 & — & — & 0.8765 & 0.0788 & — & — \\    & XYMixer-Hard  & \(m!\) & **1.0000** & 0.9931 & 0.9837 & 0.9474 & **1.0000** & 0.8498 & 0.7500 & 0.3500 \\  & NBS-Hard & \(m!\) & **1.0000** & **0.9991** & **0.9919** & **0.9826** & **1.0000** & **0.9448** & **0.8500** & **0.5000** \\   

Table 3: Results on QAP simulation with the best in bold and the best in soft constraints underlined.

with elements \(_{ij}=_{ji}\) and \(_{ij}=_{ji}\), drawn from a uniform distribution \(\). \(_{ij}=_{ji} U(0,1)\), \(_{ij}=_{ji} U(0,1),i j\).

**Baselines.**_HEA :_ the most commonly used quantum machine learning model with a simple structure and only nearest neighbor connectivity is required; _QAOA :_ the originator of utilizing VQA to solve QUBO problem; _XYmixer :_ hard constraints and is proved to be an HWP gate with the Hamiltonian as \(_{XY}=^{x}^{x}+^{y}^{y}\).

We apply soft constraints to the above baselines by adding a penalty term in the Hamiltonian with \(\) as the permutation matrix from the final state:

\[C_{Penalty}=_{i=0}^{m-1}_{j=0}^{m-1}_{ij}-1^{ 2}+_{j=0}^{m-1}_{i=0}^{m-1}_{ij}-1^{2} \]

\[_{QAP-soft}=_{QAP}+ C_{ Penalty}, \]

where \(\) is the final state and \(\) is the penalty coefficient. Moreover, we adopt XYmixer as a HWP gate in the proposed hard constraint paradigm to see the performance between different HWP gates.

**Evaluation Metric:** To better illustrate the performance difference across methods, we utilize the approximation ratio \(\) as the evaluation metric, defined as:

\[=_{max}-_{QAP}}{_{max}-_ {min}}, \]

where \(_{max}\) and \(_{min}\) denote the maximum and minimum loss for in-constraint states. For an infeasible state, the loss \(_{QAP}\) is equal to \(_{max}\), so the approximation ratio \(=0\). For an in-constraint state, \(\) is a value between \(0\) and \(1\), and it evaluates the overall performance. Apart from the approximation ratio, we also evaluate the methods based on the probability of obtaining the optimal solution denoted as \(p_{optimal}\). We utilize both metrics to avoid the situation that we converge to a second-best solution which yields high \(\) and low \(p_{optimal}\).

**Hyperparameter Setting:** In this section, we will discuss two crucial hyperparameters namely the penalty weight \(\) for soft constraints and the number of parity checks \(T\) for hard constraints. We first analyze the number of parity checks required in our model. This experiment is conducted with \(L T\) remains to be a constant so that adding parity checks will not increase the number of parameters. From Fig. 5, we can see that the probability of obtaining feasible states from the last parity check declines slowly, but the probability of obtaining an optimal solution requires a specific number of parity checks. Moreover, parity checks with excessively small intervals might cause the in-constraint states to be trapped at the initial state as the HWP layers in between two parity checks are not able to transfer the initial state to other feasible states. Thus, we set the number of parity checks \(T=4\) to balance the circuit depth and the quality of results. (Details analysis for penalty weight \(\) for soft constraints are in Apx. F.2)

**Results on simulators:** The results are shown in Tab. 3. We provide the dimension of the space in which these approaches operate. When utilizing the soft constraints, HWP ansatz can reduce the dimension from \(2^{n}\) to \(\). However, when we use hard constraints, the dimension before the parity check is \(m^{m}\) and it further decreases to \(m!\) which is exactly the problem complexity of QAP. Considering the space of those methods, we are unable to provide results for baselines with soft constraints for \(m=5\) (25 qubits) and \(m=6\) (36 qubits).

All the results for soft constraints are conducted regardless of the physical qubit topology. HEA, XYmixer-NN, and NBS-NN satisfy the nearest neighbor topology while QAOA, XYmixer-FC, and NBS-FC require full connectivity of the qubits. We set the penalty \(=1\) for all the soft constrained baselines based on the analysis in Fig. 5. The results show that: (1) HWP ansatz with soft-constraints are generally better than QAOA and HEA; (2) the dimension of DLA of HWP ansatz matters to the results see Tab. 4; (3) FC leads to better exploration of the subspace and will lead to more out-of-constrained states, which indicates lower \(\) when \(\) is set the same as NN.

While soft constraints often face difficulties in identifying optimal solutions at larger scales, hard constraints consistently demonstrate notable effectiveness and robustness. For the hard constrained methods, we show results with NN connectivity only since our method is qubit topology

    &  \\ NN & FC & NN & FC \\  \(^{2}\) & \(^{2}\) & \(^{n-1}\) & \(n\) is odd & \\ \(^{2}\) & \(^{2}\) & \(^{n}(n-1)\) & \(n\) is even & \(^{2}-1\) \\   

Table 4: DLA dimension when \(n=m^{2}\).

oriented. XYmixer can obtain a relatively high approximation ratio but with a rapid decrease in the probability of obtaining the optimal solution as \(m\) increases. The results verify the capability and efficiency of our hard constrained method as well as the expressivity of the proposed NBS gate.

### QAP on Superconducting quantum processors

We further conduct the experiment with a superconducting quantum processor. The 12 qubits (see Fig. 4) are chosen from a 66-qubit superconducting quantum processor. The processor has qubits lying on a 2D lattice, and the qubits are capacitively coupled to their four nearest neighbors. Detailed information about this processor is listed in Sec.D.2. None of the experiments on the quantum processor involve quantum error mitigation methods to post-process data. Considering the qubit quality and coupling strength, here we only conduct experiments for the case of \(m=3\) for QAP, as a primary verification of the feasibility of executing the algorithm on quantum processors. Detailed hyperparameter setting see Apx. F.1

**Evaluation Metric:** Apart from the approximation ratio \(\) and the probability of obtaining the optimal solution \(p_{optimal}\) used for the simulator, we introduce two more metrics to analyze the performance on the quantum processor. The first one is the approximation ratio for the in-constraint solution denoted as \(_{in}\). Since all the infeasible solutions are counted as \(0\) in \(\), \(_{in}\) can be seen as the true approximation ratio. Thus, it is very important to include the probability \(p_{in}\) of obtaining feasible solutions from all the output solutions as the second metric. Since the circuit error will greatly infect the solutions and \(\) will become very small, \(_{in}\) can enlarge the difference when conducting experiments on the quantum processor.

**Results:** The numerical results on the quantum processor are illustrated in Fig. 3. Quantum noise greatly affects the results, although we only utilize twelve qubits. QAOA and HEA demonstrate better performance with very few parameters and shallow circuits. All the methods requiring full connectivity will include SWAP gates during compilation, which leads to worse performance on the quantum processor. Our method consistently outperforms other soft constrained methods over all the metrics and further enlarges the overhead when executed on the quantum processor, except for HEA on \(p_{in}\) since HEA is extremely shallow and it may perform better on quantum processor some time. We believe the results will be much better if deeper circuits and more two-qubit gates are allowed. Notice that the parity checks on the columns are also able to correct the bit flip errors on the column. This may be another reason why we can achieve better performance with noise.

## 4 Conclusion and Limitations

In this paper, we first demonstrate the efficiency of HWP ansatz on ground state energy estimation problem and explain why HWP ansatz is a perfect testbed for parity check. Results on simulator with noise verify that parity check is a powerful error mitigation method for HWP ansatz. We then propose a novel method to utilize parity check as projective measurement to enforce further hard constraints for HWP ansatz. Intensive experimental results on QAP on both simulator and superconducting quantum processor illustrate the superior performance against peer VQA methods relying on soft constraints. To conclude, we provide detailed evidence in this paper to show that the combination of HWP ansatz and parity check is among the most promising candidates to demonstrate quantum advantages in the NISQ era to solve realistic problems.

**Limitation and Future Work:** We are aware that quantum algorithms might not exhibit any advantage (at least currently) under inevitable quantum noise and the extremely small problem size. However, we believe this paper still break through the upper limit of existing constrained quantum

Figure 3: Results for QAP on quantum processor. The upper one is results on noiseless simulator as a standard, the lower one is on superconducting quantum processor, under the same parameter setting.

algorithms for CO. We will further study the performance of our methods on inequality constraints in future. At the moment, our work does not have any negative societal impacts.

## 5 Acknowledgement

The authors would like to express their gratitude to Zhiyuan College, Shanghai Jiao Tong University and Zhiyuan Future Scholar Program (Grants No. ZIRC2024-07).