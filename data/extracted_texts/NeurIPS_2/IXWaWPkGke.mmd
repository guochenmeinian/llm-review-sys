# Optimization or Architecture:

How to Hack Kalman Filtering

 Ido Greenberg

Technion

gido@campus.technion.ac.il &Netanel Yannay

ELTA Systems

natiy4@gmail.com &Shie Mannor

Technion, Nvidia Research

shie@ee.technion.ac.il

###### Abstract

In non-linear filtering, it is traditional to compare non-linear architectures such as neural networks to the standard linear Kalman Filter (KF). We observe that this mixes the evaluation of two separate components: the non-linear architecture, and the parameters optimization method. In particular, the non-linear model is often optimized, whereas the reference KF model is not. We argue that _both_ should be optimized similarly, and to that end present the Optimized KF (**OKF**). We demonstrate that the KF may become competitive to neural models - if optimized using OKF. This implies that experimental conclusions of certain previous studies were derived from a flawed process. The advantage of OKF over the standard KF is further studied theoretically and empirically, in a variety of problems. Conveniently, OKF can replace the KF in real-world systems by merely updating the parameters. Our experiments are published in \(}\), and the OKF in \(}\).

## 1 Introduction

The Kalman Filter (KF)  is a celebrated method for linear filtering and prediction, with applications in many fields including tracking, navigation, control and reinforcement learning . The KF provides optimal predictions under certain assumptions (namely, linear models with i.i.d noise). In practical problems, these assumptions are often violated, rendering the KF sub-optimal and motivating the growing field of non-linear filtering. Many studies demonstrated the benefits of non-linear models over the KF .

Originally, we sought to join this line of works. Motivated by a real-world Doppler radar problem, we developed a dedicated non-linear Neural KF (NKF) based on the LSTM sequential model. NKF achieved significantly better accuracy than the linear KF.

Then, during ablation tests, we noticed that the KF and NKF differ in _both architecture and optimization_. Specifically, the KF's noise parameters are traditionally determined by noise estimation ; whereas NKF's parameters are optimized using supervised learning. To fairly evaluate the two architectures, we wished to apply the same optimization to both. To that end, we devised an Optimized KF (**OKF**, Section 3). KF and OKF have the same linear architecture: OKF only changes the noise parameters values. Yet, unlike KF, OKF _outperformed_ NKF, which reversed the whole experimental conclusion, and made the neural network unnecessary for this problem (Section 4).

Our original error was comparing two different model architectures (KF and NKF) that were not optimized similarly. A review of the non-linear filtering literature reveals that this methodology is used in many studies. Specifically, for a baseline KF model, the parameters are often tuned by noise estimation ; by heuristics ; or are simply ignored , often without public code for examination. Hussein even discusses the (Extended-)KF sensitivity to its parameters, and suggests a neural network with supervised learning - yet never considers the same supervised learning for the KF itself. In all these 10 studies, the non-linear model's added value cannot be inferred from the experimental evidence.

So far, OKF is presented as a _methodological contribution_: for comparison with non-linear methods, it forms a more coherent baseline than KF. In addition, OKF provides a _practical contribution_: it achieves more accurate filtering than the KF, using identical architecture. This is demonstrated extensively in Section 5 and Appendix B - in different domains, over different problem variations, using different KF baselines, with different data sizes, and even under distributional shifts.

**Discrepancy of objectives**: The advantage of OKF over KF may come as a surprise: KF's standard noise estimation is known to already obtain the MSE-optimal parameters! However, this optimality relies on unrealistic assumptions, often considered "fairy tales for undergraduates" [Thomson, 1994]. When violated, a conflict emerges between noise estimation and MSE optimization. We study this in detail: (a) Section 5 analyzes the conflict theoretically under certain assumption violations; (b) Appendix B.1 shows that even oracle noise estimation cannot optimize the MSE; (c) Appendix B.2 shows that when using noise estimation, **the MSE may degrade with more data**. In this light, all our findings can be summarized as follows (also see Fig. 1):

**Contribution:** (a) We observe that in most scenarios, since the KF assumptions do not hold, noise estimation is _not_ a proxy to MSE optimization. (b) We thus present the Optimized KF (OKF), also available as a PyPI package. We analyze (theoretically and empirically) the consequences of neglecting to optimize the KF: (c) the standard KF tuning method leads to sub-optimal predictions; (d) the standard methodology in the literature compares an optimized model to a non-optimized KF, hence may produce misleading conclusions. Note that we _do not_ argue against the non-linear models; rather, we claim that their added value cannot be deduced from flawed experiments.

**Scope: We focus on the supervised filtering setting**, where training data includes both observations and the true system states (whose prediction is usually the objective). Such data is available in many practical applications. For example, the states may be provided by external accurate sensors such as GPS fa Dai et al. ; by manual object labeling in computer vision [Wojke et al., 2017]; by controlled experiments of radar targets; or by simulations of known dynamic systems.

As demonstrated in the 10 studies cited above, this supervised setting is common in non-linear filtering. In linear Kalman filtering, this setting seems to be solved by trivial noise estimation; thus, the literature tends to overlook it, and instead focuses on settings that do not permit trivial noise estimation, e.g., learning from observations alone. Nevertheless, we argue that even in the supervised setting, noise estimation is often not a proxy to MSE optimization, and thus should often be avoided.

## 2 Preliminaries

Consider the KF model for a dynamic system with no control signal [Kalman, 1960]:

\[X_{t+1}=F_{t}X_{t}+_{t}(_{t}(0,Q)), Z _{t}=H_{t}X_{t}+_{t}(_{t}(0,R)). \]

\(X_{t}\) is the system state at time \(t\), and its estimation is usually the goal. Its dynamics are modeled by the linear operator \(F_{t}\), with random noise \(_{t}\) whose covariance is \(Q\). \(Z_{t}\) is the observation, modeled by the operator \(HThe KF represents \(X_{t}\) via estimation of the mean \(_{t}\) and covariance \(_{t}\). As shown in Fig. 2, the KF alternately predicts the next state (_prediction_ step), and processes new information from incoming observations (_update_ or _filtering_ step). The KF relies on the matrices \(_{t},_{t},,\), intended to represent \(F_{t},H_{t},Q,R\) of Eq. (1). Whenever \(F_{t},H_{t}\) are known and stationary, we may simplify the notation to \(_{t}=F\), \(_{t}=H\).

The KF estimator \(_{t}\) is optimal in terms of mean square errors (MSE) - but only under a restrictive set of assumptions (Kalman, 1960):

**Assumption 1** (KF assumptions).: \(_{t}=F_{t},\,_{t}=H_{t}\) are known and independent of \(X_{t}\) (linear models); each sequence \(\{_{t}\},\{_{t}\}\) is i.i.d; the covariances \(=Q,\,=R\) are known; and \(_{0},_{0}\) correspond to the mean and covariance of the initial \(X_{0}\).

**Theorem 1** (KF optimality; e.g., see Jazwinski (2007); Humpherys et al. (2012)).: Under Assumption 1, the KF estimator \(_{t}\) minimizes the MSE w.r.t. \(X_{t}\).

The KF accuracy strongly depends on its parameters \(\) and \(\)(Formentin and Bittanti, 2014). As motivated by Theorem 1, these parameters are usually identified with the noise covariance \(Q,R\) and are set accordingly: "the systematic and preferable approach to determine the filter gain is to estimate the covariances from data" (Odelson et al., 2006). In absence of system state data \(\{x_{t}\}\) (the "ground truth"), many methods were suggested to estimate the covariances from observations \(\{z_{t}\}\) alone (Mehra, 1970; Zanni et al., 2017; Park et al., 2019; Feng et al., 2014). We focus on the supervised setting, where the states \(\{x_{t}\}\) are available in the training-data (but not in inference).

**Definition 1** (Supervised data).: Consider \(K\) trajectories of a dynamic system, with lengths \(\{T_{k}\}_{k=1}^{K}\). We define their supervised data as the sequences of true system states \(x_{k,t}^{d_{x}}\) and observations \(z_{k,t}^{d_{z}}\): \(\{\{(x_{k,t},z_{k,t})\}_{t=1}^{T_{k}}\}_{k=1}^{K}\).

If \(F_{t},H_{t}\) are known, the supervised setting permits a direct calculation of the sample covariance matrices of the noise (Lacey, 1998):

\[ Cov(\{x_{k,t+1}-F_{t}x_{k,t}\}_{k,t}), Cov (\{z_{k,t}-H_{t}x_{k,t}\}_{k,t}). \]

Since Theorem 1 guarantees optimality when \(=Q,=R\), and Eq. (2) provides a simple estimator for \(Q\) and \(R\), Algorithm 1 has become the gold-standard tuning method for KF from supervised data.

**Algorithm 1** (KF noise estimation).: Given supervised data \(\{(x_{k,t},z_{k,t})\}\), return \(\) and \(\) of Eq. (2).

While Algorithm 1 is indeed trivial to apply in the supervised setting, we show below that when Assumption 1 is violated, it no longer provides optimal predictions. Violation of Assumption 1 can be partially handled by certain variations of the KF, such as Extended KF (EKF) (Sorenson, 1985) and Unscented KF (UKF) (Wan and Van Der Merwe, 2000).

## 3 Optimized Kalman Filter

Estimation of the KF noise parameters \(,\) has been studied extensively in various settings; yet, in our supervised setting it is trivially solved by Algorithm 1. However, once Assumption 1 is violated,

Figure 2: The KF algorithm. The prediction step is based on the motion model \(_{t}\) with noise \(\), whereas the update step is based on the observation model \(_{t}\) with noise \(\).

such noise estimation is no longer a proxy to MSE optimization - despite Theorem 1. Instead, in this section we propose to determine \(\) and \(\) via explicit MSE optimization. We rely on standard optimization methods for sequential supervised learning; as discussed below, the main challenge is to maintain the Symmetric and Positive Definite (SPD) structure of \(,\) as covariance matrices.

Formally, we consider the KF (Fig. 2) as a prediction model \(_{k,t}(\{z_{k,}\}_{=1}^{t};\,,)\), which estimates \(x_{k,t}\) given the observations \(\{z_{k,}\}_{=1}^{t}\) and parameters \(,\). We define the KF optimization problem:

\[*{argmin}_{Q^{},R^{}}_{k=1}^{K}_{t=1}^{T_{k}} *{loss}(_{k,t}(\{z_{k,}\}_{=1}^{t};\,Q^ {},R^{}),\;x_{k,t}),Q^{} S_{++}^{d_{x}},\;R^{ } S_{++}^{d_{z}}, \]

where \(S_{++}^{d}^{d d}\) is the space of Symmetric and Positive Definite matrices (SPD), and \(*{loss}()\) is the objective function (e.g., \(*{loss}(,x)=||-x||^{2}\) for MSE). Prediction of future states can be expressed using the same Eq. (3), by changing the observed input from \(\{z_{k,}\}_{=1}^{t}\) to \(\{z_{k,}\}_{=1}^{t-1}\).

A significant challenge in solving Eq. (3) is the SPD constraint. Standard numeric supervised optimization methods (e.g., Adam (Diederik P. Kingma, 2014)) may violate the constraint. While the SPD constraint is often bypassed using diagonal restriction (Li et al., 2019; Formentin and Bittanti, 2014), this may significantly degrade the predictions, as demonstrated in the ablation tests in Appendix B.4. Instead, to maintain the complete expressiveness of \(\) and \(\), we use the Cholesky parameterization (Pinheiro and Bates, 1996).

```
1Input: training data \(\{(x_{k,t},z_{k,t})\}_{k=1}^{K}\) (Definition 1); batch size \(b\); loss function (e.g., MSE); optimization_step function (e.g., Adam)
2\(d_{x}*{len}(x_{1,1}), d_{z}* {len}(z_{1,1})\) Initialize \(_{Q}^{d_{x}(d_{x}+1)},\;_{R}^{ d_{z}(d_{x}+1)}\)whiletraining not finished do// Get\(Q,R\)using Eq. (4) \( L(_{Q})L(_{Q})^{}, L( _{R})L(_{R})^{}\)\(*{sample}(\{1,...,K\},\) size=\(b)\)\(C 0\)for\(k\)in\(\)do Initialize \(^{d_{x}}\)for\(t\)in \(1:T_{k}\)do// KFsteps (Fig. 2) \((;\,)\)\((,z_{k,t};\,)\)\(C C+*{loss}(,\,x_{k,t})\)\(_{Q},_{R}(C,\,(_{Q},_{R}))\) Return \(,\,\)
```

**Algorithm 2**Optimized Kalman Filter (OKF)

The parameterization relies on Cholesky decomposition: any SPD matrix \(A^{d d}\) can be written as \(A=LL^{}\), where \(L\) is lower-triangular with positive entries along its diagonal. Reversely, for any lower-triangular \(L\) with positive diagonal, \(LL^{}\) is SPD. Thus, to represent an SPD \(A^{d d}\), we define \(A(L) LL^{}\) and parameterize \(L()\) to be lower-triangular, have positive diagonal, and be differentiable in the parameters \(\):

\[(L())_{ij}0&i<j,\\ e^{_{d(d-1)/2+i}}&i=j,\\ _{(i-2)(i-1)/2+j}&i>j, \]

where \(^{d(d+1)/2}\).

Both Cholesky parameterization and sequential optimization methods are well known tools. Yet, for KF optimization _from supervised data_, we are not aware of any previous attempts to apply them together, as noise estimation (Algorithm 1) is typically preferred.

We wrap the optimization process in the Optimized KF (**OKF**) in Algorithm 2, which outputs optimized parameters \(,\) for Fig. 2. Note that Algorithm 2 optimizes the state estimation at _current_ time \(t\). By switching Line 12 and Line 13, the optimization will instead be shifted to state prediction at the _next_ time-step (as \(\) becomes oblivious to the current observation \(z_{k,t}\)).

**Lack of theoretical guarantees:** If Assumption 1 cannot be trusted, neither noise estimation (Algorithm 1) nor OKF (Algorithm 2) can guarantee global optimality. Still, OKF pursues the MSE objective using standard optimization tools, which achieved successful results in many non-convex problems (Zhong et al., 2020) over millions of parameters (Devlin et al., 2019). On the other hand, noise estimation pursues a _conflicting_ objective, and guarantees significant sub-optimality in certain scenarios, as analyzed in Section 5.

## 4 OKF vs. Neural KF: Is the Non-Linearity Helpful?

In this section, we demonstrate that comparing an optimized neural network to a non-optimized baseline may lead to incorrect conclusions: the network may seem superior even if the complicated architecture has no added value. The implied message is not against neural networks, but rather that evaluating them against a non-optimized baseline carries a crucial flaw.

**The Doppler radar problem:** We consider a variant of the classic Doppler radar problem [Barton, 1988, Roy and Mitra, 2016], where various targets trajectories are tracked in a homogeneous 3D space, given regular observations of a Doppler radar. The state \(X=(x_{x},x_{y},x_{z},x_{ux},x_{uy},x_{uz})^{}^{6}\) consists of 3D location and velocity. The goal is to minimize the MSE over the 3 location coordinates. While the true dynamics \(F\) are unknown to the KF, a constant-velocity model \(\) can be used:

\[=(1&1&\\ &1&1\\ &&1&1\\ &&1&1\\ &&1&1). \]

An observation \(Z^{4}\) consists of the location in spherical coordinates (range, azimuth, elevation) and the radial velocity (the Doppler signal), with an additive i.i.d Gaussian noise. After transformation to Cartesian coordinates, the observation model can be written as:

\[H=H(X)=(1&\\ &1&\\ &&}{}&}{}&}{} ), \]

where \(r=^{2}+x_{y}^{2}+x_{z}^{2}}\). Since \(H=H(X)\) relies on the unknown location \((x_{x},x_{y},x_{z})\), we instead substitute \( H(Z)\) in the KF update step in Fig. 2.

**Neural KF:** The Neural Kalman Filter (NKF) incorporates an LSTM model into the KF framework, as presented in Appendix C and Fig. 16. We originally developed NKF to improve the prediction of the non-linear highly-maneuvering targets in the Doppler problem (e.g., Fig. 3), and made honest efforts to engineer a well-motivated architecture. Regardless, we stress that this section demonstrates a methodological flaw when comparing _any_ optimized filtering method to the KF; this methodological argument stands regardless of the technical quality of NKF. In addition, Appendix C presents similar results for other variants of NKF.

**Experiments:** We train NKF and OKF on a dataset of simulated trajectories, representing realistic targets with free motion (as displayed in Fig. 3). As a second benchmark, we also train on a dataset of simplified trajectories, with speed changes but with no turns. The two benchmarks are specified in detail in Appendix B.1, and correspond to Fig. 11(d) and Fig. 11(e). We tune the KF from the same datasets using Algorithm 1. In addition to out-of-sample test trajectories, we also test generalization to out-of-distribution trajectories, generated using different ranges of target accelerations (affecting both speed changes and turns radiuses).

Figure 4: Test errors and 95% confidence intervals, over targets with different accelerations. The middle acceleration range coincides with the training accelerations (24-48 in (a) and 8-16 in (b)), and the other ranges correspond to out-of-distribution generalization.

Figure 3: A sample trajectory and the corresponding predictions (projected onto XY plane), in the Freedom benchmark. The standard KF provides inaccurate predictions in certain turns.

Fig. 4 summarizes the test results. Compared to KF, NKF reduces the errors in both benchmarks, suggesting that the non-linear architecture pays off. However, optimization of the KF (using OKF) reduces the errors even further, and thus reverses the conclusion. That is, the advantage of NKF in this problem comes _exclusively_ from optimization, and _not at all_ from the expressive architecture.

## 5 OKF vs. KF:

Section 4 presents the methodological contribution of OKF for non-linear filtering, as an optimized baseline for comparison, instead of the standard KF. In this section, we study the advantage of OKF over the KF more generally. We show that OKF consistently outperforms the KF in a variety of scenarios from 3 different domains. This carries considerable practical significance: unlike neural models, shifting from KF to OKF merely requires change of the parameters \(\), \(\), hence can be deployed to real-world systems without additional overhead, complexity or latency on inference.

Recall that by Theorem 1, the KF is already optimal unless Assumption 1 is violated. Thus, the violations are discussed in depth, and the effects of certain violations are analyzed theoretically.

### Doppler Radar Tracking

Theorem 1 guarantees the optimality of Algorithm 1 (KF). Yet, in Section 4, OKF outperforms the KF. This is made possible by the violation of Assumption 1: while the Doppler problem of Section 4 may not seem complex, the trajectories follow a non-linear motion model (as displayed in Fig. 3).

Imagine that we simplified the problem by only simulating constant-velocity targets, making the true motion model \(F\) linear. Would this recover Assumption 1 and make OKF unnecessary? The answer is _no_; the adventurous reader may attempt to list all the remaining violations before reading on.

The simulated targets move mostly horizontally, with limited elevation changes. This is not expressed by the KF's initial state distribution (\(_{0},_{0}\)). To remedy this, one may simulate motion uniformly in all directions. A third violation comes from the observation noise. While the radar noise is i.i.d in spherical coordinates (as mentioned in Section 4), it is not i.i.d in _Cartesian_ coordinates (see discussion in Appendix A.2). To overcome this, one may simulate a radar with (physically-impossible) Cartesian i.i.d noise. This results in the unrealistically-simplified problem visualized in Fig. 5.

Despite the simplifications, it turns out that Assumption 1 is still not met, as the observation model in Eq. (6) is still not linear (i.e., \(H=H(X)\) is not constant). As shown by Proposition 1, this single violation alone results in a significant deviation of Algorithm 1 from the optimal parameters.

We first define the simplified problem.

**Problem 1** (The toy Doppler problem).: The toy Doppler problem is the filtering problem modeled by Eq. (1), with constant-velocity dynamics \(F\) (Eq. (5)), Doppler observation \(H\) (Eq. (6)), and

\[Q=^{6 6}, R=( _{x}^{2}&_{y}^{2}\\ &_{x}^{2}&\\ &&_{x}^{2}),\]

where \(_{x},_{y},_{z},_{D}>0\).

Recall that \(H=H(X)\) in Eq. (6) depends on the state \(X\), which is unknown to the model. Thus, we assume that \(=H()\) is used in the KF update step (Fig. 2), with some estimator \( X\) (e.g.,

Figure 5: The original Doppler problem (left) is simplified to a toy problem (right), with linear motion, isotropic flying directions and physically-impossible radar. After all the simplifications, Assumption 1 still does not hold, thus Algorithm 1 is still sub-optimal and outperformed by OKF.

\(=H(Z)\) in Section 4). Hence, the _effective_ noise is \(:=Cov(Z-X) Cov(Z-HX)=R\). Proposition 1 analyzes the difference between \(\) and \(R\). To simplify the analysis, we further assume that the error \(-X\) within \(\) (e.g., \(Z-X\)) is independent of the target velocity.

**Proposition 1**.: In the toy Doppler Problem 1 with the estimated observation model \(\), the effective observation noise \(=Cov(Z-X)\) is:

\[=(_{x}^{2}&_{y}^{2}\\ &_{y}^{2}\\ &&_{z}^{2}+C)=R+(0&0\\ &0\\ &&0\\ &&C), \]

where \(C=([||u||^{2}])\) is the asymptotic lower bound ("big omega") of the expected square velocity \(u\). In particular, \(C>0\) and is unbounded as the typical velocity grows.

Proof sketch (see complete proof in Appendix A.1).: We have \(Cov(Z-X)=Cov(Z-HX+(H-)X)=R+Cov((H-)X)\), where the last equality relies on the independence between the target velocity and the estimation error \(-X\). We then calculate \(Cov((H-)X)\). 

Proposition 1 has an intuitive interpretation: when measuring the velocity, Algorithm 1 only considers the inherent Doppler signal noise \(_{D}\). However, the _effective_ noise \(_{D}+C\) also includes the _transformation error_ from Doppler to the Cartesian coordinates, caused by the uncertainty in \(H(X)\) itself. Notice that heuristic solutions such as inflation of \(R\) would not recover the effective noise \(\), which only differs from \(R\) in one specific entry.

Yet, as demonstrated below, OKF captures the effective noise \(\) successfully. Critically, it does so from mere data: OKF does not require the user to specify the model correctly, or to even be aware of the violation of Assumption 1.

**Experiments:** We test KF and OKF on the toy Problem 1 using the same methodology as in Section 4. In accordance with Proposition 1, OKF adapts the Doppler noise parameter: as shown in Fig. 6, it increases \(_{D}\) in proportion to the location noise by a factor of \( 13\). Note that we refer to the proportion instead of absolute values due to scale-invariance in the toy problem, as discussed in Appendix A.1. Following the optimization, **OKF reduces the test MSE by 44%** - from 152 to 84.

**Extended experiments:** This section and Section 4 test OKF against KF in three specific variants of the Doppler problem. One may wonder if OKF's advantage generalizes to other scenarios, such as:

* Different subsets of violations of Assumption 1;
* Other baseline models than KF, e.g., Optimized Extended-KF;
* Small training datasets;
* Generalization to out-of-distribution test data.

The extended experiments in Appendix B address _all_ of the concerns above by examining a wide range of problem variations in the Doppler radar domain. In addition, other domains are experimented below. **In all of these experiments, OKF outperforms Algorithm 1 in terms of MSE**.

Finally, the goal-misalignment of Algorithm 1 is demonstrated directly by two results: even oracle noise estimation fails to optimize the MSE (Appendix B.1); and feeding more data to Algorithm 1 may _degrade_ the MSE (Appendix B.2). Fig. 7 presents a sample of the results of Appendix B.2.

Figure 6: The parameters \(\) learned by KF and OKF in the toy Doppler problem. The rows and columnsâ€™ entries correspond to location (\(x,y,z\)) and radial velocity (\(Doppler\)). The simulated noise variance is \(100^{2}\) for the positional dimensions and \(5^{2}\) for velocity, and is estimated accurately by the KF. However, OKF increases the noise associated with velocity, in accordance with Proposition 1. The decrease in the positional variance comes from scale-invariance in the toy problem, as discussed in Appendix A.1.

Figure 7: Different train data sizes in the Doppler problem (Fig. 3). Due to objective misalignment, Algorithm 1 deteriorates with more train data.

### Video Tracking

The MOT20 dataset (Dendorfer et al., 2020) contains videos of real-world targets (mostly pedestrians, as shown in Fig. 8), along with their true location and size in every frame. For our experimental setup, since object detection is out of the scope, we assume that the true locations are known in real-time. The objective is to predict of the target location in the next frame. The state space corresponds to the 2D location, size and velocity, and the observations include only the location and size. The underlying dynamics \(F\) of the pedestrians are naturally unknown, and the standard constant-velocity model is used for \(\). This results in the following model:

\[=(1&1&1&1\\ &1&1&1\\ &&1&1\\ &&1&1),=H=(1&1&0 &0\\ &1&1&0&0\\ &1&0&0).\]

Notice that the known observation model \(=H\) is _linear_ (\(H\) is independent of \(X\)), hence poses a substantial difference from Section 5.1 in terms of violations of Assumption 1.

The first three videos with 1117 trajectories are used for training, and the last video with 1208 trajectories for testing. As shown in Fig. 7(a), OKF reduces the test MSE by 18% with high statistical significance.

### Lidar-based State Estimation in Self Driving

Consider the problem of state-estimation in self-driving, based on lidar measurements with respect to known landmarks (Moreira et al., 2020). The objective is to estimate the current vehicle location. We assume a single landmark (since the landmark matching problem is out of scope). We simulate driving trajectories consisting of multiple segments, with different accelerations and turn radiuses

Figure 8: A sample of 2 trajectories in the first frame of MOT20 test video, along with the predictions of KF and OKF.

Figure 9: Summary of the test errors in the video and lidar problems. The dashed lines correspond to MSE. Both z-values correspond to p-value \(<10^{-6}\). Each z-value is calculated over \(N\) test trajectories as follows: \(z=(\{_{i}\})}{(\{_{i}\})}\), where \(_{i}=err_{i}(KF)^{2}-err_{i}(OKF)^{2}\) is the square-error difference on trajectory \(1 i N\).

(see Fig. 14(a) in the appendix). The state is the vehicle's 2D location and velocity, and \(\) is modeled according to constant-velocity. The observation (both true \(H\) and modeled \(\)) corresponds to the location, with an additive Gaussian i.i.d noise in polar coordinates. This results in the following model:

\[=(1&0&1&0\\ 0&1&0&1\\ 0&0&0&0\\ 0&0&0&1),=H=(1&0 &0&0\\ 0&1&0&0).\]

We train KF and OKF over 1400 trajectories and test them on 600 trajectories. As shown in Fig. 7(b), OKF reduces the test MSE by 10% with high statistical significance.

Notice that the lidar problem differs from Section 5.1 in the linear observation model \(H\), and from Section 5.2 in the additive noise. Both properties have a major impact on the problem, as analyzed in Proposition 1 and below, respectively.

**Theoretical analysis:** As mentioned in Section 5.1 and discussed in Appendix A.2, the i.i.d noise in polar coordinates is not i.i.d in Cartesian ones. To isolate the i.i.d violation and study its effect, we define a simplified toy model - with simplified states, no-motion model \(F\), isotropic motion noise \(Q\) and only radial observation noise. Note that in contrast to Section 5.1, the observation model is already linear.

**Problem 2** (The toy lidar problem).: The toy lidar problem is the filtering problem modeled by Eq. (1) with the following parameters:

\[F=H=1&0\\ 0&1,\;Q=q&0\\ 0&q,\;R_{polar}=r_{0}&0\\ 0&0,\]

for some unknown \(q,r_{0}>0\), with observation noise drawn i.i.d from \((0,R_{polar})\) in _polar_ coordinates. The initial state \(X_{0}\) follows a radial distribution (i.e., with a PDF of the form \(f(||x_{0}||)\)).

**Proposition 2**.: As the number \(N\) of train trajectories in Problem 2 grows, the noise parameter \(_{N}(KF)\) estimated by Algorithm 1 converges almost surely:

\[_{N}(KF)}_{est}=r_{0}/2& 0\\ 0&r_{0}/2.\]

On the other hand, under regularity assumptions, the MSE is minimized by the parameter \(_{opt}=(r&0\\ 0&r)\), where \(r<r_{0}/2\).

Proof sketch (see complete proof in Appendix A.2).: For \(_{est}\), we calculate \([_{N}(KF)]\) and use the law of large numbers. For the calculation, we transform \(R_{polar}\) to Cartesian coordinates using the random direction variable \(\), and take the expectation over \( U([0,2))\). The uniform distribution of \(\) comes from the radial symmetry of the problem. For \(_{opt}\), we calculate and minimize the expected square error directly. 

Intuitively, Proposition 2 shows that the i.i.d violation reduces the _effective_ noise. Note that the analysis only holds for the unrealistic toy Problem 2. The empirical setting in this section is less simplistic, and generalizing Proposition 2 is not trivial. Fortunately, OKF optimizes directly from the data, and does not require such theoretical analysis. Fig. 10 shows that indeed, in accordance with the intuition of Proposition 2, OKF learns to reduce the values of \(\) in comparison to KF. This results in reduced test errors as specified above.

Figure 10: The parameters \(\) learned in the lidar problem. From data alone, OKF learns to decrease the noise parameters, consistently with Proposition 2.

Related Work

**Noise estimation** of the KF parameters from observations alone has been studied for decades, as supervised data (Definition 1) is often unavailable. Various methods were studied, based on autocorrelation (Mehra, 1970; Carew and Belanger, 1973), EM (Shumway and Stoffer, 2005) and others (Odelson et al., 2006; Feng et al., 2014; Park et al., 2019). When supervised data _is_ available, noise estimation reduces to Eq. (2) and is considered a solved problem (Odelson et al., 2006). We show that while noise estimation is indeed easy from supervised data, it may be the wrong objective to pursue.

**Optimization:** We apply gradient-based optimization to the KF with respect to its errors. In absence of supervised data, gradient-based optimization was suggested for other losses, such as smoothness (Barratt and Boyd, 2020). In the supervised setting, noise estimation is typically preferred (Odelson et al., 2006), although optimization without gradients was suggested in Abbeel et al. (2005). In practice, "optimization" of KF is sometimes handled by trial and error (Jamil et al., 2020) or grid search (Formentin and Bittanti, 2014; Coskun et al., 2017). In other cases, \(Q\) and \(R\) are restricted to be diagonal (Li et al., 2019; Formentin and Bittanti, 2014). However, such heuristics may not suffice when the optimal parameters take a non-trivial form.

**Neural Networks (NNs) in filtering:** The NKF in Section 4 relies on a recurrent NN. NNs are widely used in non-linear filtering, e.g., for online prediction (Gao et al., 2019; Iter et al., 2016; Coskun et al., 2017; fa Dai et al., 2020; Belogolovsky et al., 2022), near-online prediction (Kim et al., 2018), and offline prediction (Liu et al., 2019). Learning visual features for tracking via a NN was suggested by Wojke et al. (2017). NNs were also considered for related problems such as data association (Liu et al., 2019), model switching (Deng et al., 2020), and sensors fusion (Sengupta et al., 2019).

In addition, all the 10 studies cited in Section 1 used a NN model for non-linear filtering, with either KF or EKF as a baseline for comparison. As discussed above, none has optimized the baseline model to a similar extent as the NN. As demonstrated in Section 4, such methodology could lead to unjustified conclusions.

## 7 Summary

We observed that violation of the KF assumptions is common, and is potentially difficult to notice or model. Under such violation, we analyzed (theoretically and empirically) that the standard noise estimation of the KF parameters conflicts with MSE optimization. An immediate consequence is that the KF is often used sub-optimally. A second consequence is that in many works in the literature, where a neural network is compared to the KF, the experiments become inconclusive: they cannot decide whether the network succeeded due to superior architecture, or merely because its parameters were optimized. We presented the Optimized KF (OKF), and demonstrated that it can solve both issues (Section 5 and Section 4, respectively).

From a practical point of view, the OKF is available on PyPI and is easily applicable to new problems. Since its architecture is identical to the KF, and only the parameters are changed, the learned model causes neither inference-time delays nor deployment overhead. All these properties make the OKF a powerful practical tool for both linear and non-linear filtering problems.

#### Acknowledgements

The authors thank Tal Malinovich, Ophir Nabati, Zahar Chikishev, Mark Kozdoba, Eli Meirom, Elad Sharony, Itai Shufaro and Shirli Di-Castro for their helpful advice. This work was partially funded by the European Union's Horizon Europe Programme, under grant number 101070568.