# Towards Data-Algorithm Dependent Generalization:

a Case Study on Overparameterized Linear Regression

 Jing Xu

IIIS, Tsinghua University

xujing21@mails.tsinghua.edu.cn &Jiaye Teng

IIIS, Tsinghua University

tjy20@mails.tsinghua.edu.cn &Yang Yuan

IIIS, Tsinghua University

Shanghai Artificial Intelligence Laboratory

Shanghai Qi Zhi Institute

yuanyang@tsinghua.edu.cn &Andrew Chi-Chih Yao

IIIS, Tsinghua University

Shanghai Artificial Intelligence Laboratory

Shanghai Qi Zhi Institute

andrewcyao@tsinghua.edu.cn

Equal Contribution

###### Abstract

One of the major open problems in machine learning is to characterize generalization in the overparameterized regime, where most traditional generalization bounds become inconsistent even for overparameterized linear regression . In many scenarios, this failure can be attributed to obscuring the crucial interplay between the training algorithm and the underlying data distribution. This paper demonstrate that the generalization behavior of overparameterized model should be analyzed in a both data-relevant and algorithm-relevant manner. To make a formal characterization, We introduce a notion called data-algorithm compatibility, which considers the generalization behavior of the entire data-dependent training trajectory, instead of traditional last-iterate analysis. We validate our claim by studying the setting of solving overparameterized linear regression with gradient descent. Specifically, we perform a data-dependent trajectory analysis and derive a sufficient condition for compatibility in such a setting. Our theoretical results demonstrate that if we take early stopping iterates into consideration, generalization can hold with significantly weaker restrictions on the problem instance than the previous last-iterate analysis.

## 1 Introduction

Although deep neural networks achieve great success in practice , their remarkable generalization ability is still among the essential mysteries in the deep learning community. One of the most intriguing features of deep neural networks is overparameterization, which confers a level of tractability to the training problem, but leaves traditional generalization theories failing to work. In generalization analysis, both the training algorithm and the data distribution play essential roles . For instance, a line of work  highlights the role of the algorithm by showing that the algorithm-irrelevant uniform convergence bounds can become inconsistent in deep learning regimes. Another line of work  on benign overfitting emphasizes the role of data distribution via profound analysis of specific overparameterized models.

Despite the significant role of data and algorithm in generalization analysis, existing theories usually focus on either the data factor (_e.g._, uniform convergence  and last iterate analysis ) or the algorithm factor (_e.g._, stability-based bounds ). Combining both data and algorithm factor intogeneralization analysis can help derive tighter generalization bounds and explain the generalization ability of overparameterized models observed in practice. In this sense, a natural question arises:

_How to incorporate both data factor and algorithm factor into generalization analysis?_

To gain insight into the interplay between data and algorithms, we provide motivating examples of a synthetic overparameterized linear regression task and a classification task on the corrupted MNIST dataset in figure 1. In both scenarios, the final iterate with less algorithmic information, which may include the algorithm type (_e.g._, GD or SGD), hyperparameters (_e.g._, learning rate, number of epochs), generalizes much worse than the early stopping solutions (see the Blue Line). In the linear regression case, the generalization error of the final iterate can be more than \( 100\) larger than that of the early stopping solution. In the MNIST case, the final iterate on the SGD trajectory has 19.9% test error, much higher than the 2.88% test error of the best iterate on the GD trajectory. Therefore, the almost ubiquitous strategy of early stopping is a key ingredient in generalization analysis for overparameterized models, whose benefits have been demonstrated both theoretically and empirically . By focusing on the entire optimization trajectory and performing data-dependent trajectory analysis, both data information and the dynamics of the training algorithm can be exploited to yield consistent generalization bounds.

When we take the algorithm into consideration and analyze the data-dependent training trajectory, generalization occurs if the minimum excess risk of the iterates on the training trajectory converges to zero, as the sample size tends to infinity. This accords with the real practice of training deep neural networks, where one can pick up the best parameter on the training trajectory, by calculating its loss on a validation dataset. We dub this notion of generalization as as _data-algorithm-compatibility_, which is formally defined in Section 3.2.

The significance of compatibility comes in three folds. Firstly, it incorporates both data and algorithm factors into generalization analysis, and is suitable for the overparameterization regime (see Definition 3.1). Secondly, it serves as a minimal condition for generalization, without which one cannot expect to find a consistent solution via standard learning procedures. Consequently, compatibility holds with only mild assumptions and applies to a wide range of problem instances (see Theorem 4.1). Thirdly, it captures the algorithmic significance of early stopping in generalization. By exploiting the algorithm information along the entire trajectory, we arrive at better generalization bounds than the last-iterate analysis (see Table 1 and 2 for examples).

To theoretically validate compatibility, we study it under overparameterized linear regression setting. Analysis of the overparameterized linear regression is a reasonable starting point to study more complex models like deep neural networks , since many phenomena of the high dimensional non-linear model are also observed in the linear regime (_e.g._, Figure 1). Furthermore, the neural

Figure 1: **(a) The training plot for linear regression with spectrum \(_{i}=1/i^{2}\) using GD.** Note that the axes are in the log scale. **(b) The training plot of CNN on corrupted MNIST with 20% label noise using SGD.** Both models successfully learn the useful features in the initial phase of training, but it takes a long time for them to fit the noise in the dataset. The observations demonstrate the power of data-dependent trajectory analysis, since the early stopping solutions on the trajectory generalize well but the final iterate fails to generalize. See Appendix C for details.

tangent kernel (NTK) framework [4; 26] demonstrates that very wide neural networks trained using gradient descent with appropriate random initialization can be approximated by kernel regression in a reproducing kernel Hilbert space, which rigorously establishes a close relationship between overparameterized linear regression and deep neural network training.

Specifically, we investigate solving overparameterized linear regression using gradient descent with constant step size, and prove that under some mild regularity conditions, gradient descent is compatible with overparameterized linear regression if the effective dimensions of the feature covariance matrix are asymptotically bounded by the sample size. Compared with the last-iterate analysis , the main theorems in this paper require significantly weaker assumptions, which demonstrates the benefits of data-relevant and algorithm-relevant generalization analysis.

We summarize our contributions as follows:

* We formalize the notion of data-algorithm-compatibility, which highlights the interaction between data and algorithm and serves as a minimal condition for generalization.
* We derive a sufficient condition for compatibility in solving overparameterized linear regression with gradient descent. Our theory shows that generalization of early-stopping iterates requires much weaker restrictions in the considered setting.
* Technically, we derive time-variant generalization bounds for overparameterized linear regression via data-dependent trajectory analysis. Empirically, we conduct the various experiments to verify the the theoretical results and demonstrate the benefits of early stopping.

## 2 Related Works

**Data-Dependent Techniques** mainly focus on the data distribution condition for generalization. One of the most popular data-dependent methods is uniform convergence [7; 29; 74; 75]. However, recent works [46; 47] point out that uniform convergence may not be powerful enough to explain generalization, because it may only yield inconsistent bound in even linear regression cases. Another line of works investigates benign overfitting, which mainly studies generalization of overfitting solutions [8; 21; 35; 68; 70; 76; 77].

**Algorithm-Dependent Techniques** measure the role of the algorithmic information in generalization. A line of works derives generalization bounds via algorithm stability [9; 12; 18; 19; 24; 31; 32; 45; 67]. A parallel line of works analyzes the implicit bias of algorithmic information [11; 25; 39; 40; 59; 64], which are mainly based on analyzing a specific data distribution (_e.g._, linear separable).

**Other Generalization Techniques.** Besides the techniques above, there are many other approaches. For example, PAC-Bayes theory performs well empirically and theoretically [16; 42; 43; 48; 49; 58; 61] and can yield non-vacuous bounds in deep learning regimes [50; 54]. Furthermore, there are other promising techniques including information theory [6; 56; 71] and compression-based bounds .

**Early Stopping** has the potential to improve generalization for various machine learning problems [5; 30; 33; 38; 53; 62; 69; 74]. A line of works studies the rate of early stopping in linear regression and kernel regression with different algorithms, _e.g._, gradient descent , stochastic gradient descent [15; 37; 51; 55; 66], gradient flow , conjugate gradient  and spectral algorithms [22; 36]. Beyond linear models, early-stopping is also effective for training deep neural networks [27; 34]. Another line of research focuses on the signal for early stopping [20; 52].

## 3 Preliminaries

In this section, we formally define compatibility between the data distribution and the training algorithm, starting from the basic notations.

### Notations

**Data Distribution.** Let \(\) denote the population distribution and \(\) denote a data point sampled from distribution \(\). Usually, \(\) contains a feature and its corresponding response. Besides, we denote the dataset with \(n\) samples as \(\{_{i}\}_{i[n]}\), where \(_{i}\) are i.i.d. sampled from distribution \(\).

**Loss and Excess Risk.** Let \((;)\) denote the loss on sample \(\) with parameter \(^{p}\). The corresponding population loss is defined as \(L(;)_{}(;)\). When the context is clear, we omit the dependency on \(\) and denote the population loss by \(L()\). Our goal is to find the optimal parameter \(^{*}\) which minimizes the population loss, i.e., \(L(^{*})=_{}L()\). Measuring how a parameter \(\) approaches \(^{*}\) relies on a term _excess risk_\(R()\), defined as \(R() L()-L(^{*})\).

**Algorithm.** Let \(()\) denote a iterative algorithm that takes training data \(\) as input and outputs a sequence of parameters \(\{_{n}^{(t)}\}_{t 0}\), where \(t\) is the iteration number. The algorithm can be either deterministic or stochastic, _e.g._, variants of (S)GD.

### Definitions of Compatibility

Based on the above notations, we introduce the notion of compatibility between data distribution and algorithm in Definition 3.1. Informally, compatibility measures whether a consistent excess risk can be reached along the training trajectory. Note that we omit the role of the loss function in the definition, although the algorithm depends on the loss function.

**Definition 3.1** (Compatibility).: _Given a loss function \(()\) with corresponding excess risk \(R()\), a data distribution \(\) is compatible with an algorithm \(\) if there exists nonempty subsets \(T_{n}\) of \(\), such that \(_{t T_{n}}R(_{n}^{(t)})\) converges to zero in probability as sample size \(n\) tends to infinity, where \(\{_{n}^{(t)}\}_{t 0}\) denotes the output of algorithm \(\), and the randomness comes from the sampling of training data \(\) from distribution \(\) and the execution of algorithm \(\). That is to say, \((,)\) is compatible if there exists nonempty sets \(T_{n}\), such that_

\[_{t T_{n}}R(_{n}^{(t)})0 n. \]

_We call \(\{T_{n}\}_{n>0}\) the compatibility region of \((,)\). The distribution \(\) is allowed to change with \(n\). In this case, \(\) should be understood as a sequence of distributions \(\{_{n}\}_{n 1}\). We also allow the dimension of model parameter \(\) to be infinity or to grow with \(n\). We omit this dependency on \(n\) when the context is clear._

Compatibility serves as a minimal condition for generalization, since if a data distribution is incompatible with the algorithm, one cannot expect to reach a small excess risk even if we allow for _arbitrary_ early stopping. However, we remark that considering only the minimal excess risk is insufficient for a practical purpose, as one cannot exactly find the \(t\) that minimizes \(R(_{n}^{(t)})\) due to the noise in the validation set. Therefore, it is meaningful to consider a region of time \(t\) on which the excess risk is consistent as in Definition 3.1. The larger the region is, the more robust the algorithm will be to the noise in its execution.

**Comparisons with Other Notions.** Compared to classic definitions of learnability, _e.g._, PAC learning, the definition of compatibility is data-specific and algorithm-specific, and is thus a more fine-grained notion. Compared to the concept of _benign_ proposed in , which studies whether the excess risk at \(t=\) converges to zero in probability as the sample size goes to infinity, compatibility only requires that there exists a time to derive a consistent excess risk. We will show later in Section 4.2 that in the overparameterized linear regression setting, there exist cases such that the problem instance is compatible but not benign.

## 4 Analysis of Overparameterized Linear Regression with Gradient Descent

To validate the meaningfulness of compatibility, we study it in the overparameterized linear regression regime. We first introduce the data distribution, loss, and training algorithm, and then present the main theorem, which provides a sufficient condition for compatibility in this setting.

### Preliminaries for Overparameterized Linear Regression

**Notations.** Let \(O,o,,\) denote asymptotic notations, with their usual meaning. For example, the argument \(a_{n}=O(b_{n})\) means that there exists a large enough constant \(C\), such that \(a_{n} Cb_{n}\). We use \(\) with the same meaning as the asymptotic notation \(O\). Besides, let \(\|\|\) denote the \(_{2}\) norm for vector \(\), and \(\|\|\) denote the operator norm for matrix \(\). We allow the vector to belong toa countably infinite-dimensional Hilbert space \(\), and with a slight abuse of notation, we use \(^{}\) interchangeably with \(\). In this case, \(x^{}z\) denotes inner product and \(xz^{}\) denotes tensor product for \(x,z\). A random variable \(X\) is called \(\)-subgaussian if \([e^{ X}] e^{^{2}^{2}/2}\) for any \(\).

**Data Distribution.** Let \((,y)^{p}\) denote the feature vector and the response, following a joint distribution \(\). Let \([^{}]\) denote the feature covariance matrix, whose eigenvalue decomposition is \(=^{}=_{i>0}_{i}_{i} {v}_{i}^{}\) with decreasing eigenvalues \(_{1}_{2}\). We make the following assumptions on the distribution of the feature vector.

**Assumption 1** (Assumptions on feature distribution).: _We assume that_

1. \([]=0\)_._
2. \(_{1}>0,_{i>0}_{i}<C\) _for some absolute constant_ \(C\)_._
3. _Let_ \(}=^{-}^{}\)_. The random vector_ \(}\) _has independent_ \(_{x}\)_-subgaussian entries._

**Loss and Excess Risk.** We choose square loss as the loss function \(\), i.e. \((,(,y))=1/2(y-^{})^{2}\). The corresponding population loss is denoted by \(L()=(,(,y))\) and the optimal parameter is denoted by \(^{*}*{argmin}_{^{p}} L()\). We assume that \(\|^{*}\|<C\) for some absolute constant \(C\). If there are multiple such minimizers, we choose an arbitrary one and fix it thereafter. We focus on the excess risk of parameter \(\), defined as

\[R()=L()-L(^{*})=(-^{*})^{}(-^{*}). \]

Let \(=y-^{}^{*}\) denote the noise in data point \((,y)\). The following assumptions involve the conditional distribution of the noise.

**Assumption 2** (Assumptions on noise distribution).: _We assume that_

1. _The conditional noise_ \(|\) _has zero mean._
2. _The conditional noise_ \(|\) _is_ \(_{y}\)_-subgaussian._

Note that both Assumption 1 and Assumption 2 are commonly considered in the related literatures .

**Training Set.** Given a training set \(\{(_{i},y_{i})\}_{1 i n}\) with \(n\) pairs independently sampled from the population distribution \(\), we define \((_{1},,_{n})^{}^{n p}\) as the feature matrix, \((y_{1},,y_{n})^{}^{n}\) as the corresponding noise vector, and \(-^{*}\) as the residual vector. Let the singular value decomposition (SVD) of \(\) be \(=}^{}^{}\), with \(}=\{_{1}\,,_{n}\}^{n  n}\), \(_{1}_{n}\).

We consider the overparameterized regime where the feature dimension is larger than the sample size, namely, \(p>n\). In this regime, we assume that \(()=n\) almost surely as in Bartlett et al. . This assumption is equivalent to the invertibility of \(XX^{}\).

**Assumption 3** (Linear independent training set).: _For any \(n<p\), we assume that the features in the training set \(\{_{1},_{2},,_{n}\}\) is linearly independent almost surely._

**Algorithm.** Given the dataset \((,)\), define the empirical loss function as \(()\|-\|^{2}\). We choose full-batch gradient descent on the empirical risk with a constant learning rate \(\) as the algorithm \(\) in the previous template. In this case, the update rule for the optimization trajectory \(\{_{t}\}_{t 0}\) is formulated as

\[_{t+1}=_{t}-^{}(_{t}-). \]

Without loss of generality, we consider zero initialization \(_{0}=\) in this paper. In this case, for a sufficiently small learning rate \(\), \(_{t}\) converges to the _min-norm interpolator_\(}=^{}(^{})^{-1}\) as \(t\) goes to infinity, which was well studied previously . This paper takes one step further and discuss the excess risk along the entire training trajectory \(\{R(_{t})\}_{t 0}\).

**Effective Rank and Effective Dimensions.** We define the effective ranks of the feature matrix \(\) as \(r()_{i}}{_{1}}\) and \(R_{k}()_{i})^{2}}{_{ i>k}_{1}^{2}}\). Our results depend on two notions of effective dimension of the feature covariance \(\), defined as

\[k_{0} \{l 0:_{l+1}_{i>l} _{i}}{n}\}, \] \[k_{1} \{l 0:_{l+1}_{i>0} _{i}}{n}\}, \]

where \(c_{0},c_{1}\) are constants independent of the dimension \(p\), sample size \(n\), and time \(t\)1. We omit the dependency of \(k_{0},k_{1}\) on \(c_{0},c_{1},n,\) when the context is clear.

### Main Theorem for Overparameterized Linear Regression with Gradient Descent

Next, we present the main result of this section, which provides a clean condition for compatibility between gradient descent and overparameterized linear regression.

**Theorem 4.1**.: _Consider the overparameterized linear regression setting defined in section 4.1. Let Assumption 1,2 and 3 hold. Assume the learning rate satisfies \(=O(()})\)._

* _If the covariance satisfies_ \(k_{0}=o(n),R_{k_{0}}()=(n),\;r()=o(n)\)_, it is compatible in the region_ \(T_{n}=((),)\)_._
* _If the covariance satisfies_ \(k_{0}=O(n),k_{1}=o(n),r()=o(n)\)_, it is compatible in the region_ \(T_{n}=((),o())\)_._
* _If the covariance does not change with_ \(n\)_, and satisfies_ \(k_{0}=O(n)\) _and_ \(p=\)_, it is compatible in the region_ \(T_{n}=((),o( ))\)_._

The proof of Theorem 4.1 is given in Appendix A and sketched in Section 5. The theorem shows that gradient descent is compatible with overparameterized linear regression under some mild regularity conditions on the learning rate, effective rank and effective dimensions. The condition on the learning rate is natural for optimizing a smooth objective. We conjecture that the condition \(k_{0}=O(n)\) can not be removed in general cases, since the effective dimension \(k_{0}\) characterizes the concentration of the singular values of the data matrix \(\) and plays a crucial role in the excess risk of the gradient descent dynamics.

**Comparison with Benign Overfitting.** The paper  studies overparameterized linear regression and gives the condition for min-norm interpolator to generalize. They prove that the feature covariance \(\) is benign if and only if

\[k_{0}=o(n),\;R_{k_{0}}()=(n),\;r()=o(n) \]

As discussed in Section 3.2, benign problem instance also satisfies compatibility, since benign overfitting requires a stronger condition on \(k_{0}\) and an additional assumption on \(R_{k_{0}}()\). The following example shows that this inclusion relationship is strict.

**Example 4.1**.: _Under the same assumption as in Theorem 4.1, if the spectrum of \(\) satisfies_

\[_{k}=}, \]

_for some \(>1\), we derive that \(k_{0}=(n)\). Therefore, this problem instance satisfies compatibility, but does not satisfy benign overfitting._

Example 4.1 shows the existence of a case where the early stopping solution can generalize but interpolating solution fails. Therefore, Theorem 4.1 can characterize generalization for a much wider range of problem instances.

[MISSING_PAGE_FAIL:7]

_Furthermore, for any positive constant \(\), with probability at least \(1-\), the minimal excess risk on the training trajectory can be bounded as_

\[_{t}R(_{t}))},1\}}{ }+,1\}}{n}. \]

Lemma 5.1 below shows that \(k_{1}=o(n)\) always holds for fixed distribution. Therefore, combining Corollary 5.1 and the following Lemma 5.1 completes the proof of Theorem 4.1.

**Lemma 5.1**.: _For any fixed (i.e. independent of sample size \(n\)) feature covariance \(\) satisfying assumption 1, we have \(k_{1}(n)=o(n)\)._

Next we apply the bound in Corollary 5.1 to several data distributions. These distributions are widely discussed in . We also derive the existing excess risk bounds, which focus on the min-norm interpolator  and one-pass SGD iterate , of these distributions and compare them with our theorem. The results are summarized in Table 1, which shows that the bound in Corollary 5.1 outperforms previous results for a general class of distributions.

**Example 5.1**.: _Under the same conditions as Theorem 5.1, let \(\) denote the feature covariance matrix. We show the following examples:_

1. **(Inverse Polynomial).** _If the spectrum of_ \(\) _satisfies_ \(_{k}=}\) _for some_ \(>1\)_, we derive that_ \(k_{0}=(n)\)_,_ \(k_{1}=(n^{})\)_. Therefore,_ \(_{t}V(_{t})=O(n^{})\) _and_ \(_{t}R(_{t})=O(n^{-\{, \}})\)_._
2. **(Inverse Log-Polynomial).** _If the spectrum of_ \(\) _satisfies_ \(_{k}=(k+1)}\) _for some_ \(>1\)_, we derive that_ \(k_{0}=()\)_,_ \(k_{1}=(n})\)_. Therefore,_ \(_{t}V(_{t})=O(n})\) _and_ \(_{t}R(_{t})=O(n})\)_._
3. **(Constant).** _If the spectrum of_ \(\) _satisfies_ \(_{k}=},1 k n^{1+}\)_, for some_ \(>0\)_, we derive that_ \(k_{0}=0\)_,_ \(k_{1}=0\)_. Therefore,_ \(_{t}V(_{t})=O()\) _and_ \(_{t}R(_{t})=O(})\)_._
4. **(Piecewise Constant).** _If the spectrum of_ \(\) _satisfies_ \(_{k}=\{}\,\,\,\,\,\,\,\,\,\,\,\,\,\,\, \,\,\,\,\,\,\,\,

[MISSING_PAGE_EMPTY:9]

Conclusion

In this paper, we investigate how to characterize and analyze generalization in a data-dependent and algorithm-dependent manner. We formalize the notion of data-algorithm compatibility and study it under the regime of overparameterized linear regression with gradient descent. Our theoretical and empirical results demonstrate that one can ease the assumptions and broaden the scope of generalization by fully exploiting the data information and the algorithm information. Despite linear cases in this paper, compatibility can be a much more general concept. Therefore, we believe this paper will motivate more work on data-dependent trajectory analysis.