# CTIBench: A Benchmark for Evaluating LLMs in Cyber Threat Intelligence

Md Tanvirul Alam

Rochester Institute of Technology

Rochester, NY, USA

&Dipkamal Bhusal

Rochester Institute of Technology

Rochester, NY, USA

&Le Nguyen

Rochester Institute of Technology

Rochester, NY, USA

&Nidhi Rastogi

Rochester Institute of Technology

Rochester, NY, USA

###### Abstract

Cyber threat intelligence (CTI) is crucial in today's cybersecurity landscape, providing essential insights to understand and mitigate the ever-evolving cyber threats. The recent rise of Large Language Models (LLMs) have shown potential in this domain, but concerns about their reliability, accuracy, and hallucinations persist. While existing benchmarks provide general evaluations of LLMs, there are no benchmarks that address the practical and applied aspects of CTI-specific tasks. To bridge this gap, we introduce CTIBench, a benchmark designed to assess LLMs' performance in CTI applications. CTIBench includes multiple datasets focused on evaluating knowledge acquired by LLMs in the cyber-threat landscape. Our evaluation of several state-of-the-art models on these tasks provides insights into their strengths and weaknesses in CTI contexts, contributing to a better understanding of LLM capabilities in CTI. Code and dataset available at [https://github.com/aiforsec/cti-bench](https://github.com/aiforsec/cti-bench).

## 1 Introduction

The evolving landscape of the digital world has led to an unprecedented growth in cyber attacks, posing significant challenges for many organizations. Cyber Threat Intelligence (CTI), which involves the collection, analysis, and dissemination of information about potential or current threats to an organization's cyber systems , can provide actionable insights to help organizations defend against these attacks. Large Language Models (LLMs) have the potential to revolutionize the field of CTI by enhancing the ability to process and analyze vast amounts of unstructured threat and attack data; allowing security analysts to utilize more intelligence sources than ever before. However, LLMs are prone to hallucinations  and misunderstandings of text, especially in specific technical domains, that can lead to a lack of truthfulness from the model . This necessitates the careful consideration of using LLMs in CTI as their limitations can lead to them producing false or unreliable intelligence which could be disastrous if used to address real cyber threats.

The lack of proper benchmark tasks and datasets to evaluate LLM capabilities in CTI leaves their reliability and usefulness an open research question. Without standardized benchmarks, it is difficult to objectively measure and compare how effectively LLMs handle CTI tasks and generally understand the domain. General benchmarks like GLUE , SuperGLUE , MMLU , HELM , KOLA , and various domain-specific benchmarks  provide datasets and frameworks for evaluating LLMs in terms of general language understanding or domain-specific capabilities. However, these benchmarks fail to capture the practical aspects of cybersecurity. Limited works on LLM evaluations in cybersecurity  have primarily catered to specific cybersecurityindustry or, focused on designing tasks that evaluate the memorization ability of LLMs, failing to capture the comprehension and problem-solving capabilities in the broad domain of CTI.

Addressing this gap, we propose **CTIBench**, a novel suite of benchmark tasks and datasets to evaluate LLMs in cyber threat intelligence. To this end, we construct a knowledge evaluation dataset, _CTI-MCQ_, comprising multiple-choice questions aimed at testing LLMs' understanding of crucial CTI concepts, including standards, threat identification, detection strategies, mitigation techniques, and best practices. We utilize various authoritative sources and standards within CTI domain such as NIST , MITRE , GDPR  to craft this dataset. In addition, we introduce three practical CTI tasks designed to evaluate LLMs' reasoning and problem-solving capabilities: (1) _CTI-RCM_, which involves mapping Common Vulnerabilities and Exposures (CVE) descriptions  to Common Weakness Enumeration (CWE) categories ; (2) _CTI-VSP_, which requires calculating Common Vulnerability Scoring System (CVSS) scores ; and (3) _CTI-ATE_, which focuses on extracting MITRE ATT&CK techniques from threat descriptions . These tasks assess the LLMs' proficiency in understanding and evaluating cyber threats, vulnerabilities, and attack patterns. Furthermore, we propose a more complex task, _CTI-TAA_, where LLMs are tasked with analyzing publicly available threat reports and attributing them to specific threat actors or malware families. This task necessitates a thorough understanding of how different cyber threats or malware families have behaved in the past to identify meaningful correlations. Together, these tasks provide a robust framework for assessing LLMs in CTI. Figure 1 provides an overview of our benchmark. We evaluate five state-of-the-art LLMs--three commercial and two open-source--on these tasks. Our results and analysis provide important insights into the LLMs' capabilities in CTI analysis and highlight future avenues for research. We make the datasets and code publicly available.

Through CTIBench, we provide the research community with a robust tool to accelerate incident response by automating the triage and analysis of security alerts, enabling them to focus on critical threats and reducing response time. To the best of our knowledge, CTIBench is the first benchmark specifically designed to evaluate LLMs' comprehension, reasoning, and problem-solving abilities in the broad domain of CTI, addressing the limitations of existing benchmarks that either focus on general language understanding or specific cybersecurity tasks.

## 2 Related Work

**Large Language Models in Cybersecurity.** The advent of large language models (LLMs) like ChatGPT-3 , ChatGPT-4 , LLama models , Gemini  has enabled a wide range of applications across different domains, including cybersecurity. For example: code-based LLMs like CodeLlama  that can generate secure code are already integral parts of various industries. LLMs have also found applications in several other cybersecurity tasks like vulnerability detection , incidence response , program repair , IT operations , and cybersecurity knowledge assistance . Despite these advancements of LLMs, there is a significant gap in their evaluation in the cybersecurity domain.

Figure 1: Overview of CTIBench.

**Evaluating Large Language Models.** General evaluations benchmarks like GLUE , SuperGLUE , MMLU , HELM  and KOLA  assess general understanding capabilities of LLMs. Existing evaluation works in cybersecurity are either limited by their lack of comprehensiveness or being too narrow in their domain adaptation. For example: SECURE  proposes benchmarks for ICS industries, Purple Llama CyberSecEval , and SecLLMHolmes  evaluates LLMs' propensity to generate insecure code. SevenLLM  design tasks focused on extracting entities, relationships, and generating summaries categorized into understanding and generation tasks, and lack practical problem-solving evaluation of LLMs in the CTI domain. Other cybersecurity benchmarks  only evaluate the memorization and information extraction capabilities of LLMs.

## 3 CTIBench: A Benchmark for Evaluating LLMs in CTI

We are motivated by the need to create knowledge-intensive tasks to evaluate the cognitive capabilities of LLMs in Cyber Threat Intelligence (CTI) . Our benchmark aims to verify that LLMs can understand, investigate, and analyze cyber threat reports. To this end, we have designed tasks and datasets that emphasize four fundamental cognitive capabilities of LLMs in CTI: _memorization_ (ability to recall and utilize previously learned information), _understanding_ (ability to comprehend the content and context), _problem-solving_ (ability to apply knowledge and reasoning to address specific challenges), and _reasoning_ (ability to draw logical conclusions and make informed decisions based on available information) .

### CTI-MCQ: Cyber Threat Intelligence Multiple Choice Questions

Data Collection.To generate the CTI-MCQ dataset, we utilize various authoritative sources within the CTI domain. These sources include, among others, CTI frameworks such as NIST , the Diamond Model of Intrusion Detection , and regulations like GDPR . Additionally, we incorporate CTI sharing standards such as STIX and TAXII  to formulate questions on fundamental cybersecurity and CTI knowledge. We leveraged the MITRE ATT&CK framework , CWE database , and CAPEC  to develop questions on attack patterns, threat actors, APT campaigns, detection methods, mitigation strategies, common software vulnerabilities and attack pattern enumeration. Finally, we supplement our dataset by manually collecting and curating questions from publicly available CTI quizzes, ensuring their relevance and accuracy by referencing established CTI resources. While these quizzes may introduce some bias, as they may not fully represent the entire spectrum of CTI knowledge, we ensured our diverse range of sources and manual curation process mitigated this potential limitation.

Generating Questions Using GPT-4.We utilize GPT-4o  to prepare the MCQs. Initially, we preprocess the content from the webpage to remove sections inappropriate for MCQ generation (such as page creation or update dates, references, etc.). We then optimize the prompt for creating questions that are challenging enough to test the knowledge of LLMs in cybersecurity. An example prompt is shown in Prompt A. We vary the number of questions we generate based on document length; we create more questions as the length of the document increases. We then randomly sample approximately 3000 questions for manual validation. This approach ensures a variety of questions while retaining quality

Dataset Validation.We manually analyze the quality of MCQs extracted from ChatGPT-4o to ensure the quality of the CTI-MCQ dataset. The human annotators were given access to the source URLs when analyzing the questions. We identified _two major issues from LLM-generated questions_: some questions had multiple correct options in the answers, and sometimes the LLM-given answer was incorrect. We removed the questions that were unanswerable from the given context or questions that included multiple correct options. We fixed the responses that had incorrect annotations provided by ChatGPT-4o.

Our final dataset consists of \(2500\) questions, out of which, \(1578\) questions are collected from MITRE, \(750\) from CWE, \(40\) from the manual collection, and \(32\) from standards and frameworks. This approach ensures a variety of questions while retaining quality.

### CTI-RCM: Cyber Threat Intelligence Root Cause Mapping

Root cause mapping (RCM) identifies the underlying cause(s) of a vulnerability by correlating CVE records and bug tickets with CWE entries . Accurate RCM is crucial for guides investments, policies, and practices to address and eliminate the root causes of vulnerabilities, benefiting both industry and government decision-makers. However, the current vulnerability management ecosystem does not perform this task accurately at scale , due to the complexity and nuance of CVE descriptions, the vast number of CWE categories (over 900 as of May 2024), and the need for domain expertise to interpret the relationships between them. To address this challenge, we designed the CTI-RCM task. Here is an example of RCM from MITRE . The description for CVE-2018-15506 is as follows:

In BubbleUPnP 0.9 update 30, the XML parsing engine for SSDP/UPnP functionality is vulnerable to an XML External Entity Processing (XXE) attack. Remote, unauthenticated attackers can use this vulnerability to: (1) Access arbitrary files from the filesystem with the same permission as the user account running BubbleUPnP, (2) Initiate SMB connections to capture a NetNTLM challenge/response and crack the cleartext password, or (3) Initiate SMB connections to relay a NetNTLM challenge/response and achieve Remote Command Execution in Windows domains.

The CWE is mapped to CWE-611: Improper Restriction of XML External Entity Reference. Here is the reasoning excerpt as shown in the reference link:

Reasoning: Description says "vulnerable to an XML External Entity Processing (XXE) attack." There is additional information that focuses on technical impact, for instance, "attackers can do [X]", which is rarely useful for weaknesses, so that can be ignored. When you perform a text search on CWE for "XML External Entity Processing (XXE) attack" and "XXE," it returns CWE-611. When you click the entry, you see that the entry lists XXE as an "Alternate Term." Therefore, CWE-611 is the right mapping for this CVE.

As can be seen, this is a very nuanced task and requires a deep understanding of both the CVE descriptions and the CWE taxonomy to make accurate mappings.

Data Collection.For this task, we collect data from the National Vulnerability Database (NVD) . The NVD database provides descriptions of past vulnerabilities identified by CVE, along with their associated mappings to Common Weakness Enumeration (CWE) entries. For our study, we specifically focus on vulnerabilities reported in the year 2024 that include associated CWE mappings. We then randomly sample 1,000 vulnerabilities to include in our dataset.

### CTI-VSP: Cyber Threat Intelligence Vulnerability Severity Prediction

The Vulnerability Severity Prediction task involves predicting the Common Vulnerability Scoring System (CVSS) vector string from a given vulnerability description . The CVSS is a standardized framework used to assess the severity of security vulnerabilities. It is composed of three metric groups: Base, Temporal, and Environmental. The Base metric group, which we focus on in our study, reflects the severity of a vulnerability based on its intrinsic characteristics. These characteristics are constant over time and assume a reasonable worst-case impact across different deployed environments. More details can be found in Appendix B.

While accurately calculating an accurate CVSS score requires additional detailed information such as original bug identification, third-party exploit analysis, or technical documentation for the vulnerable software, an approximation can be made using the initial CVE description1. The CVSS v3 Base Score is derived from the following eight metrics: _Attack Vector (AV)_, _Attack Complexity (AC)_, _Privileges Required (PR)_, _User Interaction (UI)_, _Scope (S)_, _Confidentiality Impact (C)_, _Integrity Impact (I)_, and _Availability Impact (A)_. Accurately calculating the CVSS score necessitates correctly mapping the vulnerability description to the appropriate severity levels for each metric. This task is inherently challenging due to the need for precise interpretation and understanding of technical language and context. Consequently, it serves as a robust benchmark for evaluating the capability of Large Language Models (LLMs) in understanding and processing cybersecurity-related information.

Note that while there is a newer CVSS standard, CVSS 4.0, it was standardized in November 2023, and not all models might have adequate knowledge of the standard. Therefore, we focus on CVSS v3.

Data Collection.We use the same data source as the CTI-RCM for this task. Specifically, we collect 1,000 vulnerability descriptions from 2024 and their associated CVSS v3 strings.

### CTI-ATE: Cyber Threat Intelligence Attack Technique Extraction

The Attack Technique Extraction task involves identifying specific attack patterns from a given description of threat behavior and mapping them to the corresponding MITRE ATT&CK technique IDs . These technique IDs represent distinct adversarial methods used at various stages of an attack lifecycle.

Consider the following example2:

Janicab is an OS X trojan that exploited a valid Apple Developer ID to deceive users during installation. It captured both audio and screenshots, which were then transmitted to a remote command and control (C2) server. For persistence, Janicab employed a cron job on affected Mac devices. The use of a legitimate Apple Developer ID enabled the trojan to bypass security restrictions by signing the malicious code.

From this description, we can identify the following relevant attack technique IDs: (i) T1123 - Audio Capture, (ii) T1053 - Scheduled Task, (iii) T1113 - Screen Capture, and (iv) T1553 - Subvert Trust Controls.

This task is valuable for CTI practitioners, as accurately mapping observed behaviors to the corresponding MITRE ATT&CK techniques is essential for designing effective mitigation strategies and deploying targeted security measures. By linking specific behaviors to their respective technique IDs, security teams can better understand the adversary's tactics, techniques, and procedures (TTPs), enabling them to take proactive actions to disrupt or mitigate ongoing threats.

Data Collection.For this task, we curated a dataset using information from the MITRE ATT&CK framework , which provides comprehensive descriptions of various malware and their associated adversarial behaviors, each categorized by a unique attack technique ID based on open-source threat reports. Our dataset includes 30 instances of malware reported in 2024, alongside their corresponding attack technique IDs--information that extends beyond the knowledge cutoff of the LLMs under evaluation. We also supplemented the dataset with 30 malware instances reported before 2024. For this task, we focused solely on techniques (excluding sub-techniques). In total, the dataset comprises 397 unique attack techniques.

### CTI-TAA: Cyber Threat Intelligence Threat Actor Attribution

Threat actor attribution is a crucial process of identifying the individuals, groups, or organizations responsible for a cyberattack or malicious activity. This is usually done by analyzing various indicators of compromise (IOCs), such as malware signatures, attack vectors, infrastructure, tactics, techniques, procedures (TTPs), and other contextual information like geopolitical motives or previous attack patterns. This is a challenging task because threat actors often use sophisticated evasion tactics, shared tools and techniques, limited and incomplete data, rapidly changing TTPs, and inherent biases in analysis . This task exemplifies abductive reasoning, which involves forming plausible conclusions from incomplete information, often seeking the best explanation . By evaluating LLMs on this task, we aim to benchmark their capability to perform complex reasoning and analysis in the context of CTI.

Data CollectionWe create a small-scale dataset to enable LLMs to reason about this intricate CTI concept. To this end, we collect 50 threat reports from reputed vendors that have an Advanced Persistent Threat (APT) group attributed to the reports . The reports vary in the amount of detail provided about the threat actor.

To create a controlled evaluation setting, we remove all mentions of the threat actors and their associated malware campaign names, replacing them with placeholders. We then task the LLMs with attributing the reports to known threat actors. To further ensure accuracy, we manually verify each LLM response to account for the multiple aliases that threat actors often use.

## 4 Experiments and Results

### Experimental Settings

We evaluate ChatGPT-3.5 (gpt-3.5-turbo) , ChatGPT-4 (gpt-4-turbo) , Gemini-1.5 , LLAMA3-70B  and LLAMA3-8B  on our benchmark tasks. We set the temperature of LLMs at 0 and \(top\_p=1\) to obtain more deterministic responses. Each task is evaluated on a zero-shot prompt template with instruction of LLMs to act as a cybersecurity expert. Below, we show a prompt template used for the vulnerability root cause mapping. Please see Appendix C for evaluation prompts used for all tasks.

You are a cybersecurity expert specializing in cyber threat intelligence. Analyze the following CVE description and map it to the appropriate CWE. Provide a brief justification for your choice. Ensure the last line of your response contains only the CWE ID.

CVE Description:

\(\{description\}\)

### Evaluation Metrics

We use accuracy to evaluate the CTI-MCQ and CTT-RCM tasks, as both tasks are equivalent to multi-class classification. For the CTI-VSP task, we compute the mean absolute deviation (MAD) between the CVSS v3.1 scores of the ground truth and the model's predictions. Although we ask the model to predict a vector string, the CVSS score can be deterministically derived from it. We utilize the Python library _cvss_ to compute the CVSS score (a numerical value in the range of 0-10 that determines the overall severity of a vulnerability) from the predicted string, ensuring that any potential errors from the LLM performing the computation are eliminated. This approach focuses solely on assessing the LLM's reasoning ability regarding vulnerability. We adopt the Micro-F1 score as the evaluation metric for the CTI-ATE task. Given that this task requires accurately extracting the relevant attack techniques from the provided text and mapping them to their corresponding MITRE ATT&CK technique IDs, the Micro-F1 score is suitable for capturing both precision and recall in a multi-label classification setting.

For the CTI-TAA task, we categorize the predictions into three types: _correct answer_ (when the LLM accurately identifies the threat actor or one of its aliases), _plausible answer_ (when the threat report lacks sufficient details to pinpoint the answer, but the LLM provides a plausible or related threat actor within a similar group), and _incorrect answer_ (when the LLM misattributes the threat actor due to misjudgment, hallucination, or spurious correlation). Based on these categories, we compute two types of accuracy: Correct Accuracy, which is the fraction of correct answers, and Plausible Accuracy, which is the fraction of correct and plausible answers combined. Details on generating the ground truth and evaluation for CTI-TAA are provided in Appendix D.

### Results Summary

Table 1 presents the performance of various LLMs on our benchmark CTI tasks. The results indicate that GPT-4 outperforms other models across all tasks except for CTI-VSP, where Gemini-1.5 takes the lead. Despite being open-source, LLAMA3-70B performs comparably to Gemini-1.5 and even outperforms it on three tasks, though it struggles with the CTI-VSP task. ChatGPT-3.5 exceeds the performance of LLAMA3-8B but is generally outperformed by the other models across most tasks. LAMA3-8B, being a smaller model, fails to match the performance of larger models on tasks requiring more nuanced understanding and reasoning. However, it performs decently on the CTI-MCQ task.

## 5 Analysis

### CTI-MCQ

The heatmap analysis of error correlations, in Figure 2(a), shows that the larger models exhibit higher error correlations. This trend suggests that these models, such as ChatGPT-4, Gemini-1.5, and LLAMA3-70B, are likely to make similar mistakes when answering the CTI-MCQ. For instance, ChatGPT-4 shows error correlations of 0.52 with Gemini-1.5 and 0.55 with LLAMA3-70B, while Gemini-1.5 and LLAMA3-70B have a correlation of 0.54. In Figure 2(b), we show the number of questions incorrectly answered by a number of LLMs. Overall, 293 questions were answered incorrectly by all the models (5) in the evaluation. Upon inspection, we found these questions to be related to mitigation plans and tools and techniques used by adversaries. We show a sample of such questions in Appendix Table 5.

Figure 2(c) displays the accuracy of different LLMs on multiple-choice questions (MCQs) from two primary sources: MITRE ATT&CK and CWE. Given that MITRE ATT&CK information is more volatile compared to the more stable nature of CWEs, models generally perform better on questions sourced from CWE. However, even the best-performing model, ChatGPT-4, achieves an accuracy of 75.65%, indicating that there is still further room for improvement.

While Table 1 presents the results for the MCQ task without an explicit reasoning step, we also performed an additional evaluation incorporating an explicit reasoning prompt. The detailed results of this evaluation are provided in Appendix E. However, this approach did not consistently lead to performance improvements. We hypothesize that this is because the MCQ task primarily relies on memorization rather than reasoning.

### Cti-Rcm

In the CTI-RCM task, LLMs are assigned to identify the underlying cause(s) of a vulnerability by correlating CVE Records with CWE entries. Figure 3(a) shows the frequency distribution of word counts across the CVE descriptions in our dataset, revealing a right-skewed distribution where most descriptions have a lower word count. Figure 3(b) demonstrates that all models, except LLAMA3-8B, improve accuracy with longer descriptions, peaking in the 54-69 word range. This trend suggests that longer descriptions offer more context, aiding the models in accurately mapping CVE records to CWE entries. However, performance declines for the longest CVE descriptions. The most likely reason is

    &  &  &  &  &  \\    & & & & **Correct** & **Plausible** \\  ChatGPT-4 & **71.0** & **72.0** & 1.31 & **0.6388** & **52** & **86** \\ ChatGPT-3.5 & 54.1 & 67.2 & 1.57 & 0.3108 & 44 & 62 \\ Gemini-1.5 & 65.4 & 66.6 & **1.09** & 0.4612 & 38 & 74 \\ LLAMA3-70B & 65.7 & 65.9 & 1.83 & 0.4720 & 52 & 80 \\ LLAMA3-8B & 61.3 & 44.7 & 1.91 & 0.1562 & 28 & 36 \\   

Table 1: Results of different LLMs on the benchmark datasets (bold indicates the best performing model, lower is better for MAD)

Figure 2: Error analysis on the CTI-MCQ tasksthat as description length increases, the potential for matching multiple weaknesses increases, causing LLMs to struggle to identify the most appropriate one.

When creating the CTI-RCM dataset, we gathered CVE descriptions exclusively from 2024, which is beyond the training cut-off date for the models we evaluated. To investigate model performance further, we conducted an additional experiment using CVE descriptions and their associated CWE mappings from 2021. The results, presented in Figure 3 (c), show that four out of five models perform slightly worse on the 2021 dataset. This suggests the task is inherently challenging and could serve as a robust evaluation benchmark for future LLMs.

### Cti-Vsp

In the CTI-VSP task, LLMs are tasked with predicting the CVSS v3 Base String based on the CVE description, which is then converted to a CVSS score using a predefined formula. We evaluate the performance of the LLMs by computing the Mean Absolute Deviation (MAD) from the ground truth in the dataset. Like the CTI-RCM task, models tend to perform better with longer descriptions, as indicated by a decrease in MAD in Figure 3(c). However, there is a noticeable performance drop for all the models, as evidenced by the sharp increase in MAD for the last quintiles. This pattern suggests that while longer descriptions provide more context and generally improve performance, they can also introduce complexity that leads to misattribution of the severity of the threat. This combined finding from the CTI-VSP and CTI-RCM tasks indicates that additional description length does not necessarily equate to better performance and may hinder the models' ability to assess the threat accurately.

We illustrate the accuracy of LLMs in predicting the CVSS v3 Base Metrics in Figure 4(a). The CVSS Base Metrics include Attack Vector (AV), Attack Complexity (AC), Privileges Required (PR), User Interaction (UI), Scope (S), Confidentiality Impact (C), Integrity Impact (I), and Availability Impact (A) (detailed in Appendix B). The heatmap shows that all models perform relatively well predicting AV, AC, and UI. However, they struggle with PR, S, C, and I, suggesting that CVE descriptions often lack sufficient detail to infer these metrics accurately.

Figure 4: CTI-VSP analysis

Figure 3: CTI-RCM and CTI-VSP analysis

Figure 4(b) illustrates the number of overestimations and underestimations made by LLMs when predicting the CVSS base score from a vulnerability description. Overestimation occurs when the predicted score is higher than the actual score, while underestimation occurs when the predicted score is lower. All models exhibit a higher frequency of overestimation compared to underestimation, with this tendency being particularly pronounced in the two open-source LLAMA models. This suggests that LLMs may need calibration to improve their accuracy in threat severity prediction.

### Cti-Ate

The results in Table 1 demonstrate that ChatGPT-4 significantly outperforms other models on the CTI-ATE task, underscoring the complexity of the task. To further investigate model performance, we evaluated the models on samples collected before and after their respective knowledge cutoff dates. These results are presented in Table 2. Most models exhibit slightly better performance on samples collected before their knowledge cutoff, except for Gemini, which performs better on post-cutoff samples. The performance differences are generally insignificant, suggesting that this can serve as a reasonable indicator of how LLMs will fare on future threat reports.

### Cti-Taa

The results of the threat actor attribution tasks (Table 1) indicate that LLMs can perform nuanced analyses of the information presented in threat reports and make insightful correlations. While smaller models like LLAMA3-8B struggle with more complex reasoning tasks, larger models demonstrate reasonable performance. Our analysis of the reasoning provided by LLMs suggests that they possess a general understanding of the cyber threat landscape, though they may occasionally misattribute information. Below, we present representative examples of threat-attribution predictions made by ChatGPT-4.

Correct response:We task the LLM to predict the threat actor CHRYSENE given a threat report by replacing the mention of the threat actor and its campaign with [PlaceHolder].3 CHRYSENE is an Iranian cyberespionage group active since 2014, targeting Middle Eastern governments and various industries. ChatGPT-4 predicted the threat actor as OilRig, which is an alias of CHRYSENE.

Plausible response:We task the LLM to predict the threat actor MuddyWater given a threat report by replacing the mention of the threat actor and its campaign with [PlaceHolder].4 MuddyWater is a cyber espionage group linked to Iran's Ministry of Intelligence and Security (MOIS) that targets government and private sectors across the Middle East, Asia, Africa, Europe, and North America. ChatGPT-4 predicted the threat actor as APT35, which is not the alias of MuddyWater but shares some common attack patterns like originating from Iran, targeting the Middle East and North America, and using multi-stage attacks.

**Incorrect response:** We task the LLM to predict the threat actor APT41 given a threat report by replacing the mention of the threat actor and its campaign with [PlaceHolder].5 APT41 is an espionage group from China that has been active since 2012 and involved in financially motivated operations, targeting healthcare, telecom, technology, and video game industries. ChatGPT-4 incorrectly predicted the threat actor as APT29, based on the fact that APT29 has been active since 2012 and its state-sponsored espionage operations.

  
**Model** & **Before (F1)** & **After (F1)** \\  ChatGPT-4 & 0.6542 & 0.6208 \\ ChatGPT-3.5 & 0.3420 & 0.3333 \\ Gemini-1.5 & 0.4360 & 0.5263 \\ LLAMA3-70B & 0.4934 & 0.4297 \\ LLAMA3-8B & 0.1813 & 0.1366 \\   

Table 2: Performance comparison on the CTI-ATE task, evaluated on samples before and after the models’ knowledge cutoff dates.

Impact of Knowledge Cutoff:We evaluate the LLMs on the CTI-TAA task using datasets from both before and after their knowledge cutoff dates. The results are displayed in the table below. With the exception of LLAMA3-8B, all other LLMs demonstrated better performance on datasets available during their training period, suggesting that memorization plays a role in improving performance to some extent in this task.

### Compute Cost

Appendix G presents the detailed token counts for each task. GPT-4 generated significantly longer responses across all tasks than the other models.

## 6 Ethical Concerns

All the evaluation tasks in our proposed benchmark utilize publicly available threat information from reputable sources such as NIST, MITRE, CVE, CWE, and EU. None of the datasets include personal information or make sensitive judgments related to social issues, bias, deception, or discrimination.

## 7 Limitations

While our evaluation of large language models (LLMs) for Cyber Threat Intelligence (CTI) tasks provides valuable insights, it is important to recognize certain limitations. First, the extensive scope of CTI activities presents a significant challenge, and our study has focused on a limited subset of tasks to assess the capabilities of LLMs. This selection may not fully capture the breadth of functionality required for comprehensive CTI operations. In future work, we plan to expand the range of evaluated tasks to encompass a broader spectrum of CTI activities, thereby ensuring a more holistic assessment of LLM performance in this domain.

Second, our evaluation is restricted to English-language CTI techniques. This limitation neglects the global nature of cyber threats, which frequently span multiple languages and regions. To address this, future studies will incorporate multilingual CTI evaluations, better reflecting the diverse linguistic landscape of cyber threats and improving the applicability of LLMs in international cybersecurity contexts.

Additionally, there is a genuine risk of the malicious use of LLMs to exploit CTI knowledge for harmful purposes. For instance, if misused, LLMs could generate and disseminate compelling but false threat intelligence reports. Such reports might mislead decision-makers, result in the misallocation of resources, or prompt inappropriate responses. Benchmarking the potential for such misuse remains an open area for future research.

## 8 Conclusion

The emergence of LLMs has opened up new possibilities in cybersecurity, especially in Cyber Threat Intelligence (CTI). However, their capabilities and limitations in this domain remain unclear. In this paper, we introduce CTIBench, a benchmark designed to evaluate LLM performance in various CTI tasks. Our evaluation offers valuable insights into the knowledge and capabilities of LLMs across various CTI aspects, as well as their limitations. We aim for our benchmark to help researchers understand the practical applications of LLMs in CTI and to pave the way for their reliable use and the effective detection and mitigation of cyberthreats.

  
**Model** &  &  \\   & **Correct** & **Plausible** & **Correct** & **Plausible** \\  ChatGPT-4 & 58.06 & 90.32 & 42.10 & 78.95 \\ ChatGPT-3.5 & 50.00 & 75.00 & 43.48 & 60.87 \\ Gemini-1.5 & 34.61 & 76.92 & 41.66 & 70.83 \\ LLAMA3-70B & 58.06 & 83.87 & 42.10 & 73.68 \\ LLAMA3-8B & 25.00 & 25.00 & 28.94 & 39.47 \\   

Table 3: Performance comparison of models before and after knowledge cutoff dates for the CTI-TAA task.