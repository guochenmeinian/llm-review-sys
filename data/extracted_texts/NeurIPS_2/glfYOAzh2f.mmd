# Selective Generation for

Controllable Language Models

 Minjae Lee

GSAI

POSTECH

minjae.lee@postech.ac.kr &Kyungmin Kim

GSAI

POSTECH

kkm959595@postech.ac.kr &Taesoo Kim

SCS & SCP

GaTech

taesoo@gatech.edu &Sangdon Park

GSAI & CSE

POSTECH

sangdon@postech.ac.kr

Equal contribution

###### Abstract

Trustworthiness of generative language models (GLMs) is crucial in their deployment to critical decision making systems. Hence, certified risk control methods such as selective prediction and conformal prediction have been applied to mitigating the hallucination problem in various supervised downstream tasks. However, the lack of appropriate correctness metric hinders applying such principled methods to language generation tasks. In this paper, we circumvent this problem by leveraging the concept of _textual entailment_ to evaluate the correctness of the generated sequence, and propose two selective generation algorithms which control the false discovery rate with respect to the textual entailment relation (FDR-E) with a theoretical guarantee: \(^{}\) and \(^{}\). \(^{}\), a direct modification of the selective prediction, is a supervised learning algorithm which exploits entailment-labeled data, annotated by humans. Since human annotation is costly, we further propose a semi-supervised version, \(^{}\), which fully utilizes the unlabeled data by pseudo-labeling, leveraging an _entailment set function_ learned via conformal prediction. Furthermore, \(^{}\) enables to use more general class of selection functions, _neuro-selection functions_, and provides users with an optimal selection function class given multiple candidates. Finally, we demonstrate the efficacy of the \(\) family in achieving a desired FDR-E level with comparable selection efficiency to those from baselines on both open and closed source GLMs. Code and datasets are provided at [https://github.com/ml-postech/selective-generation](https://github.com/ml-postech/selective-generation).

## 1 Introduction

Generative language models (GLMs)  have garnered significant attention for their ability to generate human-level language  primarily due to underlying transformer architectures . However, GLMs raise concerns about generating hallucinated facts , which is an undesirable property when they are used as knowledge retrieval sources. This issue can be mitigated by fine-tuning with human feedback , but it remains expensive in terms of training and labeling costs. Certified risk control methods such as selective prediction  and conformal prediction  are promising cost-efficient alternatives, which have been applied to the hallucination mitigation in various supervised downstream tasks .

The main bottleneck in applying such certified methods to language generation tasks is that provided risk control guarantees require correctness labels during the learning process. Specifically, in classification, high-quality correctness labels can be directly acquired by comparing true and predicted labels using exact match (EM). However, this is not the case for language generation tasks, since multiple valid answers can exist for the same question. As correctness metrics such as EM and F1-score do not account for the multiple valid answers, directly applying them to language generation tasks results in a significant gap between the true and measured correctness, which we call the _metric misalignment_. Thus, a correctness evaluation metric that accounts for multiple answers is required.

In this paper, we resolve the metric misalignment problem by leveraging _textual entailment_ to evaluate the correctness of generated answers and define the false discovery rate with respect to the textual entailment relation (FDR-E). Given two ordered sequences, a premise and a hypothesis, we say that the premise entails the hypothesis if the hypothesis is true given the premise. Based on this notion of entailment, we propose two selective generation algorithms, \(^{}\) and \(^{}\), which are generalized versions of selective classification  to control the FDR-E by abstaining from returning an answer when a GLM is uncertain of its answer.

In particular, \(^{}\), a direct modification of , is a supervised selective generator learning algorithm which requires entailment labels. This necessitates human annotations on textual entailment, where a generated answer is the premise and a true answer is the hypothesis. As labeling is expensive and \(^{}\) solely relies on entailment-labeled data, we propose a semi-supervised method, \(^{}\), which enables the exploitation of entailment-unlabeled data in learning a selective generator by pseudo-labeling textual entailment using an _entailment set function_ learned via conformal prediction . Based on an entailment classifier originally developed for the natural language inference problem , the estimated entailment set function approximates a true entailment set function, which returns all entailed answers if a true answer is given as a hypothesis.

Additionally, \(^{}\) introduces the general class of selection functions for selective generation, called _neuro-selection functions_. In selective prediction, learning a selective predictor is equivalent to learning a selection function, which is an indicator function to decide whether to abstain from returning a prediction. The standard selective prediction algorithm  considers the class of single-threshold indicator functions using a pre-specified confidence-rate function. For the same risk level, the better the confidence-rate function quantifies the model's uncertainty, the less likely the selective predictor is to abstain from making a prediction. We refer to this as _selection efficiency_ henceforth. As appropriate confidence calibration for language generation remains challenging, optimizing a single-threshold indicator function with a poorly calibrated confidence-rate function leads to low selection efficiency. Instead, we generalize the selection function by using a multiple-threshold indicator function with trainable features. Furthermore, \(^{}\) provides a user with an optimal class of selection functions among possible candidates in terms of the FDR-E.

Finally, we empirically demonstrate the efficacy of \(^{}\) over open and closed source GLMs, where we consider \(^{}\) as one of our baselines as it is a direct modification of . To validate

Figure 1: An overview and qualitative results of our method with GPT-3.5-Turbo. The crux is to learn an entailment-aware selective generator with an abstaining option that controls the rate of hallucination (in a false discovery rate) over generated sequences with a probabilistic guarantee.

our method and its theoretical guarantee, we create a new dataset on textual entailment using the Natural Questions (NQ) dataset  for each GLM. Given a question and answer pair, the textual entailment is labeled by letting a generated answer as a premise and the true answer in declarative form as a hypothesis. As communities lack human-annotated entailment-labeled data for language generation, we believe that our dataset contributes to the hallucination evaluation of GLMs. For both open and closed source GLMs, SGenSemi is effective in achieving a desired FDR-E level with better selection efficiency compared to baselines.

### Related Work

We introduce two main research directions to mitigate hallucination in GLMs.

**Heuristics for hallucination mitigation.** The hallucination in language generation usually refers to the situation where a GLM generates wrong answers with high confidence, which hinders the reliable deployment of GLMs. As fine-tuning methods are expensive, heuristics for hallucination mitigation without tuning have been proposed [18; 19]. Notably,  proposes a performant hallucination detection method, which quantifies the self-consistency among multiple generated answers for the same question using textual entailment models to detect the hallucination. However, these methods do not provide certified control over the occurrence of hallucinated contents.

**Certified methods for hallucination mitigation.** Conformal prediction outputs a prediction set that is guaranteed to contain a true label with high probability, where a provided coverage guarantee is model-agnostic under a mild assumption on a data . Although this property enables the safe deployment of complex models and has made conformal prediction popular [10; 12; 13; 20; 21; 22], the constructed prediction sets in language generation are often less-informative due to an unbounded label space, which frequently renders the coverage guarantee ineffective [23; 24]. To restrict the prediction set to a moderate size,  constructs the prediction set over answers by sampling them sequentially, while still satisfying the coverage guarantee. Still, post-selection of answers from the prediction set is necessary for final decision making, which may result in the selection bias [25; 26]. [27; 28] decompose generated answers into alignment-labeled sub-claims and return a set of sub-claims that contains no contradiction with high probability via conformal prediction. Even though the post-selection is unnecessary, it requires expensive alignment labels for every sub-claim.

Unlike conformal prediction, selective prediction directly manages target risk at a desired level by introducing an abstaining option on unsure predictions.  proposes a selective prediction method mainly for classification, which learns a threshold-based selection function that controls the false discovery rate (FDR) to a desired level.  generalizes the selective prediction to language generation. However, their theoretical guarantee is not focused on the target risk to control, but on a consistency property of a surrogate loss function with respect to a true loss function in optimization process. , concurrently published with our paper, proposes a certified selective generation method for context-given language generation which controls the FDR. Unlike  which takes the number of selected samples as constraint in learning the selection function,  set the power as constraint. However, as  does, they require an additional calibration set for training an entailment scoring function. Importantly, while existing selective generation methods are supervised learning methods, we propose a semi-supervised learning algorithm that can fully leverage entailment-unlabeled data.

## 2 Background

While we consider general language generation tasks, we confine our scope to the open-ended question-answering task and define the notation accordingly for the sake of clarity and for maintaining consistency in descriptions on the experiment. Specifically, let \(\) denote a token space constructed using a tokenizer, such as Byte Pair Encoding , and let \(^{*}\) denote a token sequence space, defined as \(^{*}_{i=0}^{}^{i}\). Let \((,)\) be a question and answer sequence pair, where \(^{*}\) and \(^{*}\) refer to the token sequence spaces of questions and answers, respectively. We assume the answer sequence is in a declarative form. Finally, \(_{i:j}\) refers to the sub-sequence of \(\) from the \(i\)-th to the \(j\)-th token.

### Language Generation

Given a question as input, a GLM generates an answer through the sequential process called decoding, which we call language generation. Here, we consider the greedy decoding, a deterministic generation process described as follows. Let \(p_{M}:_{ 0}\) denote a GLM which returns a next-tokendistribution given the input sequence \(\), where \(_{w}p_{M}(w)=1\) for all \(\). A language generator \(G:\) using greedy decoding sequentially generates tokens from the GLM as follows: \(}_{i}_{w}\,\,p_{M}(w(,}_{1:i-1}))\) for \(i 2\) and \(}_{1}_{w}\,p_{M}(w)\). The generator \(G\) returns a generated answer \(} G()\) and terminates the decoding process when the end-of-sequence (EOS) token is returned. Here, the conditional probability of the answer \(}\) is defined as \(f_{M}(,}) p_{M}(}_{1} )_{i=2}^{||}p_{M}(}_{i}(,}_{1:i-1}))\), commonly used as its uncertainty measure.

### Selective Prediction

Selective prediction refuses to make a prediction by returning "I don't know" (IDK) if the prediction is uncertain. In classification, the selective classifier \(\) consists of a pair of a classifier \(\) and a selection function \(\), and is defined as follows: \(()G()&( )=1\\ &,\) where \(()_{y}\,f(,y)\). Here, \(f(,y)\) refers to an estimated likelihood of the given input \(\) for being a class \(y\), determined by an underlying classification model \(f\). Although the selection function can be of arbitrary form, the common choice is a single threshold indicator function using the maximum likelihood as the confidence-rate function, _i.e.,_\(()(f(,))\). Here, the confidence-rate function is defined to quantify the uncertainty of the model's prediction. Under the independent and identically distributed (i.i.d.) assumption,  proposed the certified threshold learning algorithm which controls the false discovery rate (FDR) with respect to the EM metric with the PAC guarantee, where the FDR is defined as \(_{}()\{()  y()\}\). Since EM considers the answer \(()\) to be correct when it is exactly the same as the reference answer \(y\), it is an inappropriate correctness metric for language generation problems that can have multiple valid sequences for the same input. This results in learning a too conservative and vacuous selection function for language generation, which is empirically verified by our experiments. Thus, we leverage the textual entailment to evaluate the correctness of the generated sequence to alleviate the metric misalignment problem.

### Textual Entailment

Natural language inference (NLI), also denoted as recognizing textual entailment, predicts whether one sequence implies another. The former refers to a premise (\(\)), and the latter refers to a hypothesis (\(\)). Since the release of two large-scale benchmarks of ordered sequence pairs labeled with textual entailment [15; 16], a number of transformer-based entailment classifiers have been proposed and shown impressive results. Each pair is classified into one of three categories: _entailment_ if \(\) is true given \(\); _contradiction_ if \(\) is false given \(\); and _neutral_ otherwise. In this paper, we define the entailment scoring function as \(f_{E}(G(),) 1-p_{E}( =G(),=)\) to estimate and pseudo-label the correctness of \(G()\), where \(p_{E}(=G(),=)\) is the likelihood that \(G()\) contradicts \(\). While pseudo-labeling enables the full exploitation of unlabeled data to learn a selection function, controlling the mislabeling error remains as a challenge.

### Conformal Prediction

Conformal prediction  outputs a prediction set to quantify the uncertainty of a given model with a model-agnostic correctness guarantee under minimal assumptions on data generating process. Specifically, under the i.i.d. assumption, PAC conformal prediction  incorporates the interpretation of tolerance regions  and training-conditional inductive conformal prediction  through the lens of PAC learning theory . In this paper, we adopt the PAC prediction set learning algorithm to control the rate of mislabeling error in pseudo-labeled samples used to learn a selection function for selective generation. See Section A.1 for detailed discussion on conformal prediction.

**Scalar-parameterized Conformal Set.** In this paper, we consider a conformal set \(C: 2^{}\) parameterized by a scalar [11; 33] as \(C()\{y\,|\,f(,y) \},\) where \(\) is a scalar parameter to learn, \(\) is a hypothesis space (_e.g.,_\(\) a finely discretized non-negative real numbers), and \(f:_{ 0}\) is called a _scoring function_. The scoring function corresponds to a target model whose uncertainty is to be quantified, where the softmax output is a common choice in classification. Specifically, \(f(,y)\) measures the likelihood of \(y\) as a response given \(\) as input.

**PAC Guarantee.** The PAC prediction set learning algorithm outputs a conformal set \(\) which upper bounds a miscoverage rate \(_{}()\{y( )\}\) to a desired level \((0,1)\), where the miscoverage rate can be generalized to risk \(_{01}()\{_{01}(,,y )\},\) on any indicator losses that are monotonic with respect to \(\). The algorithm is _probably approximately correct_ (PAC) in the sense that it provides a calibration data-conditional guarantee at every risk and confidence level. Specifically, it controls the risk to a desired level irrespective of which calibration data is used to learn \(\) with a desired confidence \((0,1)\) as follows: \(\{_{01}()\} 1-\), where the probability is taken over the calibration set \(^{n}\) to learn the conformal set. In this paper, we leverage the PAC conformal set for a pseudo-labeling function such that the guarantee on the labeling quality provides the overall PAC guarantee in semi-supervised selective generator learning algorithm.

**Algorithm.** The PAC conformal set learning algorithm \(_{}:()^{*}\)[11; 20; 34] returns the conformal set parameter \(\), where \(\) is a finely-discretized \(_{ 0}\). Specifically, the algorithm returns \(=_{}~{}\) subject to \(U_{}(k_{};n,)\), where \(k_{}:=_{i=1}^{n}_{01}(,_{i},y_{i})\). Letting \(F(k;n,)\) be a cumulative distribution function of a binomial distribution with \(n\) trials and success probability \(\), \(U_{}(k;n,)\{~{}|~{}F(k;n, )\}\{1\}\) is an upper binomial tail bound that satisfies \(\{_{01}() U_{}(k_{};n, )\} 1-\), where \(\) is the desired confidence. Note that we similarly denote a lower binomial tail bound by \(L_{}\). If optimization in the algorithm \(_{}\) is infeasible, the algorithm returns \(=0\), a vacuous conformal set. Thus, the algorithm is PAC, and see Section A.1 for proof.

### Calibration

In classification, calibration aims to adjust the classifier's maximum likelihood response, or confidence, to be correct. We say the classifier response \(f:_{ 0}\) is _perfectly calibrated_ with respect to a distribution \(\) over \(\) and a classifier \(\) if \(\{=()~{}|~{}f(,( ))=t\}=t\) for all \(t\)[35; 36]. Calibration aims to find the classifier response such that it is perfectly calibrated asymptotically. In this paper, we make an interesting connection between calibration and selective generation. In particular, given the definition of the perfect calibration for a language scoring function \(f_{M}\), we formally provide a sufficient condition for a selective generator to control the FDR with respect to the textual entailment relation at _any_ desired risk level.

## 3 Problem: Selective Generation

Let \(\) be a question and \(\) be an answer, assuming that each question has a desired answer. Here, we assume \((,)^{}\), where \(^{}\) is a data generating process of question-answering pairs. Then, given a generator \(G:\), we consider a _selective generator_\(:\{\}\) which refuses to return \(G()\) if a selection function \((,G())\{0,1\}\) deems uncertain as follows:

\[()G()&( ,G())=1\\ &.\]

Our main goal is to learn a selective generator \(\) to control a generalized false discovery rate (FDR) with respect to a relation \(R\) as

\[_{R}()\{(G(),)  R~{}~{}()\}. \]

Here, the probability is taken over examples \((,,e,v)\), where \(e((G(),) R)\) is an additional label to be annotated due to unknown \(R\) and \(v\{0,1\}\) is a visibility flag of \(e\) for semi-supervised learning. For the data generation of \((,,e,v)\), we assume that a label \(e\) is observed with an unknown success probability of \(p_{v}\), independent of the generative process of \((,,e)\), _i.e.,_\((,,e,v)^{} \), where \(^{}\) is a distribution over \(\{0,1\}\) and \((p_{v})\). Note that the definition of \(e\), \(^{}\) varies by generator \(G\) even with the same data generating distribution of \((,)\). In this paper, we design a learning algorithm \(\) that returns a selective generator \(\) to control the generalized FDR with respect to \(R\) within a desired level \((0,1)\) with probability at least \(1-(0,1)\), _i.e.,_\(\{_{R}(())\}  1-\). Here, the probability is taken over a calibration set \(^{n}\). This guarantee is called a probably approximately correct (PAC) guarantee . Among selective generators that satisfies the PAC guarantee, we choose one that minimizes the ratio of IDK-answers with the highest _selection efficiency_. The main challenge is to find a sample and selection efficient PAC algorithm for any \(\) and \(\) along with designing a relation \(R\) for structured labels, as in question-answering. Frequently, we may not obtain a PAC algorithm for any \(\), so in this paper, we use a relaxed notion of _controllable_ instead of _correct_ if the algorithm provides minimum achievable risk beoyond a given \(\).

Semi-Supervised Learning for Controllable Selective-Generation

In this paper, we leverage the textual entailment as the evaluation metric in language generation to consider multiple valid answers in a principled way, and propose two selective generator learning algorithms which control FDR with respect to the textual entailment: \(^{}\) and \(^{}\).

### False Discovery Rate via Textual Entailment (FDR-E)

A textual entailment relation \(R_{E}\) is an ordered subset of \(\) where \((^{},) R_{E}\) if \(^{}\) entails \(\). In question-answering as an example, the generated answer \(G()\) is correct if the reference answer \(\) is a logical consequence of \(G()\). In other words, \(G()\) is valid if \(G() E_{}()\), where the true entailment set function \(E_{}: 2^{}\) is defined as follows: \(E_{}()\{^{}( ^{},) R_{E}\}\). Then, an FDR with respect to the entailment relation \(R_{E}\) (FDR-E) that we aim to control is as follows:

\[_{R_{E}}()\{G() E_{ }()()\},\]

where the probability is taken over labeled examples, _i.e.,_\((,,e)\). Here, the label \(e\) is specifically called an entailment label, _i.e.,_\(e G() E_{}()\). Then, for any \(G\), \(\), \(\), and \(\), the FDR-E can be decomposed as follows:

\[_{_{}}\{G() E_{ }()\}}_{()}=_{_{}}\{v=1\}}_{()}_{_{ }}\{e=0\}}_{()}+_{_{ }}\{v=0\}}_{()}_{_{ }}\{e=0\}}_{()}, \]

where \(_{_{}}\{\}\{ ()\}\). Note that as \((,,e)\) and \(v\) are independent, (A), (C), and (E) in (2) are of the same quantity, which is the target risk that we aim to find an upper bound.

### FDR-E Bound for Supervised Learning

We first propose the supervised learning algorithm \(^{}\) (Algorithm 8), a direct modification of  to language generation tasks. In particular, \(^{}\) is a supervised method in the sense that it solely exploits labeled examples \(_{E}\{(,,e)(,, e,v) v=1\}\) to learn a selective generator that controls the upper bound (C) in (2). Note that for supervised learning, we assume that (B) in (2) is always 1, so we only consider the the upper bound (C) via the binomial tail bound as .

### FDR-E Bound for Semi-Supervised Learning

As \(^{}\) requires human annotations for entailment labels and makes no use of abundant unlabeled examples \(_{U}\{(,)(,, e,v) v=0\}\), we further propose a novel semi-supervised learning algorithm \(^{}\) (Algorithm 5), which fully exploits both \(_{E}\) and \(_{U}\) while controlling the FDR-E in (2). In particular, we (1) estimate a true entailment set \(E_{}\) via conformal prediction with labeled examples \(_{E}\) and then (2) use the estimated entailment set \(\) to annotate pseudo-labels on \(_{U}\). Finally, we (3) use both labeled and pseudo-labeled examples to learn a selective generator. Interestingly, this heuristic-looking algorithm could be a rigorous algorithm that controls the FDR-E of a selective generator, which will be described in the following sections.

#### 4.3.1 FDR-E Decomposition

\(^{}\) leverages unlabeled examples by estimating an entailment set as a pseudo-labeling function. However, the estimation error introduces wrong pseudo-labels. Here, we consider a rigorous way to derive the FDR-E upper bound by controlling the estimation error of the pseudo-labeling function. In particular, two different types of estimation errors of an estimated entailment set \(\) are illustrated in Figure 2, _i.e.,_ a false negative entailment rate (FNER) and a false entailment rate (FER). This results in the following decomposition.

**Lemma 1**.: _(E) in (2) is decomposed as follows:_

\[_{_{}}\{e=0\}}_{(E)}= _{_{}}\{e=0,=1\}}_ {}-_{_{}}\{e=1,= 0\}}_{}+_{_{}} \{=0\}}_{}. \]Here, the first two terms are related to the entailment label estimation error and the last term is the approximate FDR-E using pseudo-labels. As three terms are inter-related, we choose to control the FER term to control (E) in (2) via conformal prediction in the following section.

#### 4.3.2 Pseudo-labeling via Conformalized Entailment Set Learning

\(^{}\) leverages the PAC conformal prediction for the entailment label estimation to control the mislabeling error. Specifically, we estimate the true entailment set function \(E_{}\) via an estimated entailment set \(\) using \(_{E}\), where we use the entailment scoring function \(f_{E}\) as a scoring function, _i.e.,_\(()\{^{} f_{E}( ^{},)_{E}\}\). Here, the corresponding loss \((,,,e)(e=0 G( )())\) is a monotonically non-increasing function with respect to \(_{E}\), so we can use the PAC conformal set learning algorithm. Given a desired risk \(_{E}\) and confidence \(_{E}\) level, the corresponding algorithm \(_{}\) (_i.e.,_ Algorithm 1) returns the estimated entailment set function \(\) which controls the _false entailment rate_ (FER) of pseudo-labeled examples \(_{}()_{_{}} \{e=0 G()()\}\) with the following PAC guarantee, where the probability is taken over training examples from \(_{}\).

\[\{_{}()_{E}\}  1-_{E}. \]

#### 4.3.3 FDR-E Bound

We then bound the FDR-E for semi-supervised learning, _i.e.,_ (E) in (2), via the PAC guarantee by the conformal set learning on \(_{E}\) and the binomial tail bound on \(_{E}\) and \(_{U}\). In particular, the FER is upper-bounded by \(_{E}\), the FNER is lower-bounded by the binomial tail bound using \(_{E}\), and NER is upper-bounded by the binomial tail bound using \(_{U}\). These bounds hold with high probability, and are therefore combined via a union bound, as in the following lemma. See Appendix G for a proof.

**Lemma 2**.: _Let \(}_{E}\{(,,e)_{E} ()\}\) and \(}_{U}\{(,)_{U} ()\}\). For any \(G\), \(\), \(\), and \(\), if \(_{}(}_{E})\) satisfies \(_{}_{E}}\{_{}() _{E}\} 1-^{}_{E}/2\), we have_

\[_{}\{e=0\}_{E}-L_{}(;| }_{E}|,^{}_{E}/2)+U_{}(;|}_{U}|,^{}_{S}) U_{} \]

_with probability at least \(1-^{}_{E}-^{}_{S}\), where the probability is taken over \(\). Here, \(_{(,,e)}_{E}}(e=1 G()())\) and \(_{(,)}_{U}}(G()())\)._

Notably, each of three bounds holds over a conditional distribution \(_{}\), but Lemma 2 relaxes this to an unconditional distribution \(\) for our final FDR-E guarantee.

**Optimizing the FDR-E Bound (5).** Lemma 2 introduces a hyper-parameter \(_{E}\), which controls a trade-off between the FER and other terms. To find a best trade-off, we optimize \(_{E}\) to minimize the upper bound (5) among \(Q\) candidates of \(_{E}\) via \(_{U_{}}\), described in Algorithm 3. This optimization algorithm can find a tighter FDR-E bound, as in the following lemma. See Appendix H for a proof.

**Lemma 3**.: _Let \(U_{}\) be as in (5) and \(\) be the \(Q\) candidates of \(_{E}\). Then, we have_

\[_{}\{e=0\} U_{}^{}_ {_{E}}U_{} \]

_with probability at least \(1-^{}_{E}/Q-^{}_{S}/Q\), where the probability is taken over \(\)._

Note that for semi-supervised learning, the upper bound of (B), (C), (D), and (E) in (2) should be provided. The upper bound of (E) is provided in (5), which we denote by \(U_{}\). The upper bound of (B), (C), and (D) are denoted by \(w_{},U_{}\), and \(w_{}\), respectively, each of which is computed by the binomial tail bound. See Algorithm 4 and the proof of Theorem 1 for details.

```
1:Input:\(\), \(\), \(\), \(^{}

score, _i.e.,_\(f_{M_{2}}(,G())_{k=1}^{K}f_{E}(}_{k},G())\), where \(}_{k}\) are generated answers with the same question \(\) but different random seeds. It is empirically shown that the self-consistency score properly quantifies uncertainty when a language model is uncertain of an answer . The importance of score calibration with respect to the true entailment relation is demonstrated in Lemma 4, which provides the sufficient condition for the selective generation algorithm using the single-threshold indicator function (Algorithm 5) to control the FDR-E at _any_ level. See Appendix J for a proof.

**Lemma 4**.: _If we have access to \(E_{}\) and \(f_{M}\) is perfectly calibrated with respect to \(E_{}\), the FDR-E is monotonically non-increasing in \(_{S}\)._

However, as  points out, calibrating the language scoring function remains an uneasy task, os it is still an active research area. Therefore, we propose a general class of selection functions, _neuro-selection functions_, which is the multiple-threshold indicator function using possibly learnable feature map \(:^{v}\) as follows: \((;,,)_{i=1}^{u}( ())_{i}+_{i} 0\), where \(^{u v}\) and \(^{u 1}\) are linear proejection and bias terms, respectively. In this paper, we only consider two specific sub-classes of neuro-selection functions, where the former reduces to learning the single-threshold selection function using a scoring function (Algorithm 5) and the latter reduces to learning the bi-threshold selection function using two scoring functions (Algorithm 6). Only the bias term \(\) is the learnable parameter for both algorithms, where the others set as hyperparameters. Specifically, \(=_{1}\), \(_{1}()=[f_{M}(,G())]\), and \(=-_{S}\) for Algorithm 5, while \(=_{2}\), \(_{2}()=[f_{M_{1}}(,G())\ f_{M_{2}}(,G())]^{T}\), and \(=-[_{S,1},_{S,2}]^{T}\) for Algorithm 6 if two promising scoring functions exist. Here, developing a selection function learning algorithm where \(\) and \(()\) are also fully learning parameters is left as future work. In the following section, we introduce our algorithm that chooses the optimal combination of scoring functions via neuro-selection functions.

### Semi-Supervised Selective Generator Learning Algorithm with Neuro-Selection

\(^{}\) is a semi-supervised learning algorithm for certified selective generation, which fully exploits unlabeled data in learning a selection function via certified pseudo-labeling and uses a neuro-selection function for choosing an optimal combination of scoring functions. In particular, \(^{}\) solves the following optimization problem over selective generators \(\) such that \(\) closely satisfies the equality in the constraint, as described in Algorithm 7:

\[_{^{}}:_{} w_{}U_{}+w_{}U_{}^{ }_{S}, \]

Here, \(\) has a selection function \((;_{2}(),(),)\), where \(\{^{T},^{T},^{T}\}\) and \(^{2}_{ 0}\). Note that \(^{}\) returns an additional term \(\), which is the FDR-E bound given the selective generator \(\) (_i.e.,_ Algorithm 4) and informs the infeasibility of the optimization. The proposed Algorithm 7 satisfies the following controllability guarantee. See Appendix I for a proof.

**Theorem 1**.: \(_{^{}}\) _satisfies the following controllable guarantee on the FDR-E, i.e.,_

\[\{\{G() E_{}()()}\} \} 1-, \]

where the inner and outer probabilities are taken over \((,,e,v)\) and \(^{n}\), respectively, and \((,)_{^{}}( )\). Here, \(_{W}+_{S}+_{E}\) is a desired confidence level, where \(_{W}\) is for the upper bounds on \(w_{}\) and \(w_{}\), \(_{S}\) is for (C) in (2) and the NER, and \(_{E}\) is for the FER and FNER.

Here, \(_{^{}}\) is _controllable_ in the sense that it upper-bounds the FDR-E of a learned selective generator to a desired level \(_{S}\) or at least to a minimum achievable level \(\) with confidence \(\).

## 5 Experiments

We demonstrate the efficacy of our methods in controlling the FDR-E on pre-trained GLMs under various setups. We use two GLMs, GPT-3.5-Turbo and Alpaca-7B, alongside the Natural Questions (NQ) dataset to annotate entailment labels for question-answer pairs. Details on model configurations, datasets, and additional experimental results can be found in Section A.3 and Appendix K.

**Methods.** We consider two heuristic semi-supervised algorithms, \(^{}_{}\) and \(^{}_{}\) (Algorithm 9) and an unsupervised learning algorithm \(_{}\) (Algorithm 10) as baselines to show the efficacy of our certified semi-supervised method \(^{}\) (Algorithm 7). \(^{}_{}\) and \(^{}_{}\) exploit the unlabeled data by pseudo-labeling textual entailment based on a threshold as a hyperparameter without any guarantee on mislabeling error. \(^{}_{}\) additionally filters out 

[MISSING_PAGE_FAIL:9]

**Why Semi-Supervised Learning.** We observe that our semi-supervised learning for selective generation is effective. In particular, the fully supervised methods in Table 3 achieves the efficiency of \(0.7535\) and \(0.2959\) for GPT-3.5 and Alpaca-7B, respectively, with the entire labeled samples \(_{E}\) (when they satisfy a \(\)-FDR-E guarantee). Compared to these, the proposed semi-supervised method \(^{}\) Table 1 achieves the efficiency of \(0.7334\) and \(0.3173\) for GPT-3.5 and Alpaca-7B, respectively, by only using \(75\%\) of labeled examples. Additionally, we observe that more unlabeled samples are beneficial to achieving better efficiency as can be seen in Figure 3. This implies that if we can approximate the entailment set well and the size of \(_{U}\) is enough, we can enjoy our certified pseudo-entailment labeling by the semi-supervised learning even with small \(_{E}\).

**Why Neuro-Selection.** It is hard to manually find a well calibrated scoring function. But, given multiple scoring functions, a neuro-selection function learns to choose right scoring functions that achieves a desired FDR-E and maximizes selection efficiency. This is empiricially validated in Table 1, as \(^{}\) is better on average efficiency.

## 6 Conclusion

We propose selective generation, a generalized version of  for GLMs to handle semantic correctness between two structured answers. To this end, we leverage logical entailment to define a new entailment-based FDR (FDR-E) metric. As obtaining entailment labels are expensive, we propose novel semi-supervised learning for selective generation by using entailment sets as a pseudo-labeling function. To enhance the low selective efficiency due to inefficient scoring functions, we propose neuro-selection functions for effectively optimizing scoring functions for better selective efficiency and the FDR-E guarantee. The efficacy of our proposed algorithms \(^{}\) and \(^{}\) are theoretically and empirically justified.

**Limitations.** Our algorithm needs the i.i.d. assumption for a correctness guarantee, which can be violated in practical situations. We leverage expensive entailment labels, where the labels are obtained by considering logical entailment between a true answer and a generated answer. This limitation is partially mitigated by proposing the semi-supervised method to propagate entailment-labeled samples to samples without entailment labels. Also, our results show the empirical FDR-E is not much closely bounded under \(\), especially on Alpaca7B, which implies that we may need a tighter FDR-E bound.

Figure 3: Efficiency results over different numbers of unlabeled samples. (a) and (b) use \(^{}_{}\) with \(f_{M_{2}}\) score. (c) and (d) use \(^{}\) that has neuro-selection function. Both methods show increasing performance as more unlabeled samples \(_{U}\) are used. For each experiment, the values were measured after averaging 10 random splits and an error bar means standard deviation.