# A Theory of Optimistically Universal Online Learnability for General Concept Classes

Steve Hanneke

Department of Computer Science

Purdue University

West Lafayette, IN 47907

steve.hanneke@gmail.com

&Hongao Wang

Department of Computer Science

Purdue University

West Lafayette, IN 47907

wang5270@purdue.edu

###### Abstract

We provide a full characterization of the concept classes that are optimistically universally online learnable with \(\{0,1\}\) labels. The notion of optimistically universal online learning was defined in  in order to understand learnability under minimal assumptions. In this paper, following the philosophy behind that work, we investigate two questions, namely, for every concept class: (1) What are the minimal assumptions on the data process admitting online learnability? (2) Is there a learning algorithm which succeeds under every data process satisfying the minimal assumptions? Such an algorithm is said to be optimistically universal for the given concept class. We resolve both of these questions for all concept classes, and moreover, as part of our solution we design general learning algorithms for each case. Finally, we extend these algorithms and results to the agnostic case, showing an equivalence between the minimal assumptions on the data process for learnability in the agnostic and realizable cases, for every concept class, as well as the equivalence of optimistically universal learnability.

## 1 Introduction

Just as computability is a core question in computation theory, learnability is now a core question in learning theory. Intuitively, learnability is trying to ask whether we can predict the future correctly with high probability by observing enough examples. In order to describe this intuition formally, we need to define learning models, such as, Probably Approximately Correct (PAC) learning  and Valiant , online learning  and query learning . In this paper, we focus on a variant of online learning: online learning under data processes. In this setting, the learning is sequential: in round \(t\), an instance \(X_{t}\) is given to the algorithm, and then the algorithm makes the prediction, \(_{t}\), based on the history \((X_{ t-1},Y_{ t-1})\) and the input \(X_{t}\), i.e., \(_{t}=f_{t}(X_{ t-1},Y_{ t-1},X_{t})\). Next, the target value \(Y_{t}\) will be revealed to the learner such that it can be used to inform future predictions. We model this sequence as a general _stochastic process_\((,)=\{(X_{t},Y_{t})\}_{t}\) (possibly with dependencies across times \(t\)). We say that the algorithm is strongly consistent under \((,)\) if the long-run average error is guaranteed to be low, i.e., \(_{t=1}^{n}[_{t} Y_{t}] 0\) almost surely, when \(n\).

In our setting, any theory of learning must be expressed based on the properties of, or restriction on, the data process, as the mistake bound is based on the data process. Thus, following an approach found in much of the learning theory literature, such as the PAC model of Valiant  and Vapnik and Chervonenkis  and the online learning model of Littlestone , we introduce the restriction by an additional component, concept class \(^{}\). The role of the concept class is to restrict the processes we need to face, such that they all are realizable under that concept class.

If there is a target function \(h^{*}\), such that \(Y_{t}=h^{*}(X_{t})\) for every \(t\), we say the data process \((,)\) is realizable (though our formal definition below is slightly more general). For a given \(\), if a learning rule is strongly consistent under \((,)\) for _every_\(\) such that \((,)\) is realizable, we say it is _universally consistent_ under \(\) in the realizable case.

It is known that we cannot get the low average error guarantee for all concept classes and data processes (Hanneke, 2021). Thus, we should make several restrictions on either the data process, the concept class, or a mixture of both. All three types of restrictions have been investigated: Littlestone (1988); Ben-David et al. (2009) studied online learning with unrestricted data processes but restricted concept classes. Haussler et al. (1994); Ryabko (2006) researched the online learning problem with a mix of both restrictions. There are also substantial amount of papers investigating online learnability with all measurable functions but restricted data processes. Most of these specifically consider the case of i.i.d. processes, such as Stone (1977); Devroye et al. (1996), though this has also been generalized to general stationary ergodic processes (Morvai et al., 1996; Gyorfi et al., 1999) or processes with certain convergence properties enabling laws of large numbers (Morvai et al., 1999; Steinwart et al., 2009).

More recently, a general question has been studied: In the case of \(\) equals the set of all measurable functions, is there a learning rule guaranteed to be universally consistent given only the assumption on \(\) that universally consistent learning is possible under \(\)? The assumption that universal consistency is possible under \(\) is referred to as the "optimist's assumption" (Hanneke, 2021), and for this reason, learning rules which are universally consistent for all \(\) satisfying the optimist's assumption are said to be _optimistically universally consistent_. There is a series of works focusing on this question, starting from Hanneke (2021) and continuing with Blanchard and Cosson (2022); Blanchard (2022); Blanchard et al. (2022). They tackle this question by first characterizing the minimal assumptions on the data process admitting universally consistent learning and then proposing an online learning algorithm that is universally consistent for all data processes satisfying that assumption. However, their works all focus on the situation with no restrictions on concepts in the concept class (i.e., \(\) as all measurable functions). Thus, a natural question arises: For which concept classes do there exist optimistically universal learning rules?

In this paper, we investigate the question mentioned above when the output is binary, i.e. \(\{0,1\}\). We handle this problem by first figuring out the minimal assumptions on the data process admitting consistent online learning as well. Thus, our results answered that question in the following aspects:

* For which concept classes is optimistically universally consistent learning possible?
* What are the sufficient and necessary conditions for processes to admit universally consistent online learning for a given concept class \(\)?
* For which concept classes is it the case that _all_ processes \(\) admit universally consistent online learning?

We first answer these questions in the realizable case. Surprisingly, the answers turn out to be intimately related to combinatorial structures arising in the work of Bousquet et al. (2021) on universal learning rates. This suggests a potential connection between the universal consistency of online learning and universal learning rates, which is of independent interest. We also extend our learning algorithms for the realizable case to the agnostic setting, where the requirement of low average loss is replaced by that of having sublinear regret. Interestingly, our answers to the above questions remain unchanged in the agnostic case, establishing an equivalence between agnostic and realizable learning in this setting.

In this paper, we first provide some interesting examples in section 3. Then section 4 investigates question three and question one for those classes and section 5 answers question two and question one for remaining classes. Finally, in section 6, we extend our algorithm to the agnostic case.

### More Related Work

Starting from Littlestone's ground-breaking work (Littlestone, 1988), online learning is becoming more and more important. In this paper, Littlestone (1988) introduces a combinatorial parameter of the concept class, known as Littlestone dimension, to characterize the online learnable concept classes in the realizable case. After that, Ben-David et al. (2009) figure out Littlestone dimension is still the property to characterize online learnability in the agnostic setting. They extend an onlinelearning algorithm for the realizable case to such an algorithm for the agnostic case using the weighted majority algorithm from Littlestone and Warmuth (1994). This line of work makes no assumption on the data process and investigates how restrictions on the concept affect the learnability of the problem. There are two other categories of assumptions also investigated in history: one is to make assumptions on both the data process and the concept, and the other is to make assumptions on the data process but not the concept. Those two categories are discussed in detail subsequently.

First, the works investigating the question of learnability with restrictions on both the data process and the concept make a variety of assumptions. For example, Haussler et al. (1994) investigate how the restrictions on the concept will affect learnability given that the data process is i.i.d. This problem is more similar to a streamlined version of PAC learning and they show that there is a logarithmic mistake bound with the assumption that the data process is i.i.d. and the concept class has finite VC dimension. Adams and Nobel (2010) reveal that all stationary ergodic sequences will uniformly converge under the concept class with finite VC dimension. However, they cannot show the convergence rate of that learning algorithm. Many other works focus on revealing the rate with slightly stronger assumptions on the sequences, such as, (Yu, 1994; Karandikar and Vidyasagar, 2002).

Another line of works focuses on the question of learnability with restrictions on the process instead of the concept, starting from the theory of universally consistent predictors under i.i.d sequences. In particular, there exists an online learning rule, such that for any i.i.d. sequence \((,)\), and every measurable function \(f^{*}\), the long-run average loss is \(0\) almost surely, such as, (Stone, 1977; Devroye et al., 1996; Hanneke et al., 2021). In the meanwhile, people are also interested in the consistency under non-i.i.d. processes; Gyorfi et al. (1999); Morvai et al. (1996) reveal that there are universally consistent online learning rules under general stationary ergodic processes. The paper of Morvai et al. (1999) and the paper of Steinwart et al. (2009) show universal consistency under some classes of processes satisfying laws of large numbers.

More recently, the work of Hanneke (2021) investigates whether there is a consistent learning rule given only the assumptions on \(\) that universally consistent learning is possible. This work generalizes the assumptions on \(\) made by the previous works on universal consistency. The assumption that universally consistent learning is possible is known as the "optimist's assumption", so the consistency under that assumption is called _optimistically universal_ consistency. Hanneke (2021) studies three different learning models: inductive, self-adaptive, and online, and proves that there is an optimistically universal self-adaptive learning rule and no optimistically universal inductive learning rule. After this beginning, the works of Blanchard and Cosson (2022); Blanchard et al. (2022); Blanchard (2022) show that optimistically universal online learning is possible and the processes that admit strongly universal online learning satisfy the condition called \(_{2}\) (see condition C for reference). This problem is also investigated under different models, such as, in contextual bandit setting Blanchard et al. (2022, 2023) and general noisy labels Blanchard and Jaillet (2023).

## 2 Preliminaries and Main Results

In this section, we provide formal definitions and model settings and briefly list the main results of this paper without proof. For brevity, we provide the high-level proof sketch in the subsequent sections and proof details are in the appendices.

Model SettingWe formally provide the learning model here. Let \((,)\) be a measurable space, in which \(\) is assumed to be non-empty and \(\) is a Borel \(\)-algebra generated by a separable metrizable topology \(\). We also define a space \(=\{0,1\}\) called _label space_. Here we focus on learning under the \(0\)-\(1\) loss: that is, \((y,y^{})[y y^{}]\) defined on \(\), where \([]\) is the indicator function. A stochastic process \(=\{X_{t}\}_{t}\) is a sequence of \(\)-valued random variables. A stochastic process \(=\{Y_{t}\}_{t}\) is a sequence of \(\{0,1\}\)-valued random variable. The concept class \(\), which is a non-empty set of measurable functions \(h:\).1

The online learning rule is a sequence of measurable functions: \(f_{t}:^{t-1}^{t-1} \), where \(t\) is a non-negative integer. For convenience, we also define \(_{t-1}=f_{t}(X_{<t},Y_{<t})\), here \((X_{<t},Y_{<t})=\{(X_{i},Y_{i})\}_{i<t}\) is the history before round \(t\).

There are two ways to define the realizable case: The most common one is that there exists \(h^{*}\) such that \(Y_{t}=h^{*}(X_{t})\). The other is the definition 1 on the realizable data process, which comes from the universal learning setting. These two definitions are equivalent in the uniform PAC learning with i.i.d. samples. However, they are different when talking about universal learning. Thus, we follow the definition from the universal learning setting.

**Definition 1**.: _For every concept class \(\), we can define the following set of processes \(R()\):_

\[R():=\{(,)=\{(X_{i},Y_{i})\}_{ i}:1, n<,\{(X_{i},Y_{i})\}_{i n}\}.\]

In the same way, the set of realizable label processes:

**Definition 2**.: _For every concept class \(\) and data process \(\), define a set \(R(,)\) of label processes:_

\[R(,):=\{=\{Y_{i}\}_{i }:(,) R()fY_{i}=f(X_{i})\}.\]

In other words, \((,)\) are label processes \(=f()\) s.t. \((,f())()\). Importantly, while every \(f\) satisfies \(f()(,)\), there can exist \(f\) for which this is also true, due to \(()\) only requiring realizable _prefixes_ (thus, in a sense, \((,)\) represents label sequences by functions in a _closure_ of \(\) defined by \(\)).2

At first, we define the universal consistency under \(\) and \(\) in the realizable case. An online learning rule is universally consistent under \(\) and \(\) if its long-run average loss approaches \(0\) almost surely when the number of rounds \(n\) goes to infinity for all realizable label processes. Formally, we have the following definition:

**Definition 3**.: _An online learning rule is strongly universally consistent under \(\) and \(\) for the realizable case, if for every\( R(,)\), \(_{n}_{t=1}^{n}[Y_{t} _{t-1}(X_{t})]=0\) a.s._

We also define the universal consistency under \(\) and \(\) for the agnostic case. In that definition, we release the restrictions that \((,)\), instead the label process \(\) can be set in any possible way, even dependent on the history of the algorithm's predictions. Thus, the average loss may be linear and inappropriate for defining consistency. Therefore, we compare the performance of our algorithm with the performance of the best possible \(^{*}(,)\), which is usually referred to as _regret_. We say an online algorithm is universally consistent under \(\) and \(\) for the agnostic case if its long-run average regret is low for every label process. Formally,

**Definition 4**.: _An online learning rule is strongly universally consistent under \(\) and \(\) for the agnostic case, if for every\(^{*} R(,)\) and for every\(\), \(_{n}_{t=1}^{n}([Y_{t}_{t-1}(X_{t})]-[Y_{t} Y_{t}^{*}]) 0\) a.s._

To describe the assumption that universal consistency is possible under the data process \(\) and the concept class \(\), we need to define the process admitting universal online learning as follows:

**Definition 5**.: _We say a process \(\) admits strongly universal online learning (or just universal online learning for convenience) if there exists an online learning rule that is strongly universally consistent under \(\) and \(\)._

If the online learning rule is universally consistent under every process that admits universal online learning, we call it **optimistically universal** under the concept class. If there is an optimistically universal learning algorithm under that concept class, we say that concept class is optimistically universally online learnable. The formal definition is provided below:

**Definition 6**.: _An online learning rule is optimistically universal under concept class \(\) if it is strongly universally consistent under every process \(\) that admits strongly universally consistent online learning under concept class \(\)._

_If there is an online learning rule that is optimistically universal under concept class \(\), we say \(\) is optimistically universally online learnable._Next, we define the combinatorial structures we use to characterize the concept class that makes all processes admit universal online learning and is optimistically universally online learnable when all processes admit strongly universally consistent online learning:

**Definition 7** (Littlestone tree Bousquet et al. (2021)).: _A Littlestone Tree for \(\) is a complete binary tree of depth \(d\) whose internal nodes are labeled by \(\), and whose two edges connecting a node to its children are labeled \(0\) and \(1\), such that every finite path emanating from the root is consistent with a concept \(h\). We say that \(\) has **an infinite Littlestone tree** if it has a Littlestone tree of depth \(d=\)._

**Definition 8** (VCL Tree Bousquet et al. (2021)).: _A **VCL Tree** for \(\) of depth \(d\) is a collection_

\[\{x_{u}^{k+1}:0 k<d,u\{0,1\}^{1}\{0,1\}^{2} \{0,1\}^{k}\}\]

_such that for every \(n<d\) and \(y\{0,1\}^{1}\{0,1\}^{2}\{0,1\}^{n+1}\), there exists a concept \(h\) so that \(h(x^{i}_{y k})=y^{i}_{k+1}\) for all \(0 i k\) and \(0 k n\), where we denote_

\[y_{ k}=(y^{0}_{1},(y^{0}_{2},y^{1}_{2}),,(y^{0}_{k},,y^{k-1}_{k} )),x_{y_{ k}}=(x^{0}_{y_{ k}},,x^{k}_{y_{ k}})\]

_We say that \(\) has **an infinite VCL tree** if it has a VCL tree of depth \(d=\)._

The characterization is formally stated in the following two theorems:

**Theorem 9**.: _If and only if a concept class \(\) has no infinite VCL tree, any process admits strongly universally consistent online learning under \(\)._

**Theorem 10**.: _If and only if a concept class \(\) has no infinite Littlestone tree, any process admits strongly universally consistent online learning under \(\), and the concept class \(\) is optimistically universally online learnable._

According to theorem 9, we know that for those concept classes with an infinite VCL tree, there exist some processes that do not admit universal online learning. Thus, we need to figure out the sufficient and necessary conditions that the processes required to admit universal online learning.

First, we define the experts as algorithms that generate predictions only based on the input \(X_{t}\). Then we define the following condition (which is a property of a data process) and state the main theorem formally:

**Condition A**.: _For a given concept class \(\), there exists a countable set of experts \(E=\{e_{1},e_{2},\}\), such that \(^{*} R(,)\), \( i_{n}\), with \( i_{n}=o(n)\), such that:_

\[[_{n}_{e_{i}:i i_{n}}_{t=1}^{n}[e_{i}(X_{t}) Y^{*}_{t}]]=0 \]

**Theorem 11**.: _A process \(\) admits strongly universally consistent online learning under concept class \(\) with infinite VCL tree if and only if it satisfies condition A._

Next, the sufficient and necessary conditions (on the concept class) for optimistically universal online learning:

**Condition B**.: _There exists a countable set of experts \(E=\{e_{1},e_{2},\}\), such that for any \(\) admits universal online learning, and any \(^{*} R(,)\), there exists \(i_{n}\), with \( i_{n}=o(n)\), such that:_

\[[_{n}_{e_{i}:i i_{n}}_{t=1}^{n}[e_{i}(X_{t}) Y^{*}_{t}]]=0 \]

Notice that these two conditions (condition A and B) only have one major difference: whether the countable set of experts depends on the process \(\).

**Theorem 12**.: _A concept class \(\) with infinite VCL tree is optimistically universally online learnable if and only if it satisfies condition B._

We also extend the algorithms for realizable cases to an algorithm for agnostic cases and show that the same characterization works for agnostic cases.

Examples

In this section, we provide some interesting examples to help the reader get a sense of what these conditions are. We first provide an example of the concept class that is universally online learnable under all processes but not optimistically universally online learnable.

**Example 1**.: _We have the instance space \(=\) and \(=\{0,1\}\), a binary output. The concept class \(\) is all of the threshold functions. In other words, \(_{}=\{h_{a}:h_{a}(x)=[x a] |a.\}\). This concept class has no infinite VCL tree, as there is no \((x_{1},x_{2})\) such that \(_{}\) shatters all possible results. Thus, all processes admit strongly universally consistent online learning under \(_{}\). However, it has an infinite Littlestone tree. Thus, for any learning algorithm, there exists a process that is not learnable by that algorithm. So it is not optimistically universally online learnable._

Referring to that line of optimistically universal online learning papers, we know that the concept class of all measurable functions is optimistically universally online learnable. The sufficient and necessary condition for processes to admit universal online learning under all measurable functions is the condition \(_{2}\) (see below). In the meanwhile, our conditions: A and B vanish to \(_{2}\) when the concept class \(\) becomes the class of all measurable functions.

**Condition C** (\(_{2}\) in Hanneke (2021)).: _For every sequence \(\{A_{k}\}_{k=1}^{}\) of disjoint elements of \(\),_

\[|\{k:X_{1:T} A_{k}\}|=o(T)\ a.s.\]

The following example shows that whether a concept class is optimistically universally online learnable is neither sufficient nor necessary to determine whether its subset is optimistically universally online learnable or not. Whether a concept class is optimistically universally online learnable will be sufficient and necessary to determine whether its subset is optimistically universally online learnable, if and only if the processes that admit universal online learning are the same under those two concept classes.

**Example 2**.: _We have the data which is sampled from input space \(=_{1}_{2}\) and here \(_{1}\) and \(_{2}\) are disjoint. For example, \(_{1}=^{+}\) and \(_{2}=^{+}\). Then we can define the concept class: \(_{1}\) is the set of all threshold functions on \(_{1}\) which are \(0\) on \(_{2}\), and \(_{2}\) is a set of all functions on \(_{2}\) which are constant on \(_{1}\). Then we can consider the following scenarios:_

1. \(=_{2}\)_: It is optimistically universally online learnable. The processes that admit universal online learning will satisfy_ \(_{2}\) _if we replace all the_ \(X_{t}_{1}\) _as dummy points._
2. \(=_{1}_{2}\)_: It is not optimistically universally online learnable, as all processes supported on_ \(_{1}\) _admit universal online learning under_ \(\)_. However, for every learning strategy, there exists at least one process on_ \(_{1}\) _forcing that strategy to make linear mistakes. (Due to theorem_ 9 _and theorem_ 10_)_
3. \(\) _are all measurable functions on_ \(\)_. This is also optimistically universally online learnable._

## 4 Sufficient and Necessary Condition that ALL Processes Admit Universal Online Learning

In this section, we answer the question: _What restrictions on concept classes make ALL processes admit universal online learning under \(\)?_ The answer is formally stated as Theorem 9. We show the sufficiency by providing a universal online learning rule (depending on \(\)) under every process \(\) and \(\) with no infinite VCL tree.

First, we define the VCL game along with the VCL tree. In this game, there are two players: the learner, \(P_{L}\), and the adversary, \(P_{A}\) and \(U_{0}=\). Then in each round \(k\):

* \(P_{A}\) choose the point \(X_{(k)}=(X_{k,1},,X_{k,k})^{k}\).
* \(P_{L}\) choose the prediction \(g_{U_{k-1}}((X_{k,1},,X_{k,k}))\{0,1\}^{k}\).
* Update \(U_{k}=U_{k-1}\{X_{(k)},g_{U_{k-1}}\}\).
* \(P_{L}\) wins the game in round \(k\) if \(_{U_{k}}=\).

Here \(_{U_{k}}=\{h: i,h(X_{(i)})=g_{i}(X_{(i)})\}\), which is the subset of \(\) that is consistent on \((X_{(i)},g_{i}(X_{(i)}))\) for all \(i k\).

A _strategy_ is a way of playing that can be fully determined by the foregoing plays. And a _winning strategy_ is a strategy that necessarily causes the player to win no matter what action one's opponent takes. We have the following lemma from Bousquet et al. (2021).

**Lemma 13** (Bousquet et al. (2021)**lemma 5.2).: _If \(\) has no infinite VCL tree, then there is a universally measurable winning strategy \(g\) for \(P_{L}\) in the game._

Notice that the winning strategy \(g\) is completely decided by \(U\), we use \(g_{U}\) as the winning strategy induced by the set \(U\). We may use this winning strategy \(g_{U}\) to design an online learning algorithm 1. This algorithm is a combination of the algorithm in the work of Bousquet et al. (2021) and the algorithm inspired by the learning algorithm for partial concept in the work of Alon et al. (2021).

In order to describe the algorithm, we first provide the definitions of partial concepts. A partial concept class \(\{0,1,*\}^{}\) is a set of partial function defined on \(\), where \(h(x)=*\) if and only if \(h\) is undefined on \(x\). And for a set \(X^{}\), \(X^{}\) is shattered if every binary pattern \(y\{0,1\}^{^{}}\) is realized by some \(h\). In this algorithm, we have \(w(^{},X_{ T})=|\{S:S\{x_{i}\}_{i T}S^{}\}|\), which is the number of the subsequences of the sequence \(X_{ T}\) that can be shattered by the partial concept class \(^{}\). \(^{g_{U}}=\{h: X_{1},X_{2},,X_{k},(h(X_{1} ),h(X_{2}),,h(X_{k})) g_{U}(X_{1},X_{2},,X_{k})\}\) is the partial concept class induced by \(g_{U}\), which contains the concepts that are not consistent with \(g_{U}\) at more than \(k-1\) data points, if \(U=\{(X_{(i)},g_{i}(X_{(i)}))\}_{i k-1}\). We define \(^{g_{U}}_{\{(X_{i},Y_{i})\}_{i t}}=\{h^{g_{U}}:  i t,h(X_{i})=Y_{i}\}\). We also define \(X_{[t,t^{}]}=\{X_{i}\}_{t t^{}}\) and \(t(m)=\).

```
\(k=1\), \(U=\{\}\), \(t^{} 0\). for\(t=1,2,3,\)do if\( j_{1},j_{2},,j_{k}<t\) such that \(g_{U}(X_{j_{1}},,X_{j_{k}})=(Y_{j_{1}},,Y_{j_{k}})\)then  Advance the game: \(|U U\{((X_{j_{1}},,X_{j_{k}}),(Y_{j_{1}},,Y_{j_ {k}}))\}.\) \(k k+1\). \(L\). \(m 1\). \(t^{} t-1\). end  Predict \(_{t}=*{argmax}_{y}[w(^{g_{U}}_{L(X_ {t},1-y)},X_{[t,t(m)+t^{}]})w(^{g_{U}}_{L},X_ {[t,t(m)+t^{}]})X_{ t}]\) if\(Y_{t}_{t}\)then \(L L\{(X_{t},Y_{t})\}\). end if if\(t+t^{}\).then \(m m+1\). end
```

**Algorithm 1**Learning algorithm from winning strategy

The following lemma from the work of Bousquet et al. (2021) holds:

**Lemma 14** (Bousquet et al. (2021)).: _For any process \(\{(X_{i},Y_{i})_{i}\} R()\), there exists \(t_{0}\), such that for all \(t t_{0}\), algorithm 1 will not update \(k\) and \(U\) and for all \(j_{1},j_{2},,j_{k}\), the winning strategy \(g_{U}\) satisfies_

\[g_{U}(X_{j_{1}},,X_{j_{k}})(Y_{j_{1}},,Y_{j_{k}}).\]

Proof.: By the definition of the winning strategy, it leads to a winning condition for the player \(P_{L}\). By the definition of \(P_{L}\)'s winning condition, we know that there exists a \(k\) such that \(_{X_{1},g_{1},,X_{k},g_{k}}=\), which means for all \(j_{1},j_{2},,j_{k}\), \(g_{U}(X_{j_{1}},,X_{j_{k}})(Y_{j_{1}},,Y_{j_{k}})\). That finishes the proof.

This lemma shows that if the concept class \(\) has no infinite VCL tree, for a sufficiently large \(t_{0}\), the VCL game will stop advancing after round \(t_{0}\). Once the game stops advancing, we are effectively just bounding the number of mistakes by a predictor based on a partial concept class of finite VC dimension. This result is interesting in its own right, we extract this portion of the algorithm into a separate subroutine, which is stated as Algorithm 2 in AppendixA.1, for which we prove the following result.

**Lemma 15**.: _For any process \(\) and \(\) be a partial concept class on \(\) with \(()=d<\). The subroutine (Algorithm 2 in AppendixA.1) only makes \(o(T)\) mistakes almost surely as \(T\)._

For brevity, we put the proof of this lemma in the appendix. The intuition behind the proof is that every mistake decreases the weight by at least half with more than half probability, so the number of mistakes is \(o(T)\).

Combining the lemmas above, for a concept class \(\) with no infinite VCL tree, for any realizable sequence, Algorithm 1 satisfies \(_{n}_{t=1}^{n}[Y_{t}_ {t-1}(X_{t})]=0\) a.s. Because the winning strategy only updates finite times, the long-run average number of mistakes is dominated by the number of mistakes made by the subroutine, which is \(o(n)\).

To prove the necessity, we show that for every concept class \(\) with an infinite VCL tree, there exists at least one process that does not admit universal online learning under \(\). Formally,

**Theorem 16**.: _For every concept class \(\) with infinite VCL tree, there exists a process \(\), such that \(\) does not admit universal consistent online learning._

We need the following definition and results from Bousquet et al. (2023) to define the sequence.

**Notation 17** (Bousquet et al. (2023)).: _For any \((\{0,1\})^{*}\), let \(()\) denote the index of \(\) in the lexicographic ordering of \((\{0,1\})^{*}\)._

**Definition 18** (Bousquet et al. (2023)).: _Let \(\) be a set and \(\{0,1\}^{}\) be a hypothesis class, and let_

\[T=\{x_{}:(\{0,1\})^{*}\}\]

_be an infinite VCL tree that is shattered by \(\). This implies the existence of a collection_

\[_{T}=\{h_{}:(\{0,1\})^{*}\}\]

_of consistent functions._

_We say such a collection is_ **indifferent** _if for every \(,,(\{0,1\})^{*}\), if \(()<()\), and \(\) is a descendant of \(\) in the tree \(T\), then \(h_{}(x_{})=h_{}(x_{})\). In other words, the functions for all the descendants of a node that appears after \(\) agree on \(\)._

_We say that \(T\) is_ **indifferent** _if it has a set \(_{T}\) of consistent functions that are indifferent._

**Theorem 19** (Bousquet et al. (2023)).: _Let \(\) be a set and \(\{0,1\}^{}\) be a hypothesis class, and let \(T\) be an infinite VCL tree that is shattered by \(\). Then there exists an infinite VCL tree \(T^{}\) that is shattered by \(\) that is indifferent._

Here is the proof sketch of Theorem 16

Proof Sketch.: First, we can modify the indifferent infinite VCL tree such that it has the property that the number of elements contained by the \(k\)-th node in the Breadth-First-Search (BFS) order is \(2^{k-1}\). The data process we are choosing is all the data come in the lexical order in each node and the BFS order among different nodes. Then we take a random walk on this tree to choose the true label for each instance. The instances in the node visited by the random walk will be labeled by the label on the edge adjacent to it in the path. The instances in the node that is off-branch will be labeled by the label decided by its descendants. (We can do this as the tree is indifferent.) Thus, when reaching a node on the path, no matter what the algorithm predicts, it makes mistakes with probability \(\). Thus, it makes a quarter mistake in expectation. Then by Fatou's lemma, for each learning algorithm, we get a realizable process such that the algorithm does not make a sublinear loss almost surely. 

We finish the proof of Theorem 9 here. We then focus on the existence of the optimistically universal online learner when all processes admit universal online learning.

### Optimistically Universal Online Learning Rule

In this part, we show that the condition whether \(\) has an infinite Littlestone tree is the sufficient and necessary condition for the existence of an optimistically universal online learning rule, when all processes admit universal online learning. This is formally stated as theorem 10. The sufficiency part of theorem 10 is proved in Bousquet et al. (2021) as the following lemma:

**Lemma 20** (Bousquet et al. (2021) Theorem 3.1, the first bullet).: _If \(\) does not have an infinite Littestone tree, then there is a strategy for the learner that makes only finitely many mistakes against any adversary._

Notice that the online learning algorithm derived from the winning strategy of the learner only makes finite mistakes against any adversary, so for every realizable data process \((,)\), this online learning algorithm also only makes finite mistakes, which means the long-run average mistake bound goes to \(0\). Thus, this is an optimistically universal online learning rule, and the concept class \(\) which does not have an infinite Littlestone tree is optimistically universally online learnable.

The necessity is restated as the following theorem:

**Theorem 21**.: _For any concept class \(\) with an infinite Littlestone tree, for any online learning algorithm \(\), there exists a process \(\) that makes \(\) have an average loss greater than a half with non-zero probability._

_Proof Sketch._ We can take a random walk on the infinite Littlestone tree to generate the target function. Thus, no matter what the algorithm predicts, it makes a mistake with a probability of more than half. Then we can use Fatou's lemma to get a lower bound of the expected average loss of the learning algorithm among all random processes and that means for every algorithm there exists a process that makes its average loss more than a half with probability more than zero. 

## 5 Concept Classes with an Infinite VCL Tree

In this section, we discuss the necessary and sufficient conditions for a process to admit universal online learning under the concept class \(\) with an infinite VCL tree. Theorem 11 states the answer formally. To prove this theorem, we first prove sufficiency (Lemma 22) and then necessity (Lemma 23).

**Lemma 22**.: _If a process \(\) satisfies condition A, it admits universally consistent online learning under concept class \(\)._

_Proof Sketch._ To prove this lemma, we use the weighted majority algorithm with non-uniform initial weights on the experts defined in condition A. The initial weight of expert \(i\) is \(\), where the index \(i\) is the index defined in condition A as well. 

**Lemma 23**.: _If a process \(\) admits universally consistent online learning under concept class \(\), it satisfies condition A._

_Proof Sketch._ In order to prove this lemma, we need to show the following statement holds:

For a given concept class \(\), and a data process \(\), if there is a learning algorithm \(\) that is strongly universal consistent under \(\) and \(\), then we have a set of experts \(E=\{e_{1},e_{2},\}\), there is a sequence \(\{i_{n}\}\) with \( i_{n}=o(n)\), such that for any realizable sequence \((,)\), for any \(n\), there is an expert \(e_{i}\) with \(i i_{n}\) such that \(Y_{t}=e_{i}(X_{t})\) for every \(t n\).

We modify the construction from the work of Ben-David et al. (2009) to build the experts. The experts are based on the set of the indexes of the rounds when the algorithm \(\) makes mistakes, so there is a one-on-one map from the set of the indexes of the mistakes to the experts. Then we can index the experts based on the set of the indexes of mistakes to show the existence of such a sequence. 

Then we can get the theorem for optimistically universal online learnability, which is theorem 12. Because the proof of lemma 23 and 22 works for any process, we can prove Theorem 12 by reusing the proof of Theorem 11.

## 6 Agnostic Case

In this section, we extend the online learning algorithm for realizable cases to an online learning algorithm for agnostic cases. The basic idea follows the idea of Ben-David et al. (2009). In otherwords, we build an expert for each realizable process \((,)\). Then we run the learning with experts' advice algorithm on those experts and get a low regret learning algorithm.

**Theorem 24**.: _The following two statements are equivalent:_

* _There is an online learning rule that is strongly universally consistent under_ \(\) _and_ \(\) _for the realizable case._
* _There is an online learning rule that is strongly universally consistent under_ \(\) _and_ \(\) _for the agnostic case._

Proof Sketch.: To prove this lemma, we first build the experts \(e_{i}\) based on the learning algorithm for the realizable case by using the construction from lemma 23. We then use the learning on experts' advice algorithm called _Squint_ from Koolen and van Erven (2015), with non-uniform initial weights \(\) for each \(e_{i}\) to get sublinear regret. Thus, we can extend the learning algorithm for realizable cases to a learning algorithm for agnostic cases no matter how the algorithm operates.

An online learning algorithm for the agnostic case is also an online learning algorithm for the realizable case, by taking \(^{*}=\), the regret becomes the number of mistakes. Thus, the two statements are equivalent. 

Theorem 24 implies that all the characterizations for the realizable case are also characterizations for the agnostic case. We formally state the following theorems:

**Theorem 25**.: _For the agnostic case and any concept class \(\) with no infinite VCL tree, any process \(\) admits strongly universal online learning under \(\). However, only the concept class with no infinite Littlestone tree is optimistically universally online learnable._

For the concept class \(\) with infinite VCL tree:

**Theorem 26**.: _For the agnostic case, a data process \(\) admits strongly universal online learning under concept class \(\) with infinite VCL tree if and only if it satisfies condition A. However, a concept class \(\) with infinite VCL tree is optimistically universally online learnable if and only if it satisfies condition B._