# Retrieval-Retro: Retrieval-based Inorganic

Retrosynthesis with Expert Knowledge

 Heewoong Noh\({}^{1}\), Namkeyeong Lee\({}^{1}\), Gyoung S. Na\({}^{2*}\), Chanyoung Park\({}^{1}\)

\({}^{1}\) KAIST \({}^{2}\) KRICT

{heewoongnoh,namkyeong96,cy.park}@kaist.ac.kr

ngs0@krict.re.kr

Corresponding Author.

###### Abstract

While inorganic retrosynthesis planning is essential in the field of chemical science, the application of machine learning in this area has been notably less explored compared to organic retrosynthesis planning. In this paper, we propose Retrieval-Retro for inorganic retrosynthesis planning, which implicitly extracts the precursor information of reference materials that are retrieved from the knowledge base regarding domain expertise in the field. Specifically, instead of directly employing the precursor information of reference materials, we propose implicitly extracting it with various attention layers, which enables the model to learn novel synthesis recipes more effectively. Moreover, during retrieval, we consider the thermodynamic relationship between target material and precursors, which is essential domain expertise in identifying the most probable precursor set among various options. Extensive experiments demonstrate the superiority of Retrieval-Retro in retrosynthesis planning, especially in discovering novel synthesis recipes, which is crucial for materials discovery. The source code for Retrieval-Retro is available at [https://github.com/HeewoongNoh/Retrieval-Retro](https://github.com/HeewoongNoh/Retrieval-Retro).

## 1 Introduction

Discovering new materials is a fundamental problem in materials science , providing innovative options in various industry fields, such as semiconductors and batteries . On the other hand, it is also important to establish synthetic routes for newly discovered materials , i.e., retrosynthesis planning, as the ability to synthesize these materials is essential for their successful commercialization beyond mere discovery.

For organic materials, retrosynthesis planning approaches identify valid and efficient synthetic routes  by breaking down complex target molecules into smaller molecules that are commercially available and easily synthesizable. During the process, they focus on the structural information of target molecules, such as functional groups and reaction centers, that are related to widely known organic reaction mechanisms . Following the practice of organic retrosynthesis, machine learning (ML) based approaches utilizing the molecular structure expressed as SMILES strings  or molecular graphs have been extensively studied .

However, unlike organic retrosynthesis, using the atomic structural information of inorganic materials for retrosynthesis presents significant challenges due to 1) the high computational load incurred by the larger number of atoms compared to organic molecules , and 2) the failure of traditional physical theories for the atomic structure computation caused by the inclusion of diverse and unusual elements . Therefore, a chemical composition-based approach is essential for retrosynthesis planning of inorganic materials. Besides the challenges of using the atomic structural information, there is a lack of a clear and general theory regarding the mechanisms of inorganic synthesis reactions. For these reasons, inorganic retrosynthesis planning is a more challenging task compared to organic retrosynthesis planning.

Given these challenges inherent in the retrosynthesis planning of inorganic materials, applying existing ML-based organic retrosynthesis methods for inorganic purposes is infeasible. Consequently, there has been limited research into inorganic retrosynthesis planning compared to that for organic materials. As a pioneering work, CVAE  generates synthesis variables for target materials using a generative model, and ElemwiseRetro  reformulates the precursor prediction task as a multi-class classification problem with dozens of curated precursor templates. However, these approaches overlook the common practices in conventional inorganic material synthesis, where chemists identify reference materials similar to the target material and consult established synthesis recipes .

More specifically, due to the aforementioned inherent challenges, chemists often engage in a costly trial-and-error method by referencing precedent recipes of reference materials from prior literature . Therefore, as illustrated in Figure 1 (c), the majority of the discovered synthetic routes for a target material share a common set of precursors with the corresponding reference material from previous studies (Figure 1 (a)), whereas only a small number of these routes involve a completely new set of precursors (Figure 1 (b)). Inspired by the common practice, He et al.  propose to retrieve reference materials that are similar to a target inorganic material from a knowledge base of previous studies, and leverage their precursor information for retrosynthesis planning of the target material.

Although the method proposed by He et al.  has proven to be effective by emulating standard practices in the field, it faces two significant limitations. The first limitation is that the model's predictive capability is limited to the precursor sets of retrieved reference material, thus inhibiting its capacity to deduce novel synthetic pathway. This is due to the heavy reliance on the precursor sets of reference materials. However, despite a small fraction of materials being synthesized with entirely new synthetic recipes as shown in Figure 1 (c), it is widely known that discovering novel synthetic routes with entirely new precursors can accelerate the inorganic material synthesis process  and facilitate the discovery of cost-effective recipes . Thus, despite a large number of materials being synthesized through slight alterations to previously known synthesis recipes due to the complexities of inorganic material synthesis, it remains critical to identify new synthetic pathways that extend beyond the commonly known synthetic recipes.

The second limitation is that it neglects the widely known domain expertise in the field : the greater (more negative) thermodynamic driving force (\( G\)) between the target material and the precursor set, the more feasible it is to actually form the target material through the precursor set . As an example in Figure 1 (d), given a target material A\({}_{2}\)BCO\({}_{4}\), a precursor set \(\{,_{2},\}\) exhibits a significantly greater \( G\) compared to another set \(\{_{2}_{2},\}\), making it more probable that the target material will be synthesized from the first precursor set. Therefore, by analyzing the thermodynamic relationships between the target material and various precursor sets, we can identify which combinations of precursors are most feasible for material synthesis. For example, considering such relationship enables the selection of precursor sets that are likely effective starting materials for synthesizing the target material, thereby facilitating successful synthesis. However, previous works  overlook this crucial domain expertise, leading to their inability to identify these optimal precursor sets.

Figure 1: An example case where **(a)** the target material shares a subset of precursors with reference material, and **(b)** the target material has an entirely new set of precursors, without sharing any subset of precursors with reference material. **(c)** The proportion of subset cases and new cases among the materials newly synthesized from 2017 to 2020. **(d)** The target material is more likely to be synthesized using the precursor set that exhibits a more negative driving force.

To this end, we propose a novel inorganic retrosynthesis planning approach by implicitly extracting the precursor information with the domain expertise-enhanced reference material retriever. Specifically, instead of directly utilizing precursor information as in He et al. --that is, explicitly incorporating precursors from retrieved materials for prediction--we propose to implicitly extract this information from reference materials using various attention layers that are designed to enhance and extract the precursor details of the reference materials. By providing the model with greater flexibility, we expect it to discover novel synthesis recipes that go beyond existing ones. Moreover, to determine which material should be referenced, we utilize well-established domain expertise in the field, i.e., the thermodynamic relationships between the target material and potential precursors, with a novel Neural Reaction Energy retriever. With a novel retriever, our model effectively identifies which material to refer to for inorganic retrosynthesis planning of the target material. Our extensive experiments demonstrate the effectiveness of Retrieval-Retro in inorganic retrosynthesis planning, especially discovering novel synthetic recipes, demonstrating the potential applicability of Retrieval-Retro in real-world materials discovery.

In this study, we make the following contributions:

* We propose to implicitly integrate the precursor information of reference materials, which enables the model to more effectively discover novel synthetic recipes of inorganic materials.
* Furthermore, we introduce a novel retriever inspired by domain expertise, which assists the model in effectively determining which material to reference during inorganic retrosynthesis planning.
* Extensive experiments demonstrate the effectiveness of Retrieval-Retro in various scenarios, particularly in the year split, which poses a more realistic and challenging environment. Additionally, its exceptional capability in uncovering new synthetic recipes for inorganic materials highlights its potential for practical application in real-world material discovery.

## 2 Preliminaries

### Problem setup

**Inorganic Retrosynthesis Planning with Chemical Composition.** In inorganic retrosynthesis planning, determining the atomic structure of inorganic materials poses significant challenges and demands costly computational efforts. As a result, both chemists  and prior ML methodologies [18; 17; 12] depend exclusively on composition information. In line with previous studies, we also base our approach on the composition information of inorganic materials instead of structural data.

**Notations.** An inorganic material can be quantitatively described by a composition vector \(^{d}\), where \(d\) represents the total number of unique chemical elements. Each element in the vector \(\) represents the proportion of each chemical element that constitutes the material. As an example, consider the material with chemical formula \(_{2}\), where Si and O correspond to element numbers 14 and 6, respectively. It can be represented as \(=(x_{1},x_{2},,x_{d})\), where \(x_{14}=\), \(x_{6}=\), with all other \(x\) values being zero. Moreover, following a previous work , we construct a fully connected composition graph \(=(,)\), where \(\) is the set of elements associated with the nonzero components of \(\), and \(\{1\}^{n n}\) is the fully connected adjacency matrix with \(n\) indicating the number of nonzero entries in \(\). We initialize the initial feature \(_{i}\) of each element \(e_{i}\) in \(\) with Matscholar , whose element embedding is obtained from the vast amount of scientific literature.

**Task: Precursor Prediction.** Following a previous work , we formulate precursor prediction as a multi-label classification problem. Given a fully connected graph \(=(,)\) representing an inorganic material, our objective is to train a model \(\) that predicts the possible precursors for the material, i.e., \(=()\), where \(\{0,1\}^{l}\) indicates the label vector with each element signifying the predefined \(l\) precursors. That is, each element \(y_{i}\) in the label vector \(\) indicates whether \(i\)-th precursor is necessary (\(y_{i}=1\)) or not (\(y_{i}=0\)) for synthesizing the target material \(\).

### Composition Graph Encoder

To begin with, we briefly introduce the compositional graph encoder, which is used to encode the material representation in the paper. Specifically, given a composition graph \(=(,)\) of a material, we obtain the material representation \(\) as follows:

\[=((,)), \]

where "Pooling" refers to the sum pooling of the node representations within the composition graph \(\), which are derived from a GNN encoder. The detailed architecture used in the paper is provided in Appendix A.1. Moreover, we examine whether the proposed framework can consistently improve in various GNN architectures in Appendix E.1.

## 3 Proposed Method: Retrieval-Retro

In this section, we introduce our proposed method Retrieval-Retro, a novel inorganic retrosynthesis planning approach that implicitly extracts the precursor information of reference materials retrieved with two complementary retrievers, i.e., Masked Precursor Completion (MPC) Retriever and Neural Reaction Energy (NRE) Retriever. The overall framework of Retrieval-Retro is shown in Figure 3.

### Reference Material Retrieval

Before we extract precursor information from the reference materials, it is essential to decide which material should be referenced for the extraction. To elaborately determine which materials to reference, we employ two complementary retrievers: the Masked Precursor Completion (MPC) retriever and the Neural Reaction Energy (NRE) retriever.

**Masked Precursor Completion (MPC) Retriever.** MPC retriever identifies the reference materials sharing similar precursors with the target material by learning dependencies between precursors. Specifically, given a chemical composition vector \(\) of a target material, we obtain its representation \(=M()\), where \(M:^{d}^{d^{}}\) indicates two layered MLPs with non-linearity. We define a learnable precursor embedding matrix \(^{l d^{}}\), whose \(i\)-th row \(p_{i}^{d^{}}\) represents a learnable embedding vector for the \(i\)-th precursor. Concurrently, we generate a randomly perturbed precursor vector \(}\) from the provided precursor information \(\), and create a perturbed precursor matrix \(}\) by applying the perturbed precursor vector \(}\) as a mask to the precursor matrix \(\). Specifically, \(_{i}\) is masked if \(_{i}=0\), and is left unchanged otherwise. We then integrate the representation \(\) and the perturbed precursor matrix \(}\) with cross-attention to form precursor conditioned representation of the material \(\). Then, the model is trained to reconstruct the original precursor vector \(\) from the precursor conditioned representation \(\) and precursor matrix \(\), by representing probability for each precursor as follows \((^{}p_{i})\). The overall training procedure of MPC retriever is in Figure 1 (a).

By doing so, it enables the retriever to learn dependencies among precursors and the correlation between the precursors and the target material. With the MPC retriever, we calculate the cosine similarity between the representation of the target material and all materials in the knowledge base obtained through \(M\), and retrieve the top \(K\) materials that are similar to the target material.

**Neural Reaction Energy (NRE) Retriever.** Although the MPC retriever effectively identifies reference materials with potentially similar sets of synthesis precursors, it overlooks widely recognized domain expertise in the field, i.e., the thermodynamic relationships between materials, which is essential for the inorganic synthesis process, particularly in selecting appropriate precursors . More specifically, the thermodynamic driving force between the target material and precursor set can be quantified by Gibbs free energy (\( G\)), which is a measure of the material's thermodynamic stability. Under constant pressure and temperature, a negative \( G\) indicates that the energy of the target material is lower than that of the precursor set, signifying that the synthesis reaction can occur spontaneously . As a result, it is widely known that the more negative \( G\), the more precursor set is likely to synthesize the target material.

Based on this knowledge, it would be beneficial to retrieve materials that have the precursor set capable of inducing favorable reactions with the target material by considering the thermodynamic force. \( G\) can be approximated by the difference \( H\) between the enthalpy of the target and

Figure 2: **(a)** Training process of the Masked Precursor Completion (MPC) retriever. **(b)** Training process of the Neural Reaction Energy (NRE) retriever.

precursor set \( H\) as follows:

\[ G H=H_{Target}-H_{Precursor\ set}, \]

where the \(H_{Target}\) and \(H_{Precursor\ set}\) represent the formation energy of the target and precursor set. Therefore, a straightforward solution for calculating \( H\) is to utilize the formation energy of the target material and the precursor set that can be directly obtained from the extensive database of structure-based DFT-calculated formation energy. However, it is widely known that DFT-calculated values frequently diverge from experimental data, while actual material synthesis occurs in real-world wet lab settings . Even worse, there is no guarantee that these databases encompass all materials of interest in inorganic retrosynthesis planning. Consequently, it is essential to develop a composition-based formation energy predictor that is specifically designed for experimental data.

To this end, we propose a learnable Neural Reaction Energy (NRE) retriever, which is pre-trained on abundant DFT-calculated formation energy data and then fine-tuned on experimental formation energy data as shown in Figure 1 (b) . Specifically, we initially pre-train the NRE retriever using the Materials Project database , training the model to predict DFT-calculated formation energy from representations derived from the composition graph encoder (see Section 2.2). Subsequently, we fine-tune the retriever using experimental formation energy data , which allows the model to adapt to experimental data. We demonstrate the effectiveness of the training mechanism in Appendix E.2. Finally, given a trained NRE retriever, we can compute the formation energies of the target material and the precursor set of reference materials in the knowledge base. We then retrieve \(K\) reference materials that exhibit the most negative \( G\), selecting from those whose precursors contain the same elements as the target material, along with other common elements such as C, H, O, and N. Note that calculations are performed prior to training, so no additional training costs are incurred.

### Implicit Precursor Extraction

Now, we discuss how to extract the precursor information from the reference materials elaborately selected in Section 3.1. While the previous work  directly utilizes the precursor information of the reference materials, this limits the model's ability to learn and deduce new synthetic recipes for the target material, which can significantly accelerate the materials discovery and reduce the cost of material synthesis. Therefore, we propose to implicitly extract the precursor information from the retrieved material with various attention layers, i.e., self-attention and cross-attention layers, which aim to enhance the representation of reference materials by considering other reference materials and extract the implicit precursor information from the enhanced representation, respectively.

To do so, we first encode the target material and \(K\) reference materials using their associated composition graphs \(\) via the composition graph encoder introduced in Section 2.2. As a result, we obtain the representation of target material \(_{t}^{D}\) and the \(K\) reference materials \(_{}=[_{}^{1},,_{}^{K}]^{K D}\), where \(_{}^{k}\) indicates the representation of the \(k\)-th reference material.

**Reference Enhancing with Self-Attention.** To effectively extract the precursor information from the reference materials, we first enhance the representation of these materials through a self-attention mechanism . This approach encourages the model to selectively determine which information to extract from a particular reference material by considering the relationships among various reference materials. To do so, we first obtain a new matrix for reference materials \(}_{r}^{0}=[}_{r}^{1},,}_{r}^{K}]\), where \(}_{r}^{k}=_{1}(_{}^{k}|| _{})\) indicates the modified representation of the \(k\)-th reference material regarding the target material, where \(||\) denotes the concatenation operation, and \(_{1}:^{2D}^{D}\) is a learnable MLP. Note that by modifying the representation of the reference material through concatenation with the target material, we allow the model to extract information pertaining to the target material, rather than focusing solely on the reference materials. Then, we implement a self-attention mechanism to determine which information to extract from the reference material, taking into account the

Figure 3: The overall framework of Retrieval-Retro.

relationships among the other reference materials:

\[}_{r}^{s}=(_{}^{ s-1}},_{}^{s-1}},_{}^{s-1}}) ^{K D}, \]

where \(s=1,,S\) indicates the index of the self-attention layers. Different from the conventional self-attention layers , we directly utilize \(}_{r}^{s-1}\) as query \(_{}^{s-1}}\), key \(_{}^{s-1}}\), and value \(_{}^{s-1}}\), without any learnable parameters . By analyzing the relationships between the reference materials, the model improves the representations of these materials, thereby supplying more appropriate references to be extracted by the cross-attention layer.

**Reference Selection with Cross-Attention.** Lastly, we extract the implicit precursor information by merging the representation of the target material with that of the enhanced reference materials via a cross-attention mechanism [38; 42]. With cross-attention layers, we expect the model to learn favorable synthesis recipes from reference materials by selectively learning from reference materials with attention weights. More formally, cross-attention layers are formulated as follows:

\[^{c}_{t}=(_{^{c-1}_{t}}, _{}^{S}_{r}},_{}^{S} _{r}})^{D}, \]

where \(c=1,,C\) indicates the index of the cross-attention layers. Note that we use an enhanced reference material representation \(}_{r}^{S}\) and target material representation \(_{t}\) as inputs to the first cross-attention layer, i.e., \(^{}}_{r}^{0}=}_{r}^{S}\) and \(^{0}_{t}=_{t}\). Moreover, we also utilize \(^{c-1}_{t}\) as query \(_{^{c-1}_{t}}\), and the reference material representation \(}_{r}^{S}\) as key \(_{}^{S}_{r}}\) and value \(_{}^{S}_{r}}\) identical to the self-attention layer, without any learnable parameters. By employing cross-attention layers between the target material and reference materials, rather than the precursor set of the reference materials, the model effectively accesses the synthetic recipes of reference materials without explicitly using precursor information, thus enabling the discovery of novel synthetic recipes for the target material. We employ this implicit precursor extraction process for the reference materials gathered using both the MPC retriever and the NRE retriever, resulting in \(^{C}_{t:}\) and \(^{C}_{t:}\), respectively.

### Model Training

Finally, we compute the model prediction \(}\) as follows: \(}=_{}(_{t}||^{C}_{t: }||^{C}_{t:})\), where \(_{}:^{3D}^{l}\) is an MLP with non-linearity. Note that each dimension in \(}\), i.e., \(_{i}\), indicates the model's predicted probability of whether precursor \(i\) will be included or not. For model training, we adopt Binary Cross Entropy (BCE) loss, which is commonly used for multi-label classification learning [5; 47], as: \(=-_{i=1}^{l}[y_{i}(_{i})+(1-y_{i}) (1-_{i})]\).

## 4 Experiments

### Experimental Setup

**Datasets.** We use 33,343 inorganic material synthesis recipes extracted from 24,304 materials science papers  following prior studies [12; 18]. Due to the lack of an extensive database containing inorganic synthesis recipes , we use the training set as the knowledge base, following a previous work . Additional details about datasets are provided in the Appendix B.

**Baseline Methods.** We compare Retrieval-Retro with two inorganic retrosynthesis methods (i.e., **He et al. ** and ElemwiseRetro ), two composition-based representation learning methods (i.e., Roost  and CrabNet ), and three newly proposed baselines (i.e., Composition MLP and Graph Network , Graph Network + MPC) to demonstrate the effectiveness of Retrieval-Retro. The first newly introduced baseline is called **Composition MLP**, which does not retrieve reference materials but instead relies on the composition vector of the material. **He et al. ** conducts inorganic retrosynthesis planning by using the MPC retriever to access reference materials based solely on the material's composition vector. **ElemwiseRetro** acquires precursor information through a fully connected graph that represents the constituent elements within the material. Furthermore, two composition-based material representation learning approaches, namely **Roost** and **CrabNet**, explore the intricate interactions among elements within materials using message passing and self-attention, respectively. Although these methods are initially designed for property prediction, we have adapted prediction heads so that they can be effectively used for inorganic retrosynthesis planning. We also evaluate two new baselines, **Graph Network** and **Graph Network + MPC**. The former predicts precursors without retrieving reference materials, while the latter does so after retrieving references. As these methods utilize the same backbone GNN structure as in our approach,

[MISSING_PAGE_FAIL:7]

[MISSING_PAGE_FAIL:8]

noisy precursor information that does not pertain to the target material. Thus, extracting precursor information from a suitable number of retrieved materials is essential for optimal performance.

**Qualitative Analysis.** We present a qualitative analysis of our proposed method in retrosynthesis planning for the target material Pb\({}_{9}\)[Li\({}_{2}\)(P\({}_{2}\)O\({}_{7}\))\({}_{2}\)(P\({}_{4}\)O\({}_{13}\))\({}_{2}\)], which can be synthesized from the precursor set: [Li\({}_{2}\)CO\({}_{3}\), NH\({}_{4}\)H\({}_{2}\)PO\({}_{4}\), PbO]. As shown in Table 4, when only the MPC retriever is used, the method fails to predict the entire precursor set due to insufficient extraction of precursor information from the retrieved materials. However, when the NRE retriever is used alongside the MPC retriever, our method successfully predicts the complete precursor set for the target material. This success is attributed to the NRE retriever, which complements the model by providing complementary retrieved materials whose precursors are feasible for synthesizing the target material, thereby enabling the extraction of diverse precursor information. For instance, the NRE retriever allows our method to extract precursor information from Pb\({}_{3}\)(PO\({}_{4}\))\({}_{2}\), which contains the essential precursor PbO, a direct precursor for the target material. Due to the complementary nature of the retrievers, our method can effectively extract precursor information from informative reference materials, leading to enhanced predictions.

## 5 Related Works

### Machine Learning for Inorganic Retrosynthesis

Owing to the intricate nature of inorganic retrosynthesis, the production of inorganic materials entails a mix of numerous synthetic variables, leading to a variety of subtasks: 1) Learning favorable reaction pathways with thermodynamic variables when a target and precursor set are provided [2; 27; 35], 2) Employing regression models to predict conditions of the reaction pathway, such as heating temperature and time , and 3) Predicting possible precursor sets for a target material. In this work, we focus on the precursor selection task, which aims to predict feasible sets of precursors for synthesizing a target material [17; 18; 12].

**Precursor Prediction Task.** As a pioneering work, CVAE  generates synthesis actions and precursors through a generative model, i.e., conditional variational autoencoder . However, it frequently produces chemically invalid precursors by relying on the generative model. ElemwiseRetro  alleviates the issue by formulating the precursor prediction task as a multi-class classification with dozens of manually created precursor templates. While it successfully suggests chemically valid precursors, it fails to incorporate knowledge from synthesis literature, which is common practice in the field of material science. More recently, inspired by the chemists' synthesis practice, He et al.  propose to use the precursor information of materials that are similar to the target material, which is retrieved from the related literature. This approach utilizes the precursors of the retrieved material as explicit conditions for predicting the precursors of the target material. However, such

Figure 4: Sensitivity Analysis results. KB refers to the knowledge base.

  
**Model** & **Retriever** & **Retrieved Material** & **Corresponding Precursor Sets** & **Predicted Precursor Set** & **Answer** \\   &  & LN\_NPPO & (Li\_CO\({}_{3}\), HP\_PO\_Na\_CO\_POexplicit utilization of precursor information can inhibit the model's capability in providing novel synthetic routes for target material. Different from the previous work, we propose to implicitly utilize precursor information of similar material rather than directly using it.

### Composition-based representation learning for Inorganic materials

While most machine learning approaches for inorganic materials predominantly utilize structural information, in real-world material discovery, structural data is often unavailable due to the high costs of computational resources. Consequently, some ML methods opt to use compositional information of inorganic materials instead of structural details. For example, ElemNet  proposes to learn the representation of material with compositional information using deep neural networks (DNNs). Roost  learns material representation by building fully connected graphs based on the composition to model interactions between elements by graph neural networks (GNNs). Additionally, CrabNet  successfully applies a self-attention mechanism to the element-derived matrix to accurately predict the properties of materials. Although these methods were originally designed for predicting material properties, they can also be applied to inorganic retrosynthesis as they similarly rely on the composition information of materials.

### Difference between Inorganic Retrosynthesis and Organic Retrosynthesis

Both organic and inorganic retrosynthesis are challenging tasks that predict the synthesis of materials by breaking down the target material into simpler precursors. However, there are significant differences between organic and inorganic retrosynthesis. Organic retrosynthesis [45; 40; 7; 9; 33] deals with organic compounds, which are molecules primarily composed of elements such as carbon, hydrogen, oxygen, nitrogen, and sulfur. These compounds are represented using molecular structure graphs or SMILES strings. In contrast, inorganic retrosynthesis involves inorganic compounds, which can include a wider variety of elements, often including metals, and have structures that periodically repeat in unit cells. Another key difference lies in the use of structural information during retrosynthesis planning. Organic retrosynthesis utilizes structural information such as functional groups and reaction centers of organic compounds, which indicate the properties of a material and its reactivity with other molecules, to predict simpler molecules (precursors) into which the target molecule can be broken down. Inorganic compounds, however, have relatively unexplored generalized synthesis mechanisms compared to organic compounds, and calculating their structures is expensive. Therefore, it is challenging to directly use structural information for retrosynthesis planning. Instead, inorganic retrosynthesis [12; 17; 18] often relies solely on the chemical composition of the materials, distinguishing it from organic retrosynthesis.

## 6 Limitations

We aim to identify favorable precursor sets by considering the thermodynamic relationships between materials and their precursor set. However, in the actual synthesis process, the phase changes of materials are influenced by synthesis temperature, synthesis time, pressure condition and pairwise reactions between precursors. Taking these factors into account would enable more accurate precursor set predictions. Nevertheless, in situations where experimental data (such as temperature and pressure) are unavailable, we estimate the reaction energy solely from the formation energy calculated under consistent temperature and pressure conditions using a trained predictor, derived from the composition of materials. Considering multiple synthesis conditions can lead to more precise predictions of precursor sets.

## 7 Conclusion

In this study, we introduce Retrieval-Retro, a novel method for inorganic retrosynthesis planning by extracting the precursor information of retrieved reference material implicitly. To do so, we employ various attention layers that enhance and extract the information from the reference material. Moreover, we design a neural reaction energy (NRE) retriever that provides complementary reference material to the MPC retriever, allowing Retrieval-Retro to integrate precursor information from a broader range of reference materials through domain expertise. Through extensive experiments, including assessments in realistic scenarios, we demonstrate the effectiveness of implicit extraction of precursor information and NRE retriever in discovering novel synthesis recipes of target material, demonstrating the potential impact of Retrieval-Retro in the field.