# [MISSING_PAGE_FAIL:1]

[MISSING_PAGE_FAIL:1]

and includes measures of interactions between the various input dimensions. Here, we focus on GSA. Approaches for GSA can be categorized into two main types: variance-based measures, also referred to as ANOVA decomposition or Sobol methods , and derivative-based global sensitivity measures (DGSMs) . Variance-based measures quantify the importance of different input variables based on their contribution to the global variability of the function output. In contrast, DGSMs quantify importance based on the global variability of the function's gradient. They are defined as an integral over the gradients or a function of the gradients across the input space.

DGSMs can often be computed directly from the function. However, for expensive black-box functions, integrating a function of the gradients over the input space is infeasible due to the limited number of function evaluations and a lack of gradient information. In this case, the function is modeled by a surrogate Gaussian process (GP) , which allows for tractable computation of both the function surrogate and its gradient. Previous work [6; 17; 21] used random and quasirandom sequences to select the data points for learning the GP; however, these space-filling approaches still require a substantial number of evaluations to accurately estimate the DGSMs.

We show here that DGSMs can be targeted for active learning with information-based acquisition functions that are tractable under GP surrogate models, which are standard for GSA. Applying active learning to DGSM quantities (e.g., gradient, absolute value of the gradient, squared value of the gradient) allows for sensitivity analysis to be performed in a highly sample-efficient manner, suitable for engineering and science applications with small evaluation budgets. To the best of our knowledge, this is the first study proposing active learning acquisition functions directly targeting the DGSM measures.

We illustrate the utility of the proposed acquisition functions for active learning using the classic Forrester  test function (Fig. 1). The posteriors of \(f\) and \(df/dx\) given observations of \(f\) are computed from the GP (Sections 2.4 and 2.5). Posteriors of \(|df/dx|\) and \((df/dx)^{2}\) derive from that of \(df/dx\) (Section 4.4); the absolute and squared DGSMs are the integrals of these functions (Section 2.3). Acquisition functions give the value of evaluating any particular point under different targets: one quantifies the information gain of the function generally (Section 3), and the others quantify the information gain of the derivative quantities (Section 4.4). The acquisition functions illustrate why active learning strategies that only target learning \(f\) are not effective for learning DGSMs. To learn \(f\), active learning selects points that are _far from_ existing observations, where \(f\) is most uncertain.

Figure 1: (Left) Posteriors of \(f\), \(df/dx\), \(|df/dx|\), and \((df/dx)^{2}\) are computed from a GP surrogate given six observations of \(f\) (black dots). Posteriors are shown as posterior mean (line) and 95% credible interval (shaded). (Right) Acquisition functions are computed from these posteriors, targeting \(f\) and derivative sensitivity measures. Dotted vertical lines show the maximizer. Acquisition functions that directly target DGSMs, not just \(f\) generally, are required to learn the DGSMs efficiently.

[MISSING_PAGE_FAIL:3]

dient, the absolute value of the gradient, and the square of the gradient :

\[S_{R}(f,)_{i}=|}_{} ()}{ x_{i}})d, S_{ Ab}(f,)_{i}=|}_{}|)}{ x_{i}}|d,\] \[S_{Sq}(f,)_{i}=|}_{}()}{ x_{i}})^{2}d.\]

In the remainder of the paper, we will refer to these quantities as the raw DGSM, absolute DGSM, and squared DGSM. These quantities may also be defined with non-uniform densities on \(\).

For the purpose of evaluating input sensitivity, the raw DGSM is considered uninformative due to a phenomenon known as _the cancellation effect_. In nonmonotonic functions, positive parts of the gradient cancel out negative parts when integrated over the entire input space, leading to a small value for the raw DGSM even for important dimensions. The most commonly used DGSMs in practice are the absolute and squared DGSMs, which avoid the cancellation effect. The squared DGSM is especially popular because of its connection to the variance of the gradient . Computing DGSMs requires computing a \(d\)-dimensional integral over \(\). This integration is usually done via Monte Carlo (MC) or quasi-Monte Carlo (QMC) sampling .

### GP Surrogates for Sensitivity Analysis

When function evaluations are expensive, the integrals over the input space required to compute the DGSMs may not be evaluated tractably from \(f\). Moreover, if \(f\) is black-box, we may not have access to its gradients. Both of these issues can be avoided by using a surrogate function for \(f\).

GSA of expensive, black-box functions is usually done using a GP surrogate model . GPs are characterized by a mean function \(m:\) and a kernel function covariance \(:\). A GP prior for the function, \(f(m,)\), means that the function values at any finite set of inputs are jointly normally distributed. For any input \(_{*}\), the function value at that input has a normally-distributed posterior \(f(_{*})|(_{*},_{*}^{2})\), whose predictive mean and variance are:

\[_{*}=_{_{*},X}K_{}^{-1}(Y-m_{X})+m_{ _{*}},_{*}^{2}=_{_{*},_{* }}-_{_{*},X}K_{}^{-1}_{,_{*}},\]

where \(_{_{*},_{*}}=(_{*},_{*})\), \(_{_{*},X}=[(_{*},_{j})]_{j=1}^{ t}\), \(m_{}=m()\), and \(K_{}=_{X,X}+^{2}I\), with \(_{X,X}=(X,X)\) and \(^{2}\) the observation noise variance of \(y\). We introduce the short-hand notation \(_{*}:=(_{*})\) and \(_{*}^{2}:=(_{*})^{2}\) for the posterior mean and variance functions.

GPs are differentiable when using any twice-differentiable kernel function \(\) and a differentiable mean function \(m\). The gradient of the GP provides a tractable estimate of the gradient of the expensive black-box function \(f\) under commonly-used kernels such as the ARD RBF. DGSMs can then be computed in a fast and scalable way on the posterior of \(f\).

### Derivatives of Gaussian Processes

GPs are closed under linear operations, therefore the derivative of a GP is itself a GP . Since \(f\) is defined over a \(d\)-dimensional input space, the model's gradient has a \(d\)-dimensional output. Under a GP prior, the joint distribution between (potentially noisy) observations of \(f\) and the gradient of at a new point \(_{*}\) is as follows :

\[Y\\  f(_{*})(m_{X}\\  m_{_{*}},K_{}&_{ _{*}},_{X,_{*}}\\ _{_{*}},_{_{*},X}&_{_{*}} ^{2},_{_{*},X_{*}}).\]

Given the observed data \(\) as before, the gradient at \(_{*}\) has a multivariate normal distribution: \( f(_{*})|(_{*}^{},_{ *}^{})\), where

\[_{*}^{} = m_{_{*}}+_{_{*}}_{ _{*},X}K_{}^{-1}(Y-m_{X}), \] \[_{*}^{} =_{_{*}}^{2}_{_{*},_{*}}-_{_{*}}_{_{*},X}K_{}^{-1} _{_{*}}_{X,_{*}}. \]

Here, \(_{*}^{}=^{}(_{*})\) and \(_{*}^{}=^{}(_{*})\) are shorthand for the posterior mean and covariance functions of the gradient. Note that the posterior for the derivative may be obtained from observations only of \(f\), and does not require direct observations of the derivative. The greatest computational expense in computing the GP posterior is the matrix inversion in \(K_{}^{-1}\), which has complexity \((t^{3})\). This same term is also the most expensive term in the posterior for the derivative. Consequently, once the posterior of the GP has been computed, the computation of the derivative does not increase the overall complexity. Given the posterior of the derivative, the DGSMs are estimated by substituting the gradient of the function with the predictive mean of the gradient from (1).

## 3 Related Work

The GP surrogate allows for computing DGSMs with a limited set of function evaluations. However, in budget-restricted experiments, the GP will only provide a faithful representation of the sensitivity of \(f\) if the right set of inputs are evaluated. There has been limited work on efficiently selecting the inputs that lead to accurate DGSM estimation, particularly with a limited evaluation budget.

**Random and space-filling designs:** The most common approach for estimating DGSMs with a GP is to evaluate the function on either a random set of inputs or with a space-filling design. For the latter, quasirandom sequences like scrambled Sobol sequences  and Latin hypercube sampling  are two common choices. Space-filling designs are effective for GSA with a sufficiently large evaluation budget, however, as we will see below, they fail when the budget is limited.

**General uncertainty reduction methods:** Several Bayesian active learning approaches have been developed for the purpose of reducing global uncertainty about \(f\). Information-based strategies that select the point that produces the largest information gain about a function's outputs are popular and effective for global identification of \(f\)[36; 16; 12]. Other global active learning approaches are based on variance reduction  and expected improvement (EI) . These general-purpose active learning strategies have been applied to the GSA problem. Pfingsten  used global predictive variance reduction as the active learning target for the purpose of GSA; Chauhan et al.  applied the EI criterion to GSA. These approaches are designed to generally minimize uncertainty of \(f\), and do not specifically target improvement of any particular GSA measure. Acquisition functions that target \(f\) are not sufficient to learn the DGSMs efficiently on a budget (Figure 1).

**Active learning involving derivatives:** Some work has incorporated derivatives into active learning for problems unrelated to GSA. Salem et al.  and Spagnol et al.  use sensitivity measures to eliminate variables during Bayesian optimization. Erickson et al.  and Marmin et al.  include a derivative term in an acquisition function for learning non-stationary functions. Wycoff et al.  do active subspace identification with an acquisition function targeting the outer product of the gradient. See the Appendix for further discussion and an empirical comparison to these methods.

**Active learning for GSA:** There has been limited work on applying active learning to GSA measures. Existing work considers only the Sobol index (variance-based measures). Le Gratiet et al.  applied variance reduction directly to the Sobol index. However, this could not be done in closed form and required expensive simulations within each active learning step. More recently, Chauhan et al.  developed an analytic improvement criterion that targets the numerator of the Sobol index. In this work, we propose the first active learning acquisition functions directly targeting DGSMs.

Bayesian Active Learning for Derivative-Based Sensitivity Analysis

In this section, we develop active learning acquisition functions that target the DGSM measures. We derive acquisition functions following three general strategies. The _maximum variance_ acquisition functions select the point with the largest posterior variance in the quantity of interest, indicating the point with the most uncertainty. The _variance reduction_ acquisition functions measure how much an observation at a point will reduce the variance at that point in expectation over the possible outcomes of the observation. Finally, the _information gain_ acquisition functions quantify the expected reduction in entropy of the posterior of the quantity of interest for each point. The latter two strategies require computing the look-ahead distribution for the derivative, which we introduce in Section 4.1. Finally, we discuss global look-ahead acquisition functions that measure the impact of evaluating an input on the posterior across the entire input space.

### The Derivative Look-Ahead Distribution

Effective active learning often relies on computing _look-ahead_ distributions that predict the impact that making a particular observation will have on the model. For our purposes, we wish to predict the impact that observing \(f\) at a candidate point \(_{*}\) will have on the model's derivatives at that location. Conditioned on the observations \(\), \(f(_{*})\) and \(_{*})}{ x_{i}}\) have a bivariate normal joint distribution for each input dimension \(i\). The well-known formula for bivariate normal conditioning provides the look-ahead distribution : \(_{*})}{ x_{i}} f(_{*})=y_{*},(^{}_{*,i},(^{}_{ *,i})^{2})\), where the look-ahead mean and variance are

\[^{}_{*,i}=^{}_{*,i}+_{*,i}}{_{* }^{2}}(y_{*}-_{*}), 14.226378pt(^{}_{*,i}) ^{2}=(^{}_{*,i})^{2}-(_{*,i}}{_{*} })^{2}, \]

with \(_{*,i}=[f(_{*}),_ {*})}{ x_{i}}]\) the posterior covariance between \(f\) and the derivative at \(_{*}\), and \((^{}_{*,i})^{2}=^{}_{i}(_{*})^{2}=[ ^{}(_{*})]_{ii}\) the posterior variance of the derivative. As before, we use the notational short-hand \(^{}_{*,i}=^{}_{i}(_{*})\) and \(^{}_{*,i}=^{}_{i}(_{*})\). This result holds when \(y_{*}\) is a noisy observation by replacing \(_{*}^{2}\) with \(^{2}+_{*}^{2}\). Remarkably, the look-ahead variance is independent of the actual observed \(y_{*}\), so acquisition functions that are based on the future variance of the derivative can be computed exactly in closed form. In the Appendix, we provide the look-ahead posterior distribution of the derivative of \(f\) at any point in the input space after observing \(f\) at \(_{*}\).

### Gradient Acquisition Functions

Maximum variance.The posterior variance of each derivative is given in (2). The maximum derivative variance acquisition function uses the sum of the variances across dimensions to find points with high total uncertainty in the derivatives: \(_{}()=_{i=1}^{d}^{}_{i}()^{2}\).

Variance reduction.The derivative variance reduction acquisition computes the expected reduction in variance of the derivatives produced by making an observation of \(f\) at \(\):

\[_{_{*}}()=_{i=1}^{d}^{}_{i}( )^{2}-_{y}[^{}_{i}()^{2}]=_ {i=1}^{d}^{}_{i}()^{2}-^{}_{i}()^{2},\]

where \(^{}_{i}()^{2}\) is the look-ahead variance of the derivative, from (3). The expectation is dropped because the look-ahead variance is independent of the observed \(y\) at the candidate point.

Information gain.We express our derivative information gain acquisition function as the sum of information gains for each derivative. Let \(H^{}_{i}()=h()}{ x_{i }}|)\) be the differential entropy of each derivative posterior and \(H^{}_{i}()=h()}{ x _{i}}|,f()=y)\) the look-ahead entropy. The Gaussian entropy is well-known , and since it is independent of the mean, the look-ahead entropy is independent of \(y\). The information gain, in nats, is:

\[_{}()=_{i=1}^{d}H^{}_{i}( )-_{y}[H^{}_{i}()]=_{i=1}^{d} (^{}_{i}())-(^{} _{i}()).\]

### Absolute Gradient Acquisition Functions

Maximum variance.The absolute value of a normal distribution is the _folded normal distribution_, whose mean and variance, \(^{}_{i_{Ab}}()\) and \(^{}_{i_{Ab}}()^{2}\), are analytical and can be computed from the moments of the corresponding normal distribution. Using those results, the posterior of \(|)}{ x_{i}}|\) has mean and variance:

\[^{}_{i_{Ab}}()=}^{ }_{i}()e^{-_{i}^{2}()}+^{}_{i }()(1-2(-r_{i}())),\] \[^{}_{i_{Ab}}()^{2}=^{}_{i}()^{2}+^{}_{i}()^{2}-^{}_{i_{Ab}}()^{2},\]

where \(\) is the standard normal CDF and we have denoted \(r_{i}()=_{i}()}{^{}_{i}( )}\). We define the maximum variance acquisition for the absolute value of the derivative as: \(_{}()=_{i=1}^{d}^{}_{i_{Ab}}( )^{2}\).

Variance reduction.The look-ahead variance for the absolute value of the derivative, denoted \(^{}_{i_{Ab}}()^{2}\), can be computed by plugging the look-ahead moments from (3) into the formula for the folded normal variance. However, unlike for the raw derivative, this variance depends on \(^{}_{i}()\) and is thus a function of \(y\), making the expectation in the variance reduction formula intractable. We follow the strategy of Lyu et al.  and approximate \(_{y}[^{}_{i_{Ab}}()^{2}]\) with a plug-in estimator, fixing \(y=()\). Plugging this estimator into (3) gives an estimate for the look-ahead derivative mean that is independent of \(y\), denoted \(^{}_{i_{Ab}}()^{2}\), and it follows that

\[_{_{i}}()=_{i=1}^{d}^{}_{i_{Ab}}( )^{2}-_{y}[^{}_{i_{Ab}}()^{2}] _{i=1}^{d}^{}_{i_{Ab}}()^{2}-^{ }_{i_{Ab}}()^{2}.\]

Information gain.The differential entropy of the folded normal distribution is not available in closed form. Tsagris et al.  provide an approximation using a truncated Taylor series. However, we show in the Appendix that it is numerically poorly behaved in this application. We introduce a novel approximation for the folded normal differential entropy, in nats:

\[H^{ab}_{i}()=H^{}_{i}()-_{i_{Ab} }()^{2}-^{}_{i}()^{2})(2)}{2^{ }_{i}()^{2}}.\]

The derivation of this approximation and an evaluation of accuracy alongside other approximations are in the Appendix. The look-ahead entropy \(H^{ab,}_{i}\) is estimated using the same plug-in strategy as for variance reduction, to remove dependence on \(y\) and get

\[_{}()=_{i=1}^{d}H^{ab}_{i}()-H^{ab, }_{i}(). \]

### Squared Gradient Acquisition Functions

Maximum variance.Let \(Q=()}{ x_{i}})^{2}\) and \(Z=_{i}()^{2}}\). The posterior of \(Z\) has a non-central \(^{2}\) distribution \(Z|^{2}_{1}(_{i}()^{2}}{ ^{}_{i}()^{2}}).\) This allows computing the posterior variance of the squared derivative using the known moments of the noncentral \(^{2}\) distribution: \(^{}_{i_{sq}}()^{2}=4^{}_{i}()^{2} ^{}_{i}()^{2}+2^{}_{i}()^{4}.\) As before, we construct the maximum variance acquisition function as \(_{}()=_{i=1}^{d}^{}_{i_{sq}}( )^{2}\).

Variance reduction.As with the absolute value, the look-ahead variance for the square of the derivative depends on the observed value \(y\) via the term \(^{}_{i}()\), making the expectation in variance reduction intractable. We again approximate the variance reduction with a plug-in estimator in (3), substituting \(^{}_{i}()\) for \(^{}_{i}()\) to estimate a look-ahead variance \(^{}_{i_{sq}}\) independent of \(y\). The variance reduction can then be computed as:

\[_{_{i}}()=_{i=1}^{d}^{}_{i_{sq}}( )^{2}-_{y}[^{}_{i_{sq}}()^{2}] _{i=1}^{d}^{}_{i_{sq}}()^{2}-^{ }_{i_{sq}}()^{2}.\]Information gain.Using properties of entropy , the differential entropy of the squared derivative follows from that of the noncentral \(^{2}\) distribution as:

\[H_{i}^{sq}()=h(Q|)=h(Z|)+2 (_{i}^{}()). \]

In the Appendix we develop two approximations for the entropy of the noncentral \(^{2}\). As shown there, the most effective approach derives from an earlier approximation of the quantile function for the noncentral \(^{2}\) by Abdel-Aty . Our novel entropy approximation relies on recent analytical expressions for the expected logarithm by Moser , as detailed in the Appendix. We plug the approximated noncentral \(^{2}\) entropy into (5) to obtain an entropy for the squared normal, and then the information gain acquisition, \(_{}()\), follows analogously to \(_{}\).

\[_{}()=_{i=1}^{d}H_{i}^{sq}()-H_{i} ^{sq,}(). \]

### Global Variance Reduction and Information Gain

The acquisition functions described so far all evaluate the impact of an observation at \(_{*}\) only on the posterior at \(_{*}\). We also considered global look-ahead acquisitions, which evaluate the impact of an observation at \(_{*}\) on the posterior across the entire input space. These acquisition functions are expressed as an integral of the acquisition functions already described. We provide their full expressions, their evaluation, and a discussion about their complexity and performance in the Appendix.

## 5 Experiments

### Experimental Setup

We compared the proposed active learning acquisition functions for DGSMs to space-filling and general uncertainty reduction approaches. We refer to quasirandom sequences as qr, variance maximization of \(f\) as fvar, and information gain about \(f\) [i.e., BALD, 12] as fig. Since our experiments use noiseless observations of \(f\), variance reduction of \(f\), \(_{r}\), is equal to fvar. For the acquisition functions developed here, we use the following acronyms (Section 4): max variance of the raw, absolute, and squared derivatives are dv, dabv, and dsqv; corresponding variance reduction acquisitions are dvr, dabvr, and dsqvr; and information gain acquisitions are dig, dabig, and dsqig. For the absolute and squared derivative information gains, we evaluated two different entropy approximations, labeled as e.g. dsqig1 and dsqig2, with the corresponding descriptions in the Appendix.

We used synthetic and real-world problems for evaluation. For synthetic experiments we used a family of functions designed specifically for evaluating sensitivity analysis measures [18; 17]: Ishigami1 (\(d=3\)), Ishigami2 (\(d=3\)), Gsobol6 (\(d=6\)), a-function (\(d=6\)), Gsobol10 (\(d=10\)), Gsobol15 (\(d=15\)) and Morris (\(d=20\)). Ground-truth DGSMs are available for these problems. We additionally used other general-purpose synthetic functions where sensitivity might be challenging to estimate : Branin (\(d=2\)), Hartmann3 (\(d=3\)) and Hartmann4 (\(d=4\)). For these functions, we numerically estimated ground-truth DGSMs. The results for Hartmann3, Gsobol6, and a-function are given in the Appendix. We considered three real-world design problems. The _Car Side Impact Weight_ problem simulates the impact of \(d=7\) design variables on the weight of a car, to study the impact of weight on accident scenarios. Design variables are the thickness of pillars, the floor, cross members, etc. We also used the _Vehicle Safety_ problem, which has two functions: the weight and the acceleration of the vehicle. Both are functions of \(d=5\) design variables describing the thickness of frontal reinforcement materials. We study the two functions as independent problems. Ground truth DGSMs for these problems were estimated numerically.

We study settings with limited evaluation budgets. Quasirandom sequences are known to perform well given enough data [6; 3]. Here, we focus on the restrictive case where we initialize our experiments using five random inputs and run 30 iterations of active learning. Our results are averaged over \(50\) replicates from different initial points, and we report the mean and two standard errors over replicates. Our primary evaluation metric is root mean squared error (RMSE) of the DGSM estimate versus ground truth. All acquisition functions were implemented in BoTorch  and were designed to be auto-differentiable and efficiently optimized with gradient optimization.

### Results and Discussion

Experimental results for the new acquisition functions are separated by their targets for clarity: Fig. 2 for the raw derivative, Fig. 3 for the absolute derivative, and Fig. 4 for the squared derivative. Across this wide set of problems, the active learning targeting DGSM quantities developed here consistently outperformed quasirandom sequences (qr) and active learning methods that target learning about \(f\) (fvar and fig). The DGSM information gain acquisition functions (dig, DAbf\({}_{1}\), DsqiG\({}_{1}\)) performed best in the majority of experiments.

There were rare instances in which RMSE increased with active learning iteration. The explore/exploit trade-off is fundamental to active learning. During exploration, adding a data point in one part of the space may cause a global adjustment in the model predictions that can cause errors in another area. With more exploration and data, the model self-corrects and RMSE will decrease.

In the high-dimensional problems (GSobol15 and Morris), we see a substantial degradation of performance for the baseline methods (qr, fvar, and fig), with little reduction of RMSE across iterations. Active learning targeting the DGSM quantities, on the other hand, continued to perform well in high dimensions. On these problems the derivative max variance acquisition functions (dv, dav, and dsqv) were competitive with or outperformed the derivative information gain acquisition functions. We hypothesize this is due to the myopic nature of the one-step look-ahead used for information gain.

Figure 3: RMSE results as in Fig. 2, here for the absolute derivative acquisition functions. These also outperformed the baselines, with absolute derivative information gain generally the best.

Figure 2: RMSE (mean over 50 runs, two standard errors shaded) for learning the DGSM, for 10 test problems. Results are shown for active learning methods targeting the raw derivative. Active learning targeting the derivative consistently outperformed space-filling designs and active learning targeting \(f\). Derivative information gain was generally the best-performing acquisition function.

Information gain is maximized near existing points (Fig. 1), and so in high dimensions, one-step look-ahead is not sufficiently exploratory to capture the whole function. Max variance is naturally more exploratory and thus can perform better in high-dimensional settings. However, the derivative information gain acquisitions still outperformed the baselines on these problems. In practice, derivative information gain measures are likely to be the best choice, possibly ensembled with a derivative max variance acquisition in high dimensional problems .

### Additional Results

In the Appendix, we also evaluate the ability of active learning to identify the correct ordering of variable importance, by using normalized discounted cumulative gain (NDCG)  as the evaluation metric. The results were generally consistent with what is seen with RMSE. We further evaluated global versions of these same acquisition functions, and found that they did not substantially improve over the results shown here, while creating a large computational burden. Finally, we evaluated a heuristic baseline that incorporates the insight of Fig. 1 by using a space-filling design plus small perturbations of those same points. This did not significantly improve performance over QR.

## 6 Conclusions

In this work, we developed a collection of active learning methods that directly target DGSMs. These strategies substantially enhanced the sample efficiency of DGSM estimation when compared to quasirandom search and even compared to active learning strategies targeting \(f\). Information gain about the derivative (raw, absolute, or squared) was generally the best approach.

Our work paves the way for additional work on active learning for DGSMs in several directions. Although both variance reduction and information gain approaches perform well in high dimensions, information gain approaches might benefit from increased exploration by using a two-step or batch look-ahead to select pairs of points in acquisition function optimization. Our acquisition functions also all take the form of a sum over dimensions. Computing the entropy of multivariate posteriors for the gradient is another possible avenue. Active learning for DGSMs could also be developed for non-Gaussian models. Finally, DGSMs have been linked via several lower/upper bound inequalities to ANOVA-based sensitivity indices . Understanding the impact of active learning for DGSMs on ANOVA-based sensitivity indices is another useful direction for future work.

**Acknowledgments.** Belakaria is supported by a Stanford Data Science Postdoctoral Fellowship. Doppa is supported in part by USDA-NIFA funded AgAID Institute award #2021-67021-35344 and NSF CAREER award IIS-1845922.

Figure 4: RMSE results as in Fig. 2, here for the squared derivative acquisition functions. As with the other derivative active learning approaches, these outperformed the baselines, and squared derivative information gain generally performed best.