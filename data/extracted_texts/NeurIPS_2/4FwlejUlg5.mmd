# Causal Effect Estimation with Mixed Latent Confounders and Post-treatment Variables

Anonymous Author(s)

Affiliation

Address

email

###### Abstract

Causal inference from observational data has attracted considerable attention among researchers. One main obstacle is the handling of confounders. As direct measurement of confounders may not be feasible, recent methods seek to address the confounding bias via proxy variables, i.e., covariates postulated to be conducive to the inference of latent confounders. However, the selected proxies may scramble both confounders and post-treatment variables in practice, which risks biasing the estimation by controlling for variables affected by the treatment. In this paper, we systematically investigate the bias due to latent post-treatment variables, i.e., _latent post-treatment bias_, in causal effect estimation. Specifically, we first derive the bias when selected proxies scramble both confounders and post-treatment variables, which we demonstrate can be arbitrarily bad. We then propose a novel Confounder-identifiable VAE (CiVAE) to address the bias. Based on a mild assumption that the prior of latent variables that generate the proxy belongs to a general exponential family with at least one invertible sufficient statistic in the factorized part, CiVAE _individually_ identifies latent confounders and latent post-treatment variables up to bijective transformations. We then prove that with individual identification, the intractable disentanglement problem of latent confounders and post-treatment variables can be transformed into a tractable independence test problem. Finally, we prove that the true causal effects can be unbiasedly estimated with transformed confounders inferred by CiVAE. Experiments on both simulated and real-world datasets demonstrate significantly improved robustness of CiVAE.

## 1 Introduction

Causal inference, which aims to infer cause-and-effect relations from data, has gained increasing prominence in various fields, such as social science, economics, and public health [10; 17; 34]. Traditional methods rely on the golden standard of randomized control trials (RCT) to draw valid causal conclusions via experimentation . Recently, more attention has been dedicated to causal inference from observational data, where treatments, outcomes, and unit features are passively observed, and researchers have no control over the treatment assignment mechanism [36; 37; 40].

One main obstacle to inferring valid causal relations from observational data is the confounding bias, which occurs when we fail to account for the systematic difference between the treatment and non-treatment group due to variables that causally influence the past treatments and the outcome, i.e., unobserved confounders . If the confounders can be measured, a simple strategy to address the bias is to control them via covariate adjustment  or propensity score re-weighting . However, confounders are not always measurable . Therefore, recent methods seek to adjust for the influence of unobserved confounders based on their proxies, which are easily acquirable covariates postulated to be causally related with the unobserved confounders [29; 42; 28]. One exemplar workis the causal effect variational auto-encoder (CEVAE) , which has demonstrated that confounding bias can be mitigated by controlling latent variables inferred from the proxies of confounders.

Although proxy-based methods have achieved substantial progress in recent years, they may risk controlling latent post-treatment variables scrambled in the proxies, where **latent post-treatment bias** can be introduced. Here, we note that the negative effects of controlling _observed_ post-treatment variables have been investigated in prior research . For example, Montgomery et al.  found that more than 50% of the papers published in top journals of politics _inadvertently control post-treatment variables_ in the experimental setting, even though researchers have complete control over which covariates to control for. On this basis, we postulate that the post-treatment bias could be even worse for proxy-based methods in the setting of observational study where variables are passively recorded. In addition, the post-treatment variables can be **latent** and scrambled into the observed covariates together with the latent confounders, which makes them difficult to disentangle.

Consider a real-world example from the Company1. We found that _changing_ a job from onsite to online mode causes applicants to make different decisions, and we want to estimate the causal effects of _switching a job from onsite to online mode_ to _the decisions of the applicants_ (reflected by statistics of applicants that apply for the job). In this case, the Company collected two groups of online (treated) and onsite (control) jobs, where the statistics of the applicants (e.g., the average age) are calculated as the surrogate outcome. Clearly, job seniority is a confounder, since less senior jobs are more likely to permit online work, and applicants for these jobs tend to be younger. However, the seniority level of a job can be difficult to measure. Therefore, the required skills of the job can be used as the proxy of the confounder "seniority", as senior jobs tend to require more advanced skills. However, **a caveat** is that switching to an online work mode may also alter the required skills of a job, thereby affecting the qualification and, therefore, the decision of the applicants. Consequently, directly using the skills as the proxy of the confounder "seniority" for adjustment could unintentionally control latent mediators (changed skills), which introduces latent post-treatment bias in the causal effect estimation.

Addressing the **latent post-treatment bias** faces multi-faceted challenges. First, there lacks a theoretical formulation of the bias when selected proxies scramble latent post-treatment variables for existing proxy-based methods. In addition, it is difficult to distinguish confounders and post-treatment variables in the latent space due to their similar observed behaviors. Existing covariate disentanglement-based methods, e.g., TEDVAE , focus on an easier task of disentangling latent confounders with latent adjusters and instrumental variables, which can be achieved by leveraging their different predictive abilities w.r.t. the treatment and outcome. However, since both latent confounders and post-treatment variables correlate with the treatment and the outcome, they cannot be disentangled by these methods. Finally, even if latent confounders can be distinguished from post-treatment variables, since most existing latent variable models have no identifiability guarantee , it is unclear whether controlling the inferred latent variables, which may be arbitrary transformations of the true confounders, can provide unbiased estimations of true causal effects.

To address the aforementioned challenges, we first analyze existing proxy-based methods when selected proxies scramble both latent confounders and post-treatment variables and show the estimation can be arbitrarily biased. We then propose a novel Confounder-identifiable VAE (CiVAE) to address the latent post-treatment bias. Specifically, we prove that based on a mild assumption that the prior of latent variables that generate the observed proxy (i.e., the latent confounders and post-treatment variables) belong to a general exponential family with at least one invertible sufficient statistic in the factorized part, latent confounders and latent post-treatment variables can be _individually_ identified up to _simple bijective transformations_. With such identifiability guarantee, based on the causal relations among confounders, mediators, and treatment, we further demonstrate that the inferred confounders

Figure 1: Comparison between the causal models assumed by CEVAE, TEDVAE, and CiVAE.

(which are actually transformed proxies of the true confounders) could be properly distinguished from the latent post-treatment variables with pair-wise conditional independence tests. Finally, we prove that the true causal effects can be unbiasedly estimated based on transformed confounders inferred by CiVAE. Experiments on both simulated and real-world datasets demonstrate that CiVAE shows more robustness to latent post-treatment bias than existing methods.

## 2 Problem Formulation

In this paper, we assume the causal model in Fig. 1-(c). We use a binary random variable \(T\) to denote the treatment, a random vector \(^{K_{X}}\) to denote the observed covariates (i.e., the proxy), and a random scalar \(Y\) to denote the outcome. Furthermore, the observed covariates \(X\) are assumed to be generated from \(K_{C}\) independent latent confounders \([C_{1},C_{2}...,C_{K_{C}}]\) causally influencing both \(T\) and \(Y\), and \(K_{M}\) latent post-treatment variables \([M_{1},M_{2}...,M_{K_{M}}]\) under the causal influence of the treatment (where the relation between \(\) and \(Y\) can be arbitrary). We use the random vector \([||]^{K_{Z}=K_{C}+K_{M}}\) to denote all latent factors. **Our aim** is to estimate the average causal effects of treatment \(T\) on outcome \(Y\) with auxiliary confounder information in \(\), where the estimation should be devoid of both confounding bias and post-treatment bias.

## 3 Theoretical Analysis of Latent Post-Treatment Bias

### Preliminaries and Assumptions

To achieve such a purpose, we first define the (conditional) average treatment effects (C/ATE) when covariates \(\) scramble both latent confounders \(\) and post-treatment variables \(\). We then define the post-treatment bias when covariates \(\) are directly used as the proxy of confounders. To facilitate the analysis, we make the following assumption regarding the causal generative process.

**Assumption 1**.: _(**Noisy-Injectivity**). We assume \(=f(,)+\), where \(f\) is a deterministic function that combines latent confounders \(\) and latent post-treatment variables \(\) into observations \(\), and \(\) is random noise. In addition, we assume that the function \(f\) is **injective**; beyond injectivity, \(f\) can be arbitrarily nonlinear. We use \(f^{}:[||]\) to denote its left inverse. We use \(f^{}_{C}:\) and \(f^{}_{M}:\) to denote the mapping from \(\) to \(\), \(\), respectively._

_Noisy-Injectivity_ is a common assumption made either explicitly or implicitly in most existing proxy-of-confounder-based causal inference algorithms. For example, if both \(\) and \(\) are categorical,  assumes that \(\) has at least the same number of categories as \(\), whereas the effect restoration algorithm  assumes that the matrix of \(p(,)\) to be full-rank. Although CEVAE  makes no explicit injectivity assumption between \(\) and \(\), it requires that the joint distribution \(p(,,T,Y)\) can be fully recovered from the observations \((,T,Y)\).  show that some of the possible identification criteria for the recovery include **1)** having multiple independent views of \(\) in \(\), and **2)**\(\) is categorical and \(\) is a mixture of Gaussian components determined by \(\) (that is, \(\) is generated by bijective mapping of \(\) to the mean of the corresponding component with added Gaussian noise).

In the following part of this section, we omit the noise \(\) to gain better intuition of latent post-treatment bias (but all the exact conclusions will still hold in the posterior sense ). In Section 4, we assume noise exists and demonstrate that our method can still properly identify the latent confounders.

### Causal Estimand and the True ATE

Based on Assumption 1, we are ready to define the estimand of average treatment effect (ATE) through controlling the covariates \(^{}\), as well the as the true (conditional) average treatment effects.

**Definition 1**.: _(**DCEV & DEV**). We define the Difference in Conditional Expected Values (DCEV) as:_

\[DCEV(^{})=[Y|T=1,^{}=^{ }]-[Y|T=0,^{}=^{}], \]

_which is the difference of the expected value of \(Y\) for units with variable \(^{}=^{}\) in the treatment group and the non-treatment group. Based on \(DCEV(^{})\), we define the Difference in Expected Value (DEV) as \(DEV(^{})=_{p(^{})}[DCEV(^{})]\) as the expectation of \(DCEV\) w.r.t. \(p(X^{})\)._\(DEV(^{})\) denotes the estimand of ATE when \(^{}\) is the covariates that we choose to control (i.e., calculate the expected difference in each stratum of \(^{}=^{}\)). If \(^{}=\), \(DEV()\) represents the _naive estimator_ that directly calculates the expected difference of the outcome \(Y\) between the treatment group and the non-treatment group. With the causal estimand \(DEV(^{})\) defined, we then derive the true causal effects with the covariates \(^{}\) when it scrambles both latent confounders and post-treatment variables according to the generative process described in Assumption 1:

**Definition 2**.: _Under Assumption 1, we define the Conditional Average Treatment Effect (CATE) for individuals with observed covariates \(=\) by controlling only the confounder part in \(\) as:_

\[CATE()=[Y|T=1,=f_{C}^{}()]-[Y|T=0,=f_{C}^{}()], \]

_with the Average Treatment Effect (ATE) of treatment \(T\) defined as:_

\[ATE=[Y|do(T=1)]-[Y|do(T=0)]=_{p()}[ [Y|T=1,]-[Y|T=0,]]. \]

Please note that we only consider the latent confounder component of the observed features \(\) in the definition of CATE in Eq. (2). This is because the causal relationship between the post-treatment variables \(\) and the outcome \(Y\) is indeterminate. However, if the specific relationship between \(\) and \(Y\) can be further established by the researcher (e.g., all elements of \(\) are latent mediators), more precise forms of CATE can be derived with path-specific counterfactual analysis .

### Latent Post-Treatment Bias

With \(DEV(^{})\) (the ATE estimator that control for the covariates \(^{}\)), CATE, and ATE defined in Section 3.2, in this section, we analyze the _latent post-treatment bias_ of existing proxy-of-confounder-based causal inference methods, such as CEVAE, that control for latent variables inferred from the covariates \(\) to estimate the ATE of \(T\) on \(Y\), when \(\) scrambles both latent confounders and post-treatment variables as Assumption 1. In our analysis, Lemma 3.1 will be frequently used.

**Lemma 3.1**.: _For an injective function \(g\), \([Y|^{}=^{}]=[Y|g(^{})=g (^{})]\) holds._

The proof when \(g\) is differentiable _a.e._ can be referred to in Appendix C.1. Since the latent variable models used in existing methods (such as VAE with factorized Gaussian prior in CEVAE) lack identifiability guarantee (i.e., the recovery of the exact latent variables), we assume that these models can recover the true latent space \(=[,]\) up to invertible transformations \(\), where the inference process can be represented as \(}=f()= f^{}()\). With such an assumption, we have the following theorem regarding the latent post-treatment bias when \(\) mixes post-treatment variables.

**Theorem 3.2**.: _If the observed covariates \(\) are generated from latent confounders \(\) and latent post-treatment variables \(\) according to Assumption 1, the latent post-treatment bias of a proxy-based causal inference algorithm that controls latent variables \(}\) inferred from \(\) via \(= f^{}:^{K_{X}}^{ K_{C}+K_{M}}\) to estimate the ATE can be formulated as follows:_

\[()&=ATE-DEV(())=ATE-[[Y|T=1,()]-[Y|T= 0,()]]\\ &=ATE-[[Y|1, f^{}(f(,))]-[Y|0, f^{}(f(,))]]\\ &=[[Y|1,]-[Y|0,]]- [[Y|1,,]-[Y|0,,]], \]

_which can be arbitrarily bad. Therefore, the estimator of existing proxy-of-confounder-based methods, i.e., \(DEV(())\), is an arbitrarily biased estimator of the ATE, when the selected proxy of confounders \(\) accidentally mixes in latent post-treatment variables \(\)._

The final step of Eq. (4) can be proved since \(f\) is injective and \(\) bijective, the composite \( f^{} f:[,]}\) is bijective, so we can use Lemma 3.1 to remove \( f^{} f\) in the condition.

### Examples in the Linear Case

Generally, the latent post-treatment bias defined in Eq. (4) cannot be simplified, because _(i)_ the causal relationship between \(\) and \(Y\) are indeterminate, and _(ii)_ the causal influence of \(\), \(\), and \(T\) on \(Y\) can be arbitrary. However, for linear structural causal models with determined causal relationships between \(\) and \(Y\) (e.g., \(\) are mediators, which are post-treatment variables that have causal influences on the outcomes), stronger conclusions can be drawn as follows:

**Corollary 3.3**.: _(**Mixed Latent Mediator**). For the linear Structural Causal Model (SCM) defined as:_

\[&(i)\;T(_{T}+_{i}  C_{i}>a),\;(ii)\;M_{j}_{M}+_{j} T\\ &(iii)\;_{X}+[|| ],\;(iv)\;Y_{Y}+ T+_{j} M_{j}+ _{i} C_{i}, \]

_where the mixture function \(f=^{K_{X}(K_{C}+K_{M})}\) is a full column-rank matrix, the CATE, ATE, and the bias of proxy-of-confounder-based causal inference model that controls the latent variables \(}\) inferred via \(}=()=^{T}\) can be formulated as follows:_

\[& ATE=CATE=+_{j}_{j},\; \;DEV(})=[DCEV(})]=DCEV(})=\\ & Bias(})=ATE-DEV(})=_{j} _{j}, \]

_where \(^{K_{X}(K_{C}+K_{M})}\) is another full column-rank matrix. Since \(_{j}_{j}\) is arbitrary, the estimator \(DEV(})=[DCEV(^{T})]\) is arbitrarily biased for ATE estimation._

The proof of Eq. (6) is provided in Appendix C.2. In addition, we show that post-treatment variables \(\) DO NOT necessarily need to have direct causal effects on the outcome \(Y\) to incur arbitrary bias in ATE estimation. In Appendix C.3, we provide another example (i.e., Mixed Latent Correlator) in the linear case where \(\) is correlated with \(Y\) through unobserved confounders \(\) in Corollary C.1.

## 4 Methodology

In this section, we introduce the proposed Confounder-identifiable Variational Auto-Encoder (**CIVAE**) in detail. Specifically, we first prove that if the prior distribution of the true latent variables \(=[,]\) satisfies certain weak assumptions, CiVAE _individually_ identify \([,]\) up to bijective transformations. Then, utilizing the causal relations between \(\), \(}\), and \(T\), we novelly transform the challenging confounder-identifiability problem into a tractable pair-wise conditional independence test problem, which can be effectively solved with kernel-based methods. The generalization of CiVAE to address the interactions among \([,]\) are discussed in Section D of the Appendix.

### Generative Process

The fundamental work on the identifiability of deep variational inference, i.e., the identifiable VAE (iVAE) , makes a strict assumption that the prior of true latent variables \(\) (i.e., \([,]\) in our case) is conditionally factorized given the available covariates. However, since both \(\) and \(\) form fork structures with the outcome \(Y\) (see Fig. 1-(c)) , \(C_{i}\), \(C_{j}\), \(M_{i}\), and \(M_{j}\) are not independent given \(Y\). Recently, Non-Factorized iVAE (NF-iVAE)  was proposed that allows arbitrary dependence among the true latent variables \(\) in the conditional priors, where \(\) can be identified up to arbitrary non-linear transformations. However, the transformation is not necessarily invertible, which is risky as multiple values of the confounders may collapse, leading to bias when estimating the ATE by averaging the \(DCEV\) calculated in each stratum of the inferred confounders.

In contrast to NF-iVAE, CiVAE guarantees the individual and bijective identifiability of \(\) by putting a general exponential family _with at least one invertible sufficient statistic in the factorized part_ as its prior when conditioning on treatment \(T\) and outcome \(Y\), which can be formulated as follows.

**Assumption 2**.: _Let \(=[||]\) be the random vector for latent variables that causally generate the observed covariates \(\) according to Assumption 1. We assume that the conditional prior of \(\) given the outcome \(Y\) and the treatment \(T\) belongs to a general exponential family with parameter vector \((Y,T)\) and sufficient statistics \(()=[_{f}()^{T},_{nf}()^{T}]^{T}\). Specifically, \(()\) is composed of (i) the sufficient statistics of a factorized exponential family, i.e., \(_{f}()=[_{1}(Z_{1})^{T},,_{K_{Z}}(Z_{K_{Z}})^{T }]^{T}\), where all components \(_{i}(Z_{i})\) have dimension larger than or equal to 2 and **each \(_{i}\) has at least one invertible dimension**, and (ii) \(_{nf}()\), where \(_{nf}\) is a neural network with ReLU activation. The density of the conditional prior can be formulated as:_

\[p_{,}(|Y,T)=()/(Y,T)[ ()^{T}(Y,T)], \]

_where \(()\) is the base measure, and \((Y,T)\) is the normalizing constant independent of \(\)._We justify that assumption 2 is weak and practical as follows. _(i)_ Neural networks with ReLU activation have **universal approximation ability** of distributions . Therefore, Eq. (7) can model arbitrary dependence between true latent confounders \(\) and post-treatment variables \(\) conditional on \(T\) and \(Y\). _(ii)_ Although CiVAE makes an extra assumption that \( i\), at least one dimension of \(_{i}\) is invertible, this can be easily satisfied as most commonly used exponential family distributions, such as Gaussian, Bernoulli, etc., has at least one invertible sufficient statistics2.

The reason why we use ReLU as the activation is that, the identifiability of iVAE relies on the condition that the sufficient statistics \(\) have zero second-order cross-derivative. The factorized part, i.e., \(_{f}\), satisfies it trivially as all cross-derivatives of \(_{f}\) are zero. In addition, since the ReLU neural networks are linear _a.e._, all second-order derivatives of \(_{nf}\) are zero. Therefore, identifiability holds after adding \(_{nf}\) in the prior that allows the capturing of arbitrary dependence among \(\).

### Optimization Objective

Combining Assumptions 1 and 2, the generative process assumed by CiVAE can be formulated as:

\[(i)\;p_{}(, Y,T)=p_{f}(),(ii)\;\;p _{,}( Y,T),\;(iii)\;p_{f}()=p_{ }(-f()). \]

where \(=(f,,)\) are the parameters of the generative distribution. Since the generative process of CiVAE is parameterized by deep neural networks, the posterior distribution of \(\), i.e., \(p_{}(,Y,T)\), is intractable. Therefore, we resort to variational inference , where we introduce an approximate posterior \(q_{}(,Y,T)\) parameterized by a deep neural network with a trainable parameter \(\), and in \(q_{}()\) finds the one closest to \(p_{}()\) measured by KL divergence. The minimization of KL is equivalent to maximization of the evidence lower bound (ELBO):

\[(,):=_{q_{}} p_{ f}()+,}( Y,T)-  q_{}()}_{}. \]

Since the normalization constant \(\) in Eq. (7) is generally intractable, it is infeasible to directly learn \(\), \(\) by optimizing Eq. (9). Therefore, we substitute the KL term in Eq. (9) with the widely-used score matching  to learn unnormalized densities instead as follows:

\[(,,):=_{q_{}()}[\|_{} q_{}( )-_{} p_{,}( Y,T)\|^{2}]\] (10) \[=_{q_{}()}[_{j=1}^{K_ {Z}}[p_{,}( Y,T)The proof of Theorem 4.1 non trivially extends the NF-iVAE paper  by incorporating the new assumption introduced in CiVAE (i.e., each \(_{i}\) has at least one invertible dimension) to ensure that the transformation of each \(Z_{i}\) is bijective. The detailed proof is provided in Appendix C.4 for reference.

### Identification of Latent Confounders

Theorem 4.1 ensures that the latent variables \(}\) inferred by CiVAE cannot _(i)_ mix confounders and post-treatment variables in each dimension, or _(ii)_ collapsing of different values of the latent confounders into the same value. To further determine the dimensions of confounder and post-treatment variable in \(}\), we rely on the causal relations between latent variables \(}\) and the treatment \(T\) and the associated marginal/conditional dependence properties, which are discussed as follows.

* _Case 1. Intra-Confounders._ Latent confounders \(C_{i}\), \(C_{j}\) and the treatment \(T\) form the _V structure_\(C_{i} T C_{j}\). Therefore, \(C_{i}\) and \(C_{j}\) are marginally **independent**, whereas they become **dependent** when conditioning on the assigned treatment \(T\).
* _Case 2. Intra-Post Treatment Variables._ Latent post-treatment variables \(M_{i}\), \(M_{j}\) and the treatment \(T\) form a _Fork-structure_\(M_{i} T M_{j}\), where \(M_{i}\), \(M_{j}\) are marginally **dependent**, but they become **independent** after conditioning on the assigned treatment \(T\).
* _Case 3. Cross-Confounder and Post-Treatment Variables._ Latent confounder \(C_{i}\), latent post-treatment variable \(M_{j}\), and the treatment \(T\) forms a Chain structure \(C_{i} T M_{j}\), where \(C_{i}\), \(M_{j}\) are marginally dependent, and they become **independent** after conditioning on \(T\).

From the above analysis we can find that, the dependence between two latent variables \(_{i}\) and \(_{j}\)**increases** after conditioning on the treatment \(T\) ONLY in the case of _intra-confounders_. Therefore, if more than one latent confounder exists, which is highly probable when covariates \(\) are high-dimensional, we can conduct independence test \((_{i},_{j})\) and \((_{i},_{j}|T)\) for all pairs of inferred latent variables, which can be implemented via kernel-based methods as , and select the pairs where the p-value of CInd is larger than that of Ind as latent confounders. Here, we note that the kernel-based (conditional) independence test incurs \(N^{2} K_{Z}^{2}\) complexity in the training phase. However, once the dimensions of the confounders in \(}\) are determined, CiVAE **has the same complexity as CEVAE** for the estimation of CATE and ATE in the test phase.

### ATE Estimator with Transformed Confounders

Finally, we demonstrate that controlling the transformed confounders \(}\) inferred by CiVAE provides an unbiased estimation of ATE. Specifically, we have the final Theorem show the unbiasedness.

**Theorem 4.2**.: _Controlling bijective of confounders is equivalent to original confounders in ATE estimation, i.e., \(DEV(})=DEV(g())=ATE\), if the transformation function \(g\) is bijective._

The proof of Theorem 4.2 for discrete \(\) is trivial (where \(}=g()\) represents a simple relabeling of the stratum that we calculate the \(DCEV\) and take the expectation). The proof in the continuous case where \(g\) is differentiable is provided in Appendix C.5. With Theorem 4.2, we can control the identified latent confounders as true confounders, providing an unbiased estimate of ATE.

## 5 Empirical Study

In this section, we provide and analyze the experiments we conduct on both simulated and real-world datasets, where a code demo written in PyTorch and Pyro is provided in this anonymous URL.

### Datasets

**Simulated Datasets.** We first establish two simulated datasets, i.e., LatentMediator and LatentCorrelator, that consider two types of post-treatment variables, i.e., _(i)_ mediators and _(ii)_ correlators, i.e., variables that are correlated with the outcome \(Y\) via latent confounders \(\), where the causal generative process is under the full control of the experimenter. The generative process of the two datasets can be referred to in Corollary 3.3 and Corollary C.1 in the Appendix, respectively. In our experiments, \(\) are generated from Gaussian distribution as \( Gaussian(0,_{K_{C}})\). For 

**LatentMediator**, \(\) is set as \([-1,-1,-1]\), \(\) is set as \(\), and \(\) is set as 2, which results in \(ATE=-1\). For the LatentCorrelator dataset, we set the same \(\) and \(\) as the LatentMediator dataset, where parameters \(\) and \(\) are set to 1, which results in an overall \(ATE\) of \(1\).

**Real-world Datasets.** In addition, we build real-world datasets from the Company to estimate the ATE of _switching a job from **onsite** to **online** work mode_ to _the statistics of the applicants_. The average age and the variance of gender of the applicants are two outcomes of interest. Covariates \(\{0,1\}^{K_{X}}\) include the required skills of the job. Specifically, we establish a cohort of 3,228 jobs from the Bay Area in the US, where a preliminary study shows that \(DEV() 2\) years3 (i.e., online job applicants are two years younger than onsite job applicants in the collected data), and \(DEV()-0.015\) (i.e., online jobs exhibit 0.015 more gender variance than onsite jobs in the collected data). To simulate \(\) and \(\), we first learn a generative model as follows:

\[ Gaussian(,_{K_{Z}}), Multi(NN_{f}() ),Y Gaussian(,1), \]

where \(Multi\) represents multinomial distribution, \(NN_{f}\) is a neural network with softmax activation, \(,^{K_{Z}}\), \(K_{Z}=8\), and \(\) represents the element-wise product operator, respectively. We then treat the first \(K_{C}=5\) dimensions of \(\) as the latent confounders \(\) and the remaining \(K_{M}=K_{Z}-K_{C}\) dimensions as the latent mediators \(\). After learning \(NN_{f}\) and \(\) according to Eq. (11), we draw latent confounders \( Gaussian(0,)\), latent mediators \(=T\), and set the outcome \(Y=[||]+ T\), where the true ATE can be calculated as \(sum(_{-K_{M}:})+\).

#### 5.1.1 Disentangle Confounders and Post-treatment Variables

We first show the \(p\)-value of the kernel-based pairwise independence test of the true latent variables before and after conditioning on the assigned treatment \(T\). From Fig. 2, we can find that the distinction of the intra-confounder case from the other two cases discussed in Subsection 4.4 is significant. Here, we should note this relies on the assumption that latent confounders are independent. If the latent confounders are correlated, we can first use causal discovery techniques such as the PC algorithm  to find direct parents of \(T\), and use our algorithm as the refinement to determine the true confounders \(C\) from the misidentified post-treatment variables (Experiments see Section D) in Appendix.

### Baselines

The baselines we include for comparisons can be categorized into three classes. **(i) Unawareness**, where no information in \(\) is used for ATE estimation. We implement the naive LR0 estimator, which regresses \(Y\) on \(T\) and uses the coefficient to estimate the ATE  (LR0 equals to \(DEV()\), i.e., the difference of the average outcome between the treatment and non-treatment group). **(ii) Control-\(\)**, which directly controls the covariates \(\). In this class, LR1 regresses \(Y\) on \(T\) and \(\), whereas TarNet uses a two-branch neural network to estimate the \(DEV()\)**(iii) Control-\(\)**, which controls latent variables \(\) learned from the covariates \(\). Methods from this class include the CEVAE  and covariate disentanglement methods, such as DR-CFR , TEDVAE , NICE , and AFS .

#### 5.2.1 Results and Analysis

From Table 1, we can find that for all four datasets, CEVAE is worse than the naive LR0 estimator. In addition, for the LatentMediator and Company (Age) dataset, all methods except CiVAE fail to predict the negativity of the ATE. Covariates disentanglement-based methods, i.e., DR-CFR and TEDVAE, inherit the latent post-treatment bias of CEVAE. The reason is that, these methods disentangle latent confounders \(\) from latent instrumental variables \(\) and latent adjusters \(\) by

Figure 2: Visualization of \(p\)-value of independence test before and after conditioning on treatment \(T\).

utilizing their causal relations with \(T\) and \(Y\), i.e., \(\) is predictive only for \(T\), \(\) is predictive only for \(Y\), whereas \(\) is predictive for both \(T\) and \(Y\). For example, TEDVAE includes three encoders to infer three sets of latent variables \(}\), \(}\), \(}\) from \(\) and adds classification losses \(p(T|},})\) and \(p(Y|T,},})\) on the CEVAE loss. However, since both latent confounders \(\) and latent post-treatment variables \(\) are correlated with both \(T\) and \(Y\), these methods cannot disentangle \(\) from \(\). An exception is NICE , which uses invariant risk minimization (IRM)  to find all causal parents of the outcome \(Y\) as the confounders, which makes it more robust in the LatentCorrelator case. However, since mediators \(\) are also the causal parent of \(Y\), the performance degrades substantially on the LatentMediator dataset. Although AFS  considers the existence of post-treatment variables \(\) in the proxy \(\), it assumes that they can be separated from other variables in \(\) in the observational space, and no relationship exists between the post-treatment variables and the outcome, so it still has poor performance in our setting since both assumptions are violated.

### Sensitivity Analysis

In this part, we vary the number of confounders and post-treatment variables that generate proxy \(\) in the Company (Age) and Company (Gender) datasets and compare CiVAE with the baseline TEDVAE in Fig. 3. Fig. 3 shows that the error is consistently lower for CiVAE. In addition, the error is comparatively higher when the number of confounders is low since the misidentification of latent post-treatment variables as confounders can have a comparatively larger influence on the ATE estimation. In addition, when the number of confounders becomes larger, the performance gap between CiVAE and TEDVAE gracefully shrinks.

## 6 Conclusions

In this paper, we systematically investigate the latent post-treatment bias in causal inference from observational data. We first prove that unresolved latent post-treatment variables scrambled in the proxy of confounders can arbitrarily bias the ATE estimation. To address the bias, we proposed the Confounder-identifiable VAE (CiVAE), which, utilizing a mild assumption regarding the prior of latent factors, guarantees the identifiability of latent confounders up to bijective transformations. Finally, we show that controlling the latent confounders inferred by CiVAE can provide an unbiased estimation of the ATE. Experiments on both simulated and real-world datasets demonstrate that CiVAE has superior robustness to latent post-treatment bias compared to state-of-the-art methods.

  Dataset & LatentMediator & LatentCorrelator & Company (Age) & Company (Gender) \\  Method & ATE. & Err. & ATE. & Err. & ATE. & Err. & ATE. & Err. \\   LR0 & 0.975 \(\) 0.032 & 1.975 & 2.977 \(\) 0.032 & 1.977 & 0.131 \(\) 0.015 & 0.399 & -0.105 \(\) 0.009 & -0.213 \\  LR1 & 1.457 \(\) 0.167 & 2.457 & 3.400 \(\) 0.130 & 2.400 & 0.093 \(\) 0.029 & 0.361 & -0.175 \(\) 0.014