# Team formation amidst conflicts

Anonymous Author(s)

###### Abstract.

In this work, we formulate the problem of _team formation amidst conflicts_. The goal is to assign individuals to tasks, with given capacities, taking into account individuals' task preferences and the conflicts between them. Using dependent rounding schemes as our main toolbox, we provide efficient approximation algorithms.

Our framework is extremely versatile and can model many different real-world scenarios as they arise in educational settings and human-resource management. We test and deploy our algorithms on real-world datasets and we show that our algorithms find assignments that are better than those found by natural baselines. In the educational setting we also show how our assignments are far better than those done manually by human experts. In the human-resource management application we show how our assignments increase the diversity of teams. Finally, using a synthetic dataset we demonstrate that our algorithms scale very well in practice.

team formation, conflicts, task assignment, diversity +
Footnote †: isbn: 978-1-4503-XXXX-X/18/06

+
Footnote †: isbn: 978-1-4503-XXXX-X/18/06

+
Footnote †: isbn: 978-1-4503-XXXX-X/18/06

+
Footnote †: isbn: 978-1-4503-XXXX-X/18/06

+
Footnote †: isbn: 978-1-4503-XXXX-X/18/06

+
Footnote †: isbn: 978-1-4503-XXXX-X/18/06

+
Footnote †: isbn: 978-1-4503-XXXX-X/18/06

+
Footnote †: isbn: 978-1-4503-XXXX-X/18/06

+
Footnote †: isbn: 978-1-4503-XXXX-X/18/06

+
Footnote †: isbn: 978-1-4503-XXXX-X/18/06

+
Footnote †: isbn: 978-1-4503-XXXX-X/18/06

+
Footnote †: isbn: 978-1-4503-XXXX-X/18/06

+
Footnote †: isbn: 978-1-4503-XXXX-X/18/06

## 1. Introduction

In large project-based classes instructors often need to create _teams_ of students and assign them to a finite number of projects they have available. Students are happy if they are in a team with friends and they work on a project they like. Additionally, student teams are efficient if there are no time conflicts between the team members; i.e., conflicts that stem from their class schedule. Traditionally, such assignments are done in an adhoc manner or manually by some admin who can spend several days on the task.

Motivated by such applications in the education domain, we formally define the above problem as a combinatorial optimization problem. For this, we assume two inputs: the _preference graph_ and the _conflict graph_. The former captures the preferences of users to projects; this is a bipartite graph with edge weights that are proportional to how much a student likes a project. The latter captures the conflicts between students, i.e., there is a (weighted) edge between two students if they are incompatible. Our goal is to find an assignment of students to projects such that every student is assigned to one project and every project is not assigned more students than its capacity. The objective is to maximize sum of the weights of the edges of the preference graph that participate in the assignment and and the sum of the weights of the conflict edges across the formed teams. Students assigned to the same project form a team so we call this problem the Team Formation amidst Conflicts (TFC) problem and we show it is NP-hard.

In this paper, we present an algorithmic framework for approximating TFC. This framework, consists of two steps: first, our objective is replaced by a concave objective - which can be optimized in polynomial time and produce a fractional solution. Then, the fractional solution is rounded, using dependent-rounding techniques (Gardner, 1999; Gardner, 1999). For our framework to work we need the original objective and its concave relaxation to match one integral inputs.

This general framework is not new. In fact, it is inspired by the _Max-k-Cut with given part sizes_ problem (Gardner, 1999). In fact, our problem is identical to the _Max-k-Cut with given part sizes_, except for the fact that we also have an additional linear term in our objective. We show that their approximation algorithm can be applied to our problem. Our contribution is a much more efficient randomized algorithm with better approximation ratio on expectation.

To the best of our knowledge the dependent-rounding techniques we use here, such as pipage and randomized pipage, have not been widely used in practical applications; they primarily stem from work in theoretical computer science (Gardner, 1999; Gardner, 1999). We see the deployment of these techniques in practice as a contribution by itself.

Using real, anonymized data, from large classes 1, we demonstrate that our algorithms work extremely well in practice. In our experiments, we show that the solutions we obtain are much better compared to the manual solutions produced by a course admin across different dimensions and metrics.

Our problem formulation is general and goes beyond educational settings. For example, we can use our framework in human-resource management in order to increase the diversity of departments in companies; depending on the dimension across which we want to diversify we can appropriately define the conflict graph. In our experiments, we show how to achieve gender diversity in a company's departments using this idea.

The generality of our framework calls for efficient algorithms. Part of our contribution is a set of speedup techniques that allow us to apply our approximation algorithms to reasonably large data. In our experimental evaluation we demonstrate that these techniques work extremely well in practice.

**Discussion:** We note here that it was a design decision from our part to consider the conflict graph and maximize conflicts across teams (instead of friends within teams). We believe that this choice gives us greater modeling flexibility to apply our model to a variety of settings. For example, the conflict graph better models time conflicts among collaborators as well as diversity constraints.

## 2. Related Work

To the best of our knowledge, we are the first to define and approximate the TFC problem. However, our work is related to works in _team formation_, in the data-mining literature, as well as other _assignment_ and _clustering_ problems, in the theoretical computer science literature. We review these works below.

**Team formation:** In terms of application, our work belongs to the team-formation literature (Becker et al., 2010; Chen et al., 2011; Chen et al., 2012; Zhang et al., 2013; Zhang et al., 2014; Zhang et al., 2015). Most of these works consider the problem of assigning groups of individuals to tasks (one group per task) such that the tasks are completed and some objective (usually related to the well-functioning of the team or the well-being of the individuals) is optimized. Our problem is a partitioning problem and as such is much more complicated than problems of finding a good team for each available task. Additionally, in many of the existing works the objective function has a well-defined structure (e.g., is monotone and submodular, concave). Our objective does not have such a structure and while this gives us modeling power, optimizing it requires more advanced techniques.

**Partitioning problems:** The _Max-k-Cut with given part sizes_ problem (Chen et al., 2011) served as an inspiration for our model. In fact, our \(1/2\)-approximation algorithm is a very close variant of the algorithm presented there. However, our objective function is slightly different from the one defined by Ageev et al. - due to an additional linear term. This allows us to design algorithms tailored to our problem, which achieve better approximation ratios under certain assumptions. Additionally, we focused on developing scalable algorithms as the running time of the algorithm proposed by Ageev et al. was not a computationally feasible approach.

**Clustering problems:** One can view our problem as a clustering problem with capacity constraints (Ageev et al., 2010; Ageev et al., 2011). Our model, however, is quite different from these works both in the objective function and the constraints.

**Assignment problems:** Our problem can be viewed as a generalization of the _weighted assignment_ problem (Ageev et al., 2011), where the goal is to assign individuals to tasks taking into account the task preferences of individuals. In our problem, apart from task preferences, we also have a graph capturing the relationships (or conflicts) between individuals. This additional structure increases the complexity of the problem significantly. Our problem is also related to the famous _stable marriage_(Grover and Leskovec, 2007) problem and its variants (Grover and Leskovec, 2007; Leskovec, 2007). However, we don't look for a stable matching. Instead, our goal is to optimize an objective function capturing the overall satisfaction of individuals.

**The metric-labeling problem**: A minimization version of our problem is the _metric-labeling_ problem (Mikolov et al., 2013), where the goal is to assign one of \(k\) labels to each node (i.e., partition the nodes). Every assignment incurs assignment costs (based on the choice of label for each node) and separation costs (based on the choice of labels for "related" nodes). In the capacitated version of metric-labeling (Becker et al., 2010) we are also given a capacity for each partition. The main disadvantage of the algorithm developed for this version (Becker et al., 2010) is that the capacity constraints are violated by a multiplicative factor. Also, the algorithm only works for labels with uniform capacities. Finally, the approximation factor of the proposed algorithm depends on the number of labels (i.e. tasks). Defining TFC as a maximization problem allows us to overcome all of the above disadvantages.

## 3. Problem Definition

In this section, we provide the necessary notation and we formally define the problem we solve in this paper.

**Notation:** Throughout the paper, we assume that we are given a weighted (undirected) graph \(G=(V,E_{G},w)\) with \(w:E_{G}_{ 0}\). More specifically, each node \(e V\) corresponds to an individual; the weight \(w_{uw}\) of an edge \((u,v) E_{G}\) captures the degree of conflict between individuals \(u\) and \(v\). We call graph \(G\) the _conflict graph_.

In addition to the conflict graph \(G\), we also assume a preference graph \(R\), which is a _bipartite graph_, i.e., \(R=(V,T,E_{R},c)\). The one side of the graph corresponds to individuals \((V)\), the other side to items or tasks \(T\). The edges \((E_{R})\) capture the preferences of individuals to projects. More specifically \(c:V T_{ 0}\) is a _preference_ function, where \(c_{wt}\) captures the satisfaction of individual \(v V\) when assigned to task \(t T\). Without loss of generality we assume that \(0 c_{wt} 1\).

Throughout, we assume that each individual \(v V\) is assigned to exactly one task and that each task \(t T\) has _capacity_\(p_{t}\), which is task-specific.

**The Team Formation amidst Conflicts problem:** Given the above, our goal is to assign individuals to tasks such that the overall satisfaction of individuals is maximized; the satisfaction of each individual is measured by how much they like the task they are assigned to and the lack of conflicts with the other individuals assigned to the same task. We capture this intuition formally in the form of a (quadratic) program. For this, we define binary variables \(x_{wt}\) such that \(x_{wt}=1\) if individual \(v\) is assigned to task \(t\) and \(x_{wt}=0\) otherwise. Thus, our goal is the following:

\[ F()=_{v V}_{t T}c_{wt}x_{wt}+ _{(u,v) E_{G}}w_{uw}(1-_{t T}x_{wt}x_{wt})\] \[ _{t T}x_{wt}=1,v V \] \[_{v V}x_{wt} p_{t},t T\] (3) \[x_{wt}\{0,1\},v V,t T \]

We call the problem captured by the above program Team Formation amidst Conflicts or TFC for short. The linear term of the objective captures the satisfaction of assigning individuals to tasks and we call it the _task satisfaction term_: \(F_{R}=_{v V}_{t T}c_{wt}x_{wt}\). The quadratic term captures conflicts in the following sense. The objective increases by \(w_{uw}\) whenever there is conflict between individuals \(u\) and \(v\) and they are assigned to different tasks. We call this term the _social satisfaction term_, i.e., \(F_{G}=_{(u,v) E_{G}}w_{uw}(1-_{t T}x_{wt}x_{wt})\); this term models Max-k-Cut with given sizes of parts (Chen et al., 2011).

As far as the constraints are concerned: the first constraint enforces that every individual is assigned to exactly one task while the second constraint enforces that we assign at most \(p_{t}\) individuals to task \(t T\); \(p_{t}\) is the capacity of tasks. Observe that our problem as represented above is a quadratic program with integer constraints and the objective function \(F\) is non-convex. This observation hints that the problem may be computationally hard. In fact, we have the following result regarding the hardness of TFC:

[MISSING_PAGE_FAIL:3]

**Approximation guarantees:** Following the analysis of Ageev et al. ((2017)) we can show that Pipage is an \(1/2\)-approximation algorithm for the TFC problem. Thus we have:

Theorem 1 ((2017)).: _The_ Pipage _algorithm is an \(\)-approximation algorithm for the TFC problem._

For completeness we present this proof in Appendix A.1

**Running time:** The overall complexity of Pipage consists of the running time of a gradient-ascent algorithm that finds a fractional solution \(^{*}\) to the Relaxed-TFC problem plus the running time of the latter is \(O((_{F}+|V|+|T|)|E_{^{*}}|)\), where \(_{F}\) is the time required to evaluate the function \(F\) and \(E_{^{*}}\) is the number of fractional components of the initial solution \(^{*}\). This is because each of the \(E_{^{*}}\) steps of pipage rounding requires time \(O(_{F}+|V|+|T|)\) since we run a Depth-First-Search and two evaluations of \(F\).

### Randomized \(\) - approximation algorithm

Here, we present a \(\)-approximation algorithm for TFC. We call this algorithm RPipage, because we use the randomized pipage rounding in order to instantiate the Relax-Round algorithm.

**The \(L_{2}\) concave relaxation:**

\[L_{2}()=_{ V}_{ T}c_{ }-(E_{G})+_{(u,v) E_{G}}_{ t T}w_{uv}(1,x_{u}+x_{}).\]

For \(L_{2}\) we have the following:

Proposition 2.: \(L_{2}\) _satisfies Properties 1 and 2._

The proof of Proposition 2 is given in Appendix A.2.

**Randomized pipage rounding** Here, we briefly present the randomized pipage scheme originally proposed by Gandhi ((2017)). Randomized pipage rounding proceeds in iterations, just like (deterministic) pipage rounding. If \(\) is the current fractional solution of the rounding algorithm, we calculate \(_{1}\) and \(_{2}\) (same as in pipage rounding) and then we probabilistically set \(y^{}\) equal to either \(_{1}\) or \(_{2}\). For more details we refer the reader to Appendix C.2.

**Approximation guarantees:** In order to prove the \(\)-approximation ratio of RPipage for TFC we need the following Lemma:

Lemma 2 ((2017)).: _If we use \(\) to denote the randomized pipage algorithm that rounds a fractional solution \(\) to an integral solution \(\), i.e. \(()=\), then \(\) satisfies the following properties:_

* \(_{}[]=\)__
* \(_{}[(1-x_{})(1-x_{})] (1-y_{})(1-y_{})\)_, for all_ \(u,v V\) _and_ \(t T\)__

The proof of this lemma is due to Chekuri et al. ((2017)), and thus omitted. The most important consequence of Lemma 2 is the following proposition, the proof of which is given in Appendix A.3

Proposition 3.: _Under Assumption 1, for all \(,\) such that \(=()\) and \(\) being the randomized pipage rounding, we have that:_

\[_{}[L()]L()\]

Now, let \(^{*}\) be the optimal fractional solution of the Relaxed-TFC problem with objective \(L_{2}\) and \((^{*})=^{*}\), with \(\) being the randomized pipage rounding scheme. Also, let \(_{}\) be the optimal solution of the integral problem TFC. Then, it holds that:

\[F(^{*})=L_{2}(^{*})L_{2}(^{*}) F(_{}).\]

Thus, we have the following theorem:

Theorem 2.: _Under Assumption 1,_ RPipage _is a \(\)-randomized approximation algorithm for the TFC problem._

**Running time:** The overall complexity of RPipage consists of the running time of a gradient-ascent algorithm that finds a fractional solution \(^{*}\) to the Relaxed-TFC problem with objective \(L_{2}\) plus the running time of the randomized pipage rounding scheme, which is \(O((|T|+|V|)|T|V|)\); assuming that the number of tasks \(|T|<|V|\), this becomes \(O(|T||V|^{2})\). In contrast to deterministic pipage rounding, observe that randomized pipage rounding does not require evaluating the objective function. This results in a significant computational speed-up.

**Discussion:** In the future, it would be interesting to examine if _swap rounding_(Brandenburg, 2017), can be used in place of randomized pipage rounding and whether such a scheme can lead to more efficient algorithms. We leave this as an open problem.

### Tuning the hyperparameter \(\)

In order for Theorem 2 to hold, we need to make the following assumption:

Assumption 1. (Balancing Assumption) _Consider a feasible fractional solution \(\). We assume that the following holds_

\[_{v V}_{t T}c_{}-(E_{G}) 0\]

\[(E_{G})}{_{u V}_{t T}c_{ }},\]

_where \((E_{G})=_{(u,v) E_{G}}w_{uw}\). If we also assume that \(0 c_{} 1\) for all \(v V\) and \(t T\), then we have_

\[(E_{G})}{|V|}=}}{2},\]

_where \(d_{}\) is the average degree of the nodes in the conflict graph \(G\) and we used the fact that \(_{t T}s_{}=1, v V\)._

The above assumption provides a way to tune the balancing parameter \(\). In practice, we do the following: we introduce the _balancing factor_\(_{>0}\) and we set \(\) to be \(=}}{2}\). In practice, we tune \(\) as follows: for different values of \(\) we evaluate the task and the social satisfaction terms \((F_{R}^{()},F_{G}^{()})\). Then, we pick the value of \(\) that gives the desired balance between the two terms.

## 5. Computational Speedups

We discuss here a few methods we use in order to speedup our algorithms. All heuristics we discuss here can be applied to both Pipage as well as RPipage.

**Converting convex to linear programs:** The algorithms we developed in Section 4 are based on the fact that the Relaxed-TFC problem with objective functions \(L_{1}\) and \(L_{2}\) is a concave problem with linear constraints and it can be solved in polynomial time via an application of gradient ascent. In fact, we show that there is away to rewrite the Relaxed-TFC problems with objectives \(L_{1}\) and \(L_{2}\) as linear programs, by adding some extra variables.

For the Relaxed-TFC problem with objective \(L_{1}\), this can be done as follows: first, we substitute the term \((1,_{t}(2-x_{ut}+x_{ot}))\) with the new variable \(x_{uw}\) and the objective becomes:

\[L_{1}()=_{v V}_{t T}c_{vt}x_{vt}+_{(u,v) E _{G}}w_{uw}z_{uw}.\]

Then we also add the constraints \(z_{uw} 1\) and \(z_{uw} 2-x_{ut}-x_{gt}\), \(t T\). The full linear program is given in Appendix A.4

The corresponding linearization of the \(L_{2}\) objective can be done as follows: we substitute the term \((1,x_{ut}+x_{ot})\) with a new variable \(x_{uut}\) such that:

\[L_{2}()=_{v V}_{t T}c_{vt}x_{vt}-w(E_{G})+_{ (u,v) E_{G}}_{t T}w_{uw}x_{uut}.\]

We also add the constraints \(x_{uut} 1\) and \(x_{uut} x_{ut}+x_{gt}\). The complete linear program is given in Appendix A.5.

The advantage of converting the convex problems into linear is that solving a linear program is much more efficient than solving a convex program with linear constraints. In practice, using the Gurobi solver we obtained speedups up to 500x (see Table 4).

**Sparsification:** When the task capacities are small and the conflict graph is dense, a heuristic, we named Sparsify, that works well in practice is randomly removing conflict edges. That is, we keep each conflict edge with a certain probability \(p\). Otherwise, with probability \((1-p)\) we discard the edge. This greatly reduces the number of terms we need to evaluate \(F_{G}\) in our objective resulting in computational speedups when optimizing the fractional relaxation.

Note that when \(p=1\), we don't alter the objective. As \(p\) decreases, we remove more conflict edges, resulting in computational speedups, although our fractional solution might not be optimal. Selecting \(p\) is problem specific. A rule of thumb is that the denser the conflict graph, the lower we can set \(p\).

**Compact:** Our intuition, but also our real-world datasets (see Section 6.2 and Appendix D.2), reveal that our data have the following pattern: the complement of the conflict graph, i.e., the friend graph, consists of relatively small densely-connected communities with similar task preferences. Intuitively, for two individuals \(u,v\) that belong in the same community and have similar preferences we would expect that the vectors of \(x_{ut}\)'s and \(x_{ot}\)'s will be similar for all \(t T\). Taking this to the extreme: individuals \(u,v\) with the same neighbors in the conflict graph \(G_{G}\) and the same preferences for tasks in \(T\) should have identical values \(x_{ut}\), \(x_{vt}\).

Formally, this is captured in the following theorem, which is proved in Appendix A.6:

**Theorem 3**.: _Consider two individuals \(u,v V\) which have identical neighbors in \(G_{G}\) (i.e.,\((u,w) E_{G}(v,w) E_{G}\)) and have identical project preferences (i.e., \(c_{ut}=c_{vt}, t T\)). Then, there exists an optimal solution \(\) of Relaxed-TFC such that \(x_{ut}=x_{ut}, t T\)._

Motivated by the above theorem we define the Compact algorithm. On a high-level the idea is to compact densely-connected subgraphs into supernodes. Note that the supernodes need not be nodes that have identical neighborhood in \(G\); after all, it may be unreasonable to assume that this will happen in practice. However, using a graph-partitioning algorithm (e.g., spectral clustering (Krishnamurthy et al., 2017), finding dense components (Bartlett and Barthelemy, 2017)) we can partition the original set of nodes into supernodes with similar neighborhoods. Let \(S\) be the set of supernodes, which is a partition of the original set of nodes \(V\). Then, we create a conflict graph between supernodes; the number of conflict edges between two supernodes \(A\) and \(B\) is approximately \(|A||B|\) (almost every node of \(A\) is in conflict with every node of \(B\)). Thus, we set in this new conflict graph we set the weight of edge \((A,B)\) to be \(w_{AB}=|A||B|\) (assuming that each edge of the original graph has unit weight). The next step is to solve the following _compact_ Relaxed-TFC problem:

\[ L()\] (10) s.t. \[_{t T}x_{gt}=1,v S \] \[_{v S}|v|x_{vt} p_{t},t T\] (12) \[0 x_{gt} 1, v S, t T. \]

where we use \(|v|\) to denote the number of simple nodes in the supernode \(v\).

Then, we unroll the solution to obtain a fractional solution for the original graph. That is, for each \(v V\) we set \(x_{vt}=x_{St}\), where \(S\) is the supernode \(v\) belongs to. Finally, we round the fractional solution to obtain an integral solution. Depending on whether we use \(L_{1}\) or \(L_{2}\) as our objective, we then round the fractional solution using Pipage or RPipage respectively.

## 6. Experiments

In this section, we evaluate our framework using both real-world as well as synthetic datasets. The experiments prove the effectiveness and efficiency of our algorithms as well as the versatility of our model to encompass many different real-world scenarios involving assignment problems with conflicts.

### Baselines and Setup

**Baselines:** For our experiments we use the following baselines:

QuadraticThis is the optimal algorithm, i.e., the algorithm that solves the original TFC problem as expressed in Equations (1)-(4). We use an off-the-shelf solver to implement Quadratic, but even though this is a powerful solver, we can run Quadratic only for small datasets since the solver is asked to optimize a non-convex quadratic function subject to integral constraints.

GreedyThe Greedy algorithm sequentially assigns an individual to the best team (i.e., the team that maximizes the objective function \(F\)) given that the constraints are satisfied. The algorithm terminates when all individuals are assigned. We refer the reader to Appendix B for a detailed analysis of Greedy.

Random: This is an algorithm that randomly assigns each individual to a team until all individuals are assigned.

Manual: This is the _manual_ assignment of individuals to tasks as made by a human expert, which is available only in some datasets.

**Experimental setup:** Our experimental setup is descried in Appendix D.1. Unless otherwise stated we use the "linearization" speedup presented in Section 5.

### Datasets

For our experiments, we use three different types of data: (a) data of preferences of students with respect to projects and collaborators in educational settings, (b) data from the Bureau of Labor statistics that concern employees and their assignment to company departments and, finally, (c) a synthetic dataset that we use to test the scalability of our algorithms and the speedups described in Section 5. We describe these datasets below. A summary of the characteristics of each dataset is shown in Table 1.

**Education data:** This is data coming from courses in a US institution 2. In the classes we considered, there were a number of projects (with fixed capacities) available to students and each student filled in a form with their project preferences (each student ranked the projects from best to worst) and their preferences with respect to other students they want to work with in the same project. We have data from four such classes: _Class-A_, _Class-B_, _Class-C_ and _Class-D_. These datasets do not contain a conflict graph between students, but instead a _friend_ graph (indicative such graphs are shown in Appendix D.2), i.e. two students that have an edge between them are friends and want to work together. We define the conflict graph as the complement of the friend graph. We assign unit weight to each edge of the conflict graph.

Next, we have to construct the preference graph by assigning weight \(c_{u,p}\) for each student \(u\) and project \(t\). Let \(rank_{u}(t)[|T|]\) be the rank of project \(t\) in student's \(u\) preference list (1 is the best, \(|T|\) is the worst). We considered the following functions:

* inverse (_Inversely_: \(c_{u,t}=(t)}\)
* linear-normalized (_LinNorm_): \(c_{u,t}=(t)+1}{|T|}\)

**Employee data:** Based on statistics from the _U.S. Bureau of Labor Statistics_3 for 2022, we built a dataset of employees in an company. Specifically, we created a company with 4000 employees and four departments: IT, Sales, HR, PR. Each department has 1000 employees. IT and Sales departments are male dominated while HR and PR are female dominated. The distribution of males and females in each department are according to the data in the _Management occupations_ section of the _U.S. Bureau of Labor Statistics_. In our experiments, we add conflict edges between all male employees, since our objective is to distribute the male employees more evenly. Equivalently, we could have added conflict edges between all females. Generally, depending on the diversity goal, one can add conflicts judiciously to guide the diversification process. For employee preferences, we set \(c_{u,t}=1\), if \(t\) is the original department of \(u\), otherwise \(c_{u,t}=0\). We assume that with probability 1% an employee is suitable for switching to a new department. For those employees we set \(c_{u,t}=1\), where \(t\) is the department to which employee \(u\) may switch.

**Synthetic data:** We also created a synthetic dataset (_Synth-TF_) to test the speedups we discussed in Section 5. For this we created \(|V|=1000\) individuals. The conflict graph is defined as the complement of the following friend graph: the friend graph is a planted partition graph where each partition has 100 nodes connected with probability 0.99. Edges across partitions are added with probability \(10^{-5}\). For each partition we select a primary project \(t\) and set \(c_{u,t}=1\) for all nodes \(v\) in the partition. Next, for each node \(v\) we choose uniformly at random a project \(t^{}\) and set \(c_{u,t^{}}=1\).

### Forming teams in education settings

In this section, we evaluate the quantitative and qualitative performance of our algorithms using the education datasets.

**Quantitative performance of our algorithms:** We evaluate the qualitative performance of our algorithms using the _approximation ratio_ AR, i.e. the ratio of the objective function evaluated at the solution and the optimal value.

Figure 1 shows the approximation ratios achieved by our algorithms and the different baselines. For all datasets we used the _LinNorm_ project preference function. The results for the _Inverse_ preference function are presented in Appendix D.3). The results demonstrate that our algorithms have approximation ratio very close to 1.

Interestingly, and despite the fact that in Appendix B we show that the worst-case approximation ratio of Greedy is unbounded, in practice Greedy has AR score very close to 1. We conjecture that this is true due to the correlation between students' friendships and preferences. In fact, we believe that one can bound the approximation ratio of Greedy under such correlation patterns; we leave this as future work.

Somewhat surprisingly, the performance of Random is quite good, although not comparable to the other algorithms. This can be explained by the high density of the conflict graph (or the sparseness of the friend graph) and the fact that the capacities of projects are small relative to the number of individuals. Since the conflict graph is almost a complete graph, small random teams inevitably have large number of conflict edges between them. That said, our analysis demonstrates that the solution given by Random has poor qualitative characteristics.

Figure 1. Education data; approximation ratio of the different algorithms. For all datasets we used the _Inverse_ project-preference function and \(=10\).

For these experiments we used \(=10\) for all datasets, since our primary goal was to assign students to projects they like. Assigning students with their friends was a secondary objective according to the course instructors. We chose the value of \(\) following the grid-search procedure of Section 4.3; the details are given in Appendix D.4. Note that by our selection of \(\), the balancing assumption holds and thus the approximation guarantees of RPipage hold.

**Qualitative performance of our algorithms:** In applications such as the assignment of students to teams, what matters is not just the value of the objective function, but the per-student satisfaction. In this section, we analyze the solutions provided by our algorithms and our baselines and compare those with the _manual_ solution provided by a domain expert who tries to find an empirically good assignment based on the input data.

In order to evaluate the quality of the results, we compute the following metrics. Given a solution \(\) to our problem we define \(r(,)\) to be the rank\({}_{}(t)\), where \(x_{}=1\), i.e. \(r(,)\) is the rank - according to \(v\) - of the task to which \(v\) was assigned. Then, we define the \(\)-preference metric to be:

\[Q_{R}()=(r(,)).\]

In the above equation, \(\) can be substituted by max or \(avg\) and the preference metric corresponds to the maximum and average ranking of the projects assigned to students; note that the minimum is not used as it is identical across algorithms and does not provide any insight. Intuitively, the lower the value of \(Q_{R}(_{})\) for a solution provided by an algorithm \(\), the better the algorithm.

Similarly, we define \(Q_{G}()\) to be the max or \(avg\) number of friends (non-conflicts) assigned to students in \(v\). In this case, the larger the value \(Q_{G}(_{})\) for a solution provided by an algorithm \(\), the better the algorithm.

Table 2 shows that students got a better project on average when using the Quadratic,Pipage and RPipage algorithms compared to the Manual assignment. Table 5 shows that students got the same (or almost the same) average number of friends using the Quadratic, Pipage and RPipage algorithms as in the manual assignment.

### Forming teams of employees

In this section, we use the _Company_ dataset in order to evaluate our algorithms' ability to form diverse teams of employees.

**Quantitative performance of our algorithms:** Figure 2 shows the approximation ratios of our algorithms and baselines for the _Company_ dataset and for \(=1,2,3,4\). Somewhat surprisingly, for \(=1\) our algorithms have a approximation ratio close to \(0.8\), while Greedy is almost optimal. Random has significantly lower approximation ratio than the other algorithms; most of the times less than \(0.5\). In general, all other algorithms have approximation ratio close to \(1\). It is interesting to observe that in this dataset Greedy performs almost optimally for all choices of \(\); despite the fact that its worst case approximation factor is unbounded (see Appendix B).

As we discussed before, we believe that the reason for this is the correlation between conflicts and task preferences.

Figure 3. Employee data; Diversity per department before (1\({}^{}\) row) and after (2\({}^{}\) row) we run the quadratic algorithm (\(=2\)), \(8\%\) of the employees changed department. The average male-female percentage gap decreased from \(35\%\) to \(26\%\).

Figure 2. Employee data; approximation ratio of the different algorithms for \(=1,2,3,4\).

**Qualitative performance of our algorithms:** In this dataset, we evaluate the qualitative performance of our framework by showing how the optimal solution to our problem (obtained by Quadratic), affected the diversification of the teams. Figure 3 demonstrates exactly this. While only 8% of the employees changed department, the average male-female percentage gap decreased from 35% to 26%. Varying the value of \(\) we can control this balance. Specifically, if we decrease the value of \(\) the number of people who change department increases, while the average male-female gap decreases. Hyperparameter tuning for the _Company_ dataset is further discussed in Appendix D.7.

### Evaluating the speedup techniques

In this section, we use the _Synth-TF_ dataset to demonstrate the speedups obtained by the different techniques we discussed in Section 5. As we discussed, solving the TFC problem as described in Equations (5)-(8) using a convex solver does not scale up. Thus, we apply to this original problem sparsification and then run the convex solver; we call this algorithm Sparsity-Concave. For the Sparsity algorithm we used \(p=0.01\), i.e., we kept only 1% of the edges of the conflict graph. Alternatively, we transform the problem into a problem with a linear objective by adding auxiliary variables and constraints (as discussed in Section 5) and run the RPipage algorithm. We call this algorithm Linear. Another algorithm we use is Sparsity-Linear, which combines sparsification and linearization. Finally, we also combine Compact with Linear to obtain the Compact-Linear algorithm. Note that for the implementation of Compact we use the spectral clustering algorithm ((21)) available in scikit-learn 4.

Figure 4 shows the approximation ratios of the above heuristics and Table 4 the running times of the same heuristics on the _Synth-TF_ dataset. For this experiment, we set the value of \(=10\).

Although all algorithms perform almost optimally, speed-ups vary. First, trying to directly optimize the Concave relaxation results in a time-out of our solver. Using Sparsity before optimizing the Concave relaxation renders the problem solvable in 1000 seconds. Using Linear algorithm yields an extra 3x speedup. Finally, combining Linear with either Sparsity or Compact further reduces the running time down to \(2-3\) seconds which is a 100x speedup. In total, we managed to reduce the time from 1095 seconds using Sparsity-Concave to \(2-3\) seconds combining Linear with one of Sparsity or Compact.

## 7. Conclusions

Motivated by the need to form teams of students in large project-based classes we defined the TFC problem and showed that (a) it is NP-hard and that (b) it is closely related to Max-\(k\)-Cut with given part sizes (Bartlett and Schober, 2009). For TFC, we designed a new efficient randomized approximation algorithm and practical methods for speeding it up. We applied our algorithms to real-world datasets and demonstrated their efficacy across different dimensions.

In the future, we want to further explore possible speedups for our algorithm and also formally investigate the extremely good performance of greedy in practice - despite its unbounded worst-case approximation ratio.

   Algorithm & Time (seconds) & \\  Concave & time out & \\ Sparsity-Concave & 1095 & \\ Linear & 342 & \\ Sparsity-Linear & 2 & \\ Compact-Linear & 3 & \\   

Table 4. Running time (seconds) for the speed-ups

Figure 4. _Synth-TF_ dataset; approximation ratios of the speedups; We used \(=10\).

   Dataset & Algorithm & max\(Q_{G}\) & avg\(Q_{G}\) & _std_ \\    } & Quadratic & 4 & 0.65 & 0.78 \\  & Pipage & 2 & 0.1 & 0.34 \\  & RPipage & 1 & 0.08 & 0.26 \\  & Greedy & 3 & 0.65 & 0.74 \\  & Random & 1 & 0.4 & 0.49 \\  & Manual & 3 & 0.63 & 0.63 \\    } & Quadratic & 2 & 0.64 & 0.77 \\  & Pipage & 2 & 0.64 & 0.77 \\  & RPipage & 2 & 0.57 & 0.78 \\  & Greedy & 3 & 0.79 & 1.08 \\  & Random & 2 & 1.5 & 0.87 \\  & Manual & 2 & 0.64 & 0.67 \\    } & Quadratic & 2 & 0.54 & 0.57 \\  & Pipage & 1 & 0.38 & 0.49 \\  & RPipage & 1 & 0.38 & 0.49 \\  & Greedy & 2 & 0.69 & 0.67 \\  & Random & 1 & 0.54 & 0.5 \\  & Manual & 2 & 0.69 & 0.54 \\    } & Quadratic & 3 & 0.43 & 0.72 \\  & Pipage & 1 & 0.29 & 0.45 \\  & RPipage & 1 & 0.23 & 0.42 \\  & Greedy & 2 & 0.38 & 0.54 \\  & Random & 0 & 0.0 & 0.0 \\   

Table 3. Education data; \(Q_{G}(x_{})\) for \(=\{,\}\) of number of friends per student and \(\) being all algorithms; we also report _std_ - the standard deviation for \(\)\(Q_{G}\); _Inverse_ project preference function and \(=10\).