# Forward.

P4GCN: Vertical Federated Social Recommendation with Privacy-Preserving Two-Party Graph Convolution Networks

Anonymous Author(s)

###### Abstract.

In recent years, graph neural networks (GNNs) have been commonly utilized for social recommendation systems. However, real-world scenarios often present challenges related to user privacy and business constraints, inhibiting direct access to valuable social information from other platforms. While many existing methods have tackled matrix factorization-based social recommendations without direct social data access, developing GNN-based federated social recommendation models under similar conditions remains largely unexplored. To address this issue, we propose a novel vertical federated social recommendation method leveraging privacy-preserving two-party graph convolution networks (P4GCN) to enhance recommendation accuracy without requiring direct access to sensitive social information. First, we introduce a Sandwich-Encryption module to ensure comprehensive data privacy during the collaborative computing process. Second, we provide a thorough theoretical analysis of the privacy guarantees, considering the participation of both curious and honest parties. Extensive experiments on four real-world datasets demonstrate that P4GCN outperforms state-of-the-art methods in terms of recommendation accuracy.

Social Recommendation, Federated Learning, Graph Neuron Network +
Footnote †: ccs: Information and Communication Networks

+
Footnote †: ccs: Information and Communication Networks

+
Footnote †: ccs: Information and Communication Networks

+
Footnote †: ccs: Information and Communication Networks

+
Footnote †: ccs: Information and Communication Networks

+
Footnote †: ccs: Information and Communication Networks

+
Footnote †: ccs: Information and Communication Networks

+
Footnote †: ccs: Information and Communication Networks

+
Footnote †: ccs: Information and Communication Networks

+
Footnote †: ccs: Information and Communication Networks

+
Footnote †: ccs: Information and Communication Networks

+
Footnote †: ccs: Information and Communication Networks

+
Footnote †: ccs: Information and Communication Networks

+
Footnote †: ccs: Information and Communication Networks

## 1. Introduction

Graph neural networks (GNNs) (Ganin and Lempitsky, 2015; Ganin and Lempitsky, 2015) are a class of deep learning models specifically designed to handle graph-structured data, including various scenarios such as social networks (Ganin and Lempitsky, 2015; Ganin and Lempitsky, 2015), finance and insurance technology (Ganin and Lempitsky, 2015; Ganin and Lempitsky, 2015), etc. By harnessing the capabilities of GNNs, social recommendation systems can gain an in-depth understanding of the intricate dynamics and social influence factors that shape users' preferences, leading to improved recommendation accuracy. For example, an insurance company could utilize social relationships extracted from a social network platform by a GNN model to enhance the accuracy of personalized product recommendations (i.e., insurance marketing). However, in real-world scenarios, privacy and business concerns often hinder direct access to private information possessed by aforementioned social platforms. Consequently, the integration of privacy-preserving technologies, such as federated learning (Ganin and Lempitsky, 2015), secure multi-party computation (Ganin and Lempitsky, 2015), homomorphic encryption (Ganin and Lempitsky, 2015), and differential privacy (Ganin and Lempitsky, 2015), into social recommendation tasks has attracted significant attention from both academia and industries.

Recent works mainly enable the recommender to collaboratively train matrix factorization (Krizhevsky et al., 2012) based recommendation models without accessing the social data owned by other platforms(Krizhevsky et al., 2012; Hinton et al., 2012). (Krizhevsky et al., 2012) proposed the secure social MF to utilize the social data as the regularization term when optimizing the model. Further, (Krizhevsky et al., 2012) significantly reduces both the computation and communication costs of the secure social matrix factorization by designing a new secure multi-party computation protocol. However, these solutions cannot be applied to training GNN models, because the computation processes involved in training GNN models are typically more complex compared to MF-based methods. For example, in GNN models, the aggregation of features from different users on the social graph involves multiplying the aggregated results with additional parameter matrices. In contrast, MF-based methods focus on reducing the distances between neighbors' embeddings based on the social data, without the need for additional parameters. In addition, the formulations used in the forward and backward processes of GNN models are much more complex than those of MF-based methods. Consequently, it is essential to develop a secure social recommendation protocol tailored explicitly to enhance the optimization of GNN models.

Figure 1. The example of vertical federated social recommendation with inaccessible social data.

To address the aforementioned challenges, we propose a novel _vertical federated Social recommendation with Privacy-Preserving Party-to-Party Graph Convolution Networks_ (**P4GCN**) to improve the social recommendation system without direct access to the social data. In our approach, we first introduce the _Sandwich-Encryption_ module, which ensures data privacy throughout the collaborative computing process. We then provide a theoretical analysis of the security guarantees under the assumption that all participating parties are curious and honest. Finally, extensive experiments are conducted on three real-world datasets, and results demonstrate that our proposed P4GCN outperforms state-of-the-art methods in terms of both recommendation accuracy and communication efficiency.

The main contributions of this study can be summarized as follows:

* We propose P4GCN, a novel method for implementing vertical federated social recommendation with theoretical guarantees. Unlike previous works that assume the availability of social data, we focus on leveraging GNN to enhance recommendation systems with fully unavailable social data in a privacy-preserving manner.
* We introduce the sandwich encryption module, which guarantees data privacy during model training by employing a combination of homomorphic encryption and differential privacy. We provide theoretical guarantees to support its effectiveness.
* Experimental results conducted on four real-world datasets illustrate the enhancements in performance and efficiency. Furthermore, we evaluate the impact of the privacy budget on the utility of the model.

## 2. Related Works

### Social recommendation

Existing social recommendation methods have adopted various architectures according to their goals and achieved outstanding results (Kumar et al., 2017). For instance, many SocialRS methods employ the graph attention neural network (GANN) (Bahdanau et al., 2014) to differentiate each user's preference for items or each user's influence on their social friends. Some other methods (Kumar et al., 2017; Li et al., 2017; Li et al., 2017; Li et al., 2017; Li et al., 2017) use the graph recurrent neural networks (GRNN) (Shen et al., 2016; Li et al., 2017) to model the sequential behaviors of users. However, these centralized methods cannot be directly applied when the social data is inaccessible.

### Federated recommendation

There are mainly two types of works addressing recommendation systems in FL. The first type is User-level horizontal FL. FedMF (Li et al., 2017) safely train a matrix factorization model for horizontal users. FedGNN (Li et al., 2017) captures high-order user-item interactions. FedSoG (Li et al., 2017) leverages social information to further improve model performance. The second type is Enterprise-level vertical FL which considers training a model with separated records kept by different companies. To promise data security in this case, techniques such as differential privacy(Li et al., 2017) and homomorphic encryption(Li et al., 2017), are widely used. (Li et al., 2017) uses random projection and ternary quantization mechanisms to achieve outstanding results in privacy-preserving. However, these works failed to construct the social recommendation model when the social data is unavailable. To address this issue, SeSore(Li et al., 2017) protects social information while utilizing the social data to regularize the model. (Kumar et al., 2017) proposed two secure computation protocols to further improve the training efficiency. Although these works can be applied to matrix factorization models, the GNN-based models have not been considered in this case.

## 3. Problem Formulation

In this section, we first introduce the notations we used, and then we give the formal definition of our problem. Let \(U=\{u_{i}\},u_{i}\) denote the user set and \(V=\{u_{i}\},u_{i}\) denote the item set, where the number of users is \(N_{U}=|U|\) users and the number of items is \(N_{V}=|V|\). There are two companies \(_{1},_{2}\) that own different parts of the user and item data. \(_{1}\) owns the user set \(U\) and the item set \(V\) with the interactions between users and items \(=\{(u_{i},u_{j},y_{k})\}\), where each \(r_{k}\) is a scalar that describes the \(k\)th interaction in \(\). \(_{2}\) owns the same user set \(U\) and their social data (i.e. user-user interactions) \(=\{(u_{i},u_{j},y_{k})\}\), where \(s_{k}\) denotes the \(k\)th interaction in \(\).

\(_{1}\) and \(_{2}\) collaboratively train a social recommendation GNN-based model \(_{}\) that predicts the rating \(_{u_{i}u_{j}} f(U,V,_{train},)\) of the user \(u\) assigning to the item \(g_{j}\). We minimize the mean square errors (i.e. MSE) (Li et al., 2017) between the predictions and the targets to optimize the model parameters \(\):

\[_{}(;U,V,_{train},)= _{train}|}_{(u_{i},g_{j},f_{})_{train}}\|r_{k}-_{u_{i}g_{j}}\|^{2}\]

Since all the computation can be done by \(_{1}\) itself except for the GNN layers for the social aggregation, we focus on protecting data privacy when computing the results of the social aggregation layer. Particularly, we consider the most classical GNN operator, Graph Convolution (GC), as the social aggregation operator in our model. Given a social-aggregation GC operator \(G(,,_{GC})\), \(_{1}\) should realize message passing mechanism of user features \(^{N d}\) over the users' social graph \(\{a_{ij}\}_{N N},a_{ij}\{0,1\}\) (i.e. the adjacent matrix) as below:\[}_{sym}=^{-}(+) ^{-},=([1+_{j}a_{1j},...,1+ _{j}a_{Nj}]) \]

\[=(+^{}),=}_{sym} \]

**Backward.**

\[}{}=}{ }}{}=}_{sym}}{}^{ },}{}=}{}}{}=^ {}}_{sym}^{}}{ } \]

where the parameters of graph convolution are \(_{GC}=[;],^{d_{im} d _{our}},^{d_{our}}\). We consider safely computing the two processes under the limitation that data privacy should be bi-directionally protected for these processes, where the parties cannot have access to another one's data (i.e. \(_{1}\) cannot infer the adjacent matrix \(\) and \(_{2}\) cannot infer the node features \(\) during computation). We follow (Li et al., 2017) to assume that all the parties are honest and curious. Different from works that consider each party to own user-user and user-item interactions partially, we attempt to apply GNNmodules to the **social-data-fully-inaccessible** vertical federated social recommendation.

## 4. Methodology

### Motivation

After social aggregation in Eq.(1) and Eq.(2), \(_{1}\) obtains the output Y for further computation of the loss \(\). To optimize the model, \(_{1}\) uses \(_{1}}{2}\) to compute the derivate of node features \(_{1}}{2}\). We notice that a key computation paradigm, multiplying three matrices, repeatedly appears in both forward and backward processes. Further, if we let the parameter matrix \(\) be kept by \(_{2}\) that owns \(}_{sym}\), the matrices on both sides and the matrix at the middle for each equation will be kept by different parties. In addition, the left-side result of each equation will be only needed by the one that owns the middle matrix. This observation motivates us to consider such a problem

_Given the matrices \(^{p q}^{r s}\) owned by the party \(p_{1}\) and the matrix \(^{q r}\) owned by the party \(p_{2}\), how can we design an algorithm to satisfy the two requirements below_

* _the party \(p_{2}\) obtains the multiplication \(=\) without exposing \(\) to the party \(p_{1}\)._
* _the party \(p_{2}\) cannot infer \(\) and \(\) from \(\) and \(\)._

As long as the above problem is solved, the computing processes of a graph convolution operator can be done without leaking data privacy. Therefore, we now focus on how to find a solution to this problem with the theoretical guarantee of privacy-preserving.

### Sandwich encryption

#### 4.2.1. Solution to \(R1\)

For the first requirement, each time there is a need to compute \(=\), the party first \(p_{2}\) encrypts the matrix \(\) with the public key \(_{pub,2}\) by simply using _Homomorphic Encryption_ (e.g. Paillier (2007)). Then, the ciphertext \([]_{_{pub,2}}\) is sent to the party \(p_{1}\) to compute \([]_{_{pub,2}}=[]_{_{pub,2}}\), and the result is returned to \(p_{2}\). By decrypting the result with the private key \(_{pub,2}\), \(p_{2}\) can know \(\) without leaking \(\) to \(p_{1}\).

#### 4.2.2. Solution to \(R2\)

Now we discuss how to protect privacy for \(\) and \(\).

#### Database-level protection

Since \(p_{2}\) doesn't know the exact values of both the two side matrices, it brings significant challenges for \(p_{2}\) to steal information about them from \(\) and \(\). To better illustrate this, we take an example where all variables of the equation \(j=lmn\) are scalars, and we can thus infer that \(j/m=ln\), which indicates there are infinite combinations of \(l\) and \(n\) for any given \(j 0,m 0\). For the matrix case, we illustrate the protection on the database level through Theorem 1.

**Theorem 4.1**.: _Given \(=\) where all matrices are not zero matrices, there exists infinite combinations of \(^{},^{}\) such that \(=^{}^{}\)._

Proof.: See Appendix A.2. 

Therefore, without knowing \(\) (or \(\)), \(p_{2}\) cannot fully recover \(\) (or \(\)), leading to the _database-level_ privacy protection. However, this barrier fails to protect the privacy of the two-side matrices at the element level. For example, if there are only two users' embeddings in \(^{2 d_{}}\) and one of the two embeddings happens to be zero, we can easily infer whether the two users have social interactions from the result \(^{2 d_{^{}}}\) by recognizing whether the aggregated embeddings corresponding to the zero embedding are still zero.

#### Element-level protection

To further enhance privacy protection for the two-side matrices at the element level, we introduce differential privacy (DP) noise (Berg et al., 2017) to the computed result \(\). DP offers participants in a database the compelling assurance that information from datasets is virtually indistinguishable whether or not someone's personal data is included. Since the object to be protected can be of high dimension, we leverage the advanced matrix-level DP

Figure 2. The framework of the _Sandwich Encryption_

mechanism, aMGM, introduced by (Zhou et al., 2017; Zhang et al., 2018) to enhance the utility of the computation.

**Definition 4.2** (analytic Matrix Gaussian Mechanism (Zhou et al., 2017)).: For a function \(f()^{m n}\) and a matrix variate \(_{m,n}(,_{1},_{2})\), the analytic Matrix Gaussian Mechanism is defined as

\[(f())=f()+ \]

where \(_{m,n}(,_{1},_{2})\) denotes matrix gaussian distribution.

**Definition 4.3** (Matrix Gaussian Distribution(Zhou et al., 2017)).: The probability density function for the \(m n\) matrix-valued random variable \(\) which follows the matrix Gaussian distribution \(_{m,n}(,_{1},_{2})\) is

\[(|,_{1},_{2})=\| ^{-1}(-)^{-}\|_{F}^{2}}{(2)^{ mn/2}|_{2}|^{n/2}|_{1}|^{m/2}} \]

where \(^{m m},^{n n}\) are invertible matrices and \(^{}=_{1},^{}=_{2} \) is the matrix determinant and \(^{m n},_{1}^{m m}, _{2}^{n n}\) are respectively the mean, row-covariance, column-covariance matrices.

The privacy protection is guaranteed by Lemma 4.4

**Lemma 4.4** (DP of aMGM (Zhou et al., 2017)).: _For a query function \(f\), aMGM satisfies \((,)-DP\), iff_

\[(f)}{b}_{m}()_{n}() \]

_where \(b\) is decided by \((,)\) and \(s_{2}(f)\) is the \(L_{2}\)-sensitivity, \(_{m}()\) and \(_{n}()\) are respectively the smallest singular values of \(\) and \(\)._

The general procedure of the _Sandwich Encryption_ is listed in Algorithm.1. The encryption process is like making a sandwich where the two pieces of bread are corresponding to the two-side matrices and the middle matrix is the meat in the sandwich as shown in Figure 2. By properly pre-processing the materials, the data privacy of each material can be preserved. While we apply DP to enhance privacy protection, how to preserve the utility of these computing processes as much as possible still brings non-trivial challenges. To this end, we design the Privacy-Preserving Two-Party Graph Convolution Network (P4GCN) to enhance the utility of the model while applying DP.

### P4gcn

#### 4.3.1. Architecture

Overview.The architecture of P4GCN is as shown in Figure 3. During each training iteration, \(_{1}\) first locally aggregates the user features \(_{user}^{(0)}\) and the item features \(_{item}^{(0)}\) by the backend (e.g., LightGCN(Chen et al., 2019)) into embeddings \(_{user}^{(1)}\) and \(_{item}^{(1)}\). Then, \(_{1}\) uses Algo.1 to collaboratively compute the user social embeddings that are aggregated on the social data by the GCN layer with \(_{2}\). After obtaining the user social embeddings \(_{user}^{(2)}\), \(_{1}\) uses the fusion layer to aggregate \(_{user}^{(1)}\) and \(_{user}^{(2)}\) together to construct the new

Figure 3. The training workflow of the proposed P4GCN

user embeddings \(_{user}^{(3)}\). Finally, both \(_{user}^{(3)}\) and \(_{item}^{(1)}\) are input into the decoder to obtain the predictions to compute the loss. The backward computation of the social GCN layer is also protected by Algo.1.

Fusion LayerThe fusion layer is designed for two reasons. For one thing, the DP mechanism may bring too much noise that leads to the degradation of the model performance. For another thing, the social information of different users may not consistently improve the model's performance but harm it. Therefore, we design the fusion layer to adaptively extract useful information by reweighing the inputs. Concretely, the fusion layer allocates weights to each activation in each user's embeddings by a two-layer MLP with a softmax function and position-wisely fuses them. This introduces a chance for the party \(_{1}\) to avoid the collaboration significantly reducing local model performance.

#### 4.3.2. Privacy-Preserved Social Aggregation

We analyze the sensitivity of the graph convolution and then apply aMGM to its computing processes.

ForwardDuring aggregation, the user \(i\)'s social embedding is specified by \(_{i}^{(2)}=_{user,i}^{(2)}= _{i}_{i}=}_{sym,i}\), which can be independently computed without queries on other users' social embeddings. Therefore, we focus on the computing sub-process \(f_{i}(,)\) to protect user-level privacy (i.e., the social interaction between any two users). Given two adjacent social databases \(\) and \(^{}\) whose elements are the same except one (e.g., \(||-^{}||_{F}=1\)), the \(L_{2}\)-sensitivity of each \(f_{i}, i[N]\) is bounded by

\[s_{2}(f)=_{A,A^{}}\|f_{i}^{}-_{ i}\|_{F}||\|_{F}\|\|_{FSI}(i) \]

\[s_{l}(i)=\{(+}c_{0})^{1/2},&,_{i}=\\ (||_{i}^{2}+||||_{i}}c_{i}+ ||_{i}}c_{0})^{1/2},&,. \]

where \(c_{i}=_{j=1}^{N} i(i+j)}{||_{i}||_{i}+1}||a_{i }||_{1}+1,c_{0}=_{j}_{j}||_{i}+1} 1,s_{l}(i)  2\) always hold for all users. Then, we respectively clip \(\) and \(\) by \((1,||_{F}}{c_{0}})\) to bound the sensitivity \(s_{2}(f) C^{2}s_{l}(i)\) (e.g., the coefficient \(C=1\) in experiments) before computation and finally rescale the computed result by the inverse scale factor. We empirically scale \(_{sym}\) with a factor \(\) in practice. We detail the derivation of the sensitivity term in Appendix A.1.

Backward for node featuresThe backward process for node features \(f_{i}^{}\) is \(}{_{i}^{(2)}}=_{i}( }{})^{}\). We bound the sensitivity of \(f_{i}^{}\) like forward process \(f_{i}\), leading to the same bound

\[s_{2}(f_{i}^{}) C^{2}s_{l}(i) \]

Backward for model parametersThe backward process for model parameters is \(}{}=^{}}_{sym}^{}}{}\). We notice that the actual function sensitivity can be significantly influenced by the Frobenius norms of all the three matrices that scale with the user number \(N\), leading to large noise added to the computed result. Therefore, we seek for an alternative to this computing process by splitting \(=_{p_{1}}_{p_{1}},_{p_{2}} ^{d_{in} d_{in}},_{p_{1}}^{d_{in} d_{out}}\) and freeze \(_{p_{1}}\) that is kept by the party \(_{2}\) without updating it. We initialize \(_{p_{2}}\) by normal distribution to approximate full rank and then clip it only once before training starts. The parameter \(_{p_{1}}\) is updated by \(_{1}\) without any communication to \(_{2}\) since components in \(}{_{p_{1}}}=(}_{sym }_{p_{1}})^{}}{ }\) are already known by \(_{1}\).

PrivacyWe independently apply aMGM mechanism to each user's social embedding based on its sensitivity bound (e.g., Eq.(4.3.2) and Eq.(9)). Eq.(8) suggests that the more social relations one user owns, the smaller sensitivity its computing process is, resulting in less noise being injected into the intermediates of this user. The total privacy cost can be estimated by the maximum privacy cost among users according to the parallel composition theorem (Shen et al., 2017). We follow (Shen et al., 2017) to accumulate privacy costs across iterations based on the privacy loss distribution of aMGM in Lemma.4.5.

**Lemma 4.5**.: _[Privacy Loss of aMGM(Shen et al., 2017)] The privacy loss variable of aMGM follows gaussian distribution \((,2)\) and \(\) is given by \(=^{-1}(f(X)-f(X^{}))^{-1}\|_{F}^{2}}{2}\)._

#### Efficiency

Batch-wise optimizationWe now show how to optimize the model in a batch-wise manner for efficiency. The full batch training will bring large communication and computation costs (e.g., frequently encrypting large matrices and transmitting the expanded ciphertext). To tackle this issue, for a batch of records \(\{(u_{k_{i}},v_{k_{i}},P_{k_{i}})\}||_{k=1}^{|B|}\), we denote the users in the current batch as \(^{|||N},|||B|\). Then, the corresponding computing process is

\[_{B}=(}_{sym})_{i} }{_{B}}=(}_{sym}^{})}{_{B}}^{} \]

In this way, the party \(_{2}\) can store the full ciphertext \([]\) that will be only encrypted once and batch-wisely update it by \(\)\([}{_{B}}]\). Unlike full batch training, the embeddings of users out of the batch cannot be updated. Otherwise, the social interactions will be easily exposed to the recommender.

CommunicationThe communication cost lies in the transmission of the encrypted middle matrices (i.e. \(\), \(}{_{B}}\)) and the results (i.e. \(_{B},}{_{B}}\)). Since \(\) is only encrypted and transmitted once, the total communication cost is \((Nd+TBd)\) over iterations \(T\) where \(}{_{B}},^{| | d_{out}}\), \(}{_{B}}^{||  d_{in}}\) and \(d=,d_{out})}\).

## 5. Evaluation

### Experimental Setting

  
**Dataset** & **CiaoDVD** & **FilmTrust** & **Douban** & **Epinions** \\ 
**Users** & 7375 & 1508 & 3000 & 22158 & 5258 \\
**Items** & 99746 & 2071 & 3000 & 296277 & 5258 \\
**Ratings** & 278483 & 35497 & 136891 & 728517 & 529 \\
**Social Links** & 111781 & 1853 & 7765 & 355364 & 528 \\
**Density\({}_{Rating}\)** & 0.0379\% & 1.1366\% & 1.5210\% & 0.0110\% & 522 \\
**Density\({}_{Link}\)** & 0.2055\% & 0.0815\% & 0.0863\% & 0.0723\% & 533 \\   

Table 1. Dataset statistics _Datasets._ We use four social recommendation datasets to validate the effectiveness of the proposed method: Filmtrust (Shi et al., 2018), CiaoDVD (Shi et al., 2018), Douban (Shi et al., 2018), and Epinions (Shi et al., 2018). Specifically, we set the social data owned by \(_{2}\) and other data owned by \(_{1}\). We show the statistics of the datasets in Table 1.

_Implementation._ All our experiments are implemented on a Ubuntu 16.04.6 server with 64 GB memory, 4 Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz, 4 NVidia(R) 3090 GPUs, and PyTorch 1.10.1.

_Baselines._ We compare P4GCN with two types of baselines. The first type contains traditional methods without using social data. These methods are concluded as follows

* **PMF(Huang et al., 2019)** is a classic matrix factorization model that only uses rating data on \(_{1}\).
* **NeuMF(Shi et al., 2018)** is a neuron-network-based matrix factorization method that has superior performance against traditional MF methods.
* **GCN(Shi et al., 2018)** is a classic convolutional graph neural network that only uses rating data on \(_{1}\).
* **LightGCN(Shi et al., 2018)** improves the convolutional graph neural network by reducing the parameters and aggregating the activations of different layers.
* **FeSoGe**-(Shi et al., 2018) removes the social aggregation module from the original version that requires social links to be stored together with user features, which will break our fundamental assumption of inaccessible social data. We compare FeSog with fully available data in Sec. 5.7

The second type contains methods that safely use social data to make social recommendations:

* **SeSoRec(Shi et al., 2018)** tries to solve the privacy-preserving cross-platform social recommendation problem, but suffers from excessive and efficiency problems.
* **SeSeNet(Shi et al., 2018)** is the state-of-the-art method that solves the safety problem and improves the efficiency within the scope of matrix factorization on the basis of **SeSoRec**.
* **P4GCN** (ours) is set to satisfy \((,)\)-DP guarantee (e.g., \(\) depends on the dataset) and **P4GCN\({}^{*}\)** corresponds to the ideal case without injecting DP noise.

_Hyper-parameters._ We fix the embedding dimensions \(k=64\) of the model for all the datasets. We tune the learning rate \(\{1e-3,1e-2,1e-1,1,10,100,1000\}\) and batch size \(|B|\{64,256,512,1024,2048,4096\}\), full to achieve each method's optimal results. We respectively limit the privacy budgets of P4GCN by \(=\{15,10,10,10,0,3.0\}\) and \(=1e-4\) across datasets in columns of Table 2 (i.e., FilmTrust, CiaoDvd, Douban, and Filmtrust). The hyper-parameter \(_{}\) is tuned on \(\{0.01,0.05,0.1,0.5,1.0,10.0,100.0\}\) and both \(_{}\) and \(_{}\) are tuned on \((1e-4,1e-3,1e-2,1e-1)\).

_Metrics._ We follow previous works (Chen et al., 2019) to use Root Mean Square Error (RMSE) and Mean Absolute Error (MAE) as the evaluation metrics of model performance.

### Model performance

From Table 2, we find that: (1) P4GCN\({}^{*}\) without DP consistently improves both MAE and RMSE metrics over all the baselines on the first three datasets (i.e., FilmTrust, CiaoDVD, and Douban) and achieves competitive results (e.g., RMSE= 1.0642, MAE=0.8186) against others' optimal results (e.g., RMSE\({}_{}=1.0746\) and MAE\({}_{}=0.8020\)). (2) Our proposed Sandwich Encryption Module can well preserve the final model performance over four datasets given proper privacy budgets, which achieves the optimal or second optimal results over 87.5% columns. (3) P4GCN exhibits superior performance to traditional matrix-decomposition-based social recommendation (e.g., SeSoRec and S3Rec), especially on datasets of large-scale (e.g., CiaoDVD with 7375 clients and Epinions with 22158 clients). We attribute this enhancement to the adaption of GNN which has a stronger representation ability than the traditional matrix-decomposition-based model in recommendation.

   &  &  &  &  \\   & & RMSE & MAE & RMSE & MAE & RMSE & MAE & RMSE & MAE \\   & PMF & 0.8007 & 0.6106 & 1.2245 & 0.9651 & 0.8361 & 0.6300 & 1.2487 & 0.9721 & 648 \\   & NeuMF & 0.8287 & 0.6319 & 1.1842 & 0.8839 & 0.7894 & 0.6222 & 1.1285 & **0.8020** & 648 \\   & GCN & 0.8765 & 0.6796 & 1.1076 & 0.8383 & 0.7989 & 0.6346 & 1.1513 & 0.8177 & 648 \\   & LightGCN & 0.7960 & 0.6079 & 1.1186 & 0.8396 & 0.7892 & 0.6209 & 1.0746 & 0.8412 & 649 \\   & FeSeg\({}^{-}\) & 0.8029 & 0.6118 & 1.2314 & 0.9741 & 0.8331 & 0.6498 & 1.2171 & 0.9530 & 651 \\   & SeSoRec & 0.8009 & 0.6106 & 1.1988 & 0.9635 & 0.8171 & 0.6316 & 1.2131 & 0.9598 & 652 \\   & S3Rec & 0.8009 & 0.6106 & 1.1988 & 0.9635 & 0.8171 & 0.6316 & 1.2131 & 0.9598 & 653 \\    & P4GCN & 0.7929 & 0.6059 & **1.0776** & **0.8224** & 0.7672 & **0.6023** & 1.0744 & 0.8272 & 655 \\    & P4GCN\({}^{*}\) & **0.7905** & **0.6032** & 1.0803 & 0.8225 & **0.7670** & 0.6035 & **1.0642** & 0.8186 \\  

Table 2. Comparison results of different models in terms of model accuracy (in RMSE and MAE). The optimal (second optimal) result of each column is bolded (underlined).

### Impact of privacy budget \(\)

_Privacy Budget._ We investigate the impact of privacy budget \(\) on our proposed method in Figure 4, where the red dashed line corresponds to results without leveraging social data and the green dashed line corresponds to the ideal results without adding DP noise. First, as the privacy budget grows properly, P4GCN introduces non-trivial improvements over the results without using social information (e.g., the bars below the red dashed lines). Second, our proposed privacy-preserving mechanism can well preserve the performance of the ideal case without adding DP noise (e.g., the green dashed lines), which confirms the effectiveness of our P4GCN in leveraging social data to enhance existing recommendation systems.

_Ablation on the fusion layer._ We further demonstrate the effectiveness of the fusion layer integrated into P4GCN by directly averaging the user social embeddings (e.g., scaled by \(\)) and the original user embeddings for comparison. As shown in Figure 4, P4GCN will suffer performance degradation after removing the fusion layer across different datasets, where most of the yellow bars are higher than the blue ones under the same privacy budget \(\). In addition, P4GCN w.o. the fusion layer failed to approximate the ideal performance even though the privacy budget is relatively large (e.g., \(=10.0\) in CiaoDVD), while the version w. Fusion did. This suggests the excellent ability of the fusion layer to aggregate the social information into the user features. Further, P4GCN with the fusion layer also shows a better tolerance to the low privacy budget than the one without using the fusion layer. For example, P4GCN w.o. the fusion layer will harm the original recommendation system on FilmTrust when \(=10.0\) and Douban when \(=5.0\), while the usage of the fusion layer decreases the minimal effective privacy budget. These results confirm the effectiveness of the proposed fusion layer in both handling DP-noise and fusing social information.

### Integrate To Existing Methods

We show that existing local recommendation methods (e.g., PMF and GCN) without considering social data can benefit from our proposed P4Layer on FilmTrust and CiaoDVD in Table 3, which suggests that companies can improve their local recommendation system by leveraging our proposed P4GCN in a plug-in manner. The parameters of differential privacy are consistent with the settings in Table 2.

### Impact of hyper-parameter \(\)

We study the impact of the choice of hyper-parameter \(\) on the model performance in Figure 5. We denote P4GCN without adding DP noise as the ideal case (e.g., the red notations). The figure shows that the optimal value of \(\) is always larger than 0 across all the datasets, indicating that the recommendation system can consistently benefit from social information integrated by our P4GCN regardless of differential privacy. In addition, the DP noise lowers the optimal degree of leveraging social information (e.g., the blue

Figure 4. The model performance RMSE and MAE of P4GCN w/w.o. fusion layer v.s. privacy budget \(\).

   } &  &  \\  & RMSE & MAE & RMSE & MAE \\   & **original** & 0.8007 & 0.6106 & 1.2245 & 0.9651 & 783 \\  & **+P4Layer\&DP** & **0.7997** & 0.6112 & 1.2163 & 0.9648 & 784 \\  & **+P4Layer-Ideal** & **0.7997** & **0.6105** & **1.2125** & **0.9642** & 786 \\   & **original** & 0.8765 & 0.6796 & 1.1709 & 0.8731 & 778 \\  & **+P4Layer\&DP** & 0.8569 & 0.6606 & **1.1388** & 0.8766 & 788 \\  & **+P4Layer-Ideal** & **0.8506** & **0.6486** & 1.1414 & **0.8598** & 790 \\   

Table 3. The improvement on model performance by integrating P4Layer to existing methods.

star never appears on the left of the red star) since the aggregation efficiency can be degraded by the noise. We also notice that a large value of \(\) will lead to the degradation of the model performance, which suggests the choice of \(\) should be very careful in practice. We consider how to efficiently and adaptively decide effective \(\) as our future works.

### Communication cost

We list the communication costs of P4GCN and another communication-efficient VFL social recommendation method (i.e., S3Rec (He et al., 2016)) in Table 4. We report the communication costs under fixed parameter settings (e.g., 3th-5th columns) and the practical settings used in Table 2 (e.g., the last columns). P4GCN causes nearly 2.2\(\) costs than S3Rec when the epoch number and batch size are fixed on three datasets (i.e., FilmTrust, CiaoDVD, and Douban), and P4GCN saves \(\) costs on Epinions. Although S3Rec exhibits lower communication amounts than P4GCN under fixed settings, P4GCN can achieve competitive communication efficiency when each method runs until reaching its optimal results. We also plan to further improve the communication efficiency of P4GCN in our future works.

### Comparison with FeSog w. social data

We finally compare our method with FeSog-Ideal which can directly access the full social data to verify the advantage of P4GCN in enhancing recommendation systems with social data. As shown in Figure 6, integrating social data can slightly improve model performance in FeSeg when the social data is fully available in most cases (e.g., CiaoDVD, Douban, and Epinions). However, FeSeg-Ideal failed to leverage social data to enhance performance in FilmTrust. We attribute this to the weak connection between social information and recommendations in FilmTrust, where S3Rec/SeSoRec also suffers similar failure and the improvement of P4GCN is also limited. Further, our P4GCN dominates FeSeg in terms of RMSE and MAE across all the datasets regardless of the availability of social data to FeSeg and the usage of differential privacy, which confirms the advantage of P4GCN in federated social recommendation.

## 6. Conclusion

This paper addresses the development of GNN-based models for a secure social recommendation. We present P4GCN, a novel vertical federated social recommendation approach designed to enhance recommendation accuracy when dealing with inaccessible social data. P4GCN incorporates a sandwich-encryption module, which guarantees comprehensive data privacy during collaborative computing. Experimental results on four datasets demonstrate that P4GCN outperforms state-of-the-art methods in terms of recommendation accuracy. We are considering leveraging other formats of graph information like LLM guidance, and knowledge graph, by P4GCN to enhance recommendation systems in our future works.

 
**Dataset** & **Method** & **B–64** & **B–1024** & **B–4096** & **Prac.** \\   & P4GCN & 10.70 & 10.68 & 3.81 & 61.77 \\  & S3Rec & 5.48 & 5.47 & 1.78 & 118.33 \\   & P4GCN & 21.88 & 21.88 & 21.74 & 21.88 \\  & S3Rec & 15.01 & 15.01 & 14.88 & 21.00 \\   & P4GCN & 42.28 & 42.22 & 31.44 & 82.18 \\  & S3Rec & 19.23 & 19.20 & 14.01 & 33.70 \\   & P4GCN & 394.44 & 394.44 & 394.24 & 716.38 \\  & S3Rec & 1160.98 & 1160.96 & 1160.09 & 2785.83 \\  

Table 4. Communication costs (GB) under the fixed epoch \(E=5\) with varying batch sizes (e.g., 64, 1024, and 4096) and the practical cost in our experiments in Table 2 (e.g., the last column)

Figure 5. The impact of social aggregation degree \(\) v.s. model performance (i.e. MAE)

Figure 6. The model performance of FeSeg and P4GCN across datasets where smaller areas are better. Each metric is divided by its corresponding maximum value for a clear view.