# Unleashing the Power of Large Language Models for Denoising Recommendation

Anonymous Author(s)

###### Abstract.

Recommender systems are vital for personalizing user experiences, yet they often rely on implicit feedback data that can be noisy and misleading. Existing denoising studies typically involve either incorporating auxiliary information or learning denoising strategies from interaction data. Nonetheless, they face challenges due to the inherent limitations of external knowledge and interaction data, as well as the non-universality of certain predefined assumptions, which hinder their ability to accurately identify noise. Recently, large language models (LLMs) have garnered significant attention due to their extensive world knowledge and powerful reasoning capabilities. Despite this, the potential of LLMs to enhance the denoising process in recommendations remains largely unexplored. In this paper, we introduce LLad, a novel framework that leverages LLMs to improve the denoising process in recommender systems, thereby enhancing overall recommendation performance. Specifically, LLad generates denoising-related knowledge by first enriching semantic insights from observational data through LLMs, facilitating a comprehensive inference of user-item preference knowledge. It then employs a novel Chain-of-Thought (CoT) technique over user-item interaction graphs to uncover relation knowledge pertinent to denoising. Finally, it utilizes the Information Bottleneck (BI) principle to align the denoising knowledge generated by LLMs with the recommendation targets, effectively filtering out both data noise and irrelevant knowledge produced by the LLMs. Empirical results demonstrate the effectiveness of our proposed framework, showcasing its superior performance in denoising and recommendation accuracy. The code is available at [https://anonymous.4open.science/r/LLad-5EE5](https://anonymous.4open.science/r/LLad-5EE5).

+
Footnote †: ccs: Information and machine learning systems

+
Footnote †: ccs: Information and machine learning systems

+
Footnote †: ccs: Information and machine learning systems

+
Footnote †: ccs: Information and machine learning systems

+
Footnote †: ccs: Information and machine learning systems

+
Footnote †: ccs: Information and machine learning systems

+
Footnote †: ccs: Information and machine learning systems

+
Footnote †: ccs: Information and machine learning systems

+
Footnote †: ccs: Information and machine learning systems

+
Footnote †: ccs: Information and machine learning systems

+
Footnote †: ccs: Information and machine learning systems

+
Footnote †: ccs: Information and machine learning systems

+
Footnote †: ccs: Information and machine learning systems

## 1. Introduction

Recommender systems (Kang et al., 2016; Li et al., 2016; Wang et al., 2017; Wang et al., 2017) have become essential for mitigating information overload and delivering personalized services. High-quality interaction data that accurately reflect user preferences play a crucial role in enhancing the performance of these recommendation models. In the context of limited explicit feedback (Kang et al., 2016; Li et al., 2016), implicit feedback (_e.g._, click, purchase and views) has emerged as a popular alternative due to its abundance and ease of collection (Li et al., 2016; Li et al., 2016). However, implicit feedback data are often noisy and influenced by various incidental factors, which can hinder their ability to accurately represent user preferences (Li et al., 2016; Wang et al., 2017; Wang et al., 2017). For instance, false positive interactions (Li et al., 2016) may arise from users' curiosity-driven clicks or unsatisfactory purchases, while false negative interactions (Li et al., 2016) can result from limited exposure or restricted browsing opportunities.

To tackle the challenge of noisy implicit feedback, denoising has become a significant focus in recommendation research, which can be broadly categorized into two main approaches:

* **Denoising based on side information.** Early studies (Bishop, 1996; Hinton et al., 2006; Goodfellow et al., 2014) utilize user dwell time and gaze patterns to identify noise. Subsequent work incorporates sequence (Zhu et al., 2017) and multi-behavior data (Kang et al., 2016; Wang et al., 2017; Wang et al., 2017) for more effective noise detection. Recent approaches integrate external knowledge graphs (Li et al., 2016; Li et al., 2016; Li et al., 2016) or social graphs (Li et al., 2016); (Li et al., 2016) to better model user preferences. However, these methods can incur high data collection costs, and large-scale graphs may introduce additional noise, such as irrelevant attributes diluting user signals (Li et al., 2016) or simplistic integrations amplifying noise (Li et al., 2016).
* **Denoising driven by interaction data.** These methods utilize data selection and weighting strategies. Selection-based approaches (Kang et al., 2016; Li et al., 2016; Li et al., 2016) identify and filter noisy interactions by analyzing data features or employing decision networks. For example, (Li et al., 2016) introduces an adaptive training strategy, while (Li et al., 2016; Li et al., 2016) develop networks to exclude noisy samples. Reweighting-based methods (Li et al., 2016; Wang et al., 2017) adjust sample weights during training to mitigate noise effects, such as T-CE (Li et al., 2016) which uses training loss for noise identification, BOD (Wang et al., 2017) which leverages interaction-derived priors with a bi-level optimization process.

Despite the effectiveness of interaction data-driven methods, they usually exhibit notable limitations. Firstly, they focus on learning user preferences from interaction data to identify noise. However, limited observational data result in only a partial understanding of user preferences, particularly in recognizing interactions that signal new interests or exploration tendencies (Li et al., 2016; Wang et al., 2017). For instance,

Figure 1. (a) An intuitive example of learning user preferences from observational data. (b) Improvements of our method (red) over existing methods (dark green).

in Figure 1(a), the pink area represents the user's true preference space \(P\), while the green area denotes the observable preference space \(\). The intersection \(P\) reflects the true preferences inferred from observational data. Interactions deemed as noise often consist of data inconsistent with currently learned preferences. For example, if an art enthusiast accidentally clicks on a gardening video, it may be labeled as noise, but it might indicate a latent interest in gardening sketches. Secondly, some studies rely on predefined assumptions (Zhu et al., 2017; Zhang et al., 2018) in the noise identification process. For instance, (Zhu et al., 2017) judging high-loss samples in training as noise, which inadequately captures user preferences and potential associations during noise identification (_e.g.,_ links between fine arts and gardening). Consequently, it will diminish the model's effectiveness in denoising. To enhance the understanding of user preferences, large language models (LLMs) (Golovneel et al., 2013; Zhang et al., 2018; Zhang et al., 2019) present a promising direction due to their extensive world knowledge and reasoning capabilities. Recent studies (Zhu et al., 2017; Zhang et al., 2018) have explored the application of LLMs in recommendation systems to improve the robustness of user representations by incorporating additional semantic and textual information. However, these approaches primarily enhance the semantic richness of representations while they insufficiently leveraging the potential of LLMs for denoising.

To explore the potential of LLMs for denoising in recommendation, we must address several significant challenges.

* **C1: How can LLMs effectively mine information relevant to denoising?** LLMs excel at processing textual information, allowing us to expand and enrich semantic insights that can inform denoising efforts. However, the interactive data represented in the graph structure of users and items contains rich collaborative information that is also valuable for denoising. Unfortunately, LLMs struggle to process this complex graph data effectively.
* **C2: How can we utilize the information generated by LLMs for denoising?** While LLMs can produce additional knowledge for denoising, they may also generate hallucinations (Zhu et al., 2017), making direct application potentially suboptimal. Thus, it is crucial to consider how to constrain the knowledge generated by LLMs to align with the specific prediction targets in recommendations.

To address these challenges, we propose the **L**arge **L**anguage **M**odel-enhanced **R**ecommendation **D**enoiser (LLaRD), a novel framework designed to develop recommendation models that are robust to noisy data. LLaRD consists of two main components: a knowledge generation module and a knowledge-enhanced denoising module. To tackle **C1**, the knowledge generation module leverages LLMs to extract two types of denoising-related knowledge: 1) **Preference knowledge**. Utilizing the inherent world knowledge of LLMs, we enrich the semantic information of the data through the analysis, reasoning, and refinement of text and interaction data. This process extrapolates the scope of observational data and infers user and item preferences more comprehensively. 2) **Relation knowledge**. We implement a novel chain-of-thought (CoT) prompting strategy (Zhu et al., 2017; Zhang et al., 2018; Zhang et al., 2019) over graph structures to expand relation knowledge by iteratively reasoning about connections among users, items, and their neighborhood subgraphs. This approach encourages LLMs to consider key collaborative information hidden within the graph structure, thereby capturing relation knowledge pertinent to denoising. To address **C2**, the knowledge-enhanced denoising module is built upon the Information Bottleneck (IB) (Zhu et al., 2017; Zhang et al., 2018; Zhang et al., 2018). It maximizes the mutual information across denoised data, generated knowledge, and recommendation targets, while minimizing the mutual information between the denoised data and the original data. This mechanism further filters out knowledge irrelevant to denoising from the information generated by LLMs, reducing the integration of irrelevant information, such as hallucinations, and thereby enhancing denoising performance. As illustrated in Figure 1(b), we anticipate that LLMs will improve the learning process of the denoising model, enabling it to more accurately capture the trajectory of true user preferences (orange arrow) and extensively encompass the preference area (pink region). In summary, our approach facilitates enhanced denoising by utilizing LLM-driven insights to improve recommendation performance.

The main contributions of this paper are summarized as follows:

* We identify and address the limitations of existing denoising recommendation methods, proposing a novel application of LLMs' world knowledge and reasoning capabilities to enhance the performance of recommendation models.
* We introduce LLaRD, a framework that integrates knowledge generation and knowledge-enhanced denoising strategies to leverage the capabilities of LLMs for achieving noise-robust recommendation models.
* We validate the effectiveness of LLaRD through extensive experiments on three benchmark datasets and two mainstream backbone models, demonstrating the framework's superior performance in denoising recommendation.

## 2. Preliminaries

### Denoising Recommendation

Let the user set be \(=\{u\}\) and the item set be \(=\{i\}\), with \(||\) and \(||\) representing the number of users and items, respectively. The interaction matrix is \(\{0,1\}^{||||}\), where \(r_{ui}=1\) indicates that user \(u\) has interacted with item \(i\). Given the interaction data \(=\{(u,i,r_{ui})|u,i\}\), we train a recommendation model \(f\) with parameters \(_{f}\) to predict the likelihood of user interactions with unseen items, formulated as \(_{f}=_{_{f}}_{rec}()\), where \(_{rec}\) is the recommendation loss. Using the BPR (Zhu et al., 2017) loss as an example, we have:

\[_{rec}=_{(u,i,j)-}((f(_{u}) ^{}f(_{i}))-f(_{u})^{}f(_{j})), \]

where \(_{u/i}^{d}\) is the user/item representations, and \(()\) is the sigmoid function. The triple \((u,i,j)\) consists of user \(u\), positive sample \(i\), and negative sample \(j\), sampled pairwise from \(\). While \(r_{ui}=1\) typically indicates a positive preference, observed interactions (_e.g.,_ views, clicks, and purchases) may introduce noise that does not accurately reflect true preferences. The denoising recommendation task aims to learn a clean interaction matrix \(^{*}\{0,1\}^{||||}\) representing users' genuine preferences or to derive noise-free representations \(_{u/i}^{*}^{d}\) from the noisy data.

### Information Bottleneck

The Information Bottleneck (IB) (Zhu et al., 2017; Zhang et al., 2018; Zhang et al., 2018) is a powerful framework rooted in information theory, commonly used for representation learning. Its goal is to enhance the robustness of learned representations for downstream tasks by discarding task-irrelevant information from the input data. We give the following definition:

Definition 1 (Information Bottleneck).: _Let \(X\) and \(Y\) be random variables with joint distribution \(p(X,Y)\), where \(X\) contains information relevant to \(Y\). The relevant information is quantified by the mutual information \(I(X;Y)\). The IB framework seeks the most informative yet compressed representation \(Z\) by optimizing the objective: \(_{Z}\{I(Y;Z),I(X;Z) I_{c}\}\), where \(I_{c}\) is the information constraint between \(X\) and \(Z\)._

By introducing a Lagrange multiplier \(\), the constrained optimization is reformulated as an unconstrained objective: \(_{Z}I(Y;Z)- I(X;Z)\). The IB principle is widely applied to generalization and denoising tasks. Several studies (Zhou et al., 2017; Zhang et al., 2018) employ the Graph Information Bottleneck (GIB) principle to identify stable subgraphs to enhance model generalization, while methods like CGI (Zhou et al., 2017) leverage the IB framework for denoising recommendation.

### Chain-of-Thought Prompting

Chain-of-Thought (CoT) prompting (Zhou et al., 2017; Zhang et al., 2018; Zhang et al., 2018; Zhang et al., 2018) enhances the reasoning capabilities of LLMs by guiding them to generate intermediate reasoning steps structured as \(<\) input, thoughts, output \(>\) instead of directly producing answers. This approach improves both interpretability and accuracy, particularly for tasks requiring multi-step reasoning or logical deductions.

Definition 2 (CoT Prompting).: _CoT prompting directs a language model to produce a sequence of intermediate reasoning steps \(R\) before generating the final output \(Y\), given an input prompt \(X\). Mathematically, this framework models the output \(Y\) as:_

\[p(Y|X)=_{R}p(Y|R,X),p(R|X). \]

_This decomposition transforms complex tasks into manageable subtasks, enhancing the reasoning capabilities of model._

By generating structured reasoning steps, CoT prompting enables more accurate and reliable responses in complex tasks.

## 3. Methodology

In this section, we introduce the Large Language Model-enhanced Recommendation **D**enoiser (LLaRD). As illustrated in Figure 2, it comprises two knowledge generation modules and a denoising module. Below, we provide a detailed overview of each component.

### Preference Knowledge Generation

In this module, we extract semantic preference information from textual data and user-item interactions despite inherent data noise. For example, the Amazon-Book dataset includes descriptions with irrelevant attributes, and reader reviews are often subjective and unstructured, featuring imaginative content, citations, or counterfactual statements. These factors complicate the direct extraction of meaningful preference semantics. To address this issue, we adopt methods from prior studies (Zhou et al., 2017; Zhang et al., 2018), utilizing LLMs for text denoising and preference knowledge reasoning. We design system prompts \(S_{u}\) and \(S_{i}\) for users and items, respectively, and construct configuration texts \(_{u}=\{T_{u}^{1},T_{u}^{2},...,T_{u}^{||}\}\) and \(_{i}=\{T_{i}^{1},T_{i}^{2},...,T_{i}^{||}\}\) for each user and item as follows:

\[T_{u}^{k}=, \]

\[T_{i}^{k}=. \]

The reasoning process of profile information is defined as:

\[_{u},_{i}=([S_{u}\|T_{u}],[S_{i}\|T_{i}] ), \]

where LLM(\(\)) denotes the LLM reasoning process, \(\) denotes the concatenation of the system prompt and configuration texts. \(_{u}\) and \(_{i}\) denote the profile information for each user and item, respectively. While LLMs effectively refine user preferences and item features, integrating extensive textual knowledge for collaborative analysis across thousands of users and items leads to semantic imprecision and high token inference costs. To mitigate these issues, we propose a keyword condensation technique for each user and item, reducing semantic ambiguity and enabling incremental updates to preference semantics. This approach accommodates the dynamic nature of users and items, ensuring robust and efficient preference extraction. Furthermore, we enhance system prompts by introducing the \(S_{u/i}^{}\) which guides LLMs to refine the keywords of user preferences and item features based on the obtained profile information \(_{u}\) and \(_{i}\). The keyword generation process is defined as follows:

\[_{u},_{l}=([S_{u}^{}\|_{ u}],[S_{i}^{}\|_{i}]), \]

where \(_{u}=\{A_{u}^{1},A_{u}^{2},...,A_{u}^{||}\}\) and \(_{l}=\{A_{i}^{1},A_{i}^{2},...,A_{i}^{||}\}\). We then combine the profile information \(_{u/i}\) with keywords \(_{u/i}\) to form the preference knowledge \(_{u/i}\). The preference knowledge \(_{u/i}\) is converted into token sequences, resulting in token embedding matrices \(_{u/i}=\{_{1},_{2},...\}\). These token embeddings are processed through a multi-layer perceptron (MLP) network \(W_{t}\) to generate semantic embeddings for each user and item:

\[}_{u},}_{t}=W_{t}(([_{u}, _{i}]))+b. \]

Finally, we encapsulate the obtained preference semantic embeddings \(}_{u}\) and \(}_{t}\) into the preference knowledge \(_{p}\) as:

\[_{p}=\{}_{u}=\{}_{u1},}_{u2},...\},}_{t}=\{}_{i1},}_{i2},...\}\}. \]

### Relation Knowledge Generation

Previous studies utilizing LLMs to infer user preferences from interaction sequences often struggle to capture multi-hop relationships and long-path dependencies essential for understanding complex interactions. In contrast, our approach leverages the reasoning capabilities of LLMs over graph-structured data. By integrating preference semantics with collaborative information, we enable LLMs to identify associative semantics among multiple interaction nodes. Furthermore, we iteratively infer additional interaction edges to construct a relation knowledge graph, enhancing the graph learning process and improving the denoising of implicit feedback.

#### 3.2.1. **User-Centric CoT Reasoning Framework**

The collaborative information within the user-item interaction graph is invaluable for denoising. However, LLMs often struggle to achieve strong reasoning performance when dealing with complex interconnected data. To address this, we introduce a user-centric CoT reasoning framework. It meticulously designs inputs for multi-hopinteractions within user-centric neighborhoods and analyzes noisy and latent interactions based on semantic associations. By mining associative semantics between multi-hop neighbors through a multi-step reasoning process, we maintain LLM performance despite the complexity and volume of historical data. Additionally, the LLM is required to provide reasoning foundations and explanatory text when inferring potential interaction edges, enhancing the interpretability and transparency of the decision-making mechanisms.

**Step1: Preference Ratings.** We represent the preference of each user for items in their interaction sequence using a three-tier rating system: \(\{ {High, Medium, Low} \}\). For a user \(u\), given the preference knowledge containing profile information and preference keywords, along with the interaction sequence \(_{u}^{(1)}=\{i_{1},i_{2},...\}\) and attribute keywords list \(A_{k}^{k}\) for each item \(i_{k}\), we follow the steps referring the Figure 2 for LLM inference. The output is a rated interaction sequence \(_{u}^{Rated}=\{(i_{1},l_{ui_{1}}),(i_{2},l_{u_{2}}),...\}\), where \(i_{k}\) denotes an item interacted with by user \(u\), and \(l_{u_{k}}\{ {High, Medium, Low} \}\) represents the user's preference rating for \(i_{k}\).

**Step2: Noise Identification.** Building on Step 1, we enable the LLM to identify noise among interactions rated as \(Low\), denoted by \(_{u(low)}^{(1)}=\{i_{k}_{u}^{(1)} l_{u_{k}}=Low\}\). The set of noise interactions is defined as:

\[I_{u}^{Noise}=\{i_{k}_{u(low)}i_{k}\}. \]

Consequently, the noise interaction edges for each user are represented by:

\[^{Noise}=\{(u,i_{k}) u,i_{k} I_{u}^{Noise}\}. \]

By rigorously analyzing the semantic associations between user preferences and item attributes, our approach minimizes the misclassification of interactions that may reflect latent user interests. This sophisticated semantic analysis enables the model to discern and retain interactions that, although rated \(Low\), may indicate emerging or subtle preferences.

**Step3: Collaborative Enhancement.** We perform second-hop neighbor exploration within the neighborhood of user \(u\) to identify users with similar preferences, constructing enhanced collaborative interactions through semantic associations. Utilizing the preference ratings from Step 1, we focus on items rated as \(High\), defined as \(_{u(high)}^{(1)}=\{i_{k}_{u}^{(1)} l_{u_{k}}=High\}\). The set of second-hop neighbors is then determined by: \(_{u}^{(2)}=_{i_{k}_{u(high)}}U_{u_{k}} \{u\}\), where \(U_{u_{k}}\) represents users who have interacted with item \(i_{k}\), \(\) represents the union operation, and \(\{u\}\) ensures that user \(u\) is excluded from their own set of neighbors. Subsequently, we identify collaboratively enhanced users through LLM inference:

\[_{u}^{Collab}=\{u_{k}_{u}^{(2)}i_{k}\}. \]

The corresponding set of collaborative enhancement interaction edges for each user is represented as:

\[^{Collab}=\{(u,u_{k}) u,u_{k}_{u}^{ Collab}\}. \]

This collaborative enhancement leverages semantic associations to connect users with similar high-preference interactions, thereby enriching the recommendation capability to accurately discern and predict user preferences.

**Step4: Interests Exploration.** In this step, we utilize LLM reasoning to explore interests within the third-hop neighborhood of user \(u\). To prevent an exponential growth of high-order neighbors in the interaction graph, we selectively retain only interaction edges labeled as \(High\), emphasizing their importance in accurately reflecting user preferences. Building on the preference intensities from previous steps and the analysis of first- and second-order neighbors, we infer potential interest interactions among third-order neighbors, defined as: \(_{u}^{(3)}=_{u_{k}_{u(high)}^{(2)}}I_{u_{k}} _{u}^{(1)}\). We then identify the set of interest items for user \(u\) as:

\[I_{u}^{Interests}=\{i_{k}_{u}^{(3)}i_{k}\}. \]

Figure 2. The overview of the proposed LLaRD framework.

The corresponding set of interest interaction edges is represented by:

\[^{Interests}=\{(u,i_{k}) u,i_{k} I_{u}^{Interests}\}. \]

Utilizing our user-centric CoT reasoning framework, we integrated collaborative information from the interaction graph with preference semantics. This integration enabled the identification of potential interactions that accurately reflect users' true preferences and encapsulate associative semantics. Through this multi-step reasoning process, we effectively capture the underlying association semantics, enhancing the ability of discerning and predicting nuanced user preferences and improving recommendation.

#### 3.2.2. Relation Knowledge Construction

To effectively leverage the reasoning results, we construct the above three distinct groups of interaction edges as relation knowledge:

\[_{r}=\{^{Noise},^{Collab},^{Interests}\}. \]

Subsequently, we integrate this relation knowledge into the original interaction graph \(=(,,)\), where \(\) and \(\) represent the sets of users and items, respectively, and \(=\{(u,i)|u,i,r_{ui}=1\}\) denotes the existing interaction edges. The enriched interaction graph \(_{rel}\) is formulated as:

\[_{rel}=(,,(^{Noise})^{Collab}^{Interests}). \]

This enriched graph incorporates the relation knowledge by removing noise interactions and adding collaborative and interest-based interactions. This integration enhances the downstream denoising learning process, enabling more accurate and semantically rich preference extraction.

### Knowledge-enhanced Denoising

After generating denoising knowledge, it is essential to use this to guide the denoising process. To achieve this, we propose a knowledge-enhanced denoising learning approach. As illustrated in the lower half of Figure 2, this approach includes a mask generator and a knowledge-guided information bottleneck framework.

#### 3.3.1. Mask Generator

To effectively capture comprehensive user preferences and latent semantic associations within the graph structure, we incorporate additional injected knowledge. This enhanced understanding facilitates data selection, reweighting, and representation learning, enabling a robust recommendation model even when denoising is limited to observed data. We employ a mask generator to create a learnable mask that distinguishes noisy interaction edges from informative ones in the original interaction data. Specifically, given the interaction graph \(=(,)\), where \(=\) and \(=\{(u,i)|u,i,r_{ui}=1\}\), each edge is associated with a random variable \(q()\). An edge is retained if \(q=1\) and deleted otherwise. We parameterize the Bernoulli parameter \(\) using a MLP network \(\) as \(=(_{u}\|_{t})\), where \(\|\) denotes concatenation, and \(_{u},_{t}^{d}\) are the embeddings of user \(u\) and item \(i\) from the original interaction graph \(\). To enable end-to-end training, we adopt the Gumbel-Softmax reparametrization trick, converting the discrete variable \(q\) into a continuous variable in the range \(\):

\[q=((-(1-)+_{m})/), \]

where \(\) is the temperature hyperparameter and \((0,1)\). As \( 0\), \(q\) approaches a binary value. Finally, we obtain the masked graph \(^{}=(,,^{})\), where \(^{}=\{(u,i)(u,i),q_{m} 1\}\). This denoised graph retains only the informative interaction edges deemed relevant by the mask generator, thereby enhancing the downstream denoising learning process.

#### 3.3.2. Knowledge-guided Information Bottleneck for Denoising

Building on the Information Bottleneck (IB) principle, we present an optimization framework for denoising interaction graphs. Our dual objectives are to maximize the retention of user preference information in the denoised graph and to minimize the mutual information between the denoised and original graphs. To comprehensively capture true user preferences, we integrate supervisory signals from interaction data with additional knowledge from LLMs, encompassing both explicit preferences and latent semantic associations. This combined approach effectively guides the denoising process. The optimization objective is formally expressed as:

\[_{^{}}I(;^{})+ I( _{p};_{r};^{})- I(^{ };), \]

where \(I(;^{})\) denotes the mutual information between recommendation targets \(\) and the denoised graph \(^{}\). \(I(_{p},_{r};^{})\) incorporates the mutual information between preference knowledge \(_{p}\) relation knowledge \(_{r}\), and the denoised graph \(^{}\) integrating additional supervisory signals from LLMs. \(I(^{};)\) denotes the mutual information between the denoised graph \(^{}\) and the original graph \(\) Here, \(\) and \(\) are the hyperparameters that balance the influence of knowledge integration and noise reduction, respectively. Next, we detail the implementation of each term in Equation (18).

**Term1: Maximizing Mutual Information with Recommendation Information.** The first term aims to maximize information relevant to the recommendation task. We maximizes mutual information with the task-related information within \(^{}\) by minimizing the BPR loss:

\[_{rec}=_{(u,i,j)}-(y_{ui}^{}-y_{ ui}^{}) y_{ui}^{}=_{u}^{_{i}}_{i}^{ }, \]

where \(=\{(u,i,j)|(u,i)^{+},(u,j)^{-}\}\) is the training set, \(_{u/i}\) and \(_{u/i}^{}\) are the user and item representations after \(L\) GNN layers on \(^{}\). Minimizing \(_{rec}\) effectively maximizes \(I(;^{})\), ensuring that the denoised graph retains essential preference information from recommendation prediction.

**Term2: Preference & Relation Knowledge Integration.** The second term promotes retaining information in the denoised graph \(^{}\) that integrate with both preference knowledge \(_{p}\) and relation knowledge \(_{r}\). Given the collaborative embeddings \(_{u}\) and the preference knowledge embedding \(}_{u}\) and \(}_{t}\) from \(_{p}\), our optimization objective uses the InfoNCE (Golov et al., 2013) loss to denote:

\[_{prf}=_{v}-(_ {v}^{},}_{v})/)}{_{v^{}^{ },v^{} v}((_{v}^{},}_{v^{}})/^{})}, \]

which sim(-) is the cosine similarity function, and \(^{}\) is the temperature parameter. \(_{v}^{}\) is the final representation on \(^{}\) after \(L\) GNN layers, and \(}_{v}\) are embeddings derived from preference knowledge \(_{p}\) Minimizing \(_{prf}\) enhances the agreement between \(^{}\) and preference knowledge, capturing user preferences within semantic information. For the relation knowledge \(_{r}\), we treat the relation knowledge graph \(_{rel}\) with embeddings \(_{u}=\{}_{u1},}_{u2},...\}\) and \(}_{i}=\{}_{i1},}_{i2},...\}\) as an augmented view of the interaction graph. After \(L\) GNN layers on \(_{rel}\), we obtain representation \(}_{u}\) and \(}_{i}\). The optimization objectives is defined as:

\[_{rel}=_{}-_{o}^{},}_{o})/^{})}{_{^{} ^{},^{}}((_{o}^{ },}_{^{}})/^{})}, \]

where \(^{}\) is the temperature parameter and \(()\) is the cosine similarity function. Minimizing \(_{rel}\) integrates \(^{}\) with relation knowledge \(_{r}\), capturing latent semantic associations within the graph structure.

**Term3: Minimizing Mutual Information for Denoising.** The third term facilitates the compression of information in the original interaction graph, filtering out of redundant interactions. Directly minimizing mutual information between two high-dimensional graph representations is computationally intractable. To overcome this, we utilize the Hilbert-Schmidt Independence Criterion (HSC) as an approximation for mutual information between \(\) and \(^{}\).

First, we select appropriate kernel functions \(k()\) and \(m()\) for \(\) and \(^{}\), respectively. For instance, Gaussian kernels are employed:

\[k(_{o},_{j})=(-_{o}-_{j}\|^{2}}{2_{k}^{2}}),\;m(_{o}^{}, _{j}^{})=(-_{o}^{}- _{j}^{}\|^{2}}{2_{m}^{2}}), \]

where \(_{k}\) and \(_{m}\) are kernel bandwidth parameter, \(\) and \(^{}\) are the user/item representation of \(\) and \(^{}\), respectively. Using these kernel functions, we compute the kernel matrices \(K\) and \(M\) from the \(\) and \(^{}\):

\[=[k(_{o},_{j})]_{n m},=[m( _{o}^{},_{j}^{})]_{n m}, \]

where \(n\) is the number of users/items in the graph and \(o,j[0,n]\). To center the kernel matrices and remove the mean, we apply the centering matrix \(=-^{}\), where \(_{n}\) is the \(n n\) identity matrix and \(\) is an \(n\)-dimensional vector of ones. The centralized kernel matrices are \(}=\) and \(}=\). Using the centralized matrices \(}\) and \(}\), we compute HSC as an approximation of mutual information between \(\) and \(^{}\):

\[(,^{})=}( }}). \]

The loss term for information compression using HSIC is defined as:

\[_{comp}=(,^{})=}(}}). \]

Minimizing HSIC effectively reduces the mutual information between the original graph \(\) and the denoised graph \(^{}\), ensuring that \(^{}\) retains only the information necessary for the recommendation task, thereby achieving maximum compression and eliminating redundant interactions.

**Model Optimization.** The overall loss function combines the BPR loss, preference & relation knowledge and information compression loss, defined as:

\[=_{rec}+(_{prf}+_{rel})+ _{comp}, \]

where \(\) and \(\) are hyperparameters that balance the contribution of the preference alignment loss and the information compression loss, respectively.

## 4. Experiments

To evaluate the effectiveness of LLaRD, we carry out a series of experiments to address the following **R**esearch **Q**uestions:

* **RQ1:** How does LLaRD perform compared to various state-of-the-art denoising models when applied to different backbones?
* **RQ2:** How can we verify the effectiveness of denoising knowledge mined by LLMs in denoising learning?
* **RQ3:** How effectively can LLaRD help the model acquire robust representations mitigate noise issues?
* **RQ4:** Is LLaRD effective in boosting the performance of cold-start users?

### Experimental Settings

We conduct experiments on three benchmark datasets: Steam, Yelp, and Amazon-Book. We use two backbone models: GMF (Zhou et al., 2017) and LightGCN (Zhou et al., 2017). Our baseline methods consist of instance-level denoising and representation-level denoising. The instance-level method include WBPR (Zhou et al., 2017), T-CE (Zhou et al., 2017), R-CE (Zhou et al., 2017), DeCA (Zhou et al., 2017), SGD (Zhou et al., 2017) and DCF (Zhou et al., 2017). The representation-level method include SGD (Zhou et al., 2017), SimGCL (Zhou et al., 2017) and RLMRec (Zhou et al., 2017). More details of the dataset and implementation are provided in Appendix B.

### Performance Comparison (RQ1)

To evaluate the effectiveness and generalizability of our framework, we compared our proposed LLaRD method with existing denoising baselines across three datasets and two backbone models. The following observations summarize our findings:

* Our proposed LLaRD consistently outperforms mainstream denoising techniques across all three datasets and both backbone models. On average, LLaRD surpasses the second-best model, BOD, by approximately 6.92% when integrated with GMF, and by 11.79% with LightGCN. Although BOD employs a bi-level optimization strategy to extract prior knowledge, it lacks a comprehensive understanding of preferences and mining the relational semantics within interaction samples, resulting in inferior performance compared to our method.
* Against interaction data-driven methods such as T-CE, DeCA, DCF, and SGDL, which are constrained to identifying patterns within observed data and rely on training loss for noise identification, LLaRD demonstrates a substantial performance improvement ranging from 46.1% to 68.53%. This significant enhancement is attributed to our utilization of LLMs to infer user preferences beyond the available interaction data and the application of CoT reasoning to progressively uncover complex semantic associations within the interaction graph, thereby eliminating dependence on predefined assumptions.
* LLaRD outperforms robust representation learning methods by approximately 34.34% to 49.31%. The LLa-enhanced method, RLMRec, also achieves a significant 14.93% improvement over traditional approaches like SGD and SimGCL by aligning user preferences across semantic and collaborative spaces, demonstrating the effectiveness of LLMs in providing task-relevantinformation. However, LLaRD surpasses these methods by not only ensuring robust representations but also addressing data-level denoising. It leverages higher-order associative semantics compared to RLMRec and enhances noise recognition capabilities, resulting in superior performance.

### Ablation Study (RQ2)

To verify the effectiveness of denoising knowledge mined by LLMs and ensure its effective utilization in model learning, we conduct ablation studies to assess the contributions of various components within LLaRD. We design the following four model variants:

* w/o \(_{}\): Removes the process of minimizing mutual information between the denoised and original interaction graph.
* w/o \(_{}\): Removes the process of maximizing mutual information between the denoised graph and denoising knowledge.
* w/o PK: Removes the integration of preference knowledge in the denoising framework.
* w/o RK: Removes the integration of relation knowledge in the denoising framework.

As shown in Table 2, removing certain components leads to varying degrees of the performance degradation in LLaRD. The most significant decline occurs with the **w/o \(_{}\)** variant, demonstrating the effectiveness of our denoising approach based on the information bottleneck principle. Additionally, omitting either preference knowledge (**w/o PK**) or relation knowledge (**w/o RK**) results in performance reductions, highlighting their importance for denoising recommendations. Furthermore, when using the **w/o \(_{}\)**, the performance decreases, underscoring the significance of denoising knowledge for model learning.

### Model Benefits Analysis (RQ3 & RQ4)

**Robustness to Noisy Interactions.** To evaluate the robustness of LLaRD to noisy interactions, following previous studies (Zhu et al., 2019; Wang et al., 2020), we conducted experiments by introducing adversarial interaction examples (_i.e._, 5%, 10%, 15%, and 20% negative user-item interactions) into the training set, while keeping the test set unchanged. Figures 3(a) and 3(b) present the results on the Amazon-Book and Steam datasets, respectively. This demonstrates that LLaRD consistently outperforms all baseline methods across all noise levels. Additionally, the performance drop of LLaRD remains relatively

    &  &  &  \\ 
**Backbone** & **Method** & **R@10** & **N@10** & **R@20** & **N@20** & **R@10** & **N@10** & **R@20** & **N@20** & **R@10** & **N@10** & **R@20** & **N@20** \\    & Normal & 0.0506 & 0.0399 & 0.0740 & 0.0463 & 0.0437 & 0.0352 & 0.0787 & 0.0465 & 0.0603 & 0.0512 & 0.0984 & 0.0599 & 768 \\  & WBPR & 0.0513 & 0.0404 & 0.0753 & 0.0477 & 0.0440 & 0.0359 & 0.0793 & 0.0569 & 0.0599 & 0.0505 & 0.0984 & 0.0597 & 784 \\  & R-CE & 0.0664 & 0.0508 & 0.0995 & 0.0615 & 0.0550 & 0.0464 & 0.0894 & 0.0578 & 0.0636 & 0.0536 & 0.1030 & 0.0665 & 782 \\  & T-CE & 0.0679 & 0.0533 & 0.1017 & 0.0604 & 0.0535 & 0.0453 & 0.0871 & 0.0565 & 0.0641 & 0.0536 & 0.1029 & 0.0663 & 763 \\  & DeCA & 0.0814 & 0.0619 & 0.1237 & 0.0710 & 0.0600 & 0.0515 & 0.0981 & 0.0610 & 0.0619 & 0.0677 & 0.0555 & 0.1047 & 0.0676 \\  & SGDL & 0.0975 & 0.0741 & 0.1489 & 0.0902 & 0.0683 & 0.0560 & 0.1098 & 0.0696 & 0.0704 & 0.0582 & 0.1084 & 0.0699 & 764 \\  & RLMRec & 0.0968 & 0.0728 & 0.1483 & 0.0896 & 0.0662 & 0.0548 & 0.1092 & 0.0693 & 0.0810 & 0.0654 & 0.1283 & 0.0811 & 763 \\  & BOD & 0.1009 & 0.0779 & 0.1520 & 0.0944 & 0.0706 & 0.0574 & 0.1126 & 0.0712 & 0.0718 & 0.0596 & 0.1135 & 0.0744 & 764 \\   & LLaRD & **0.1083** & **0.0851** & **0.1619** & **0.1027** & **0.0708** & **0.0578** & **0.1135** & **0.0723** & **0.0819** & **0.0657** & **0.1291** & **0.0817** & 768 \\   & Normal & 0.0670 & 0.0495 & 0.1010 & 0.0613 & 0.0539 & 0.0452 & 0.0871 & 0.0566 & 0.0731 & 0.0627 & 0.1170 & 0.0784 & 769 \\  & WBPR & 0.0674 & 0.0496 & 0.1016 & 0.0620 & 0.0539 & 0.0450 & 0.0877 & 0.0571 & 0.0735 & 0.0629 & 0.1165 & 0.0777 & 778 \\  & T-CE & 0.0693 & 0.0530 & 0.1079 & 0.0715 & 0.0585 & 0.0501 & 0.0906 & 0.0612 & 0.0736 & 0.0624 & 0.1133 & 0.0754 & 771 \\  & DCF & 0.0723 & 0.0557 & 0.1112 & 0.0743 & 0.0614 & 0.0524 & 0.0926 & 0.0627 & 0.0768 & 0.0672 & 0.1164 & 0.0771 & 772 \\  & DeCA & 0.0823 & 0.0611 & 0.1291 & 0.0799 & 0.0652 & 0.0576 & 0.1092 & 0.0689 & 0.0827 & 0.0711 & 0.1288 & 0.0882 & 773 \\  & SGL & 0.1018 & 0.0791 & 0.1498 & 0.0949 & 0.0718 & 0.0603 & 0.1171 & 0.0759 & 0.0795 & 0.0671 & 0.1254 & 0.0833 & 773 \\  & SimCL & 0.1109 & 0.0873 & 0.1538 & 0.1013 & 0.0709 & 0.0559 & 0.1146 & 0.0748 & 0.0576 & 0.0471 & 0.0903 & 0.0587 & 774 \\  & SGDL & 0.1135 & 0.0872 & 0.1675 & 0.1054 & 0.0800 & 0.0661 & 0.1323 & 0.0841 & 0.0933 & 0.0769 & 0.1458 & 0.0755 & 775 \\  & RLMRec & 0.1034 & 0.0788 & 0.1600 & 0.0960 & 0.0794 & 0.0652 & 0.1275 & 0.0815 & 0.0926 & 0.0746 & 0.1452 & 0.0924 & 776 \\  & BOD & 0.1244 & 0.0985 & 0.1777 & 0.1131 & 0.0922 & 0.0739 & 0.1432 & 0.0884 & 0.1001 & 0.0802 & 0.1469 & 0.0891 & 777 \\  & LLaRD & **0.1408** & **0.1126** & **0.2028** & **0.1326** & **0.0975** & **0.0809** & **0.1574** & **0.1008** & **0.1054** & **0.0868** & **0.1631** & **0.1059** & 778 \\   

Table 1. Overall performance comparison of different baselines on the backbone models. Bold numbers indicate the best performance, and underlined numbers indicate the second-best performance. “**R**” and “**N**” stand for Recall and NDCG, respectively.

Figure 3. Impact comparison _ur.t._ noise ratio in added interaction data. The bars display Recall@20, while the curve shows the drop rate in performance.

stable compared to the baselines, highlighting its superior resilience to differing noise intensities. These results indicate that the denoising framework LLaRD effectively identifies and leverages useful patterns even in the presence of significant noise.

**Cold-Start Recommendation.** To evaluate the effectiveness in cold-start scenarios characterized by extremely sparse interaction data, we divide all users into five groups based on their interaction frequency. A lower group ID corresponds to sparser user activity and more severe cold-start issues. We compare LLaRD with various baseline methods across different cold-start levels. As shown in Figure 4, the results clearly indicate that LLaRD consistently outperforms baselines across all cold-start levels. This superior performance is attributed to the ability of LLaRD to derive preference knowledge and relation knowledge from LLMs, thereby enabling effective noise identification and robust modeling of both users and items, even in cold-start scenarios.

## 5. Related Work

**Denoising in Recommendation.** Recommendation typically treat observed interactions as positive and unobserved ones as negative in implicit feedback (Henderson et al., 2015; Chen et al., 2016). However, this approach can incorporate erroneous clicks or biased behaviors, leading to false positives and negatives that degrade user experience (Zhu et al., 2017). Existing denoising methods are generally categorized as follows: **1) Selection-Based Methods**: These methods (Henderson et al., 2015; Chen et al., 2016) filter out noisy feedback while retaining clean data. Early approaches (Chen et al., 2016; Chen et al., 2016) use samplers based on data characteristics, whereas adaptive strategies later identify unreliable instances by detecting significant loss early in training. Recent techniques (Li et al., 2017) employ deep reinforcement learning for effective noise removal. DCF (Chen et al., 2016) uses a dual-correction framework to identify noise through changes in sample loss over time. **2) Re-weighting-Based Methods**: This approach assigns higher weights to informative interactions. Initial methods (Zhu et al., 2017; Chen et al., 2018) utilize training loss to assign lower weights to high-loss samples. Recent works like DeCA (Zhu et al., 2017) and BOD (Wang et al., 2017) have introduced novel evaluation criteria and optimization strategies for more accurate weight learning. **3) Side-Information-Based Methods and Special Strategies**(Chen et al., 2016; Chen et al., 2016): Early approaches (Chen et al., 2016; Chen et al., 2016; Chen et al., 2016) utilize dwell time and annotations to detect noise. (Chen et al., 2016; Chen et al., 2016; Chen et al., 2016) incorporate sequential or multi-behavior data to capture unexpected interactions. (Chen et al., 2016; Chen et al., 2016) have employed knowledge graphs to enhance preference modeling, facilitating denoising frameworks. In addition, there are some studies that learn robust representations by designing special denoising strategies. Early work (Chen et al., 2016; Chen et al., 2016; Chen et al., 2016) employ autoencoders to reduce noise in representations. (Chen et al., 2016; Chen et al., 2016) leverage self-supervised learning on graph-structured data for greater stability. Despite their effectiveness, existing methods rely heavily on observed data and predefined assumptions to model user preferences and distinguish noise. In contrast, our approach leverages LMs to acquire denoising knowledge, extracting inferred preference and relational semantics to capture noise interactions.

**LIMs in Recommendation.** LIMs (Chen et al., 2016; Chen et al., 2016) have emerged as powerful tools for enhancing recommendation by leveraging deep semantic understanding and extensive pre-trained knowledge (Chen et al., 2016; Chen et al., 2016; Chen et al., 2016). Some approaches (Chen et al., 2016; Chen et al., 2016) capture latent preferences by generating textual tokens derived from user and item semantics, effectively modeling user preferences through LIMs' rich semantic capabilities. Other studies (Chen et al., 2016; Chen et al., 2016; Chen et al., 2016; Chen et al., 2016) employ LMs as recommenders by crafting specific instructions and fine-tuning them for recommendation tasks, utilizing their adaptability for tailored functionalities. Additionally, certain research (Chen et al., 2016; Chen et al., 2016) adapts LIMs to downstream tasks using prompts without fine-tuning. For example, (Chen et al., 2016) introduce LIMs as zero-shot conversational recommender systems, while TooIce (Zhu et al., 2017) and RecMind (Zhu et al., 2017) design CoT prompts to enable LIMs to handle complex reasoning within recommendation scenarios. Furthermore, methods (Zhu et al., 2017; Chen et al., 2016; Chen et al., 2016; Chen et al., 2016) generate rich-semantic embeddings and integrate reasoning knowledge into traditional models, improving understanding of user preferences and item features, thereby improving recommendation. Despite advancements in utilizing LIMs for various tasks, exploration in denoising recommendations remains limited. Our approach leverages LIMs to extract denoising-related knowledge, enhancing robustness by addressing noise interactions.

## 6. Conclusion

In this paper, we introduced LLaRD, a novel framework that leverages large language models (LLMs) to enhance the denoising process in recommendation. It improved denoising ability of the model by guiding LIMs to mine and inferred denoising-related knowledge from text and interaction data. Specifically, it first enriched semantic insights via LIMs, enabling a more comprehensive inference of user-item preferences. Then it employed a Chain-of-Thought (CoT) strategy over user-item interaction graphs to uncover relation knowledge relevant to denoising. Finally, the Information Bottleneck (IB) principle effectively aligned the denoised knowledge with recommendation targets. Through extensive empirical evaluations, we demonstrated that LLaRD significantly improves both denoising and recommendation accuracy compared to existing methods. Future work will explore further refinements to the framework and its applicability across diverse recommendation scenarios.

Figure 4. Recommendation performance over different cold-start user groups on Amazon-Book (upper) and Steam (lower) dataset.

Unleashing the Power of Large Language Models for