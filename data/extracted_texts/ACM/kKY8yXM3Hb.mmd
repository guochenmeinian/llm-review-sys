# Robust Decision Aggregation with Second-order Information

Anonymous Author(s)

Submission Id: 419

###### Abstract.

We consider a decision aggregation problem with two experts who each make a binary recommendation after observing a private signal about an unknown binary world state. An agent, who does not know the joint information structure between signals and states, sees the experts' recommendations and aims to match the action with the true state. Under the scenario, we study whether supplemented additionally with second-order information (each expert's forecast on the other's recommendation) could enable a better aggregation.

We adopt a minimax regret framework to evaluate the aggregator's performance, by comparing it to an omniscient benchmark that knows the joint information structure. With general information structures, we show that second-order information provides no benefit - no aggregator can improve over a trivial aggregator, which always follows the first expert's recommendation. However, positive results emerge when we assume experts' signals are conditionally independent given the world state. When the aggregator is deterministic, we present a robust aggregator that leverages second-order information, which can significantly outperform counterparts without it. Second, when two experts are homogeneous, by adding a non-degenerate assumption on the signals, we demonstrate that random aggregators using second-order information can surpass optimal ones without it. In the remaining settings, the second-order information is not beneficial. We also extend the above results to the setting when the aggregator's utility function is more general.

Decision Aggregation, Second-order Information, Robust Aggregation 1

## 1. Introduction

Two marketing experts at a company are providing advice on whether to launch a new product now or delay the launch to next year. The unknown binary world state is whether the market has a high demand for the product now or a low demand currently. Each expert can recommend "launch now" or "delay launch" as the optimal action. If the action matches the true demand (launch now when high demand, or delay when low demand), the utility of the company is \(+1\). If mismatched, the utility is \(-1\).

The agent takes the experts' recommendations into consideration and outputs an aggregated decision. If both experts recommend the same action, the agent can follow this consensus recommendation. When they suggest opposite actions, the aggregator may follow the expert who has superior past accuracy. However, in the one-shot setting, the aggregator would fall into a dilemma without access to performance history. Like the above motivating example, similar dilemmas universally exist in other scenarios, e.g., when a patient faces different diagnoses from two doctors, when an investor faces diverse opinions on a startup company, and when an editor faces conflicting recommendations from two referees.

Now, let us ask each expert to provide a prediction about their peer's recommendation, called the second-order setting. Back to our motivating example, for instance, the first expert recommends "launch now" and predicts her peer recommends "launch now" with a probability of 0.4, and the second expert recommends "delay launch" and predicts her peer recommends "launch now" with a probability of 0.2. Our question is - _by having each expert additionally provide a prediction about their peer's recommendation, can we better aggregate their recommendations?_

A series of works have demonstrated the benefit of the additional second-order information in the information aggregation problem. The most closed setting is considered by Prelec et al. (2018), proving that second-order information enhances aggregation given a sufficiently large group size. However, the value of second-order information remains less explored for smaller expert groups.

In particular, prior analyses considered settings where second-order information identifies the true world state, even absent prior data. However, with only two experts, the information often cannot unambiguously determine the state. In such a case, we adopt a robust aggregation paradigm to evaluate the aggregator performance against an omniscient benchmark. The paradigm is introduced by Arieli et al. (2018). The omniscient agent observes the experts' private signals and knows the true joint distribution between signals and states. This allows a perfect aggregation to output the optimal recommendation. In contrast, we focus on aggregators who only know the family of possible information structures, not the exact structure itself. The goal is to identify an aggregation rule with minimum regret compared to the omniscient benchmark. Here, regret is defined as the worst-case difference between the benchmark's expected utility and the aggregator's expected utility among all information structures.

Under the robust aggregation paradigm, we will identify the optimal aggregator that only uses the experts' first-order recommendations; and the optimal aggregator that uses both the first-orderrecommendations and second-order predictions. By comparing the regret achieved by the optimal aggregators with and without second-order predictions, we can quantify the value of the additional higher-order information for robust aggregation.

### Summary of Results

As indicated by the motivating example, our primary focus lies in the scenario where two experts are asked to provide recommendations for binary actions after observing a binary signal, with the agent aiming to align the action with a binary world state.

_General information structures._ We initially make no assumption on the underlying information structure, allowing for the possibility of a strong conditional correlation between the signals observed by the two experts. In this context, we present a negative result, demonstrating that no random aggregator can ensure a regret below 0.5, even when equipped with second-order information (Theorem 3.1). Further, this regret can be guaranteed by a trivial aggregator that consistently follows the first expert's recommendation (Theorem 3.3). Consequently, the second-order information does not provide any assistance in constructing a robust aggregator under these circumstances.

_Conditionally independent information structures._ Subsequently, we narrow our focus to conditionally independent information structures to reveal the power of second-order information. Here, conditionally independent information structures mean that two experts' signals are independent conditioning on the world state. We start with no additional assumptions, allowing for heterogeneous experts. We then consider homogeneous experts, meaning that two experts have an identical marginal signal distribution. Building on this, we further assume non-degenerate signals, i.e., experts recommend different actions after seeing distinct signals. On the aggregator side, we consider two kinds: (1) deterministic aggregators that output a fixed action, and (2) random aggregators that output a random action according to a probability distribution over actions.

Two key positive results emerge. First, for deterministic aggregators, significant improvements occur in the general conditionally independent setting. Second, for random aggregators, we demonstrate that second-order information enables lower regret guarantees under the assumptions of homogeneous experts with non-degenerate signals. The remainder of the results are negative, i.e., second-order information cannot enhance the robustness of the aggregator. All results are presented in Table 1. We now discuss these results in more detail.

_1. Heterogeneous experts._ We first consider the general scenario where two experts can be heterogeneous. In this context, with respect to deterministic aggregators, we present a positive result. We construct an aggregator that adheres to the more "informative" expert when two experts' recommendations split. For a better understanding, the more "informative" expert has better accuracy in predicting the other's recommendation1. We show that such an aggregator guarantees a regret of \(1/3 0.3333\), which is the most robust deterministic aggregator with second-order information (Theorems 4.3 and 4.4). Furthermore, it is essential to note that no aggregator can guarantee a regret lower than 0.5 without second-order information. This highlights the substantial assistance offered by second-order information (Theorem 4.1).

However, considering random strategies, second-order information proves to be redundant in terms of robustness. In particular, no aggregator equipped with second-order information can ensure a regret of less than 0.25 (Theorem 4.5); while such a regret can also be achieved by a simple aggregator that uniformly chooses an action in cases of different recommendations (Theorem 4.6).

To summarize, when facing heterogeneous experts, under the robust aggregation paradigm, (1) when the aggregator is deterministic, second-order information can significantly enhance its decision-making capabilities; (2) when the aggregator can be random, second-order information is not beneficial to the regret.

_2. Homogeneous experts._ We also investigate the scenarios where two experts are homogeneous. We show that without further assumption, neither deterministic aggregators (Theorems 5.2 and 5.4) nor random aggregators (Theorems 5.5 and 5.6) can derive benefits from second-order information. This is due to a special case where both experts always recommend the same action, rendering the second-order information useless. We show that such a case is the worst one, and could lead to a tight regret lower bound of \(3-2 0.1716\).

_3. Homogeneous experts with non-degenerate signals._ To avoid the above special case, we focus on the information structures where experts will recommend different actions when observing different signals. In this setting, we encounter a negative outcome considering deterministic strategies: no aggregator with second-order information can surpass the performance of the follow-the-first-expert aggregator, which guarantees a regret of \(3-2\) (Theorem 5.4 and Corollary 6.2). Notably, when facing homogeneous experts, this aggregator is equivalent to the uniform aggregator, which uniformly chooses an action when two recommendations conflict.

However, when considering random aggregators, we provide two aggregators leveraging second-order information that give better performance. The first aggregator follows a similar principle to the robust deterministic aggregator when dealing with heterogeneous experts, i.e., granting more weight to the expert with more accurate predictions. This aggregator guarantees a regret of 0.1682 (Theorem 6.10). The second aggregator, derived from the online learning algorithm proposed by Guo et al. (2019), guarantees an even lower regret of 0.1673 (Theorem 6.11). Both of these aggregators outperform the uniform aggregator with a regret of \(3-2 0.1716\), which is already optimal without second-order information (Theorem 6.5). This positive result aligns with the findings in Prelec et al. (2019), which highlights that second-order information can enable the aggregator to achieve no regret when confronted with infinite experts. In our investigation, we extend this positive outcome to the case of two experts. We also establish a lower bound of \(1/6 0.1667\) for aggregators with second-order information (Theorem 6.7).

_Extension: general utility functions with homogeneous experts._ In Section 7 and Appendix A, we also extend the above findings for homogeneous experts to encompass general utility functions, where the agent's objective goes beyond aligning actions with states. We first perform a reduction to allow us to focus solely on the ratio of the utility gap between adopting two actions when the state is 0 and when the state is 1. We observe that the results for random aggregators mirror those in the previous setting. Without further assumptions, the previous negative outcome still holds when both experts always advocate an identical action, resulting in high regret for all aggregators. However, when we introduce the non-degenerate signal assumption, we demonstrate that second-order information enhances aggregators' robustness with different ratios. These findings underscore the significance of second-order information for a wide range of utility functions.

### Related Work

Our work focuses on decision aggregation, a subset of the broader field of information aggregation. A significant portion of information aggregation literature focuses on forecast aggregation. This body of work explores various methodologies, including simple techniques like averaging (Garfinkel and Goyal, 2016), median averaging (Garfinkel and Goyal, 2016), and their respective modifications (Garfinkel and Goyal, 2016; Goyal, 2016; Goyal, 2016). These studies showcase the efficacy of straightforward aggregation rules, such as averaging or random dictating (Garfinkel and Goyal, 2016; Goyal, 2016; Goyal, 2016; Goyal, 2016), mirroring some of our findings. Furthermore, there exists a body of literature on decision aggregation, such as De Oliveira et al. (2016), Arieil et al. (2016), and Prelec et al. (2016), which closely align with our work.

The most closely related paper is Prelec et al. (2016), as it also examines the role of second-order information in decision aggregation. The key distinction from our setting is their focus on infinite, homogeneous experts. Leveraging second-order information, they develop an aggregator that identifies the true world state, i.e., has no regret compared to the omniscient agent. In contrast, we focus on two heterogeneous experts, representing a small expert group. We demonstrate that for such settings, regret is unavoidable even with second-order information. Further, we characterize cases where second-order information does not help reduce regret. Our regret analysis and findings on the limitations of small heterogeneous groups add new insights into decision aggregation with second-order information.

We adopt a regret-based minimax paradigm in our analysis. While De Oliveira et al. (2016) also employ a minimax approach, they use a loss-based framework and show the optimal aggregator simply follows the best expert. In contrast, we evaluate aggregator performance in comparison to an omniscient benchmark using a regret formulation. This regret-based robust paradigm follows the approach of Arieli et al. (2016), which studied forecast aggregation under Blackwell-ordered and conditionally independent structures. Additional works employing the regret-based approach include Babichenko and Garber (2016), which explores partial-evidence information structures within a repeated game context, and Guo et al. (2016), which proposes an algorithmic framework for robust forecast aggregation.

Our model focuses on the setting where the aggregator does not have access to the exact information structure. Many other works also consider settings with ambiguity but differ in the knowledge they assume the aggregator possesses. For instance, both De Oliveira et al. (2016) and Arieil et al. (2016) assume that the aggregator possesses knowledge of the marginal distribution of each expert's signal and aim to enhance the robustness of correlations based on this information. This consideration is also prevalent in (Garfinkel and Goyal, 2016; Goyal, 2016; Goyal, 2016). In contrast, our work assumes that the aggregator is ignorant about the full information structure and solely has access to the experts' outputs and the set to which the information structure belongs. This approach aligns with Arieli et al. (2016), Kong (2016), and Prelec et al. (2016). Moreover, Arieli et al. (2016) characterize the set of identifiable information structures and introduce a scheme that uniquely identifies the state of nature in finite cases.

We study whether second-order information improves the performance of the decision aggregator. A substantial body of literature also explores the benefit of second-order information. Prelec (2016) started the exploration and introduced a framework wherein agents provide both their answers and predictions for a single multi-choice question. Building upon this foundation, subsequent works have delved into the design of aggregators utilizing second-order information. Among these, the "surprisingly popular" approach, initially introduced by Prelec et al. (2016) and subsequently developed by researchers such as Palley and Soll (2016), Palley and Satopaa (2016), and Chen et al. (2016), have garnered significant attention.

Furthermore, Kong (2016) employs second-order and even higher-order information in forecast aggregation, particularly in scenarios featuring two experts who are either Blackwell-ordered or receive signals that are conditionally independent and identically distributed. Wang et al. (2016), Martinia et al. (2016), and Wilkening et al. (2016) have designed prediction-aided forecast aggregators and

   ^{}\)} & Deterministic & Helps? & Random & Helps? \\   & 1st\({}^{}\) & 0.5 &  & 0.25 &  & 296 \\    & 2nd\({}^{}\) & 0.3333\({}^{}\) & & 0.25 & 0.25 & \\   & 1st & 0.1716\({}^{}\) &  & 0.1716 &  & 297 \\    & 2nd & 0.1716 & & 0.1716 & & \\   & 1st & 0.1716 &  & 0.1716 &  & 299 \\    & 2nd & 0.1716 & & & \([0.1667,0.1673]\)\({}^{}\) & \\   

* \({}^{*}\)When the entry is a single value, it means the lower/upper bound coincides at the value; when the entry is an interval, the endpoints of the interval respectively represent the lower/upper bound.
* \({}^{}\) ist: only using first-order recommendations, 2nd: also using second-order predictions.
* 2\(\), 0.1667 = 1/6, 0.1673 is a numerically rounded estimate.

Table 1. An overview of our main results.

conducted experimental analyses to showcase their effectiveness and potential in real-world applications.

In addition to decision aggregation and forecast aggregation, the utilization of second-order information finds application in many other domains. For instance, Kong et al. (Kong et al., 2016) focus on open-response questions and ask agents what they think other people will answer. They use the information to rank the answers without any prior knowledge. Also, Hosseini et al. (Hosseini et al., 2013) and Schoenebeck and Tao (Schoenebeck and Tao, 2017) employ a similar framework to rank a predefined set of candidates. In the context of election forecasting, Rothschild and Wolters (Rothschild and Wolters, 2016) utilize voters' expectations regarding other people's votes to provide more accurate predictions of election outcomes.

## 2. Problem Statement

A company is deciding whether to launch a new product now (action 1) or delay it until next year (action 0). There are two marketing experts, expert 1 and expert 2, providing recommendations to the company's CEO (the agent). There are two possible world states about the current demand, high (state 1) and low (state 0), and we use \(=\{0,1\}\) to denote the unknown true state. Let \(a A=\{0,1\}\) denote the action adopted by the CEO. If the action matches the true demand (launch now with high demand or delay with low demand), the CEO's utility is \(+1\). Otherwise, the CEO's utility is \(-1\).

Each expert \(i\{1,2\}\) receives a private signal \(S_{i} S=\{L,H\}\) about the demand, where an \(L\) signal implies a lower likelihood of the high demand state than \(\) if signal. The realization of \(S_{i}\) is \(s_{i}\). An information structure \((^{2})\) is a joint distribution of the state and two private signals \(S_{1},S_{2}\), which encodes the correlation between the true state and private signals. Here, \(()\) stands for the set of all distributions on the support. The information structure is shared by both experts. Thus, the prior of the world state \(=(=1)\) is also known to both experts. For simplicity, we rewrite the key parameters of any specific information structure in the rest of this paper. Let

\[k_{1} (S_{1}=L=1), l_{1} (S_{1}=L=0);\] \[k_{2} (S_{2}=L=1), l_{2} (S_{2}=L=0).\]

denote the signal probabilities and the posteriors are written as

\[b_{1L} (=1 S_{1}=L) b_{1H} (=1 S_{1}=H);\] \[b_{2L} (=1 S_{2}=L) b_{2H} (=1 S_{2}=H).\]

Here, \((S_{1}=L=1)\) stands for the probability that \(S_{1}=L\) conditioning on \(=1\). Similar meanings hold for similar notations. Note that \(b_{1L} b_{1H}\) and \(b_{2L} b_{2H}\) hold since an \(L\) signal indicates a lower likelihood of the high demand state 1.

The experts observe their private signals and compute posteriors on the demand state. They recommend "launch now" (action 1) if the posterior on the high demand \( 0.5\) and "delay launch" (action 0) otherwise. We assume that experts report truthfully. Such incentive compatibility can be guaranteed by rewarding the experts later with the revelation of the true state.

The CEO aims to aggregate the expert recommendations into an optimal product launch decision but lacks knowledge of the underlying information structure. Formally, the CEO observes the recommendations \(a_{1},a_{2} A=\{0,1\}\) from the two marketing experts. The CEO's aggregator outputs a final decision, which may be deterministic (denoted by \(f^{d}:A^{2} A\)) or randomized (denoted by \(f^{r}:A^{2} A(A)\)). Here \(\) means its output is a random action following a probability distribution.

_Benchmark and regret._ We compare the aggregator to an omniscient agent who knows the true information structure \(\) and observes the realized signals \(s_{1},s_{2}\). The benchmark's output is

\[a^{*}(s_{1},s_{2},)((=1 S_{1}=s_{1},S_{2}=s_{2})),\]

where \((b)\{b 0.5\}\). \(\{\}\) is the indicator which is valued 1 when the inner condition is true and 0 otherwise.

The loss of any aggregator regarding information structure \(\) is defined by the benchmark's expected utility subtracted by the aggregator's expected utility:

\[L(f,)=[\{a^{*}(s_{1},s_{2},)=\} -\{f(a_{1}(s_{1}),a_{2}(s_{2}))=\}].\]

Here, the expectation is taken on the world state \(\), experts' private signal realizations \(s_{1},s_{2}\), and the randomness of the aggregator's output, if it is random.

_Second-order information._ Each expert, denoted as \(i\), is also asked to provide a prediction, \(p_{i}\), for the probability that the other expert recommends action 1. This is represented as follows:

\[p_{1} _{_{1}}[(b_{2})=1 S_{1}=s_{1}]\] \[=_{s_{2}}(S_{2}=s_{2} S_{1}=s_{1})((=1  S_{2}=s_{2})),\]

and \(p_{2}\) is defined analogously. The CEO aims to find an aggregator that can effectively incorporate this additional second-order information. Such an aggregator is denoted as \(f:A^{2}^{2}(A)\) or \(A\). We distinguish between deterministic aggregators \(f^{d}\) with deterministic outputs, and randomized aggregators \(f^{r}\) that output probability distributions over actions.

Given the information structure \(\), the loss of any aggregator equipped with second-order information is defined as follows:

\[L(f,)[\{a^{*}(s_{1},s_{2},)= \}-\{f(a_{1},a_{2},p_{1},p_{2})=\}].\]

Here, \(a_{1},a_{2},p_{1},p_{2}\) are abbreviations for \(a_{1}(s_{1}),a_{2}(s_{2}),p_{1}(s_{1}),p_{2}(s_{1})\), respectively. Again, the expectation is taken on the state \(\), experts' private signal realizations \(s_{1},s_{2}\), and the randomness of the aggregator's output, if it is random.

_Robust aggregation._ As the CEO lacks knowledge of the exact information structure, her goal is to design an aggregator that performs well across all possible information structures within the family \(P\). To model such robustness, we define the _regret_ of a deterministic aggregator \(f\) as the worst-case loss across all information structures in \(P\):

\[L_{P}(f)_{ P}L(f,).\]

This work considers different sets of information structures to capture various real-world scenarios. For each of these information structure family \(P\), our objective is to identify the best aggregators \(f\), both with and without second-order information, that minimize the regret \(L_{P}(f)\). We denote the set of all deterministic aggregators without second-order information as \(F_{+1}\), and the set of deterministic aggregators with second-order information as \(F_{+2}\). Formally,we address the following optimization problems:

\[_{f^{d} F_{ 1}}L_{P}(f^{d}) =_{f^{e} F_{ 1}}_{ P}L(f^{d},),\] \[_{f^{d} F_{ 2}}L_{P}(f^{d}) =_{f^{e} F_{ 2}}_{ P}L(f^{d},),\] \[f^{e}_{(F_{ 1})}L_{P}(f^{f}) =_{f^{e}(F_{ 1})}_{ P}L(f^{f},),\] \[_{f^{e}(F_{ 2})}L_{P}(f^{f}) =_{f^{e}(F_{ 2})}_{ P}L(f^{f},).\]

We further study whether the inclusion of second-order information leads to a strict decrease in regret for the agent. In other words, we examine for different family \(P\) whether the following two values \(<0\):

\[_{f^{d} F_{ 2}}L_{P}(f^{d}) -_{f^{d} F_{ 1}}L_{P}(f^{d}),\] \[f^{e}_{(F_{ 2})}L_{P}(f^{f}) -f^{e}_{(F_{ 1})}L_{P}(f^{f}).\]

## 3. Warm-Up: General Information Structures

As a warm-up, this section examines the information structure family \(\), which contains all information structures that encode the correlation between the state and two signals. Missing proofs of this section can be found in Appendix B. We start by presenting a universal lower bound.

**Theorem 3.1**.: _For every random aggregator \(f^{e}(a_{1},a_{2},p_{1},p_{2})(F_{ 2})\), \(L_{}(f^{e}) 0.5\)._

To prove the above lower bound, we adapt Yao's principle (Yao, 2017) to our setting, establishing a connection between the expected regret of any random aggregator and the best aggregator for any distribution over information structures. The lemma below will be invoked repeatedly in the subsequent sections.

**Lemma 3.2** (Yao's principle (Yao, 2017)).: _In any aggregator family \(F\) and information structure family \(P\), for any random aggregator \(f^{e}(F)\) and any distribution \(D(P)\),_

\[_{f^{d} F}_{ D}[L(f^{d},)]_{ P}_{f^{d} f^{e}}[L(f^{d},)].\]

We now present a deterministic aggregator in \(F_{ 1}\) that achieves for \(\) the lowest regret among all aggregators in \((F_{ 2})\), which we refer to as the follow-the-first-expert aggregator.

_The follow-the-first-expert aggregator._ The aggregator is characterized by unconditionally adhering to the recommended action of expert 1, irrespective of expert 2's advice. This aggregator can be mathematically expressed as \(f_{fffe}(a_{1},a_{2})=a_{1}\). We have the following regret guarantee for \(f_{fffe}\).

**Theorem 3.3**.: \(L_{}(f_{fffe})=0.5\)_._

Since \(f_{fffe}\) is optimal among all aggregators in \((F_{ 2})\) and is itself in \(F_{ 1}\), we conclude that the agent cannot reach a lower regret when two experts have conditional correlations even by using a random strategy or incorporating second-order information. We therefore turn our focus to conditionally independent information structures in the following sections.

## 4. Heterogeneous Experts

We now come to consider conditionally independent information structures and make no additional assumptions on experts, allowing them to be heterogeneous. Specifically, a conditionally independent information structure ensures that two experts' signals are independent given the state. The set of all conditionally independent information structures is referred to as \(\). Missing proofs of this section can be found in Appendix C.

### Deterministic Aggregators

We first establish the following lower bound for deterministic aggregators.

**Theorem 4.1**.: _For every deterministic aggregator \(f^{d}(a_{1},a_{2}) F_{ 1}\), \(L_{}(f^{d}) 0.5\)._

We now revisit the follow-the-first-expert aggregator introduced in Section 3. Since \(\), as a corollary of Theorems 3.3 and 4.1, within \(\), this aggregator is still the optimal among all deterministic aggregators.

**Corollary 4.2**.: \(L_{}(f_{fffe})=0.5\)_._

We proceed to establish a lower bound for deterministic aggregators equipped with second-order information, which notably falls far below the lower bound for deterministic aggregators lacking second-order information.

**Theorem 4.3**.: _For every deterministic aggregator \(f^{d}(a_{1},a_{2},p_{1},p_{2}) F_{ 2}\), \(L_{}(f^{d}) 1/3 0.3333\)._

To further establish the effect of second-order information in this setting, we now introduce a robust "threshold aggregator". Remarkably, within \(\), \(f_{thr}\) attains the lowest regret among all deterministic aggregators in \(F_{ 2}\). This observation underscores the potential of prediction knowledge in enabling an agent without randomness to achieve a lower regret in \(\).

_The threshold aggregator._ This aggregator follows experts' recommendations if the experts agree. When the experts disagree, it compares the sum of their predictions to \(1\). If the predictions sum to less than \(1\), it chooses action \(1\). Otherwise, it chooses action \(0\). Concretely, we have

\[f_{thr}(a_{1},a_{2},p_{1},p_{2})=a_{1}&a_{1}=a_{2}\\ 1&a_{1} a_{2},p_{1}+p_{2} 1\\ 0&a_{1} a_{2},p_{1}+p_{2}>1.\]

The aggregator tends to trust the expert who makes a more accurate prediction. From another perspective, it is equivalent to the "surprisingly popular" approach proposed by Prelee et al. (Prelee et al., 2019). When \(p_{1}+p_{2} 1\), the answer \(1\) is more popular than predicted. Conversely, when \(p_{1}+p_{2}>1\), the answer \(0\) is the surprisingly popular one. We demonstrate that the threshold aggregator has a regret of \(1/3\).

**Theorem 4.4**.: \(L_{}(f_{thr})=1/3\)_._

In summary, the threshold aggregator resolves the experts' disagreement based on who can predict the other more accurately.

While there still exists a gap compared with the omniscient benchmark, using second-order information already significantly improves the aggregator's performance versus relying solely on raw recommendations.

### Random Aggregators

For random aggregators, we first establish that it is impossible to ensure a regret below 0.25 even when utilizing second-order information.

**Theorem 4.5**.: _For every random aggregator \(f^{}(a_{1},a_{2},p_{1},p_{2})(F_{ 2})\), \(L_{ CI}(f^{}) 0.25\)._

We now introduce a random aggregator that does not require predictive information yet still guarantees tight regret. We refer to the aggregator as the uniform aggregator. It can be seen as a random version of the follow-the-first-expert aggregator.

_The uniform aggregator._ The uniform aggregator outputs the recommendations of experts when they agree; when they disagree, the aggregator uniformly selects an action. In other words, the uniform aggregator can be expressed as

\[f_{}(a_{1},a_{2})=a_{1}&a_{1}=a_{2}\\ 0.5&a_{1} a_{2}.\]

Here, when \(f_{}\) outputs 0.5, it means choosing action 1 with probability 0.5. A similar interpretation also holds for random aggregators to be introduced later.

**Theorem 4.6**.: \(L_{ CI}(f_{})=0.25\)_._

## 5. Homogeneous Experts

In the above results for random aggregators, an important reason why the predictions are useless is that, in the worst cases, they do not assist the agent in distinguishing the omniscient report from the ignorant one, thus the aggregator can only choose the uniform strategy at best. However, the benchmark, aided by the information structure, is always able to identify the more informed expert. As a result, there exists a substantial utility gap between the agent and the benchmark, irrespective of the agent possessing knowledge of the prediction.

In this section, we assume that the two experts are homogeneous, which means their marginal signal distribution is the same. Intuitively, the knowledge of prediction may help the agent identify the representative signal that includes the information of the real state. Formally, we take the following assumption in this section.

**Assumption 5.1** (Homogeneous experts).: _The two experts are homogeneous. In other words, \(k_{1}=k_{2}=k\), \(l_{1}=l_{2}=l\), \(b_{1L}=b_{2L}=b_{L}\) and \(b_{1H}=b_{2H}=b_{H}\)._

We then focus on the set of all conditionally independent information structures with homogeneous experts, which is referred to as HCI. All missing proofs of this section are deferred to Appendix D.

### Deterministic Aggregators

To begin, we establish a lower bound for deterministic aggregators, demonstrating that no deterministic aggregator in \(F_{ 2}\) can achieve a regret less than \(3-2 0.1716\).

**Theorem 5.2**.: _For every deterministic aggregator \(f^{d}(a_{1},a_{2},p_{1},p_{2}) F_{ 2}\), \(L_{ HCI}(f^{d}) 3-2\)._

Interestingly, the threshold aggregator, which is optimal with heterogeneous experts, achieves suboptimal performance in the homogeneous setting, still giving a regret of \(1/3\).

**Theorem 5.3**.: \(L_{ HCI}(f_{})=1/3\)_._

Nevertheless, the follow-the-first-expert aggregator can guarantee a lower regret. Moreover, \(f_{ e}\) achieves the lowest regret among all deterministic aggregators in \(F_{ 2}\) regarding HCI. This also indicates that knowledge of prediction cannot help the agent without randomness attain a lower regret in HCI.

**Theorem 5.4**.: \(L_{ HCI}(f_{})=3-2\)_._

### Random Aggregators

For random aggregators utilizing second-order information, we first show that their regret lower bound in HCI is \(3-2\).

**Theorem 5.5**.: _For every random aggregator \(f^{}(a_{1},a_{2},p_{1},p_{2})(F_{ 2})\), \(L_{ HCI}(f^{}) 3-2\)._

As an intuition of the proof, we provide an information structure in which the aggregator always observes the input \((1,1,1,1)\), which means the best strategy is to adopt action 1 all the time. However, when two signals are both \(L\), the benchmark's posterior is less than 1. Therefore, no aggregator can avoid such a difference, leading to an unavoidable regret of \(3-2\).

We then show that the uniform aggregator is optimal with a tight regret of \(3-2\). We notice here that since experts are homogeneous, the uniform aggregator is equivalent to the follow-the-first-expert-aggregator.

**Theorem 5.6**.: \(L_{ HCI}(f_{})=3-2\)_._

Thus, surprisingly, the second-order information offers no help under the robust paradigm even if we assume experts are homogeneous. This motivates an additional natural assumption that we will introduce in the following section.

## 6. Homogeneous Experts with Non-Degenerate Signals

According to the proof of Theorem 5.5, when experts' recommended actions do not vary with their observed signals, the predictions contain no useful information and thus cannot aid the agent in achieving lower regret. In this section, alongside assuming expert homogeneity, we further assume the experts will recommend different actions when observing different signals, specifically that \(b_{L}<1/2 b_{H}\).

**Assumption 6.1** (Homogeneous experts with non-degenerate signals).: _Two experts are homogeneous. Also, they recommend different actions when observing different signals. In other words, \(b_{L}<1/2 b_{H}\)._

This section studies the set of all possible conditionally independent information structures satisfying Assumption 6.1, denoted by NHI. Missing proofs of this section can be found in Appendix E.

### Deterministic Aggregators

For deterministic aggregators, we notice that all results we establish in Section 5 still work for the information structure family \(\), with no changes in the proof. To summarize, we have the following corollaries.

**Corollary 6.2**.: _For every deterministic aggregator \(f^{d}(a_{1},a_{2},p_{1},p_{2}) F_{42}\), \(I_{}(f^{d}) 3-2 0.1716\)._

**Corollary 6.3**.: \(I_{}(f_{thr})=1/3\)_._

**Corollary 6.4**.: \(I_{}(f_{fffe})=3-2\)_._

### Random Aggregators

We first establish the lower bound for random aggregators in \((F_{})\). As with \(\), no random aggregator without second-order information can guarantee a regret less than \(3-2\) for the worst case over \(\).

**Theorem 6.5**.: _For every random aggregator \(f^{r}(a_{1},a_{2})(F_{})\), \(I_{}(f^{r}) 3-2\)._

Since the uniform aggregator guarantees a regret of \(3-2\) for any information structure in \(\) by Theorem 5.6, it guarantees at least this regret against all structures in \(\). Thus, the aggregator is also optimal in this setting.

**Corollary 6.6**.: \(I_{}(f_{uni})=3-2\)_._

We then come to consider aggregators utilizing second-order information, starting by establishing a lower bound, which is slightly smaller than that for random aggregators without second-order information.

**Theorem 6.7**.: _For every random aggregator \(f^{r}(a_{1},a_{2},p_{1},p_{2})(F_{})\), \(I_{}(f^{r}) 1/6 0.1667\)._

To reduce the search space, we now study the characteristics of a robust random aggregator in \((F_{})\), aiming to achieve a low regret regarding information structures in \(\). First, we present a lemma showing that when two experts split in recommendation, the expert with recommendation \(1\) always has a no less prediction value than the other expert.

**Lemma 6.8**.: _Suppose \(a_{1}=1\) and \(a_{2}=0\), then \(p_{1} p_{2}\)._

Hence, it suffices for us to consider the scenario that \(p_{1} p_{2}\) when \(a_{1}=1\) and \(a_{2}=0\). To add to this, we also have the following results:

**Proposition 6.9**.: _There exists a random aggregator \(f^{r}\) that achieves the lowest regret among all random aggregators in \((F_{})\) regarding \(\) that satisfies the following for any \(a_{1},a_{2}\{0,1\}\), \(p_{1},p_{2},p\):_

1. \(f^{r}(1,1,p_{1},p_{2})=1\) _and_ \(f^{r}(0,0,p_{1},p_{2})=0\)_._
2. \(f^{r}(a_{1},a_{2},p_{1},p_{2})=f^{r}(a_{2},a_{1},p_{2},p_{1})\)_._
3. \(f^{r}(a_{1},a_{2},p_{1},p_{2})+f^{r}(1-a_{1},1-a_{2},1-p_{1},1-p_{2})=1\)_._
4. _when_ \(a_{1} a_{2}\)_,_ \(f^{r}(a_{1},a_{2},p_{1}-p)=0.5\)_._

The intuition behind (a) is that when the experts' recommendations agree, the agent straightforwardly takes that action. This follows directly from the information structure definition. (b) means that the agent treats the two experts equally. (c) shows the equivalence of the two states. At last, (d) indicates that when two experts' predictions deviate from each other's true recommendations by the same amount, the aggregator shows no inclination toward either action. These three properties are proved by constructing another aggregator for any optimal one with the same regret guarantee, and then linearly combining them.

We now introduce a random aggregator, referred to as the "big-lor" radial aggregator, that satisfies the criteria in Proposition 6.9. Moreover, \(f_{bir}\) attains a lower regret over \(\) compared to random aggregators without second-order information. This shows that predictive knowledge can help agents achieve better performance.

#### The bipolar radial aggregator

This aggregator follows the recommendation when the experts agree. When recommendations differ, it treats the experts equally and chooses based on how much their predictions deviate. Specifically, it fixes a center point (\(0.6,0.4\)) on the \(p_{1}\)-\(p_{2}\) graph, outputs \(0.5\) around this center, and moves toward the extremes as the distance increases. This aggregator tends to trust the expert who predicts the other's action more accurately. Formally, when \(a_{1}=1,a_{2}=0\), the aggregator is:

\[f_{bir}(1,0,p_{1},p_{2})=\] (78) \[\{1,(p_{1}-0.6)^{2}+(p_{2}-0.4)^{2}+0.5\},&p_{1}+p_ {2}<0.98\\ \{0,0.5-(p_{1}-0.6)^{2}-(p_{2}-0.4)^{2}\},&p_{1}+p_{2}>1.02\\ 0.5,&\] \[a_{1}=0,a_{2}=1\) is symmetric. We show the contour graph of the aggregator in the case of \(a_{1}=1,a_{2}=0\) in Figure 1(a).

**Theorem 6.10**.: \(I_{}(f_{bir}) 0.1682\)_._

Theorem 6.10 leaves a gap between the upper and lower bound in the context of worst-case scenarios within \(\). Although closing this gap is challenging, we can enhance the upper bound by employing a more intricate aggregator derived from the algorithm introduced by Guo et al. (2018), which views robust aggregation as a zero-sum game between nature and the aggregator and enables online learning techniques to solve the game effectively.

#### The aggregator from the online learning algorithm

As suggested by Proposition 6.9, this aggregator follows experts' recommendation when they agree. When they disagree, the aggregator treats the two experts equally and selects an action based on their predictions. Specifically, the algorithm learns an aggregator on discretized points \((p_{1},p_{2})\) where \(p_{1}\) and \(p_{2}\) are multiples of \(0.1\), and uses linear interpolation to give the output at other points. We present a contour graph of the algorithmic aggregator when \(a_{1}=1\) and \(a_{2}=0\) in Figure 1(b).

**Theorem 6.11**.: \(I_{}(f_{didy}) 0.1673\)_._

The bipolar radial aggregator in Figure 1(a) provides an intuitive and symmetrical way to weigh expert recommendations based on prediction accuracy and satisfies Proposition 6.9. The algorithmic aggregator in Figure 1(b) always favors action \(0\) in conflicts, which may seem unintuitive. However, its regret guarantee can be mirrored by an aggregator always favoring action \(1\) instead. Specifically, according to Proposition 6.9 and the linearity of theloss function, defining \(f_{alg}^{}\) as the mirror that flips predictions and outputs \(f_{alg}^{}(a_{1},a_{2},p_{1},p_{2})=1-f_{alg}(1-a_{2},1-a_{1},1-p_{2},1-p_{1})\) guarantees the same regret \(0.1673\). We present the contour graph of this aggregator when \(a_{1}=1\) and \(a_{2}=0\) in Figure 1(c). Therefore, to have a low regret, we can either favor action \(0\) or favor action \(1\) when the experts disagree, as long as the tendency varies with the predictions. Furthermore, we can observe a common pattern: medium values at the center and extreme values on both sides. These unexpected findings illustrate the intricacy of second-order information's role and complexity in small expert groups.

## 7. Extension: general utility functions with homogeneous experts

This section extends the setting to general utility functions. We no longer assume that the agent's goal is to match the action with the correct state. Instead, we consider a more general scenario where the agent's utility is determined by both the state and the action taken, captured by a utility function \(u:A R\).

Same as the original setting, the two experts will each recommend their preferred action \(a_{1},a_{2}\) according to the utility function and provide prediction \(p_{1},p_{2}\) about the probability of the other expert recommending action \(1\). We further assume these two experts are homogeneous (Assumption 5.1). We still explore two layers of information: one where the agent can observe both recommended actions and predictions, and the other where the agent can only observe the recommended actions.

We also assume that \(u(0,0)>u(1,0)\) and \(u(1,1)>u(0,1)\), otherwise one action is dominated by another and the problem is trivial. Let the utility gap of two actions when the state \(a\) be \( u_{0} u(0,0)-u(1,0)\) and the gap when the state is \(1\) be \( u_{1} u(1,1)-u(0,1)\). Also, we introduce their ratio as \(t u_{1}/ u_{0}\). Apparently, \(t=1\) in our original setting.

Note that the recommended action is still a threshold function of the posterior, parameterized by \(t\), that is

\[a_{i}=^{I}(b_{i}) =\{b_{i}\}\] \[=\{b_{i}\}.\]

The action of the benchmark when observing signals \((s_{1},s_{2})\) regarding information structure \(\) should be \(a^{*}^{I}((=1 S_{1}=s_{1},S_{2}=s_{2}))\).

We focus on random aggregators. The regret of any random aggregator \(f^{}\) with second-order information regarding information structure \(\) can be defined as

\[L(f^{},,u) _{,f^{}()}[u(a^{*},)-u(f^ {}(a_{1},a_{2},p_{1},p_{2}),)].\]

The regret of any random aggregator without second-order information is similar:

\[L(f^{},,u) _{,f^{}()}[u(a^{*},)-u(f^ {}(a_{1},a_{2}),)].\]

Here the randomness comes from the information structure \(\) and the output of random aggregator \(f^{}\).

Building upon the preceding results, we start by establishing negative outcomes for possibly degenerate signals. We then focus on non-degenerate signals as Section 6 and introduce robust aggregators with second-order information, tailored to different utility ratios, demonstrating that second-order information empowers the agent to achieve lower regret across many utility functions. Due to the space limit, we defer the details to Appendix A.

## 8. Conclusion and discussion

In this work, we study the benefit of second-order information in decision aggregation with two experts. Specifically, we investigate binary actions, binary states, and binary signals, examining the optimal deterministic and random aggregators, both with and without second-order information. Our research provides insight into the crucial question about the effectiveness of second-order information in mitigating regret, with various underlying assumptions. Furthermore, we extend our findings to encompass more general utility functions, thereby broadening our results' applicability scope. Future research directions of this work include conducting real-world experiments, exploring the scenario with more experts, and considering more complex signal settings.