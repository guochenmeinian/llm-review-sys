# Span-Pair Interaction and Tagging for Dialogue-Level Aspect-Based Sentiment Quadruple Analysis

Anonymous Author(s)

Submission Id: 259

###### Abstract.

The Dialogue-level Aspect-based Sentiment Quadruple analysis (DiaASQ) task has recently received attention in the Aspect-Based Sentiment Analysis (ABSA) field. It aims to extract _target_, _aspect_, _opinion_, _sentiment_) quadruples from multi-turn and multi-party dialogues. Compared to previous ABSA tasks focusing on text such as sentences, the DiaASQ task involves more complex contextual information and corresponding relations between terms, as well as longer sequences. These characteristics challenge existing methods that struggle to model explicit span-level interactions or have high computational costs. In this paper, we propose a span-pair interaction and tagging method to solve these issues, which includes a novel Span-pair Tagging Scheme (STS) and a simple and efficient Multi-level Representation Model (MRM). STS simplifies the DiaASQ task to a span-pair tagging task and explicitly captures complete span-level semantics by tagging span pairs. MRM efficiently models the dialogue structure information and span-level interactions by constructing multi-level contextual representation. Besides, we train a span ranker to improve the running efficiency of MRM. Extensive experiments on multilingual datasets demonstrate that our method outperforms existing state-of-the-art methods.

Natural language processing, Aspect-based sentiment analysis, Quadruple extraction, Dialogue scene +
Footnote †: ccs: Computing methodologies Natural language processing

+
Footnote †: ccs: Computing methodologies Natural language processing

+
Footnote †: ccs: Computing methodologies Natural language processing

+
Footnote †: ccs: Computing methodologies Natural language processing

+
Footnote †: ccs: Computing methodologies Natural language processing

+
Footnote †: ccs: Computing methodologies Natural language processing

+
Footnote †: ccs: Computing methodologies Natural language processing

+
Footnote †: ccs: Computing methodologies Natural language processing

+
Footnote †: ccs: Computing methodologies Natural language processing

+
Footnote †: ccs: Computing methodologies Natural language processing

## 1. Introduction

Aspect-Based Sentiment Analysis (ABSA) is a crucial research field in natural language processing, which aims to determine the sentiment polarities towards specific aspects of targets (Han et al., 2016; Krizhevsky et al., 2012). ABSA has found wide applications in E-commerce platforms, where it helps improve products and services based on customer feedback from web content.1 In recent years, there has been a growing trend of discussing products and services through multi-turn and multi-party dialogues on social media platforms such as Twitter and Weibo. However, existing ABSA methods (Bahdanau et al., 2015; Krizhevsky et al., 2012; Krizhevsky et al., 2012; Krizhevsky et al., 2012; Krizhevsky et al., 2012; Krizhevsky et al., 2012; Krizhevsky et al., 2012; Krizhevsky et al., 2012; Krizhevsky et al., 2012) primarily focus on text-level ABSA tasks, analyzing individual texts such as sentences and documents while ignoring more complex and dynamic dialogue scenes.

To address this limitation and promote the development of dialogue-level ABSA, Li et al. (Li et al., 2016) proposed the Dialogue-level Aspect-based Sentiment Quadruple analysis (DiaASQ) task. This task aims to extract _target_, _aspect_, _opinion_, _sentiment_) quadruples from multi-turn and multi-party dialogues, as illustrated in Figure 1. Compared to text-level ABSA tasks, DiaASQ exhibits the following characteristics: 1) More complex contextual information resulting from the structure of multi-turn and multi-party dialogues. 2) More complex corresponding relations between terms resulting from more types of terms (a new term _target_). 3) Longer sequences due to the inclusion of multiple utterances in dialogue. These characteristics challenge existing methods in addressing the DiaASQ task.

Figure 1. An example of a DiaASQ task. The capital letters \(A_{i}\), \(B\), \(C\), and \(D\) identify the speakers. Dotted lines with arrows show the reply relations between utterances. The quadruple consists of three terms (i.e., _target_, _aspect_, _opinion_) and a sentiment polarity.

Token-pair tagging is a popular method for text-level ABSA tasks , and Li et al.  extended the classical token-pair tagging method GTS  for the DiaASQ task. As illustrated on the left side of Figure 2, given a dialogue snippet containing \(N\) tokens, the method first extracts terms, relations, and sentiment polarities by tagging each token pair in an \(N N\) token-level matrix and then decodes quadruples from the extracted results. **However, the token-pair tagging method cannot capture complete semantic information of spans due to the lack of span-level modeling and interactions.** For example, this method identifies the token pair (_iPhone, not_) with _negative_ sentiment and the (_6, good_) with _positive_ sentiment, leading to failure to determine the sentiment polarity of the quadruple. The complex contextual information and corresponding relations between terms in the DiaASQ task exacerbate the issue. To this end, some works  proposed span-level enumeration methods to capture the complete span-level semantic information. **However, this method leads to high computational costs and label sparsity problems due to the more types of terms and longer sequences involved in the DiaASQ task.** As shown on the right side of Figure 2, this method enumerates spans to create a span list of size \(L=N(N+1)/2\). Then, it arranges spans into (_target, aspect, opinion_) triplets and predicts their sentiment polarities, leading to a high time complexity (\(O(L^{3})\)). Besides, the abundant invalid triplets cause label sparsity problems that hinder training from reaching optimal performance. In this paper, we propose a span-pair interaction and tagging method, comprising a novel Span-pair Tagging Scheme (STS) and a simple and efficient Multi-level Representation Model (MRM), to solve the issues of the above two kinds of methods. In contrast to previous works of tagging token pairs, STS can explicitly capture complete span-level semantic information by tagging span pairs in the span-level matrix. Meanwhile, MRM generates the \(L L\) span-level matrix by modeling the multi-level information. Compared to the span-level enumeration method, MRM exhibits stable time complexity at \(O(L^{2})\) and does not increase with the number of term types.

Concretely, STS extracts target, aspect, and opinion terms by tagging the span-level matrix diagonal. It also extracts the type of relations between terms and sentiment polarities by tagging the strictly upper triangular region of the matrix. Then, STS decodes quadruples under the verification of terms and the type of relations between terms. Furthermore, MRM models the dialogue structure information at the token level by self-attention mechanism  and models interactions between spans at the span level by Hadamard product operation, respectively. It enumerates all spans and constructs a \(L L\) span-level matrix. Then, it obtains quadruples with the help of STS. The simple structure of MRM ensures the \(O(L^{2})\) time complexity. Besides, we train a span ranker to improve the running efficiency of MRM. It further optimizes the time complexity to \(O(K^{2})\) by selecting the top \(K\) spans to reduce the size of the matrix from \(L L\) to \(K K\) (\(K L\), \(K<N\), \(N\) is the number of tokens, and \(L\) is the number of spans). Our contribution can be summarized as follows:

(1) We design a Span-pair Tagging Scheme (STS) that explicitly capture complete span-level semantic information by tagging span pairs rather than token pairs. To our best knowledge, this is the first time to solve the dialogue-level ABSA task by tagging span pairs.

(2) We propose a simple and efficient Multi-level Representation Model (MRM), which explicitly models the dialogue information and the interactions between spans at the token and span level, respectively. Besides, we train a span ranker to make MRM run more efficiently than previous models.

(3) We conduct extensive experiments on multilingual DiaASQ datasets. The experimental results demonstrate that our method outperforms the state-of-the-art methods.2

## 2. Related Work

### Text-level Aspect-Based Sentiment Analysis

Text-level Aspect-Based Sentiment Analysis (ABSA) is a fine-grained sentiment analysis problem that aims to determine the opinion and sentiment polarity at the aspect level from sentences or documents . Early works focused on single ABSA tasks such as Aspect Term Extraction (ATE)  and Aspect Sentiment Classification (ASC) . However, recent studies have explored compound ABSA tasks such as Aspect-Opinion Pair

Figure 2. _Left:_ Token-pair tagging method proposed by Li et al. . The T/A/O label denotes the target/aspect/opinion term. The h2h and t2t identify the relation between spans by aligning the head and tail tokens between spans. The sentiment polarity label is attached to the h2h and t2t labels between the target and opinion terms. _Right:_ Span-level enumeration method.

Extraction (AOPE) (Gir et al., 2014; Chen et al., 2015; Chen et al., 2016), Aspect Sentiment Triplet Extraction (ASTE) (Gir et al., 2014; Chen et al., 2015; Chen et al., 2016; Chen et al., 2016), and Aspect Sentiment Quad Prediction (ASQP) (Chen et al., 2016; Chen et al., 2016) due to their practicality. Next, we will focus on the ASTE task and provide a detailed explanation of its methods as it is most relevant to the DiaASQ task. ASTE is a prevalent compound ABSA task that aims to extract _(aspect, opinion, sentiment)_ triplets from texts such as sentences (Wu et al., 2016). Wu et al. (2016) proposed the Grid Tagging Scheme (GTS) for the ASTE task. GTS extracts aspect terms, opinion terms, and sentiment polarities by tagging token pairs. To alleviate the boundary insensitivity and relation inconsistency problems of GTS, Zhang et al. (2016) and Liang et al. (2016) proposed Boundary-Driven Table-Filling (BDTF) and Span TAgging and Greed inference (STAGE) methods, respectively. However, these methods cannot explicitly capture complete span-level semantic information because they all belong to the token-pair tagging scheme. To this end, span-level enumeration methods are proposed (Chen et al., 2016; Chen et al., 2016; Chen et al., 2016). This method enumerates all spans, arranges them into _(aspect, opinion)_ pairs, and predicts their sentiment polarities. Xu et al. (2016) proposed an end-to-end model, Span-ASTE, which includes a dual-channel span pruning strategy to ease the high computational cost. Chen et al. (Chen et al., 2016) proposed a span-level bidirectional network to extract triplets from both aspect-to-opinion and opinion-to-aspect directions. Feng et al. (2016) infused syntax knowledge into the span-level enumeration method. However, the time complexity of the span-level enumeration methods increases exponentially with the increase of the term types.

### Dialogue-level Aspect-based Sentiment Quadruple Analysis

In recent years, there has been a proliferation of conversational scenes on social media platforms. Individuals increasingly use posts and comments on sites such as Twitter and Weibo to discuss products and services in a dialogue format. In order to promote the development of ABSA in dialogue scenarios, Li et al. (2014) proposed the Dialogue-level Aspect-based Sentiment Quadruple analysis (Di-aASQ) task and annotated large-scale datasets in both Chinese and English. The DiaASQ task aims to extract _(target, aspect, opinion, sentiment)_ quadruples given multi-turn and multi-party dialogues. Compared with text-level ABSA, DiaASQ adds the new term _target_, which denotes words or phrases that refer to the evaluated object, such as _iPhone 6_. Li et al. (2014) proposed an end-to-end token-pair tagging method based on GTS (Li et al., 2014). The method models the dialogue information by a multi-head attention mechanism (Li et al., 2014) and designs a new token-pair tagging scheme. However, it still cannot explicitly capture the complete span-level semantic information. Besides, Li et al. (2014) evaluated the span-level enumeration method on the DiaASQ task. However, high computational costs and label sparsity problems caused by characteristics of the DiaASQ task degrade its performance and efficiency. Before the span pair-level method proposed in this paper, no work could still efficiently model full span-level semantics in the DiaASQ task.

## 3. Methodology

### Task Formulation

A dialogue contains multiple utterances \(D=(u_{1},u_{2},,u_{|D|})\) with the corresponding reply sequence \(Re=(re_{1},re_{2},,re_{|D|})\) and speaker sequence \(Sp=(sp_{1},sp_{2},,sp_{|D|})\), where \(re_{i}\) denotes the index of the utterance that the \(i\)-th utterance replies to and \(sp_{i}\) denotes the speaker identity of the \(i\)-th utterance3. The goal of the DiaASQ task is to extract all _(target, aspect, opinion, sentiment)_ quadruples in \(D\). The quadruple set is denoted as:

\[Q=\{(t_{k},a_{k},a_{k},p_{k})\}_{k=1}^{|Q|}, \]

where \(t\), \(a\), and \(a\) are spans from origin dialogue \(D\) and represent target, aspect, and opinion term, respectively. \(p\{positive,negative,other\}\) is sentiment polarity.

### Span-pair Tagging Scheme

In this section, we first introduce the definition of span-pair labels. Then, we provide a straightforward decoding process. Finally, we summarize several differences between the Span-pair Tagging Scheme (STS) and the token-pair tagging scheme proposed by Li et al. (2014) to further emphasize the advantages of STS.

#### 3.2.1. The Definition of Span-pair Labels

1) Term Types: We use the T, A, and O labels to denote the target, aspect, and opinion terms. For example, the _screen_ is an aspect term if the span pair (_screen, screen)_ is tagged with A. 2) Relations between Terms: We use TA, AO, and TO labels to denote the three relations between terms, namely target-aspect relation, aspect-opinion relation, and target-opinion relation. For example, if the span pair (_iPhone 12, screen)_ is tagged with TA, the relation between _iPhone 12_ and _screen_ is a target-aspect relation. 3) Sentiment Polarities: We use POS, NEG, and OTH labels to denote the positive, negative, and other sentiment polarities. To ensure consistency in the tagging scheme,

Figure 3. An example of span-pair tagging. Due to the space constraints, we selected a few candidate spans from Figure 1 to form the span-level matrix.

we attach sentiment labels to the TO label to form TO-POS, TO-NEG, and TO-OTH labels. For example, there is a target-opinion relation with positive sentiment if the span pair (_iPhone 13, no lag_) is tagged with TO-POS. All span-pair labels are as follows:

\[\{,,,,,,, ,\}. \]

Figure 3 shows a matrix tagged by span-pair labels. It is worth noting that labels \(\{,,\}\) are only in the matrix diagonal, while labels \(\{,,,,\}\) are only in the strictly upper triangular region of the matrix.

#### 3.2.2. The Decoding Process

The design of span-pair labels makes the decoding process more straightforward and intuitive. When decoding quadrupoles, we first obtain the (_target_, _spect_, _opinion_) triplets under the supervision of labels \(\{,,\}\) and \(\{,\}\). Then, we filter invalid triplets and identify sentiment polarities by labels \(\{,,\}\). The detailed decoding process and algorithm are in the Appendix A.

#### 3.2.3. Differences from Token-pair Tagging Scheme

Li et al. (Li et al., 2018) first applied the token-pair tagging scheme to the DiaASQ task by retrofitting the GTS (Wang et al., 2018). For convenience, we refer to the token-pair tagging scheme proposed by Li et al. (Li et al., 2018) as the GTS-Dia scheme. Our STS differs from the GTS-Dia scheme in the following ways:

(1) **the granularity of tagging is different.** STS tags at the span level, while GTS-Dia scheme tags at the token level. Therefore, STS can explicitly capture the complete semantics of spans and model the span-level interactions while the GTS-Dia scheme fails.

(2) **The difficulty of tagging is different.** The labels \(\{,,\}\) and labels \(\{,,,,\}\) are distributed across different regions of the span-level matrix in the STS, which reduces the difficulty of tagging. In other words, the model can narrow down the choice of labels by identifying whether two spans in a span pair are the same or not. In contrast, in the GTS-Dia scheme, all labels will likely appear in the strictly upper triangular region of the token-level matrix, making tagging more challenging.

(3) **The difficulty and efficiency of decoding are different.** The decoding process of STS is both straightforward and intuitive thanks to the design of span-pair labels, as mentioned in section 3.2.2. However, the GTS-Dia scheme requires a human-designed heuristic algorithm for complicated situations. One such issue is the difficulty in determining the correspondence between hzh and tzt labels. Besides, it can be tricky to determine the sentiment polarity when the sentiment labels attached to hzh and tzt are different. These issues complicate the decoding process of the GTS-Dia scheme.

### Multi-level Representation Model

Figure 4 shows an overview of our Multi-level Representation Model (MRM).

**Token Encoding**: We use Pre-trained Language Models (PLMs) as the contextual encoder of the dialogue \(D=(u_{1},u_{2},,u_{|D|})\). In order to take full advantage of the capabilities of the PLMs, the whole dialogue \(D\) with \(\) and \(\) is fed into the PLMs:

\[I=(>,u_{1},/s>,,>,u_{|D|},</s>), \]

\[=(_{1},_{2},,_{|I|})=(I), \]

where \(\) and \(</s>\) denote special tokens of PLMs, \(_{i}\) denotes the contextual representation of the \(i\)-th token of input sequence \(I\). We construct the reply mask \(^{Re}\) and speaker mask \(^{Sp}\) to denote the reply sequence \(Re\) and speaker sequence \(Sp\), respectively. Following previous work (Li et al., 2018), we use multi-head self-attention mechanisms (Li et al., 2018) to infuse this information:

\[^{s}=(,,,^{*})\] \[=(^{T})^{*}}{}), \]

where \(*\{Re,Sp\}\), \(===,\) denotes Hadamard product operation, and \(d\) denotes the hidden size. Next, we use the MaxPooling operation to obtain the contextual representations of tokens with dialogue structure information:

\[^{f}=(_{1}^{f},_{2}^{f},,_{|I|}^{f})=(^{Re},^{Sp}). \]

**Span Generating & Pruning**: We obtain the span list \(SL\) by enumerating all spans. Then, we define the contextual representation of each span by infusing boundary and width information and obtain the span's contextual representation list \(\) corresponding to \(SL\):

\[_{i}=[_{(span_{i})}^{f},_{( span_{i})}^{f},_{}],\] \[=(_{1},_{2},...,_{L}), \]

Figure 4. Multi-level Representation Model.

where \(span_{i} SL\) denotes the \(i\)-th span, \(L=|SL|=||\) denotes the total number of spans, \((span_{i})\) and \((span_{i})\) denotes the index of the start and end token for the \(i\)-th span, and \(_{i}\) denotes the learnable embeddings of width \(=|(span_{i})-(span_{i})+1|\). In order to improve running efficiency, we train a Span Ranker (It will be described below) to prune \(SL\) and S. The Span Ranker gives the score of term types for \(span_{i}\):

\[score_{i}=P(|span_{i})+P(|span_{i})+P(|span_{i}), \]

where \(P(|span_{i})\) denotes the probability that the \(i\)-th span is predicted as the target term. Then, we use the contextual representations of the top \(K\) spans with the highest score to form a new contextual representation list:

\[_{top}=\{_{1},_{2},,_{K}\}, \]

where \(|_{top}|=K L\).

**Span pair Generating & Classifying** To model the span-level interactions and the distance information between spans, we construct the contextual representation of each span pair as:

\[_{i,l}=[_{i},_{j},_{i} _{j},_{l}], \]

where \(\) denotes the learnable embeddings of distance \(=min(|(span_{j})-(span_{i})|,|(span_{j} )-(span_{i})|),\)\(1 i j K\) and \(_{i},_{j}_{top}\). The contextual representations of all span pairs form the upper triangular matrix of size \(K K\). We apply a Multi-Layer Perception (MLP) to predict the probability distribution of labels:

\[P(y_{i,j})=((_{i,j})), \]

where the label \(y_{i,j}\) is distributed among nine categories, as shown in Formula 2.

**Decoding** Finally, we obtain all quadruples from the tagged span-level matrix with the help of STS.

### Span Ranker

We train a Part-Of-Speech-aware (POS-aware) Span Ranker to score candidate spans within the MRM. Like the MRM, we concatenate utterances by special tokens of PLMs and feed them into PLMs to obtain the initial contextual representation of tokens \(=(_{1},_{2},,_{|I|})\), as shown in Formulas 3 and 4.

In fact, the type of term is closely related to its POS. For example, the _target_ term is generally a proper noun or noun phrase, and the _opinion_ term is generally an adjective or adjective phrase. Therefore, we enumerate all spans and obtain their boundary POS information using natural language processing tools (NLTK4 for English and Jieba3 for Chinese). Besides, we use the AveragePooling operation to obtain the overall semantic representation of each span. The final contextual representation of each span is as follows:

\[_{a,b}^{sr}=[_{a}, _{pos},_{b},_{pos},_{ [b-a+1]},\\ (_{a},_{a+1},,_{b})], \]

where superscript \(sr\) is the abbreviation for Span Ranker, \(_{pos}\) denotes the learnable embedding of POS _pos_, and \(pos_{a}\) denotes the POS of the \(a\)-th token. We apply a MLP to predict the probability distribution of labels:

\[P(y_{a,b}^{sr})=((_{a,b}^{sr})), \]

where the label \(y_{a,b}^{sr}\{,,,\}\).

### Training

For the MRM, the loss function is defined using the span pair-level cross-entropy loss:

\[=-_{l=1}^{K}_{j=l}^{K}y_{i,j}(P(y_{i,j})). \]

For the Span Ranker, the loss function is defined using the span-level cross-entropy loss:

\[_{sr}=-_{a=1}^{|I|}_{b=a}^{|I|}y_{a,b}^{sr}(P(y_{a,b}^{ sr})). \]

## 4. Experiments

### Dataset and Metrics

We conducted experiments on the DiaASQ dataset (Song et al., 2017) derived from posts and comments on the Chinese social media platform Weibo 6. The dataset is in the mobile phone domain and includes Chinese (ZH) and English (EN) versions. Table 1 lists the statistics of the dataset.

Following previous works (Song et al., 2017), we take identification-F1 (iden-F1 for short) (Bang et al., 2017) and micro-F1 as measurements for evaluating the DiaASQ task. The micro-F1 measures the whole quadruple, while iden-F1 does not distinguish the sentiment polarity. We also test the span match and pair extraction subtasks using exact-F1, where a prediction is only correct if the extracted span or pair matches the ground truth exactly. Besides, we use macro-F1 to measure the performance of Span Ranker.

   Datasets & ZH & EN \\  Dialogue & 1,000 & 1,000 \\ Utterance & 7,452 & 7,452 \\  Target & 8,308 & 8,264 \\ Aspect & 6,572 & 6,434 \\ Opinion & 7,051 & 6,933 \\  Quadruple & 5,742 & 5,514 \\ Intra & 4,467 & 4,287 \\ Inter & 1,275 & 1,227 \\  Avg. of \#Word per dialogue & 206 & 181 \\ Avg. of \#Ultterance per dialogue & 7.45 & 7.45 \\ Avg. of \#Quadruple per dialogue & 15 & 14 \\   

Table 1. Statistics of DiaASQ dataset. The “Intra” denotes the intra-utterance quadruples, where terms come from the same utterances. The “Inter” denotes the inter-utterance quadruples, where terms come from different utterances. The “Avg” is the abbreviation for Average.

### Baselines

Because DiaASQ is a new task, Li et al. (Li et al., 2019) redesigned several existing methods and proposed a new token-pair tagging method, GTS-Dia, based on GTS (Li et al., 2019). We redesign another token-pair tagging method, BDTF-Dia, based on the table representation approach of the BDTF (Li et al., 2019). Besides, we utilize the few-shot in-context learning method to evaluate the ChatGPT 7. The detailed settings for ChatGPT are in Appendix B. All baselines are as follows:

**Token-pair Tagging Methods:** GTS-Dia (Li et al., 2019) and BDTF-Dia (Li et al., 2019).

**Span-level Enumeration Method:** Span-ASTE (Li et al., 2019).

**Few-shot In-Context Learning Method:** ChatGPT.

**Other Methods:** CRF-Extract-Classify (Chen et al., 2019), SpERT (Chen et al., 2019), and Paraphrase (Yang et al., 2019).

### Experimental Settings

All fine-tuned models use the Roberta-Large (Zhu et al., 2019) and Chinese-Roberta-wwm-base (Chen et al., 2019) as PLMs for English and Chinese datasets. For our MRM, we set \(K=128\). The max length of the span is 10. We select the model with the highest micro-F1 scores on the validation set for the test set. Our experiments run on a single Nvidia RTX 3090 GPU with 24GB of memory, and all experimental results are the average values over five runs under the seed list .

### Main Results

We compare our model against baselines in the DiaASQ task using micro-F1 and iden-F1 scores. Besides, we also evaluate the performance of our model in two sub-tasks (Span Match and Pair Extraction). Table 2 presents these results.

For the DiaASQ task, our model shows considerable and stable performance improvements, surpassing the previous state-of-the-art GTS-Dia by an average of **8.06%** in iden-F1 and **8.07%** in micro-F1 scores across two languages. We attribute these gains to our span-pair tagging scheme and the consideration of our model on the three characteristics of DiaASQ tasks mentioned in the Introduction. For the Pair Extraction task, our model achieves the best performance, reflected by exact-F1 scores exceeding 50% for TA, AO, and TO extraction on Chinese and English datasets. These improvements highlight the effectiveness of our model in capturing relations between terms through span-level interactions. Besides, the performance of Span-ASTE is unsatisfactory despite modeling span-level interactions. The reason is that the enumerated triplets are mostly invalid, leading to a severe label sparsity problem. The problem further prevents Span-ASTE from training toward the optimal solution. For the Span Match task, our model achieves an overall performance improvement in both languages. Furthermore, the performance of all models is poor in the Opinion Match task. The phenomenon is related to the diverse expressions of opinion.

Besides, we use 5-shot in-context learning to evaluate the performance of ChatGPT. On the one hand, ChatGPT performs better than CRF-Extract-Classify and SpERT in many cases, demonstrating its potential in resource-constrained scenarios. On the other hand, it still falls short compared to most PLMs-based fine-tuned models. The performance sharply decreases when dealing with complex tasks such as DiaASQ, indicating that ChatGPT struggles with understanding complex structured sentiment information. This conclusion is consistent with the observations of Zhang et al. (Zhang et al., 2019) and Zhao et al. (Zhao et al., 2019).

    & &  &  &  \\   & & T & A & O & TA & TO & AO & Iden-F1 & **Micro-F1** \\   & CRF-Extract-Classify & 91.11 & 75.24 & 50.06 & 32.47 & 26.78 & 18.90 & 9.25 & 8.81 \\  & SpERT & 90.69 & 76.81 & 54.06 & 38.05 & 31.28 & 21.89 & 14.19 & 13.00 \\  & ParaPhrase & / & / & / & 37.81 & 34.32 & 27.76 & 27.98 & 23.27 \\  & Span-ASTE & / & / & / & 44.13 & 34.46 & 32.21 & 30.85 & 27.42 \\  & BDTF-Dia & 91.08 & 76.24 & 60.88 & 51.41 & 49.33 & 52.58 & 41.06 & 34.22 \\  & GTS-Dia & 90.23 & 76.94 & 59.35 & 48.61 & 43.31 & 45.44 & 37.51 & 34.94 \\  & ChatGPT (5-shot ICL) & 68.78 & 57.87 & 36.45 & 34.98 & 42.48 & 27.43 & 20.59 & 18.41 \\   & Ours & **91.49\({}_{ 0.21}\)** & **77.10\({}_{ 0.30}\)** & **61.24\({}_{ 0.35}\)** & **53.56\({}_{ 0.54}\)** & **50.29\({}_{ 0.22}\)** & **53.26\({}_{ 0.64}\)** & **42.82\({}_{ 0.37}\)** & **40.59\({}_{ 0.36}\)** \\   & CRF-Extract-Classify & 88.31 & 71.71 & 47.90 & 34.31 & 20.94 & 19.21 & 12.80 & 11.59 \\  & SpERT & 87.82 & 74.65 & 54.17 & 28.33 & 21.39 & 23.64 & 13.38 & 13.07 \\  & ParaPhrase & / & / & / & 37.22 & 32.19 & 30.78 & 26.76 & 24.54 \\  & Span-ASTE & / & / & / & 42.19 & 30.44 & 45.90 & 28.34 & 26.99 \\  & BDTF-Dia & 88.60 & 73.37 & 62.53 & 49.26 & 47.55 & 49.95 & 38.80 & 31.81 \\  & GTS-Dia & 88.62 & 74.71 & 60.22 & 47.91 & 45.58 & 44.27 & 36.80 & 33.31 \\  & ChatGPT (5-shot ICL) & 68.05 & 53.22 & 45.08 & 28.76 & 37.24 & 25.36 & 17.17 & 15.26 \\   & Ours & **89.00\({}_{ 0.71}\)** & **75.09\({}_{ 0.08}\)** & **63.57\({}_{ 1.07}\)** & **55.12\({}_{ 0.89}\)** & **53.11\({}_{ 0.29}\)** & **56.52\({}_{ 1.15}\)** & **47.61\({}_{ 0.78}\)** & **43.80\({}_{ 0.76}\

## 5. Further Analysis

### Ablation Study

We conduct ablation studies to verify the effectiveness of different modules in MRM, using the micro-F1 scores in the DiaASQ task as the measure. Besides, we study the impact of POS information in the Span Ranker, using the macro-F1 scores in three span match subtasks as the measure.

As shown in Table 3, each module positively functions on MRM. Our model performs better than the state-of-the-art baseline even without all modules, demonstrating that MRM benefits from the span-pair tagging scheme. Specifically, the performance of MRM degrades on both Chinese and English datasets when removing speaker and reply attention modules \(^{S}\) and \(^{Re}\), demonstrating the necessity of dialogue structure information. The speaker and reply sequence can provide relevant information between utterances. Besides, MRM needs the width information of spans due to the imbalanced distribution of the width of terms, so removing the **w**emb hurts the performance. After removing the distance information between spans **dem**, our model cannot perceive the relative distance between spans in span pairs, so the performance drops. MRM can explicitly model the span-level interactions by Hadamard product \(s_{i} s_{j}\). Removing \(s_{i} s_{j}\) makes the performance of MRM sharply degrade. Finally, we study the effect of POS in Span Ranker. The performance improvement of the Span Ranker gains from POS information penn is limited. One possible reason is that PLMs acquired substantial POS knowledge during pre-training.

### Detailed Study on Complex Scenarios

To verify the ability of our model to deal with complex scenarios, we conduct the three subsets of the test set: 1)\(_{1}\): each dialogue in the \(_{1}\) contains inter-utterance quadruples. 2)\(_{2}\): the number of quadruples for each dialogue in the \(_{2}\) is not less than 15. 3)\(_{3}\): the number of utterances for each dialogue in the \(_{3}\) is not less than 8. The \(_{1}\), \(_{2}\), and \(_{3}\) accounted for 68%, 14%, and 48% of the ZH test set and 32%, 32%, and 48% of the EN test set. We compare the performance of our model with GTS-Dia and BDTF-Dia on the DiaASQ task, and the micro-F1 scores are in Table 4. The performance of GTS-Dia sharply drops when facing complex scenarios. BDTS-Dia performs more stably than GTS-Dia, but the performance is still unsatisfactory. In contrast, our model exhibits a stable and considerable performance when facing complex scenarios, outperforming the GTS-Dia and BDTF-Dia in all cases. The phenomenon suggests that our model is more effective in 1) capturing inter-utterance dependencies, 2) handling complex corresponding relations between terms caused by abundant quadruples, and 3) handling longer sequences.

### Effect of \(K\) value

The \(K\) value denotes the number of remaining spans after pruning, determining the size of the span-level matrix. We study the effect

   Model & Overall & \(_{1}\) & \(_{2}\) & \(_{3}\) \\   ZH \\  } & GTS-Dia & 34.94 & 30.19(14.75) & 34.81(120.13) & 25.29(19.463) \\  & BDTF-Dia & 34.22 & 30.53(13.89) & 32.98(11.24) & 35.40(17.18) \\  & Ours & 40.59 & 37.62(12.97) & 42.34(17.75) & 40.37(10.22) \\   EN \\  } & GTS-Dia & 33.31 & 26.65(14.63) & 31.25(12.06) & 32.85(10.46) \\  & BDTF-Dia & 31.81 & 30.00(11.13) & 30.69(11.12) & 30.89(10.87) \\  & Ours & 43.80 & 43.09(10.71) & 42.76(11.40) & 42.97(10.83) \\   

Table 4. Results on complex scenarios.

Figure 5. Analysis results with respect to \(K\) on the English dataset. In the second line chart, recall@\(K\) denotes the ratio of the number of terms in the top \(K\) spans to the total number of terms; Label sparsity@\(K\) denotes the ratio of the number of None labels to the total number of labels in the \(K K\) matrix; Label num@\(K\) denotes the overall number of labels in the \(K K\) matrix. The results of the Chinese dataset are in Appendix C.

   Model & ZH & EN \\  MRM & **40.59** & **43.80** \\  w/o all modules & 36.80(13.79) & 38.62(15.18) \\  w/o H\({}^{S}\) & \(^{Re}\) & 39.35(11.24) & 42.53(11.27) \\  w/o H\({}^{S}\) & 40.45(10.14) & 42.89(10.91) \\  w/o H\({}^{Re}\) & 40.53(10.06) & 43.00(10.80) \\  w/o **wemb** & 40.41(1of the \(K\) value on the English dataset, as depicted in Figure 5. We selected the model with the best performance in the validation dataset to evaluate the test dataset.

Specifically, the performance of our model is suboptimal with a small \(K\) value, such as 16. The reason is that a small \(K\) corresponds to a low recall, indicating that abundant terms do not appear in the \(K K\) matrix. Subsequently, our model achieves state-of-the-art performance as \(K\) increases due to increased recall and label number. However, the performance does not infinitely increase with the increase of \(K\). The reasons for this phenomenon are as follows: 1) the high label sparsity makes it difficult for the model to converge to the optimal solution during training; 2) The number of non-None labels has an upper bound. Besides, the training time of our model positively correlates with the \(K\) value. Our model exhibits extremely high training efficiency when \(K\) is less than 256. In conclusion, our model demonstrates superior performance compared to GTS-Dia and Span-ASTE regarding effectiveness and efficiency, provided that a suitable value of \(K\) is chosen (such as 64 and 128).

### Analysis of Time Complexity

Table 5 shows the time complexity of the three models. On the one hand, our model outperforms the Span-ASTE with or without using the span pruning strategy because we construct the span-level matrix rather than enumerate all spans and triplets, which leads to Span-ASTE's \(O((N^{2},K^{3}))\) time complexity. On the other hand, GTS-Dia has \(O(N^{2})\) time complexity due to its token-level matrix. The time complexity of our model is slightly worse at \(O((N^{2},K^{2}))\) because we enumerate spans and construct the span-level matrix. In practice, the time complexity of our model is optimized to \(O(N^{2})\) due to \(K<N\). Besides, the Span Ranker accelerates the enumeration of spans in MRM by caching the span indices so that the running speed of our model is faster than GTS-Dia.

### Case Study

In order to better understand the capacity of our model, we illustrate a case study using GTS-Dia and our model. As shown in Figure 6, our model can correctly extract all quadruples while GTS-Dia fails. Concretely, GTS-Dia ignores the _not_ and wrongly identifies the sentiment polarity by tagging the token pairs (\(OnePR,good\)) and (\(9Pro,good\)) when extracting the first quadruple. In the third quadruple, GTS-Dia wrongly extracts _consumption_ rather than _power consumption_. The reason is that GTS-Dia cannot capture the complete span-level semantics. In contrast, our model correctly extracts quadruples by tagging the span pairs.

## 6. Conclusions and Future Work

This paper proposes a novel span-pair interaction and tagging method for the Dialogue-level Aspect-based Sentiment Quadruple analysis (DiaASQ) task, which includes a novel Span-pair Tagging Scheme (STS) and a simple and efficient Multi-level Representation Model (MRM). The STS explicitly captures the complete span-level semantics by tagging span pairs in a span-level matrix. MRM enumerates spans and constructs a span-level matrix of span pairs based on the STS, explicitly modeling the dialogue information and the span-level interactions. Besides, we train a Span Ranker to improve the running efficiency of the MRM. Extensive experiments on the DiaASQ datasets demonstrate the superiority of our method.

There are also several potential limitations in this work. When K is small, the Span Ranker may filter out some terms from the candidate span list with the result that they cannot appear in the span-level matrix. These errors further limit the performance of final quadruple decoding. In the future, we will extend our work and develop an end-to-end framework to solve this issue under the premise of efficiency. Besides, there is mutual supervision information between span-pair labels in the span-level matrix. We plan to apply contrastive learning to model label-level supervision information.

   Model & Time Complexity \\  GTS-Dia & \(O(N^{2})\) \\ Span-ASTE & \(O(N^{2})+O(K^{3})=O((N^{2},K^{3}))\) \\ w/o span pruning & \(O(N^{2})+O(L^{3})=O(L^{3})\) \\  Ours & \(O(N^{2})+O(K^{2})=O((N^{2},K^{2}))\) \\ w/o span pruning & \(O(L^{2})\) \\   

Table 5. Time Complexity. The \(N,L\), and \(K\) denote the number of tokens, spans, and remaining spans after pruning, where \(L N\) and \(L K\). We ignore the dimension of vector representations for convenience. It is worth noting that our span pruning strategy implemented by the Span Ranker differs from the span pruning strategy of the Span-ASTE.

Figure 6. An example predicted by GTS-Dia and our model.