# Subgraph Federated Unlearning

Anonymous Author(s)

###### Abstract.

Subgraph federated learning aims to collaboratively train a global model over distributed subgraphs stored in multiple local clients with strict privacy constraints, which is crucial to a wide range of applications such as healthcare, recommendation systems, and financial crime detection. With the increasing emphasis on the "right to be forgotten," the issue of machine unlearning of subgraph federated models has gained significant importance. However, existing federated unlearning approaches largely focused on unstructured data, overlooking the impact of structural dependency and cross-client interferences in graph-based data. To this end, in this paper, we propose ReGEnUnlearn, a subgraph federated unlearning framework for efficient and comprehensive unlearning of multiple target clients. Specifically, we first propose the _Reinforced Federated Policy Sampler_ (RFPS) to learn optimal sampling strategies that minimize the interference among cross-client subgraphs. By interacting with the federated graph sampling environment, the agent learns to selectively forget an optimal subgraph of target clients, thus preserving the global model utility. Moreover, we propose the _Parameter-free Graph Prompt Knowledge Distillation_ (PGPKD) module, which retains the unique graph knowledge contributed by the target clients, thereby facilitating comprehensive unlearning via a tailored gradient ascent objective. Extensive experiments in various federated settings demonstrate ReGEnUnlearn's superiority over existing federated unlearning methods, offering a speedup of 3.6\(\) to 9\(\) compared to traditional retraining while maintaining model utility within a range of 100\(\%\) - 102\(\%\). The source code is available at [https://anonymous.4open.science/r/Unlearn-F27B/README.md](https://anonymous.4open.science/r/Unlearn-F27B/README.md)

machine unlearning; subgraph federated learning +
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

+
Footnote †: ccs: Computing methodologies Supervised learning

## 1. Introduction

Subgraph federated learning aims to address the challenges of collaborative learning across distributed subgraphs stored in multiple local systems while adhering to strict privacy regulations . This approach is critical to diverse applications, including healthcare, recommendation systems, and financial crime detection, especially in cross-silo federated learning scenarios . With increasing emphasis on privacy rights, such as the "right to be forgotten ," subgraph federated unlearning emerges as a crucial task, aiming to selectively remove specific clients' contributions from the global model. For example, in the context of international banks applying federated learning for financial crime detection, changing privacy laws may compel certain banks to withdraw their data, underscoring the need for effective unlearning mechanisms.

Nevertheless, existing federated unlearning approaches, as discussed in , predominantly focus on non-graph data, thus failing to address the complexities in subgraph federated unlearning. For example, VERIFI  involves the submission of gradient updates by all clients to the server. The server then amplifies gradients from remaining clients while reducing contributions from the target clients. Halimi _et al._ introduce a projected gradient ascent to maximize empirical loss on the target clients. As another example, FedRecover  iteratively eliminates contributions from target clients based on historical storage models. However, the above methods primarily focused on erasing the contribution of a target client with unstructured data (_e.g._, image, time series, and text _etc_), largely overlook the impact of structural dependency and cross-client interferences in graph-based data, as depicted in Figure 1. To address this gap, we investigate the subgraph unlearning problem in a federated environment with multiple client participants.

However, it is a non-trivial issue to effectively opt out of the contribution of multiple distributed clients while maintaining the model utility. (1) _Cross-client subgraph interference_. In the federated scenario, the subgraphs held by each client may overlap with each other (_e.g._, common users in multiple banks, patients shared by

Figure 1. (a) Traditional federated unlearning on unstructured data (_e.g._, image, time series, and text _etc_). (b) Subgraph federated unlearning raises additional concerns about erasing structural knowledge and cross-client subgraph overlap.

different hospitals). Simply eliminating contributions of a subgraph in a target client may forget common knowledge encoded in the overlapped subgraph, therefore leading to unexpected performance degradation of the global model, as illustrated in Figure 2(a). One straightforward solution is removing cross-client subgraphs via graph sampling and applying unlearning on the filtered subgraph, as depicted in Figure 2(b). However, due to privacy constraints, both the server and clients have limited access to the identity of cross-client subgraphs. How to eliminate the cross-client interference to guarantee the global model utility is the first challenge. (2) _Diversified structural contribution of each client._ A key benefit of federated learning is to collaboratively train a better global model by absorbing personalized knowledge from each client, _e.g._, rare disease cases in a hospital, exclusive user purchase records in an e-commerce platform. However, removing the unique contribution of a target client from a global graph model requires identifying various knowledge, such as entity attributes, node connectivity, and high-order structural patterns. How to comprehensively unlearn subgraph knowledge of a target client is another challenge.

To address the aforementioned challenges, we introduce the _Reinforced Graph Knowledge Enhancement Subgraph Federated Unlearning (ReGEnUnlearn)_ framework, comprising two key modules. First, the _Reinforced Federated Policy Sampler_ (RFPS) module is proposed to mitigate the interference among cross-client subgraphs. By interacting with the federated graph sampling environment, the agent learns optimal graph sampling strategies that facilitate the removal of cross-client nodes while preserving model utility. Second, a _Parameter-free Graph Prompt Knowledge Distillation_ (PGPKD) module is devised to distill specific graph knowledge from the target clients. This process encodes target clients' unique knowledge into the distilled graph prompts, which can be inserted into the sampled subgraph. In this way, the structural knowledge of a target client can be comprehensively unlearned by optimizing a gradient ascent objective over the prompt-enhanced subgraph.

The contributions of our work are summarized as follows: (1) To our knowledge, this is the first study to investigate subgraph federated unlearning with consideration of multiple target clients. (2) We propose the ReGEnUnlearn framework to comprehensively eliminate multiple target clients while preserving utility. ReGEnUnlearn is agnostic to federated algorithms and can be easily integrated into different subgraph federated scenarios. (3) We conduct comprehensive experiments on four real-world datasets under various subgraph federated settings. The proposed framework demonstrates notable speedups ranging from 3.6\(\) to 9\(\) compared to traditional retraining while maintaining model utility within a range of 100%-102%.

## 2. Preliminaries

In this section, we provide the background on subgraph federated learning and federated unlearning.

### Subgraph Federated Learning

#### 2.1.1. Notation

We represent the global graph as \(=(,,)\), where \(\) denotes the node set, \(\) represents the edge set, and \(\) denotes the node feature set. Each node \(v\) is associated with its feature \(_{v}\). In the federated learning system, we consider a central server denoted as \(S\) and \(M\) distributed local clients \(C=\{C_{1},,C_{M}\}\), each possessing a subgraph \(_{i}=(_{i},_{i},_{i})\). These entities collaboratively train a global model \(F()\), where \(\) is the model weights and \(=_{i=1}^{M}V_{i}\).

#### 2.1.2. Local Graph Learning

The _Message Passing Neural Network (MPNN)_ is a widely used framework for graph data that can accommodate various Graph Neural Network (GNN) architectures. In the subgraph federated learning, each client has a local GNN model and collaborates with others to train a global model. The local graph learning process consists of the following two phases.

**Message Passing.** For each client \(_{i}\), the \(l\)-th layer in MPNN is defined as follows,

\[_{j}^{l+1,l}=_{^{l,i}}(_{j}^{L,l}, _{j}^{l+1,l}), \]

where \(_{j}^{l+1,l}\) represents the node feature vector at layer \(l+1\) for node \(v_{j}\) in client \(_{i}\). The term \(_{j}^{l+1,l}\) denotes the aggregated message from the neighbors of node \(v_{j}\), and \(_{^{l,i,l}}\) is a function updating the node feature vector, with \(^{l+1,l}\) as the corresponding parameter in the \(l\)-th layer. The computation of the message \(_{j}^{l+1,l}\) is define as below,

\[_{j}^{l+1,l}=_{v_{k}(v_{j})}_{ ^{l+1,l}}(_{j}^{L,l},_{k}^{L,l},_{jk}^{ Lj}), \]

where \((v_{j})\) represents the neighborhood of node \(v_{j}\), \(_{^{l+1,l}}\) is the function generating the message from node features, and \(^{l+1,l}\) is the corresponding parameter. \(_{jk}^{L,l}\) denotes message embedding associated with the edge between nodes \(v_{j}\) and \(v_{k}\) in the \(l\)-th layer.

**Readout.** The readout phase computes the final feature for subsequent tasks,

\[_{v_{j}}^{l}=P_{^{l}}(_{j}^{L,l}|v_{j}^{ l}), \]

where \(_{v_{j}}^{l}\) represents the prediction for node \(v_{j}\). The readout function \(P_{^{l}}\) encompasses methods such as mean pooling, where \(^{l}\) is the parameter for the readout function.

Figure 2. (a) Comparison of unlearning on subgraphs with non-overlapping (Non-OL) and overlapping (OL) on the Photo dataset. The subgraph overlapping significantly reduces the model’s utility. (b) Unlearning on optimally sampled subgraph (OS Subgraph) better retains the model utility compared to heuristically sampled subgraph (HS Subgraph).

#### 2.1.3. Subgraph Federated Optimization

The objective of subgraph federated learning is defined as follows,

\[_{}_{i=1}^{M}p_{i}_{i}(_{i}()), \]

where the term \(p_{i}\) denotes the model aggregation weight, with the constraint that \(_{i=1}^{M}p_{i}=1\). The function \(_{i}()\) corresponds to the local empirical risk function and is formally expressed as

\[_{i}(_{i}()):=_{(_{i}, _{i})}(_{i}(;_{i} ),_{i}), \]

where \((_{i}(;_{i}),_{i})):= {|_{i}|}_{_{i}}l(_{i}(;_{i}(n_{i})),y_{_{i}})\) is the local loss function, \(_{i}()\) is the GNN model for client \(C_{i}\).

To optimize the objective function, we consider the classic federated algorithm, FedAvg algorithm (Zhou et al., 2017), for illustration. In each round \(t\), the central server sends the global model \(^{t}\) to all local clients. Subsequently, each client performs multi-steps of the Stochastic Gradient Descent (SGD) optimization method to refine their local models. Following this local optimization, the clients transmit their updated local models as \(_{t}^{t}\) back to the central server. Finally, the central server aggregates these local models by weights \(p_{i}\) to obtain the next round's global model \(^{t+1}=_{i}p_{i}_{t}^{t}\). This optimization process iterates over a specified number of \(T\) rounds.

### Federated Unlearning

**Approximate Federated Unlearning.** In this paper, we specifically focus on client-level federated unlearning. In this scenario, multiple clients want to opt out of the federation and eliminate their contribution from the global model. Assume that there are \(N_{t}\) clients who want to opt out of the federation. We refer to these clients as target clients \(T=\{I_{1},,I_{N_{t}}\} C\). Naive retraining methods from scratch are computationally expensive and impractical, especially when confronted with frequent removal requests.

**Objective.** The objective of this paper is to solve approximate federated unlearning, which can eliminate the contribution of the subgraph in target clients while maintaining comparable model utility comparable to full retraining.

**Unlearning Verification.** The backdoor trigger is one of the most widely adopted verification methods for evaluating the performance of federated unlearning methods (Golov et al., 2013; Glorot and Bengio, 2010; Goodfellow et al., 2014). In practical scenarios, target clients utilize their datasets, incorporating a fraction of the data injected with backdoor triggers corresponding to specific target labels. The resulting global model learns the correlation between the trigger patterns and the target labels. By denoting the backdoor trigger as \(g\), a successful trigger would lead the GNN model to classify into the target label,

\[_{i} g(;_{i}(n_{i}))=y_{r}, \]

where \(y_{r}\) represents the target label. A successful unlearning method should disentangle this correlation, resulting in a lower attack success rate.

\[_{i} g(;_{i}(n_{i}))=y_{_{i}}, \]

**Threat Model.** This work focuses on semi-honest scenarios, excluding considerations of malicious clients or model replacement attacks. The global model is expected to exhibit robust performance on clean datasets, ensuring that introducing a backdoor trigger does not compromise its overall performance.

## 3. Reinforced Graph Knowledge Enhancement Subgraph Federated Unlearning

**Overview.** Figure 3 illustrates the overall framework of Reinforced Graph Knowledge Enhancement Subgraph Federated Unlearning, which consists of two crucial modules: (1) Reinforced Federated Policy Sampler (RFPS) module aims to mitigate the cross-client interference. (2) Prompt Knowledge Enhancement Graph Distillation (PKEGD) module distills specific graph knowledge from the target clients for comprehensive subgraph unlearning. In particular, the first module RFPS, selectively samples subgraphs for unlearning to guarantee the global model utility. For the second module, PKEGD encodes key graph knowledge to graph prompts, which can be inserted with the sampled subgraph from RFPS. Finally, the global model is optimized via the tailored unlearning loss over the integrated subgraph for multi-client unlearning.

### Reinforced Federated Policy Sampler

Unlearning across multiple clients would significantly decrease the model utility, especially with cross-client node interference. Based on the observation illustrated in Figure 2, the first intuition of our model is unlearning on a sampled subgraph. However, a key challenge is to remove the overlapping subgraph without accessing other clients' data. To address this issue, we propose a Reinforced Federated Policy Sampler, which leverages a reinforcement learning algorithm to enable the agent to determine the optimal policy for sampling a subgraph. The graph sampling process is formulated into a general decision \(=\{^{(t)},^{(t)},^{(t)},R\}\) for client \(C_{i} C\). Here, \(^{(t)}=\{s_{t}^{(t)}\}\) represents the set of states comprising all possible intermediate and final sampled graphs. The set \(^{(t)}=\{a_{t}^{(t)}\}\) represents the actions characterizing the sampled graph's behavior at each time step. \(^{(t)}\) is the transition dynamics specifying the possible outcomes of carrying out an action. \(R(s_{t}^{(t)})\) is a reward function specifying the reward after reaching the state \(s_{t}^{(t)}\).

**State.** For a client \(C_{i} C\), we define the state as all possible sampled graphs. Specifically, each state \(s_{t}\) is represented by a graph \(_{i}^{}=(_{i}^{},_{i}^{}, _{i}^{})\), where \(^{}=\{(u,w) u,w^{}(u,w)\}\), and \(_{i}^{}\) represents the corresponding node features.

**Action.** The action space encompasses all possible combinations of selected \(k\) nodes, ranging from the original graph \(^{(t)}\). The \(a_{t}^{(t)}=\{0,1\}^{n}\) represents an action, where the \(i\)-th of value \(a_{t}\) indicates whether node node \(v_{i}\) is selected (1) or not (0). Specifically, the action is generated by a policy function \(_{}(a_{t}^{(t)}|s_{t}^{(t)})\), which takes the state and the original graph as input, where \(\) represents the parameters. In particular, the policy network \(_{}(a_{t}^{(t)}|s_{t}^{(t)})\) consists of node embedding and action prediction functions.

**Node Embedding.** To predict actions, the policy network first computes the node embedding of the input graph using the node embedding function \(g_{}()\), parameterized with \(\). Specifically, we employ a graph neural network to calculate the node embedding:

\[H^{(l+1)}=((^{-} ^{}H^{l}W)), \]where \(H^{(t+1)}\) represents the node features matrix at layer \(l+1\). AGG(-) denotes the aggregation function, \(\) is the activation function, \(\) is the normalized degree matrix, \(\) is the adjacency matrix, and \(W\) is the learnable weight matrix.

**Action Prediction.** The action \(a_{t}^{(i)}\) is predicted based on two components: the probability-sampling-based action \(a_{P_{t}}^{(i)}\) and the learnable action \(a_{I_{t}}^{(i)}\),

\[a_{t}^{(i)}=(a_{P_{t}}^{(i)},a_{I_{t}}^{(i)}), \]

where CONCAT represents the concatenation function, and \(a_{P_{t}}^{(i)} P_{}\) is a stochastic probability distribution with parameter \(\). The learnable action \(a_{I_{t}}^{(i)}\) is defined by the following equations,

\[a_{I_{t}}^{(i)}=(((g_{}(s_{t-1}^{(i) }),g_{}(_{i})))), \]

where \(()\) denotes the softmax function. The final sampled graph is denoted as \(_{t}^{}=(_{t}^{},_{t}^{}, _{t}^{})\), where \(^{}=\{(u,w) u,w^{}(u,w)\}\), and \(_{t}^{}\) signifies the corresponding node features. The sampled nodes in \(_{t}^{}\) are derived from the action \(a_{t}\) and maintain their \(K\)-hop neighborhood \(_{K}(v)\).

\[_{t}^{}=\{_{t}, a _{t}^{(i)}\}_{v_{t}}_{K}(v)\;, \]

where \(_{K}(v)\) represents the set of \(K\)-hop neighboring nodes in the original graph \(_{i}\). Here, the sampling rate is denoted by \(s=_{t}|}\) to control the number of sampled nodes.

**Transition.** After taking action \(a_{t}^{(i)}\), the environment undergoes a transition, and the state changes from \(s_{t}^{(i)}\) to \(s_{t+1}^{(i)}\), governed by the transition probability \(P(s_{t+1}^{(i)}|s_{t}^{(i)},a_{t}^{(i)})\).

**Reward Design.** The environment yields a reward \(R(r_{t}^{(i)})\) to assess the action \(a_{t}^{(i)}\) in the state \(s_{t}^{(i)}\) for client \(C_{t}\). The environment aims to assign a positive reward when the sampled graph does not significantly impact the model's utility while preserving unlearning performance. The reward function is designed as follows,

\[R(s_{t}^{(i)})=_{0}-_{1}+1}&_{1}<_{0}\\ -1&, \]

where \(_{0}\) denotes the client's accuracy on the pre-unlearning model. The \(_{1}\) represents the accuracy post the client's unlearning process. To conduct the unlearning procedure, a gradient ascent is executed on the presently sampled graph \(^{}_{t}\) at time \(t\).

**Federated Policy Gradient Training**. The objective of the agent is to train an optimal policy network capable of maximizing the expected reward. The training of the policy network involves defining the overall loss as follows.

\[()=_{t}_{_{}(a_{t}^{(i)}|s_{t}^{(i)})} [(r_{t}^{(i)}_{}(a_{t}^{(i)} s_{t}^{(i)})]. \]

The optimization of the policy network utilizes Adam optimizer, which is detailed in Appendix A.

### Parameter-free Graph Prompt Knowledge Distillation

Recent research (Wang et al., 2018; Wang et al., 2018) demonstrates the ability of graph prompts to enhance performance on downstream tasks by leveraging the knowledge from pre-trained models and increasing the expressiveness of downstream graph representations. Graph prompts can serve as a medium for distilling knowledge from pre-trained models (Wang et al., 2018). However, existing graph prompt methods are parameter-extensive, which are computationally expensive to improve downstream tasks (Wang et al., 2018). In this module, we introduce the parameter-free graph prompt to distill subgraph knowledge from the target clients.

#### 3.2.1. Graph Prompt Generation.

We first learn a graph prompt generator \(f_{}()\) to derive graph prompts, which comprises three major components: graph prompt token vectorization, graph prompt aggregation, and graph prompts insertion.

**Graph Prompt Token Vectorization.** To derive the graph prompt, we first generate vectorized graph prompt tokens, which can be done via a Multi-Layer Perceptron (MLP),

\[MLP(_{t}^{})=_{_{q}}^{(i)}, \] \[_{_{q}}^{(i)}=(,),\] \[_{ij}=(_{i}_{j})&(_{i}_{j})>\\ 0&otherwise, \]

where \(_{_{q}}^{(i)}\) is the graph prompt for node \(_{q}^{}\), \(=\{_{1},,_{q}\}\) denotes the vectorized tokens. The superscript indicates the index for subgraph \(_{t}^{}\). \(=\{(_{i},_{j})|_{i},_{j} \}\) denotes the pairwise connected relation among the tokens, \(_{ij}\) is the connection relation between token \(_{i}\) and \(_{j}\). \(\) is the sigmoid function and \(\) is the hyperparameter serving as a control threshold.

Figure 3. Framework overview.

**Graph Prompt Aggregation.** To integrate the distilled graph prompts with the sampled graph, we initiate the process by aggregating the graph tokens. Let \(f_{}(_{_{q}^{i}}^{(i)})\) denote a universal aggregation function with parameter \(\). The initial step involves aggregating the graph prompt tokens by taking into account the similarity among tokens,

\[_{i}^{I}=(_{_{j}(_{j})} _{ij}_{i}_{j}^{k-1}), \]

where \(_{i}^{I}\) is the embedding of token \(_{i}\) at the \(l\)-th layer, and \(_{l}\) is the function weights at layer \(l\). The the universal aggregation function parameter \(\) is defined as \(\{_{k}\}_{k=1}^{L}\). \((_{j})\) represents the connected relation set of token \(_{j}\). Finally, mean global pooling is applied to obtain the final embedding,

\[_{i}^{}=_{j=1}^{q}_{j}^{(L)}, \]

where \(_{j}^{(L)}\) is the feature vector of the token \(_{j}\) at final layer \(L\).

**Graph Prompts Insertion.** To incorporate the aggregated graph prompts into the sampled graph \(_{i}^{}\), we firstly generate \(N_{q}\) graph prompts \(\{_{_{j}^{i}}^{(i)}\}_{j=1}^{N_{q}}\). Then, we randomly select \(N_{q}\) nodes from the sampled graph \(_{i}^{}\) for insertion. The embedding \(\{_{j}^{}\}_{i=1}^{N_{q}}\) of aggregated graph prompt tokens are added to the sampled graph \(_{i}^{}\).

\[_{i}^{}=_{i}^{}+_{i}^{ }&_{i}^{}_{x}\\ _{i}^{}&otherwise, \]

where \(_{x}=\{_{1}^{},,_{q}^{}\}\) denote the sampled nodes feature set.

The final sampled graph inserted with graph prompts is termed knowledge enhancer graph \(_{i}^{}=(_{i}^{},_{i}^{}, }_{i}^{})\), where \(}_{i}^{}=\{_{i}^{},,_{q }^{}\}\) is augmented feature set, where \(}_{q}^{}\) is the enhanced target node feature.

#### 3.2.2. Graph Prompt Turning.

The goal of graph prompts turning is that the specific graph knowledge learned from the target client by fine-tuning the task parameters, denoted as \(=\{\{_{_{j}^{i}}^{(i)}\}_{j=1}^{N_{q}},\{\}\}\). The graph prompts turning loss is defined as follows,

\[_{_{i}^{}}=l(F_{i}(;}_{i }^{}),_{i}^{}), \]

where \(l()\) is the cross-entropy node classification loss, \(_{i}^{}\) is the label set for graph \(_{i}^{}\). The model weight of the local model \(F_{i}()\) in the target client is fixed.

### Gradient Descent Unlearning

Based on the knowledge enhancement graph, the target clients are ready for unlearning. To provide guidance for the unlearning process, we employ the average weights of the remaining models as a constraint on the global model. The final unlearning loss is defined as follows,

\[_{u}(())& =_{_{i}}[- |}_{u^{}^{}}[l(_{i}(; }_{i}(u^{})),y_{u^{}})].\\ &+_{u}\|_{i}-^{*} \|^{2}], \]

where \(^{*}=_{i}|}_{i_{i }}_{i}\) is the guided model constraint, and \(_{u}\) is the constrain parameter. \(l()\) is the cross-entropy loss. The final unlearned global model is denoted as \(_{_{i}}()\).

We also employ the Adam optimizer to minimize the unlearning loss. After unlearning, the performance of the updated global model may decrease for other clients. To mitigate this issue, the server conducts a few rounds of federated learning involving the remaining clients (Ganin et al., 2016; He et al., 2016; Chen et al., 2017). Empirical studies demonstrate that, in practice, only a few rounds are sufficient to keep the new global model \(_{}\) up to date. The complete procedure for subgraph federated unlearning is reported in Algorithm 1.

```
Input:Client data \(\{_{i}\}_{i=1}^{M}\), pretrained policy sampler \(_{}()\), global model \(F()\), fine-tuning epoch \(E\) Result:Enhanced compact subgraph \(}_{i}^{}=(_{i}^{},_{i}^{ },}_{i}^{})\)
1 Use pre-trained policy sampler \(_{}()\) to sample the graphs \(\{^{}\}_{i=1}^{N_{q}}\) based on Equation 11.;
2foreachtarget client \(C_{i}\) in paralleldo
3for\(k=1\)to\(E\)do
4 Generate the graph prompts based on Equation 14;
5 Aggregate the tokens embedding based on Equations 17 and 18;
6 Insert the graph tokens based on Equation 19;
7 Compute the prompt enhancement loss by Equation 20;
8 Update \(=\{\{_{_{j}^{(i)}}^{N_{q}}\}_{j=1}^{N_{q}},\{\}\}\) using Adam
9 optimization with the gradients of \(_{}_{i}^{}}\) ;
10 end for
11
12 end for
13
14 Use Adam optimizer to optimize the unlearning loss based on Equation 21;
15 Return unlearned model \((_{})\).
```

**Algorithm 1**Reinforced Graph Knowledge Enhancement

## 4. Experiments

In this section, we empirically evaluate the proposed framework and compare it with the state-of-the-art federated unlearning methods. We report the unlearning performance on the real-world dataset. To be more specific, we aim to answer the following research questions.

**RQ 1**: Does the proposed method effectively eliminate contributions from multiple clients compared to state-of-the-art unlearning methods? **RQ 2**: How effective are the proposed components within the unlearning framework? **RQ 3**: How robust is the proposed method concerning changes in hyperparameter values? **RQ 4**: Does the unlearning process compromise the privacy of the clients?

### Environmental Setup

**Datasets.** The distributed subgraph is constructed by partitioning the datasets into a predetermined number of participants. In subgraph federated learning (FL), each client possesses a subgraph asa subset of the original graph. Specifically, we utilize a set of real-world graph datasets, including Cora (Brock et al., 2018), Pubmed (Zhu et al., 2018), Photo (Zhu et al., 2018), and Cs (Brock et al., 2018). In the default setting, the overlapping nodes are set to 0.2. Various overlapping nodes setting experiments is presented in Appendix B.1.

**Evaluation Metrics.** For evaluating the effectiveness of federated unlearning methods, we use the widely acknowledged metrics (Zhu et al., 2018; Li et al., 2018; Li et al., 2018). (1) Attack Success Rate (ASR): The backdoor trigger is employed to evaluate the efficacy of unlearning methods. ASR quantifies the successful classification of manipulated data into the target label (Zhu et al., 2018). A lower ASR signifies heightened proficiency in unlearning. (2) Model Accuracy (MA): We assess the accuracy of the global model after the unlearning process as the model utility.

**Baselines.** We consider the following federated unlearning methods: _Retraining from Scratch_: This approach involves retraining on an initialized model using the data from the remaining clients. _Projected Gradient Ascent (PGA)_(Li et al., 2018): PGA is an unlearning method designed to maximize the empirical loss on the local clients. _EWCSGA_(Zhu et al., 2018): EWCS-SGA combines elastic weight consolidation and stochastic gradient ascent to enable the removal of client's contribution without the need for full model retraining. _Noisy-GD_(Zhu et al., 2018): Noisy-GD is a robust data-deletion method that ensures differential privacy constraints are met. _ULKD_(Zhu et al., 2018): ULKD is a server storage history method used to eliminate target client sharing and improve the model's utility through distillation. In evaluating sampled-based methods, we utilize random sampling and node degree for graph selection. Stochastic Gradient Ascent (SGA) is then applied to eradicate target client information in the sampled graph, denoted as _SGA-Random_ and _SGA-Degree_. _ReGEnUnlearn-Degree_ is the variant of our proposed method by using the vanilla heuristics degree-based graph sampler.

**Implementations Details.** All code is executed within the PyTorch framework. The experiments are carried out on two servers: a Linux CentOS Server equipped with 4 RTX 3090 GPUs and a Linux Ubuntu Server with 1 A800 GPU. The unlearning scenario considered involves the server conducting federated learning training and subsequently receiving \(N_{t}=4\) target clients' requests to opt out of the federation. In the context of federated subgraph learning, there are \(M=10\) clients. The different numbers of target clients are discussed in Sections 4.4. Due to the page limit, the variations in the number of clients are presented in Appendix B.1. For the graph backdoor trigger, we employ the Erdos-Renyi (ER) model to generate the graph trigger, with a trigger size of five, and use the Gaussian distribution for the trigger features. We consider FedAvg as the default federated algorithm. Additionally, we evaluate the effectiveness of the proposed ReGEnUnlearn under more advanced federated algorithms in Appendix B.2. Each experiment is iterated five times to derive average results.

### RQ 1: Main Results

Table 1 presents comprehensive results for the proposed methods and respected baseline models across two metrics. We can make the following observations: the proposed framework's superior performance in ASR across four datasets when compared to all baseline models. In particular, ReGEnUnlearn achieves nearly 100% elimination of multi-client contributions on datasets Cora, Pubmed, and Cs. Furthermore, our proposed framework demonstrates superiority model utility when compared to retraining methods across all four datasets. In specific, ReGEnUnlearn achieves performance levels of 100.66%, 100.69%, 103.47%, and 102.42%, which are directly comparable to retraining methods. We further report the running time of federated unlearning methods in Figure 4 and 5. Specifically, our proposed framework achieves 3.66x, 4.7x, 16.07x, and 9.08x speedup when compared to retraining methods on four datasets.

### RQ 2: Ablation Study

To evaluate the effectiveness of each module within ReGEnUnlearn, we executed an ablation study across four datasets, employing two metrics. Specifically, we investigated the following variants: (1) _ReGEnUnlearn-WoPolicy_ excludes the policy sampler module using the random sampler to replace it: (2) _ReGEnUnlearn-WoPrompt_ excludes the graph prompt empowerment module.

As delineated in Table 2, the following observations across four datasets. Each of the two modules significantly contributes to the overall performance. Notably, the removal of any single module results in performance degradation. Furthermore, our investigation reveals a performance decline when substituting the policy sampler with the vanilla heuristics sampler method, underscoring the tangible benefits of employing a learnable sampling strategy to navigate the graph. Additionally, a performance improvement

Figure 4. Running time on Cora and Pubmed.

Figure 5. Running time on datasets Photo and Cs.

is observed when omitting the graph prompts modules, providing empirical validation for the efficacy of unlearning the contributions of target clients. Overall, the above results verify the effectiveness of the proposed ReGEnUnlearn framework.

### RQ 3 Parameter Analysis

Next, we investigate the parameter sensitivity of our proposed approach. We present findings related to the number of target clients \(N_{I}\), the sampling rate s, and the number of graph tokens \(q\) on the Cora dataset across three metrics. Similar trends are observed across the other three datasets.

First, we vary the value of \(N_{I}\) from 1 to 5, as depicted in Figure 6(a). The observations are summarized as follows. The proposed ReGEnUnlearn framework successfully eliminates all client contributions across the range of target clients. Additionally, an increase in \(K\) initially leads to a rise in subtle MA.

Finally, we vary the number of graph tokens \(q\) within the range of 10 to 50, as depicted in Figure 7(a). Our observations yield the following synthesis: with an increase in \(q\), the ASR exhibits an initial ascent followed by a subsequent descent. Simultaneously, MA maintains a relatively stable profile devoid of pronounced variations.

Overall, adjusting the above hyperparameters induces performance variations within a reasonable range across three metrics, thereby demonstrating the robustness of our approach.

### RQ 4: Privacy Analysis

**Privacy Protection.** In the phase of federated unlearning, the direct uploading of the GCN model by target clients poses potential privacy concerns. The gradients in the model update may inadvertently expose private information to the target clients, as the GCN model gradients inherently encode graph information preferences. To protect the privacy of the target clients, Differential Privacy (DP) can be employed during the unlearning stage.

\[_{i}+(0,^{2}) \]

    &  &  \\  Methods & Attack Success Rate & Model Accuracy & Attack Success Rate & Model Accuracy & 788 \\  Retrain & 0 & 0.8720 (0.0244) & **0** & 0.8548 (0.0032) & 789 \\ PGA & 0.2 (0.4472) & 0.8594 (0.0532) & 0.2 (0.4) & 0.6621 (0.0203) & 789 \\ SGA-Random & 0.2 (0.4472) & 0.8628 (0.0277) & 0.4 (0.5477) & 0.746 (0.0416) & 761 \\ SGA-Degree & 0.2 (0.4472) & 0.8696 (0.0382) & 0.4343 (0.5211) & 0.7429 (0.0353) & 762 \\ EWC-SGA & 0 & 0.7174 (0.0505) & 0 2 (0.4) & 0.7694 (0.0260) & 763 \\ Noisy-GD & 0.9993 (0.0014) & 0.7430 (0.0578) & 0.9999 (0.0001) & 0.8383 (0.0236) & 764 \\ ULKD & 0 & 0.4029 (0.1808) & 0.3998 (0.4897) & 0.7178 (0.2179) & 765 \\
**ReGEnUnlearn-Degree (Ours)** & 0 & 0.8763 (0.0227) & 0.0159 (0.0283) & **0.8639 (0.0169)** & 766 \\
**ReGEnUnlearn (Ours)** & **0** & **0.8778 (0.0202)** & 0.0027 (0.0048) & 0.8607 (0.014) & 760 \\   &  &  \\  Methods & Attack Success Rate & Model Accuracy & Attack Success Rate & Model Accuracy & 788 \\  Retrain & **0** & 0.7 (0.0751) & 0 & 0.8437 (0.0128) & 789 \\ PGA & 0 & 0.5008 (0.0537) & 0.2 (0.4472) & 0.8379 (0.0680) & 770 \\ SGA-Random & 0.3285 (0.3505) & 0.6287 (0.0600) & 0.2 (0.4472) & 0.8415 (0.0371) & 771 \\ SGA-Degree & 0.2364 (0.1388) & 0.6327 (0.2364) & 0.2 (0.4472) & 0.8494 (0.0191) & 772 \\ EWC-SGA & 0.6914 (0.3908) & 0.7128 (0.0287) & 0.4007 (0.5471) & 0.8505 (0.0287) & 773 \\ Noisy-GD & 1 & 0.6991 (0.0300) & 0.1995 (0.3985) & 0.8650 (0.0045) & 774 \\ ULKD & 0.2 (0.4) & 0.4994 (0.0420) & 0 & 0.3569 (0.1294) & 778 \\
**ReGEnUnlearn-Degree (Ours)** & 0.2629 (0.31) & 0.7229 (0.0431) & 0 & **0.8730 (0.0068)** & 778 \\
**ReGEnUnlearn (Ours)** & 0.1703 (0.1202) & **0.7243 (0.0725)** & **0** & 0.8642 (0.0137) & 777 \\   

Table 1. Overall Performance of Federated Unlearning

Figure 6. (a) Effect of the number of target clients. (b) Effect of the number of target clients.

Figure 7. (a) Effect of the number of tokens. (b) Effect of the number of \(\).

## 5. Related Work

### Subgraph Federated Learning

Recently, researchers have made substantial progress in federated subgraph learning (Wang et al., 2019; Wang et al., 2019; Wang et al., 2019). Various FL frameworks have been designed for graph learning tasks, encompassing recommendation (Wang et al., 2019), graph classification (Wang et al., 2019), and node classification (Wang et al., 2019), among others (Wang et al., 2019; Wang et al., 2019). For instance, Wu _et al._(Wu et al., 2019) introduced a federated framework for privacy-preserving Graph Neural Network (GNN)-based recommendation systems. This framework enables collective training of GNN models from decentralized user data. He _et al._(He et al., 2016) proposed FedGNN, a unified framework applicable to graphs from diverse domains. In federated subgraph learning, a key challenge involves addressing missing link problems. Zhang _et al._(Zhang et al., 2019) introduced FedSegAge+, a subgraph federated unlearning framework that trains neighborhood generators along with FedSage to handle missing links across local subgraphs. Baek _et al._(Baek et al., 2019) presented FedPub, a federated subgraph framework utilizing functional embeddings to construct client relations based on similarity. Another challenge lies in defending against poisoning attacks. Recent studies indicate that federated subgraph systems are vulnerable to backdoor attacks, making them susceptible to graph triggers. For example, Liu _et al._(Liu et al., 2019) formally proposed a federated graph backdoor framework capable of attacking federated graph systems. However, there is a notable absence of attention to privacy issues within the context of machine unlearning. To address this gap, to the best of our knowledge, we are the first to explore subgraph federated unlearning. We introduce ReGEnUnlearn framework for efficient and comprehensive unlearning of multiple target clients.

### Federated Unlearning

Recently, federated unlearning (Wang et al., 2019; Wang et al., 2019; Wang et al., 2019; Wang et al., 2019; Wang et al., 2019) has garnered significant research attention. Two scenarios exist in federated unlearning: sample-level federated unlearning (Wang et al., 2019; Wang et al., 2019; Wang et al., 2019; Wang et al., 2019) and client-level federated unlearning (Wang et al., 2019; Wang et al., 2019; Wang et al., 2019; Wang et al., 2019). Sample-level unlearning is a natural extension of the centralized setup. In such settings, FL systems are tasked with requesting the forgetting of a particular category or subset. For example, Wang _et al._(Wang et al., 2019) proposed a federated unlearning framework capable of scrubbing specific categories. Liu _et al._(Liu et al., 2019) proposed a rapid training approach to completely erase data samples from a trained FL model. In client-level federated unlearning, the FL system is tasked with requesting the forgetting of the client's entire contribution in a cross-silo scenario. For instance, Wu _et al._(Wu et al., 2019) propose that the server stores historical local client information. When clients out of the federation, the server eliminates their contributions and uses knowledge distillation to maintain model utility. Halimi _et al._(Halimi et al., 2019) proposed a gradient descent method to unlearn the client's entire contribution. Subgraph federated unlearning primarily occurs in cross-silo scenarios where multiple institutes (e.g., banks and hospitals, _et al._) hold a subgraph and train FL models under strict privacy regulations. Therefore, our primary focus is on considering how to eliminate the entire contributions of multiple clients.

## 6. Conclusions

In this paper, we presented ReGEnUnlearn, a subgraph federated unlearning framework for efficient and comprehensive unlearning of multiple target clients. By sampling the graphs and distilling graph knowledge, the proposed framework improves both model utility and unlearning performance. Specifically, we introduce the _Reinforced Federated Policy Sampler_ (RFPS) to learn optimal sampling strategies that minimize the interference among cross-client subgraphs. By interacting with the federated graph sampling environment, the agent learns to selectively forget an optimal subgraph of target clients, thus preserving the global model utility. Moreover, we propose the _Parameter-free Graph Prompt Knowledge Distillation_ (PGPKD) module, which retains the unique graph knowledge contributed by the target clients, thereby facilitating comprehensive unlearning via a tailored gradient ascent objective. We conduct extensive experiments under diverse federated settings to demonstrate the superiority of the proposed framework over state-of-the-art federated unlearning approaches. It is also worth mentioning that the framework is federated algorithm-agnostic, which means it can be easily adopted in other subgraph federated scenarios. In the future, we plan to apply ReGEnUnlearn other tasks such as federated graph classification and link prediction tasks.

    &  &  \\  Methods & Attack Success Rate & Model Accuracy & Attack Success Rate & Model Accuracy \\  ReGEnUnlearn-WoPolicy & 0 & 0.8744 (0.0264) & 0.1293 (0.2574) & 0.7882 (0.0321) \\ ReGEnUnlearn-WoPrompt & 0.6 (0.5477) & 0.8633 (0.0188) & 0.3890 (0.5273) & 0.8264 (0.03324) \\
**ReGEnUnlearn (Ours)** & **0** & **0.8778 (0.0202)** & **0.0027 (0.0048)** & **0.8607 (0.014)** \\   &  \\  Methods & Attack Success Rate & Model Accuracy & Attack Success Rate & Model Accuracy \\  ReGEnUnlearn-WoPolicy & 0.282 (0.3123) & 0.7002 (0.0528) & 0.2 (0.4) & 0.8605 (0.01467) \\ ReGEnUnlearn-WoPrompt & 0.3918 (0.4803) & 0.6212 (0.0960) & 0 & 0.8617 (0.0099) \\
**ReGEnUnlearn (Ours)** & **0.1703 (0.1202)** & **0.7243 (0.0725)** & **0** & **0.8642 (0.0137)** \\   

Table 2. Ablation Study of Federated Unlearning