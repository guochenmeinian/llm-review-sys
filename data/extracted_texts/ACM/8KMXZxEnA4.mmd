# Malicious Package Detection using Metadata Information

Anonymous Author(s)

###### Abstract.

Protecting software supply chains from malicious packages is paramount in the evolving landscape of software development. Attacks on the software supply chain involve attackers injecting harmful software into commonly used packages or libraries in a software repository. For instance, JavaScript uses Node Package Manager (NPM), and Python uses Python Package Index (PyPi) as their respective package repositories. In the past, NPM has had vulnerabilities such as the event-stream incident, where a malicious package was introduced into a popular NPM package, potentially impacting a wide range of projects. As the integration of third-party packages becomes increasingly ubiquitous in modern software development, accelerating the creation and deployment of applications, the need for a robust detection mechanism has become critical. On the other hand, due to the sheer volume of new packages being released daily, the task of identifying malicious packages presents a significant challenge. To address this issue, in this paper, we introduce a metadata-based malicious package detection model, _MeMPec_. This model extracts a set of features from package metadata information. These extracted features are classified as either easy-to-manipulate (ETM) or difficult-to-manipulate (DTM) features based on monotonicity and restricted control properties. By utilising these metadata features, not only do we improve the effectiveness of detecting malicious packages, but also we demonstrate its resistance to adversarial attacks in comparison with existing state-of-the-art. Our experiments indicate a significant reduction in both false positives (up to 97.56%) and false negatives (up to 91.86%).

NPM Metadata, Malicious Detection, Feature Extractions, Adversarial Attacks, Software Supply Chain +
Footnote †: isbn: 978-1-4503-XXXX-X/18/06

+
Footnote †: isbn: 978-1-4503-XXXX-X/18/06

+
Footnote †: isbn: 978-1-4503-XXXX-X/18/06

+
Footnote †: isbn: 978-1-4503-XXXX-X/18/06

+
Footnote †: isbn: 978-1-4503-XXXX-X/18/06

+
Footnote †: isbn: 978-1-4503-XXXX-X/18/06

+
Footnote †: isbn: 978-1-4503-XXXX-X/18/06

+
Footnote †: isbn: 978-1-4503-XXXX-X/18/06

+
Footnote †: isbn: 978-1-4503-XXXX-X/18/06

## 1. Introduction

Nowadays, Free and Open-Source Software (FOSS) has become part and parcel of the software supply chain. For example, the Open Source Security and Risk Analysis (OSSR) report in 2020 shows that as much as 97% of codeases contain open-source code (Shen et al., 2020) and the proportion of enterprise codeases that are open-source increased from 85% (Shen et al., 2020) to 97% (Shen et al., 2020). Thus, modern software developers thrive through the opportunistic reuse of software components that save enormous amounts of time and money. The node package manager (NPM) offers a vast collection of free and reusable code packages to support JavaScript developers. Since its inception in 2010, NPM has grown steadily and offers over 3.3 million packages as of September 2023 (Han et al., 2020). The extensive library of packages provided by NPM is a valuable resource for developers worldwide and is expected to continue growing. Different from JavaScript, Python uses Python Package Index (PyPi) as their package repositories. Both NPM and PyPi have faced security vulnerabilities in the past, such as the event-stream incident, where a malicious package was introduced into a popular NPM package, potentially impacting a wide range of projects. Similarly, PyPi has experienced concerns with typo-squatted packages that appear similar to common libraries but contain malicious code, posing a risk of inadvertent installation by developers. Therefore, detecting malicious packages is essential to protect software supply chains.

Metadata associated with package repositories plays a crucial role in the software development lifecycle. Such metadata includes information about the creator, update history, frequency of updates, and authorship, among other details. This information can be indicative of maliciousness within packages, for example, a package that has unknown authors is likely to be malicious (Bahdanau et al., 2015). However, such heuristics are not sufficient as attackers can intentionally compromise metadata information to bypass detection models. Thus, extracting a set of features that are both predictive yet resistant to adversaries seeking to game the model is critical. There are several advantages of using metadata feature selection to detect malicious packages. First, it can help identify malicious packages quickly without requiring extensive manual review. Second, it is efficient because it can detect malicious packages faster than thorough code analysis. Third, metadata analysis can be used to gain insights into behavioural patterns of malicious packages in large datasets. Lastly, the incorporation of metadata features increases model resilience against adversarial attacks, offering a more robust defense mechanism compared to existing state-of-the-art methods.

There are some existing research works that utilise metadata information. For example, by using metadata information, Zahan et al. (Zahan et al., 2015) introduced a model for measuring NPM supply chain weak link signals to prevent future supply chain attacks. However, they do not consider the challenge of adversarial attacks. The main motivation of this research is to propose a model to detect malicious packages in the NPM repository to protect software developers, organizations, and end-users from security breaches that can result from downloading and using packages containing malicious code.

As the NPM repository is widely used to store and distribute open-source packages, it is an attractive target for attackers looking to compromise the security of a large number of systems. By detecting malicious packages in the repository, organizations can ensure that their software development processes are not disrupted and that security threats do not compromise their systems. Detecting malicious packages also helps maintain the trust and integrity of open-source package repositories, which are essential for the long-term success and growth of the software development community.

In this paper, we address the following research questions.

* **RQ1:** How can metadata information be effectively leveraged to accurately identify malicious packages within repositories?
* **RQ2:** How can the robustness of metadata-based detection models be enhanced against adversarial attacks?

To address these research questions, a metadata based malicious package detection model is developed. The main contributions of our research work are as follows:

* We propose an advanced metadata based malicious package detection (_MeMPtee_) model leveraging new metadata features and machine learning algorithm.
* We introduce a new metadata feature extraction technique which partitions features into easy-to-manipulate and difficult-to-manipulate.
* We investigate stakeholder based adversarial attacks and propose adversarial attack resistant features based on monotonicity and restricted control properties.
* We conduct extensive experiments1 that show our proposed _MeMPtee_ outperforms the existing feature selection strategies from the state-of-the-art in terms of precision, recall, F1-score, accuracy and RMSE. It reduces false positives on average by 93.44% and 97.5% in balanced data and imbalanced data, respectively, and reduces false negatives on average by 91.86% and 80.42% in balanced and imbalanced data, respectively.

## 2. Existing Works

In this research work, we have focused on attack detection utilising metadata in NPM ecosystems. Works on attack detection and remediation include the followings. Liu et al. (Liu et al., 2019) introduced a knowledge graph-driven approach for dependency resolution that constructs a comprehensive dependency-vulnerability knowledge graph and improved vulnerability remediation method for NPM packages. Zhou et al. (Zhou et al., 2019) enriched the representation of Syslog by incorporating contextual information from log events and their associated metadata to detect anomalies behaviour in log files. Zaccarelli et al. (Zhou et al., 2019) employed machine learning techniques to identify amplitude anomalies within any seismic waveform segment metadata, whereas the segment's content (such as distinguishing between earthquakes and noise) was not considered. Anomaly detection on signal detection metadata by utilising long and short-term memory recurrent neural networks in the generative adversarial network has been introduced in (Brockman et al., 2018). Mutmback et al. (Mumback et al., 2019) developed a heterogeneous traffic classifier to classify anomalies and normal behaviour in network metadata. Pfretzschner et al. (Pfretzschner et al., 2019) introduced a heuristic-based and static analysis to detect whether a Node.js is malicious or not. Garrett et al. (Garrett et al., 2019) proposed an anomaly detection model to identify suspicious updates based on security-relevant features in the context of Node.js/NPM ecosystem. Taylor et al. (Taylor et al., 2019) developed a tool named _TypoGard_ that identifies and reports potential typosquatting packages based on lexical similarities between names and their popularities.

Some efforts have been devoted in the literature to detect malicious attacks using metadata features. For example, Abdellatif et al. (Abellatif et al., 2018) utilised metadata information for the packages' rank calculation simplification. Zimmermann et al. (Zimmermann et al., 2019) have demonstrated a connection between the number of package maintainers and the potential for introducing malicious code. Scalco et al. (Scalco et al., 2019) conducted a study to assess the effectiveness and efficiency of identifying injected code within malicious NPM artifacts. Seifja et al. (Seifja et al., 2019) presented automated malicious package finder for detecting malicious packages on NPM repository by leveraging package reproducibility checks from the source. Vu et al. (Vu et al., 2019) applied metadata to identify packages' reliability and actual sources. Ohm et al. (Ohm et al., 2019) investigated limited metadata information (e.g., package information, dependencies and scripts) to detect malicious software packages using supervised machine learning classifiers. However, these approaches do not address the issue of adversarial attacks, and as demonstrated by our experiments (_c.f._ Section 6.3), the features proposed in the literature are prone to adversarial manipulation.

Other works related to software security, but not metadata based include (Zahn et al., 2019; Zhang et al., 2019; Zhang et al., 2019; Zhang et al., 2019). Zahon et al. (Zahon et al., 2019) compared the security practices of NPM and PyPI ecosystems on GitHub using Scorecard tools that identifies 13 compatible security metrics and 9 metrics for package security. Sun et al. (Sun et al., 2019) introduced _CoProtect_, a tool designed to safeguard open-source GitHub repositories from unauthorized use during training. Wi et al. (Zahn et al., 2019) proposed a scalable system that detects web vulnerabilities, such as bugs resulting from improper sanitization, by employing optimization techniques to tackle the subgraph isomorphism problem. Zhang et al. (Zhang et al., 2019) developed _GERAI_, which uses a differential private graph convolutional network to protect users' sensitive data from attribute inference attacks. Zhu et al. (Zhu et al., 2019) built a system that uses various information types to detect spam reviews.

### Differences with Previous Works

Our proposed malicious detection based on metadata information differs from state-of-the-art malicious detection techniques in various aspects. Firstly, we categorise the different sets of features that can be derived from metadata information, whereas existing methods considering metadata information do not make a distinction between the types of metadata features that can be extracted. Secondly, we consider the problem of adversarial attacks and introduce the concept of difficult-to-manipulate (_DTM_) features that reduce the risk of adversarial attacks. Table 1 highlights some key differences between features derived from our approach versus those proposed in the literature. In the foregoing, we use the term _Existing_,_,_,_,_,_,_ metadata features to refer collectively to the sets of features proposed in the literature for malicious package detection.

## 3. Preliminaries and Problem Statement

In this section, we present the preliminary notations and definitions.

Let \(P=\{p_{1},,p_{n}\}\) be set of packages. A package often involves several participants, namely _author_, _maintainer_, _contributor_, _publisher_. We refer to these collectively as stakeholders denoted by \(S_{i}=\{s_{j}\}_{i}\) such that \(s_{ji}\) is a stakeholder of type \(j\) involved in package \(p_{i}\).

Definition 1 (Package Metadata Information (PMI)).: _Given a package \(p_{i} P\), the package metadata information denoted \(T_{i}=\{ k,v\}\) is the set of key-value pairs of all metadata information associated with \(p_{i}\)._

In this work, without loss of generality, we adopt the NPM package repository as an exemplar due to its popularity in web applications and various cross platforms (Krishnamurthy et al., 2017). Table 2 shows our considered NPM package metadata information.

Definition 2 (Problem Definition).: _Given a package \(p_{i} P\) and its package metadata information \(T_{i}=\{ k,v\}\), the goal is to develop a malicious package detector \(\) as follows:_

\[(p_{i},T_{i})=1,&p_{i},\\ 0,&\]

There are three key challenges to address in the problem definition above. Firstly, the PMI of each package may contain several pieces of information, some of which may be irrelevant to the detection task, and it may also have inconsistent representation across different packages (**Challenge 1**). For example, packages may contain copyright and browser dependencies that are often not relevant for detecting malicious packages. Secondly, metadata information may be prone to manipulation by an adversary who wishes to evade detection by a detection model \(\) (**Challenge 2**). Thirdly, for any detection model \(\) to be practical, it needs to achieve high true positive rates with low false positive rates (**Challenge 3**).

To address the above challenges, we propose a novel solution called _Metadata based Malicious Package Detection_ (McMptec). _McMptec_ relies on a feature engineering approach to address the aforementioned challenges. This is detailed in the following sections.

## 4. Categorisation of Package Metadata Information

Each piece of information contained in PMI represents a different type of information. In this section, we categorise each PMI in order to understand its relevance for malicious package detection. This is important because not all information in metadata packages is crucial for malicious package detection (**Challenge 1**). We consider the following categories.

* **Descriptive Information**: This includes information that describes the resource, such as package title, versions, description, readme, scripts and distribution tag.
* **Stakeholder Information**: It provides information about the individuals or organizations involved in developing, maintaining and distributing a package. Some stakeholder information includes authors, contributors, maintainers, publishers and licenses.
* **Dependency Information**: Dependency information provides details about the external packages or modules that a particular package depends on. These include dependencies and development dependencies.
* **Provenance Information**: It provides information about when various events related to the package occurred. This information can be useful for tracking the package's history and understanding how it has evolved over time. For example, package created, modified and published time information.
* **Repository Information**: It provides information about the location of the source code repository for a package, such as the NPM link, homepage link and GitHub link.
* **Context Information**: Context information provides additional information based on their functionality and purpose. For example, keywords, tags and topics.

Table 3 presents the categories of package metadata information.

## 5. Feature Extraction and Selection

It is necessary to extract features from the PMI for each package to generate a consistent set of features for all packages. For example, let \( package\_name,generator@1\) be a toy example of a key-value pair in the PMI \(\). The package name is _generator@1_, but we can derive features from this package name, such as whether or not it contains a special character or the length of the package name. These features are of particular relevance in the context of detecting malicious packages since package names play a crucial role in identifying combosquatting and typosquatting (Krishnamurthy et al., 2017). Thus,

   package\_name, version, description, readme, scripts, distribution tag, authors, contributors, maintainers, publishers, licenses, dependencies, development\_dependencies, created\_time, modified\_time, published\_time, NPM\_link, homepage\_link, GitHub\_link, bugs\_link, issues\_link, keywords, tags and topics. \\   

Table 2. Package Metadata Information.

feature extraction in our context is a one-to-many mapping between PMI and a set of features that is formally defined as follows:

Definition 3 (Feature Extractor \(\)).: _Given a package \(p_{i}\) and its associated PMI containing \(\) key-value pairs, \(I_{i}=\{(k,v_{1}) k,v_{}\}\), a feature extractor denoted \(\) is a multivalued function which maps each PMI \((k,v)_{j}\) into one or more features in the set \(X\):_

\[:I_{i} X.\]

As noted earlier, one of the challenges to be addressed while developing malicious package detector \(\) is its ability to resist adversarial attacks (**Challenge 2**). We define an adversary as follows:

Definition 4 (Adversary).: _An adversary \(\) is any stakeholder in \(S_{i}\) of package \(p_{i}\), who has the authority to modify the metadata information \(I_{i}\) of package \(p_{i}\), and attempt to do so to evade detection by a model._

The definition above represents the scenario where a stakeholder of a malicious package may alter the metadata information to evade detection by a model. We make the following assumption and then present two important properties relevant to the feature \(x X\).

Assumption 1.: _Given a repository environment such as the NPM package repository, we assume that all security protocols are intact, and users follow the protocols to engage with the repository environment i.e. there is no suversion of the system by an adversary._

This assumption is pivotal to our approach and indeed to any metadata-based malicious package detection technique, including (Bahdanau et al., 2015; Chen et al., 2016; Chen et al., 2016). If this assumption does not hold, then it renders metadata information useless for any purpose. At the same time, it is a reasonable assumption because, although possible, the subversion of a repository has not been observed as the preferred approach for propagating malicious packages.

We now define the _monotonicity_ and _restricted control_ properties.

Property 1 (Monotonicity).: _A feature \(x X\) is said to be monotonic if and only if \(x\) is a numerical feature, and any update on its value, \(x\).value, can only occur in one direction._

For example, if _package_age_ is a feature (measured in years) and this value can only be increased, we say that _package_age_ possesses monotonicity property. On the other hand, package _description_length_ as a feature can be increased or decreased by the author of the package and is thus non-monotonic. The monotonicity property is hereinafter referred to as _Property 1_.

Property 2 (Restricted Control).: _A feature \(x X\) is said to possess the property of restricted control if and only if a stakeholder in \(S_{i}\) associated with package \(p_{i}\) cannot change its value, \(x\).value._

For example, if _number_of_stars_ is a feature (measured in count). This feature is calculated based on the interactions that other developers and code users interact with a given package. As such _number_of_stars_ cannot directly be modified by a package author. Thus, we say that _number_of_stars_ possesses the property of restricted control. A counter-example is _number_of_versions_, which a package author can directly influence by generating several versions. In this case, we say that _number_of_versions possesses the monotonicity property but lacks the property of restricted control. The restricted control property is hereinafter referred to as _Property 2_.

We define a feature \(x X\), specially denoted by \(\), as a **difficult-to-manipulate** (DTM) feature if any one of the following cases holds:

1. If \(x\) satisfies the monotonicity property _i.e._\(x(Property~{}1)\), then \(x\);
2. If \(x\) satisfies the restricted control property _i.e._\(x(Property~{}2)\), then \(x\);

Otherwise, \(x\) is considered an **easy-to-manipulate** (ETM) feature. It is important to note that \(X\) comprises both easy-to-manipulate (ETM) and difficult-to-manipulate (DTM) features denoted by \(x\) and \(\) respectively _i.e._\(X x,\).

### Easy-to-Manipulate Features

As noted earlier, an easy-to-manipulate feature denoted by \(x\) is a feature that does not possess either Property 1 or Property 2 and thus can easily be changed by the author of a package. Although ETM features are inherently good at helping to predict malicious packages (_c.f._ Section 6.2), by being able to manipulate these features, an adversary can _trick_ detection models to classify malicious packages as benign. In our metadata feature extraction \(\), we identify the following types of features as not satisfying either Property 1 or Property 2 and thus considered as ETM.

* **Exist**: This type of feature refers to whether or not certain Information is present in package metadata. This takes on a binary indicator whose value is _TRUE_ or _FALSE_ depending on whether or not the specified Information is present.
* **Special Character**: A special character is any character that is not a letter, digit, or whitespace. The use of special characters in package names is known to be indicative of typo-squatting (Shen et al., 2016; Wang et al., 2016).
* **Length**: The length of an item is the number of characters it contains, can serve as a useful indicator of malicious packages, especially when they lack detailed descriptions.

Our experiments show that, although these types of features are simple and easy-to-manipulate by the adversary, they are often useful predictors of maliciousness. For example, if the metadata of a package does not contain author information or source code address, that package is likely to be malicious. However, models

 p{341.4pt}}  Category & Information Name \\  Descriptive & Package name, Versions, Description, Readme and Scripts \\  Stakeholder & Authors, Contributors, Maintainers, Collaborators and Publishers \\  Dependency & Package Dependencies and Development Dependencies. \\  Provenance & Package Created, Modified and Published time. \\  Repository & NPM Link, Homepage Link, GitHub Link, Bugs Link and Issues Link. \\  Context & Keywords, Distribution Tag and Licenses. \\  

Table 3. Package metadata information and their corresponding categories.

built solely on these features are vulnerable to adversarial attacks. Incorporating DTM features can mitigate the risk.

### Difficult-to-Manipulate Features

These are features which satisfy Property 1 or 2. They often depend on time or package interaction, which are difficult to manipulate. The types of features in this category are as follows:

* **Temporal**: Features that involve temporal information often satisfy Property 1 and as such are DTM. In this work, our feature extractor \(\) generates _package_age_age_, _package_modified_duration_ and _package_published_duration_ which represent the age of the package, the time interval between package creation and last modification date, and the time interval between when the package was created and when it was published respectively. Other features include stakeholder \(s_{j_{1}}\) service time (\(s_{j_{1}}\_\)_service_time) which reflects the number of days which a stakeholder has been associated with the package \(p_{i}\).
* **Package Interaction**: This relates to the number of interactions that a package \(p_{i}\) or its stakeholder \(s_{j_{1}}\) has. It includes (1) number of other packages which \(s_{j_{1}}\) has contributed to denoted \(s_{j_{1}}\_\)_CPN_; (2) number of package pull requests _pull_request_; (3) number of reported package issues; (4) number of times package is forked; and (5) number of stars a package has received. (1) satisfies Property 1 while (2), (3), (4) and (5) satisfy Property 2.

Table 4 provides the list of the ETM and DTM features used in this work. It is worth noting that the DTM features in the table also include a combination of base DTM features _e.g._ stakeholders' community contribution score (\(s_{j_{1}}\_\)_CCS_) is a combination of stakeholder contribute package number \(s_{j_{1}}\_\)_CPN_ and stakeholder service time \(s_{j_{1}}\_\)_Service_time._ Appendix A.1 provides details for \(s_{j_{1}}\_\)_CCS_ DTM features derived from base DTM features.

### Proposed _MeMPtec_ Model

Figure 1 shows the pipeline for our proposed \(}\) based \(}\) Package \(}\) (_MeMPtec_) model. The figure shows the phases of model building _i.e._ training phase and prediction phase. In the training phase, PMI is fed into the feature extraction stage and assigned a label as either benign or malicious. The metadata is extracted using our feature extractor \(\) into both easy-to-manipulate (ETM) (_c.f. Section 5.1_) and difficult-to-manipulate (DTM) (_c.f. Section 5.2_) features. We then adopt existing machine and deep learning models to train a model. In the prediction phase, we follow a similar process of feature extraction, feeding these extracted features into the built model to make predictions regarding the maliciousness of packages.

Algorithm 1 gives the details of the steps in _MeMPtec_. It takes PMI \(\{I_{1},,I_{n}\}\), ML_Algo, \(\{I_{new}\}\) as input and provides malicious package detector \(\) as output. The algorithm has two parts: Model Training Phase and Prediction Phase. In the Training Phase, we extract labels \(\), ETM and DTM features (_c.f._ Section 5.1 and 5.2) in lines 3-5, respectively. Then, we combine two sets of features and create \(\) in line 6. The \(\) and \(\) are partitioned into train data (70%), validation data (10%) and test data (20%) in line 7. After that, the model is built based on the existing machine learning algorithm and train and validation data in line 8. The build-in model \(\) performance has been measured using test data in lines 9-10. Therefore, the model training phase returns malicious package detector model \(\) and performance in line 11.

In the prediction phase, we similarly extract the relevant features and apply the built model \(\) to each set of features \(X_{new}\) associated with a package's PMI \(_{new}\) (lines 13-16). The function returns predicted label in line 17. Finally, in lines 18 and 19, these two phases are called to as model training and prediction.

## 6. Experiments

### Experimental Setup

It is worth recalling that the crux of this work is in its feature engineering approach; thus we compare our approach with existing features proposed by closely related work such as (Chen et al., 2017; Wang et al., 2018; Wang et al., 2018; Wang et al., 2018; Wang et al., 2018). All experiments were implemented in Python and conducted in Windows 10 environment, on an Intel Core i7 processor (1.70 GHz, 16GB RAM).

#### 6.1.1. Datasets and Baseline Methods

In this work, we use NPM repository 2 as an exemplar to generate package metadata information. We make the assumption that packages that are currently not flagged as malicious in NPM repository are considered benign. In NPM repository, packages flagged as malicious are often removed. Thus, to obtain malicious NPM packages, we use publicly available data on GitHub 3(Wang et al., 2018). We then generate a balanced

   ETM Features & DTM Features \\ name \_exist, name \_length, dist-tags \_exist, dist-tags \_length, versions \_exist, versions \_length, versions \_num_count, maintainers \_exist, description \_exist, description \_length, readme \_exist, readme \_length, scripts \_exist, scripts \_length, author\_exist, author\_name, author\_email, License\_exist, License\_length, directories \_exist, directories \_length, keywords \_length, keywords \_num_count, homepage \_exist, homepage \_length, github\_exist, github \_length, bugslink\_exist, bugslink\_length, issueslink\_exist, issue\_length, dependencies\_exist, dependencies\_length, devDependencies\_exist, devDependencies\_exist, \(}\) means community contribution score and CPN means contribute package number. \\   

* CCS means community contribution score and CPN means contribute package number.

Table 4. List of easy-to-manipulate (ETM) and difficult-to-manipulate (DTM) Featuresdataset with a proportion of 50% malicious packages, and an imbalanced datasets with only 10% malicious packages. Variants of these datasets are generated for experimental purposes (Table 5). In the table, _Existing_tec_ refers to feature model generated using features proposed in the literature (Bishop, 2006; Lee et al., 2015; Lee et al., 2015; Lee et al., 2015; Lee et al., 2015); _MeMPtec_E_ and _MeMPtec_D_ refer to feature model with ETM and DTM features respectively; while _MeMPtec_ refers to the combination of ETM and DTM features based feature model.

#### 6.1.2. Machine Learning/Deep Learning Techniques

In building the detection models, we adopted five different but commonly used model building techniques namely, _Support Vector Machine_(Krizhevsky et al., 2009); _Gradient Boosting Machine (GBM)_(Bishop, 2006); _Generalized Linear Model (GLM)_(Krizhevsky et al., 2009); _Distributed Random Forest (DRF)_(Bishop, 2006); and _Deep Learning - ANN (DL)_(Bishop, 2006; Lee et al., 2015).

In all experiments, we adopt a 70:10:20 split for training, validation and testing, respectively, and conduct five-fold cross-validation.

#### 6.1.3. Evaluation Metrics

In this work, we adopt the well-known metrics of _precision_, _recall_, _F1-score_, _accuracy_ and _root mean squared error_ (RMSE) also used in (Bishop, 2006; Lee et al., 2015). We also evaluate model performances based on the number of _false positives_ (FP) and _false negatives_ (FN) like in (Krizhevsky et al., 2009; Lee et al., 2015).

### Performance Evaluation of _MeMPtec_ (Rq1)

Table 6 shows the performance analysis of our proposed approach. From the table, we notice that _MeMPtec_ (_resp._ balance and imbalance data) consistently achieves the best results across all metrics and ML/DL algorithms. It is important to note that _RMSE_ indicates the confidence of a model in its prediction as it measures the error between the probability of the prediction and the true label. Notice that _MeMPtec_ (_resp._ for both data) consistently has significantly lower errors, indicating that combining ETM and DTM leads to more robust model.

Although one may question the significance of the improvement, it is important to note that in the domain of software security, marginal improvements are desirable since even 1 missed malicious

Figure 1. Proposed Metadata-based Malicious Package Detection (_MeMPtec_) model architecture.

  Feature & \# Features &  &  \\  Model & & \# Malicious & \# Benign & \# Malicious & \# Benign \\  _Existing_tec_ & 11 & 3232 & 3232 & 3232 & 32320 \\ _MeMPtec_E_ & 36 & 3232 & 3232 & 3232 & 32320 \\ _MeMPtec_D_ & 21 & 3232 & 3232 & 3232 & 32320 \\ _MeMPtec_ & 57 & 3232 & 3232 & 3232 & 32320 \\  

Table 5. Description of datasets parameters.

Figure 1. Proposed Metadata-based Malicious Package Detection (_MeMPtec_) model architecture.

package (false negative) can have catastrophic consequences. For this reason, we further analyse the false positives (FP) and false negatives (FN). In a balanced dataset, _MeMPtec_ significantly outperforms _Existing_ _ _tec_ in reducing FP in Figure 3 (a). On the GLM algorithm, _MeMPtec_ achieves a 98.33% reduction (\(12.0 0.2\)), and on the SVM algorithm, it achieves an 88.69% reduction (\(23.0 2.6\)). On average, _MeMPtec_ reduces FPs by 93.44% (\(14.64 0.96\)). _MeMPtec_ also performs well in reducing FP in Figure 3 (b). It reduces the maximum number of FNs by 98.70% on the DRF algorithm (\(15.4 0.2\)) and achieves a minimum reduction of 79.66% (\(11.8 2.4\)) on the SVM algorithm. On average, _MeMPtec_ reduces FNs by 91.86% (\(15.24 1.24\)).

The results in Figure 3 (c) exhibit consistent trends in the imbalanced dataset. _MeMPtec_ reduces FP maximum 97.96% (\(58.8\) to \(1.2\)) on SVM, minimum 97.29% (\(51.4 1.4\)) on DRF algorithm. It reduces FP on average 97.5% (\(54.6 1.36\)) than the _Existing_ _ _tec_. It also reduces on average, 80.42 % of the FN numbers from 31.88 \( 6.24\) in Figure 3 (d). In all Figures 3, we observe that by using _MeMPtec_ \(E\) and _MeMPtec_ \(D\), the FP and FN can be reduced by an order of magnitude than the _Existing_ _tec_. These experiments illustrate the efficacy of _MeMPtec_ in addressing **Challenges 1 & 3**.

   & ML/DL Algo & Feature Model & Precision \(\) & Recall \(\) & F1-score \(\) & Accuracy \(\) & RMSE \(\) \\   & Existing\_ & _tec_ & \(0.9651 0.003\) & \(0.9817 0.002\) & \(0.9733 0.001\) & \(0.9731 0.001\) & \(0.1640 0.002\) & 798 \\  & _MeMPtec\_E_ & \(\) & \(0.9725 0.003\) & \(0.9857 0.002\) & \(0.9859 0.002\) & \(0.1175 0.008\) & 790 \\  & _MeMPtec\_D_ & \(0.9856 0.002\) & \(\) & \(0.9914 0.001\) & \(0.9913 0.001\) & \(0.0927 0.004\) & 761 \\  & _MeMPtec_ & \(0.9960 0.002\) & \(0.9963 0.001\) & \(\) & \(\) & \(\) & 762 \\   & Existing\_ & _tec_ & \(0.9798 0.001\) & \(0.9734 0.002\) & \(0.9766 0.001\) & \(0.9766 0.001\) & \(0.1595 0.002\) & 763 \\  & _MeMPtec\_E_ & \(0.9875 0.003\) & \(0.9817 0.003\) & \(0.9846 0.002\) & \(0.9847 0.002\) & \(0.1032 0.006\) & 764 \\  & _MeMPtec\_D_ & \(0.9951 0.001\) & \(0.9963 0.001\) & \(0.9957 0.000\) & \(0.9957 0.000\) & \(0.0689 0.002\) & 765 \\  & _MeMPtec_ & \(\) & \(\) & \(\) & \(\) & \(\) & 766 \\   & & Existing\_ & _tec_ & \(0.9813 0.001\) & \(0.9753 0.002\) & \(0.9783 0.001\) & \(0.9783 0.001\) & \(0.1407 0.003\) & 767 \\  & _MeMPtec\_E_ & \(0.9966 0.001\) & \(0.9947 0.001\) & \(0.9956 0.001\) & \(0.9957 0.001\) & \(0.0581 0.006\) & 768 \\  & _MeMPtec\_D_ & \(0.9963 0.002\) & \(0.9976 0.001\) & \(0.9996 0.001\) & \(0.9969 0.001\) & \(0.0512 0.004\) & 769 \\  & _MeMPtec\_ & \(\) & \(\) & \(0.9992 0.000\) & \(\) & \(\) & 770 \\   & & Existing\_ & \(0.9798 0.001\) & \(0.9762 0.003\) & \(0.9780 0.001\) & \(0.9780 0.001\) & \(0.1416 0.003\) & 771 \\  & _MeMPtec\_E_ & \(0.9982 0.001\) & \(0.9941 0.002\) & \(0.9961 0.001\) & \(0.9961 0.001\) & \(0.0548 0.006\) & 772 \\  & _MeMPtec\_D_ & \(0.9963 0.002\) & \(0.9972 0.001\) & \(0.9968 0.000\) & \(0.9968 0.000\) & \(0.0471 0.002\) & 773 \\  & _MeMPtec\_ & \(\) & \(\) & \(\) & \(\) & \(\) & 744 \\   & & Existing\_ & \(0.9810 0.001\) & \(0.9756 0.002\) & \(0.9738 0.001\) & \(0.9783 0.001\) & \(0.1447 0.003\) & 775 \\  & _MeMPtec\_E_ & \(0.9891 0.003\) & \(0.9922 0.002\) & \(0.9907 0.002\) & \(0.9907 0.002\) & \(0.0874 0.011\) & 776 \\  & _MeMPtec\_D_ & \(0.9954 0.002\) & \(0.9969 0.000\) & \(0.9961 0.001\) & \(0.9961 0.001\) & \(0.0597 0.007\) & 778 \\  & _MeMPtec\_ & \(\) & \(\) & \(\) & \(\) & \(\) & 778 \\    & Existing\_ & _tec_ & \(0.9127 0.004\) & \(0.9511 0.006\) & \(0.9314 0.004\) & \(0.9873 0.001\) & \(0.1126 0.003\) & 779 \\  & _MeMPtec\_E_ & \(0.9940 0.001\) & \(0.9688 0.003\) & \(0.9812 0.001\) & \(0.9966 0.000\) & \(0.0579 0.002\) & 760 \\  & _MeMPtec\_D_ & \(0.9799 0.004\) & \(0.9417 0.014\) & \(0.9601 0.006\) & \(0.9929 0.001\) & \(0.0833 0.006\) & 781 \\  & _MeMPtec\_ & \(\) & \(\) & \(\) & \(\) & \(\) & 782 \\   & & _D\_ \_imb\_\_\_1 & \(0.9134 0.010\) & \(0.9508 0.014\) & \(0.9317 0.008\) & \(0.9873 0.001\) & \(0.1094 0.005\) & 783 \\  & _MeMPtec\_E_ & \(\) & \(0.9688 0.007\) & \(0.9832 0.003\) & \(0.9970 0.001\) & \(0.0559 0.005\)

### Robustness of _MeMPtec_ (RQ2)

In this section, we evaluate the robustness of _MeMPtec_ against adversarial attack. We assess the impact of data manipulation on the performance of the models by (1) ranking the features for each dataset according to their importance for each model; and (2) replacing the true values of the features in the malicious dataset with random values selected from a distribution of values for the same feature in the benign dataset iteratively beginning from the most important feature (Appendix A.2 has the details of the algorithm). By doing this, we are simulating various degrees of the worst-case scenario adversarial attack where an adversary deliberating tries to game the model.

Figure 2 is the result of this experiment. In this experiment, in decreasing order of importance, the values of features for the malicious dataset are replaced. The figure shows the decline in accuracy performance for the balanced dataset across the models. We note that in all the models, as the percentage of features is manipulated, the model performance decreases drastically for the _Existing_,_tee_ and _MeMPtec_,\(E\) based features. However, this is less so for the _MeMPtec_ features. In fact, even after manipulating 100% of the features _MeMPtec_ based approach performs significantly better (_e.g_ GLM model: 99.87% \(\) 92.73%). We conduct further extensive experiments, achieving similar results, by considering only the top ten features (Appendix A.3) as well as indirect manipulation of the features via the package metadata information (Appendix A.3)- not included due to space constraints.

In Figure 4, we also investigate the impact of the monotonicity property on the ability of an adversary to manipulate the DTM features. Figure 4 (a) shows the modification of all temporal DTM features by increasing their time-based values iteratively (in number of days). The aim of the experiment is to show the robustness of _MeMPtec_ even when the adversary attempts to game the model via DTM features. We note that for DL, even after 360 days, _MeMPtec_ features only decline marginally in performance (0.9998 \(\) 0.9928). Similarly, Figure 4 (b) shows the modification of all package interaction-based DTM features. In this experiment, the count of each figure increased iteratively. Similarly, we notice that for DL, _MeMPtec_ features only decline marginally in performance after 50 count updates (0.9998 \(\) 0.9989). As can be seen, the behaviour is consistent across all the different models.

These experiments validate the _MeMPtec_'s ability to mitigate against adversarial attacks (**Challenge 2**).

## 7. Conclusion

In this paper, we proposed metadata based malicious detection algorithm named _MeMPtec_, which relies on a novel feature engineering strategy resulting in easy-to-manipulate (ETM) and difficult-to-manipulate (DTM) features from metadata. We conduct extensive experiments to demonstrate _MeMPtec_'s efficacy for detecting malicious packages in comparison with existing approaches proposed in the state-of-the-art. In particular, _MeMPtec_ leads to an average reduction of false positives by an impressive 93.44% and 97.5% across two experimental datasets, respectively. Additionally, false negative numbers decrease on average 91.86% and 80.42% across the same datasets, respectively. Furthermore, we analyse _MeMPtec_'s resistance against adversarial attacks and show that, even under worst-case scenarios, our approach is still highly resistant.

Figure 4. Performance analyses of _MeMPtec_ wrt monotonic property (temporal information and package interaction).

Figure 3. False Positive and False Negative numbers comparison on balanced and imbalanced datasets.

Figure 2. Performance analyses of various models wrt feature manipulation.