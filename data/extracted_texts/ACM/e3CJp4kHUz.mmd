# Perceptions in Pixels: Analyzing Perceived Gender and Skin Tone in Real-world Image Search Results

Anonymous Author(s)

###### Abstract.

The results returned by image search engines have the power to shape peoples' perceptions about social groups. Existing work on image search engines leverages hand-selected queries for occupations like "doctor" and "engineer" to quantify racial and gender bias in search results. We complement this work by analyzing peoples' real-world image search queries and measuring the distributions of perceived gender, skin tone, and age in their results. Specifically, we utilize 54,070 unique image search queries from a representative sample of 643 US residents. For each of these queries we collect the top 50 results returned on both Google and Bing Images.

We learn multiple new things from analysis of real-world image search queries. First, less than 5% of unique queries are open-ended people queries (i.e., not queries for named entities). Second, fashion search is by far the most common category of open-ended people queries, accounting for over 30% of the total. Third, the modal skin tone on the Monk Skin Tone scale is two out of ten (the second lightest) for images from both search engines. Finally, we observe a bias against older people: eleven of our top fifteen query categories have a median age that is lower than the median age in the US.

**ACM Reference Format:**

Anonymous Author(s). 2024. Perceptions in Pixels: Analyzing Perceived Gender and Skin Tone in Real-world Image Search Results. In _Proceedings of the Web Conference 2024 (WWW '24), May 13-17, 2024, Singapore_. ACM, New York, NY, USA, 9 pages. [https://doi.org/10.1145/XXXX.XXXX](https://doi.org/10.1145/XXXX.XXXX)

## 1. Introduction

Search engines are widely trusted sources of information (Bauer et al., 2017), but the fact that people trust them grants them power to shape peoples' perceptions. For example, prior work has found that the political information presented in search engine result pages (SERPs) may influence voting behavior (Bauer et al., 2017; Bauer et al., 2017), and that the demographics of people that appear in image search results can alter perceptions of social groups (Hernandez et al., 2017; Goyal et al., 2017; Goyal et al., 2017). The fact that search engines like Google measure their audience in billions means that these systems must be carefully scrutinized to understand the potential impacts they may be having on individuals and society (Goyal et al., 2017).

In this work we focus specifically on _representational_ problems (Selvin et al., 2016) in image search results. Critics and algorithm auditors have used controlled experiments--in which they send hand-selected queries to image search engines--to uncover scenarios where the images in SERPs are biased along gender and racial lines. Examples include queries for occupations (e.g., 'doctor' and 'engineer') that return stereotypical images of (white) men (Hernandez et al., 2017; Goyal et al., 2017), or queries that include gender-neutral adjectives (e.g., 'intelligent') that also return mostly images of men (Hernandez et al., 2017; Goyal et al., 2017). These studies clearly highlight specific categories of queries where image search engines struggle to produce unbiased results.

Our goal in this study is to complement and expand on existing work by examining demographic representation in images produced in response to _open-ended people queries_ to image search engines. We define a _people query_ as a query that produces a SERP where a large fraction of the images contain people. By _open-ended_, we mean that the people in the image are not predetermined by the query itself. For example, queries for _named entities_ (e.g., Taylor Swift) are not open-ended and we would not expect the resulting images to be demographically diverse. In contrast, open-ended people queries offer image search engines the opportunity to select images containing diverse people--whether they do or not determines whether their output may cause representational harms.

To implement our study, we rely on a dataset of 54,070 unique image search queries from a real-world sample of 643 US residents. For each of these queries we collect the top 50 results returned on Google and Bing Image Search. We apply a series of filters (e.g., named entity recognition) to isolate open-ended people queries from within our dataset, and then measure the distributions of perceived gender, skin tone, and age in the corresponding SERPs. This approach enable us to understand demographic representation in image search results under real-world, ecological conditions, and compare representativeness of results between Google and Bing.

We investigate the following research questions:

* **RQ1**: What categories of queries have the most open-ended people queries?
* **RQ2**: How representative, in terms of perceived gender, skin tone, and age, are results for open-ended people queries?
* **RQ3**: Are there differences in representativeness between image search results from Google and Bing?
* **RQ4**: To what extent do people use adjectives to refine open-ended people queries, and what kinds of people engage in this refinement?

We learn multiple new things from analysis of real-world image search queries. Less than 5% of unique queries are open-ended people queries, and fashion queries are by far the most common category of open-ended people queries, accounting for over 30% of the total. The modal skin tone on the Monk Skin Tone scale (Selvin et al., 2016; Goyal et al., 2017) is two out of ten (the second lightest) for images from both search engines. Finally, we observe a bias against older people: eleven of our top fifteen query categories have a median age that is lower than the median age in the US (discounting the children category, which we expect to have a low median age).

Overall, our results show that, although open-ended people queries are somewhat rare, Google and Bing have a long way to go towards addressing representational problems in their results.

Further, our results highlight new categories of queries that have not been explored extensively by controlled studies, pointing the way for future algorithm audits.

The outline of our study is as follows: in SS2 we discuss related work on image search engines and contextualize our study within this literature. In SS3 we introduce our datasets and present our methods in SS4. We present the results of our analysis in SS5 and conclude in SS6.

## 2. Background

We begin by presenting an overview of work on representational issues and harms in the context of image search engines.

### Representation in Image Search

There is a robust literature on representational harms (Zagor et al., 2017) in image search engines. In their seminal 2015 study, Kay et al. (2016) examined representation of men and women in Google Image Search results in response to queries for occupations. They found that search results for many occupations overrepresented men relative to their baseline level of employment from government statistics. Furthermore, users judged images that matched gender stereotypes (e.g., a man as a doctor) as more 'professional' and 'appropriate.' Otterbacher et al. (2016) found similar representational and stereotyping issues when they queried Bing for a 'person' that had various attributes. Men were overrepresented in search results when agentic adjectives (e.g., 'competent', 'decisive') modified the query, but women were overrepresented when 'warm' adjectives modified the query. Ulloa et al. (2016) observed similar overrepresentation of men when they added the adjective 'intelligent' to image queries on Google, Yandex, and Baidu. Additionally, they observed _face-ism_ in search results from these search engines, a stereotype in which photos of men tend to focus on the face while photos of women include a greater proportion of the body.

Other work on representation in image search results focuses on race and the intersection of race and gender. Noble (2016) catalogued many queries that returned racist, sexist, and stereotypical results on Google. Metaxa et al. (2016) replicated and expanded the Kay et al. (2016) experiment, finding that White people are even more overrepresented than men in Google Image Search results for occupations. Urman et al. (2016) studied the representation of migrants in response to English and German queries across six image search engines: Google, Bing, Baidu, Yandex, Yahoo, and DuckDuckGo. They found that non-White people were overrepresented, while women were underrepresented. Finally, Makhortykh et al. (2016) found a predominantly White portrayal of Artificial Intelligence across the same six search engines.

### Effects of Representation

Researchers have consistently found that demographic representation in image search results can impact peoples' perceptions of search result quality. Multiple studies have confirmed that participants rate image search results to be higher-quality when the people in the images conform to gender stereotypes (Kay et al., 2016; Kaya et al., 2016), especially when a given participant holds strongly discriminatory views (Kay et al., 2016).

There is evidence, however, that increasing representation in image search results can lead users to correspondingly shift their views. Kay et al. (2016) found that manipulating gender representation in search results for occupational queries shifted users' estimates of gender proportions in occupations by \(\)7%. Metaxa et al. (2016) replicated this finding, and also demonstrated that manipulating gender and racial representation affected users' level of interest in an occupation, their perception of its inclusivity, and expectations about feeling valued in that occupation. This importance of perception is also echoed in Mitchell et al. (2016), who present metrics to measure the nebulous concepts of _diversity_ and _inclusion_ going beyond traditional group fairness metrics. Finally, Vlasceanu and Amodio (2016) demonstrated that manipulating gender representation affected participants' decisions in a hypothetical hiring scenario.

### Situating Our Study

Existing work clearly demonstrates that demographic representation issues exist in image search engines. The importance of identifying and mitigating these problems is highlighted by work suggesting that interventions may, in the long-term, be able to overcome peoples' initial, negative relevance judgments and meaningfully reshape their views.

Our study is motivated by and builds on prior empirical work in two ways. First, we examine demographic representation in image search results--from Google and Bing Image Search--in response to _ecological queries_ from a large, real-world panel of US residents (described in SS3). This contrasts with prior studies that have utilized _controlled queries_ selected by researchers themselves (Kay et al., 2016; Kaya et al., 2016; Kaya et al., 2016; Kaya et al., 2016; Kaya et al., 2016; Kaya et al., 2016). As we show in SS5, access to ecological queries enables us to identify areas of concern that previous studies have not identified, as well as contextualize the prevalence of known-problematic queries (e.g., about occupations). Second, we expand the set of demographic traits from prior work by examining representation in terms of perceived gender, skin tone, and age.

Prior work on representation in image search results has framed their findings around 'bias' (Kay et al., 2016; Kaya et al., 2016). According to Friedman and Nissenbaum (1999), a computer system has a problematic normative bias if it "systematically and unfairly discriminates against certain individuals or groups". Crucially, assessing bias requires a more-likely defensible baseline against which to judge a given system. In SS5 we use baselines drawn from the US Census to assess bias in image search results with respect to perceived gender and age.

## 3. Data Collection

In this section we introduce the image query and image search result datasets that facilitate our study.

    & & &  \\
**Search Engine** & **No Users** & **\% Searches** & **Mean** & **Std** \\  Google Images & _607_ & 93510 & 4.89 & 31.69 & 177 \\ Bing Images & 127 & 13754 & 11.66 & 57.76 & 178 \\   

Table 1. Summary statistics from image query dataset.

### Image Search Queries

From August to December 2020, we worked with the survey company YouGov to recruit a nationally representative sample of 2,000 US residents. Participants answered survey questions about their demographics and 926 people opted to install a browser extension that we developed for Chrome and Firefox. Our extension collected multiple types of data from participants' web browsers, but we only analyze participants' browsing histories in this study. Our study was IRB approved and $6.2 describes participants' protections.

We identified and extracted queries that participants' made on Google and Bing Image Search using the URL structures of these services.1 We ignored consecutive URLs with identical queries, which represented user interactions with the initial search, e.g., clicking on an image thumbnail. Table 1 shows the total number of users, total number of searches, and summary statistics about user daily activity on each image search engine. We define a participant as a user of a search engine if they made at least one search during our observation window on that search engine. According to this definition, 66% of our participants use Google Images, 14% use Bing Images, and 10% use both. Overall, we observe 107,264 total image searches and 54,302 unique queries from 644 participants across Google and Bing. Table 3 describes the demographics of these participants: they are substantially Whiter (80.4% vs. 58.9%) and older (by virtue of none being under 18) than the US population.

### Image Search Results

We developed an open-source2 web crawler that collected the top 50 image search results from both Google and Bing for each unique query that our participants issued. The crawler iterated through queries in a random order to prevent spillover and used a 1920\(\)1080 viewport, which is the most common desktop screen resolution.3 The crawler collected two types of image data--(1) full-page screenshots and (2) individual image files along with their metadata, e.g., position on the SERP-- and saved both as Base64 encoded images. We ran the crawler in August 2022 from an IP address in (redacted). Table 2 shows the total number of screenshots and image files collected, as well as summary statistics about the number of images returned per query. Overall, we collect image data from both Google and Bing for 54,070 unique queries.

## 4. Methods

In this section, we describe how we identified and categorized open-ended people queries and how we labeled the demographics of people in a sample of images.

### Identifying Open-Ended People Queries

We applied four filters--listed in Table 4--to isolate and validate a set of open-ended people queries from our larger query corpus.

#### 4.1.1. Detecting People Queries

We use YOLOv3 (Redmon et al., 2016), an object detection model pretrained on the COCO dataset (Lin et al., 2016), to detect the number of people in each image in our corpus.3 We summarize these inferences at the query-level by measuring the fraction of images on the corresponding SERP that contain at least one person. Figure 1 presents a histogram of this distribution for each search engine. In 45% of Bing SERPs and 42% of Google SERPs, fewer than 10% of images have people. At the other end of the spectrum, more than 90% of images have people in only 21% of Bing SERPs and 17% of Google SERPs.

We choose a conservative threshold and only remove queries where fewer than 25% of images on either Google or Bing have people. This leaves us with 21,539 queries (40%) that are potentially people related.

#### 4.1.2. Filtering Named Entities

When filtering named entities, our goal is to minimize the number of false negatives, i.e., queries labeled as open-ended, but which actually have a named entity. We make this decision because the demographics of images returned for a query with a named entity, e.g., Taylor Swift, are predetermined.

We combine three labeling approaches and remove the query if any approach identifies a named entity:

1. We make predictions using a spaCy CNN model pre-trained on the Ontonotes dataset (Vaswani et al., 2017).5 This model identifies entities in 14,693 (68%) of the people queries.

    &  \\
**Search Engine** & **No Sreenshots** & **No Images** & **Mean** & **Std** \\  Google Images & 54211 & 2510331 & 46.31 & 8.09 \\ Bing Images & 54127 & 2688585 & 49.68 & 2.70 \\   

Table 2. Summary statistics from image search crawls.

    &  \\  & & **N** & **\%** & **US Census** \\ 
**Gender** & Female & 334 & 51.9 & 50.4 \\  & Male & 310 & 48.1 & 49.6 \\ 
**Race/Ethnicity** & While & 518 & 80.4 & 58.9 \\  & Black & 49 & 7.6 & 13.6 \\  & Hispanic & 34 & 5.3 & 19.1 \\  & Asian & 14 & 2.2 & 6.3 \\  & Native American & 1 & 0.2 & 1.3 \\  & Two or more & 13 & 2.0 & 3.0 \\  & Other & 15 & 2.3 & – \\ 
**Age** & \(<18\) & 0 & 0.0 & 21.7 \\  & 18-64 & 507 & 78.7 & 50.4 \\  & \( 65\) & 137 & 21.3 & 17.3 \\   

Table 3. Demographics of participants who contributed image search queries.

2. We search the query on general Google Search and record whether the results page contains a knowledge-panel or a top-image-carousel (see (Sen et al., 2017) and (Berg et al., 2017) for examples of these SERP components). This approach identifies entities in 7,439 (35%) of the people queries.
3. We check whether the query contains the keyword'meme' or 'gif'. We observed that these queries often returned a specific meme or gif with a specific person. This approach identifies entities in 728 (3%) of the people queries.

This leaves us with 4,387 open-ended people queries (20% of people queries and 8% of all queries).

#### 4.1.3. Filtering NSFW Images

It is important to analyze open-ended people searches that return not-safe-for-work (NSFW) images to audit sexualization of racial and gender groups (Sen et al., 2017; Sohn et al., 2017). However, we choose to remove these images from our study because we hire crowd workers to label perceived demographics (see SS4.1.4) and we choose not to risk exposing them to sexual images. We use Yahoo's OpenNSFW model (Cai et al., 2017) to identify NSFW images, which is one of the best performing models for CSAM detection (Cai et al., 2017).6 Specifically, we make NSFW predictions for each image on a SERP and filter out queries where the average NSFW probability is \(>=20\%\). This approach flags 659 (15%) of open-ended people queries as NSFW.

#### 4.1.4. Expert Manual Review

Two authors manually reviewed the remaining 3,728 purportedly safe-for-work (SFW), open-ended people queries to identify any remaining false negatives. Specifically, we built an application that presented the Google and Bing full-page screenshots for each query and allowed the authors to review the automated (a) named entity and (b) NSFW labels. The two authors had a Cohen's \(=0.7\) on a random sample of 93 named entity labels. Additionally, the two authors (c) recorded the presence of people adjectives (e.g., "Black" or "female") in the query, and (d) removed queries that were not sufficiently people-focused (e.g., focused on cars) or that might be triggering to crowd workers.

Overall, we identified 1,673 (45%) of the remaining queries as named entities, 49 (1%) as NSFW, and 209 (6%) as potentially triggering or not sufficiently people-focused. This leaves us with 1,801 SFW, open-ended people searches (3% of all queries).

### Categorizing Open-Ended People Queries

One goal of our study is to examine demographic representation in image search results stratified by query category. To implement this goal, we categorize open-ended people queries according to the second level of the Worknet Domains hierarchy (Berg et al., 2017).7 We made a handful of modifications to the taxonomy after exploratory analysis of our queries. Specifically we added three categories (food, gastronomy, and animals), removed one (alimentation), and changed two (sport \(\) sports and earth \(\) earth science).

We assign a query to a category by computing the cosine similarities between an embedding of the query and embeddings of each category name. The embeddings are generated using a pre-trained language model that was fine-tuned to identify semantically similar sentence pairs (Song et al., 2017).8 We select the category with the maximum cosine similarity. Formally, let \(q\) represent the query, \(K\) represent the set of WordNet category names, and \(f\) represent the pre-trained language model. Our classification approach is:

\[*{argmax}_{K}.\]

We also add one category to the taxonomy that featured prominently in our manual review: children. We assign queries that contained the keyword 'kid', 'preschool', 'toddler', 'newborn', or 'newborn' to this category.

Figure 5(a) plots the distribution of queries over categories, which we discuss in SS5.2. To evaluate our categorization approach, Figure 2 plots Fleiss' \(\) scores between three labelers (two authors and the cosine similarity method) on a random sample of 54 queries as the cosine similarity threshold varies. We see that the point estimate for agreement is \( 0.7\) when the cosine similarity is \( 0.3\).

### Labeling Open-Ended People Queries

The final step in our methodology is to obtain demographic labels for a sample of images in our corpus. Similar to prior work, we hire crowd workers to do this task (Ghosh et al., 2017; Goyal et al., 2017). Our labeling task was IRB approved and SS6.2 describes crowd workers' protections.

Figure 1. Histogram of fraction of images per SERP containing at least one person.

Figure 2. Category assignment agreement as cosine similarity threshold varies.

[MISSING_PAGE_FAIL:5]

## 5. Results

In this section, we describe the topical distribution of open-ended people queries and analyze the distributions of perceived gender, skin tone, and age across search engines and categories.

### Representation Across Search Engines

Figure 5 compares the distributions of perceived gender, skin tone, and age across Google and Bing. Continuous age labels are binned into ten-year age brackets. We compute 95% confidence intervals using the percentile bootstrap with 1000 replications over queries, which is our sampling unit [(3)].

#### 5.1.1. Gender

Google and Bing have similar perceived gender distributions. Both search engines have slightly higher fractions of feminine than masculine presenting people, but these differences are not distinguishable from zero.

#### 5.1.2. Skin Tone

Search results for both Google and Bing are heavily skewed toward lighter skin tones. The modal skin tone for both search engines is two out of ten. 63-69% of Google images and 68-73% of Bing images have a skin tone \(\) 3. The mean skin tone on Google (3.18) is slightly higher than the mean skin tone on Bing (2.97) (95% CI 0.08-0.36).

#### 5.1.3. Age

The modal perceived age bracket for both search engines is 20-30. Perceived age is \(\) 40 in 81-87% of Google images and 82-88% of Bing images. One interesting observation is that the 0-10 age bracket represents 8-16% of Google images and 10-18% of Bing images. This large fraction of babies and children motivated the addition of children to our taxonomy.

### Representation Across Categories

Figure 6a plots the distribution of queries over categories. We observe that fashion is by far the most popular category, comprising more than 30% of queries. Art is the second most popular category, comprising just under 10% of queries. Sports is the third largest category, accounting for around 5% of queries. All other categories account for less than 5% of queries.

The rest of Figure 6 compares the distributions of perceived gender, skin tone, and age across categories. For each category, we compute a Bonferonni-corrected 95% confidence interval (i.e., a 99.8% confidence interval that accounts for 15 category comparisons) using the percentile bootstrap with 1000 replications over queries. We apply a Bonferroni correction because we compare each category to an overall baseline. Specifically, we compare the fraction of feminine presenting images to 50.4% (see Table 3) and the median age to 38.9 years.10 In lieu of an existing baseline for the Monk Skin Tone Scale, we use the midpoint of the scale: 5.5.

#### 5.2.1. Gender

Sports has the lowest fraction of feminine presenting images (13-49%), while medicine (44-86%), fashion (43-86%), and body care (43-78%) have the highest. However, only sports is distinguishable from the US Census baseline.

#### 5.2.2. Skin Tone

All categories have significantly lighter skin tones than the midpoint of the Monk Skin Tone Scale. Additionally, confidence intervals for all categories overlap, so we cannot distinguish them from each other.

#### 5.2.3. Age

All but three categories have lower median ages than the US median age. This is expected for the children category, but perhaps surprising for other categories, such as fashion and psychology. Overall, this demonstrates the bias that Google and Bing have away from images of older people.

### Query Adjective Use

In this section we analyze participants' use of demographic adjectives (e.g., 'Black' or 'female') in the query refinement process. The participants referenced here are those described in SS3.1 and Table 3.

We construct query refinement sequences by sorting participants' queries in time and comparing the semantic similarity of consecutive queries. For instance, one example sequence is: 'fall outfits' \(\) 'fall outfits for women' \(\) 'fall outfits for black women.' We measure semantic similarity between queries using the method in SS4.2.

Figure 7 compares the probability that a refined query contains a demographic attribute to the probability that an initial query contains one, as we vary the similarity threshold used to identify

Figure 5. Perceived gender, Monk Skin Tone, and age distributions in image search results.

refinement sequences. The point estimate for the difference in proportions is positive for all values of the similarity threshold. This indicates that refined, open-ended people queries are more likely to contain demographic adjectives than initial, open-ended people queries.

Table 6 presents results from three linear probability models that regress the use of specific demographic adjectives in open-ended people queries on participants' self-reported gender and race. We observe that Black participants were substantially more likely to use the adjective 'Black' in their open-ended people queries.

## 6. Discussion

This study generates new insights about representation on image search engines by focusing on real-world, _open-ended people queries_. First, we find that less than 5% of unique queries are open-ended people searches (i.e., not searches for named entities). This suggests that fairness interventions, which can be computationally expensive (Krishna et al., 2017), need not be run all of an image search engine's traffic. Second, we categorize open-ended people queries and find that fashion is by far the most popular category, accounting for over 30% of queries. Another prominent category is children: 4% of queries contain the keyword 'kid', 'preschool', 'toddler', 'newborn', or 'new born', and between 8-18% of images across Google or Bing fall into the 0-10 age bracket. Fashion and children are two categories that seem ripe for future controlled audits and user perception experiments. Stereotypical representation of people in fashion related image searches has also been studied in other works, such as work

Figure 6. Perceived gender, Monk Skin Tone, and age across categories. The red lines in (b), (c), and (d) compare each category to a reference baseline: fraction of women from the US Census, the midpoint of the Monk Skin Tone Scale, and the median age from the US Census, respectively.

Figure 7. Refined queries are more likely to contain adjectives than the initial query in a sequence.

by Pinterest (Pinterest, 2017) that focused on end-to-end diversification of its search and recommender systems.

The labels we collected on a sample of open-ended people queries across categories on Google and Bing also generated findings about perceived skin tone, age, and gender. First, Google and Bing are heavily skewed toward lighter skin tones. Across both search engines, the modal skin tone on the Monk Skin Tone Scale (Zhou et al., 2017) is two out of ten, and around 2/3 of images have a skin tone \( 3\). Our use of the ten-level Monk Skin Tone Scale, which Google introduced to better represent darker skin tones, emphasizes the concentration of image results at the light-end of the scale. Second, both search engines also demonstrate a bias away from older people. Over 80% of images are of people \( 40\) and eleven out of fifteen categories have a median age that is significantly lower than the US median age. Age bias is a representational harm that has not yet been studied in controlled settings--e.g., occupational queries--but which could have important effects. We also observed that two popular query categories, sports and fashion, conformed to gender stereotypes.

Finally, we explored participants use of people adjectives in the query refinement process. We found that refined queries were slightly more likely to contain people adjectives and that Black participants were significantly more likely to append 'Black' to their searches. Unfortunately, we did not have enough data to identify relationships between other demographics and the use of people adjectives. However, this suggests that some users might need to use people adjectives to arrive at results that better represent them. This demonstrates an opportunity for image search engines to improve the user experience--a motivation reflected in Pinterest's system overhaul (Pinterest, 2017).

### Limitations

Our study has several limitations. Our approach to identifying open-ended people queries relies on pre-trained models for person detection, named entity recognition, and NSFW detection, as well as manual review. We didn't incorporate uncertainty from these specific choices into our analyses further downstream. The same is true of our taxonomy for open-ended people queries and the corresponding classification approach. Furthermore, although we leverage real-world image search queries, we acknowledge that 80% of the participants who generated these queries were White, and the crowd workers who annotated our image sample skewed male and White. Lastly, we operationalize skin tone using a light-to-dark scale, but this fails to incorporate variable skin tone hues. Assessment utilizing a multidimensional scale (Zhou et al., 2017) may uncover more representational problems in image search results.

### Ethics

Our data collection protocol was approved by (IRB redacted). We informed potential participants about the data our browser extension would collect and asked for their consent to collect this data. Participants were compensated, could revoke consent at any time (none did), and our browser extension uninstalled itself at the end of the study period. Participant data was encrypted in transit and only approved members of the project may access it. Due to privacy concerns we cannot release participant data.

Our image labeling protocol was approved by (IRB redacted). We took extensive measures to remove NSFW images from our corpus before seeking labels. That said, out of an abundance of caution, we informed workers about the potential risks of our task (e.g., viewing disturbing images) before they could complete our task. We did not collect identifiable information from workers. We accepted all submissions from workers and compensated them.