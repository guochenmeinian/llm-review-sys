# ORFA: Exploring WebAssembly as a Turing Complete Query Language for Web APIs

Anonymous Author(s)

###### Abstract.

Web APIs are the primary communication form for Web services, with RESTful design being the predominant paradigm. However, RESTful APIs are typically fixed once defined, causing data under- or over-fetching as they can't meet clients' varying Web service needs. While semantic enriched API query languages like GraphQL mitigates this problem, they still face expressiveness limitations for logical operations such as indirect queries and loop traversals. To address this, we propose ORFA (One Request For All), the first in literature that employs WebAssembly (Wasm) as a Web API query language to achieve complete expressiveness of client requests. ORFA's key advantage lies in its use of Wasm's Turing completeness to allow clients to compose arbitrary operations within a single request, thus significantly eliminating redundant data transmission and boosting communication efficiency. Technically, ORFA provides a runtime for executing Wasm query programs and incorporates new module splitting strategies and a caching mechanism customized for integrating Wasm into Web API services, which can enable lightweight code transfer and fast request responses. Experimental results on a realistic testbed and popular Web applications show that ORFA effectively reduces latency by 18.4% and network traffic by 24.5% on average, compared to the state-of-the-art GraphQL.

Web API, WebAssembly, Query Language, Expressiveness, Runtime +
Footnote †: _WWW’25, April 28-May 02, 2025, Sydney, Australia_

+
Footnote †: _WWW’25, April 28-May 02, 2025, Sydney, Australia_

+
Footnote †: _WWW’25, April 28-May 02, 2025, Sydney, Australia_

+
Footnote †: _WWW’25, April 28-May 02, 2025, Sydney, Australia_

+
Footnote †: _WWW’25, April 28-May 02, 2025, Sydney, Australia_

+
Footnote †: _WWW’25, April 28-May 02, 2025, Sydney, Australia_

+
Footnote †: _WWW’25, April 28-May 02, 2025, Sydney, Australia_

+
Footnote †: _WWW’25, April 28-May 02, 2025, Sydney, Australia_

+
Footnote †: _WWW’25, April 28-May 02, 2025, Sydney, Australia_

## 1. Introduction

In modern Web systems, Web APIs play a crucial role as the primary method of co-operation and communication between -services , particularly in microservice architectures . Web service interfaces are required to support increasingly complex network services and have evolved from traditional Restful APIs  to more flexible solutions such as GraphQL . As illustrated in Figure 1, different clients may request various types of information through the API to interact with the Web server. Despite varying client needs, RESTful APIs are generally fixed in service, which can easily cause data over-fetching and under-fetching in practice . Over-fetching occurs when the server's response includes more data than the client requires, leading to unnecessary network transmission costs, while under-fetching happens when the data returned is insufficient, forcing the client to make additional requests.

GraphQL is the state-of-the-art query language that can mitigate these data over-fetching and under-fetching issues at Web services, given its enhanced expressiveness. For instance, in a scenario where client \(A\) only needs _create_time_ and client \(B\) requires only the _last_login_ time of the target user, both clients use a _GET_/_user_/_id_ request if using RESTful style APIs. This causes unnecessary network transmission since redundant information will be returned using this query. In contrast, with improved expressiveness of GraphQL, the clients can submit _query[user[id, create_time]_ and _query[user[id, last_login]_) to acquire the exact required information, effectively saving network resources by eliminating over-fetching. On the other hand, under-fetching can also occur by using RESTful style, which causes significant back-and-forth communications across the network. As shown in Figure 2 (top), _GET_/_user[id]_ request is for acquiring detailed information of user _[id]_ like privilege roles; and _POST_/_user[id]_/_notice_ for sending notification. Then, to implement the logic of "_sending notifications to adnins_", the client needs to send \(1+m+n\) requests, where \(m\) is the user count and \(n\) is the adn count. In contrast, the same operation can be accomplished via GraphQL in just two requests, as detailed in Figure 2 (middle). Apparently, enhanced expressiveness significantly helps shorten the operation time and reduces the data transmitted.

**Expressiveness limitations of GraphQL**. Despite its improved expressiveness, GraphQL still has a critical limitation in that _it is not Turing complete_, meaning not all operations can be accomplished within a single request. In practice, some common logic patterns such as indirect queries  and loop traversals  remain inexpressible by GraphQL. For instance, due to GraphQL's inability to mix _query_s and _mutations_, at least two requests are needed to accomplish the task, shown in Figure 2 (middle). If we elevate the expressiveness of the query language to a Turing complete level, e.g., allowing clients to send a program as a query, then it theoretically enables arbitrarily complex operations performed in a single query, realizing the full potential of **"One Request For All"**. Demonstrated by Figure 2 (bottom), with a Turing complete query language (like C), only **one** request is needed for this task. Thus, there still remains significant potential for further enhancing expressiveness.

However, implementing this Turing complete idea poses practical challenges. Executing client-provided programs on the server

Figure 1. A typical modern Web API service example that supports various clients with varying needs.

introduces data and resource security risks, as these programs might exploit vulnerabilities or overconsume resources. To address these risks, the programming language used for queries and its interpreter must enforce strong data isolation and resource constraints, which traditional languages often lack. Fortunately, WebAssembly (Wasm) (Hardt et al., 2016) meets the strict security requirements. Wasm is a Turing complete intermediate representation (IR) with built-in performance and security mechanisms, originally for running server-sent programs in client browsers with strong safety guarantees. Moreover, the core of Wasm (Hardt et al., 2016) is neural and general-purpose, making it suitable for applications beyond the browser.

Building on these insights, this paper explores the novel use of Wasm as a Turing-complete query language for Web APIs. Traditionally, Wasm is employed in a server-to-client model, where the server sends Wasm binaries to the client (often a Web browser) for secure execution in a sandbox environment. Our approach reverses this conventional flow by enabling clients to send queries as Wasm programs to the server, which poses unique implementation challenges. 1 The foremost problem is the programming model, i.e., how should the Wasm program be written, executed, and de-bugged in such a new querying scenario? 2 Although Wasm is more compact than traditional binary programs like x86 ELF files, it is still too large for most query use cases. Typical queries are only a few kilobytes in size, whereas even the simplest _hello-world_ Wasm program can exceed 100 kilobytes, which can greatly burden the request initiation. 3 Unlike GraphQL, Wasm programs spend much more time on compilation and instantiation before execution, thus necessitating an effective solution to reuse previously served programs, particularly for repeated queries.

We give our solutions to the above-mentioned issues in this paper. Specifically, the contributions of this work are as follows:

1. We highlight the necessity of enhancing expressiveness for Web API requests and the imperfection of the SOTA GraphQL in terms of completeness, which motivate us to propose ORFA, a Web-oriented framework employing Wasm as the query language to achieve Turing completeness and reaches the goal of "One **Request For All**".
2. We introduce ORFA's programming model and explain how to program, execute and debug the query programs. To reduce the size of the query module, we propose a novel module splitting technique that utilizes Wasm's inherit _import/export_ functionality and avoids relocation overhead in existing linking methods. We also design a caching mechanism for ORFA that significantly reduces the startup latency, program transmission, and resource usage at the servers. Our mechanism achieves a new application of Wasm to Web API querying scenarios with effective solutions addressing the program size and startup problems simultaneously.
3. Evaluations on representative system and workloads demonstrate that ORFA remarkably reduces request latency and network traffic, effectively outperforming the traditional RESTful APIs and the state-of-the-art GraphQL.

## 2. Background and Related Works

**RESTful Web API.** Modern Web systems rely on Web APIs for inter-service communication and co-operation (Bauer et al., 2016; Barends et al., 2016; Barends et al., 2016), especially in distributed and microservice architecture (Bauer et al., 2016; Barends et al., 2016). Although many protocols can be used for Web APIs, such as SOAP (Hardt et al., 2016), JSON-RPC (Hardt et al., 2016), etc., RESTful style that directly utilizes the elements in the HTTP protocol has become the default choice for Web API design (Hardt et al., 2016; Hardt et al., 2016; Hardt et al., 2016; Hardt et al., 2016). REST (Bauer et al., 2016) is not a specific protocol, but rather a vague set of design rules and guidelines. OpenAPI (OpenAPI, 2016) specification is an effort to formalize and standardize REST that defines a format to describe and document APIs in an organized and predictable manner, serving both for humans and machines.

**GraphQL and Query Languages.** GraphQL has become a popular supplement and alternative for traditional RESTful API design. By 2023, as many as 23% software projects have adopted GraphQL (Hardt et al., 2016), with industrial companies such as GitHub, Shopify, and Yelp implementing it. Practical evidence has demonstrated that GraphQL can significantly reduce engineering efforts, accelerate development (Hardt et al., 2016), and decrease communication overheads (Hardt et al., 2016), strongly demonstrating the necessity and feasibility of enhancing expressiveness. Netflix (Hardt et al., 2016), a JavaScript library rather than an formal query language. However, due to GraphQL's growing popularity, Netflix has discontinued Falcor. Other techniques, such as OData (Hardt et al., 2016) and HTML SQL (Hardt et al., 2016), embed SQL queries into HTTP URLs for client request customization. But they are limited to specific application scenarios and thus do not generalize well for broader Web API use cases. Query languages are more commonly associated with database systems, as seen with graph query languages including SPARQL (Hardt et al., 2016), Cypher (Cypher, 2016), Gremlin (Gremlin, 2016), and more. These database scenarios are different from Web services in that databases manage well-structured, static data, while Web services handle more dynamic and client-specific interactions. Therefore, Turing completeness is not the focus and primary goal of database works.

**WebAssembly (Wasm)** was proposed to address the performance limitations of JavaScript on the current Web platform (Hardt et al., 2016). The strict

Figure 2. An example illustrating data under-fetching using RESTful (top), problem mitigation by GraphQL (middle), and the best solution using a Turing Complete language (bottom).

security limitations of browsers ensure that Wasm is executed in isolated sandbox environments with strong safety features. Although originally designed for the Web, Wasm's language design avoids introducing Web-specific components and keeps its core purely computational. As a result, it has become an ideal, general-purpose intermediate representation suitable for various systems and has been widely applied to many outside-browser domains, including cloud and serverless computing (Zhu et al., 2017; Wang et al., 2018), high-performance computing (Zhu et al., 2017; Wang et al., 2018), and the Internet of Things (Zhu et al., 2017; Wang et al., 2018). Similarly, Wasm can be very promising to reshape and empower the query-based Web systems.
* **Wasm-based Server-side Remote Execution.** The native use of Wasm is to execute programs sent by Web servers, inside client browsers. But this paper aims at the reverse, i.e., sending query programs from the clients to be executed on the server. In fact, the practice of sending Wasm to servers for remote execution is not new, with one common usage to offload computation from clients to servers for both Wasm (Zhu et al., 2017; Wang et al., 2018; Wang et al., 2018) and JavaScript (Zhu et al., 2017; Wang et al., 2018; Wang et al., 2018). Nonetheless, the Web API querying scenario focused by QRFA differs significantly from these works in terms of the program size, execution time, and job amount by orders of magnitude. Therefore, these techniques cannot replace QRFA. Wasm has also been widely explored for serverless systems as a lightweight alternative for Linux containers (Zhu et al., 2017; Wang et al., 2018; Wang et al., 2018), where the Wasm programs act as remote executions from the perspectives of serverless developers. The Wasm programs in these systems function as normal Web services and are pre-uploaded to the serverless platform, whereas QRFA's query programs are dynamic and unpredictable. As far as we know, no existing works have used Wasm as a query language for Web APIs to enable the complete expressiveness of client requests.

## 3. Orfa

### Overview

Figure 3 illustrates the overall architecture of QRFA, a framework consisting of programming supports and server-side runtime. The programming support aims to assist client developers to compose their consecutive Web API operations into a Wasm query module, embedded as part of the client application. The runtime is deployed as a microservice alongside existing Web API microservices, minimizing communication costs between them. At run time, the client application sends the query module along with the associated query data to the QRFA runtime for remote execution. The query module is then combined with the environment module preloaded on the server and executed within the Wasm engine, with existing query program instances being reused if the cache hits. During execution, the query module can perform arbitrary computations and send requests to system-specified Web API services via QRFA's HTTP APIs. The Turing completeness of Wasm ensures that any complex operational logic can be encapsulated within a single query module. This approach allows the original **n** cross-internet remote Web API requests to be reduced to **1** remote request plus **n** inexpensive local requests, thereby reducing overall operational latency and network traffic. On the other hand, for Web API services, since QRFA enables users' customization for query operations, service developers now can refine Web API granularity to eliminate redundant functionalities, thus reducing service code maintenance costs.

The clients communicate with QRFA via the HTTP protocol, with additional headers supporting QRFA's functionalities, as summarized in Table 1. The main components of the client's request are the query data and the Wasm query module, shown in Figure 3, which are encoded in binary and concatenated to form the HTTP request body, with the _ORFA-Input_ header indicating the boundary in between. If the query succeeds, QRFA puts the result in the HTTP response body and returns it to the client. The specific content and encoding of the response body are entirely determined by the query module. Here are two major differences between QRFA and GraphQL: First, QRFA enforces the separation of query data and the query program, whereas GraphQL allows the mixture of the variable parts and the query code (refer to Figure 2), though it does recommend the usage of variables to achieve such separation (Zhu et al., 2017). The enforcement caters to the usual static compilation usage of Wasm and plays a key role in supporting QRFA's caching mechanism (SS3.4). Second, GraphQL defines its response body as JSON format corresponding to the request's query structure, while QRFA allows the query itself fully determines the response body, allowing autonomous selection of the most efficient and compact encoding method. This is attributed to the Turing complete expressiveness, which enables the computation required for encoding.

|p{142.3pt}} 
**Header** & **Note** \\  QRFA-Input & Specify the length of input data in the message body, used to separate input data and Wasm module code. \\  QRFA-Limit & Specify the required time and space for program execution. \\  QRFA-Debug & Used in debugging mode. \\  QRFA-Cache & Specify cache mode and cache token for caching mechanisms. \\  QRFA-Trust & ECDSA signature of Wasm module, used for verifying the integrity of the received program. \\  

Table 1. Additional headers defined by QRFA.

Figure 3. ORFA is a Wasm-based framework consisting of programming supports and server-side runtime. The Wasm query modules are programmed into client applications and then sent to remote runtime for execution to issue multiple local requests in substitution of original remote requests.

To prevent clients from abusing the computational resource, ORFA uses the _ORFA-Limit_ header to constrain the resource usage during execution. The resource safety risks associated with enhanced expressiveness is unavoidable and also exists in non-Turing-complete GraphQL (Grabblu et al., 2015; Grabblu and Kudrolli, 2016; Grabblu et al., 2017; Grabblu et al., 2018), but the success of GraphQL demonstrates that these risks can be accepted in practice1.

### Programming Web API Queries

Unlike usual Wasm programs, ORFA defines the query's entry point as a Wasm function named "orfa", which accepts two 132 parameters representing the starting address and length of the query data in the request body, respectively. Since Wasm is a general-purpose intermediate representation supported by many programming languages, any language capable of generating such a Wasm function can be used to write ORFA's query modules. For simplicity and due to the maturity of the toolchain, we choose C as the source language in this work.

As shown in Figure 4, the entry point of the ORFA query program corresponds to a C function with the signature void _orfa(void", int)_. Before executing the _orfa_ function, ORFA places the query data from the request body into the Wasm program's address space and passes the starting address and data length as arguments. The query then executes from the beginning of _orfa_, where programmers can write arbitrary code for computation or calling functions from Table 2 to interact with external services. Finally, at the end of the query execution, the programmer should collect the necessary data and encode it into a contiguous address space, then call the _done_ function to submit the data to the ORFA runtime. The data will be put into the response body and returned to the client by ORFA, thereby completing the query.

One thing to note about Table 2's API design is that the function used for issuing HTTP requests is asynchronous, thus allowing for the overlapping of multiple Web API operations. Also, it is important to point out that writing a practical query program requires significantly more supports than what is provided by the Wasm built-in instructions and Table 2's APIs, such as dynamic memory allocation, string manipulation, JSON parsing, and more. Without these supports, writing a query program would be exceptionally difficult. However, these supports are essentially purely computational and can be implemented as Wasm functions. ORFA consolidates these basic supports into a common Wasm environment module for shared use across all requests. The specific implementation details will be discussed in SS3.3.

The complexity of query code greatly surges along with the enriched expressiveness, which thus crucially necessitates the support for debugging to facilitate query programming. In such Web API querying scenario, connecting a debugger to a remote Wasm runtime service is not feasible, as the queries are very short-live and the server needs to handle massive queries, hence unavailable for interactive debugging with programmers. Therefore, we choose an alternative design: recording and replaying the query program's execution. The availability of this approach highly relies on the deterministic property of ORFA's programming model. As the Wasm core is fully sandboxed and purely computational, by recording all inputs during the execution, the entire running process can be reproduced elsewhere. To enable the recording, clients set the _ORFA-Debug_ header in its requests, and ORFA will respond the recorded log data instead of the original query result. The log data can be later used by our _ORFA Mock_ tools at the client side locally, as shown in Figure 5. The query code links to different environment libraries in normal execution and debugging simulation,

 
**Function** & **Note** \\  void done(const void*, uint32\_t) & Submit the response data. \\  void Handle\_del(Handle) & Delete an object. \\  int32\_t & Check that whether a future \\ Future\_ready(Handle) & object is ready. \\  Handle http(Request*) & Send a HTTP request asynchronously, returning a future object handle. \\  int32\_t & Extract data from a future object if it’s ready. \\  

Table 2. Built-in functions in ORFA environment.

Figure 4. Programming an ORFA query. The query data carried in the request body is passed as parameters. The query should submit the data to response body by calling done(). Arbitrary HTTP requests can be made to the specified Web API service.

Figure 5. The record and replay debugging of ORFA. The ORFA Mock tool together with native libraries ensures the equivalence of query execution environment.

and _ORFA Mock_ ensures the equivalence of the simulated environment between real remote environment. This way, the query code can be debugged locally like a normal program.

### Shrinking Query Module Size

Using a normal Wasm module as the query program may bring an serious issue that the program size itself greatly outweighs the truly critical query data, thus potentially nullifying the traffic reducing benefits of composing multiple requests into one. This isn't to say that Wasm format is bloated; in fact, quite the opposite is true that Wasm programs are significantly smaller than typical binary programs (such as x86 machine code). However, in our query scenario, the programs are extremely small, with just a few kilobytes usually, whereas even the simplest Wasm "Hello, World" program can exceed 100 KB. This discrepancy forces us to devise a method to reduce the size of the query module.

We have identified that this issue arises from the semantic gap between queries and Wasm. In detail, to support "simple" data extraction and assembly operations in queries, Wasm programs require a substantial amount of basic support code like dynamic string concatenation from standard libraries. But just including the _musl libc_ from WASI-SDK (Mikolov et al., 2013) can cost over 1 MB, without consideration of other libraries. If we could separate these common basic codes from the query code and pre-load them onto the servers, it would eliminate the need to repeatedly transfer them over the Internet. Therefore, we propose a method to split a complete query Wasm program into a query module and an environment module. The environment module contains the common basic code, provided by the server and pre-loaded into ORFA. The query module includes query-specific variable code, provided by the client and combined with the environment module to form a whole Wasm program for execution.

Figure 6 explains the splitting and recombination of the two modules. A compiled Wasm program mainly consists of _functions_, which can be easily split and recombined using the _import_ and _export_ mechanisms. However, making functions from two separate modules work together requires additional conventions that are not explicitly defined in the Wasm specifications. A representative example is that both modules must agree on the memory layouts, which is reflected in the addresses used by all memory access instructions across all functions. Our design involves splitting the global variable segment in the memory space into two regions with one for the query module and another for the environment. We then customize the Wasm linker to allocate different regions for the global variables of each module, ensuring that they do not overlap. To correctly access stack data, we export the global __stack_pointer from the environment module and import it in the query module, making both modules share a common stack. Finally, during the query initialization process, the global constructors generated in both modules, __wasm_call_env_ctors and __wasm_call_ctors, should be both invoked in order to ensure proper execution of the query code.

Be noted that our module splitting and recombination method is neither existent static linking (Mikolov et al., 2013) nor dynamic linking (Mikolov et al., 2013). It is directly based on the Wasm's _import_ and _export_ mechanisms instead and requires no additional compilation information. Accordingly, one advantage of this splitting design is that it avoids the traditional linking overhead of redirecting all memory access instructions, and allows the environment module to be pre-loaded into ORFA.

### Reducing Query Startup Latency

The execution of a Wasm query program consists of three phases, i.e., compilation, instantiation and execution. The first two phases are newly introduced compared to GraphQL. Considering that query requests are typically short-lived and massive in scale, the two phases may incur considerable startup overhead and latency. On the other hand, unlike GraphQL, whose programs are in text format and easy to be assembled dynamically, Wasm programs are in binary format and usually compiled statically from hand-written source code in high-level languages. As a result, Wasm query modules tend to remain unchanged during the run time of the client applications, leading to repeated compilation and instantiation of same query programs. Based on this observation, we extend ORFA with a caching mechanism to store the compiled results (referred to as the _ORFA-code_ mode) or the initialized instances (referred to as the _ORFA-inst_ mode). The _ORFA-inst_ mode can help eliminate the startup overhead, achieving performance comparable to native code, but requires additional server memory and more careful coding of the query module to make the Wasm instance stateless and reusable.

To enable caching, the client must set the _ORFA-Cache_ header in the request, specifying the desired caching mode and the previously cached token (if any). If the caching succeeds, the server then returns the refreshed cache token, and the client can omit the Wasm

Figure 6. The splitting and recombination of the query module and environment module. This figure shows the _export/import_ relation of key elements of query and environment modules and the partition of memory space for the two modules.

query module part in later requests to further reduce the network overhead. For cache management, we employ a function-based (Zhu et al., 2017) strategy, which exploits a background thread to periodically check the cache. If the number of cache items reaches a predefined threshold, the thread removes the least valuable cache items. The value of a cache item is calculated simply as the ratio of use counts to the time since last use.

It is common to see the same query programs sent from different front-end clients, as a client application usually serves many end-users. To share caches of query programs between clients, the value of the _ORFA-Trust_ header is used as a key to retrieve the existing cache token at the first caching request. The _ORFA-Trust_ value is a cryptographic signature of the query program, whose private key is generated by the client developers, and the corresponding public key is given to server maintainers and preset into the 0RFA service. Using cryptographic signatures instead of plain hashes can also helps to avoid the risks of caching efficiency downgrading when malicious attackers flood the server with useless cache requests to exhaust the cache capacity. Such signature-based caching mechanism is made possible by the data-query separation design in 0RFA's requests, and is not feasible in GraphQL for those dynamically assembled queries from clients, as it is impossible to sign the query program in advance.

## 4. Evaluation

To demonstrate the effectiveness of the proposed 0RFA, we evaluate primarily from the following aspects. 1) **Efficiency (SS4.2)**: we apply 0RFA in three widely-used realistic applications, and compare the latency and traffic metrics with those of GraphQL and the REST API; 2) **Sensitivity (SS4.3)**: we further conduct sensitivity studies to investigate the impact of network conditions and workflow complexities by adjusting client locations and the task workflow; 3) **Cost (SS4.4)**: to understand 0RFA's service cost and its impact on other Web API services when sharing server resources, we collect the peak throughput of GraphQL and 0RFA by stress testing with synthesized and realistic workloads respectively.

### Experimental Methodology

#### 4.1.1. Node Testbed

To model the real scenarios, our experiments are conducted on two virtual machines of different public cloud services: an AWS t2.micro and an Azure Standard B1s. These machines are designated to operate as the client and server, respectively. As detailed in Table 3, they roughly have equivalent configurations. And, for 0RFA, we choose the popular outside-browser embedder, Wasmtime2, as the Wasm engine.

#### 4.1.2. Workloads

Three representative and popular applications on GitHub are chosen as benchmarks:

* **Gitea3 (39k stars)**: a popular open-source Git server written in Go. Gitea only provides REST APIs specified with OpenAPI.
* **Memos4 (21k stars)**: a self-hosted lightweight online notetaking service developed in Go. Similarly, it only provides OpenAPI-specified REST interfaces for third-party integration. * **Strapi5 (58k stars)**: a leading open-source headless content management system (CMS) developed purely in JavaScript. Strapi uses REST APIs as default, and also provides a GraphQL interface as a plugin.

For each application, we compose two types of workflows, with one for read-only query and the other for write-operation query (with data modification). In total, as listed in Table 4, there are six workflows, which are denoted with suffix._r/._w. For instance, the read-only workflow of _Memos_ is _Memos.r_. Each workflow is further associated with a variable \(N\), representing the complexity of the workflow. Notably, since _Gitea_ and _Memos_ only provide REST interfaces in OpenAPI format, we use the OpenAPI-to-GraphQL (Song et al., 2017) tool to generate GraphQL wrappers.

#### 4.1.3. Metrics

We focus on three common metrics, latency, network traffic, and throughput, to quantify 0RFA's efficiency. The latency represents the time taken to complete the entire workflow, the network traffic is the amount of data transmitted during the workflow execution, and the throughput is the request number processed within a fixed time interval. The results are obtained using JMeter6, a popular load testing tool.

#### 4.1.4. Comparison Designs

We compare baseline and our proposed methods as listed below:

* **REST** represents that the operations are done by invoking REST APIs directly. The number of remote requests to complete each workflow is \(N\).
* **GraphQL** depicts that the same operations are performed indirectly by GraphQL queries. Using GraphQL, these workflows need to first retrieve a JSON list, followed by batching operations on the elements in the list. Thus, the number of remote requests is always 2, regardless of the value of \(N\).
* **ORFA-base** represents that the same operations are performed indirectly by sending a Wasm query module to 0RFA without caching. Due to the improved expressiveness, the number of remote requests is always 1.
* **ORFA-code** is same as 0RFA-base except that the compiled results are cached so that the code of the query module will not be sent repetitively. In this mode, the compilation is eliminated but the initialization is still required.
* **ORFA-inst** is same as 0RFA-code except that the final instance is cached and reused too, so that all overheads of compilation and initialization are eliminated. 0RFA-inst is our default configuration in continuously running serving processes.

   & **AWS t2.micro** & **Azure Standard B1s** \\  & **(Client)** & **(Server)** \\ 
**RAM** & 1G + 16 SWAP & 1G + 16 SWAP \\
**CPU** & Intel Xeon E5-2676 v3 & Intel Xeon E5-2673 v4 \\  & @ 2.40GHz (1 vCPU) & @ 2.30GHz (1 vCPU) \\
**OS** & Ubuntu 22.04 & Ubuntu 22.04 \\  

Table 3. Configurations of the experimental machines.

#### 4.2.1. Latency

For the latency analysis, we execute each workflow ten times and choose the median as the final result, as shown in Figure 6(a). ORFA poses lower latency across all work modes when compared to both REST and GraphQL, with the only exception of the _gitea.r_ workflow. Particularly, QRFA-inst reduces at most 52% latency on _memos.r_ compared to GraphQL, with an average of 18.4% reduction. In terms of _gitea.r_, the obviously long bar in Figure 6(b) and the observed latency issues are attributed to the parsing of the uncommonly long JSON data returned by Gitea's REST interface. In QRFA, this parsing process is conducted using cJSON within the Wasm interpreter, which is significantly less efficient compared to GraphQL's approach. GraphQL utilizes highly optimized JavaScript engine code for parsing, leading to better performance in this workflow. This additional parsing overhead in QRFA becomes the primary contributor to latency, overshadowing the benefits gained from reduced network communication.

#### 4.2.2. Network Traffic

Since the volume of data transmission is solely determined by the task and method, it remains consistent and is thus unaffected by variations in network conditions. Figure 6(b) presents the network traffic for each workflow. We can see that ORFA mostly has the least transmission volume, especially in the caching modes. On average, 24.5% traffic is reduced in ORFA-base and 72.4% in QRFA-code/ORFA-inst. This is because the increased expressiveness reduces the number of requests and allows the workflow-specific data encoding. There is only one exception: QRFA-base in the _memos.w_ workflow. In this case, the data transmitted is not so much that the extra size of the Wasm query module diminishes the benefits of reducing one data round trip compared to GraphQL. As a result, ORFA-base's total transmission is slightly higher than GraphQL's.

Putting together, the latency and traffic results demonstrate that QRFA can effectively improve latency and network transmission, outperforming the existing REST and GraphQL.

### Impacts of Network and Workflow

To further validate the efficiency and robustness of QRFA, we continue investigating the influence of network conditions and workflow complexities. Previously, we position the client in Sydney, with a delay of 93ms to the server, and choose a moderate value for **N**, being set as 4. For network conditions, we relocate clients to another two positions, Hong Kong and San Jose, and then observe changes in overall latency. For workflow complexities, we sweep over different values of **_N_** to understand their effects on latency and network traffic.

 
**Application** & **Read-only Workflow (.r)** & **Read-write Workflow (.w)** \\   & Get the second newest notes of each user. \(N\) is the user & Change the visibilities of all notes from a user. \(N\) is the notes number. \\   & Get related entries in table A for each entry in table B. & Add relations between entries in table A and a entry in table B. \(N\) is the number of entries in table A. \\  & \(N\) is the number of entries in table B. & table B. \(N\) is the number of entries in table A. \\   & Get the second newest commits of all branches in a repository. \(N\) is the number of branches. & Delete users whose name stars with a prefix. \(N\) is the number of filtered users. \\  & & number of filtered users. \\  

Table 4. Composed workflows of real applications.

Figure 7. Experimental results of realistic applications.

#### 4.3.1. Network Conditions

In terms of network conditions, clients in Sydney, Hong Kong, and San Jose respectively have a delay of 93ms, 35ms and 170ms. Since the data transmission amount is unaffected by network latency, we only analyze latency results. At first, we notice that the network condition change causes a shift on latency and the trend largely remains stable, which is illustrated in Figure 6(a). We further calculate the ratio between the latency of OFFA-inst and that of GraphQL, with results being reported in Figure 8. It can be observed that in almost all cases, OFFA achieves lower latency than GraphQL regardless of network conditions. Overall, OFFA can generally perform better with constrained network conditions, i.e., higher transmission delays.

#### 4.3.2. Workflow Complexity

Regarding workflow complexity, we place the client in Sydney and choose 2, 4, 8, 16 for **N**. Figure 9 summarizes the latency and network traffic ratios between OFFA-inst and GraphQL. Overall, in most cases, OFFA still maintains advantages in all values of **N**, demonstrating the robustness of our design. In terms of the network traffic, OFFA consistently achieves lower network transmission. Besides, for latency and throughput, we observe that applications react differently to changes in the value of **N** and two workflows of the same application react similarly. _Memos_'s workflows are not very sensitive to **N**, as _Memos_ is lightweight on operations. To the contrary, _Strapi_ is significantly affected. When **N** increases, the latency of the related workflows grows rapidly and the throughput decreases instead. This is because the intermediate Web API responses become pretty verbose, bringing in higher parsing overhead. _Gita_ does not show significant differences when **N** is large. This is because the server is already overloaded when **N** is 8. Both OFFA and GraphQL spend most of their time on _Gita_'s internal operations.

### Service Cost

In this section, we compare the peak throughput of OFFA with that of GraphQL to evaluate the running overhead, or rather service costs. Specifically, we tend to figure out two questions: 1. How much overhead does executing the Wasm program itself brings? 2. How much impact does OFFA have on the services when co-located on the same server? For the first question, we defined a synthesized task, which solely commands the server to return a "hello world" string as the result, for both GraphQL and OFFA. For the second question, we deployed OFFA and GraphQL alongside with three applications (in RESTful) on the same machine and collected their throughput metrics. Three three applications maintain the same workloads when co-existing with OFFA and GraphQL. Also, they only contain read workflows, as the write workflows are not idempotent. The results for both questions are reported in Table 5.

Table 4(a) shows that OFFA significantly lowers throughput (\(57\%\) - \(76\%\)) and increases latency (\(134\%\) - \(157\%\)) compared to GraphQL in the no-caching (ORFA-base) and code caching (ORFA-code) modes, which can be attributed to the compilation and initialization cost of Wasm programs. On the other hand, when the compilation and initialization are completely eliminated in the instance caching mode (ORFA-inst), ORFA achieves \(22\%\) throughput boost and \(18.2\%\) latency reduction with \(68\%\) less CPU usage, demonstrating the high performance of Wasm's execution and effectiveness of proposed caching revisions.

Table 4(b) shows that OFFA generally achieves much lower throughput than original RESTful APIs, with a median value of \(54.9\%\), demonstrate the the high cost of using Web API services indirectly through OFFA. This is reasonable, as the additional costs not only come from the compilation and initialization of Wasm query programs, but also from the clients' offloaded computation for parsing and assembling HTTP messages. Also, note that GraphQL achieves even better result than original RESTful API in _strapi.r_. This falls onto the embedding of GraphQL into service code, which eliminates the overhead of a wrapper layer, thereby hinting more potential performance gain by integrating OFFA and the service.

## 5. Conclusion

In this paper, we propose ORFA, a framework that employs WebAssembly as a Turing complete query language for Web API services, allowing "One Request For All" operations to eliminate all data round-trips. We present ORFA's programming support and runtime design, explain how to program, run, and debug a Wasm query module. We also introduce two key techniques of module splitting and caching to reduce query module size and query startup latency. Experimental results on representative systems and workloads demonstrate that ORFA significantly boosts Web API service efficiency with reduced latency and transmission traffic.

    & **GraphQL** &  **ORFA** \\ **-base** \\  &  **ORFA** \\ **-code** \\  & 
 **ORFA** \\ **-inst** \\  \\ 
**TPS** & 909.09 & 222.22 & 384.62 & 1111.11 \\ 
**Time (ms)** & 1.1 & 4.5 & 2.6 & 0.9 \\ 
**CPU** & 88\% & 100\% & 100\% & 20\% \\   

Table 4. Stress testing results.

Figure 9. The latency and network traffic ratio of OFFA-inst to GraphQL when **N** varies (Lower is better).

*  Y. Hu et al. 2014. A Time-Aware and Data Sparsity Tolerant Approach for Web Service Recommendation. In _2014 IEEE International Conference on Web Services_. (June 2014), 33-40. doi: 10.1109/ICWS.2014.18.
*  Maria Malsakowski et al. 2010. Investigating web apis on the world wide web. In _2010 Eighth IEEE European Conference on Web Services_. (Dec. 2010), 107-114. DOI: 10.1109 EXCOWS.2010.9.
* A Large-Scale Empirical Study of Web APIs From Two Publicly Accessible Regions: Listing Using Stack Overflow and at User Verber. _Transportation on Software Engineering_, 49, 2 (Feb. 2023), 498-528. doi: 10.1109/TSE.2023.154769.
*  Johannes Thiese. 2015. Microservice. _IEEE Software_, 32, 1, (Jan. 2015), 116-116. doi: 10.1109/MS.2015.11.
* Research and Development_, 33, 2017. doi: 10.1007/s0040-016-0337-0.
*  Roy Thomas Fielding et al. 2000. _Architectural styles and the design of networked software architectures_. Ph.D. Dissertation. Issue: 0509/1810. A10/08/181058718.
* . [a.] I. Graphj'a query language for your api: Retrieved Oct. 26, 2023 from [https://graphj.org/](https://graphj.org/).
*  Glision Rhie et al. 2019. Migrating to graphj a practical assessment. In _2020 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER)_. 2019 IEEE 26th International Conference on Software Analysis, Evolution and Reengineering (SANER). (Feb. 2019), 140-150. doi: 10.1109/SANER.2019.8607698.
*  Glision Rhie et al. 2020. Best vs graphk a controlled experiment. In _2020 IEEE International Conference on Software Architecture (ICSA)_. 2020 IEEE International Conference on Software Architecture (ICSA), 81-90. doi: 10.1109/ICSA.7634.2020.00016.
*  Piatr Rokoski et al. 2020. Evaluating execution strategies of graph queries. In _2020 46th International Conference on Telecommunications and Signal Processing (ISP)_. 2020 464-644. doi: 10.1109/ISP2995892.029163501.

- Stock 2017 Workshop_. Lars Heraubach et al., 2018. Springer International Publishing, Cham, 283-295. issu: 978-319-9174-1, doi: 10.1007/978-319-9174-1, 23.
*  2018 Graphj. an vom mutte the results of a query Stack Overflow. (Sept. 14, 2018). Retrieved Jan. 10, 2024 from [https://stackoverflow.com/q/52330018/1378-4274](https://stackoverflow.com/q/52330018/1378-4274).
*  2018 Graphj loop through array and get all results. Stack Overflow. (Jan. 18, 2018). Retrieved Nov. 13, 2023 from [https://stackoverflow.com/q/48321689/13784274](https://stackoverflow.com/q/48321689/13784274).
*  Andreas Haas et al. 2017. Bringing the web to speed with webassembly. In _Proceedings of the 28th ACM SIGPLAN Conference on Programming Language Design and Implementation_. (PLDI 2017). Association for Computing Machinery, Barcelona, Spain, 185-200. doi: 10.1145/364513.3606263.
* woksembly 2.0 (draft 2023-12-01). Retrieved Dec. 24, 2023 from [https://webassembly.github.io/spec/](https://webassembly.github.io/spec/).
*  19. [b.] 20021 Version 12 Part 1: Messaging Framework (Second Edition). [https://www.io/TP/tsu2/02/](https://www.io/TP/tsu2/02/). Retrieved Dec. 20, 2023 from.
*  2018. JSON-HPC 20 Specification. [https://www.jsonr.org/specification](https://www.jsonr.org/specification). (0. Retrieved Dec. 20, 2023 from [https://www.jsonr.org/](https://www.jsonr.org/).
*  Andy Neumann et al. 2021. An Analysis of Public REST Web-Service APIs. IEEE Transactions on Services Computing, 14, 4, (July 2021), 957-970. doi: 10.1109/TSC.2018.287434.
*  Mohamed A. Omauz et al. 2021. Empirical Study on REST APIs Usage in Android Mobile Applications. In _Service-Oriented Computing_. Michael Marsili et al., (Eds.) Springer International Publishing, Cham, 614-622. issu: 978-319-40955-3, doi: 10.1007/978-3-319-6095-3, 34.
*  [a.] OpenAPI Specification v3.1.0 Introduction, Definitions, & More. [https://spec.openapis.org/v3.1.0](https://spec.openapis.org/v3.1.0). Retrieved Dec. 2, 2023 from [https://www.openapi.org/v3.1.0](https://www.openapi.org/v3.1.0). Retrieved Dec. 2, 2023 from [https://www.setup.org/v3.1.0](https://www.setup.org/v3.1.0). Retrieved Dec. 3, 2023 from [https://www.setup.org/](https://www.setup.org/).
*  2023 state of software quality (api) asai: [https://smuerbear.com/state-of-software-quality/api/](https://smuerbear.com/state-of-software-quality/api/).
*  [a.] 2014. Yahoo: an early computer Review. Retrieved Dec. 10, 2023 from [https://net.github.io/sla/](https://net.github.io/sla/).
*  [a.] 2021 draft 2007. Htsu-a native web query language. 439-445.
*  Jorge Perez et al. 2009. Semantics and complexity of SPARQL. ACM Trans. Database Syst., 34, Sept. 2009. 1, 16-186. doi: 10.1145/364512.365728.
*  Nadime Francis et al. 2018. Cybern: An Evolving Query Language for Property Graphs. In _Proceedings of the 2028 International Conference on Management of Data_ (SIGMOD '18). Association for Computing Machinery, New York, NY, USA, (May 2018), 1433-1445. issu: 978-1-4503-4705-7, doi: 10.1145/318753.31.90657.
*  Harsh Thakkar et al. 2017. Towards an Integrated Graph Algebra for Graph Pattern Matching with Gremlin. In _Database and Expert Systems Applications_. Dylan Bemslinner & G.L. (eds.). Springer International Publishing, Cham, 81-91. issu: 978-319-64468-4, doi: 10.1007/978-3-319-64468-4, 56.
*  Philipp Gadsatzter et al. 2022. Training Services to the Edge with WebMeasurely Businesses. In _2022 42nd IEEE International Symposium on Cluster, Cloud and Internet Computing (CCOFiM)_ (May 2022), 140-149. doi: 10.1109/CCGrid54584.2022.0022.0023.
*  Simon Shillaker et al. 2020. TensorFlow: lightweight solution for efficient digital serverless computing. In _2020 USENIX Annual Technical Conference (USENIX ATC)_. USENIX Association, (July 2020), 419-433. issu: 978-1-3913-14-4.
*  Mohan Chadha et al. 2023. Exploring the use of webassembly in hpc. In _Proceedings of the 28th ACM SIGPLAN Annual Symposium on Principles and Practice of Parallel Programming_ (PPoPP '23). Association for Computing Machinery, New York, NY, USA, (Feb. 21, 2023), 92-160. issu: 978-0007/0156. doi: 10.1145/372845.377436.
*  Samuel Ginsburg et al. 2023. Vectorvisor: a binary translation scheme for throughput-oriented (jog) acceleration. In _2023 USENIX Annual Technical Conference (USENIX ATC)_. 2017-1037. issu: 978-1-3913-35-9. Retrieved July 24, 2023 from [https://www.sensor.org/conference/utc23/presentation/ginz.php](https://www.sensor.org/conference/utc23/presentation/ginz.php).
* IEEE Conference on Computer Communications_. IEEE INFOCOM 2021
- IEEE Conference on Computer Communications. (May 2021), 1-10. doi: 10.1109/TCOM204298.12021.488424.
*  James Minchevsky et al. 2022. Watz: a trusted webassembly runtime environment with remote attestation for trustzone. In _2022 IEEE 2nd International Conference on Distributed Computing Systems (ICDCS)_. (July 2022), 1177-1189. doi: 10.1109/ICDCS854.2022.00116.
*  Sebastian Heil et al. 2023. Dem dynamic client-server code migration. In _Web Engineering_. (Lecture Notes in Computer Science). Ieen Gargios et al., 2024. Springer Switzerland, Cham, 3-18. issu: 978-531-34444-2, doi: 10.1007/978-3-031-34444-2_1.
*  Phylus-Jon Jeong et al. 2019. Semantics Offloading of Web App Computations From Mobile Device to Edge Clouds via HTML5 Web Worker Migration. In _Proceedings of the ACM Symposium on Cloud Computing_ (SoCC). 19. Association for Computing Machinery, New York, NY, USA, (May 2019), 38-48. issu: 978-1-4503-697-9, doi: 10.1145/337233.336273.
*  Xiaolin Gong et al. 2016. WebPow: An Energy Efficient Offloading Framework for Mobile Webpage. In _Proceedings of the 13th International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services_ (MOD bioinformatics), 106-19. Association for Computing Machinery, New York, NY, USA, (Nov. 2016), 160-169. issu: 978-1-5403-7201-1, doi: 10.1145/299479349.3749379.
*  Chacon Yau et al. 2014. Mqia: mobile offloading for javger applications. In _25th IET Irish Signal & Systems Conference 2014 and 2014 China-Ireland International Conference on Information and Communication Technologies_ (ISC 2014TCT 2014). 25th IETT in Signals & Systems Conference 2014 and 2014 China-Ireland International Conference on Information and Communications (ISEC 2014TCT 2014). (June 2014), 59-63. doi: 10.1049/2014.0659.
*  Meihua Yu et al. 2015. Javascript offloading for web applications in mobile-cloud computing. In _2015 IEEE International Conference on Mobile Services_. 2015 IEEE International Conference on Mobile Services. 2015. doi: 10.1109/MobSer.2015.346.
*  David Coltsche et al. 2019. AcCTEE: A WebAssembly-based Two-way Sand-flow for Trusted Resource Accounting. In _Proceedings of the 20th International Middleware Conference on Software_. (Marquez '19). Association for Computing Machinery, New York, NY, USA, (Dec. 2019), 123-135. issu: 978-1-4503-7009-7, doi: 10.1145/3155.325154.
*  Vojian Kyoreitos et al. 2023. WebAssembly as an Enaler for Next Generation Services Computing. Journal of Grid Computing, 21, 3, (June 2023), 34. doi: 10.1007/s10723-0696-8.0.
*  Qizera, "Metric

[MISSING_PAGE_FAIL:10]