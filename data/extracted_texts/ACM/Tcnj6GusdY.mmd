# [MISSING_PAGE_FAIL:1]

[MISSING_PAGE_FAIL:1]

violating ads on partner websites_? Based on our findings regarding the limitations and flaws of allowlist rules, we propose ways to enhance the enforcement of acceptable ads by implementing more precise allow rules and avoiding overly permissive ones. We evaluate our proposed enhancement by demonstrating reduced non-compliant ads when testing on real-world websites.

In summary, we make the following contributions to enhance the understanding and improvement of ad compliance on websites adhering to the Acceptable Ads Standard:

* We developed a web crawling tool that utilizes a proxy-based approach to inject scripts into web pages for measuring properties of web elements. Additionally, we crawl the same page using different configurations of ad filtering rules, enabling us to retrieve the ads of interest. Additionally, the injected script performs in-situ telemetry to identify ad elements that violate Acceptable Ads Standard. We will also open-source our measurement framework to the public.
* We conducted a comprehensive web measurement study involving 10,000 domains selected from the intersection of Tranco's 100K domains and partner websites listed in the Acceptable Ads exception list. Our findings indicate that one in every ten websites display at least one violating ad.
* Leveraging the telemetry data collected, we identified overly permissive rules and DOM elements consistently associated with violating ads. We implemented improvements to the exception list and demonstrated a reduction in violating partner websites by 32.4%.

These contributions enhance the existing literature on ad compliance and provide actionable insights for refining ad standards.

## 2. Background

Online advertising is a primary revenue model for millions of websites, providing financial support for free content and services. In the US alone, the online advertising market surpassed 225 billion dollars in 2023 (Lewis et al., 2022). Digital advertisements come in various forms, including text ads, video ads, pop-ups, and in-video ads. Despite their economic significance, advertisements can often hinder user experience due to their disruptive nature, leading to the development of ad-filtering technologies.

Ad-filtering software, or ad blockers, have become widely popular as users increasingly seek to minimize interruptions and protect their privacy. These tools block or hide unwanted ads from being displayed on websites, offering a cleaner browsing experience. However, the widespread adoption of ad blockers poses challenges for websites that rely on ad revenue, prompting the development of acceptable ad standards and efforts to strike a balance between ad-based revenue and user control.

### Ad-Filtering and EasyList

A cornerstone of ad-filtering is the use of blocklists, which define the specific rules for identifying and blocking ads. One of the most prominent of these blocklists is _EasyList_(Kumar et al., 2017). EasyList is an open-source, community-maintained list that contains rules used by most ad blockers to filter unwanted ads. These rules cover a wide range of ad types, including banners, pop-ups, and tracking elements. EasyList, integrated into popular ad-blockers like AdBlock Plus (Brockman et al., 2017) and uBlock Origin (Kumar et al., 2017), provides rules for blocking or hiding URL patterns, CSS selectors, and scripts, enabling seamless filtering of intrusive elements from webpages.

The list is continually updated by a group of volunteers and contributors who review and add new rules based on user submissions or as new advertising techniques emerge. EasyList also contains regional variations, known as supplementary lists, to accommodate language- and region-specific ads. While EasyList is highly effective at reducing intrusive advertisements, it can hurt the economic perspectives of domain owners who may rely on ad monetization. This has led to efforts to develop standards for non-intrusive ads that meet both user and publisher needs.

### Acceptable Ad Standard

The Acceptable Ads Standard aims to balance user experience with website monetization by allowing certain non-intrusive ads that are less disruptive. It creates an exemption for non-intrusive ads by declaring rules in an Exception list (Brockman et al., 2017) that is structured similarly to the EasyList. The standard describes in detail the distinction, size, and placement of the ads in the following manner:

* **Size:** Ads must occupy a reasonable amount of screen space, with specific size and dimension limitations.
* **Placement:** Ads should be clearly distinguishable from the primary content.
* **Labeling:** All ads must be clearly labeled as such.

In contrast, the following types of ads, shown in Figure 1, are deemed unacceptable and are considered violations of the standard:

* **Pop-ups and Pop-under Ads:** Ads that appear in separate frames, windows or tabs, either above or below the current context.
* **Animated Ads:** Advertisements with rapid animations or flashing effects.
* **Audio/Video Ads with Sound:** Advertisements that play audio or video with sound automatically upon loading of the page.
* **Ads Covering Content:** Ads that cover significant portions of the webpage's content.

These criteria formed the foundation for our heuristics to automate ad vetting, ensuring that only ads conforming to the Acceptable Ads Standard are allowed. The heuristics, which we discuss in Section 4.3, were tailored specifically to desktop ads, with mobile ads being outside the scope of this analysis.

## 3. Related Work

**Online Ads.** The subject of digital advertising has attracted significant attention from various stakeholders within the online ecosystem (Selvin et al., 2016; Wang et al., 2017; Wang et al., 2018). Economic incentives have driven research into the

Figure 1. Ad formats strictly forbidden under acceptable ads.

effectiveness of different advertising formats and the key factors that capture user attention (Zhou et al., 2017; Wang et al., 2018; Wang et al., 2019). Some studies approach this issue from a privacy perspective, highlighting the potential harms posed by targeted advertising to users' privacy (Zhou et al., 2017; Wang et al., 2019). These privacy concerns have fostered the development of tools and privacy controls designed to empower users to defend against tracking by advertising entities (Wang et al., 2018; Wang et al., 2019). Additionally, security researchers have exposed vulnerabilities in ad systems, demonstrating how they can be exploited to perpetrate fraud against online users (Zhou et al., 2017; Wang et al., 2019). For example, Oentaryo et al. (2018) outlines methods for detecting fraudulent ad publishers who generate deceptive ad links aimed at misleading users.

**Ad Blocking.** Prior research has extensively examined various aspects of online ad experiences, with particular attention to intrusive ads. In response, several tools and extensions have been developed for ad blocking, such as Adblock Plus (Brockman et al., 2016), ulBlock Origin (Kumar et al., 2017), and Ghostery (Brockman et al., 2016). These tools primarily rely on community-maintained blocking lists, like EasyList (for ads) (Kumar et al., 2017) and EasyPrivacy (for trackers) (Kumar et al., 2017), to block specific content URLs. Additionally, some studies have explored automated approaches, such as machine learning classifiers, to adapt to evolving ad and tracker characteristics (Zhou et al., 2017; Wang et al., 2019). These solutions aim to block all types of ads.

**Ad Compliance.** The issue of ad compliance has become increasingly prominent as it pertains to the quality of online ad experiences. Early on, governmental organizations such as the FTC established guidelines to promote greater transparency among websites and publishers within the digital advertising ecosystem (Zhou et al., 2017). These governmental frameworks have spurred the creation of self-regulatory bodies by ad publishers to ensure compliance with industry standards (Zhou et al., 2017; Wang et al., 2019). Various studies have evaluated publisher adherence to organizations such as NAI and DAA (Datta et al., 2018). More recently, regulations focused on user data, including GDPR and CCPA, have had a profound impact on the digital advertising landscape (Zhou et al., 2017; Wang et al., 2019). Research has examined the effects of these data protection regulations on advertising practices (Wang et al., 2018; Wang et al., 2019), with findings showing that despite such regulations, ad publishers continue to adapt their methods to collect user data for targeted advertising.

In addition to these regulatory frameworks, ad policies like the Acceptable Ads Standard (Brockman et al., 2016) and the Better Ads Standard (Brockman et al., 2016) have provided explicit guidance on ad practices, such as size, placement, and display rules, to minimize disruption to users while allowing site owners to earn through ad monetization. Researchers have studied the impact and privacy implications of these ad policies (Wang et al., 2018; Wang et al., 2019), and Yan et al. have quantitatively assessed the effectiveness of the Better Ads Standards (Zhou et al., 2017). To our knowledge, however, we are the first to conduct a detailed examination of compliance with the Acceptable Ads Standard by partner websites and publishers.

## 4. Methodology

This section outlines the methodology we deploy to crawl the webpages for identifying ad types. It discusses the technical details of our crawler, including the various configurations we use to discover ads. Lastly, it discusses the design of our heuristics for non-compliant ads that help us determine the compliance rates.

### Ad Filtering Configurations

We utilize the functionality of AdBlock Plus (Brockman et al., 2016) to block/allow ads on the webpage. The extension allows configuring various blocking and allow lists. For our approach, we develop three configurations that are important to the two-crawl process:

* \(}\): The first crawl does not use any list. The second crawl uses only EasyList (i.e., all ads are blocked). The difference gives us all ads. We will refer to this dataset of ads as \(_{}\), and use it to report the overall prevalence of ads observed on the web.
* \(}\): The first crawl uses EasyList and Exception list and the second crawl uses only EasyList. The difference in the elements recorded in the two crawls gives us acceptable ads only.1 We will refer to this dataset of Acceptable Ads as \(_{}\): and use it to report the frequency of forbidden ad types observed despite the Acceptable Ads Standard enforcement through an exception list. * \(}\): In this study, we also propose solutions to improve the Exception list. To test the impact of these changes, we modify the Exception list and implement the following configuration: The first crawl uses EasyList combined with the modified Exception list, while the second crawl uses EasyList. By comparing the elements captured in both crawls, we identify the acceptable ads displayed after filtering out non-compliant ads. We will refer to this dataset of acceptable ads as \(_{}\) and use it to demonstrate the effectiveness of our proposed changes in improving the Exception list that provides a greater degree of adherence to the Acceptable Ads Standard.

### Two-Crawl Detection Approach

Our configurations enable the tool to capture the required ads based on the configuration we use. Below, we outline the tool's workflow as it crawls webpages and collects telemetry data.

For each domain, the tool performs two consecutive crawls with a 10-second delay between them, ensuring minimal changes to the webpage within this time frame (Kumar et al., 2017). During each crawl, we inject a script into the webpage's head using mitmproxy (Kumar et al., 2017), with the defer attribute set to run before the DOMContentLoaded event. This script scans the page and lists all elements, including media content like images, videos, and SVG files. Once all resources (scripts, images, subdocuments, etc.) are loaded (triggering Load event), the script waits 10 seconds to ensure rendering completion before traversing the DOM. If the Load event doesn't trigger, the tool stays on the page for up to 60 seconds before terminating. If loading fails, we retry the domain once before removing it from analysis.

Since frames are isolated by same-origin-policy, we use mit tmproxy to modify Cross-Origin Resource Sharing (CORS) flags and configure the browser to disable web security. This ensures the script can access all resources loaded in the browser.

The script captures details such as CSS properties, class names, XPaths, optimized XPaths, and other attributes of each element. It is important to note that ad resources are typically placed in well-defined sections of the DOM, and repeated visits to the webpage will render ads in the same locations. Ad-blocking tools utilize this deterministic behavior to hide the DIV elements assigned to ad networks. We also leverage this determinism to identify ads wherever they appear on the rendered webpage. By comparing the lists of web elements generated from the two crawls (using XPaths), we can identify the content blocked by AdBlock Plus and determine which elements were detected as ads (as shown in Figure 2).

### Detection of Non-Compliant Ad Categories

We note that Better Ad Standards and Acceptable Ads Standard both block some common ad format (e.g. popup, popunders, autoplay media, interstitial and overlay). Therefore, we take inspiration from the work of Yan et al. (that has studied the ad types not allowed under Better Ads Standard) (XPaths) to design heuristics for forbidden ad types in the Acceptable Ads Standard. We define heuristics for six specific types of non-compliant ads based on their CSS properties. These specific formats were chosen due to their clear violation definitions and detectability, as demonstrated by existing work (XPaths).

These include:

* **Over-Sized Image Ads**: While The Acceptable Ads Standard prohibits 'Generally Oversized Image' ads but does not specify exact size limitations. For our analysis, we consider ads occupying more than 80% of the screen's width or height blatantly oversized.
* **Autoplasy Media**: Media ads are identified if they have the autoplasy attribute enabled or are automatically preloaded. This applies to both videos and images
* **Overlay Ads**: There are ads with sticky ads that are placed on the top or at the edge of the viewport and have fixed or absolute positioning
* **Popup Ads**: Popups are detected by their high z-index combined with fixed or absolute positioning
* **Popunder Ads**: Popunders are similar to popups but are positioned beneath content, indicated by a negative z-index
* **Interstitial Ads**: These are full-screen ads detected if they cover more than 75% of the viewport and have fixed or absolute positioning

These rules enable the systematic identification of different types of non-compliant ads across crawled domains.

## 5. Data Collection

To collect data for measuring online advertisements and their compliance with Acceptable Ads Standard, we developed a specialized tool, the details for which have been described in Section 4.2. This section focuses on the process and setup used for data collection, including the selection of websites and the technical infrastructure used for crawling.

### Website Selection

We aimed to analyze advertisements on a broad and diverse set of domains. To achieve this, we chose to crawl websites that are in the intersection of two specific lists: the Tranco top 100K websites (Krishna et al., 2016) and the first-party domains found in the Acceptable Ads Standard's Exception list (Brock et al., 2016). The Tranco list is a frequently updated ranking of the most popular websites on the internet, ensuring that our dataset reflects domains with significant user traffic. The exception list, on the other hand, contains rules for allowing ads on certain partner domains, provided they comply with Acceptable Ads Standard.

Table 1 shows the number of partner domains and their corresponding rank divisions. By selecting domains present in both the Tranco top 100K and the acceptable and exception list, we ensured that our dataset included high-traffic websites that serve ads and are subject to compliance regulations. After excluding inactive or publicly inaccessible domains, we were left with a set of 9,463 domains for our analysis.

### Crawling Setup

The data collection process was conducted on a server with 32 cores and 64 GB of RAM, enabling us to run 30 parallel crawling processes to expedite the data collection workflow. Each crawling process was tasked with visiting the selected domains and capturing the ad content displayed on the webpages. For automation, we used Puppeeteer (Puppeeters et al., 2016), a Node.js library that provides a high-level API for controlling headless browsers. To avoid detection by bot-detection algorithms, we employed Puppeeter's stealth plugin (Puppeeters et al., 2016). Additionally, we incorporated randomization in the scrolling behavior during each crawl to mimic human interaction patterns (e.g., each iteration of scroll-up and scroll-down had a random factor of movement), further evading potential bot detection.

### Crawling Process

We restricted our crawling to the landing page of each domain. We detect failure to load a webpage by inspecting mitdump file generated by the proxy. The dump file contains network exchange records and can be used to determine if the site server failed to respond. In that case, we simply reattempt one more time.

The browser remained on the page until the Load event is triggered, signaling that the initial content had fully loaded. To ensure all dynamically-rendered content, including ads, was captured, we allowed an additional 10 seconds of idle time. Additionally, we took screenshots of the web interaction before closing the browser, which were later used to report the violations.

  
**Rank Division** & **Domain Count** \\ 
1-1,000 & 326 \\
1,001-10,000 & 1,791 \\
10,001-100,000 & 7,883 \\   

Table 1. Number of partner domains per rank division analyzed in our measurement.

Figure 2. Two-crawl ad detection. **_Mi_**proxy** injects a scanner script that traverses DOM object. Difference of the two crawl reveals ads.

Crawling 9,463 domains in our setup took approximately two days to complete. The data was collected in the United States to ensure consistency in the results and avoid regional differences in ad serving practices. By utilizing parallel processes and a carefully curated domain set, our crawling infrastructure enabled efficient and thorough data collection, allowing us to evaluate ad compliance across high-traffic websites effectively.

### Ethical Considerations

In our study, we are acutely aware of the ethical concerns surrounding web measurement and data collection. Our method of web crawling involves injecting a telemetry script into the web page, but it is essential to emphasize that this process does not alter or manipulate the webpage in any way. We do not generate additional requests to website servers; instead, our telemetry consists of inspecting web elements present on the page. The functionalities of our approach are akin to what can be achieved using browser developer tools, such as Chrome Dev tools. To minimize our impact, we remain on each site for a duration of no more than 60 seconds before closing the browser window. This approach ensures that our activities do not impose any load on the website's server, effectively preventing the risk of DDOS attacks or similar disruptions.

## 6. Prevalence of Violating Ads

This section will discuss our analysis on non-compliant ads found in our datasets, thereby answering **RQ1**: What is the prevalence of non-compliant advertisements on partner websites exempted under the Acceptable Ads Standard?

### Effectiveness of Acceptable Ads Standard

As a first step towards understanding the prevalence of non-compliant ads on the web, we selected 10K domains that are common in Tranco's 100K domain set and Acceptable Ads Standard's Exception List. The latter list provides exception filter rules enforced on specific domains to unblock ads that are supposed to be compliant with the stated acceptable ad standard.

Our analysis focused on six specific categories of non-compliant ads, derived from the Acceptable Ads Standard. These categories, along with the number of instances detected across all domains, are summarized in Table 2. We highlight the frequencies found in the dataset \(_{}\). For comparison, we also show the number of ads detected in \(_{}\). The contrast of the two configuration shows the prevalence of ads not conforming to the Acceptable Ads Standard. For instance, we observed that the clean browser profile encounter 4.86 times more overlay ads than a browser profile with adblocking functionality. A Chi-Squared test (Yang et al., 2019) comparing ad type distributions between the configurations with and without Adblock Plus resulted in a highly significant difference (\(y^{2}=1907.24\), \(p<0.0001\)), indicating the two configurations have statistically different ad type distributions. Specifically, ad types such as oversized images, overlay ads, and interstitial ads show substantial differences, confirming that Adblock Plus effectively blocks or reduces certain types of ads more than others.

While the EasyList in combination with the Exception list is effective in significantly reducing intrusive/disruptive ads, it does not achieve complete blocking of such non-conforming ads. Our study found that 9.91% of the websites in our dataset displayed at least one violating ad among those deemed acceptable. In an ideal scenario, with full adherence to the Acceptable Ads Standard, \(_{}\) configuration should block all ads that violate these guidelines. However, our results suggest that the Exception list fails to fully enforce compliance, allowing ads to be displayed that do not meet the size and type restrictions it promotes.

**Finding 1:**_Despite the effectiveness of EasyList in combination with the Exception list at reducing non-compliant ads significantly, we found violating ads to be present in 9.91% of the domains that were partners in Acceptable Ads Standard's exception list._

Among the 9.91% of domains displaying violating ads, we analyzed the breakdown of the types of violations. Figure 3 shows the distribution of these categories, with each data peak representing the frequency of a particular ad type observed on a domain. The most common violations were Oversized Image Ads and Overlay Ads. Notably, certain domains exhibited higher frequencies of violations. For instance, aszgeniasto.pl displayed 103 Overlay Ads, despite filtering under the Acceptable Ads Standard. This domain features continuous scrolling that feeds in overlay and oversized ads, trigger the heuristics to log all the elements found in Section 4.3. Another high-ranking domain, express.co.uk, displayed oversized ads below the primary content, violating size limitations. Autoplasy Ads were the least frequent type of violation, though they were observed on some high-traffic sites, such as gsnarena.com. Appendix A contains example screenshots that highlight some of these violations.

**Finding 2:**_Oversized Image Ads and Overlay Ads were observed to be the most common non-compliant ads in our dataset._

### Non-compliant Ad Publishers

We also assess the contribution of various ad publishers who display violating ads in \(_{}\). As discussed in Section 4.2, our crawl gathers CSS properties of ad elements. For more complex cases, we also navigate through parent nodes, collecting class names and other CSS selectors if available. This method provides a rich metadata inventory for each ad, which can be used to trace the ad publishers that displays the ad.

Additionally, we match this data with filter rules from the exception list to identify the publisher responsible for showing the ad. Figure 4 shows an example of a metadata report generated

  
**Ad Types** & \(_{}\) & \(_{}\) \\  Oversized Ads & 3,410 & 22,878 \\ Autoplasy Media & 20 & 297 \\ Overlay Ads & 3,865 & 23,891 \\ Interstitial Ads & 121 & 3,503 \\ Popup Ads & 465 & 2,529 \\ Popunder Ads & 29 & 358 \\ 
**Total** & **7,910** & **53,456** \\   

Table 2. Counts of forbidden ad types found using \(_{}\) and \(_{}\).

after crawling gsmarena.com. It highlights metadata from an overlay ad, which violates the Acceptable Ads Standard, published by brwsrfrm.com. The filter_rule refers to the exception list rule that allows this ad. In this instance, any ad element within a DIV with the classname ad_label is permitted, even if it violates other properties, such as triggering sticky or overlay behaviors.

From this example, we can conclude that brwsrfrm.com is an ad publisher associated with a non-compliant ad instance. Our inventory of non-compliant ads identified during our crawling revealed multiple other publishers displaying invasive ads in a similar manner. To determine which ad publishers frequently displayed these violations, we utilized our metadata inventory to identify the parent companies that own these networks. First, we extract the URL of the ad element itself. If the URL is absent, we fetch the container frame's URL. Then, we extract the tld+1 (Top-level domain + 1) out of the URL. Lastly, we match these domains with entity and services domains found in the list of ad companies, along with the respective services under them, curated by Disconnect (Dixon et al., 2018). Figure 5 illustrates the share of ad publishers contributing to the prevalence of non-compliant ads across the three ranges of domain ranks we crawled. The top five ad publishing companies displaying violating ads are Google, Amazon, Smoads.com, Outbrain, and Blockthrough. This analysis underscores the role of various ad networks in perpetuating non-compliant advertising practices.

Figure 4. Example of metadata of an Overlay ad found on gsmarena.com

Figure 5. Different ad networksâ€™ role in the distribution of non-compliant ads.

Figure 3. Distribution of violating ads under Acceptable Ads Standard across the different ranked websites. Violations appear across all ranks.

### Temporal Consistency of Violations

The presence and nature of ads on the web are subject to significant fluctuations due to various dynamic factors. Live global events, time of day, regional politics, and evolving user interests all influence the ads displayed. Additionally, ad publishers engage in real-time bidding (Zhu et al., 2017), competing for ad space, which can further impact what users see at any given moment. Due to these variables, performing a second round of crawl for all the domains is crucial for assessing the consistency of ad violations. This approach ensures a more accurate evaluation of compliance over time, accounting for the changing landscape of digital advertising.

To evaluate consistency of violating ads, we have two rounds of crawl conducted on September 7, 2024 (Crawl 1) and October 7, 2024 (Crawl 2) using \(}\) configuration. We compare the proportions of various ad types found to be in violation. It was observed that these proportions of violating ad types in both crawls were quite similar. For instance, oversized images represented 43.11% (3,410) of violations in Crawl 1 and 43.61% (3,203) in Crawl 2. Overlay ads made up 48.86% (3,865) of violations in Crawl 1, while accounting for 48.38% (3,593) in Crawl 2. The differences across other ad types were similarly minor. Additional details on these discrepancies can be found in Table 3.

A Chi-squared test was conducted to assess the statistical significance of differences in ad distributions, yielding a statistic of \(^{2}=1.9432\) with 5 degrees of freedom 2 (\(p=0.8569\)), indicating no significant difference. The expected and observed frequencies for each ad type closely aligned, suggesting consistency between the two crawls. Additionally, the Kullback-Leibler divergence (Kullback and Leibler, 1959) of 0.000259 further supports minimal divergence, reinforcing that the distribution of violating ad types remained consistent between the two time periods.

**Finding 4**: _The results of the temporal analysis indicate no significant differences in the distribution of violating ad types between the two crawls_

## 7. Improving Acceptable Ads Standard

The goal of this section is to identify the underlying reasons why non-compliant ads are displayed and discover ways to refine the Exception list by eliminating problematic rules that allow these ads to interfere with the user experience. We accomplish this by parsing the list and analyzing the telemetry data collected during our crawl of the offending ads.

### Primary Causes for Non Compliant Ads

We provide the primary causes that lead to the display of non-compliant ads, thereby addressing **RQ2**: What limitations and flaws currently exist in the Exception list? To answer this, we inspect the potential sources of violating ads in our dataset.

**Over-Permissive Rule**. We parse the Exception list and find rules that match with the violating domains in \(}\). For certain domains, we identified that '$document unblocking rules were being enforced. These rules effectively creating a complete exception for the specified domain by overriding any adblocking rule on the entire site (Brockman et al., 2017). Among the 9.91% of domains displaying non-compliant ads, 52 of them were found to have this '$document allowlisting rule in place, which represents 5.34% of the non-compliant domains. This high prevalence indicates a significant flaw in the current enforcement mechanisms, as such unrestricted allowing can lead to the display of invasive ads.

We contend that such rules contradict the intent of the Acceptable Ads Standard, which aims to strike a balance between user experience and monetization.

**Finding 5**: _Among the 9.91% of domains exhibiting non-compliant ads, 52 domains utilized the overly permissive document allowlisting rule._

**Offending Element Unblocking Rule.** We also identify the container elements where non-compliant ads are rendered. These containers are detected and unblocked by their \(\) using Exception list rules. Figure 4 shows an example of the metadata of violating ads, compiled during and after the crawl. This metadata includes the class and tag type of the parent node where the ad is embedded. From both crawls (09/07 and 10/07), we observe that these parent nodes consistently display the same violating ad format, regardless of the ad publisher, across multiple site visits. To mitigate the impact of violating elements, we gather all relevant rules that correspond to these elements in our dataset. 6 highlights some examples of rules within the Exception list that unblock offloading content.

### Improving Compliance

In this section, we seek to answer **RQ3**: Can we improve the Exception list to enhance ad compliance rates. Based on our observation from Section 7.1, we identify all rules in the Exception list that are either overly permissive or that allow exceptions for parent containers displaying violating ads consistently. It should be noted

Figure 6. Examples of exception rules that are removed from the Exception list.

 
**Ad Type** & **097/2024** & **107/2024** & **Change (\%)** \\  Oversized Image & 3,410 & 3,203 & 6.07\(\) \\ Autoplay Media & 20 & 19 & 5.0\(\) \\ Overlay Ads & 3,865 & 3,593 & 7.03\(\) \\ Interstitial Ads & 121 & 105 & 13.2\(\) \\ Popup Ads & 465 & 440 & 5.37\(\) \\ Popunder Ads & 29 & 28 & 3.44\(\) \\  

Table 3. Counts of non-compliant ads using \(}\) at two distinct time stamps.

[MISSING_PAGE_FAIL:8]

[MISSING_PAGE_FAIL:9]

[MISSING_PAGE_EMPTY:10]

Figure 8. Overlay Image Ad from nasemisato.pl

Figure 9. Popunder Ad from Amazon.ca