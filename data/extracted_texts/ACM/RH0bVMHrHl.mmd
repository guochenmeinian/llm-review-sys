# Mirror Gradient: Towards Robust Multimodal Recommender Systems via Exploring Flat Local Minima

Anonymous Author(s)

###### Abstract.

Multimodal recommender systems utilize various types of information to model user preferences and item features, helping users discover items aligned with their interests. The integration of multimodal information mitigates the inherent challenges in recommender systems, e.g., the data sparsity problem and cold-start issues. However, it simultaneously magnifies certain risks from multimodal information inputs, such as information adjustment risk and inherent noise risk. These risks pose crucial challenges to the robustness of recommendation models. In this paper, we analyze multimodal recommender systems from the novel perspective of _flat local minima_ and propose a concise yet effective gradient strategy called Mirror Gradient (MG). This strategy can implicitly enhance the model's robustness during the optimization process, mitigating instability risks arising from multimodal information inputs. We also provide strong theoretical evidence and conduct extensive empirical experiments to show the superiority of MG across various multimodal recommendation models and benchmarks. Furthermore, we find that the proposed MG can complement existing robust training methods and be easily extended to diverse advanced recommendation models, making it a promising new and fundamental paradigm for training multimodal recommender systems.

Recommender systems, Multimodal, Flat local minima, Robust +
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

+
Footnote †: ccs: Computing methodologies Artificial intelligence

## 1. Introduction

**Relevance to the Web and to the track.** Recommender systems play a crucial role in helping users navigate the wealth of choices on the web and discover suitable items or online services. In fact, the integration of deep learning techniques into recommender systems has become widespread (Hardt et al., 2016; Liu et al., 2016; Wang et al., 2017; Wang et al., 2017). These techniques leverage historical user-item interactions to model user preferences, thereby facilitating the personalized recommendation of items. In recent years, with the emergence of rich multimodal content information encompassing texts, images, and videos, multimodal recommender systems (Wang et al., 2017; Wang et al., 2017) alleviate challenges (Wang et al., 2017) such as data sparsity and cold start. However, incorporating multimodal information into recommender systems also increases some inevitable risks about the input distribution shift.

The first risk is **inherent noise risk** which always appears in the training phase. Some previous works (Wang et al., 2017; Wang et al., 2017) show that the performance of recommender systems encounters substantial challenges when confronted with input containing some noise in multimodal information. These noises are intrinsic, such as subpar image quality of items or the presence of a significant number of irrelevant or error information in items' features. These factors contribute to inherent noise introduced to the model's input, and the introduction of multimodal data in multimodal recommender systems makes mitigating inherent noise risk more challenging. Another risk is **information adjustment risk**. After the recommender system has been trained based on multimodal data, it is well-known that multimodal data is prone to frequent adjustments. For example, merchants need to keep pace with trends or promotional activities to tailor keywords for items, and the descriptive images of items must be adjusted in line with iterative updates. This implies that in practical scenarios, the multimodal information within recommender systems often undergoes frequent modifications. A straightforward solution to address this risk is to update the model with the latest dataset, but as the volume of data increases, the cost of iterating the model significantly escalates, especially in multimodal recommender systems. In summary, these two risks pose a significant challenge (Wang et al., 2017; Wang et al., 2017; Wang et al., 2017; Wang et al., 2017) to multimodal recommender systems. Fig. 1 is **an e-commerce case** to illustrate the effect of the risks. On one hand, during the training phase of recommender systems, inherent noise exists in multimodal features such as the text, which is intrinsic and has a potentially negative effect in the inference phase. On the other hand, during the inference phase of recommender systems, the multimodal feature as shown in Fig. 1 of the bedysuit is edited due to promotional activities and the emphasis on the

Figure 1. An illustrative example of multimodal risks. Merchants add popular tags (e.g., “ins style”) and broad keywords (e.g., “suit”) to the text of the bedysuit to increase the likelihood of the item being recommended. At the same time, merchants dynamically change the item’s visual features in real-time due to Women’s Day marketing campaigns and the emphasis on the superiority of the item’s material. These actions make it difficult for the recommender system to accurately determine the target user for the current item, leading to incorrect recommendations for young girls.

item's material. These two risks confuse the recommender system resulting in incorrect recommendations, which will be explicitly and quantitatively assessed in Section 6.

To mitigate the aforementioned risks of information adjustment and inherent noise, the necessity for building a more robust multimodal recommender system becomes apparent. For enhancing the robustness, prior efforts (Bang et al., 2017; Li et al., 2017) have chiefly employed adversarial training techniques. These methods improve the robustness of multimodal recommender systems by explicitly countering noise at input during the training phase. Different from them, in this paper, we first rethink the robustness of multimodal recommender systems from the loss landscape perspective by considering the _flat local minima_ of multimodal recommendation models. Then, we propose a concise yet effective training strategy named Mirror Gradient (MG) for implicitly improving system robustness.

Specifically, we can first present an intuitive insight into why a recommender system should consider the flat local minima, which are located in large weight space regions with very similar low loss values (Li et al., 2017). In Fig. 2, \(_{o}\) represents the original loss landscape, which is associated with the model's parameters, architecture, data distribution, etc. When the system's inputs face shifts in data distribution due to risks like information adjustment or inherent noise, \(_{o}\) (transparent surface) also shifts to \(_{s}\) (opaque surface). If the model's parameters are optimized to a sharp local minimum \(_{b}\), the error caused by this shift \(|_{s}(_{b})-_{0}(_{b})|\) may be significantly larger than \(|_{s}(_{a})-_{0}(_{a})|\) of flat local minima \(_{a}\). This indicates that the system is not robust while the parameters are in sharp local minima. Therefore, we should strive to guide the learnable parameters of a multimodal recommender system towards flat local minima during training to enhance the model's robustness against potential risks of input distribution shifts.

To this end, we propose a concise gradient strategy MG that inverses the gradient signs appropriately during training to make the multimodal recommendation models approach flat local minima easier compared to models with normal training. Additionally, we conduct extensive experiments and analysis to validate the effectiveness of MG across various datasets and systems empirically. To elaborate our MG strategy, we first model it formally and then analyze how it improves the model's robustness by driving the parameters towards flat local minima implicitly from a theoretical perspective. The visualization method from Li et al. (2017) supports our theoretical analysis and shows that MG indeed can help the model achieve flatter minima. Besides, we also empirically verify that MG is versatile, as it is compatible with most optimizers and other adversarial training-based robust recommendation methods. In summary, our contributions are threefold:

* We analyze the robustness of multimodal recommender systems from the perspective of flat local minima.
* From the perspective of flat local minima, we propose Mirror Gradient (MG), a concise yet effective gradient strategy that guides recommender system models toward flat local minima, enhancing model robustness. We also provide theoretical evidence for its effectiveness.
* Extensive experiments demonstrate the efficacy and versatility of MG. We also discuss the limitations of MG.

## 2. Related Works

**Multimodal Recommender Systems.** Traditional recommender systems (Li et al., 2017; Li et al., 2017; Li et al., 2017) model the interaction between users and items, relying on extensive user-item interaction data to ensure accurate recommendations. In the presence of diverse multimodal information, multimodal recommender systems (Li et al., 2017; Li et al., 2017; Li et al., 2017) leverage supplementary multimodal information to complement historical user-item interactions, mitigating challenges like data sparsity (Zhu et al., 2018) and cold start (Li et al., 2017; Li et al., 2017) in the recommendation. Early researchers often employed collaborative filter (Li et al., 2017; Li et al., 2017) or matrix factorization (Li et al., 2017) for multimodal recommendation modeling. Recently, many works (Li et al., 2017; Li et al., 2017) employ graph neural networks for multimodal recommender systems, with self-supervised learning (Li et al., 2017; Li et al., 2017) also gaining traction in this domain.

**Robust Recommender Systems.** Recent studies (Li et al., 2017; Li et al., 2017) have shed light on the vulnerability of recommender systems, highlighting how disturbances introduced by noise can significantly undermine the accuracy of recommendations. In pursuit of bolstering the robustness of recommender systems, a multitude of efforts (Li et al., 2017; Li et al., 2017; Li et al., 2017; Li et al., 2017) have focused on adversarial training. This approach, which operates under the premise that each instance may serve as a potential target for attacks (Li et al., 2017), introduces controlled perturbations to either the input data or model parameters to enhance robustness. However, most existing studies have overlooked the potential risks arising from information adjustment in multimodal recommender systems.

**Flat Local Minima.** Flat local minima have been consistently linked to the favorable generalization capabilities of deep neural networks (Li et al., 2017; Li et al., 2017; Li et al., 2017; Li et al., 2017; Li et al., 2017). In the wake of this insight, numerous researchers have surfaced, exemplified by works such as Du

Figure 2. Illustration of flat local minima. When the distribution of the inputs shifts, for example, facing the risks of inherent noise and information adjustment, the loss landscape \(_{o}\) of the recommender system also shifts (to \(_{s}\)) accordingly. The parameters \(_{a}\) located in flat local minima are more robust compared to \(_{b}\) in sharp local minima.

et al. (2017), Zhao et al. (2019), Zhuang et al. (2019), which strive to enhance model performance through exploring flat local minima. Specifically, Foret et al. (2010) introduces a novel approach named Sharpness-Aware Optimization (SAM), wherein the optimization process hinges on addressing a mini-max problem to achieve an optimal sharpness value. Kwon et al. (2018), on the other hand, proposes a scale-invariant variant of SAM, named ASAM, bolstered by an adaptive radius mechanism aimed at augmenting training stability. Moreover, Mi et al. (2019) innovatively delve into the realm of sparse perturbation with their SSAM (Sparse Sharpness-Aware Minima) approach, strategically focusing on perturbations that encapsulate the most critical yet sparse dimensions of the problem space.

## 3. Preliminary

### Multimodal Recommender Systems.

Considering a set of users \(=\{u_{1},u_{2},...,u_{|}\}\), and a set of items \(=\{i_{1},i_{2},...,i_{|}\}\), each user \(u\) is associated with an item set \(_{u}\) about which \(u\) has expressed explicit positive feedback. Besides, each item \(i\) has multimodal information denoted by visual features \(v_{i}\) and textual features \(t_{i}\) in this paper. Then given a multimodal recommendation model denoted as \(()\),

\[y_{u,i}=(u,i_{v},t_{i},_{u}), \]

where \(\) represents the model parameters of \(()\), and score \(y_{u,i}\) signifies the preference of user \(u\) towards item \(i\). A higher score suggests that item \(i\) is more suitable to be recommended to user \(u\).

**Loss Function of Recommender Systems.** Most works (Grover et al., 2010; Zhao et al., 2019) optimize the model parameters \(\) of multimodal recommender systems using Bayesian personalized ranking loss (Zhuang et al., 2019). This optimization seeks to ensure that \(y_{u,i}\), where \(i_{u}\), is greater than \(y_{u,i^{}}\) when \(i^{{}^{}}_{u}\), thus promoting positive interactions while discouraging negatives ones. Additionally, some recommender systems introduce supplementary losses (Zhuang et al., 2019; Zhao et al., 2019) to enhance their performance. We adopt the unified notation \(L_{}()\) to represent those losses.

## 4. Methodology

In this section, we first elaborate on the algorithm of the proposed MG. Then, we introduce the theoretical insight of MG.

### Mirror Gradient

MG is a concise and easily implementable approach that enhances the gradient of the model during the optimization process of recommender systems. This enhancement is equivalent to adding a regularization term to improve the system's robustness on input. The proposed MG consists of two phases in each training epoch: Normal Training and Mirror Training.

During Normal Training, the conventional gradient descent is applied to the loss function \(L_{}()\) with the current learnable parameters \(_{t-1}\), as follows:

\[_{t}=_{t-1}-_{}L_{}(_{t-1}), \]

where \(\) represents the learning rate. As shown in the Algorithm 1, we use an interval \(\) to control the effect of MG on each training epoch. After updating per \(-1\) iterations using Eq. (2), we employ the Mirror Training strategy to update the parameter \(_{t-1}\) as follows:

\[\{ _{t}^{}&=_{t-1}- _{1}_{}L_{}(_{t-1}),\\ _{t}&=_{t}^{}+_{2}_{ }L_{}(_{t}).. \]

Here, in order to control the relative size of updates introduced by mirror training, we introduce two positive scaling coefficients, \(_{1}\) and \(_{2}\), with \(_{1}>_{2}\).

Although the MG we proposed is highly simple, it possesses a strong theoretical insight and remarkable versatility. This enables consistent performance improvements across a wide array of experimental scenarios. Furthermore, in Section 6, we demonstrate the compatibility of MG with various optimizers and existing robust recommender system techniques. Moreover, it can achieve superior performance compared to some conventional optimization strategies about flat local minima.

### Theoretical Insight of MG

In this part, we introduce Lemma 4.1 and Theorem 4.2 which can help us analyze how MG helps the model's parameters tend towards flat local minima from a theoretical perspective, thereby enhancing the input robustness of the recommender system.

Lemma 4.1.(Zhuang et al., 2019; Zhao et al., 2019) Consider a neural network \(f(x)\) with \(L\) layers and learnable parameters \(\). \(h_{i},1 i L\), denotes the feature map from \(i\) to layer. For any scalar function \(g\) of \(h_{L}\), we have

\[\|_{}g(x)\|_{2}^{2}_{j=1}^{L}O(\|_{2}^{2}}{ \|_{}x_{h}\|_{2}^{2}})\|_{}g_{}(x)\|_{2}^{2}. \]

Theorem 4.2. Mirror Training in Eq. (3) is equal to introducing an implicit regularization term \(\|_{}L_{}()\|_{2}^{2}\) to the original optimization objective \(L_{}()\).

Proof.: In Mirror Training, we have

\[_{t} =_{t}^{}+_{2}_{}L_{} (_{t}^{})\] \[=_{t-1}-_{1}_{}L_{}(_{t -1})\] \[+_{2}_{}L_{}(_{t-1}- _{1}_{}L_{}(_{t-1})). \]Next, since \(\) is small, we can use Taylor expansion for estimating \(_{}L_{}(_{t-1}-_{1}_{}L_{} (_{t-1}))\), and we have

\[_{t} _{t-1}-_{1}_{}L_{}( _{t-1})+_{2}_{}L_{}(_{t-1})\] \[-_{1}_{2}^{2}_{}^{2}L_{} (_{t-1})^{}_{}L_{}(_{t-1})\] \[=_{t-1}-(_{1}-_{2})_{}L_{} (_{t-1})\] \[-_{1}_{2}^{2}_{} \|_{}L_{}(_{t-1})\|_{2}^{2}. \]

Therefore, from Eq. (6), we can find that the equivalent objective function for Mirror Training \(L_{M}\) is

\[L_{M}=(_{1}-_{2})}()}_{} _{1}_{2}}_{}L_{}(_{t-1})\|_{2}^{2}}_{} \]

where \(_{1}_{2}>0\) and \(_{1}-_{2}>0\). 

The essence of MG, as revealed in Theorem 4.2, lies in the addition of a regularization term concerning gradient magnitude to the original objective function \(L_{}()\) implicitly. It's worth noting that the magnitude of gradients near flat local minima is quite small. And since \(_{1}_{2}>0\), Eq. (6) requires that the norm of gradient \(\|_{}L_{}()\|_{2}^{2}\) should be sufficiently small, i.e., MG will lead the model's parameters towards flatter minima. Furthermore, from Lemma 4.1 and Eq.(7), let the scalar function is \(L_{}\) in recommender system, we have

\[L_{M} _{1}_{2}\|_{}L_{}( _{t-1})\|_{2}^{2}\] \[_{1}_{2}_{j=1}^{L}O( \|_{2}^{2}}{\|_{x}h_{i}\|_{2}^{2}})L_{ }\|_{2}^{2}}_{}. \]

In general, \((1+\|h_{i}\|_{2}^{2})/(\|_{x}h_{i}\|_{2}^{2})\) is bounded and positive. Taking BM3 on the Baby as an example, its value is around 96.16 with the well-trained system. Therefore, from Eq. (8) and Eq. (7), we can infer that MG also aims to minimize the impact of inputs on the loss, \(\|_{x}L_{}\|_{2}^{2}\), while enhancing the model's robustness against input perturbations.

Furthermore, although Eq. (7) reveals that our proposed MG is equivalent to adding a regularization term \(\|_{}L_{}(_{t-1})\|_{2}^{2}\) during the optimization process of recommender systems, we do not recommend directly including this term in the loss function. On one hand, computing this term requires the prior calculation of the gradient \(_{}L_{}(_{t-1})\), implying additional computational overhead during inference and not easy to implement. On the other hand, this kind of explicit loss term is not conducive to optimization and generally results in relatively poor performance (Gulrajani et al., 2017). In fact, our proposed MG is an implicit optimization of the additional regularization term shown in Eq. (7). It is also straightforward to implement. Hence, MG possesses greater practical applicability and potential.

## 5. Experiments

In this section, we present our experimental setup and empirical results.

### Experimental Settings

**Datasets.** The dataset statistics have been summarized in Table 1. We primarily employ four multimodal datasets from Amazon (Xiong et al., 2017), including Baby, Sports, Clothing, and Electronics. These datasets comprise textual and visual features in the form of item descriptions and images. Our data preprocessing methodology follows the approach outlined in Zhou et al. (2017). Furthermore, we utilize the dataset Pinterest to assess the compatibility of Mirror Gradient with adversarial training methods in alignment with the official implementation of the adversarial training baseline AMR (Xiong et al., 2017).

**Metrics.** For the evaluation of recommendation performance, we pay attention to top-5 accuracy as recommendations in the top positions of rank lists are more important (Xiong et al., 2017), and adopt four widely used metrics (Zhou et al., 2017; Zhou et al., 2017; Zhou et al., 2017; Zhang et al., 2017) including recall (REC), precision (PREC), mean average precision (MAP), and normalized discounted cumulative gain (NDCG). These four evaluation metrics are chosen because they each focus on different crucial aspects. REC measures whether the system captures a user's potential areas of interest, PREC gauges the accuracy of recommendations, MAP focuses on the average accuracy of rankings, and NDCG emphasizes the quality

   Dataset & \# Users & \# Items & \# Interactions & Sparsity (Xiong et al., 2017) \\  Pinterest & 3,226 & 4,998 & 9,844 & 99.94\% (Xiong et al., 2017) \\ Baby & 19,445 & 7,050 & 160,792 & 99.88\% (Xiong et al., 2017) \\ Sports & 35,598 & 18,357 & 296,337 & 99.95\% (Xiong et al., 2017) \\ Clothing & 39,387 & 23,033 & 237,488 & 99.97\% (Xiong et al., 2017) \\ Electronics & 192,403 & 63,001 & 1,689,188 & 99.99\% (Xiong et al., 2017) \\   

Table 1. Statistics of datasets. These datasets comprise textual and visual features in the form of item descriptions and images.

   Model & REC & PREC & MAP & NDCG (Xiong et al., 2017) \\  VBPR & 0.0182 & 0.0042 & 0.0098 & 0.0122 \\ VBPR + MG & 0.0203 & 0.0046 & 0.0110 & 0.0136 \\  Improv. & 11.54\% & 9.52\% & 12.24\% & 11.48\% (Xiong et al., 2017) \\   MMGCN & 0.0140 & 0.0033 & 0.0075 & 0.0094 \\ MMGCN + MG & 0.0157 & 0.0036 & 0.0084 & 0.0106 \\  Improv. & 12.14\% & 9.09\% & 12.00\% & 12.77\% (Xiong et al., 2017) \\  GCNN & 0.0226 & 0.0051 & 0.0126 & 0.0155 \\ GRCN + MG & 0.0250 & 0.0057 & 0.0139 & 0.0171 \\  Improv. & 10.62\% & 11.76\% & 10.32\% & 10.32\% (Xiong et al., 2017) \\  DualGNN & 0.0238 & 0.0054 & 0.0132 & 0.0162 \\ DualGNN + MG & 0.0249 & 0.0056 & 0.0139 & 0.0170 \\ Improv. & 4.62\% & 3.70\% & 5.30\% & 4.94\% (Xiong et al., 2017) \\   BM3 & 0.0280 & 0.0062 & 0.0157 & 0.0192 \\ BM3 + MG & 0.0285 & 0.0063 & 0.0159 & 0.0195 \\ Improv. & 1.79\% & 1.61\% & 1.27\% & 1.56\% (Xiong et al., 2017) \\  FREEDOM & 0.0252 & 0.0056 & 0.0139 & 0.0171 \\ FREEDOM + MG & 0.0260 & 0.0058 & 0.0144 & 0.0176 \\ Improv. & 3.17\% & 3.57\% & 3.60\% & 2.92\% (Xiong et al., 2017) \\    & **7.31\%** & **6.54\%** & **7.46\%** & **7.33\%** \\   

Table 2. Top-5 recommendation performance of baselines with or without MG on Electronics. ‘Improv.’ indicates the relative enhancement of MG compared to the baseline. ‘Avg. Improv.’ represents the average improvement.

of rankings. These metrics complement each other and collectively provide a comprehensive evaluation, aiding in a holistic understanding of the recommender system's performance. Additionally, when comparing against the adversarial training method AMR (Shi et al., 2018), we apply the hits ratio (HR) in alignment with the evaluation approach used in the original AMR paper. The choice of HR serves the purpose of maintaining consistency and comparability with established benchmarks, allowing for a direct comparison of our results with those reported in the paper. All the above-cited metrics range from 0 to 1, the closer to 1 the better.
* **Baselines.** We extensively examine MG's performance across a variety of multimodal recommendation models, encompassing matrix factorization (VBPR (Verbik et al., 2015), graph neural networks (MMGCN (Shi et al., 2018), GRCN (Shi et al., 2018), DualGNN (Shi et al., 2018), FREEDOM (Shi et al., 2018), DRAGON (Shi et al., 2018)), self-supervised learning (SLMRec (Shi et al., 2018), BM3 (Shi et al., 2018)), as well as non-multimodal models(LayerGCN (Shi et al., 2018), SelfCF (Shi et al., 2018)). We utilize AMR (Shi et al., 2018) as our foundational adversarial training method, given its widespread popularity in the field. Additionally, we compare our MG with flat local minima approach SSAM (Shi et al., 2018), as it represents a leading-edge, versatile solution for addressing flat local minima.
* **Implementation Details.** We retain the standard settings for all baselines. Following the settings of some current works in multimodal recommender systems (Shi et al., 2018; Shi et al., 2018; Shi et al., 2018), we perform a grid search on hyperparameters \(_{1}\) and \(_{2}\), and set \(\) to 3. Unless otherwise specified, Adam (Kingma and Ba, 2014) serves as the chosen optimizer. The training and evaluation of all models is conducted using the RTX3090 GPU.

### Overall Performance

**Observation #1:** MG can enhance the performance of diverse multimodal recommender systems consistently.** As shown in Table 3, we conduct an extensive evaluation of MG across eight baseline models using three distinct datasets. Our experimental findings unequivocally illustrate that it is difficult to overlook the enhancements in the performance of multimodal recommender systems with MG across all evaluation metrics. Remarkably, the most substantial improvement is observed in the case of VBPR training on the dataset Clothing, resulting in an impressive performance enhancement of over 20%. To summarize, MG we propose excels at

    &  &  &  \\   & REC & PREC & MAP & NDCG & REC & PREC & MAP & NDCG & REC & PREC & MAP & NDCG \\  VBPR & 0.0265 & 0.0059 & 0.0134 & 0.0170 & 0.0353 & 0.0079 & 0.0189 & 0.0235 & 0.0186 & 0.0039 & 0.0103 & 0.0124 \\ VBPR + MG & 0.0273 & 0.0061 & 0.0149 & 0.0184 & 0.0375 & 0.0084 & 0.0203 & 0.0251 & 0.0230 & 0.0048 & 0.0129 & 0.0155 \\ Improv. & 3.02\% & 3.39\% & 11.19\% & 8.24\% & 6.23\% & 6.33\% & 7.41\% & 6.81\% & 23.66\% & 23.08\% & 25.24\% & 25.00\% \\  MMGCN & 0.0240 & 0.0053 & 0.0130 & 0.0160 & 0.0216 & 0.0049 & 0.0114 & 0.0143 & 0.0130 & 0.0028 & 0.0073 & 0.0088 \\ MMGCN + MG & 0.0269 & 0.0060 & 0.0139 & 0.0175 & 0.0241 & 0.0054 & 0.0126 & 0.0158 & 0.0153 & 0.0032 & 0.0081 & 0.0100 \\  Improv. & 12.08\% & 13.21\% & 6.92\% & 9.38\% & 11.57\% & 10.20\% & 10.53\% & 10.49\% & 17.69\% & 14.29\% & 10.96\% & 13.64\% \\  GRCN & 0.0336 & 0.0074 & 0.0182 & 0.0225 & 0.0360 & 0.0080 & 0.0196 & 0.0241 & 0.0269 & 0.0056 & 0.0140 & 0.0173 \\ GRCN + MG & 0.0354 & 0.0078 & 0.0186 & 0.0232 & 0.0383 & 0.0086 & 0.0207 & 0.0256 & 0.0276 & 0.0058 & 0.0146 & 0.0179 \\ Improv. & 5.36\% & 5.41\% & 2.20\% & 3.11\% & 6.39\% & 7.50\% & 5.61\% & 6.22\% & 2.60\% & 3.57\% & 4.29\

[MISSING_PAGE_FAIL:6]

range \([-100,100]\), and init noise \(n_{1},n_{2}\) from the standard normal distribution. \(n_{1},n_{2}\) have the same shape as \(p\). We then update the model's parameters to \((p+mn_{1}+nn_{2})\) and calculate the corresponding loss values, simulating the shift of the loss landscape as depicted in Fig. 2. By employing this methodology, we can generate training loss landscapes as illustrated in Fig. 3. The flatter the training loss landscape, the flatter the local minima to which the current model converges. Notably, the landscapes associated with MG demonstrate a flatter topography when compared to those of the baseline approaches and prominently encompass an area characterized by low loss (depicted in blue). These visualization results show that MG can make multimodal recommender system approach flatter minima. Moreover, from the visualization results, the loss landscape associated with FREEDOM appears flatter compared to that of BM3. This indicates that FREEDOM may be more robust to noise, aligning with the observations in Table 4.

**Convergence Speed of MG (RQ4).** In this part, we visualize the training loss of both widely used and leading-stage models to confirm MG's superior convergence. Following the training configuration outlined by Zhou et al. (2019), we set the maximum number of epochs to 1000 while implementing an early stopping strategy. Subsequently, we visualize the progression of the loss value for multiple multimodal recommendation models before and after the application of MG, as shown in Fig. 4. Noticeably, MG often leads the models to meet the termination criteria with fewer training iterations and achieve a smaller final training loss value.

**Comparing with Sharpness-aware Minimization (RQ5).** Recently, several general smoothing methods (Zhou et al., 2019; Li et al., 2019; Wang et al., 2019; Wang et al., 2019; Wang et al., 2019) about flat local minima have been proposed. In this section, we compare these methods with MG in multimodal recommender systems. Specifically, we apply the recent method SSAM (Wang et al., 2019) to the multimodal recommendation model DRAGON on the dataset Baby, and the results are laid out in Table 7. The experimental results show that MG outperforms both SSAM-F, which draws upon fisher information, and SSAM-D, which capitalizes on the principles of dynamic sparse training mask (Wang et al., 2019). These experiments suggest the MG's inherent advantage of identifying flat local minima compared with other minimization methods in the scenario of multimodal recommender systems.

**Compatibility with Various Optimizers (RQ6).** As a gradient method, it is necessary for MG to adapt to various optimizers. Therefore, in this part, we evaluate the performance of MG on the dataset Baby under various optimizers and baselines as illustrated in Table 6. The optimizers include Adam (Kingma and Ba, 2014), SGD (Goodfellow et al., 2014; He et al., 2016), RMSprop (Kingma and Ba, 2014), and Adagrad (Abadi et al., 2014). Here, we choose the classic multimodal recommender system GRCN and the latest state-of-the-art multimodal recommender system DRAGON as baselines. Despite the considerable performance fluctuations observed among baselines under different optimizers, MG consistently delivers a noticeable enhancement in recommendation accuracy. This consistency highlights the stable performance of MG across a range of optimizers.

   Optimizer & Model & REC & PREC & MAP & NDCG & Model & REC & PREC & MAP & NDCG & 758 \\   & GRCN & 0.0336 & 0.0074 & 0.0182 & 0.0225 & DRAGON & 0.0374 & 0.0082 & 0.0202 & 0.0249 & 758 \\  & GRCN + MG & 0.0354 & 0.0078 & 0.0186 & 0.0232 & DRAGON + MG & 0.0419 & 0.0092 & 0.0219 & 0.0273 & 757 \\  & Improv. & 5.36\% & 5.41\% & 2.20\% & 3.11\% & Improv. & 12.03\% & 12.20\% & 8.42\% & 9.64\% & 759 \\   & GRCN & 0.0013 & 0.0003 & 0.0005 & 0.0007 & DRAGON & 0.0182 & 0.0040 & 0.0093 & 0.0118 & 760 \\  & GRCN + MG & 0.0014 & 0.0003 & 0.0006 & 0.0008 & DRAGON + MG & 0.0188 & 0.0041 & 0.0097 & 0.0122 & 761 \\  & Improv. & 7.69\% & 0.00\% & 20.00\% & 14.29\% & Improv. & 3.30\% & 2.50\% & 4.30\% & 3.39\% & 762 \\   & GRCN & 0.0338 & 0.0074 & 0.0184 & 0.0227 & DRAGON & 0.0367 & 0.0081 & 0.0198 & 0.0245 & 764 \\  & GroCN + MG & 0.0345 & 0.0076 & 0.0187 & 0.0231 & DRAGON + MG & 0.0391 & 0.0087 & 0.0201 & 0.0253 & 765 \\  & Improv. & 2.03\% & 2.63\% & 1.60\% & 1.73\% & Improv. & 6.54\% & 7.41\% & 1.52\% & 3.27\% & 766 \\   & GRCN & 0.0283 & 0.0063 & 0.0152 & 0.0189 & DRAGON & 0.0393 & 0.0086 & 0.0215 & 0.0264 & 767 \\  & GRCN + MG & 0.0286 & 0.0064 & 0.0154 & 0.0191 & DRAGON + MG & 0.0408 & 0.0090 & 0.0216 & 0.0269 & 768 \\   & Improv. & 1.06\% & 1.59\% & 1.32\% & 1.06\% & Improv. & 3.82\% & 4.65\% & 0.47\% & 1.89\% & 769 \\   

Table 6. Top-5 recommendation performance of GRCN and DRAGON with or without MG on Baby. ‘Improv.’ indicates the relative enhancement of MG compared to the baselines.

Figure 4. Convergence of MG on the dataset Baby.

[MISSING_PAGE_FAIL:8]