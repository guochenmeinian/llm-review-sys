# [MISSING_PAGE_FAIL:1]

[MISSING_PAGE_FAIL:1]

Entities within STKGs can be expressed using triplets, (_Shop_, \(t_{i}\), _loc_), signifying an entity's state at a specific time. Meanwhile, relations are represented as (\(e_{i}\), \(relation\), \(e_{j}\)) under a given \(time\), \(location(i,j)\) highlighting the spatial-temporal connection between two entities. By integrating these triplets, a semantic path is constructed, elucidating the evolution of relationships grounded in spatial-temporal data.

STKGs are versatile tools suitable for predictive tasks, encompassing forecasting specific store sales or traffic volumes at designated stations. Their utility also extends to recommendation tasks, facilitating predicting the next POI. Despite the potential, the dynamic nature of data and intricate relationships within the graph present challenges in harnessing an STKG effectively for downstream applications, which leads to research questions: How can an STKG framework be versatile enough to accommodate diverse data types? How to enable this framework for KG completions while ensuring its interpretability?

In this paper, a novel framework is raised for constructing and exploring Spatial-temporal knowledge graphs for prediction and recommendation. By integrating spatial-temporal data into KGs and exploiting these KGs through entity and relation embeddings, the framework aims to leverage the strengths of KGs to enhance the accuracy and relevance of spatial-temporal predictions. While keeping the embeddings suitable for real-world datasets, the framework ensures efficiency as well as interpretability. To validate its efficacy, the framework was applied to two datasets: Safegraph's SpendOhio dataset and the traffic volume of New South Wales (TFNSW) dataset to do experiments on temporal sequence prediction.

## 2. Related Work

### Spatial-Temporal Data Prediction & Recommendation

Doing prediction or recommendation on spatial-temporal data has been a hot topic of research in recent years, addressing challenges in domains like traffic volume prediction, selling record prediction, and next point-of-interest recommendation. Early methods are based on statistical knowledge, or using machine learning. ARIMA (Safegraph, 2017) was based on the Wold decomposition theorem, using linear time-series techniques, however, it is unable to capture enough spatial-temporal dependencies, this drawback also occurs in early machine learning methods, like CSVM (Krishnan et al., 2017) and SVM (Krishnan et al., 2017). More recently, researchers have begun to consider more complex methods, thanks to the emergence of deep learning. Recurrent Neural Networks(RNNs) like long short-term memory (LSTM) networks, or Temporal Convolutional Networks(TCNs) can effectively capture temporal features, while Graph Neural Networks(GNNs) and Convolutional Neural Networks(CNNs) perform well in spatial data. The fusion of deep learning models leads to a great fit for spatial-temporal data. Spatial-temporal GNNs like graph convolutional neural networks(GCNs) can simultaneously model spatial and temporal information (Golov et al., 2013), and are widely used in real-world cases like traffic flow prediction (Golov et al., 2013; Velickovic et al., 2014; Zhang et al., 2015) or weather forecasting (Golov et al., 2013).

### Knowledge Graph for prediction

#### 2.2.1. Static KGs for Prediction

Since KGs have a unified structure, based on their embeddings or paths, they can be used to predict potential links hidden in established datasets. For static data, KGs can assist and accelerate drug discovery (Krishnan et al., 2017) in the medical field, and they also perform well on fake news detection (Krishnan et al., 2017) by finding the shortest path between facts.

#### 2.2.2. Temporal KGs/STKGs for Prediction

Dynamic data, typically sourced from sensors, can also be transferred into structured entities and shaped into temporal KGs(TKGs) or STKGs. Embeddings encompassing distinct spatial or temporal information are compared to determine the entities that would appear in certain time points under certain locations. Since dynamic KGs capture time relationships between entities in events, temporal predictions like the time of natural disasters (Krishnan et al., 2017) could be achieved. STKGs also help in spatial predictions, by modeling trajectories data, users' mobility patterns or activities can be predicted (Safegraph, 2017; Chen et al., 2017).

### Knowledge Graph for recommendation

KGs can help solve cold start problems as external sources. Also, by modeling data into KGs, Problems caused by the sparsity or low popularity bias of data are reduced, which can normally influence traditional recommendation methods like collaborative filtering. Normally the recommendation methods on KGs are categorized into path-based and embedding-based.

#### 2.3.1. Path-based recommendation

Paths in KGs contain relationships between entities, enabling the extraction of features such as users' preferences or item characteristics by analyzing paths. KPRN (Zhu et al., 2017) used the LSTM network to represent path information, like users and movie interactions, thus can calculate user preferences towards target movies.

#### 2.3.2. Embedding-based recommendation

Entities and relations can normally be transferred into embeddings under certain rules, these embeddings can be applied to recommendation algorithms. Entity2ree (Zhu et al., 2017) uses property-specific embeddings on KGs to do recommendation, while HAKG (Krishnan et al., 2017) uses subgraph embeddings for enhanced user preference prediction.

While the aforementioned methodologies have registered good performances in designated tasks, they are encumbered by certain limitations: 1) Their inherent complexity or the extensive versatility of entity types often renders them time-intensive or restricts their adaptability to diverse domains. 2) They are not explainable enough

Figure 1. An example of KG containing spatial-temporal information

to describe features extracted from spatial-temporal data. The proposed model aspires to bridge these gaps, presenting a solution that is streamlined and adaptable to diverse data types while ensuring interpretability.

## 3. Methodology

### Preliminaries and method overview

The STKG problem is defined as: An optimal STKG should accommodate the dynamic nature of data, adapting to changes in entities' attributes influenced by time and location. Moreover, it is essential for the framework to facilitate STKG completions post-construction and predict forthcoming attributes.

**Input representation** The objective of the proposed STKG is to attain universality. To this end, a uniform representation for diverse types of spatial-temporal data is integrated to generalize raw entities and relations types.

**STKG embedding model** The embedding model is designed to encode entity attributes into vector representations and subsequently decode embeddings into numerical representations mirroring the raw data. The embedding model facilitates KG completion on existing STKG and enables the prediction of underlying or between entities.

Table 1 summarizes notations used in the paper as well as their meanings.

Figure 2 illustrates the general workflow of the framework. Upon acquiring spatial-temporal data, pre-established rules are utilized to extract and compute entities, relationships, and facts, thereby constructing STKG while _ensuring limited entity types and relationship types_. Subsequently, a new embedding model is raised to vectorize the features of entities, enabling the utilization of the STKG in downstream tasks. This streamlined process facilitates a more efficient and effective application of knowledge graphs in real-world scenarios, able to be used for inference with enhanced speed. Finally, the underlying patterns and insights captured by the STKG are interpreted based on its structure, making the whole model explainable.

### Knowledge Graph Construction

#### 3.2.1. Definition of STKG

The spatial-temporal knowledge graph is defined as graphs \(G=(E,R,T,F)\), where \(E\), as table 1 shows, is entities that contains spatial-temporal attributes. \(R\) represent the set of relation between entities. \(T\) describes how the temporal records get divided. \(F\) is the set of facts mentioned in section 1. Specifically, \(R\) and \(T\) in the knowledge graph define _certain relation between entities under certain time_, which denotes facts. Facts under STKG are seen as a quadruple \((e_{i},t,t_{j},r)\).

#### 3.2.2. Simplified STKG

Considering when entities like stores are rigidly classified according to their business establishments, as exemplified by the 6-digit North American Industry Classification System (NAICS) code. The strict categorization can lead to an excessive fragmentation of entity types. Also, the dynamics of relationships between entities can vary significantly based on spatial and temporal factors. Two entities, even if their spatial distances are fixed, might have totally inverted relations at different times. Moreover, detailed numerical time and location are hard to be transferred as distinct entities.

In light of these complexities, the simplified STKG aims to provide a more flexible and realistic representation of entities and their relationships, establishing rules for the SSTKG as follows:

* _Rule 1:_ Time and location are not treated as independent entities. Instead, they are integrated as attributes inherent and between entities, represented as part of entity and relation embeddings.
* _Rule 2:_ The model prioritizes a reduction in the number of entity types, embedding classification data directly within the entity. This not only simplifies the graph structure but also facilitates more efficient and direct retrievals of classification information from the entity embeddings.
* _Rule 3:_ Numerical representations are adopted to directly articulate the relationship between two entities. Under this paradigm, the association between entities is conceptualized as a continuous variable termed "influence". Within this framework, any pair of entities can exhibit a relationship that is fluid across both temporal and spatial dimensions
* _Rule 4:_ Relationships between entities that are quantitatively negligible are omitted, ensuring focus on significant interactions and reducing noise within the graph.

Leveraging this SSTKG framework, entities are directly extracted from structured data. The process of relation extraction is thus transformed into "relation computation", or "influence computation", while fact still be seen as the quadruple \((e_{i},t,t_{j},r)\).

 Notation & Description \\
**e**, **r** & An entity and a relation \\
**e**, **r** & Vector representation of e and r \\ \(r_{i,j}\) & directional relation from i to j \\ \(E,R\) & Entity set and relation set \\ \(d(e_{i},e_{j})\) & Distance between two entities \\ \(G\) & A STKG \\ \(T\) & The set of time \\ \(e_{attribute}\) & The embeddings of certain attribute of entities \\ 

Table 1. Notations and descriptions

Figure 2. The workflow of proposed framework

[MISSING_PAGE_FAIL:4]

Given a training tuple \(x=(e_{0},R,E_{0},t)\), the score function is defined as:

\[f_{p1}(x)=f_{1}(e_{0},R,E_{0},t)=||p_{e_{0}}*e_{0\_out}^{t}-e_{0\_in}^{t}||_{2}^ {2} \]

Equation (10) defined a score as how precise one entity is **influenced** by related entities. Meanwhile, valid relations and embedding sets are used to obtain a lower score of \(f_{SSTRG}\), then the first loss function is defined as:

\[l_{emb}(x)=l_{emb}(e_{0},R,E_{0},t)=-_{i}log(f_{p1}(e_{0},R^{i},E_ {0},t)-f_{p1}(x)) \]

Embedding \(e_{out}^{i}\) is replaced in \(f_{p2}(e_{0},R^{i},E_{0},t)\) with another random entity that has similar overall selling records in the whole dataset and without relations with \(e_{i}\), using the same Influence value.

An alternate score function is defined for the loss of entity influence values. For an entity \(e_{0}\), its influence on the SSTKG, which is related to entities \(E_{0}\) that connect with \(e_{0},R\) now denotes after optimizing out-embeddings, the influence of \(e_{0}\) to entities in \(E_{0}\). Given a training tuple \(x=(e_{0},R,E_{0},t)\), the score function is articulated as:

\[f_{p2}(x)=f_{p2}(e_{0},R,E_{0},t)=||p_{e_{0}}*e_{0\_out}^{t}-_{i}R_{i}* e_{i\_out}^{t}||_{2}^{2} \]

\[l_{inf}(x)=l_{inf}(e_{0},R,E_{0},t)=-_{i}log(f_{p2}(e_{0},R,E_{0}^ {i},t)-f_{p2}(x)) \]

In \(f_{SSTRKG}(e_{0},R^{i},E_{0},t)\) one related entity's influence is replaced to average. The second loss function denotes the loss of specific **"influence"** value, which is the relations.

The process of learning improved embeddings and influences are shown as pseudocode in Algorithm 2.

```
0:\(N_{epochInf},N_{epochEmb}\); SSTKG \(G\) with initialized \(e_{static}\), \(e_{out}\), influence
0:SSTKG with trained \(e_{out}\), influence
1:for\(i=1\) to \(N_{epochInf}\)do
2:\(S_{1} G\)
3:while\(S_{1}\)do
4: Sample batch \(S_{batch} S_{1}\)
5:\(S_{1} S_{1} S_{batch}\)
6:\(L_{1} 0\)
7:for\(s S_{batch}\)do
8:\(f_{p1}(s)\) compute score using (10)
9:\(l_{inf}(s)\) compute loss using (11)
10:\(L_{1} L_{1}+l_{inf}(s)\)
11:endfor
12: Update out embeddings using \( L_{1}\)
13:endwhile
14:endfor
15:for\(i=1\) to \(N_{epochEmb}\)do
16:\(S_{2} G\)
17:while\(S_{2}\)do
18: Sample batch \(S_{batch} S_{2}\)
19:\(S_{2} S_{2} S_{batch}\)
20:\(L_{2} 0\)
21:for\(s S_{batch}\)do
22:\(f_{p2}(s)\) compute score using (12)
23:\(l_{emb}(s)\) compute loss using (13)
24:\(L_{2} L_{2}+l_{emb}(s)\)
25:endfor
26: Update influence in relations using \( L_{2}\)
27:endwhile
28:endfor
```

**Algorithm 2** Training entity embeddings and relations for SSTKG

## 4. Model Properties

### Efficiency and Speed

The proposed model is designed with computational efficiency in mind. It requires less computational resources compared to traditional models, thereby enabling faster construction of the STKG. This feature is particularly beneficial in scenarios where rapid knowledge graph construction is crucial. Here is the test result of constructing and optimizing an SSTKG using the Spend-Ohio dataset mentioned in Section 5.1, with 100 training epochs.

### Inference Patterns

By using the embedding model in Section 3.3, a certain entity's temporal record is predicted using its related entities' records. Based on Equation (8), trained static embedding of related entities and their current temporal records are used to compute the target entity's out-embedding. Therefore, final temporal records are decoded from out embedding as well as the static embedding, since for the trained embeddings, influence \(R\) are obtained, while having related entities' records on time slot \(t_{1}\), the out/in embeddings for \(e_{0}\) is inferred based on Equation (8) and (9). Subsequently, the referred \(e_{i\_records}^{t}\) is decoded in accordance with Equation (6).

### Interpretability

Another significant advantage of SSTKG is its interpretability. The simplified structure and the numerical representation of relationships make it easier to understand the underlying patterns and insights captured by the STKG. This interpretability enhances the model's usability, especially in applications where understanding the reasoning behind predictions is important.

Embedding directly reflects the spatial-temporal properties of each entity based on backward induction. The whole fitting and training process, to simply explain, is a process of finding proper embeddings that incorporate an entity's spatial-temporal data, such that the embedding (out-embedding), is viewed as the result of the combined effects of related entities' embeddings(out-embedding), during which the unidirectional relation between two entities serves as the parameter of fitting the whole equation. First, an expansion of the Equation (8) is resen

   entity number & time records (day) & average time(s) \\ 
1000 & 30 & 347.7 \\
30000 & 30 & 13087.3 \\   

Table 2. Time cost for training SSTKG on Spend-Ohio dataset\[p_{i}*e_{i,in}^{t}=_{j}t_{j} e_{i\_static},e_{i,records}^{t}* Influence_{j,i} \]

Which could be transferred as

\[p_{i}*e_{i,in}^{t}=_{j}e_{j\_static}*(e_{i\_records}^{t}Influence_{j,i}) \]

Clearly, \(\) after this transformation, served as connecting parameters of out-embeddings (the temporal record) to the influence variables: it's a temporal relation of entity \(j\) to \(i\), which is further explained as **entity \(j\)'s influence to \(i\) under time \(t\)**, also it can serve as generating an embedding of temporal relation, which is simplified as:

\[p_{i}*e_{i}^{t}=_{j}e_{j}^{t} influence_{j,i}=_{j}e_{j\_static}  r_{j,i}^{t} \]

Thus, from the final result, training the embedding serves to refine the processes undertaken during SSTKG construction. it optimizes the whole SSTKG, forming the exact relationship using both entities' categorical, spatial, and temporal attributes.

## 5. Experiments

### Datasets

Two datasets are used to evaluate the performance of SSTKG. The first one is Spend-Ohio data from January 2022 to April 2023, collected by Safegraph, containing many Ohio stores' geographical and categorical information, as well as the selling records **counted by day**. The second one is Traffic Volume of Transport for New South Wales (TFNSW) data, which encompasses the traffic volume from a collection of permanent traffic counters and classifiers in Sydney, with data collated since 2008 on an **hourly basis**. Locations of these counters have been further categorized based on their respective suburbs. Table 3 presents the size of the two datasets. Notably, the 'distance' attribute represents the distance threshold employed during SSTKG construction as per Algorithm 1.'

Specifically, the attributes used in processed Spend-Ohio and TFNSW data are shown in Table 4.

### Evaluation

The accuracy rate for a prediction ACCn is defined as, if the predicted value is judged as correct, then:

\[r_{predict}(r_{real}(1-n\%),r_{real}(1+n\%)) \]

When evaluating, apart from accuracy, RMS and RSD are also used for evaluation and defined as:

\[RMS=^{n}(o_{i}-p_{i})^{2}}{_{i=1}^{n}(o_{i})^{2}}} \]

\[RSD=^{n}(o_{i}-p_{i})^{2}}{N}} \]

Apart from our model (SSTKG), other models are used for comparison: (1) Support Vector Regression Machine(SVR), which is based on support vector machine. (2)Long Short Term Memory (LSTM) network that models the sequence of temporal records. (3) TGCN, the combination of graph convolutional network(GCN) and

    & **Spend-Ohio dataset** \\  attribute & detail explanation \\  placekey & a tuple representing entity location \\ NAICE code & 6-digit code reflecting category \\ temporal records & selling records collected day by day \\ overall records & overall records calculated by past results \\   \\  attribute & detail explanation \\  location & counters’ locations \\ suburb & the suburb where counters are located \\ temporal records & traffic volume collected by hour \\ overall records & overall traffic volume aggregated to days/weeks \\   

Table 4. Attributes for constructing SSTKG in datasets

Figure 3. Part of checkpoints chosen in TFNSW dataset

    &  \\  data & entities & distance & relations & records \\ 
2022-3 & 39188 & 2km & 2941374 & 1014976 \\
2022-4 & 39461 & 2km & 2970417 & 1055901 \\
2022-5 & 39654 & 2km & 3028519 & 1083649 \\
2022-6 & 39931 & 2km & 3062957 & 1098972 \\
2023-1 & 41200 & 2km & 3200018 & 127200 \\
2023-2 & 41138 & 2km & 3194903 & 1151864 \\
2023-3 & 42932 & 2km & 3314523 & 1300893 \\   \\  data & entities & distance & relations & records \\ 
2015 & 67 & 4km & 496 & 1045200 \\
2016 & 69 & 4km & 511 & 1212192 \\   

Table 3. Quantities of data used in datasetsgated recurrent unit(GRU), while GCN can learn spatial characteristics of nodes, and GRU learns temporal features of historical temporal records. (4) STGCN (Wang et al., 2019) which uses 2 TCNs and 1 GCN and could serially capture spatial-temporal dependencies in the data.

### Case study

In order to validate the interpretability of the proposed model, a case study was conducted using the Spend-Ohio data in 2023-1. Specific stores served as exemplars. Following the knowledge graph construction and training of the influences and embeddings, the distance thresholds were adjusted to modify the quantity of entities deemed related in the knowledge graph. By repeating the construction process with these variations, differences in outcomes aim to elucidate the model's explainability.

## 6. Result

### Experiment Results

#### 6.1.1. Safegraph: Spend-Ohio dataset

In Spend-Ohio dataset, the first 25 days are used to construct and train the SSTRG for monthly data, while the rest data is used for testing(which is 6 days, 3 days, and 6 days in the three subsets). To help compare and reduce the effect of null values, when calculating the RMS and RSD, the score's selling records is normalized to a range of **(0,20)**. The results are shown in Table 5.

#### 6.1.2. Tfnsw dataset

In TFNSW data, two separate experiments were done. The first one used the hourly data collected 24/7. 40 weeks' data were used to train, and then a 24-hour prediction in the following days was generated. In the second experiment, hourly records were added to daily ones, then the daily records were used to train. It is similar to the scale in the Spend-Ohio dataset. Similarly, the traffic volume was also normalized to **(0,20)**. The accuracy result (acc10 and acc15) and the RMS and RSD for normalized data are shown in Table 6:

### Result analysis

From the results, the prediction of T-GCN, ST-GCN, and SSTKG are much better than SVR and LSTM. This is because SVR and LSTM only focus on temporal record correlations while failing to consider spatial relations. SSTKG, as well as T-GCN and ST-GCN, model both spatial and temporal characteristics to ensure the data effectiveness. SSTKG is better than T-GCN. Compared with ST-GCN, SSTKG performs better on acc15 and RSD on the Spend-Ohio dataset, while being better in acc15, RMS, and RSD for hourly prediction, in acc10 and RMS for daily prediction in the TFNSW dataset.

### Interpretability: case study

This section presents the predicted result for a single entity in the Spend-Ohio dataset, in order to demonstrate the interpretability of SSTKG. The selected sample entity possesses attributes outlined in Table 7, with certain values masked to maintain privacy.

For this entity, distances of nearby entities are shown in Figure 4. There are 36 entities in SSTKG that have influence with this shop. Figure 5 shows the influence values that are calculated and extracted from SSTKG.

From the above results, generally, entities close to the sample are more likely to have larger influence values, whereas those entities far away from samples have nearly no influence.

By integrating the above influences with trained embeddings, the sample's selling is predicted based on Equation (6), (8) and (9)

    &  \\  method & acc@10 & acc@15 & RMS & RSD & 788 \\  SVR & 0.701 & 0.7583 & 0.6737 & 129.8 & 780 \\ LSTM & 0.7639 & 0.8072 & 0.5615 & 113.4 & 781 \\ GRU & 0.7825 & 0.8404 & 0.475 & 107.8 & 782 \\ T-GCN & 0.7973 & 0.8345 & 0.497 & 105.2 & 783 \\ ST-GCN & **0.8137** & 0.8641 & 0.429 & 96.9 & 784 \\ SSTKG & 0.8095 & **0.8692** & **0.4245** & **95.7** & 785 \\   \\  method & acc@10 & acc@15 & RMS & RSD & 780 \\  SVR & 0.7914 & 0.8215 & 0.5047 & 90.1 & 788 \\ LSTM & 0.8145 & 0.8374 & 0.459 & 87.2 & 789 \\ GRU & 0.8609 & 0.9285 & 0.3867 & 63.7 & 778 \\ T-GCN & 0.8745 & 0.948 & 0.3641 & 67.5 & 771 \\ ST-GCN & **0.8435** & 0.9291 & 0.399 & 76.8 & 773 \\ SSTKG & 0.8374 & **0.9289** & **0.396** & **71.7** & 773 \\   

Table 6. Test results for TFNSW datasets

    &  \\  method & acc@10 & acc@15 & RMS & RSD \\  SVR & 0.5621 & 0.6528 & 0.9872 & 158.9 \\ LSTM & 0.5984 & 0.7025 & 0.9031 & 135.7 \\ GRU & 0.7057 & 0.8544 & 0.607 & 97.3 \\ T-GCN & 0.7489 & 0.8386 & 0.651 & 103.5 \\ ST-GCN & 0.7902 & **0.8945** & 0.463 & 87.9 \\ SSTKG & **0.8016** & 0.8922 & **0.452** & **86.1** \\   \\  method & acc@10 & acc@15 & RMS & RSD \\  SVR & 0.6015 & 0.7325 & 0.9751 & 144.3 \\ LSTM & 0.6394 & 0.7672 & 0.8865 & 127.2 \\ GRU & 0.7359 & 0.8897 & 0.528 & 88.3 \\ T-GCN & 0.7826 & 0.8597 & 0.562 & 91.3 \\ ST-GCN & **0.8435** & 0.9291 & 0.399 & 76.8 \\ SSTKG & 0.8374 & **0.9289** & **0.396** & **71.7** \\   

Table 5. Test results for Spend-Ohio datasets(first calculate embeddings then decode records). However, if some related entities were masked, the predicted result would change, like entities A, B, and group C shown in Figure 5, while entity A has a positive influence, B has a negative influence, and group C has barely non-influence. Table 8 shows the change of prediction after masking entities A, B, and group C.

A hypothesis test is set to show the difference between predicted data. While the former predicted data is \(R_{0}\), predicted data after removing A, B and C are \(R_{a},R_{b}\) and \(R_{c}\), the null hypothesis are: \(H_{0a}:R_{0}<R_{a}\); \(H_{0b}:R_{0}>R_{b}\); \(H_{0c}:R_{0}!=R_{c}\), while alternative hypothesis are \(H_{1a}:R_{0}>R_{a}\); \(H_{1b}:R_{0}<R_{b}\); \(H_{1c}:R_{0}=R_{c}\). Table 9 shows the p-value after t-test under 95% confidence level:

For all three null hypotheses, the p-value of t-test is greater than 0.05, thus are all rejected, drawing the conclusion that, by masking entity A, the predicted value for sample's selling decreased(\(R_{0}>R_{a}\)), while by masking B the predicted value increased (\(R_{0}>R_{b}\)) - those who have positive influence on SSTKG would increase prediction, which means "prosperity in one shop leads to prosperity to another", and vice versa. On the other hand, in group C, where entities have small influence values, the prediction value changed a little after masking them (more than 95% confidence to confirm that \(R_{0}=R_{c}\)).

## 7. Conclusions and Future Work

In this paper, a new knowledge graph framework is proposed, i.e., simple spatial-temporal knowledge graph (SSTKG), which leverages 3 kinds of embeddings (static, temporal in and out embeddings) to model entities, as well as using "influence" to model the spatial-temporal relations between entities. A comprehensive evaluation using real-world data has underscored the efficacy of the proposed SSTKG in prediction tasks and highlighted its interpretability. Future endeavors will focus on refining the SSTKG construction algorithm, moving beyond distance thresholds to embrace node similarity without spatial constraints. Moreover, the potential application of SSTKG in recommendation tasks will also be explored.

## 8. Ethical Use of Data

The Spend-Ohio dataset from SafeGraph was utilized for this study. While it provides granular transaction data, all transactions and associated credit or debit card details have undergone rigorous anonymization to safeguard consumer privacy. Specific details about the merchants (like location and brand) within the Spend-Ohio dataset were masked from the study. All information regarding merchants and consumers was handled with strict confidentiality, ensuring that no privacy boundaries were breached. No credit information of merchants and consumers is involved in this paper.

Additionally, the TFNSW dataset used in the experiment is a publicly available dataset that contains neither personal nor private details. The dataset only incorporates generic traffic flow without identifiable details, without specific identifiable details such as license plate numbers or exact timestamps of certain car passes.

Figure 4. Related entities’ distances with sample shop

Figure 5. Related entities’ influence to sample shop

    & p-value & result \\  \(H_{0a}:R_{0}<R_{a}\) & 0.9998975 & reject \(H_{0a}\), accept \(H_{1a}\) \\ \(H_{0b}:R_{0}>R_{b}\) & 0.999873 & reject \(H_{0b}\), accept \(H_{1b}\) \\ \(H_{0c}:R_{0}!=R_{c}\) & 0.6717662 & reject \(H_{0c}\), accept \(H_{1c}\) \\   

Table 9. Result for t-test