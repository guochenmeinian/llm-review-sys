ID: 2IwSOTWvXu
Title: Convergence-Aware Online Model Selection with Time-Increasing Bandits
Conference: ACM
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel framework for online model selection based on the multi-armed bandits formulation, specifically tailored to the LLMs setting. The authors propose the TI-UCB algorithm, which incorporates loss convergence in the reward formulation and demonstrates its effectiveness through extensive experimentation and formal proofs. The work addresses a timely and significant problem in the context of LLM advancements, with a clear writing style and sound presentation of results.

### Strengths and Weaknesses
Strengths:
- The paper is relevant and timely for the community, addressing a critical issue in model selection.
- The theoretical contributions, including regret bounds, are well-supported and sound.
- The experimental setup is well-explained, enhancing reproducibility.

Weaknesses:
- The model does not explicitly capture the finetuning cost, which is crucial to the problem.
- The reward model's justification for LLM convergence is insufficiently defined.
- The regret definition lacks clarity, particularly regarding the optimal action sequence.

### Suggestions for Improvement
We recommend that the authors improve the model by explicitly incorporating the finetuning cost into the reward formulation. Additionally, the authors should provide a formal definition of LLM convergence and clarify the conditions under which convergence occurs, including how finetune data selection impacts this. The definition of regret should be refined, particularly the term n*_i(T), to ensure it accounts for variations in finetuning data. Furthermore, we suggest enhancing the background information on online model selection and conducting real-world experiments to validate the findings, as the current experiments are primarily in a synthetic environment. Lastly, we encourage the authors to clarify ambiguous terminology and imprecise statements throughout the paper.