ID: ZcuFDaMTYw
Title: Optimal testing using combined test statistics across independent studies
Conference: NeurIPS
Year: 2023
Number of Reviews: 19
Original Ratings: 6, 5, 7, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 2, 2, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on aggregation strategies for combining test statistics from independent experiments, focusing on the many normal means model. The authors derive minimax lower and upper bounds for testing errors, demonstrating that optimal aggregation methods depend on the number of trials and dimensions. They identify two regimes based on the relationship between the number of aggregated statistics (m) and the square of the signal dimension (d^2), where different strategies yield varying effectiveness. The authors also explore the implications of shared randomness between trials and provide numerical confirmations of their theoretical findings. Additionally, the paper includes a framework that discusses Bonferroni's method for combining p-values, clarifying that it is more general than smooth combination functions and encompasses methods like Tippett's method and the Bonferroni correction. The authors differentiate between multiple testing and meta-analysis, emphasizing that their analysis focuses on testing the same hypothesis across multiple studies.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, exhibiting "textbook" quality and clarity, particularly in explaining complex concepts like separation rates.
- The theoretical results are sound and based on established techniques, with a good overview of existing methods for combining test statistics.
- The authors provide a clear explanation of the differences between multiple testing and meta-analysis.
- The simulation study has been improved with cleaner and more interpretable plots.
- The paper is technically solid and well presented, with satisfactory responses to reviewer concerns.

Weaknesses:
- The significance of the approach is unclear, particularly regarding the motivation for using published test statistics without access to full datasets.
- The paper may not be a perfect fit for NeurIPS, as it leans heavily towards statistical methodology rather than machine learning.
- Clarity could be improved by providing more intuition about the proposed methods and their practical applications.
- The Bonferroni correction is noted as unnecessarily conservative for the authors' specific context, which may limit its applicability in their framework.

### Suggestions for Improvement
We recommend that the authors improve the motivation for their approach, particularly addressing the limitations of using published test statistics without full data access. Additionally, we suggest that the authors clarify the connection between meta-analysis and meta-learning, as this distinction is crucial for the paper's relevance to the NeurIPS audience. To enhance accessibility, we encourage the authors to include more intuitive explanations of their methods and results. Furthermore, we recommend that the authors improve the explicit mention of Bonferroni's method in the context of their framework, despite its conservativeness. Including a more detailed discussion on the implications of heterogeneity and varying sample sizes would also enhance the paper's comprehensiveness. Finally, addressing the clarity of the mathematical framework and ensuring the accuracy of the R script would strengthen the paper.