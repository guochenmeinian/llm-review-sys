ID: QEaHE4TUgc
Title: Fast TRAC: A Parameter-Free Optimizer for Lifelong Reinforcement Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 5, 6, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method, PACE, aimed at mitigating plasticity loss in lifelong reinforcement learning (RL) by employing a hyperparameter-free approach inspired by online convex optimization (OCO). The authors demonstrate that PACE significantly improves performance over two baselines, PPO with ADAM and CReLU, across various environments, while addressing the critical issue of hyperparameter tuning dependency in existing continual learning methods. The authors propose that while PACE outperforms Mechanic, the latter has not been previously applied in lifelong learning contexts. Both methods surpass existing approaches that require hyperparameter tuning, which is impractical. The authors emphasize that their contribution is not merely applying a method to a new domain but revealing significant insights about OCO's advantages in lifelong RL.

### Strengths and Weaknesses
Strengths:
- The introduction of a hyperparameter-free method for plasticity loss mitigation is a significant contribution to the field of lifelong RL.
- The empirical results show substantial improvements with PACE compared to the benchmark algorithms.
- The theoretical grounding in OCO enhances the method's credibility and provides a solid foundation for its design.
- The paper demonstrates that parameter-free OCO provides superior regularization compared to traditional methods, effectively mitigating plasticity loss.
- Additional experiments with increased sample sizes support the claim that PACE outperforms Mechanic, with statistically significant results.
- The inclusion of an ablation study clarifies the contributions of individual components within PACE.

Weaknesses:
- The comparison with Mechanic is insufficient, as results indicate that it performs similarly to PACE, raising questions about statistical significance.
- The comparison between PACE and Mechanic, while showing some significance, remains marginal and is based on a limited number of environments.
- There is a lack of comparisons with other relevant methods designed to mitigate plasticity loss, which could strengthen the case for PACE.
- The algorithm's explanation is not fully self-contained, lacking clarity on how its components interact and their individual contributions.
- The writing quality varies, with some sections requiring restructuring for improved clarity and focus.

### Suggestions for Improvement
We recommend that the authors improve the comparison with Mechanic by including more comprehensive empirical results in the main paper to substantiate claims of PACE's superiority. Additionally, we suggest incorporating comparisons with other plasticity loss mitigation methods, even if they involve hyperparameter tuning, to provide a broader context for PACE's advantages. Clarifying the algorithm's components and their interactions through an ablation study would enhance understanding. We also recommend conducting further experiments across a broader range of environments to strengthen the claims regarding PACE's performance. Lastly, we advise revising sections of the paper for clarity and coherence, particularly in the method description and theoretical discussions, and consider restructuring the paper to clearly delineate the algorithmic contributions and their significance in the context of the existing literature.