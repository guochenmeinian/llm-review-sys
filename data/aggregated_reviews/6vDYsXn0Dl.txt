ID: 6vDYsXn0Dl
Title: Linear Time Approximation Algorithm for Column Subset Selection with Local Search
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 7, 6, 5, 6, 7, -1, -1
Original Confidences: 3, 4, 3, 4, 3, -1, -1

Aggregated Review:
### Key Points
This paper presents a new algorithm for the Column Subset Selection (CSS) problem, aiming to select a subset of $k$ columns from a matrix $A \in \mathbb{R}^{n \times d}$ to minimize the residual error $\|A - SS^{\dagger}\|_F^2$. The authors propose a local search strategy combined with adaptive sampling techniques, achieving a linear runtime of $O(nd)$ and an approximation ratio of $100(k+1)$. This represents a significant improvement over previous algorithms, which had higher approximation ratios and non-linear runtimes.

### Strengths and Weaknesses
Strengths:
- The paper significantly improves the approximation ratio for small values of $k$, making it practically feasible.
- The algorithm demonstrates superior performance, being at least 10 times faster than existing methods across various datasets.
- The theoretical analysis is novel and solid, contributing to the understanding of local search in CSS.

Weaknesses:
- The experimental section lacks detailed discussions on parameter settings and experimental setups for baseline algorithms.
- The analysis resembles existing adaptive sampling techniques, raising questions about the novelty of the approach.
- The paper could benefit from clearer organization, particularly in separating theoretical results from algorithmic details.

### Suggestions for Improvement
We recommend that the authors improve the experimental section by providing detailed discussions on the parameter settings and experimental setups used for baseline algorithms. Additionally, we suggest moving the main theorem earlier in the paper to clarify the approximation ratio before presenting Table 1. It would also be beneficial to unify the wording of Lemmas 3.7 and 3.8 for consistency. Furthermore, addressing the lack of comparison with the QRP method, which is known for its efficiency, would strengthen the paper. Lastly, we encourage the authors to elaborate on the significance of subset selection compared to top-k-SVD to enhance the motivation for their work.