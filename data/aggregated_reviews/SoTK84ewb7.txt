ID: SoTK84ewb7
Title: Zero-Shot Scene Reconstruction from Single Images with Deep Prior Assembly
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 5, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework called "Deep Prior Assembly," which utilizes various pretrained large models for zero-shot scene reconstruction from single images. The authors propose a task decomposition strategy and a RANSAC-like optimization method for recovering scene layouts, demonstrating that simply combining large models is insufficient due to challenges such as occlusions and low-resolution instances. The method employs models like SAM for segmentation, Shap-E for 3D object generation, and Omnidata for depth estimation, aiming to enhance the reconstruction of diverse objects and layouts without relying on additional data-driven training. The authors also introduce innovative techniques, such as using the StableDiffusion model for image enhancement and employing CLIP models for quality filtering.

### Strengths and Weaknesses
Strengths:  
- The methodology effectively integrates multiple deep priors from large models, enhancing robustness and reducing dependency on specific datasets.  
- The proposed RANSAC-like solution enhances the robustness of pose and scale optimization, effectively linking deep priors for zero-shot reconstruction.  
- The experiments and ablation studies are thorough, demonstrating the effectiveness of the proposed pipeline.  
- The proposed technique achieves strong zero-shot performance relative to baseline methods despite not training on similar data.  
- Innovative techniques, such as using the StableDiffusion model for image enhancement, contribute to the overall quality of the reconstruction.

Weaknesses:  
- The technical contribution appears limited, as the approach mainly combines existing pretrained models without significant integration.  
- High memory costs arise from assembling numerous pre-trained modules, posing challenges for mobile edge device applications.  
- The reconstruction quality heavily relies on the performance of the single-image reconstruction model, which is sensitive to input image scale.  
- The methodology's complexity raises concerns about robustness, and the argument for heuristic depth shift selection lacks convincing support.  
- The method's performance on outdoor scenes remains uncertain, and comparisons to state-of-the-art baseline methods are outdated.  
- The approach may be perceived as more of an engineering effort rather than a theoretical advancement suitable for the NeurIPS community.  
- Concerns remain regarding the overall pipeline setup and its effectiveness compared to alternative methods.

### Suggestions for Improvement
We recommend that the authors improve the integration of deep priors to enhance the overall robustness of the framework. Additionally, addressing the high memory costs associated with assembling multiple pretrained modules would be beneficial. The authors should explore the sensitivity of the reconstruction quality to input image scale and consider establishing a universal scale for all instances. Furthermore, we suggest clarifying the methodology's performance on outdoor scenes and updating comparisons with more recent state-of-the-art methods in single-view scene reconstruction. Emphasizing the "zero-shot" aspect of their work by featuring impressive results on in-the-wild images more prominently in the revised manuscript would strengthen the paper. We also recommend considering the training data handling methods from competing approaches, such as those outlined in the ZeroShape project, as a potential alternative for enhancing performance. Finally, conducting more experiments on the combination of deep priors, as mentioned in the discussions, would further solidify the paper's contributions. Simplifying complex figures, such as Figure 2, could also aid in better conveying the main ideas of the method.