ID: aw35mW41XY
Title: Interpretable Knowledge Tracing with Multiscale State Representation
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Multiscale-state-based Interpretable Knowledge Tracing (MIKT) model, which aims to enhance interpretability while representing students' knowledge states in both fine-grained and coarse-grained manners. The model consists of four components: Expanded Rasch, Cognitive Thinking, IRT Prediction, and Cognitive Update. The authors conduct experiments comparing overall model performance, ablation studies, verification of interpretability, and the impact of the extended Rasch module on other Knowledge Tracing (KT) models. However, the paper does not replace the extended Rasch module with the regular module in ablation experiments, which limits the confirmation of its effectiveness. The evaluation metrics are also questioned, as only AUC is used without presenting accuracy (ACC) results.

### Strengths and Weaknesses
Strengths:
1. The paper effectively combines graph-based and sequential-based KT models, enhancing the representation of knowledge states.
2. The introduction of the IRT prediction module improves model interpretability.
3. Extensive experiments across 20 state-of-the-art KT models provide substantial evidence for the model's effectiveness.

Weaknesses:
1. Clarity issues exist, including unclear definitions of key concepts and inconsistent symbol usage.
2. The interpretability claims are not convincingly supported by evidence, particularly in the figures presented.
3. The experiments lack hyper-parameter tuning for baseline models, raising concerns about the validity of performance gains.

### Suggestions for Improvement
We recommend that the authors improve clarity by providing clearer definitions of domain and conceptual knowledge, as well as ensuring consistent symbol usage throughout the paper. Additionally, we suggest including a comparison of MIKT's interpretability with other interpretable KT models, such as QIKT and Deep-IRT, to substantiate claims of interpretability. The authors should also conduct hyper-parameter tuning for baseline models to validate performance improvements and consider including ACC results alongside AUC in the evaluation metrics. Finally, we encourage the authors to address the limitations of the MIKT model and outline future work in the conclusion.