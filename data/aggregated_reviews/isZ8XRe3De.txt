ID: isZ8XRe3De
Title: Customizing Language Models with Instance-wise LoRA for Sequential Recommendation
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 7, 4, 7, 5, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents iLoRA, a method that integrates LoRA with a mixture of experts framework to enhance sequential recommendations by capturing individual user preferences. The authors propose using multiple LoRA "experts" to address the variability in user behavior, employing an attention-like gating mechanism to determine the contribution of each expert based on input sequence embeddings. Extensive experiments on three public datasets demonstrate that iLoRA outperforms existing state-of-the-art methods, validating the proposed approach.

### Strengths and Weaknesses
Strengths:
- The paper is clearly written and effectively communicates the key concepts and motivations behind iLoRA.
- Extensive experimentation, including ablation studies, supports the claims made and demonstrates the method's effectiveness across multiple datasets.
- The integration of established concepts (MoE, Attention, LoRA) in a novel way addresses significant challenges in sequential recommendation.

Weaknesses:
- The contribution is somewhat limited, as the novelty lies in combining existing ideas rather than introducing a fundamentally new approach.
- The evaluation metrics used are insufficient; common metrics like HitRate@K and NDCG@K should be included for a more comprehensive assessment.
- The impact of training data size on model performance was not analyzed, which is critical given the sparse nature of recommendation data.
- The paper lacks a detailed discussion on out-of-domain capabilities and cold start recommendations, which are significant challenges in this field.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by incorporating additional metrics such as HitRate@K and NDCG@K to provide a more holistic view of output quality. Additionally, we suggest conducting an analysis on the impact of training data size on model performance, as this could enhance the paper's significance. Further exploration of the model's out-of-domain abilities and its performance in cold start scenarios would also strengthen the paper. Lastly, clarifying the differences between the proposed MoE framework and soft-attention mechanisms, as well as refining the ablation study analysis, would add depth to the discussion.