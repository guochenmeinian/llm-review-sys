ID: ZE6fN4OO18
Title: Leveraging Multiple Teachers for Test-Time Adaptation of Language-Guided Classifiers
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents TALC: Test-time Adaptation of Language-guided classifiers, which addresses the classification of unlabeled data using multiple natural language explanations. TALC builds on the ExEnt model and introduces a learnable label aggregation component that utilizes an EM algorithm to weight predictions from explanations. The authors demonstrate that TALC outperforms ExEnt by 3.3% across six tasks in the CLUES benchmark and provide extensive analysis on various factors affecting performance.

### Strengths and Weaknesses
Strengths:
- The paper tackles an important problem in test-time adaptation for language-guided classifiers, aligning well with real-world applications.
- TALC shows strong empirical results, outperforming the previous state-of-the-art method, ExEnt.
- The analysis of the method's sensitivity to the number and quality of explanations is thorough.

Weaknesses:
- The novelty and technical contributions of TALC compared to existing data programming techniques, particularly MeTaL, require clearer justification.
- The methodology lacks clarity, particularly regarding the label aggregator and the rationale for using EM over other methods.
- Baselines do not include larger language models, limiting the comparison scope.
- The paper does not provide sufficient direct takeaways from the analysis, making it difficult to apply the findings in practice.

### Suggestions for Improvement
We recommend that the authors improve the justification of TALC's novelty compared to MeTaL, clarifying the distinctions between the two approaches. Additionally, including baselines with larger language models, such as GPT-3, would enhance the evaluation. We suggest providing clearer explanations of the label aggregator and the choice of EM over variational inference, possibly including update equations in the appendix. Lastly, we encourage the authors to distill direct takeaways from their analysis to guide practical application, such as optimal adaptation ratios and the number of explanations needed for effective performance.