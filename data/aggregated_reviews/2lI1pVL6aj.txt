ID: 2lI1pVL6aj
Title: CRAB: Assessing the Strength of Causal Relationships Between Real-world Events
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 9
Original Ratings: -1, -1, -1, -1, 2, 2, 2, 3, -1
Original Confidences: -1, -1, -1, -1, 2, 3, 3, 3, 4

Aggregated Review:
### Key Points
This paper presents the Causal Reasoning Assessment Benchmark (CRAB), a dataset comprising 2,730 pairs of real-world events aimed at evaluating causal understanding in narratives. The authors detail the dataset's creation, which involved extracting events from 173 documents and annotating causal relationships through human evaluators. The paper analyzes the performance of various language models (LMs) on this dataset, revealing significant challenges in capturing complex causal structures.

### Strengths and Weaknesses
Strengths:  
- The dataset is a valuable resource for research, focusing on real-world events and causal relations.  
- The annotation process appears thorough, with multiple annotators involved, ensuring a level of quality in the data.  
- The paper is well-written, providing clear explanations of labeling methods and data statistics.

Weaknesses:  
- The dataset's limited scope, based on only 20 stories, raises concerns about its generalizability.  
- Key details regarding the dataset creation process, such as selection criteria for stories and events, are inadequately addressed.  
- The evaluation of LMs is critiqued for relying on models that were not fine-tuned for the task, leading to poor performance results.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the dataset creation methodology by including details on how stories were selected and the criteria used by annotators to score causal relations. Additionally, consider training a simple model with the dataset to provide a more robust evaluation of causal reasoning capabilities. It would also be beneficial to discuss the implications of using LMs for causal reasoning, particularly regarding biases in human judgments, and to clarify the definitions of causality and responsibility within the context of the task. Lastly, ensure that all figures referenced in the text are included and correctly labeled to avoid confusion.