ID: eDNslSwQIj
Title: Neural Assets: 3D-Aware Multi-Object Scene Synthesis with Image Diffusion Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 7, 7, 7, 6, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method for 3D-aware editing of multi-object images using an object-centric representation called Neural Assets. The authors propose conditioning a diffusion model on per-object appearance and pose tokens, allowing for fine control over object poses and enabling applications such as object transfers between scenes. The method is trained on videos with 3D bounding box annotations, demonstrating superior performance compared to existing methods, particularly in multi-object settings.

### Strengths and Weaknesses
Strengths:
- The approach effectively disentangles appearance and pose features for multi-object images.
- The method outperforms state-of-the-art 3D-aware image editing techniques, particularly in multi-object scenarios.
- The generated images exhibit impressive realism, especially in the Waymo Open dataset.

Weaknesses:
- The paper lacks an in-depth discussion comparing the proposed architecture with existing works like BlobGAN-3D.
- Background modeling issues are noted, particularly in the Objectron dataset, where object transformations affect the background inappropriately.
- There is no measure of 3D consistency, which could enhance the evaluation of the proposed method.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the superiority of their network architecture compared to existing methods, particularly BlobGAN-3D. Additionally, addressing the background modeling issues in the Objectron dataset is crucial; exploring alternative modeling techniques could mitigate the observed problems. We also suggest incorporating a measure of 3D consistency to evaluate the proposed method against benchmarks like zero-1-to-3. Finally, presenting failure cases would provide deeper insights into the model's performance limitations.