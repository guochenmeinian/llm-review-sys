ID: ZFwNdsDCRL
Title: Learning to Reason and Memorize with Self-Notes
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 5, 6, 7, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel prompting approach for LLMs called "Self-Notes," which allows models to generate intermediate notes while processing prompts, rather than only at the end. The authors evaluate this method across various reasoning benchmarks and model types, including supervised, semi-supervised, unsupervised, and few-shot prompted models. The results indicate that Self-Notes can enhance reasoning performance, particularly in generalizing to unseen cases.

### Strengths and Weaknesses
Strengths:
- The concept of generating Self-Notes during input processing is innovative and has not been previously explored.
- The paper evaluates multiple datasets and tasks, including Toy-Story and Chess simulations.
- It effectively situates itself within the existing literature and is well-written.

Weaknesses:
- The reliance on relatively small models, particularly GPT-2, raises concerns about the generalizability of the findings to larger models, which may exhibit different behaviors.
- Few-shot prompting experiments were conducted using GPT-J, which is less robust compared to newer models like GPT-3/4.
- The evaluation of Self-Notes on stronger models is lacking, limiting the paper's soundness and contribution.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by testing Self-Notes on larger models such as GPT-3.5, GPT-4, and open-source alternatives like LLaMA and LLaMA-2. Additionally, conducting semi-supervised experiments across all tasks and ensuring consistent evaluation sets for all experiments would strengthen the findings. Lastly, addressing the potential scaling challenges and societal impacts of the proposed method would enhance the paper's comprehensiveness.