ID: lnnNPiZtzR
Title: FungiTastic: A multi-modal dataset and benchmark for image categorization
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 3, 8, 8, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the FungiTastic dataset, a large-scale, multi-modal collection of fungi images and associated metadata, including satellite images, meteorological observations, and segmentation masks. The dataset comprises approximately 350,000 observations across over 6,500 categories, aiming to support various machine learning tasks such as closed-set and open-set classification, few-shot learning, and temporal classification. The authors propose benchmark challenges that address real-world applications and emphasize the dataset's potential for advancing image classification technology. Furthermore, the paper explores open set classification, temporal image classification, and classification beyond the 0-1 loss function, asserting that open set classification requires datasets with diverse and incremental classes, high variability, and both labeled and unlabeled data. For temporal image classification, the dataset should consist of sequences of images with corresponding labels that may change over time. The authors also highlight the importance of nuanced loss functions for classification beyond 0-1 loss, particularly in scenarios with class imbalance and hierarchical class labels.

### Strengths and Weaknesses
Strengths:
- The dataset offers a comprehensive and diverse resource for research in multi-modal classification and biological studies.
- The challenges proposed are well-motivated and relevant, enhancing the dataset's utility for the broader machine learning community.
- The paper is well-structured and clearly written, providing detailed descriptions of the dataset's components.
- The authors address critical aspects of open set classification, temporal image classification, and advanced loss functions, providing a well-rounded discussion on dataset requirements.
- The authors acknowledge the need for baseline experiments and have committed to adding them, which enhances the paper's credibility.

Weaknesses:
- The contributions of the paper are unclear, particularly regarding the novelty of the dataset compared to existing resources.
- The paper lacks a checklist, and the links to Kaggle and GitHub are either broken or incomplete.
- There is insufficient analysis of the methodological approaches and existing methods, particularly concerning the use of metadata and multi-modal data in experiments.
- The current state of the art does not fully support the ambitious goals set by the authors, as indicated by the frequent use of "can be" and "could be" in the dataset examples.
- There is a lack of thorough comparisons with related biological datasets and insufficient baseline experiments, particularly for multimodal and temporal image classification.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their contributions, explicitly stating the novelty of the dataset and its attributes. The introduction should be concise and include citations to support claims. The authors should also revise the related works section to incorporate recent biological datasets. We suggest providing a complete and functional GitHub page and correcting the Kaggle link. Additionally, we recommend that the authors improve the clarity of the term "temporal image classification" by considering the use of "domain shift" to emphasize the differences between training and test data distributions. The authors should include specific baseline experiments that exploit camera data and demonstrate the impact of metadata on problem-solving. Finally, we encourage the authors to provide results for temporal image classification in Section 3.2 to strengthen their argument and conduct experiments utilizing the multi-modal nature of the dataset, including baseline experiments in the supplementary materials. Lastly, the overall presentation of the paper requires significant refinement for clarity and coherence.