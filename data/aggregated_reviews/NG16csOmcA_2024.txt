ID: NG16csOmcA
Title: Neural Residual Diffusion Models for Deep Scalable Vision Generation
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 6, 5, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework for visual generative diffusion models, addressing challenges related to numerical propagation errors and scalability in deep stacked networks. The authors propose Neural Residual Diffusion Models (Neural-RDM), introducing learnable gated residual parameters to enhance generative denoising capabilities. The paper links the dynamics of the diffusion-based neural network to an ODE, deriving a novel loss function and validating it through extensive experiments in image and video generation.

### Strengths and Weaknesses
Strengths:
- The paper effectively unifies the dynamics of z_t across UNet and Flow architectures and derives a highly useful loss function based on these dynamics.
- The theoretical analysis, including the use of continuous-time neural ODEs, is well-motivated and clear.
- Extensive experiments demonstrate state-of-the-art performance on various generative tasks.

Weaknesses:
- Some sections, particularly 2.2 and 2.3, lack clarity, especially regarding variable dimensions and the network's denoising capabilities.
- The captions for Figures 1 and 2 do not adequately explain the figures, leading to confusion about the differences and meanings of various lines.
- The introduction of gated residual parameters may complicate the model, potentially hindering training and understanding.
- The specific definitions of "Scalability" in Tables 1 and 2 are unclear, and scalability comparisons with baseline architectures are insufficient.

### Suggestions for Improvement
We recommend that the authors improve the clarity of sections 2.2 and 2.3 by explicitly mentioning the dimensions of involved variables and clarifying whether the network is used to completely or partially denoise the input. Additionally, please enhance the captions for Figures 1 and 2 to explain the differences and meanings of the lines more thoroughly. It would also be beneficial to provide a clearer definition of the "Scalability" metrics in Tables 1 and 2 and to include comparisons with baseline architectures to better illustrate scalability. Finally, consider adding a discussion on how the value of gamma was empirically determined, possibly in the supplementary materials.