ID: 7RwKMRMNrc
Title: You Don’t Need Domain-Specific Data Augmentations When Scaling Self-Supervised Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 7, 5, 5, -1, -1, -1, -1
Original Confidences: 4, 4, 5, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper examines the necessity of hand-crafted domain-specific data augmentations in self-supervised learning (SSL), particularly in the context of Joint-Embedding Architectures (JEAs) like DINOv2. The authors demonstrate through experimental analysis that the primary benefit of data augmentation is to increase the effective dataset size, and with sufficient data, compute, and model complexity, the performance gap between using and not using such augmentations can be minimized. The findings suggest that effective image representations can be achieved with minimal augmentation—specifically cropping without resizing—while still attaining state-of-the-art results.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and easy to follow, presenting a clear motivation and experimental results.
- It addresses a fundamental question in SSL, providing insights into the application of SSL to new data modalities.
- The experimental results convincingly support the argument that scaling dataset size can close the performance gap with and without hand-crafted augmentations.

Weaknesses:
- The experiments exclusively utilize DINOv2, raising concerns about the generalizability of the findings across different SSL algorithms and architectures.
- The title is misleading as cropping is still considered an augmentation; thus, the claim that "you don't need data augmentations" is not fully substantiated.
- The paper lacks evidence regarding the generalizability of learned representations to non-vision domains, such as medical imaging, where cropping may not be effective.
- There is insufficient discussion on the model's ability to learn invariance to augmentations, which is crucial for understanding the implications of the findings.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the title to accurately reflect the use of cropping as an augmentation. Additionally, the authors should conduct experiments with other SSL models to validate the claim of not needing augmentations across different architectures. It would also be beneficial to provide evidence of the generalizability of their learned representations to non-visual domains, addressing potential limitations in the effectiveness of cropping in those contexts. Finally, we suggest including a discussion on the model's learning of invariance to augmentations, as this perspective is relevant to the work.