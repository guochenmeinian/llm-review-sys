ID: LClyG4vZmS
Title: Cascading Bandits: Optimizing Recommendation Frequency in Delayed Feedback Environments
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 7, 4, 6, 6, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents modifications to the cascading bandit setting to accommodate delayed feedback and user abandonment, making it applicable to online ad retargeting. The authors propose an algorithm for optimizing message queueing with fixed user/environment parameters and a UCB-style algorithm for learning these parameters while making decisions. They provide regret bounds for their algorithm and conduct experiments in both non-contextual and contextual settings. The work generalizes the cascading bandit model by allowing for delayed feedback, variable action frequency, and personalized recommendations.

### Strengths and Weaknesses
Strengths:  
- The authors propose a significant modification to cascading bandits, enhancing its applicability to real-world problems like online advertising.  
- The paper includes algorithms for both contextual and non-contextual cases, supported by theoretical proofs and experiments.  
- The writing is generally clear, and the motivation for the study is well articulated.

Weaknesses:  
- There are concerns regarding the implementation of the UCB heuristic in Algorithms 2 and 3, specifically the use of q^UCB instead of q^LCB.  
- The experiments lack a comparison to a standard cascading bandits baseline.  
- The assumption that each message can only be used once is seen as restrictive.  
- The theoretical analysis is limited, particularly regarding the regret bounds for Algorithm 2 and the computational feasibility of the proposed methods.

### Suggestions for Improvement
We recommend that the authors improve the implementation of Algorithms 2 and 3 by using q^LCB instead of q^UCB to align with the optimism in the face of uncertainty heuristic. Additionally, the authors should include comparisons to traditional cascading bandit baselines in their experiments. It would be beneficial to relax the assumption that each message can only be used once and to address the computational feasibility of the dynamic programming approach used in their method. Furthermore, we suggest providing a detailed comparison of the regret bounds for Algorithm 2 with existing bounds and discussing the implications of the fixed message frequency assumption. Lastly, the literature review should be expanded to include relevant works on Thompson sampling algorithms and click models that incorporate user abandonment.