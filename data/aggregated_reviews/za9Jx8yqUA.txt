ID: za9Jx8yqUA
Title: GenRL: Multimodal-foundation world models for generalization in embodied agents
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 5, 7, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for leveraging foundation multimodal models to learn world models for reinforcement learning (RL) through a connector-aligner mechanism integral to the GenRL framework. The authors propose aligning the latent space of a video language model (VLM) with that of a generative world model via connector and aligner networks. This alignment allows for deriving rewards based on the cosine similarity between states visited by a policy and those generated by the connector-aligner when conditioned on language prompts. The authors conducted experiments across 35 tasks, revealing that while the aligner is crucial for GenRL's performance, its absence leads to a notable decline in effectiveness compared to baseline methods. The paper evaluates GenRL's performance across various tasks, including Walker Walk, Stickman Run, Stickman Lunge Pose, and Walker High Kick, indicating varying levels of success and challenges in multitask generalization.

### Strengths and Weaknesses
Strengths:  
- The core idea of transferring foundation model knowledge to enhance policy learning is relevant and timely.  
- The paper provides a novel approach to aligning a foundation model with a world model, which has not been extensively explored in prior work.  
- The additional experiments provide valuable insights into the contributions of the connector-aligner mechanism.  
- The writing is generally clear, and the preliminary results indicate promise in generalizing to new tasks.  
- GenRL achieves expert-level performance in the Walker Walk task, demonstrating effective behavior.  
- The authors acknowledge the challenges of adding the Humanoid environment, providing transparency regarding computational costs.

Weaknesses:  
- The evaluation is limited in scope, with few environments and baselines compared to other text-conditioned policy learning methods.  
- The clarity of certain experimental details is lacking, particularly regarding the training of the aligner and connector networks.  
- The claims about generalization and the effectiveness of the method are not sufficiently supported by robust experimental evidence.  
- The performance of GenRL without the aligner is significantly worse than that of the baselines, raising questions about the underlying advantages of the proposed method.  
- The choice of evaluation metrics, particularly the use of HNS for expert policies, lacks strong justification and may not align with common practices in the field.  
- The agent struggles with tasks outside its training distribution, limiting its generalization capabilities in the Kitchen environment.  
- The lack of clarity regarding the performance differences between GenRL and baselines without the aligner remains a concern.

### Suggestions for Improvement
We recommend that the authors improve the evaluation suite by including additional environments and comparing against more diverse baselines, such as LIV for kitchen settings or Text2Reward for general cases. Clarifying the rationale behind the evaluation strategy and addressing the sparse details regarding the model components, such as the aligner's implementation, would enhance the paper's clarity. Additionally, we suggest providing stronger evidence for the claims of generalization and reconsidering the use of the term "data-free RL," potentially adopting terminology like zero-shot reward models. We encourage the authors to improve the analysis of why GenRL without the aligner performs poorly compared to the baselines, and to provide additional visualizations in the Appendix to illustrate the impact of the aligner on decoding language prompts. Furthermore, we suggest that the authors elaborate on the challenges faced in multitask generalization, particularly in the Kitchen environment, to provide a more comprehensive discussion of the limitations and potential solutions. Lastly, we recommend revising their evaluation approach, particularly the use of HNS for expert policies, to align with standard practices and provide a more straightforward interpretation of results.