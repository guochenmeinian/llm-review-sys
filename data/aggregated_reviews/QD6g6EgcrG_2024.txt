ID: QD6g6EgcrG
Title: EnsemW2S: Can an Ensemble of LLMs be Leveraged to Obtain a Stronger LLM?
Conference: NeurIPS
Year: 2024
Number of Reviews: 2
Original Ratings: 7, 7
Original Confidences: 2, 4

Aggregated Review:
### Key Points
This paper presents a new method for weak-to-strong generalization in LLMs, utilizing weak models trained on simpler tasks to supervise stronger models on complex tasks. The authors propose an AdaBoost-inspired ensemble algorithm, EnsemW2S-AdaBoost, to enhance the performance of stronger LLMs on QA datasets. The methodology is well-founded and adapted for both classification and generative tasks, demonstrating significant improvements over existing baselines.

### Strengths and Weaknesses
Strengths:  
1. The paper is clearly written and well-motivated.  
2. The EnsemW2S-AdaBoost method effectively utilizes multiple weak LLMs to improve performance on complex tasks, addressing challenges in applying AdaBoost to generative AI models.  
3. Comprehensive experiments show the effectiveness of ensemble learning in weak-to-strong generalization, reporting up to 14% improvement over baselines.  
4. The writing is technical yet accessible, with effective use of figures and tables to illustrate results.  

Weaknesses:  
1. The study primarily focuses on GPT-2 variants, which may not represent the diversity of LLM architectures.  
2. Experiments are limited to multiple-choice QA datasets; broader evaluation on diverse NLP tasks is needed.  
3. The paper lacks a detailed analysis of why the ensemble method outperforms single weak supervisors and the limitations encountered.

### Suggestions for Improvement
We recommend that the authors improve the diversity of LLM architectures in their experiments to better represent the field. Additionally, expanding the evaluation to include a broader range of NLP tasks would strengthen the findings. Finally, providing a deeper analysis of the ensemble method's advantages over single weak supervisors and discussing encountered limitations would enhance the paper's contributions.