ID: LrIzmhveQM
Title: HaSa: Hardness and Structure-Aware Contrastive Knowledge Graph Embedding
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method for mining true hard negative samples in contrastive learning for knowledge graph embedding (KGE), specifically addressing the generation of false negative triples. The authors propose the Hardness and Structure-aware (HaSa) method, which integrates a heuristic-based approach that correlates the distance between head and tail entities with the number of false negatives. The methodology incorporates important sampling and the law of total expectation into the optimization process. The evaluation demonstrates that HaSa achieves competitive results on the WN18RR and FB15k-237 datasets compared to traditional KGE methods.

### Strengths and Weaknesses
Strengths:
- The paper introduces significant findings regarding the characteristics of false negative triples.
- The theoretical derivation and implementation of the HaSa method are well-articulated and supported by experimental data.

Weaknesses:
- The performance on the FB15k-237 dataset is not convincing, with results falling short of state-of-the-art benchmarks.
- The writing and presentation require improvement, particularly the related work section and the absence of a method overview figure.
- Important recent baselines in KGE, such as SimKGC, PairRE, and DualE, are missing from the experiments.
- The experiments lack comprehensive comparisons with other negative sampling methods and do not utilize consistent backbones across different models.

### Suggestions for Improvement
We recommend that the authors improve the performance evaluation on the FB15k-237 dataset to better demonstrate the superiority of HaSa. Additionally, the authors should enhance the presentation quality by expanding the related work section and including a method overview figure. It is crucial to incorporate recent KGE baselines in the experiments and to conduct a thorough comparison with other negative sampling methods. We also suggest using the same backbone for all PLM-based KGE methods to ensure fair comparisons and to explore HaSa's applicability to classical KGE methods. Finally, addressing the identified typos and clarifying the claims regarding state-of-the-art results will strengthen the paper's credibility.