ID: YxyYTcv3hp
Title: Ferrari: Federated Feature Unlearning via Optimizing Feature Sensitivity
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 5, 8, 5, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 5, 5, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents "Ferrari," a framework for federated feature unlearning that optimizes feature sensitivity to uphold the 'right to be forgotten' in machine learning. Ferrari enables clients to remove sensitive or biased features from a model without requiring full retraining or access to other clients' data. The authors demonstrate that unlearning a feature for one client can inadvertently affect similar features in other clients, as shown in empirical results across various datasets. They argue that removing sensitive features from the global model is essential for compliance with regulations like GDPR while maintaining model utility for other clients. The authors also highlight the effectiveness of their approach in Non-IID, backdoor, and bias unlearning scenarios, asserting that Ferrari incurs less utility loss compared to exact unlearning methods.

### Strengths and Weaknesses
Strengths:  
1. Originality: Ferrari offers a novel perspective on federated learning, emphasizing data privacy through feature unlearning.  
2. Quality: The paper is well-organized, featuring a comprehensive set of experiments that demonstrate the unlearning process and its implications for feature sensitivity and Membership Inference Attack (MIA) rates.  
3. Clarity: The presentation is clear, effectively delineating the problem, solution, and results, supported by helpful figures and tables.  
4. Significance: This work is crucial for enhancing data privacy in machine learning, aligning with ethical AI practices, and effectively arguing the necessity of feature removal for regulatory compliance without significantly diminishing model utility.  

Weaknesses:  
1. The article's format requires rechecking, as some formulas are incorrectly placed after punctuation.  
2. There is insufficient analysis of Ferrari's robustness against adversarial attacks aimed at reintroducing forgotten features.  
3. More real-world application details are needed, particularly regarding network delays, client availability, and the computational burden on client devices.  
4. The challenges of the paper are not well articulated, and the sensitivity reduction approach may not adequately address federated feature unlearning.  
5. The potential impact of unlearning on model performance for clients with similar features may require further exploration.  
6. The distinction between "unseeing" and unfitting could benefit from additional clarification to enhance understanding.  

### Suggestions for Improvement
We recommend that the authors improve the article's formatting to correct the placement of formulas. Additionally, the authors should provide a thorough evaluation of Ferrari's defenses against potential adversarial attacks that seek to reintroduce unlearned features. It would also be beneficial to include more practical insights on implementing Ferrari in real-world scenarios, addressing factors such as network delays and client device workloads. Furthermore, we suggest enhancing the clarity of the challenges presented in the paper and exploring the implications of sensitivity reduction in the context of federated feature unlearning. Lastly, we recommend improving the discussion on the implications of unlearning for clients with similar features to address potential concerns about model performance, as well as providing a more detailed explanation of the concept of "unseeing" versus unfitting to clarify this critical aspect of their methodology.