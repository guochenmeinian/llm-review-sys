ID: BROvXhmzYK
Title: SELF-DISCOVER: Large Language Models Self-Compose Reasoning Structures
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 6, 4, 5, 4, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents SELF-DISCOVER, a framework that enhances the reasoning capabilities of Large Language Models (LLMs) by enabling them to autonomously identify and compose intrinsic reasoning structures tailored for various tasks. The framework operates through a two-stage process: first, it selects and adapts reasoning modules, and then implements these modules into a JSON reasoning structure for task execution. The authors evaluate SELF-DISCOVER against several baselines, demonstrating its superior performance across multiple benchmarks while maintaining low computational costs.

### Strengths and Weaknesses
Strengths:
- The proposed method significantly improves LLM reasoning abilities, achieving substantial performance gains with only 3 extra inference calls per task.
- The evaluations are robust, with empirical evidence supporting all major claims, including thorough ablation studies that validate the contributions of each step in the process.
- The reasoning structures generated show strong transferability across different LLM families, enhancing the framework's applicability.

Weaknesses:
- The paper inadequately emphasizes the necessity of task adaptation, limiting its classification as a general zero-shot method. This aspect should be more clearly articulated.
- The effectiveness of the framework heavily relies on the quality of atomic reasoning modules, which may require significant human effort to define, and no guidelines are provided for their development.
- The comparative analysis lacks depth, as it does not include recent state-of-the-art methods or a broader range of models beyond GPT-4 and PaLM-2.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the necessity of task adaptation to clarify the framework's limitations as a zero-shot method. Additionally, including more comparisons with recent prompt adaptation techniques and automatic prompting engineering methods would strengthen the analysis. The authors should also provide guidelines for developing atomic reasoning modules and conduct a systematic evaluation across a wider range of models. Finally, a more comprehensive comparative analysis with recent literature and methods would enhance the paper's contribution.