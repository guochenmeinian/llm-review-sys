ID: ce9B2x3zQa
Title: Max-Sliced Mutual Information
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 7, 6, 8, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Max-Sliced Mutual Information (mSMI), a novel measure that captures maximal mutual information between low-dimensional projections of high-dimensional variables. The authors demonstrate that mSMI retains essential properties of mutual information and can be efficiently estimated using a neural network, outperforming existing methods for estimating average-SMI. The paper also discusses the relationship between mSMI and canonical correlation analysis (CCA), introduces multivariate conditional mSMI, and explores its applications in independence testing, multi-view representation learning, and algorithmic fairness.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and detailed, providing significant theoretical contributions and practical implementations.
- mSMI is a natural extension of sliced mutual information (SMI) and shows promising results in various applications.
- The neural estimation method for mSMI is computationally efficient and offers better error rates compared to traditional methods.

Weaknesses:
- The incremental nature of mSMI relative to existing measures like SMI and k-SMI raises questions about its novelty.
- The paper lacks comparisons between mSMI and SMI in multi-view representation and fair representation contexts.
- Some explanations, particularly regarding non-Gaussian data and the extension of theoretical results to deep architectures, are insufficiently detailed.

### Suggestions for Improvement
We recommend that the authors improve clarity in sections discussing the implications of mSMI for non-Gaussian data, particularly in Remark 4, and provide concrete examples of how projections differ from CCA. Additionally, we suggest including a comparison of mSMI with SMI in the contexts of multi-view representation and fair representation to substantiate its advantages. Lastly, we encourage the authors to elaborate on how the theoretical results can be extended to deep networks and other activation functions, addressing potential difficulties and solutions.