ID: GtgFo5lmOB
Title: Joint Data-Task Generation for Auxiliary Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 6, 5, 6, 7, 7, -1, -1, -1, -1
Original Confidences: 3, 2, 4, 5, 5, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel auxiliary learning framework that jointly generates new auxiliary data and tasks to address the negative transfer problem associated with manually collected auxiliary data. The authors propose a joint data-task generation framework (DTG-AuxL) that employs a bi-level optimization strategy to optimize both the task learning model and the data generation model. The framework is designed to be applicable across various scenarios, including both regression and classification tasks. Experimental results demonstrate that DTG-AuxL outperforms existing methods, even in cases where auxiliary data may be harmful.

### Strengths and Weaknesses
Strengths:
- The proposed method effectively addresses the negative transfer issue in auxiliary learning, showing strong results across multiple benchmarks.
- The paper is well-organized, with clear explanations of the methodology and comprehensive experimental validation.
- The framework's adaptability to different types of input data and tasks enhances its applicability.

Weaknesses:
- The contribution of the bi-level optimization strategy is questionable, as it has been previously proposed in prior works. Instance regularization appears to be a straightforward application of existing techniques.
- Experiments are limited in scope, primarily focusing on simple tasks with single auxiliary tasks. Broader experimentation with more complex tasks and multiple auxiliary tasks is necessary.
- The rationale behind the framework's ability to improve performance despite harmful auxiliary tasks is insufficiently explained.
- The visualization of generated data lacks clarity, and the relationship between task generation and label generation needs further elaboration.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the explanation regarding the framework's performance in the presence of harmful auxiliary tasks. Additionally, we suggest expanding the experimental scope to include more complex tasks and multiple auxiliary tasks, similar to previous studies. It would be beneficial to discuss the potential application of pretrained generative models, such as Stable Diffusion, to enhance the framework. Furthermore, we advise moving the experimental results related to the MixUp comparison from the appendix to the main manuscript for better visibility. Lastly, please ensure that all tables are formatted for clarity and ease of reading, and consider adding citations for methods in the experimental tables.