ID: ZZgfS1DbmO
Title: Continuous Parametric Optical Flow
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 5, 5, 5, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 4, 5, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel continuous parametric optical flow estimation method utilizing B-spline representations and ODE-ConvGRU for feature extraction. The authors propose a network that processes multiple image frames to output control points for each pixel, demonstrating competitive performance against existing methods like RAFT and PIPs. Extensive experiments, including the creation of new datasets, validate the effectiveness of the proposed approach.

### Strengths and Weaknesses
Strengths:
- The concept of estimating continuous optical flow using a neural network is relatively novel.
- The experimental results are promising and competitive with state-of-the-art methods.
- The presentation is generally clear, and the ablation study highlights the advantages of the B-spline representation and ODE-ConvGRU.

Weaknesses:
- The paper contains numerous typos and lacks smooth transitions, indicating a need for additional proofreading.
- The literature review is insufficient, failing to adequately position the work within the existing body of research and lacking clarity on its unique contributions.
- Scalability issues arise due to high memory requirements when processing multiple frames, raising concerns about fairness compared to less memory-intensive techniques.
- The novelty of the contribution is questionable, as much of the work appears inspired by existing techniques, particularly regarding the use of ODE-ConvGRU.
- Specific limitations of the technique, such as performance under varying motion complexities and the implications of using B-splines, are not thoroughly addressed.

### Suggestions for Improvement
We recommend that the authors improve the overall editorial quality by thoroughly proofreading the manuscript to eliminate typos and enhance the flow of the text. Additionally, the literature review should be expanded to better contextualize the work and clarify its unique contributions compared to existing methods. It would be beneficial to explicitly outline potential downstream applications of the technique, such as 3D modeling, tracking, or stabilization. Furthermore, the authors should address scalability concerns by investigating the model's performance under different motion scenarios and providing clarity on the computational complexity and memory costs associated with the proposed algorithm. Lastly, we suggest that the authors elaborate on the limitations and broader societal impacts of their work in a dedicated section.