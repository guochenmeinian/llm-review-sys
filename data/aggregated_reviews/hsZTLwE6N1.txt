ID: hsZTLwE6N1
Title: DensEMANN: How to Automatically Generate an Efficient while Compact DenseNet
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 4, 3, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 2, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an enhanced version of DensEMANN, an algorithm designed for neural architecture search (NAS) that efficiently grows and trains small DenseNet architectures. The authors employ a macro-algorithm for layer expansion and a micro-algorithm for constructing convolution operations, claiming to generate novel architectures within a few GPU hours. The evaluation is conducted on popular benchmarks, including CIFAR-10, Fashion-MNIST, and SVHN, aiming to achieve state-of-the-art performance in terms of accuracy and model size.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and provides detailed experimental settings.
- The pruning and recovery stages are novel and clearly explained, contributing to the architecture's efficiency.
- The approach of growing architectures at both macro and micro levels is valid and shows comparable performance to state-of-the-art methods.

Weaknesses:
- The motivation for the research needs further clarification.
- The novelty of the contributions is limited, primarily consisting of hyperparameter adjustments to the existing DensEMANN algorithm.
- The experimental comparison with the original DensEMANN is absent, and the method is only tested on small datasets, raising questions about its applicability to larger datasets like ImageNet-1k.
- The paper does not adequately justify the parameter limit of 500k, nor does it explore the implications of exceeding this limit.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation behind their research. Additionally, it would be beneficial to include a direct comparison with the original DensEMANN to highlight the advancements made. We suggest conducting experiments on larger datasets, such as ImageNet-1k, to assess the algorithm's scalability and performance. Furthermore, the authors should provide a clearer rationale for the chosen parameter limit of 500k and explore the potential for adapting DensEMANN to other tasks beyond image classification. Lastly, we encourage the authors to focus on quality per unit time in their performance comparisons, as this is crucial for evaluating efficiency in NAS.