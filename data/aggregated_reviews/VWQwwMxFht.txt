ID: VWQwwMxFht
Title: Model Supply Chain Poisoning: Backdooring Pre-trained Models via Embedding Indistinguishability
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a transferable backdoor attack, named TransTroj, targeting pre-trained models (PTMs) by embedding backdoors that are indistinguishable from clean samples in the embedding space. The authors propose a two-stage optimization framework that separately optimizes triggers and model parameters to achieve this embedding indistinguishability. Experimental results indicate that TransTroj effectively transfers across various downstream tasks while maintaining model accuracy on clean data.

### Strengths and Weaknesses
Strengths:
1. The proposed attack can transfer to different downstream tasks, highlighting a significant security concern.
2. Comprehensive experiments demonstrate superior performance over baseline methods.
3. The paper is well-structured and easy to follow.

Weaknesses:
1. The authors' claim regarding the success rate of backdoor defenses based on qualitative similarity lacks robustness; incorporating quantitative measures, such as using pre-trained encoders like CLIP, would enhance this analysis.
2. The relationship between the proposed backdoor attack and universal adversarial attacks (UAP) needs clarification, as the global perturbation trigger shows similarities with UAP.
3. The fixed number of fine-tuning epochs (20) in experiments requires justification, as different tasks may necessitate varying fine-tuning steps.
4. The paper lacks a thorough discussion on how embedding indistinguishability addresses previous challenges, which would improve interpretability.

### Suggestions for Improvement
We recommend that the authors improve the analysis of backdoor defense techniques by incorporating quantitative measures of similarity between datasets. Additionally, the authors should clarify the distinctions between their backdoor attack and universal adversarial attacks, providing more insights into their methodology. Justifying the choice of 20 fine-tuning epochs in experiments is essential, as different tasks may require different settings. Finally, we suggest including a more in-depth discussion on how the proposed method addresses existing challenges to enhance interpretability.