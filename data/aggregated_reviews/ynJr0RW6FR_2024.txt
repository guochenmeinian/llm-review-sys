ID: ynJr0RW6FR
Title: ReGS: Reference-based Controllable Scene Stylization with Gaussian Splatting
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 5, 6, 6, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for stylizing 3D Gaussian Splatting (3DGS) using a single reference image, introducing a texture-guided control mechanism that differs from the position-guided approach in the original 3DGS. The method effectively edits the appearance of a pretrained 3DGS to align with the reference image's texture while maintaining the original geometry. The authors also modify the training loss to include depth-based geometry regularization and pseudo-view supervision. The results indicate that the proposed method achieves superior stylization compared to previous techniques.

### Strengths and Weaknesses
Strengths:
- The Gaussian splitting strategy based on color gradients is innovative and well-suited for the task.
- The ablation study demonstrates a reduction in the number of Gaussians needed for effective texture modeling.
- The paper is well-written, with adequate implementation details and convincing experiments.

Weaknesses:
- The novelty appears limited, primarily relying on Ref-NPR for image-reference-guided stylization.
- The method's performance with heavily stylized geometry remains unclear.
- The presentation could be improved, particularly in detailing the modified training algorithm and loss functions.
- Comparisons with only one table lack depth; more detailed quantitative analyses are needed.

### Suggestions for Improvement
We recommend that the authors improve the presentation of the modified training algorithm by utilizing *Algorithmic/Algorithm2E features of LaTeX* or providing pseudocode for clarity. Additionally, conducting ablation studies for the proposed loss functions would help verify their compatibility with 3DGS representations. We suggest including detailed tables for each test scene to enhance quantitative comparisons and visualizations showing how different style reference images affect a single scene. Finally, addressing the performance of the method with heavily stylized geometry would strengthen the paper's contributions.