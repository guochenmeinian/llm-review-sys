ID: MJJQRUFzeX
Title: Unified Convergence Theory of Stochastic and Variance-Reduced Cubic Newton Methods
Conference: NeurIPS
Year: 2023
Number of Reviews: 6
Original Ratings: 8, 5, 6, 3, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to solving minimization problems, particularly nonconvex ones, by introducing a "helper framework" that unifies stochastic and variance-reduced second-order algorithms. The authors claim that their framework allows for improved convergence rates for objectives with Lipschitz Hessians and can be applied to gradient-dominated functions. They analyze various settings of their main algorithm, Algorithm 1, which replicates different variants of Newton's method, including stochastic and variance-reduced Newton methods.

### Strengths and Weaknesses
Strengths:
- The approach is original, combining stochastic and variance-induced second-order algorithms.
- The writing quality is good, with clear notation and a solid recap of related work.
- The framework extends the analysis to gradient-dominated functions without assuming convexity.

Weaknesses:
- The necessity of a new framework for analyzing different variants of Newton's method is unclear.
- The practicality of the meta-algorithm is questioned, particularly regarding the estimation of input parameters like $m$.
- The improved complexity guarantees claimed in the paper lack clarity.
- The introduction of additional variables in the helper framework may complicate the understanding of basic second-order methods.

### Suggestions for Improvement
We recommend that the authors improve the clarity surrounding the necessity and insights provided by the helper framework. Additionally, please expand on the implementability of Algorithm 1, particularly regarding practical methods for setting the parameter $m$. We suggest providing more theoretical insights or experimental results on the new variables $\delta_1$ and $\delta_2$ to enhance understanding of the complexity guarantees. Furthermore, a discussion on the choice of helper functions and their properties would be beneficial. Lastly, addressing the lack of literature discussion on variance-reduced methods and strengthening the experimental section would enhance the paper's contribution.