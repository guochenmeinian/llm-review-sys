ID: fkmSyrSjnq
Title: Topic-Informed Dialogue Summarization using Topic Distribution and Prompt-based Modeling
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new model for Topic-Informed Dialogue Summarization, termed TIDSum, which captures and reflects the distribution of multiple topics within dialogues. The model utilizes an effective topic discovery mechanism called TopClus to estimate topic distributions and employs a task-specific soft-prompt, the "topic-informed prompt," to enhance the summarization process. The authors demonstrate that TIDSum achieves state-of-the-art performance on the SAMSum and DialogSum datasets.

### Strengths and Weaknesses
Strengths:  
- The model explicitly considers the distribution of multiple topics, resulting in comprehensive and representative summaries.  
- The integration of the "topic-informed prompt" enhances the encoder and decoder context vectors, effectively capturing topic information throughout the summarization process.  
- The experimental results indicate that TIDSum outperforms existing methods on key dialogue summarization datasets.  

Weaknesses:  
- The paper lacks a discussion on the scalability of the proposed model, which is crucial for real-world applications.  
- The model description is unclear in certain areas, particularly regarding the calculation of specific components.  
- Insufficient experimental analysis is presented; only ablation and main experiments are included, lacking deeper model and sample analyses.  
- The selection of a limited number of topics for the datasets raises questions about the model's effectiveness in more diverse dialogue scenarios.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the model description, particularly by providing a formula example for the calculation of the tip. Additionally, we suggest including a discussion on the scalability of the model and conducting further analyses to validate the assumption that the topic distribution in the ground truth summary aligns with that of the dialogue. Furthermore, testing the topic similarity between gold standard summaries and dialogue inputs could provide valuable insights. Lastly, enhancing the writing in certain methodological sections and providing more comprehensive analyses would strengthen the paper.