ID: Fy1S3v4UAk
Title: A Dual-Stream Neural Network Explains the Functional Segregation of Dorsal and Ventral Visual Pathways in Human Brains
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 7, 7, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a dual-stream neural network designed to simulate the functions of the ventral and dorsal visual streams in the human visual system. The network comprises a WhereCNN for spatial attention and gaze direction, and a WhatCNN for object recognition. The authors demonstrate that the WhereCNN predicts dorsal stream voxels better, while the WhatCNN excels in predicting ventral stream voxels. The study also investigates the functional specialization of these pathways and how the model's predictions align with human fMRI data.

### Strengths and Weaknesses
Strengths:
1. The dual-stream model is novel and effectively motivates the separation of processing streams, providing insights into human visual processing.
2. The experiments are well-reasoned, with logical comparisons to human gaze behavior and neural responses, enhancing the clarity of the contributions.
3. The paper offers substantial content, solid experimental results, and clear writing.

Weaknesses:
1. Some details are lacking, such as the datasets used for synchronous training and the rationale for differing learning rates when training the streams together versus separately.
2. The model's reliance on static data raises questions about its applicability to dynamic fMRI visual inputs; consideration of dynamic datasets could enhance training.
3. The claim that the functional segregation of the visual pathways is driven by different learning objectives is overly strong and not sufficiently supported by the results.
4. The relevance of the retinal transformations and foveated vision to performance is unclear, as the results suggest that task differences may be more critical.

### Suggestions for Improvement
We recommend that the authors improve the discussion on how their dual-stream model could benefit a broader computer vision audience, specifically addressing potential performance enhancements in object recognition or robustness. Additionally, providing numerical results or general discussions on these benefits would strengthen the paper. Clarifying the training details, particularly regarding the WhereCNN's learning from human gaze attention data, and addressing how the model relates to existing metrics like BrainScore would also be beneficial. Lastly, we suggest revisiting the claims about the functional segregation of the visual pathways to ensure they are adequately supported by the findings.