ID: NuMemgzPYT
Title: LLM-in-the-loop: Leveraging Large Language Model for Thematic Analysis
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a human-in-the-loop framework for thematic analysis (TA) that integrates large language models (LLMs) as collaborative agents alongside human coders. The proposed methodology involves four steps: data familiarization, initial code generation, refinement, and final coding. The authors demonstrate that the human coder and machine coder achieve higher inter-annotator agreement than the gold standard across two datasets. However, the agreement with a third human coder is significantly lower, raising questions about the reliability of the LLM's coding.

### Strengths and Weaknesses
Strengths:
- The framework effectively leverages LLMs to reduce labor and time in thematic analysis.
- Empirical results indicate that the human coder and machine coder exhibit "almost perfect" agreement.
- The study presents a novel application of LLMs in qualitative research, contributing valuable insights to the field.

Weaknesses:
- The evaluation is limited to one LLM and two datasets, making broader claims about LLM effectiveness in TA premature.
- Key concepts such as 'QR' and 'code' are not clearly defined, potentially confusing readers.
- The analysis lacks comprehensive metrics beyond cosine similarity, and the discussion of missed codes is insufficient.

### Suggestions for Improvement
We recommend that the authors improve the clarity of key concepts such as 'QR' and 'codebook' early in the paper. Additionally, we suggest expanding the evaluation to include more datasets and coders to strengthen the generalizability of the findings. Incorporating metrics like accuracy and recall, alongside a qualitative analysis of codebook generation, would provide a more robust evaluation. Furthermore, we encourage the authors to address the potential biases in the codebook that may affect inter-coder reliability, particularly in light of the discrepancies observed with Coder 3. Finally, enhancing the presentation of results, such as ensuring that tables and figures are discussed on the same page, would improve readability.