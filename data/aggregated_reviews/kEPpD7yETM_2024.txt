ID: kEPpD7yETM
Title: Large Language Models Play StarCraft II:Benchmarks and A Chain of Summarization Approach
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 5, 8, 6, -1, -1, -1
Original Confidences: 4, 3, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents TextStarCraft II, a text-based environment designed to evaluate the strategic decision-making and planning capabilities of large language models (LLMs) in real-time scenarios within StarCraft II (SC2). The authors propose the Chain of Summarization (CoS) method, which enhances LLMs' abilities to process complex information and make strategic decisions efficiently. Key experiments include testing various LLMs against SC2's built-in AI, evaluating commercial models on SC2 knowledge, and conducting human-AI matches to assess performance and strategic adaptability.

### Strengths and Weaknesses
Strengths:
- The introduction of the CoS method improves LLMs' ability to summarize and process complex game states, leading to more effective decision-making in real-time scenarios.
- The study contributes valuable insights into LLM capabilities and limitations in handling complex, real-time decision-making tasks, establishing a novel benchmark for LLM evaluation.

Weaknesses:
- The paper does not clearly explain how LLMs interact with the game, particularly regarding human players' adherence to LLM suggestions.
- Detailed information on latency and real-time feedback is lacking, raising questions about the method's responsiveness.
- The reliance on rule-based scripts for micro-management and text-based inputs may limit the diversity and applicability of AI strategies.
- The objective of how LLMs achieve victory is inadequately defined, and the execution of actions and observations within the textual setting is insufficiently explained.

### Suggestions for Improvement
We recommend that the authors improve the clarity of LLM interaction with the game, specifically addressing how human players utilize LLM suggestions. Additionally, we suggest providing detailed information on latency and the capability for real-time feedback. The authors should also consider diversifying the input methods beyond text to enhance strategy applicability. Furthermore, we encourage the authors to define the winning criteria for LLMs more explicitly and clarify the methodology regarding how LLMs execute actions and observe the environment.