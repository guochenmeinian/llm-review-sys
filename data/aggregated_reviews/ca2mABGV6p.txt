ID: ca2mABGV6p
Title: Faster Diffusion: Rethinking the Role of the Encoder for Diffusion Model Inference
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 8, 5, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an approach to accelerate diffusion model inference by reusing encoder features across time steps, significantly reducing computation and improving generation speed. The authors propose a prior noise injection method to enhance image quality and demonstrate their method's effectiveness across various tasks, including text-to-image and text-to-video generation. Extended experiments validate the approach's performance against state-of-the-art acceleration methods.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and presents insightful analysis, particularly in section 1 and Fig. 4, which illustrates encoder propagation methods.
2. The empirical evaluation is comprehensive, validating the method across diverse datasets and architectures, and includes comparisons with state-of-the-art methods like DeepCache.
3. The parallel denoising approach maintains an acceptable memory cost, addressing initial concerns.
4. The method can be seamlessly integrated with other acceleration techniques, enhancing its applicability.

Weaknesses:
1. The manual selection of key time-steps may not be optimal; automatic strategies for determining these steps should be explored to avoid repetitive analysis with new architectures.
2. Evaluation metrics are limited, particularly regarding the universality of FID; additional metrics like ImageReward and Pick Score should be considered.
3. The latency comparison with fewer sampling steps is unclear, and the marginal performance improvement seems primarily due to prior noise injection rather than the core contribution.
4. Comparisons between multi-GPU and single-GPU results may not be fair, and the paper's organization could be improved for clarity.

### Suggestions for Improvement
We recommend that the authors improve the selection process for key time-steps by investigating automatic strategies to enhance efficiency. Additionally, expanding the evaluation metrics to include ImageReward and Pick Score would provide a more comprehensive assessment of model performance. Clarifying latency comparisons when using fewer sampling steps and ensuring fair comparisons between multi-GPU and single-GPU results will strengthen the paper. Finally, we suggest reorganizing the layout for better coherence and readability, particularly regarding the order of tables and figures.