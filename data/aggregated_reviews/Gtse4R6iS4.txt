ID: Gtse4R6iS4
Title: Robustifying Generalizable Implicit Shape Networks with a Tunable Non-Parametric Model
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 5, 6, 5, 5, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 4, 3, 4, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method for implicit shape reconstruction from noisy point clouds, leveraging Kernel Ridge Regression (KRR) to enhance generalization and robustness. The authors propose a technique that combines a pre-trained occupancy network (Poco) with KRR to fine-tune implicit shape networks, addressing the limitations of existing deep learning methods that struggle with domain shifts and noise. Additionally, the authors introduce improvements to generalizable shape networks, tackling issues such as underfitting and the resource intensity of training large models. They propose a learnable N-KRR as an alternative to unstable network weight tuning, emphasizing its shape-specific expressiveness and regularization tradeoff, and utilize a Gaussian kernel for its universality properties. The method demonstrates improved performance on various datasets, including ShapeNet, FAUST, and ScanNet, compared to prior approaches, and the manuscript has been reorganized for clarity, with enhancements made to the introduction, related work, methodology, results, and limitations sections.

### Strengths and Weaknesses
Strengths:
- The proposed method achieves higher accuracy and robustness in surface reconstruction compared to existing techniques, effectively addressing generalization issues.
- The introduction of a learnable N-KRR provides a novel approach to address stability in network tuning.
- Extensive experiments validate the method's performance across multiple datasets, showcasing its ability to handle noisy input and improve reconstruction quality.
- The manuscript is well-organized, with improved writing that enhances clarity, particularly in the introduction and results sections.
- The integration of KRR with a pre-trained network is a logical approach that enhances the overall effectiveness of the reconstruction process.

Weaknesses:
- The clarity of the writing is a significant concern, particularly in the methodology section, which contains grammatical errors and lacks detailed explanations.
- The paper does not adequately discuss the computational overhead associated with the KRR optimization process, nor does it provide a clear rationale for the choice of training samples.
- There is insufficient exploration of the method's limitations, particularly regarding its performance on real-world data and the impact of varying input conditions.
- The relationship and differences from prior work could still be more explicitly articulated, particularly regarding references [76,78].
- Some aspects of the methodology may require further elaboration for better understanding.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing, particularly in the methodology section, to make it more accessible to novice readers. Additionally, it would be beneficial to include a discussion on the computational time required for KRR optimization and to clarify the reasoning behind the selection of training samples. We suggest that the authors provide more qualitative examples of failures and limitations, especially regarding the method's performance on complex geometries. Furthermore, we recommend improving the clarity of the relationship and differences from prior work, particularly regarding references [76,78], and providing further elaboration on certain methodological aspects to enhance reader comprehension. Finally, a more thorough comparison with classical methods and other test-time optimization techniques would strengthen the paper's contribution.