ID: 8NA76tz7Jj
Title: Data Augmentation for Code Translation with Comparable Corpora and Multiple References
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents methods for code translation, specifically translating programming languages like Python into Java, by addressing data scarcity through two data augmentation techniques. The authors propose generating comparable corpora using docstrings to create supervised data and enriching the training set with multiple target references filtered by unit tests. The experiments demonstrate positive results compared to baseline models, suggesting the methods are beneficial, particularly in low-resource scenarios.

### Strengths and Weaknesses
Strengths:
- The paper is well written, structured, and easy to understand.
- It employs a solid experimental method with positive results, exploring various pertinent questions.
- The incorporation of docstrings as a supervisory signal enhances the approach.

Weaknesses:
- The paper lacks novelty, as it builds on existing methods without introducing a new model.
- The explanations of results are at times unconvincing, particularly regarding the effectiveness of models trained on comparable corpora.
- The experimental design raises concerns, particularly the reliance on the CodeT5 model and the limited evaluation dataset.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their contributions and novelty compared to prior work. Additionally, addressing the confusion regarding the experimental design is essential. We suggest including statistical significance testing for the results to strengthen the claims made. Furthermore, consider discussing the potential of using advanced models like GPT-3.5/GPT-4 for generating parallel code pairs, and clarify the training process and quality of docstrings used in the generative model.