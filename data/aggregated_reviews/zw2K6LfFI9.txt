ID: zw2K6LfFI9
Title: PERIA: Perceive, Reason, Imagine, Act via Holistic Language and Vision Planning for Manipulation
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 6, 6, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework called PERIA that integrates large multimodal language models (MLLMs) and diffusion models for holistic language and vision planning in long-horizon robotic manipulation tasks. The authors propose a method that aligns visual and language encoders, generates subgoal images from language descriptions, and incorporates a consistency loss to enhance the relationship between generated language and images. Experimental results indicate that PERIA significantly outperforms competitive baselines.

### Strengths and Weaknesses
Strengths:
- The paper addresses the important challenge of long-horizon robotic planning, effectively combining language and visual generation.
- The alignment stage enhances overall capabilities, as demonstrated by the experimental results.
- The experiments are comprehensive, providing valuable insights into the trained MLLM's performance.

Weaknesses:
- The experimental evaluation is weak, lacking in-depth analysis of training and inference costs, and not addressing the trade-offs associated with different MLLMs.
- There is a lack of real-world evaluation, which is crucial for demonstrating the framework's effectiveness in practical scenarios.
- The utility of the diffusion model is unclear, as the tasks could potentially be handled by existing multimodal language models without additional training data.
- The explanation of the low-level policy is insufficient, leaving unclear how the MLLM outputs are integrated into robot motion.

### Suggestions for Improvement
We recommend that the authors improve the analysis of training and inference costs, including the trade-offs associated with different MLLMs in terms of training time, FLOPs, and MACs. Additionally, we suggest incorporating real-world evaluations to demonstrate PERIA's effectiveness in long-tailed object distributions. It would also be beneficial to include a baseline comparison with modern multimodal language models to clarify the diffusion model's contribution. Furthermore, we encourage the authors to provide a clearer explanation of the low-level policy and its integration with the MLLM outputs, as well as to justify the alignment loss's contribution through additional experimental results.