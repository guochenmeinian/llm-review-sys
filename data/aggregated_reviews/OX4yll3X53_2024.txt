ID: OX4yll3X53
Title: Local to Global: Learning Dynamics and Effect of Initialization for Transformers
Conference: NeurIPS
Year: 2024
Number of Reviews: 21
Original Ratings: 5, 6, 6, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates the learning dynamics of single-layer transformers on first-order Markov chains, focusing on the impact of parameter initialization. The authors propose a low-rank parameterization that simplifies the analysis to a three-variable learning dynamics, allowing for a comprehensive characterization of convergence conditions. They empirically validate their theoretical insights, demonstrating that specific initialization strategies can lead to improved convergence outcomes compared to standard methods. Additionally, the paper presents an analysis of attention mechanisms in transformers, emphasizing the learning of attention scores and the implications of initialization schemes. The authors utilize a 1-layer transformer with non-linear soft-max attention for experiments, while employing a linear attention mechanism for theoretical analysis. They argue that their initialization scheme outperforms standard Gaussian initialization due to insights derived from the loss landscape, as illustrated in their figures and characterized in the theoretical framework.

### Strengths and Weaknesses
Strengths:
- The paper is the first to highlight the critical role of initialization in transformer training dynamics.
- It provides a rigorous theoretical framework and empirical validation, enhancing the understanding of convergence behavior in transformers.
- The initialization analysis is deemed insightful and impactful, supported by robust experimental results.
- The presentation is generally clear, with well-structured explanations and high-quality visualizations.

Weaknesses:
- The generalizability of the insights is limited, as the study focuses on a simplified model with a binary input alphabet and single-layer transformers.
- The dynamics analysis is constrained to a low-rank manifold, raising concerns about the applicability of results to more complex architectures.
- There are inconsistencies in the definitions of the attention scalar $a$, leading to confusion regarding its training implications.
- The empirical results lack sufficient detail regarding variability across trials, and the discussion of limitations is too brief.
- The limitations of the analytical simplifications are not clearly articulated, which may affect the perceived impact of the findings.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their findings by conducting further experiments on more complex datasets and transformer architectures, including multi-state Markov chains. Additionally, we suggest providing more quantitative measures of rank in the empirical results and including error bars to reflect variability across trials. Clarifying the definition of the attention scalar $a$ in the main body and expanding the discussion of limitations to encompass all assumptions made would also enhance the paper's clarity and depth. Furthermore, it would be beneficial to explicitly outline the limitations of the current approach and discuss the implications of these limitations throughout the text. Finally, we encourage the authors to enhance the presentation of their results by incorporating shaded error bars in their figures and quantifying the low-rankness of matrices more effectively.