ID: B29BlRe26Z
Title: SLowcalSGD : Slow Query Points Improve Local-SGD for Stochastic Convex Optimization
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 7, 6, 4
Original Confidences: 4, 4, 4

Aggregated Review:
### Key Points
This paper presents a new federated learning algorithm called Slowcal-SGD, which integrates anytime-SGD into the federated learning context. The authors provide a solid theoretical convergence analysis, demonstrating that Slowcal-SGD can outperform both mini-batch SGD and local SGD in heterogeneous data settings. The method builds on customizing a slowly-changing sequence of query points to mitigate bias from local updates. However, no empirical experiments are included to validate the proposed algorithm's performance.

### Strengths and Weaknesses
Strengths:
- The proposed algorithm is novel and well-articulated, with insightful discussions accompanying each theorem that clarify why the algorithm performs better.
- The clarity of the comparison between Slowcal-SGD and other algorithms in Table 1 is commendable.

Weaknesses:
- The paper lacks experimental results, making it difficult to assess the practical effectiveness of the proposed algorithm.
- Definitions, such as that of "query," are vague and could lead to confusion, particularly regarding the treatment of mini-batch gradient computations.
- The theoretical assumptions presented are strong, raising questions about the differences between Slowcal-SGD and general variance reduction SGD.

### Suggestions for Improvement
We recommend that the authors include numerical experiments in a convex setting, such as multinomial logistic regression or least squares, to empirically evaluate the performance of Slowcal-SGD. Additionally, we suggest clarifying the definition of "query" to avoid potential controversy and confusion. A discussion on the main challenges in demonstrating improved convergence relative to accelerated mini-batch SGD would also enhance the paper's depth. Finally, addressing the assumptions in equations (1) - (3) and their implications for data heterogeneity would strengthen the theoretical foundation of the work.