ID: czxX6jjpVJ
Title: Discovering Highly Influential Shortcut Reasoning: An Automated Template-Free Approach
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for automatically discovering granular-feature shortcut reasoning in NLP models and quantitatively evaluating its impact on model robustness. The authors propose a three-step approach that identifies input patterns using Integrated Gradients, calculates the generality of these patterns, and assesses the performance drop caused by them. The method successfully identifies both known and previously unknown shortcuts in NLI and sentiment analysis datasets.

### Strengths and Weaknesses
Strengths:
1. The paper makes a significant contribution by proposing an automatic method for identifying shortcut reasoning, addressing limitations of prior work.
2. The method is conceptually straightforward and can be easily implemented across various datasets.
3. The presentation is clear and concise, facilitating understanding.

Weaknesses:
1. The reliance on the availability of an OOD dataset limits the method's applicability and impact.
2. The evaluation lacks human annotation, which raises concerns about the trustworthiness of the identified shortcuts.
3. Some methodological details are confusing, and certain claims may not be sufficiently supported by evidence.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the method description, particularly regarding the terminology used for "words" and "tokens" to ensure consistency. Additionally, we suggest providing more comprehensive details in the experimental section, including specific settings and results, and consider releasing the code for reproducibility. A more thorough discussion of the limitations, especially regarding the necessity of an OOD dataset and the computational cost, should be included. Finally, we encourage the authors to enhance the comparison with related work, particularly in terms of evaluation methods and dataset usage.