ID: d94iPelgSD
Title: Intra-Event and Inter-Event Dependency-Aware Graph Network for Event Argument Extraction
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an event argument extraction model that utilizes graph neural networks to model intra and inter-event argument dependencies. The authors propose that these dependencies can be effectively captured through their architecture, which includes an event memory and retrieval module. Experimental results on ACE05, RAMS, and WikiEvents datasets indicate that their methods outperform several baselines, showcasing promising state-of-the-art performance.

### Strengths and Weaknesses
Strengths:
- The motivation for using graph convolutional networks (GCN) to model argument dependencies is clear and well-articulated.
- The innovative incorporation of an event memory and retrieval module allows for dynamic construction of inter-event dependencies during inference.
- The experimental results demonstrate significant advantages over existing methods.

Weaknesses:
- The writing lacks clarity, with many technical details inadequately explained, hindering understanding and reproducibility.
- The performance improvements over prior methods appear relatively modest, and the results do not convincingly reflect the variance from multiple experiments.
- The paper does not sufficiently address existing literature on dependency modeling, particularly regarding claims that previous work neglects this aspect.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their writing by reorganizing and polishing the descriptions throughout the paper. Specifically, they should clarify the decoder input parameters and the relationship between role representations and triggers. Additionally, we suggest that the authors provide clearer comparisons with existing works, such as Lin et al. (2020) and Lv et al. (2021), to contextualize their contributions. Finally, the authors should ensure that the results reflect the variance of scores from multiple experiments with different seeds to strengthen their claims.