ID: A86JTXllHa
Title: On the Importance of Feature Separability in Predicting Out-Of-Distribution Error
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 6, 8, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a dataset-level method for predicting out-of-distribution (OOD) scores, focusing on high inter-class dispersion and low intra-class compactness in representation learning. The authors demonstrate that inter-class dispersion correlates strongly with OOD performance, while intra-class compactness does not. Experiments on CIFAR and TinyImageNet reveal the method's effectiveness compared to previous approaches.

### Strengths and Weaknesses
Strengths:
1. The method is well-motivated, with a clear explanation of why traditional metrics like MMD and Fr√©chet distance are inadequate for OOD error prediction. The proposed dispersion score shows superior performance.
2. The approach is user-friendly and does not require training, making it adaptable to various OOD data scenarios.
3. Empirical results indicate that the method outperforms existing benchmarks in most cases.

Weaknesses:
1. The experimental settings are simplistic, relying on augmented datasets that retain class overlap with the ID set. This raises questions about the method's applicability to standard OOD benchmarks like CIFAR and ImageNet.
2. The lack of non-overlapping ID and OOD datasets in experiments limits the real-world relevance of the findings. More robust tests using datasets like CIFAR10/CIFAR100 are recommended.
3. The rationale for the ineffectiveness of intra-class compactness is not sufficiently explained, and exploring its combination with dispersion could yield valuable insights.

### Suggestions for Improvement
We recommend that the authors improve the experimental design by validating the proposed method on standard OOD benchmarks such as CIFAR and ImageNet-1k, rather than relying solely on simple augmentations. Additionally, incorporating non-overlapping ID and OOD datasets, such as CIFAR10 and CIFAR100, would enhance the practical relevance of the findings. We also suggest conducting an ablation study to explore the potential benefits of combining intra-class compactness with dispersion. Finally, providing a clearer explanation of why intra-class compactness is ineffective would strengthen the paper's theoretical foundation.