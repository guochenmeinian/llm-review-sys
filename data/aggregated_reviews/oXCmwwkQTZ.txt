ID: oXCmwwkQTZ
Title: Implicit Regularization Paths of Weighted Neural Representations
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 7, 7, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 2, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates implicit regularization through weighted linear regression, establishing a connection between weighted ridge regression and simple ridge regression under the assumption of asymptotic freeness. The authors provide theoretical results linking regularization strengths and derive an optimal sub-sample size for ensemble training, supported by experimental verification. Additionally, the study extends results to structured features and proposes an efficient cross-validation method for subsampled pretrained representations.

### Strengths and Weaknesses
Strengths:  
- The manuscript is well-written, offering interesting insights into subsampling and explicit regularization connections.  
- The theoretical results are comprehensive, with relaxed assumptions on features and weights, and are verified through experiments.  
- The paper considers a general scheme for the weighting matrix, enhancing its applicability beyond subsampling scenarios.  
- Table 1 provides a clear overview of previous works and the paper's contributions.  

Weaknesses:  
- The results have limited applicability, particularly regarding the choice of weighting matrix and the computational challenges associated with determining the optimal sub-sample size.  
- The paper's abstract and introduction are somewhat confusing, lacking clear explanations of key concepts like the "path of equivalence."  
- The problem setup and notations are not clearly defined before use, making it difficult to follow the results.  
- The analysis is conducted in an asymptotic regime, which may limit practical implications.  

### Suggestions for Improvement
We recommend that the authors improve the clarity of the abstract and introduction by providing a more intuitive explanation of the "path of equivalence." Additionally, the authors should clearly define the problem setup and notations before their use to enhance readability. It would be beneficial to address the computational challenges related to determining the optimal sub-sample size and to consider providing insights on the implications of their results in a finite sample context. Lastly, we suggest that the authors explore real-world applications where the weighting matrix is not a diagonal matrix to broaden the applicability of their findings.