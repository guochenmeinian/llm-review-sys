ID: qyEm4tF2p1
Title: Landscape Surrogate: Learning Decision Losses for Mathematical Optimization Under Partial Information
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 5, 7, 5, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework for Smart Predict and Optimize (SPO) and Mixed Integer Non-Linear Programming (MINLP), focusing on learning the parameters of optimization models from limited information. The authors propose an iterative algorithm to learn two optimization models: one for the objective and another for the coefficients. The method is applied to traditional benchmarks, demonstrating overall benefits. The paper also discusses the challenges of integrating optimization models into learning pipelines due to difficulties in differentiation.

### Strengths and Weaknesses
Strengths:  
- The main contribution, Algorithm 1, offers an elegant solution to SPO problems.  
- The paper is well-written, with clear exposition and thorough experiments that compare the proposed method to relevant past work.  
- The connection between learned surrogates and MINLP is intriguing and adds depth to the discussion.

Weaknesses:  
- The formalization is problematic, with unclear notations and inconsistencies in the model definitions.  
- The paper lacks documentation on training considerations for the model, particularly regarding the importance of convex surrogates and hyperparameter tuning.  
- There are significant implementation details missing, such as the execution of the theta-step during testing and specifics on the replay buffer trick.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the formalization by addressing the notational inconsistencies and providing detailed explanations of model inputs. Additionally, the authors should include experiments that document the training considerations for $\mathcal{M}_w$, particularly regarding the impact of hyperparameter choices and the robustness of results to these choices. It would also be beneficial to clarify the use of the theta-step during testing and provide more information on the replay buffer trick, including the number of points stored. Lastly, restructuring Section 4 could enhance the presentation by clearly delineating the introduction of the proposed method from implementation details.