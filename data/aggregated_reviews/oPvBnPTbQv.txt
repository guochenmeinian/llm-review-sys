ID: oPvBnPTbQv
Title: Referencing Where to Focus: Improving Visual Grounding with Referential Query
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 7, 3, 6, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 4, 5, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel visual grounding framework, RefFormer, which introduces a query adaption module (QA) that can be integrated into various layers of CLIP. The QA module captures target-related referential queries and provides prior information to the decoder, enhancing the learning process of learnable queries. Extensive experiments on five visual grounding benchmarks validate the effectiveness of the proposed method, demonstrating its applicability to both REC and RES tasks.

### Strengths and Weaknesses
Strengths:
1. The integration of query learning and adapter functionalities into the QA module effectively leverages multi-level feature information within CLIP.
2. The QA module allows for adaptive extraction of target-related information, improving performance with fewer training parameters.
3. The paper is well-written, with clear motivation and sufficient empirical support for the proposed method.

Weaknesses:
1. The selection of specific layers for the QA module lacks theoretical justification, and the empirical evidence provided is insufficient to explain why certain layers perform better.
2. The interaction between the query and visual/textual representations in the CAMF module is not well-motivated, leaving questions about its design choices.
3. Some technical details, such as the backbone version and channel dimensions in the QA module, are inadequately specified.

### Suggestions for Improvement
We recommend that the authors improve the theoretical justification for layer selection in the QA module and provide more empirical evidence to support their choices. Additionally, we suggest clarifying the design motivation for the CAMF module and detailing the interaction between queries and visual/textual representations. Furthermore, please ensure that all technical details, including the backbone version and channel dimensions in the QA module, are clearly specified in the revised manuscript.