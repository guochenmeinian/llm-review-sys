ID: sFaFDcVNbW
Title: GSGAN: Adversarial Learning for Hierarchical Generation of 3D Gaussian Splats
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 5, 7, 6, 6, -1, -1, -1
Original Confidences: 4, 5, 4, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a 3D-aware GAN (3DGAN) framework utilizing a 3D Gaussian Splatting (3DGS) model. The proposed method can generate 3D-aware images of quality comparable to state-of-the-art (SOTA) NeRF-based methods while achieving up to 100x faster rendering speeds during inference. The framework ensures strict 3D consistency by rendering all pixels with 3DGS without relying on post-2D super-resolution techniques. The authors introduce hierarchical Gaussian representations learned in a coarse-to-fine manner and utilize anchor Gaussians for regularization. The generator architecture incorporates attention-based MLP structures, and a layerscale layer is introduced to stabilize Gaussian positions during early training.

### Strengths and Weaknesses
Strengths:
- The paper effectively presents a 3D GAN framework using 3DGS, achieving strict 3D consistency and significantly improved rendering speed while maintaining comparable FID scores to SOTA methods.
- The hierarchical architecture for learning 3D representations from single-view images is a notable advancement in computational efficiency.
- The paper includes sufficient numerical and qualitative comparisons and is easy to follow.

Weaknesses:
- The related work section is notably short and lacks relevant citations, missing recent papers in the field that should be included.
- The motivation for introducing anchor Gaussians is unclear, and the paper does not adequately explain their necessity.
- Some technical details are missing, such as the impact of the L_pose loss on training and the handling of scale regularizations across different layers.

### Suggestions for Improvement
We recommend that the authors improve the related work section by including relevant citations, particularly recent works like **GGHead** and **WYSIWYG**, to provide a comprehensive context for their contributions. Additionally, the authors should clarify the role of anchor Gaussians and consider addressing the questions regarding the L_pose loss and the application of scale regularizations to all layers. Furthermore, we suggest refining the figures to enhance the understanding of the hierarchical design's motivation and providing evidence of geometry extraction from the models to compare with existing methods.