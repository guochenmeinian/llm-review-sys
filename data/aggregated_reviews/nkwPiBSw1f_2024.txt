ID: nkwPiBSw1f
Title: Dual-Personalizing Adapter for Federated Foundation Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 3, 6, 8, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on personalization and test-time adaptation in federated learning of foundation models, proposing two methods evaluated on the FLAN dataset. The authors aim to address the challenges of test-time distribution shifts in federated foundation models (FedFM), introducing a dual-personalizing adapter mechanism. The work emphasizes the trade-off between personalization and generalization in client-specific models.

### Strengths and Weaknesses
Strengths:
- The paper is generally well-written and easy to understand.
- The proposed method is novel, addressing a significant challenge in the emerging domain of FedFM.
- The experimental setup is reasonable, and the clarity of presentation is commendable, with well-organized content and supportive figures.

Weaknesses:
- The motivation for the proposed approach is weak, as it does not clearly articulate why the "test" distribution differs from the training distribution in federated learning.
- The training method lacks novelty, as similar approaches exist in the literature, and the evaluation scenario is overly artificial, favoring personalization.
- Limited performance gains are observed, with confusion arising from the authors proposing two methods that excel in different areas without a clear rationale for their simultaneous consideration.

### Suggestions for Improvement
We recommend that the authors improve the motivation section to clarify the significance of the test-time distribution shift in real-world applications. Additionally, a more insightful discussion on the selection of important weights in the dual-personalizing adapter mechanism is warranted. The authors should also consider conducting larger-scale experiments to validate their findings further. Lastly, addressing the artificial nature of the evaluation scenario and comparing their approach with multi-task learning methods would strengthen the paper's contributions.