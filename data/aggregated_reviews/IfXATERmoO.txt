ID: IfXATERmoO
Title: Responsible Diffusion Models via Constraining Text Embeddings within Safe Regions
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to enhance safety and fairness in text-to-image diffusion models by constraining text embeddings to "safe regions" within the embedding vector space. The authors propose learning semantic direction vectors in the CLIP embedding space to guide text prompts away from unsafe content, utilizing Low-Rank Adaptation (LoRA) for initialization. The effectiveness of this method is demonstrated through extensive experiments across multiple datasets and models.

### Strengths and Weaknesses
Strengths:
- The approach addresses a significant issue in responsible image generation, providing a robust solution that operates on prompt embeddings rather than raw prompts.
- It does not introduce significant computational overhead and avoids costly re-training of diffusion models, making it practical for real-world applications.
- The use of LoRAs helps maintain image quality and semantic similarity, as evidenced by FID and CLIP scores.
- The method is versatile and can potentially reduce biases in image generation beyond inappropriate content prevention.

Weaknesses:
- There is a lack of critical reflection on the limitations of the approach, particularly regarding its reliance on linear relationships in CLIP, which may not hold for all concepts.
- The experiments are limited to one txt2img model and CLIP embeddings, raising questions about generalizability to other architectures.
- The method may overly restrict output variability, potentially limiting creative use cases for artists.
- The paper does not adequately address the coverage of unsafe concepts and sensitive terms, nor does it provide clarity on the definition of "safe regions."

### Suggestions for Improvement
We recommend that the authors improve the discussion on the limitations of their approach, particularly regarding generalizability and the implications of linear relationships in CLIP. The authors should also motivate the choice of datasets used for experimentation and consider including more recent datasets to enhance the robustness of their findings. Additionally, we suggest providing more structured details on computational complexity and clarifying how the method would function with multiple text encoders. The authors should include examples of the method's failures and elaborate on how their approach differs from SDL, particularly in terms of the impact of CFG. Finally, we encourage the authors to define relevant terms clearly before their use and explore the applicability of their method to attributes beyond gender and race, such as age.