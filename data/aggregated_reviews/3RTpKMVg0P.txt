ID: 3RTpKMVg0P
Title: Privacy Implications of Retrieval-Based Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into the privacy risks associated with retrieval-based language models (kNN-LMs) and explores the implications of private data leakage during training and inference. The authors demonstrate that kNN-LMs are particularly vulnerable to privacy breaches and propose mitigation strategies, including data sanitization and the use of public datasets for training encoders. The paper also identifies realistic threat models and provides a framework for assessing privacy leakage in large language models.

### Strengths and Weaknesses
Strengths:
- The paper addresses a critical issue of data leakage in large language models, contributing to ongoing research in privacy.
- It offers a structured approach to assess privacy risks and provides a framework for systematic exploration of privacy leakage.
- The experimental results validate the effectiveness of proposed attacks and countermeasures.

Weaknesses:
- The framework may not be easily applicable to other retrieval-augmented LLMs, such as RETRO or chain-of-thought models.
- The results are specific to the training data used, limiting generalizability to other datasets or LLMs.
- The definition of privacy and the threat model are not clearly articulated, and the choice of privacy metrics lacks justification.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the privacy definition, possibly by incorporating established definitions like k-eidetic memorization. Additionally, the authors should provide a more detailed justification for the threat model and clarify the assumptions made regarding access to private datasets. It would also be beneficial to include differential privacy as a defense in the experiments, as it is a standard approach to mitigate privacy risks. Lastly, we suggest that the authors explore the implications of privacy risks in other types of retrieval-based language models and consider different utility measures beyond perplexity.