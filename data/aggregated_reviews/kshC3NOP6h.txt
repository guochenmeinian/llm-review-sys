ID: kshC3NOP6h
Title: Towards Last-layer Retraining for Group Robustness with Fewer Annotations
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 6, 3, 6, 7, -1, -1, -1, -1
Original Confidences: 3, 4, 5, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for enhancing group robustness through last-layer retraining, specifically introducing selective last-layer finetuning (SELF) to improve worst-group accuracy with minimal worst-group data. The authors demonstrate that last-layer retraining can significantly enhance worst-group accuracy, even with a limited dataset. The study includes experiments across various datasets, revealing that the proposed methods yield comparable performance to existing techniques.

### Strengths and Weaknesses
Strengths:
1. The focus on improving robustness via last-layer retraining under spurious correlation is both interesting and practical.
2. The experiments are well-executed, with consistent comparisons throughout the paper.
3. The findings are clearly presented, particularly the observation that last-layer retraining can improve worst-group accuracy even with a small proportion of worst-group data.

Weaknesses:
1. Novelty concerns arise as last-layer retraining is a common technique in imbalanced learning, raising questions about the uniqueness of the findings.
2. The proposed method's performance is not consistently superior to existing methods, as evidenced by Table 4.
3. The reliance on group labels for model selection limits the practicality of the method in real-world scenarios.
4. Certain figures lack necessary legends, and the contribution section is overly lengthy.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Figure 1(a) by adding legends and clarify the y-axis of Figure 1(b) to indicate that it represents relative increases. Additionally, we suggest condensing the contribution section for brevity. To address novelty concerns, it would be beneficial to compare the worst-group accuracies achieved by SELF without using any group labels during training or validation. Furthermore, we encourage the authors to evaluate the performance of SELF as a function of the total number of group-labeled examples used, as this is crucial for assessing the method's contributions. Lastly, providing qualitative examples of how dropout SELF disagreement outperforms misclassification would enhance the understanding of the method's effectiveness.