ID: gGl0n7Onug
Title: Theoretical and Practical Perspectives on what Influence Functions Do
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 7, 8, 7, 7, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 2, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper reexamines the assumptions underlying influence function (IF) methods to elucidate their failure in predicting leave-some-out-retrain performance. The authors identify that all five assumptions are often violated in practice and propose a combination of HIF and Arnoldi-based methods to address these issues. They demonstrate that while four assumptions can be resolved, the challenge of *parameter divergence* remains inherent, leading to a gradual decline in the predictive ability of IFs over training steps. The authors suggest interpreting IFs as proxies for the effects of limited fine-tuning steps.

### Strengths and Weaknesses
Strengths:  
- **Originality:** The paper provides a thorough analysis of the assumptions of IFs, integrating theoretical insights with experimental data.  
- **Clarity:** Results are presented clearly, making the paper enjoyable to read.  
- **Significance:** The work addresses critical obstacles in the field and proposes viable solutions, which are valuable for practitioners using influence functions.

Weaknesses:  
- The authors' claims regarding the benefits of Arnoldi-based methods and the impact of training trajectories would benefit from ablation experiments or relevant citations.  
- There is a lack of explanation for the poor performance of IF methods on ResNet, warranting further investigation.  
- The paper does not sufficiently contrast its findings with those of Bae et al. (Neurips 2022), which could enhance the discussion of related work.  
- Some sections, particularly those discussing Arnoldi methods, may be challenging for readers unfamiliar with the topic.

### Suggestions for Improvement
We recommend that the authors improve the paper by including ablation experiments or citing relevant literature to support their claims about the effectiveness of Arnoldi-based methods and training trajectories. Additionally, we suggest investigating the reasons behind the differing performance of IF methods on NLP versus CV tasks. It would also be beneficial to provide a clearer contrast with the findings of Bae et al. to strengthen the paper's contribution. Finally, enhancing the clarity of sections discussing Arnoldi methods and ensuring that key proofs are included in the main text could improve overall readability.