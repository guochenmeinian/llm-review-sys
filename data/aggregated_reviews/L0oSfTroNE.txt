ID: L0oSfTroNE
Title: Benchmarking LLMs via Uncertainty Quantification
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 6, 7, 7, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 5, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a conformal prediction-based uncertainty quantification benchmark for LLMs, evaluating nine models across five NLP tasks. The authors aim to characterize the uncertainty of LLMs, revealing insights into the relationship between uncertainty scores and model performance, as well as the effects of instruction fine-tuning. The major contribution is a large-scale study on conformal prediction for uncertainty quantification, although the paper faces criticism regarding its novelty and relevance to the benchmark track.

### Strengths and Weaknesses
Strengths:
- The paper provides an interesting method for estimating uncertainty scores of LLMs.
- It includes an extensive study involving nine LLMs and five diverse NLP tasks.
- The use of conformal prediction is a natural choice given the computational costs of other methods.

Weaknesses:
- The motivation for the benchmark is unclear, as it primarily focuses on multiple-choice classification tasks, limiting its applicability to LLMs' generative capabilities.
- The paper lacks rigorous definitions for terms like "distribution-free" and "statistically rigorous," and does not provide mathematical proof for the theoretical guarantees of the proposed metric.
- The results may not generalize well to real-world applications of LLMs, as they do not adequately address free-form generation tasks.

### Suggestions for Improvement
We recommend that the authors improve the justification for the benchmark's motivation and consider including a broader range of uncertainty estimation methods beyond conformal prediction. Additionally, the authors should explore free-form generation tasks to enhance the relevance of their findings. Clearer definitions of key terms and a discussion on the limitations of the conformal prediction approach, particularly regarding its reliance on model output logits, would strengthen the paper. Finally, including the AUROC metric could provide a more intuitive understanding of the relationship between accuracy and uncertainty.