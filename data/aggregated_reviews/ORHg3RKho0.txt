ID: ORHg3RKho0
Title: Auto-Instruct: Automatic Instruction Generation and Ranking for Black-Box Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Auto-Instruct, a pipeline approach to automatically generate instructions for large language models (LLMs) in few- and zero-shot settings. The authors propose generating diverse candidate instructions using a black-box LLM and then training a scoring model to rank these instructions. The top-ranked instruction is selected for inference. The results on SuperNI and BigBench indicate that LLM-generated instructions outperform human-generated ones, and the ranking process enhances performance.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and the proposed ranking method improves results over random selection.
- The experimental design effectively evaluates the capability of LLMs in true few-shot settings.
- Auto-Instruct demonstrates improved performance on established benchmarks.

Weaknesses:
- The novelty of Auto-Instruct is questioned, as many previous studies have explored instruction generation with LLMs.
- The experiments rely solely on closed LLMs, and the inference strategy is unclear.
- The improvements in performance appear marginal, particularly on BigBench, and the evaluation relies heavily on automatic metrics without human assessment.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the inference strategy, including how many instructions are sampled at inference time and the overhead involved. Additionally, we suggest that the authors report results from an oracle reranker to establish an upper bound for Auto-Instruct's effectiveness. Evaluating the reranker model using silver labels based on prompt performance could provide further insights. Finally, incorporating human evaluation alongside automatic metrics would enhance the robustness of the findings and address concerns regarding the reliance on metrics like ROUGE-L.