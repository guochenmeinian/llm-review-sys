ID: 2HzZIDo48o
Title: Meta-Referential Games to Learn Compositional Learning Behaviours
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 7, 6, 5, -1, -1, -1
Original Confidences: 2, 1, 5, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Symbolic Behaviour Benchmark (S2B) to evaluate artificial agents' abilities to exhibit compositional learning behaviours (CLBs) by addressing the binding problem in a domain-agnostic manner. The authors define CLBs as the capacity to generalize from combinations of novel atomic components. Key contributions include defining CLBs, proposing the Symbolic Continuous Stimulus (SCS) representation, introducing Meta-Referential Games as the task framework, and providing baseline results and error analysis. The paper is structured logically, with clear explanations of key concepts.

### Strengths and Weaknesses
Strengths:
1. Addresses the significant problem of evaluating compositional learning and binding.
2. Novel framing of CLBs and the binding problem within symbolic behaviour.
3. Introduction of a new domain-agnostic stimulus encoding (SCS).
4. Insightful analysis of linguistic compositionality and task performance correlation.

Weaknesses:
1. Unclear distinction of why SCS is domain-agnostic compared to existing benchmarks like SCAN or gSCAN.
2. Poor performance of MARL models raises concerns about the benchmark's practicality.
3. Lack of clarity in the relationship between CLBs, meta-learning, and referential games.
4. Figures are too small to read, and essential information is relegated to the appendix.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the introduction to better articulate the connection between CLBs, meta-learning, and referential games. Additionally, please enhance the readability of figures and ensure that critical information is included in the main text rather than the appendix. A more detailed experimental setup, including hyperparameter tuning and comparisons with other benchmarks, would strengthen the paper's contribution. Finally, consider expanding the benchmark to include various modalities and exploring different agent architectures beyond LSTM-based models.