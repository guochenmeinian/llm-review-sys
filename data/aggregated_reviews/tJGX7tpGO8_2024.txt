ID: tJGX7tpGO8
Title: What Matters in Graph Class Incremental Learning? An Information Preservation Perspective
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 6, 5, 6, 6, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on graph class incremental learning (GCIL), focusing on the preservation of information from old classes to mitigate catastrophic forgetting. The authors propose the Graph Spatial Information Preservation (GSIP) framework, which preserves both low-frequency (local-global) and high-frequency information in the graph's spatial domain. The theoretical analysis reveals that maintaining graph information can help overcome semantic and structural shifts, and the empirical results demonstrate GSIP's effectiveness across three public datasets.

### Strengths and Weaknesses
Strengths:
1. The paper addresses the significant challenge of catastrophic forgetting in GCIL, providing a theoretical foundation and empirical validation.
2. The quantification of semantic and structural shifts on the CoraFull dataset enhances the understanding of the forgetting mechanism.
3. Comprehensive experiments, including ablation studies and hyper-parameter tuning, support the proposed framework's effectiveness.

Weaknesses:
1. The motivation for preserving global low-frequency information is unclear, and the rationale for separating local and global components for low-frequency but not high-frequency needs further theoretical analysis.
2. The writing lacks clarity, particularly in the abstract and introduction, where terms like "graph information" and "local-global parts" should be defined.
3. The experimental settings for each dataset are not sufficiently justified, and additional results for varied task configurations are recommended.
4. Implementation details, especially hyper-parameters for each dataset, are missing, and further hyper-parameter experiments, such as sensitivity analysis on \(\alpha\), are necessary.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing by defining key terms in the introduction. Additionally, the authors should provide a more detailed theoretical analysis regarding the separation of local and global components for both frequency types. It would be beneficial to justify the experimental settings and include results from different task configurations. Furthermore, we suggest adding comprehensive implementation details, particularly hyper-parameters for each dataset, and conducting more hyper-parameter experiments, including sensitivity analysis on \(\alpha\). Finally, a discussion on data privacy and the societal implications of the work should be included.