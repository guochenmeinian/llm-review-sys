ID: ARLEUVVfTL
Title: Improving Neural ODE Training with Temporal Adaptive Batch Normalization
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 7, 4, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Temporal Adaptive Batch Normalization (TA-BN), designed specifically for Neural Ordinary Differential Equations (Neural ODEs). The authors argue that traditional Batch Normalization (BN) fails in this context due to the inability to track population statistics meaningfully over continuous time. The proposed solution involves using a uniform time grid for tracking these statistics, allowing for interpolation during ODE solving to obtain time-dependent mean and variance. The effectiveness of TA-BN is demonstrated through evaluations on image classification and physical system modeling tasks, showing improved performance compared to standard BN.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and presents a meaningful problem with an elegant solution.
- Extensive and convincing evaluations support the proposed method.
- A thorough analysis of why traditional BN fails in Neural ODEs enhances understanding of the issue.

Weaknesses:
- The work is considered "incremental," limiting its overall impact.
- Some experiments lack error bars and details on the number of repeats, which need clarification.
- The paper does not sufficiently compare TA-BN with related works, particularly in the context of Spiking Neural Networks (SNN).
- There is a lack of theoretical analysis and ablation studies to support claims regarding the efficacy of TA-BN.

### Suggestions for Improvement
We recommend that the authors improve the clarity of experimental results by including error bars for all experiments and providing details on the number of repeats conducted. Additionally, a comprehensive comparison with related works, especially TAB in SNNs, would clarify the novelty of this paper. We suggest conducting further experiments to explore the application of TA-BN to Neural Controlled Differential Equations (Neural CDEs) and Continuous Normalizing Flows, as well as investigating the impact of TA-BN on training efficiency. Lastly, a deeper theoretical analysis of why TA-BN is effective could strengthen the paper's contributions.