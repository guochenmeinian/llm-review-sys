ID: 0Gl5WxY6es
Title: Grounding Multimodal Large Language Models in Actions
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 5, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on grounding multimodal LLMs (MLLMs) to the action spaces of agents with various embodiments, focusing on "Action Space Adapters" (ASAs) for different environments. The authors evaluate five embodied AI environments (three continuous and two discrete) and over 100 tasks, providing theoretical grounding and actionable recommendations for adapting MLLMs. The research indicates that VQ-VAEs yield superior performance in many tasks, particularly in action prediction.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant issue regarding the generalization of MLLMs to embodied environments and diverse action spaces.
- A comprehensive set of experiments across various environments and action spaces is conducted.
- The combination of theoretical motivation and practical recommendations constitutes a strong contribution to the field.

Weaknesses:
- The paper is dense and complex, making it difficult to follow in parts, which affects clarity.
- Some terms, such as "codes" and "codebook," are not clearly defined.
- There is a lack of specific example outputs, which would help clarify definitions and ground the problem more effectively.
- The description of the VQ-VAE variants lacks detail on training methods, and the choice of benchmarks raises questions about their suitability.

### Suggestions for Improvement
We recommend that the authors improve clarity by defining key terms more explicitly and providing specific example outputs to enhance understanding. Additionally, we suggest that the authors clarify the differences between SemLang and Lang, and address the training methods for VQ-VAE variants in more detail. It would also be beneficial to consider using VIMA-Bench for systematic generalization and to expand the evaluation of BabyAI to ensure a more robust demonstration of model capabilities. Finally, we encourage the authors to discuss the limitations of their analysis more thoroughly, particularly regarding the impact of different training methods and embodiments on results.