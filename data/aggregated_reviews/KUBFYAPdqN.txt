ID: KUBFYAPdqN
Title: Trading-off price for data quality to achieve fair online allocation
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 7, 5, 6, 5, -1, -1, -1, -1, -1
Original Confidences: 3, 2, 3, 2, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an online allocation problem with long-term fairness constraints, where protected attributes are not observed but can be purchased from multiple sources. The authors propose a virtual-value-based algorithm that achieves $O(\sqrt{T})$ online regret while maximizing overall utility minus the cost of information and a fairness penalty characterized by a convex function. The contributions include a computationally efficient algorithm and regret bounds for various penalties, addressing a significant gap in the literature regarding the optimization of data sources in fair online allocation.

### Strengths and Weaknesses
Strengths:  
- This is the first paper to consider optimizing over data sources in the fair online allocation problem, contributing an algorithm with proven regret bounds.  
- The assumption that protected attributes are not observed is a realistic model, potentially appealing to a wide audience.  
- The simultaneous source selection and dual gradient descent in Algorithm 1 is an important contribution, demonstrating that separate approaches are insufficient.  
- The proposed algorithm is compatible with various notions of group fairness.  

Weaknesses:  
- The paper lacks empirical results and code, which would enhance its contribution to the research community.  
- The problem setup is confusing, particularly the relationships among public context $z_t$, protected attributes $a_t$, and purchased information $c_{tk_t}$.  
- The authors do not sufficiently explain the intuitions behind their algorithms or justify their novelty, as the source selection appears to be a variation of existing algorithms.  
- The fairness is treated as a penalty rather than a hard constraint, which needs clarification, especially given the title's emphasis on long-term fairness.  
- There is insufficient discussion on the trade-off between the cost of additional information and fairness, and the implications of using potentially biased past data for estimating protected attributes are not addressed.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the problem setup by explicitly detailing the relationships among $z_t$, $a_t$, and $c_{tk_t}$. Additionally, we suggest incorporating a running example throughout the paper to contextualize model assumptions and enhance reader understanding. The authors should also provide a more thorough explanation of the intuitions behind their algorithms and highlight the novelty of their contributions compared to existing works. Furthermore, we encourage a formal discussion of the trade-offs between paying for additional information and achieving fairness, as well as addressing potential biases in past data that may affect fairness outcomes.