ID: h3Kv6sdTWO
Title: DiffusionBlend: Learning 3D Image Prior through Position-aware Diffusion Score Blending for 3D Computed Tomography Reconstruction
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 7, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method for solving the inverse problem in computed tomography (CT) using a diffusion model that incorporates z-axis consistency and utilizes 3D data as input for the neural network. The authors propose two approaches, DiffusionBlend and DiffusionBlend++, achieving state-of-the-art (SOTA) results in ultra-sparse-view and limited-angle 3D CT reconstruction on benchmark datasets. The method demonstrates impressive inter-slice consistency and outperforms existing baselines without requiring large-scale data or extensive computational resources.

### Strengths and Weaknesses
Strengths:
1. The method's probabilistic modeling of 3D volumes considering neighboring slices is innovative.
2. The paper is well-organized and clearly articulates the authors' motivation and implementation strategy.
3. The results, particularly in sparse-view reconstruction, are commendable and visually striking.

Weaknesses:
1. The novelty of the approach is somewhat diminished by existing literature, particularly the cited work on generative models for inverse problems in medical imaging.
2. The evaluation of the method lacks a comprehensive comparison with traditional CT reconstruction techniques beyond filtered back projection (FBP), which may not adequately represent the performance landscape.
3. Artifacts generated by the diffusion model could interfere with clinical diagnosis, necessitating further exploration of methods to mitigate these issues.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their contributions by explicitly distinguishing their innovations from existing literature, particularly the cited work on generative models. Additionally, the authors should evaluate their method's performance across a broader range of angles (e.g., 20, 40, 60, 80, and 100 angles) and include comparisons with classic CT reconstruction methods such as SIRT, CGLS, and SBTV, ensuring that hyperparameters are optimized through grid search for a fair assessment. Furthermore, we suggest that the authors address the artifacts observed in their results by exploring strategies such as increasing the number of angles or enhancing the training dataset. Finally, we encourage the authors to share their code upon acceptance to facilitate further research and validation in the community.