ID: lAEc7aIW20
Title: Unsupervised Learning for Solving the Travelling Salesman Problem
Conference: NeurIPS
Year: 2023
Number of Reviews: 23
Original Ratings: 6, 8, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents UTSP, an unsupervised learning framework designed to address the Travelling Salesman Problem (TSP). The framework operates in two phases: heat map construction and local searching. A surrogate loss function is introduced to train Graph Neural Networks (GNNs), enabling the model to implicitly adhere to TSP constraints while identifying the shortest path. The heat map effectively narrows the search space, enhancing local search efficiency. Empirical results demonstrate that UTSP, utilizing approximately 10% of model parameters and 0.2% of training samples, competes well with or surpasses existing baselines in solution quality and inference time. The paper also includes analyses of search space and smoothing effects. Additionally, the authors compare their Unsupervised Learning (UL) method with various other methods for solving TSP, showing that the UL method outperforms baselines such as Att-GCRN, DIFUSCO, and DIMES in terms of solution quality and training efficiency, particularly highlighting the reduced time cost for generating training data compared to supervised methods.

### Strengths and Weaknesses
Strengths:
- The proposed method is sound, novel, and technically efficient, significantly reducing model parameters and training samples without requiring labeled data.
- The empirical analyses regarding the non-smoothing heat map and reduced search space are insightful.
- The UL method shows competitive solution quality while significantly reducing training and label collection costs.
- The authors provide comprehensive performance comparisons across multiple problem sizes, illustrating the advantages of their approach.
- The source code is made available for further research.

Weaknesses:
- The applicability of the method appears limited to TSP, with significant domain knowledge required for local search and an excessive number of hyperparameters.
- The related work review is insufficient, omitting many recent neural methods for TSP, necessitating an expanded section in the Appendix.
- The clarity of the local search presentation is lacking; a visual representation is recommended.
- There is a disconnect between the theoretical framework and the practical implementation, particularly regarding the discreteness constraints of the matrices involved.
- Evaluation is insufficient, lacking comparisons with recent end-to-end neural methods and benchmark datasets, and the results on larger TSP instances are missing.
- The scope of the paper is perceived as limited, with concerns about the breadth of the research and the reliance on specific training datasets and methods, which may restrict the generalizability of the findings.

### Suggestions for Improvement
We recommend that the authors improve the related work section by incorporating recent neural methods for TSP, such as POMO, DIMES, and DIFUSCO, to provide a more comprehensive context. Clarifying the local search process with a figure would enhance understanding. Additionally, addressing the theoretical gaps by introducing a regularization term to enforce discreteness in the matrices could strengthen the methodology. The authors should also include more extensive evaluations against state-of-the-art methods on larger TSP instances and classical benchmark datasets like TSPLIB. Furthermore, we suggest that the authors broaden the scope of the paper by discussing additional methodologies and clarifying the training problem sizes for each method to enhance transparency and understanding. Lastly, a detailed discussion on the limitations of the proposed approach and its potential extensions to other routing problems would be beneficial.