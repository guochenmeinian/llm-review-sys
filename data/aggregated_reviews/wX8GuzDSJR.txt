ID: wX8GuzDSJR
Title: What can a Single Attention Layer Learn? A Study Through the Random Features Lens
Conference: NeurIPS
Year: 2023
Number of Reviews: 19
Original Ratings: 5, 7, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an exploration of the learning capabilities of single-layer attention models with fixed, randomly initialized key and query matrices, utilizing a ReLU-based self-attention module instead of the conventional softmax method. The authors establish expressivity results, demonstrating that the model can learn functions exhibiting permutation invariance and that its sample complexity surpasses that of two-layer random feature networks. Theorems provide bounds on representation and generalization, highlighting the advantages of attention models over standard MLPs in specific contexts. The authors propose that the ReLU attention serves as a pragmatically useful starting point, supported by recent findings indicating comparable performance to softmax-based transformers. The paper includes numerical experiments validating the theoretical findings and discusses the interaction between tokens in their model, suggesting that multi-layer attention networks could be an interesting avenue for future work.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and presents novel results that contribute to the literature on random-feature models.
- The theoretical results are clearly articulated, and the proofs appear correct.
- The work effectively formalizes the advantages of attention models in computing and aggregating pairwise functions of sequential inputs.
- The introduction of a ReLU-based self-attention mechanism could enhance practical applications.
- The authors effectively address limitations raised by reviewers and commit to improving transparency regarding their methodology.
- The discussion on the differences between CNNs and transformers adds depth to the analysis of architectural capabilities.

Weaknesses:
- The use of ReLU instead of the standard softmax function is nonstandard for transformers and should be explicitly addressed.
- The fixed key and query matrices limit the learning capacity, making the attention layer less effective.
- The analysis relies on upper bounds for both attention and MLP models, raising questions about the generality of the results.
- The paper lacks a thorough exploration of the limitations associated with the requirement for the number of heads to be greater than the number of tokens.
- The analysis may oversimplify the complexities of transformers, potentially limiting the applicability of random feature analysis.
- The paper contains several typographical errors that detract from its overall quality.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their choice to use ReLU over softmax by explicitly discussing this in the abstract and introduction. Additionally, the authors should consider addressing the limitations posed by fixed key and query matrices and explore the implications of using trainable attention maps. To enhance the generality of their findings, we suggest providing comparisons with lower bounds for random feature MLPs. Furthermore, a more detailed discussion on the limitations related to the requirement for the number of heads being greater than the number of tokens would be beneficial. Including practical examples and clarifying the equivalence with the model using \( e_1^\top \) could further enhance the paper's readability and impact. Finally, correcting the identified typos and clarifying the implications of permutation invariance in relation to natural language tasks would strengthen the paper.