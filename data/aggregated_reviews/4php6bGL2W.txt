ID: 4php6bGL2W
Title: Seek Commonality but Preserve Differences: Dissected Dynamics Modeling for Multi-modal Visual RL
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 6, 6, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Dissected Dynamics Modeling (DDM), a method for multi-modal environment dynamics modeling in visual reinforcement learning (RL). The authors propose a framework that extracts both modality-consistent and modality-inconsistent features using designated losses for regularization. The model aims to maximize mutual information between consistent features across modalities at different timestamps while enforcing orthogonality for inconsistent features. Experimental results on CARLA and DMControl demonstrate DDM's superiority over state-of-the-art methods, supported by ablation studies.

### Strengths and Weaknesses
Strengths:
- The approach of decoupling modality-consistent and modality-inconsistent features is insightful and could inform future research in this area.
- Experimental results indicate significant improvements over existing methods, affirming DDM's effectiveness in visual RL.
- Comprehensive ablation studies and visualizations provide a deeper understanding of the method, justifying its soundness and superiority.

Weaknesses:
- The method is limited to visual modalities, constraining its generalizability for multi-modal learning. Additionally, it appears to only work with visual inputs from the same camera perspective, raising questions about its applicability to inputs from multiple camera positions.
- The experimental details, such as the masking process for different timestamps in DMControl and the absence of results with varying masking ratios, are unclear.
- Some technical descriptions lack accuracy, leading to potential misunderstandings regarding modality-consistent and modality-inconsistent features and their interactions.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of DDM by demonstrating its effectiveness with visual inputs from multiple camera perspectives. Additionally, clarifying the masking methodology for different timestamps and providing results with various masking ratios would enhance the experimental rigor. We also suggest revising unclear technical descriptions to ensure accurate representation of the concepts, particularly regarding the roles of modality-consistent and modality-inconsistent features. Finally, addressing the lack of reported metrics such as DS/RC/IP and providing supporting evidence for claims about the benefits of certain loss components would strengthen the paper.