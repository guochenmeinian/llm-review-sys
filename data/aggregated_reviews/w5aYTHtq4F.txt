ID: w5aYTHtq4F
Title: Harmful Terms and Where to Find Them: Measuring and Modeling Unfavorable Financial Terms and Conditions in Shopping Websites at Scale
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis, categorization, and detection of unfavorable financial phrases in the terms and conditions of shopping websites. The authors develop an automated data collection and topic modeling pipeline, TermMiner, and analyze 1.9 million terms from 8,979 websites to classify unfavorable financial terms into four categories and 22 types. The study finds that 47.21% of purchasing websites contain at least one unfavorable term, particularly among less popular sites, highlighting consumer hazards and weak protections.

### Strengths and Weaknesses
Strengths:
- The paper represents a systematic effort to categorize and detect unfavorable financial conditions in online purchasing sites.
- It introduces the TermLens plugin for automatic detection of adverse financial terms.
- The creation of the ShopTC-100K dataset, which includes 8,251 websites and 1.8 million keywords, is commendable.

Weaknesses:
- There is insufficient focus on technical phrases, particularly legal terms.
- The methodology lacks robustness against adversarial perturbations, such as jailbreak and prompt injection attacks on LLMs, which may lead to incorrect outputs.
- Important methodological details are missing, including the false positive rate of the shopping website classifier and specifics regarding the classification module.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the false positive rate measurement, particularly in relation to the implications of a 2.3% FPR in long terms and conditions documents. Additionally, the authors should provide more evidence regarding the scale of the problem, addressing the credibility of the 47.21% statistic. Enhancing the robustness of LLM-based systems against adversarial attacks is crucial; we suggest exploring adversarial training or other defensive techniques. Furthermore, the authors should clarify the fine-tuning process for the LLMs, including the adequacy of the 244 data points used, and elaborate on the prompt engineering strategies employed. Lastly, discussing the cost implications of using LLMs on large datasets would provide valuable context.