ID: JW3UKn4bmG
Title: Is ChatGPT a Good Causal Reasoner? A Comprehensive Evaluation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper measures the causal reasoning abilities of GPT-3.5 and GPT-4, emphasizing the importance of evaluating ChatGPT in this context, which has been overlooked in current research. The authors propose a comprehensive evaluation of four ChatGPT models across five benchmarks, revealing that these models excel at explaining causal relations but struggle with classification. The analysis indicates a tendency for hallucination and sensitivity to prompts and features of causal events.

### Strengths and Weaknesses
Strengths:  
- The topic is timely and relevant given the popularity of ChatGPT.  
- The paper includes thorough experiments and analyses that support its main claims.  
- It provides valuable insights into the limitations of ChatGPT in causal reasoning tasks.

Weaknesses:  
- The paper lacks novel findings, as hallucination and prompt sensitivity have been previously discussed.  
- The baselines for the Causal Explanation Generation task are outdated, and more recent models should be considered.  
- The analysis of in-context learning does not adequately address the influence of few-shot demonstration order.  
- There are inconsistencies in claims regarding lexical distances and causal reasoning performance.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their findings by incorporating more recent baselines, such as FLAN-T5 and LLaMA, for the Causal Explanation Generation task. Additionally, the authors should discuss the order of few-shot demonstrations in their analysis of in-context learning. Clarifying the relationship between lexical distances and causal reasoning performance is essential, as the current claims are not supported by the results. Furthermore, we suggest providing a detailed error analysis to identify common types of hallucinations and elaborating on the prompts used in the zero-shot setting for each task. Lastly, the authors should interpret specific terms like “causal interpreter,” “hallucination,” and “lexical distance” before their usage to enhance clarity.