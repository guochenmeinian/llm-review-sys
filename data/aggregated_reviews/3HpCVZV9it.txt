ID: 3HpCVZV9it
Title: Geometric-Averaged Preference Optimization for Soft Preference Labels
Conference: NeurIPS
Year: 2024
Number of Reviews: 20
Original Ratings: 6, 5, 6, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 4, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to aligning Large Language Models (LLMs) with human preferences by incorporating distributional soft preference labels. The authors argue that existing methods like Direct Preference Optimization (DPO) rely on binary preferences, which fail to capture the nuanced nature of human judgments. They propose a modification to DPO that employs a weighted geometric average of LLM output likelihood in the loss function, allowing for a more nuanced representation of preferences. The method can be applied to any DPO-based algorithm and demonstrates consistent improvements on standard alignment benchmarks, particularly with data containing modestly-confident labels. Additionally, the paper explores geometric averaging methods for aligning LLMs, discussing the implications of log probabilities in training dynamics and the performance of PaLM 2 models, which achieve high training and validation accuracy but show significant drops on out-of-distribution data.

### Strengths and Weaknesses
Strengths:
1. The algorithm is based on a simple and intuitive assumption, leading to a clear final form of the loss functions.
2. The paper is well-written, with understandable technical sections.
3. The approach of adapting scaling factors in preference optimization is practical and well-motivated.
4. The authors provide a thorough analysis of the geometric averaging methods and their scalability to different LLMs.
5. The paper effectively addresses the relationship between log probabilities and alignment performance, supported by experimental evidence.
6. The authors demonstrate a clear understanding of the implications of using LLMs for AI feedback and the potential biases involved.

Weaknesses:
1. The paper lacks sufficient theoretical analysis to justify the use of "Geometric Averaging" for soft labels in preference optimization.
2. Some aspects of the paper are unclear, particularly the definition of soft preference labels and their implications for model training.
3. The experiments, while suggestive of improvements, may not be optimal, and the paper does not adequately address the trade-offs between diverse aspects of preferences.
4. The paper does not fully resolve the structural gap in handling real-world preferences.
5. There is a concern regarding the sufficiency of the datasets used for validating the method's efficacy, particularly in relation to the TLDR and Anthropic HH datasets.

### Suggestions for Improvement
We recommend that the authors improve the theoretical analysis of the geometric averaging method to clarify its effectiveness and differentiate it from prior work. Additionally, a more thorough explanation of the soft preference labels and their implications for model training should be included to enhance clarity. We suggest expanding the experiments to include comparisons with more recent models and addressing potential issues related to the trade-offs in preference representation. Furthermore, we recommend that the authors improve the discussion on the potential biases introduced by LLMs in providing AI feedback, particularly regarding the accuracy of preference labels. It would also be beneficial to include a more comprehensive analysis of the effects of using synthetic data in training, especially in terms of performance degradation. Finally, we encourage the authors to expand the dataset used for validation to ensure robustness in the findings and to incorporate discussions on the learning dynamics of new variations of DPO, as highlighted in the referenced literature, to enhance the theoretical understanding of their approach.