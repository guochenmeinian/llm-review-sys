ID: rzW3RouIXc
Title: Query-as-context Pre-training for Dense Passage Retrieval
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method for context-supervised pre-training for dense passage retrieval, utilizing generated pseudo queries as context. The authors propose this query-as-context pre-training as an alternative to the traditional passage-passage pairs, arguing that the latter are often weakly related. The method is integrated with existing frameworks like coCondenser and CoT-MAE, and evaluated on the MS-MARCO passage retrieval dataset and out-of-domain zero-shot BEIR benchmarks, demonstrating effectiveness compared to baseline methods.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and presents a clear and simple idea of using pseudo queries for pre-training.
2. Experimental results show significant improvements on standard datasets, indicating the method's effectiveness.

Weaknesses:
1. The technical contribution is limited, as the use of generated pseudo queries has been previously explored in various contexts.
2. The requirement for labeled data to train the query generator may restrict the method's applicability compared to frameworks that utilize unlabeled data.
3. The novelty of the proposed method is questioned, as it closely resembles existing works in the domain, and the critique of passage-passage pairs lacks validation.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their technical contributions by explicitly differentiating their work from existing methods like NCI and DSI-QG. Additionally, we suggest integrating both query-passage and passage-passage pairs in a complementary manner through multi-task learning, as not all passage-passage pairs are irrelevant. The authors should also provide experimental results that compare the effects of combining both types of pairs. Furthermore, we encourage the authors to present generated query samples in the appendix to enhance reproducibility and clarity. Lastly, addressing the criteria for dividing passages based on semantic units rather than token length would strengthen the methodology.