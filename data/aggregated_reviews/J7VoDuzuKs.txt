ID: J7VoDuzuKs
Title: Unlocking Feature Visualization for Deep Network with MAgnitude Constrained Optimization
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 7, 4, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents MACO, a feature visualization technique that optimizes image phase while maintaining a constant magnitude of the Fourier spectrum, marking the first method capable of scaling to deep networks and generating non-adversarial feature visualizations on modern architectures. The authors propose three core contributions: (1) the MACO technique itself, (2) the integration of feature visualization with feature attribution, and (3) quantitative metrics for evaluating the method's effectiveness, including plausibility, FID, and transferability. The evaluation demonstrates MACO's scalability to modern vision models and provides a valuable resource for identifying misleading correlations in ImageNet classes. The authors acknowledge the importance of human experiments and are considering their integration in a future version of the paper.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and easy to follow.
2. MACO is a simple yet effective approach, motivated by human perception, particularly the significance of the phase spectrum.
3. The method broadens the scope of feature visualizations, addressing a gap in the literature.
4. The authors provide an interactive website for exploring findings and understanding model transparency.
5. Clear connections between visualized concepts and natural images are established.
6. The inclusion of quantitative evaluations, despite some assumptions, is a positive step in a field often reliant on qualitative assessments.

Weaknesses:
1. The combination of attribution and feature visualization lacks reliability, as many attribution methods are problematic, and the employed method may yield unreliable attributions.
2. The assumption that visualizations resembling natural images are superior could mislead, as it is independent of the model being analyzed.
3. The claim of providing a reliable tool for explaining semantic information in vision models may be overstated, given the limitations of feature visualizations.
4. The lack of a standardized protocol for quantitatively evaluating feature visualization methods is a significant drawback.
5. The proposed metrics (Plausibility, FID, and Transferability) may not be sufficient alone, and further clarification on their combined effectiveness is needed.
6. The evaluation metrics proposed may not adequately connect to explainability, necessitating a user study to assess interpretability effectively.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by including a user study to establish a clearer connection between the proposed metrics and explainability. Additionally, we suggest that the authors provide a more detailed explanation of how feature attribution and visualization can be quantitatively validated. It would be beneficial to clarify the selection process for the visualizations presented in the figures, ensuring transparency regarding whether they were randomly chosen or cherry-picked. Furthermore, we encourage the authors to tone down the claims regarding the reliability of their tool for explaining semantic information, perhaps framing it as a tool for exploring hypotheses instead. Lastly, addressing the limitations of the proposed metrics and including a runtime analysis would enhance the paper's robustness.