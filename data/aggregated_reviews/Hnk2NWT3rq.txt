ID: Hnk2NWT3rq
Title: ReliK: A Reliability Measure for Knowledge Graph Embeddings
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ReliK, a novel metric designed to measure the reliability and performance of knowledge graph embeddings (KGEs) across various downstream tasks without requiring additional training. The authors demonstrate that ReliK correlates with task performance in both common tasks (e.g., tail/relation prediction, triple classification) and advanced tasks (e.g., rule mining, question answering), while maintaining locality. The metric is task-agnostic and offers a theoretical foundation for evaluating KGEs.

### Strengths and Weaknesses
Strengths:
- The paper addresses an important topic in knowledge graph research by proposing a reliable evaluation metric.
- The theoretical analysis supporting ReliK is sound and well-articulated.
- Experiments are comprehensive, involving diverse tasks and datasets.

Weaknesses:
- The selection of KGE methods evaluated is limited, lacking representation from graph-based and semantic-based approaches.
- A detailed comparison with other recently proposed KGE evaluation metrics is necessary.
- The paper does not adequately explain performance disparities across different tasks, particularly between relation prediction and classification tasks.
- ReliK's applicability to a broader range of tasks, such as entity classification or clustering, remains untested.

### Suggestions for Improvement
We recommend that the authors improve the representation of KGE methods by including additional approaches, such as CompGCN, NBFNet, RGCN, TuckER, and KG-BERT, and clarify the rationale behind their current selection. Additionally, we suggest providing a qualitative analysis with specific examples of triples and their corresponding ReliK scores to illustrate the metric's practical value. A comprehensive comparison with other KGE evaluation metrics should be included to enhance the paper's robustness. Lastly, we encourage the authors to explore the performance of ReliK on a wider variety of tasks beyond those currently tested, such as entity classification, to demonstrate its generality and applicability.