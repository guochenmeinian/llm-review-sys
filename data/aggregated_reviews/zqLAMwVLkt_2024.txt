ID: zqLAMwVLkt
Title: Generative Semi-supervised Graph Anomaly Detection
Conference: NeurIPS
Year: 2024
Number of Reviews: 26
Original Ratings: 5, 6, 5, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 5, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach for node anomaly detection in a semi-supervised setting, proposing the generation of pseudo anomaly nodes to enhance training data. The authors introduce two priors—namely, asymmetric local affinity and egocentric closeness—aimed at mimicking real anomalies in both graph structure and feature representation. The methodology, referred to as GGAD, effectively incorporates graph structure information, particularly through the asymmetric local structural affinity prior. The authors argue that Gaussian noise is utilized as a hyperparameter to diversify outlier nodes without significantly impacting GGAD's performance. Extensive experiments demonstrate the effectiveness and robustness of the proposed method across various datasets and noise distributions, highlighting the importance of their loss functions in generating effective outlier nodes.

### Strengths and Weaknesses
Strengths:
- The semi-supervised setting is novel and reflects real-world scenarios where normal nodes are typically known.
- The motivation for the proposed regularization losses is intuitive and clearly articulated.
- The methodology effectively integrates graph structure information in generating outlier nodes.
- Empirical results support the performance claims of GGAD across different datasets and noise distributions.
- The authors provide clear explanations for their design choices, particularly regarding the loss functions.

Weaknesses:
- The two regularization losses are heavily based on empirical analysis, which may not generalize to other datasets.
- The assumption that anomaly nodes sharing similar local structures will have similar feature distributions lacks empirical verification.
- Some reviewers express concerns about the necessity of Gaussian noise and its impact on outlier distribution.
- The experiments do not include comparisons with diffusion-based generative anomaly detection baselines.
- There is confusion regarding the optimization of constraints and the selection of normal nodes, which may affect the clarity of the methodology.
- The model's reliance on prior knowledge may limit its applicability to anomaly types that do not conform to these priors.

### Suggestions for Improvement
We recommend that the authors improve the empirical verification of the assumptions underlying the regularization losses, particularly by providing comprehensive experimental validation across diverse datasets. Additionally, we suggest including a comparison with diffusion-based generative anomaly detection methods to strengthen the experimental framework. We encourage the authors to clarify the role of Gaussian noise and its necessity in the outlier generation process, as well as to address concerns related to the optimization of constraints more explicitly, particularly in the context of homophily in social networks. Furthermore, clarifying the optimization process for the loss functions, particularly how the two objectives can be reconciled, would enhance the paper's rigor. Finally, we recommend elaborating on the distinction between "hard" and "trivial" outliers in the manuscript to enhance the understanding of their methodology's contributions.