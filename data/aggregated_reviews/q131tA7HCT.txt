ID: q131tA7HCT
Title: Learning Linear Causal Representations from Interventions under General Nonlinear Mixing
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 7, 8, 8, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 5, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on learning latent causal models from interventional data, extending previous work on linear or polynomial mixing to a more general nonlinear mixing setting. The authors prove strong identifiability results for unknown single-node interventions and propose a novel contrastive algorithm for identifying latent variables. The paper evaluates the algorithm's performance on synthetic tasks and a modified image dataset, demonstrating its effectiveness.

### Strengths and Weaknesses
Strengths:
- The extension to nonlinear mixing is a significant and challenging advancement in causal representation learning.
- The contrastive algorithm for model parameter identification is innovative and sound.
- The paper is clearly written, providing thorough descriptions of its contributions and experimental methodologies.

Weaknesses:
- The focus on single-node interventions limits the generalizability of the results; the authors should discuss the potential for broader applications.
- The identifiability of the latent dimension \(d\) in the nonlinear setting is not addressed, which raises questions about its practical applicability.
- The Gaussian assumption is restrictive and should be acknowledged as a limitation, along with a discussion of its implications.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the generalizability of their results beyond single-node interventions. Additionally, they should clarify whether the latent dimension \(d\) is identifiable in the nonlinear setting and provide strategies for identifying \(d\) in practical applications. It would also be beneficial to include a concrete toy example to illustrate the identifiability results more clearly. Finally, the authors should be more upfront about the limitations of the Gaussian assumption and evaluate the sensitivity of their method to non-Gaussian latents in their experiments.