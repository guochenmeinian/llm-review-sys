ID: 9WSxQZ9mG7
Title: Large Language Models for Automated Data Science: Introducing CAAFE for Context-Aware Automated Feature Engineering
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 6, 6, 3, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Context-Aware Automated Feature Engineering (CAAFE), which utilizes Large Language Models (LLMs) to automate feature engineering for tabular datasets. The proposed method generates new features by prompting LLMs with dataset descriptions and iteratively evaluates their impact on model performance. Experimental results demonstrate that CAAFE can enhance the performance of state-of-the-art classifiers across various datasets, including those from OpenML and Kaggle.

### Strengths and Weaknesses
Strengths:
- The work is novel, introducing LLMs for automated feature engineering, which is a less explored area.
- The paper is technically sound, with experimental results supporting its claims and limitations clearly outlined.
- It is well-written and easy to follow, with a clear discussion of contributions and significance.

Weaknesses:
- The evaluation of alternative feature generation methods is limited, primarily comparing against AutoFE without considering other techniques like PCA or deep learning methods.
- The human-in-the-loop aspect is not thoroughly discussed, particularly regarding the frequency of revisions needed for LLM-generated code.
- The paper lacks extensive comparisons with existing AutoML systems, which diminishes the perceived value of the proposed approach.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by including comparisons with more effective automatic feature engineering methods like FETCH and OpenFE. Additionally, it would be beneficial to empirically validate the hypothesis regarding the limited benefit of deep learning methods on small datasets. We also suggest discussing the human-in-the-loop aspect more comprehensively, particularly how often human intervention is required to correct LLM outputs. Furthermore, clarifying the meaning of bold entries in tables and addressing the clarity of Figure 2 would enhance the presentation. Lastly, we encourage the authors to explore the implications of semantic information extraction from feature names and consider conducting experiments with semantic blinding to substantiate their claims.