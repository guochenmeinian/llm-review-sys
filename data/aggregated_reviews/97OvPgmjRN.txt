ID: 97OvPgmjRN
Title: Enhancing Chess Reinforcement Learning with Graph Representation
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 5, 6, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents AlphaGateau, a novel variant of AlphaZero utilizing a graph neural network (GNN) architecture that enhances generalization across board sizes. The authors demonstrate that AlphaGateau outperforms the original AlphaZero under specific conditions, achieving faster learning and greater data efficiency during initial training iterations. The introduction of the Graph Attention neTwork with Edge features from Attention weight Updates (GATEAU) layer addresses limitations of traditional CNNs, showing promise in reinforcement learning applications for chess.

### Strengths and Weaknesses
Strengths:
- The paper introduces an innovative graph-based approach to game state representation, leveraging GNNs to overcome CNN limitations.
- AlphaGateau exhibits significantly improved learning efficiency, achieving higher playing strength in less training time compared to AlphaZero.
- The authors provide reproducibility by making their code publicly available.

Weaknesses:
- The evidence for generalization capabilities is limited, primarily focusing on 5x5 and 8x8 chess variants without exploring other games.
- There is a lack of thorough comparative analysis with other state-of-the-art models beyond AlphaZero, which would clarify the proposed method's relative performance.
- The paper does not adequately address real-world applicability or potential applications of the graph-based approach outside chess.

### Suggestions for Improvement
We recommend that the authors improve the evaluation of AlphaGateau by including a more extensive comparative analysis with other graph-based reinforcement learning models. Additionally, conducting experiments on a broader range of games would strengthen claims of generalization. To enhance the validity of Elo ratings, we suggest anchoring these scores to other competent agents and providing detailed information on the hyperparameters used for Elo calculations. Furthermore, we advise the authors to discuss the limitations of their comparison to AlphaZero more clearly and to extend the training of AlphaZero to provide a more robust performance comparison. Lastly, including results from external evaluations, such as those from Lichess, would bolster the credibility of their findings.