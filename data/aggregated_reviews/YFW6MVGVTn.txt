ID: YFW6MVGVTn
Title: NICE: NoIse-modulated Consistency rEgularization for Data-Efficient GANs
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 8, 6, 5, 7, 6, -1, -1, -1, -1
Original Confidences: 2, 4, 4, 4, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a noise modulation and regularization scheme for GANs, termed NoIse-modulated Consistency rEgularization (NICE), aimed at reducing discriminator overfitting and enhancing training stability in low-data scenarios. The authors demonstrate the effectiveness of NICE through extensive theoretical analysis and empirical results across various network architectures and datasets, achieving state-of-the-art performance in low-shot generation tasks.

### Strengths and Weaknesses
Strengths:
- The paper includes extensive comparisons with competing methods and provides a solid theoretical foundation for the proposed technique.
- Numerical results are excellent, showcasing consistent improvements across different datasets and architectures.
- The organization and clarity of the paper facilitate understanding, despite its mathematical complexity.

Weaknesses:
- The absence of generated images in the main paper limits the visual validation of results, especially given concerns about FID reliability.
- The terminology used may confuse non-experts; clearer definitions of terms like "generation gap" and "discriminator discrepancy" are needed.
- Some supplemental images are of low quality, particularly CIFAR results, which require integer upscaling for clarity.
- The computational overhead of NICE is not quantitatively assessed, raising concerns about scalability and training costs.

### Suggestions for Improvement
We recommend that the authors improve the presentation of results by including generated images in the main text to enhance visual validation. Additionally, providing brief descriptions of complex terms would aid non-expert readers. The authors should also ensure that supplemental images are of sufficient quality and consider discussing the computational cost and scalability of NICE more thoroughly. Clarifying the tuning of new hyperparameters and addressing the limitations of the method in the main text would strengthen the paper. Finally, we suggest including a comparison of NICE with strong baseline methods, such as SSGAN-LA, to provide a more comprehensive evaluation.