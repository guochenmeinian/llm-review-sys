ID: tSEeRl7ACo
Title: Human-Guided Complexity-Controlled Abstractions
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 6, 6, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for learning discrete representations with varying complexity levels, proposing a human-in-the-loop framework where humans select from pretrained models based on prototypes. The authors demonstrate that representation complexity significantly affects fine-tuning performance through experiments and a user study, suggesting that simpler representations can enhance data efficiency in specific scenarios. Additionally, the paper introduces a new architecture, VQ-VIB$_\mathcal{C}$, which generates discrete prototypes with varied representation complexities. The authors argue that while lower complexity models can be beneficial in low-data scenarios, they show little to no advantage when sufficient finetuning data ($k > 5$) is available. The importance of a human-in-the-loop framework for encoder selection in low-data contexts is emphasized, supported by user study results indicating that participants can effectively identify optimal encoders.

### Strengths and Weaknesses
Strengths:
- The work introduces an intriguing method for learning a discrete 'codebook' with controllable complexity.
- The proposed reframing of the paper clarifies the findings and limitations of the human-in-the-loop method.
- Experiments reveal a clear non-monotonic relationship between complexity and usefulness in downstream tasks.
- The user study demonstrates that humans can select optimal encoders in complex settings, addressing previous concerns about the validity of the human experiment.
- The proposed VQ-VIB_C approach shows notable performance improvements over baselines in specific settings, and additional experiments, including validation set approaches, strengthen the overall argument.

Weaknesses:
- The paper fails to adequately address previous reviewer concerns, particularly regarding the realism of the human-in-the-loop approach and the lack of autonomous selection of abstraction levels.
- The experiments are limited to single benchmarks, lacking comparisons across diverse tasks or realistic pretraining and finetuning scenarios.
- The method shows minimal improvement in scenarios with $k \leq 10$, particularly in datasets like iNat, raising questions about its significance.
- The reliance on human input may not be sufficiently motivated, as the model performs comparably well autonomously with a small number of examples.
- There is insufficient discussion on the effort required for human guidance and the potential for automating abstraction selection.
- Concerns remain regarding the theoretical underpinnings of the entropy penalty and its implications for broader claims about abstraction levels.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the limitations of their approach, particularly regarding the human-in-the-loop paradigm and the need for a method to autonomously select the appropriate encoder. Additionally, we suggest that the authors provide clearer comparisons of the human-in-the-loop approach's performance against fully autonomous methods in various scenarios. The authors should also address the theoretical concerns regarding the connection between representation degradation and abstraction levels more robustly. Furthermore, we recommend providing more concrete examples of practical applications for their method and considering evaluating models using a validation set from downstream tasks instead of relying solely on human input. Finally, further validation of the method's effectiveness in diverse low-data contexts would enhance the paper's impact.