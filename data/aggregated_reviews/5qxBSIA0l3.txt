ID: 5qxBSIA0l3
Title: Explainable Multi-Modality Alignment for Transferable Recommendation
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the EARec method, an innovative explainable generative multimodal alignment framework for transferable recommendations. It introduces a two-stage pipeline that aligns multimodal information into a unified interpretable space, addressing limitations of traditional pairwise alignment methods regarding interpretability, consistency, and scalability. The method integrates recommendation behavior as a modality and employs an adaptive weight model combination, leveraging large language models (LLMs) for processing diverse modal inputs. Experimental results indicate that EARec outperforms baseline methods in metrics like HR@K and NDCG@K, particularly in cross-platform recommendation scenarios.

### Strengths and Weaknesses
Strengths:
- The method effectively addresses key limitations of traditional pairwise alignment methods.
- The integration of behavioral modality enhances the recommendation framework.
- The experimental results demonstrate significant performance improvements over baseline methods.

Weaknesses:
- The model's complexity may lead to high computational costs, particularly with multiple LLMs.
- The experiments are primarily based on Amazon and Movielens datasets, limiting the evaluation of the method's applicability in diverse recommendation scenarios.
- The theoretical foundations of the method are underexplored, and the paper lacks detailed explanations of training losses and model performance.

### Suggestions for Improvement
We recommend that the authors improve the literature review by including existing studies on generative alignment methods in other domains to highlight the originality of EARec. Additionally, provide a detailed explanation of the defined training losses, including the loss functions used in pretraining tasks. Strengthen the theoretical underpinnings of the model by discussing the theoretical basis behind generative alignment and including a detailed analysis of the simulation results. Clarify the modalities used in Table 2 and add more baseline comparisons to validate the model's performance. Address the poor performance on the Instruments dataset by explaining the reasons for this outcome. Improve the clarity of visualizations in Figure 5 by adding a legend and enhancing the layout of figures for better distinction of components. Finally, include more empirical evaluations to discuss the effectiveness of learned representations in various recommendation tasks.