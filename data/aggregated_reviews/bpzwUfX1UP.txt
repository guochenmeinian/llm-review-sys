ID: bpzwUfX1UP
Title: Parallel Sampling of Diffusion Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 8, 6, 7, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for accelerating sampling in diffusion models through parallelization using Picard iterations. The authors propose ParaDiGMS, which samples multiple time steps simultaneously and iteratively refines these estimates until convergence, trading increased computational cost for reduced latency. The method is evaluated on various control tasks and large-scale image datasets, demonstrating consistent latency reduction while maintaining sample quality.

### Strengths and Weaknesses
Strengths:
- The approach effectively addresses a significant problem in diffusion model sampling, potentially leading to widespread adoption for latency-sensitive applications.
- The method is clearly articulated, supported by theoretical analysis, and validated through comprehensive experiments across relevant datasets.
- The results indicate substantial speedups over traditional sequential sampling methods without compromising quality.

Weaknesses:
- The exploration of compute/latency trade-offs could be enhanced by conducting experiments with smaller problems and varying window sizes more extensively.
- The benefits of the method in low model evaluation scenarios remain unclear, particularly in comparison to existing techniques like DPMSolver.
- Terminology inconsistencies, such as the use of "batch size" instead of "batch window size," may lead to confusion regarding the method's implementation.

### Suggestions for Improvement
We recommend that the authors improve the exploration of the compute/latency trade-off by conducting experiments that vary the window size more thoroughly. Additionally, clarifying the method's performance in low evaluation regimes compared to DPMSolver would be beneficial. We suggest maintaining consistent terminology, specifically using "batch window size" throughout the paper to avoid confusion. Furthermore, providing additional qualitative results and commonly-used metrics like FID for image generation would strengthen the evaluation of the proposed method.