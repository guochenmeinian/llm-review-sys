ID: nge5deRsEH
Title: On the Power of Decision Trees in Auto-Regressive Language Modeling
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 5, 6, 7, -1, -1, -1, -1
Original Confidences: 4, 2, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents autoregressive decision trees (ARDTs) as a novel machine learning model with both theoretical and empirical contributions. The authors demonstrate that ARDTs can efficiently simulate automata, Turing machines, and $k$-sparse circuits, providing a simple example that highlights their improved expressivity over traditional decision trees. Empirically, ARDTs are applied to tasks such as generating short stories and solving reasoning tasks, showing effectiveness with limited training data and parameters.

### Strengths and Weaknesses
Strengths:
1. The theoretical results regarding ARDTs are novel and potentially impactful, particularly as they do not have analogous results for regular decision trees.
2. The paper is mostly well-written, with clear explanations of necessary preliminaries.
3. The application of ARDTs to language modeling is acknowledged as complex, with notable results on the Big-Bench-Hard benchmark.

Weaknesses:
1. Some proofs, particularly those of Theorems 3 and 6, lack clarity and raise doubts about their correctness, with specific concerns regarding the application of Lemma 10 and the definitions of functions involved.
2. The experimental evaluation, especially in Section 4.2, lacks variability metrics and raises concerns about the use of GPT-4 as an evaluator, questioning its consistency and the validity of the evaluation protocol.
3. The selection of reasoning tasks in Section 4.3 appears arbitrary, and the performance metrics raise questions about the comparison with state-of-the-art (SOTA) models.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the proofs, particularly addressing the concerns regarding Lemma 10 and the definitions of functions in Theorem 6. Additionally, please provide variability metrics such as standard deviation for the story generation results and clarify the evaluation protocol with GPT-4, including whether control tests were conducted. It would also be beneficial to justify the selection of reasoning tasks and ensure that the experimental evaluation aligns with the theoretical framework. Lastly, consider discussing the limitations of ARDTs for language modeling and the implications of parameter limitations on performance and scalability.