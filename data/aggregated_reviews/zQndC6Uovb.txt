ID: zQndC6Uovb
Title: Annealing Machine-assisted Learning of Graph Neural Network for Combinatorial Optimization
Conference: NeurIPS
Year: 2024
Number of Reviews: 2
Original Ratings: 6, 7
Original Confidences: 3, 3

Aggregated Review:
### Key Points
This paper presents a method to integrate graph neural networks (GNNs) with annealing machines (AMs) to tackle large-scale combinatorial optimization problems. The authors propose compressing large graphs into smaller segments, applying AMs to these segments, and aggregating the resulting features to inform a primary GNN solver. This approach aims to address the limitations of AMs in handling large problems while enhancing the accuracy of GNNs through AM-derived information. The authors perform numerical experiments to assess the performance and computation time of the GNN+AM scheme compared to GNN alone.

### Strengths and Weaknesses
Strengths:
- The combination of GNN and AM is an intriguing concept that appears to facilitate the resolution of large-scale combinatorial optimization problems.
- The authors explore various prototypical optimization problems, such as maximum cut, maximum independent set, and graph partition, and conduct extensive numerical experiments to evaluate different GNN modules.

Weaknesses:
- The performance improvement from combining GNN and AM is not convincingly demonstrated, with inconsistent results for maximum cut and graph partition that seem model-specific. The authors should conduct additional experiments to investigate these inconsistencies.
- Algorithm 1 lacks a self-contained presentation; newly introduced variables, such as the calculation of $\bar{R}^i$, should be explicitly defined.

### Suggestions for Improvement
We recommend that the authors improve the robustness of their findings by conducting more experiments to clarify the inconsistent performance trends observed in maximum cut and graph partition. Additionally, we suggest that the authors ensure Algorithm 1 is self-contained by providing explicit calculations for all newly introduced variables. Finally, we encourage the authors to include results on real-world graphs and to discuss scenarios where the GNN+AM approach may underperform compared to other methods.