ID: nuPp6jdCgg
Title: Evaluating Large Language Models on Controlled Generation Tasks
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper evaluates the controllability of large language models (LLMs) on controlled generation tasks, introducing five unexplored tasks and a new benchmark called “numerical planning.” The authors investigate the performance of LLMs against various constraints, revealing that while LLMs perform well on soft constraints, they struggle with fine-grained hard constraints, particularly in numerical planning.

### Strengths and Weaknesses
Strengths:  
- The evaluation is detailed and well-designed, with a comprehensive spectrum of tasks that illuminate LLMs' limitations in controllability.  
- The paper is well-organized and easy to follow, with clear figures and tables that enhance understanding.  
- Extensive experiments are conducted across a wide range of controlled generation tasks, contributing valuable insights to the field.  

Weaknesses:  
- Many findings are not novel to the community, and the paper lacks a thorough discussion on why LLMs struggle with fine-grained constraints and potential solutions.  
- The comparison of LLMs across different sections lacks consistency, as various models are used without clear justification.  
- The appendix requires more details, including additional examples and failed attempts, to enhance transparency.  

### Suggestions for Improvement
We recommend that the authors improve the appendix by including more examples and a presentation of failed examples. Additionally, we suggest providing a more in-depth discussion on why LLMs struggle with fine-grained hard constraints and how to address these issues. It would also be beneficial to ensure consistency in the models compared across sections and to clarify the rationale behind the positioning of tasks on the spectrum. Finally, we encourage the authors to revise the conclusion to better articulate the significance of the spectrum of tasks and their implications for future research.