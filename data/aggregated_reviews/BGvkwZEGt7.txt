ID: BGvkwZEGt7
Title: Large Language Models Are Latent Variable Models: Explaining and Finding Good Demonstrations for In-Context Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 5, 6, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel demonstration selection method for enhancing in-context learning in large language models (LLMs) through a two-stage process involving latent concept learning and demonstration selection. The authors propose a framework that utilizes prompt-tuning to derive task-specific token embeddings, which are then used to select in-context samples that maximize the likelihood of these learned tokens. Experimental results across multiple datasets indicate that this method consistently outperforms random selection and semantic similarity-based selection.

### Strengths and Weaknesses
Strengths:
- Originality: The approach, while inspired by prior work, offers a sufficiently distinct method for selecting effective demonstrations.
- Quality: The theoretical foundation and methodology are solid, with clear generative assumptions leading to a well-structured two-stage algorithm.
- Clarity: The paper is well-written, with a clear definition of tasks and detailed presentation of the proposed method.
- Empirical Results: The method demonstrates impressive performance, particularly in transferring demonstrations from smaller models to larger ones.

Weaknesses:
- Problem Setting: The assumption of having a relatively large training set for demonstration selection is considered somewhat artificial, as alternatives like parameter-efficient tuning may yield better results.
- Evaluation Tasks: The selected downstream tasks are perceived as too simplistic, raising concerns about the generalizability of the method to more complex tasks.
- Assumptions: The assumption that the task latent derived through prompt-tuning is optimal may not hold universally, suggesting a need for reconsideration.
- Notation and Clarity: Some notational elements are difficult to follow, and the analysis of selected demonstration examples lacks depth.

### Suggestions for Improvement
We recommend that the authors improve the problem setting by addressing the applicability of their method in scenarios with limited training data, potentially comparing it with parameter-efficient tuning methods. Additionally, we suggest expanding the evaluation to include more challenging tasks to better assess the generalizability of the proposed method. The authors should also clarify the assumptions regarding the optimality of task latents derived from prompt-tuning and consider incorporating a more intuitive understanding of task representation. Lastly, we encourage a deeper analysis of the attributes shared by selected demonstration examples to elucidate the mechanisms of in-context learning.