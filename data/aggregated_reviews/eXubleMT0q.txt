ID: eXubleMT0q
Title: Penguin: Parallel-Packed Homomorphic Encryption for Fast Graph Convolutional Network Inference
Conference: NeurIPS
Year: 2023
Number of Reviews: 6
Original Ratings: 6, 5, 7, 6, -1, -1
Original Confidences: 4, 2, 3, 3, -1, -1

Aggregated Review:
### Key Points
This paper presents Penguin, a novel HE-based ciphertext packing technique aimed at accelerating GCN inference on encrypted graph data while maintaining data privacy. Penguin addresses the significant computation and memory overhead associated with HE operations by focusing on matrix-matrix multiplications, which are identified as the bottleneck in private GCN inference. The authors propose a two-dimension parallel packing technique and an interleaved assembly technique to minimize HE rotations and utilize blank slots in polynomials. Theoretical analysis and experimental validation demonstrate that Penguin achieves up to ∼10× speedup and approximately ∼79% reduction in computational memory overhead compared to state-of-the-art solutions.

### Strengths and Weaknesses
Strengths:
1. The motivation is reasonable, as the paper effectively analyzes latency breakdown in private GCN inference and identifies matrix-matrix multiplications as the primary bottleneck.
2. The proposed methods, including Two-Dimension Parallel-Packing and Interleaved Assembling, are direct and effective, with experimental results supporting their efficacy.
3. The writing quality is excellent, providing logical coherence and clarity.

Weaknesses:
1. The paper lacks comparisons with several highly related works, particularly SIMD-based methods like Gazelle, which could provide context for the proposed techniques.
2. There is insufficient discussion on coefficient encoding methods, which may outperform the proposed approach in matrix operations.
3. The baseline comparisons are weak, particularly regarding CryptoGCN and other works optimizing HE for GCNs.

### Suggestions for Improvement
We recommend that the authors improve the paper by including detailed comparisons with existing approaches, particularly SIMD-based methods like Gazelle and coefficient encoding techniques such as Cheetah. Additionally, a stronger baseline comparison with CryptoGCN and other relevant works would enhance the paper's contributions. We also suggest addressing the discrepancies in latency reduction versus the number of CMults in Table 2 and discussing the limitations and potential future directions of the proposed technique more thoroughly.