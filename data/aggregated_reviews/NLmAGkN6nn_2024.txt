ID: NLmAGkN6nn
Title: PTQ4DiT: Post-training Quantization for Diffusion Transformers
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 5, 5, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents PTQ4DiT, a post-training quantization method specifically designed for Diffusion Transformers (DiTs). It addresses quantization challenges stemming from extreme magnitudes in salient channels and the temporal variability of activations across multiple timesteps. The authors propose techniques such as Channel-wise Salience Balancing (CSB) and Spearmen’s ρ-guided Salience Calibration (SSC) to minimize quantization errors and dynamically adapt across different timesteps, enhancing the performance of quantized DiTs without requiring re-training.

### Strengths and Weaknesses
Strengths:
- The method incorporates temporal information into the calibration process for salience balancing.
- The experimental results are robust, demonstrating the method's efficacy across various scenarios.
- The paper is well-organized with clear illustrations and presents the first quantization method for DiTs.

Weaknesses:
- The classifier-free guidance scales for sampling are unspecified, which may affect reproducibility.
- Under the W4A8 setting, significant performance degradation is observed, indicating limitations at lower bit-widths.
- The SSC technique's effectiveness is only moderately supported by results in Table 3, necessitating further evidence to emphasize its unique contribution.
- The paper lacks experiments on a broader range of DiT models and does not provide W8A8 results for ImageNet 512x512.

### Suggestions for Improvement
We recommend that the authors improve the clarity and detail regarding the classifier-free guidance scales to enhance reproducibility. Additionally, we suggest providing more comprehensive experimental results, including testing on a wider variety of DiT architectures and reporting W8A8 results for ImageNet 512x512. To strengthen the paper's claims, we encourage the authors to include direct evidence demonstrating the effectiveness of CSB and SSC, such as visualizations of activation distributions before and after applying these techniques. Lastly, we advise the authors to clarify the rationale behind the choice of the geometric mean for balancing activation and weight channels and to address the implications of introducing a time-varying $B_{\rho}^w$.