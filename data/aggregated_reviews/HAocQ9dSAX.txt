ID: HAocQ9dSAX
Title: DOGS: Distributed-Oriented Gaussian Splatting for Large-Scale 3D Reconstruction  Via Gaussian Consensus
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 6, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 5, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DoGaussian, a novel method that incorporates a distributed training strategy using the ADMM algorithm for large-scale 3D Gaussian Splatting (3DGS) tasks. By dividing scenes into K local blocks while maintaining a global model, DoGaussian achieves over six times faster training without compromising rendering quality. The method enhances rendering efficiency during inference by querying only the global block.

### Strengths and Weaknesses
Strengths:
1. DoGaussian introduces a significant acceleration in the 3DGS training process while preserving visual quality.
2. The method functions as a plugin, applicable to various GS representation works.
3. The paper is well-structured and easy to follow, with a high-quality supplementary video.

Weaknesses:
1. **Artifacts in Teaser:** Noticeable artifacts are present in the teaser, particularly in the bottom right image, necessitating an explanation and resolution from the authors.
2. **Limited Dataset Applicability:** Experiments are solely conducted on aerial datasets; demonstrating applicability on street datasets, such as the San Francisco Mission Bay dataset or MatrixCity's Block_A, is essential.
3. **GPU Memory Concerns:** The approach may face limitations due to GPU memory constraints, as all datasets are processed on a single GPU. The authors should demonstrate DoGaussian's effectiveness on larger datasets, including urban aerial and street data from MatrixCity.

### Suggestions for Improvement
We recommend that the authors improve the explanation of the artifacts in the teaser and address them appropriately. Additionally, it would be beneficial to conduct experiments on street datasets and larger datasets to validate the method's applicability. Furthermore, we encourage the authors to explore the visibility-aware splitting strategy of VastGaussian to assess potential improvements in final results. Lastly, a discussion regarding the memory consumption of the master node and its scalability with the number of Gaussians would enhance the paper's depth.