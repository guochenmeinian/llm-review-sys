ID: SYjxhKcXoN
Title: LFME: A Simple Framework for Learning from Multiple Experts in Domain Generalization
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 8, 4, 8, 4, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework called LFME for learning from multiple experts in domain generalization. LFME incorporates a logarithmic regularization term to align the target model with expert models, enabling it to leverage knowledge from various source domains and perform effectively across testing domains. The authors emphasize the need to interpret the gradients $\partial \mathcal{L}_{cla}$ and $\partial \mathcal{L}_{guid}$ collectively for joint classification tasks, arguing that these gradients serve distinct purposes to encourage the model to focus on different feature types without compromising its discriminative ability. Additionally, the authors discuss the role of knowledge distillation (KD) in sample reweighting, asserting that mining hard samples from domain experts enhances domain generalization by promoting the learning of domain-invariant features. Experimental results indicate that LFME surpasses existing methods in classification and segmentation tasks, demonstrating its capability to utilize more information for predictions and identify challenging samples from experts, thereby improving generalization.

### Strengths and Weaknesses
Strengths:
- The paper introduces a novel approach based on a new knowledge distillation paradigm for domain generalization, with a clear motivation for using multiple experts.
- The implementation is straightforward, and the results are compelling, supported by rigorous evaluation protocols.
- The theoretical insights and empirical analyses provided are valuable and enhance the understanding of the method's effectiveness.
- The authors provide a clear explanation of the gradient updating process in LFME, highlighting the complementary roles of $\partial \mathcal{L}_{cla}$ and $\partial \mathcal{L}_{guid}$.
- The discussion on hard sample mining from domain experts is well-founded, linking it to the improvement of domain generalization through the exploration of domain-invariant features.
- Empirical evidence supporting the effectiveness of hard sample mining is presented, reinforcing the proposed mechanisms.

Weaknesses:
- Although LFME shows improvements over the baseline ERM, it incurs higher training costs, requiring 1.5 times more training time than ERM, which should be acknowledged as a significant limitation.
- The paper does not explore the use of Vision Transformers (ViTs), which could provide insights into the method's performance with advanced architectures.
- The contribution of the proposed method is marginal compared to existing models, and the baseline models for comparison are not clearly defined, complicating the understanding of results.
- The discussion on the advantages of LFME over foundation models is insufficient, leaving the benefits of using expert models unclear.
- The explanation of the relationship between hard sample mining and confidence reduction could be further elaborated for clarity.
- The distinction between the proposed KD approach and traditional methods may require more detailed comparisons to enhance understanding.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the baseline models used for comparison and explicitly discuss the differences between their approach and foundation models. Additionally, we suggest including experiments with ViT backbones to assess the method's performance with more advanced architectures. The authors should also provide a more detailed explanation of the training time implications and consider including an ablation study to justify the choice of hyper-parameter ranges. Furthermore, addressing the discrepancies in performance claims compared to previous works, such as Meta-DMoE, would strengthen the paper's arguments. Lastly, we recommend that the authors improve the clarity of the relationship between hard sample mining and the confidence reduction perspective, possibly by providing more illustrative examples, and include more detailed comparisons between LFME and traditional KD methods to better highlight the differences in weighting strategies and their implications for performance.