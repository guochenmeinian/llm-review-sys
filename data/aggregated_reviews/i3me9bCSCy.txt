ID: i3me9bCSCy
Title: Set-based Neural Network Encoding Without Weight Tying
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 7, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Set-based Network Encoding (SNE), a method for encoding the weights of neural networks to predict various properties such as performance and training loss. The authors utilize a chunking mechanism along with layer-wise and block-wise positional encodings to enhance generalization across different neural network architectures. The paper includes transferability experiments, demonstrating SNE's ability to predict properties across different model architectures, which is a notable achievement. The methodology is clearly articulated, and the experimental results are generally convincing, supported by ablation studies and visualizations.

### Strengths and Weaknesses
Strengths:
- The novel approach of using a network's weights to infer attributes is a significant contribution.
- The Methodology section is clear, particularly the aggregation mechanism in Eq. 9, which parallels graph aggregation in GNNs.
- The experimental results are compelling, showcasing SNE's superior performance in cross-architecture and cross-dataset scenarios.
- The paper includes a limitations section that reasonably addresses the constraints of the experiments.

Weaknesses:
- The motivation for the research is weak, lacking concrete examples of practical applications.
- Presentation issues are notable, including unclear terminology (e.g., "Implicit Neural Representations") and citation format inconsistencies.
- The evaluation is primarily conducted on simpler datasets, which raises questions about the generalizability of the findings.

### Suggestions for Improvement
We recommend that the authors improve the motivation section by providing specific examples of applications for their research. Additionally, the authors should revise the presentation to clarify terms and ensure proper citation formats. For instance, they should explain "Implicit Neural Representations" and correct "modelzoo" to "model zoo." Float captions need to be expanded for clarity, particularly for Tables 2 and 3. Figure 2 should be enhanced for better visibility, and the NeurIPS checklist should be placed after the references. Lastly, we suggest that the authors conduct evaluations on more complex datasets, such as ImageNet, to strengthen their claims regarding generalizability.