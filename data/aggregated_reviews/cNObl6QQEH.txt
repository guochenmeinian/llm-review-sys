ID: cNObl6QQEH
Title: PanoGen: Text-Conditioned Panoramic Environment Generation for Vision-and-Language Navigation
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 5, 7, 8, 4, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 5, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach for generating diverse panoramic environments conditioned on text for visual-language-navigation (VLN) using stable diffusion and recursive inpainting. The authors propose pretraining and finetuning strategies to maximize the benefits of synthesized data, demonstrating effectiveness across various benchmarks. The method, named PANOGEN, addresses environment scarcity by generating new environments without human annotation, enhancing performance in VLN tasks.

### Strengths and Weaknesses
Strengths:
1. The use of strong generative models like Stable Diffusion to augment training data for robotics learning is promising and could be applied in other domains.
2. The paper is well-written, easy to follow, and includes sufficient experiments and strict ablation studies.
3. The proposed method shows significant improvements in instructed navigation tasks across multiple benchmarks.

Weaknesses:
1. The lack of examples for mPLUG captioning limits understanding of how suitable captions are created for generated images.
2. There is insufficient discussion on the selection of the image caption model and the necessity of novel layouts with instructions.
3. The generated panorama may lack coherence and quality, raising concerns about the effectiveness of the synthetic data.
4. Comparisons to previous data augmentation methods are missing, and the paper does not provide qualitative results of generated environments.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the selection of the image caption model and clarify the necessity of novel layouts with instructions. Including examples of mPLUG captioning would enhance reader comprehension. Additionally, providing qualitative results of generated panoramic environments and comparisons to existing data augmentation methods would strengthen the paper. Finally, addressing the coherence and quality of the generated data is crucial for evaluating its impact on VLN tasks.