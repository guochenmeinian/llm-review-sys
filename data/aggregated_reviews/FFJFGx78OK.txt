ID: FFJFGx78OK
Title: Consistency Diffusion Bridge Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 7, 6, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an innovative approach to improve the sampling efficiency of denoising diffusion bridge models (DDBMs) by extending consistency models (CMs). The authors propose a consistency diffusion bridge model (CDBM) that integrates two paradigms: consistency bridge distillation and consistency bridge training. The motivation is to reduce the high computational cost associated with DDBMs, which typically require numerous neural network evaluations. The authors derive a consistency loss tailored for DDBMs and demonstrate the effectiveness of their method through experiments in image-to-image translation and image inpainting. Additionally, the paper discusses the validity of the proposed forward stochastic differential equation (SDE) and backward ordinary differential equation (ODE) in maintaining the same marginals, arguing that diffusion bridges are Markovian processes when the endpoint is fixed. A rigorous proof for the Brownian bridge case is provided, demonstrating that simulating the SDE and ODE maintains the marginals, although concerns are raised regarding the Kolmogorov forward equation and its applicability in non-Markovian contexts.

### Strengths and Weaknesses
Strengths:
- The paper introduces a novel solution to enhance the sampling of DDBM-like models, addressing a significant challenge in diffusion-based models.
- The proposed method shows competitive performance and scalability compared to existing diffusion-based generative models with fewer evaluations.
- The paper is well-structured, with clear mathematical statements and a comprehensive presentation of the background, aiding readability.
- The authors provide a rigorous proof that maintains marginals in the Brownian bridge case, enhancing the theoretical foundation of their work.
- The clarification regarding the Markovian nature of diffusion bridges is insightful and adds depth to the discussion.

Weaknesses:
- The extension of CMs to DDBMs contains theoretical loopholes, particularly in the mathematical definitions used, such as the reverse-time standard Wiener process, which is not well-defined.
- The novelty of the contribution is questioned, as the adaptation of consistency methods to DDBMs may not significantly differ from existing approaches.
- The paper lacks sufficient intuition regarding the design of the consistency schedule, which is crucial for the method's success.
- There is ambiguity regarding the Kolmogorov forward equation and its relationship to the proposed models, which may undermine the validity of the probability flow ODE.
- The lack of a valid probability flow ODE is identified as a major flaw, which could affect the overall credibility of the paper.

### Suggestions for Improvement
We recommend that the authors improve the mathematical rigor in defining the stochastic differential equations (SDEs) used, particularly addressing the issues surrounding the reverse-time standard Wiener process and ensuring that the definitions align with established SDE literature. Additionally, we suggest providing more detailed intuition on the design of the consistency schedules, including examples of effective and ineffective schedules. Furthermore, a clearer motivation for combining CMs with DDBMs should be articulated, emphasizing the necessity of this integration. We also recommend improving the clarity surrounding the Kolmogorov forward equation and its implications for the proposed models. Including the proof for the Brownian bridge case in the paper would strengthen the argument regarding the validity of the probability flow ODE. Lastly, addressing concerns about the comparison of metrics, particularly PSNR and SSIM, in relation to sample quality would enhance the paper's robustness.