ID: b5pbHYNJnX
Title: Rethinking Model Selection and Decoding for Keyphrase Generation with Pre-trained Sequence-to-Sequence Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents systematic experiments on PLM choice, pre-training corpus, pre-training tasks, and decoding strategies in Keyphrase Generation (KPG), providing explanations and analyses. The authors propose a decoding strategy called DESEL, which significantly improves performance across multiple datasets. The study emphasizes the importance of model selection and the impact of design choices on KPG systems.

### Strengths and Weaknesses
Strengths:
1. The paper showcases thorough experiments on multiple datasets and various backbones, demonstrating a solid workload.
2. The proposed DESEL decoding strategy is straightforward yet powerful, leading to significant improvements.
3. The paper is well-written and organized, with detailed analyses and ablation studies supporting its contributions.

Weaknesses:
1. The baseline for comparison is limited and somewhat outdated; incorporating more robust baselines would enhance evaluation.
2. The parameter scale of the selected backbone is relatively small, raising questions about the validity of results for larger models.
3. The reasons behind the improvements from in-domain pre-training and task-adaptive pre-training are not clearly discussed.
4. There are no tests for statistical significance of the results, and the writing could be improved in certain areas.

### Suggestions for Improvement
We recommend that the authors improve the baseline comparisons by incorporating more recent and robust models. Additionally, the authors should explore the scalability of the DESEL approach for longer texts and clarify how it would perform with full documents. We suggest including tests for statistical significance to validate the results. Furthermore, a deeper discussion on why DESEL outperforms other decoding methods would strengthen the paper. Lastly, addressing the lower F1-scores for absent keyphrases and improving the organization of the paper would enhance clarity.