ID: 6IhNHKyuJO
Title: Hierarchical Randomized Smoothing
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 6, 4, 7, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 4, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new threat model for adversarial robustness, focusing on the intersection of $\ell_0$ and $\ell_2$ norms, where $\ell_0$ is defined as the number of modified rows in a matrix. To certify robustness against this model, the authors propose a hierarchical smoothing scheme that involves random selection of rows followed by Gaussian smoothing. The paper demonstrates the effectiveness of this approach on graph-network tasks, showing superiority over baseline methods.

### Strengths and Weaknesses
Strengths:
- The paper introduces a relevant threat model for adversarial attacks on graphs.
- The certification method outperforms existing baselines tailored to individual threat models.

Weaknesses:
- The technical novelty is limited, primarily extending existing methods without significant new insights.
- Claims regarding robustness certification need clarification, particularly concerning fixed points and distance assumptions.
- The exposition is overly complex, making it difficult to grasp the core ideas without substantial effort.
- Key tuning parameters lack principled selection guidance, and datasets are inadequately described.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their claims, ensuring that robustness is certified for all points within a specified distance rather than a fixed point. Additionally, we suggest simplifying the exposition, possibly by providing pseudocode to clarify the hierarchical smoothing process. It would also be beneficial to include guidance on selecting key parameters and to provide detailed descriptions of the datasets used in the experiments.