ID: Kig2YJVYfq
Title: Transferable Adversarial Robustness for Categorical Data via Universal Robust Embeddings
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 5, 6, 5, 6, 6, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method to enhance adversarial robustness in machine learning models for tabular data by utilizing universal robust embeddings derived from neural networks. The authors propose a bilevel alternating minimization framework to create these embeddings, which can be transferred to tree-based models, enabling them to achieve robustness without adversarial training while maintaining high accuracy. The empirical results demonstrate that the proposed methods outperform existing techniques within a practical threat model.

### Strengths and Weaknesses
Strengths:  
- The paper is well-written and easy to follow, presenting a novel approach applicable to categorical features.  
- The proposed method effectively addresses adversarial robustness under financial constraints, which is practical for real-world applications.  
- Empirical results validate the performance of the proposed approach, and the ablation study is insightful.  

Weaknesses:  
- There is insufficient theoretical analysis regarding the effectiveness of neural network embeddings on other models.  
- The claim about the lack of existing algorithms for cost-based objectives in decision-tree classifiers is imprecise, as similar models exist in the literature.  
- The paper does not adequately discuss the limitations of the proposed methods, particularly regarding the assumptions made about cost modifications and the datasets used for evaluation.  
- Concerns about catastrophic overfitting during adversarial training and the need for empirical evidence to support claims about hyperparameter selection remain unaddressed.

### Suggestions for Improvement
We recommend that the authors improve the theoretical analysis of why embeddings from neural networks are effective for other machine learning models. Additionally, the authors should clarify the differences between their approach and existing algorithms, particularly in relation to Chen et al. (2021), and provide empirical comparisons for robustness and efficiency. A discussion on the limitations and scope of the proposed approach would enhance the paper's clarity. Furthermore, we suggest including a more thorough examination of the impact of hyperparameters on performance and addressing the potential for catastrophic overfitting with empirical evidence. Lastly, the authors should consider highlighting practical use-cases for their work to better contextualize its applicability in industrial settings.