ID: Ud2UQ9ZCep
Title: Open Domain Multi-document Summarization: A Comprehensive Study of Model Brittleness under Retrieval
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on multi-document summarization (MDS) in the context of open-domain scenarios, where documents are retrieved via information retrieval (IR) methods rather than curated by humans. The authors propose a new dataset and evaluate various approaches, highlighting the impact of retrieval performance on summarization quality. They find that MDS models struggle with topically diverse documents and emphasize the need for high-quality datasets to advance research in this area.

### Strengths and Weaknesses
Strengths:
- The paper introduces an interesting perspective on MDS and addresses a real-world application gap.
- It includes meticulous experimental design and thorough error analysis, providing valuable insights.
- The writing is clear, and the flow of information is logical.

Weaknesses:
- The novelty of the contribution is low for an EMNLP paper, and the length of the paper makes it difficult to follow.
- The reliance on human-written reference summaries for queries may bias retrieval performance.
- The paper does not sufficiently quantify the challenges posed by irrelevant documents in the new dataset.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by reducing its length and integrating key content from the appendices into the main text. Additionally, the authors should provide a deeper evaluation of how input size limitations affect performance, considering alternatives to truncating documents. It would also be beneficial to analyze the phenomenon of irrelevant documents in more detail and consider releasing a "real" dataset in future work.