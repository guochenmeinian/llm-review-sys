ID: j7U4pFkCYB
Title: DynPoint: Dynamic Neural Point For View Synthesis
Conference: NeurIPS
Year: 2023
Number of Reviews: 19
Original Ratings: 7, 7, 3, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DynPoint, an algorithm designed for novel view synthesis from monocular videos by predicting scene flow and depth parameters. It aims to enhance the synthesis process by enabling information aggregation from neighboring frames, demonstrating significant training time reduction and robustness in handling uncontrolled, lengthy videos. The authors propose improvements to scene flow estimation using corrected depth values, and the method shows competitive results against existing approaches across various datasets. Additionally, the authors express a commitment to enhancing the quality of the demo in future iterations, planning to unveil a project webpage alongside the conference publication that will compile all demos showcased during the rebuttal process.

### Strengths and Weaknesses
Strengths:  
- The proposed technique for scene flow estimation is a solid contribution, addressing inconsistencies in depth and flow.  
- The hierarchical scheme for rendering semi-explicit structures is novel and efficient, applicable to any baseline method.  
- Experimental results indicate substantial improvements and robustness, contributing significantly to the field.  
- The authors demonstrate a proactive approach to improving their work by acknowledging feedback and planning future enhancements.

Weaknesses:  
- The method's reliance on existing models raises questions about quality consistency when substituting them.  
- The authors do not investigate the quality of correspondences, which could be valuable.  
- Presentation of visual results needs enhancement, particularly in Figure 3, which lacks clarity.  
- There is no comparison with "DynIBaR: Neural Dynamic Image-Based Rendering," and the absence of video results limits the evaluation of metric improvements.  
- The paper lacks a limitations or ethical considerations section.  
- The current demo may not meet the expected standards, indicating a need for further refinement before the conference.

### Suggestions for Improvement
We recommend that the authors improve the investigation of correspondence quality by extending Section 4.4 to include comparisons with methods like "Deformable Sprites" by Ye et al. Additionally, enhancing the presentation of visual results, particularly by providing close-ups in Figure 3, would clarify findings. We suggest including comparisons with "DynIBaR" and adding numerical results for the Nvidia dataset. Incorporating video metrics, such as VMAF, would strengthen the evaluation. Lastly, addressing the issues in Figure 5, discussing the method's limitations and ethical considerations, and improving the quality of the demo to align with the feedback received would enhance the paper's comprehensiveness. Ensuring that the project webpage is comprehensive and effectively showcases all relevant demos, including **demo1 and demo2**, is also recommended.