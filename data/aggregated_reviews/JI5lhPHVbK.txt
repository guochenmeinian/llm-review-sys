ID: JI5lhPHVbK
Title: Battle of the Large Language Models: Dolly vs LLaMA vs Vicuna vs Guanaco vs Bard vs ChatGPT - A Text-to-SQL Parsing Comparison
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive evaluation of the text-to-SQL parsing capabilities of various large language models (LLMs), including both open-source and closed-source options. The authors conduct experiments across nine benchmark datasets and five prompting strategies, revealing that open-source models significantly lag behind closed-source alternatives. The evaluation metrics used are execution accuracy (EX) and test suite accuracy (TS) for the Spider dataset. The authors highlight the sensitivity of model performance to different prompting strategies and the limitations of few-shot learning.

### Strengths and Weaknesses
Strengths:  
- The paper is well-written and provides a systematic comparison of multiple LLMs, contributing valuable insights into text-to-SQL parsing.  
- It includes some hyperparameters for reproducibility and offers a satisfactory list of references.  
- The exploration of prompting strategies and the analysis of few-shot learning sensitivity are noteworthy contributions.

Weaknesses:  
- Over 50% of the references lack peer-review venue indications, raising concerns about the paper's academic rigor.  
- The novelty is limited, focusing solely on text-to-SQL parsing without introducing new techniques or insights.  
- The methodology lacks clarity, particularly regarding model selection and prompting strategy rationale.  
- The paper primarily uses one evaluation metric (EX), limiting the robustness of the findings, and does not adequately address the anomaly described on line 315.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the methodology by detailing the selection criteria for models and the rationale behind the prompting strategies. Additionally, the authors should consider including a more comprehensive comparison with state-of-the-art models in text-to-SQL parsing to contextualize their findings. To enhance the robustness of the results, we suggest employing multiple evaluation metrics beyond EX. Furthermore, addressing the unexplained anomaly on line 315 and providing deeper error analysis would strengthen the paper. Lastly, we encourage the authors to proofread for grammatical accuracy and eliminate unnecessary repetitions in the text.