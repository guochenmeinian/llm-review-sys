ID: Y1edWJH9qB
Title: Tracing Hyperparameter Dependencies for Model Parsing via Learnable Graph Pooling Network
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 5, 5, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the model parsing (MP) task, which involves predicting hyperparameters of generative models from generated images. The authors propose a Learnable Graph Pooling Network (LGPN) that utilizes a Generation Trace Capturing Network (GTC) and a learnable pooling-unpooling graph mechanism called the GCN Refinement Block to explore hyperparameter dependencies. The effectiveness of LGPN is validated through extensive experiments on the newly introduced RED140 dataset, showing superior performance compared to existing methods.

### Strengths and Weaknesses
Strengths:
1. The introduction of graph pooling mechanisms to model hyperparameter dependencies in the MP task is innovative.
2. The creation of the RED140 dataset, which builds upon RED116, is a valuable contribution.
3. The proposed method demonstrates outstanding performance on both RED116 and RED140 datasets.

Weaknesses:
1. The distinction between the RED140 and RED116 datasets needs clarification, particularly regarding the ground-truth feature vector for Discrete Architecture hyperparameters.
2. The comparison primarily focuses on FEN-PN, lacking a broader range of evaluation metrics and dataset types, which raises concerns about the generalizability of the proposed method.
3. The performance drop observed in Fig. 6(b) compared to FEN-PN requires further explanation.
4. The analysis of hyperparameter dependencies is insufficient; the authors do not adequately discuss what dependencies exist and how they manifest.
5. The correlation graph construction method may overuse dataset information, potentially skewing comparisons with FEN-PN.
6. The sensitivity of certain parameters, such as thresholds for graph relations, is not addressed.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the differences between the RED140 and RED116 datasets, specifically about the ground-truth feature vector for Discrete Architecture hyperparameters. Additionally, the authors should expand their experimental comparisons to include more evaluation metrics and diverse dataset types to strengthen claims of generalizability. An explanation for the performance drop in Fig. 6(b) is necessary. Furthermore, we suggest that the authors provide a more thorough analysis of hyperparameter dependencies, detailing specific relationships and their implications. It would also be beneficial to address the potential overuse of dataset information in correlation graph construction and to discuss the sensitivity of parameters like thresholds for graph relations.