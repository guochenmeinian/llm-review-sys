ID: eOx0SMRUv7
Title: Online Consistency of the Nearest Neighbor Rule
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 6, 7, 6, -1, -1, -1
Original Confidences: 4, 3, 2, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the non-uniform consistency of the nearest neighbor prediction rule in a realizable online setting, particularly when instances are drawn from a well-behaved stochastic process. The authors generalize results from Cover and Hart (1967) and Kulkarni and Posner (1995), proving that under uniform dominance, the nearest neighbor rule is consistent for any measurable function. They introduce labeling functions on mutually labeling sets and provide convergence rates for smooth stochastic processes, contributing to the understanding of online learning beyond traditional assumptions.

### Strengths and Weaknesses
Strengths:  
The paper addresses an important question in online learning literature, filling a gap regarding the consistency of the nearest neighbor rule. It outlines various conditions under which this rule is consistent and is well-written, making significant contributions to the field.

Weaknesses:  
The writing style is overly reliant on geometric concepts, which may obscure the learning-theoretical insights. The proof techniques employed are somewhat standard in the literature, and the paper primarily focuses on the $1$-NN setting without adequately addressing the $k$-NN scenario.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing by minimizing the use of complex geometric concepts and focusing on Euclidean space in the main text, relegating generalizations to the appendix. Additionally, we suggest that the authors clarify why the main theorems assume uniform dominance instead of ergodic dominance, and provide a more detailed explanation of the "sequentially-constructed cover tree." It would be beneficial to move part of Section 7 to the appendix and enhance the explanation of Theorem 15 in the main text. Finally, we encourage the authors to explicitly address the $k$-NN setting and clarify the relationship between their results and those of Dasgupta (2012).