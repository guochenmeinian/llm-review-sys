ID: ty7Qk12Pd8
Title: Hierarchical Time-Aware Mixture of Experts for Multi-Modal Sequential Recommendation
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Hierarchical Time-Aware Mixture of Experts for Multi-Modal Sequential Recommendation (HM4SR), addressing challenges in multi-modal sequential recommendation by extracting key information from multi-modal data and incorporating explicit temporal information. The method employs a two-level hierarchical MoE, consisting of Interactive MoE and Temporal MoE, alongside a multi-task learning strategy to enhance model performance. Experimental results across four public datasets demonstrate the effectiveness of the proposed method.

### Strengths and Weaknesses
Strengths:
1. The HM4SR method effectively tackles challenges in multi-modal sequential recommendation, showing significant performance improvements (2.13% - 22.9%) over traditional and multi-modal baselines.
2. The innovative design of the two-level hierarchical MoE enhances item feature extraction and captures user dynamic interests through explicit temporal information.
3. The multi-task learning strategy mitigates information loss due to data sparsity, improving the model's preference learning ability.

Weaknesses:
1. The figures lack clarity, particularly in representing the sparseness of user-item data and the relevance of the multi-task learning module within the overall framework.
2. The effectiveness of the proposed method varies across datasets, particularly on the Games Dataset, warranting further investigation into contributing factors.
3. Limited experiments on multi-task learning's impact on data sparsity and the absence of comparisons with existing MoE approaches hinder a comprehensive evaluation of the proposed method.
4. The novelty of utilizing explicit time information is questioned, as it could have been better leveraged to learn user periodicity or seasonality.

### Suggestions for Improvement
We recommend that the authors improve the clarity of figures to better convey the sparseness of user-item data and the relevance of the multi-task learning module. Further investigation into the varying effectiveness across datasets, particularly the Games Dataset, should be conducted to identify additional contributing factors. We suggest conducting experiments on datasets with varying sparsity levels and comparing the proposed Interactive MoE with existing MoE approaches to validate its effectiveness. Additionally, we encourage the authors to clarify how the PCL loss captures the correlation between temporal information and multi-modal data, and to explore more effective ways to utilize explicit time information in the model. Finally, including training scripts and detailed instructions for reproducibility would enhance the paper's overall quality.