ID: et2T8SKF1O
Title: Library Learning Doesn’t: The Curious Case of the Single-Use “Library”
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 6, 8, 8
Original Confidences: 3, 4, 3

Aggregated Review:
### Key Points
This paper examines the claims of "library learning largely improves performance" made by LEGO-Prover and TROVE, revealing that lemma/tool reuse is infrequent in solutions generated by these systems. The authors conduct ablation experiments demonstrating that ablating reuse does not significantly affect performance, suggesting that self-correction and self-consistency are the primary drivers of performance gains rather than function reuse.

### Strengths and Weaknesses
Strengths:  
- The paper identifies a potentially unsound claim in prior works, highlighting the need for thorough ablation studies.  
- The results of the ablation experiments are convincing and provide valuable insights into the performance contributors in library-learning systems.  
- The writing is clear, offering a friendly summary of LEGO-Prover and TROVE alongside detailed descriptions of the experiments.  

Weaknesses:  
- A comparison between LEGO-Prover/TROVE and cases where tool reuse is crucial for performance gain is lacking, which could clarify differences and similarities in performance attribution.  
- The paper does not address whether the problems in MiniF2F and MATH genuinely require reuse, which could provide a fair assessment of the effectiveness of the library learning modules.  
- The authors do not specify the underlying LLM used for the ablations, nor do they explore the impact of different model sizes on function reuse.

### Suggestions for Improvement
We recommend that the authors improve the paper by including a comparison between LEGO-Prover/TROVE and cases where tool reuse is essential for performance gain. Additionally, addressing whether the problems in MiniF2F and MATH require reuse would enhance the assessment of the library learning modules. Furthermore, we suggest that the authors mention the underlying LLM used for the ablations and discuss its impact, as well as conduct experiments with different model sizes to evaluate the potential benefits of function reuse for certain models.