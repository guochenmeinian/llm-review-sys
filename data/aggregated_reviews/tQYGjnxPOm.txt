ID: tQYGjnxPOm
Title: D$^2$CSG: Unsupervised Learning of Compact CSG Trees with Dual Complements and Dropouts
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 7, 6, 6, 6, 8, -1, -1, -1, -1
Original Confidences: 5, 4, 5, 2, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a neural architecture, D2CSG, for inferring constructive solid geometry (CSG) programs to reconstruct complex 3D shapes. The architecture features two branches—a cover branch and a residual branch—differentiating to form the complete shape. Key improvements over CAPRI-Net include the use of primitive complements, distinct primitive sets for each branch, a dropout training stage promoting program sparsity, and a transition from an encoder to an auto-decoder framework. The method employs an occupancy-based reconstruction loss during a test-time optimization scheme. D2CSG demonstrates superior reconstruction quality compared to previous neural relaxation approaches, achieving a new state-of-the-art in CSG program inference.

### Strengths and Weaknesses
Strengths:  
The paper provides compelling evidence that D2CSG significantly enhances 3D CSG program inference, supported by both qualitative and quantitative results. The ablation studies are well-structured and informative, and the ability of D2CSG to represent a broader set of shapes than CAPRI-Net is a notable advantage.

Weaknesses:  
The methodological advancements are primarily incremental relative to CAPRI-Net, which may limit the perceived novelty. The clarity of the paper could be improved, as some technical details are relegated to supplemental material. Additionally, the dropout pruning process lacks clarity, and the sensitivity of the method to input noise and outliers raises concerns about robustness.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by providing more detailed explanations and visualizations of the architecture and training scheme, particularly in Figure 2 and the introductory paragraphs discussing the matrices. It would be beneficial to clarify the dropout pruning process and its application during training. We suggest adding rows to Table 3 to report results for just the dropout and just the optimization stages, aiding in understanding their individual impacts. Furthermore, a discussion on the implications of the design choices, particularly regarding robustness to noise and the use of quadric surfaces as primitives, should be included in the limitations section. Lastly, we encourage the authors to consider user studies comparing generated CSG trees to real modeling sequences to assess their naturalness and applicability in practical CAD contexts.