ID: hp9isRQZqr
Title: Qualitative Study of Gesture Annotation Corpus: Challenges and Perspectives
Conference: ACM
Year: 2024
Number of Reviews: 2
Original Ratings: 6, 7
Original Confidences: 5, 5

Aggregated Review:
### Key Points
This paper presents an initial study on the reliability of gesture annotations in the BEAT dataset, which includes three analyses: a comparison of a 5-second segment with a re-annotation by the authors, a word recognition test identifying 0.81% of lexical affiliates as likely erroneous, and an analysis of gesture durations revealing a high ratio of outlier durations. The authors discuss the shortcomings of the gesture-annotation methodology in BEAT and propose solutions for more rigorous annotation.

### Strengths and Weaknesses
Strengths:
- The paper addresses an important and understudied aspect of gesture generation.
- It is well-written, with detailed background and discussion sections.
- The experiments reveal significant shortcomings in the gesture annotations of a popular motion-capture dataset.
- A thorough discussion on gesture-annotation methodology is provided, aiding the community's progress.

Weaknesses:
- The introduction lacks a section number.
- McNeil's gesture classification is dimensional rather than categorical, which may limit the proposed annotation's ability to categorize multiple gestures simultaneously.
- Although the annotation considers gesture phases, these phases are not annotated, which could enhance co-speech gesture generation.
- Concrete examples for methodological suggestions, such as separating annotation tasks between expert and non-expert annotators, would be beneficial.
- The SaGA dataset is not referenced, despite its detailed gesture annotations and public annotation manual.

### Suggestions for Improvement
We recommend that the authors improve the introduction by adding a section number. Additionally, the authors should clarify the dimensional nature of McNeil's gesture classification and consider how to incorporate multiple gesture categories in their annotation. We suggest that the authors annotate gesture phases to utilize this information in co-speech gesture generation. Furthermore, including concrete examples for their methodological suggestions would enhance the paper's clarity. Lastly, we recommend that the authors include a reference to the SaGA dataset to provide a more comprehensive context for their work.