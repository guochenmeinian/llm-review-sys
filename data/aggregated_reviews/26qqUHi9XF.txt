ID: 26qqUHi9XF
Title: General Munchausen Reinforcement Learning with Tsallis Kullback-Leibler Divergence
Conference: NeurIPS
Year: 2023
Number of Reviews: 6
Original Ratings: 6, 6, 7, 6, -1, -1
Original Confidences: 3, 3, 3, 2, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on Tsallis regularized MDPs and proposes a practical algorithm for Tsallis KL divergence based on Munchausen RL. The authors extend Munchausen value iteration to create MVI($q$), demonstrating notable performance improvements across 35 Atari games. The theoretical foundations are established, and the empirical results suggest significant gains, attributed to changes in exploration strategies.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and provides a clear introduction to the background and concepts.
- The properties of Tsallis policies are thoroughly analyzed, and the theoretical foundations for MVI($q$) are well established.
- Empirical results indicate substantial performance improvements over existing baselines.

Weaknesses:
- The justification for the benefits of Tsallis regularization in regularized value iteration is unclear, lacking theoretical intuition.
- The main characteristics and advantages of MVI($q$) are insufficiently explained, making it difficult to discern its unique benefits compared to controlling the regularization coefficient.
- The experiments are limited in scope, lacking comparisons with more established baselines and not addressing the limitations of the proposed method.

### Suggestions for Improvement
We recommend that the authors improve the theoretical justification for why Tsallis regularization is beneficial for regularized value iteration. Additionally, clarify the unique advantages of MVI($q$) over controlling the regularization coefficient and include case scenarios demonstrating its superiority in toy problems. Expanding the experimental comparisons to include more baselines, such as SAC and TRPO, and standardizing experiments against commonly accepted benchmarks would enhance the robustness of the findings. Finally, addressing the computational overhead of MVI($q$) and providing a detailed algorithm in the appendix would be beneficial for completeness.