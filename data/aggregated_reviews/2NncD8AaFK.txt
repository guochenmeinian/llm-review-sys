ID: 2NncD8AaFK
Title: CoLLAT: On Adding Fine-grained Audio Understanding to Language Models using Token-Level Locked-Language Tuning
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 6, 6, 7, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to train audio embeddings grounded in text embeddings for audio classification. The authors propose a token interaction module followed by a frozen text encoder to learn audio representation, achieving state-of-the-art results in audio tagging, classification tasks, cross-modal retrieval, and audio-guided image generation. They introduce several loss terms to enhance audio-text alignment and demonstrate the efficacy of their method through extensive evaluations.

### Strengths and Weaknesses
Strengths:
- The approach of appending a token interaction module followed by a text encoder is innovative and effectively leverages the capabilities of a frozen language model.
- The extensive evaluations, including zero-shot and linear probe settings, provide a thorough understanding of the proposed system's behavior.
- The results convincingly demonstrate the model's effectiveness across various downstream tasks, including audio classification and cross-modal retrieval.

Weaknesses:
- The training methodology using AudioSet labels for constructing prompts appears arbitrary, and the claim regarding template effectiveness lacks sufficient evidence. The work could benefit from pre-training with additional audio and natural language descriptions.
- The evaluation is limited to audio tagging and classification tasks; incorporating language-based audio retrieval would provide a broader perspective on the audio-text pre-training.
- Insufficient details are provided for reproducing experiments, particularly regarding the audio encoder architecture and the permutation module's functionality.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the training methodology, particularly by providing more evidence for the effectiveness of the proposed templates. Additionally, consider incorporating more audio-text tasks, such as language-based audio retrieval, to enhance the evaluation scope. We suggest including detailed explanations of the token interaction module and the denoising pipeline, as well as conducting ablation studies to validate architectural choices. Finally, ensure that all relevant prior works are referenced and that the final version includes comprehensive results and metrics in the evaluation tables.