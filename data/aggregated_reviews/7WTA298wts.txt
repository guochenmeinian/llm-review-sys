ID: 7WTA298wts
Title: Masked Image Residual Learning for Scaling Deeper Vision Transformers
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 6, 5, 6, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the degradation issue in deeper layers of Vision Transformers (ViTs) during Masked Image Modeling (MIM) pre-training. The authors propose a new framework called Masked Image Residual Learning (MIRL) to address this problem by reformulating the learning objective to recover both the main image component and its residuals. Experimental results indicate that MIRL enhances performance in deeper ViTs compared to traditional MIM approaches.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and easy to follow.
2. The authors systematically analyze the effectiveness of MIM pre-training for deeper layers of ViTs.
3. The proposed method is novel and effectively addresses a significant issue in the field.
4. Extensive experiments demonstrate the efficacy of MIRL, with code provided in supplementary material.

Weaknesses:
1. Comparisons against other methods are unfair due to the inclusion of an exponential moving average (EMA) in MIRL's fine-tuning, which should be standardized across models.
2. The rationale behind the effectiveness of residual learning is not sufficiently explained.
3. Observations regarding different pre-training methods are not clearly represented in the figures, particularly in Figure 2.
4. The experiments lack necessary results for deeper models, limiting the clarity of the proposed method's effectiveness.
5. Some baseline methods are missing from the comparisons, and the design choices for certain models are unclear.

### Suggestions for Improvement
We recommend that the authors improve the fairness of comparisons by fine-tuning all models without EMA. Additionally, the authors should provide a clearer explanation of why learning residuals alleviates degradation in deeper layers. It would be beneficial to revise Figure 2 to include separate plots for vanilla MAE and truncated MAE. Furthermore, we suggest including results for deeper models like ViT-L and comparing with additional baseline methods. Clarifying the configurations in Table 2 and addressing minor typos would also enhance the paper's quality. Lastly, a comparison with recent CVPR'23 works should be included to contextualize the proposed method within the current research landscape.