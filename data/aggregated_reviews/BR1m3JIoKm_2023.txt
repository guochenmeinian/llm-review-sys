ID: BR1m3JIoKm
Title: BoardgameQA: A Dataset for Natural Language Reasoning with Contradictory Information
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 6, 7, 7, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents BoardgameQA, a synthetic dataset designed to assess the multi-hop defeasible reasoning capabilities of existing language models (LMs) when dealing with conflicting information guided by preferences. The authors propose an algorithm for generating facts, rules, preferences, and questions, along with a template-based natural language conversion. They evaluate various LMs, including BERT, T5, and PaLM, across different reasoning depths, providing a detailed analysis of model performance, particularly at depth 2, revealing significant challenges in preference understanding and defeasible reasoning. The analysis also incrementally increases the depth of proofs from 1 to n, with illustrative figures demonstrating errors at depths 1, 2, and 3. The authors propose generating and publicly releasing subsets of their dataset with higher depths for future analysis. The incorporation of natural language variations is achieved through multiple templates for rules and predicates, a large set of mutually exclusive entities and predicates, and various fact specifications. The paper discusses quantification in natural language, providing examples in Table 3, and clarifies that only questions are negated, not logical formulae, with an example of this process included. Standard deviations for the BERT model are provided in Appendix A.

### Strengths and Weaknesses
Strengths:  
- The dataset effectively measures reasoning abilities with conflicting sources, highlighting the need for improved models.  
- The algorithm for dataset generation is efficient and supports varying depths of reasoning.  
- Comprehensive analysis of proof depth with illustrative figures yields valuable insights into model performance.  
- Effective incorporation of natural language variations enhances model robustness.  
- Clear rationale for using templates over LLMs addresses potential biases and verification costs.  

Weaknesses:  
- Lack of clarity on the significance and application of existential and universal quantifiers in data generation.  
- Limited exploration of existing LMs' capabilities for generating diverse natural language samples.  
- Insufficient explanation of the negation generation process for logical sentences, particularly concerning inference rules.  
- Absence of statistical significance for results from freely available models like BERT and T5.  
- Insufficient exploration of the implications of negating only questions rather than logical formulae.  

### Suggestions for Improvement
We recommend that the authors improve the explanation of the significance of existential and universal quantifiers in the dataset generation process, providing specific examples of their application in natural language. Additionally, consider leveraging existing LMs to generate more diverse and natural samples instead of relying solely on template-based methods. Clarifying the algorithm for generating negations, especially for logical sentences involving inference rules, is essential. We suggest including experiments with GPT-family models to enhance the analysis and presenting statistical significance for results from BERT and T5. Furthermore, we recommend elaborating on the implications of negating only questions, as this could enhance the understanding of the logical framework presented. Finally, an analysis demonstrating the incremental increase in reasoning depth beyond 3 would provide further insights into the dataset's challenges.