ID: jIabKyXOTt
Title: Sparsity-Agnostic Linear Bandits with Adaptive Adversaries
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 6, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper studies the sparse linear bandit problem without prior knowledge of sparsity, considering an adaptive adversary and arbitrary action sets. The authors propose algorithms based on OFUL, specifically SparseLinUCB and AdaLinUCB, providing regret bounds. SparseLinUCB achieves a $\tilde{O}(S \sqrt{dT})$ regret bound, while AdaLinUCB updates the sampling distribution of the confidence radius to achieve a $\tilde{O}(\sqrt{T})$ regret bound. The paper includes numerical experiments to support the theoretical claims.

### Strengths and Weaknesses
Strengths:
- The paper lifts assumptions from existing works while maintaining or improving regret bounds.
- SparseLinUCB is the first sparsity-agnostic linear bandit algorithm for adversarial contexts, matching lower bounds when sparsity is known.
- AdaLinUCB's approach to updating the confidence radius distribution is innovative, achieving better regret bounds than previous methods.
- The paper is well-written, with clear explanations and supportive empirical results.

Weaknesses:
- The instance-dependent regret bound of SparseLinUCB shows no improvement over the standard OFUL algorithm and can be worse under certain conditions.
- The algorithm AdaLinUCB appears to rely on stochastic assumptions not clearly explained, raising questions about its performance under adaptive adversaries.
- The writing lacks clarity in several areas, including definitions and notations, which may confuse readers.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing, particularly in defining terms and notations, such as the distribution $\{q_i\}_{i \in [n]}$ and the confidence set notation. Additionally, we suggest providing a separate paragraph to highlight the theoretical novelty of the techniques used. The authors should also clarify the necessity of using an online learning oracle in the algorithm design and address the implications of varying $n$ on the regret bound. Lastly, we encourage the authors to explore additional distribution selection cases that could recover the $dS/\Delta$ instance-dependent bound in the known sparsity and adaptive adversary setup.