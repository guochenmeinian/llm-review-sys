ID: PcyioHOmjq
Title: What Makes CLIP More Robust to Long-Tailed Pre-Training Data? A Controlled Study for Transferable Insights
Conference: NeurIPS
Year: 2024
Number of Reviews: 19
Original Ratings: 5, 5, 4, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an empirical study on the mechanisms behind CLIP's robustness to data imbalance, exploring factors such as language supervision, classification templates, data scaling, and open-world concepts. The authors propose that these factors contribute to CLIP's superior performance compared to supervised learning, particularly in the context of imbalanced datasets. Additionally, this paper investigates the concept distribution of web-crawled datasets and assesses the robustness of industry-trained CLIP models. Systematic experiments reveal that web data is imbalanced and that CLIP demonstrates robustness to this imbalance. The findings suggest that the advantages of CLIP can be transferred to both supervised and self-supervised learning scenarios, and the authors emphasize the importance of transferring these insights to other domains. They have made their code and data publicly available to benefit future research.

### Strengths and Weaknesses
Strengths:
- The proposed problem is significant and well-motivated, addressing the robustness of CLIP to data imbalance.
- The experiments are comprehensive and utilize high-quality datasets, particularly ImageNet-Captions, elucidating the factors influencing CLIP's performance.
- The paper reveals critical insights into the distribution of concepts in vision-language pretraining datasets and highlights the robustness of CLIP training.
- The authors contribute valuable insights that are transferable to other domains, enhancing the relevance of their findings.
- The release of code and data supports transparency and encourages further research.

Weaknesses:
- Some observations regarding robustness and generalization are already well-known in the community, such as the benefits of high-quality, richly described data.
- Certain sections, particularly Section 3, lack clarity and coherence; brief conclusions for each subsection are recommended.
- The methodology for handling training data during vocabulary subsampling is ambiguous, and the impact of this technique on models with smaller default dimensions remains unclear.
- There are lingering concerns regarding the CLIP head, which is not the authors' primary contribution but is analyzed in detail.
- The discussions may have become overly detailed, potentially obscuring the main contributions of the paper.
- The paper primarily focuses on data factors, neglecting other potential influences on robustness, such as loss function comparisons.

### Suggestions for Improvement
We recommend that the authors improve clarity by adding brief conclusions to each subsection in Section 3. Additionally, the authors should provide a more detailed explanation of the methodology for handling training data during random subsampling of vocabulary in Section 3.3. It would also be beneficial to include experiments that directly assess the impact of vocabulary subsampling on smaller models, as well as a quantitative analysis of the proposed class sub-sampling training method in Section 4.2. Furthermore, we suggest that the authors improve the clarity of their main contributions to ensure they are not overshadowed by detailed discussions on the CLIP head. Lastly, we recommend that the authors soften claims regarding the uncovering of mechanisms behind CLIP's generalizability, as the characterization of these mechanisms may not be fully complete, and further elaborate on the implications of their findings in relation to the broader context of data-centric approaches in machine learning.