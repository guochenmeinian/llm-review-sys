ID: Oy2x0Xfx0u
Title: What do Graph Neural Networks learn? Insights from Tropical Geometry
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 5, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study of the expressivity of message passing neural networks (MPNNs) through tropical geometry, establishing equivalences between piecewise linear polynomials, tropical geometric functions, and MPNNs. The authors propose methods for counting linear regions and express types of tropical functions as MPNNs. They introduce a lower bound for the maximal number of linear regions in ReLU MPNNs, which is dependent on the architecture's parameters and the maximum degree of the input graph. Theoretical contributions include lower and upper bounds for the number of linear regions and a comparison of aggregation operators, revealing that the max operator exhibits greater geometric complexity than the sum operator. The authors also claim a connection between geometric complexity and generalization, stating that if geometric complexity is upper bounded by \( r \), then the VC-dimension is at most \( r \), leading to a generalization bound. They acknowledge the need for clarification in their definitions and notation.

### Strengths and Weaknesses
Strengths:
- The paper is well-structured, clear, and well-motivated, laying a foundation for future work utilizing tropical geometry in neural networks.
- It provides thorough analyses of theoretical contributions, including significant results on expressivity and linear regions.
- The authors demonstrate a clear understanding of the relationship between geometric complexity and generalization.
- They are responsive to reviewer feedback, indicating a willingness to improve the clarity and correctness of their work.

Weaknesses:
- The paper lacks sufficient context and clarity, particularly for readers unfamiliar with tropical geometry, making it a challenging read.
- The literature review is inadequate, failing to acknowledge previous work on the equivalence of tropical signomial maps and feedforward neural networks.
- The definition of complexity is inconsistent, leading to confusion regarding the input to \( \mathcal{N} \).
- The theoretical analysis may not directly apply to practical graph predictions, and the assumptions made could be overly restrictive.
- The VC-dimension bound provided is considered loose and not as informative as existing bounds in the literature.

### Suggestions for Improvement
We recommend that the authors improve the paper's presentation by providing more background on tropical geometry and discussing main results at a higher level to enhance accessibility. Clarifying the definitions of key terms, such as "equivalence," and explicitly stating the implications of geometric complexity on generalization would be beneficial. Additionally, we suggest expanding the literature review to include relevant works on tropical geometry and machine learning, ensuring appropriate credit is given. The authors should also consider revising the notation to avoid ambiguity, particularly regarding \( \mathcal{N} \), and improve its definition to clarify that it should apply to a family of CPLMs rather than a single continuous piecewise linear map. Furthermore, we advise refining the discussion on VC-dimension to acknowledge its potential looseness and to better position their results in relation to existing literature, particularly the work by Bartlett et al. Lastly, a richer discussion of limitations and future work in the conclusion would strengthen the paper's impact, and please ensure that the references on tropical geometry are included and appropriately positioned in the updated version.