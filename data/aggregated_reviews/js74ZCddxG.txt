ID: js74ZCddxG
Title: RFLPA: A Robust Federated Learning Framework against Poisoning Attacks with Secure Aggregation
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 5, 5, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents RFLPA, a framework designed to enhance the robustness of federated learning (FL) against poisoning attacks while ensuring privacy. The authors propose a defense mechanism that utilizes cosine similarity detection within secure aggregation (SecAgg) and introduces a novel dot-product aggregation method to mitigate information leakage. The framework claims to reduce communication and computation overhead significantly compared to previous works, while maintaining competitive accuracy. Additionally, the paper introduces a protocol for packed secret sharing with dot product aggregation, emphasizing its efficiency in encryption and decryption through symmetric methods, which are faster than asymmetric encryption used in HE-based protocols. The authors argue that their approach mitigates privacy risks associated with secret sharing and reconstruction while addressing the issue of privacy leakage.

### Strengths and Weaknesses
Strengths:  
1. The paper is well-structured and provides a comprehensive explanation of how RFLPA integrates cosine similarity detection with packed Shamir secret sharing and dot-product aggregation.  
2. The theoretical analysis and empirical results demonstrate that RFLPA reduces communication and computation costs by 75% compared to BREA while sustaining accuracy.  
3. The framework effectively addresses a critical issue in FL security, supported by extensive experimental validation.  
4. The use of symmetric encryption enhances efficiency in the protocol and effectively addresses privacy leakage concerns.  
5. The authors provide a clear rationale for the benefits of their approach over HE-based methods.

Weaknesses:  
1. The paper's reliance on the assumption that the server possesses a clean root dataset is a fundamental limitation, as this may not be feasible in real-world scenarios.  
2. The communication costs associated with computing cosine similarity among clients are not adequately addressed, potentially undermining the claimed efficiency.  
3. The experimental evaluation lacks robustness testing against more subtle Byzantine attacks and does not explore the applicability of RFLPA to diverse federated learning models.  
4. Notations and formulations throughout the paper are unclear, leading to potential confusion regarding the algorithm's implementation.  
5. The omission of encryption and decryption in BREA's solution poses risks to user privacy.  
6. The trade-off between client selection and collusion thresholds may require further clarification.

### Suggestions for Improvement
We recommend that the authors improve the clarity of notations and formulations to enhance reader comprehension, particularly in Algorithm 3. Additionally, the authors should provide a more detailed analysis of the communication costs incurred by cosine similarity computation and clarify the implications of the server's role in the framework. We suggest conducting further experiments to evaluate RFLPA's performance against a broader range of Byzantine attacks and exploring its applicability to more dynamic client populations. Furthermore, we recommend that the authors improve the discussion on the necessity of encryption and decryption processes in their protocol to emphasize the risks posed by BREA's approach. Clarifying the implications of client selection on privacy risks and providing more detailed comparisons of computation costs between their method and BREA's protocol would also be beneficial. Finally, highlighting the significance of the degree reduction as a side benefit in the context of privacy could enhance the clarity of their contributions.