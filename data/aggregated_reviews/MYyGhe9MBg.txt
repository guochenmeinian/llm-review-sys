ID: MYyGhe9MBg
Title: T2VSafetyBench: Evaluating the Safety of Text-to-Video Generative Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 21
Original Ratings: 7, 6, 6, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a benchmark for evaluating the safety of text-to-video (T2V) models, identifying 12 safety aspects relevant to T2V generation. The authors propose T2VSafetyBench, which incorporates both GPT-4 and human evaluations to assess safety across various models. Key findings indicate that no model excels in all safety aspects, and there is a notable trade-off between usability and safety as generative capabilities improve. Additionally, the paper addresses ethical concerns and potential biases in human review processes, implementing safety measures for human evaluators, including age restrictions, health screenings, and clear communication about distressing content. The authors provide definitions and examples to mitigate cultural bias among reviewers and propose to discuss overcensorship issues related to prompts used in benchmarks.

### Strengths and Weaknesses
Strengths:
- The paper addresses a critical issue in T2V safety and provides a structured benchmark for evaluation.
- It includes extensive case studies and clear analysis, demonstrating the effectiveness of the proposed evaluation method.
- The consideration of unique aspects like Temporal Risk adds depth to the safety assessment.
- The authors have effectively addressed ethical concerns and implemented safety measures for human evaluators.
- The inclusion of a diverse group of reviewers helps to standardize cultural specificity.
- Significant revisions based on reviewer feedback enhance clarity and detail in the evaluation process.

Weaknesses:
- The benchmark lacks comprehensiveness, evaluating only four models compared to existing benchmarks that assess more.
- The novelty of the methodology is limited, resembling jailbreak attacks on text-to-image models without sufficient differentiation.
- The dataset requires further detoxification, particularly concerning NSFW content and the handling of human faces.
- Some reviewers expressed concerns about the potential for overcensorship in prompts, indicating a need for further examination.
- The manuscript's updates are still pending, particularly regarding dataset links and the release of the prompt dataset.

### Suggestions for Improvement
We recommend that the authors improve the comprehensiveness of the benchmark by including a broader variety of T2V models. Additionally, a more in-depth analysis of unique safety aspects, particularly Temporal Risk, would enhance the paper's contribution. Increasing the diversity of prompts beyond those generated by GPT-4, possibly through frameworks like Self-Instruction, is advisable. Furthermore, the evaluation method should be refined to ensure that all frames of generated videos are considered, and the authors should clarify the number of human evaluators involved and the specifics of their assessment process. We also recommend that the authors improve the discussion on overcensorship issues in the revised manuscript. Please ensure that the real-world prompts from VidProM are included in the final publication to enhance practicality. Lastly, we urge the authors to expedite the release of the dataset links and provide access protocols to facilitate research use.