ID: rgos321qpD
Title: PEFTDebias : Capturing debiasing information using PEFTs
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a two-stage approach called PEFTDebias, which utilizes parameter-efficient fine-tuning (PEFT) methods to mitigate biases in pre-trained models. The authors propose leveraging debiasing parameters identified during an upstream phase while keeping the base model frozen, followed by fine-tuning the base model on downstream tasks with the PEFT parameters frozen. Evaluations on various datasets demonstrate the effectiveness of this method in reducing downstream biases and its transferability across tasks.

### Strengths and Weaknesses
Strengths:
- The paper addresses an important foundational task of bias mitigation in pre-trained models.
- Clear motivation and comprehensive experiments provide strong support for the claims.
- The proposed method enhances both debiasing and fundamental performance aspects of language models.

Weaknesses:
- The evaluation is limited to BERT, lacking insights from other language models, particularly generative models like GPT.
- The operation of the proposed method is difficult to comprehend without pseudo-code, which could clarify the upstream and downstream phases.
- There is insufficient performance evaluation regarding the efficiency of the proposed method, despite its title suggesting a focus on this aspect.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the proposed method by including pseudo-code to elucidate the upstream and downstream phases. Additionally, we suggest expanding the evaluation to include other language models beyond BERT, particularly generative models, to strengthen the claims. Finally, we encourage the authors to incorporate an analysis of the computational costs associated with their approach to better address the efficiency aspect implied in the title.