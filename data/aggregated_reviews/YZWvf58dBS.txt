ID: YZWvf58dBS
Title: Why Not Transform Chat Large Language Models to Non-English?
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 5, 5, 3, 4, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the TransLLM framework, designed to transform English-centric chat LLMs into non-English languages, specifically Thai. It addresses the challenges of transferring advanced capabilities without supervised data and mitigating catastrophic forgetting. Key contributions include the Translation Chain-of-Thought (TCOT) for task division, Low-Rank Adaptation (LoRA), and Recovery Knowledge Distillation (KD) to preserve original LLM parameters. The framework's effectiveness is demonstrated through experiments with LLaMA-2-chat-7B, where it outperformed strong baselines and ChatGPT in multi-turn conversations and safety benchmarks, indicating significant improvements in helpfulness and safety.

### Strengths and Weaknesses
Strengths:
1. The introduction of TransLLM, which combines TCOT and recovery knowledge distillation, effectively transforms English-centric LLMs to non-English languages while addressing catastrophic forgetting.
2. The method shows notable improvements in safety and human preference alignment, outperforming GPT-4 and ChatGPT on the AdvBench safety benchmark.

Weaknesses:
1. Experiments are limited to transforming LLaMA-2-chat-7B to Thai, restricting the generalizability of findings to other languages and models. Further validations on additional models or sizes would strengthen the paper.
2. The proposed method lacks testing on traditional NLU benchmarks like MMLU in English, which would provide a more comprehensive assessment of performance across various language tasks.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their findings by conducting experiments on additional languages and models beyond Thai. Incorporating a wider range of evaluation benchmarks, including traditional NLU tasks, would enhance the assessment of the model's performance. Additionally, we suggest exploring other concatenation templates for TCOT and assessing the sensitivity of performance to these choices. Clarifying the human evaluation process in Table 9, including the number of annotators and inter-annotator agreement, would also strengthen the paper's rigor. Lastly, addressing the quality of MT data used for translations and considering quality estimation methods like CometKiwi and TransQuest would provide valuable insights into the impact of translation quality on results.