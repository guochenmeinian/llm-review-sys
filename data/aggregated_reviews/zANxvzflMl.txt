ID: zANxvzflMl
Title: Towards Foundation Models for Scientific Machine Learning: Characterizing Scaling and Transfer Behavior
Conference: NeurIPS
Year: 2023
Number of Reviews: 7
Original Ratings: 7, 6, 6, 6, -1, -1, -1
Original Confidences: 3, 3, 2, 2, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into the "pretraining+finetuning" paradigm for neural networks applied to partial differential equations (PDEs) within the context of scientific machine learning (SciML). The authors analyze the effects of various factors on performance, including downstream dataset scale, model scale, out-of-distribution (OOD) data characteristics, and pretraining on systems governed by different physics. The findings indicate that pretraining significantly enhances performance, particularly in data-constrained scenarios relevant to SciML.

### Strengths and Weaknesses
Strengths:
- The work is significant for the community, addressing critical topics in SciML with extensive results that are well-structured and easy to follow.
- A variety of scenarios are explored, including OOD characteristics and dataset sizes, with appropriate comparisons to a "from scratch" baseline, effectively addressing challenges in the field.
- The authors provide open-source code, enhancing reproducibility and impact.

Weaknesses:
- The experiments lack systematic exploration across the proposed systems, particularly with SYS-3, which is not featured in downstream dataset and model scaling scenarios.
- The framing around large language models contains inaccuracies, particularly regarding the concept of emergence and the terminology surrounding few-shot learning.
- The analysis is limited to the Fourier Neural Operator (FNO) architecture, raising questions about the generalizability of the findings to other architectures and OOD problems.

### Suggestions for Improvement
We recommend that the authors improve the systematic exploration of experiments across all proposed systems, particularly including SYS-3 for downstream dataset and model scaling. Additionally, we suggest providing more comprehensive comparisons with SYS-2 and addressing the behavior observed in extreme OOD scenarios in Figure 4d. Clarifying the statement regarding finetuning efficiency in NLP and providing a reference for the claims made would enhance the paper's rigor. To avoid confusion, we recommend consistently using "few-shot finetuning" instead of "few-shot learning." Finally, a more critical examination of the limitations and potential overfitting in transfer learning settings would strengthen the paper.