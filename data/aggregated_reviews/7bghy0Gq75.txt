ID: 7bghy0Gq75
Title: HOH: Markerless Multimodal Human-Object-Human Handover Dataset with Large Object Count
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 7, 6, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the HOH dataset, a large-scale markerless 3D multimodal dataset focused on human-human handovers, comprising multi-view RGBD data, skeletons, point clouds, grasp types, handedness labels, and 2D/3D segmentations for 2,720 interactions. The dataset's strengths include its size and the natural appearance of the captured data due to markerless techniques, which are intended to enhance human-robot interaction (HRI) algorithms. Additionally, the authors present benchmark results from neural networks trained for grasp prediction tasks, including giver grasp prediction from an object point cloud (o2gg), receiver grasp prediction from object and giver point clouds (g2rg), and transfer orientation prediction from object point clouds (o2or). They also retarget trajectory prediction to proactively forecast the receiver trajectory from the giver trajectory (g2rt). Ground truth metrics are computed for all completed networks and reported in Table 3, with additional qualitative results provided in Figure 9. The authors plan to compactify the dataset collection and data analysis sections to meet the page limit.

### Strengths and Weaknesses
Strengths:
- The dataset is extensive, featuring a significant number of objects, participants, and interactions, which can contribute to more generalizable algorithms.
- The use of markerless capture allows for more natural image appearances compared to traditional marker-based systems.
- The authors have addressed most reviewer concerns and provided experimental demonstrations.
- Benchmark results support the intended use cases effectively.
- The paper has been reorganized for clarity, with clear sections summarizing dataset philosophy, collection, and analysis.

Weaknesses:
- The comparison in Table 1 lacks depth; it only addresses the quantity of assets without demonstrating diversity through visualizations like t-SNE.
- Some metrics in Table 3 remain incomplete pending the completion of network training.
- The paper does not experimentally validate the dataset's applicability, nor does it provide benchmarks to showcase improvements in systems trained on the dataset.
- The limited diversity in image appearances raises concerns about the generalizability of vision-based systems trained on this dataset.
- The absence of 3D poses for hands and objects diminishes the dataset's attractiveness for handover analysis.
- The paper may still require further refinement to ensure all material fits within the specified page limit.

### Suggestions for Improvement
We recommend that the authors improve the depth of the comparison in Table 1 by including visualized t-SNE maps to illustrate the diversity of assets in the HOH dataset. Additionally, the authors should experimentally demonstrate the dataset's applicability by showing systems trained on HOH outperforming those trained without it. To address concerns regarding the benefits of markerless capture, we suggest conducting experiments comparing systems trained on existing mocap data versus the proposed dataset. We also recommend that the authors improve the completeness of metrics in Table 3 by ensuring all networks are fully trained and results are reported. Lastly, we encourage the authors to finalize the compactification of the dataset collection and data analysis sections to adhere to the 10+refs-page limit effectively, and to consider incorporating 3D poses of hands and objects to enhance the dataset's utility for handover analysis.