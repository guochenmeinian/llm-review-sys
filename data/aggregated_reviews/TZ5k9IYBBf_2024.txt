ID: TZ5k9IYBBf
Title: RanDumb: Random Representations Outperform Online Continually Learned Representations
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 5, 7, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents RanDumb, a representation learning-free method for online continual learning (OCL) that utilizes data-independent random Fourier transforms to project data into a high-dimensional space, followed by normalization and classification using a nearest class mean (NCM) classifier. The authors demonstrate that RanDumb outperforms many continual learning algorithms across various benchmarks, suggesting that traditional continual learning methods may not effectively learn representations. The paper includes extensive experiments and an ablation study, revealing that the naive approach can bridge a significant performance gap compared to joint learning methods.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and presents a clear and simple idea that is easy to understand.
- The extensive benchmarks and comprehensive ablation study provide convincing evidence of RanDumb's effectiveness.
- The investigation challenges existing assumptions about representation learning in OCL, highlighting a blind spot in the field.

Weaknesses:
- The originality of the proposed method is limited, as it largely implements known techniques across different benchmarks.
- The meta-discussion regarding the implications of the findings is minimal and lacks depth, particularly in comparing with prior works like g-dumb.
- The paper's presentation is confusing, particularly with the labeling of benchmarks and the overall structure, making it difficult to follow.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper's presentation by revising the labeling of benchmarks and enhancing the overall structure to facilitate better understanding. Additionally, we suggest that the authors expand the meta-discussion to provide a more thorough analysis of why the existence of simple methods that outperform continual learning algorithms is concerning, including a deeper comparison with previous works such as g-dumb. Furthermore, we encourage the authors to elaborate on the efficiency of computing the dot product in the high-dimensional space and clarify the definition of online continual learning (OCL) for readers unfamiliar with the concept.