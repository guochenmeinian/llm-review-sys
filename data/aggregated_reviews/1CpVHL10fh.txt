ID: 1CpVHL10fh
Title: Should I Stop or Should I Go: Early Stopping with Heterogeneous Populations
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 6, 7, 6, 7, 7, 7, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 3, 4, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents CLASH, a two-stage method for early stopping in randomized experiments, particularly in heterogeneous populations where treatment may harm a minority group. The authors motivate the need for this approach by highlighting the limitations of traditional methods in detecting subgroup-level harms. The first stage involves estimating the conditional average treatment effect (CATE) using machine learning, while the second stage computes weighted test statistics to inform stopping decisions. Theoretical analyses support the method's efficacy, and experimental results demonstrate its advantages over homogeneous stopping tests.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant and timely issue in clinical trials, providing a novel solution with minimal assumptions.
- It is well-written, with clear exposition and logical flow between sections.
- The theoretical insights and experimental results, including simulations and real-world applications, convincingly support the proposed method.

Weaknesses:
- The task is somewhat niche, and the generalizability of the stopping task to other domains remains unclear.
- The work relies on idealized assumptions, and practical applicability, especially in real-world clinical trials, is not thoroughly evaluated.
- The method's performance on high-dimensional data is not addressed, and the reliance on treatment effect estimation methods in Stage 1 poses practical challenges.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their method by discussing how it could be adapted for online settings, where stopping decisions could be made for harmed subgroups only. Additionally, it would be beneficial to evaluate the method's performance in more complex scenarios, such as those involving multiple groups with varying treatment effects. We suggest including a wider range of sample sizes in simulations to reflect common clinical trial conditions and addressing the limitations of CATE estimation in high-dimensional settings. Finally, we encourage the authors to clarify how practitioners might specify minimum group sizes to avoid false alarms with trivial subgroups.