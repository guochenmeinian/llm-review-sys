ID: v3jHuoxMw8
Title: Vision-Language Navigation with Energy-Based Policy
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 5, 7, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 2, 5, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an Energy-based Navigation Policy (ENP) aimed at addressing catastrophic failure issues in behavioral cloning (BC) within vision-and-language navigation (VLN). The authors propose that ENP learns expert policies from demonstrations by prioritizing full trajectory learning over single-time step decisions. The method is evaluated across various VLN agents and datasets, demonstrating its potential effectiveness.

### Strengths and Weaknesses
Strengths:
- The paper tackles the significant issue of catastrophic failure in BC, which is relevant to VLN.
- The method is straightforward and well-described.
- The proposed ENP introduces a novel training perspective for VLN, supported by thorough analyses and evaluations across multiple baselines and datasets.
- The writing is clear, with well-presented content, tables, and figures.

Weaknesses:
- The performance improvements of ENP over BC are minimal, often around $1-2\%$ in terms of success rate (SR) and similar in success path length (SPL), raising questions about its practical benefits.
- It is unclear when ENP outperforms BC, necessitating a more detailed analysis of success and failure cases.
- The training cost of ENP compared to BC is likely higher, and a compute comparison should be included.
- The evaluation is limited to a small scale of VLN datasets, leaving uncertainty about ENP's scalability with larger models and data.

### Suggestions for Improvement
We recommend that the authors improve the analysis of success and failure cases for ENP versus BC to clarify when ENP is beneficial. Creating a benchmark specifically to test this could enhance the motivation for ENP. Additionally, including a compute comparison for training ENP versus BC would provide valuable insights into the method's practicality. We also suggest testing ENP on larger-scale datasets to assess its scalability and generalizability. Lastly, addressing the limitations of the method in detail, particularly regarding training time, would strengthen the paper.