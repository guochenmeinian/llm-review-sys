ID: AfyZTKGhUi
Title: Lean-STaR: Learning to Interleave Thinking and Proving
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 6, 7, 6, 6, 8
Original Confidences: 5, 3, 3, 3, 4

Aggregated Review:
### Key Points
This paper presents Lean-STaR, a method for enhancing theorem proving by integrating informal "thoughts" with formal tactics. The authors propose a framework that employs expert iteration to fine-tune models on correct proofs using (state, thought, tactic) triplets. The results indicate significant improvements in pass rates on the miniF2F benchmark, showcasing the effectiveness of combining informal reasoning with formal proof steps.

### Strengths and Weaknesses
Strengths:
- The integration of informal thoughts with formal tactics is a promising advancement in theorem proving, extending the STaR framework effectively.
- The expert iteration phase consistently yields performance gains, with clear improvements across iterations.
- The creation of the first thought-augmented dataset for theorem proving is a novel contribution that could inspire further research in thought-augmented reasoning.

Weaknesses:
- The experiments are primarily confined to the Lean environment on the miniF2F-test benchmark, which may limit the generalizability of the findings.
- There is insufficient detail on training hyperparameters and settings, which may hinder reproducibility.
- The comparison table lacks clarity regarding the conditions under which results were obtained, potentially misleading readers.
- The paper would benefit from more in-depth ablation studies to isolate the contributions of individual components, such as thought augmentation and expert iteration.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the comparison table by indicating which results were reproduced under consistent conditions and which were sourced from other works. Additionally, including more ablation studies would strengthen the claims, particularly comparing models trained without thought augmentation. We also suggest expanding experiments to include additional models and evaluation datasets to enhance the generalizability of the results. Finally, enhancing the examples in the introduction to better illustrate the advantages of the proposed method over traditional approaches would improve the paper's overall impact.