ID: OWwdlxwnFN
Title: MonkeySee: Space-time-resolved reconstructions of natural images from macaque multi-unit activity
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 6, 6, 7, 4, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a CNN-based decoder that reconstructs visual stimuli from multi-unit activity (MUA) recorded from the macaque ventral stream (V1, V4, and IT). The authors propose three decoding variations: a baseline CNN decoder mapping MUA to image space, and two U-Net based decodersâ€”one using only spatial information and the other being time-resolved (spatiotemporal). The spatiotemporal decoder achieves the highest performance, evaluated through feature correlation and occlusion analysis. The study emphasizes the significance of retinotopic mapping and the learned receptive field (LRF) layer in enhancing model interpretability.

### Strengths and Weaknesses
Strengths:  
- The paper addresses a significant area of stimuli reconstruction using MUA, providing superior time-resolution compared to fMRI techniques.  
- The experimental setup, involving 15 Utah arrays from a single monkey, is commendable and yields state-of-the-art image reconstructions.  
- The integration of a U-Net architecture for pixel-to-pixel mapping is innovative, and the results demonstrate the effectiveness of the end-to-end model.

Weaknesses:  
- There are inconsistencies between the text and figures, such as discrepancies in performance claims and figure references.  
- The paper lacks a comprehensive discussion of the LRF layer and its implications, and does not provide hyperparameters for decoder loss.  
- Comparisons with existing decoding techniques are absent, limiting the contextual understanding of the proposed methods.  
- The overall loss function's complexity may hinder model training, and the absence of a complete ablation analysis raises concerns about the necessity of all model components.

### Suggestions for Improvement
We recommend that the authors improve the clarity and consistency between the text and figures, particularly addressing the discrepancies noted regarding performance claims and figure references. Additionally, we suggest providing a thorough discussion of the learned receptive field layer and its impact on model interpretability. Including hyperparameters for decoder loss and conducting comparisons with existing decoding techniques would enhance the paper's rigor. Furthermore, we encourage the authors to perform a complete ablation analysis to clarify the contributions of different model components and simplify the overall loss function to facilitate training dynamics.