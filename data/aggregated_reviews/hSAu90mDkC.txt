ID: hSAu90mDkC
Title: ViLCo-Bench: VIdeo Language COntinual learning Benchmark
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 7, 6, 8, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ViLCo-Bench, a benchmark for continual learning in video-language tasks, utilizing a dataset derived from Ego4D. The benchmark features three tasks: Moment Query (MQ), Natural Language Query (NLQ), and Visual Query (VQ). The authors propose a memory-efficient framework that integrates self-supervised learning to address challenges such as memory complexity and text-video misalignment, while providing comparative analyses against state-of-the-art models.

### Strengths and Weaknesses
Strengths:  
- The paper outlines a standardized benchmark for multimodal continual learning, facilitating consistent comparisons among methodologies.  
- Empirical results suggest that integrating visual and textual modalities may lead to more robust representations, potentially mitigating catastrophic forgetting in continual learning scenarios.  

Weaknesses:  
- The benchmark relies solely on a single dataset, raising questions about the generalizability of the findings and the ability to evaluate continual learning effectively.  
- Several sections of the manuscript lack vital citations and clarity, which diminishes the paper's impact.

### Suggestions for Improvement
We recommend that the authors improve the manuscript by addressing the following:  
- Expand the dataset to include multiple sources to enhance the evaluation of continual learning across diverse data distributions.  
- Clarify the rationale behind the random order of tasks and its impact on results.  
- Extend ablation studies, particularly in continual learning, and consider additional backbones for visual features, such as TimeSformer, X3D, ViViT, MViT, or VideoMAE.  
- Ensure all sections are well-cited and provide clearer explanations, particularly in complex areas such as lines 240-248 and the discussion of task mixing.  
- Revise Figure 4 to eliminate text overlap and improve readability.  
- Enhance the README in the repository with detailed instructions for dataset handling and construction, including a direct link to the dataset.