ID: q3FJk2Nvkk
Title: IMP-MARL: a Suite of Environments for Large-scale Infrastructure Management Planning via MARL
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 8, 4, 8, 9, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents IMP-MARL, a suite of cooperative multi-agent reinforcement learning (MARL) environments designed for large-scale infrastructure management planning, particularly focusing on structural components affected by fatigue and corrosion in underwater environments. The environments can accommodate between 2 to 100 agents and are equipped with Gym and PyMARL wrappers for ease of use. The authors benchmark various MARL algorithms against expert heuristics, highlighting the potential of cooperative RL in real-world applications. They also plan to enhance the framework by incorporating sensor installations and monitoring data collection, and encourage the development of IMP-MARL environments for electrical and mechanical components.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and timely, addressing a significant gap in benchmarking multi-agent RL for infrastructure management.
- Extensive benchmarking is conducted, comparing learned policies with expert heuristics, which underscores the utility of the proposed environments.
- The authors have shown responsiveness to feedback, clarifying potentially unclear statements and improving the manuscript's readability.
- Detailed explanations regarding the training process and the definition of "best results" in their experiments are provided.
- The open-source release of the environments, along with comprehensive documentation and tutorials, facilitates community engagement and further research.

Weaknesses:
- Some terms are not well-defined, leading to reduced clarity.
- The scope of the benchmark environments is considered too narrow, lacking diversity in the problems addressed.
- The simulation of offshore wind farms is critiqued for its simplistic approach, particularly in how it models maintenance challenges.
- There is an initial lack of clarity regarding specific cooperative multi-agent reinforcement learning concepts, and further explanations of training parameters and episode sampling are needed.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by defining key terms more thoroughly and expanding on the explanation of how decentralized agents share networks. Incorporating an additional figure to illustrate how agents are trained would enhance understanding. We also suggest that the authors further elaborate on cooperative multi-agent reinforcement learning concepts within the main text rather than relegating them to the appendices. Additionally, integrating real-world data streams into the environments would enhance their applicability. The authors should consider benchmarking recent state-of-the-art MARL algorithms like HAPPO/HATRPO and MAT, as these could provide valuable insights into the performance of the IMP environments. Finally, expanding the diversity of the benchmark problems, including scenarios related to climate change and other real-world applications, would strengthen the contribution of the paper.