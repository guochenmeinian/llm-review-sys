ID: fzdFPqkAHD
Title: Agent-to-Sim: Learning Interactive Behavior from Casual Videos
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 7, 6, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 2, 1, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ATS (Agent-To-Sim), a framework for modeling agent behavior from multiple casual video captures in indoor environments over extended periods. The proposed pipeline includes (1) 4D reconstruction of scene geometry and agent motion, utilizing coarse-to-fine registration and novel feature-metric losses for robust alignment, and (2) controllable agent behavior learning and generation through hierarchical diffusion models that condition on the agent's egocentric perspective. The experiments demonstrate the quality of the 4D reconstructions and improvements in displacement errors compared to baselines.

### Strengths and Weaknesses
Strengths:
- The paper achieves a significant technical milestone in reconstructing agent behavior in indoor settings by leveraging shared information across videos and robust alignment techniques based on DINOv2 features.
- It successfully generates plausible long-horizon agent motion conditioned on the environment and past trajectories.
- The writing is clear and concise, making complex concepts accessible.

Weaknesses:
- The focus on environment-aware motion in the presence of an observer limits the exploration of more complex agent-environment interactions.
- The experiments are conducted in a limited number of environments, raising concerns about the system's scalability for broader applications.
- Certain technical details, particularly in the methodology, are unclear, hindering understanding and reproducibility.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the methodology section, particularly around the definitions of symbols and technical terms. Including a comprehensive symbol table in the appendix would enhance reader comprehension. Additionally, we suggest expanding the experimental evaluation to include detailed quantitative assessments of 4D reconstruction quality and a thorough ablative study to support claims made in the paper. Addressing the scalability of the framework for new scenes and objects, as well as discussing potential extensions for complex interactions, would also strengthen the paper.