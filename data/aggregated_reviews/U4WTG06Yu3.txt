ID: U4WTG06Yu3
Title: Towards Efficient and Accurate Winograd Convolution via Full Quantization
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 5, 6, 7, 5, 5, -1, -1, -1, -1
Original Confidences: 3, 3, 5, 3, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a PTQ-Aware Winograd (PAW) method that optimizes the transformation procedures required for post-training quantization of pre-trained ResNet models. The authors propose a factorized scale quantization (FSQ) method to balance value ranges in the Winograd domain, achieving significant improvements in classification accuracy on CIFAR-10 and ImageNet datasets. The proposed methods fully quantize the Winograd convolution and demonstrate superior performance compared to existing approaches.

### Strengths and Weaknesses
Strengths:
1. The paper is well-organized, clearly addressing the accuracy degeneration in Winograd convolution and proposing a targeted solution.
2. The factorized-scale quantization approach enhances hardware friendliness compared to previous per-pixel methods.
3. The experimental results show notable accuracy improvements over baseline methods.

Weaknesses:
1. The experiments lack comparisons of computation cost or inference time, which are crucial for evaluating efficiency beyond accuracy.
2. The paper does not discuss limitations or compare with quantization-aware training (QAT) algorithms that achieve full quantization, which could undermine its novelty.
3. The presentation is sometimes unclear, with numerous language issues and a need for better justification of the work's motivation.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the presentation by addressing language issues and providing clearer definitions for terms such as tile size. Additionally, the authors should include comparisons of computation costs and inference times with QAT methods, as well as discuss the limitations of their approach. It would also be beneficial to test the proposed method on a wider range of model architectures beyond ResNet. Finally, we suggest providing a quantitative evaluation of the algorithm's speed relative to previous methods to assess any potential computational overhead.