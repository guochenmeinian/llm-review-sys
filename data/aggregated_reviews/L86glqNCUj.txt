ID: L86glqNCUj
Title: Symmetries in Overparametrized Neural Networks: A Mean Field View
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 7, 7, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study of the Mean-Field limit of generalized shallow neural networks trained with Wasserstein gradient flow, focusing on symmetry-leveraging techniques such as data augmentation, feature averaging, and equivariant architectures. The authors propose that optimizations with data augmentation and feature averaging are equivalent in the mean-field limit under mild assumptions, while noting that equivariant architectures may have limited expressivity. Additionally, the paper explores the "intertwining action" of a group \( G \) on a parameter space \({\cal Z} = \mathbb{R}^{c \times b} \times \mathbb{R}^{d \times b} \times \mathbb{R}^b\), emphasizing the significance of \( G \)-equivariance in neural networks. The authors clarify the implications of a trivial action on the intermediate layer and its effects on joint equivariance, particularly when using a Norm-ReLU activation. The results provide insights into learning with symmetries, particularly regarding invariant laws on the parameter space and the dynamics of training under symmetric data.

### Strengths and Weaknesses
Strengths:  
- The paper offers deep theoretical insights into learning with symmetries in the mean-field limit, presenting results with clarity and embedding them in relevant literature.  
- The rigorous mathematical framework is supported by well-designed experiments that validate the theoretical claims.  
- The exploration of symmetry-leveraging techniques is comprehensive and relevant to current practices in neural network training.  
- The authors provide a clear and thorough explanation of the intertwining action and its implications for equivariance in neural networks.  
- They effectively address reviewer concerns and clarify complex concepts, enhancing the paper's overall clarity.  
- The numerical experiments demonstrate that the freely-trained particles remain within the equivariant space \({\cal E}^G\), supporting their theoretical claims.  

Weaknesses:  
- The theoretical results may not provide novel insights beyond existing intuitions for some readers.  
- The paper's writing could be improved for clarity, particularly regarding the numerous abbreviations and complex notations.  
- Certain assumptions, such as Assumption 1 regarding joint equivariance, may limit the practical applicability of the results to real-world scenarios.  
- Some phrasing, particularly in line 1585, may lead to confusion, as noted by the reviewers.  
- The discussion on the limitations of the group action could be perceived as lacking depth, particularly regarding the implications of a "boring" group action.  

### Suggestions for Improvement
We recommend that the authors improve the clarity of Figure 1 by using markers like (a)-(d) to reduce ambiguity. Additionally, they should consider enlarging the markers in Figure 2 and clarifying the insights derived from the second row. To enhance accessibility, we suggest providing more detailed explanations of mathematical terminology, such as the pushforward of a probability measure. Furthermore, the authors should address the concerns regarding Assumption 1 and its implications for practical applications of data augmentation and feature averaging. We also recommend improving the phrasing in line 1585 to eliminate potential confusion regarding the WI teacher's particles. Additionally, we suggest that the authors expand their discussion on the limitations of the group action to provide a more nuanced understanding of its implications for the architecture's expressiveness. Lastly, consolidating the limitations discussed throughout the paper into a dedicated section would improve the overall structure and readability.