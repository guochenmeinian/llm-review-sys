ID: igEYxgQP7t
Title: RVD: A Handheld Device-Based Fundus Video Dataset for Retinal Vessel Segmentation
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 8, 9, 8, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a retinal video database (RVD) comprising 635 videos from 450 patients, making it the largest public dataset in this field for retinal vessel segmentation. The dataset includes approximately 13,000 frames with various annotations, such as binary vessel masks, general vein-artery masks, fine-grained vein-artery masks, and temporal annotations for spontaneous retinal venous pulsations (SVP). The authors also conduct a comprehensive study on smartphone-based fundus imaging devices, emphasizing their clinical significance in resource-limited settings. They address potential biases in data collection by utilizing multiple clinics and devices and incorporate inter-rater reliability assessments to ensure annotation consistency. Furthermore, the authors provide baseline AI models for segmentation and classification, aiming to measure the domain gap between their dataset and existing public datasets.

### Strengths and Weaknesses
**Strengths:**
- The dataset is extensive and offers diverse annotations not available in other datasets, enhancing its utility for various applications.
- The authors detail the labeling process and provide baseline AI models, facilitating benchmarking.
- Measures have been implemented to reduce bias in data collection and ensure annotation reliability.
- The dataset captures dynamic retinal characteristics, representing a significant advancement over traditional static image datasets.
- The discussion on the clinical significance of handheld devices emphasizes their potential for improving ocular disease detection.

**Weaknesses:**
- The domain gap claims lack robust experimental support, and the experiments presented do not convincingly demonstrate this gap.
- Annotations are manually performed, potentially introducing bias; the authors should clarify the dependence on annotator expertise.
- The dataset lacks demographic information regarding gender and disease presence, which could provide valuable insights.
- The dataset may still be affected by noise due to factors like operator hand stability and eye movements during recording.
- The authors acknowledge that the scale of the dataset can be further improved, indicating limitations in its current form.

### Suggestions for Improvement
We recommend that the authors improve the robustness of their domain gap claims by conducting experiments that train models on similar amounts of data from different datasets, such as RVD and DRIVE, to measure the domain gap effectively. Additionally, please clarify the extent to which annotations and frame selection depend on annotator expertise and consider involving multiple annotators to reduce bias. It would also be beneficial to include demographic information regarding the distribution of normal versus diseased eyes and the types of eye diseases represented. We suggest incorporating more diverse samples to enhance the dataset's robustness and providing more sophisticated data cleaning and preprocessing strategies to mitigate the impact of low-quality frames. Lastly, we encourage the authors to ensure the dataset is hosted on a permanent repository with proper DOI information for future accessibility and impact.