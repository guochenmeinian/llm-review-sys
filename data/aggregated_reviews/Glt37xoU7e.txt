ID: Glt37xoU7e
Title: Omnigrasp: Grasping Diverse Objects with Simulated Humanoids
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 7, 5, 6, -1, -1, -1, -1
Original Confidences: 4, 5, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Omnigrasp, a method for controlling a simulated humanoid with dexterous hands to grasp and manipulate various objects along complex trajectories. The authors propose a universal humanoid motion representation to enhance training efficiency and scalability, achieving state-of-the-art success rates in object manipulation tasks while generalizing well to unseen objects. Key contributions include a dexterous motion representation, simplified state and reward designs for training, and high success rates across diverse manipulation scenarios.

### Strengths and Weaknesses
Strengths:
- The exploration of full-body dexterous grasping, considering physical constraints and instability, is significant.
- The method allows for omnidirectional movement post-grasping, enabling object manipulation in any reachable direction.
- The paper presents an effective algorithm with extensive experimental validation on various objects, demonstrating high grasping success rates.

Weaknesses:
- The method's transferability to real-world scenarios is hindered by inherent flaws in the simulation, particularly regarding the accurate access to state variables like object mesh, pose, and velocity.
- Important baselines are missing, such as fully end-to-end reinforcement learning comparisons and details on the dexterous hand's control.
- The current formulation does not adequately address the challenges of real-world application, including noise in input data and the morphological differences between humanoid robots and human motion data.

### Suggestions for Improvement
We recommend that the authors improve the discussion on bridging the gap between simulation and real-world applications, particularly addressing how to handle the lack of access to object pose, velocity, and mesh in real environments. Additionally, we suggest including more details about the dexterous hand and its control mechanisms, as well as comparisons with other models. A more comprehensive analysis of failure cases and their causes would enhance the understanding of the method's limitations. Finally, exploring alternative approaches for learning actions and discussing the robustness of the system in noisy conditions would strengthen the paper.