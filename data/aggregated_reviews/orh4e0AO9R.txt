ID: orh4e0AO9R
Title: Bypassing the Simulator: Near-Optimal Adversarial Linear Contextual Bandits
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 7, 6, 7, 8, -1, -1, -1, -1
Original Confidences: 3, 2, 4, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a significant advancement in the study of adversarial linear contextual bandits, where loss vectors are selected adversarially and contexts are drawn from a fixed distribution. The authors propose an algorithm that achieves a regret of $\widetilde O(\sqrt{T})$ without requiring a simulator, addressing a critical gap in existing methods that either depend on simulators or achieve sub-optimal regret of $\widetilde O(T^{5/6})$. The approach includes a computationally inefficient algorithm yielding $\widetilde O(d\sqrt{T})$ regret, enhancing the EXP4 algorithm. The paper also introduces a novel feature centralization technique that effectively manages bias in estimators.

### Strengths and Weaknesses
Strengths:  
- The algorithm innovatively applies an individual Follow-The-Regularized-Leader (FTRL) approach to each action set, promising improved optimization in adversarial settings.  
- The construction of loss estimators and feature covariance matrix estimators is robust, particularly in scenarios lacking context distribution knowledge.  
- The paper achieves an improved bound on bias, surpassing previous techniques and enhancing practical performance.  
- The introduction of feature centralization elegantly addresses bias compensation in estimators.  
- The handling of strong dependence between policy and empirical context distribution is commendable.

Weaknesses:  
- A significant weakness is the lack of empirical or numerical experiments to validate theoretical results, making it challenging to assess practical efficacy.  
- The paper's readability is hindered in places, particularly for those unfamiliar with prior works, which may obscure understanding of key concepts.

### Suggestions for Improvement
We recommend that the authors improve the paper by incorporating empirical experiments to validate the theoretical results and demonstrate the practical performance of the proposed estimators across various datasets. Additionally, clarifying the problem setting, particularly the definition and assumptions regarding the action set $A_t$ and its relation to distribution $D$, would enhance comprehension. It would also be beneficial to elaborate on how the methods surpass those in previous studies and to provide more context for readers unfamiliar with the foundational algorithms referenced.