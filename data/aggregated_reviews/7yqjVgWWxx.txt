ID: 7yqjVgWWxx
Title: Your Absorbing Discrete Diffusion Secretly Models the Conditional Distributions of Clean Data
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 6, 6, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 2, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a simplified discrete diffusion model aimed at enhancing prior language diffusion models. It proves that the probability ratio in the time reverse rate matrix for an absorbing state diffusion model can be expressed as a function of conditional distributions of clean data given partial masking, scaled by an analytic time-dependent weighting. The authors propose that this simplification improves the parametrization of absorbing state diffusion models, leading to better performance and faster sampling on text datasets.

### Strengths and Weaknesses
Strengths:  
- The work is clearly written, and Theorem 1 is expected to be beneficial for future research in absorbing state diffusion models.  
- The proposed method is simple, scalable, and shows improvements in sample quality and speed, particularly in large sample step regimes.  
- The insights regarding decoupled model parameterizations and simplified learning objectives are theoretically grounded and numerically verified.

Weaknesses:  
- Theorem 2 is incorrect, as it presents a lower bound rather than an equality, necessitating its removal.  
- The claims regarding speed improvements may be misleading, as they do not translate to smaller sample sizes.  
- The results are marginal, with discrepancies noted between figures and tables, particularly regarding generative perplexity.  
- The exact likelihood computation is not applied, and the model size is limited, requiring further verification on medium quality.

### Suggestions for Improvement
We recommend that the authors remove Section 3.3 and replace it with a discussion on Autoregressive Diffusion Models, as this connection is currently missing. Additionally, please clarify the narrative surrounding Table 2, particularly regarding the performance of your models compared to standard SEDD. We suggest including a baseline against autoregressive diffusion models to highlight the differences in token revealing strategies. Lastly, please provide more details on the intuition behind the absorbing matrix $Q^{\text{absorb}}$ and the necessity of the DSE loss in your formulation.