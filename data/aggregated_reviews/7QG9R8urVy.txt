ID: 7QG9R8urVy
Title: Doubly Mild Generalization for Offline Reinforcement Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 7, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an algorithm called Doubly Mild Generalization (DMG) aimed at addressing over-generalization in Offline Reinforcement Learning (RL). The authors propose two components: mild action generalization, which selects actions near the dataset to maximize Q values, and mild generalization propagation, which controls value overestimation during bootstrapping. Theoretical guarantees suggest DMG outperforms in-sample optimal policies, and empirical results demonstrate state-of-the-art performance across various offline RL benchmarks.

### Strengths and Weaknesses
Strengths:
1. The concept of DMG is innovative and effectively balances generalization with the risk of over-generalization.
2. The paper provides a thorough theoretical analysis, proving advantages in both oracle and worst-case scenarios.
3. DMG shows superior empirical results on multiple benchmarks, including complex tasks, and transitions smoothly from offline to online learning.

Weaknesses:
1. The theoretical analysis relies on continuity assumptions that may not hold in all practical scenarios, potentially limiting applicability.
2. The performance may be sensitive to hyperparameters like the mixture coefficient (λ) and penalty coefficient (ν), necessitating a more detailed analysis of hyperparameter sensitivity.
3. The main results are based on only 5 seeds, which raises concerns about reliability; increasing the number of seeds is recommended.

### Suggestions for Improvement
We recommend that the authors improve the robustness of their results by increasing the number of seeds used in experiments, as well as adopting high-confidence confidence intervals instead of standard errors. Additionally, a deeper exploration of the sensitivity of DMG to hyperparameters would enhance the understanding of its robustness. Clarifying the relationship between the theoretical assumptions and practical applicability, particularly regarding Assumption 11, would also benefit the paper.