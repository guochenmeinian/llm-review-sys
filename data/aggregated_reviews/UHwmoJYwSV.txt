ID: UHwmoJYwSV
Title: Attacks on Online Learners: a Teacher-Student Analysis
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 5, 5, 3, 6, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 2, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis of the vulnerabilities of online learners to adversarial attacks, specifically focusing on data poisoning in a teacher-student framework. The authors theoretically and empirically investigate the dynamics of online learning under such attacks, formalizing the problem as a stochastic optimal control issue. The findings reveal that the effectiveness of attacks can be significant, particularly as the attack strength increases, and that greedy strategies can be as effective as those with full knowledge of the model.

### Strengths and Weaknesses
Strengths:
1. The paper provides a theoretical analysis of online data poisoning within a well-established framework, yielding novel insights into the learning dynamics and steady states of linear regression models.
2. The comparison of various attack strategies, particularly the effectiveness of greedy attacks, adds valuable contributions to the literature.
3. Empirical studies on real datasets, including MNIST and CIFAR10, support the theoretical findings and suggest applicability to more complex scenarios.

Weaknesses:
1. The focus on linear regression models limits the exploration of adversarial impacts on other machine learning types.
2. The paper lacks concrete real-world examples illustrating the consequences of adversarial attacks on online learners.
3. There is insufficient discussion on potential defense mechanisms or countermeasures against these attacks.
4. The comparison with existing literature on online learner attacks is not thoroughly addressed.
5. The threat model's practicality requires more detailed discussion.

### Suggestions for Improvement
We recommend that the authors improve the exploration of adversarial impacts by including a broader range of machine learning models beyond linear regression. Additionally, providing specific real-world scenarios where these attacks could have significant consequences would enhance the paper's relevance. We suggest incorporating a detailed discussion of potential defense mechanisms to mitigate the impact of these attacks. A thorough comparison with existing literature on online learner attacks should also be included. Finally, clarifying the practicality of the studied threat model and its implications would strengthen the overall analysis.