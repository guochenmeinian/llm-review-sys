ID: MoEfm3iPMy
Title: Self-Knowledge Guided Retrieval Augmentation for Large Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method called Self-Knowledge guided Retrieval augmentation (SKR) that aims to enhance the efficiency of language models by flexibly calling a retriever based on the model's self-knowledge. The authors propose four strategies: SKR_prompt, SKR_icl, SKR_cls, and SKR_knn, which collectively demonstrate improvements over various baselines across five question-answer datasets. The study effectively motivates the importance of understanding a model's self-awareness regarding its knowledge.

### Strengths and Weaknesses
Strengths:
1. The paper introduces an innovative framework for retrieval-augmented LLMs, addressing the critical issue of when to perform retrieval.
2. The KNN approach yields consistent improvements over both retrieval-augmented and non-retrieval-augmented baselines.
3. The paper is well-organized and easy to follow, with extensive and convincing experimental evaluations.

Weaknesses:
1. The advantages of SKR_knn over baseline methods appear limited, with minimal improvements observed in several datasets.
2. The analysis lacks a thorough examination of the effectiveness of various self-knowledge methods, relying solely on final QA performance without comparing accuracy, precision, and recall.
3. The approach depends on access to the training dataset, which may not be feasible in real-world applications.
4. The proposed method retrieves knowledge based on the entire query rather than focusing on specific unknown components.

### Suggestions for Improvement
We recommend that the authors improve the experimental design by incorporating more knowledge-intensive datasets, such as those in KILT, and by including comparisons with IR-augmented baselines like Self-Ask and DSP, as well as reasoning baselines like Recite-and-answer. Additionally, we suggest exploring the impact of retrieval quality on response accuracy and considering the performance of SKR with different retrievers. Finally, we encourage the authors to clarify the analysis of self-knowledge methods by comparing relevant metrics beyond final QA performance.