ID: qynH28Y4xE
Title: Wyze Rule: Federated Rule Dataset for Rule Recommendation Benchmarking
Conference: NeurIPS
Year: 2023
Number of Reviews: 19
Original Ratings: 7, 5, 8, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Wyze Rule Dataset, the first public release of a large-scale federated dataset for smart home rule recommendation, comprising over 1 million rules from 300,000 users. This dataset significantly expands upon a previously published smaller subset and offers advantages over prior datasets, such as IFTTT, due to its size and natural federated split, making it suitable for benchmarking federated rule recommendation algorithms. The authors aim to document the dataset thoroughly and establish benchmarks for various learning paradigms, emphasizing its extensive size and statistical heterogeneity as critical for developing federated learning techniques. Experiments are conducted comparing graph representation learning models in centralized and federated settings.

### Strengths and Weaknesses
**Strengths:**
- The dataset is extensive and well-organized, providing a valuable resource for researchers in smart home automation and unlocking new research opportunities.
- It supports federated learning, allowing exploration of privacy-preserving rule recommendations and robust model development to handle user heterogeneity.
- The paper is well-written, with clear documentation and guidelines for data access, and aims to inspire further research into specialized algorithms for the dataset.

**Weaknesses:**
- The dataset lacks time information and device location data, which are crucial for personalized recommendations.
- The introduction and some figures, such as Figure 1, may not clearly convey the nature of the rules.
- The benchmarking study lacks empirical evidence demonstrating that larger-scale non-IID data introduces greater challenges, and the authors primarily use their own FedRules algorithm for benchmarking, raising questions about the generalizability of insights gained from the dataset.
- There is insufficient comparison between the small and large-scale Wyze Rule datasets, and the necessity of the larger dataset remains unclear. Additionally, the paper does not utilize certain mentioned algorithms (R-GCN, GCMC, etc.) in benchmarking experiments.

### Suggestions for Improvement
We recommend that the authors improve the paper by quantifying the statistical heterogeneity of the dataset, potentially using tools from prior benchmarks like FLamby. Additionally, the authors should enhance the codebase by adhering to PEP coding conventions and removing any dead code. It would be beneficial to explore the hyper-parameter space and provide a visual comparison of the Wyze Rule Dataset against others like IFTTT. Furthermore, discussing the implications of the absence of time and location data, as well as the potential for dynamic rule recommendations, would strengthen the paper. We also suggest that the authors improve the benchmark study to empirically validate that the Wyze Rule dataset reveals new insights into existing studies and/or new challenges that cannot be evaluated using existing datasets. Clearly articulating the differences in performance and characteristics between the small and large-scale datasets, including comparisons with various baselines such as R-GCN, GCMC, RotatE, and HetGNN, would enhance the benchmarking analysis. Lastly, providing evidence supporting their claims regarding the challenges posed by larger-scale non-IID data would further solidify the paper's contributions.