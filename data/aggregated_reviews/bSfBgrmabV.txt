ID: bSfBgrmabV
Title: Dual-Feedback Knowledge Retrieval for Task-Oriented Dialogue Systems
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Task-Oriented Dialogue System utilizing a retriever-generator architecture that addresses the challenge of training the retriever without explicit labels. The authors introduce a dual-feedback mechanism where the generator provides both positive and negative feedback as pseudo labels for optimizing the retriever. Experiments on three public benchmarks demonstrate the method's effectiveness, achieving good performance and outperforming previous work on BLEU and Entity-F1 metrics.

### Strengths and Weaknesses
Strengths:
- The innovative use of generator feedback to produce pseudo labels effectively addresses the lack of retriever training labels.
- The introduction of negative feedback helps prevent the retriever from assimilating incorrect knowledge.
- Extensive experiments and analyses validate the proposed methods, and the source code is provided.

Weaknesses:
- The negative loss function may not adequately fulfill its intended purpose, requiring further explanation.
- Evaluation of natural language generation (NLG) systems relies solely on word-overlap metrics like BLEU, lacking semantic-based metrics such as BERTSCORE.
- The training process lacks detailed descriptions, particularly regarding the timing of end-to-end training and the sampling frequency of negative samples.
- Zero-shot and few-shot experiments are underexplained, necessitating more detail on the training data and accuracy of self-reported scores.

### Suggestions for Improvement
We recommend that the authors improve the explanation of the negative loss function in Section 3.2 to clarify its effectiveness. Additionally, we suggest incorporating semantic-based metrics like BERTSCORE for evaluating NLG systems. It would be beneficial to provide a more detailed description of the training process, including when end-to-end training begins and the frequency of negative sample generation. Furthermore, we encourage the authors to elaborate on the zero-shot and few-shot experiments, specifying the number of ChatGPT samples used and exploring the potential for obtaining useful scores through alternative pretrained language models.