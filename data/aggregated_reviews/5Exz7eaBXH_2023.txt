ID: 5Exz7eaBXH
Title: Physion++: Evaluating Physical Scene Understanding that Requires Online Inference of Different Physical Properties
Conference: NeurIPS
Year: 2023
Number of Reviews: 18
Original Ratings: 6, 6, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Physion++, a benchmark designed for visual physical prediction based on mechanical properties such as mass, friction, elasticity, and deformability across nine scenarios. The authors propose that the dataset addresses complexities overlooked in the original Physion benchmark, aiming to enhance understanding of intuitive physics through extensive experiments comparing model performance and human studies. They emphasize the challenges of physical scene understanding, which requires a blend of visual perception and property inference. Despite advancements, the authors argue that existing state-of-the-art (SOTA) models do not match human performance, raising questions about the dataset's effectiveness.

### Strengths and Weaknesses
Strengths:
- The problem addressed is both intuitive and impactful, focusing on learning intuitive physics.
- The dataset is well-motivated and aims to advance research in mechanical property inference.
- The experiments are comprehensive, including multiple baselines and human evaluations, indicating the gap in reasoning between deep neural networks and human understanding.
- The authors have provided a reproducible methodology, enhancing the dataset's utility for the research community.

Weaknesses:
- Human performance is notably low, with accuracy often close to random guessing, particularly in hard trials, raising concerns about the dataset's definition and the feasibility of the task for both humans and machines.
- The paper lacks clarity regarding the input and expected outputs of the models trained on the dataset.
- The authors' rebuttal suggests that the improvements over the original Physion benchmark may be incremental, which could undermine the perceived novelty of the work.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by providing more comprehensive details about the input data and expected outputs for the models trained on the dataset. Additionally, we suggest conducting a human agreement analysis across all physical properties and scenarios to strengthen the validity of the dataset. It would be beneficial to analyze the reasons behind the low human performance, especially in hard trials, and to consider whether the dataset is ill-defined. We encourage the authors to explore the possibility of collecting explanations from human subjects to better understand the theories they apply, which may inform the design of machine systems. Lastly, a deeper analysis of the differences between human and model performance, particularly in specific trials, would enhance understanding of their respective strengths and weaknesses.