ID: LEzx6QRkRH
Title: RL-GPT: Integrating Reinforcement Learning and Code-as-policy
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 5, 8, 5, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents RL-GPT, a hierarchical framework that integrates Large Language Models (LLMs) with Reinforcement Learning (RL) to enhance performance in complex embodied tasks, particularly in the Minecraft environment. The authors propose a two-level approach where a slow agent decomposes tasks and a fast agent generates code or RL configurations. The framework demonstrates superior performance on the MineDojo benchmark, especially in the ObtainDiamond task, outperforming traditional RL methods and existing LLM agents.

### Strengths and Weaknesses
Strengths:
- The integration of RL training pipelines is novel and applicable to various domains.
- Strong empirical results on Minecraft tasks, supported by detailed ablation studies.
- The paper is clearly written and well-structured, effectively illustrating the framework's components and performance improvements.

Weaknesses:
- The evaluation is limited to Minecraft, raising questions about generalizability to other domains.
- The introduction of the term “Code-as-Policy” lacks definition, potentially confusing readers.
- The methods section lacks clarity and detail, with insufficient examples and references to appendices.
- There are no standard deviations reported for experimental results, and the number of seeds used is unclear.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the methods section by providing more detailed explanations and examples, as well as references to figures and appendices. Additionally, we suggest defining the term “Code-as-Policy” in the introduction to avoid confusion. The authors should also consider expanding the evaluation to include other environments beyond Minecraft to enhance the significance of their findings. Furthermore, we advise including standard deviations in the experimental results and clarifying the number of seeds used in the experiments.