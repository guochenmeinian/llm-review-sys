ID: 8IvW2k5VeA
Title: Exploring Loss Functions for Time-based Training Strategy in Spiking Neural Networks
Conference: NeurIPS
Year: 2023
Number of Reviews: 7
Original Ratings: 7, 8, 6, 6, -1, -1, -1
Original Confidences: 5, 5, 4, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on loss functions for time-based training schemes of spiking neural networks (SNNs), demonstrating that rate-based loss functions can be effectively applied in this context. The authors propose an enhanced counting loss to replace the traditional mean square counting loss, which stabilizes training and improves performance. Additionally, they introduce a normalization method that adjusts the threshold rather than standardizing weights. The experimental results indicate that the proposed method achieves state-of-the-art performance among time-based approaches.

### Strengths and Weaknesses
Strengths:
1. The training algorithm is novel and aligns well with the event-driven nature of SNNs, linking temporal and rate coding effectively.
2. The paper provides a thorough analysis of applying rate-coded losses in time-based training, with the enhanced counting loss improving overall training stability and performance.
3. The organization and writing quality of the paper are commendable.

Weaknesses:
1. The performance of the proposed training algorithm does not match that of BPTT-based methods.
2. The description of equations (1)-(5) may be challenging for readers unfamiliar with time-based learning, suggesting a need for detailed derivation in an appendix.
3. The loss function (13) lacks clarity when no spikes are emitted, requiring further explanation.

### Suggestions for Improvement
We recommend that the authors improve the clarity of equations (1)-(5) by including detailed derivations in an appendix to aid reader comprehension. Additionally, we suggest addressing the corner case of the loss function (13) when no spikes are emitted by providing a clear explanation. It would also be beneficial for the authors to discuss the advantages of time-based learning methods over activation-based approaches and to clarify the relationship of sections 4.1 and 4.2 to the proposed methods. Lastly, including a comparison with BPTT-based methods in the experiments could strengthen the paper's contributions.