ID: Orp1K2dZvY
Title: Weakly Supervised 3D Open-vocabulary Segmentation
Conference: NeurIPS
Year: 2023
Number of Reviews: 25
Original Ratings: 6, 6, 2, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach for 3D open-vocabulary segmentation by integrating pre-trained CLIP and DINO features into a NeRF framework. The authors propose a Relevancy-Distribution Alignment loss to mitigate ambiguities in CLIP features and a Feature-Distribution Alignment loss to enhance segmentation boundaries. They argue that their method operates similarly to CLIP in a zero-shot setting, requiring only new labels without prior annotations. The method is evaluated on a self-collected dataset, demonstrating the potential for accurate segmentation without explicit annotations. The authors compare their approach with LERF, noting that both require pre-trained CLIP, DINO, multi-view images, and user-provided text labels, but assert that LERF's use of labels at inference limits its semantic knowledge. They also claim their setup is identical to baselines Sem(ODISE) and Sem(OV-Seg), which utilize user-provided text labels for 2D segmentation maps before NeRF training.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant challenge in 3D open-vocabulary segmentation, leveraging 2D foundation models to reduce annotation costs.
- The method does not require annotated per-point labels, allowing for weakly-supervised or unsupervised learning.
- The organization and presentation of the paper are commendable, with clear motivation for the proposed losses and a clear distinction between their approach and close-vocabulary methods.

Weaknesses:
- The reliance on a closed set of classes for training raises questions about the true open-vocabulary nature of the method, as it necessitates prior knowledge of object classes and cannot query arbitrary objects without retraining.
- The experimental evaluation is limited to a small dataset of 10 custom scenes, lacking diversity and comparison with established benchmarks like LERF.
- The comparison with LERF is misleading, as LERF allows querying any object without re-optimization, which is an advantage not shared by the proposed method.
- Several mathematical notations and concepts are unclear, leading to difficulties in understanding the algorithm's workings and implications.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their claims regarding the open-set nature of their method, as it currently gives an unfair advantage over baselines that allow for different test categories. We also suggest improving the clarity of the mathematical notations and providing detailed explanations for key equations, particularly addressing the concerns raised about Eq. (3), Eq. (6), and the RDA loss in Eq. (8). Additionally, we encourage the authors to expand the experimental evaluation to include comparisons with established datasets like LERF and to conduct experiments to evaluate the method's performance on unseen classes to substantiate its open-set capabilities. Finally, we suggest reconsidering the title and terminology used in the paper, potentially adopting "weakly-supervised" instead of "open-vocabulary" to better reflect the method's characteristics and enhance the quantitative evaluation of their method to bolster confidence in its performance.