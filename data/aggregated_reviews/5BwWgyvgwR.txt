ID: 5BwWgyvgwR
Title: Unsupervised Modality Adaptation with Text-to-Image Diffusion Models for Semantic Segmentation
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 7, 6, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Modality Adaptation with text-to-image Diffusion Models (MADM), which extends traditional image domain adaptation to modality adaptation for unsupervised semantic segmentation in multimodal scenarios. The authors propose two key components: Diffusion-based Pseudo-Label Generation (DPLG) and Label Palette and Latent Regression (LPLR), aimed at improving label accuracy and extracting high-resolution features. Experimental results demonstrate that MADM achieves state-of-the-art performance across depth, infrared, and event modalities.

### Strengths and Weaknesses
Strengths:
1. The paper is well-organized, concise, and easy to understand.
2. It innovatively extends adaptation from image domains to modalities for the first time.
3. The proposed MADM significantly outperforms existing methods across three different modalities.
4. Figures 3 and 5 effectively illustrate the impact of DPLG on pseudo-label generation.

Weaknesses:
1. The paper lacks visualization results from the VAE Decoder, which would enhance understanding of LPLR.
2. Specific layers of the multiscale features extracted from the UNet decoder are not clearly stated.
3. The novelty of the proposed modules is questionable, as they are commonly used in generative fields.
4. The approach is time-consuming, and complexity analysis is absent.
5. There is insufficient discussion on the method's performance with varying data volumes, which is critical for practical applications.

### Suggestions for Improvement
We recommend that the authors improve the paper by adding the LPLR visualization results and providing a thorough analysis of these results. Additionally, details regarding the framework implementation should be supplemented. It would be beneficial to include a complexity analysis in Table 1 and discuss the method's performance with different data volumes, testing datasets ranging from 500 to 10,000 samples across modalities. Lastly, the authors should clarify the motivations behind critical components and ensure that all references are accurate and relevant.