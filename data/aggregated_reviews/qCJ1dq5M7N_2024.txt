ID: qCJ1dq5M7N
Title: FouRA: Fourier Low-Rank Adaptation
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 4, 7, 6, 5, -1, -1
Original Confidences: 5, 4, 3, 4, -1, -1

Aggregated Review:
### Key Points
This paper presents FouRA, a novel parameter-efficient fine-tuning (PEFT) method primarily for text-to-image tasks, which operates in the frequency domain to learn low-rank adapter transforms. FouRA addresses issues of data copying and distribution collapse, enhancing image quality and demonstrating effectiveness across both computer vision (CV) and natural language processing (NLP) tasks. The method incorporates input-dependent adaptive rank selection, allowing for flexible merging of multiple adapters.

### Strengths and Weaknesses
Strengths:
- The paper is well-organized and clearly describes the FouRA method.
- The motivation for using frequency domain adaptation is compelling and effectively addresses limitations of existing LoRA methods.
- Extensive experiments validate the superiority of FouRA over vanilla LoRA, with convincing qualitative and quantitative results.

Weaknesses:
- The introduction of additional computational operations raises concerns about efficiency; specifically, the time required for each training epoch and GPU peak memory during fine-tuning are not adequately reported.
- The paper lacks clarity in certain sections, particularly regarding the derivation of key equations and the implications of eigenvalue distributions.
- There is insufficient analysis of the adaptive rank selection's impact on convergence and generalization, and no ablation studies on rank selection are provided.
- The focus on multiple adapters lacks evaluation of critical metrics such as efficiency and memory usage.
- The generality of FouRA to tasks beyond text-to-image generation is not convincingly demonstrated.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the derivation for $\Delta W_{foura}$ from Eq.5 and provide a simpler method to verify the error of the FouRA approximation. Additionally, please include a detailed analysis of the computational overhead compared to LoRA, specifically addressing memory usage and inference time. We suggest conducting ablation studies to elucidate the contributions of each component of FouRA and to compare the adaptive rank selection with fixed dynamic rank. Lastly, we encourage the authors to concentrate their writing on the text-to-image task to enhance readability and highlight the contribution of FouRA more effectively.