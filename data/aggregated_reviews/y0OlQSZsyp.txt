ID: y0OlQSZsyp
Title: Learning Causal Models under Independent Changes
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 7, 7, 7, 4, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a score-based method for causal discovery from multi-environment data, utilizing Gaussian Process (GP) models. The authors propose a scoring criterion based on the complexity of GP models, aiming to identify causal structures under certain conditions. The method is theoretically sound, with identifiability guarantees provided, and is evaluated on synthetic and real datasets.

### Strengths and Weaknesses
Strengths:
- The toy example effectively illustrates the proposed idea.
- The use of GP model complexity as a score function for causal models is innovative.
- The paper includes sufficient evaluations across various datasets, demonstrating the method's effectiveness.

Weaknesses:
- The empirical score function is not defined, and the algorithm lacks clarity on estimating the score function from data.
- There are numerous typos and missing explanations, such as the role of the penalty term $R(X_{S})$ and the definition of $L(h)$ in Section 2.2.
- Assumption numbering is inconsistent, and some terms are undefined, impacting readability and comprehension.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the empirical score function and provide a detailed explanation of how to estimate it from data. Additionally, we suggest addressing the missing explanations and correcting typos throughout the manuscript. Specifically, the authors should clarify the role of the penalty term $R(X_{S})$, define $L(h)$ in Section 2.2, and ensure consistent assumption numbering. Finally, enhancing the accessibility of the paper by defining key terms, such as "algorithmic independence," would benefit readers.