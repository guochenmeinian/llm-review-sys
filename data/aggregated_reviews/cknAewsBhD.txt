ID: cknAewsBhD
Title: EGSST: Event-based Graph Spatiotemporal Sensitive Transformer for Object Detection
Conference: NeurIPS
Year: 2024
Number of Reviews: 20
Original Ratings: 5, 6, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel event-based graph spatiotemporal sensitive network (EGSST) for object detection, utilizing graph structures to process event data efficiently. Key components include a spatiotemporal sensitivity module (SSM) and an adaptive temporal activation controller (TAC), which enhance processing efficiency while achieving state-of-the-art performance. Additionally, the authors propose a method for handling event generation in varying motion scenarios by constructing connected subgraphs and employing an inter-subgraph attention mechanism through the Graph Attention Network (GAT) to enhance model robustness. The integration of a lightweight, multi-scale Linear Vision Transformer (LViT) further contributes to the framework's efficiency. However, the writing quality is poor, making the paper difficult to follow, and the novelty of the approach is considered modest.

### Strengths and Weaknesses
Strengths:  
1. The approach of processing event-based data as graph data is innovative and retains spatiotemporal information effectively.  
2. The SSM module is well-designed for event-based data characteristics.  
3. The incorporation of the GAT module enhances adaptability to varying data and provides a method for reducing noise impact through connected subgraphs.  
4. The proposed method demonstrates strong experimental results and efficiency.  
5. The authors express a commitment to improving clarity and detail in their revisions.

Weaknesses:  
1. The claim that the SSM mimics human eye dynamics is flawed, as it does not account for large static objects generating many events.  
2. Key functions, such as the $\pi$ function and the definition of $f(\cdot)$ in the SSM, lack clarity.  
3. The paper does not adequately differentiate between event-based and frame-based processing, particularly regarding the removable CNN module.  
4. The experimental validation is insufficient, with a lack of qualitative results and comparisons to other methods.  
5. The presentation of the paper lacks clarity, and the authors need to address the contributions of graph construction and optimization more thoroughly.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the definitions and functions related to the SSM and TAC modules, particularly the $\pi$ function and $f(\cdot)$. Additionally, the authors should provide more detailed experimental validation, including qualitative results and comparisons with existing methods. It would be beneficial to clarify the advantages of the proposed model over the AEC+YOLOv5 method and to conduct experiments with a YOLOX detection head. Furthermore, we suggest that the authors include a concise visualization of data to demonstrate the effectiveness of the SSM and TAC modules in prioritizing fast-moving objects. We also recommend improving the clarity of the description in line 197 and providing a detailed explanation of subgraph construction and dynamics in Section 3. Including a discussion in the appendix about the impact of parameters on effectiveness and efficiency would be valuable. The authors should add experiments to clarify the contributions of the graph construction optimization process and subsequent graph network processing. Lastly, we urge the authors to promptly update the publicly available code and ensure that all relevant components are included.