ID: MU27zjHBcW
Title: DePLM: Denoising Protein Language Models for Property Optimization
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 5, 7, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method, DePLM, for supervised fine-tuning of protein language models (PLMs) aimed at fitness prediction tasks. DePLM employs a denoising framework with a rank correlation objective to iteratively refine PLM likelihoods, enhancing predictions by focusing on relevant fitness properties. The authors report that DePLM outperforms existing methods on ProteinGym benchmarks and demonstrates generalization across different datasets, addressing limitations of traditional PLMs in protein optimization.

### Strengths and Weaknesses
Strengths:
- The paper effectively addresses the limitation of PLMs in fitness prediction by proposing a denoising approach to filter out irrelevant features.
- It introduces innovative ideas, such as using a denoising framework and a rank correlation objective for fine-tuning.
- The experiments conducted provide valuable insights into the generalization capabilities of fitness prediction methods.

Weaknesses:
- **Major:**
  1. More baselines and ablation studies are necessary to establish DePLM as state-of-the-art, particularly including methods that utilize structural information.
  2. The datasets used in experiments require clearer descriptions, especially regarding discrepancies in baseline results on ProteinGym.
  3. The use of the diffusion framework is confusing and may obscure relevant comparisons to DePLM.
  4. The absence of error bars on experimental results raises concerns about statistical significance.
  5. The paper needs more thorough experiments with stronger baselines to validate performance gains from the proposed architecture.

- **Minor:**
  - Several typographical errors need correction.

### Suggestions for Improvement
We recommend that the authors improve the clarity of dataset descriptions and address discrepancies in baseline results on ProteinGym. Additionally, we suggest including more relevant baselines that leverage structural information to strengthen claims of DePLM's performance. The authors should clarify the use of the diffusion framework, ensuring it accurately reflects the method's operations. Including error bars or statistical analyses in the results would enhance the robustness of the findings. Finally, we encourage the authors to provide detailed hyperparameter choices and computational cost comparisons to contextualize the benefits of their approach.