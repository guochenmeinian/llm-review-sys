ID: 4sueqIwb4o
Title: Regularized Q-Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 5, 4, 5, 8, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel Q-learning variant called RegQ, which incorporates a regularization term to address the instability associated with traditional Q-learning when using linear function approximation. The authors prove that RegQ converges under these conditions, contributing to a deeper understanding of the 'deadly triad' in reinforcement learning. The algorithm is empirically shown to outperform related methods, and its theoretical framework is grounded in switched system theory.

### Strengths and Weaknesses
Strengths:
- The paper tackles a significant issue in reinforcement learning, providing a theoretically rigorous approach to ensure convergence.
- The simplicity of the proposed framework allows for convergence proofs without relying on numerous artificial assumptions, making it more accessible.

Weaknesses:
- The analysis primarily follows an ODE style, yielding only asymptotic guarantees, while non-asymptotic results could be provided with additional effort.
- The experimental section is limited, lacking sufficient details and comparisons with prior work to validate claims about the algorithm's performance.
- The paper does not adequately address the implications of using a fixed behavior policy, which may limit practical applicability.

### Suggestions for Improvement
We recommend that the authors improve the experimental section by providing more comprehensive comparisons with baseline algorithms and clarifying the conditions under which RegQ outperforms them. Additionally, the authors should explore the implications of Assumption 2.2 regarding the orthogonality of columns in the feature matrix and consider relaxing this assumption. It would also be beneficial to include a discussion on how the proposed algorithm relates to the framework of regularized MDPs introduced by Geist et al. (2019). Furthermore, we suggest clarifying the phases mentioned in Figure 1c and providing more detailed explanations of the experimental results to enhance understanding.