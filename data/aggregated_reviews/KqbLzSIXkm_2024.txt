ID: KqbLzSIXkm
Title: DiMSUM: Diffusion Mamba - A Scalable and Unified Spatial-Frequency Method for Image Generation
Conference: NeurIPS
Year: 2024
Number of Reviews: 22
Original Ratings: 4, 8, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel Mamba-based diffusion model, DiMSUM, which integrates wavelet transformation to enhance local feature detection in image generation by combining spatial and frequency information. The architecture employs a query-swapped cross-attention technique and incorporates transformer blocks to enrich global context features. The authors claim that their method achieves state-of-the-art results with faster training convergence and high-quality outputs across standard benchmarks. Additionally, the DiMSUM model utilizes the flow matching framework for improved inference speed, with comparisons to the DiT-L/2 model made under the same sampling conditions to ensure equitable evaluation. The authors clarify a typo regarding the parameters of DiMSUM-L/2, which should be 460M instead of 480M.

### Strengths and Weaknesses
Strengths:
- The proposed method effectively utilizes frequency domain processing, which is a promising approach compared to existing Mamba diffusion methods.
- The architecture draws inspiration from DiT, creating an interesting hybrid model.
- The paper is well-organized, with valuable methodology design and experimental ablations demonstrating promising performance on multiple datasets.
- The authors provide a clear rationale for their model's design choices, particularly in aligning sampling methods for fair comparisons.
- The use of the dopri5 ODE adaptive solver allows for efficient sampling with fewer NFEs, contributing to improved performance.

Weaknesses:
- The method exhibits signs of overfitting with longer training, contradicting findings from other transformer-based diffusion models.
- There is a lack of comparative analysis between the proposed method and competitors at both 256 and 512 resolutions, particularly regarding the claimed issues with quadratic computation.
- Scalability is inadequately addressed, which weakens the paper's overall impact.
- Performance on ImageNet is not convincingly superior to DiT or other advanced models, indicating that the proposed method may still be under-explored.
- The inference speed of DiMSUM-L/2 is slower than its counterpart at 256x256 images when using the same NFE, raising questions about its overall efficiency.
- The paper lacks clarity on the specific number of NFEs used for different resolutions, which could lead to misunderstandings regarding the model's speed advantages.

### Suggestions for Improvement
We recommend that the authors improve the analysis of overfitting by conducting experiments to verify the sensitivity of DiMSUM's generation performance to scanning order. Additionally, stronger baselines and experiments on more datasets, such as conditional generation on MSCOCO, should be included. It would be beneficial to clarify the rationale behind the parameter sharing in transformers and to provide a detailed comparison of inference speed and memory usage against other models. We also suggest improving clarity by explicitly confirming whether the proposed method's speed advantage primarily stems from using fewer NFEs in sampling. Furthermore, providing concrete details on the NFEs used for each method in the tables would enhance understanding of the performance metrics. Finally, we suggest revising claims regarding the scalability and state-of-the-art performance to accurately reflect the findings and limitations of the proposed method.