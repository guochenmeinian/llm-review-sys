ID: Ek87791lcO
Title: Prompt as Triggers for Backdoor Attack: Examining the Vulnerability in Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ProAttack, a novel method for clean-label backdoor attacks on language models that utilizes prompts as triggers. The authors demonstrate the effectiveness of ProAttack through extensive experiments, achieving state-of-the-art results in rich-resource and few-shot settings on the clean-label backdoor attack benchmark. They also identify limitations, such as the need for further verification of generalization performance in diverse scenarios and the exploration of effective defense methods.

### Strengths and Weaknesses
Strengths:
- Proposes a novel and efficient method for clean-label backdoor attacks based on prompts.
- Achieves state-of-the-art attack success rates in rich-resource settings.
- Raises awareness of the security threats posed by prompt-based textual backdoor attacks.
- Highlights limitations and suggests future research directions.

Weaknesses:
- The claim regarding the "stealthy" nature of the attack lacks experimental justification.
- Evaluation is insufficient, with limited comparisons to relevant backdoor attacks and defense methods.
- Some references are poorly formatted, and the paper requires further proofreading.

### Suggestions for Improvement
We recommend that the authors improve the experimental evaluation by including comparisons in few-shot settings and against relevant prompt-based backdoor attacks, such as those by Xu et al. (2022) and Cai et al. (2022). Additionally, we suggest conducting experiments to demonstrate the effectiveness of ProAttack under existing defense methods, such as the ONION defense. Finally, we encourage the authors to ensure proper formatting of references and to proofread the paper for grammatical and stylistic improvements.