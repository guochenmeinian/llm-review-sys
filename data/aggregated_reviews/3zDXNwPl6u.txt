ID: 3zDXNwPl6u
Title: Target Span Detection for Implicit Harmful Content
Conference: ACM
Year: 2024
Number of Reviews: 5
Original Ratings: 0, -2, 1, -1, -1
Original Confidences: 4, 5, 3, 4, 5

Aggregated Review:
### Key Points
This paper presents a new dataset for identifying implicit targets of hate speech, defining a novel task and introducing a baseline method. The authors utilize human annotations for validation through a pooling approach. However, the definitions of implicit and explicit targets are insufficiently articulated, and the rationale for identifying implicit targets is unclear given existing explicit target annotations. The annotation process, conducted by researchers involved in the study, raises concerns about the expertise required for such a complex task. Additionally, the relationship between the proposed method and existing pooling techniques is not adequately clarified.

### Strengths and Weaknesses
Strengths:  
- The paper is well-written and easy to follow.  
- The dataset developed is a valuable resource for future research in hate speech detection.  
- Preliminary experimental results, despite being based on simple architectures, are promising.  

Weaknesses:  
- The definitions of implicit and explicit targets lack clarity.  
- The annotation methodology is questionable, relying solely on GPT-3.5 without incorporating human annotator similarities.  
- The connection of the dataset's creation process to established pooling methods is tenuous.  
- The paper may not be suitable for the ICTIR conference due to its focus on dataset contribution rather than information retrieval.

### Suggestions for Improvement
We recommend that the authors improve the definitions of implicit and explicit targets to clarify their importance. It would be beneficial to involve experts in the annotation process and provide detailed guidelines, including the demographics of the annotators. Additionally, the authors should explore the variability of results by running prompts multiple times. In Table 1, including overall numbers would enhance clarity. Finally, we suggest that the authors consider submitting to a more appropriate NLP-related conference with a resource focus, as the connection to IR is not strong.