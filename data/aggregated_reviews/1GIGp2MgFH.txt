ID: 1GIGp2MgFH
Title: Lower-Left Partial AUC: An Effective and Efficient Optimization Metric for Recommendation
Conference: ACM
Year: 2023
Number of Reviews: 3
Original Ratings: -1, -1, -1
Original Confidences: -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Lower-Left Partial AUC (LLPAUC), a new optimization metric that aims to correlate better with Top-K ranking metrics than AUC while maintaining computational efficiency. The authors propose a relaxation of LLPAUC for optimization within a deep learning framework, asserting that optimizing its surrogate loss enhances top-k ranking performance and maintains training efficiency akin to point-wise loss functions. Additionally, LLPAUC is claimed to be robust against noisy data, supported by experiments conducted in both clean and noisy training environments.

### Strengths and Weaknesses
Strengths:
- The work addresses an important topic in recommendation systems, providing a novel metric that aligns more closely with top-k ranking metrics than AUC.
- The paper is well-written, technically sound, and includes thorough theoretical analyses and proofs.
- Extensive experiments across multiple datasets and models validate the effectiveness of the proposed method.

Weaknesses:
- The experimental section lacks comparisons with advanced pairwise or listwise learning-to-rank methods commonly used in real-world applications.
- There are minor issues in the empirical analysis, such as missing information on the number of evaluation runs and inaccuracies in reported results (e.g., NDCG@20 for LightCGN).

### Suggestions for Improvement
We recommend that the authors improve the experimental section by including comparisons with advanced pairwise or listwise learning-to-rank methods to strengthen their claims. Additionally, please clarify the number of evaluation runs conducted to contextualize the reported standard deviations. Addressing the inaccuracies in Table 3 and ensuring all technical details, such as L299 and L114, are correct will enhance the paper's clarity and precision. Finally, consider adding more datasets, such as Movielens, to provide stronger evidence of the generality of the approach.