ID: x7pjdDod6Z
Title: MeshFormer : High-Quality Mesh Generation with 3D-Guided Reconstruction Model
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 7, 8, 7, 7, 7, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 5, 5, 5, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents MeshFormer, a sparse-view reconstruction model that generates high-quality 3D textured meshes from sparse RGB images and corresponding normal maps. The model employs voxel representation, integrates 3D convolution and attention layers, and utilizes SDF loss for direct geometry supervision. Experimental results indicate that MeshFormer achieves state-of-the-art performance in generating detailed 3D shapes while being computationally efficient, requiring only 8 GPUs for training.

### Strengths and Weaknesses
Strengths:
- The authors provide a thorough explanation of the model's design motivations, demonstrating the rationale behind choices like voxel representation and 3D convolutions.
- The model is simpler to train than baseline methods and yields superior qualitative and quantitative results.
- The ablation study confirms the importance of normal input, SDF supervision, and geometry enhancement techniques.

Weaknesses:
- The method section lacks mathematical symbols and equations, which could clarify the pipeline.
- More implementation details are needed for reproducibility, including model architecture and hyperparameter values.
- The paper does not compare inference time and memory usage with baseline models, and there are potential misclaims regarding technical novelties that require citation and discussion of related works.

### Suggestions for Improvement
We recommend that the authors improve the method section by incorporating more mathematical symbols and equations to enhance clarity. Additionally, please provide comprehensive implementation details, including model architecture and hyperparameter values, to facilitate reproducibility. It is essential to report the comparison of inference time and memory usage with baseline models. Furthermore, we suggest revising the manuscript to accurately cite and discuss related works to address potential misclaims regarding technical contributions. Lastly, consider including an ablation case in Table 3 to visualize the impact of errors from 2D models on reconstruction performance.