ID: 5d2eScRiRC
Title: Imitating Language via Scalable Inverse Reinforcement Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 8, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates the application of inverse reinforcement learning (IRL) to the language imitation learning problem, specifically reformulating IQLearn as a temporal difference regularized extension of maximum likelihood estimation (MLE). The authors demonstrate that their method consistently outperforms vanilla MLE across various base models on benchmarks like XSUM and GMS8K, while incurring minimal computational overhead. The paper also provides an extensive analysis of other potential IRL algorithms for imitation learning with large language models (LLMs).

### Strengths and Weaknesses
Strengths:  
- The paper is well-written and clearly motivates the problem, with a novel approach that bridges IRL and MLE.  
- Extensive validation of the proposed method across multiple models and benchmarks, showing its effectiveness in maintaining diversity while maximizing performance.  
- The time profiling section is particularly helpful, indicating similar training efficiency to MLE.

Weaknesses:  
- The performance gains are marginal, around 1% accuracy on GMS8K and 1 ROUGE-1 score, raising questions about the method's overall impact.  
- The clarity of the figures, particularly Figure 1, could be improved to better illustrate the differences between MLE, offline IRL, and online IRL.  
- More experimental tasks should be included, and the paper lacks error bars in several figures, which could enhance the analysis.  
- The writing contains some typos and could benefit from minor revisions for clarity.

### Suggestions for Improvement
We recommend that the authors improve the clarity of figures, particularly Figure 1, to better differentiate between MLE, offline IRL, and online IRL. Additionally, including more experimental tasks such as CommonGEN, ROCStories, EMNLP2017, and COCO would strengthen the empirical analysis. We also suggest adding error bars to Figures 2, 3, and 4 to provide a clearer understanding of the results. Furthermore, addressing the quality-diversity trade-off and providing pseudo code for the proposed algorithm would enhance the paper's comprehensibility and reproducibility. Lastly, we encourage the authors to clarify the performance implications of varying the hyperparameter $\lambda$ in their experiments.