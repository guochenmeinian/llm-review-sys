ID: PTvxck0QDE
Title: Simplicity Bias in 1-Hidden Layer Neural Networks
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 5, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on simplicity bias (SB) in one-hidden layer neural networks (NNs), specifically defining low-dimensional input dependence simplicity bias (LD-SB). The authors investigate SB theoretically in infinite-width networks and practically in finite-width networks, focusing on the independent features model (IFM). They assert that pretrained representations from self-supervised learning are sufficiently clustered for effective separation by a linear classifier, although the independence of these features is questioned, particularly regarding the size of the representations relative to the problem inputs. The authors propose an ensemble method, OrthoP, to enhance classifier diversity by training on orthogonal projections of input data. Empirical results indicate that NNs exhibit LD-SB, primarily relying on a limited set of features despite the availability of more complex ones. However, the metrics in subsection 4.4.1 are critiqued for potentially overlooking crucial information about the similarity of labels, complicating the interpretation of results. The discussion of results needs to focus more on the quality of outcomes rather than just the metrics.

### Strengths and Weaknesses
Strengths:
1. The related work section is comprehensive, addressing various topics and emphasizing the importance of context in conference papers.
2. The concept of independent representations for diverse classifiers is intuitive and well-articulated.
3. The authors provide a detailed analysis of the correlation between features in pretrained representations, supporting the independence assumption with empirical data.
4. The response to critiques demonstrates a willingness to clarify and improve the manuscript based on reviewer feedback.

Weaknesses:
1. The main results are limited to a specific case involving the IFM dataset, with insufficient justification for the assumptions made.
2. The metrics in subsection 4.4.1 do not account for correlations between examples and labels, potentially misrepresenting their intended purpose and leading to ambiguous interpretations of the results.
3. The absence of a baseline for comparison in Table 1 makes it difficult to assess the significance of the findings.
4. The paper lacks sufficient discussion on the empirical results, leaving readers uncertain about their significance.
5. Concerns remain regarding the theoretical foundation of the LD-SB definition and its implications for the model's predictions.
6. The experimental comparisons are inadequate, particularly regarding the performance of OrthoP against other ensemble methods.

### Suggestions for Improvement
We recommend that the authors improve the justification for the assumptions related to the IFM dataset and provide a more robust argument for their relevance. Additionally, we suggest revising the metrics in subsection 4.4.1 to incorporate correlations between examples and labels, as well as label similarity into the evaluation criteria. It would be beneficial to include a baseline for comparison in Table 1 to contextualize the results. We encourage the authors to enhance the discussion surrounding the empirical results to clarify their implications and significance. Furthermore, we suggest that the authors elaborate on the theoretical underpinnings of LD-SB, particularly addressing the concerns raised about the definition and its implications for the model's predictions. Lastly, exploring various strategies for constructing P in both lazy and rich regimes could enhance the robustness of the findings and strengthen the experimental validation of OrthoP against other ensemble methods.