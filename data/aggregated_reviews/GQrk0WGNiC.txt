ID: GQrk0WGNiC
Title: Pre-training Differentially Private Models with Limited Public Data
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 4, 5, 7, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a theoretical framework analyzing the impact of various parameters of differential privacy (DP) training on model performance, utilizing the Hessian of per-sample gradients to compute per-iteration loss improvement. The authors propose that DP affects pre-training more significantly than fine-tuning and suggest using public data for continual pre-training as a remedy. They also derive the optimal batch size for private training under a fixed computation budget and empirically demonstrate the effectiveness of their approach on large-scale vision models.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, with major claims supported by arguments, derivations, and graphs, making it easy to follow.
- The derivation of the decelerator component of per-iteration loss provides valuable insights into DP-SGD training dynamics.
- The proposed continual learning approach appears practically useful in privacy-sensitive settings, with impressive few-shot accuracy.

Weaknesses:
- The assumption that per-sample gradient clipping does not introduce bias into the gradient approximation is strong and not widely accepted, requiring further justification.
- The analysis assumes oracle knowledge of matrices G and H, which may not be feasible in practical applications.
- There is a disconnect between theoretical results and experimental evaluations, particularly regarding the mixing ratios of public/private data.
- The experiments lack ablation studies and proper baselines, and compute resources used for experiments are not reported.

### Suggestions for Improvement
We recommend that the authors improve the justification for the assumption regarding clipping bias, clarifying its scope and implications. Additionally, we suggest providing empirical evidence to support theoretical claims and including ablation studies to validate the key methodological proposals. The authors should also explore different mixing ratios of public/private data in their experiments and report the compute resources used for reproducibility. Finally, a formal algorithm for the DP continual pre-training approach would enhance clarity.