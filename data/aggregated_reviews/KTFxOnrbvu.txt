ID: KTFxOnrbvu
Title: Argument mining as a multi-hop generative machine reading comprehension task
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to argument mining by reformulating it as a multi-hop reading comprehension (MRC) task, utilizing the concept of "chain of thought." The authors process instances into a quadruple of <query, context, answer, path> and train a BART model to predict both the path and the answer. Experimental results demonstrate the efficacy of this method across two datasets, achieving state-of-the-art performance. The paper is generally well-written and the experiments sound, although certain aspects, such as the training process and evaluation measures, lack clarity.

### Strengths and Weaknesses
Strengths:
- The conversion of argument mining into a multi-hop reading comprehension task is innovative and well-motivated.
- The experimental results support the model's efficacy for the task.
- The paper is mostly well-written and clear in its presentation.

Weaknesses:
- The reliability of results is questionable due to unclear details on cross-fold validation and significance testing.
- The focus on a single path in the "chain of thought" may overlook inherent variability.
- Key experimental findings, such as the impact of including the full argument graph and the differences between datasets, require further discussion and interpretation.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the training process by providing details such as the number of epochs and any fine-tuned hyperparameters. Additionally, addressing whether cross-fold validation was performed would strengthen the reliability of the results. We suggest exploring the implementation of their approach as a prompt for large language models to assess its effectiveness. Furthermore, we encourage the authors to discuss the implications of the differences between the datasets more thoroughly, particularly regarding the performance variations observed. Lastly, we advise replacing speculative language with quantitative data to enhance clarity and understanding.