ID: Grz2ijKrWI
Title: STXD: Structural and Temporal Cross-Modal Distillation for Multi-View 3D Object Detection
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 5, 5, 5, 4, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 5, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel cross-modal knowledge distillation framework for multi-view 3D object detection, named STXD. It incorporates three strategies: (1) correlation-based cross-modal feature distillation to bridge the domain gap at the feature level, (2) feature similarity guided temporal feature distillation to account for dynamic scenes across multiple frames, and (3) response-level distillation via bipartite matching between teacher and student predictions. The authors also introduce a Correlation Regularizing Distillation loss aimed at addressing distributional divergences in 3D detection. They demonstrate that STXD significantly enhances current 3D detectors on the nuScenes dataset and acknowledge the importance of validating their approach across diverse datasets, particularly the Waymo dataset.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and easy to follow.
2. It offers new perspectives on knowledge distillation for multi-view 3D detectors, particularly through temporal-based feature distillation.
3. Extensive experiments validate the effectiveness of STXD on the nuScenes dataset.
4. The proposed Correlation Regularizing Distillation loss is innovative and has received positive feedback for its potential impact on 3D detection.
5. The authors demonstrate a willingness to address reviewer concerns and incorporate additional validation results in future versions.

Weaknesses:
1. The novelty of the correlation-based feature distillation is questionable, as similar methods have been proposed recently (e.g., TiG-BEV).
2. The response-level distillation shows limited novelty, resembling techniques in BEVDistill.
3. The paper lacks experimental comparisons with classic feature-level distillation and does not sufficiently demonstrate the effectiveness of temporal consistency distillation.
4. The motivation for structural and temporal distillation is inadequately explained.
5. Implementation challenges related to the Waymo dataset hinder comprehensive evaluation.
6. There is a need for extended experiments involving long-term temporal information and complex settings related to BEVDepth, which have not yet been addressed.

### Suggestions for Improvement
We recommend that the authors improve the novelty aspect by providing clearer distinctions between their methods and existing literature, particularly regarding correlation-based and response-level distillation. Additionally, we urge the authors to successfully implement experiments on the Waymo dataset, despite current challenges, to enhance the generalizability of their findings. Conducting extended experiments involving long-term temporal information (more than 8 frames) and exploring complex settings related to BEVDepth would also strengthen the paper. Furthermore, we suggest including more comprehensive analyses of temporal consistency distillation and clarifying the motivation behind their structural distillation approach. Lastly, addressing the computational constraints and potential memory issues related to the use of multiple similarity matrices would bolster the overall contribution of the work.