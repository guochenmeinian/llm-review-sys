ID: L9I9FhHfS3
Title: Consensus and Subjectivity of Skin Tone Annotation for ML Fairness
Conference: NeurIPS
Year: 2023
Number of Reviews: 19
Original Ratings: 6, 6, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel and detailed skin tone scale (Monk Skin Tone, MST) that improves upon the Fitzpatrick skin types and offers practical suggestions for practitioners to enhance the data labeling process. The authors demonstrate how to reliably annotate skin tone using both trained crowdsourced annotators and subject-matter experts, while releasing the MST-E dataset to support further research. Additionally, the paper explores skin tone annotation using Dr. Monkâ€™s annotations as a verification tool, clarifying that Dr. Monk was not the sole annotator. The authors, led by Auriel Wright, supervised the selection of models based on skin tone, and all annotations will be released, not just those of Dr. Monk. The study focuses on the annotations provided by photographers, aligning with the goal of assessing skin tone in imagery, and acknowledges the potential interest in comparing annotations from various types of experts for future research.

### Strengths and Weaknesses
Strengths:  
- The paper introduces a comprehensive and more detailed skin tone scale (MST) than existing methods.  
- It provides valuable insights into the annotation process, emphasizing the importance of using geographically diverse annotators to mitigate bias.  
- The MST-E dataset is well-constructed and publicly available for further research, serving as a useful resource for fairness-related annotations.  
- There is a clear clarification of the annotation process and the involvement of multiple annotators.  
- The focus on a relevant and specific aspect of skin tone assessment in imagery is commendable.  
- The acknowledgment of the potential for future research comparing different expert annotations adds depth to the study.

Weaknesses:  
- The dataset's reliance on Dr. Monk as the sole annotator for ground truth is a significant limitation, raising concerns about consistency and robustness.  
- The limited number of subjects (18) may lead to under-representation and potential memorization biases among annotators.  
- The paper lacks detailed discussions on the dataset's applications in machine learning and does not adequately address the potential for misuse of the annotations.  
- There is a lack of comparison between different types of experts in the current study.  
- Ethical concerns regarding the potential misuse of the dataset, particularly in generating synthetic images or videos, are not sufficiently addressed.

### Suggestions for Improvement
We recommend that the authors improve the technical acquisition details and preprocessing procedures of images in the dataset. Additionally, addressing the differences in annotation practices among diverse cultural backgrounds would enhance the study's depth. The authors should also consider including dermatologists in the annotation process to strengthen the study's validity. Furthermore, it would be beneficial to illustrate specific applications of the dataset in machine learning tasks and clarify allowed use cases for the images and annotations. We suggest improving the abstract to include the positioning of the paper and details about the dataset. Lastly, we recommend outlining potential misuses of the dataset, such as the creation of synthetic images or videos, and including potential uses of the dataset in the computer vision community to address ethical concerns.