ID: cu8FfaYriU
Title: A Taxonomy of Challenges to Curating Fair Datasets
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 7, 8, 6, 9, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive taxonomy of challenges in curating fair and unbiased datasets for machine learning (ML), based on insights from 30 semi-structured interviews with dataset curators. It explores the definition of fairness, the processes for collecting fair datasets, and the trade-offs encountered during dataset collection. The taxonomy categorizes challenges across different stages of the dataset lifecycle—requirements, design, implementation, evaluation, and maintenance—while also addressing individual, organizational, and regulatory levels. The authors propose actionable recommendations to mitigate these challenges, contributing to the ongoing discourse on fairness in ML.

### Strengths and Weaknesses
Strengths:
- The taxonomy of challenges is a significant contribution, providing a structured framework for understanding fairness issues in dataset curation.
- The paper is well-structured and easy to follow, with rich qualitative data from diverse participants enhancing the findings.
- The focus on ethical considerations and fair labor practices is commendable, highlighting the social impact of the work.

Weaknesses:
- The taxonomy's explanation is difficult to follow across sections, leading to confusion about its components, such as the role of Table 4.
- There is limited discussion on mitigating biases in participant selection and interview responses, which could enhance the study's credibility.
- Some recommendations lack empirical support, and the generalizability of findings may be limited due to the qualitative nature of the study.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the taxonomy by ensuring consistent explanations across sections and explicitly linking components like Table 4 to the taxonomy. Additionally, we suggest incorporating a comparison with existing works in data reporting and documentation to clarify the paper's contributions. Addressing potential biases in participant selection and providing more detail on the thematic analysis process would enhance methodological transparency. Finally, including empirical evidence or case studies to support the proposed recommendations would strengthen the paper's impact.