ID: TKo2JXw7vL
Title: Large Language Models Meet Harry Potter: A Dataset for Aligning Dialogue Agents with Characters
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the 'character alignment' problem, focusing on how a dialogue agent aligns itself with specific characters through the introduction of the Harry Potter Dialogue (HPD) dataset. The dataset comprises 1,000 dialogue sessions from the Harry Potter novels, annotated with rich background information including dialogue scenes, speakers, character relationships, and attributes. The authors demonstrate that this rich information significantly enhances character alignment compared to baselines that rely solely on dialogue history and context.

### Strengths and Weaknesses
Strengths:
- The paper introduces a novel dataset with comprehensive annotations, addressing the underexplored area of dynamic and multiple-character relationships.
- The annotation schemes are thoughtfully designed, and experimental results indicate that the information contributes positively to character alignment.
- The study deepens understanding of the complexities involved in role-playing within intricate contexts.

Weaknesses:
- The small number of professional annotators raises concerns about dataset bias, and the dataset's generalizability is limited due to its reliance on well-defined background information.
- The conclusion regarding the performance of powerful LLMs compared to human expectations is questioned, as it is unclear whether this stems from insufficient scene information or model output selection.
- The dataset's size and scope are restricted to the Harry Potter series, and some annotations focus primarily on interactions involving Harry, neglecting other characters.
- The reliance on human annotation for model performance improvement is impractical for real-world applications.

### Suggestions for Improvement
We recommend that the authors improve the dataset by increasing the number of professional annotators to mitigate bias and enhance generalizability. Additionally, we suggest discussing data quality and inter-annotator agreement (IAA) more thoroughly, addressing potential biases introduced by individual annotators. The authors should also clarify the model selection process given the absence of a validation set and provide more details on the scene summarization process, including the window size and the relevance metrics used. Finally, we encourage the authors to explore methods for automatically generating annotated information to enhance the practicality of their approach in real-world applications.