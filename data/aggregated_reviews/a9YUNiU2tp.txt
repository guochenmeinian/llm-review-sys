ID: a9YUNiU2tp
Title: How to Determine the Preferred Image Distribution of a Black-Box Vision-Language Model?
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 6, 8, 8
Original Confidences: 4, 4, 3

Aggregated Review:
### Key Points
This paper presents a novel method for assessing the confidence of Vision-Language Models (VLMs) by measuring output consistency across various image distributions using CAD images, without accessing internal model parameters. The authors introduce the CAD-VQA dataset for evaluating VLM performance on CAD tasks, addressing significant research gaps. The study also highlights the effectiveness of human feedback in enhancing model accuracy.

### Strengths and Weaknesses
Strengths:
- The introduction of output consistency as a proxy for model confidence is a fresh and creative approach for black-box VLMs.
- The CAD-VQA dataset fills an important gap in evaluating VLMs in specialized technical fields like CAD, providing a valuable benchmark for future research.
- The evaluation methods incorporate manual human verification across multiple dimensions, including Relevance, Accuracy, Detail, Fluency, and Overall Quality.

Weaknesses:
- The small dataset size of only 25 data points may introduce randomness, affecting result reliability.
- The discussion around results lacks depth, particularly regarding the reasons behind model performance variations, such as the impact of in-domain training examples or model architecture.
- High consistency in model outputs does not always correlate with accuracy, raising concerns about misleading evaluations.
- The source and details of the human experts involved in the evaluation are not provided, which would enhance the context for comparisons.

### Suggestions for Improvement
We recommend that the authors improve the dataset size to enhance reliability and consider investigating the potential benefits of mixed distributions for model accuracy. Additionally, we suggest that the authors provide a more detailed discussion of the results, exploring factors influencing model performance. To address the correlation between output consistency and accuracy, we advise the inclusion of a normalization term to mitigate additional contextual information in the image distributions. Finally, we encourage the authors to disclose the source and details of the human experts to strengthen the evaluation context.