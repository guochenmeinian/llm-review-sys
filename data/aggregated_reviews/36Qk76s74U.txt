ID: 36Qk76s74U
Title: Towards Multimodal Empathetic Response Generation: A Rich Text-Speech-Vision Avatar-based Benchmark
Conference: ACM
Year: 2024
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel multimodal empathetic response generation (MERG) task and introduces the AvaMERG dataset, which integrates text, audio, and dynamic avatar videos. The authors propose the Empatheia system, equipped with multimodal encoders and a chain-of-empathetic reasoning mechanism, to enhance understanding and reasoning in empathetic responses. Extensive experiments validate the effectiveness of Empatheia, demonstrating its superiority over baseline methods in both traditional text-based and multimodal contexts.

### Strengths and Weaknesses
Strengths:
- The paper innovatively generates responses across three modalities, addressing a gap in multimodal dialogue research.
- It includes comprehensive experiments and results analysis, contributing valuable insights to the field.
- The writing is clear and well-structured, with detailed descriptions of dataset construction and system design.

Weaknesses:
- The paper lacks a dedicated section on limitations, which should be addressed.
- Some figures and sections, such as Figure 3 and Section 6.4, are incomplete or unclear.
- The experimental design appears chaotic, with insufficient ablation studies on the proposed model.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the avatar-based explanations and provide justification for selecting the ED dataset for expansion. Additionally, we suggest including a keywords section for better accessibility, enhancing citations of prior works in the introduction, and emphasizing distinctions in the related work section. The authors should also adjust the spacing between tables for clarity, complete any incomplete sections, and consider condensing the appendix to ensure relevance. Finally, addressing the data imbalance issue in the discussion would strengthen the paper's findings.