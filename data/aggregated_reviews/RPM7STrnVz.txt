ID: RPM7STrnVz
Title: VideoTetris: Towards Compositional Text-to-Video Generation
Conference: NeurIPS
Year: 2024
Number of Reviews: 18
Original Ratings: 6, 6, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents VideoTetris, a novel framework for compositional text-to-video (T2V) generation that addresses the limitations of existing methods in handling complex scenes with multiple objects and dynamic changes. Key innovations include: I) Spatio-Temporal Compositional Diffusion, which manipulates cross-attention in denoising networks to synthesize videos that adhere to complex instructions; II) Dynamic-Aware Video Data Processing, which filters and recaptions video-text pairs to enhance consistency in long video generation; and III) Consistency Regularization with Reference Frame Attention, which maintains coherence in multi-object generation. Extensive experiments demonstrate that VideoTetris significantly outperforms state-of-the-art methods in both short and long video generation tasks.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and easy to follow, contributing to overall readability.
2. It introduces a new approach for compositional T2V generation, effectively addressing challenges associated with complex scenes.
3. Extensive experiments validate the superior performance of VideoTetris in generating high-quality, coherent videos.

Weaknesses:
1. The computational cost increases due to the decomposition of input text using LLMs and the computation of cross-attention for multiple sub-objects and frames, which may impact efficiency.
2. The Reference Frame Attention module assumes object features remain consistent across frames, which may not hold true in dynamic scenes. More robust consistency regularization methods should be explored.
3. The generated videos exhibit subtle variations in content, potentially resulting in static scenes that limit practical applicability.
4. The paper lacks clarity regarding the novelty of the Spatio-Temporal Compositional Diffusion method and presents limited technical innovations, focusing more on engineering implementation.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the specific novelty introduced by the Spatio-Temporal Compositional Diffusion method and emphasize its unique aspects to distinguish it from prior works. Additionally, we suggest providing more examples for qualitative results to ensure a statistically representative evaluation and conducting a user study with at least 50 samples and 15 users. It would also be beneficial to include comparisons with stronger baselines specifically designed for Short Video Generation with Single Multi-Object Prompts and to conduct ablations for the Spatio-Temporal Compositional Diffusion method to enhance understanding of its effectiveness. Finally, addressing the visual quality degradation in long video generation and providing more detailed examples would strengthen the paper's contributions.