ID: RGnjY6l2HT
Title: UniEdit: A Unified Tuning-Free Framework for Video Motion and Appearance Editing
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 5, 5, 6, -1, -1, -1, -1
Original Confidences: 1, 4, 2, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents UniEdit, a tuning-free framework for editing videos that allows manipulation through text prompts to alter visual style and motion patterns. The authors utilize a pre-trained text-to-video diffusion model, incorporating an auxiliary reconstruction branch and a motion-reference branch to maintain the original video's structure while enabling motion editing. The results demonstrate improvements over existing methods.

### Strengths and Weaknesses
Strengths:  
- The core idea is straightforward and well-presented, with a large amount of visual content showcasing the quality of the contribution.  
- The method successfully applies feature injection for video diffusion models, yielding impressive results.  
- The paper addresses the challenge of preserving non-edited areas through the use of spatial and temporal attention modules.  
- It provides versatile applications, including motion editing and background editing.  

Weaknesses:  
- The implementation may not be entirely reconstructable, raising concerns about reproducibility.  
- The mathematical descriptions contain inaccuracies, such as the mischaracterization of matrix notation.  
- The novelty of applying feature injection to video models is questioned, as it is a known technique in image editing.  
- There is insufficient analysis of the temporal self-attention layers beyond visual results, lacking quantitative support for the claims made.  
- The user study's participant number may not be representative, and the absence of a benchmark complicates result evaluation.

### Suggestions for Improvement
We recommend that the authors improve the mathematical accuracy in the paper, particularly addressing the notation issues identified. Additionally, we encourage the authors to provide a more thorough quantitative analysis of the temporal self-attention layers and to clarify the evaluation process referenced in the paper. It would also be beneficial to increase the number of participants in the user study to enhance representativeness and to include ablation studies for motion injection and structure control in Table 2. Finally, addressing the lack of a benchmark for evaluating the method would strengthen the overall contribution.