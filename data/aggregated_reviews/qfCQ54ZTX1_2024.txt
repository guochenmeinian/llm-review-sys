ID: qfCQ54ZTX1
Title: Entity Alignment with Noisy Annotations from Large Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 4, 7, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents LLM4EA, a framework for annotating entity alignment pairs using a Large Language Model (LLM) that operates without ground truth labels for training. The authors propose a five-step process that includes selecting important source entities, recalling candidate counterparts, identifying target entities using an LLM, refining pseudo-labels through probabilistic reasoning, and training the entity alignment (EA) model. The framework introduces an active learning policy and an unsupervised label refiner to efficiently collect pseudo-labels, demonstrating strong performance on OpenEA benchmarks. The authors clarify that their method is distinct from existing approaches like BootEA, focusing on optimizing the selection policy to maximize the utility of a fixed annotation budget. However, the practicality of the proposed method is questioned, particularly regarding its reliance on LLMs for generating training pairs, which may not be necessary given existing methods like string matching.

### Strengths and Weaknesses
Strengths:
- The paper is well-structured and easy to follow, effectively communicating the design and motivation behind LLM4EA.
- The iterative process of LLM4EA is designed to dynamically adjust source entity selection, enhancing the effectiveness of label-free EA.
- The proposed method achieves better performance than baseline methods on the OpenEA dataset, demonstrating a significant improvement in precision compared to traditional methods that rely solely on text embedding matching.
- The experimental design is reasonable and demonstrates the framework's effectiveness.

Weaknesses:
- The novelty of the algorithm is limited, as it closely resembles existing methods like BootEA and similar unsupervised methods that utilize bootstrapping algorithms for label refinement.
- The practicality of using LLMs for generating training pairs is questioned, as simpler methods could yield more accurate results and may limit the method's applicability in scenarios where name features are unavailable.
- Several statements in the paper are misleading or incorrect, particularly regarding dataset characteristics and the evaluation of baseline methods.
- The writing could benefit from clearer explanations and reduced notation to enhance understanding.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their statements, particularly regarding the characteristics of the OpenEA datasets and the novelty of their approach compared to existing methods. It is essential to clearly distinguish LLM4EA from similar unsupervised methods in terms of its unique contributions, particularly in scalable pseudo-label generation and advanced label refinement techniques. Additionally, the authors should benchmark LLM4EA against approaches that incorporate textual information, such as MultiKE, to provide a more comprehensive evaluation. Including a detailed description of the prompt templates used in experiments for reproducibility would also be beneficial. Furthermore, we suggest addressing the concerns regarding the practicality of using LLMs for generating training pairs and considering alternative methods like string matching or semantic similarity for baseline comparisons.