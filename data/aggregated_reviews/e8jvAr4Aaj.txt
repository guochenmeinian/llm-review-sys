ID: e8jvAr4Aaj
Title: Enhancing Conversational Search: Large Language Model-Aided Informative Query Rewriting
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an approach for conversation query rewriting using large language models (LLMs) to generate and edit queries, addressing the limitations of human rewrites that often lack contextual information. The authors propose a "rewrite-then-edit" process, allowing LLMs to refine initial rewrites generated by smaller models. The study evaluates the performance of distilled models trained on LLM-generated rewrites, demonstrating that these models can outperform human performance on specific datasets.

### Strengths and Weaknesses
Strengths:
- Well-structured paper with thorough evaluations against multiple baselines, including human rewrites.
- Introduction of the "rewrite editor" concept, significantly enhancing retrieval performance.
- Comprehensive definition of four essential properties for instructing LLMs, contributing to the field's advancement.
- Valuable insights into the informativeness and correctness of query rewrites.

Weaknesses:
- Limited novelty, primarily relying on LLMs to generate silver data for training smaller models.
- Insufficient exploration of the informativeness requirement's impact on generated queries, with ablation studies indicating its limited effect.
- Claims regarding LLM rewrites' superiority over human rewrites are undermined by lower performance in certain datasets, lacking further exploration of LLM applicability for complex queries.

### Suggestions for Improvement
We recommend that the authors improve the exploration of the informativeness requirement in their instructions, clarifying the differences between various informative requirements. Additionally, we suggest including results from ED(Self) to assess the effectiveness of the informativeness requirement comprehensively. Finally, addressing the limitations of LLMs in handling complex queries and providing future directions for their applicability would strengthen the paper's claims.