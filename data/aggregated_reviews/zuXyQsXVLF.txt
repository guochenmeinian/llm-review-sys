ID: zuXyQsXVLF
Title: Enhancing Adversarial Contrastive Learning via Adversarial Invariant Regularization
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 8, 6, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents AIR, a method to regulate contrastive learning through causal reasoning, aiming to enhance robustness against adversarial examples. The authors analyze the causal graph of contrastive learning and enforce invariance in the distribution of representations under various interventions. The proposed regularizer is intended to make learned representations style-independent, thereby improving robustness. The authors report experimental results demonstrating consistent performance gains when applying AIR/SIR terms to ACL/DynACL, alongside theoretical justifications for the AIR term.

### Strengths and Weaknesses
Strengths:
- The core idea is technically novel and well-presented.
- The theoretical analysis is detailed, supporting the effectiveness of the proposed method.
- Experiments across various datasets show improvements over baselines.

Weaknesses:
- The method requires tuning of two hyper-parameters, $\lambda_1$ and $\lambda_2$, which interact in a non-trivial manner, complicating the tuning process.
- The performance improvements are marginal, often less than 1%, raising concerns about significance.
- The paper lacks comprehensive comparisons with other baselines and does not evaluate performance on larger datasets, such as sub-imagenet.
- The theoretical contributions appear to be incremental rather than novel, as they closely follow existing work.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the theoretical analysis by specifying which input types the KL divergence loss applies to, enhancing reproducibility. Additionally, please include comparisons with other baselines in Table 4 and evaluate the performance on WideResNet architectures to assess generalizability. We also suggest providing more substantial justification for the combined use of SIR and AIR, as well as clarifying the significance of performance gains in robustness experiments. Finally, addressing the concerns regarding the marginal performance improvements and the applicability of the method on larger datasets would strengthen the paper.