ID: K1ih2El1IO
Title: A Predictive Factor Analysis of Social Biases and Task-Performance in Pretrained Masked Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into the impact of various model attributes (size, training data, tokenization methodology, pre-training objective) on social biases in masked language models (MLMs). The authors analyze 39 models across different categories, employing predictive factor analysis with 30 factors and utilizing bias benchmarks such as StereoSet and Crow-S-Pairs, alongside performance metrics from GLUE and TweetEval. The findings indicate that model size, tokenization, and training objectives are the most significant factors, with multilingual models exhibiting lower social bias compared to monolingual ones.

### Strengths and Weaknesses
Strengths:  
- The diversity of model types and the comprehensiveness of model factors in the experimental setup enhance the study's robustness.  
- The use of well-known bias benchmarks and a representative metric (AULA) adds credibility to the evaluation.  
- The paper is well-written, making the complex analysis accessible.

Weaknesses:  
- The observational research design limits the establishment of causal relationships between model attributes and social biases.  
- The regression analysis is challenging to interpret, particularly with negative R^2 values for GLUE, raising concerns about the significance of the results.  
- The exclusion of de-biased models and certain bias benchmarks from the analysis may undermine the comprehensiveness of the findings.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the regression analysis, particularly addressing the negative R^2 values for GLUE and providing significance testing for the results. Additionally, including a detailed description of all models and their categorization in the appendix would enhance transparency. It would be beneficial to explore the potential confounding effects of multiple factors and consider conducting an experimental design to better establish causal relationships. Lastly, we suggest adding clear warnings regarding the reliability of the GLUE results and investigating specific tasks responsible for low performance.