ID: qkoZgJhxsA
Title: SocraticLM: Exploring Socratic Personalized Teaching with Large Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 8, 7, 8, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to enhance LLM teaching capabilities through a “Dean-Teacher-Student” pipeline, utilizing three LLM-based agents to generate Socratic teaching dialogues. The authors introduce a student cognitive system to simulate six types of students, contributing to the diversity of dialogue data. They also employ data augmentation for four essential teaching abilities and explore three training strategies to optimize the balance between problem-solving and Socratic teaching skills. The fine-tuned SocraticLM demonstrates superior teaching performance compared to several LLMs, including GPT-4 and EduChat, supported by comprehensive experiments validating the significance of single-round data and training strategies.

### Strengths and Weaknesses
Strengths:
- The motivation for LLM-based teaching is timely and relevant for intelligent education systems.
- The SocraTeach dataset, a first-of-its-kind public large-scale Socratic teaching dataset, is a significant contribution to the field.
- The “Dean-Teacher-Student” methodology is logical and reproducible, with the student cognitive system ensuring diverse dialogue data.
- Extensive experiments validate the performance of SocraticLM, providing convincing evidence of its effectiveness.

Weaknesses:
- The reliance on GPT-4 for data construction raises concerns about the potential limitations of SocraticLM's performance.
- More detailed explanations of experimental results are needed to better illustrate the effectiveness of SocraticLM.
- The evaluation method should be contextualized within existing literature to clarify how this work differs from and improves upon related methods.

### Suggestions for Improvement
We recommend that the authors improve the analysis of the Dean agent's effectiveness within the proposed pipeline to clarify its impact on the results. Additionally, we suggest providing further explanations for the experimental results, particularly regarding the performance discrepancies noted in the metrics. It would also be beneficial to contextualize the work among existing literature on Socratic LLM teaching to highlight its unique contributions and advantages. Lastly, addressing the ethical concerns raised regarding human evaluation processes and ensuring clarity on the dataset's public release would strengthen the paper.