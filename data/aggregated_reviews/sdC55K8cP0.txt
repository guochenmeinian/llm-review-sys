ID: sdC55K8cP0
Title: WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents WikiChat, a multi-stage pipeline that utilizes Wikipedia to enhance LLM chatbot responses. The system involves seven steps, including passage retrieval, summarization, claim extraction, fact-checking, and response refinement, aiming to produce factual and conversational outputs. The authors demonstrate that a distilled 7B LLaMA model can outperform larger models when fine-tuned on WikiChat responses. The effectiveness of the approach is supported by user studies and evaluations against GPT-4.

### Strengths and Weaknesses
Strengths:
- The proposed method achieves state-of-the-art performance and shows significant improvements in factuality and conversationality.
- The commitment to releasing the code and distilled model will benefit the research community.
- Comprehensive experiments validate the effectiveness of the method.

Weaknesses:
- The specific contributions of each stage in the pipeline are unclear, leading to potential circularity in the design.
- Implementation details are scattered across multiple sections, making the paper difficult to follow.
- The tone of the paper is criticized for being non-scientific and overly bold, with major claims lacking proper grounding.

### Suggestions for Improvement
We recommend that the authors improve the clarity of method, experiment, and evaluation details, ensuring they are well-organized and accessible. It would be beneficial to include an evaluation of the system's latency, given the complexity of the seven-stage process. Additionally, we suggest rewriting the introduction to adopt a more scientific tone and provide adequate citations for claims made. Clarifying the definition of conversationality and explicitly comparing WikiChat to existing systems, such as the Wizard of Wikipedia, would strengthen the paper. Finally, addressing the questions raised regarding claim splitting, response time, and the user simulator's quality would enhance the overall rigor of the study.