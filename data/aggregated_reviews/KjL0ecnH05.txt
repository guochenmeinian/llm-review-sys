ID: KjL0ecnH05
Title: WellDunn: On the Robustness and Explainability of Language Models and Large Language Models in Identifying Wellness Dimensions
Conference: EMNLP/2024/Workshop/BlackBoxNLP
Year: 2024
Number of Reviews: 3
Original Ratings: -1, -1, -1
Original Confidences: 3, 2, 2

Aggregated Review:
### Key Points
This paper presents an exploration of Language Models (LMs) in mental health applications, focusing on the alignment of model explanations with clinical determinations. The authors propose an evaluation framework called WellDunn, which emphasizes the robustness and explainability of LMs in identifying Wellness Dimensions (WD) using two datasets: MULTIWD and WELLXPLAIN. The evaluation criteria include robustness measured by Sigmoid Cross Entropy (SCE) and Gamblerâ€™s Loss (GL), and explainability assessed through Singular Value Decomposition (SVD) and Attention-Overlap (AO) Score. Findings indicate low alignment between attention and explanations across models, with GPT-3.5/4 underperforming compared to RoBERTa, and a significant performance drop when using a confidence-oriented loss function.

### Strengths and Weaknesses
Strengths:  
- The study is well-motivated, comprehensive, and well-written, examining multiple language models and providing thorough performance comparisons.  
- The proposed method shows novel contributions, achieving better performance than existing state-of-the-art models, with a notable F1 score of 0.82.  
- Insightful error analysis is provided, enhancing the understanding of model performance.

Weaknesses:  
- Only one medical LLM is trained, which performs worse than LLAMA, likely due to LLAMA's larger training dataset.  
- The inconsistency in performance drops associated with Gambler's Loss is not fully explained.  
- The low AO score raises questions about the reliability of attention as a medium for explanation, and the paper does not address potential limitations in ground truth explanations.  
- The choice of top-k tokens in calculating the AO score is not discussed, nor is there a comparison with other popular explanation methods.  
- The paper lacks clarity regarding the experimental details and model architecture, particularly in the "Making LMs risk-averse with abstention" section.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the experimental details and model architecture to enhance understanding. Specifically, rephrasing the research question regarding the impact of the number of WDs on accuracy would provide clearer insights. Additionally, addressing the reliability of the AO score and discussing the implications of the choice of top-k tokens in the evaluation would strengthen the paper. It would also be beneficial to compare the proposed method with other explanation techniques and clarify the unexpected performance drops associated with Gambler's Loss. Finally, the authors should consider referencing related works that address emotions and well-being to contextualize their findings more effectively.