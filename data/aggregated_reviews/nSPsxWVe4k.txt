ID: nSPsxWVe4k
Title: SLOG: A Structural Generalization Benchmark for Semantic Parsing
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents SLOG, a benchmark dataset designed to evaluate semantic parsers on compositional generalization at the structural level, contrasting with the lexical focus of the previous COGS benchmark. The authors empirically investigate various semantic parsing approaches, revealing that standard transformer models struggle with SLOG, while structure-aware models like the AM-Parser demonstrate differing performance. The extension of COGS includes 17 new phenomena, enhancing evaluation criteria to score semantically equivalent parses as correct.

### Strengths and Weaknesses
Strengths:
- The extension of COGS is nontrivial and thoughtfully constructed, providing a useful resource for researchers.
- The paper is generally well-written, demonstrating a clear understanding of the state of the field and related literature.
- It effectively highlights the limitations of existing models in handling more complex syntactic patterns.

Weaknesses:
- There is insufficient justification for why new unseen patterns are deemed learnable from the training data, particularly regarding recursive forms that may encourage over-generalization.
- The predictive task is not well described, assuming familiarity with COGS, which may confuse readers.
- Many task examples appear to be of theoretical interest only, and the dataset's applicability to languages beyond English is not addressed.

### Suggestions for Improvement
We recommend that the authors improve the justification for the learnability of new unseen patterns, especially concerning recursive forms that may not reflect natural language use. Additionally, clarifying the predictive task and its assumptions about COGS would enhance accessibility for readers unfamiliar with it. A more thorough discussion of the choices made regarding the syntactic patterns, particularly those that may conflict with human generalization capabilities, would also be beneficial. Finally, we suggest considering the inclusion of structured stack-based transduction models to better address recursion in future iterations of the dataset.