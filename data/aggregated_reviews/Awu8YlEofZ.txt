ID: Awu8YlEofZ
Title: GS-Blur: A 3D Scene-Based Dataset for Realistic Image Deblurring
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 10, 6, 7
Original Confidences: 4, 4, 3

Aggregated Review:
### Key Points
This paper presents GS-blur, a method for synthesizing realistic blurry images from clean images by reconstructing 3D scenes through GS and simulating motion blur via a 3D camera trajectory. The authors propose a novel dataset, GS-Blur, created using 3D Gaussian Splatting (3DGS), which features diverse types of blur and generalizes well to real-world scenarios. The method demonstrates superior performance compared to existing deblurring networks, highlighting its potential impact on deblurring tasks.

### Strengths and Weaknesses
Strengths:
1. The paper is well written and easy to follow.
2. Clear motivation with direct real-world impact.
3. The results are significant, demonstrating the superiority of the method over other baselines.
4. The scale of GS-Blur is larger than previous deblurring datasets, with qualitative comparisons showing better data quality.

Weaknesses:
1. The method is limited to video captures, potentially restricting its applicability to single images.
2. Concerns regarding the accuracy of sharp images rendered from a fixed camera position as "ground truth."
3. Lack of in-depth discussion on the scale of the training data and its impact on performance.

### Suggestions for Improvement
We recommend that the authors improve the accuracy of the sharp images used as ground truth by addressing potential inaccuracies in the 3DGS rendering process. Additionally, we suggest providing more detailed explanations regarding the comparison of different datasets, particularly why the GS-Blur dataset yields better performance than real blur datasets. Furthermore, we encourage the authors to conduct ablation studies on the scale of the GS-Blur dataset, as the training of 3DGS is not expensive. Lastly, the authors should consider addressing the potential influence of floating points on the quality of GS-Blur during novel view synthesis.