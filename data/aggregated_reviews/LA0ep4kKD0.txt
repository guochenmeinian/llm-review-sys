ID: LA0ep4kKD0
Title: How new data pollutes LLM knowledge and how to dilute it
Conference: NeurIPS
Year: 2024
Number of Reviews: 4
Original Ratings: 6, 5, 8, 7
Original Confidences: 3, 3, 4, 3

Aggregated Review:
### Key Points
This paper presents an investigation into how new texts impact the existing knowledge of large language models (LLMs). The authors propose a priming metric that quantifies the influence of new data on specific token probabilities and introduce a dataset called "Outlandish" to explore priming behavior. They empirically validate two methods to mitigate priming effects: ignoring the top-k% of gradient updates and a text-augmentation strategy that utilizes knowledge of keywords.

### Strengths and Weaknesses
Strengths:
- The framing of the study on how new data affects LLM knowledge is highly relevant.
- The metrics are operationalized and straightforward, facilitating application in other research.
- The paper is well-organized, clearly written, and supported by comprehensive experiments.

Weaknesses:
- The paper does not apply or compare any continual learning algorithms or benchmarks, nor does it reference relevant works in the Related Work section.
- Many design choices in dataset creation are unclear, raising questions about the appropriateness of selected categories and the representativeness of the keywords.
- The training process descriptions contain unclear phrases and lack detailed explanations of model behavior and training dynamics.
- Justifications for model choices and the proposed strategies are underdeveloped, limiting the understanding of their generalizability.

### Suggestions for Improvement
We recommend that the authors improve the paper by incorporating continual learning algorithms and benchmarks to enhance relevance. Clarifying the dataset creation process and providing a rationale for the chosen categories would strengthen the paper's foundation. Additionally, we suggest that the authors elaborate on the training process and provide clearer definitions of terms used. Justifying the model choices and exploring the theoretical underpinnings of the proposed strategies would also enhance the paper's robustness. Finally, addressing minor typographical errors and considering connections to practical use-cases would further enrich the work.