ID: GprvtTwOxy
Title: Unlearn What You Want to Forget: Efficient Unlearning for LLMs
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for handling unlearning requests in large language models (LLMs) by introducing unlearning layers that freeze the model's parameters while allowing for the tuning of these layers to forget specific data. The authors propose a fusion mechanism to integrate multiple unlearning layers trained through a sequence of requests. Experiments demonstrate significant improvements with the proposed efficient unlearning method (EUL) across both classification and generation tasks.

### Strengths and Weaknesses
Strengths:
- The paper addresses a timely and relevant topic in machine unlearning, which is underexplored.
- The proposed method is straightforward, effective, and beneficial for removing sensitive or mislabeled data without retraining the entire model.
- Clear motivation and methodology, with reasonable experimental design showing the effectiveness of the EUL.

Weaknesses:
- The effectiveness of the fusion mechanism remains unevaluated in experiments.
- The method is validated only on specific models (T5-base and T5 3b), lacking comparisons with larger LLMs like LLAMA.
- Insufficient evaluation metrics, particularly regarding privacy concerns, such as Membership Inference Attack (MIA).
- The paper does not address whether the model can recall previously forgotten content or if forgotten data becomes identifiable.

### Suggestions for Improvement
We recommend that the authors improve the evaluation of the fusion mechanism in experiments to validate its effectiveness. Additionally, conducting experiments on larger LLMs, such as LLAMA, would provide essential insights into the scalability of the proposed method. It is crucial to include metrics like MIA to assess the model's performance on unlearning privacy-related data. Furthermore, the authors should clarify the architecture of the unlearning layers and provide time series results for the sequence of forgotten requests to demonstrate the model's ability to maintain privacy over time. Lastly, enhancing the technical writing and addressing the consistency of terminology would improve the overall clarity of the paper.