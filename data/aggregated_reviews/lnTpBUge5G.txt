ID: lnTpBUge5G
Title: Sample Complexity for Quadratic Bandits: Hessian Dependent Bounds and Optimal Algorithms
Conference: NeurIPS
Year: 2023
Number of Reviews: 7
Original Ratings: 6, 7, 4, 5, -1, -1, -1
Original Confidences: 3, 3, 3, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on Quadratic Hessian bandits, establishing both lower and upper bounds on algorithm performance to characterize simple regret. The authors propose an algorithm that operates independently of Hessian knowledge. Additionally, the paper explores quadratic stochastic zeroth-order optimization, providing asymptotically tight bounds on minimax simple regret and demonstrating the existence of a universally optimal algorithm. The analysis includes matching sample complexity bounds for black-box optimization of quadratic functions, dependent on the PSD matrix.

### Strengths and Weaknesses
Strengths:  
- The paper addresses a novel problem in quadratic bandits, offering a complete characterization of simple regret.  
- It provides tight upper and lower sample complexity bounds that are instance-dependent, recovering previous results.  
- The results remain valid even for heavy-tailed noise distributions, aided by a truncation method.  

Weaknesses:  
- The writing lacks flow, with proofs appearing disorganized, making comprehension difficult.  
- The clarity of Theorem 2.1 is insufficient, as it does not explicitly state the lower bound.  
- The proposed algorithm requires extensive problem-related knowledge, limiting its practicality.  
- There is no experimental evaluation to support the theoretical claims.  
- The motivation for solving black-box optimization of quadratic functions is unclear, and the focus may be too narrow.

### Suggestions for Improvement
We recommend that the authors improve the writing for better flow and coherence, ensuring that proofs are self-contained and accessible. Specifically, the proof of Theorem 2.1 should include all intermediate steps or cite relevant results, such as the MMSE estimator. Additionally, clarify the statement of Theorem 2.1 to explicitly include the lower bound and enhance the phrasing of Theorem 2.4 to highlight the algorithm's independence from Hessian knowledge. We also suggest defining terms like "energy allocation" and "Truncated Diff" formally, and consider exploring more efficient joint estimators for $A$ that leverage its positive semi-definiteness. Lastly, we encourage the authors to include experimental evaluations to demonstrate the practical applicability of their results.