ID: 3R7Go6WkDm
Title: Post-Hoc Reversal: Are We Selecting Models Prematurely?
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 7, 5, 5, -1, -1
Original Confidences: 3, 3, 4, -1, -1

Aggregated Review:
### Key Points
This paper presents empirical evidence that common model selection approaches can be enhanced by less greedy alternatives, particularly through a phenomenon termed *post-hoc reversal*. The authors highlight that post-training transformations, such as temperature scaling, weight averaging, and ensembling, can reverse trends observed in independent training runs, particularly in overfitting scenarios. These transformations not only mitigate growing test error trends but also narrow the generalization gap, leading to smoother error curves. The authors propose incorporating these post-training transforms into the model selection pipeline, yielding improved performance across various settings. They attribute post-hoc reversal to the high variance in neural network training, which can be mitigated by the studied transformations.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and addresses a highly relevant practical problem.
- It features a broad evaluation across multiple model classes, sizes, and data modalities.
- The conclusions provide clear, actionable recommendations for enhancing model selection.

Weaknesses:
- The notation-heavy presentation may hinder readability, although this is primarily a stylistic concern.
- The empirical assessment largely focuses on a limited scale involving variations of the CIFAR-10 dataset and smaller neural networks, which may weaken the strength of the evidence.
- The experiments predominantly examine multi-epoch training settings, raising questions about the applicability to common pre-training scenarios with fewer epochs.
- The analysis lacks consideration of robustness, particularly regarding the performance of post-hoc reversal when the test set differs from the validation set.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their presentation by reducing the reliance on heavy notation to enhance readability. Additionally, consider replicating a subset of results on larger datasets, such as ImageNet, to strengthen empirical evidence. Address the applicability of post-hoc selection in non-multi-epoch training situations and clarify whether post-hoc reversal occurs when the test set is shifted relative to the validation set. Finally, providing insights into the reasons behind the observed improvements in noisy settings would enhance the theoretical understanding of the results.