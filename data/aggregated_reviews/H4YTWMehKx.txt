ID: H4YTWMehKx
Title: GatorTron and GatorTronGPT: Large Language Models for Clinical Narratives
Conference: AAAI
Year: 2024
Number of Reviews: 4
Original Ratings: 7, 5, 8, 6
Original Confidences: 4, 4, 3, 3

Aggregated Review:
### Key Points
This paper presents an overview of the GatorTron Foundational Model and GatorTronGPT, both trained on clinical data, which is highly relevant for the workshop. The authors summarize the models' performances on clinical NLP benchmark tasks and discuss their applications in a clinical context. However, the paper lacks clarity regarding the methodological novelty and performance improvements of the proposed models.

### Strengths and Weaknesses
Strengths:
- The writing is generally clear and easy to understand.
- The training of billion-parameter LLMs on extensive datasets is a significant technical achievement.
- The performance on various benchmarks is strong and relevant to the symposium.

Weaknesses:
- The performance ranking complicates the visualization of the model's actual performance; more fine-grained evaluation metrics, such as accuracy for QA and precision and recall for extraction tasks, are needed.
- The selection process of cited studies is ambiguous, raising questions about the systematic review of evidence.
- There is no comparison with state-of-the-art general LLMs, which would strengthen the hypothesis regarding the inclusion of clinical notes in training data.
- The rationale for training from scratch rather than fine-tuning a pre-trained model is unclear, especially given the smaller training corpus compared to open-source models.
- The paper lacks a section on ethical considerations related to the use of clinical notes.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the performance metrics by including more fine-grained evaluation metrics. Additionally, a direct comparison with general-purpose models like ChatGPT would enhance the argument regarding the benefits of specialized training. The authors should clarify the rationale for training from scratch and consider discussing the ethical implications of using clinical data. Finally, including details on the compute required for training and providing links to open-source model weights or training code would aid reproducibility.