ID: voG6nEW9BV
Title: Conditional score-based diffusion models for Bayesian inference in infinite dimensions
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 7, 8, 6, 8, 6, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 3, 3, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for learning the posterior distribution in infinite-dimensional Bayesian linear inverse problems using amortized conditional Score-based Diffusion Models (SDMs). The authors extend conditional SDMs into infinite-dimensional function spaces, addressing a gap in existing literature that primarily focuses on finite-dimensional vector spaces. The key technique involves defining the conditional score in this infinite setting, which allows for avoiding costly proximal optimization steps. The authors provide a comprehensive theoretical analysis, demonstrating the convergence of the reverse SDE to the target distribution and establishing conditions for uniform time estimates of the conditional score. They validate their approach through a toy experiment that approximates non-Gaussian multi-modal distributions.

### Strengths and Weaknesses
Strengths:
- The paper makes a novel contribution to diffusion model literature by extending conditional SDMs into infinite-dimensional spaces, enabling broader applications.
- It provides a rigorous theoretical framework, including the consistency of the conditional denoising estimator and conditions for successful application of the score-based diffusion model.
- The writing is generally clear and well-organized, making complex concepts accessible.

Weaknesses:
- The experimental validation is limited, relying on a simple one-dimensional toy model without comparing against established baselines, such as the discretization-based approach or the proximal optimization method by Pidstrigach.
- The paper lacks a thorough discussion of potential applications beyond PDEs and does not adequately motivate the relevance of inverse problems in Hilbert spaces.

### Suggestions for Improvement
We recommend that the authors improve the experimental section by including comparisons with the discretization-based approach and the proximal optimization method to substantiate claims of efficiency and performance. Additionally, we suggest expanding the introduction to include a broader range of applications for their method beyond PDEs. In the conclusion, we encourage the authors to reflect on the strengths and weaknesses of their approach and discuss potential future directions. Clarifying the differences between their method and Gaussian processes, as well as addressing the implications of the conditional score's singular behavior at small times, would enhance the paper's depth. Finally, including a "Limitations and Broader Impacts" statement would provide a more comprehensive view of the work's implications.