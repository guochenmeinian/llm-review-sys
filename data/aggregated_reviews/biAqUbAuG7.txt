ID: biAqUbAuG7
Title: Adam on Local Time: Addressing Nonstationarity in RL with Relative Adam Timesteps
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 4, 6, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a modification to the Adam optimizer, termed Adam-Rel, aimed at addressing the issue of large updates in non-stationary environments typical in reinforcement learning. The authors propose resetting the timestep parameter at each target network update in algorithms like PPO and DQN. This approach is validated through experiments in Atari and Craftax environments, demonstrating performance improvements over standard Adam. Additionally, the paper provides empirical results evaluating DQN with Adam and Polyak averaging against DQN with Adam-Rel and Polyak averaging in the Atari-10 setting. The results indicate that while the method yields a lower average score, it demonstrates the applicability of Polyak averaging. The authors argue that their empirical evaluations exceed the standards set by previous top conference submissions, addressing concerns about the thoroughness of their experiments and the multifaceted nature of optimization in reinforcement learning.

### Strengths and Weaknesses
Strengths:
- The proposed method is simple and easy to implement, facilitating potential wide adoption.
- The paper provides a clear introduction to the problem and offers theoretical justification for the proposed solution.
- Extensive evaluation benchmarks suggest applicability across various problems.
- The authors provide new experimental results that extend their method to Polyak averaging, demonstrating its applicability.
- They effectively argue that their empirical evaluations surpass those of similar past research, justifying their approach to optimization in reinforcement learning.

Weaknesses:
- The paper lacks depth in its analysis, particularly regarding the momentum estimates and their correlation with gradient errors.
- Limited comparison with related methods, especially those like Adam with $\beta_1 = \beta_2$, raises questions about the novelty and robustness of the findings.
- Writing quality could be improved, particularly in the mathematical explanations and terminology used.
- The results show lower average scores, which may raise concerns about the effectiveness of Polyak averaging in the Atari setting.
- The paper may not fully address the reviewers' expectations for a broader range of algorithms and domains to validate the generalizability of the proposed technique.

### Suggestions for Improvement
We recommend that the authors improve the depth of analysis regarding momentum estimates and their relationship with gradient errors to provide clearer insights. Additionally, a more comprehensive comparison with methods like Adam with $\beta_1 = \beta_2$ is necessary to strengthen the contribution of this work. Enhancing the clarity of mathematical terms and providing pseudocode for Adam-Rel with DQN would also benefit the paper. Furthermore, we suggest improving the empirical evaluation by including a wider variety of algorithms and environments to strengthen the generalizability of their findings. Finally, clarifying the implications of the lower average scores in the context of Polyak averaging could enhance the paper's impact.