ID: LZq3crn3Bv
Title: Cross-Lingual Cross-Target Stance Detection with Dual Knowledge Distillation Framework
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to stance detection, specifically focusing on cross-lingual and cross-target scenarios. The authors propose a knowledge distillation method utilizing two teacher models—one for language transfer and another for stance target transfer—to train a student model. The experiments demonstrate that their method outperforms various baselines when transferring from German training data to French and English test data.

### Strengths and Weaknesses
Strengths:
- The proposed cross-lingual cross-target stance detection task is novel and intriguing for researchers.
- The experimental design is well-structured, showcasing the effectiveness of the method.
- The approach addresses a relevant task and is supported by empirical results.

Weaknesses:
- The complexity of the method may hinder its adaptability to other tasks or settings.
- The reliance on a validation set in the target language for hyperparameter optimization contradicts the zero-shot assumption.
- The introduction contains exaggerated claims regarding the novelty of the contribution and lacks precision in discussing related work.
- The experiments are limited to two stance classification datasets, and the correlation between text and images is insufficient.

### Suggestions for Improvement
We recommend that the authors improve the clarity of model descriptions and define all notations clearly. Additionally, we suggest including sections on case studies and error analysis, which are essential in high-quality research. The authors should also consider expanding their evaluation to include more stance labels and datasets, as well as addressing the computational complexity of their approach. Finally, we advise revising the introduction to accurately reflect the contributions and context of related work.