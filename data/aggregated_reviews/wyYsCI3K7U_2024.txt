ID: wyYsCI3K7U
Title: LoRANN: Low-Rank Matrix Factorization for Approximate Nearest Neighbor Search
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 7, 5, 8, 6, -1, -1, -1
Original Confidences: 5, 3, 1, 3, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for approximate nearest neighbor (ANN) search that utilizes low-rank matrix factorization and k-means clustering to enhance computational efficiency. The authors propose a novel approach that approximates the ordinary least squares solution of inner product computations through reduced-rank regression. Extensive experiments demonstrate that the proposed method, LoRANN, outperforms existing algorithms in terms of speed and accuracy, particularly in high-dimensional data contexts.

### Strengths and Weaknesses
Strengths:
- The proposed method is straightforward and effective for supervised dimensionality reduction in ANN search.
- Extensive experimental results indicate that LoRANN outperforms leading product quantization-based algorithms and shows competitive query times against graph-based methods.
- The paper is generally easy to read, with clear arguments.

Weaknesses:
- The novelty of the method is minimal, as many techniques used are already established in the field.
- The experimental setup conflates the effects of clustering and score computation, making it difficult to isolate the contributions of LoRANN.
- The visual presentation of the results could be improved for better clarity and consistency.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their presentation by focusing on the core contributions related to the score computation phase in clustering-based ANN search, minimizing distractions from clustering details. Theorem 1 should be reconsidered for relevance, possibly moving it to the appendix. 

In terms of methodology, we suggest exploring a ranking formulation instead of a uniform regression approach, as this could leverage existing literature on learning-to-rank. 

For the experimental evaluation, we recommend partitioning the data once to fairly compare LoRANN against other IVF methods, ensuring that the effects of clustering and dimensionality reduction are not conflated. Additionally, consider comparing a variant of LoRANN trained solely on data points without training queries, and incorporate query distribution into Scann for a more balanced comparison. 

Lastly, we encourage the authors to analyze the reasons behind the varying performance of LoRANN at different recall levels and to enhance the visual presentation of results for better comparison across methods.