ID: URrUpcp6Qh
Title: PAC-Bayes Generalization Certificates for Learned Inductive Conformal Prediction
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 3, 5, 6, 6, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 3, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach that combines Inductive Conformal Prediction (ICP) with PAC-Bayes theory to derive generalization bounds for both coverage and efficiency of prediction sets. The authors propose an algorithm that optimizes nonconformity score functions using calibration data, ensuring efficient predictions without requiring a separate hold-out dataset. Empirical results demonstrate that the proposed method outperforms traditional ICP and learned ICP baselines in various scenarios.

### Strengths and Weaknesses
Strengths:
- The paper introduces original generalization bounds on coverage and efficiency, contributing to the theoretical landscape of ICP.
- The proposed algorithm is mathematically rigorous and well-supported by theorems, enhancing its credibility.
- The structure of the paper is clear, effectively presenting theoretical foundations followed by practical algorithm details.

Weaknesses:
- The benefit of the efficiency bound in Theorem 2 is unclear, particularly regarding its algorithmic advantages.
- The use of PAC-style ICP as a baseline raises questions about its tightness, as previous work suggests tighter alternatives.
- The claim of utilizing "the entire calibration dataset" is misleading since the proposed method still requires splitting the dataset for prior learning.
- The nonconformity score function used in regression is criticized for being weak and not adequately capturing per-sample uncertainty.

### Suggestions for Improvement
We recommend that the authors improve clarity on the algorithmic benefit of the efficiency bound in Theorem 2. Additionally, if the authors utilize the tighter PAC-style ICP (Proposition 2b from Vovk [2012]), they should clarify whether the standard ICP and learned ICP baselines could outperform the proposed approach. We also suggest that the authors provide a clearer explanation of the benefits of PAC-Bayes in achieving efficient prediction sets, particularly in relation to the necessity of splitting calibration data. Furthermore, we advise the authors to consider using a variance-normalized score function to better capture uncertainty and potentially enhance the performance of the standard ICP, as this could lead to a more robust comparison against the proposed method.