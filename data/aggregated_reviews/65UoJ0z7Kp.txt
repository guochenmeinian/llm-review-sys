ID: 65UoJ0z7Kp
Title: SeTAR: Out-of-Distribution Detection with Selective Low-Rank Approximation
Conference: NeurIPS
Year: 2024
Number of Reviews: 26
Original Ratings: 6, 5, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents SeTAR, a novel training-free method for out-of-distribution (OOD) detection that utilizes selective low-rank approximation of weight matrices in vision-language and vision-only models. SeTAR enhances OOD detection by modifying the model's weight matrices through a greedy search algorithm. The authors also introduce SeTAR+FT, a fine-tuning extension aimed at further optimizing OOD detection performance. Experimental results indicate that SeTAR outperforms existing methods on CLIP-specific benchmarks and demonstrates broad effectiveness across various architectures, including CLIP, Swin, and CNN models. The authors emphasize that existing sparsification-based CNN methods, such as ReAct and ASH, are limited in their applicability to CLIP due to their reliance on distinct activations from in-domain data. In contrast, SeTAR can enhance CLIP's zero-shot OOD detection capabilities and provides a systematic analysis of greedy search strategies compared to existing methods like LASER.

### Strengths and Weaknesses
Strengths:
1. The paper introduces a unique training-free method for enhancing OOD detection, representing a significant contribution to the field.
2. SeTAR achieves state-of-the-art performance across multiple architectures and OOD detection tasks.
3. Comprehensive ablation studies and sensitivity analyses provide insights into the robustness and generalizability of the proposed approach.
4. The method is highly compatible with various score functions and model backbones, enhancing its applicability.
5. Extensive empirical evaluations across multiple benchmarks demonstrate the effectiveness of SeTAR and SeTAR+FT.
6. SeTAR is lightweight and efficient, requiring no additional training, making it practical for real-world applications.

Weaknesses:
1. The performance improvements of SeTAR (SeTAR+FT) appear limited compared to MCM and GL-MCM, with notable gains primarily observed on specific models like Swin-T.
2. The performance of SeTAR compared to methods like CLIPN and NegLabel raises concerns about its relative effectiveness.
3. There is a lack of theoretical analysis explaining the effectiveness of SeTAR, which is essential for advancing the method.
4. The optimal hyperparameters (Î» and K) vary significantly across different backbones, complicating practical OOD detection scenarios without extensive hyperparameter tuning.
5. The reliance on the loss function (Eq. 11) may limit the method's applicability, particularly in CNNs, and comparisons with sparsification-based methods are insufficient.
6. The improvements in CNN models are not as pronounced, which may limit its perceived impact in those areas.

### Suggestions for Improvement
We recommend that the authors improve the clarity of performance metrics, particularly regarding the computation of FPR95 values, to avoid confusion. Additionally, we suggest including results on near-OOD detection in the main text to address the more challenging and realistic aspects of OOD detection. The authors should also provide a theoretical analysis to justify the effectiveness of SeTAR and explore its application to CNN-based models, including comparisons with previous methods. Furthermore, we recommend improving the clarity of the distinctions and innovations in their approach, particularly regarding the limitations of traditional sparsification methods. Lastly, expanding the discussion of related works on OOD detection in computer vision and a discussion on the stability and convergence of the greedy search algorithm would enhance the robustness of the findings.