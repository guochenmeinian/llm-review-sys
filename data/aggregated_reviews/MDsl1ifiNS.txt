ID: MDsl1ifiNS
Title: Robust Offline Active Learning on Graphs
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 5, 6, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 2, 4, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an offline active learning method that selects nodes for querying by integrating information from both network structure and node covariates. The authors establish a theoretical relationship between generalization error and the number of nodes selected, demonstrating the method's effectiveness through extensive experiments on synthetic and real-world datasets.

### Strengths and Weaknesses
Strengths:
- The theoretical analysis is robust, providing guarantees that indicate superiority over random sampling (Theorem 2) and characterizing the error rate achievable with this active semi-supervised learning strategy (Theorem 3).
- The proposed method is novel, clearly explained, and easy to implement, with empirical evaluations showcasing its robustness and effectiveness.

Weaknesses:
- The experimental section lacks depth, as it primarily relies on datasets like Cora, which are insufficient compared to larger-scale datasets used in recent works on graph active learning.
- The empirical analysis does not convincingly demonstrate that the proposed method outperforms the considered baselines, and the figures lack confidence intervals or error bars.
- The paper does not adequately position itself within the existing literature on active learning and active semi-supervised learning on graphs, lacking a related work section.
- Clarity in Section 3 could be improved by reducing unnecessary symbols and providing more intuitive descriptions of the steps involved.

### Suggestions for Improvement
We recommend that the authors improve the experimental section by including detailed results on additional datasets, particularly larger-scale ones, to enhance the robustness of their findings. It would be beneficial to compare the proposed method against a broader range of active learning baselines from the graph learning literature. Furthermore, we suggest adding a related work section to clarify the paper's positioning within the existing literature. To enhance clarity, consider simplifying Section 3 by minimizing the use of symbols and providing clearer descriptions of the methodology. Additionally, including confidence intervals or error bars in the experimental results would strengthen the empirical analysis.