ID: Xoi31wJ5iI
Title: Seeing is not always believing: Benchmarking Human and Model Perception of AI-Generated Images
Conference: NeurIPS
Year: 2023
Number of Reviews: 28
Original Ratings: 6, 5, 7, 4, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new, large-scale dataset named "Fake2M," which is claimed to be the largest and most diverse dataset aimed at advancing fake image detection research. The authors establish two benchmarks: HPBench, which evaluates human capability to discern fake AI-generated images from real ones, and MPBench, which includes 11 fake validation datasets for assessing model capabilities in identifying fake images generated by advanced generative models. The dataset comprises 2M training and 257K evaluation images based on the latest generative models, covering various generation paradigms. The authors also propose significant enhancements to the dataset, including improved visualizations, detailed comparisons with existing datasets, and comprehensive analyses of dataset quality. They introduce new methods for deepfake detection and provide a public questionnaire to engage the community in human evaluations.

### Strengths and Weaknesses
Strengths:
- The paper is well-motivated and addresses an important issue in society regarding fake images.
- The creation of the dataset is a solid contribution, and the extensive study on human capability and AI algorithm proficiency is commendable.
- The introduction of Fake2M as a comprehensive dataset includes a diverse range of image types and generation models.
- The establishment of new benchmarks (MPBench and HPBench) provides valuable insights into model performance and human detection capabilities.
- The authors have made substantial revisions based on reviewer feedback, enhancing clarity and comprehensiveness.
- The inclusion of detailed dataset visualizations and comparisons aids in understanding the dataset's utility.
- The introduction of new methods and a public questionnaire fosters community engagement and further research.

Weaknesses:
- The dataset/benchmark website is poorly operated, with insufficient documentation on data collection, organization, and maintenance.
- Limited description of the Fake2M dataset in the main paper, focusing more on benchmarks rather than the dataset itself.
- Concerns about the credibility of HPBench due to a limited number of participants and lack of diverse backgrounds.
- The dataset lacks comparison with existing datasets, making claims of being the "largest and most diverse" less convincing.
- Quality control is necessary to ensure the dataset's representativeness and image quality.
- There are concerns about the dataset's applicability for specific categories of fake image detection, particularly regarding face images.
- Some reviewers remain skeptical about the dataset's overall utility given the potential for unlimited image generation from generative models.

### Suggestions for Improvement
We recommend that the authors improve the dataset/benchmark website and enhance the documentation to include detailed information on data collection, organization, and maintenance. Additionally, the authors should provide a more comprehensive description of the Fake2M dataset, including themes, generation processes, and typical images. It would be beneficial to explore cases where humans frequently misidentify real versus AI-generated images and investigate the potential benefits of ensemble learning. The authors should also consider making the questionnaire publicly available to enhance the credibility of the study and address the limited number of participants in HPBench. Furthermore, we suggest that the authors improve the description of the dataset collection pipeline, including the prompts used and categories of images, to enhance transparency. To address concerns about the representativeness of the dataset, we recommend incorporating additional generative models and configurations in future updates. Lastly, we encourage the authors to expand their human evaluation sample size and create subsets for different model types and object categories to strengthen the reliability of their conclusions and enhance the dataset's relevance for specific research interests.