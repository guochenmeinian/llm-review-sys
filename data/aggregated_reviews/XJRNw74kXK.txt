ID: XJRNw74kXK
Title: POSQA: Probe the World Models of LLMs with Size Comparisons
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new dataset (POSQA) aimed at assessing the knowledge of Large Language Models (LLMs) regarding the physical sizes of various real-world objects. The authors constructed pairwise questions, categorized into "General Questions" and "Specific Questions," to evaluate LLM performance. They enhanced prompts with in-context demonstrations and introduced variations through perturbations in the quality of information. Experimental results indicate that while models like GPT3.5-Turbo achieve high accuracy with gold size information, they still lag behind human knowledge. The study also explores the alignment of LLM knowledge with human understanding, although this aspect is only briefly addressed.

### Strengths and Weaknesses
Strengths:
- The dataset is novel and well-designed, filling a gap in the literature on LLMs and size comparison.
- The methodology and evaluation metrics are detailed, allowing for systematic testing of LLMs.
- The findings regarding LLMs' reliance on context versus internal weights are significant and suggest avenues for future research.

Weaknesses:
- The analysis of LLM alignment with human comprehension is limited and lacks depth.
- Several grammatical errors may hinder comprehension, particularly for non-native English speakers.
- The dataset link is inactive, preventing verification of claims.

### Suggestions for Improvement
We recommend that the authors improve the analysis of the experiment comparing LLMs' knowledge to human understanding to provide deeper insights into alignment or disparities. Additionally, addressing the grammatical errors identified in the presentation improvements section is crucial for clarity. We also suggest ensuring the dataset link is active for verification purposes. Furthermore, including sensitivity analyses on prompts and parameters, as well as the human annotation process, would enhance the robustness of the findings. Finally, providing specific examples of prompts and clarifying the human response data would strengthen the paper's contributions.