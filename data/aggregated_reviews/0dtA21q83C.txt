ID: 0dtA21q83C
Title: DeNetDM: Debiasing by Network Depth Modulation
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 6, 6, 5, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a theoretical framework demonstrating that samples with spurious correlations reside on a lower rank manifold, with the depth of a network serving as an implicit regularizer for the rank of the attribute subspace. The authors propose a method, *DeNetDM*, which utilizes a biased strong encoder (deep network) and a debiased weak encoder (shallow network) to train a final strong encoder that is debiased. The method shows improved performance over existing baselines across various datasets, including CMNIST, C-CIFAR10, BAR, and BFFHQ.

### Strengths and Weaknesses
Strengths:
- The theoretical characterization is intuitive and confirms that examples with spurious attributes lie on a lower-dimensional manifold, making it a significant contribution.
- The empirical validation through synthetic experiments supports the theoretical claims.
- The proposed method effectively outperforms prior work, demonstrating its practical applicability.

Weaknesses:
- The empirical evaluation relies on non-standard datasets, lacking common benchmarks like Waterbirds and CelebA, and could benefit from including newer datasets such as UrbanCars and SpuCoAnimals.
- There is insufficient discussion of similarities with related works, particularly in comparing the proposed method with approaches that address bias in deep networks.
- The analysis of network depth's impact on learning different ranks is limited to CMNIST, necessitating further experiments on other datasets.
- The necessity of a deep biased branch is questioned, as shallower layers could also capture core and spurious features effectively.

### Suggestions for Improvement
We recommend that the authors improve the empirical evaluation by incorporating standard datasets such as Waterbirds and CelebA, as well as newer challenging datasets like UrbanCars and SpuCoAnimals. Additionally, we suggest enhancing the discussion of related work by comparing the proposed method with similar approaches to clarify its contributions. Expanding the empirical analysis to include various benchmark datasets beyond CMNIST would strengthen the validity of the findings. Lastly, we encourage the authors to explore the potential benefits of a shallower biased branch and clarify the necessity of the two-stage training process.