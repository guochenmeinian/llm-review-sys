ID: qw9N1ObLR2
Title: Lexically-constrained automated prompt augmentation: A case study using adversarial T2I data
Conference: NeurIPS
Year: 2024
Number of Reviews: 2
Original Ratings: 6, 7
Original Confidences: 3, 4

Aggregated Review:
### Key Points
This paper presents an innovative approach to augmenting datasets for evaluating the safety of text-to-image (T2I) models. The authors recognize that T2I models can generate harmful images through careful or erroneous prompting, and existing datasets for studying this issue are limited. To address this, they propose augmenting the Adversarial Nibbler Challenge dataset, which contains 1,241 human-generated prompts, by combining human-generated adversarial prompts with automated techniques. Their method aims to create a more comprehensive and scalable dataset while maintaining realism. The authors employ multiple evaluation techniques, including correcting typographical errors and replacing trigger words with synonyms, providing both quantitative and qualitative analyses of their results. They demonstrate thoroughness in their approach, although manual inspection reveals limitations in automated safety classifiers. The study utilizes the same T2I model suite as Quaye et al., including Dall-E-2 and variations of Stable Diffusion, but it would be beneficial to assess newer models. The authors acknowledge the preliminary nature of their results and the subjective nature of image safety, including appropriate content warnings.

### Strengths and Weaknesses
Strengths:  
- The combination of human creativity and automated lexical constraints to scale adversarial prompt generation is novel.  
- The paper evaluates the effectiveness of augmented adversarial prompts using both Typographical Errors and Semantic Ambiguity strategies, which are comprehensive.  

Weaknesses:  
- The dataset could be expanded for more robust results.  
- There is a need for deeper analysis and theoretical discussion around semantic ambiguity and its broader impact on T2I models.  
- Additional attack strategies beyond typographical errors and semantic ambiguity should be explored.  
- Incorporating more sophisticated safety classifiers for detecting bias and hate in generated images would strengthen the analysis.  
- Conducting user studies to validate the effectiveness of the augmented prompts in real-world scenarios would enhance the paper's impact.  

### Suggestions for Improvement
We recommend that the authors improve the dataset by expanding its size and exploring additional attack strategies beyond typographical errors and semantic ambiguity. We also suggest providing a deeper analysis and theoretical discussion around semantic ambiguity and its broader impact on T2I models. Incorporating more sophisticated safety classifiers, particularly for detecting bias and hate in generated images, would strengthen the analysis. Finally, conducting user studies to validate the effectiveness of the augmented prompts in real-world scenarios would enhance the paper's impact.