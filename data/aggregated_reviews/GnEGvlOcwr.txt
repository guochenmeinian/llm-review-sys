ID: GnEGvlOcwr
Title: Error Detection for Text-to-SQL Semantic Parsing
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a semantic error detection approach for text-to-SQL semantic parsers, which includes (a) a method for generating a cross-domain error detection dataset, (b) a model for error detection, and (c) a comprehensive study on error detection in text-to-SQL parsing. The authors collect errors using weak versions of base parsers and employ an encoder based on CodeBERT, integrating outputs from graph models that analyze both natural language and SQL. The model is fine-tuned with cross-entropy loss, and results indicate that it outperforms baseline methods. The paper also explores cross-parser generalization and reranking of beam results across different parsers.

### Strengths and Weaknesses
Strengths:
- The paper addresses an increasingly important task in the community, given the rise of text-to-SQL parsers.
- It reports strong experimental results and includes extensive experimentation across various scenarios relevant to error detection.
- The action triggering experiment provides a practical perspective on parser errors.
- The writing is clear and accessible.

Weaknesses:
- The chosen base models are not among the strongest, as they rank below 15th on the Spider leaderboard.
- The generalizability of the cross-domain data generation method to other datasets is unclear.
- The reranking results with SmBoP are suboptimal, suggesting potential limitations of the proposed model with stronger parsers.
- The novelty of the error detection model is questioned, as it resembles a semantic matching model.

### Suggestions for Improvement
We recommend that the authors improve the clarity of how dependency and constituency trees are merged and provide explanations for the terms "hit" and "miss." Additionally, we suggest that the authors consider training the proposed model on outputs from multiple parsers and test its performance against stronger baseline models. It would also be beneficial to clarify the implications of the cross-domain data generation method for in-domain evaluations. Lastly, we advise addressing the novelty concerns by highlighting distinct contributions compared to existing reranking approaches.