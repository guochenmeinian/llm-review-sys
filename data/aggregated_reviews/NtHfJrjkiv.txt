ID: NtHfJrjkiv
Title: ReCEval: Evaluating Reasoning Chains via Correctness and Informativeness
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ReCEval, a novel reference-free metric suite for evaluating reasoning chains in QA tasks, focusing on correctness and informativeness. Correctness is assessed through entailment relationships among reasoning content units (RCUs), defined as "subject-verb-object" phrases, while informativeness is measured using the Pointwise Value of Information (PVI). Extensive experiments on the Entailment Bank and GSM-8K datasets demonstrate that ReCEval outperforms existing metrics, including ROSCOE, and validates the effectiveness of its components.

### Strengths and Weaknesses
Strengths:
- The proposed metric is well-motivated and addresses the evaluation of reasoning chains comprehensively by considering multiple dimensions.
- The paper is well-structured, clearly written, and includes extensive experiments, including ablation studies, enhancing its credibility.
- ReCEval shows superior performance compared to previous state-of-the-art methods, indicating its potential for improving downstream reasoning chain generation.

Weaknesses:
- The experimental design is limited to only two datasets, raising concerns about generalization and applicability.
- The method for selecting the best performance metric among the three sub-metrics for correctness is unclear, which may limit ReCEval's practical use.
- The reliance on an external neural network introduces potential instability and irreproducibility, particularly regarding the neural network's ability to detect its own errors.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their findings by including additional datasets in their experiments. Clarifying how the three sub-metrics for correctness are combined into a final score would enhance the applicability of ReCEval. Additionally, we suggest incorporating a large language model baseline to provide a more comprehensive evaluation of the proposed metric. Addressing the concerns regarding the neural network's stability and error detection capabilities, as well as providing detailed calculations for PVI using the T5 model, would strengthen the paper's contributions.