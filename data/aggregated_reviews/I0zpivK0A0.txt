ID: I0zpivK0A0
Title: Terra: A Multimodal Spatio-Temporal Dataset Spanning the Earth
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 7, 6, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Terra, a multimodal spatio-temporal dataset that spans the Earth, incorporating hourly time series data from 6,480,000 grid areas over the past 45 years, along with geo-images and explanatory text. The authors propose that Terra will enhance understanding and forecasting of environmental changes. The dataset's contributions include large scale, fine granularity, and multi-modality. The authors conduct experiments demonstrating its versatility in spatio-temporal forecasting and location-based predictions.

### Strengths and Weaknesses
Strengths:
- The dataset's extensive temporal and spatial coverage ensures robustness and generalizability in research.
- Terra supports fine granularity with up to 3-hourly time intervals and 0.1Â° spatial resolution, facilitating detailed analysis.
- The paper is well-organized, with clear explanations of methodologies and potential applications.
- The multimodal nature enhances originality and utility, addressing a significant gap in existing datasets.

Weaknesses:
- The complexity of the multimodal dataset may pose challenges for researchers in data processing and integration.
- The paper lacks a direct comparison with other datasets at the experimental level.
- There is insufficient discussion regarding the limitations of the dataset and the potential for missing or sparse data over the 45-year span.

### Suggestions for Improvement
We recommend that the authors strengthen the technical details of the proposed approach and provide a more comprehensive discussion on the limitations of the dataset. Additionally, a face-to-face comparison with other datasets at the experimentation level would enhance the paper's contributions. The authors should also consider including more details about the experimental setup, such as data examples and the methodology for generating vision-language prompts. Finally, we urge the authors to release all data publicly as soon as possible or provide a clear rationale for any delays in doing so.