ID: QNUs3Ramad
Title: Adversarial Self-Training Improves Robustness and Generalization for Gradual Domain Adaptation
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 6, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an Adversarial Self-Training (AST) method that integrates adversarial training with gradual self-training to enhance robustness and clean accuracy in gradual domain adaptation scenarios. The authors empirically demonstrate that AST significantly improves both adversarial and clean accuracy on datasets like MNIST and Portraits, while also providing theoretical bounds based on Margin Disparity Discrepancy that offer insights into the method's effectiveness compared to standard self-training.

### Strengths and Weaknesses
Strengths:  
- The empirical results showing AST's ability to enhance clean accuracy are compelling, supported by both theoretical and empirical analyses.  
- The paper is well-organized and clearly written, making the methodology easy to follow.  
- The theoretical analysis, particularly in Section 4.1, is clear and informative, contributing to the understanding of AST's performance.

Weaknesses:  
- The contributions in the Introduction could be summarized more effectively, particularly regarding the experimental findings and theoretical analysis.  
- The assumption of slight distribution shifts may not be realistic, and the experiments are conducted on relatively simple datasets like MNIST and Portraits, which may not adequately demonstrate AST's effectiveness in practical applications.  
- The proposed method appears to lack novelty, being an application of existing methods under gradual domain adaptation.  

### Suggestions for Improvement
We recommend that the authors improve the clarity of the contributions in the Introduction by explicitly summarizing the main findings and theoretical insights. Additionally, conducting experiments on more challenging datasets, such as CIFAR10, and exploring the effects of larger adversarial budgets on clean accuracy would strengthen the validation of AST. We also suggest providing a more detailed discussion on the implications of the assumptions made in the theoretical analysis, particularly regarding Theorem 4.9, and including a discussion of the limitations of the study.