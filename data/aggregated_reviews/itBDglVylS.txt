ID: itBDglVylS
Title: NYU CTF Bench: A Scalable Open-Source Benchmark Dataset for Evaluating LLMs in Offensive Security
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 8, 6, 6, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for assessing the capabilities of Large Language Models (LLMs) in solving cybersecurity Capture the Flag (CTF) challenges by developing an open-source benchmark database. The dataset comprises 200 CTF challenges from various categories, supported by Docker images and JSON files for easy setup. The authors propose a framework for evaluating both open-source and black-box LLMs, providing insights into their performance in tackling these challenges. The paper emphasizes ethical considerations and the potential misuse of LLMs in cybersecurity.

### Strengths and Weaknesses
Strengths:
- The dataset is well-organized and publicly accessible, ensuring clarity and usability for the research community.
- The framework facilitates interaction with a working environment, adding substantial value to the dataset.
- The variety of challenges allows for a comprehensive assessment of LLM capabilities in offensive security.

Weaknesses:
- The dataset's reliance on existing public data may undermine its relevance for assessing LLM capabilities.
- Limited categories and imbalanced sample sizes hinder the dataset's diversity.
- The relationship between Figure 3 and the textual explanations lacks clarity, and the limitations of the dataset are not fully articulated.

### Suggestions for Improvement
We recommend that the authors improve the dataset by incorporating more LLMs for broader skill comparison and adding various CTF-like challenges to enhance diversity. Additionally, we suggest clarifying the scope and application of the dataset, particularly regarding its ability to assess LLMs' command execution capabilities. An extended comparison with related work should be included to emphasize the unique aspects of this research. Finally, we advise addressing the ethical implications of using LLMs in cybersecurity tasks more explicitly, particularly concerning potential misuse.