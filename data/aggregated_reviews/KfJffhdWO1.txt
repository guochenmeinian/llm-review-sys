ID: KfJffhdWO1
Title: Evaluating Evaluation Metrics: A Framework for Analyzing NLG Evaluation Metrics using Measurement Theory
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the application of measurement theory to evaluate the quality of metrics for natural language generation (NLG), specifically focusing on text summarization using the SummEval dataset. The authors propose a framework that systematically analyzes and compares various NLG metrics against a human evaluation baseline, moving beyond mere correlation analysis. The case study includes a thorough examination of both reference-based and reference-free metrics.

### Strengths and Weaknesses
Strengths:  
- The paper offers an interesting framework that addresses the important task of estimating the quality of commonly used metrics.  
- It provides a thorough description of measurement theory and its application, enabling broader use by other researchers.  
- The case study is extensive, featuring a good selection of metrics and clear communication of ideas.

Weaknesses:  
- There is uncertainty regarding the applicability of measurement theory, primarily developed for human evaluation, to automatic metrics.  
- The scope of the case study is limited to summarization, raising questions about generalizability to other tasks.  
- The related work section lacks depth and does not sufficiently discuss prior research on evaluating evaluation metrics.

### Suggestions for Improvement
We recommend that the authors improve the argumentation for the unique benefits of applying measurement theory in this context, particularly regarding its relevance to automatic metrics. Additionally, we suggest expanding the related work section to include a more comprehensive discussion of previous literature, such as Caglayan et al. (2020) and Ni'mah et al. (2023). It would also be beneficial to provide a higher-level conclusion from the case study results, detailing which metrics perform well and why. Lastly, addressing the missing references and typographical errors noted by reviewers will enhance the paper's clarity and completeness.