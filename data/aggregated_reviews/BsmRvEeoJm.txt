ID: BsmRvEeoJm
Title: Gene Pathogenicity Prediction using Genomic Foundation Models
Conference: AAAI
Year: 2024
Number of Reviews: 4
Original Ratings: 5, 7, 7, 5
Original Confidences: 2, 3, 3, 3

Aggregated Review:
### Key Points
This paper presents a benchmarking study of three Genomic Foundation Models (HyenaDNA Tiny, GenaLM, and Nucleotide Transformer) for gene pathogenicity prediction using the ClinVar dataset. The authors propose that the Nucleotide Transformer demonstrates superior generalizability and accuracy due to extensive pretraining on diverse human genomes. However, the manuscript lacks detailed descriptions of fine-tuning and evaluation datasets, making it challenging to interpret results. 

### Strengths and Weaknesses
Strengths:
- The paper provides a well-written and detailed description of prior work in the domain, alongside a rigorous metrics comparison of transformer-based models against traditional models like SNPred.
- The innovative approach of direct genomic sequence classification marks a significant advancement over conventional methods.
- The tSNE embedding visualization effectively illustrates performance gaps between models.

Weaknesses:
- The manuscript is overly focused on background and related work, which should be reduced to allow for more discussion of experiments and results.
- Limited explanation of embeddings fails to distinguish between pathogenic and benign variants adequately.
- The study lacks external validation and comparisons with non-LLM models, which could enhance the evaluation of the proposed models.
- The formatting of tables is inconsistent and could be improved for clarity.

### Suggestions for Improvement
We recommend that the authors improve the manuscript by reducing the background section by at least one page to allocate more space for experimental details and broader discussions of results. Additionally, we suggest providing a table that describes pertinent statistics for fine-tuning and evaluation datasets. To enhance clarity, consider standardizing the formatting of tables and ensuring consistent reporting of significant figures. Furthermore, addressing the limited explanation of embeddings and including comparisons with non-LLM models would strengthen the study's findings. Lastly, exploring computational techniques such as LORA could mitigate resource constraints and broaden model evaluation.