ID: I5BnQIgQIM
Title: From Parse-Execute to Parse-Execute-Refine: Improving Semantic Parser for Complex Question Answering over Knowledge Base
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents state-of-the-art results on the KQA Pro Knowledge Base Question Answering dataset, proposing a novel parse-execute-refine (PER) architecture that enhances the existing parse-execute framework by incorporating a refinement step. The authors demonstrate through an ablation study that this refinement step leads to performance improvements. The paper is well-structured and easy to follow, although it is limited to a single dataset, which the authors acknowledge can be extended to others using existing methodologies.

### Strengths and Weaknesses
Strengths:
- The paper shows clear improvements over existing work using the same benchmark datasets.
- The proposed PER-KBQA approach effectively addresses the deviation problem in neural semantic parsers by refining logical forms with intermediate execution results.
- The experimental design is thorough, validating the efficacy of the approach across various scenarios.

Weaknesses:
- The evaluation is limited to a single dataset, restricting comparisons with a broader range of knowledge base QA work.
- The ideas of alignment and using intermediate results for refinement are not novel and have been explored in prior works, which may undermine the perceived impact of the proposed method.
- The overall technical paradigm appears slightly outdated, lacking discussion on the potential integration of LLMs for parsing and merging tasks.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the novelty of their approach by clearly differentiating it from previous works that have explored similar concepts, such as schema linking and intermediate reasoning. Additionally, we suggest that the authors include a thorough comparison with related work that has focused on similar tasks and datasets to contextualize their contributions better. It would also strengthen the paper to address the impact of using LLMs in the refinement process and to provide insights into the observed decrease in zero-shot performance after refinement. Lastly, clarifying the measurement of accuracy for the parsing-only setup and ensuring consistency in terminology throughout the paper would enhance clarity.