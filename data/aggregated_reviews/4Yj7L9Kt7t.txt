ID: 4Yj7L9Kt7t
Title: Taming Heavy-Tailed Losses in Adversarial Bandits and the Best-of-Both-Worlds Setting
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 6, 7, 6, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 3, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper studies multi-armed bandits (MAB) with heavy-tailed losses, proposing a Best-of-Both-Worlds (BOBW) policy based on the Online Mirror Descent (OMD) and detect-switch framework. The authors present high-probability near-optimal regret bounds applicable to both stochastic and adversarial settings, utilizing Freedman's inequality in their proofs. The work aims to bypass the truncated non-negative losses assumption prevalent in prior studies, specifically addressing the challenges posed by heavy-tailed distributions.

### Strengths and Weaknesses
Strengths:
- The manuscript is clearly written and easy to follow.
- It provides high-probability regret bounds, which are rare in heavy-tailed bandits and BOBW algorithms.
- The proposed policy is novel, effectively combining OMD and a switch-detect policy for heavy-tailed bandits.

Weaknesses:
- The requirement for prior knowledge of parameters $u$ and $v$ limits the algorithm's adaptability compared to existing adaptive algorithms.
- The assumptions made regarding losses are contentious, as they may not be directly comparable to those in previous works, particularly regarding the limitations of achieving lower bounds.
- There are critical errors in the proofs, such as incorrect assumptions in Lemma 2 and inconsistencies in the adversarial setting analysis.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their assumptions regarding the parameters $u$ and $v$, and provide a more thorough comparison with existing adaptive algorithms. Additionally, we suggest addressing the identified proof errors, particularly in Lemma 2 and the adversarial setting, to ensure the correctness of the results. It would also be beneficial to include a table comparing results across different studies for better contextualization. Lastly, we encourage the authors to clarify the computational efficiency of the refined update rule over the truncated simplex.