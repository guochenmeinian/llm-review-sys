ID: B9qg3wo75g
Title: Generative Fractional Diffusion Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 6, 6, 2, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to continuous score-based generative models by utilizing fractional diffusion, where Brownian Motion (BM) is substituted with fractional Brownian Motion (fBM). The authors introduce a Markovian approximation of fBM through the addition of $K$ correlated Ornstein-Uhlenbeck (OU) processes, facilitating tractable learning and inference. They propose an augmented score matching loss that allows a single D-dimensional score model to effectively approximate the full score in $\mathbb{L}_2$. Experiments conducted on MNIST and CIFAR10 validate the method's performance and the impact of hyper-parameters ($K, H$), demonstrating advantages over classical score-based diffusion. However, the authors claim that their approach closely recovers the original model, which the review highlights does not adequately demonstrate marginal improvement. The paper also addresses several technical issues, including the introduction of notation and corrections to equations.

### Strengths and Weaknesses
Strengths:
- The theoretical framework is well-contextualized within the research of fractional Brownian Motion, employing effective techniques to address limitations of prior approaches.
- The introduction of tractable learning and inference methods, along with a D-dimensional score model, is a significant contribution.
- The paper is clearly written, providing necessary background and addressing variance issues effectively.
- The authors have engaged with reviewer feedback and made detailed corrections to technical aspects of the paper, including clarifications on notation and typos.

Weaknesses:
- The empirical study is insufficiently detailed, with performance gains appearing only mildly convincing and lacking clarity regarding hyper-parameter effects.
- The paper does not adequately compare its method with other diffusion approaches across different noise regimes, failing to address limitations of classical models such as slow convergence and mode-collapse.
- The motivation for using fBM over BM is not thoroughly elaborated, and the results lack sensitivity analysis for hyper-parameters $H$ and $K$.
- The authors fail to convincingly demonstrate marginal improvements while controlling for other factors, leading to perceptions of the work as merely a plug-in approach.
- There are inconsistencies in the authors' arguments regarding the subjectivity of their contributions and the reviewer's critiques.

### Suggestions for Improvement
We recommend that the authors improve the empirical study by providing a more comprehensive analysis of performance gains and clearer interpretations of hyper-parameter effects. Including a detailed comparison with other diffusion models addressing their respective advantages and limitations would strengthen the paper. Additionally, we suggest conducting sensitivity analyses on $H$ and $K$ across various datasets to assess the consistency of results. Clarifying the motivation for employing fBM and discussing its implications in the context of the results would enhance the theoretical foundation of the work. Furthermore, we recommend that the authors improve their demonstration of marginal contributions by controlling for training-related parameters and hyper-parameters, as well as addressing all randomness involved. Finally, addressing the limitations of diffusion models mentioned in the abstract, particularly regarding convergence and mode-collapse, through targeted experiments would be beneficial.