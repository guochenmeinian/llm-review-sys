ID: D0gAwtclWk
Title: Rethinking Negative Pairs in Code Search
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Soft-InfoNCE, a weighting mechanism in the contrastive loss (InfoNCE) aimed at mitigating the negative impact of false negatives by assigning low weight scores to estimated false negative pairs. The authors propose three methods for obtaining these weighting scores: 1) lexical matching (BM25), 2) unsupervised learning (SimCSE), and 3) supervised learning (a trained model with InfoNCE). The experimental results on the CodeSearchNet benchmark across six languages demonstrate the effectiveness of Soft-InfoNCE over traditional InfoNCE.

### Strengths and Weaknesses
Strengths:
- The approach is simple yet effective, providing a novel solution to significant issues in contrastive learning for code search models.
- The authors offer thorough theoretical analysis and extensive empirical evidence supporting the effectiveness of Soft-InfoNCE.
- The paper challenges existing assumptions about negative pairs in contrastive learning, potentially inspiring further research.

Weaknesses:
- The work is considered incremental, lacking distinct challenges in the finetuning stage that differentiate it from pre-training.
- Section 4.2 does not adequately explain the theoretical basis for the improved estimation with the incorporation of weighting scores.
- The paper lacks detailed comparisons with other methods and an in-depth analysis of results, including limitations of the Soft-InfoNCE loss function.

### Suggestions for Improvement
We recommend that the authors improve the theoretical explanation in Section 4.2, particularly regarding the implications of incorporating $w_{ij}$ for more precise estimation. Additionally, please address the distinct challenges in the finetuning stage to clarify the novelty of your approach. It would be beneficial to include a more thorough comparison with alternative methods and a detailed analysis of the results, discussing any limitations of Soft-InfoNCE. Furthermore, consider discussing the computational efficiency of the proposed method and its implications for other NLP tasks. Lastly, please enhance the presentation of figures and ensure clarity in the discussion of hyperparameters.