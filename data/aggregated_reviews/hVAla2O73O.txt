ID: hVAla2O73O
Title: A Pseudo-Semantic Loss for Autoregressive Models with Logical Constraints
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 7, 6, 6, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a pseudo-semantic loss for deep generative models with logical constraints, specifically targeting autoregressive generative distributions like RNNs and Transformers. The authors propose an approximation of the likelihood of constraints at a random, local point, termed "pseudolikelihood," which aids in constructing a pseudo-semantic loss. This method demonstrates utility in tasks such as finding the shortest path on Warcraft maps, solving partially filled 9x9 Sudokus, and detoxifying generations from LLMs, with results shown on detoxifying GPT-2.

### Strengths and Weaknesses
Strengths:  
- The problem of incorporating constraints with semantic losses is significant and impacts relevant issues like reducing toxicity.  
- The approximations presented are sound, exhibiting good fidelity and low deviation from ground truth.  
- Experiments across various tasks highlight the method's promise.

Weaknesses:  
- The authors need to provide more examples of constraints and logical circuits, clarifying how the loss encourages the reuse of sub-problems. Figure 2 lacks clarity, particularly regarding the choice of numbers and the computation of probabilities.  
- Scalability of the approach is not adequately discussed, particularly concerning the complexity of circuits.  
- There is a lack of exploration of alternative constraints for toxicity, and the authors should discuss circuit design issues more thoroughly.  

### Suggestions for Improvement
We recommend that the authors improve the clarity of Figure 2 and provide more concrete examples of constraints and logical circuits. Additionally, a more detailed discussion on the scalability of the approach and the complexity of circuits used is necessary. We suggest exploring other constraints for toxicity beyond the initial token avoidance and comparing the proposed method against existing approaches like NeuroLogic in the LLM detoxification task. Lastly, please clarify the title to reflect that the work specifically addresses autoregressive models with logical constraints.