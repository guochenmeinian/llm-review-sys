ID: 35DAviqMFo
Title: Understanding Emergent Abilities of Language Models from the Loss Perspective
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 7, 3, 7, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates the relationship between pre-training loss and downstream performance in language models, arguing that pre-training loss is a more reliable predictor of emergent capabilities than model size or compute. The authors present evidence that models with similar pre-training losses perform comparably across various tasks and define emergent abilities based on a threshold of pre-training loss, below which performance is akin to random guessing. Additionally, the paper analyzes the Brier Score in relation to emergent abilities, specifically addressing the performance of models trained on different corpora. The authors argue that a decrease in Brier Score above 0.75 does not indicate improved performance, as some models perform worse than random guessing. They also contend that the slopes of Brier Score plots vary significantly across models, suggesting that intermediate training dynamics differ from later stages. The authors reject the notion that continuous metrics can fully capture emergent abilities, emphasizing the need for stronger evidence against previous findings.

### Strengths and Weaknesses
Strengths:
- The paper provides a novel perspective by linking emergent abilities to pre-training loss, unifying various factors previously considered separately.
- It presents thorough evaluations across multiple models and tasks, validating findings with existing models like Llama and Pythia.
- The writing is clear, and the experiments are comprehensive, addressing common misconceptions about emergence in language models.
- The analysis of Brier Score effectively highlights differences in training dynamics across models of varying sizes and offers a thorough examination of its implications for emergent abilities.
- The rebuttal addresses reviewer concerns and provides additional results that enhance confidence in the findings.

Weaknesses:
- The evidence supporting the claim that emergent abilities appear suddenly after crossing a specific loss threshold is less convincing, relying on a limited subset of benchmarks.
- The paper does not adequately engage with existing literature that challenges its findings, particularly regarding the relationship between pre-training loss and specialized metrics.
- There are concerns about the clarity of certain discussions, such as the role of data quality and the implications of metric thresholding effects on the interpretation of emergence.
- The evidence presented does not convincingly support the argument that aggregate loss is directly predictive of specific task capabilities.
- The claim that emergent abilities do not arise suddenly is questioned, with suggestions that some tasks may follow a continuous trend instead.

### Suggestions for Improvement
We recommend that the authors improve the discussion of data quality and its potential impact on pre-training loss and emergence points, as this aspect is currently underrated. Additionally, we suggest including results from a broader range of benchmarks, such as those in BigBench, to strengthen the argument regarding the emergence threshold. Clarifying the motivations behind the ablation studies and providing a more detailed qualitative analysis of easier questions that models first answer correctly would enhance the paper's depth. We also recommend improving the clarity of the argument regarding the relationship between aggregate loss and specific task capabilities, providing more robust evidence to support their claims. Conducting higher-resolution sampling on tasks like word unscramble and IPA transliterate could better assess the nature of transitions in performance. Finally, we encourage the authors to compare checkpoints from different model families on the same test set to explore whether similar loss values yield comparable downstream performance across families.