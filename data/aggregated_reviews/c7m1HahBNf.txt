ID: c7m1HahBNf
Title: Exploring Structured Semantic Priors Underlying Diffusion Score for Test-time Adaptation
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 7, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DUSA, a method utilizing diffusion models for test-time adaptation (TTA). The authors propose a framework where class codes are selected based on a pretrained classifier and random sampling, generating noise candidates that are combined according to predicted probabilities. The optimization involves updating both the classifier and diffusion model based on the error between aggregated and ground truth noises, effectively addressing challenges in corrupted images for both classification and segmentation tasks. The results demonstrate significant improvements across various tasks and classifiers.

### Strengths and Weaknesses
Strengths:  
- Figure 1 effectively illustrates the method.  
- The approach is novel, leveraging single time steps and conditional score matching (CSM).  
- Results show substantial improvements across multiple tasks, with reproducibility across different models and hyperparameter settings.  

Weaknesses:  
- The paper does not explore the potential benefits of using multiple time steps, which could enhance the accuracy of approximations.  
- The introduction lacks sufficient motivation for TTA, given its niche status compared to other tasks.  
- The optimization process for the diffusion model's weights is unclear, and the computational overhead is not adequately discussed.  
- The applicability of the method to various discriminative tasks is questionable, particularly regarding the computation of conditionals for segmentation tasks.  
- The title may mislead regarding the algorithm's content, and the term "fresh" is used ambiguously.

### Suggestions for Improvement
We recommend that the authors improve the introduction to better motivate the task of TTA, emphasizing its significance. Additionally, exploring the impact of using more than one time step could provide valuable insights into the method's accuracy. Clarifying the joint update process for the diffusion model and discussing the computational overhead in detail would enhance the paper's rigor. We also suggest integrating the algorithm described in the Appendix into the main body for better coherence and addressing the ambiguity surrounding the term "fresh." Lastly, a comparison of the diffusion model's performance when trained on different datasets would strengthen the analysis.