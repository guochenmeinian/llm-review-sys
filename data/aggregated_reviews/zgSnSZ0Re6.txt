ID: zgSnSZ0Re6
Title: Point Cloud Matters: Rethinking the Impact of Different Observation Spaces on Robot Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 18
Original Ratings: 7, 6, 7, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents OBSBench, a benchmark designed to compare different observation spaces (RGB, RGB-D, and point cloud) in robot learning, particularly focusing on behavior cloning across 125 contact-rich manipulation tasks. The authors conduct extensive experiments to evaluate the impact of these modalities, concluding that point cloud observations offer superior performance and generalization capabilities. The key contributions include the benchmark itself and an open-source software infrastructure, which is the first of its kind aimed specifically at evaluating observation spaces.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and clearly structured, providing a comprehensive study that is timely and relevant to the robot learning community.
- It includes extensive evaluations across various visual encoders and observation modalities, yielding valuable empirical findings.
- The insights on processing point cloud information for robotic manipulation tasks are particularly noteworthy.

Weaknesses:
- A fundamental issue arises from the use of different model architectures for point cloud observations compared to RGB and RGB-D, making it unclear whether performance improvements stem from observation space changes or model architecture differences.
- The study does not introduce novel datasets or tasks, relying instead on existing benchmarks, which limits its contribution to an evaluation study.
- All experiments are conducted in simulated environments, potentially undermining the applicability of findings to real-world scenarios.

### Suggestions for Improvement
We recommend that the authors improve the soundness of their empirical results by ensuring that the same model architectures are used across different observation spaces, possibly by modifying input layers to accommodate various modalities. Additionally, the authors should clarify the coordinate frame used for point cloud baselines and discuss its impact on results. Including real-world experiments would strengthen the conclusions drawn from simulations, and expanding the experimental framework to include other methodologies, such as reinforcement learning, would provide a more comprehensive understanding of robot learning. Finally, a clearer explanation of preprocessing steps when using depth images as inputs is necessary to enhance the clarity of the findings.