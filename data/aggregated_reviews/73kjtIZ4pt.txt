ID: 73kjtIZ4pt
Title: TELeR: A General Taxonomy of LLM Prompts for Benchmarking Complex Tasks
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a general taxonomy for designing prompts, termed TELeR, aimed at querying large language models (LLMs) on complex tasks. The authors propose that this taxonomy will enable meaningful comparisons across benchmarking studies, establish a common standard, and facilitate more accurate conclusions regarding LLM performance on specific complex tasks. The taxonomy defines prompts as Directive + Data, with six levels of detail, distinguishing between instruction and question types, as well as defined and undefined roles.

### Strengths and Weaknesses
Strengths:  
1. The paper is well-organized and easy to follow, with thorough consideration of facets relevant to querying LLMs.  
2. The proposed taxonomy is interesting and could be beneficial for comparing LLM performances, as it provides a structured approach to prompt design.  

Weaknesses:  
1. The paper lacks a comprehensive analysis of each prompt category, including suggestions for suitable prompts for specific tasks or models.  
2. There is insufficient empirical evidence demonstrating the practical application of the taxonomy, particularly in evaluating performance across LLMs with complex questions.  
3. The writing needs improvement, as some terms, such as "complex task," are ambiguous and require formal definitions.  

### Suggestions for Improvement
We recommend that the authors improve the analysis of the taxonomy by providing detailed suggestions on which types of prompts are suitable for particular tasks or models. Additionally, including quantitative comparisons using various datasets and baselines would enhance the understanding of the differences among prompt classes. We also suggest that the authors clarify the definition of "complex tasks" and address how prompts can be categorized and transformed across different levels systematically. Finally, providing empirical results demonstrating the effectiveness of the taxonomy in evaluating LLM performance would strengthen the paper's contributions.