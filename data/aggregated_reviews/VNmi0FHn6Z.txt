ID: VNmi0FHn6Z
Title: The Bayesian sampling in a canonical recurrent circuit with a diversity of inhibitory interneurons
Conference: NeurIPS
Year: 2024
Number of Reviews: 23
Original Ratings: 7, 5, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates how canonical recurrent circuits in the cortex can implement sampling algorithms, specifically focusing on circuits with excitatory (E) and two types of inhibitory neurons (PV and SOM). The authors demonstrate that circuits with only E and PV neurons implement Langevin dynamics, while the inclusion of SOM neurons enables Hamiltonian sampling. The paper builds on previous work in Bayesian sampling, providing analytical insights into neuronal circuits performing Bayesian inference. Additionally, the authors present a rigorous analysis of the equilibrium distribution \( p(z) \) using a Fokker-Planck approach, showing that the equations can effectively sample the desired distribution. They define the Hamiltonian and its corresponding dynamics, demonstrating that mixing Hamiltonian dynamics with Langevin dynamics does not alter the equilibrium distribution. The authors also propose exploring a gating mechanism on recurrent weights to represent high-dimensional complex posteriors and clarify the role of multiplicative noise in their sampling model.

### Strengths and Weaknesses
Strengths:
- The paper rigorously connects canonical circuits and Bayesian sampling, showcasing a solid understanding of neurophysiology and dynamical systems.
- The mathematical rigor in deriving the equilibrium distribution and its sampling dynamics is commendable.
- The writing is clear, and the experimental results are well-illustrated, contributing to the technical soundness of the work.
- The proposed gating mechanism for recurrent weights shows potential for enhancing the model's representational capacity.
- The authors effectively address the importance of multiplicative variability in neural sampling.

Weaknesses:
- The paper's presentation is convoluted, making it difficult to read and understand the significance of the main results. The authors could provide more intuitive explanations of Langevin and Hamiltonian sampling.
- The manuscript lacks clarity in distinguishing between canonical intralaminar microcircuits and typical laminar microcircuits, which may hinder understanding.
- The definition of the stochastic process in Eq. (1) is not clearly articulated, potentially confusing readers.
- The proposed model is limited to low-dimensionality and a uniform prior, only demonstrating sampling of 1-D Gaussian distributions, which restricts its applicability to more complex stimuli.
- The authors' assumption that PV neurons are not tuned to stimuli lacks sufficient empirical support and should be presented as an assumption rather than a fact.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the presentation by providing more intuitive explanations of the main results, particularly regarding the implications of different types of interneurons on sampling dynamics. Additionally, please ensure that the manuscript explicitly distinguishes between canonical intralaminar microcircuits and typical laminar microcircuits throughout the text. We also suggest that the authors clearly define the variable \( \xi(\theta, t) \) in Eq. (1) to enhance reader comprehension. Furthermore, the authors should discuss how their proposed circuits can scale to sample from more complex, high-dimensional distributions, as recent literature suggests that recurrent circuits can handle such complexities. We recommend that the authors reconsider their assumption regarding the tuning of PV neurons and present it as a supported hypothesis. Lastly, addressing the limitations of the model in relation to high-dimensional stimuli and the implications of heterogeneous tuning curves would enhance the paper's contribution to the field.