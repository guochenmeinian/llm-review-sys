ID: w4FwmICSHZ
Title: Multitask Multimodal Prompted Training for Interactive Embodied Task Completion
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the development of an Embodied MultiModal Agent (EMMA) aimed at enhancing interactive and embodied tasks in Vision & Language (VL) models. The authors propose a unified encoder-decoder model that integrates reasoning over images and trajectories, framing action prediction as multimodal text generation. EMMA achieves a state-of-the-art success rate of 36.81% on the Dialog-guided Task Completion (DTC) benchmark in the Alexa Arena. The authors also introduce two data augmentation methods that significantly improve performance and conduct extensive evaluations against existing VL models.

### Strengths and Weaknesses
Strengths:
- The motivation for addressing challenges in leveraging VL models for interactive tasks is compelling and well-articulated.
- The architecture of the EMMA model is simple yet effective, successfully unifying various tasks into a text generation framework.
- The paper is well-written, with thorough evaluations including quantitative and qualitative analyses.

Weaknesses:
- There is a lack of comparison between EMMA and similar concurrent works, such as PaLM-E, which would enhance the discussion of novelty.
- Some implementation details are unclear, particularly regarding model inputs and outputs, and the language decoder used for main results.
- The novelty of the approach is somewhat limited, with only marginal improvements over existing VL baselines, raising questions about the fairness of comparisons in terms of model size and computational costs.

### Suggestions for Improvement
We recommend that the authors improve clarity by providing a clearer definition of model inputs and outputs, as well as detailing the task-specific prompts used for the CR, AE, and VG subtasks. Additionally, we suggest including a comparison with PaLM-E to better contextualize the contributions of EMMA. A more comprehensive discussion on the evaluation results, particularly regarding the benefits over existing VL models and the implications of model size and training data, would strengthen the paper. Lastly, restructuring the paper to incorporate critical information from the appendix into the main text would enhance readability and accessibility.