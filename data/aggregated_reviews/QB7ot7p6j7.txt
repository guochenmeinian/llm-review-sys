ID: QB7ot7p6j7
Title: DiffAttack: Evasion Attacks Against Diffusion-Based Adversarial Purification
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 5, 6, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DiffAttack, a framework designed to attack diffusion-based adversarial purification defenses. The authors propose two main strategies: (a) a deviated-reconstruction loss that maximizes the distance between the noisy input and its denoised counterpart, addressing gradient vanishing/exploding issues, and (b) a segment-wise forward-backward algorithm to reduce memory costs during gradient backpropagation. The evaluation results indicate that the deviated-reconstruction loss alone is insufficient for effective attacks, but when combined with the classification loss, it significantly enhances the optimization process. The authors also clarify the randomness problem introduced by the diffusion process and detail how their method mitigates this issue through multiple sampling strategies. Empirical evaluations demonstrate the effectiveness of these methods across various models on CIFAR-10 and ImageNet, showing significant improvements in robust accuracy compared to existing methods.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and presents a clear problem statement.
- The proposed deviated reconstruction loss and segment-wise forward-backward algorithm are effective and innovative.
- The method demonstrates strong results in improving adversarial attack performance and effectively addresses the gradient issue and randomness problem.
- Extensive experimental results support the claims, providing clear evaluations and comparisons of loss functions.

Weaknesses:
- The impact of the segment-wise forward-backward approach on computational speed remains unclear.
- The novelty of the method may not be as pronounced, as it builds on existing techniques like gradient checkpointing.
- The paper lacks a discussion on how larger budgets for adversarial samples affect their characteristics.
- The absence of provided code limits reproducibility; including demo code would enhance the paper.
- The necessity of carefully tuning the $\lambda$ weights for the two losses is not addressed.
- There remains a gap between theoretical results and practical implementation, particularly regarding the TV distance calculations.
- The relationship of DiffAttack's effectiveness to other networks is not explored, despite relevant literature suggesting potential transferability.

### Suggestions for Improvement
We recommend that the authors improve clarity by explicitly discussing the computational speed implications of the segment-wise forward-backward approach and referencing the gradient checkpointing technique when introducing it. Additionally, addressing how larger $\epsilon$ budgets influence adversarial sample behavior would strengthen the paper. Including demo code in the supplementary materials is essential for reproducibility. We also suggest that the authors clarify the importance of tuning the $\lambda$ weights and explore the transferability of DiffAttack to other networks, as this could enhance the contribution of the work. Finally, we recommend that the authors further reduce the gap between theoretical insights and practical formulations, particularly in Theorem 1, by providing more detailed explanations of how maximizing the distance between Gaussian means relates to maximizing the TV distance, including these theoretical intuitions in Section 3.2 to improve the overall clarity and impact of the paper.