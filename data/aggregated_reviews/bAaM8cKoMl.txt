ID: bAaM8cKoMl
Title: MindSet: Vision. A toolbox for testing DNNs on key psychological experiments
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 4, 7, 9, -1, -1
Original Confidences: 5, 4, 5, -1, -1

Aggregated Review:
### Key Points
This paper presents the MindSet toolbox, designed to evaluate the alignment between deep neural networks (DNNs) and human vision through systematically manipulated image datasets. It addresses existing benchmarks' limitations by focusing on experimental conditions that test specific hypotheses about human visual perception and object recognition. The toolbox includes datasets representing various psychological findings and scripts for dataset regeneration and DNN performance analysis.

### Strengths and Weaknesses
Strengths:
- The goal of the paper is ambitious and significant.
- The paper is well-written and easy to follow.
- The toolbox is well-organized, with publicly available code and data.
- It covers a comprehensive set of phenomena from human psychophysical experiments.

Weaknesses:
- The claim regarding researchers' unfamiliarity with psychological experiments is inaccurate; prior works systematically study various aspects of vision.
- The paper lacks scientific insights and successful demonstrations from the proposed dataset.
- Concerns exist regarding the training of AI models and their alignment with human vision, particularly the need for ablation studies on the ResNet model.
- The validity of using a decoder method for visual illusion problems is questionable, and the training set structure for linear classifiers needs clarification.
- Existing datasets incorporated into the toolbox do not contribute new insights and are somewhat redundant.
- The stimuli lack diversity, particularly in motion, and the evaluation metrics beyond accuracy are not discussed.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their claims regarding the novelty of their approach in relation to existing psychological research. The authors should demonstrate the dataset's usefulness by identifying research gaps and providing concrete examples of model shortcomings in achieving human-level performance. Additionally, we suggest conducting ablation studies on the ResNet model to compare performance differences and clarify the training set structure for linear classifiers. Incorporating domain knowledge related to visual illusions in the documentation is essential to prevent misinterpretation by users unfamiliar with psychology. Lastly, the authors should consider expanding the diversity of stimuli and discussing additional evaluation metrics beyond accuracy.