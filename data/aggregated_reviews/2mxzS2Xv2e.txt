ID: 2mxzS2Xv2e
Title: A Causal View of Entity Bias in (Large) Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a structured causal model (SCM) aimed at mitigating entity bias in pre-trained language models (PLMs) and large language models (LLMs). The authors propose a method that replaces entities with placeholders, identifies similar entities, generates definitions for these placeholders, and integrates them into a comprehensive input sentence. The experimental results indicate that this framework outperforms baseline models. The paper also introduces techniques for both training-time and prompting interventions, demonstrating improvements in out-of-distribution (OOD) performance.

### Strengths and Weaknesses
Strengths:  
- The paper provides strong empirical results and demonstrates the effectiveness of the proposed approach.  
- It offers a thorough analysis of previous entity bias mitigation techniques and presents a well-structured causal model.  
- The experimental setup, including ablation studies, is robust and well-illustrated, particularly in Figures 3 and 4.  
- The writing is clear and accessible, making the concepts easy to follow.

Weaknesses:  
- The method's effectiveness may depend heavily on the LLM's ability to retrieve similar entities, raising concerns about its generalizability.  
- In-domain performance decreases when applying the training-time intervention, which could limit its practical applicability.  
- Some important baselines for in-context prompting are missing, and there are unresolved questions regarding the construction of the convex hull and the handling of long-tail entities.

### Suggestions for Improvement
We recommend that the authors improve the clarity of how entity embeddings are obtained for constructing the convex hull during training-time intervention. Additionally, further analysis is needed on how the proposed method impacts long-tail entities and whether the training-time intervention can debias across multiple axes, such as nationality and gender. We also suggest including more experiments in the in-context prompting section to address missing baselines and discussing the implications of decreased in-domain performance. Lastly, we encourage the authors to explore the potential prompt dependency of entity bias and to reference relevant literature that discusses similar approaches to mitigate entity bias.