ID: UuiZEOVtHx
Title: Safe and Efficient: A Primal-Dual Method for Offline Convex CMDPs under Partial Data Coverage
Conference: NeurIPS
Year: 2024
Number of Reviews: 18
Original Ratings: 6, 5, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates offline convex Markov Decision Processes (MDPs) under safety constraints and proposes a linear programming-based primal-dual algorithm for solving these problems. The authors achieve a sample complexity of $\mathcal{O}(\frac{1}{(1-\gamma)\sqrt{n}})$, improving upon the current state-of-the-art of $\mathcal{O}(\frac{1}{(1-\gamma)^2\sqrt{n}})$. The empirical evaluation demonstrates that the proposed algorithm outperforms existing methods in terms of reward and safety.

### Strengths and Weaknesses
Strengths:
- The formulation of offline convex CMDPs is promising, encompassing various applications, including safe imitation learning.
- The theoretical results are robust, with a significant improvement in sample complexity, which is crucial for the offline safe reinforcement learning community.
- The authors provide empirical results in two settings, enhancing the practical relevance of their theoretical contributions.

Weaknesses:
- The empirical experiments are limited, relying on toy problems without sufficient baseline comparisons. The benchmark task of frozen lake is notably easier than those in prior work.
- The authors claim to include limitations, but the discussion lacks depth regarding scalability and empirical performance in more complex tasks.
- The presentation is somewhat unclear, particularly regarding the definitions of the sets $\mathcal{W}$ and $\mathcal{X}$, and the assumptions made about the behavior policy.

### Suggestions for Improvement
We recommend that the authors improve the empirical evaluation by including more complex environments and additional baseline methods to enhance the robustness of their findings. Furthermore, we suggest that the authors provide a clearer discussion of the limitations of their approach, particularly concerning scalability and performance in more complicated tasks. Additionally, clarifying the definitions and roles of the sets $\mathcal{W}$ and $\mathcal{X}$, as well as the assumptions regarding the behavior policy, would strengthen the presentation of the paper.