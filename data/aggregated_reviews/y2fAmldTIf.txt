ID: y2fAmldTIf
Title: HEPrune: Fast Private Training of Deep Neural Networks With Encrypted Data Pruning
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 6, 7, 5, 5, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a data pruning algorithm for training Homomorphic Encryption (HE)-based neural networks, introducing an HE-friendly importance score and client-aided masking to prune dataset samples. The authors propose ciphertext-wise pruning to merge ciphertexts with empty slots, reducing computational costs during training. Empirical studies validate the effectiveness of the proposed method across five datasets, demonstrating improvements in training speed and accuracy.

### Strengths and Weaknesses
Strengths:
1. The paper introduces a new data pruning method for HE-encrypted data, proposing the HEL2N score, which replaces the $\ell_2$-norm in the EL2N score with the $\ell_1$-norm.
2. Ciphertext-wise pruning allows the server to merge ciphertexts with empty slots, enhancing communication efficiency.
3. Experiments on five datasets effectively compare the proposed method with the HETAL method.

Weaknesses:
1. The paper requires revisions for clarity and consistency, including typographical errors and inconsistent terminology.
2. Concerns arise regarding the computational costs of data pruning, as the HEL2N score involves multiple gradient computations, and ciphertext-wise pruning may require extensive rotations.
3. The novelty of the HEL2N score is questionable, as it primarily modifies existing methods, and the need for client-server communication may undermine the advantages of HE-based methods.

### Suggestions for Improvement
We recommend that the authors improve clarity by correcting typographical errors and ensuring consistent terminology throughout the paper. Additionally, the authors should address the computational costs associated with data pruning, particularly the intensive operations required for the HEL2N score and ciphertext-wise pruning. We suggest providing a theoretical justification for the HE-friendly score and clarifying how it differs from existing methods. Furthermore, the authors should explain the rationale behind the pruning ratio and its determination, as well as discuss the implications of server model privacy in their threat model. Lastly, we encourage the authors to elaborate on the potential side channel risks and acknowledge the limitations of their approach in managing indirect data leakage.