ID: VzOgnDJMgh
Title: WAGLE: Strategic Weight Attribution for Effective and Modular Unlearning in Large Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 7, 4, 8, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents WAGLE (Weight Attribution-Guided LLM unLEarning), a novel method aimed at enhancing large language model (LLM) unlearning by identifying influential weights while considering retain loss. The authors propose a bi-level optimization framework for weight attribution and provide a closed-form solution for calculating weight attribution scores. WAGLE is evaluated across various unlearning tasks and benchmarks, demonstrating improved unlearning efficacy and competitive model utility compared to existing methods.

### Strengths and Weaknesses
Strengths:
- Novel integration of weight attribution in LLM unlearning.
- Theoretical foundation in bi-level optimization.
- Extensive evaluation across multiple unlearning tasks and benchmarks.
- Compatibility with existing unlearning methods (e.g., GradDiff, NPO, PO).
- Insights into influential model components for unlearning.

Weaknesses:
- Limited theoretical justification for the effectiveness of weight attribution in unlearning.
- Insufficient discussion on computational complexity and scalability.
- Lack of comparison with recent unlearning methods.
- Limited exploration of potential negative effects or failure cases.
- Hyperparameter sensitivity, particularly regarding the choice of Î³, requires further investigation.

### Suggestions for Improvement
1. We recommend that the authors improve the theoretical justification for why weight attribution enhances unlearning.
2. Include a dedicated section on limitations and future work in the main text rather than the appendix.
3. Discuss the computational complexity of WAGLE and its scalability to larger models.
4. Provide clarity on the Membership Inference Attack (MIA) evaluation metric and its implications.
5. Explore the potential for negative transfer or catastrophic forgetting when using WAGLE.
6. Consider investigating the applicability of WAGLE to other model architectures beyond LLaMA and Zephyr.
7. Address the societal ramifications of unlearning, including potential benefits and risks.