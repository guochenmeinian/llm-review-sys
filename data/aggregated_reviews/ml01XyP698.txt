ID: ml01XyP698
Title: FreeSplat: Generalizable 3D Gaussian Splatting Towards Free View Synthesis of Indoor Scenes
Conference: NeurIPS
Year: 2024
Number of Reviews: 19
Original Ratings: 5, 6, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a generalizable 3D Gaussian splitting model, FreeSplat, designed for reconstructing geometrically consistent 3D scenes from long sequence inputs. The authors introduce Low-cost Cross-View Aggregation for feature matching and Pixel-wise Triplet Fusion for fusing Gaussian triplets, demonstrating significant advancements in long sequence novel view synthesis. The experiments indicate that FreeSplat effectively reduces inference costs and enhances the quality of novel views.

### Strengths and Weaknesses
Strengths:
1. The introduction of Low-cost Cross-View Aggregation allows for efficient feature matching and reduces computational costs.
2. Pixel-wise Triplet Fusion effectively mitigates redundancy in overlapping regions, enhancing multi-view 3D Gaussian feature aggregation.
3. The paper is well-structured, with clear explanations, detailed architectural diagrams, and comprehensive ablation studies, making it accessible and reproducible.

Weaknesses:
1. The novelty of the Low-cost Cross-View Aggregation module is questioned, as its components appear to be derived from existing methods without sufficient differentiation.
2. The evaluation lacks clarity, particularly regarding the fixed maximum gap between input views and the unexpected drop in novel view image quality with an increasing number of input views.
3. The absence of comparative results on datasets like RealEstate10k and ACID raises concerns about the generalizability of the proposed method.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the definitions for FreeSplat-fv and FreeSplat-spec. Additionally, including the training time of the model would provide valuable insights into its efficiency. We suggest conducting comparative experiments on the RealEstate10k and ACID datasets to strengthen the validity of the claims. A more thorough analysis of failure cases and limitations, including specific examples and potential strategies for improvement, would enhance the paper's rigor. Lastly, providing visualizations to illustrate how Gaussian ellipsoids are reduced in overlapping regions would clarify the effectiveness of the Pixel-wise Triplet Fusion module.