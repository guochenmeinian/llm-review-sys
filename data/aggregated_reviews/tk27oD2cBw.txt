ID: tk27oD2cBw
Title: The Harvard USPTO Patent Dataset: A Large-Scale, Well-Structured, and Multi-Purpose Corpus of Patent Applications
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 7, 8, 7, 7, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 3, 5, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents HUPD, a large-scale, well-structured dataset of 4.5 million patent applications submitted to the USPTO from 2004 to 2018, encompassing both accepted and rejected applications. The dataset features rich structured metadata, enhancing its utility for legal and NLP research, and introduces a new task: patent acceptance prediction. The authors explore various tasks enabled by HUPD, such as automated IPC classification, language modeling, plagiarism detection, and analyzing human versus LLM-written patents, providing baseline results for these tasks. They acknowledge the complexities involved in predicting patent acceptance and subject classification due to the intricate nature of patent law and the fine-grained classification system.

### Strengths and Weaknesses
**Strengths:**
1. The dataset is extensive, well-organized, and includes original inventor-submitted versions of patent applications, which enhances its utility for research.
2. The paper is well-written, providing a clear overview of related work and detailed documentation of the dataset.
3. It discusses limitations, biases, and ethical considerations, ensuring transparency.
4. The dataset opens new research avenues, particularly in legal NLP, and effectively addresses the complexities of patent acceptance prediction and subject classification.

**Weaknesses:**
1. The dataset is limited to USPTO patents in English, restricting its geographical and multilingual applicability.
2. The time window of 2004-2018 lacks justification, and the absence of final patent versions and patent drawings is noted as a limitation.
3. Formulating patent acceptance prediction as a classification problem oversimplifies a complex task, which should be acknowledged.
4. The accuracy of patent acceptance predictions is low due to the inherent difficulties in the task.

### Suggestions for Improvement
We recommend that the authors improve the dataset's versatility by including the final versions of corresponding licensed patents once recent application data is integrated. Additionally, it would be beneficial to clarify the rationale behind the chosen time window of 2004-2018 and consider expanding the dataset to include patents from other countries to facilitate comparative analyses of patent activity across different jurisdictions. We suggest exploring more practical downstream tasks, such as detecting plagiarized patents, and providing explanations for the observed performance in patent acceptance prediction. Furthermore, we encourage the authors to report perplexity scores for the language modeling task and contextualize ROUGE scores with lead/oracle baselines. Lastly, enhancing the readability of figures, clarifying the complexities surrounding the patent acceptance prediction task, and addressing minor inaccuracies in the text would improve clarity.