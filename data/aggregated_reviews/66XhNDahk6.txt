ID: 66XhNDahk6
Title: A Competitive Algorithm for Agnostic Active Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 7, 7, 7, 4, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper studies agnostic active learning by proposing a competitive algorithm that achieves a label complexity of roughly $\tilde{O}(m^* \log |H|)$, where $m^*$ is the optimal instance-dependent label complexity. The authors introduce a novel "capping" approach to the weight over hypotheses, ensuring the potential function grows by at least $\Omega(1/m^*)$. The paper also establishes that improving the $O(\log |H|)$ overhead is NP-hard, contributing to the understanding of active learning in agnostic settings.

### Strengths and Weaknesses
Strengths:
- The proposed algorithm is a novel modification of the classical multiplicative weight update algorithm, with sound proofs and a significant contribution to agnostic active learning.
- The approximation hardness based on Set-Cover is a valuable addition, and the analysis from a competitive perspective is innovative.

Weaknesses:
- The additional factor of $\log |H|$ in the label complexity may render the algorithm less competitive compared to existing methods, and the NP-hardness argument regarding this factor is seen as less relevant.
- The computational efficiency of the algorithm is vague, particularly regarding its polynomial runtime claim, which may not hold in the dimension parameter $d$.
- The analysis appears to conflate active learning with a stronger oracle model, potentially misleading in the title and abstract.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their algorithm's computational cost by providing specific running time analyses concerning parameters such as $d$, $m$, $|H|$, and $|X|$. Additionally, we encourage the authors to include a comprehensive comparison with related works, particularly addressing the bounds established by Hanneke and Yang, and discussing the implications of noise assumptions on their results. It would also be beneficial to explore scenarios where $\epsilon$ is smaller than $\eta$, as this could yield interesting theoretical insights. Lastly, we suggest revising the title and abstract to accurately reflect the nature of the oracle used in their analysis.