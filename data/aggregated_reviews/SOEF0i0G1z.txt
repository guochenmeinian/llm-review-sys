ID: SOEF0i0G1z
Title: Cognitive Model Discovery via Disentangled RNNs
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 5, 6, 7, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Disentangled RNNs (DisRNNs), a novel recurrent neural network architecture designed to learn interpretable cognitive models from behavioral data. The authors demonstrate that DisRNNs can effectively replicate latent variables from synthetic data and real rodent behavioral data, achieving competitive performance while maintaining interpretability through the use of bottlenecks. The model's structure allows for independent updates of latent units, which is expected to enhance understanding of cognitive processes. Additionally, the paper explores a bounded accumulator model and its implications for interpretability in cognitive neuroscience, indicating that the DisRNN can effectively fit data from this model. However, the reviewer seeks clarification on the exact ground truth update equations and references for the process model, while also emphasizing that the focus on interpretability relies on prior knowledge of the models, raising questions about how the proposed methodology can accelerate discovery in unknown systems. The terminology surrounding "agent" is discussed, suggesting that the prefix "reinforcement learning" may be misleading.

### Strengths and Weaknesses
Strengths:
- The approach to interpretable machine learning is compelling, with a strong justification for using noisy channels from a computational neuroscience perspective.
- The manuscript is well-written, clearly explaining the foundational principles and algorithmic details.
- The authors provide a thorough response to reviewer comments, demonstrating engagement with the feedback.
- The DisRNN's ability to fit data from the bounded accumulator model is a positive indication of its interpretability.

Weaknesses:
- The interpretation of DisRNNs trained on real behavioral data lacks depth, focusing on a "typical-best" example without systematic analysis.
- The selection process for the parameter $\beta$ is not adequately detailed, raising concerns about the robustness of the model to hyperparameter choices.
- The model's application is limited to a single task, making it difficult to assess its scalability and broader applicability.
- There is a lack of clarity regarding the ground truth update equations and references for the bounded accumulator model.
- The reliance on prior knowledge of models for interpretability raises concerns about the methodology's applicability to unknown systems.
- The use of the term "agent" may cause confusion due to its implications of learning/training.

### Suggestions for Improvement
We recommend that the authors improve the analysis of the DisRNNs trained on real behavioral data by providing a systematic evaluation of learned representations across multiple instances. Additionally, we suggest that the authors clarify the selection criteria for the parameter $\beta$ to enhance understanding of its impact on model performance. Improving the clarity of the ground truth update equations and providing appropriate references for the bounded accumulator model would also be beneficial. We encourage the authors to clarify how their methodology can accelerate discovery in the context of unknown systems. Expanding the scope of the experiments to include various cognitive tasks would strengthen the paper's contribution and applicability. Lastly, we advise the authors to consider dropping the "reinforcement learning" prefix to avoid potential misunderstandings regarding the term "agent," and to address the clarity of figures while providing open-source code to facilitate reproducibility and further exploration of their work.