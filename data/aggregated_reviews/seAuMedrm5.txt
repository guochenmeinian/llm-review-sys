ID: seAuMedrm5
Title: Aligner-Encoders: Self-Attention Transformers Can Be Self-Transducers
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 7, 7, 7, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 2, 5, 5, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel ASR model called Aligner, which integrates a self-aligned encoder with a simplified decoder, drawing from the strengths of RNN-T and AED models. The authors propose that the transformer encoder can inherently learn to align input and output sequences through self-attention, trained with label-wise cross-entropy loss, leading to improved computational efficiency. The model's performance is evaluated on Librispeech and other large-scale datasets, demonstrating competitive results with existing ASR models while significantly reducing computational costs.

### Strengths and Weaknesses
Strengths:
- The model offers a clear motivation for computational efficiency and successfully addresses limitations of existing ASR models.
- The internal alignment capability of the transformer encoder provides valuable insights.
- The paper includes comprehensive evaluations and acknowledges limitations, enhancing reader understanding.

Weaknesses:
- The explanation of the aligner modification for long-form audio is unclear; visual aids or equations could improve comprehension.
- Experimental results should be summarized in a table for clarity, particularly regarding the efficiency claims.
- The model's applicability may be limited to non-streaming scenarios, which could restrict its use cases.
- The reproducibility of results is hindered by the lack of source code and non-public data.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the aligner modification explanation by incorporating figures or equations. Additionally, summarizing the experimental results in Section 4.6 into a table would enhance reader convenience. To broaden the model's applicability, consider addressing the limitations related to streaming applications. Lastly, releasing the source code would significantly aid in reproducibility and verification of results.