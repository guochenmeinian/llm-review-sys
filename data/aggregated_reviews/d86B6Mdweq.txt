ID: d86B6Mdweq
Title: 3D Copy-Paste: Physically Plausible Object Insertion for Monocular 3D Detection
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 5, 6, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 4, 4, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a data augmentation approach for monocular 3D detectors by inserting 3D objects into indoor scenes in a physically plausible manner. It addresses two main challenges: the placement of objects and the rendering of realistic illumination. The experiments validate that the generated data enhances state-of-the-art monocular 3D detectors, with detailed ablation studies providing insights into the method's effectiveness. The authors introduce 3D Copy-Paste for generating annotated 3D objects, ensuring physical plausibility in location, size, pose, and illumination. The method shows improved performance on the SUN RGB-D dataset.

### Strengths and Weaknesses
Strengths:
- The basic idea is clear, and the illustrations effectively convey the method.
- The pipeline is systematic and comprehensive, addressing key aspects of 3D object insertion and data generation.
- The proposed method achieves state-of-the-art results on the SUN RGB-D benchmark, supported by detailed ablation studies.
- The approach is fully automated and ensures physical plausibility in object placement and illumination.

Weaknesses:
- The related work section contains inaccuracies and omits significant literature on monocular 3D detection and data augmentation.
- The methodology relies heavily on existing techniques, making the contribution appear more engineering-focused rather than novel.
- The experiments are limited to ImVoxelNet and SUN RGB-D, lacking validation on other datasets and baselines, which would strengthen the claims of effectiveness.

### Suggestions for Improvement
We recommend that the authors improve the related work section by correcting inaccuracies and including relevant literature on monocular 3D detection and data augmentation. Additionally, we suggest enhancing the novelty of the methodology by incorporating more original techniques rather than relying on existing ones. To bolster the experimental validation, we encourage the authors to test their approach on a wider range of datasets and baselines, including outdoor scenes like KITTI and nuScenes. Finally, we advise including comparisons with common 3D corruptions and exploring the impact of their method on other 3D and 2D tasks to reinforce their findings.