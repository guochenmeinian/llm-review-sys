ID: YGTVEmBXtV
Title: Make Your LLM Fully Utilize the Context
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 7, 6, 6, 8, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents INformation-INtensive (IN2) training, a data-driven method aimed at resolving the "lost-in-the-middle" problem in large language models (LLMs) with long context windows. The authors hypothesize that this issue arises from inadequate explicit supervision during long-context training. They create a synthetic long-context question-answering dataset that compels models to leverage information from various positions within long contexts. By applying IN2 training to the Mistral-7B model, they develop FILM-7B, which shows significant performance improvements on probing tasks assessing long-context utilization and real-world long-context tasks while maintaining comparable performance on short-context tasks. The authors provide comprehensive analyses of their training strategies, including the effects of sliding windows and position encoding adjustments.

### Strengths and Weaknesses
Strengths:
- The introduction of IN2 training presents an innovative solution to the "lost-in-the-middle" problem, addressing a critical issue in long-context LLMs and potentially enhancing their information utilization.
- The authors develop a robust evaluation framework, VAL Probing, which assesses long-context capabilities across diverse context styles and retrieval patterns, offering a more rigorous testing suite than existing benchmarks.
- FILM-7B demonstrates notable improvements on both probing and real-world long-context tasks, maintaining performance on short-context tasks, and achieving results comparable to or better than GPT-4-Turbo on certain tasks.

Weaknesses:
- A potential concern is whether the model might memorize synthetic data, affecting generalizability to other long-context tasks. 
- The authors should provide more details regarding the construction of their training data and justify their choices in data generation and segment selection.

### Suggestions for Improvement
We recommend that the authors improve the justification for using synthetic data over existing long-context datasets, such as L-EVAL and LongBench, and clarify the criteria for selecting segments with gold answers. Additionally, we suggest providing a more detailed evaluation of the quality of the synthetic QA pairs and conducting ablation studies to assess the contributions of different fine-tuning approaches. It would also be beneficial to define "higher information intensity" with greater rigor and explore the implications of increasing the RoPE base in more detail. Finally, we encourage the authors to consider releasing their training data to the community for further validation and exploration.