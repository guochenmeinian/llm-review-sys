ID: wS3PPBUDX8
Title: Constructing Semantics-Aware Adversarial Examples with Probabilistic Perspective
Conference: NeurIPS
Year: 2023
Number of Reviews: 18
Original Ratings: 6, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to generating adversarial examples that preserve the semantic meaning of the original inputs, utilizing Langevin Monte Carlo techniques. The authors propose a semantically-aware distance measure to replace traditional geometric measures, framing the problem as a box-constrained non-convex optimization task. The method employs a learned energy function to guide adversarial sample generation, with rejection sampling and refinement techniques enhancing sample quality. Evaluation results indicate a significant success rate against defended models, suggesting potential for practical application. Additionally, the authors focus on improving adversarial example generation specifically for CIFAR-10 by reducing the TPS perturbation from 0.1 to 0.05 and incorporating scaling into the data augmentation $\mathcal{T}$, which has led to significantly enhanced visual results. They acknowledge previous overstatements regarding the impact of adversarial attacks on image semantics and commit to clarifying these points in the revised version, emphasizing the importance of the choice of $\mathcal{T}$ in preserving semantics.

### Strengths and Weaknesses
Strengths:
- The work addresses the important issue of unrestricted adversarial attacks, moving beyond traditional bounded attacks.
- The method effectively breaks defended models, as illustrated in Figures 1 and 2, demonstrating advantages over norm-bounded attacks.
- The introduction of a semantically-aware distance measure is both novel and theoretically sound.
- The authors have successfully improved visual results for CIFAR-10 through experimental adjustments to TPS perturbation and scaling.
- Acknowledgment of previous overstatements demonstrates a commitment to accuracy and clarity.
- The paper shows potential for advancing the understanding of adversarial examples in the context of semantic preservation.

Weaknesses:
- The computational cost of the attack is unclear, and the evaluation is limited to two toy datasets (MNIST and SVHN), raising concerns about generalizability to larger datasets.
- An ablation study on key components, such as the effect of TPS as data augmentation and the choice of sampling method, is missing.
- The experimental success rate relies on subjective human evaluation, which may undermine credibility.
- The motivation for using energy-based models (EBMs) and Langevin Monte Carlo (LMC) methods is not sufficiently clarified.
- The initial submission contained overstatements that required clarification.
- Conducting a comprehensive ablation study on TPS parameters was not feasible, which may limit the depth of analysis.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by including experiments on more challenging datasets like CIFAR-10 and CIFAR-100 to assess the generalizability and transferability of their method. Additionally, conducting an ablation study to analyze the impact of various components, such as TPS augmentation and hyperparameter choices, would strengthen the paper. Clarifying the necessity of using EBMs and LMC in the methodology is essential. Furthermore, we suggest exploring more objective metrics for evaluating the semantic preservation of adversarial examples to enhance the credibility of the results. We also recommend improving the clarity of their statements regarding the impact of adversarial attacks on image semantics, particularly in relation to different datasets. Including a detailed discussion of the choice of $\mathcal{T}$ for semantic preservation, potentially illustrating earlier results as a failure mode, would enhance awareness among researchers and practitioners. Lastly, showcasing various selections of scaling and TPS within $\mathcal{T}$ in the revised version would provide a broader understanding of their effects.