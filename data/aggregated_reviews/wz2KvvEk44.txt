ID: wz2KvvEk44
Title: Focus On What Matters: Separated Models For Visual-Based RL Generalization
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 5, 7, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents SMG (Separated Models for Generalization), a novel approach to enhance generalization in visual-based reinforcement learning (RL) by utilizing two model branches to separately extract task-relevant and task-irrelevant representations. The method introduces multiple loss terms, including four additional losses and two consistency losses, to guide the agent's focus on relevant features across various scenarios. Experimental results demonstrate that SMG outperforms existing benchmarks, particularly in challenging video-background settings.

### Strengths and Weaknesses
Strengths:
- The separation of foreground and background for reconstruction is a logical approach to improving generalization in visual RL.
- Extensive experiments across diverse settings validate the effectiveness of SMG.
- The architecture is designed as a plug-and-play module, facilitating integration with existing off-policy RL algorithms.

Weaknesses:
- The novelty of learning mask models to distinguish noise from the environment is limited, as similar concepts have been explored in prior works.
- The paper lacks sufficient discussion on its limitations and does not compare its performance with model-based RL methods.
- The complexity of the proposed objective, with numerous loss terms, may complicate practical implementation and tuning.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing, addressing typos and disorganized figures. Additionally, we suggest including a detailed pseudo code for calculating the various losses to enhance readability. It would be beneficial to broaden the comparison to include model-based RL methods and discuss the implications of the mask ratio $\rho$ more thoroughly. Finally, we encourage the authors to explore the performance of SMG in more challenging generalization scenarios beyond visual backgrounds, such as dynamic generalization and task generalization.