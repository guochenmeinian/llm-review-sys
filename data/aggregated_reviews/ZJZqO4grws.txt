ID: ZJZqO4grws
Title: Learning to Learn with Contrastive Meta-Objective
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 4, 6, 3, 4, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a contrastive regularizer aimed at enhancing meta-learning through a contrastive meta-objective that improves alignment and discrimination abilities of meta-learners, thereby facilitating better task adaptation and generalization. The authors demonstrate the empirical effectiveness of the proposed ConML across various meta-learning and in-context learning scenarios. The framework is versatile, applicable to optimization-based, metric-based, and amortization-based methods, and shows improvements across standard benchmarks.

### Strengths and Weaknesses
Strengths:
- The introduction of contrastive regularization is intuitively straightforward and motivating.
- The implementation covers major meta-learning methods, making the study more comprehensive than previous works.
- Numerical results are promising, and the provision of code enhances reproducibility.

Weaknesses:
- The specific contrastive strategy raises concerns about potential model representation collapse due to the absence of appropriate regularization or constraints.
- The contrastive objective does not align with commonly studied approaches like InfoNCE.
- The meta-objective's reliance on computations involving representations from different tasks during each episode lacks discussion on training and inference efficiency, leaving scalability unclear.
- There is insufficient sensitivity analysis on hyperparameters and the sampling strategy for task subsets, which could affect performance and efficiency.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the risks of model representation collapse and clarify whether they have considered these risks. Additionally, the authors should explore the rationale for not following established contrastive learning objectives like InfoNCE. A detailed analysis of training and inference efficiency should be included to address scalability concerns. Furthermore, we suggest incorporating a sensitivity analysis on hyperparameters and discussing how different strategies would impact performance and efficiency. Lastly, validation on the MetaDataset and comparisons with state-of-the-art methods would strengthen the contribution of the paper.