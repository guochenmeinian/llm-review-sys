ID: WRGldGm5Hz
Title: DYffusion: A Dynamics-informed Diffusion Model for Spatiotemporal Forecasting
Conference: NeurIPS
Year: 2023
Number of Reviews: 19
Original Ratings: 4, 7, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DYffusion, an innovative approach that mimics diffusion models for probabilistic multi-step spatiotemporal forecasting. It reformulates the noising process as interpolation (parameterized by \(I_\phi\)) and the denoising process as forecasting (parameterized by \(F_\theta\)), effectively reinterpreting the noising step \(T\) as a temporal step in forecasting. DYffusion integrates dynamics-informed forward and reverse processes, addressing the limitations of traditional deterministic models that struggle with uncertainty quantification and long rollouts. The model demonstrates competitive performance on various forecasting tasks, including sea surface temperatures, Navier-Stokes flows, and spring mesh systems, evaluated through probabilistic skill score metrics. DYffusion shows significant improvements in speed, memory usage, and forecasting accuracy across benchmark datasets, establishing itself as a leading model in this domain.

### Strengths and Weaknesses
Strengths:
1. DYffusion creatively reinterprets continuous-time probabilistic forecasting as a diffusion process, leveraging existing diffusion algorithms for accelerated inference sampling.
2. The model effectively tackles the challenges of uncertainty quantification and long-term forecasting, achieving competitive or superior scores while significantly reducing time costs compared to traditional diffusion methods.
3. DYffusion is the first diffusion model utilizing task-informed processes, offering a new perspective on diffusion model design.

Weaknesses:
1. Equation (6) is incorrect; it should involve a differential rather than a derivative in the integral.
2. The empirical studies lack appropriate baselines, such as extrapolating \(dF_\theta/ds\) using an ODE solver.
3. Utilizing \(F_\theta\) trained with Algorithm 1 in the baseline method Dropout is inappropriate; the forecaster in Dropout should be trained with an objective like \(||F_\theta(x_{t+i}, i)-x_{t+h}||^2\).
4. Clarity and presentation issues remain, particularly regarding the interplay between the forecaster and interpolator.
5. A complexity analysis is absent, despite claims that DYffusion reduces complexity.
6. There is insufficient discussion on related works concerning neural SDEs, which are inherently suitable for modeling continuous-time processes.
7. Some reviewers expressed concerns about the relevance of deterministic models and the adequacy of baselines in neural ODE and SDE comparisons.

### Suggestions for Improvement
We recommend that the authors improve Equation (6) to correctly reflect the necessary differential in the integral. Additionally, the authors should include appropriate baselines in their empirical studies, such as using an ODE solver for \(dF_\theta/ds\). It is crucial to revise the training method for the forecaster in the Dropout baseline to align with the proposed objectives. We also suggest conducting a complexity analysis to substantiate claims regarding reduced complexity. Furthermore, we recommend improving clarity and presentation, particularly in elucidating the relationship between the forecaster and interpolator. Consider enhancing the introduction of the 'cold posterior' sampling scheme and using simpler terminology, such as 'naive sampling', for better comprehension. Additionally, we suggest conducting further ablation studies to clarify the necessity and advantages of the forecaster, and exploring diffusion settings that generate forecasts from Gaussian noise conditioned on initial conditions. Lastly, ensure that the manuscript addresses the concerns regarding the use of deterministic models and the appropriateness of the baselines employed in comparisons.