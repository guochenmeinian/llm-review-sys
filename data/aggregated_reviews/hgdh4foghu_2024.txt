ID: hgdh4foghu
Title: Policy-shaped prediction: avoiding distractions in model-based reinforcement learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 6, 5, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Policy-Shaped Prediction (PSP), a method in model-based reinforcement learning (MBRL) aimed at mitigating distractions by focusing on significant aspects of the environment. The authors propose a combination of segmentation and adversarial learning to enhance policy learning by utilizing saliency maps. They introduce a novel distraction benchmark and demonstrate that PSP achieves up to 2x improvement in robustness against distractions while maintaining performance in distraction-free settings. The authors highlight impressive results, particularly in challenging environments, showcasing the potential impact of their contributions on the field.

### Strengths and Weaknesses
Strengths:
- The motivation for the proposed approach is sound and clearly articulated.
- Empirical results substantiate the efficiency of the proposed method, showcasing improvements over existing techniques.
- The innovative nature of the PSP approach and its application to model-based reinforcement learning is noteworthy.
- The introduction of a segmentation model enhances the application of policy-gradient based weighting, providing a novel contribution to the field.
- The paper includes detailed descriptions of the distraction benchmark and presents concise experiments with necessary reproducibility details.

Weaknesses:
- The effectiveness of simpler segmentation models remains unclear, as the method appears agnostic to the choice of segmentation model; evaluating additional models could enhance the paper.
- The claim regarding predictable background distractions in the benchmark may limit its applicability, as many distractions are independent of the agent's actions.
- The paper does not address domain adaptation approaches in RL, which also aim to learn policies invariant to distractions.
- There is a lack of analytical consideration regarding the empirical complexity of the PSP approach.
- Insufficient exploration of scalability, trade-offs, and resource constraints in various environments.

### Suggestions for Improvement
We recommend that the authors improve the evaluation of simpler segmentation models to assess their impact on PSP's performance and training speed. Additionally, we suggest revisiting the benchmark to include distractions that are independent of agent actions to enhance its relevance. The authors should also consider discussing domain adaptation methods in relation to their approach, providing a comparative analysis to highlight the advantages of PSP. Furthermore, we recommend that the authors include a Scalability Analysis to explore how the complexity of each component of PSP scales with problem size, particularly regarding state space, action space, and environment complexity. A Trade-off Analysis should be conducted to examine the relationship between segmentation accuracy, computational cost, and overall performance, particularly how different segmentation models impact these factors. Lastly, we suggest addressing Resource-Constrained Scenarios by providing insights into how the computational overhead affects real-world applications, especially in robotics or embedded systems, and exploring strategies for optimizing or simplifying PSP for feasibility in such contexts.