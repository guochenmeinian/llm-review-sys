ID: LZV0U6UHb6
Title: Zero-shot Image Editing with Reference Imitation
Conference: NeurIPS
Year: 2024
Number of Reviews: 19
Original Ratings: 5, 7, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for imitative editing, allowing users to modify specific areas of a source image using content from a reference image. The authors propose a generative training framework called MimicBrush, which utilizes dual diffusion techniques to replace key and value features from the source image with those from the reference image. The method is trained in a self-supervised manner, masking parts of the image for recovery. The paper also introduces a benchmark for evaluating part composition and texture transfer tasks. Additionally, the authors analyze the Reference U-Net's ability to preserve details through higher resolution feature maps, which they argue is crucial for their proposed task. They conducted ablation studies and provided both qualitative and quantitative analyses to support their claims, emphasizing that the dual U-Net structure is not their contribution, and their novelty lies beyond just the data used.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and easy to understand.
- The end-to-end pipeline does not require fine-tuning for each image.
- The method is user-friendly, requiring only a source image, reference image, and mask for automatic content alignment.
- Experimental results demonstrate impressive performance across various categories and metrics.
- The proposed setting for part-level image editing is novel and beneficial for designers.
- The authors provide thorough ablation studies and analyses to support their claims.
- The paper addresses the importance of high-resolution feature maps in the proposed task.

Weaknesses:
- The method is not truly zero-shot, as it necessitates training and significant resources.
- The novelty of the approach is questionable, as it relies on existing techniques like those from MasaCtrl and combines them with an old training strategy.
- The requirement for source and reference images to be of the same scale and contain only one salient object limits applicability.
- The definition of inter vs. inner is unclear, and the paper lacks rigorous formulation of the problem and algorithm.
- The reviewers seem to misunderstand the authors' contributions, focusing on the novelty of the Reference U-Net and training data rather than the authors' actual innovations.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation and advantages of their proposed network design, particularly in comparison to existing methods like Controlnet and IP-adapter. Additionally, we suggest providing a more rigorous mathematical formulation of the input, output, and masks involved in the algorithm, as well as clarifying the training objective and loss functions used. It would also be beneficial to include qualitative comparisons in the ablation studies to illustrate the impact of different training strategies on visual quality. Furthermore, we recommend adding a small paragraph at the end of the introduction to summarize their novelties and including an explanatory paragraph in Section 3.2 to clarify that the dual U-Net is not a contribution of this paper. Finally, addressing the limitations regarding editing types and the use of SAM data in training would strengthen the paper.