ID: Vq2kzpig8v
Title: Reciprocal Reward Influence Encourages Cooperation From Self-Interested Agents
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 6, 6, 3, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for incorporating the influence of other agents into an agent's reward function, promoting cooperation in social dilemmas such as the Iterated Prisoner's Dilemma (IPD) and the Coin game. The authors propose a new intrinsic reward that tracks influence balance compared to a counterfactual baseline, providing incentives for naive learners to cooperate. Additionally, the paper introduces an opponent shaping method that offers specific advantages over existing approaches, including improved sample efficiency, reliance solely on first-order derivatives, and resistance to exploitation. The authors argue that their choice of baselines, such as LOLA and MFOS, is appropriate as their method demonstrates cooperation in a setting of simultaneous learning within an unmodified environment. They clarify their use of the term "emergent cooperation," acknowledging that it may be misleading and have adjusted their language accordingly.

### Strengths and Weaknesses
Strengths:  
- The paper is well written and clearly presents comparisons with state-of-the-art methods.  
- It demonstrates strong results, particularly in the Coin game, and highlights the ability to achieve cooperation without privileged information.  
- The manuscript addresses an important topic in multi-agent reinforcement learning, relevant to the NeurIPS community.  
- The authors effectively position their method as a significant advancement in opponent shaping, highlighting its unique advantages.  
- They provide a clear rationale for their choice of baselines, demonstrating a thorough understanding of the relevant literature.  
- The acknowledgment and adjustment of the term "emergent cooperation" reflect a willingness to engage with feedback and improve clarity.  

Weaknesses:  
- Not all results are clearly presented for IPD-Rollout or Coins; a result matrix or explanation for omissions is needed.  
- Missing implementation details, such as the number of seeds and averaging methods, limit reproducibility.  
- The contribution of each mechanism (1-step influence, debt mechanism, intrinsic reciprocal reward) is not adequately discussed, raising questions about their necessity and interplay.  
- The argument against the appropriateness of other baselines may benefit from further elaboration to strengthen the case.  
- Comparisons with unrelated algorithms like LOLA and MFOS may misrepresent the nature of cooperation being studied, and the paper could provide more detailed comparisons with identified similar works to clarify distinctions.  

### Suggestions for Improvement
We recommend that the authors improve the clarity of results presentation, particularly for IPD-Rollout and Coins, by including a result matrix or an explanation for any omissions. Additionally, please provide more extensive implementation details, such as the number of seeds and averaging methods, to enhance reproducibility. It would be beneficial to discuss the contribution and necessity of each mechanism in detail. Furthermore, we recommend elaborating on why other baselines are considered trivial, potentially including more detailed comparisons with similar works to clarify distinctions. Finally, consider refining the comparisons with LOLA and MFOS to better align with the specific type of cooperation your method aims to achieve.