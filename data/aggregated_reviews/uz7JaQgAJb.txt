ID: uz7JaQgAJb
Title: Neural McKean-Vlasov Processes: Inferring Distributional Dependence
Conference: NeurIPS
Year: 2023
Number of Reviews: 22
Original Ratings: 8, 2, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study of McKean-Vlasov Stochastic Differential Equation (MV-SDE) models, which generalize Ito processes by incorporating the evolution of the law of the process \(X_t\) (denoted \(p_t\)). The authors propose a model where \(p_t\) influences the dynamics through a term \(\mathbb{E}_{y_t \sim p_t}[\varphi(X_t, y_t)]dt\), allowing the transition density to be expressed as a solution to a PDE. Two neural architectures are introduced: Implicit Measure (IM) and Marginal Law (ML), each designed to represent the general form of MV-SDEs, including the factorization of drift and interaction. The paper also discusses parameter estimation methods, including maximum likelihood estimation (MLE) and techniques for handling missing data, while addressing the accuracy of distribution estimation based on sample points.

### Strengths and Weaknesses
Strengths:
* The submission explores non-trivial ideas in depth, demonstrating a comprehensive understanding of both theory and methodology.
* The writing is clear, and the numerical experiments are well-executed, showcasing the proposed methods effectively.
* The authors provide a clear motivation for their proposed architectures and their relevance to MV-SDEs.
* The inclusion of additional KS statistics demonstrates the potential for improved accuracy with increased computational resources.
* The paper addresses reviewer concerns and clarifies technical aspects effectively.

Weaknesses:
* The paper lacks clarity regarding the contexts in which MV-SDE modeling is beneficial and could improve on motivating the task at hand.
* The derivation of the implicit measure architecture is not clearly articulated, making it difficult to understand.
* There are contradictions in the assumptions made about the regularity of the drift term versus the goal of modeling jump behavior.
* The novelty of the IM and ML architectures is questioned, as they resemble existing techniques in the machine learning community.
* Some reviewers find the presentation of the energy distance and its derivation unclear, leading to confusion regarding its relevance to the proposed methods.
* The paper lacks concrete examples of MV-SDEs with regular interaction kernels that exhibit discontinuous dynamics.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the contexts where MV-SDE modeling is applicable, perhaps by including a discussion on potential contributions to machine learning tasks. Additionally, a clearer motivation for the task would enhance understanding, particularly regarding the relationship between SDEs and particle approximations. The authors should also provide more detailed explanations of the implicit measure architecture and clarify the assumptions made about the drift term. Furthermore, we suggest that the authors improve the clarity of the presentation, particularly regarding the definitions and roles of the energy distance and gradient flow in relation to their methods. It would be beneficial to provide explicit examples of MV-SDEs with regular interaction kernels that lead to discontinuous dynamics, as this would address concerns about the fundamental assumptions of the project. Lastly, clearly stating the quantities being approximated using neural networks and the parameters to be learned would ensure that the audience can easily follow the methodology.