ID: yxOrSmS5wR
Title: AV-Cloud: Spatial Audio Rendering Through Audio-Visual Cloud Splatting
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 6, 7, 5, -1, -1, -1, -1
Original Confidences: 3, 1, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents AV-Cloud, a framework for high-quality spatial audio rendering in 3D scenes that operates independently of visual cues. AV-Cloud introduces Audio-Visual Anchors and the Audio-Visual Cloud Splatting module to generate viewpoint-specific spatial audio synchronized with visual content, addressing issues like audio lag and visual dependency in existing methods. The approach shows superior performance in audio reconstruction accuracy, perceptual quality, and acoustic effects across multiple benchmarks.

### Strengths and Weaknesses
Strengths:
1. The concept of using Audio-Visual Anchors and Cloud Splatting to decouple audio rendering from visual rendering is intriguing.
2. The paper demonstrates comprehensive experimentation and robust evaluation across various benchmarks.
3. The structure and clarity of the presentation are commendable, with figures and supplementary examples aiding reader comprehension.
4. The proposed method effectively addresses critical issues in real-time audio-visual rendering.

Weaknesses:
1. The mathematical formulation of the Audio-Visual Cloud Splatting module lacks detail, particularly regarding Equation (2) and the computation of weights $a_{ki}$.
2. The technical derivation of the Spatial Audio Render Head (SARH) is insufficiently detailed, especially concerning the significance of the mixture mask $m_m$ and the difference mask $m_d$ in Equations (4) and (5).
3. The examples provided are overly idealized, lacking challenging elements such as interfering sounds, which raises concerns about the robustness of AV-Cloud in complex real-world environments.
4. The clarity of the Audio-Visual anchor points is questionable, particularly regarding their relationship to audio generation and the rationale for using Structure-from-Motion (SfM) points.

### Suggestions for Improvement
We recommend that the authors improve the mathematical formulation of the Audio-Visual Cloud Splatting module by providing a clearer explanation of Equation (2) and the computation of weights $a_{ki}$. Additionally, the authors should elaborate on the technical derivation of the Spatial Audio Render Head (SARH), particularly the roles of the mixture and difference masks in audio quality. To enhance the robustness of the method, we suggest validating AV-Cloud with more complex real-world examples that include interfering sounds. Furthermore, we recommend providing a primer on Structure-from-Motion (SfM) in the supplementary material and clarifying the relationship between AV anchor points and audio generation to strengthen the conceptual framework. Lastly, we encourage the authors to conduct proper subjective tests to evaluate the quality and spatial characteristics of the generated spatial audio.