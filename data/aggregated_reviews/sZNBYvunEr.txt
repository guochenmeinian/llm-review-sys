ID: sZNBYvunEr
Title: DreamSparse: Escaping from Platoâ€™s Cave with 2D Diffusion Model Given Sparse Views
Conference: NeurIPS
Year: 2023
Number of Reviews: 19
Original Ratings: 6, 5, 7, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for novel view synthesis using pretrained diffusion models, specifically leveraging Stable Diffusion to generate images at a resolution of 512x512. The authors propose a two-stage approach that first aggregates features from context views into a 3D-aware representation and then utilizes a conditional diffusion model to generate novel views. The method claims to encourage 3D consistency, although reviewers note that it does not strictly ensure it. The paper demonstrates good quantitative and qualitative results, showing improvements over existing state-of-the-art sparse-view methods like SparseFusion, GeNVS, and 3DiM, while also addressing the complexity of converting camera poses from the CO3D dataset to fit the requirements of Zero 1-to-3.

### Strengths and Weaknesses
Strengths:
- The introduction of a 3D geometry module that integrates 3D awareness into the 2D diffusion process is a novel contribution, diverging from conventional NeRF-based methods.
- The paper demonstrates improvements over SparseFusion and other baseline methods in terms of image quality metrics (PSNR, SSIM).
- The authors provide additional qualitative results and ablation studies, enhancing the clarity of their contributions.
- The method is efficient, requiring less training time compared to competing methods.

Weaknesses:
- The term "Scene Level Novel View Synthesis" in Section 4.3.2 is considered overclaimed, as many scene-level works handle more complex configurations.
- Claims regarding 3D consistency are not fully supported, as results still exhibit flickering and lack geometrical consistency.
- The lack of input view visualizations alongside novel-view synthesis results limits clarity on model hallucination.
- Comparisons to significant existing works like zero-123, NVS-Fusion, and 3DIM are insufficient, leaving claims unsupported regarding geometric consistency and scene-level synthesis.
- The rationale for not using PixelNeRF and the limitations of the geometry module are not adequately addressed.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the naming in Section 4.3.2 to better reflect the complexity of the task. Additionally, including side-by-side visualizations of input views with synthesis results would enhance understanding of model performance. The authors should explicitly state the limitations regarding 3D consistency in the paper and provide further qualitative results that evaluate the geometric consistency of the outputs. Furthermore, we suggest addressing the lack of comparison to zero-123, NVS-Fusion, and 3DIM, providing justification for their absence in the evaluation. To address concerns about the geometry module, we encourage the authors to elaborate on the advantages of their approach over PixelNeRF and consider conducting ablation studies to validate their design choices. Finally, enhancing the writing quality by correcting grammatical errors and ensuring consistent terminology will improve the overall presentation.