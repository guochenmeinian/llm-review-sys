ID: LhVJdq4cZm
Title: AlberDICE: Addressing Out-Of-Distribution Joint Actions in Offline Multi-Agent RL via Alternating Stationary Distribution Correction Estimation
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 5, 5, 5, 7, 5, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents AlberDICE, an offline Multi-Agent Reinforcement Learning (MARL) algorithm that addresses the out-of-distribution (OOD) joint action challenge through centralized training of individual agents based on stationary distribution optimization. The authors propose an alternating optimization procedure that computes the best response of one agent at a time, effectively avoiding the exponential complexity associated with MARL. Theoretical proof of convergence to Nash policies is provided, and experimental results demonstrate that AlberDICE significantly outperforms baseline algorithms across standard MARL benchmarks.

### Strengths and Weaknesses
Strengths:
- The paper proposes a novel solution to the distribution shift problem in offline reinforcement learning, effectively mitigating excessive distribution shift in offline MARL.
- AlberDICE reduces computational burden by computing the best response of individual agents sequentially.
- Theoretical convergence to Nash policies is established, offering a solid theoretical foundation for the algorithm.
- Experimental evaluations show that AlberDICE achieves superior performance compared to baseline algorithms across various multi-agent environments.

Weaknesses:
- The assumption of fixed policies for other agents may overlook scenarios with multiple cooperation strategies present in the dataset.
- Section 3 contains many derivations from existing work, which could be simplified to better highlight the contributions of this paper.
- The use of Behavioral Cloning (BC) to learn \(\pi^D_{-i}\) may lead to poor performance when the dataset quality is low, particularly in medium datasets.
- There is insufficient discussion on the algorithm's limitations and applicability, which may hinder its generalization.
- Necessary ablation experiments regarding parameter robustness and network model selection are lacking.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Section 3 by simplifying derivations and emphasizing original contributions. Additionally, the authors should explore the implications of fixed policies for other agents and consider the impact of dataset quality on the performance of BC. A more thorough discussion of the algorithm's limitations and applicability, including special cases, would enhance the manuscript. Finally, we suggest conducting ablation studies to investigate the robustness of parameters and the selection of network models.