ID: Lbuxdzg1pd
Title: The Secretary Problem with Predicted Additive Gap
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 6, 7, 6, 6, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation of the value maximization secretary problem, focusing on how the optimal competitive ratio of $1/e$ can be improved in a learning-augmented context with predictions about an additive gap. The authors demonstrate that with knowledge of any additive gap $c_k = w_1 - w_k$, the competitive ratio can be enhanced to $0.4$, and if both $k$ and $c_k$ are known, a better competitive ratio dependent on $k$ can be achieved. The authors also adapt their algorithm for robustness against erroneous predictions of $c_k$ and provide simulations that validate their theoretical findings.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, balancing technical results with intuitive explanations.
- The theoretical results are intriguing and contribute to the understanding of learning-augmented algorithms.
- The motivation for the new type of advice is well-grounded in both theoretical and practical contexts.
- The appendices offer interesting follow-up research directions.

Weaknesses:
- The paper lacks tightness results proving the optimality of the algorithms presented.
- The bounds in Section 5 assume knowledge of the prediction error, which could be strengthened by expressing algorithm performance as a function of the prediction error without prior information.
- The justification for studying additive gaps could be enhanced by citing previous works on weak types of advice.
- The "consistency vs robustness" framework is overly simplistic, lacking a nuanced analysis of prediction error impacts.

### Suggestions for Improvement
We recommend that the authors improve the paper by providing tightness results to establish the optimality of their algorithms. Additionally, the performance of the algorithms should be expressed as a function of the prediction error without requiring prior knowledge of its bounds. It would also be beneficial to include citations of relevant literature on weak types of advice to strengthen the motivation for additive gaps. Finally, we suggest refining the discussion on "consistency vs robustness" to include a more modern analysis of algorithm performance as a function of prediction error.