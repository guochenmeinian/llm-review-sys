ID: EkcO9tHm6S
Title: Recaptured Raw Screen Image and Video Demoir√©ing via Channel and Spatial Modulations
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 6, 6, 4, 4, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 5, 4, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a neural algorithm for removing moire patterns in images and videos captured from displays, focusing on raw data to exploit simpler moire patterns. The authors propose a new dataset with better alignment and diverse moire patterns to enhance network training. The method achieves state-of-the-art (SOTA) performance in image and video demoireing tasks.

### Strengths and Weaknesses
Strengths:
- The topic is of broad interest, particularly for cellphone camera users capturing display content.
- It is the first paper to explore raw video demoireing.
- The design of channel and spatial modulations is reasonable, effectively integrating information from multiple raw channels.
- The constructed dataset offers extra raw signals, diverse moire patterns, and improved alignment.
- The proposed method achieves SOTA scores and promising visual results.

Weaknesses:
- The paper does not sufficiently cite existing works on raw image and video demoireing, which may undermine its novelty.
- The dataset's train/val/test split is unclear, raising concerns about the generalization ability of the proposed method.
- The method lacks consideration of temporal consistency, potentially leading to flickering in videos with varying moire patterns.
- The network structure is not particularly novel, and the performance gain over existing methods is minimal.

### Suggestions for Improvement
We recommend that the authors improve the citation of existing works, particularly [30], to clarify the novelty of their contributions. Additionally, the authors should provide a clearer explanation of the dataset's train/val/test split to justify the generalization ability of their method. To address temporal consistency, we suggest incorporating techniques to mitigate flickering in video outputs. Furthermore, the authors should consider synthesizing a video dataset using data synthesis approaches as described in [27, 28] to enhance dataset diversity and alignment. Lastly, we encourage the authors to conduct a more detailed comparison of their method in the SRGB domain and explore the impact of loss functions and multi-scale constraints in their experiments.