ID: hLoiXOzoly
Title: Contrastive losses as generalized models of global epistasis
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 5, 5, 6, 7, 5, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 3, 3, 5, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the use of contrastive loss, specifically the Bradley-Terry (BT) loss, as an alternative to Mean Squared Error (MSE) for modeling global epistasis in fitness prediction tasks. The authors demonstrate that the BT loss improves the estimation of fitness functions over MSE by effectively handling both complete and incomplete datasets, as evidenced by experiments on the FLIP benchmark. The paper argues that the BT loss is particularly suitable due to its invariance to monotonic transformations of observed values, which aligns with the characteristics of global epistasis.

### Strengths and Weaknesses
Strengths:
- **Well-motivated approach**: The use of contrastive loss is natural for ranking fitness values, enhancing the learning of the underlying fitness function.
- **Robustness against nonlinearity**: The authors show that different nonlinearities do not significantly affect estimation results, indicating the method's versatility.

Weaknesses:
- **Unclear necessity of nonlinear function $g$**: The role of the nonlinear transformation $g$ in the model is not convincingly justified, as the neural network modeling the fitness function may already capture necessary nonlinearities.
- **Lack of theoretical analysis**: The paper does not provide a rigorous theoretical framework to explain the differences in performance between BT and MSE, particularly under varying conditions.
- **Limited experimental comparisons**: The evaluation is restricted to CNN baselines and the FLIP dataset, lacking comparisons with other standard fitness prediction tasks and models.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the necessity of the nonlinear function $g$ in their modeling framework. Additionally, we suggest incorporating a theoretical analysis that links the hypothesis class of $g$ to its learnability under different loss functions. To strengthen the evaluation, we encourage the authors to include comparisons with other standard fitness prediction tasks and models, such as protein language models and structure-based models. Finally, expanding the experimental setup to include a wider variety of datasets would enhance the robustness of the findings.