ID: CG0L2PFrb1
Title: D4: Improving LLM Pretraining via Document De-Duplication and Diversification
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 6, 5, 6, 8, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 2, 5, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a data filtering method for pre-training language models, termed D4, which combines two existing approaches—SemDeDup and Prototypicality (also referred to as SSL Proto)—in a pipeline to enhance the selection of training data. The authors demonstrate that this method can save up to 20% of training time compared to random data selection and shows that duplicating selected data can yield performance gains. They provide experimental evidence using different datasets and clarify the methodology behind their figures, particularly addressing confusion regarding the x-axis in Figure 1. The authors emphasize the importance of demonstrating significant performance gains from this combination compared to individual methods and reveal that careful data selection can enhance training efficiency and model quality.

### Strengths and Weaknesses
Strengths:
- The method offers a straightforward approach to enhance the value of text data for pre-training large language models (LLMs).
- Extensive experiments validate the proposed method's effectiveness across various model architectures and tasks, including additional experiments on the C4 dataset.
- The paper is well-written, with clear motivations and thorough discussions of related work, and the revisions improve clarity regarding the methodology and definitions.

Weaknesses:
- The proposed method appears incremental, primarily combining two existing techniques without demonstrating significant novelty or substantial performance improvements over them.
- The reliance on the Instruct OPT metric as a primary evaluation measure may undermine the scientific significance, as downstream task scores are of greater interest in the NLP community.
- Certain aspects of the methodology, such as the definition of a document and the clarity of figures, require further elaboration, with some figures still presenting clarity issues despite revisions.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their contribution by providing clearer evidence of D4's superiority over the individual methods it combines. Additionally, we suggest that the authors present more comprehensive comparisons with existing methods in their experiments. Clarifying the definition of a document and the metrics used for perplexity would enhance the paper's clarity. We also recommend that the authors improve the clarity of the Instruct OPT metric's role in the evaluation framework by emphasizing the use of multiple metrics in the manuscript. Furthermore, we encourage the authors to explore the effects of embedding space on data selection, include alternative combinations of the filtering methods as baselines, and conduct experiments with larger models, such as those with 100B parameters, to demonstrate the method's scalability. Lastly, addressing the color selection in figures for better visibility would improve the overall presentation.