ID: u9ShP64FJV
Title: Protecting Your LLMs with Information Bottleneck
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 7, 7, 6, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 2, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents IBProtector, a defense mechanism against jailbreak attacks on large language models (LLMs) based on the information bottleneck (IB) principle. The method compresses and perturbs adversarial prompts using a lightweight, trainable extractor, ensuring retention of essential information while mitigating harmful content generation. Empirical evaluations demonstrate that IBProtector outperforms existing defenses without significantly impacting response quality or inference speed, showcasing its effectiveness and adaptability across various attack methods and target models.

### Strengths and Weaknesses
Strengths:  
1. IBProtector effectively defends against jailbreak attacks without requiring modifications to underlying language models, ensuring compatibility and preserving response quality and inference speed.  
2. The design principle based on IB theory is suitable for extracting task-related information.  
3. The paper is well-organized and easy to follow.  

Weaknesses:  
1. Experiment results on LLaMA need confirmation, as they differ significantly from the original PAIR paper.  
2. The extraction process may favor low-entropy stop words over high-entropy informative words, potentially affecting the quality of the extracted subsentence.  
3. The paper does not address IBProtector's performance against cipher-based jailbreak attacks or adaptive attacks, necessitating further experiments.  

### Suggestions for Improvement
We recommend that the authors improve the experimental design by ensuring that all defenses are trained on the same dataset to allow for fair comparisons. Additionally, conducting tests against white-box attacks is crucial for validating the robustness of IBProtector. We also suggest exploring whether IBProtector can generate contextually coherent sentences using the IB principle, as well as addressing the potential bias towards low-entropy words in the extraction process. Lastly, we encourage the authors to investigate the adaptability of IBProtector to various LLMs and adversarial scenarios, particularly with larger models.