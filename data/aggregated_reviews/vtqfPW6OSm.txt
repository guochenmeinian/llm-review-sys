ID: vtqfPW6OSm
Title: Linear-Time Modeling of Linguistic Structure: An Order-Theoretic Perspective
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to structured prediction problems in NLP, utilizing directed graphs represented as partial orders on a "token-split" set. The authors demonstrate that these partial orders can be expressed as intersections of total orders, specifically showing that k=2 is sufficient for trees and forests. A neural model is trained to generate 2k real numbers per token, enabling the recovery of the tree or forest structure. The experiments conducted on dependency parsing and coreference resolution yield competitive results and notable efficiency.

### Strengths and Weaknesses
Strengths:  
- The contribution is highly original and applicable to various structured prediction problems.  
- The empirical results demonstrate both accuracy and efficiency.  
- The paper establishes interesting connections to lesser-known discrete mathematics literature, presented in a clear and accessible manner.  
- Excellent writing quality, particularly in conveying key ideas.  
- Solid theoretical foundation and elegant approach with wide applicability.

Weaknesses:  
- Dependency parsing experiments utilize gold PoS tags, leading to potentially misleading comparisons.  
- Unclear reasoning regarding the performance difference between k=2 and k=4, despite theoretical guarantees for k=2.  
- Some references to linearization schemes are narrow, missing other relevant approaches.  
- Minor typographical and grammatical issues present throughout the paper.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the dependency parsing comparisons by addressing the use of gold versus predicted PoS tags. Additionally, clarify the performance discrepancy between k=2 and k=4, and consider exploring larger values of k. We suggest expanding the references in Section 2 to include other linearization approaches that prioritize coverage. Furthermore, we encourage the authors to correct typographical errors, such as the unclear meaning of "#token" in Table 2, and to include a non-projective tree example in Appendix J. Finally, moving details about the UD treebanks and hardware used in the efficiency measures to the main text would enhance clarity.