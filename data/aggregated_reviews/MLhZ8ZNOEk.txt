ID: MLhZ8ZNOEk
Title: Swift Sampler: Efficient Learning of Sampler by 10 Parameters
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 5, 7, 6, 6, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 5, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Swift Sampler (SS), an efficient algorithm for automatic learning of data samplers in deep learning model training. SS tackles challenges of high-dimensionality and costly evaluations by mapping samplers to a low-dimensional hyper-parameter space and employing a novel transform function to smooth the objective function. Utilizing Bayesian Optimization, SS efficiently evaluates sampler quality, demonstrating effectiveness in tasks such as image classification and face recognition across datasets like ImageNet and CIFAR, with notable performance improvements. The samplers learned by SS show good transferability across different neural network architectures, indicating the algorithm's generality and computational efficiency.

### Strengths and Weaknesses
Strengths:
1. The writing is clear and easy to read.
2. Extensive experiments enhance the verification of results.
3. The method is novel, with a small number of parameters, enabling application to large datasets.
4. The proposed pipeline with Dimension Reduction, Objective Function Smoothing, and Local Minima Approximation is innovative.
5. Empirical results show consistent improvements across multiple datasets and model architectures.

Weaknesses:
1. The paper lacks ablation studies or sensitivity analyses to demonstrate the impact of different components or hyperparameters.
2. The focus on image classification limits the comprehensiveness; results on more complex tasks would be beneficial.
3. The theoretical analysis of the proposed formulation and approximation method is insufficient.
4. The outer loop's validation set usage may mislead results; clarification is needed on its sampling from the training set.
5. The generalizability of the method beyond image data is not adequately addressed.

### Suggestions for Improvement
We recommend that the authors improve the theoretical analysis of the proposed formulation, transform function, and approximation method to provide deeper justification. Additionally, conducting ablation studies and sensitivity analyses would clarify the effects of various components and hyperparameters. To enhance the comprehensiveness of the work, we suggest including experimental results on more complex tasks beyond image classification, such as detection segmentation in vision or VQA in language. Furthermore, the authors should clarify the sampling strategy for the validation set and discuss the potential computational overhead introduced by the Swift Sampler method. Lastly, we encourage the authors to explore the method's applicability to non-image data to strengthen its generalizability.