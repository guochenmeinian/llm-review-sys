ID: luQiVmnviX
Title: UniBias: Unveiling and Mitigating LLM Bias through Internal Attention and FFN Manipulation
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 6, 6, 5, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into internal biases in large language models (LLMs) that lead to prompt brittleness. The authors propose the UniBias method, which identifies and masks biased components within LLMs, specifically focusing on feedforward networks (FFNs) and attention heads. The method aims to enhance in-context learning (ICL) performance, with experiments across various NLP tasks demonstrating its effectiveness.

### Strengths and Weaknesses
Strengths:
- The paper explores the internal contributions of FFN vectors and attention heads to LLM bias, an area that has received limited attention.
- UniBias is a straightforward method that does not incur additional inference time costs, unlike post-calibration methods.
- The methodology is novel, applying mechanistic interpretability to isolate specific components responsible for prompt brittleness, and shows consistent performance improvements across diverse datasets.

Weaknesses:
- There is a disconnect between the problem of prompt sensitivity and the objectives of the preliminary analysis, particularly regarding the relationship between label bias and prompt bias.
- The paper lacks clarity on how suppressing bias towards labels can alleviate prompt sensitivity, raising questions about the generalizability of the findings across different LLMs and tasks.
- The reliance on grid search with a limited number of labeled instances for identifying biased components raises concerns about scalability and efficiency.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the relationship between label bias and prompt sensitivity in their analysis. Specifically, they should explicitly state how suppressing label bias contributes to mitigating prompt brittleness. Additionally, the authors should consider expanding their analysis to include the identification of shared biased components across tasks and provide more detailed mathematical formulations related to the identification of biased components to enhance reproducibility. Finally, we suggest that the authors explore the distribution of biases across different layers of the model to gain deeper insights into how biases propagate.