ID: A33u66KmYf
Title: BIOSCAN-5M: A Multimodal Dataset for Insect Biodiversity
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 4, 8, 7, 8, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 5, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents BIOSCAN-5M, an expansion of the BIOSCAN-1M dataset, which includes over 5 million high-resolution images and more than 320,000 categories of arthropod specimens, along with multi-modal data inputs such as DNA barcode sequences, taxonomic labels, and geographical information. The authors propose three benchmark experiments to demonstrate the dataset's utility: DNA-based taxonomic classification, zero-shot image/barcode feature clustering, and multimodal retrieval among images, barcodes, and Linnaean taxonomy text sequences. The main contribution is the provision of a significantly larger dataset, which aims to enhance classification performance at various taxonomic levels.

### Strengths and Weaknesses
Strengths:
- The dataset is well-constructed with meticulous annotations, including valuable multi-modal data.
- It significantly expands the previous BIOSCAN-1M dataset, providing a more diverse and larger-scale resource.
- The benchmarks are well-designed, showcasing the dataset's applicability for machine learning tasks.

Weaknesses:
- The geographical coverage is limited, particularly in northern Africa and Asia, which may affect the dataset's representativeness.
- The benchmarks do not leverage geographical information or size data, which could enhance model performance.
- Taxonomic annotation is limited beyond the family rank, impacting the relevance of sequence classification using advanced ML models.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the terminology used, specifically by replacing 'species' with 'taxon/taxa' where appropriate to avoid confusion. Additionally, we suggest that the authors include an error analysis in their benchmarks to identify patterns of model confusion and guide future data collection efforts. It would also be beneficial to explore the impact of geographical and size information on classification accuracy in future benchmarks. Lastly, we encourage the authors to consider expanding the geographical coverage of the dataset and incorporating habitat information in future versions to enhance its utility for researchers.