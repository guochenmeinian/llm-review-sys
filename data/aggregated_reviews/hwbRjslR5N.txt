ID: hwbRjslR5N
Title: Visual Riddles: a Commonsense and World Knowledge Challenge for Large Vision and Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 7, 9, 7, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new dataset and benchmark called Visual Riddles, designed to evaluate vision-language models (VLMs) on visual question answering (VQA) tasks that require identifying subtle visual cues and leveraging commonsense knowledge. The dataset consists of 400 visual riddles generated by various text-to-image models, and the authors compare the performance of multiple VLMs against human responses. The findings indicate that current models underperform compared to human accuracy.

### Strengths and Weaknesses
Strengths:
- The dataset creation and benchmark design are well thought out, incorporating diverse tools and cultural knowledge.
- The paper evaluates multiple open-sourced VLMs and considers various tasks, including auto-evaluations.
- The clarity and quality of writing enhance the paper's accessibility.

Weaknesses:
- A breakdown of the generative image tools used and the backgrounds of the creators would enhance the benchmark's diversity.
- Table 1's human rating percentage is confusing and requires clarification.
- The difficulty levels of the riddles are unclear, and aggregated performance data across difficulties is needed.
- More examples of visual riddles and their correct answers should be included for better understanding.
- Given the small dataset size, a statistical analysis of results and evaluations over multiple seeds is recommended.

### Suggestions for Improvement
We recommend that the authors improve clarity by providing a breakdown of the generative tools and the backgrounds of the creators. Additionally, please clarify the human rating percentage in Table 1 and provide aggregated performance data across difficulty levels. Including more examples of visual riddles with correct answers would also enhance comprehension. Finally, we suggest conducting a statistical analysis of the results to strengthen the findings given the dataset's limited size.