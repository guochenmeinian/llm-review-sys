ID: RLmpJ4xol2
Title: Learning Preference Model for LLMs via Automatic Preference Data Generation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents AutoPM, an innovative approach for enhancing preference model generation through two novel data generation methods: In-Breadth Data Generation (IBDG) and In-Depth Data Generation (IDDG). These methods aim to create a more reliable preference model that effectively captures human preferences. The authors support their claims with comprehensive experiments on five benchmark datasets, demonstrating the effectiveness of their approach.

### Strengths and Weaknesses
Strengths:  
- The paper clearly defines its primary contribution, detailing the rationale behind the data generation techniques and their effectiveness in capturing human preferences.  
- Extensive experimentation on diverse datasets enhances the credibility of the proposed methods, with detailed insights into the experimental setup and comparative analyses.  
- The in-breadth and in-depth methods target specific alignment criteria, leading to better performance than baseline models despite fewer preference samples.  
- The experiments are thorough, evaluating the preference model across multiple alignment criteria and demonstrating its utility as a re-ranker.

Weaknesses:  
- Some aspects of training Preference Models require further exploration, particularly regarding alternative training methods that could complement the data generation techniques.  
- The writing is frequently unclear, making it difficult to fully grasp the authors' intentions.  
- There is insufficient comparison between the three data generation methods, weakening the justification for each.  
- The impact of the amount of generated data on results remains unclear, with fixed amounts used in experiments leaving questions about data diversity and model performance.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing throughout the paper to enhance reader comprehension. Additionally, we suggest conducting more comparisons between the data generation methods to substantiate their individual contributions. It would also be beneficial to explore how varying the amount of generated data affects model performance and to report inter-annotator agreement for consistency evaluations. Finally, we encourage the authors to discuss the relevance of Constitutional AI in relation to their work.