ID: nB1Apc36yp
Title: Beyond Binary: Towards Fine-Grained LLM-Generated Text Detection via Role Recognition and Involvement Measurement
Conference: ACM
Year: 2024
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to detecting LLM-generated content through two tasks: LLM Role Recognition (LLM-RR) for identifying specific roles of LLMs in content generation, and LLM Influence Measurement (LLM-IM) for quantifying LLM involvement. The authors introduce the LLMDetect benchmark, which includes the Hybrid News Detection Corpus (HNDC) and the DetectEval evaluation suite, aimed at assessing model robustness across diverse contexts. The study evaluates multiple baseline detection methods, revealing that fine-tuned models like DeBERTa outperform others in detecting LLM-generated content.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant topic, advancing detection methods for LLM-generated content.
- The clear structure and thorough methodology enhance the presentation.
- The development of the LLMDetect benchmark provides valuable tools for future research.

Weaknesses:
- The training dataset is limited to specific news domains and a single LLM, reducing generalizability.
- The boundaries between roles in LLM-RR are unclear, and the necessity of LLM-RR alongside LLM-IM is questionable.
- Insufficient technical details on generation steps and hyperparameters hinder reproducibility.
- The reliance on reused prompts raises concerns about overfitting, as indicated by degraded performance in cross-domain evaluations.

### Suggestions for Improvement
We recommend that the authors improve dataset diversity by incorporating a wider range of text types beyond news articles. Additionally, we suggest providing more detailed descriptions and summary statistics for DetectEval, including the number of tasks and domains included. Clarifying the rationale behind the 7:2:1 train-validation-test split, as opposed to cross-validation, would strengthen the methodology. The authors should also address the potential overfitting caused by prompt reuse and clarify the practical distinctions between LLM-RR and LLM-IM. Finally, we encourage the inclusion of additional interpretability and error analysis to enhance the understanding of model performance.