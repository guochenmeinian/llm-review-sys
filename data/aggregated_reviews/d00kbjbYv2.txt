ID: d00kbjbYv2
Title: How to Train Your  Dragon: Diverse Augmentation Towards Generalizable Dense Retrieval
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a data augmentation framework for dense retrieval models (DRAGON), enabling BERT-size models to achieve state-of-the-art performance. The authors propose a unified approach that combines query augmentation techniques, such as sentence cropping and synthetic queries, with a progressive label method for relevance label augmentation. The experimental results indicate that the proposed method is effective and less expensive compared to prior work.

### Strengths and Weaknesses
Strengths:
- The proposed method demonstrates state-of-the-art performance in both supervised and zero-shot evaluation settings.
- The paper is well-written, structured, and explores the important issue of enhancing performance while maintaining or reducing model size.
- The experimentation effectively illustrates the impact of various query augmentation approaches and training supervision methods.

Weaknesses:
- Technical details are insufficient for easy reproduction, lacking clarity on error propagation prevention and theoretical analysis.
- The optimal number of supervisions for relevance label augmentation is unclear, and statistical significance of improvements is not reported.
- Concerns regarding the complexity introduced by requiring multiple teacher retrievers and the potential for overfitting due to augmented data are not adequately addressed.

### Suggestions for Improvement
We recommend that the authors improve the technical details provided in the paper, including code disclosure, to facilitate easy reproduction and evaluation of the proposed method. Additionally, conducting a thorough theoretical analysis on preventing error propagation during data augmentation would enhance the paper's scientific rigor. Clarifying the optimal number of supervisions for relevance label augmentation and reporting statistical significance for improvements would also strengthen the findings. Finally, addressing the potential for model collapse due to augmented data would provide a more comprehensive understanding of the proposed framework.