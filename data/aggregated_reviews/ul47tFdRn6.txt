ID: ul47tFdRn6
Title: DiffuVST: Narrating Fictional Scenes with Global-History-Guided Denoising Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DiffuVST, a diffusion-based system for visual storytelling that generates coherent narratives from images through a single conditional denoising process. The authors propose a unique design incorporating bi-directional text history guidance and multimodal adapter modules, enhancing inter-sentence coherence and image-to-text fidelity. Experimental results indicate that DiffuVST outperforms traditional autoregressive models in text quality and inference speed across four fictional visual-story datasets.

### Strengths and Weaknesses
Strengths:
- The DiffuVST model is innovative, being the first to utilize diffusion models in visual storytelling, effectively addressing efficiency challenges.
- Comprehensive experiments demonstrate superior performance compared to previous autoregressive models, with well-motivated design choices.
- The paper is well-written and easy to follow, with thorough analyses of various parameters.

Weaknesses:
- The architecture and mathematical formulation of the multimodal adapter module are not specified, raising concerns about clarity.
- Limited baseline comparisons hinder the assessment of DiffuVST's true performance; only an outdated LSTM model is used as a baseline.
- The paper lacks qualitative results and detailed analyses of the model's advantages beyond inference speed, and it does not address the limitations of DiffuVST adequately.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the architecture and mathematical formulation of the multimodal adapter module. Additionally, the authors should include comparisons with more recent state-of-the-art autoregressive models to validate the effectiveness of DiffuVST. Providing qualitative results and a thorough analysis of the model's strengths and weaknesses, as well as addressing the limitations of the proposed method, would enhance the paper's contribution. Furthermore, we suggest that the authors clarify the technical details, such as the forward training process and the specific diffusion model utilized.