ID: QVuVwt1QLh
Title: Unifying Text, Tables, and Images for Multimodal Question Answering
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on multimodal question answering (MMQA) through a framework called UniMMQA, which integrates text, tables, and images into a text-to-text format using position-enhanced table linearization and diversified image captioning techniques. The authors argue that existing MMQA methods are limited by single-modal or bi-modal approaches, and their framework aims to enhance cross-modal reasoning by incorporating a multimodal rationale generator. Experimental results indicate that UniMMQA outperforms prior methods on benchmark datasets.

### Strengths and Weaknesses
Strengths:
- The paper is well-structured and presents a coherent approach to improving MMQA by aggregating multiple modalities.
- Comprehensive experiments and ablation studies support the claims made.
- The incorporation of a multimodal rationale generator is a valuable addition that may enhance reasoning capabilities.

Weaknesses:
- The technical novelty and contributions are perceived as limited, with methods such as diversified image captioning and table linearization being seen as incremental.
- The complexity of the UniMMQA framework may hinder its practical implementation, as multiple techniques are introduced without sufficient clarity.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the integration process by providing more comprehensive explanations and examples. Additionally, addressing the limitations mentioned regarding the image model's ability to extract detailed information would strengthen the paper. Specifically, we suggest comparing the current approach with the use of a visual encoder or a frozen visual encoder in conjunction with fine-tuning T-5 models. Furthermore, the authors should clarify the rationale examples presented, as some may not effectively support downstream QA tasks.