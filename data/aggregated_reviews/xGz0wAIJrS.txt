ID: xGz0wAIJrS
Title: State2Explanation: Concept-Based Explanations to Benefit Agent Learning and User Understanding
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 4, 7, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents State2Explanation (S2E), a framework designed to enhance the training of reinforcement learning (RL) agents by leveraging the Protégé Effect, which posits that explaining knowledge reinforces self-learning. The authors propose a method for learning joint embeddings between state-action pairs and concept-based explanations, facilitating reward shaping that benefits both the agent and the end-user. The framework is validated through experiments in two RL environments: Connect 4 and Lunar Lander, demonstrating improvements in both agent training and user performance. Additionally, the paper includes a user study structured into four stages: "practice," "pre-test," "explanation," and "post-test," investigating the impact of different types of explanations on user performance in games. The authors suggest that "action-based" or "value-based" explanations may lead to decreased user performance due to misinterpretations of agent actions and propose conducting in-depth qualitative analyses, such as semi-formal interviews, to explore this further.

### Strengths and Weaknesses
Strengths:
1. The paper provides concrete desiderata for concept explanations, emphasizing generalizability and task relevance.
2. The approach of reward shaping through explanations is potentially novel and expands the utility of explanations beyond mere interpretability.
3. A thorough evaluation assesses the impact of various model components, clarifying the roles of Information Filtering (InF) and Temporal Grouping (TeG).
4. The user study design is comprehensive, with clear stages that facilitate understanding of user interactions.
5. The authors provide a robust statistical justification for their sample size, demonstrating high statistical power.
6. The user study effectively demonstrates the real-world applicability of the model from a human explainability perspective.

Weaknesses:
1. The reliance on expert knowledge for defining concepts may limit generalizability to complex domains with extensive state-action pairs.
2. The absence of an additional baseline in Section 6 obscures the impact of the study conditions, particularly regarding the influence of practice on performance.
3. Claims about reward shaping in Lunar Lander may stem from the definitions of concepts rather than the algorithm's performance.
4. The rationale for the chosen cutoff of a single action as an indicator of participant effort may be perceived as overly simplistic.
5. The need for more qualitative insights into user experiences is acknowledged but not yet implemented.
6. The paper condenses too much information, leading to readability issues, particularly with complex figures.
7. There is insufficient discussion on the challenges of creating frameworks for more intricate scenarios and the implications of incorrect explanations on training and user performance.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the presentation, particularly in figures and complex sections, to enhance readability. Additionally, consider including a baseline with no intervention to better assess the performance impacts of the proposed framework. It would be beneficial to discuss how concepts can be selected beyond expert-defined thresholds and to elaborate on the process of creating, storing, and verifying these concepts. We also suggest that the authors improve the qualitative analysis by incorporating semi-formal interviews post-study to gain deeper insights into user experiences and performance declines. Furthermore, refining their criteria for participant effort beyond the single action cutoff would help avoid potential biases in interpreting user engagement. Finally, addressing the potential consequences of incorrect explanations on both training and user performance would strengthen the paper's contributions.