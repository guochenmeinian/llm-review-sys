ID: 4WrqZlEK3K
Title: LMGQS: A Large-scale Dataset for Query-focused Summarization
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to curate a large dataset for query-focused summarization (QFS) by leveraging Large Language Models (LLMs) to generate hidden queries from existing summarization datasets. The authors propose a dataset construction framework that eliminates the need for labor-intensive human annotation, resulting in the LMGQS dataset. The paper demonstrates the effectiveness of the LMGQS dataset by fine-tuning a pretrained language model, achieving state-of-the-art performance on multiple QFS benchmarks. Additionally, it addresses the challenge of query unification across diverse formats.

### Strengths and Weaknesses
Strengths:
- Innovative dataset construction that creatively addresses the lack of large-scale QFS datasets.
- The LMGQS BART model achieves state-of-the-art zero-shot and supervised performance on multiple benchmarks.
- Extensive evaluation of the LMGQS dataset and proposed models against baseline models, including a human study.
- The approach to query unification effectively tackles a critical challenge in zero-shot QFS.

Weaknesses:
- The novelty primarily lies in using LLMs for query augmentation, but the quality of generated queries lacks thorough validation.
- Insufficient analysis on the accuracy and meaningfulness of query conversions, which may lead to misaligned summaries.
- Potential biases in queries generated by InstructGPT and insufficient discussion on hyperparameter sensitivity affecting performance.
- Several unclear methods hinder readability and reproducibility, such as the specifics of fine-tuning the BART model and the query transformation process.

### Suggestions for Improvement
We recommend that the authors improve the validation of the quality of generated queries to provide a more comprehensive analysis. Additionally, addressing the ambiguities in query transformation and ensuring accurate conversions across datasets is crucial. We suggest including a section on potential biases or controversial language produced by InstructGPT to address ethical concerns. Furthermore, clarifying the fine-tuning process of the BART model and providing detailed hyperparameter settings would enhance reproducibility. Lastly, we encourage the authors to compare the LMGQS dataset with existing datasets like QMDSIR and QMDSCNN to highlight its advantages.