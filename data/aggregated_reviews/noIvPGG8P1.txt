ID: noIvPGG8P1
Title: Search Augmented Instruction Learning
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for fine-tuning language models to effectively utilize web search results for knowledge-intensive tasks. The authors create a new dataset by querying search engines with self-instructions and labeling results as informative or distracting using an entailment model. Fine-tuning the LLaMA-7B model on this dataset leads to significant improvements in various tasks, including instruction following and question answering, particularly on a new corpus of questions from recent articles.

### Strengths and Weaknesses
Strengths:  
- The problem addressed is both interesting and important, focusing on filtering noisy information to enhance LLM performance.  
- The proposed method is simple yet effective, improving the ability of LLMs to filter out irrelevant contexts.  
- The experimental results are convincing, demonstrating performance gains across multiple downstream tasks.  

Weaknesses:  
- The paper lacks detailed information about the datasets, such as the number of retrieved, informative, and noisy documents.  
- The evaluation does not clarify whether performance improvements can be attributed to the denoising capability of the proposed method.  
- The finetuning method is perceived as simple and ad-hoc, limiting its technical novelty.  

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper's title to better reflect its contributions regarding instruction fine-tuning and the role of public search engines. Additionally, please provide evidence for the claim that models are misled by search results, as this is a guiding theme. Clarifying the starting point of model generation in Figure 1 and addressing the concerns raised about its example would enhance understanding. We suggest revising the terminology in Footnote 1 to "privacy-preserving" and ensuring consistency in referring to the new datasets as either "New-Questions-80" or "News-Questions-80." Furthermore, please include more details on the dataset composition and present prediction results on both noisy and informative documents to demonstrate the denoising ability of the proposed method. Lastly, we encourage the authors to consider the implications of using GPT-4 as an evaluator, given its potential limitations.