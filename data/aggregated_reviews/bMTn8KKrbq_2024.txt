ID: bMTn8KKrbq
Title: Towards training digitally-tied analog blocks via hybrid gradient computation
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 6, 7, 7, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Feedforward-tied Energy-based Models (ff-EBMs), a hybrid model that integrates analog energy-based models (EBMs) and digital feedforward layers for digital and analog circuits. The authors propose an algorithm for end-to-end gradient computation, combining backpropagation and equilibrium propagation, and apply the Lagrangian method to derive optimality conditions. The model demonstrates state-of-the-art performance on the ImageNet32 dataset, achieving a top-1 accuracy of 46%. The primary source of accuracy improvement is attributed to the increased depth of the model, with ff-EBMs being trained to twice the depth of previous EBMs. The method is deemed hardware plausible, as it accommodates both analog and digital operations, scales linearly with the number of blocks, and enhances convergence time. 

### Strengths and Weaknesses
Strengths:  
1. The paper tackles an important problem in AI training, presenting a robust framework that effectively combines analog and digital components.  
2. The application of the Lagrangian method provides a rigorous framework for training the hybrid model.  
3. The proposed algorithm effectively intertwines backpropagation and equilibrium propagation, validated by compelling experimental results.  
4. The model's ability to scale linearly with depth is a significant advantage over previous methods, enhancing performance and efficiency.  
5. The method is hardware plausible and can leverage quantization and zero-order (ZO) algorithms for efficient implementation.  

Weaknesses:  
1. The paper lacks a detailed analog computing device model, leaving questions about the tolerance of ff-EBMs to variations in analog devices and the relationship between convergence speed and these variations.  
2. Energy efficiency claims are not clearly articulated; the paper does not provide energy-related data or comparisons with existing systems.  
3. The reliance on the ImageNet32 dataset for validation may limit the generalizability of findings; a broader range of datasets should be considered.  
4. The motivation for combining analog and digital components is vague, and the advantages of incorporating energy-based models over other methods are not sufficiently explained.  
5. The paper may benefit from clearer communication of high-level motivations and algorithmic details.  

### Suggestions for Improvement
We recommend that the authors improve the discussion on the analog computing device model, specifically addressing how significant variations in analog devices affect the performance of ff-EBMs and the relationship between convergence speed and these variations. Additionally, we suggest including energy-related data to substantiate energy efficiency claims and providing detailed comparisons with existing systems. Expanding the experimental validation to include a broader range of datasets would strengthen the paper's conclusions. We also recommend improving the clarity of the high-level motivations and details of their algorithm to enhance reader understanding. Lastly, adding a pseudo algorithm in the appendix to demonstrate how ZO could be applied within feedforward blocks would allow gradients to be computed using forward passes only in both analog and feedforward components.