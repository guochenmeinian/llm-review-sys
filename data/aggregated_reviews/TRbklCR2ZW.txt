ID: TRbklCR2ZW
Title: GLOBER: Coherent Non-autoregressive Video Generation via GLOBal Guided Video DecodER
Conference: NeurIPS
Year: 2023
Number of Reviews: 20
Original Ratings: 4, 6, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel video generation framework called GLOBER, which utilizes a non-autoregressive method to generate global features for video synthesis. The authors argue that their approach, which includes a video auto-encoder and a decoder that synthesizes frames based on global features, outperforms existing methods on benchmarks such as UCF-101, Taichi-HD, and SkyTimelapse. The study also introduces a coherence and realism adversarial loss to enhance the quality of the generated videos.

### Strengths and Weaknesses
Strengths:
- The proposed method improves inference efficiency by employing a non-autoregressive approach.
- The inclusion of Coherence and Realism Adversarial Loss is a novel contribution that enhances video quality.
- Extensive experiments demonstrate the method's effectiveness across multiple benchmarks.

Weaknesses:
- The framework's complexity, including numerous notations, makes it challenging to follow. Specific questions arise regarding the integration of $I_j$ in the video decoder and the training methodology of components like KL-VAE.
- The paper lacks a comparison with recent latent video diffusion models (e.g., LVDM and PVDM) regarding efficiency and performance.
- There are inconsistencies in reported results that hinder direct comparisons with related works, such as VideoFusion.
- The method's scalability for long videos and complex datasets remains uncertain, particularly concerning the low-dimensional latent representation.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the framework by simplifying notations and providing detailed explanations for the integration of components. Additionally, we suggest including comparisons with recent latent video diffusion models to substantiate claims of efficiency and performance. Addressing the inconsistencies in results and providing justifications for GLOBER's superiority over VideoFusion, beyond the CRA loss, would strengthen the paper. Finally, we encourage the authors to conduct experiments on long videos with higher-dimensional latents to evaluate scalability and performance comprehensively.