ID: cCL92OPlDz
Title: ParallelEdits: Efficient Multi-Aspect Text-Driven Image Editing with Attention Grouping
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 6, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ParallelEdits, a method for simultaneous editing of multiple objects or attributes while maintaining quality, utilizing a novel attention distribution mechanism and multi-branch design. The authors introduce the PIE-Bench++ dataset for evaluating multi-object and multi-attribute image editing tasks. Experimental results indicate that ParallelEdits outperforms existing editing techniques.

### Strengths and Weaknesses
Strengths:
1. The task of multi-aspect editing is both interesting and practically useful.
2. The proposed method demonstrates efficiency in application.
3. The overall editing results exhibit promising visual effects, with seamless integration of different aspect edits.

Weaknesses:
1. The theoretical basis of the proposed method, particularly the DDCM process, appears questionable, as it suggests that the output $z$ equals $z_0$, indicating no need for Virtual Inversion.
2. The pairing process of $E^{i \rightarrow j}$ may burden users, especially with multiple objects.
3. The paper lacks clarity on how to select the hyperparameter $\lambda$ for rigid and non-rigid edits, and its impact on cross-branch interaction.
4. There is insufficient discussion on controlling the editing strength of multiple actions, which is crucial for harmonious editing.
5. The paper does not conduct qualitative and quantitative experiments to support claims regarding the order of aspect modifications affecting quality.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the theoretical foundations, particularly regarding the DDCM process and the necessity of Virtual Inversion. Additionally, presenting intermediate editing results for sequential editing would help readers understand the limitations of previous methods. We suggest incorporating a comprehensive evaluation using the benchmark proposed in [2]. Furthermore, the authors should clarify how to obtain the attention map M for real images and explain the combination of the attention map with the target prompt in Figure 2. Lastly, a discussion on the control of editing strength and the implications of hyperparameter $\lambda$ on editing outcomes would enhance the paper's depth.