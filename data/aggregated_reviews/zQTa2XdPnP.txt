ID: zQTa2XdPnP
Title: AI4HPC: Library to Train AI Models on HPC Systems using CFD Datasets
Conference: NeurIPS
Year: 2023
Number of Reviews: 5
Original Ratings: 2, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 5, 3

Aggregated Review:
### Key Points
This paper presents an open-source library designed to connect artificial intelligence systems with high-performance computing for exascale applications, specifically targeting Computational Fluid Dynamics (CFD) simulations. The authors describe the library's components, which include data manipulation, machine learning algorithm training, distributed training handling, hyperparameter optimization, and monitoring capabilities. The library demonstrates scalability up to 3664 GPUs. However, the paper lacks clarity on how the library assists users from different fields, such as physics, in applying AI to HPC contexts.

### Strengths and Weaknesses
Strengths:
- The library addresses significant challenges in integrating AI with CFD and proposes multiple solutions.
- Performance results indicate good scalability and efficiency, achieving a speedup with 916 compute nodes.
- The library is applicable to various machine learning architectures and features an easy compilation process.

Weaknesses:
- The contribution of the library is unclear, with no comparison to existing libraries that serve similar functions.
- There is insufficient explanation of how the library optimizes AI in CFD simulations, and the pros and cons of proposed solutions are not discussed.
- The paper lacks detailed performance analysis and does not specify which ML architecture was used for testing.
- The documentation is inadequate, with installation instructions and software citations improperly formatted.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the library's contributions by providing a detailed comparison with existing frameworks, such as PhiFlow and Modulus. Additionally, the authors should clarify how the library can handle various data types, including irregular meshes, and specify the ML architectures used in performance tests. We suggest including a thorough performance analysis that discusses the impact of each optimization and solution proposed. Furthermore, we advise that installation instructions be moved to documentation rather than included in the paper, and that the authors provide the code for review, possibly through Zenodo. Lastly, the authors should consider expanding the paper to include more detailed descriptions of the library's modules and their functionalities.