ID: vwr4bHHsRT
Title: Optimal Regret Is Achievable with Bounded Approximate Inference Error: An Enhanced Bayesian Upper Confidence Bound Framework
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 7, 6, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study of Bayesian bandit algorithms utilizing approximate posteriors, specifically introducing the Enhanced Bayesian Upper Confidence Bound (EBUCB) algorithm. The authors demonstrate that under a two-bounded $\alpha$-divergence assumption, EBUCB achieves an optimal logarithmic regret of $O(\log T)$. They also establish that sub-linear regret cannot be attained with only one-bounded $\alpha$-divergence. Theoretical findings are corroborated through experiments in synthetic environments.

### Strengths and Weaknesses
Strengths:  
1. The paper addresses a significant issue in Bayesian bandit algorithms by providing a surprising result: an upper bound of $O(\log T)$-regret that does not depend on $\varepsilon$.  
2. The authors conduct experiments, albeit in simple synthetic environments, to validate their theoretical results.  

Weaknesses:  
1. The dependence of $\varepsilon$ in Corollary 3.8 is not adequately discussed, raising questions about its implications.  
2. The results are limited to Bernoulli bandits, which restricts the generalizability of the findings to more complex distributions.  

### Suggestions for Improvement
We recommend that the authors improve the discussion surrounding the dependence of $\varepsilon$ in Corollary 3.8 to clarify its significance. Additionally, the authors should address the limitations of their results being confined to Bernoulli distributions and provide insights into the applicability of their findings to more general distributions, such as Gaussian. Further, we suggest that the authors elaborate on the intuition behind why small $\alpha$-divergence is insufficient and how two-bounded $\alpha$-divergence facilitates their results.