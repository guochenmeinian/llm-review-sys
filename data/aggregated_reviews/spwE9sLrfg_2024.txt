ID: spwE9sLrfg
Title: Verified Code Transpilation with LLMs
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 4, 3, 7, 3, -1
Original Confidences: 4, 4, 3, 3, -1

Aggregated Review:
### Key Points
This paper presents LLMLIFT, an LLM-based approach for building verified lifting tools that automates code transpilation for domain-specific languages (DSLs). LLMLIFT utilizes large language models (LLMs) to generate both code and proof annotations, demonstrating improved performance over previous symbolic-based tools in terms of the number of benchmarks transpiled and transpilation time, while requiring less effort to build. The evaluation covers four real-world DSLs, showcasing the method's potential for achieving functional correctness.

### Strengths and Weaknesses
Strengths:
- The paper addresses an important problem in code transpilation, demonstrating a novel integration of LLMs and verification to produce provably correct code.
- The approach effectively utilizes Python as an intermediate representation (IR), enhancing readability and accuracy.
- The evaluation is comprehensive, covering diverse scenarios and showing significant improvements in latency and semantic accuracy.

Weaknesses:
- The writing is unclear and contains syntactic and semantic issues, including typos and a lack of technical details on key processes such as verifying equivalence and generating target programs.
- The experimental results do not convincingly illustrate the advantages of LLMs for validation, and the paper lacks a performance comparison.
- The novelty is limited, as similar approaches exist, and the paper does not adequately discuss its limitations or the rationale behind key design choices.

### Suggestions for Improvement
We recommend that the authors improve the clarity and formalization of the writing, addressing syntactic and semantic issues. It would be beneficial to include detailed explanations of the verification method and the process of generating target programs from program summaries in the appendix. We suggest designing benchmarks that better demonstrate LLMLIFTâ€™s advantages, particularly in solving a greater number of test cases. Additionally, including ablation studies on important hyperparameters and providing a clearer rationale for design choices, such as the selection of Python as the IR and the use of GPT-4, would enhance the paper's rigor.