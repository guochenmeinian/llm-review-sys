ID: tRRWoa9e80
Title: Token Merging for Training-Free Semantic Binding in Text-to-Image Synthesis
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 7, 6, 6, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method to address the semantic binding problem in text-to-image (T2I) models by merging tokens of entities and their related attributes. The authors introduce Token Merging (ToMe), which aggregates related tokens into a composite token, ensuring they share the same cross-attention map. Two training-free optimizations are proposed: Semantic Binding loss, which aligns the composite token's predictions with the full phrase, and Entropy loss, which focuses tokens on their designated regions. The authors analyze the information encoded in different tokens and demonstrate that their method outperforms or is comparable to existing approaches.

### Strengths and Weaknesses
Strengths:
- The creation of a composite token and its optimization is a creative approach to the semantic binding issue.
- The focus on object binding fills a gap in the literature.
- The analysis of information encoded in tokens, particularly in EOT tokens, is insightful.
- The paper is well-written and presents extensive experimental results.

Weaknesses:
- The related work section underrepresents the contributions of Attend-and-Excite and SynGen, which are foundational to this paper.
- The method's performance on complex prompts is unclear, particularly regarding how it handles attributes of sub-objects.
- Lack of human evaluation experiments raises concerns about the reliability of the automatic metrics used.
- The iterative composite token update process lacks clarity, particularly in how the proposed losses are integrated during testing.

### Suggestions for Improvement
We recommend that the authors improve the related work section by adequately crediting Attend-and-Excite and SynGen for their contributions. Additionally, clarify how syntactic information is obtained and whether it is automatic or an input constraint. We suggest including examples of complex prompts to demonstrate ToMe's effectiveness in those scenarios. Conducting a user study would enhance the validation of ToMeâ€™s performance. Lastly, please elaborate on the iterative composite token update process and how the proposed losses are utilized in the T2I pipeline.