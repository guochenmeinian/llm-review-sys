ID: Yg5uDwWQti
Title: Beat LLMs at Their Own Game: Zero-Shot LLM-Generated Text Detection via Querying ChatGPT
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a "zero-shot black-box method" for detecting texts generated by Large Language Models (LLMs). The authors propose measuring the similarity between original texts and their revisions by ChatGPT, positing that LLM-generated texts will require fewer revisions. The method achieves state-of-the-art results across multiple datasets and demonstrates strong out-of-distribution generalization. However, the reliance on ChatGPT for revisions raises questions about the method's performance with other models.

### Strengths and Weaknesses
Strengths:  
- The approach is novel, simple, and effective, addressing the important task of detecting machine-generated text.  
- The authors provide promising findings from evaluations across various datasets, achieving good generalization.  
- The study is sound, with sufficient support for its claims.

Weaknesses:  
- Baseline comparisons may be flawed due to the use of different models for generating text and calculating log likelihood, undermining the reliability of comparisons.  
- The continuous reference to appendices for crucial information detracts from the paper's readability.  
- The method's performance is only tested with ChatGPT, leaving uncertainty about its effectiveness with other models.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by minimizing reliance on appendices for critical information. Additionally, we suggest including datasets such as XSum, SQuAD, and WritingPrompts to enhance comparability with DetectGPT. To strengthen the findings, consider testing the method with other models, such as Claude or PALM, to evaluate its robustness across different generator-revision model pairs. Lastly, addressing the limitations of binary classification in detecting machine-generated text could enhance the overall impact of the study.