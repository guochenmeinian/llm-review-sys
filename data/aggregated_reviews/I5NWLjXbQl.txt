ID: I5NWLjXbQl
Title: ACQUIRED: A Dataset for Answering Counterfactual Questions In Real-Life Videos
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the ACQUIRED dataset, designed for counterfactual reasoning in real-life videos, incorporating physical, social, and temporal dimensions. The authors benchmark various video-language models and a state-of-the-art text-only model (GPT-4) on this dataset, revealing significant challenges in utilizing video contexts for counterfactual reasoning. The dataset aims to motivate advancements in multimodal models capable of such reasoning.

### Strengths and Weaknesses
Strengths:
- The dataset is novel and serves as a valuable testbed for evaluating counterfactual reasoning in multimodal contexts.
- The task is challenging, evidenced by a notable performance gap between human and model responses.
- Extensive benchmarking of recent models enhances the dataset's credibility and relevance.

Weaknesses:
- Annotation details are unclear, necessitating further clarification.
- The novelty is limited due to existing datasets like NExTQA and Causal-VidQA, which require more thorough discussion.
- Some writing lacks clarity and requires improvement.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the annotation details and provide a more in-depth analysis of existing datasets such as NExTQA and Causal-VidQA. Additionally, we suggest enhancing the writing for better comprehension. In section 3.1, the authors should specify the pretrained (text-only) QA model chosen and the rationale behind this selection, as well as provide detailed sampling methods for validation, including sample rates and quantitative results like error rates. Furthermore, we advise revising the answer format to incorporate an answer-reasoning mode, as this would better reflect the model's reasoning capabilities in counterfactual situations.