ID: VIaw1XHb4G
Title: Interactive Multi-fidelity Learning for Cost-effective Adaptation of Language Model with Sparse Human Supervision
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 6, 7, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Interactive Multi-Fidelity Learning (IMFL) framework aimed at developing small domain-specific Large Language Models (LLMs) under limited annotation budgets. The authors propose a method that balances low-fidelity LLM annotations with high-fidelity human annotations to enhance model performance. Through experiments on four domain-specific tasks, particularly in financial and medical domains, the IMFL framework demonstrates superior performance compared to single fidelity annotations, providing a cost-effective solution for LLM development.

### Strengths and Weaknesses
Strengths:
- The paper effectively addresses practical challenges in deploying LLMs for domain-specific tasks, particularly regarding scale and high annotation costs.
- The IMFL framework offers a realistic and effective strategy for optimizing the performance of fine-tuned LLMs under resource constraints.
- Extensive experiments validate the method across different datasets, consistently outperforming baseline models and providing empirical evidence of its effectiveness.

Weaknesses:
- The paper lacks a comprehensive comparison with alternative approaches or baselines, which would better highlight the specific advantages of IMFL.
- There is insufficient rationale provided for the selection of datasets used in the experiments.
- The assumption of having a good pool of unlabeled data is a significant limitation, as many real-world settings may not have such data readily available.

### Suggestions for Improvement
We recommend that the authors improve the paper by providing a more detailed comparison with alternative annotation approaches to better illustrate the advantages of IMFL. Additionally, offering a clearer rationale for dataset selection would enhance the paper's clarity. It would also be beneficial to explore the effects of using different LLMs, such as GPT-3.5 and GPT-4, as annotators, and to include performance analyses under varying annotation budgets. Furthermore, we suggest including a detailed description of the "prompt retrieval" process in Algorithm 1 for clarity, as well as providing tables for hyperparameters used in model training and additional statistics on dataset characteristics.