ID: 1L5vaNIoK5
Title: Diffusion Policy Attacker: Crafting Adversarial Attacks for Diffusion-based Policies
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 7, 6, 4, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DP-Attacker, a suite of algorithms designed to generate adversarial attacks against diffusion-based policies (DPs). The authors explore two attack scenarios: (1) hacking the scene camera by adding imperceptible digital perturbations to visual inputs, and (2) hacking the scene by attaching small adversarial patches to the environment. The effectiveness of DP-Attacker is demonstrated through extensive experiments on pre-trained diffusion policies across various robotic manipulation tasks, revealing significant performance degradation for both online and offline attacks.

### Strengths and Weaknesses
Strengths:
- Novelty: The paper introduces the first suite of white-box attack algorithms specifically for visual-based diffusion policies, utilizing noise prediction loss to navigate the challenges of diffusion models.
- Significance: By exposing the vulnerabilities of diffusion policies to adversarial attacks, the research raises critical safety concerns for real-world applications, marking a significant step toward developing more robust DP systems.

Weaknesses:
- Lack of Defense Strategies: The paper does not propose any defensive strategies to mitigate the identified vulnerabilities, limiting the development of robust DP systems.
- Limited Attack Scenarios: The focus on only two attack scenarios restricts the understanding of the system's vulnerabilities; broader exploration is needed.
- Computational Complexity: While the proposed noise prediction loss addresses some computational complexity issues, further analysis and comparison with other attack methods regarding efficiency would be beneficial.

### Suggestions for Improvement
We recommend that the authors improve the paper by exploring and proposing specific defensive strategies to mitigate the vulnerabilities of diffusion policies. Additionally, expanding the range of attack scenarios to include other potential weaknesses in the DP system would provide a more comprehensive understanding of its vulnerabilities. Further analysis of the computational complexity and efficiency of the proposed methods compared to existing techniques would enhance the paper's contribution. Finally, a clearer definition of the threat model and the transferability of adversarial perturbations across different environments and robot models should be included to strengthen the findings.