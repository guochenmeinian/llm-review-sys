ID: bN5PA3HHo8
Title: Efficient LLM Jailbreak via Adaptive Dense-to-sparse Constrained Optimization
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 5, 5, 7, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to discrete prompt optimization through a token-level jailbreaking attack that transitions from discrete to continuous optimization. The authors propose a method that gradually increases the sparsity of the continuous vector, achieving high attack success rates (ASR) compared to existing baselines. The evaluation is conducted on multiple datasets, including AdvBench and Harmbench, demonstrating improved efficiency and effectiveness over methods like GCG. Additionally, the authors focus on optimizing adversarial attacks on language models, specifically comparing the performance of GCG with other methods such as AutoDan and PAIR. They show that GCG can be batch optimized from multiple initial suffixes, achieving a 46.0% success rate on Llama2 in two GPU minutes, significantly outperforming BEAST's 12%. The authors clarify their experimental settings and the rationale behind their choice of comparison methods.

### Strengths and Weaknesses
Strengths:
- The addressed problem of discrete optimization is significant, and the proposed methodology is innovative.
- The paper is well-organized and clearly presented.
- Comprehensive evaluations across several datasets and consideration of multiple baselines enhance the validity of the findings.
- The authors effectively address reviewer concerns and provide comprehensive experimental results.
- The proposed method shows significant performance improvements over existing techniques, particularly in terms of attack success rates.

Weaknesses:
- Comparisons against baselines are unfair due to the high resource requirements of the proposed method, which necessitates 8 GPUs, while other methods can run on a single GPU.
- Some methodological steps lack clarity and motivation, requiring further elaboration.
- The perplexity of generated sentences is high, making them vulnerable to defense mechanisms based on perplexity.
- The comparison metrics used for GCG and PAIR may lack rigor due to differences in evaluation criteria.
- The rationale for not including evolutionary methods like AutoDAN and GPTFUZZER in the evaluation could be better justified.

### Suggestions for Improvement
We recommend that the authors improve the fairness of baseline comparisons by addressing the resource disparity in their evaluations. Additionally, we suggest including an ablation study to assess the impact of the proposed adaptive sparsity, as well as evaluating the method against existing defenses, such as perplexity-based defenses. Clarifying the rationale behind certain methodological choices and providing detailed explanations for the optimization process would enhance the paper's rigor. Furthermore, we recommend improving the rigor of comparisons by ensuring that all methods are evaluated under the same metrics and providing a clearer justification for the exclusion of evolutionary techniques like AutoDAN and GPTFUZZER. Lastly, including examples of attacks in the appendix could help readers better understand the practical implications of the proposed method.