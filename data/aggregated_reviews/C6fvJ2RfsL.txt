ID: C6fvJ2RfsL
Title: Self-Consistent Velocity Matching of Probability Flows
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 5, 6, 6, 7, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for solving mass-conserving partial differential equations (PDEs) using an iterative optimization scheme that enforces a self-consistency condition. The authors propose a framework that parameterizes the velocity field through neural networks, specifically Time-dependent Invertible Push-Forward (TIPF) and Neural ODE (NODE), and minimizes a self-consistency loss without requiring spatial or temporal discretization. The method is evaluated against several important PDEs, demonstrating lower computational complexity and strong empirical results compared to previous approaches.

### Strengths and Weaknesses
Strengths:
- The proposed method significantly reduces computational complexity while maintaining good empirical performance.
- The paper is well-written, with a clear motivation and comprehensive literature review.
- Extensive empirical evaluations against baseline models are provided, showcasing the method's applicability in high-dimensional settings.

Weaknesses:
- The introduction lacks context, and some figures, particularly Figures 3, 4, and 5, are of poor quality and difficult to read.
- There is insufficient discussion on the implications of the biased gradient estimate used in the optimization process.
- The paper does not provide convergence guarantees for the proposed method, and the limitations of the TIPF and NODE approaches are not explored in depth.

### Suggestions for Improvement
We recommend that the authors improve the clarity and quality of the figures to enhance readability. Additionally, providing a more detailed comparison between SCVM-NODEs and SCVM-TIPFs would help readers understand the strengths and weaknesses of each method in specific PDE contexts. We suggest including a preliminary analysis of the effect of the biased gradient estimate on model performance and discussing boundary conditions and their impact on accuracy. Lastly, addressing the lack of convergence guarantees and exploring systematic studies on computational costs and performance metrics across varying dimensions would strengthen the paper.