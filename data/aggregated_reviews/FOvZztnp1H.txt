ID: FOvZztnp1H
Title: AutoTimes: Autoregressive Time Series Forecasters via Large Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 20
Original Ratings: 7, 7, 7, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents AutoTimes, a novel approach that repurposes large language models (LLMs) for time series forecasting by leveraging their autoregressive properties. The authors address the underexplored area of adapting LLMs to handle arbitrary lookback and forecasting horizons, utilizing techniques such as in-context learning. Experimental results indicate that AutoTimes outperforms baseline methods while requiring fewer trainable parameters compared to traditional LLM fine-tuning approaches. Additionally, the paper provides a comprehensive evaluation of the method's effectiveness through extensive experiments on various datasets, demonstrating improvements based on reviewer feedback, including additional baseline models, benchmark datasets, and systematic evaluations of in-context forecasting. The results indicate that their method outperforms existing state-of-the-art models across multiple metrics and datasets.

### Strengths and Weaknesses
Strengths:
1. The paper effectively exploits the autoregressive property of LLMs, providing a clear and intuitive framework.
2. Comprehensive experiments demonstrate the method's effectiveness across various forecasting scenarios, including zero-shot and in-context forecasting.
3. The authors have significantly enhanced the paper by incorporating more baseline models and benchmark datasets, leading to improved performance metrics.
4. The rebuttal effectively addresses concerns regarding the role of LLMs and timestamp embeddings, showcasing practical applications of in-context forecasting.
5. The method is evaluated on diverse tasks, providing a thorough analysis of its generality, efficiency, and scaling behavior.
6. The writing is clear and accessible, with well-defined contributions and innovative concepts like the One-for-all benchmark.

Weaknesses:
1. The autoregressive approach may appear trivial, and the extent of improvements from autoregressive generation lacks clarity; direct comparisons or theoretical analyses are needed.
2. The evaluation of scaling behaviors is insufficient, relying on comparisons among OPT-x models rather than contrasting different model architectures.
3. Some reviewers expressed concerns that the amount of experimental results and discussions may necessitate a major revision of the paper.
4. The selection criteria for datasets from the LOTSA collection were questioned, particularly regarding the limitations of time execution and computational resources.
5. The chosen color scheme in figures is overly vivid, making them difficult to read, and the paper simplifies assumptions about time series segment independence, potentially overlooking complex inter-dependencies.

### Suggestions for Improvement
We recommend that the authors improve clarity by providing direct comparisons or theoretical analyses to substantiate the benefits of autoregressive generation. Additionally, consider enhancing the evaluation of scaling behaviors by comparing different model architectures, such as OPT with LLaMA or GPT-2. We suggest including the experimental results for the Q6 Table on scaling behavior to enhance the comprehensiveness of the work. To improve figure readability, we recommend adopting a more subdued color scheme. Finally, we encourage the authors to elaborate on the contributions and novelty of their method to further clarify its significance in the field, and to improve the clarity of their dataset selection criteria in the final version, explicitly addressing the limitations faced during the evaluation process.