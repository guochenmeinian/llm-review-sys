ID: Gp8EmdJLUj
Title: Simplicity Level Estimate (SLE): A Learned Reference-Less Metric for Sentence Simpliﬁcation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Simplicity Level Estimate (SLE), a referenceless metric for evaluating sentence simplification. SLE is finetuned on a pretrained RoBERTa model using a dataset from Newsela, which consists of articles rewritten to five reading levels. The authors introduce label softening and document-level optimization to address challenges in sentence-level and document-level simplicity annotations. SLE demonstrates strong performance, achieving high correlations with human evaluations and outperforming other referenceless metrics, while remaining competitive with reference-based metrics.

### Strengths and Weaknesses
Strengths:
- SLE is intuitive and performs well as a referenceless measure, showing strong correlations with human scores.
- The paper is well-written, easy to follow, and presents a novel approach to measuring simplicity in sentence simplification.
- The methodology, including the use of document-level annotations, is sound and effectively communicated.

Weaknesses:
- Concerns exist regarding the generalizability of SLE, as it is trained on a limited dataset of news articles.
- Some technical aspects lack clarity, such as the rationale for scaling FKGL scores to [0, 2] and the summation of FKGL scores with simplicity levels.
- The evaluation dataset, Simplicity-DA, may have undesirable qualities that could affect the robustness of the results.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the technical details, particularly regarding the scaling of FKGL scores and the summation of scores in Equation (3). Additionally, it would be beneficial to discuss the potential generalizability of SLE to out-of-distribution data, such as oral texts. Including Kendall’s Tau alongside Pearson correlation in the evaluation would enhance confidence in the results. We also suggest presenting examples of outputs that receive high and low scores from SLE, and comparing these with other metrics to illustrate the differences. Finally, providing more information on hardware setup, training parameters, and validation results would aid in reproducibility.