ID: L7IW2foTq4
Title: Attention-Enhancing Backdoor Attacks Against BERT-based Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel Trojan Attention Loss (TAL) aimed at enhancing the efficacy of textual backdoor attacks by manipulating attention patterns on poison samples during training. The authors observe that attention weights in backdoored models tend to concentrate on trigger tokens, and TAL is designed to maximize attention on these triggers across all layers. The extensive experiments validate the effectiveness of TAL across various attack methods, demonstrating consistent improvements in attack efficiency.

### Strengths and Weaknesses
Strengths:  
- The analysis of attention concentration provides a solid foundation for the proposed TAL method, which is intuitive and novel.
- Comprehensive experiments support the claims, showing strong empirical results across different models and tasks.
- The paper is well-written, with clear methodology and analysis.

Weaknesses:  
- There are concerns regarding the necessity of improving attack efficiency under model-manipulated-based attack settings, as the proposed method may not apply when adversaries lack control over the training process.
- The paper lacks insight into why TAL is necessary and does not provide a proper comparison with naive baselines, which raises questions about the fairness of the comparisons made.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the Attack Scenario section (4.1) by explicitly introducing different types of backdoor attacks, as the current descriptions may mislead the audience. Additionally, we suggest including an ablation study to illustrate the necessity for attention concentration across all layers, comparing the proposed method with existing works on last-attention layer attacks and defenses. Furthermore, addressing the questions regarding the comparison of TAL with higher strength on L_poison in equation 4 would enhance the paper's rigor. Lastly, it is essential to include references to relevant defense methods to provide a comprehensive context for the proposed attention-enhanced methods.