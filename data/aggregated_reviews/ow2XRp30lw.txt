ID: ow2XRp30lw
Title: UniLP: Unified Topology-aware Generative Framework for Link Prediction in Knowledge Graph
Conference: ACM
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a unified approach to link prediction (LP) in knowledge graphs (KG) using generative pre-trained language models (PLM). The authors address three challenges: unified input forms, task-specific context modeling, and topological information encoding. The proposed method, UniLP, utilizes context demonstration templates and topology-aware soft prompts, achieving significant performance improvements across various LP subtasks.

### Strengths and Weaknesses
Strengths:
1. The LP task and unified perspective are meaningful and interesting.
2. The motivation and components of the proposed method are clear and well-justified.
3. The experiments are extensive, covering diverse LP subtasks, and the source code is available.

Weaknesses:
1. Some method details and experimental settings lack clarity.
2. The novelty of the approach is questioned, particularly regarding the integration of existing frameworks like KG-S2S.
3. The benefits of topology-aware soft prompts and their empirical validation are insufficiently addressed.
4. The paper does not compare the training and inference efficiency of UniLP against traditional methods.

### Suggestions for Improvement
We recommend that the authors improve clarity regarding the differences between Static LP and Inductive LP. Additionally, the authors should provide a more detailed explanation of the advantages of their method over previous approaches that utilize additional GNNs for structural information. We suggest clarifying the terminology of "relation-domain" and "relation-range" and elaborating on the use of T5-base as mentioned in the paper. Furthermore, we encourage the authors to explore the performance of UniLP in few-shot settings and to address the lack of citations regarding the context demonstration templates and topology-aware soft prompts. Lastly, we recommend including a comparison of training and inference efficiency with traditional methods to strengthen the paper's contributions.