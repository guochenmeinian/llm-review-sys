ID: 3uUIwMxYbR
Title: Revisiting Differentially Private ReLU Regression
Conference: NeurIPS
Year: 2024
Number of Reviews: 21
Original Ratings: 3, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on learning a planted ReLU regression model under differential privacy, proposing two algorithms: DP-GLMtron and DP-TAGLMtron. The authors claim that their methods outperform traditional approaches like DP-SGD and DP-FTRL, providing theoretical analyses of privacy utility tradeoffs. The work introduces a novel perspective on dimensionality reduction in specific cases, such as eigenvalue decay, which has been overlooked in previous Differential Privacy (DP) studies. The authors conducted experiments on both synthetic datasets and Bernoulli data to validate their theoretical insights, demonstrating significant performance gaps between their proposed algorithms and traditional methods across various datasets and privacy budgets. However, the results do not explicitly account for the ambient dimension \(d\), instead using terms like "effective dimension" that may obscure the true dependence on \(d\).

### Strengths and Weaknesses
Strengths:
- The paper addresses a challenging problem in private, non-convex optimization, specifically focusing on planted ReLU regression.
- The proposed algorithms are novel, and the theoretical analysis is comprehensive, extending beyond typical Gaussian-like assumptions.
- Empirical evaluations are conducted on both synthetic and real-world datasets, supporting the theoretical claims and indicating potential improvements in convergence.

Weaknesses:
- The fit with related literature is unclear, particularly regarding comparisons with existing works, such as the lack of analysis against a more robust baseline [4].
- The analysis lacks motivation, as the practicality of the proposed algorithms in real-world deep learning scenarios is questionable.
- The dependence on the ambient dimension \(d\) is inadequately addressed, raising concerns about the assumptions made regarding the covariance matrix and the term \(\Gamma\).
- The applicability of findings beyond the specific data and model settings remains unclear.
- Empirical results are weak, with puzzling outcomes in experiments, particularly regarding the performance of DP-SGD and the increase in excess risk with sample size. Some reviewers expressed concerns about the clarity and interpretation of experimental results, particularly regarding the wine quality dataset.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their literature review by providing a more explicit comparison with relevant works, particularly [4]. Additionally, we suggest that the authors focus on providing bounds on DP-SGD to enhance the practical relevance of their algorithms. It would be beneficial for the authors to clarify their assumptions regarding \(\Gamma\) and to elaborate on the experimental settings used for DP-SGD on MNIST data. We also recommend that the authors improve the clarity of their experimental results by providing a detailed explanation of the reported scores and their implications. Sharing the implementation code through an anonymized repository could enhance transparency and allow reviewers to better assess the findings. Finally, the authors should consider extending their analysis to more complex models, such as deep neural networks, and addressing the broader applicability of their theoretical insights to strengthen the paper's impact.