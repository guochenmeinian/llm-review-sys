ID: QVnlBmGrWS
Title: ORCHID: A Chinese Debate Corpus for Target-Independent Stance Detection and Argumentative Dialogue Summarization
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel Chinese dataset, OrChiD, aimed at advancing research in stance detection and debate summarization, specifically targeting three tasks: target-independent stance detection, debate summarization, and stance-specific summarization. The authors apply various baseline methods, including pretrained models and large language models, to evaluate the dataset, reporting that stance detection is comparatively easier than summarization tasks. The dataset is significant for its comprehensive coverage of 1036 debates across 403 unique topics, addressing a notable gap in Chinese language resources.

### Strengths and Weaknesses
Strengths:
- The dataset is a pioneering contribution to Chinese dialogue summarization and stance detection, particularly with the introduction of stance-specific summarization.
- The experiments are thorough, utilizing a range of models and providing a versatile testbed for future research.
- The paper is well-structured, with a detailed summary of existing work that aids reader comprehension.

Weaknesses:
- Clarity issues exist regarding the criteria for modifying debate rounds for summaries and the quality control measures for the summaries.
- The analysis of experimental results is limited, primarily focusing on ROUGE scores without deeper insights into dataset challenges.
- The data collection process lacks transparency, and there is insufficient analysis comparing the dataset to existing corpora.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the criteria used for modifying debate rounds to obtain summaries and include a discussion on quality control measures for the summaries. Additionally, a more in-depth analysis of the experimental results, including error analysis and challenges faced with the dataset, would enhance the paper's contributions. We also suggest that the authors provide a detailed account of the data collection process, including the selection criteria for videos and the annotation process, to bolster reproducibility. Furthermore, clarifying the methodology for generating stance-specific summaries and addressing potential biases in the annotation process would strengthen the paper.