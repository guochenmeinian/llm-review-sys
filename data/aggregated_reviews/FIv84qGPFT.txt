ID: FIv84qGPFT
Title: Pseudo-Likelihood Inference
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 6, 6, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Pseudo-Likelihood Inference (PLI) as a novel method within the simulation-based inference (SBI) framework, addressing the challenge of intractable likelihoods in Bayesian system identification. The authors propose integrating neural approximations with Approximate Bayesian Computation (ABC) to enhance performance, particularly in scenarios involving stochastic simulations and multi-modal posterior landscapes. The method employs integral probability metrics and introduces a smooth likelihood kernel with an adaptive bandwidth, allowing for optimization of neural posteriors via gradient descent without relying on summary statistics. The effectiveness of PLI is evaluated through experiments on four classical SBI benchmark tasks and a dynamic physical system.

### Strengths and Weaknesses
Strengths:
- PLI effectively combines neural approximation with ABC, achieving competitive performance in challenging tasks.
- The adaptive bandwidth for the smooth likelihood kernel enhances accuracy in parameter estimation.
- The paper is well-written and presents solid methodological developments supported by experiments.

Weaknesses:
- The experimental results lack robustness, with some benchmarks showing PLI performing comparably or worse than existing methods like MMD-ABC.
- There is insufficient discussion on the computational efficiency and resource requirements of PLI compared to other SBI approaches.
- The paper does not provide code, which is crucial for reproducibility.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the algorithm and computational steps for estimating relevant divergences, particularly how to compute IPM for MMD vs. Wasserstein. Expanding the discussion on the analogy with variational inference would enhance understanding of the proposal distribution formulation. Additionally, we suggest including a more comprehensive evaluation of PLI against other SBI methods, particularly Markov Chain Monte Carlo methods, to provide a clearer comparative analysis. Addressing the computational cost associated with retraining the density estimator at each step is also essential. Finally, correcting typographical errors and improving the presentation of equations would enhance readability.