ID: dlDFakG6kJ
Title: Sample Complexity of Forecast Aggregation
Conference: NeurIPS
Year: 2023
Number of Reviews: 7
Original Ratings: 7, 7, 8, 7, -1, -1, -1
Original Confidences: 2, 4, 4, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on forecast aggregation in a Bayesian setting, where n experts observe individual signals correlated with an unknown binary event and report their posterior beliefs to a principal. The principal aggregates these reports to produce a prediction, assessed using square loss. The authors investigate the minimax sample complexity required to achieve an additive excess error of $\epsilon$ compared to the best aggregator with knowledge of the conditional distribution of truth given reports. They derive results for arbitrary distributions and those that factorize, revealing an exponential gap in sample complexity between these cases, with the latter showing independence from the number of experts.

### Strengths and Weaknesses
Strengths:
- The paper is well written and technically sound.
- It introduces the study of sample complexity to the forecast aggregation literature.
- The results are interesting and applicable to multiple natural settings.
- A novel lower bound construction for distribution estimation facilitates a reduction from estimation to aggregation.

Weaknesses:
- There are non-matching upper and lower bounds in most cases.
- The main technical challenge lies in the lower bound construction, while the upper bounds lack significant new ideas.
- Techniques appear limited to the specific loss function and discrete truth/signal settings, with a need for commentary on possible extensions.

### Suggestions for Improvement
We recommend that the authors improve the discussion on alternative loss functions, such as considering different weights for type 1 versus type 2 errors, or exploring continuous truth/signal distributions where experts report the conditional mean of the truth given their signals. Additionally, we suggest clarifying the rationale behind the choice of mean squared error as the optimality measure, as it may be more intuitive to minimize the probability of error based on the experts' reports. Finally, we encourage the authors to provide a more intuitive explanation for the lower bound proof and consider addressing the implications of the conditionally independent signals in real-world scenarios.