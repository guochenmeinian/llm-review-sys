ID: qxF8Pge6vM
Title: Reinforcement Learning with Simple Sequence Priors
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 6, 5, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a reinforcement learning method that aims to produce simplified action sequences by defining simplicity as the predictability of the next action, measured by the number of bits required to encode the action sequence. The authors propose two methods for regularizing RL policies: SPAC, which uses a learned sequence model to predict the next action, and LZ-SAC, which employs a compression algorithm to penalize the number of bits needed for storage. The evaluation shows that these methods can lead to improved performance compared to traditional action regularization techniques.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and presents a novel approach using LZ4 for action sequence regularization.
- The motivation for simplifying action sequences is reasonable and interesting for the community.
- The experiments conducted are diverse, comparing performance and the ability to use open-loop control.

Weaknesses:
- The lack of complex experiments limits the validation of claims regarding policy search and robustness.
- Insufficient comparisons to other state-of-the-art methods and a vague connection to existing literature on simplicity and maximum entropy RL.
- Some unclear prose, particularly in the abstract, introduction, and methods sections, detracts from clarity.
- The choice of LZ4 over other compression methods requires further justification, and the performance of the proposed methods varies across tasks.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by revising unclear sections, particularly the abstract and introduction. Additionally, the authors should include more complex experiments to validate their claims and provide comparisons with a broader range of state-of-the-art methods. Justifying the choice of LZ4 over other compression methods and addressing the performance discrepancies across tasks would strengthen the paper. Finally, including ablation studies on the transformer architecture and action discretization could provide valuable insights into the trade-offs between simplicity and performance.