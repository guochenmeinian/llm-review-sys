ID: PRgvdEbhdH
Title: Policy Space Diversity for Non-Transitive Games
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 7, 5, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates the strategy exploration problem in learning-based game-solving algorithms, proposing a solution that expands the empirical game with policies that are approximate best responses and maximally expand the policy hull. The authors analyze the exploitability of the population captured by the empirical game and demonstrate performance benefits across various games. They introduce a new diversity metric and algorithm, PSD-PSRO, which aims to improve convergence properties in approximating Nash Equilibria (NE) in multi-agent non-transitive games. Additionally, the authors discuss the evaluation of policy diversity within the context of Policy Space Response Oracles (PSRO), arguing that the impact of introducing a new policy is crucial for achieving a NE. They propose a population-based anchor for evaluating this impact and define a *fine policy representation*, suggesting that their Bregman divergence metric can enhance policy clustering and downstream tasks like opponent modeling. The authors also address concerns regarding computational complexity and clarify the relationship between the gradient of policies and their minimum counterparts.

### Strengths and Weaknesses
Strengths:  
- The paper is well-organized, with clear framing and a thorough overview of related literature.  
- It effectively addresses the issue of diversity in policy space, providing a unified language for discussing diversity in game-solving.  
- The empirical results for PSD-PSRO are comprehensive, and the theoretical justification for policy hull expansion is sound.  
- The authors provide a clear rationale for their approach to evaluating policy diversity in PSRO.  
- The definition of *fine policy representation* and the use of Bregman divergence are innovative contributions that may enhance policy clustering and modeling.  
- The authors effectively address reviewer concerns regarding computational complexity and proof clarity.  

Weaknesses:  
- There is confusion regarding the distinction between empirical games and the "meta game," which undermines several claims in the paper.  
- Some arguments, particularly in A1 regarding the gradient of policies, lack sufficient rigor and clarity, leading to confusion among reviewers.  
- The derivation of the gradient calculation in equation (15) may be incorrect, raising concerns about the correctness of results.  
- The relationship between $\pi_i$ and $\pi_i^{min}$ is not fully articulated, which may hinder understanding.  
- The critique of gamescapes is overly harsh; the authors should consider the long-term benefits of gamescape analysis.  
- The paper lacks a focused discussion on limitations and broader impacts, particularly regarding the selection of opponent policies and their influence on diversity measures.

### Suggestions for Improvement
- We recommend that the authors clarify the distinction between empirical games and the "meta game" to avoid confusion and strengthen their claims.  
- We suggest improving the rigor of arguments in A1, particularly regarding the gradient relationship between $\pi_i$ and $\pi_i^{min}$. Providing more detailed explanations and possibly including the proposition from Theorem 2.1 in [1] would enhance clarity.  
- We encourage the authors to revisit the derivation of the gradient calculation in equation (15) to ensure its correctness, particularly the relationship between $\pi_i^{\min}$ and $\pi_i$.  
- We recommend moderating the critique of gamescapes and emphasizing specific applications of per-iteration policy exploration instead.  
- We suggest including a focused discussion on the limitations of the work, particularly regarding the impact of opponent policy selection on diversity measures and computational costs.  
- Lastly, we urge the authors to clarify the empirical results and experimental settings, particularly regarding the computation of diversity metrics and the use of exact best-response solvers. Additionally, we recommend revising the text in lines 164-166 to better convey their point about the relationship between gamescape enlargement and NE approximation.