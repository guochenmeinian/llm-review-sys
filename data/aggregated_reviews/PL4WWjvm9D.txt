ID: PL4WWjvm9D
Title: Decoupling Quantile Representations from Loss Function
Conference: NeurIPS
Year: 2023
Number of Reviews: 20
Original Ratings: 3, 4, 6, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 1, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework that extends an existing pre-trained classifier to a full quantile representation of target data by setting the pre-trained classifier as the median classifier and optimizing over pinball losses across different quantile values. The authors propose a novel approach to computing quantile representations for binary classification problems without relying on pinball loss, addressing optimization difficulties. They emphasize the practical value of their method, particularly demonstrated through calibration experiments showing that quantile probabilities are distortion-invariant. The authors clarify that their experiments serve as sanity checks rather than claims of state-of-the-art performance, asserting that their method outperforms a strong MSP baseline but is only comparable to the MLS approach due to mixed results. They acknowledge that achieving state-of-the-art results requires significant scale, training strategies, and hyperparameter tuning, which were constrained by computational limitations. Experimental results indicate that the framework is competitive in out-of-distribution detection and model calibration.

### Strengths and Weaknesses
Strengths:
- The paper introduces a unique approach that leverages the duality between probabilities and quantiles, effectively decoupling quantile representations from the loss function.
- The proposed method demonstrates practical value through distortion-invariant calibration experiments and effectiveness in out-of-distribution detection and model calibration.
- The authors provide a clear comparison to existing methods, highlighting advantages over a strong MSP baseline.

Weaknesses:
- The main algorithm's reliance on the monotonicity property is problematic, as monotonicity is not guaranteed in practice. The claim that "using eq.2 enforces the solution to have monotonicity property" is misleading.
- The results are mixed when compared to the MLS approach, and the authors do not claim to be state-of-the-art, which may limit the perceived impact of their findings.
- Experimental comparisons are limited to a simple baseline model, lacking robustness and convincing evidence of superiority.
- Computational limitations hindered the exploration of more novel ideas and larger scales, and the notation and presentation are confusing, hindering understanding of the proposed method and theoretical results.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the notation and presentation to facilitate understanding, particularly regarding the definitions of quantile functions and the relationships between variables. Additionally, we suggest including more recent and relevant baseline methods in the experiments to strengthen the evaluation of the proposed framework. The authors should clarify their claims regarding the performance of their method relative to state-of-the-art approaches and provide more detailed discussions on the limitations imposed by computational resources and how future work could address these challenges. Finally, addressing the potential for quantile crossing and clarifying the discrepancies in the algorithm and equations will enhance the paper's rigor.