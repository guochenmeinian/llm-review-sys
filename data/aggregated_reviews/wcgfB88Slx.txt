ID: wcgfB88Slx
Title: Explanation Selection Using Unlabeled Data for Chain-of-Thought Prompting
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework for selecting explanations from a candidate set in a chain-of-thought prompting scheme, demonstrating that different explanations can significantly impact the performance of language models. The authors propose efficient proxy metrics to rank explanations, leading to consistent performance improvements across four datasets. Key contributions include a formulation of the explanation selection problem, empirical validation of the impact of explanation choice, and the development of a framework that enhances performance compared to the original set of explanations.

### Strengths and Weaknesses
Strengths:
- The experimental design is robust, with strong results validating the proposed metrics and framework.
- The framework's compatibility with common prompting techniques and its efficiency under reduced computational budgets are noteworthy.
- The analysis is well-articulated, and the insights gained from the proxy metrics and pseudo-labeling are valuable for broader applications.

Weaknesses:
- The method relies on a silver set of pseudo-labeled examples, and the assumption that combining the best individual explanations yields the best overall set may limit performance.
- The complexity of the framework, involving multiple components, could hinder its practical application.
- The effectiveness of selected explanations is highly dataset-dependent, raising concerns about generalizability.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the limitations of their approach, particularly the lack of guarantee for selecting the optimal combination of explanations. Additionally, consider including a comparison with a best-of-$k$ baseline for better contextual understanding. Addressing the questions raised about the inclusion of seed explanations in candidate sets and the potential biases in few-shot examples would enhance the paper's depth. Finally, updating the references to include more recent works on black-box optimization and in-context learning would strengthen the literature review.