ID: u6BYyPuD29
Title: MADG: Margin-based Adversarial Learning for Domain Generalization
Conference: NeurIPS
Year: 2023
Number of Reviews: 21
Original Ratings: 5, 6, 6, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a margin-loss based analysis of domain generalization (DG) and proposes a margin-based adversarial framework (MADG) to minimize margin disparity discrepancy (MDD) between source domains. The authors derive a generalization upper bound using MDD and demonstrate the effectiveness of their method on the DomainBed benchmark, achieving competitive results against existing methods. The proposed MADG algorithm utilizes MDD to address the DG problem, with plans to clarify the novelty of their work, specifically the advantages of MDD and the adversarial learning formulation of MADG. The paper will also include a computational cost analysis and performance comparisons against recent baselines, demonstrating that MADG consistently outperforms methods like MIRO and SD across various datasets.

### Strengths and Weaknesses
Strengths:
- The theoretical analysis provides a principled approach to DG, enhancing the interpretability of the solutions.
- The empirical results show that MADG performs competitively across various benchmarks, supported by detailed ablation studies.
- The proposed MADG algorithm shows improved performance on the challenging DomainBed benchmark.
- The authors provide comprehensive evaluations, including comparisons with recent methods and ablation studies.
- The addition of results from the ColoredMNIST dataset supports the effectiveness of MADG in specific settings.

Weaknesses:
- The introduction lacks clarity regarding the motivation for the theoretical framework, failing to adequately address existing theoretical work in DG.
- The performance gap across different tasks raises concerns about the overall effectiveness of MADG, particularly as it shows marginal improvements over baselines like ERM.
- The reliance on labeled out-of-distribution (OOD) data for hyperparameter selection limits the practical applicability of the results.
- The complexity of training multiple models for MDD computation may not be justified compared to simpler methods.
- The initial lack of comparison with MIRO and other recent methods raised concerns about performance evaluation.
- The paper could benefit from clearer organization and descriptions in Sections 4 and 5 to enhance reader comprehension.

### Suggestions for Improvement
We recommend that the authors improve the introduction by clearly articulating the specific gaps in existing literature that their theoretical framework addresses. Additionally, the authors should provide a more thorough comparison with recent DG methods to contextualize their contributions. It would be beneficial to include an analysis of training dynamics to elucidate the workings of MADG. Furthermore, we suggest simplifying Table 1 by removing unnecessary baselines and conducting experiments that demonstrate MADG's superiority over ERM in simpler settings. We also recommend improving the clarity of the novelty statement in Section 1 by explicitly discussing the advantages of MDD. In Section 2, the authors should provide a detailed comparison of existing adversarial methods and clearly differentiate the margin loss used in their work. To enhance the organization of Sections 4 and 5, including a clear description of their structure after the introductory paragraph in Section 4 would be beneficial. Additionally, we suggest adding a 'Computational cost' analysis in Section 7 to explicitly state the tradeoff between computation and generalization performance. Lastly, ensure that the results from the ColoredMNIST dataset are included in the final version to address reviewer concerns.