ID: BKAFLUcpBS
Title: Outlier-Robust Gromov-Wasserstein for Graph Data
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 7, 8, 7, 4, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Robust Gromov-Wasserstein (RGW) distance to address the high sensitivity to outliers in common Gromov-Wasserstein (GW) distances. The authors propose relaxing both the marginal distribution and the transport plan using KL divergence, and they introduce an algorithm based on Bregman Proximal Alternating Linearization Minimization (BPALM) with guaranteed convergence. Theoretical analysis shows robustness to Huber-$\epsilon$ contamination, while empirical results indicate RGW's effectiveness in partial correspondence tasks amidst outliers.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and presents a theoretically and empirically sound analysis.
- It addresses a critical robustness issue in GW distances, potentially benefiting various OT-related research areas.
- Experimental results demonstrate RGW's effectiveness in challenging tasks like partial correspondence and subgraph alignment.

Weaknesses:
- A section on related works is strongly encouraged to discuss RGW's relation and superiority over other relaxed GW methods, such as UGW and srGW.
- Modifications in the experimental section are encouraged for better clarity and presentation.

### Suggestions for Improvement
We recommend that the authors improve the paper by including a comprehensive section on related works to contextualize RGW within existing literature. Additionally, we suggest clarifying the benefits of the extra relaxation imposed on the marginal distribution compared to UGW. The authors should also address the accuracy of the statement regarding Theorem 2.3 and provide justifications for the choices of KL divergence in the proximal operators. Empirical evaluations on the convergence of BPALM and the effects of hyperparameters in experiments should be included, along with a sensitivity analysis of these parameters. Lastly, we encourage the authors to elaborate on the implications of their findings, particularly regarding the robustness of RGW in the presence of noisy subgraphs.