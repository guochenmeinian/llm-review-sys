ID: 80ZDEuEJVC
Title: A Parallel Corpus for Vietnamese Central-Northern Dialect Text Transfer
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an exploration of dialectal representation in NLP for the Vietnamese language, specifically focusing on the central Vietnamese dialect. The authors propose a new parallel corpus for northern-central Vietnamese aimed at facilitating dialect transfer. Key contributions include benchmarking dialect transfer using pretrained BART models and employing them as adaptors for downstream NLG tasks. The study highlights the inadequacy of multilingual models for dialect-specific tasks and emphasizes the importance of dedicated resources for the central dialect.

### Strengths and Weaknesses
Strengths:
- The introduction of a new dataset for central Vietnamese, which is currently underrepresented in NLP research, is a significant contribution.
- The thorough methodology for dataset creation and benchmarking experiments is commendable.
- The findings align with existing dialectal research, particularly in the context of Arabic, reinforcing the relevance of the study.

Weaknesses:
- The discussion of results can be challenging to follow due to brief table captions and unclear terminology.
- Certain contributions, such as text-image retrieval, are mentioned but not adequately discussed in the main body of the paper.
- The clarity of the corpus annotation process and the details of model fine-tuning are insufficiently addressed.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the results discussion by expanding table captions to provide necessary context. Additionally, any contributions mentioned in the paper should be discussed in the main body rather than relegated to the appendix. It is crucial to clarify the terminology used for models and approaches to avoid confusion. We also suggest that the authors provide detailed explanations of the dataset's annotation process and the fine-tuning techniques employed. Furthermore, ensuring that the corpus and models are made publicly available would enhance the impact of this work. Lastly, revising the abstract for conciseness and including specific summaries of experimental outcomes would strengthen the overall presentation.