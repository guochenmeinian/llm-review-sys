ID: CIHdlhfrOo
Title: Self-Supervised Adversarial Training via Diverse Augmented Queries and Self-Supervised Double Perturbation
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 5, 5, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method aimed at addressing the robust generalization gap and clean accuracy degradation in self-supervised adversarial training (SAT). The authors propose the DAQ-SDP (Diverse Augmented Queries Self-supervised Double Perturbation) method, which incorporates strong data augmentation and weight perturbation into the self-supervised learning framework. The experimental results indicate that the DAQ-SDP method outperforms existing baselines, demonstrating non-trivial improvements in robust accuracy across benchmark datasets.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written, making it easy to follow the motivations and implementations.
2. The experimental results show that DAQ-SDP outperforms other baselines like DecoupledACL and TARO.
3. The method introduces weight perturbation into the self-supervised learning context, which is a novel approach.

Weaknesses:
1. The exclusion of ResNet-18 results raises concerns about academic integrity, as it may appear the authors are omitting unfavorable data.
2. The claims regarding the effectiveness of strong data augmentation lack sufficient empirical support, particularly in relation to model capacity.
3. The presentation suffers from clarity issues, with several terms undefined and numerous typographical errors throughout the paper.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their writing, particularly in the rebuttal, to ensure that responses are concise and well-structured. Additionally, we suggest including results for ResNet-18 to provide a more comprehensive evaluation of the method's performance across different model sizes. An ablation study comparing the "pairwise-BatchNorm" technique with standard BatchNorm should also be included to substantiate claims regarding its effectiveness. Finally, addressing the typographical errors and ensuring all terms are clearly defined will enhance the overall presentation of the paper.