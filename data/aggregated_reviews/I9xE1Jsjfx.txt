ID: I9xE1Jsjfx
Title: Evaluating and Inducing Personality in Pre-trained Language Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 7, 5, 8, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into the manifestation of personality traits in large language models (LLMs) using the Machine Personality Inventory (MPI), which is based on the Big Five personality traits. The authors propose a method called Personality Prompting (P2) to induce specific personality traits in LLMs. Experimental results indicate that LLMs, particularly GPT-3.5 and Alpaca 7B, align with human personality traits, and the P2 method successfully enhances the consistency of these traits. The study emphasizes the potential for LLMs to exhibit human-like personality characteristics and introduces a systematic approach to evaluate and control these traits.

### Strengths and Weaknesses
Strengths:
- **Originality**: The authors are among the first to systematically evaluate personality in LLMs, providing a novel application of psychological theory in AI.
- **Quality**: The experimental results validate the efficacy of the P2 method, and the evaluation methods are sound and well-motivated.
- **Clarity**: The paper is well-written, with clear diagrams and a logical flow of ideas.
- **Significance**: The systematic evaluation of personality induction in LLMs is a valuable contribution, and the authors' commitment to open-sourcing their code and data enhances its impact.

Weaknesses:
- The conclusion that LLMs possess an inherent "personality" is not well-supported, as it may reflect training data rather than true personality.
- The P2 method is only tested on GPT-3.5, limiting generalizability; a broader analysis across different models with documented training data is needed.
- Experimental results lack rigorous statistical testing, relying on descriptive statistics without assessing effect sizes, which is crucial given the disparity in sample sizes between LLMs and human responses.

### Suggestions for Improvement
We recommend that the authors improve the statistical rigor of their analysis by incorporating proper statistical testing to validate claims regarding personality traits in LLMs. Additionally, we suggest expanding the evaluation of the P2 method across a wider range of LLMs to draw more robust conclusions about personality induction. Clarifying the evaluation methodology for the MPI and addressing potential biases in prompt generation would also strengthen the paper. Lastly, we encourage the authors to explore the implications of personality induction in LLMs, particularly concerning ethical considerations and potential societal impacts.