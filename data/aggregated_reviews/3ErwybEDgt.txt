ID: 3ErwybEDgt
Title: DiQAD: A Benchmark Dataset for Open-domain Dialogue Quality Assessment
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a large-scale Chinese dataset for dialogue evaluation called DiQAD, containing 100k dialogues annotated on six dimensions: grammaticality, relevance, consistency, empathy, proactivity, and informativeness. The dialogues are sourced from real-world scenarios and annotated by a trained team, ensuring quality. The authors conduct extensive experiments to evaluate various methods for classifying dialogue quality, providing a benchmark for future research.

### Strengths and Weaknesses
Strengths:
- The proposed dataset is a significant contribution to the NLP community, being larger than existing datasets in this domain.
- Extensive empirical studies are conducted, offering valuable insights and baseline results for future dialogue evaluation research.

Weaknesses:
- The proposed aspects of human-centered evaluation lack novelty, as similar dimensions have been previously explored in existing literature.
- The short average length of dialogues (less than 512 tokens) may not adequately represent real-world scenarios requiring long-term dependencies.
- The quality annotation process is unclear, with only one annotation per dialogue despite multiple evaluation criteria.

### Suggestions for Improvement
We recommend that the authors improve clarity regarding the quality annotation process, specifying how each dimension contributes to the overall quality score. Additionally, the authors should consider addressing the limitations posed by the short dialogue lengths and explore the inclusion of labels for evaluating generated responses. Providing more details about the data collection process and including a Data Card and Human Evaluation Data Sheet would enhance reproducibility. Lastly, we suggest that the authors have a native English speaker proofread the paper to improve readability.