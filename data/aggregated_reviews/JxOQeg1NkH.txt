ID: JxOQeg1NkH
Title: RoboMamba: Efficient Vision-Language-Action Model for Robotic Reasoning and Manipulation
Conference: NeurIPS
Year: 2024
Number of Reviews: 19
Original Ratings: 5, 7, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents RoboMamba, a multimodal large language model (MLLM) utilizing the Mamba state-space model (SSM) for robotic reasoning and manipulation. The authors propose a multi-stage training pipeline that integrates language and vision, demonstrating strong performance on various reasoning and manipulation benchmarks with minimal fine-tuning parameters. RoboMamba achieves faster inference speeds and improved efficiency compared to existing methods, addressing limitations in computational costs and reasoning capabilities of prior MLLMs.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and presents a comprehensive set of experiments across general reasoning and robot-specific benchmarks.
- The use of the Mamba architecture allows for linear computational complexity, enhancing efficiency in robotic tasks.
- Experimental results indicate that RoboMamba retains strong reasoning capabilities while achieving state-of-the-art performance in both simulated and real-world environments.

Weaknesses:
- The method lacks significant technical novelty, primarily combining existing architectures without providing new insights.
- The evaluation of robotic manipulation tasks is limited, focusing on single-step predictions rather than closed-loop policies.
- The paper does not adequately address the implications of the parameter efficiency claims or provide detailed results on inference times and scalability.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their contributions by providing a clearer analysis of how RoboMamba's architecture uniquely benefits robotic tasks compared to other linear-complexity models. Additionally, please include quantitative results for real-world reasoning experiments and address potential failure cases to avoid cherry-picking qualitative examples. We suggest conducting further experiments to evaluate the scalability of RoboMamba and to clarify the impact of the manipulation head's parameter count on performance. Finally, enhancing the clarity of the presentation and addressing minor errors will strengthen the overall quality of the paper.