ID: j2oYaFpbrB
Title: Active Vision Reinforcement Learning under Limited Visual Observability
Conference: NeurIPS
Year: 2023
Number of Reviews: 20
Original Ratings: 5, 7, 6, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 5, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel reinforcement learning (RL) framework called SUGARL, designed for scenarios where an agent must manage both motor actions and sensory perception. The authors propose a two-branch joint learning framework, define a sensorimotor reward based on an inverse dynamics model, and introduce a technique for accumulating historical observations termed Persistence-of-Vision Memory. Experiments conducted on Atari and DMControl demonstrate the framework's effectiveness against Random View and Raster Scanning baselines. Additionally, the paper analyzes robotics experiments showing that ActiveRL can enhance visual manipulation tasks, with quantitative results indicating that SUGARL performs significantly better in 3D environments compared to 2D. However, some reviewers express concerns regarding the sufficiency of the new experiments relative to the extensive work in the initial paper.

### Strengths and Weaknesses
Strengths:
- The paper addresses the intriguing problem of Active RL, which has significant real-world implications for Visual RL applications.
- A new intrinsic reward based on the inverse dynamics model is well-motivated and effective in enhancing sensorimotor policy learning.
- The evaluation is extensive, covering both continuous and discrete action spaces, with thorough ablation studies of each component.
- The visualizations of the learned sensorimotor policy are compelling, highlighting task-oriented object focus.
- The paper effectively demonstrates the potential of ActiveRL in improving robotics tasks, with significant performance gains of SUGARL in 3D environments.

Weaknesses:
- The experimental environments do not align with the proposed problem setting, as they are limited to 2D RL environments, neglecting more relevant robotic simulation environments.
- The baselines used for comparison are weak, primarily consisting of Random View and Raster Scanning, which do not adequately showcase the advantages of SUGARL. Stronger baselines should be included for a more robust evaluation.
- The paper lacks a limitations section, failing to address the constraints of the environments and the assumptions made regarding active perception.
- The new experiments are considered insufficient compared to the original paper's extensive experiments.
- There is a lack of learning curves for the robotics experiments, which raises concerns about the completeness of the analysis.

### Suggestions for Improvement
We recommend that the authors improve the alignment of their experimental environments with the proposed Active RL setting by incorporating more realistic robotic simulation environments, such as MetaWorld or RoboSuite. Additionally, we suggest devising stronger baselines, such as using pre-trained detection networks or hand-crafted features, to provide a fairer comparison. The authors should also include a limitations section discussing the constraints of their approach and the assumptions regarding the instantaneous nature of sensory actions. Furthermore, we encourage the authors to enhance the clarity and readability of the paper, including the experimental section to facilitate better understanding of key takeaways. Conducting experiments in more realistic robotic settings, specifically where moving the camera incurs a cost and where physical occluders are present, would strengthen the findings. Including learning curves for the robotics experiments and addressing the cost of perception would enhance the overall analysis. Lastly, we suggest that the authors release the code for both 2D and 3D environments to benefit the community.