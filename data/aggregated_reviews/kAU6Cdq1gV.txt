ID: kAU6Cdq1gV
Title: Discovering General Reinforcement Learning Algorithms with Adversarial Environment Design
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 6, 4, 7, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 2, 2, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents GROOVE (General RL Optimizers Obtained Via Environment Design), a meta reinforcement learning algorithm that integrates the Learned Policy Gradient (LPG) and Unsupervised Environment Design (UED) techniques to enhance generalization in unseen environments. The authors introduce a metric called algorithmic regret (AR) to evaluate and guide the meta-training process. Experimental results demonstrate that GROOVE outperforms baseline methods on Atari games.

### Strengths and Weaknesses
Strengths:
1. The paper is well-organized, with a thorough introduction to related work.
2. The experimental results indicate that the proposed AR metric surpasses existing metrics.

Weaknesses:
1. The approximation of algorithmic regret is heavily dependent on the choice of an oracle algorithm as UEDs, which may limit GROOVE's performance. An ablation study using different antagonist agents is needed.
2. The novelty of GROOVE is limited, as it primarily combines existing methods (UED and LPG).
3. The paper lacks sufficient definitions and formalizations, making it difficult to follow, particularly in sections discussing U_\eta, y_\theta, and the meta-optimizer F.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by providing clearer definitions and formalizations for key components, particularly U_\eta, y_\theta, and the meta-optimizer F. Additionally, we suggest conducting an ablation study to evaluate the impact of different antagonist agents on performance. It would also be beneficial to explicitly list the contributions of the paper in the introduction and to enhance the discussion on the relationship between GROOVE and related works in RL and meta-learning. Lastly, including a comprehensive notation summary and reorganizing the structure for better readability would significantly aid understanding.