ID: 2Rdfdri2oT
Title: Making Large Language Models Better Data Creators
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for utilizing Large Language Models (LLMs) as efficient data creators, proposing a unified data creation pipeline that requires only a single formatting example applicable to various tasks. The authors introduce a self-reference method to enhance diversity and balance in data generation. The experiments demonstrate that models trained with LLM-generated data outperform those trained with human-labeled data in out-of-distribution (OOD) settings while maintaining comparable performance in in-distribution (ID) tasks.

### Strengths and Weaknesses
Strengths:  
1. The paper provides a structured approach to LLM-based data generation through a formal framework.  
2. It creatively enhances the self-reference method with contrastive selection, similar selection, and tree selection strategies.  
3. Comprehensive experiments analyze the benefits of LLM-generated examples, particularly in OOD settings.

Weaknesses:  
1. The paper lacks comparisons with other LLM-based data generation methods, which undermines claims of superiority.  
2. It does not provide results on training LLMs with the generated examples, limiting insights into the effectiveness of the generated data.  
3. Several technical details are missing, such as optimal grid search settings and the random seed for data selection, affecting reproducibility.

### Suggestions for Improvement
We recommend that the authors improve the paper by including comparisons to other LLM-based data generation methods, even if they are sub-optimal. Additionally, providing results on training LLMs with the generated examples would enhance the understanding of their effectiveness. We also suggest including detailed technical specifications, such as the optimal settings for grid search and the random seed used for data selection, to improve reproducibility. Furthermore, clarifying the implementation of "discarding duplicate and ill-formatted data" and addressing the LLM-related faithfulness issue during data creation would strengthen the paper. Lastly, adding an ethics section to discuss the potential biases in LLM-generated data is encouraged.