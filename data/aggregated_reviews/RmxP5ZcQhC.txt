ID: RmxP5ZcQhC
Title: Agnostic Multi-Group Active Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 4, 5, 7, 6, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on active learning in a multi-group setting, focusing on adaptive sampling for binary classification tasks. The authors aim to extend disagreement-based active learning approaches to this context by proposing a novel worst-case loss estimator for the learner. The performance is evaluated based on maximal loss across groups, and theoretical analyses of sample complexity using this estimator are provided.

### Strengths and Weaknesses
Strengths:
- The paper addresses a challenging and relevant problem in the active learning community, particularly the multi-group extension, which can be viewed as a variant of the Group-DRO problem.
- It rigorously demonstrates the limitations of traditional disagreement-based active learning in this setting and introduces a multi-group loss estimator with reasonable theoretical guarantees.
- The writing is generally clear and accessible.

Weaknesses:
- Major:
  1. Algorithm 1 appears computationally intractable, lacking a thorough complexity analysis, particularly for key steps involving potentially uncountably infinite sets.
  2. The improvement claimed in Theorem 1 over passive and collaborative learning is unclear, as the bound still depends on $d/\epsilon^2$, and the additional factor may worsen the bound.
  3. The absence of a lower bound makes it difficult to assess the tightness of the upper bounds presented.
  4. There is insufficient empirical evaluation.
- Minor:
  1. References to technical lemmas are missing, leading to ambiguity in the text.
  2. Certain terms in the uniform convergence bound appear redundant and could be simplified.
  3. There are typographical errors and inconsistencies in the equations.

### Suggestions for Improvement
We recommend that the authors improve the computational complexity analysis of Algorithm 1, particularly for the steps involving $R_i$ and $\mathcal{H}_{i+1}$. Additionally, the authors should clarify how the bound in Theorem 1 is superior to existing bounds and consider providing a lower bound for comparison. We suggest including more empirical evaluations to support the theoretical claims and addressing the limitations of the proposed algorithms in the main text. Lastly, we advise correcting the missing references to technical lemmas and addressing typographical errors throughout the paper.