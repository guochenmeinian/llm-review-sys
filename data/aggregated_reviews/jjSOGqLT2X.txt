ID: jjSOGqLT2X
Title: Video-Helpful Multimodal Machine Translation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new multimodal machine translation (MT) dataset called EVA, designed to address linguistic ambiguity in translation by utilizing visual context. The authors propose a model named SAFA, which incorporates Frame attention loss and Ambiguity augmentation, demonstrating improved performance on EVA and the existing VISA datasets. The paper is well-organized, with comprehensive experiments supporting its claims.

### Strengths and Weaknesses
Strengths:  
- The dataset contribution is significant and addresses a unique problem in multimodal translation.  
- The writing is clear and easy to follow.  
- The experimental results are solid, showing that the proposed methods effectively enhance translation quality.  

Weaknesses:  
- The definitions of "ambiguous" and "disambiguation" are questionable, as the examples provided focus on omitted words rather than true polysemy.  
- The characterization of ambiguity is too general and lacks sufficient evidence to justify its claims.  
- Figures 1 and 4 require more illustrative detail to enhance understanding.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their definitions regarding ambiguity, providing more evidence to support their claims, such as the proportion of polysemy versus omitted words in the EVA dataset. Additionally, we suggest including more examples of true polysemy to strengthen their argument. The authors should also consider using other evaluation metrics, such as Cider and Spice, and provide information on the distribution of the translation set sizes to clarify the ambiguity degree of the task. Finally, enhancing Figures 1 and 4 with more illustrative content would significantly benefit the paper.