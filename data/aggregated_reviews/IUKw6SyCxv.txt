ID: IUKw6SyCxv
Title: DiffS2UT: A Semantic Preserving Diffusion Model for Textless Direct Speech-to-Speech Translation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to textless direct speech-to-speech translation by introducing an effective diffusion model. The authors propose a framework that integrates continuous and discrete diffusion models by decoupling the diffusion forward and backward processes. Experimental results indicate that the proposed method outperforms vanilla diffusion models and achieves competitive performance compared to auto-regressive models.

### Strengths and Weaknesses
Strengths:
- The introduction of diffusion generative models to the textless S2ST task is innovative and significant.
- The integration of continuous and discrete diffusion processes is well-conceived and effectively demonstrated in experiments.
- The paper is well-written and provides a comprehensive introduction to diffusion models.

Weaknesses:
- The paper lacks comparisons with other non-autoregressive methods, such as TranSpeech, and stronger baseline models, particularly from Lee et al. (2021).
- The introduction section is excessively long, detracting from the focus on the proposed model.
- The performance of the proposed methods is not sufficiently strong across all translation directions, with noted downgrades in some cases.

### Suggestions for Improvement
We recommend that the authors improve the comparison of their model with stronger baseline models, particularly Lee et al. (2021), to provide a clearer context for their performance. Additionally, we suggest condensing the introduction to focus more on the proposed model and its implications. Finally, we encourage the authors to include a more intuitive comparison of computational costs between diffusion and auto-regressive methods, possibly by fixing the target sequence length for evaluation.