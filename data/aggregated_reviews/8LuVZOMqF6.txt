ID: 8LuVZOMqF6
Title: Plug and Play: Enabling Pluggable Attribute Unlearning in Recommender Systems
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Pluggable Attribute Unlearning (PAU) framework, addressing the critical issue of attribute unlearning in recommender systems. The framework's modular design allows for efficient unlearning operations without altering base model parameters. While the use of rate-distortion theory is theoretically sound, its integration lacks depth, and the experimental evaluations, although comprehensive, do not convincingly compare with more recent state-of-the-art baselines. The paper raises questions about the framework's ability to improve recommendation performance while effectively erasing sensitive attributes.

### Strengths and Weaknesses
Strengths:
- The PAU framework offers a practical solution for dynamic unlearning requirements.
- The use of rate-distortion theory is mathematically sound and enhances learning efficiency.
- The paper is well-structured, with clear motivation and comprehensive experimental evaluations.

Weaknesses:
- The choice of baseline models is not convincing, lacking comparisons with more recent literature.
- The metrics for evaluating unlearning quality are insufficient; alternative metrics should be considered.
- The paper lacks critical implementation details and statistical validation of experimental results.

### Suggestions for Improvement
We recommend that the authors improve the comparison with more recent and relevant baselines in the field of machine unlearning, such as the works referenced in the review. Additionally, the authors should address the unexplained phenomena observed in Table 2 and clarify how the framework improves recommendation quality while erasing sensitive attributes. We suggest incorporating alternative metrics for unlearning quality evaluation, such as Completeness and JS-Divergence, to provide a more comprehensive assessment. Furthermore, the authors should provide a deeper theoretical analysis of the chosen objective functions and clarify the necessity of rate-distortion theory in this context. Finally, including larger datasets and advanced models, such as Transformer-based architectures, would enhance the robustness of the experiments.