ID: uBVCPAMDGk
Title: Enhancing Consistency-Based Image Generation via Adversarialy-Trained Classification and Energy-Based Discrimination
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 5, 6, 7, 5, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a post-processing method utilizing a joint classifier-discriminator model to enhance the generation quality of consistency models. The model is trained adversarially, with the robust classifier providing gradients based on class assignments and discriminator scores. The method demonstrates consistent improvements in generated image quality, reflected in better FID scores for both consistency distillation and training. However, the evaluations are limited to the ImageNet dataset at a resolution of 64x64, which may not adequately represent high-resolution generation trends.

### Strengths and Weaknesses
Strengths:
- The method can be seamlessly integrated into generative models, facilitating applications.
- The approach is efficient and easy to implement, with clear writing and organization.
- The method outperforms baselines on the evaluation dataset, and the methodology is well justified.

Weaknesses:
- The theoretical connections to Robust Classifier and Energy-based Models are not comprehensively derived.
- The motivation for using the joint classifier-discriminator is unclear, particularly in relation to adversarial attacks and robustness.
- Evaluation is limited to a single dataset at a low resolution, lacking qualitative results and broader applicability.
- The marginal improvement in final loss compared to using CE and BCE alone raises questions about the method's effectiveness.

### Suggestions for Improvement
We recommend that the authors improve the theoretical derivation of the connections to Robust Classifier and Energy-based Models. Additionally, a clearer motivation for the joint classifier-discriminator approach should be provided, particularly regarding its relevance to adversarial robustness. To enhance evaluation, we suggest including datasets with higher resolutions, such as LSUN and FFHQ, and employing additional metrics like precision and recall. Furthermore, we encourage the authors to conduct ablation studies on hyper-parameters, including the radius $\epsilon$, and to provide more qualitative visualizations, particularly with datasets sensitive to human perception, such as Flicker Faces. Lastly, incorporating a figure overview of the pipeline could improve clarity.