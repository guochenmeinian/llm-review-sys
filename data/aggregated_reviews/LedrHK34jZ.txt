ID: LedrHK34jZ
Title: TAPE: Tailored Posterior Difference for Auditing of Machine Unlearning
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents TAPE, a novel method for auditing machine unlearning that addresses privacy concerns by evaluating the effectiveness of unlearning processes without relying on inefficient backdoor-based methods. TAPE utilizes posterior differences between models before and after unlearning to assess data erasure. The experimental results indicate TAPE's efficiency and effectiveness across various datasets, achieving significant improvements over state-of-the-art methods.

### Strengths and Weaknesses
Strengths:
1. The writing is clear, and the formulas are correct.
2. The experimental design is abundant and multi-dimensional, effectively supporting the research objectives.
3. TAPE demonstrates broad applicability for auditing genuine unlearned samples in both single- and multi-sample scenarios, achieving at least a 4.5Ã— speedup compared to baseline methods.

Weaknesses:
1. The shadow model construction relies on first-order influence estimation, which may introduce errors, particularly with highly nonlinear or complex data. The authors should provide evidence on more complex data.
2. TAPE assumes minimal impact on model parameters during unlearning, which may limit its usability in cases requiring substantial parameter updates. The authors should analyze the effects of unlearning a large number of samples.
3. The paper includes limited method comparisons, primarily with backdoor-based verification methods, and lacks broader benchmarking with advanced unlearning verification techniques.
4. The source code appears incomplete and seems prepared for another conference, raising concerns about its relevance.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the relationship between the reconstructor and unlearned models, ensuring that it is evident how the reconstructor performs without an unlearning method. Additionally, the authors should clarify the differences between their work and similar studies, as well as provide more technical details and proofs regarding the implementation of the shadow model and reconstructor. Finally, addressing the potential complexities of the methodology and ensuring the availability of local datasets for auditing would enhance the paper's robustness.