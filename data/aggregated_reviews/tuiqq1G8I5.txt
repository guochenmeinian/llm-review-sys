ID: tuiqq1G8I5
Title: DisCEdit: Model Editing by Identifying Discriminative Components
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 5, 7, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for model editing that addresses structured pruning and selective class forgetting by utilizing a distributional approach to identify critical components in neural networks. The authors propose a moment-based lower bound on the total variation (TV) distance to evaluate the discriminative ability of filters, leading to the introduction of DISCEDIT-U for unlearning and DISCEDIT-SP for structured pruning. The experimental results indicate the effectiveness of DISCEDIT in both tasks.

### Strengths and Weaknesses
Strengths:
- The paper employs lower bounds on the TV distance to quantify the discriminative ability of neural network filters.
- The introduction of DISCEDIT-U and DISCEDIT-SP facilitates selective pruning and unlearning, respectively.
- Experimental results demonstrate the efficacy of the proposed methods.

Weaknesses:
- The provided code links to an empty GitHub repository, hindering reproducibility.
- The paper lacks an introductory overview of machine unlearning and structured pruning, failing to contextualize its contributions within existing research.
- DISCEDIT-U's performance is not compared against other unlearning methods, complicating the assessment of its effectiveness.
- Results for DISCEDIT-SP show no significant improvement over existing baselines, particularly against CHIP on ImageNet.

### Suggestions for Improvement
We recommend that the authors improve the introduction by providing a detailed overview of machine unlearning and structured pruning, contextualizing their work within the current research landscape. To demonstrate the effectiveness of DISCEDIT-U, the authors should compare its performance with other existing unlearning methods. Additionally, we suggest incorporating a more detailed description of the experimental setup and results in the main text rather than relegating them to the appendix. Furthermore, the authors should address the minor issues identified, such as the motivation for the choice of witness functions and the reporting of actual model accuracies in their results.