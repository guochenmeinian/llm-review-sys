ID: w50ICQC6QJ
Title: Discovery of the Hidden World with Large Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 28
Original Ratings: 6, 5, 8, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Causal representatiOn AssistanT (COAT), which integrates large language models (LLMs) to enhance causal discovery from unstructured data. COAT utilizes LLMs to identify high-level variables and convert unstructured data into structured formats, which are then analyzed by causal discovery algorithms to uncover causal relationships. The iterative process allows for feedback to refine variable identification, ultimately aiming to establish a Markov blanket for target variables. Empirical evaluations across synthetic and real-world datasets demonstrate COAT's effectiveness compared to simple baselines. Additionally, the authors propose a theoretical framework for evaluating the performance of LLMs in causal inference tasks, emphasizing the importance of factors such as LLM capabilities, data faithfulness, and prompt templates. Key revisions in the manuscript include clearer definitions, intuitive interpretations of metrics, and discussions on the impact of factor quality on faithfulness conditions.

### Strengths and Weaknesses
Strengths:
1. The paper addresses a significant problem in causal discovery, effectively combining LLMs and traditional algorithms.
2. COAT is novel and well-motivated, with theoretical discussions supporting its soundness.
3. The model-agnostic nature of COAT allows flexibility in LLM and data modality choices.
4. Extensive experiments and benchmarks validate the proposed method's performance.
5. The authors have made substantial revisions that enhance clarity and motivation behind key equations and propositions.
6. Inclusion of ablation studies and theoretical results strengthens the manuscript's contributions.
7. The revisions reflect a thoughtful engagement with reviewer feedback, improving the overall quality of the work.

Weaknesses:
1. The theoretical claims are overstated, relying on strong assumptions about LLM capabilities and data diversity.
2. The empirical evaluation lacks robust comparisons with advanced prompting techniques and stronger baselines.
3. Key evaluation aspects are relegated to the appendix, hindering full assessment.
4. The paper lacks a detailed limitations section, particularly regarding the evaluation methodology.
5. Some reviewers noted that while concerns were addressed, there may still be "unfixable" issues that require further clarification.
6. The manuscript may still benefit from additional comparisons to existing methods, such as CoT.

### Suggestions for Improvement
We recommend that the authors improve the theoretical analysis by exploring the impact of LLM modules, such as prompt templates and feedback responsiveness. Additionally, a thorough ablation study on the initial prompts and feedback mechanisms should be conducted to strengthen the paper. The authors should also provide more comparisons with advanced prompting techniques and include stronger baselines from the related work to substantiate claims of COAT's effectiveness. Furthermore, it is essential to enhance the clarity of the paper by including key evaluation details in the main text and expanding the limitations section to address potential risks associated with LLMs in causal discovery. Lastly, we recommend integrating a comparison to CoT in future revisions and clarifying any remaining "unfixable" concerns raised by reviewers to enhance the manuscript's comprehensibility.