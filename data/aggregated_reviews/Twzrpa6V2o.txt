ID: Twzrpa6V2o
Title: InfiMM-WebMath-40B: Advancing Multimodal Pre-Training for Enhanced Mathematical Reasoning
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 7, 9, 7
Original Confidences: 3, 5, 5

Aggregated Review:
### Key Points
This paper presents "InfiMM-WebMath-40B," a large-scale multimodal dataset aimed at enhancing mathematical reasoning in Large Language Models (LLMs). The authors detail the data collection and processing pipeline, including a comprehensive data curation process that integrates text and visual data. The dataset has shown state-of-the-art performance on benchmarks like MathVerse and We-Math, indicating its effectiveness and potential impact on the open-source community.

### Strengths and Weaknesses
Strengths:
- The dataset fills a critical gap in the open-source community for multimodal mathematical reasoning.
- The methodology is detailed, ensuring reproducibility and transparency.
- Innovative filtering techniques enhance dataset quality, and strong experimental results validate its effectiveness.
- The paper is well-structured, with clear figures and tables that support the narrative.

Weaknesses:
- Limited performance in the Vision-Only category suggests potential issues with the vision encoder.
- The model training process is resource-intensive, which may hinder accessibility for smaller research groups.
- There is a lack of detailed error analysis or qualitative examples of model outputs.

### Suggestions for Improvement
We recommend that the authors improve clarity by including summary statistics on the images and document sizes in the dataset, detailing the number of images, pixel dimensions, and file formats. Additionally, the authors should classify the types of math problems associated with the documents and images, as this would aid in ablation studies. To address potential false positives and negatives in the cleansing process, we suggest estimating confusion matrices for the classifiers based on a subset of document/image pairs. Furthermore, the math extraction tool should be open-sourced to enhance reproducibility, and the authors should clarify the process for Chinese language processing and how it differs from English. Lastly, we encourage the authors to provide information on where the dataset will be publicly available.