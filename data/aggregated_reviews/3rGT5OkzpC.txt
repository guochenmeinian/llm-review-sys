ID: 3rGT5OkzpC
Title: Comparing Humans, GPT-4, and GPT-4V On Abstraction and Reasoning Tasks
Conference: AAAI
Year: 2023
Number of Reviews: 5
Original Ratings: 2, 2, 2, 2, -1
Original Confidences: 2, 2, 2, 2, 3

Aggregated Review:
### Key Points
This paper presents an evaluation of GPT-4, GPT-4V, and human performance on the ConceptARC benchmark, which assesses abstract reasoning through grid analogy puzzles. The authors provide empirical evidence that these models are still significantly behind human-level concept abstraction and understanding. The systematic evaluation of GPT-4V on reasoning tasks is noteworthy and contributes to ongoing discussions in the field.

### Strengths and Weaknesses
Strengths:
* The paper is well-written, clear, and provides thorough evaluations.
* It addresses key limitations in previous research and offers significant contributions to understanding model performance on abstraction tasks.

Weaknesses:
* The relevance of the paper's contribution to the workshop theme is questioned, despite its importance for causal reasoning.
* Certain methodological aspects, such as the subjective nature of prompt design and the inclusion of specific participants, require further clarification.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the comparison between zero-shot and one-shot prompting, particularly regarding the unexpected performance differences observed. Additionally, we suggest that the authors analyze the leakage issue in GPT-4Vâ€™s outputs further, as it may impact performance. It would be beneficial to clarify the inclusion criteria for participants and to explore the definition of "ground truth" labels in ConceptARC for a more robust evaluation. We also encourage the authors to enhance the reporting of GPT-4V results by focusing on how accurately the model describes abstract rules, and to consider a grid reference system for clearer communication of grid descriptions. Finally, we recommend delineating experiments with varying degrees of prompt specificity to better understand the relationship between background information and output accuracy.