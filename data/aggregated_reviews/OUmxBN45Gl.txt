ID: OUmxBN45Gl
Title: Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a systematic analysis of the cost and utility of OpenAI's API across 22 typologically diverse languages, highlighting the issue of suboptimal tokenization that leads to significant variance in token requirements. The authors find that many languages experience heavy fragmentation, resulting in higher costs and lower model utility from the APIs. They critique the pricing policy based on token counts, which disadvantages over-fragmented languages, and propose potential remedies.

### Strengths and Weaknesses
Strengths:
- The methodology is exhaustive, covering various dimensions such as monolingual and multilingual models, model performance, and socioeconomic implications.
- The findings provide critical insights into language properties and their impact on model utility due to tokenizer over-fragmentation.
- The paper effectively discusses the socioeconomic implications of API pricing policies and offers recommendations for LLM practitioners.

Weaknesses:
- The conceptual-theoretical foundation is weak, with insufficient grounding for value judgments regarding fairness in token pricing.
- The analysis lacks comprehensive evaluations beyond ChatGPT and BloomZ, omitting other significant models like Anthropic's Claude and Cohere.
- Some key figures and results are inadequately presented, with missing details on datasets and tokenization processes.

### Suggestions for Improvement
We recommend that the authors improve the conceptual grounding of their value judgments regarding token pricing fairness, possibly by incorporating philosophical or economic perspectives. Additionally, we suggest including evaluations of other models such as Anthropic's Claude and Cohere to strengthen the analysis. Clarifying the methodologies used for tokenization, particularly for the BLOOMZ tokenizer, and providing a complete list of languages analyzed would enhance transparency. Furthermore, addressing the concerns raised about the presentation of results in Figures 2 and 3, as well as the careful use of terminology related to "language" and "script," would improve the clarity of the paper.