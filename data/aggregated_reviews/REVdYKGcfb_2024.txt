ID: REVdYKGcfb
Title: What Factors Affect Multi-Modal In-Context Learning? An In-Depth Exploration
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 4, 8, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive investigation into the factors influencing Multi-modal In-Context Learning (MM-ICL), focusing on demonstration retrieval, ordering, and prompt construction. The authors conduct extensive experiments across six vision large language models (VLLMs) and 20 strategies, revealing that multi-modal alignment is a critical bottleneck, intra-demonstration ordering is more significant than inter-demonstration ordering, and introductory instructions enhance task comprehension. Reviewers express gratitude for the authors' efforts and propose that the authors incorporate their suggestions to enhance the quality of their work in future versions.

### Strengths and Weaknesses
Strengths:
- The paper addresses an important and underexplored problem in MM-ICL.
- It conducts detailed experiments across multiple models and strategies, providing valuable insights.
- The findings can serve as a foundational guide for future research in optimizing MM-ICL strategies.
- The authors have effectively addressed all concerns raised by the reviewers, demonstrating a commitment to improving their work.

Weaknesses:
1. The claim of being the first to study multimodal ICL is misleading, as similar studies exist without acknowledgment.
2. The paper does not utilize standard benchmarks or commonly accepted metrics, leading to potentially flawed conclusions.
3. Some experimental results appear intuitive, lacking novelty, and qualitative analysis is insufficient.
4. Claims regarding the impact of demonstration numbers and model scaling are inconsistent with prior research and require further evidence.
5. Captions for figures are inadequate, and there are inaccuracies in citations and terminology.

### Suggestions for Improvement
We recommend that the authors improve the acknowledgment of prior works related to multimodal ICL to avoid misleading claims. It is crucial to incorporate standard benchmarks such as VQAv2, COCO captioning, and others, using metrics like Accuracy, CIDEr, and BLEU to support their findings. We suggest enhancing the clarity of the 'Exploration of MM-ICL Prompt Construction' section and moving some appendix details to the main text. Additionally, the authors should provide more qualitative analysis and detailed figure captions to aid reader comprehension. Lastly, we advise refining claims about the number of demonstrations and model scaling with robust evidence to align with existing literature.