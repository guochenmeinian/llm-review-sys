ID: kMueEV8Eyy
Title: Abide by the law and follow the flow: conservation laws for gradient flows
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 7, 7, 7, 7, 8, -1, -1, -1
Original Confidences: 3, 4, 3, 4, 3, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study of conservation laws in the gradient flow dynamics of neural networks, introducing a local factorization of the loss function into a data-independent term $\phi$ and a data-dependent term $f$. The authors characterize conserved quantities for fixed $\phi$ and all $f$, claiming this is equivalent for ReLU networks under certain assumptions. They explore the polynomial nature of conservation laws in linear and ReLU networks and conjecture that known conservation laws form a maximal set, with implications for deeper architectures. 

### Strengths and Weaknesses
Strengths:
- The paper is well-written and guides the reader through complex results with minimal prerequisite knowledge.
- The results appear novel and integrate well with existing literature.
- The main text provides reasonable justification for formal results, which are proven in the Appendix.

Weaknesses:
- The necessity of the introduced factorization property is unclear; the analysis may be applicable to concrete examples without it. Additional high-level explanations could clarify this concept.
- The paper is primarily focused on two-layer linear and ReLU networks, limiting its applicability to more complex architectures.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the factorization's necessity and its implications by adding high-level explanations or justifications. Additionally, addressing whether the requirement in Eq. 2 is vacuous could enhance understanding; a counter-example or clarification on the conditions for $\phi$ and $f$ would be beneficial. We suggest including a discussion on the implications of the Lie algebra being infinite-dimensional and exploring how conservation laws might apply to architectures with non-piecewise linear activation functions. Lastly, we recommend improving the organization of the manuscript to present definitions and theorems in a more coherent manner.