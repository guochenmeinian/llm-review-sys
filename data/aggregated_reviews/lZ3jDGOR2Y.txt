ID: lZ3jDGOR2Y
Title: Synergizing Large Language Models and Knowledge-based Reasoning for Interpretable Feature Engineering
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ReaGen, an automated feature engineering (AutoFE) approach that integrates Large Language Models (LLMs) with Knowledge Graphs (KGs) to enhance interpretability and performance in machine learning tasks, particularly for tabular data. ReaGen extracts relevant knowledge from KGs and uses LLMs to iteratively generate and evaluate new features, aiming to improve interpretability and reduce LLM hallucinations while providing human-understandable explanations. Experiments validate ReaGen's effectiveness, demonstrating performance improvements across various public datasets.

### Strengths and Weaknesses
Strengths:
- ReaGen emphasizes generating interpretable features crucial for real-world applications.
- The integration of LLMs and KGs enhances the generation of meaningful and contextually relevant features.
- The approach shows significant accuracy and interpretability improvements over traditional AutoFE methods.
- The method is computationally efficient and scalable, tested on large datasets.
- It provides human-like explanations for generated features, facilitating validation by domain experts.

Weaknesses:
- The reliance on external KGs may limit applicability in domains lacking high-quality KGs.
- LLMs still exhibit limitations in specific domain-related reasoning and context-aware transformations.
- The paper does not explore the model's sensitivity to variations in LLM parameters, KG quality, or feature complexity.
- There is limited discussion on performance across different industries or specialized fields.
- The methodology section lacks organization, making it difficult to understand.
- The paper does not provide code for reproducibility and relies on outdated baselines for comparison.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the knowledge graph integration process, specifically regarding how to use external knowledge effectively. Additionally, the authors should provide code to enhance reproducibility and consider including more recent baseline comparisons to strengthen their evaluation. It would be beneficial to elaborate on the limitations of existing methods in achieving high-order features and to clarify the evaluation of interpretability in their framework. Finally, addressing the optimal feature selection strategies with LLMs and providing details on the specific LLM used, including operational costs, would enhance the paper's comprehensiveness.