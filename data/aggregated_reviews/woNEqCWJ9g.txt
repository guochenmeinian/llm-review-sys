ID: woNEqCWJ9g
Title: Distributionally Robust Optimisation with Bayesian Ambiguity Sets
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 8, 6, 9
Original Confidences: 3, 3, 3

Aggregated Review:
### Key Points
This paper presents a new method, DRO-BAS, aimed at enhancing decision-making under uncertainty by addressing risks from noisy data and model misspecification. The authors propose optimizing the worst-case risk using ambiguity sets informed by posterior distributions, extending traditional Bayesian DRO approaches. They validate DRO-BAS through theoretical proofs and a numerical example involving the Newsvendor problem, demonstrating its effectiveness.

### Strengths and Weaknesses
Strengths:
- DRO-BAS exhibits superior out-of-sample performance compared to existing Bayesian DRO techniques, especially with small sample sizes, as illustrated in Figure 2.
- The paper establishes a solid theoretical foundation, including a closed-form dual representation for various exponential family models.
- The method simplifies the dual formulation into a single-stage stochastic program, thereby reducing computational complexity.

Weaknesses:
- The applicability of DRO-BAS to more general, high-dimensional problems is only briefly mentioned as future work, limiting its immediate relevance to broader decision-making contexts.
- The performance advantage of DRO-BAS over BDRO diminishes with larger datasets, where both methods yield similar out-of-sample performance.
- The method complicates the selection of the ambiguity set's tolerance level.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the extension of DRO-BAS to a broader class of distributions and provide tools or suggestions for solving Eq. 3 in more general cases. Additionally, we suggest addressing the limitations of using KL divergence and exploring the potential for employing other divergence measures, as the current results heavily depend on KL properties.