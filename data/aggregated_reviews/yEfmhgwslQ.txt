ID: yEfmhgwslQ
Title: Encoding Time-Series Explanations through Self-Supervised Model Behavior Consistency
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 5, 7, 7, 6, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 2, 4, 2, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents TimeX, a novel method for training an interpretable surrogate model for pre-trained time series classification models. TimeX generates a latent embedding of time series observations and outputs classification probabilities consistent with a reference model while identifying time-localized patterns. The method involves training an explanation generator and encoders/decoders that preserve the topology of latent spaces and output distributions. The authors introduce a self-supervised objective called model behavior consistency, ensuring the preservation of relationships in the latent space induced by the pre-trained model.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and presents a strong motivation for the proposed method.
2. TimeX is the first to suggest in-hoc explanations for time series data.
3. The methodology includes convincing justifications for design choices like discrete masking and consistency learning.
4. The evaluation is robust, utilizing diverse datasets and multiple comparison methods.

Weaknesses:
1. Some statements are inaccurate, such as the claim about state-of-the-art models in time series classification versus forecasting.
2. The description of the method lacks clarity and intelligibility, particularly regarding the functions and notations used.
3. There is insufficient analysis of the discovered temporal patterns, and the paper does not adequately discuss the quality of explanations or the computational complexity of the explainer modules.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the method description, particularly by explicitly defining functions and notations used throughout the paper. Additionally, we suggest including a discussion on the quality of explanations, possibly by introducing metrics such as IoU with ground truth. The authors should also consider providing further analysis of the temporal patterns identified by TimeX and how they compare to existing methods. Lastly, a clearer discussion of the computational complexity and resource requirements for training the explainer modules relative to other methods would enhance the paper's contribution.