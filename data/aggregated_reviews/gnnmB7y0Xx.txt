ID: gnnmB7y0Xx
Title: In-Context Learning State Vector with Inner and Momentum Optimization
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 7, 4, 4, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the novel concept of the state vector, which encapsulates information from in-context learning (ICL) examples using separate tokens as anchors. The authors propose inner and momentum optimization techniques to generate task-specific state vectors, addressing the context length limitation of large language models (LLMs) through a divide-and-conquer (D&C) strategy. Additionally, the paper analyzes the D&C aggregation method in comparison to average aggregation and ICL baselines across zero-shot and few-shot settings. Experimental results indicate that patching the state vector during inference outperforms previously proposed task and function vectors. The D&C aggregation method shows significant improvement as the number of examples increases, outperforming the ICL baseline at the 100-example setting across four datasets.

### Strengths and Weaknesses
Strengths:  
1. The approach of optimizing the state vector using inner/momentum optimization is well-motivated, despite the idea of using vectors for ICL not being new.  
2. The paper is well-organized, with sound experiments and ablation studies that provide useful insights.  
3. The in-depth analysis of ICL vectors across various datasets enhances the understanding of the optimization methods.  
4. Comprehensive experimental results clearly demonstrate the performance of the D&C aggregation method, effectively highlighting the limitations of average aggregation.  
5. Notable improvements in performance with increased examples are well-documented, showcasing the method's effectiveness.

Weaknesses:  
1. The applicability of this work to larger models or more complex datasets remains unclear, raising questions about its generalizability.  
2. The necessity of including a dummy query when extracting the state vector is not justified, leading to ambiguity.  
3. The definition of state vectors lacks a rigorous theoretical basis, complicating the inference of the approach's reliability across different NLP tasks.  
4. D&C aggregation underperforms compared to the ICL baseline in few-shot settings with limited examples, which may raise concerns about its applicability in such scenarios.  
5. The reliance on a small number of examples in the conquer stage limits the model's ability to compress information effectively.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the applicability of the state vector to larger models and more complex datasets. Additionally, the authors should provide a rationale for the inclusion of a dummy query in the state vector extraction process. To enhance the theoretical foundation, we suggest that the authors clarify the similarities and differences between the state vector and updated parameters with gradient descent. Furthermore, we recommend that the authors improve the clarity of the discussion surrounding the limitations of D&C aggregation in few-shot settings, particularly regarding the impact of the conquer stage's reliance on limited examples. Providing further insights into potential strategies for enhancing performance in low-example scenarios could strengthen the paper. Finally, we encourage the authors to explore the performance of the state vector method on more complex ICL tasks, such as math and text summarization, to better understand its limitations and potential.