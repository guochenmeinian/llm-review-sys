ID: YZJ3oewPcu
Title: Language Model Quality Correlates with Psychometric Predictive Power in Multiple Languages
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into the relationship between the linguistic predictive ability of transformer models and their psychological accuracy in predicting human reading times across multiple languages. The authors report that better language models correlate with improved predictions of reading data, addressing a significant issue in computational psycholinguistics. The study employs a cross-linguistic approach, which is essential for testing general theories in the field.

### Strengths and Weaknesses
Strengths:
- The cross-linguistic approach is commendable and necessary for broader applicability.
- The integration of formal proof with empirical results is elegantly executed.
- The paper is technically sound and theoretically rigorous, with the authors training their own transformer models to mitigate data leakage.

Weaknesses:
- The study relies on small models and reduced training data scales, which may not align with existing literature that reports contrasting findings at larger scales.
- The proof sketch lacks clarity regarding how it applies to models with memory constraints, which could affect the validity of the claims.
- The paper does not adequately address why the correlation does not hold for certain languages, such as Japanese, Finnish, and German.

### Suggestions for Improvement
We recommend that the authors improve the framing of their findings to acknowledge the differences in model sizes compared to previous literature. Additionally, we suggest including results for entropy and surprisal tested separately in an appendix to enhance dialogue with existing research. The authors should clarify the proof sketch, particularly regarding its applicability to models with memory limitations, and provide examples to illustrate this. Lastly, we encourage the authors to discuss the reasons for the lack of correlation in specific languages and to ensure that all relevant recent literature is cited in the revised manuscript.