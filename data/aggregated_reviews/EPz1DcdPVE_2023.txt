ID: EPz1DcdPVE
Title: Towards Federated Foundation Models: Scalable Dataset Pipelines for Group-Structured Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 19
Original Ratings: 8, 8, 6, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Dataset Grouper, a library designed to create large-scale group-structured datasets for federated learning (FL) simulations. It allows users to partition existing datasets based on specified criteria, resulting in four new large-scale federated datasets (FedC4, FedWiki, FedBookCO, FedCCNews) that facilitate the evaluation of FL algorithms such as FedAvg and FedSGD. The authors demonstrate that FedAvg excels in personalization while FedSGD is superior for global model performance, providing detailed evaluations across multiple datasets and highlighting the efficiency of the streaming data format compared to hierarchical and in-memory formats. The authors generate new insights into these algorithms through their experiments, emphasizing the library's potential to enhance understanding in the field.

### Strengths and Weaknesses
Strengths:
- The authors address a significant gap in the availability of large-scale federated datasets, which enhances the generalizability of insights in FL.
- The library's capabilities are demonstrated through the creation of four large-scale datasets and their application in evaluating FL algorithms.
- The authors provide clear experimental results that illustrate the advantages of different algorithms and dataset formats.
- The Dataset Grouper supports various user-defined partitioning functions, enhancing its applicability.
- The paper includes practical examples and scripts to facilitate user experimentation.

Weaknesses:
- The paper lacks clarity regarding the difficulty of user-specified partition methods and does not adequately compare different dataset formats or detail optimization strategies for streaming formats.
- Some aspects of the dataset format comparisons and user-specified partition methods lack clarity.
- Limitations regarding the support for automatically creating meaningful data distributions and the implications of restricting data access patterns are not thoroughly discussed.
- The limitations of the streaming format regarding data access patterns and the inefficiencies of hierarchical formats are not fully addressed.

### Suggestions for Improvement
We recommend that the authors improve the functionality of Dataset Grouper by incorporating automated partitioning options based on user-specified statistical properties. This would enable systematic studies of FL performance under various data partitionings (IID vs. non-IID). Additionally, we suggest that the authors provide a more detailed discussion of the rationale and trade-offs associated with different partitioning methods and their implications for FL and LLM training. Improving the clarity of the discussion surrounding the difficulty of user-specified partition methods and the implications of dataset format comparisons would enhance the paper's comprehensibility. Furthermore, clarifying the usability of the library in multiprocessing workflows and reporting memory usage and overhead for datasets would also enhance the paper's comprehensiveness. Finally, conducting more extensive experiments on larger models and additional datasets would strengthen the library's applicability and generalizability.