ID: VpuOuZOVhP
Title: LLM-AutoDA: Large Language Model-Driven Automatic Data Augmentation for Long-tailed Problems
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 8, 7, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents LLM-AutoDA, a novel framework that utilizes large language models (LLMs) to automatically generate data augmentation strategies for long-tailed learning. The authors propose a method that balances the use of existing knowledge with the encouragement of innovation, effectively addressing challenges associated with long-tailed data distributions. They discuss the limitations of traditional methods and emphasize that their approach, while incorporating black-box elements, remains fundamentally explainable and provides valuable insights into long-tailed learning. Extensive experiments demonstrate the effectiveness of LLM-AutoDA across multiple long-tailed datasets, showcasing adaptive strategies for data augmentation and resource balancing across categories.

### Strengths and Weaknesses
Strengths:
1. The integration of LLMs for data augmentation in long-tail learning is innovative and contributes significantly to the field.
2. The method effectively reduces manual design costs and adapts strategies based on validation performance.
3. Empirical and ablation studies are well-executed, showcasing the method's effectiveness.
4. The paper demonstrates significant improvements in experimental results and clarity following revisions.
5. The authors effectively address reviewer concerns, highlighting the innovative aspects of their methodology and providing insights into the interplay between LLM creativity and long-tailed learning.

Weaknesses:
1. The paper lacks clarity in explaining the impact of multiple prompts on the augmentation strategy.
2. There is insufficient evaluation of LLM-AutoDA against other methods under varying long-tailed settings.
3. The clarity of notation and definitions is poor, making it difficult to understand the algorithm.
4. The paper contains several syntax errors and typos that need correction.
5. Some elements of the research may still be perceived as black-box, potentially obscuring interpretability.
6. The relationship to reinforcement learning is not fully articulated, which may lead to confusion regarding the methodology's classification.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by providing detailed explanations of the impact of multiple prompts on the augmentation strategy. Additionally, evaluate and compare the performance of LLM-AutoDA with other automated data augmentation methods like AutoAugment and PBA under different long-tailed settings. It would also be beneficial to unify the figure and text sizes in the appendix and correct the identified syntax errors and typos for better readability. Furthermore, we suggest that the authors clarify the distinctions between their approach and reinforcement learning to prevent misinterpretation. Lastly, consider providing examples of the augmentation strategies generated by LLM to enhance transparency and understanding of their effectiveness.