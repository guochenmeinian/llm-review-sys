ID: eM5d7ZmekA
Title: GeoLRM: Geometry-Aware Large Reconstruction Model for High-Quality 3D Gaussian Generation
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 4, 4, 7, -1, -1, -1, -1
Original Confidences: 5, 4, 5, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a geometry-aware large reconstruction model that utilizes a Proposal Transformer to identify valid occupancy grids and employs Deformable Cross Attention for aggregating image features to predict 3D Gaussians. The authors claim state-of-the-art performance, particularly as the number of input views increases, addressing the limitations of previous methods that lack explicit correspondence between 2D features and 3D representations.

### Strengths and Weaknesses
Strengths:
- The paper introduces an innovative approach to large reconstruction models by predicting occupancy grids, potentially reducing memory consumption with increased input views.
- The proposed method demonstrates state-of-the-art performance, improving with more input views.
- The architecture effectively integrates higher frequency information and selective computing through a proposal network.

Weaknesses:
- The comparison with InstantMesh is deemed unfair due to differing training conditions regarding input views, undermining the validity of the main claims.
- The rendering resolution of 448x448 deviates from the 512x512 standard used in other works, complicating fair comparisons.
- The introduction of the Proposal Transformer adds complexity, and an inference time comparison with other methods is lacking.
- The evaluation is limited to the GSO dataset, and comparisons with additional datasets like OmniObject3D would enhance credibility.
- The paper lacks clarity, particularly in the method section, with inconsistent terminology and insufficient detail on the Proposal Transformer.

### Suggestions for Improvement
- We recommend that the authors improve the fairness of comparisons by retraining InstantMesh under the same conditions as their model.
- To facilitate better comparisons, consider standardizing the rendering resolution to 512x512.
- We suggest including GPU memory and inference time comparisons in Table 2 to highlight the advantages of the proposed method.
- Expanding the evaluation to include additional datasets would strengthen the claims made in the paper.
- Clarifying the method section, particularly the Proposal Transformer and its relationship to the Reconstruction Transformer, would enhance readability and understanding.