ID: pJwlMI7AYm
Title: NERetrieve: Dataset for Next Generation Named Entity Recognition and Retrieval
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a position paper assessing the current state of named entity recognition (NER) solutions, particularly in the context of large-scale language models (LLMs). The authors define three challenging NER tasks: (1) fine-grained supervised NER, (2) zero-shot fine-grained NER, and (3) exhaustive typed-entity retrieval. They introduce a new dataset, NERetrieve, consisting of 4 million paragraphs with entity spans marked for 494 types, aimed at supporting research on these tasks. The authors conclude that even the latest LLMs do not adequately address these challenges, indicating a need for further research.

### Strengths and Weaknesses
Strengths:
- The paper provides a clear description of real-world use cases for challenging NER tasks.
- It contributes to the NLP research community by offering a substantial dataset that facilitates analysis of new solutions for the defined tasks.

Weaknesses:
- The paper lacks references to relevant works on extreme multi-label classification tasks, which are conceptually related to fine-grained NER.
- The motivation for selecting baseline/reference models for the newly defined tasks is unclear.
- The main contributions of the paper are ambiguous, particularly regarding the novelty of the proposed tasks.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper's main contributions, particularly by explicitly stating how their work differs from existing literature on fine-grained supervised NER and zero-shot fine-grained NER. Additionally, we suggest that the authors provide a baseline model on the NERetrieve dataset to demonstrate its utility and quality. It would also be beneficial to address the concerns regarding the dataset's quality evaluation and its future availability. Furthermore, we encourage the authors to incorporate references to related works on extreme multi-label classification tasks, such as skill extraction, to strengthen their position. Lastly, we recommend enhancing the writing quality by addressing the identified typos and improving the overall presentation.