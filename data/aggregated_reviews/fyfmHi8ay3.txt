ID: fyfmHi8ay3
Title: Template-free Articulated Neural Point Clouds for Reposable View Synthesis
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 6, 6, 6, 4, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 3, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for dynamic radiance fields of articulated objects using skeletal animation. The authors propose an automatic skeleton extraction via medial axis transform and derive an object feature point cloud from a pre-trained NeRF, utilizing linear blend skinning to express positions as a function of the skeleton. The animatable point cloud is optimized using the PointNeRF renderer, incorporating losses for RGB, rigidity, animation smoothness, and 2D CD against the mask. Evaluations on the Robots and Blender datasets indicate favorable comparisons with previous works.

### Strengths and Weaknesses
Strengths:
- The use of a point-based representation effectively addresses local deformations.
- Automatic part decomposition and reposing are valuable contributions compared to other dynamic NeRFs.
- Favorable comparisons with relevant previous work, particularly WIM.
- The extracted part decompositions and skinning weights are intuitive and visually appealing.
- The paper is well-written and clearly articulates limitations and failure cases.

Weaknesses:
- The work is largely constructive, relying on existing concepts without significant novel insights; however, the joint system does offer some novelty.
- The method closely resembles existing approaches for animatable human radiance fields but lacks direct comparisons with them.
- While relevant related work is mentioned, it is not consistently compared against, particularly NeRFies and NSFF, which are known for superior results.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the utilization of features $\mathbf{f}_i$ from TiNeuVox, specifying whether they are optimized or kept fixed. Additionally, a comparison with human-focused methods would enhance the paper's robustness. We suggest including quantitative and qualitative results on human-related datasets, such as ZJU-MoCap, to provide a more comprehensive assessment. Furthermore, addressing the robustness of the initialization process and clarifying the implications of using time-dependent rotations would strengthen the methodology. Lastly, we encourage the authors to explore the potential of incorporating artist-driven animations to enhance the reposing results.