ID: 4B296hrTIS
Title: Causal Inference using LLM-Guided Discovery
Conference: AAAI
Year: 2023
Number of Reviews: 3
Original Ratings: 2, 2, -1
Original Confidences: 3, 2, 3

Aggregated Review:
### Key Points
This paper presents a promising approach that utilizes a prompting and voting strategy to enhance the reliability of estimated causal graphs, further employing discovery methods to derive the final causal graph. The authors justify the causal order metric for effect estimation, building on existing work that leverages large language models (LLMs) to generate causal graphs from background domain knowledge.

### Strengths and Weaknesses
Strengths:  
1. The proposed method achieves promising causal discovery compared to baseline discovery methods.  
2. The method introduces a novel idea of leveraging LLMs to generate improved causal order.  

Weaknesses:  
1. LLMs require meaningful variable names.  
2. It is unclear how LLMs address ambiguities in variable names.  
3. There is a lack of comparison regarding the running time of different methods and how the proposed method scales with an increasing number of variables.  

### Suggestions for Improvement
We recommend that the authors improve clarity on the choice of GPT-3.5 and GPT-4. Additionally, consider comparing the results shown in Table 1 with a baseline of simple pairwise variable prompts for LLMs or whole graph generation. It would also be beneficial to include more variables in each group of variables to enhance the analysis.