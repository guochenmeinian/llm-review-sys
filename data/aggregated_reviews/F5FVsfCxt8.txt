ID: F5FVsfCxt8
Title: Decision Tree for Locally Private Estimation with Public Data
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 6, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a scheme for training decision trees using a combination of public and private data under local differential privacy (LDP). The authors propose the locally differentially private decision tree (LPDT) algorithm, which utilizes public data to establish splitting criteria while private data is used for regressed values. The authors demonstrate that, under specific assumptions, the algorithm achieves a near-optimal convergence rate for decision tree regression under LDP constraints. Empirical evaluations on 15 real and 1 synthetic dataset indicate that LPDT outperforms existing methods, such as private histograms and deconvolution.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and presents substantial theoretical analysis.
- Extensive empirical evaluation across multiple datasets demonstrates the algorithm's superiority over existing methods.
- The exploration of different hyperparameter settings is clearly articulated.

Weaknesses:
- The validity of Assumption 3.2 is questionable, particularly regarding decision trees' ability to model discontinuous data.
- Sections 2 and 3 are dense with mathematical notation and complex phrasing, making them difficult to read.
- The exploration of $\epsilon$ values is limited to relatively high values, neglecting the implications of $\epsilon < 1$ for privacy.
- The algorithm's performance is not adequately assessed with categorical features present in the datasets.
- Limitations and broader impacts are relegated to the appendix instead of being included in the main text.
- Visualizations lack standard deviations or standard errors, and comparisons with global differentially private decision trees are absent.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Sections 2 and 3 by simplifying the mathematical notation and phrasing. Additionally, the authors should explore lower values of $\epsilon$ to assess the algorithm's performance under stronger privacy constraints. It would be beneficial to include discussions on the limitations of using public data, especially regarding data heterogeneity. The authors should also consider integrating the limitations and broader impacts into the main text rather than the appendix. Finally, providing visualizations that include standard deviations or standard errors would enhance the empirical results' clarity.