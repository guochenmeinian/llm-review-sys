ID: yO4cAfFjlp
Title: Theory of Mind for Multi-Agent Collaboration via Large Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper evaluates the capabilities of Large Language Models (LLMs) in multi-agent collaborations, specifically in a bomb defusal task requiring communication and teamwork. The authors propose a novel evaluation framework that assesses Theory of Mind (ToM) inference capabilities across three orders, demonstrating that LLM agents can explain their intentions and understand others' intentions. The study identifies systematic shortcomings in LLM-based agents and suggests prompt-engineering strategies to improve collaborative efficiency.

### Strengths and Weaknesses
Strengths:  
- The paper is well-written and presents interesting findings regarding LLM capabilities in collaborative tasks.  
- It highlights systematic failures of LLM-based agents and proposes future directions for improvement.  
- The evaluation of psychological settings related to ToM is compelling and contributes to the understanding of multi-agent interactions.  

Weaknesses:  
- There is a lack of clarity regarding the implementation and evaluation of ToM inference tasks.  
- The action space for agents is relatively small, limiting the generalizability of the findings.  
- The paper lacks sufficient background information on the baseline reinforcement learning method MAPPO and the CBS Planner.  

### Suggestions for Improvement
We recommend that the authors improve the clarity of the evaluation methods for ToM inference tasks and provide more detailed descriptions of the baseline models, including whether they were specifically trained for the task. Additionally, we suggest discussing how the work could be applied in larger-scale settings and adding case studies in the appendix to illustrate a complete game process. The authors should also consider expanding the action space and enhancing the human annotation details in Table 2. Finally, we advise including a bullet-point list to describe the RL environment and addressing the typos and formatting issues noted in the reviews.