ID: vtLNwa6uX0
Title: The Geometry of Neural Nets' Parameter Spaces Under Reparametrization
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 7, 8, 6, 6, -1, -1, -1, -1
Original Confidences: 4, 3, 1, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis of reparametrizations in neural networks through the lens of Riemannian geometry. The authors argue that many quantities, such as the Hessian determinant, trace, and eigenvalues, are not invariant under reparametrization unless the correct transformation rules are applied. They demonstrate that by incorporating Riemannian metrics, one can achieve invariance for these quantities, as well as for gradient descent and probability densities. The work also explores applications to infinite-width neural networks, the Laplace marginal likelihood, and preconditioned optimizers.

### Strengths and Weaknesses
Strengths:
- The perspective of Riemannian geometry provides clarity on reparametrizations.
- The paper is well-written and insightful, covering a broad range of implications for machine learning.
- It effectively discusses the utility of non-invariant reparametrization in various contexts.

Weaknesses:
- The discussion on flatness-based generalization measures lacks engagement with existing bounds for reparameterization-invariant measures.
- The mathematical formulation could be more precise, particularly regarding the use of global homeomorphisms and the concept of "equivariance under reparametrization," which is non-standard and potentially confusing.

### Suggestions for Improvement
We recommend that the authors improve the precision of their mathematical formulations, particularly by addressing the use of global homeomorphisms and incorporating local charts to include polar coordinates. Additionally, we suggest removing the concept of "equivariance under reparametrization" and instead referring to it as coordinate independence or covariance. It would also be beneficial to discuss the relationship between their work and existing literature, such as the studies by Weiler et al. (2021) and Cohen et al., to clarify how their findings relate to previous research. Furthermore, we encourage the authors to elaborate on the significance of sections 5.1 and 5.2 for better clarity and to address the utility of the sharpness measurement method discussed in section 5.3. Lastly, minor corrections regarding terminology and definitions should be made to enhance clarity for readers unfamiliar with the concepts.