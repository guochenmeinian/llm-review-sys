ID: DUHX779C5q
Title: Language Grounded Multi-agent Reinforcement Learning with Human-interpretable Communication
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 7, 5, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework for aligning multi-agent communication with natural language using a pipeline that leverages synthetic datasets generated by large language models (LLMs). The authors propose grounding agent communications on these datasets to facilitate human-interpretable messages and ad-hoc collaboration in multi-agent reinforcement learning (MARL) environments. The training process incorporates a cosine similarity loss to align communication messages with embeddings from LLMs, demonstrating improved performance in task-related metrics and BLEU scores compared to existing baselines. Additionally, the paper provides a comparative analysis of LangGround and LLM embodied agents, noting that while LLMs are recognized for their planning capabilities, they often produce infeasible action plans due to hallucinations and biases. The authors argue that MARL agents, including LangGround, are generally more efficient and cost-effective for task completion, requiring less effort for generalization across scenarios. They conducted a gating experiment indicating MARL's ability to learn selective communication through language grounding and clarified the experimental settings for zero-shot generalization results, emphasizing the limitations of their dataset.

### Strengths and Weaknesses
Strengths:
- The approach is flexible and applicable to various standard RL algorithms.
- The simplicity and effectiveness of the loss function enhance the training process.
- Empirical results indicate that the proposed method outperforms other state-of-the-art models in MARL communication tasks.
- The paper provides a clear comparison between LangGround and LLM embodied agents, highlighting efficiency and cost-effectiveness.
- The gating experiment offers valuable insights into the communication capabilities of MARL agents.
- The authors effectively clarify experimental settings, enhancing the understanding of their zero-shot generalization results.

Weaknesses:
- The clarity of Figure 1 and its caption is insufficient, requiring additional detail about the architecture.
- The experiments on zero-shot generalizability lack convincing evidence, particularly regarding the model's performance in larger environments.
- The ad-hoc teamwork experiment's methodology is unclear, including the control of LLM agents and the decoding of communication messages.
- The reliance on simple grid-world environments limits the exploration of the model's capabilities in more complex scenarios.
- The paper does not fully optimize LangGround for task rewards or utilize state-of-the-art MARL models.
- The dataset used for generalization experiments is limited, potentially affecting the robustness of the results.
- There is a lack of qualitative analysis regarding the impact of discarded messages on task performance.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Figure 1 by providing a more detailed caption that explains the architecture. Additionally, the authors should enhance the experimental evaluation of zero-shot generalizability by testing the model in larger environments, such as 10x10 grids, to assess its ability to handle unseen coordinates. Clarifying the methodology for the ad-hoc teamwork experiment, including how LLM agents are controlled and how communication messages are decoded, would also strengthen the paper. Furthermore, we recommend that the authors improve the optimization of LangGround for task rewards and consider integrating state-of-the-art MARL models as a backbone. Conducting a qualitative analysis of the discarded messages to assess their impact on task performance would be beneficial. Finally, we encourage the authors to provide a more comprehensive explanation of the dataset limitations and their implications for generalization performance.