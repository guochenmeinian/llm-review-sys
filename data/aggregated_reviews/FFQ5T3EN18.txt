ID: FFQ5T3EN18
Title: Rethinking Fine-tuning Through Geometric Perspective
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 6, 6, 6, 6, -1
Original Confidences: 3, 4, 3, 4, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to fine-tuning pre-trained neural networks through a geometric perspective, specifically using a geometry-guided fine-tuning method that models weight movement on a low-dimensional manifold via an ordinary differential equation (ODE). The authors introduce DELoRA, which adapts existing fine-tuning techniques by leveraging differential geometry tools, demonstrating competitive performance across multiple dense prediction tasks while achieving parameter efficiency compared to methods like LoRA.

### Strengths and Weaknesses
Strengths:  
1. The paper introduces an innovative geometric perspective on fine-tuning, providing insights through differential geometry.
2. The proposed method achieves parameter efficiency, using fewer trainable parameters than existing methods.
3. The presentation is clear and logically structured, making core ideas accessible.
4. Empirical results show competitive performance in a multi-task learning setting.

Weaknesses:  
1. The empirical demonstration of the geometry-guided fine-tuning is limited to its connection with LoRA, raising questions about its generality.
2. The claim of providing a "unifying theoretical foundation" is ambiguous, lacking clarity on its applicability to other fine-tuning techniques.
3. The evaluation is restricted to a single dataset (PASCAL-MTL), limiting the robustness of the findings.
4. Clarity on the specific implementation of multi-task learning and the role of the Riemannian metric is lacking.

### Suggestions for Improvement
We recommend that the authors improve the empirical validation by demonstrating their geometry-guided fine-tuning in more diverse settings beyond the connection to LoRA, including applications to other fine-tuning strategies or different model architectures. Additionally, the authors should clarify the unification aspect of their framework by elaborating on how other fine-tuning methods could be derived or enhanced using the proposed geometric approach. Finally, extending the empirical evaluation to include other datasets or tasks would strengthen the empirical foundation and support the broader applicability of the approach.