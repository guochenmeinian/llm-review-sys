ID: I6tRENM5Ya
Title: Revisiting Self-Supervised Heterogeneous Graph Learning from Spectral Clustering Perspective
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 5, 5, 6, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 3, 5, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel framework for Self-Supervised Heterogeneous Graph Learning (SHGL) that revisits existing methods from a spectral clustering perspective. The authors propose a rank-constrained spectral clustering method that refines the affinity matrix to mitigate noise, while integrating node-level and cluster-level consistency constraints to enhance the capture of invariant and clustering information. Theoretical analysis and experimental results demonstrate significant performance improvements in downstream tasks compared to existing approaches.

### Strengths and Weaknesses
Strengths:
1. The paper provides a theoretical investigation of previous SHGL methods through the lens of spectral clustering.
2. The proposed framework effectively captures cluster-level graph invariant representations.
3. Experimental results consistently show the effectiveness of the proposed methods across various datasets.

Weaknesses:
1. The paper lacks clarity in motivation and logical flow, particularly regarding the challenges presented in the introduction and the relationships among them.
2. Notations related to heterogeneous graphs are not clearly defined, leaving the objective of the problem ambiguous.
3. The rationale for bridging SHGL methods with graph-cut algorithms is unclear, as is the benefit of the rank constraint in mitigating noise.
4. The derivation details in Section 2.2 are convoluted, making it difficult to follow the contributions; technical derivations should be relegated to the appendix.
5. The logical connections between Sections 2.2 and 2.3 need clarification regarding the necessity of both low-rank and dual consistency constraints.
6. The choice of using two homogeneous graph datasets for evaluation is questionable given the paper's focus on heterogeneous graph learning.
7. Limitations and potential societal impacts of the work are not adequately discussed.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the introduction by elaborating on the challenges and their significance. The authors should clearly define all notations introduced in Section 2 and articulate the objective of the problem more explicitly. We suggest providing a clearer rationale for the connection between SHGL methods and graph-cut algorithms, as well as the benefits of the rank constraint. Additionally, the authors should simplify the presentation of derivations in Section 2.2 and consider moving technical details to the appendix. Clarifying the relationship between the low-rank and dual consistency constraints is essential, as is justifying the use of homogeneous datasets for evaluation. Finally, we encourage the authors to discuss the limitations and potential societal impacts of their work more thoroughly in the main text.