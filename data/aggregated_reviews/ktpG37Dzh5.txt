ID: ktpG37Dzh5
Title: BMRS: Bayesian Model Reduction for Structured Pruning
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 8, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Bayesian model reduction for structured pruning (BMRS), an efficient method that enhances Bayesian structured pruning with multiplicative noise. It combines Bayesian model reduction with a principled pruning strategy based on Bayesian model comparison. The authors propose two variants, threshold-free BMRS_N and BMRS_U, which allow for aggressive compression. Experimental evaluations across various datasets and neural network architectures demonstrate the effectiveness of both approaches.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant problem with societal implications, particularly regarding the resource demands of large language models.
- It is well-written, clearly introducing necessary concepts for readers less familiar with the field and focusing on a specific gap in the literature.
- An anonymous code repository with a clear structure and dependencies is provided.
- The experiments are well-designed, covering a range of datasets and architectures, with sufficient aggregation across random seeds and clear presentation of results.

Weaknesses:
- The BMRS method outperforms SNR for simple architectures but loses this advantage for complex architectures, where SNR achieves higher compression at similar accuracy. This critical analysis is lacking in the discussion.
- The computational overhead of multiplicative noise is mentioned but not evaluated in experiments; runtime information should be included in tables for comparison with baselines.
- The novelty of the BMRS method appears limited, as it seems to extend previous works without significant theoretical or empirical contributions.
- The experimental evaluation lacks comparisons to advanced pruning algorithms beyond L2, weakening the overall assessment.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Figure 1 by adding explicit descriptions and axis labels. Additionally, the authors should consider including Imagenet experiments in their evaluations, as this is a standard benchmark for pruning on vision datasets. It would also be beneficial to apply their approach to modern architectures with complex interconnections, such as ResNets, to explore the implications of their method further. Furthermore, we suggest that the authors analyze "how many filters/components are required to learn a given dataset" to provide deeper insights into their variational approach. Lastly, we encourage the authors to compare their method against a broader range of baselines, particularly advanced pruning algorithms, to strengthen their evaluation.