ID: xEhKwsqxMa
Title: Dissecting Chain-of-Thought: Compositionality through In-Context Filtering and Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 6, 7, 5, 5, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates how transformer-based models can compositionally learn complex functions, such as multi-layer perceptrons (MLPs), by decomposing them into simpler problems. It bridges the gap between Chain-of-Thought (CoT) in-context learning (ICL) methods and theoretical analyses of sample complexity. The authors provide both theoretical and empirical evidence that CoT significantly reduces the sample complexity of ICL, enhancing the model's ability to learn complex functions.

### Strengths and Weaknesses
Strengths:
- The paper presents a novel perspective on CoT in the context of learning MLPs, contributing valuable insights into the mechanics of CoT and ICL.
- The experimental results are convincing and supported by theoretical analyses, revealing interesting relationships between in-context samples and input dimensions.

Weaknesses:
- The paper is difficult to follow due to abstract theoretical sections, particularly in section 3.2, which lacks intuitive explanations.
- The organization of experimental sections is poor, with results scattered across multiple sections, disrupting the paper's flow.
- The transition between ICL and pertaining settings in section 4.3 is unclear, necessitating a clearer distinction and rationale.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the theoretical contributions, particularly by elaborating on how Theorem 1 is formulated in section 3.2. Additionally, we suggest reorganizing the experimental results to consolidate them and enhance readability, ensuring that similar information is not repeated across figures. It would be beneficial to clearly explain the differences between ICL and pertaining settings and the rationale for conducting experiments in both contexts. Furthermore, addressing the limitations regarding the generalization capabilities of CoT in ICL and providing a more robust discussion on the implications of the findings would strengthen the paper. Lastly, we advise correcting typographical errors and ensuring precise expressions throughout the manuscript.