ID: 6ZwJSk2kvU
Title: DreamMesh4D: Video-to-4D Generation with Sparse-Controlled Gaussian-Mesh Hybrid Representation
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 7, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 2, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DreamMesh4D, a framework for generating animated surfaces from input videos by transforming static images into 4D dynamic meshes. It employs a Gaussian-mesh hybrid representation and a geodesic-based deformation graph to refine object geometry and texture. The authors propose a new skinning algorithm that merges Linear Blend Skinning (LBS) and Dual Quaternion Skinning (DQS) for enhanced deformation. The framework integrates loss terms from existing methods, including reference view photometric loss and score distillation loss, to optimize the learning process.

### Strengths and Weaknesses
Strengths:
- The paper is well-contextualized and informative, making it accessible even to specialists outside the immediate field.
- The results demonstrate readiness for current Computer Graphics pipelines, utilizing meshes and skinning effectively.
- The mathematical modeling is structured around intuitive loss terms, contributing to a coherent presentation.
- The use of geodesic distance for the deformation graph enhances robustness over traditional methods.

Weaknesses:
- The paper lacks supplementary video material, which would clarify temporal coherence and enhance understanding of the 4D approach.
- There is a deficiency in references to 4D neural implicit surfaces in the Related Work section, which could provide additional context.
- The mathematical notation is overly complex, with excessive use of subscripts and superscripts, making it harder to read.
- The novelty of the work is limited, as it closely resembles existing methods, particularly in training strategies and loss function structures.

### Suggestions for Improvement
We recommend that the authors improve the supplementary material by including a video to demonstrate temporal coherence, which would help clarify the 4D approach. Additionally, we suggest incorporating references to relevant 4D neural implicit surface literature in the Related Work section to enhance contextualization. To improve readability, we advise simplifying the mathematical notation by reducing the use of subscripts and superscripts, opting for distinct symbols where necessary. Finally, we encourage the authors to provide a clearer distinction of their innovative contributions compared to existing methods, particularly regarding the Gaussian-mesh hybrid representation and the skinning algorithm.