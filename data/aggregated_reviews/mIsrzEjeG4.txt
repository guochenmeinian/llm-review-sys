ID: mIsrzEjeG4
Title: When Do Decompositions Help for Machine Reading?
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper addresses the utility of question decomposition in multi-step question answering (QA), asserting that decomposition is beneficial with limited training samples but counterproductive with ample data. The authors conduct experiments across three models and two datasets, demonstrating that decomposition may not enhance performance and can even hinder it in certain contexts.

### Strengths and Weaknesses
Strengths:
- The writing is clear and the paper is easy to understand.
- The conclusions provide valuable guidelines for future research in the community.
- Multiple models and datasets are utilized, reinforcing the generalizability of the findings.

Weaknesses:
- The experimental design, particularly in Figure 3, raises concerns regarding the comparison of zero-shot and no decomposition methods using fine-tuned models on SQuAD.
- The motivation behind focusing on machine reading questions over open-domain questions lacks clarity.
- The zero-shot setup and error analysis require further elaboration to clarify the results.

### Suggestions for Improvement
We recommend that the authors improve the experimental design by using pretrained language models instead of fine-tuned QA models for comparisons. Additionally, an analysis of the inductive bias introduced by question decomposition should be included to enhance the paper's conclusions. Clarifying the zero-shot setup and providing a detailed error analysis would also strengthen the findings. Furthermore, addressing the presentation of figures for better clarity and including relevant references on prompting strategies for zero-shot decomposition would be beneficial.