ID: w4AnTVxAO9
Title: Can Language Models Learn to Skip Steps?
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 5, 6, 4, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for training language models to skip steps in reasoning processes, enhancing efficiency without compromising accuracy. The authors introduce a controlled framework that iteratively refines models to generate shorter reasoning paths, demonstrating improved generalization capabilities in out-of-domain scenarios after fine-tuning on datasets that include both complete and skipped reasoning sequences. The empirical results are based on experiments conducted with LlaMa-7B across various tasks, including algebraic evaluations and multi-digit addition.

### Strengths and Weaknesses
Strengths:
- The empirical results are robust across three domains, showcasing the efficiency benefits of the proposed method.
- The paper is clearly written and well-organized, facilitating comprehension of the methodology and findings.
- The proposed skip reasoning pipeline is evaluated against a diverse set of tasks, providing insightful analyses of the training pipeline's effects.

Weaknesses:
- The study considers only one backbone model; experiments across different model families and sizes are necessary to demonstrate the generalization ability of the proposed methods.
- The out-of-domain (OOD) test is essentially a harder in-domain test, raising questions about the method's generalization across different domains.
- The tasks used in experiments are somewhat artificial, lacking representation of real-world reasoning tasks, which limits the empirical validation of the proposed metric.
- The methodology lacks clarity on how full-step reasoning data is created, and the filtering process for correct answers during training raises concerns about the model's ability to generate accurate shorter answers independently.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their findings by conducting experiments across multiple model families and sizes. Additionally, consider using more realistic reasoning tasks, such as GSM8K or MATH, to strengthen the empirical validation of the proposed method. Clarifying the process of creating full-step reasoning data and ensuring the quality of auto-generated datasets through human evaluation would enhance the paper's rigor. Finally, addressing the discrepancies between Sections 5.1 and 5.2 regarding performance with fewer steps would provide clearer insights into the method's effectiveness.