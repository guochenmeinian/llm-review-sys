ID: IT9mWLYNpQ
Title: Implicit Bias of Gradient Descent for Logistic Regression at the Edge of Stability
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 8, 7, 7, 5, 6, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 3, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis of gradient descent (GD) for logistic regression on linearly separable datasets, particularly focusing on large step sizes within the edge of stability (EoS) regime. The authors demonstrate that GD converges for any positive constant step size, even those leading to non-decreasing loss curves, and that the limit direction maximizes the margin. They also provide counterexamples for exponential loss, illustrating conditions under which convergence fails, thereby highlighting the practical preference for logistic loss.

### Strengths and Weaknesses
Strengths:
- The study addresses a significant topic (EoS) in a well-established area (logistic regression), yielding strong results regarding convergence for any step size.
- The distinction between logistic and exponential losses offers valuable insights into their practical implications.
- The paper is well-structured and presents a novel proof technique that accommodates large step sizes, enhancing clarity and understanding.

Weaknesses:
- While the results are robust, the analysis is limited to logistic regression on linearly separable data, raising questions about applicability to more complex models.
- The implicit bias results do not provide insights into the dynamics at the edge of stability, which could be elaborated upon by the authors.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the implications of their findings regarding implicit bias at the edge of stability, particularly how it relates to generalization. Additionally, including numerical examples of convergence with extremely large step sizes would enhance understanding of the loss curve behavior. The authors should also consider discussing recent literature on the EoS phenomenon in related contexts, such as the works by Even et al. (2022) and Andriushchenko et al. (2022), to provide a broader context for their findings.