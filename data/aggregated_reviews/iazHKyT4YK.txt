ID: iazHKyT4YK
Title: Optimizing Markov Chain Monte Carlo Convergence with Normalizing Flows and Gibbs Sampling
Conference: NeurIPS
Year: 2023
Number of Reviews: 2
Original Ratings: 6, -1
Original Confidences: 4, 5

Aggregated Review:
### Key Points
This paper presents a method for sampling unnormalized densities using Gibbs MCMC in the latent space of a pretrained normalizing flow. The authors conduct experiments on a single 2D toy Boltzmann distribution, which raises questions about the generalizability of their results.

### Strengths and Weaknesses
Strengths:
1. The paper addresses an important problem in sampling unnormalized densities, relevant to many scientific applications.
2. The structure and writing of the paper are commendable, making it a pleasant read.

Weaknesses:
1. The novelty is limited, as MCMC in the latent space of normalizing flows has been extensively explored, with the primary contribution appearing to be the choice of Gibbs updates, which is more of a hyperparameter decision than a technical insight.
2. The experiments are conducted on only a single toy system, questioning the generalizability of the findings.

### Suggestions for Improvement
We recommend that the authors improve the novelty of the work by discussing how GflowMC compares against standard flow-based sampling approaches using Reverse KL for approximating multimodal distributions, particularly in relation to Ref [1]. Additionally, we suggest reorganizing the references in the order of appearance, as the current alphabetical arrangement is unusual.