ID: 99y2EfLe3B
Title: Separate and Reconstruct: Asymmetric Encoder-Decoder for Speech Separation
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 5, 6, 6, 7, -1, -1
Original Confidences: 3, 5, 4, 5, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel transformer-based architecture, SepReformer, for speech separation utilizing a Siamese decoder network that operates on separated speech signals in the encoded space. The authors introduce an asymmetric encoder-decoder framework that analyzes features based on the number of speakers, employing global and local Transformer blocks for efficient long-sequence processing. The proposed model achieves state-of-the-art performance on benchmark datasets while demonstrating computational efficiency.

### Strengths and Weaknesses
Strengths:
1. The paper demonstrates state-of-the-art performance on various datasets, achieving up to 25dB on the WSJ 2 mix.
2. The architecture is computationally efficient compared to baseline methods, making it suitable for real-world applications.
3. The supplementary materials include high-fidelity wav files and thorough ablation studies, enhancing reproducibility and understanding of component contributions.

Weaknesses:
1. The presentation quality is lacking, particularly in the abstract, which fails to adequately set up the problem and provide an overview.
2. The experiments primarily focus on two-speaker separation, raising concerns about generalizability to scenarios with more than two speakers.
3. The evaluation metrics are limited to SI-SNRi, with no consideration of other important metrics like PESQ or STOI, which could better represent perceptual quality.

### Suggestions for Improvement
We recommend that the authors improve the presentation quality by providing a clearer overview and context in the abstract. Additionally, we suggest conducting experiments on scenarios involving more than two speakers to assess the method's generalizability. It would also be beneficial to include evaluations using other metrics, such as PESQ or STOI, to provide a more comprehensive assessment of the model's performance. Finally, we encourage the authors to evaluate the model on real data, such as the Chime-6 dataset or LibriCSS, to demonstrate its effectiveness in practical applications.