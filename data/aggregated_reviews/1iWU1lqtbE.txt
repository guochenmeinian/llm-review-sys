ID: 1iWU1lqtbE
Title: An Active Learning Performance Model for Parallel Bayesian Calibration of Expensive Simulations
Conference: NeurIPS
Year: 2024
Number of Reviews: 2
Original Ratings: 6, 5
Original Confidences: 3, 3

Aggregated Review:
### Key Points
This paper presents a performance model for active learning in the context of parallel Bayesian calibration of expensive simulations. It addresses computational challenges in optimizing calibration efficiency using Gaussian Process (GP) emulators. The authors introduce an acquisition function and analyze trade-offs between batch size, parallelism, and acquisition time, demonstrating their effects on Bayesian calibration performance.

### Strengths and Weaknesses
Strengths:
- The work addresses a significant challenge in simulation-based learning, emphasizing the need for efficient calibration techniques in high-performance computing contexts.
- A well-structured set of experiments, including variations in batch sizes and worker configurations, effectively illustrates the impact of computational factors on calibration performance, validated through synthetic functions and performance metrics.
- The paper is logically organized, facilitating reader comprehension from the introduction of the calibration problem to the presentation of the performance model and experiments.

Weaknesses:
- The empirical findings, while compelling, lack deeper theoretical justifications for observed phenomena, particularly regarding the impact of batch size on active learning efficiency.
- The reliance on the Himmelblau function for experimental evaluation does not fully capture the complexity of real-world calibration tasks; incorporating results from real-world simulations would enhance generalizability.
- The focus on the EIVAR criterion for acquisition limits the analysis; including alternative functions like expected improvement or Thompson sampling could provide a more comprehensive comparison.

### Suggestions for Improvement
We recommend that the authors improve the theoretical exploration of the observed phenomena to strengthen the contribution. Incorporating results from real-world simulations or more complex systems would enhance the generalizability of the findings. Additionally, including a comparison with alternative acquisition functions could reveal potential advantages or limitations of the selected criterion. Finally, a stronger conclusion that ties together empirical findings and offers concrete recommendations for practitioners would be beneficial.