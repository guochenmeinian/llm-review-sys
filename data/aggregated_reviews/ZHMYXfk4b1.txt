ID: ZHMYXfk4b1
Title: Prompt-based Node Feature Extractor for Few-shot Learning on Text-Attributed Graph
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 4, 4, 3, 5, 4, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 2, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents G-Prompt, a novel framework designed for representation learning on text-attributed graphs (TAGs), focusing on few-shot node classification. The authors propose a method that integrates graph topology and downstream task information by enhancing pretrained language models (PLMs) with graph awareness through a graph adapter. This adapter, combined with task-specific prompts, generates graph-aware node representations, outperforming existing methods in few-shot learning scenarios.

### Strengths and Weaknesses
Strengths:
- Clear motivation for the method.
- Well-written summary of existing work, including taxonomy and pros and cons.
- Strong performance in few-shot node classification.
- Valuable insights into the utility of graph information and prompts for both language models and graph neural networks.

Weaknesses:
- Some tables and figures lack clarity; for instance, Figure 1 and Table 2 require more detailed captions for better comprehension.
- Background on few-shot learning is insufficient, particularly regarding its adaptation from supervised learning methods like GIANT.
- Claims of efficiency are not experimentally validated; comparisons with other methods regarding training parameters and resource usage are necessary.
- The framework's compatibility with large language models (LLMs) is limited, as it requires access to LLMs' latent embeddings or logits, which are not available in models like GPT-3.5 and GPT-4.

### Suggestions for Improvement
We recommend that the authors improve the clarity of tables and figures by providing more comprehensive captions. Additionally, the authors should include a more thorough background on few-shot learning to assist readers unfamiliar with the topic and explicitly discuss how existing supervised methods can be adapted for few-shot scenarios. To substantiate claims of efficiency, we suggest providing empirical comparisons regarding training parameters, memory usage, and training speed. Furthermore, addressing the limitations of compatibility with LLMs and discussing potential adaptations for other tasks would enhance the paper's depth. Finally, we encourage the authors to proofread the manuscript to correct typographical errors and improve overall readability.