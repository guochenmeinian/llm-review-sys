ID: L8Q21Qrjmd
Title: Pessimistic Backward Policy for GFlowNets
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 6, 5, 5, 3, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a solution to the under-exploitation problem in Generative Flow Networks (GFlowNets) through the Pessimistic Backward Policy (PBP-GFN). The authors argue that traditional GFlowNets fail to adequately explore high-reward objects due to limited observation of backward trajectories. By adjusting backward flow probabilities, the proposed method enhances exploration and exploitation, demonstrating superior performance across various benchmarks, including mode discovery and distribution fitting.

### Strengths and Weaknesses
Strengths:
- The paper effectively identifies a significant issue in GFlowNets related to under-exploitation due to unobserved backward trajectories.
- The methodology is clearly explained, including the training process and loss function for the backward policy.
- Extensive experiments validate the efficacy of PBP-GFN across multiple environments.

Weaknesses:
- The introduction of PBP-GFN adds complexity to the training process, potentially making it computationally expensive and difficult to tune. The authors should address this concern.
- The experiments do not compare PBP-GFN with recent GFlowNets methods that claim improvements over baselines, raising questions about its relative performance.
- There is a lack of comprehensive theoretical analysis regarding the impact of the auxiliary objective on the original GFN training objective.
- The paper does not sufficiently evaluate the potential bias introduced by the pessimistic training scheme, which could affect exploration and sample diversity.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the computational complexity and tuning challenges associated with PBP-GFN. Additionally, including comparisons with newer GFlowNets methods, such as those referenced in the reviews, would strengthen the paper. We suggest providing a more robust theoretical analysis of the auxiliary objective's effects on the original training objectives. Furthermore, a deeper investigation into the potential biases introduced by the pessimistic training scheme and its impact on exploration and diversity would enhance the paper's contributions.