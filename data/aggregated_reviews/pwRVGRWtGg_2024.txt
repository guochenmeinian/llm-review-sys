ID: pwRVGRWtGg
Title: Apathetic or Empathetic? Evaluating LLMs' Emotional Alignments with Humans
Conference: NeurIPS
Year: 2024
Number of Reviews: 19
Original Ratings: 5, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates the empathy ability of large language models (LLMs) by evaluating their responses to 428 distinct emotional situations. The authors propose a dataset based on psychological theories and compare LLM responses with human benchmarks, revealing that LLMs exhibit weak emotional alignment with humans. The evaluation involves five LLMs, including GPT and LLaMA models, and utilizes a self-report questionnaire format for assessment.

### Strengths and Weaknesses
Strengths:
- The dataset is extensive, covering a wide range of emotional situations and is grounded in relevant psychological theories.
- The paper is well-written, with comprehensive analyses and discussions that are easy to follow.
- The findings, particularly regarding LLMs' emotional responses, are intriguing and may have broader implications.

Weaknesses:
- The application of self-report questionnaires lacks novelty, as it generalizes previous works and may limit technical contributions.
- Human evaluations of LLM-generated texts are insufficient; subjective ratings from human participants are crucial for a complete understanding of LLM behaviors.
- The emotional responses evaluated appear limited, with no evidence of generalization beyond the specific tasks proposed in the paper.

### Suggestions for Improvement
We recommend that the authors improve the paper by:
- Including details on hyperparameters used for decoding, such as temperature, top-K, or top-P values.
- Investigating prompt sensitivity to determine if LLM responses vary with different prompts.
- Providing a more in-depth analysis of factors influencing LLM responses, including potential reasons for observed behaviors and strategies to enhance LLM empathy.
- Differentiating their work from existing studies on emotional alignment to clarify its unique contributions.
- Expanding evaluations to include additional LLM families and domain-specific models to strengthen the findings.