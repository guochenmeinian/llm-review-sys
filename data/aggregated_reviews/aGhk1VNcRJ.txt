ID: aGhk1VNcRJ
Title: Assessing and Post-Processing Black Box Large Language Models for Knowledge Editing
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework called "postEdit" for knowledge editing in black-box LLMs, focusing on privacy protection and style retention. The authors propose a retrieval mechanism and a specialized post-editor to ensure effective editing while maintaining the coherence of outputs. The experimental results indicate that postEdit significantly outperforms existing methods in both editing efficacy and stylistic consistency.

### Strengths and Weaknesses
Strengths:
- The experimental section is comprehensive, effectively illustrating the proposed methods and their advantages.
- The introduction of retention into the evaluation framework is innovative, assessing both accuracy of edits and stylistic coherence.
- The paper is well-motivated and clearly written, making it accessible to readers.

Weaknesses:
- The model design is relatively simple, relying on a two-part structure that may limit its complexity and adaptability.
- The experimental design lacks comprehensive consideration, particularly in baseline comparisons that do not optimize for retention.
- Evaluation is limited to only two benchmarks, which may not fully validate the model's effectiveness.

### Suggestions for Improvement
We recommend that the authors improve the model design by integrating existing structured output generation approaches for enhanced adaptability. Additionally, consider using a baseline enhanced with prompt-based retention methods for a more equitable comparison in experiments. Expanding the evaluation to include more benchmarks would provide a deeper understanding of the model's capabilities. Furthermore, addressing the handling of logical errors and ambiguous edits within the postEdit framework could clarify its limitations and potential improvements.