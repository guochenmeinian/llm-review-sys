ID: E8b4yOLGZ5
Title: Meta-Learning Universal Priors Using Non-Injective Change of Variables
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 5, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to meta-learning by utilizing non-injective normalizing flows to model the prior distribution of parameters, addressing the limitations of predefined Gaussian priors. The authors propose a Bayesian model-agnostic meta-learning framework, demonstrating that their method outperforms existing techniques in few-shot classification tasks on mini-ImageNet and CUB datasets. The theoretical analysis supports the use of Sylvester normalizing flows, although these flows are not the primary contribution of the paper.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and clear, making the complex topic accessible.
2. The problem of learning a prior in meta-learning is highly relevant.
3. The theoretical analysis provides a solid motivation for using Sylvester normalizing flows, which appears sound.
4. Experimental results convincingly demonstrate the proposed method's superiority over baseline approaches.
5. Code availability during submission reflects a commitment to openness.

Weaknesses:
1. The novelty of the proposed solution is questionable, as it lacks clear differentiation from existing probabilistic formulations in meta-learning.
2. Important experimental baselines are missing, which undermines the quality of the comparisons.
3. The non-injective Sylvester flows section is confusing, lacking clarity on the conditions for invertibility.
4. The paper does not adequately discuss the number of meta-parameters used in experiments, raising questions about the source of improvements.
5. The benchmarks employed are outdated, limiting the relevance of the findings in the current landscape of meta-learning.

### Suggestions for Improvement
We recommend that the authors improve the novelty section by clearly articulating how their approach differs from existing methods and emphasizing its unique contributions. Additionally, we suggest including more comprehensive experimental baselines to enhance the quality of comparisons. Clarifying the non-injective Sylvester flows and their invertibility conditions would also strengthen the paper. Furthermore, we encourage the authors to conduct experiments on more contemporary benchmarks, such as the meta-dataset, to validate their claims of scalability and expressiveness. Lastly, a thorough discussion on the trade-off between computational complexity and performance should be included to address the limitations of the proposed solution.