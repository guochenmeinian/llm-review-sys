ID: tKuLgnDWWN
Title: SILENCE: Protecting privacy in offloaded speech understanding on resource-constrained devices
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 5, 5, 6, 5, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 2, 4, 2, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for enhancing privacy in automatic speech recognition (ASR) and spoken language understanding (SLU) systems by selectively obscuring short-term dependencies in speech signals. The authors propose a learnable mask generator that disrupts local dependencies, allowing SLU models to maintain high accuracy while protecting user privacy. The implementation on low-resource devices demonstrates significant improvements in computational efficiency and memory usage compared to existing solutions.

### Strengths and Weaknesses
Strengths:
- The proposed method significantly outperforms existing baselines in computational efficiency and memory usage.
- The evaluation includes both black-box and white-box adversaries, providing a comprehensive assessment of the method's robustness.
- The paper is well-organized and presents clear explanations of key concepts and methodologies.

Weaknesses:
- The focus on passive adversaries limits the exploration of threats from active adversaries who may reconstruct raw signals from masked outputs.
- The assumption that SLU tasks primarily rely on long-term dependencies may not hold for all scenarios, particularly for tasks requiring local utterances.
- The paper lacks detailed analysis on how the granularity of the mask affects privacy protection and SLU performance.
- Experiments are primarily conducted on a single dataset, which may not adequately demonstrate the method's generalizability.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the potential impact of active adversaries on ASR accuracy and provide visualizations of the masks generated by the trained mask generator to verify their effectiveness. Additionally, we suggest conducting experiments on a broader range of datasets to enhance the generalizability of the findings. Finally, providing a more detailed analysis of how mask granularity affects both privacy and SLU performance would strengthen the paper's contributions.