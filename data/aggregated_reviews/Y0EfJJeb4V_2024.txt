ID: Y0EfJJeb4V
Title: Goal Reduction with Loop-Removal Accelerates RL and Models Human Brain Activity in Goal-Directed Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 9, 4, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 2, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method called goal-reducer, which identifies subgoals from past experiences without prior knowledge by eliminating loops in trajectories. The authors define a filtration radius to extend the concept of loops in continuous cases. Through experiments, the authors demonstrate that goal-reducer can enhance reinforcement learning (RL) by providing subgoals, operate independently to find immediate next subgoals, and correlate with human brain activity in subgoal-related tasks. The method is applicable across various RL frameworks, showing effectiveness in established benchmarks.

### Strengths and Weaknesses
Strengths:
1. The writing is clear and effectively communicates contributions relative to previous methods.
2. The paper addresses a significant problem in both computer science and neuroscience, with strong motivation in the introduction.
3. The proposed method is intuitive and effective, theoretically sound and empirically validated through experiments, eliminating the need for prior knowledge.
4. The experiments robustly support the claims made in the paper.

Weaknesses:
1. The applicability of goal-reducer beyond goal-reaching behavior is uncertain, particularly in tasks where state distinctions are critical, such as the fMRI study task.
2. The motivation for Equations 6-7 is unclear; specifically, why should the loss only be present when entropy decreases with the introduction of a subgoal?
3. The mention of Indiana University IRB raises concerns about anonymity requirements during the review stage.
4. The code was not easily accessible for review, and the authors did not provide sufficient information on data sharing practices.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the applicability of goal-reducer in more complex tasks beyond navigation, addressing potential issues with state distinctions. Additionally, we suggest providing a clearer justification for the loss function in Equations 6-7 to avoid encouraging uncertainty in policy actions. The authors should ensure that the code is readily accessible and consider using established open data sharing platforms to enhance reproducibility. Lastly, we encourage the authors to discuss the potential negative societal impacts of their work in the rebuttal.