ID: 6muz29kMQu
Title: Multilingual Holistic Bias: Extending Descriptors and Patterns to Unveil Demographic Biases in Languages at Scale
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents MultilingualHolisticBias, a multilingual extension of the HolisticBias dataset, which covers 50 languages and aims to measure demographic bias in multilingual machine translation systems and sentence encoders. The dataset includes 20k sentences across three demographic axes, extending the English-only bias measurement dataset. The authors conduct a comprehensive analysis using this dataset, revealing that multilingual translation models, particularly NLLB, tend to output masculine translations, and that masculine translations are closer to English neutral sentences in the embedding space.

### Strengths and Weaknesses
Strengths:
- The introduction of a multilingual dataset covering 50 languages is valuable for measuring demographic biases.
- The paper provides a practical framework for quantifying gender biases in machine translation, supported by interesting analyses.

Weaknesses:
- The limited number of sentences per language (325 to 650) may affect the robustness of the results.
- Some parts of the paper are hard to follow, particularly regarding the presentation of results and the ordering of figures.
- The storyline lacks precision in discussing gender biases across languages and does not sufficiently position the work within existing literature on biases in machine translation.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the results presented in Figure 4, particularly regarding the gendered references in English. Additionally, we suggest reordering the figures to align better with the overall narrative of the paper. To enhance the discussion, we encourage the authors to better position their work in relation to existing studies on gender bias in machine translation, such as "Gender Bias in Machine Translation" by Savoldi et al. (2021). Finally, we advise addressing the missing references on biases in machine translation to strengthen the paper's foundation.