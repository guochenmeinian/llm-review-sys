ID: D8oHQ2qSTj
Title: Fairness-guided Few-shot Prompting for Large Language Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 5, 5, 6, 6, 4, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to constructing prompts for improving in-context learning (ICL) in large language models (LLMs) by introducing a content-agnostic fairness metric based on predictive bias. The authors propose two search strategies, T-fair-Prompting and G-fair-Prompting, to identify optimal prompts that enhance predictive quality. The effectiveness of these methods is empirically demonstrated across various downstream tasks using state-of-the-art LLMs, showing that higher predictive bias correlates with poorer performance.

### Strengths and Weaknesses
Strengths:
- The paper effectively highlights the significance of prompt quality and introduces a novel metric for evaluating prompt performance based on predictive bias.
- The proposed search strategies, T-fair-Prompting and G-fair-Prompting, are well-validated through extensive experiments, demonstrating competitive performance against state-of-the-art methods.
- The writing is clear, and the methodology is well-articulated, facilitating understanding and reproducibility.

Weaknesses:
- The computational complexity of G-fair-Prompting may hinder scalability, particularly with larger datasets or models.
- The generalizability of the proposed methods is limited, as they primarily focus on text classification tasks without exploring other potential applications.
- The methodological novelty is questioned, as the predictive bias metric is adapted from existing literature without sufficient exploration of its implications or alternative approaches.

### Suggestions for Improvement
We recommend that the authors improve the scalability discussion by addressing the computational costs associated with larger datasets. Additionally, extending the evaluation of their methods to include various downstream tasks beyond text classification would enhance generalizability. We also suggest conducting sensitivity analyses on hyperparameters, such as the number of demonstrations (k) and fairness thresholds, to better understand their impact on performance. Finally, clarifying the use of the term "fairness" in the context of their methods and providing a more nuanced discussion of its implications would strengthen the paper.