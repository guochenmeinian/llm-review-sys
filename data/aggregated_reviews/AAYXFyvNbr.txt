ID: AAYXFyvNbr
Title: Tokenization Consistency Matters for Generative Models on Extractive NLP Tasks
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an important examination of tokenization inconsistency in generative models for extractive tasks, particularly in extractive question answering (QA). The authors identify how this inconsistency can degrade model performance and lead to hallucinations. They propose a straightforward method to ensure consistent tokenization, demonstrating its effectiveness through experiments on multiple QA datasets, resulting in improved performance metrics, faster convergence, and reduced out-of-context answers.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant yet often overlooked issue in generative model training, enhancing understanding of tokenization's impact.
- The proposed method is clear and easy to understand, with consistent metric improvements observed across various datasets.
- The results provide strong evidence supporting the claims, showcasing enhancements in both in-domain and out-of-domain settings.

Weaknesses:
- The focus on extractive QA may limit the generalizability of the findings to other extractive tasks, and the evaluation across only eight QA datasets may not capture the full diversity of the issue.
- There is insufficient evidence demonstrating the widespread nature of tokenization inconsistencies across different models, and the proposed method appears more as a workaround rather than a fundamental solution.
- The conclusions are primarily based on the BPE tokenizer, raising questions about the applicability of the approach to other tokenization methods.

### Suggestions for Improvement
We recommend that the authors expand the scope of their research to include a broader range of extractive tasks and datasets to enhance the generalizability of their findings. Additionally, a direct comparison with existing methods addressing tokenization inconsistency would provide a more comprehensive evaluation. We also suggest conducting an extensive error analysis to identify scenarios where the proposed method is most and least effective. Finally, exploring the applicability of their approach to other tokenizers, such as sentencepiece, could further validate their findings and benefit the community.