ID: PBwotNgvp3
Title: Zero-shot Topical Text Classification with LLMs - an Experimental Study
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a systematic study of the performance of large language models (LLMs) on zero-shot topical text classification (TTC) using a benchmark called TTC23, which includes 23 diverse datasets. The authors compare various approaches to zero-shot TTC, including similarity-based, QA-based, NLI-based, and instruction-tuned models, and propose fine-tuning on existing labeled TTC datasets. The findings indicate that fine-tuning significantly enhances zero-shot performance, with Flan-T5-XXL FT achieving the best results. The authors conclude that LLMs demonstrate strong zero-shot capabilities, and fine-tuning on diverse TTC data can improve performance on unseen categories.

### Strengths and Weaknesses
Strengths:
- The paper introduces the first comprehensive benchmark (TTC23) for evaluating zero-shot topical text classification, facilitating future research.
- It provides extensive empirical comparisons of various methods, demonstrating that fine-tuning large LMs like Flan-T5 on TTC data significantly improves performance.
- The organization and clarity of the paper are commendable, with effective use of tables and graphs to enhance comprehension.

Weaknesses:
- The paper does not evaluate recent powerful LLMs like ChatGPT, limiting the generality of its conclusions.
- The largest model tested contains only 13B parameters, which may not exhibit significant "emergence" capabilities.
- The data, code, and fine-tuned models have not been made public, hindering verification and reproducibility of results.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by including powerful recent LLMs such as ChatGPT to enhance the generality of their findings. Additionally, we suggest providing more details on hyperparameters, particularly the decoding strategy, as this could impact model performance and inference runtime. An exploration of the models' strengths and weaknesses at the dataset level, including metrics like standard deviation, would also be beneficial. Lastly, we encourage the authors to clarify their rationale for not comparing against ICL models and to discuss the effects of pre-training data on model performance more thoroughly.