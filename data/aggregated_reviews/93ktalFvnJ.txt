ID: 93ktalFvnJ
Title: Boosting Alignment for Post-Unlearning Text-to-Image Generative Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 5, 6, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to model unlearning in text-to-image generative models, framing it as a constraint optimization problem. The authors introduce a new loss function that combines remaining loss and forgetting loss, alongside the concept of "restricted gradient." They employ an "LLM in the loop" strategy to enhance data diversity during the unlearning process. The work aims to mitigate the generation of harmful or undesired content by balancing unlearning objectives with text-image alignment. Additionally, the authors define Unlearning Accuracy (UA) as 1 minus the accuracy of the unlearned model on the forget set, indicating that higher UA values reflect better unlearning performance. The evaluation focuses on the effectiveness of forgetting the target class while maintaining model utility for retained classes, using Remaining Accuracy (RA) to assess the generation of images from these classes. The authors acknowledge the need for clearer explanations regarding the construction of the forget set and the generation of retain sets, which they plan to address in the revised version.

### Strengths and Weaknesses
Strengths:
- The paper provides a unique perspective on gradient surgery as constraint optimization.
- The "LLM in the loop" approach is innovative and engaging.
- The empirical investigation is thorough, with a balanced presentation of experiments and theoretical analysis.
- The authors provide a clear definition of UA and RA, enhancing understanding of their evaluation metrics.
- The approach to generating diverse retain prompts is well-articulated, emphasizing the importance of independence from the target concept.
- Empirical evidence supports claims of monotonic improvement in unlearning tasks, demonstrating the effectiveness of their method.

Weaknesses:
- The justification for the proposed loss function is insufficient, particularly regarding the forgetting loss, which may lead to random predictions that compromise image fidelity.
- The method's effectiveness in achieving diversity during the unlearning process is unclear, especially for tasks involving a wide range of concepts.
- The primary technical contribution, "restricted gradient," lacks experimental validation.
- Initial details regarding the construction of the forget set and retain sets were insufficiently presented, leading to potential confusion.
- The relationship between the CLIP alignment score and human judgment may not be fully aligned, raising questions about the robustness of the evaluation metrics.
- The paper does not adequately define the unlearning objective or its connection to privacy and copyright issues, leading to ambiguity in its formulation.

### Suggestions for Improvement
We recommend that the authors improve the justification for the proposed loss function, particularly the role of the forgetting loss, to clarify its impact on image fidelity. Additionally, the authors should provide a more detailed explanation of how diversity is achieved in the unlearning process, especially for complex concepts. We suggest including comparisons with retrain-from-scratch methods to establish a clearer performance benchmark. Furthermore, the authors should articulate a unified problem formulation for unlearning, explicitly linking it to the applications of privacy and copyright concerns. We also recommend improving the clarity of the UA metric definition, emphasizing that it is calculated as 1 minus the accuracy on the forget set. The authors should provide more detailed explanations of the forget set construction and the generation of retain sets in the revised paper. It would be beneficial to include a discussion on the relationship between CLIP alignment scores and human judgment to address potential gaps. Finally, incorporating the results of additional experiments with different pre-trained models will strengthen the generalizability of their findings.