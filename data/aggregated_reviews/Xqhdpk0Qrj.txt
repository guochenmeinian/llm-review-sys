ID: Xqhdpk0Qrj
Title: GLEN: Generative Retrieval via Lexical Index Learning
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel generative retrieval method that employs tokens as document ID representations, termed GLEN. The approach aims to bridge the knowledge of pre-trained language models (PLMs) with identifier generation, demonstrating effectiveness in experimental results. The authors claim that GLEN achieves top performance, particularly in zero-shot and cross-domain retrieval, while offering a fresh perspective compared to traditional numeric identifiers.

### Strengths and Weaknesses
Strengths:
- The new ID generation method is innovative and provides valuable insights for future research.
- The writing is clear and accessible, with extensive experimental validation.
- The methodology is well-structured, and the results show promise, especially in zero-shot and cross-domain contexts.

Weaknesses:
- The expressiveness of the lexical identifiers is questionable, as they may not fully capture the information within documents.
- Experimental results do not adequately compare against strong baselines like GENRET, raising concerns about the validity of the findings.
- The analysis of the differences between GLEN and GENRET is insufficient, particularly regarding performance discrepancies across datasets.

### Suggestions for Improvement
We recommend that the authors improve the analysis comparing GLEN with GENRET to clarify the advantages of using lexical identifiers. It would be beneficial to emphasize the implications of dynamic learning and its potential side effects, such as the need for re-indexing documents. Additionally, we suggest including significance tests for the results presented in Table 6 to better assess the importance of each component. Clarifying the terminology around "identifier" throughout the paper and providing a consistent naming convention for notations would enhance readability. Lastly, incorporating comparisons with state-of-the-art models like ColBERT would strengthen the paper's contributions.