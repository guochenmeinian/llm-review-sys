ID: YokfK5VOoz
Title: Copyright Violations and Large Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an empirical analysis of the extent to which large language models (LLMs) reproduce copyrighted text material during their training. The authors analyze LLMs from six families (OPT, Pythia, Falcon, LLaMA 1, GPT3.5, Claude) and test their ability to reproduce text from copyrighted sources, including textbooks and LeetCode problems. They measure sequence overlap using metrics like longest common subsequence (LCS) and Levenshtein distance, finding that larger LLMs tend to reproduce copyrighted material verbatim, particularly closed-source models. The paper concludes with implications for copyright law and recommendations for compliance.

### Strengths and Weaknesses
Strengths:
- The paper addresses a crucial and practical issue regarding the legal implications of LLMs, potentially informing future policy.
- It analyzes several state-of-the-art LLMs, providing valuable insights for researchers and practitioners in mitigating copyright infringements.

Weaknesses:
- The findings may not significantly differ from previous work on memorization, particularly that of Carlini et al., 2023, which utilized similar methods.
- There is ambiguity regarding the definition of copyright violation, particularly concerning the interpretation of the 50-word limit mentioned in the abstract.
- The study may reduce to a focus on long-text memorization, which has been previously established, limiting its novelty.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their definition of copyright violation and provide a more nuanced discussion of legal considerations, potentially involving legal experts. Additionally, we suggest including error bars in the plots to depict variability in the LCS results. The authors should also clarify the metrics used for measuring copyright infringement and consider exploring broader research questions, such as the types of material more likely to be quoted verbatim and potential modifications to LLMs to avoid copyright issues.