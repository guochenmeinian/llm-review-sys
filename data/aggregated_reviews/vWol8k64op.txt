ID: vWol8k64op
Title: A Dataset for Investigating the Impact of Context for Offensive Language Detection in Tweets
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the development of a Turkish dataset consisting of over 20,000 tweet-reply pairs annotated for offensive language detection. The dataset is notable for its manual curation and contextual enrichment, as replies include the original tweets. The authors also compare the performance of various machine learning models with and without contextual information, revealing that context had limited impact on model performance.

### Strengths and Weaknesses
Strengths:
- The dataset is a valuable resource for a low-resource language, providing a large-scale annotated collection.
- The contextual enrichment of replies enhances the dataset's potential for understanding offensive language in conversations.
- The comparative analysis of machine learning models establishes a benchmark for future research.

Weaknesses:
- The dataset's positive class is less than 5%, limiting its usability and raising concerns about the representativeness of the test set.
- Some decisions in dataset construction, such as the narrow definition of offensive language, may restrict its applicability and introduce confusion for machine learning models.
- The annotation process lacks independence, as the authors were involved in labeling, which may affect the validity of the results.

### Suggestions for Improvement
We recommend that the authors improve the dataset by addressing the skewness in class distribution and providing a more balanced representation of offensive language. Additionally, we suggest expanding the definition of offensive language beyond the current narrow focus to enhance the dataset's applicability. Clarifying the annotation process, including the training of human annotators and ensuring independent adjudication, would strengthen the study's credibility. Furthermore, we encourage the authors to explore alternative forms of context, such as user profiles or conversation threads, and to provide detailed descriptions of the machine learning models used, including their architectures and hyperparameters, to facilitate reproducibility.