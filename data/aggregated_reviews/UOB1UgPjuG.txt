ID: UOB1UgPjuG
Title: Class-Distribution-Aware Pseudo-Labeling for Semi-Supervised Multi-Label Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 7, 5, 6, 7, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 5, 5, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Class-Aware Pseudo-labeling (CAP) method to address the semi-supervised multi-label learning (SSMLL) problem. The authors propose a class-aware pseudo-labeling strategy that avoids estimating the number of true labels for each instance, transforming the challenge into estimating the class distribution of unlabeled data. The method incorporates a regularized learning framework and a class-distribution-aware thresholding (CAT) strategy, providing theoretical verification and generalization error bounds for the estimated class distribution. Extensive empirical studies demonstrate the method's effectiveness across various datasets.

### Strengths and Weaknesses
Strengths:  
- The motivation for the paper is clear, addressing the limitations of traditional pseudo-labeling methods in multi-label scenarios.  
- The proposed method is intuitive and effectively transforms the problem into estimating class distributions, which is well-supported by theoretical and empirical validation.  
- The paper is well-structured, with clear presentation of methods and solid experimental results.

Weaknesses:  
- The reliance on a single threshold for determining positive and negative pseudo-labels for each class lacks clarity; the authors should explain the rationale for using two thresholds.  
- The paper does not adequately discuss how to set the parameter of ASL or the implications of distribution mismatches in unlabeled data.  
- There are language errors that require careful proofreading, and the paper lacks sufficient references to related works in SSMLL.

### Suggestions for Improvement
We recommend that the authors improve the explanation of the thresholding strategy, particularly the choice of using an exponential transformation for the threshold value in the CAP method. Additionally, the authors should provide a more comprehensive discussion of the parameter settings for ASL and address potential distribution mismatches in unlabeled data. It is also suggested that the authors include comparisons with existing SSMLL methods, such as UPS, and conduct experiments with multiple random seeds to assess the robustness of their results. Finally, careful proofreading is necessary to correct language mistakes and ensure clarity.