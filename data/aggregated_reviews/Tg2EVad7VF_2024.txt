ID: Tg2EVad7VF
Title: DiffNorm: Self-Supervised Normalization for Non-autoregressive Speech-to-speech Translation
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 5, 7, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DiffNorm, a diffusion-based self-supervised method for speech data normalization aimed at addressing the multimodal problem in non-autoregressive speech-to-speech translation (NAT). The authors utilize a Variational Autoencoder (VAE) to reconstruct speech features and a diffusion model to manipulate the latent vector's noise. Experiments on CVSS En-Fr and En-Es datasets demonstrate significant improvements in NAT translation quality compared to baseline methods.

### Strengths and Weaknesses
Strengths:
1. The proposed diffusion method for normalizing target speech units shows superior performance over previous approaches.
2. The substantial improvement in ASR-BLEU scores, particularly a 7 BLEU increase in the En-Es direction, highlights the method's effectiveness.
3. The ablation studies on noise levels and training provide valuable guidance for adapting DiffNorm to various datasets and models.

Weaknesses:
1. The paper overstates its contributions, claiming to be the first to apply diffusion in speech-to-speech translation while primarily generating auxiliary training targets and adhering to the S2UT strategy.
2. The authors only compare two of the three translation directions, and the minimal improvement (0.3 BLEU) in the En-Fr task raises questions about the method's effectiveness.
3. There is a lack of baseline comparisons with recent S2ST models, and the rationale for using a VAE in conjunction with the diffusion model is unclear.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their contributions by accurately contextualizing their work within existing literature. Additionally, we suggest expanding the comparison to include more recent S2ST models to strengthen the evaluation. The authors should also clarify the rationale behind using a VAE for normalization and consider conducting experiments on real speech datasets to validate their claims further. Lastly, ensure consistent significant figures in Tables 3 and 4, and consider reordering Table 3 before Table 4 for better presentation.