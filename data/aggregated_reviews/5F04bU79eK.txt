ID: 5F04bU79eK
Title: Provable Guarantees for Neural Networks via Gradient Feature Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 7, 5, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a general framework for analyzing feature learning in two-layer ReLU neural networks, focusing on "gradient features" that align with the gradients of the loss induced by data distributions and initial model parameters. The authors establish that gradient descent on these networks achieves generalization error close to that of the optimal model under weak assumptions, with specific instantiations for Gaussian mixtures and parity functions. The results show improvements over kernel methods and match or exceed existing feature learning literature.

### Strengths and Weaknesses
Strengths:
1. The paper addresses a highly relevant topic with a novel and powerful concept of gradient features, potentially extending to models beyond two-layer ReLUs.
2. The instantiations of the main result are well-chosen, providing significant improvements over kernel methods and matching rates for learning parities.
3. The presentation is clear and rigorous, with extensive coverage of related works.

Weaknesses:
1. The significance of the main result is unclear without further discussion on the applicability of gradient features beyond the two special cases.
2. A result demonstrating the implications of large risk in the optimal model would strengthen the paper.
3. The analysis primarily focuses on early gradient descent steps, leaving the alignment with practical scenarios ambiguous.

### Suggestions for Improvement
We recommend that the authors improve the discussion on when gradient features can lead to effective models beyond the current examples. Including a result that connects large risk in the gradient feature class with learnability by gradient descent would enhance the paper's impact. Additionally, clarifying the alignment of the analysis with practical applications and providing insights into the training of the first layer would be beneficial. Lastly, addressing the presentation issues, such as adding figures for clarity and discussing the choices of step size in Theorem 3.12, would improve the overall readability and understanding of the framework.