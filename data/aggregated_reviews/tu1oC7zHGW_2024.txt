ID: tu1oC7zHGW
Title: Unveiling the Tapestry of Consistency in Large Vision-Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 7, 5, 5, -1, -1
Original Confidences: 4, 4, 4, -1, -1

Aggregated Review:
### Key Points
This paper presents a multimodal Consistency Benchmark (ConBench) designed to systematically evaluate the capabilities of LVLMs through diverse question formats. ConBench comprises 4,000 questions across 1,000 images and 3,000 discriminative ground truths, along with two special metrics for assessing LVLM consistency. The authors conduct a comprehensive analysis of inconsistency in LVLMs and propose a trigger-based diagnostic refinement method (TDR) to enhance LVLM generation skills without additional training.

### Strengths and Weaknesses
Strengths:
- The constructed ConBench effectively evaluates LVLMs and promotes advancements in the consistency domain.
- The findings provide valuable insights for future research in the community.
- The proposed TDR method shows potential for improving the consistency of LVLMs.

Weaknesses:
- The results in Table 4 indicate that TDR significantly enhances baseline LVLM consistency, but its impact on performance across comprehensive multimodal benchmarks remains unclear.
- Some presentations lack clarity, particularly the definitions of discriminative and generative domains, which should be clearly articulated.
- Certain metrics, including ConScore[C], metric[C], and metric[D], require clearer explanations.
- The use of GPT4 for comparing LVLM output with ground truth raises concerns about potential biases and inconsistent judgments, necessitating further exploration of experimental variations.
- The TDR method appears similar to previous work in the LLM domain, and further clarification is needed to distinguish its unique aspects.

### Suggestions for Improvement
We recommend that the authors improve the clarity of definitions for the discriminative and generative domains at the beginning of the paper. Additionally, provide clearer explanations for the metrics mentioned in Section 4.1. To address the concerns regarding GPT4's biases, we suggest conducting multiple experiments to assess the variability of results. Lastly, we encourage the authors to elaborate on how TDR differs from similar approaches in the LLM realm to enhance the paper's contribution.