ID: ByDy2mlkig
Title: On the explainable properties of 1-Lipschitz Neural Networks: An Optimal Transport Perspective
Conference: NeurIPS
Year: 2023
Number of Reviews: 18
Original Ratings: 6, 5, 6, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a theoretical analysis of 1-Lipschitz Neural Networks (Optimal Transport Neural Networks, OTNN) trained with an optimal transport dual loss, establishing connections between gradient direction, optimal transport, and adversarial examples. The authors explore the explainability properties of OTNN, particularly focusing on the alignment of gradient direction with human explanations. They demonstrate that gradient-based attributions from OTNN exhibit improved fidelity and stability compared to traditional models, enhancing explainability in various XAI metrics. The paper introduces new empirical results using ClickMe and Feature Visualizations and addresses concerns regarding the relationship between robustness and explainability in neural networks.

### Strengths and Weaknesses
Strengths:
- The paper provides valuable theoretical insights into the properties of OTNN, particularly the relationship between gradient direction and optimal transport.
- It is well-written and presents empirical results that convincingly support the claims made regarding the advantages of OTNN in explainability.
- The authors effectively address most reviewer concerns, particularly regarding experimental verification and the relevance of their findings.
- The paper offers intriguing insights into the properties of OTNN models and their gradients, suggesting a theoretical link between robustness and explainability.

Weaknesses:
- The novelty of the paper is questioned, as many insights regarding the interpretability of robust models have been previously established, making the contributions appear incremental.
- The experimental results show that OTNN performance lags behind existing models, and the comparisons presented are insufficiently detailed.
- The dataset used for experiments is overly simplistic, limiting the verification of theoretical results.
- The clarity regarding the linearity of OTNN in large local regions remains unresolved.
- Some statements, such as the superiority of OTNN gradients over those of adversarially trained networks, lack sufficient justification.
- The alignment of OTNN gradients with human attention is questioned, as it may not necessarily indicate better model performance.
- The paper does not adequately engage with recent literature on 1-Lipschitz networks, which could enhance the discussion of the findings.

### Suggestions for Improvement
We recommend that the authors improve the novelty and significance of their contributions by clearly articulating insights that differentiate their work from existing literature. Additionally, we suggest conducting more comprehensive comparisons between OTNN and traditional neural networks, including large-scale experiments and organizing results into a table for clarity. The authors should also explore more complex datasets to validate their theoretical claims and visualize the loss landscape to support their assertions about gradient properties. Furthermore, we recommend improving the clarity around the linearity of the trained OTNN in large local regions and providing a more robust justification for claims regarding the relevance of OTNN gradients compared to adversarially trained networks. Engaging more deeply with the three related papers suggested by the reviewers could enhance the theoretical framework of the paper. Finally, we encourage the authors to clarify the implications of gradient alignment with human attention, ensuring that it is contextualized within broader XAI metrics.