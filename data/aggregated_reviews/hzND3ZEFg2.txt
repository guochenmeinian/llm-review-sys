ID: hzND3ZEFg2
Title: Learning to Influence Human Behavior with Offline Reinforcement Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 6, 5, 4, 6, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into using offline reinforcement learning (RL) to influence suboptimal human opponents in agent-human interactions. The authors claim that agents can learn to influence human actions and latent strategies by training on human-human interaction data. Experimental results indicate that the CQL algorithm achieved higher test returns against human opponents, and that decoding latent representations outperformed other opponent modeling techniques. However, the paper lacks explicit empirical evidence to substantiate these claims.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and organized, facilitating comprehension and clearly connecting to existing literature.
2. The problem of influencing suboptimal human opponents is significant for human-agent interactions.
3. The approach of learning influence strategies from human-human data is both interesting and intuitive.

Weaknesses:
1. There is insufficient empirical evidence to support claims regarding the agent's ability to influence human actions and strategies. The reported improvements in test returns could be attributed to other factors, and the evidence provided is not adequately annotated.
2. The presentation of latent strategies is confusing, lacking a clear definition and relationship to opponent actions.
3. The evaluation is limited to offline RL methods without comparisons to other approaches, and the claims regarding long-term influence require further substantiation.

### Suggestions for Improvement
We recommend that the authors improve the empirical support for their claims by providing explicit quantitative evidence of influence, such as reporting action frequencies of human participants. Additionally, clarifying the definition of "latent strategies" and their relationship to opponent actions is essential. We suggest incorporating comparisons with state-of-the-art methods in human-agent collaboration to contextualize the findings better. Furthermore, expanding the evaluation to include both objective and subjective metrics, as well as considering competitive interactions, would enhance the robustness of the study. Finally, addressing ethical considerations regarding human trust and the potential for negative reactions during influence attempts is crucial for responsible human-AI interactions.