ID: gzh9nTUtsY
Title: Least Squares Regression Can Exhibit Under-Parameterized Double Descent
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 7, 7, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, 2, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an exploration of the double descent phenomenon in regression, demonstrating that the peak of risk can shift from the interpolation point into the under-parameterized regime due to violations of specific assumptions. The authors provide theoretical results and examples that illustrate this behavior, contributing to the understanding of generalization in high-dimensional data.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant topic in machine learning, enhancing understanding of double descent.
- The theoretical analysis is rigorous, and the results are relevant.
- The contextualization of prior work is commendable, with clear examples and figures aiding comprehension.

Weaknesses:
- Clarity is lacking in several sections, with specific areas needing better exposition, such as the interpretation of Theorem 1 and the abstract's phrasing.
- The conclusions are brief and not very informative, particularly in Section 6, and the examples provided are imbalanced in depth.
- The unconventional notation complicates understanding, and some assumptions are overly strong, limiting the generalizability of the results.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by refining the exposition in critical sections, particularly regarding the interpretation of Theorem 1 and the abstract's phrasing. Additionally, we suggest providing a more balanced discussion of the examples in Section 6 and ensuring that the notation used is consistent and conventional to facilitate reader comprehension. It would also be beneficial to explicitly discuss the limitations of the work and how the assumptions relate to previous theories on double descent.