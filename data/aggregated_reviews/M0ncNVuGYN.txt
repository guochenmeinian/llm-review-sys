ID: M0ncNVuGYN
Title: Are High-Degree Representations Really Unnecessary in Equivariant Graph Neural Networks?
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 7, 6, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis of the necessity for higher-degree features in Graph Neural Networks (GNNs) that operate on geometric graphs with E(3) symmetries. The authors challenge the assumption that 1st-degree equivariant features are sufficient, demonstrating through theoretical results that such representations can lead to degenerate outputs for symmetric structures. They propose HEGNN, an extension of the EGNN model that incorporates higher-degree steerable vectors while maintaining computational efficiency via scalarization. The expressivity of HEGNN is theoretically analyzed and empirically validated on various benchmarks, showing improved performance over existing models. The paper also provides a thorough evaluation of the HEGNN model, highlighting its efficiency in utilizing high-degree steerable features through a scalarization trick and addressing the relationship between model time consumption and the degree, noting that the bottleneck is influenced by both the degree \(L\) and the number of channels. The authors clarify the performance gap of SEGNN compared to the original paper, attributing it to differences in datasets and preprocessing methods, and emphasize the novelty of their work, particularly in explaining expressivity barriers of low-degree representations.

### Strengths and Weaknesses
Strengths:  
- The research question is well-motivated, addressing a significant gap in the understanding of equivariant GNNs.  
- The theoretical analysis provides valuable insights into the limitations of low-degree representations, supported by empirical results that align with the theoretical predictions.  
- The proposed HEGNN model is original and offers a promising approach to integrating higher-degree representations efficiently.  
- The paper provides insightful analyses and thorough evaluations of the proposed HEGNN model.  
- The authors effectively address reviewer concerns and clarify the model's performance discrepancies.  
- The theoretical contributions, particularly Theorems 3.5, 3.6, and 4.1, are notable for their clarity and significance.

Weaknesses:  
- The experimental comparisons, particularly on N-body systems, are limited and do not include recent state-of-the-art methods, hindering direct performance assessment.  
- The focus on predicting future positions may not fully demonstrate the advantages of high-degree representations across diverse applications.  
- Some relevant baselines are missing from the comparisons, which could provide a more comprehensive evaluation of HEGNN's performance.  
- Clarity issues in the presentation limit accessibility, particularly for readers unfamiliar with geometric GNNs and related concepts.  
- The novelty of the work is perceived as limited by some reviewers.  
- Certain results, such as those in Table S3, are suggested to be moved to the main text for better visibility.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the presentation by providing intuitive explanations for key concepts, such as *x-degree steerable representations* and the *Clebsch-Gordan tensor product*, early in the paper. Additionally, elaborating on examples 3.2 and 3.3 would strengthen the motivation for the proposed methodology. We suggest conducting additional experiments across various tasks to demonstrate the broader applicability of HEGNN and including comparisons with recent state-of-the-art methods like ClofNet and GMN. A more detailed analysis of the computational trade-offs involved in using high-degree representations would also enhance the paper. Furthermore, we recommend that the authors improve the clarity of the novelty of their contributions, particularly in relation to existing works on high-degree features. Including the results from Table S3 in the main text rather than the Appendix would enhance accessibility. It would also be beneficial to incorporate clearer comparisons with the CG tensor product to illustrate the technical contributions more effectively. Lastly, we encourage the authors to discuss the limitations of their work in a dedicated section, addressing potential gaps in expressiveness compared to other steerable methods like TFN and SEGNN, and to address the computational complexity and runtime discussions as suggested by the reviewers.