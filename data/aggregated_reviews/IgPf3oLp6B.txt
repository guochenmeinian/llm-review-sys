ID: IgPf3oLp6B
Title: Query2Triple: Unified Query Encoding for Answering Diverse Complex Queries over Knowledge Graphs
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a graph transformer-based approach (Query2Triple) for knowledge graph logical query answering, leveraging pretrained knowledge graph embeddings. It proposes novel methods for utilizing both the scoring function and embeddings, transforming the query answering problem into a tail estimation problem. The authors demonstrate strong performance on EPFO queries but exhibit suboptimal results on negation queries.

### Strengths and Weaknesses
Strengths:
- The paper introduces novel methods for using knowledge graph embeddings.
- It achieves state-of-the-art performance on EPFO queries, with competitive overall results.
- The analysis and discussion provide valuable insights for future research.

Weaknesses:
- Key technical details are missing, such as the application of label smoothing to the negative sampling loss.
- The paper overclaims its contributions, particularly in its comparison to LMPNN, which also trains neural networks while keeping KG embeddings unchanged.
- Lack of ablation studies to validate the importance of the proposed answer decoding approach.
- The model does not outperform previous state-of-the-art models on negative queries, raising concerns about its generalization capabilities.

### Suggestions for Improvement
We recommend that the authors improve the clarity of key technical details, particularly regarding the application of label smoothing in the negative sampling loss. Additionally, we suggest that the authors double-check their claims regarding the contributions compared to LMPNN, as well as provide an ablation study to validate the significance of their answer decoding approach. It would also be beneficial to include discussions on missing baselines such as FuzzQE and GNN-QE, and to clarify the discrepancies in the results presented in Table 1. Finally, enhancing the coherence of the text and addressing minor conceptual descriptions will strengthen the paper.