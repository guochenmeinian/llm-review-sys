ID: m0iCbfjGQk
Title: Division-of-Thoughts: Harnessing Hybrid Language Model Synergy for Efficient On-Device Agents
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Division-of-Thoughts (DoT), a novel framework for efficient edge-cloud collaboration in LLM-based AI assistants. The authors propose a method to decompose complex queries into subtasks, allocating them between small language models (SLMs) on edge devices and large language models (LLMs) in the cloud. The framework employs a graph-based task scheduler and a lightweight plug-and-play adapter, achieving significant reductions in reasoning time and API costs while maintaining comparable accuracy to existing baselines.

### Strengths and Weaknesses
Strengths:
1. The framework design is technically sound, providing a clear separation of concerns through its three-component architecture (Task Decomposer, Task Scheduler, and Plug-and-Play Adapter).
2. The empirical results demonstrate substantial practical improvements, with average reductions of 66.12% in reasoning time and 83.57% in API costs.
3. The plug-and-play adapter is resource-efficient, adding only 13M parameters while enhancing task allocation capabilities.

Weaknesses:
1. The evaluation of core architectural components, such as task decomposition and dependency graph construction, is insufficient, lacking rigorous individual assessments and metrics for measuring decomposition quality.
2. Generalization and adaptability of the framework are not thoroughly explored, raising questions about the applicability of a single task allocator adapter across different task types and dynamic requirements.
3. The optimization objective is not fully aligned with the evaluation metrics, leading to ambiguity in how performance is influenced by changes in parameters.

### Suggestions for Improvement
We recommend that the authors improve the evaluation methodology by conducting rigorous individual assessments of the task decomposition and dependency graph components, including comparisons with other methods and metrics for measuring decomposition quality. Additionally, the authors should clarify whether a single adapter can handle all task types or if separate adapters are necessary, and explore the framework's adaptability to dynamic task requirements. Furthermore, we suggest aligning the optimization objective more closely with the evaluation metrics to clarify its impact on performance. Lastly, minor writing fixes, such as removing unnecessary words in figure captions and addressing casing issues, should be made for clarity.