ID: UjOPUHPoTM
Title: Blackbird language matrices (BLM), a new task for rule-like generalization  in neural networks: Can Large Language Models pass the test?
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper extends existing work by qualitatively examining ChatGPT's responses to prompts that highlight rule-based linguistic reasoning, such as correspondence finding and item novelty. The authors propose a benchmark inspired by Raven's Progressive Matrices, aiming to assess linguistic reasoning in LLMs. While the qualitative analysis is thorough, the paper lacks robust quantitative evaluation and comparison to human performance, raising questions about the universality of the reasoning demonstrated by ChatGPT.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and easy to follow, providing a comprehensive qualitative analysis of ChatGPT's reasoning abilities.
- It connects to established concepts in psychology, specifically Raven's matrices, which is a well-motivated idea for the NLP community.
- The inclusion of prompts in both English and Italian broadens the scope of the hypothesis testing.

Weaknesses:
- The study relies heavily on anecdotal evidence and lacks a quantitative evaluation, limiting its methodological validity.
- There is no comparison to human performance, leaving unclear whether the reasoning capabilities observed in ChatGPT are replicable in humans.
- The manuscript is not self-contained, requiring constant reference to the appendix, which complicates readability.

### Suggestions for Improvement
We recommend that the authors improve the manuscript by incorporating a quantitative evaluation to support their claims and enhance methodological rigor. Additionally, including comparisons to human performance would clarify the implications of their findings. Expanding the test set and incorporating other state-of-the-art LLMs as baselines would strengthen the study's contributions. Finally, we suggest making the main text more self-contained to improve accessibility for readers.