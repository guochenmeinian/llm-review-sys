ID: m11TbsaQQI
Title: Efficient Hyper-parameter Optimization with Cubic Regularization
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 5, 6, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a stochastic cubic regularization algorithm for hyperparameter optimization that does not rely on hyper-gradients. Theoretical analysis indicates that the method can converge to approximate second-order stationary points with lower sample complexity than first-order optimization methods. The authors also extend convergence results to inexact gradients and demonstrate the algorithm's effectiveness through experiments on both synthetic and real data.

### Strengths and Weaknesses
Strengths:
1. The paper is clearly written and introduces a new algorithm for nonconvex bilevel hyperparameter optimization problems.
2. The cubic subproblem is computationally efficient due to its small dimensionality.
3. The theoretical analysis shows that the proposed method achieves lower sample complexity compared to first-order methods.

Weaknesses:
1. The algorithm's design is a straightforward application of cubic regularization, lacking novelty.
2. The technical novelty in the convergence analysis compared to inexact cubic regularization is unclear, particularly regarding the bias in the constructed $g$ and $B$.
3. Existing literature on second-order stationary points in bilevel optimization is not adequately discussed or compared.
4. Experimental results show many piece-wise flat curves, raising questions about hyperparameter changes during those iterations.

### Suggestions for Improvement
We recommend that the authors improve the novelty of the algorithm by providing a more distinct contribution beyond the application of cubic regularization. Clarifying the technical aspects of the convergence analysis, especially regarding the bias of estimators, would enhance the paper's rigor. A thorough comparison with existing works on second-order stationary points should be included. Additionally, the authors should address the implications of piece-wise flat curves in their experimental results and provide more detailed explanations of their experimental setup, including the machine learning models used and the hyperparameters involved.