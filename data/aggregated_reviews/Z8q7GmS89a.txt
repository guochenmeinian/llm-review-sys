ID: Z8q7GmS89a
Title: How to Leverage Imperfect Demonstrations in Offline Imitation Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 7, 3, 4, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method called Offline Imitation Learning with Imperfect Demonstrations (iLID) aimed at enhancing policy learning from both expert and imperfect demonstrations. The authors propose a data selection technique that leverages trajectories from suboptimal demonstrations leading to expert states, combined with a constrained behavior cloning approach. While the theoretical motivation is framed in deterministic cases, iLID is asserted to be applicable to general stochastic environments. The empirical results indicate that iLID outperforms several state-of-the-art baselines, particularly in scenarios with limited expert demonstrations. However, the authors acknowledge limitations related to the necessity of state similarity between expert and suboptimal data, the requirement for labeled datasets, and the lack of theoretical guarantees in general Markov Decision Processes (MDPs).

### Strengths and Weaknesses
Strengths:
- The original idea of selecting imperfect demonstrations that lead to expert states is both novel and intuitive.
- The policy optimization problem is well-structured and can be implemented effectively using alternating dual ascent.
- Empirical results demonstrate significant performance improvements for iLID compared to existing methods, especially when expert demonstrations are scarce.
- The authors provide a clear theoretical framework for iLID and its applicability to stochastic environments.
- They demonstrate a willingness to address and integrate feedback regarding the limitations of their work.

Weaknesses:
- The presentation quality requires enhancement, particularly in notation clarity and theoretical explanations.
- The assumption in Theorem 3.1 is overly strong and lacks sufficient discussion.
- The algorithm's performance is heavily reliant on the existence of state similarity between expert and suboptimal data.
- There is a requirement for labeled datasets of expert and imperfect demonstrations, which may limit practical applicability.
- The lack of theoretical guarantees in general MDPs remains a significant concern.
- The paper does not adequately address the limitations of the proposed method, particularly regarding the reliance on labeled datasets.

### Suggestions for Improvement
We recommend that the authors improve the clarity of notation, especially regarding $\tilde{\mathcal{D}}$ in equation (6), and provide citations for the sample complexity of behavior cloning in Section 3.1. Additionally, we suggest that the authors clarify the explanation on behavior interference for the complementary dataset $\tilde{\mathcal{D}}$, particularly why more recent actions are preferred in repeated states. It would also be beneficial to include empirical studies that explore the performance of iLID without seeding expert data, as well as a discussion on the effect of varying the quality of suboptimal data on the method's performance. Furthermore, we recommend that the authors improve the clarity of the limitations section by explicitly stating the implications of the lack of state similarity on the algorithm's performance. We also suggest that the authors explore the theoretical guarantees in general MDPs further, potentially by utilizing the analytical ideas introduced in their work. Lastly, the authors should consider addressing the stochasticity of expert behaviors more comprehensively in their methodology.