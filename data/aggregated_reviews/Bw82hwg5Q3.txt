ID: Bw82hwg5Q3
Title: Self-Evaluation Guided Beam Search for Reasoning
Conference: NeurIPS
Year: 2023
Number of Reviews: 20
Original Ratings: 6, 3, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 5, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a self-evaluation enhanced beam search method aimed at improving multi-step reasoning tasks in Large Language Models (LLMs). The authors propose a novel prompting approach that integrates self-evaluation guidance through stochastic beam search, utilizing LLM self-evaluation as an automatic criterion to optimize the traditional beam search algorithm. Experimental results demonstrate significant improvements across various arithmetic, symbolic, and commonsense reasoning tasks. Additionally, the authors show that their method outperforms PAL + SC given a comparable number of tokens, and they plan to clarify the title to "Self-Evaluation Guided Beam Search for Reasoning" while updating related content. They acknowledge the need to adjust terminology from "faithfulness" to "self-evaluation score" to enhance clarity and provide a thorough cost analysis comparing their method with PAL + SC, emphasizing the impact of computation costs on performance.

### Strengths and Weaknesses
Strengths:
1. The authors propose a novel multi-step decoding method that employs LLM self-evaluation and temperature-controlled randomness, enhancing LLM performance on reasoning tasks.
2. Extensive experiments on a wide range of reasoning benchmarks yield considerable improvements, supported by comprehensive ablations and running examples.
3. The authors demonstrate that their method can outperform PAL + SC under specific conditions, particularly with smaller language models.
4. The revised title and terminology enhance clarity and accurately reflect the contributions of the work.
5. The inclusion of detailed cost analyses and comparisons improves transparency in the evaluation of methods.

Weaknesses:
1. The paper lacks self-containment, particularly in the introduction of key concepts like self-evaluation, which can hinder reader comprehension. Additionally, details of the evaluation benchmarks are insufficiently introduced.
2. The comparison between the proposed method and greedy decoding is misleading due to significant differences in computational costs, which are not adequately addressed in the results.
3. Some results for PAL-SC are missing in the main-text Table 1, which may hinder comprehensive evaluation.
4. The estimation of costs based on maximum lengths rather than average lengths may not provide a practical perspective on performance.

### Suggestions for Improvement
We recommend that the authors improve the self-containment of the paper by concisely introducing key notions, such as self-evaluation, upon their first mention. Furthermore, details regarding the evaluation benchmarks and baseline methods should be clearly articulated in the experimental section. We urge the authors to provide a more equitable comparison of their method against baselines that utilize similar computational resources, as the current experimental setup inflates the perceived improvements. Additionally, we recommend that the authors improve Table 1 to include all relevant results for PAL-SC to ensure a complete comparison. We suggest clarifying the cost analysis by using average lengths instead of maximum lengths for a more practical assessment. It would also be beneficial to expand the analysis to include additional datasets beyond GSM8K, particularly non-math datasets, to strengthen the findings. Lastly, we encourage the authors to incorporate the new experiments and results into the final version, emphasizing their significance in the introduction and results sections.