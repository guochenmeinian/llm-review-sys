ID: xeviQPXTMU
Title: FedGMark: Certifiably Robust Watermarking for Federated Graph Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 5, 6, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents FedGMark, a backdoor-based watermarking framework aimed at protecting Federated Graph Learning (FGL) models from unauthorized copying and model theft. FedGMark introduces two key modules: a Customized Watermark Generator (CWG) for creating watermarked trigger samples using each client's secret key, and a Robust Model Loader (RML) that ensures the watermarked models are robust against layer perturbation attacks. The authors assert that FedGMark is the first method to provide certified robustness against watermark removal attacks, supported by experiments demonstrating its effectiveness across various datasets.

### Strengths and Weaknesses
Strengths:
- The first attempt to watermark federated graph learning models.
- The watermarked models are certifiably robust against attacks.
- Comprehensive experiments validate the effectiveness of FedGMark.
- The design of CWG and RML is clear and intuitive, addressing significant challenges in watermarking techniques.

Weaknesses:
- The threat model is unclear, particularly regarding the adversary's capabilities and the assumption of client trustworthiness.
- Privacy concerns arise from using clients' training graphs for watermarking, potentially leading to privacy leakage.
- There is a lack of experiments validating robustness against backdoor defenses.
- Ownership verification procedures are not adequately introduced or clarified.
- The reliance on pre-defined private keys for watermark generation may not be practical, and the assumption of limited attacker knowledge is overly simplistic.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the threat model and explicitly define the adversary's capabilities. Additionally, addressing the privacy concerns related to using clients' training graphs for watermarking is crucial. The authors should include analysis or experiments on the robustness of FedGMark against backdoor defenses. Furthermore, clarifying the ownership verification procedure and exploring alternative key management methods would enhance the paper's soundness. Lastly, the authors should consider discussing the implications of using different aggregation methods beyond FedAvg on watermark robustness.