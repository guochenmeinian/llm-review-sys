ID: YWSOpYjyG4
Title: Predicting a Protein's Stability under a Million Mutations
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 8, 5, 7, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the "Mutate Everything Method," a novel approach to model a protein's thermodynamic stability based on mutations in its sequence. A key feature is its capacity for extensive parallel evaluations, enhancing computational efficiency. The authors outline the challenges in designing stable proteins through mutations, define thermal stability as a physical metric, and provide a mathematical framework for their method. The approach utilizes protein sequence embeddings from pretrained models (AlphaFold, ESM) to predict thermal stability using lightweight MLP heads for each mutation. Experiments demonstrate improved modeling and computational performance across various mutation datasets. The method is capable of handling higher-order mutations, although the authors acknowledge the difficulty in rigorously benchmarking performance in this area. The paper discusses the intuition behind predicting the residual and clarifies terminology regarding predicted versus experimental values. The baseline methods are described in the appendix, but further explanations for certain methods are recommended for clarity.

### Strengths and Weaknesses
Strengths:
- Originality: The method offers a pragmatic solution to a significant problem in modeling mutation effects on protein stability.
- Quality: Detailed evaluations across multiple tasks and datasets, with comparisons to various methods regarding modeling performance and computational efficiency.
- Clarity: The paper effectively communicates the purpose, goals, and details of the method and results.
- Significance: Addresses a relevant issue with notable performance improvements in diverse settings.
- The method's ability to handle higher-order mutations is a significant contribution.
- The authors have shown responsiveness to feedback by providing additional results and agreeing to clarify terminology and baseline methods.

Weaknesses:
- Clarity in the parallel evaluation pipeline is lacking; Figure 3 should be enhanced with labels indicating how mutations affect specific sequence parts, akin to Figure 2.
- The analysis of homology in Section 5.3 is intriguing but requires a deeper discussion, potentially in the appendix due to space limitations.
- The method's contribution to the field may be perceived as incremental, primarily relying on existing models like AlphaFold2.
- Some evaluations lack detail, particularly regarding higher-order mutations, and the absence of standard deviations in results tables raises concerns about the robustness of the findings.
- Concerns about the novelty of the contributions in both machine learning and protein modeling fields remain.

### Suggestions for Improvement
We recommend that the authors improve clarity in the parallel evaluation pipeline by enhancing Figure 3 with appropriate labels. Additionally, a more in-depth discussion on the homology analysis in Section 5.3 should be included, possibly in the appendix. To strengthen the contribution claim, the authors should clarify the novelty of their approach compared to existing methods. Providing detailed evaluations for higher-order mutations and including standard deviations in results tables would enhance the robustness of the findings. We also recommend that the authors improve the clarity of their terminology by revising L174-175 to “computationally predicted ΔΔG.” Furthermore, we suggest that the authors provide brief descriptions for baseline methods like DeepSequence and EVE in the appendix to enhance understanding for general readers. Finally, we encourage the authors to add a conclusion section to summarize the paper's contributions and implications.