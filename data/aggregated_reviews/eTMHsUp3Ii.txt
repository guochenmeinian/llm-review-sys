ID: eTMHsUp3Ii
Title: Double Randomized Underdamped Langevin with Dimension-Independent Convergence Guarantee
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 7, 6, 5, 6, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 2, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel algorithm for sampling from a Gibbs distribution using discretized Langevin dynamics, achieving state-of-the-art performance in terms of precision requirement $\epsilon$ and ambient dimension $d$. The authors propose a two-step method with random step sizes for discretizing the dynamics, which reduces the time complexity to reach a Wasserstein error of $\epsilon$ by a factor of $\epsilon^{-1/3}$. The algorithm adapts the Randomized Midpoint Method to composite optimization, improving the dependency from $O(\mathrm{Tr}(H)/\epsilon)$ to $O((\mathrm{Tr}(H)/\epsilon)^{1/3})$. The paper also explores the sample complexity rates in terms of effective dimension, completing and generalizing previous results.

### Strengths and Weaknesses
Strengths:  
- The algorithm achieves significant improvements in sampling efficiency and complexity bounds.  
- The introduction of double randomization is a novel technique that enhances the analysis of discretization error.  
- The paper is generally well-written, with clear explanations of the main ideas.

Weaknesses:  
- Some proofs are difficult to follow due to excessive simplifications, particularly in Section B.2.  
- The novelty of the contributions is questioned, as they largely build on previous works without sufficiently clarifying the challenges addressed.  
- The presentation lacks clarity in several sections, particularly regarding the rationale behind the random step sizes and their impact on discretization error.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the proofs, especially in Section B.2, by providing more detailed explanations of the steps involved. Additionally, we suggest expanding the discussion on the relationship to prior works, particularly [Shen and Lee '19] and [Freund et al. '22], to better articulate the unique contributions of this paper. It would also be beneficial to include numerical findings that illustrate the advantages of the doubly randomized ULA over constant or decreasing step sizes. Lastly, we encourage the authors to address the numerous typos and inconsistencies in the text to enhance overall readability.