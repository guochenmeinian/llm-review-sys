ID: K9dmkfZcMu
Title: A Recurrent Neural Circuit Mechanism of Temporal-scaling Equivariant Representation
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 7, 4, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 2, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a continuous attractor neural network model that generates temporal sequences at speeds adjustable by varying the gain of a constant input. The authors analyze their model through the lens of Lie group theory, proposing a framework for temporal scaling in neural circuits. They demonstrate the model's efficacy via simulations that illustrate its ability to produce patterns at different rates.

### Strengths and Weaknesses
Strengths:  
- The proposed model is intuitive and aligns well with empirical data, providing a comprehensive analysis supported by well-designed figures.  
- The originality of separating components for speed control in sequence generation is notable, and the mathematical rigor is commendable.  
- The clarity of presentation, including detailed proofs and supplementary materials, enhances the paper's accessibility.

Weaknesses:  
- The necessity of the Lie group perspective is unclear, as it complicates the analysis without apparent benefit.  
- The novelty claims regarding gain modulation are overstated, as similar concepts exist in prior literature, such as dynamic time warping and studies on gain control in neural networks.  
- The limited scope of simulations, focusing primarily on simple hand-written digits, raises questions about the generalizability of the findings.

### Suggestions for Improvement
We recommend that the authors clarify the relevance of the Lie group perspective and its contribution to the analysis. Additionally, addressing the potential overlap with existing literature on gain modulation would strengthen the novelty claims. Expanding the simulation experiments to include a broader range of patterns and demonstrating the model's applicability to more complex sequences would enhance the paper's significance. Lastly, revising the notation for clarity, particularly regarding rectification, would improve reader comprehension.