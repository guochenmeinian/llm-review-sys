ID: b9N6i7QYDA
Title: Lightspeed Black-box Bayesian Optimization via Local Score Matching
Conference: NeurIPS
Year: 2024
Number of Reviews: 2
Original Ratings: 6, 6
Original Confidences: 4, 3

Aggregated Review:
### Key Points
This paper presents a new and efficient approach to optimize the Probability Improvement (PI) acquisition function for Bayesian Optimization by utilizing local score matching to estimate the gradient. This method enables gradient ascent without the costly covariance matrix inversion typical of GP-based methods, reducing complexity from $O(n^3)$ to $O(n)$. The authors validate their method through experiments on synthetic objectives, comparing it with state-of-the-art $O(n)$ Likelihood-Free Bayesian Optimization (LFBO) and random search.

### Strengths and Weaknesses
Strengths:
- The reduction of complexity to $O(n)$ using local score matching is a significant advancement over traditional GP-based methods.
- The application of local score matching for gradient estimation is a novel technique that simplifies acquisition function optimization.
- The paper provides derivations supporting the gradient estimation's soundness, including a closed-form solution and proof of asymptotic unbiasedness under certain conditions.
- The method's efficiency is validated on synthetic objective functions with dimensions from 5 to 20, showcasing its scalability.

Weaknesses:
- The phrase "directly maximize the PI acquisition function" may mislead; the gradient is estimated via local score matching, not directly computed.
- The paper lacks a clear explanation of the computational complexity reduction from $O(n^3)$ to $O(n)$.
- The limitation of the method to the PI acquisition function is not adequately discussed.
- Immediate regret as a performance metric is mentioned without justification for its selection over other metrics.
- The absence of an explanation regarding the different acquisition function used for LFBO in experiments is noted.
- Standard PI optimization methods are not included as baselines in the experiments.
- Clarity issues exist in Figures 1 and 2 regarding result aggregation and variability.
- Additional experiments, including higher dimensions and real-world problems, are recommended.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the statement regarding the gradient ascent process to explicitly mention that the gradient is estimated via local score matching. Additionally, a brief discussion explaining the computational complexity difference would enhance understanding. It would also be beneficial to provide a rationale for the limitation to the PI acquisition function. We suggest including a justification for the choice of immediate regret as a performance metric and clarifying the acquisition function used for LFBO. Incorporating standard PI optimization methods as baselines in the experiments would strengthen the comparison. Furthermore, improving the clarity of Figures 1 and 2 regarding result aggregation and variability is essential. Lastly, we encourage the authors to conduct more thorough experiments, including higher dimensions and real-world applications, to further validate their approach.