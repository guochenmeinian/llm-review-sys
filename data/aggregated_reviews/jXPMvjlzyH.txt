ID: jXPMvjlzyH
Title: MSTI-Plus: Introducing Non-Sarcasm Reference Materials to Enhance Multimodal Sarcasm Target Identification
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper analyzes the limitations of the current Multimodal Sarcasm Target Identification (MSTI) benchmark and proposes a new MSTI-Plus benchmark. The authors introduce a pluggable Semantics-aware Sarcasm Target Identification (SaSTI) mechanism that enhances MSTI by incorporating non-sarcastic reference materials, thereby improving the identification of sarcastic elements in multimodal contexts. The authors also reformulate the task into target classification and create a fine-grained, manually annotated dataset.

### Strengths and Weaknesses
Strengths:
1. The paper is meticulously structured, with a logical flow and appropriate presentation of figures and tables that enhance clarity.
2. It identifies significant gaps in the original MSTI framework and proposes innovative solutions, including the inclusion of non-sarcastic reference materials.
3. The authors substantiate their arguments with exemplary cases and conduct extensive experiments, ensuring clarity and reproducibility.
4. The release of the MSTI-Plus dataset is a valuable contribution to the field.

Weaknesses:
1. The dataset may still be prone to biases due to varying interpretations among annotators, potentially affecting model training and accuracy.
2. The experimental comparisons lack rigorous validation, as the datasets differ significantly in sample size and distribution, raising concerns about the reliability of results.
3. The paper lacks a thorough theoretical analysis to support the rationale behind the SaSTI mechanism, which would strengthen its foundation.
4. There is insufficient clarity regarding the computational efficiency of MSTI-Plus and SaSTI, including performance metrics and GPU time savings.
5. The distinction between B-/I-Normal and O labels is unclear, which could lower annotator agreement.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the dataset annotations to enhance agreement among annotators. Additionally, the authors should conduct a more rigorous and transparent comparison of the MSTI-Plus dataset against the original MSTI dataset, ensuring that performance discrepancies are not solely attributed to dataset composition. A deeper theoretical analysis of the SaSTI mechanism would provide valuable insights into its effectiveness. Furthermore, we suggest including a broader set of evaluation metrics beyond F1 scores to provide a more comprehensive performance assessment. Lastly, an analysis of the computational complexity and resource usage of the SaSTI approach would be beneficial, along with exploring the integration of existing multimodal datasets to augment the proposed framework.