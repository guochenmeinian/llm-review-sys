ID: aJx9onwsR4
Title: Predicting the Performance of Foundation Models via Agreement-on-the-Line
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 5, 7, 7, 7, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the applicability of agreement-on-the-line (AGL) in finetuned foundation models, demonstrating that AGL can predict out-of-distribution (OOD) performance based on in-distribution (ID) agreement. The authors find that AGL holds across various vision and language benchmarks and that random head initialization is crucial for this phenomenon. They also show that ensembles of different pretrained models exhibit AGL.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and presents substantial experiments on AGL across multiple benchmarks.
- The topic of predicting model performance under distribution shifts is significant in the field.
- The proposed method outperforms previous techniques in predicting OOD performance in most cases.

Weaknesses:
- The novelty of the methodology is limited as it extends a previously proposed method (Baek et al. 2022) without providing theoretical insights into why AGL should hold.
- The paper lacks a discussion on the robustness of the method concerning hyperparameter changes.
- There is insufficient analysis of the differing behaviors of vision and language models, and the assumption that full finetuning and finetuning with LoRA yield the same AGL phenomenon needs further examination.

### Suggestions for Improvement
We recommend that the authors improve the clarity of figures, particularly Figure 1 and Figure 3, by providing more detailed captions and explanations. Additionally, we suggest that the authors elaborate on the sections discussing the contrast with previous literature and the limitations of AGL's applicability to all datasets. Including a more thorough analysis of the robustness of the method with respect to hyperparameters and exploring the differences in behavior between various parameter-efficient fine-tuning (PEFT) methods would enhance the paper's contributions. Lastly, addressing the potential causes for the observed differences in AGL behavior between vision and language models would strengthen the overall analysis.