ID: EjiA3uWpnc
Title: Equivariant Neural Operator Learning with Graphon Convolution
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 5, 5, 6, 7, 8, -1, -1, -1, -1, -1
Original Confidences: 3, 2, 4, 4, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an architecture that combines a coefficient learning scheme with a residual operator layer for learning mappings between continuous functions in 3D Euclidean space, aiming for SE(3) equivariance. The authors propose that their method, which can be interpreted as convolution on graphons, captures geometric information while preserving equivariance. Experimental results indicate that the proposed model outperforms existing state-of-the-art architectures on large-scale electron density datasets.

### Strengths and Weaknesses
Strengths:  
- The integration of structural information and graph spectral interpretation appears to be original and contributes to the model's effectiveness.  
- The paper is well-written, with clear notation and accessible communication of ideas.  
- The proposed method addresses the computational challenges of traditional approaches in electron density estimation.

Weaknesses:  
- The construction of spectral convolution for graphons is not novel and has been previously established in the literature.  
- The exposition and mathematical formulations are often unclear and inaccurate, making the paper difficult to follow.  
- The novelty of the work compared to existing methodologies is not sufficiently articulated, and the chosen baselines are outdated.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the mathematical formulations and provide rigorous definitions for terms such as "equivariant basis" and "basis of the Hilbert space." Additionally, we suggest that the authors clarify the connection between the proposed method and existing works, particularly regarding the construction of the graphon and its implications for equivariance. It would also be beneficial to include more recent baseline methods for comparison and to explicitly discuss the computational complexity and scalability of the proposed approach.