ID: HIBDxkl5n4
Title: Continual Event Extraction with Semantic Confusion Rectification
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for continual event extraction that addresses semantic confusion and imbalanced event distribution in natural language text. The authors propose innovations such as data augmentation with pseudo labels, pivotal knowledge distillation, and prototype knowledge transfer to enhance model performance. Their experimental results demonstrate that the model achieves new state-of-the-art performance on three datasets, showing significant improvements, particularly for long-tailed event types.

### Strengths and Weaknesses
Strengths:  
- The paper introduces multiple innovations that improve continual event extraction, including the use of pseudo labels and prototypical feature vectors.  
- Experimental results are thorough, showcasing the model's superior performance compared to previous methods.  
- The ablation study effectively highlights the contributions of each innovation, aiding future research in the field.

Weaknesses:  
- The technical details can be challenging to follow, with heavy reliance on citations without sufficient summaries of borrowed methods.  
- Mathematical formulations are presented without clear definitions, making it difficult for readers to interpret them.  
- Key concepts and terms are introduced late in the paper, which may confuse readers unfamiliar with the subject.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their writing by providing simpler, explicit definitions of key concepts earlier in the paper. Additionally, summarizing the mathematical formulations in commonly used language would enhance understanding. It would also be beneficial to clarify the relationship between their methods and previous work, ensuring that the distinctions are clear to the reader.