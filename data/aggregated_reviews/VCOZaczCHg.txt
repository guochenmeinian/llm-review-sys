ID: VCOZaczCHg
Title: Mixed-Initiative Multiagent Apprenticeship Learning for Human Training of Robot Teams
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 5, 7, 4, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Mixed-Initiative Multi-Agent Apprenticeship Learning (MixTURE) framework aimed at teaching a team of agents through demonstrations from human experts. The framework enables the learning of both cooperative policies and inter-agent communication protocols, leveraging a mutual information maximization-based communication module. Evaluations on synthetic and real human data demonstrate that MixTURE outperforms existing methods, achieving significant improvements in collaborative task performance.

### Strengths and Weaknesses
Strengths:
- The paper introduces an innovative approach to inter-agent communication in dynamic environments, utilizing a differentiable communication module based on Mutual Information (MI).
- Comprehensive evaluations, including statistical analyses and human-subject studies, support the effectiveness of the proposed framework.
- The methodology is well-structured, with clear explanations and thorough technical details, ensuring reproducibility.

Weaknesses:
- The simplicity of the tasks may not fully showcase the framework's capabilities; more complex environments like ITHOR or Habitat could provide better insights.
- The rationale for choosing GRU over a transformer in the MixTURE architecture needs clarification.
- The assumptions regarding the human expert's access to joint observations and simultaneous command of all agents are unrealistic for real-world applications.
- The communication learning module's dependency on global joint action-observation raises questions about its feasibility in decentralized settings.

### Suggestions for Improvement
We recommend that the authors improve the complexity of the experimental environments to better demonstrate the capabilities of MixTURE. Additionally, we suggest elaborating on the choice of GRU over transformers to enhance clarity. A performance comparison between single and multiple human experts could provide valuable insights into expert diversity's impact. Finally, addressing the assumptions regarding joint observations and providing qualitative analyses of learned policies and communication protocols would strengthen the paper's contributions.