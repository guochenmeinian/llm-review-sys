ID: kNCHv0NZ69
Title: A Tale of Pronouns: Interpretability Informs Gender Bias Mitigation for Fairer Instruction-Tuned Machine Translation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into gender bias in instruction-tuned models for machine translation, utilizing established post-hoc interpretability techniques. The authors conduct experiments on WinoMT for English-to-German and English-to-Spanish translations, revealing a tendency of these models to neglect gendered pronouns. They introduce a sampling procedure to select in-context examples based on importance scores, demonstrating significant improvements in debiasing translations. The work is notable for its empirical evaluation of large-scale language models and its qualitative analysis of failure cases, marking it as one of the first applications of interpretability techniques to mitigate representational biases in machine translation systems.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and presents a timely application of interpretability methods to analyze and reduce gender bias in generative language models.
- It provides a thorough empirical evaluation and qualitative insights, enhancing the understanding of gender bias in instruction-tuned models.
- The proposed debiasing method is simple yet effective, suggesting broader applicability for other natural language generation tasks.

Weaknesses:
- Some strong statements lack sufficient clarification or supporting evidence, which could undermine the paper's overall validity.
- The assumption that the results motivate the adoption of instruction-tuned models in real use cases is questionable, particularly given the performance limitations compared to smaller models.
- The use of WinoMT for both few-shot examples and bias evaluation raises concerns about the generalizability of the proposed method.

### Suggestions for Improvement
We recommend that the authors improve the clarity of strong statements by providing explicit supporting evidence. Additionally, a more detailed discussion on the relevance of instruction-tuned models compared to smaller models in translation tasks would strengthen the paper. We suggest exploring the impact of using non-profession-overlapping lists in experiments to assess the influence of overlap on results. Furthermore, addressing the suitability of existing resources for non-binary and gender-neutral translations would enhance the paper's robustness. Lastly, clarifying the aggregation method for attribution scores and ensuring comprehensive references to related works would improve the overall quality of the manuscript.