ID: aCcldkVyq2
Title: Mining Exploratory Queries for Conversational Search
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents methods for generating exploratory queries within conversational search systems, introducing a rule-based model, a neural generation model, and a Large Language Model (LLM)-based approach. The authors validate their methods through extensive experiments, demonstrating that their models outperform baseline systems in generating high-quality exploratory queries. The paper compares heuristic rules, weakly supervised exploratory query generation, and LLM-based in-context learning, enhancing its originality by addressing a less-studied area of query expansion.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant research problem and is well-structured, making it easy to follow.
- The proposed models achieve better performance than existing baselines, with clear experimental results.
- The comparative analysis of different approaches adds value to the research.

Weaknesses:
- The novelty of the work is somewhat limited, as it does not include state-of-the-art methods in the baseline comparisons.
- Methodological details, such as the rationale behind certain model inputs and the annotators' qualifications, are insufficiently explained.
- The evaluation metrics do not directly assess the quality of query recommendations, and the ground truth data labeling lacks clarity.

### Suggestions for Improvement
We recommend that the authors improve the clarity of how exploratory queries integrate with conversational search systems to enhance the broader application of their research. Additionally, we suggest providing more explicit methodological details, particularly regarding the structure of the document collection and the qualifications of the annotators. The authors should also consider including state-of-the-art methods in their baseline comparisons and refining the evaluation metrics to better assess the quality of query recommendations. Furthermore, we advise separating the results and ablation study tables for clarity and discussing the performance across different metrics and models more comprehensively.