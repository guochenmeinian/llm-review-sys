ID: oQSfcVTNr1
Title: SoundCam: A Dataset for Finding Humans Using Room Acoustics
Conference: NeurIPS
Year: 2023
Number of Reviews: 21
Original Ratings: 6, 8, 7, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents SoundCam, a dataset comprising 5,000 10-channel room impulse response (RIR) measurements and 2,000 10-channel music recordings from three distinct rooms, aimed at facilitating research in human localization, identification, and detection using audio signals. The authors provide baseline experiments to evaluate these tasks, addressing limitations in existing datasets that primarily focus on inanimate objects. Additionally, the paper explores sound localization and identification using a multi-channel VGGish framework, emphasizing the importance of sample rate in sound-related tasks and demonstrating that higher sample rates yield better performance. The authors clarify their methodology regarding participant consent and IRB approval, while also addressing the diversity of human poses as a critical factor for dataset extension.

### Strengths and Weaknesses
**Strengths:**
- The dataset is comprehensive and well-constructed, addressing a significant gap in room acoustics research involving humans.
- The evaluation of baselines is extensive, with clear documentation of the experimental design and methods.
- The authors have improved dataset accessibility and clarified their error metrics.
- The thorough experimental design highlights the effect of sample rate on localization and identification tasks, and a clear distinction is made between active and passive localization methods.
- Ethical considerations regarding the dataset's use are mostly well addressed, focusing on potential misuse and participant consent.

**Weaknesses:**
- The paper lacks clarity in distinguishing between active and passive localization methods, which may confuse readers.
- The evaluation metrics for localization error are not clearly defined, leading to questions about the validity of the results.
- Many human detection results fall below the random guess rate, indicating potential issues in model training and selection.
- The simplicity of the baselines may not fully capture the complexity of the tasks, and certain issues could have been explored further.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the manuscript by explicitly stating the focus on active localization and distinguishing it from passive methods. Additionally, the authors should provide a clear definition of the localization error metric used and discuss the limitations of the results more thoroughly. Including RT60 values for each room would enhance the dataset's documentation. We also suggest that the authors improve the complexity of their baselines to better reflect the challenges of the tasks at hand and further explore the implications of sample rate on baseline performance. Lastly, it would be beneficial to ensure that the main landing page for the dataset links directly to the Stanford Digital Repository version, rather than just the original download links.