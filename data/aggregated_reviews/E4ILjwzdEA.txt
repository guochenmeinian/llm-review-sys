ID: E4ILjwzdEA
Title: Length Optimization in Conformal Prediction
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 4, 6, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents two distinct contributions: a novel method called Conformal Prediction with Length Optimization (CPL) aimed at enhancing the efficiency and conditional validity of conformal prediction methods, and a detailed explanation of the experimental setup for the RxRx1 dataset from the WILDS repository, focusing on predicting genetic treatments from cell images. The authors propose a minimax optimization problem that minimizes the length of prediction intervals while ensuring approximate conditional coverage, demonstrating that CPL outperforms previous methods in producing narrower prediction intervals with finite-sample guarantees. Additionally, they utilize a pre-trained ResNet50 model to characterize covariate shifts and plan to include large-scale experiments involving LLM question-answering datasets in the camera-ready version to showcase the scalability of their method.

### Strengths and Weaknesses
Strengths:
- The introduction of CPL fills a significant gap in the literature by unifying conditional validity and length efficiency in conformal prediction.
- The method is theoretically robust, providing both infinite and finite sample guarantees, enhancing its practical applicability.
- Extensive empirical evaluations demonstrate CPL's superior performance across diverse datasets and settings.
- The authors provide a comprehensive description of their experimental setup and methodologies, particularly in the context of the RxRx1 dataset.
- The use of a pre-trained ResNet50 model and the detailed explanation of covariate shift characterization are well-articulated.
- The planned inclusion of large-scale experiments indicates a commitment to demonstrating the applicability of their method.

Weaknesses:
- The assumptions of L-Lipschitz continuity for conditional distributions and bounded derivatives for conformity scores may limit the method's applicability.
- The computational complexity of the inner maximization and outer minimization steps is not thoroughly discussed, raising concerns about scalability for large datasets.
- Some distinctions made regarding the black-box approach and related work appear arbitrary and may not significantly strengthen the contribution.
- The presentation of the paper requires thorough revision to incorporate clarifications and new experimental details.
- The inconsistency in train/calibration/test splits in additional experiments raises questions about the methodology.
- The novelty of the contributions is somewhat limited, as they build upon existing conformal training ideas without providing a clear roadmap for future work in handling infinite-dimensional classes.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the presentation, particularly regarding notation and the description of experimental setups. The empirical results should include more detailed analyses, including statistics beyond mean results, to enhance the robustness of the findings. Additionally, addressing the computational costs associated with the proposed optimization procedure is crucial, as this could impact the method's scalability. We suggest that the authors improve the clarity of the distinctions made between their method and related work, particularly regarding the black-box approach, to avoid perceptions of arbitrariness. Furthermore, we recommend ensuring consistency in train/calibration/test splits across experiments to enhance methodological rigor. Finally, we encourage the authors to utilize the extra page in the revised manuscript to further elaborate on the experimental setup and results, addressing the feedback received.