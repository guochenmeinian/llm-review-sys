ID: 05vb8rwGct
Title: Towards Informative Few-Shot Prompt with Maximum Information Gain for In-Context Learning
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to demonstration selection in in-context learning (ICL) by utilizing information gain (IG) to quantify the informativeness of potential examples. The authors propose selecting the most informative candidates as demonstration examples and introduce a calibration method to mitigate "template bias," which arises from the template used in prompts. The methodology is evaluated across several classification tasks using various GPT-style LLMs, demonstrating substantial performance improvements.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant issue in NLP, linking ICL with active learning.
- The proposed method is cost-efficient, requiring no large annotated datasets and allowing for demonstration selection based solely on task and template.
- The information gain method shows a notable relative improvement in performance across tasks.

Weaknesses:
- The methodology lacks sufficient detail and clarity, particularly in the methods section.
- The proposed approach is limited to classification tasks, and the independent quantification of information gains may overlook potential performance improvements from joint estimation.
- There is a lack of comparative analysis with contemporary methods, which hinders the assessment of the proposed method's effectiveness.

### Suggestions for Improvement
We recommend that the authors improve the clarity and detail in the methods section to enhance understanding. Additionally, consider including a comparative analysis with contemporary methods to validate the proposed approach's effectiveness. It may also be beneficial to explore joint estimation of information gains to potentially enhance performance. Furthermore, addressing potential biases in the experimental setup, particularly concerning one-shot learning scenarios, is crucial for ensuring the accuracy of results. Lastly, expanding the range of tasks beyond classification could provide a more comprehensive evaluation of the proposed method.