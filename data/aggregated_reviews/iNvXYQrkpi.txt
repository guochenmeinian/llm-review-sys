ID: iNvXYQrkpi
Title: Fast and Memory-Efficient Video Diffusion Using Streamlined Inference
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 6, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 2, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a training-free framework aimed at optimizing video diffusion models by reducing computational demands and peak memory usage. The framework consists of three components: Feature Slicer, Operator Grouping, and Step Rehash, which collectively lead to significant improvements in memory efficiency and inference speed. The authors demonstrate that the peak memory of AnimateDiff can be reduced from 41.7GB to 11GB, making advanced video generation feasible on consumer-grade GPUs.

### Strengths and Weaknesses
Strengths:
- The proposed framework effectively reduces peak memory and accelerates inference for video diffusion models.
- The method is straightforward, intuitive, and well-documented, facilitating ease of implementation.
- Comprehensive experiments indicate substantial improvements in memory usage and inference speed.

Weaknesses:
- The evaluation lacks diversity in baseline comparisons, primarily focusing on SVD and AnimateDiff, both of which are based on T2I diffusion models. The generalizability of the framework to other models, such as those with DiT backbones or 3D diffusion, remains unverified.
- The reliance on FVD and CLIP-Score for performance metrics is insufficient; human-level metrics should be included to assess video visual quality more comprehensively.
- There is a noticeable degradation in video generation quality, particularly in synthesized images, which raises concerns about the framework's applicability in practical scenarios.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by including a wider range of baseline models, particularly those utilizing DiT backbones and 3D diffusion techniques. Additionally, incorporating human-level metrics alongside FVD and CLIP-Score would provide a more robust assessment of video quality. It would also be beneficial to clarify the relationship between the optimization method and batch size, as well as to conduct user studies to evaluate the perceived quality of generated videos. Finally, a more detailed breakdown of the contributions of each component in the framework would enhance understanding of their individual impacts.