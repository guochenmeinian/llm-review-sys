ID: GPtroppvUM
Title: Adversarial Training for Graph Neural Networks: Pitfalls, Solutions, and New Directions
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 5, 7, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a thorough examination of the limitations of transductive adversarial training for Graph Neural Networks (GNNs) in node classification and advocates for an inductive approach. The authors propose a robust diffusion mechanism that utilizes learnable message-passing schemes and local constraints to enhance adversarial training. They also introduce an efficient attack method, LR-BCD, which incorporates both local and global perturbations. The experimental results validate the effectiveness of the proposed methods.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant issue in GNN adversarial robustness, providing valuable insights into the limitations of transductive learning.
- The proposed robust diffusion framework is efficient and adaptable for various GNN architectures, demonstrating empirical robustness.
- The authors present a comprehensive analysis of existing research and articulate the challenges of transductive settings effectively.

Weaknesses:
- There is a disconnect between the analysis of transductive limitations and the design of the defense mechanism, lacking clarity in motivation and correlation with adaptive spectral GNNs.
- The claim of interpretability for GPRGNN is not sufficiently substantiated, as the focus on learned weights does not convincingly demonstrate interpretability.
- The theoretical sections appear redundant, particularly regarding the clean graph's role in adversarial training, which does not necessitate mathematical justification.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation behind their defense mechanism and its connection to the analysis of transductive settings. Additionally, we suggest providing a more robust theoretical justification for the proposed local constraints and their impact on graph semantics. Expanding experimental evaluations to include diverse datasets and comparisons with other robust GNN models would strengthen the contributions. Finally, consider revising Sections 2.1 and 2.1.1 to focus on essential insights while reducing redundancy.