ID: 1DTCoyAFiV
Title: Cascading Contextual Assortment Bandits
Conference: NeurIPS
Year: 2023
Number of Reviews: 20
Original Ratings: 5, 7, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper studies the contextual cascading assortment bandit problem, proposing low regret algorithms, specifically UCB-CCA and UCB-CCA+, which generalize existing cascading and assortment bandits. The authors claim to achieve tighter regret bounds by eliminating dependencies on cascade length \( K \) and the constant \( \kappa \). The work includes an improved UCB-based bandit algorithm designed for the contextual assortment bandit problem, establishing regret bounds that eliminate suboptimal dependencies and providing a rigorous approximation guarantee for the cascading assortment optimization problem, yielding a 0.5 approximation of the optimal solution. Numerical simulations demonstrate the effectiveness of the proposed methods, which have practical applications across various domains.

### Strengths and Weaknesses
Strengths:
1. The study introduces a novel problem that combines contextual cascading and assortment bandits, motivated by real-world applications in recommender systems.
2. The proposed algorithms, particularly UCB-CCA+, achieve improved regret bounds, addressing significant technical challenges.
3. The writing is generally clear and supported by intuitive figures and tables, enhancing comprehension.
4. Development of a novel UCB-based algorithm that addresses long-standing issues in regret bounds.
5. Provision of a rigorous approximation guarantee for the contextual cascading bandit problem.

Weaknesses:
1. The reward function simplifies the problem, potentially undermining the complexity addressed in prior work.
2. There are noticeable grammatical errors and typos throughout the paper, affecting overall presentation.
3. The authors did not adequately address limitations, particularly regarding the assumptions made in the algorithms and the implications of their results.
4. Misunderstandings in reviewer comments regarding the interpretation of key terms such as cascade length \( K \) and position effects.
5. Some reviewers expressed concerns about the restrictive nature of the disjunctive objective used in the model.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the reward function's implications and ensure it aligns with the complexities of prior work. Additionally, addressing the grammatical errors and typos, particularly in the specified lines, will enhance the paper's presentation. We suggest including a discussion on the structural properties of optimal assortments and clarifying the necessity of the optimistic exposure swapping technique. Furthermore, we encourage the authors to provide a more detailed analysis of the proof for Lipschitz continuity in Lemma 4.2 and to discuss the lower bounds for contextual assortment combinatorial bandits. Lastly, improving clarity in their communication regarding the definitions of key terms, particularly \( K \) and position effects, and addressing concerns about the restrictive disjunctive objective could enhance the paper's reception.