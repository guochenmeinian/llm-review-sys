ID: oUXiNX5KRm
Title: Universal Physics Transformers: A Framework For Efficiently Scaling Neural Operators
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 7, 6, 7, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Universal Physics Transformers (UPTs), a framework designed for efficient learning and scaling of neural operators applicable to both grid- and particle-based structures. UPTs utilize a low-dimensional latent space for dynamics propagation, enabling rapid simulations and evaluations at any space-time point. The authors demonstrate UPTs' effectiveness through extensive experiments on fluid dynamics problems, showcasing their scalability and performance. Furthermore, the paper introduces DiT modulation to condition on boundary conditions such as timestep and inflow velocity, enhancing the model's adaptability. The encoding of the signed distance function (SDF) of geometry using a shallow CNN allows for flexible representation, while the numerical stability of UPT is highlighted, showcasing its resilience against instability and compatibility with techniques used in training large language models.

### Strengths and Weaknesses
Strengths:
- UPTs effectively handle both mesh-based and particle-based data, enhancing flexibility across simulation types.
- The framework leverages a low-dimensional latent space for efficient temporal dynamics propagation, facilitating rapid evaluations.
- The authors conducted compelling Navier-Stokes experiments and demonstrated UPTs as a robust baseline.
- UPTs exhibit excellent scalability with input size, outperforming other baselines across various scales.
- The integration of DiT modulation for boundary conditions significantly improves model adaptability.
- The encoding of SDF using a shallow CNN demonstrates innovative representation techniques.
- UPT's resilience to numerical instability is well-articulated, showcasing its advantages over traditional methods.
- The clarity of presentation and thorough background information enhance the paper's accessibility and reproducibility.

Weaknesses:
- Although labeled as universal, UPTs are only tested on fluid dynamics, lacking experiments on other PDEs.
- The scalability of UPTs with model size appears poor, as indicated by Figure 5, necessitating additional experiments for large-scale applications.
- The stability of the latent rollout technique for long rollouts remains uncertain, raising concerns about its reliability.
- The novelty of UPTs is somewhat limited due to existing works utilizing transformers for PDE problems, and comparisons to these works are missing.
- The methodology lacks clarity, particularly in the implementation of encoding and decoding schemes, which could benefit from additional diagrams or pseudo-code.
- Limited discussion on scalability with extremely large datasets and in distributed computing environments raises concerns about practical applicability.
- Insufficient analysis of generalization capabilities and potential overfitting issues detracts from the robustness of the claims.
- The paper does not provide a detailed comparison with established particle and grid-based methods, nor does it adequately address how UPTs handle complex boundary conditions.

### Suggestions for Improvement
We recommend that the authors improve the experimental scope by testing UPTs on a wider range of PDEs beyond fluid dynamics. Additionally, further experiments should be conducted to clarify the scalability of UPTs concerning model size and training size. To enhance the reliability of the latent rollout technique, the authors should provide more analysis on its stability during long rollouts. We also suggest including comparisons to existing transformer-based models to better contextualize the novelty of UPTs. Furthermore, we recommend that the authors improve the clarity of the methodology by providing detailed explanations or diagrams of the encoding and decoding processes. Discussing the performance of UPTs with extremely large datasets and in distributed environments would enhance the paper's relevance. A more thorough analysis of generalization capabilities, particularly in unseen scenarios, should be included to strengthen the claims. We also suggest including a detailed comparison with traditional particle and grid-based methods, particularly regarding boundary condition handling and numerical stability. Finally, addressing potential overfitting concerns with strategies for regularization and data augmentation would be beneficial, and including the pseudocode for UPT in the revised version would be crucial for understanding the implementation details.