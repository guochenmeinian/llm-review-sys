ID: uFpjPJMkv6
Title: FairLISA: Fair User Modeling with Limited Sensitive Attributes Information
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 7, 8, 5, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents FairLISA, a framework designed for fair user modeling with limited sensitive attribute information. The authors propose a method that efficiently utilizes both known and unknown sensitive attributes to enhance fair model training, supported by theoretical guarantees from a mutual information perspective. Extensive experiments validate FairLISA's effectiveness across various scenarios with differing ratios of missing sensitive attributes.

### Strengths and Weaknesses
Strengths:
1. The investigation of missing sensitive attributes in fair user modeling is meaningful and relevant.
2. The paper is well-structured and accessible.
3. FairLISA effectively leverages unlabeled data without predicting missing attributes, offering a straightforward approach with theoretical backing.
4. Comprehensive experiments demonstrate FairLISA's robustness in two user modeling tasks.

Weaknesses:
1. The focus on a specific fairness definition (mutual information being zero) overlooks other established fairness metrics like Equalized Odds and Demographic Parity, which warrants further exploration.
2. The sensitive information ratio setting is not clearly presented in Table 1.
3. The theoretical analysis relies on the assumption of a Bayesian optimal discriminator, which may not be practical.
4. The datasets used are not widely recognized, making it challenging to evaluate the proposed method's effectiveness.

### Suggestions for Improvement
We recommend that the authors improve the discussion on how FairLISA performs concerning classic fairness metrics such as Equalized Odds and Demographic Parity. Additionally, please clarify the sensitive information ratio setting in Table 1. We suggest providing a more detailed explanation of the theoretical analysis, particularly regarding the implications if the discriminator is not optimal. It would also be beneficial to conduct experiments on more commonly used fairness datasets, such as ADULT and COMPAS, and to include additional baselines for comparison. Finally, addressing the grammatical errors and typos present in the manuscript will enhance its overall quality.