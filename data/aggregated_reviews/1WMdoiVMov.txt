ID: 1WMdoiVMov
Title: Robust Knowledge Transfer in Tiered Reinforcement Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 5, 5, 5, 7, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 1, 3, 4, 3, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an extension of "Tiered-RL," a multi-fidelity reinforcement learning framework that executes a "low-fidelity" environment in parallel with a "high-fidelity" environment to accelerate training while maintaining near-optimal regret. The authors propose novel online learning algorithms that achieve constant regret on partial states based on task similarity and near-optimal regret when tasks are dissimilar. The work also introduces a source task selection mechanism for multiple low-tier tasks, enhancing knowledge transfer across a larger state-action space.

### Strengths and Weaknesses
Strengths:
- The paper provides a thorough theoretical evaluation of a relevant setting in reinforcement learning, particularly in transferring knowledge from low-tier to high-tier tasks.
- The regret analysis of the robust tiered multi-armed bandit models is comprehensive, and the originality of removing the assumption of task similarity is noteworthy.
- The proposed algorithms and lower bounds contribute valuable findings to the field of Tiered RL.

Weaknesses:
- The absence of empirical evaluations limits the understanding of the practical implementation and performance of the proposed algorithms.
- The paper does not adequately cite existing literature on multi-fidelity RL, which raises concerns about the novelty of the proposed framework.
- Several grammatical errors and a lack of clarity regarding the relationship between parallel knowledge transfer and meta-learning detract from the overall quality.

### Suggestions for Improvement
We recommend that the authors improve the manuscript by including empirical evaluations to demonstrate the practical performance of the proposed algorithms. Additionally, we suggest that the authors incorporate relevant literature on multi-fidelity RL into the related works section to clarify the novelty of their approach. Providing illustrative examples or toy problems would help motivate the generalization of the proposed method. Furthermore, a more detailed discussion on the selection of the hyperparameter \(\lambda\) would enhance the completeness of the paper. Lastly, addressing grammatical issues and clarifying the distinctions between parallel knowledge transfer and meta-learning would improve clarity.