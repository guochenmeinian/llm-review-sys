ID: 7W0f7lifDk
Title: Human-3Diffusion: Realistic Avatar Creation via Explicit 3D Consistent Diffusion Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 18
Original Ratings: 6, 4, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a pipeline for creating a 3D model of a full body avatar from a single input image, effectively addressing challenging scenarios such as loose clothing and diverse character types. The authors propose a method that combines a large-scale 2D pre-trained multiview image model with a 3D consistent generative model using Gaussian splatting. This joint diffusion process generates four orthogonal views from the input image, which are refined through a 3D generative model to ensure consistency. The final output is achieved by redecoding the 3D rendering with a 2D model. The model is trained on a dataset of 6000 human scans, demonstrating convincing results across multiple challenging datasets, including Sizer, IIT-Human, and GSO. A user study indicates an 80.3% preference for their method over existing state-of-the-art (SOTA) baselines, although some reviewers express concerns regarding qualitative results and input resolution limitations.

### Strengths and Weaknesses
Strengths:
- Convincing results on challenging datasets, surpassing ten recent baselines in human reconstruction.
- The method is generic and applicable to various objects, not just humans, demonstrating strong generalization capabilities.
- Extensive numerical and qualitative comparisons show improved performance over previous methods.
- Positive user study results indicating significant preference for the method.
- The integration of both 2D and 3D generative models is a notable advancement.
- The paper is well-structured and generally easy to follow.

Weaknesses:
- Some key technical details are missing, including the architecture of the noise-conditioned Gaussian-based 3D generative model and processing time for images.
- Concerns regarding the qualitative results of the reconstruction, particularly in relation to input resolution limitations.
- The complexity of training both 2D and 3D generative models is a concern, especially given the limited dataset of 6000 scans.
- The paper contains grammatical errors and typos that detract from its professionalism.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the technical details, particularly regarding the architecture of the 3D generative model and the expected processing time for images. Additionally, we suggest simplifying the pipeline to reduce complexity and reliance on limited 3D scans. To address reviewer concerns, we encourage the authors to enhance the qualitative results of their reconstruction and explore the integration of higher-resolution models, such as MVDiffusion++ and CAT3D, to improve detail in facial and hand geometry. Proofreading for grammatical errors and typos is essential to enhance the overall presentation. Furthermore, we recommend including comparisons with additional state-of-the-art methods to strengthen their claims of performance improvements.