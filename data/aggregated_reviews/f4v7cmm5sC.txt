ID: f4v7cmm5sC
Title: Foundation Inference Models for Markov Jump Processes
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 7, 8, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a foundation model for Markov jump processes (MJPs) that is trained on synthetic datasets to predict the corresponding rate matrix and initial state distribution. The authors demonstrate that the model can perform zero-shot inference on unseen sequences, showcasing its generalizability without the need for fine-tuning. The approach contrasts with traditional unsupervised methods by focusing on supervised learning to accurately predict model parameters in inverse synthetic experiments.

### Strengths and Weaknesses
Strengths:  
The authors provide a clear and well-motivated exposition of their approach, effectively demonstrating the model's performance through extensive experiments. The simplicity of the model contributes to its generalizability, making it a practical tool for extracting information from time-dependent processes.

Weaknesses:  
Despite the originality of the work, important details regarding the application of trained models to real data are unclear. The limitations of the approach are not adequately explored, particularly concerning the realism of synthetic dataset generation and the model's performance on complex processes. Additionally, the numerical experiments lack sufficient depth, failing to compare against state-of-the-art methods or systematically demonstrate the model's capabilities under varying conditions.

### Suggestions for Improvement
We recommend that the authors improve the clarity of how the trained models can be applied to real datasets, including details on data standardization and scaling methods. A more thorough exploration of the limitations, particularly regarding the realism of synthetic datasets and the model's performance on complex processes, is necessary. We also suggest enhancing the numerical experiments to include comparisons with state-of-the-art methods and a detailed analysis of model behavior across a broader range of parameters. Furthermore, addressing the questions raised about the scaling of data and the behavior of the model with varying numbers of states would strengthen the manuscript.