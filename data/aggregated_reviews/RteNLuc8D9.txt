ID: RteNLuc8D9
Title: Dynamic Personalized Federated Learning with Adaptive Differential Privacy
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 8, 8, 5, 5, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 4, 1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an adaptive method for Personalized Federated Learning with Differential Privacy (DP-PFL) that addresses inflexibility and convergence difficulties. The authors propose a dynamic personalization strategy using layer-wise Fisher information to retain informative local parameters and mitigate noise perturbation. Additionally, they introduce an adaptive approach that applies differential constraint strategies to enhance convergence. Empirical results on CIFAR-10 and FEMNIST datasets demonstrate the method's effectiveness in improving personalization performance and robustness against clipping.

### Strengths and Weaknesses
Strengths:
- The authors tackle a significant challenge in personalized federated learning, offering a balance between model personalization, privacy protection, and noise impact.
- The introduction of Fisher information values for dynamic parameter selection is a novel approach that enhances flexibility in personalization.
- The literature review is comprehensive, and the experimental results show promising performance compared to state-of-the-art methods across various settings.

Weaknesses:
- The analysis of complexity in Section 3.3 is insufficient, focusing only on the number of parameters without considering dataset size.
- The discussion on potential adverse societal impacts is limited, and the rationale behind certain adaptive differential privacy components lacks clarity.
- Experiments are primarily conducted on simple datasets, and further validation on larger datasets is necessary to assess real-world applicability.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the potential adverse societal impacts of their methodology to provide a more comprehensive analysis. Additionally, we suggest that the authors elaborate on the motivation for preserving parameters with high Fisher values and how these enhance the personalization process in federated learning. It would also be beneficial to conduct further experiments on larger datasets to validate the model's effectiveness at scale. Finally, we encourage the authors to provide a more thorough analysis of the computational costs associated with their approach, particularly in relation to deep models.