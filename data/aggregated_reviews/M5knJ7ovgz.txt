ID: M5knJ7ovgz
Title: MRRL: Modifying the Reference via Reinforcement Learning for Non-Autoregressive Joint Multiple Intent Detection and Slot Filling
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method, Modifying the Reference via Reinforcement Learning (MRRL), to non-autoregressively solve multi-intent joint detection and slot filling. The authors identify two main issues in existing non-autoregressive approaches: the multi-modality problem and the lack of alignment between predictions for intent detection and slot filling. MRRL modifies the reference based on model outputs to provide better training targets and introduces a compromise reward to balance the two tasks. The method shows significant performance improvements, achieving state-of-the-art results on two benchmarks.

### Strengths and Weaknesses
Strengths:
- The writing is clear, and the experiments are extensive.
- The proposed method can be easily applied to existing approaches.
- The architecture is straightforward, and the results demonstrate significant performance improvements.

Weaknesses:
- The authors need to clarify the differences between golden labels and the modifier's outputs, providing evidence for why the latter serves as a better training target.
- More evidence is required to support the claim that the compromise reward effectively aligns predictions between the two tasks.
- Additional analysis is necessary to demonstrate the necessity of the modifier module and the benefits of using reinforcement learning directly on base models.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their writing, particularly by reducing the content on related work and background in Section 2. Additionally, they should enhance Table 2 to clearly separate the baselines, proposed models, and other models for easier comprehension. Further analysis should be conducted to illustrate how the proposed method addresses the issues of misalignment and multi-modality. Lastly, providing quantitative and qualitative insights into the convergence and performance of RL-aided models would strengthen the paper's claims.