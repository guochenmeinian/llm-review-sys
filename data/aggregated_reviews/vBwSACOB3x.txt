ID: vBwSACOB3x
Title: Neural Algorithmic Reasoning Without Intermediate Supervision
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 6, 4, 5, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 4, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for neural algorithmic reasoning that operates without intermediate supervision, addressing the challenge of executing algorithms solely based on input-output pairs. The authors propose a modified no-hint reasoning scheme and a self-supervised objective utilizing a contrastive loss term to ensure that similar inputs yield consistent representations across algorithmic steps. The method reportedly achieves competitive results on a subset of the CLRS benchmark, indicating its potential for broader applications in algorithmic reasoning. Additionally, the paper provides a comparative analysis of "no-hint" and hint-based models, emphasizing that the "no-hint" structure primarily adds two linear layers, thereby increasing network capacity. The authors clarify the roles of the encoder and decoder in their model, noting that the latent representation consists of logits for edges, trained solely on output supervision. They argue that while both hint supervision and invariance methods have costs, the latter may align better with model architectures.

### Strengths and Weaknesses
Strengths:  
- The paper tackles an important problem in neural algorithmic reasoning, clearly articulating its motivation and relevance.  
- The proposed method demonstrates competitive performance against fully supervised benchmarks, with promising results and comprehensive evaluations.  
- The clarity of writing and the provision of source code enhance reproducibility.  
- The authors provide a clear explanation of the "no-hint" model's structure and its implications for network capacity.  
- The discussion on the costs associated with hint supervision versus invariance methods is insightful and well-articulated.  
- The authors are open to incorporating additional experiments and clarifications based on reviewer feedback.

Weaknesses:  
- The explanation of the method, particularly regarding Hint-ReLIC, lacks clarity and coherence, making it difficult for readers to follow.  
- Experimental details are insufficiently explained, with missing values in tables and unclear reasons for identical results across different random seeds.  
- The originality of the approach is questioned, as many concepts are borrowed from previous work without sufficient differentiation.  
- The method's applicability appears limited, primarily effective for sorting algorithms, raising concerns about its generalizability.  
- There is a significant gap in empirical evaluation, particularly regarding non-fully connected graphs, which raises concerns about the robustness of the proposed approach.  
- Some reviewers express skepticism about the claims regarding the relative difficulty of finding invariances compared to building hints.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the method's explanation, particularly regarding Hint-ReLIC, by consolidating relevant information in a dedicated section. Additionally, please provide more detailed experimental descriptions, including the rationale for missing values in Table 1 and the identical results across different random seeds. It would be beneficial to clarify the architectural differences between the proposed "no-hint" and original methods, including relevant hyperparameters. We also suggest conducting ablation studies to explore the method's performance across a wider range of algorithms beyond sorting, and to address the potential limitations of the self-supervised term in relation to algorithmic dynamics. Furthermore, we recommend improving the empirical evaluation by including experiments on non-fully connected graphs to strengthen the validation of the approach. Lastly, we encourage the authors to clarify the distinctions between the no-hint model and the model with the contrastive term in the text, and to consider and mention specific sparse architectures in their evaluation to address the performance gap noted by reviewers.