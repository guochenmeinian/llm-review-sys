ID: dxxj4S06YL
Title: Fair Secretaries with Unfair Predictions
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 7, 5, 8, 6, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study of algorithms for the secretary problem with predictions, focusing on fairness. The authors define an algorithm as fair if it can accept the best candidate with at least a constant probability, addressing the shortcomings of existing algorithms that may lead to zero probability of selecting the best candidate. The proposed algorithm, based on a pegging idea, ensures both fairness and competitive performance, and it can be extended to the k-secretary problem. Extensive experiments demonstrate its advantages over state-of-the-art (SOTA) algorithms in terms of fairness and competitive ratios.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant issue by investigating algorithmic fairness in the context of biased machine-learned predictions, proposing a novel algorithm to tackle these fairness concerns.
- The pegging idea utilized in the algorithm's design is both innovative and effective, with potential extensions to the k-secretary problem.
- Empirical results convincingly show the proposed algorithm's superiority over SOTA learning-augmented algorithms regarding fairness and competitiveness.

Weaknesses:
- The fairness definition is somewhat vague, particularly regarding its application when the best and second-best candidates have closely valued utilities. A more thorough discussion and validation of this definition would enhance clarity.
- The trade-off between smoothness and fairness is not adequately explored, raising questions about the flexibility of the algorithm to adjust this trade-off.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the fairness definition, particularly in scenarios where the top candidates have similar values, to ensure it is comprehensively validated. Additionally, the authors should discuss the inherent trade-off between smoothness and fairness more explicitly, including whether the current algorithm can be tuned to achieve different balances between these two metrics. Furthermore, we suggest enhancing the presentation of the algorithm, particularly by defining I_pegged formally and clarifying the initial conditions for Algorithm 1 to improve readability. Lastly, including a simple example of unfairness in existing methods within the main text could better illustrate the shortcomings of prior approaches.