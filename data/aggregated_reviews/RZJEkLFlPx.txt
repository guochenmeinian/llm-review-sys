ID: RZJEkLFlPx
Title: ClimateLearn: Benchmarking Machine Learning for Weather and Climate Modeling
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 6, 6, 8, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ClimateLearn, an open-source PyTorch library designed to manage various weather datasets and support machine learning applications in weather forecasting, climate prediction, and downscaling. The authors propose an end-to-end pipeline that consolidates models and datasets, aiming to democratize machine learning research in this domain. The library includes basic model implementations and evaluation metrics, facilitating standardized comparisons across different tasks. The authors also introduce a new subset, "Extreme-ERA5," for extreme weather forecasting and discuss the flexibility of the library in accommodating different datasets and tasks. They acknowledge the importance of the climate contribution, which builds on existing benchmarks like ClimateBench, and propose to enhance the library by expanding its tasks beyond weather forecasting, climate projection, and climate downscaling.

### Strengths and Weaknesses
Strengths:  
- ClimateLearn unifies access to multiple weather datasets, simplifying the process for non-experts.  
- It provides model implementations that enable practitioners to quickly engage with the tools.  
- The library supports easy extension to new models, tasks, and datasets, enhancing its usability.  
- The authors have addressed reviewer concerns by clarifying methodologies and improving the paper's clarity.  
- The paper is recognized for its utility in helping ML and weather researchers engage with the subject matter.

Weaknesses:  
- The datasets are downsampled to coarse resolutions, limiting their utility for scientific applications.  
- The variable sets are small, which may hinder the performance of machine learning models.  
- The library lacks advanced state-of-the-art (SoTA) models and complex baselines, which could enhance its utility.  
- The name "ClimateLearn" may be misleading, as it does not fully convey the library's focus on both weather and climate.  
- The climate contribution is perceived as lacking novelty, primarily relying on existing benchmarks.  
- Concerns exist regarding the practicality of extending the package for high-resolution datasets, including issues related to GPU memory and I/O bottlenecks.  
- The transferability of findings from coarse to fine resolutions is not trivial and remains uncertain.  
- The effect of distribution shifts on transfer learning is mentioned but not explored in depth.

### Suggestions for Improvement
We recommend that the authors improve the resolution and variable sets of the datasets to better serve scientific needs. Additionally, we suggest including more challenging baselines, such as FourCastNet and Pangu-Weather, to enhance the library's benchmarking capabilities. We encourage the authors to clarify how ClimateLearn differentiates itself from existing frameworks like CliMetLab and consider expanding the range of supported tasks beyond the current limitations. Furthermore, we advise that the authors provide more thorough documentation for the "Extreme-ERA5" dataset and ensure that the definitions used for extreme weather events are robust and well-evaluated. To improve clarity regarding the library's contributions, we recommend considering a name change to "AtmosphereLearn" to better reflect its dual focus. We also suggest enhancing the novelty of their climate contributions by incorporating more original methodologies or datasets rather than relying heavily on existing benchmarks. Finally, we recommend that the authors discuss the implications of transferability between coarse and fine resolutions more thoroughly and explore the topic of distribution shifts to enhance the paper's depth.