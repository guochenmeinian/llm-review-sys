ID: ktTSji9ZIs
Title: Multi-task learning with summary statistics
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 6, 7, 5, 6, 5, -1, -1, -1
Original Confidences: 3, 2, 4, 2, 3, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a multi-task learning framework that utilizes summary statistics instead of individual-level data, addressing constraints in healthcare and biomedical research. The authors propose a linear model with a regularized least-squares optimization framework, emphasizing that only summary statistics are necessary for implementation. A significant contribution is the theoretical analysis bounding the quality of sparse or low-rank estimators, considering factors like overlap and distributional shifts between discovery and proxy datasets. The paper also discusses hyperparameter tuning through Lepskiâ€™s method, which is practical when only summary-level data is available. Experiments conducted on simulated data align with the theoretical findings.

### Strengths and Weaknesses
Strengths:
- The approach is relevant given tightening regulations on sharing individual-level data.
- The formulation of the multi-task summary statistic learning problem is novel, providing new insights into the effects of discovery and proxy data on learning.
- The analysis of both L1,2 and nuclear norm regularization variants is commendable.
- The proposed hyperparameter tuning method offers a practical solution for scenarios lacking individual data.
- The writing is generally clear and technically rigorous.

Weaknesses:
- The paper lacks convincing real-world applications or benchmark datasets that validate the assumptions of the learning setting.
- There are no experiments conducted on real-world data to demonstrate the approach's benefits.
- The reliance on linearity in the underlying model and task relationships is somewhat restrictive.

### Suggestions for Improvement
We recommend that the authors improve the practical relevance of their work by including real-world examples or benchmark datasets that align with the proposed learning setting. Additionally, conducting experiments on actual data would enhance the understanding of the method's applicability. Clarifying the assumption regarding the separation of discovery and proxy datasets would also be beneficial. Furthermore, addressing the limitations of linearity in the model and exploring potential extensions to non-linear models could broaden the framework's applicability. Lastly, we suggest enhancing the presentation by clearly defining terms and improving the overall structure for better clarity.