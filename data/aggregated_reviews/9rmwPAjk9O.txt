ID: 9rmwPAjk9O
Title: Gradient-Free Kernel Stein Discrepancy
Conference: NeurIPS
Year: 2023
Number of Reviews: 6
Original Ratings: 4, 8, 4, 6, -1, -1
Original Confidences: 3, 3, 4, 3, -1, -1

Aggregated Review:
### Key Points
This paper presents a method to estimate the kernel Stein discrepancy (KSD) without requiring gradients, introducing the gradient-free kernelized Stein discrepancy (GF-KSD). The authors leverage a Stein operator developed by Han and Liu (2018) and establish sufficient conditions for the divergence to control and detect convergence. The empirical evaluation extends the application of GF-KSD to Stein importance sampling and Stein variational inference, surpassing previous work. The paper also discusses the theoretical properties of GF-KSD and its limitations.

### Strengths and Weaknesses
Strengths:
- The introduction of GF-KSD fills a significant gap in the literature by establishing conditions for detecting convergence of empirical distributions.
- Theoretical and empirical results are well-discussed, with limitations thoroughly examined and supported by evidence.
- The writing is clear, with well-structured motivations and discussions.

Weaknesses:
- The paper is not clearly written for those unfamiliar with the field, leading to confusion about prior work and the applicability of the method.
- Empirical results primarily focus on low-dimensional toy examples, raising concerns about the method's performance in more complex, high-dimensional scenarios.
- Certain mathematical definitions and properties are either undefined or under-discussed, impacting the clarity of the theoretical contributions.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing to ensure accessibility for readers unfamiliar with the field. Specifically, they should clarify whether similar methods have been published and elaborate on the limitations of the GF-KSD approach. Additionally, we suggest conducting empirical evaluations on higher-dimensional problems to validate the method's applicability in realistic scenarios. Addressing the numerical instability issue noted in Section 4.2 is crucial, particularly in high-dimensional contexts. Finally, the authors should provide a clearer characterization of the class of target distributions for which Theorem 2 applies, as well as the practical construction of auxiliary distributions that satisfy its assumptions.