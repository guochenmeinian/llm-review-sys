ID: RUTmwmSVwf
Title: Bit-mask Robust Contrastive Knowledge Distillation for Unsupervised Semantic Hashing
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Bit-mask Robust Contrastive Knowledge Distillation (BRCD) method, which addresses the limitations of existing knowledge distillation approaches in the context of semantic hashing. The authors propose a framework that optimizes a lightweight "student" model to replicate a more complex "teacher" model while refining the hash function to ensure semantically similar images are closer in Hamming space. The empirical study demonstrates that the BRCD model outperforms state-of-the-art image hashing algorithms.

### Strengths and Weaknesses
Strengths:
- The paper identifies shortcomings in previous methods and proposes a novel framework to address these issues.
- It is well-written and easy to follow, with a clear motivation and interesting observations.
- Extensive experiments are conducted across multiple datasets, showcasing the effectiveness of the proposed method.

Weaknesses:
- The experimental analysis lacks sufficient rigor, particularly in the need for significance testing and comparisons at smaller cutoff values.
- The rationale for using CIFAR-10 as a dataset is unclear, especially given its simplicity.
- The absence of source code may hinder reproducibility.

### Suggestions for Improvement
We recommend that the authors improve the experimental analysis by including significance tests to clearly demonstrate performance differences, particularly between KL and BRCD. Additionally, we suggest providing comparisons with smaller cutoff values, such as @K=10 and @K=50, to address potential position/click bias. The authors should clarify the choice of CIFAR-10 and analyze the performance of BRCD on more complex datasets. Furthermore, we encourage the inclusion of the source code to enhance reproducibility. Lastly, we recommend a more detailed discussion on the effects of the clustering method and the parameters alpha and sigma, including their optimal values for different datasets.