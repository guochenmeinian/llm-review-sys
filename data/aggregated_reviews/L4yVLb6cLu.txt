ID: L4yVLb6cLu
Title: Hi-ToM: A Benchmark for Evaluating Higher-Order Theory of Mind Reasoning in Large Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Hi-ToM, a new benchmark for evaluating higher-order Theory of Mind (ToM) reasoning in large language models (LLMs). It includes stories with questions up to fourth-order ToM, requiring comprehensive understanding of complex narratives. The dataset is generated from scripts with manual verification, and experiments with models like GPT-3.5, GPT-4, Claude, and Guanaco reveal performance declines as ToM order increases, particularly with deceptive communications. The authors provide a detailed analysis of these results, highlighting limitations in recursive reasoning and suggesting implications for future LLM developments.

### Strengths and Weaknesses
Strengths:
- The authors explore a relevant cognitive theme by constructing and validating a higher-order ToM benchmark, which could serve as a valuable resource for evaluating LLMs.
- The evaluation of state-of-the-art LLMs demonstrates significant performance gaps on the proposed benchmark.
- The analysis of experimental results offers thoughtful insights into the challenges faced by LLMs in complex reasoning tasks.

Weaknesses:
- Concerns arise regarding the validity of story-grounded question-answering benchmarks in genuinely assessing LLMs' ToM abilities, as LLMs may rely on linguistic patterns rather than cognitive processes.
- The Hi-ToM dataset is relatively small, with only 146 samples, raising questions about its robustness, and implementation details for question and answer generators are insufficiently explained.
- The rationale for incorporating deceptive communications in agent interactions is not adequately justified, and the necessity of higher-order ToM in generalist LLMs is questioned.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the limitations of story-grounded benchmarks in assessing LLMs' ToM capabilities, addressing concerns about reliance on linguistic patterns. Additionally, the authors should consider expanding the Hi-ToM dataset to enhance its validity and provide more detailed implementation information for the question and answer generators. Clarifying the motivation behind the use of deceptive communications in agent interactions is essential, as is justifying the necessity of higher-order ToM for generalist LLMs. Lastly, we suggest integrating the content of Section 6 into the introduction to streamline the paper's structure.