ID: nvX3MiQM0G
Title: State-Action Similarity-Based Representations for Off-Policy Evaluation
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 6, 7, 5, 5, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new diffuse-metric for measuring behavioral similarity between state-action pairs for off-policy evaluation (OPE), named ROPE. ROPE enhances state-action representations using offline data, theoretically bounding the OPE error. Empirical results indicate that ROPE improves the data-efficiency of fitted Q-evaluation (FQE) and achieves lower OPE error compared to existing OPE-based representation learning algorithms. The authors claim this is the first successful application of representation learning to enhance data-efficiency in OPE.

### Strengths and Weaknesses
Strengths:
1. The paper introduces a novel application of representation learning to improve data-efficiency in OPE, marking a significant contribution to the field.
2. The research on related works is comprehensive, and the mathematical proofs are rigorous and interesting.
3. The main body of the paper is well-written and easy to follow.
4. The proposed method significantly enhances the data-efficiency of OPE methods.

Weaknesses:
1. While the writing is generally clear, there are areas that require improvement, particularly in the appendix.
2. Plots could be enhanced by improving the color scheme for colorblind accessibility.
3. There are several misprints in the text that need correction.
4. The paper lacks a clear discussion on why learning state-action representations is easier than directly performing OPE.
5. Some experimental results and analyses are superficial, and the advantages of the proposed method over baselines are not always evident.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the discussion regarding the benefits of learning state-action representations for data-efficiency in OPE. Additionally, including visual aids and algorithms in the main text would facilitate understanding. The authors should also provide supplementary explanations of the methods referenced and clarify the relationship between ROPE and existing works. Furthermore, a more intuitive introduction of the other OPE-based representation learning methods and a detailed analysis of experimental results would enhance the paper's comprehensiveness. Lastly, addressing the identified misprints and improving the plots for accessibility would strengthen the presentation.