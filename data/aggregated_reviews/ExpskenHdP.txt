ID: ExpskenHdP
Title: StereoMap: Quantifying the Awareness of Human-like Stereotypes in Large Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework called StereoMap for assessing stereotypes encoded in large language models (LLMs), grounded in the Stereotype Content Model (SCM) from social psychology. The framework involves measuring two dimensions of social groups: warmth and competence, and applies this analysis to various LLMs, including Google Bard and OpenAI models. The authors aim to align model outputs with established psychological stereotypes.

### Strengths and Weaknesses
Strengths:  
- The incorporation of established psychological theories (SCM) provides a solid theoretical foundation for measuring stereotypes in LLMs.  
- The paper is well-written and addresses key points expected in such research, contributing to the NLP community's understanding of stereotypes.  
- Reviewers appreciated the interdisciplinary approach and sound methodology.

Weaknesses:  
- Concerns exist regarding the reliability of results derived from prompts that directly ask models to evaluate warmth and competence, potentially leading to biased outputs.  
- The study's experimental design may be impacted by the selection of prompts, which could affect the validity of the findings.  
- Some unexpected results raise questions about the distribution of traits and the reliability of the model's self-assessments.

### Suggestions for Improvement
We recommend that the authors improve the robustness of their findings by conducting pilot studies or validation procedures to assess the effectiveness of the prompts used. Additionally, addressing the unexpected results, such as the high competence ratings for marginalized groups, would enhance the paper's depth. We also suggest that the authors consider incorporating a broader range of social groups and models in future work. Clarifying the distinction between the models' perceptions and societal views in their wording would strengthen the paper's claims. Finally, we encourage the authors to ensure that all references are properly cited and relevant literature is included.