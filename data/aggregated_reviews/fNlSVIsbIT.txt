ID: fNlSVIsbIT
Title: HoneyBee: Progressive Instruction Finetuning of Large Language Models for Materials Science
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an iterative instruction generation method for materials science, applicable to other scientific domains. The authors propose a two-step framework where ChatGPT generates domain-specific instructions, which are evaluated and refined by an independent evaluator, enhancing instruction quality and model performance. The resulting billion-parameter LLM, specialized in materials science, demonstrates superior performance on benchmarks compared to existing models. The paper also introduces MatSci-Instruct, a framework for generating training data using various commercial LLMs, and fine-tunes a LLaMa model named HoneyBee for materials science NLP tasks.

### Strengths and Weaknesses
Strengths:
- The two-step framework effectively generates trustworthy instructions in scientific domains, showing effectiveness in materials science.
- The billion-parameter HoneyBee model is a valuable resource, outperforming existing models in materials science.
- The iterative approach allows for continuous improvement of domain-specialized models.

Weaknesses:
- The paper lacks motivation for the proposed approach and justification for design choices.
- Insufficient details on the data generation process hinder assessment of its correctness and generalizability.
- The methodology is relatively straightforward and lacks novelty compared to existing approaches.
- The paper does not adequately analyze the computational resources required for training and fine-tuning.

### Suggestions for Improvement
We recommend that the authors improve the motivation and justification for their approach, addressing why existing knowledge distillation methods are ineffective for scientific domains. Additionally, please provide a detailed analysis of the computational resources required for training and fine-tuning. Clarifying the data generation process and ensuring consistency in terminology throughout the paper would enhance clarity. We also suggest including a comparison of HoneyBee's performance against ChatGPT on the benchmark dataset to better inform practitioners. Lastly, a careful revision of the manuscript for clarity and inclusion of missing details is essential.