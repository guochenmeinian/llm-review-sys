ID: eVAzmJgrAc
Title: Lost in Translation: Benchmarking Commercial Machine Translation Models for Dyslexic-Style Text
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 2, 4, 4
Original Confidences: 5, 4, 4

Aggregated Review:
### Key Points
This paper presents an evaluation of how well commercial machine translation (MT) systems handle dyslexic-style text, focusing on the generation of synthetic dyslexic data through established perturbation techniques. The authors benchmark major MT services, revealing significant challenges in translating dyslexic errors, which raises concerns about the inclusivity and fairness of AI systems.

### Strengths and Weaknesses
Strengths:
- The paper addresses the critical issue of AI system fairness for dyslexic users and introduces an automated benchmark construction method.
- It highlights the suboptimal performance of state-of-the-art MT systems in handling dyslexic-style text.
- The writing is clear and effectively communicates the research findings.

Weaknesses:
- The method for constructing synthetic dyslexic data lacks novelty and rigorous verification, relying heavily on existing approaches.
- The evaluation is limited to commercial MT models, omitting open-source alternatives, which diminishes the comprehensiveness of the findings.
- The paper does not provide sufficient human evaluation or analysis of the underlying causes of errors, leading to a lack of convincing evidence for its conclusions.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their approach by clearly differentiating their method from existing ones and providing a thorough comparison. Additionally, it is crucial to verify the quality of the generated dyslexic data and its relevance to real-world applications. Incorporating human evaluation, possibly using a framework like MQM, would enhance the credibility of the findings. The authors should also consider expanding their evaluation to include open-source models and additional metrics, such as COMET, to provide a more comprehensive analysis. Finally, further clarification on the "Confusion set" error type and the interpretation of evaluation figures would strengthen the paper.