ID: Pk49a9snPe
Title: ViCA-NeRF: View-Consistency-Aware 3D Editing of Neural Radiance Fields
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 4, 5, 6, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for editing 3D scenes using text prompts, focusing on achieving 3D consistency through a two-stage process. The authors propose a diffusion model to perform 2D edits on key views, which are then optimized for 3D representation. Two regularization techniques are introduced: geometric regularization via depth-aware warping and learned regularization by aligning latent codes. The method is evaluated against two baselines, demonstrating improvements in 3D consistency. The authors argue that the blurriness observed in results is primarily due to the smoothing of high-frequency information during 2D editing with the IP2P diffusion model, rather than the averaging component. They acknowledge that while some results may appear blurry, others demonstrate improved clarity and realism, as validated by user studies. The authors emphasize the importance of achieving 3D consistency, which they consider a unique challenge in the field.

### Strengths and Weaknesses
Strengths:
- The paper addresses the critical issue of 3D consistency in text-based editing, which is lacking in existing methods.
- The proposed method exhibits sufficient novelty with various new components compared to the baseline.
- The depth-aware warping regularization is a reasonable approach.
- The method's efficiency is notable, reportedly being three times faster than the baseline, IN2N.
- Experimental results indicate better 3D consistency than the baseline.
- User studies indicate that the method produces more realistic results, with significantly higher scores in text faithfulness and diversity.
- The authors provide innovative solutions to mitigate blurriness, such as using SAM for segmentation masks and depth-guided propagation.

Weaknesses:
- The visual quality of the proposed method is questionable, with results appearing blurry and lacking detail, raising concerns about the overall quality.
- Some results are perceived as very blurry and unrealistic, which could undermine the method's effectiveness.
- The method section lacks clarity, making it difficult to follow, with some details missing or poorly explained. Diagrams are too general to aid understanding.
- Keyframe selection and editing processes are not well-defined, raising questions about their independence and sequential editing.
- The limitations section could benefit from visualizations of failure cases, particularly those not encountered in IN2N.
- Despite the authors' rebuttal, the method section requires significant refinement for clarity, as some reviewers found it ambiguous.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the method section by providing more detailed explanations and clearer diagrams. Additionally, addressing the visual quality issues by analyzing the sources of blurriness and considering alternatives to the averaging of latent codes would be beneficial. We suggest that the authors clarify the keyframe selection process and whether keyframes are edited independently or sequentially. Including visualizations of failure cases would enhance the limitations discussion. Furthermore, we recommend that the authors provide a more comprehensive comparison of final rendered results with and without averaging to substantiate their claims regarding clarity. Lastly, conducting experiments to determine the optimal number of keyframes for effective editing could strengthen the paper's contributions.