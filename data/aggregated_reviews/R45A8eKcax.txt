ID: R45A8eKcax
Title: Scaling MLPs: A Tale of Inductive Bias
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 4, 8, 6, 6, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 3, 5, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive study and empirical evaluation of the scaling capabilities of Multi-Layer Perceptrons (MLPs) in the context of image classification tasks, particularly on ImageNet. The authors challenge the conventional belief regarding MLPs' performance limitations by demonstrating that they can achieve competitive results when scaled appropriately, utilizing modern deep learning components such as normalization layers, skip connections, and bottlenecks. The findings suggest that while MLPs lack inherent inductive bias, this limitation can be effectively compensated for with data augmentation and sufficient data volume. The authors acknowledge that their best model's test accuracies do not fully indicate that MLPs will overcome the lack of inductive bias for complex tasks, yet they provide evidence predicting that MLPs could achieve approximately 71% test accuracy with sufficient compute. They emphasize that their results are competitive, particularly given the constraints of using a resolution of $64 \times 64$ and less powerful linear probes, and they aim to contribute to the theoretical understanding of MLPs by providing data points on their performance in modern settings.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant research gap by empirically validating the hypothesis that inductive bias can be circumvented with increased data.
- The experiments are thorough and well-executed, providing convincing results and transparent analyses.
- The writing quality is excellent, with clear communication of ideas and methods.
- The results on smaller datasets are remarkable, and the improvement on ImageNet is strong.
- The authors maintain a cautious approach regarding potential performance on ImageNet, avoiding overclaims.

Weaknesses:
- The interpretation of experimental results raises concerns, particularly regarding the strength of claims made about MLPs' performance on ImageNet.
- There is insufficient evidence to conclusively suggest that properly scaled MLPs will achieve near state-of-the-art performance on ImageNet.
- The paper lacks discussions on the importance of processing images in patches and the effects of image resolution on results.
- Hyperparameters such as learning rate and weight decay are not carefully tuned, potentially affecting the validity of the observed trends.
- The authors acknowledge limitations in their ability to empirically demonstrate scaling at large scales due to resource constraints.

### Suggestions for Improvement
We recommend that the authors improve the interpretation of their results, particularly regarding the claims about MLPs' performance on ImageNet, and consider conducting experiments across different domains to strengthen their conclusions. Additionally, it would be beneficial to include discussions on the significance of processing images in patches and the implications of image resolution on performance. We also suggest that the authors carefully tune hyperparameters and clarify their experimental methodology, including validation set usage and training accuracies, to enhance the robustness of their findings. Furthermore, we recommend that the authors seek additional resources to empirically demonstrate scaling laws for MLPs at larger scales and provide more detailed discussions on the implications of their findings for future theoretical work to enhance the paper's contribution to the field.