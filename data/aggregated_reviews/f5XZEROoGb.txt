ID: f5XZEROoGb
Title: SubjECTive-QA: Measuring Subjectivity in Earnings Call Transcripts' QA Through Six-Dimensional Feature Analysis
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 6, 7, 6, 8, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 3, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents SubjECTive-QA, a novel dataset for analyzing subjective features in long-form question-answer pairs from Earnings Call Transcripts (ECTs). The dataset comprises 2,747 QA pairs annotated across six subjective dimensions: Assertive, Cautious, Optimistic, Specific, Clear, and Relevant. The authors benchmark various pre-trained language models (PLMs) and large language models (LLMs), finding that RoBERTa-base performs best overall. They demonstrate the dataset's generalizability by testing on White House Press Briefings, achieving an average weighted F1 score of 65.97%. The work addresses the gap in manually annotated datasets for subjective features in formal QA settings, with applications in finance, politics, and misinformation detection.

### Strengths and Weaknesses
Strengths:
- The paper introduces a high-quality dataset that fills a significant gap in the analysis of subjective features in formal QA settings.
- The dataset is meticulously annotated by nine annotators, ensuring reliability and a rich, multi-faceted view of subjectivity.
- The authors provide a comprehensive baseline for future work by evaluating a range of models, including domain-specific models like FinBERT.
- The clarity of the paper is commendable, with detailed methodology and robust benchmarking.

Weaknesses:
- The paper lacks in-depth analysis of why certain models perform better on specific features, and a more detailed error analysis could provide valuable insights.
- There is insufficient discussion on how potential biases in annotations were mitigated and how they might impact the dataset's utility.
- The rationale for selecting the six subjective features is not rigorously justified, and the interaction between these features is not analyzed.
- The paper does not compare SubjECTive-QA to existing datasets in financial sentiment analysis, which would better contextualize its contributions.
- An analysis of how subjective features might have changed over time, given the dataset spans from 2007 to 2021, is missing.

### Suggestions for Improvement
We recommend that the authors improve the depth of analysis regarding model performance by conducting a detailed error analysis. Additionally, a thorough discussion on how potential biases in annotations were addressed would enhance the paper's credibility. We suggest providing a more rigorous justification for the selection of the six subjective features and analyzing their interactions. A comparison with existing datasets in financial sentiment analysis would contextualize the contribution of SubjECTive-QA. Finally, an exploration of how subjective features have evolved over time would provide valuable insights into the dataset's relevance.