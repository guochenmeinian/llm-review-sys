ID: NMMRH80gha
Title: Simple and Effective Input Reformulations for Translation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents three novel input formats for fine-tuning translation models, specifically targeting challenging translation tasks using pre-trained language models. The authors propose the "Partial Output English Scaffold" (POSE), "Parallel Scaffold in English" (ParSE), and "Mixed-language Parallel Scaffold" (MiPS) techniques to enhance translation performance on multilingual foundation language models like mT5. The experiments are conducted on the Flores200 translation benchmark and a Tibetan-to-English task.

### Strengths and Weaknesses
Strengths:
- The proposed techniques are straightforward and demonstrate effectiveness for both high-resource and low-resource languages.
- The paper introduces three data-efficient methods that improve translation performance and emphasizes the importance of input reformulation.
- The authors conducted exhaustive experiments to understand the applicability of the proposed techniques.

Weaknesses:
- The effect of the proposed methods is not very persuasive, lacking direct comparisons to standard fine-tuning of large language models (LLMs).
- The conditions for using each proposed technique are unclear, and the paper does not achieve performance levels comparable to dedicated multilingual translation models like NLLB.
- The structure and writing of the paper require improvement, with a need for deeper analysis and clearer technical details.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the conditions under which each data technique should be applied. Additionally, we suggest providing direct comparisons to standard fine-tuning methods to strengthen the argument for the proposed techniques' effectiveness. The authors should also enhance the paper's structure by separating methodological descriptions from the introduction and providing more detailed technical insights. Finally, addressing the questions regarding the applicability of the methods to different language pairs and the generation of guidance translations would enhance the paper's depth.