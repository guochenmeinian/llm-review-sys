ID: FGBWDf7Z19
Title: XLS-R fine-tuning on noisy word boundaries for unsupervised speech segmentation into words
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for enhancing unsupervised speech segmentation by fine-tuning the XLS-R model using labels generated from off-the-shelf unsupervised word segmentation systems, specifically DPDP, VG-HuBERT, and DP-Parse. The authors demonstrate a significant performance improvement, particularly a 130% increase when using pseudo labels from DP-Parse. This work advances the state-of-the-art in unsupervised word-level speech segmentation and contributes to the understanding of multilingual self-supervised speech models.

### Strengths and Weaknesses
Strengths:  
- The significant performance gains from simple finetuning on pseudo labels reveal interesting properties of pretrained self-supervised speech models.  
- The robustness of the proposed approach is indicated by universal improvements across different unsupervised systems.  
- Training a single model on multiple languages yields better performance than language-specific models, a phenomenon observed for the first time in smaller datasets.  
- The introduction of various techniques such as augmentation, smoothing, loss selection, and peak detection, while not novel, is applied effectively in this context.

Weaknesses:  
- The paper lacks sufficient explanations regarding the impressive zero-shot performance of DP-Parse and the discrepancies observed between different pseudo-labeling systems.  
- There is a need for ablation studies to clarify the impact of various techniques on performance.  
- The paper does not convincingly demonstrate the generalization and novelty of the proposed method, primarily showcasing the effectiveness of fine-tuning.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their results by providing detailed explanations for the zero-shot performance of DP-Parse and the discrepancies between different pseudo-labeling systems. Additionally, we suggest conducting ablation studies to analyze how different techniques, such as augmentation and loss selection, affect performance. Furthermore, the authors should investigate the generalization of their approach, particularly in relation to the performance of different SSL models on various languages. Lastly, we advise including the missing references to relevant literature to strengthen the paper's foundation.