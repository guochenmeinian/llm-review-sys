ID: 1mdTYi1jAW
Title: Adjustable Robust Reinforcement Learning for Online 3D Bin Packing
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 4, 5, 7, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel adjustable robust reinforcement learning (AR2L) framework aimed at solving the online 3D Bin Packing Problem (3D-BPP). The authors propose a permutation-based adversary to evaluate packing policies under worst-case scenarios, optimizing a weighted sum of expected and worst-case returns. The framework includes two algorithms: an exact version that requires training a hybrid dynamics adversary and an approximate version that samples from the original dynamics. Additionally, the authors focus on the robustness of the packing policy, utilizing a heuristic method for candidate generation due to challenges in reproducing the baseline method PCT. They emphasize the importance of maintaining consistent candidate generation across all approaches to ensure fair comparisons and acknowledge the need for thorough replication of baseline performance. The authors also highlight the potential benefits of incorporating challenging instances during training to improve generalization. Experimental results demonstrate the effectiveness of the AR2L framework across discrete and continuous settings.

### Strengths and Weaknesses
Strengths:
- The problem addressed is significant, extending the state-of-the-art PCT algorithm to enhance worst-case performance through an adversarial approach.
- The paper is well-organized, demonstrating a strong understanding of packing and reinforcement learning, supported by clear data and theory.
- The introduction of a permutation-based adversary is innovative, providing practical insights into robustness.
- The authors demonstrate a clear understanding of the packing problem and the importance of robustness in their approach.
- Extensive experiments compare the AR2L framework with multiple methods, showcasing its advantages in average performance and robustness.
- The authors are receptive to feedback and willing to clarify their methodology and findings, which adds to the paper's potential value in the packing problem research community.

Weaknesses:
- The paper lacks a detailed analysis of the experimental results, particularly regarding the metrics Std and Num in Table 2, with insufficient exploration of computational complexity.
- The attacker’s capacity is questioned; it only permutes one item rather than the entire sequence, limiting its effectiveness.
- There is no guidance on selecting hyperparameters α and ρ, and the optimal configurations for real-world applications remain unclear.
- The empirical results are not consistently convincing, with some instances where AR2L underperforms compared to baselines like RARL.
- There is a lack of persuasive experimental results in the current version, leading to concerns about the empirical evaluations.
- Inconsistencies in performance metrics, particularly regarding standard deviations and the impact of varying the parameter α, raise questions about the robustness of the findings.
- The authors' explanations for observed phenomena may not fully convince reviewers of their validity.

### Suggestions for Improvement
We recommend that the authors improve the clarity and detail of the analysis for Table 2, particularly regarding Std and Num metrics. Additionally, a thorough examination of computational complexity should be included. To enhance the attacker's capacity, consider allowing it to permute the entire sequence of observable items rather than just one. We also suggest providing guidelines for selecting hyperparameters α and ρ, as well as discussing the implications of these choices on performance. Furthermore, we urge the authors to replicate the performance of existing methods using the latest official implementation of PCT to strengthen their empirical evaluations. Addressing the observed inconsistencies in standard deviations and providing more detailed explanations regarding the rationale behind the selection of α will also enhance the paper's contributions. Finally, addressing the empirical results more comprehensively, particularly in cases where AR2L underperforms, would strengthen the paper's contributions.