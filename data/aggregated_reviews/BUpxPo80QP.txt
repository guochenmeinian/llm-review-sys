ID: BUpxPo80QP
Title: InterDreamer: Zero-Shot Text to 3D Dynamic Human-Object Interaction
Conference: NeurIPS
Year: 2024
Number of Reviews: 20
Original Ratings: 7, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework, InterDreamer, aimed at generating text-conditioned 3D human-object interactions (HOIs) without relying on paired text-interaction data. The authors propose a multi-stage approach that includes high-level planning using large language models (LLMs) and low-level control through existing text-to-motion methods, ultimately optimizing interactions with a world model. The authors emphasize that many visual artifacts observed in their results stem from limitations in the BEHAVE dataset, particularly regarding hand motion and dexterity. Evaluated on the BEHAVE and CHAIRS datasets, InterDreamer demonstrates the capability to produce coherent and text-aligned HOI sequences, addressing the limitations of existing motion capture data. The authors argue that their method, which allows for free-form text input, is inherently more challenging than existing supervised methods, yet achieves comparable or fewer artifacts. They also highlight their decoupling strategy and integration of dynamics models as significant contributions to the field.

### Strengths and Weaknesses
Strengths:
- The authors introduce a novel task of synthesizing whole-body interactions with dynamic objects guided by textual commands, effectively reducing dependence on large-scale interaction datasets.
- The integration of a decoupling strategy and dynamics models is innovative and may inspire future research.
- The framework's decoupling of interaction semantics and dynamics is a sound approach to understanding human-object interaction positions.
- The technical details are robust, and the experimental results indicate zero-shot capabilities.
- The response to reviewer feedback demonstrates a commitment to improving clarity and addressing concerns.

Weaknesses:
- The framework struggles with complex long interactions, such as a person walking to a chair and sitting down.
- Visual quality issues remain, including floating objects and interpenetration, which detract from the overall realism.
- The novelty of the method is limited, as it primarily combines existing techniques without sufficiently highlighting differences, with some reviewers viewing the use of LLMs for preprocessing as less innovative.
- Several details are missing, including the dataset construction process and the training requirements for low-level control.
- The motivation for certain quantitative experiments is unclear, and the definitions of specific terms, such as vertex-based control and "full state," are lacking.
- The manuscript's clarity is insufficient, with some explanations placed far from relevant content, leading to confusion.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by providing more detailed descriptions of the query protocol for the high-level planning module and explicitly stating how each stage differs from existing methods. Additionally, the authors should clarify the dataset construction process and the training requirements for low-level control. It would be beneficial to elaborate on the motivation behind the quantitative experiments and provide definitions for terms like vertex-based control and "full state." We also suggest enhancing the visual quality of the generated results by addressing the artifacts related to hand motion and dexterity in the BEHAVE dataset. Lastly, ensuring that explanations are coherent and logically placed within the text, and addressing the handling of complex and long sequences would enhance the overall writing quality and clarity of the manuscript.