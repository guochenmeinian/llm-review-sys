ID: ddEkATzwiD
Title: Leveraging Passage Embeddings for Efficient Listwise Reranking with Large Language Models
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the PE-Rank framework, which enhances the efficiency of listwise reranking while maintaining competitive performance. It integrates passage embeddings as a context compression method and employs a two-stage training strategy alongside dynamic constrained decoding to optimize reranking. The originality lies in addressing input length constraints and improving output formatting.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written, logically structured, and accessible to a broad audience.
2. The integration of context compression techniques to overcome input length limitations is innovative.
3. Detailed experiments analyze the efficiency of PE-Rank, demonstrating its competitive ranking performance.
4. The clever use of dynamic constrained decoding ensures the uniqueness of ranked passages without requiring post-processing.

Weaknesses:
1. The methodology description lacks clarity, particularly regarding the 'special token' and its implications for retrieval performance.
2. PE-Rank's performance does not surpass models like RankGPT, which may limit its applicability in scenarios where retrieval accuracy is crucial.
3. The paper suffers from readability issues due to inconsistent symbols and incomplete descriptions, making it hard to follow.
4. The dynamic-constrained decoding strategy, while ensuring local optimality, does not guarantee global optimality.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the methodology description, particularly regarding the 'special token' and its impact on retrieval performance. Additionally, the authors should provide a clearer explanation of the performance comparison with RankGPT and address the readability issues by ensuring consistent symbols and complete descriptions throughout the paper. Furthermore, a discussion on the scalability of PE-Rank's effectiveness and efficiency with varying token counts would enhance the understanding of its applicability.