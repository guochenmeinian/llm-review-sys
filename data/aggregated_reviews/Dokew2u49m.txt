ID: Dokew2u49m
Title: Make Continual Learning Stronger via C-Flat
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 8, 6, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents C-Flat, a novel method aimed at mitigating catastrophic forgetting in continual learning (CL) by optimizing for a flatter loss landscape. The authors argue that this approach stabilizes the learning process and enhances model generalization across tasks by enabling the model to find and utilize flatter minima. The method is described as a plug-and-play solution that can be integrated into various existing CL approaches, and its effectiveness is demonstrated across multiple datasets.

### Strengths and Weaknesses
Strengths:
1. The introduction of C-Flat is innovative, emphasizing flatness in the loss landscape to address catastrophic forgetting, supported by extensive experimental results.
2. The theoretical analysis provided for the convergence of the proposed loss adds depth to the paper.
3. The visualization of the loss landscape effectively illustrates the impact of C-Flat, offering clear comparative insights into how it modifies learning dynamics.

Weaknesses:
1. The contribution of the paper is unclear, as it claims to be the first to compare CL methods with loss landscapes, despite existing works that have discussed flatness in CL.
2. The theoretical analysis section lacks organization, making it confusing; a clearer structure starting with assumptions followed by theorems and proofs is needed.
3. The paper does not adequately discuss the computational cost of C-Flat, which requires multiple forward and backward propagations, and the performance improvements are only slight compared to existing methods.

### Suggestions for Improvement
We recommend that the authors elaborate on the differences between their method and current CL approaches in the introduction to clarify their contributions. Additionally, we suggest restructuring the theoretical analysis section for better clarity, starting with assumptions and followed by theorems and proofs. It would also be beneficial to include a discrete limitations section in the conclusion and to report the average performance boost alongside the maximum boost in the results section. Finally, we encourage the authors to address the computational cost of C-Flat more thoroughly and to include confidence intervals in their experimental results to substantiate claims of significance.