ID: GfITbjrIOd
Title: Human-Aligned Calibration for AI-Assisted Decision Making
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 6, 6, 7, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a theoretical framework for understanding human decision-making in AI-assisted contexts, focusing on the interaction between classifier and decision maker confidence scores. The authors demonstrate that even with calibrated AI confidence, humans may struggle to identify optimal decision-making policies. They propose "human-alignment" as a solution, achievable through multicalibration, and aim to validate these theoretical insights with empirical studies based on prior work.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and effectively motivates the need for human-centered AI design.
- It introduces an interesting problem regarding the monotonicity of confidence values and incorporates noise into the model.
- The theoretical framework contributes to understanding AI output communication, and the mathematics is sound.

Weaknesses:
- Concerns arise regarding the discretization of human confidence, particularly the use of only three bins, which may oversimplify the representation of human uncertainty.
- The empirical validation lacks clarity on design and baselines, making it difficult to understand how the results substantiate the theoretical claims.
- Limitations of the study are not adequately discussed, particularly regarding the simplicity of the model and the scope of the experiments.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the discretization of human confidence, considering finer-grained representations and justifying the choice of three bins. Additionally, we urge the authors to clarify the empirical validation design, explicitly stating the baselines and how the results relate to their theoretical insights. A more thorough limitations section should be included, addressing potential negative societal impacts and the simplicity of the model. Lastly, we suggest expanding on the connection between their findings and real-world applications, particularly in the context of LLM-based systems and multi-categorical decision-making.