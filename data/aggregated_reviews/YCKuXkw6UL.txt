ID: YCKuXkw6UL
Title: Acoustic Volume Rendering for Neural Impulse Response Fields
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 6, 7, 7, 8, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method for sound synthesis from arbitrary positions by modeling acoustic fields through an implicit neural representation that incorporates acoustic wave propagation principles. The authors employ a volume rendering technique to ensure consistency across various positions, demonstrating superior performance compared to existing methods. Additionally, a new impulse response simulation platform is introduced, which enhances the realism of impulse responses.

### Strengths and Weaknesses
Strengths:
1. The integration of volume rendering for consistency across positions is innovative, capturing detailed waveform characteristics effectively.
2. The method significantly outperforms state-of-the-art techniques, particularly in phase reconstruction.
3. The introduction of a new acoustic simulation platform is a valuable contribution to the field.

Weaknesses:
1. The network architecture is relatively small (6 layers), raising questions about the lengthy training time of 24 hours, especially when compared to faster methods in the literature.
2. The paper lacks a detailed description of the new simulation platform in the main text, which is essential for understanding its contributions.
3. Qualitative comparisons with other methods are insufficient, and the implications of design decisions on performance and runtime are not adequately discussed.

### Suggestions for Improvement
We recommend that the authors improve the clarity and detail of the new simulation platform's description in the main text. Additionally, it would be beneficial to include comparisons with prior physics-based methods to highlight the advantages of modeling wave propagation. We suggest conducting separate analyses for high-frequency versus low-frequency components and near-field versus far-field scenarios to better understand the framework's limitations. Furthermore, including synthesized audio from other methods in the supplementary material would enhance the submission's comprehensiveness. Finally, we encourage the authors to address the computational complexity and runtime of their method more thoroughly, particularly in relation to existing approaches.