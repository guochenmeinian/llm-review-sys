ID: 4czwwExZKQ
Title: ActSort: An active-learning accelerated cell sorting algorithm for large-scale calcium imaging datasets
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 5, 5, 6, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ActSort, an active learning framework designed for cell sorting in large-scale calcium imaging datasets, featuring a user-friendly software interface. The authors validate their method through extensive benchmarking involving six domain experts and approximately 160,000 candidate cells, demonstrating that ActSort significantly reduces the need for human annotation to 1%-5% while improving sorting accuracy. The framework integrates domain expert feature engineering with a novel active learning algorithm that interleaves automated classification with human labeling of informative outlier cells. Additionally, ActSort comprises three modules: preprocessing, cell selection, and active learning, and can effectively handle both one-photon and two-photon datasets without requiring retraining. The authors emphasize the importance of incorporating spatiotemporal information into the input data for enhanced performance and argue that existing deep learning approaches, such as CAIMAN, are suboptimal for one-photon movies.

### Strengths and Weaknesses
Strengths:
- The proposed active learning approach is innovative and addresses a significant bottleneck in processing large-scale calcium imaging datasets.
- The integration of domain expert knowledge enhances the robustness and accuracy of the classification.
- The software is user-friendly, allowing non-programmers to utilize it effectively.
- The empirical validation through a large-scale benchmark dataset demonstrates the method's effectiveness.
- Additional ablation studies and control experiments validate the effectiveness of the DCAL method.
- The comparison with ResNet-50 for feature extraction, despite not outperforming the authors' method, adds value to the analysis.
- Detailed analysis of manual annotation accuracy enhances understanding of data quality.
- Clear explanations regarding human performance comparisons and classifier performance are provided.
- The authors have improved the technical depth and relevance of the paper for the NeurIPS community.

Weaknesses:
- The paper lacks a thorough comparison with existing semi-automated methods, making it difficult to assess the claimed advantages of ActSort.
- There is insufficient theoretical justification for the proposed query strategy, DCAL, and a lack of systematic analysis on weight adjustments.
- The reliance on handcrafted features limits the potential for generalization to new datasets and experimental paradigms.
- The discussion of annotation noise and error is inadequate, potentially overestimating the method's performance.
- The paper does not provide sufficient details on the experimental setup, including hyperparameter selection and network architecture.
- Some reviewers express concerns about the appropriateness of the venue for this work.
- The reliance on correct cell extraction by existing algorithms may propagate errors to the sorting process.
- There is a need for further exploration of the expertise levels of annotators, as variability in their skills could affect results.

### Suggestions for Improvement
We recommend that the authors improve the theoretical justification and discussion surrounding the DCAL query strategy, including a systematic analysis of weight adjustments. Additionally, conducting a quantitative comparison with existing semi-automated cell sorting methods would strengthen the paper's claims. The authors should consider incorporating data-driven automatic feature learning capabilities, such as pre-trained models like CNNs, to enhance generalization. Addressing the issues of annotation noise and providing a more robust methodology for handling it would also be beneficial. We suggest that the authors improve the Discussion section by including more details on extending ActSort to other data modalities and reducing repetition of ActSort's strengths. Furthermore, we encourage the authors to visualize the decision boundary in Fig. 3A and clarify the reasoning behind the distance metric change in Fig. N3, as well as update Fig. N5 to a log scale. Finally, exploring the potential for merging segmented or duplicated cells in future versions of ActSort to mitigate errors from the cell extraction step would be advantageous.