ID: L3RYBqzRmF
Title: Counter-Current Learning: A Biologically Plausible Dual Network Approach for Deep Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 21
Original Ratings: 6, 4, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 2, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a counter-current learning (CCL) framework, inspired by biological mechanisms, to address critiques of backpropagation (BP) regarding biological plausibility. The authors propose a dual network approach that decouples input and backpropagation information, allowing for local learning signals without full gradient propagation. The framework is applied to various neural network architectures and demonstrates competitive performance in classification tasks. The authors emphasize biological plausibility, particularly through the CCL algorithm, addressing concerns regarding weight transport, locality, and update locking. They assert that their method achieves good performance despite weak alignment between forward and feedback weights, with a loss function designed to align neural activities in feedforward and feedback pathways, inspired by local learning principles in neuroscience. The authors acknowledge challenges of overfitting in BP models, supported by validation loss trends from experiments.

### Strengths and Weaknesses
Strengths:
- The proposed CCL framework is novel and offers insights into biologically plausible learning mechanisms.
- The empirical results indicate strong performance across multiple datasets, suggesting the potential for practical applications.
- The authors provide a clear motivation for biological plausibility, contributing to the understanding of neural network learning.
- The CCL algorithm demonstrates potential improvements in mitigating update locking and activity freezing compared to traditional methods.
- The revised theoretical derivation aligns more closely with the CCL process, addressing previous inaccuracies.

Weaknesses:
- The paper lacks thorough comparisons with other biologically plausible methods, such as forward-forward and deep softhebb, and does not justify model selection criteria.
- There is insufficient discussion on biological plausibility, particularly regarding update-locking and non-frozen activities, leading to skepticism about the relevance of local objectives to higher-level cortical functions.
- The derivation of the evidence lower bound (ELBO) contains approximations that were not clearly stated, leading to confusion regarding its validity.
- The partial mitigation of update locking and activity freezing issues raises questions about the overall effectiveness of the proposed method.
- The presentation and organization could be improved, with some figures needing higher abstraction levels or clearer comparisons.

### Suggestions for Improvement
We recommend that the authors improve the comparison of their results with other biologically plausible methods, such as forward-forward and deep softhebb, or provide justification for their model selection criteria. Additionally, we suggest a more detailed discussion on the biological plausibility of their approach, particularly concerning weight transport, locality, and update locking, as well as a robust justification for the relevance of local loss functions to higher-level cortical functions. We also recommend improving the clarity of their theoretical derivation by explicitly stating all assumptions and approximations made, and consider removing the term 'ELBO' to prevent confusion due to the approximations involved. Finally, further clarification on the implications of halving activity freezing time and its importance in the context of biological neural networks would strengthen the manuscript, along with enhancing the clarity of their presentation, potentially by presenting Figure 2 at a higher abstraction level and ensuring that all numerical results are consistent and clearly reported.