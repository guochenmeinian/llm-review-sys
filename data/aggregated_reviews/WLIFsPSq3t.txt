ID: WLIFsPSq3t
Title: Beyond Layout Embedding: Layout Attention with Gaussian Biases for Structured Document Understanding
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach called "Layout Attention with Gaussian Biases" aimed at enhancing structured document understanding through efficient document layout representation learning. The authors investigate the limitations of existing methods, such as the Cartesian coordinate system, and propose using polar coordinates to model layout information. The method incorporates relative positional relationships directly into the attention matrix using a Gaussian function, demonstrating positive results on datasets like FUNSD and CORD.

### Strengths and Weaknesses
Strengths:
- The innovative use of polar coordinates to represent layout information is compelling.
- The proposed method shows significant performance improvements on relevant datasets for both transformer and multi-modal transformer models.
- The paper is well-written and presents its findings clearly.

Weaknesses:
- The performance improvements for some backbone models are marginal, and critical comparisons with existing methods are lacking.
- The innovation is limited, as the approach is somewhat analogous to existing document pre-training models.
- The experimental setup is incomplete, with no pre-training experiments on multi-modal transformers and insufficient ablation studies across multiple datasets.

### Suggestions for Improvement
We recommend that the authors improve the experimental rigor by conducting ablation experiments on additional datasets to assess the impacts of the Gaussian kernel and polar coordinates more comprehensively. Additionally, we suggest providing a more in-depth analysis of the advantages of polar coordinates over Cartesian coordinates, including meaningful comparisons of attention maps between LayoutLMv3 and LayoutLMv3+LAGaBi. Lastly, we encourage the authors to address the missing references and to clarify the reasons for the absence of experiments on the DocVQA dataset.