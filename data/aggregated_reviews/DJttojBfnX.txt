ID: DJttojBfnX
Title: Adversarial Mask Explainer for Graph Neural Networks
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on instance-level explanations for Graph Neural Networks (GNNs) through the proposed Adversarial Mask Explainer (AMExplainer). The authors claim that previous methods depend on a predefined explanation size and introduce a scaling function to automatically select subgraphs. The method aims to enhance the interpretability of GNNs by generating sparse masks that indicate node importance, while experimental results suggest improved performance over prior approaches.

### Strengths and Weaknesses
Strengths:
1. The exploration of instance-level explanations for GNNs is a significant and relevant topic.
2. The proposed method effectively automates the selection of explanation subgraph size while maintaining sparsity.
3. Experimental results indicate that AMExplainer outperforms previous methods in terms of accuracy and interpretability.

Weaknesses:
1. The motivation behind the claim that the complementary subgraph lacks predictive ability is unclear.
2. The experimental evaluation relies on small and specific datasets, raising questions about the method's generalizability to broader node classification tasks.
3. The use of fidelity as a metric for evaluation is questionable, especially given that other methods achieve low fidelity without interpretability.
4. Several sections of the paper lack clarity, and the originality of the approach appears limited compared to existing regularization methods.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation for the complementary subgraph's predictive ability. Additionally, the authors should consider evaluating their method on a wider range of real datasets, such as Cora and PubMed, to demonstrate generalizability. We suggest incorporating decomposition-based interpreters as baselines in the experimental section. Furthermore, the authors should provide a more detailed explanation of the mutual information calculation and clarify the selection process for the beta parameter. Lastly, including temporal and spatial complexity analyses would enhance the assessment of the method's significance.