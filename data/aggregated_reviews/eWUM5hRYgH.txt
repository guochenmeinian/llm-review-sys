ID: eWUM5hRYgH
Title: Statistical Efficiency of Distributional Temporal Difference Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 3, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the finite sample performance and non-asymptotic analysis of distributional temporal difference (TD) learning, proposing a non-parametric distributional TD algorithm (NTD) that achieves tighter near-minimax optimal sample complexity bounds. The authors leverage a novel Freedman’s inequality in stochastic approximation to derive these results, which also apply to the categorical TD (CTD) algorithm. The paper aims to improve upon existing literature by providing a clearer understanding of the statistical efficiency of distributional TD algorithms.

### Strengths and Weaknesses
Strengths:
- The investigation into non-asymptotic convergence of distributional TD is reasonable and relevant.
- Theorems 4.1 and 4.2 yield technically sound conclusions based on stochastic approximation techniques.
- The notation is standard and clear, facilitating comprehension of the theoretical contributions.
- The proposed analysis of NTD and CTD offers tighter sample complexity bounds compared to prior methods.
- The new Freedman’s inequality is a valuable addition for future research.

Weaknesses:
- The theoretical contribution is limited in scope, primarily offering tighter non-asymptotic bounds without significant novelty.
- The non-parametric distributional TD is impractical for real-world applications, as its theoretical results parallel those of CTD.
- The Freedman’s inequality may not be sufficiently novel and should be positioned more appropriately within the context of the paper.
- The writing quality requires substantial improvement for clarity, with some mathematical derivations being difficult to follow.
- Several minor typographical errors and unclear notations detract from the overall presentation.

### Suggestions for Improvement
We recommend that the authors improve the motivation for their theoretical contributions, particularly regarding the novelty of the Freedman’s inequality. It should be emphasized more clearly within the main text. Additionally, the authors should enhance the clarity of their writing, especially in mathematical derivations, to ensure that all parts of the paper are easily understandable. Including a table summarizing sample complexities of this paper and related works would also aid in clarifying contributions. Finally, we suggest correcting the identified typographical errors and ensuring that all relevant works are cited appropriately.