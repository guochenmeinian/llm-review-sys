ID: EhdNQiOWgQ
Title: SwapPrompt: Test-Time Prompt Adaptation for Vision-Language Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 5, 8, 5, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents SwapPrompt, a novel method for test-time prompt adaptation in vision-language models, utilizing self-supervised contrastive learning. The authors propose a dual prompt mechanism and a swapped prediction strategy, achieving state-of-the-art performance across multiple datasets. Experimental validation demonstrates that SwapPrompt outperforms several baselines, including methods that utilize labeled data.

### Strengths and Weaknesses
Strengths:
- The experimental results are convincing and demonstrate the effectiveness of the proposed method.
- The paper is well-organized and clearly written, making it easy to follow.
- The authors conduct a thorough experimental analysis across various datasets.

Weaknesses:
- The proposed method lacks novelty, as it primarily builds on existing techniques without significant innovation.
- Certain statements, such as those regarding zero-shot inference and fine-tuning, are confusing and require clarification.
- The paper lacks sensitivity analysis for hyperparameters α and β, and the notation for loss functions in equations is inconsistent.
- Important ablation studies are missing, particularly regarding the effectiveness of the swapped prediction loss.

### Suggestions for Improvement
We recommend that the authors improve the novelty of the proposed method by incorporating more innovative elements beyond existing techniques. Clarifying confusing statements in the introduction regarding zero-shot inference and fine-tuning is essential. Additionally, providing a sensitivity analysis for hyperparameters α and β would enhance the robustness of the findings. The authors should also include a detailed ablation study focusing on the impact of only Lswap in Table 2 and ensure consistent notation for loss functions. Finally, addressing the lack of comparisons with relevant existing works in the related literature would strengthen the paper.