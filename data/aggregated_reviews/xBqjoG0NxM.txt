ID: xBqjoG0NxM
Title: SODA: Robust Training of Test-Time Data Adaptors
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 6, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents SODA, a test-time data adaptor that utilizes Zeroth-Order Optimization (ZOO) to adapt unlabelled test data to a deployed model without access to its parameters. It introduces variations such as SODA-R, which uses gradient information, and SODA-O for online settings. The method demonstrates superior performance over existing benchmarks like BETA and DINE, with comprehensive experiments conducted on CIFAR10-C and CIFAR100-C. However, the authors acknowledge that additional benchmark datasets would enhance confidence in the framework's practical applicability.

### Strengths and Weaknesses
Strengths:
1. The motivation for addressing the test-time adaptor problem is well-articulated, potentially reducing training costs.
2. The simplicity of the approach, relying on mutual information maximization and cross-entropy loss with pseudo labels, is commendable.
3. The application of ZOO effectively addresses the challenge of lacking gradient information, outperforming benchmarks on CIFAR10-C and CIFAR100-C.

Weaknesses:
1. The relationship between model perturbation and data augmentation in the proposed framework is unclear.
2. The choice of parameters $\sigma, \alpha, \tau$ is critical but not sufficiently detailed in the main paper, raising concerns about their dataset/task dependency.
3. The rationale behind the performance of $\sigma=0.5$ and $\alpha=0.0001$ needs further exploration, including an ablation study of each loss term.
4. The experiments are limited to CIFAR10-C and CIFAR100-C, lacking validation on other datasets like Office-31 and ImageNet-C.
5. The necessity of ZOO and the black-box nature of the data adaptor require clarification.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the relationship between model perturbation and data augmentation within the framework. Additionally, please make the discussion of the parameters $\sigma, \alpha, \tau$ more explicit in the main paper, especially if they are dataset/task-dependent. An ablation study to investigate the performance implications of these parameters is also necessary. Furthermore, we suggest expanding the experimental validation to include a wider range of datasets to strengthen the claims of effectiveness. Lastly, clarifying the necessity of ZOO and the operational characteristics of the data adaptor would enhance the paper's comprehensibility.