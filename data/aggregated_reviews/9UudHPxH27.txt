ID: 9UudHPxH27
Title: Benchmark and Neural Architecture for Conversational Entity Retrieval from a Knowledge Graph
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel task, Conversational Entity Retrieval from a Knowledge Graph (CER-KG), and introduces NACER, a model built on handcrafted features for this task. The authors adapt the existing QBLink dataset to create a benchmark for evaluating entity retrieval in conversational contexts, focusing on the relevance of Knowledge Graph (KG) entities to user queries across dialog turns.

### Strengths and Weaknesses
Strengths:
1. The paper addresses a significant gap in conversational information retrieval by focusing on entity retrieval from KGs in a dialog setting.
2. NACER's design incorporates a comprehensive range of lexical and semantic features, demonstrating a thorough approach to the problem.
3. The adaptation of the QBLink benchmark to create QBLink-KG is a practical contribution that facilitates further research.

Weaknesses:
1. The paper lacks the source code for the benchmark, limiting reproducibility.
2. The intricate design of NACER may pose challenges in implementation and optimization.
3. The authors miss important relevant datasets, such as Wizard of Wikipedia, and the comparison to larger generative models is absent.
4. The notation used in the paper is complex, hindering readability and understanding of NACER's retrieval process.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the filtering phase described in section 3, particularly regarding the "set of candidate entities Y." Additionally, enhancing the accessibility of the paper for a broader audience by better outlining the task and its phases before delving into technical details would be beneficial. The authors should also consider including a discussion on the connection between CER-KG and CQA-KG, justifying the independent importance of CER-KG. Furthermore, clarifying the "practical considerations" that limit NACER to using only the previous turn's answer and the current turn's query would strengthen the paper. Lastly, we suggest that the authors explore testing NACER on diverse real-world datasets and provide a more robust comparison against state-of-the-art models.