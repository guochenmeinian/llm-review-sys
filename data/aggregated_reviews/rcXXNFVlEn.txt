ID: rcXXNFVlEn
Title: Why think step by step? Reasoning emerges from the locality of experience
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 8, 7, 7, 7, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates the impact of zero-shot chain-of-thought (CoT) reasoning on language models, particularly focusing on the role of local structures in training data. The authors hypothesize that reasoning is beneficial when training data contains local clusters of variables that influence each other, allowing models to connect remote variables through intermediate reasoning. They conduct experiments using Bayes nets, demonstrating that models generating intermediate variables outperform those making direct predictions, particularly when training data exhibits the described locality. The findings suggest that CoT reasoning enhances inference when concepts are indirectly related through observed variables.

### Strengths and Weaknesses
Strengths:
- The paper is exceptionally clear and connects theoretical results to real-world phenomena, enhancing understanding of zero-shot CoT reasoning.
- The authors provide a simple theoretical framework that precedes the experimental section, effectively isolating the effects of training data locality.
- Results clearly indicate that reasoning improves prediction accuracy when local structures are present, highlighting data efficiency benefits.

Weaknesses:
- The connection between the proposed setup and actual zero-shot CoT reasoning in state-of-the-art language models is insufficiently articulated.
- The experiments rely on a single LLM architecture, limiting generalizability; a broader range of models would strengthen conclusions.
- The paper lacks explicit examples of how local structures in training data relate to real-world language use.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the connection between their experimental setup and real-world language reasoning, providing explicit examples of local structures in language. Additionally, consider expanding the experiments to include multiple LLM architectures to assess the robustness of the findings across different model sizes. It would also be beneficial to analyze the implications of non-overlapping clusters on reasoning performance and clarify the distinction between "burstiness" and locality in the context of their research.