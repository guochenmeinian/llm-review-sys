ID: prXfM5X2Db
Title: Frieren: Efficient Video-to-Audio Generation Network with Rectified Flow Matching
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 7, 7, 5, 5, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents FRIEREN, an efficient video-to-audio generation model based on rectified flow matching, achieving state-of-the-art results. The model utilizes a Transformer-based architecture and incorporates a conditional video input via channel-level concatenation to audio tokens, enhancing temporal alignment. The experimental results indicate significant improvements over existing models both quantitatively and qualitatively.

### Strengths and Weaknesses
Strengths:
- The authors successfully introduce rectified flow matching for video-to-audio generation, addressing a critical gap in generative AI.
- The model design is simple and reasonable, facilitating effective temporal alignment.
- Experimental results demonstrate substantial performance gains, and the manuscript is well-written and clear.

Weaknesses:
- The introduction lacks scientific rigor, with vague statements that require specificity.
- The empirical analysis of the model's performance is insufficient, particularly regarding the contributions of architectural choices versus the rectified flow.
- Experiments are limited to a single dataset (VGGSound), which raises concerns about the model's generalization capability.

### Suggestions for Improvement
We recommend that the authors improve the introduction by providing specific details rather than general statements. Additionally, we encourage the authors to conduct experiments with multiple datasets to validate the model's generalization capabilities. An empirical analysis distinguishing the contributions of the model architecture and rectified flow would enhance the manuscript's depth. Finally, clarifying the computation of alignment accuracy and considering the use of CLIP for visual representation could strengthen the paper.