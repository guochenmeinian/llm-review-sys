ID: vCOgjBIZuL
Title: Direct3D: Scalable Image-to-3D Generation via 3D Latent Diffusion Transformer
Conference: NeurIPS
Year: 2024
Number of Reviews: 18
Original Ratings: 6, 4, 5, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Direct3D, a scalable image-to-3D generation model that utilizes a 3D Latent Diffusion Transformer. The method comprises two main components: a Direct 3D Variational Auto-Encoder (D3D-VAE) that encodes high-resolution 3D shapes into a compact latent triplane space, and a Direct 3D Diffusion Transformer (D3D-DiT) that models the distribution of encoded 3D latents. The D3D-VAE introduces a triplane latent space for direct 3D supervision through occupancy, marking it as the first of its kind in neural rendering. The authors claim superior reconstruction quality compared to recent methods like 3DShape2VecSet and Michelangelo, which utilize implicit 1D latent spaces. They address limitations in using occupancy for mesh supervision, particularly the abrupt gradient variations near object surfaces, by implementing a semi-continuous surface sampling strategy. The framework incorporates semantic-level and pixel-level conditions from images, enabling the generation of 3D shapes consistent with provided images. The authors assert that their model demonstrates improved performance and generalization capabilities, especially when trained with both Objaverse and internal data, and claim that Direct3D outperforms previous methods in generation quality and generalization.

### Strengths and Weaknesses
Strengths:  
1. The manuscript is well-written, clearly explaining motivations and methods.  
2. The introduction of triplane latent space for direct 3D supervision is innovative.  
3. The proposed semi-continuous surface sampling technique is technically sound and improves reconstruction quality for intricate meshes.  
4. Direct3D can handle in-the-wild input images without complex optimization techniques.  
5. The integration of pixel-level conditions significantly enhances mesh generation quality.  
6. The framework demonstrates promising capabilities in conditional 3D generation.

Weaknesses:  
1. The lack of novelty is a significant concern, as the pipeline primarily extends existing methods like Point-E and Shap-E without substantial innovation.  
2. Key components of the proposed method are not novel, as similar techniques have been previously explored.  
3. The model's performance is evaluated on a private dataset of 500k samples, raising questions about the fairness of comparisons with other methods trained on smaller datasets.  
4. There is insufficient quantitative evaluation, with only user studies presented; metrics like Chamfer Distance, PSNR, or SSIM are needed for a more robust assessment.  
5. The manuscript lacks detail in the "Implementation Details" section, particularly regarding the near-surface sampling strategy and the specifics of the loss functions used.  
6. Some reviewers express a preference for rejection until a more polished submission is presented.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their work by providing a clearer distinction between their approach and existing methods like Shape-E and LN3Diff, including a detailed discussion of differences and contributions. Additionally, we suggest conducting thorough quantitative evaluations using established metrics such as Chamfer Distance and PSNR to substantiate claims of performance. It would also be beneficial to include a detailed explanation of the near-surface sampling strategy in the "Implementation Details" section for reproducibility. Furthermore, we encourage the authors to clarify the dataset used for training and consider releasing the trained models and dataset details to enhance transparency and reproducibility. Finally, we recommend that the authors include all promised experiments and clarifications in the next submission to address concerns about the soundness of the paper and expedite the release of their open-sourced model/code as previously promised.