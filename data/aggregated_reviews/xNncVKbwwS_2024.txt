ID: xNncVKbwwS
Title: Universal Online Convex Optimization with $1$ Projection per Round
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 7, 6, 5, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents methods for constrained online convex optimization (OCO) that achieve optimal regret rates without prior knowledge of the loss functions' properties, requiring only one projection per round. The authors propose an algorithm that simplifies the constrained optimization problem using a black-box reduction technique, allowing for significant computational efficiency compared to existing methods that typically require multiple projections. The paper addresses a gap in the literature by introducing novel surrogate losses and improving regret bounds for various loss types.

### Strengths and Weaknesses
Strengths:  
- The paper effectively tackles a significant problem in the literature, providing a straightforward yet innovative modification of existing techniques.  
- It is well-written, offering valuable insights and a clear introduction to the challenges and methodologies involved.  
- The results are non-trivial, demonstrating technical challenges overcome by the authors, particularly in the strongly convex case.  

Weaknesses:  
- The paper feels poorly factored, with excessive back references that complicate readability, especially in print.  
- The theoretical advancements may seem incremental, appealing primarily to a niche audience, and the reliance on a meta-aggregation procedure lacks elegance.  
- The claimed convex rate is inaccurately stated as $O(\sqrt{T})$ instead of the correct $O(\sqrt{T \log\log T})$.  

### Suggestions for Improvement
We recommend that the authors improve the paper's structure by better factoring results into lemmas and propositions to enhance readability. Additionally, addressing the inaccuracies in the stated convex rate is essential. We suggest exploring the potential of projection-free algorithms, such as variants of Online Frank Wolfe, to eliminate the need for multiple projections while maintaining adaptability to smoothness. Lastly, consider whether a simple doubling trick could help tune the parameters $G$ and $T$ effectively.