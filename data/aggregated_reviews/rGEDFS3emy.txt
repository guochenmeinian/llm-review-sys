ID: rGEDFS3emy
Title: F-OAL: Forward-only Online Analytic Learning with Fast Training and Low Memory Footprint in Class Incremental Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 4, 5, 8, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Forward-only Online Analytic Learning (F-OAL) method for online class incremental learning (OCIL), which does not rely on back-propagation. The authors utilize a pre-trained frozen encoder and recursive least squares to update a linear classifier, effectively addressing catastrophic forgetting while significantly reducing memory usage and computational time. The method is evaluated across multiple benchmarks, demonstrating superior performance compared to existing exemplar-free and several replay-based methods.

### Strengths and Weaknesses
Strengths:
The F-OAL framework introduces a forward-only learning mechanism that effectively reduces computational overhead and memory footprint. The empirical results show strong performance against continual learning baselines, and the extensive comparisons to state-of-the-art methods are compelling.

Weaknesses:
1) Some descriptions, particularly Formula 4, are unclear and require more vivid explanations. 
2) The innovation appears limited, primarily relying on the forward process and least squares method, which may lead to overfitting.
3) The paper lacks a detailed discussion on potential limitations, such as the dependence on the quality of the pre-trained encoder and challenges in varying data scenarios.
4) Notations are sometimes confusing, and writing issues, including typos, detract from clarity.

### Suggestions for Improvement
We recommend that the authors improve the clarity of descriptions, particularly for Formula 4, and provide a proof process to validate its correctness. Additionally, a more comprehensive evaluation could include recent exemplar-free methods relevant to OCIL, such as those listed in the weaknesses. We also suggest addressing the limitations of the method more thoroughly, particularly regarding the reliance on a strong pre-trained encoder and the implications for data privacy claims. Finally, refining notations and correcting typos will enhance the paper's presentation.