ID: vDlj3veE9a
Title: The Space Complexity of Approximating Logistic Loss
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 7, 6, 5, 5, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 1, 2, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents lower bounds on space complexity for data structures approximating logistic loss with $\epsilon$-relative error, establishing that any coreset providing such an approximation requires storing $\Omega(d/\epsilon^2)$ rows of the original data matrix. The authors also demonstrate a general $\Omega(d \cdot \mu_y(X))$ space lower bound for constant $\epsilon$, indicating that the dependency on the complexity measure $\mu_y(X)$ is intrinsic. Additionally, the paper refutes a prior conjecture regarding the difficulty of computing $\mu_y(X)$ by providing an efficient linear programming formulation.

### Strengths and Weaknesses
Strengths:
- The paper introduces new space complexity lower bounds for logistic loss approximation, which is a significant contribution.
- It effectively refutes a prior conjecture about the complexity measure $\mu_y(X)$ and provides a linear programming method for its computation.
- The writing is clear, with a structured presentation of the problem, contributions, and results.

Weaknesses:
- The discussion on upper bounds is slightly outdated; updating to the $O(d\mu/\epsilon^2)$ upper bounds would strengthen the contributions.
- The paper does not cover the 'for this solution' sparsification, which is weaker than the 'for all' sparsification but still relevant for many applications.
- The experiments could benefit from being conducted on more diverse datasets beyond synthetic and KDDCup datasets.

### Suggestions for Improvement
We recommend that the authors improve the articulation of how their contributions differ from existing works, particularly those by Munteanu et al. and Mai et al. Additionally, we suggest conducting experiments on a broader range of real-world datasets to enhance the empirical validation of their methods. Finally, including more detailed explanations of the new method for computing the complexity measure $\mu_y(X)$ would be beneficial for reader comprehension.