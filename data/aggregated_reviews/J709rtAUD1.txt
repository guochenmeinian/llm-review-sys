ID: J709rtAUD1
Title: Causal Temporal Representation Learning with Nonstationary Sparse Transition
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 6, 5, 4, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 4, 2, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel framework, Causal Temporal Representation Learning with Nonstationary Sparse Transition (CtrlNS), aimed at identifying distribution shifts and latent factors in non-stationary time series without strong prior knowledge of domain variables. The authors develop an identifiability theory for sequential data influenced by non-stationary latent causal processes and validate their approach through experiments on synthetic and real-world datasets, demonstrating its effectiveness in recovering latent variables and domain indices.

### Strengths and Weaknesses
Strengths:
- The paper addresses the significant issue of causal discovery in non-stationary time series, introducing a fresh perspective on the identifiability of domain variables.
- The theoretical foundation is rigorous, with convincing proof flows and intuitive results.
- The evaluation on realistic tasks, such as weakly supervised action segmentation, showcases the practical applicability of the proposed method.
- The writing is clear and well-organized.

Weaknesses:
- The paper overstates the claim of deriving identifiability results "without prior knowledge of the domain variables," as it still requires assumptions like the ground-truth number of domains.
- The assumptions made in the theoretical framework are not fully testable in real-world scenarios, and some definitions, such as "weakly diverse lossy transitions," lack clarity and motivation.
- The authors do not sufficiently discuss existing related work, which raises concerns about the novelty of their contributions.
- Architectural details and parameter setups for the neural networks in the CtrlNS framework are inadequately described.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their claims regarding prior knowledge requirements by explicitly stating the assumptions necessary for their framework. Additionally, a more thorough discussion comparing their assumptions with those of existing works would strengthen the paper's novelty claims. We also suggest including clearer definitions and motivations for key concepts, such as "weakly diverse lossy transitions," potentially with graphical model examples. Furthermore, providing detailed architectural information and parameter setups for the CtrlNS framework would enhance reproducibility. Lastly, the authors should consider expanding their experimental evaluations to include more diverse real-world applications beyond action segmentation, such as healthcare and finance.