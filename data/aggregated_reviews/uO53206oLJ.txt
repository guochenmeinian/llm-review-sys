ID: uO53206oLJ
Title: Nonconvex Federated Learning on Compact Smooth Submanifolds With Heterogeneous Data
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 4, 3, 7, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper studies federated learning on a compact smooth submanifold using distributed Riemannian optimization methods. The authors propose a new algorithm for non-convex optimization on smooth manifolds, demonstrating its efficiency through numerical experiments on PCA and low-rank matrix completion tasks. The proposed methods aim to avoid client drift and reduce computational costs.

### Strengths and Weaknesses
Strengths:
- The proposed proximal smoothness of a manifold is intuitive and interesting.
- The computational cost is advantageous, potentially making new problems feasible.
- The paper is well-written, with clear articulation of novelties and contributions.

Weaknesses:
- The theoretical analyses lack comparisons with related Euclidean and Riemannian methods.
- Presentation is unclear, particularly regarding the use of projections instead of direct manifold work, which may mislead readers.
- Experimental analyses are limited, particularly in the number of clients considered and the types of privacy mechanisms analyzed.
- The claim of improved results with heterogeneous data lacks detailed justification.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the presentation by explicitly stating the limitations of their methods to Euclidean spaces and addressing the misleading implications of working on manifolds. Additionally, the authors should provide comparative analyses with related works, such as "Distributed Principal Component Analysis with Limited Communication" and "Communication-Efficient Distributed PCA by Riemannian Optimization," both theoretically and experimentally. It would also be beneficial to examine how results change with a larger number of clients and to include analyses with different privacy mechanisms. Furthermore, we suggest clarifying the definition of convexity on manifolds and discussing the nonconvexity of both the manifold constraint and the objective function in the introduction. Lastly, the authors should ensure that necessary notation is included in the main text for better self-containment.