ID: mDPUF7ubAv
Title: An Empirical Study of Instruction-tuning Large Language Models in Chinese
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive evaluation of various large language models (LLMs) tailored for the Chinese language, focusing on instruction-tuning methods and their effectiveness. The authors conduct extensive experiments comparing different LLMs, datasets, and learning techniques, particularly highlighting the benefits of instruction tuning for the LLM "Bloom" and the effectiveness of the LoRA method. The study also examines factors such as vocabulary, prompt language, and human values to mitigate toxic content. The authors plan to release a new Chinese LLM with performance comparable to ChatGLM.

### Strengths and Weaknesses
Strengths:
- The paper provides valuable quantitative comparisons and insights into instruction-tuning LLMs for Chinese, which could benefit a wide audience.
- It is well-written and comprehensible, making it accessible to readers.
- The research is pioneering in systematically studying instruction-tuning in Chinese, with intensive experimentation yielding useful findings.

Weaknesses:
- The majority of the content consists of evaluations of existing datasets and models, lacking substantial new insights and generalizable conclusions.
- The choice of benchmarks and instruction datasets is not convincingly justified, and the results may only be locally optimal due to variable control methods.
- Evaluations rely solely on ChatGPT without human assessment, raising concerns about potential biases in the results.

### Suggestions for Improvement
We recommend that the authors improve the depth of discussions surrounding the implications of their findings, particularly regarding the application of English LLMs to Chinese. Additionally, the authors should enhance the clarity of descriptions for existing models and datasets, ensuring that critical information is not relegated to table captions. It would also be beneficial to incorporate human evaluations alongside ChatGPT assessments to address potential biases. Finally, we suggest that the authors clarify the rationale for selecting specific benchmarks and instruction datasets to strengthen the validity of their results.