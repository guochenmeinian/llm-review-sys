ID: yySpldUsU2
Title: Changing the Training Data Distribution to Reduce Simplicity Bias Improves In-distribution Generalization
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 6, 6, 4, 4, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method called USEFUL (UpSample Early For Uniform Learning) aimed at modifying the training data distribution to enhance in-distribution generalization. The authors analyze a 2-layer CNN to compare the feature learning dynamics of Gradient Descent (GD) and Sharpness-Aware Minimization (SAM), demonstrating that SAM mitigates simplicity bias more effectively than GD. USEFUL clusters examples based on layer output similarity and upsamples those with slow-learnable features, showing improved performance across various datasets and optimizers. The authors validate their method through extensive experiments, outperforming random clustering baselines.

### Strengths and Weaknesses
Strengths:
- The paper is well-motivated and clearly written, with a solid theoretical foundation.
- Comprehensive assessment of the method across different hyper-parameters, datasets, and architectures.
- The inclusion of a random clustering baseline strengthens the evaluation.

Weaknesses:
- The choice of using the last output activation vector for clustering is unclear, as is the optimal epoch for clustering, which may complicate hyper-parameter tuning.
- The robustness of the upscaling factor of 2 in long-tail distributions is questionable, and claims of generalization to out-of-distribution (OOD) tasks are inadequately supported.
- Limited novelty due to existing literature on simplicity bias and a lack of discussion on potential limitations and societal impacts.

### Suggestions for Improvement
We recommend that the authors clarify the rationale for selecting the last output activation vector for clustering versus intermediate vectors. Additionally, they should provide guidance on determining the optimal epoch for clustering without extensive ablation studies. It would be beneficial to explore the robustness of the upscaling factor in long-tail distributions and to temper claims of generalization to OOD tasks by presenting more comprehensive results across various datasets. Finally, a discussion of the limitations and societal impacts of their method should be included to enhance the paper's depth.