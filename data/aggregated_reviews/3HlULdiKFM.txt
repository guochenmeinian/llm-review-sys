ID: 3HlULdiKFM
Title: CoVR: Learning Composed Video Retrieval from Web Video Captions
Conference: NeurIPS
Year: 2023
Number of Reviews: 7
Original Ratings: 5, 5, 5, 5, -1, -1, -1
Original Confidences: 5, 4, 3, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to Compositional Video Retrieval (CoVR), focusing on ranking and retrieving modified videos based on a given video and modification text. The authors develop a large-scale dataset, WebVid-CoVR, utilizing modifications generated by a Large Language Model (LLM) and provide a smaller manually annotated dataset for evaluation. The proposed method employs HH-NCE for learning video compositions, demonstrating effective performance in both supervised and zero-shot settings, and shows transferability to Compositional Image Retrieval (CoIR) datasets.

### Strengths and Weaknesses
Strengths:
- The created dataset(s) is a valuable contribution to vision-language pre-training, particularly for CoVR, which previously lacked a training dataset.
- The methodology for dataset creation is well-structured, especially the manual annotation process.
- The paper is well-written and easy to follow.

Weaknesses:
- The meaning of Top K sampling in Line 137 is unclear, particularly regarding whether it refers to tokens within modification text.
- The rule-based ablation in Table 6 raises questions about the potential for LLM paraphrasing of generated rules, suggesting that a standard LLM could suffice without fine-tuning.
- The source of noise in the WebVid-CoVR dataset is not clearly identified, raising concerns about the reliability of the generated modifications.
- The learning process for the parameters \alpha and \tau is not adequately explained, and the implications of treating \tau as a fixed hyperparameter versus a learnable one are not discussed.
- There is a lack of analysis regarding the types of modifications in the dataset, which could enhance understanding of its limitations.

### Suggestions for Improvement
We recommend that the authors improve clarity regarding the Top K sampling definition in Line 137. Additionally, consider exploring whether the generated rules in Table 6 could be paraphrased by a standard LLM. It would be beneficial to provide a detailed analysis of the noise sources within the WebVid-CoVR dataset and clarify how \alpha and \tau are learned, including a comparison of fixed versus learnable \tau during training. We also suggest conducting an analysis of the types of modifications present in the dataset to better understand its coverage and limitations. Lastly, enhancing the dataset analysis to include visual characteristics would provide deeper insights into the dataset's strengths and weaknesses.