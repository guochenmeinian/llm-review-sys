ID: ArSMQ3dCUx
Title: Noise-Robust Semi-Supervised Learning for Distantly Supervised Relation Extraction
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a semi-supervised learning approach for distantly supervised relation extraction, focusing on assigning relation labels at the sentence level rather than the bag level. The authors propose the SSLRE framework, which utilizes noisy instances as unlabeled data with pseudo-labels, incorporating techniques such as curriculum learning and mixup supervised contrastive learning. Experimental results on datasets like NYT10m and wiki20m demonstrate that the proposed method outperforms strong baseline models.

### Strengths and Weaknesses
Strengths:
- The paper is well organized and easy to follow.
- The novel idea of utilizing noisy samples instead of discarding them is interesting.
- Experimental results indicate significant improvements over existing models.

Weaknesses:
- The experimental protocol is under-specified, hindering reproducibility and confidence in results.
- The approach appears to be a collection of existing techniques, lacking substantial technical novelty.
- Some experimental results for baselines are inconsistent with original papers.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the experimental protocol to enhance reproducibility. Specifically, please clarify whether results are averaged over multiple runs or based on a single run. Additionally, we suggest including precision/recall curves in the appendix, as is common in distantly supervised relation extraction. It would also be beneficial to address the discrepancies in reported results for baseline models and provide standard deviation or confidence interval information to support claims of significant performance improvements. Lastly, consider discussing the novelty of using mislabeled instances more thoroughly, as similar ideas have been explored previously.