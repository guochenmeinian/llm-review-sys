ID: STrXsSIEiq
Title: Learning Robust Statistics for Simulation-based Inference under Model Misspecification
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 5, 5, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method to enhance neural posterior estimation (NPE) robustness against model misspecification by introducing a regularized loss function that incorporates the maximum mean discrepancy (MMD) between the learned posterior and observed data. The authors apply this method to both benchmark tasks and a real-world radio propagation example, focusing on likelihood-free approaches such as NPE and approximate Bayesian computation (ABC).

### Strengths and Weaknesses
Strengths:
- The radio propagation example effectively demonstrates the potential of the MMD regularizer.
- The paper is well-structured and generally clear in its presentation.

Weaknesses:
- The novelty of the approach is questionable, particularly in relation to existing work, such as reference [72] and the InfoVAE framework, which share similarities in their formulations.
- The paper's clarity suffers; the descriptions of the approach and its motivations are often difficult to follow, particularly regarding the training data setup and the lack of clarity on the amortized NPE.
- The evaluation is limited to comparisons with ABC and NPE, raising questions about the applicability of the method to other estimators like Neural Likelihood Estimators.
- The hyperparameter selection process for the regularizer lacks detail, and the implications of using the Euclidean distance for ABC are not adequately addressed.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by providing a more explicit discussion of how their work differs from reference [72] and clarifying the novelty of their contributions. Additionally, the authors should elaborate on the hyperparameter selection process for the regularizer and consider including comparisons with other estimation methods beyond ABC and NPE. It would also be beneficial to clarify the training data setup and the implications of summarizing over datasets versus individual observations. Finally, we suggest ensuring that the figures, particularly Figure 5, share consistent axes for better interpretability.