ID: zdMislOLTv
Title: Zero-Shot-BERT-Adapters: a Zero-Shot Pipeline for Unknown Intent Detection
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for zero-shot intent detection tasks using a two-stage zero-shot BERT adapter (Z-BERT-A). The approach first employs a dependency parser to extract potential intents and then utilizes NLI methods with BERT models for classification. Experimental results indicate that this method outperforms various baselines in both known intents zero-shot classification and unseen intent discovery.

### Strengths and Weaknesses
Strengths:
- The paper addresses significant tasks in zero-shot intent classification and discovery.
- The proposed method demonstrates effectiveness, achieving state-of-the-art results on public datasets.

Weaknesses:
- The contribution of the paper is not clearly articulated, particularly in comparison to existing language model adapters.
- The method's reliance on explicit intent words limits its effectiveness, especially if intents are not directly mentioned in the input.
- The experimental results show only marginal improvements over baselines, and there is a lack of comprehensive baseline comparisons.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their contributions by explicitly comparing their method to existing language model adapters. Additionally, we suggest including more baseline comparisons in Table 4 to substantiate the effectiveness of their approach. To enhance the robustness of their findings, the authors should consider conducting a more thorough ablation study and provide a small sample of human evaluations to validate performance against LLMs. Furthermore, clarifying the tunable and frozen parameters, as well as the size of the trainable parameters, would strengthen the technical details of the paper. Lastly, we encourage the authors to explore experiments in additional languages to demonstrate the multilingual capabilities of their method.