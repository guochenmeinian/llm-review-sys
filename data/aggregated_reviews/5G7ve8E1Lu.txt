ID: 5G7ve8E1Lu
Title: Grammar-Aligned Decoding
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 5, 7, 6, -1, -1
Original Confidences: 4, 3, 4, -1, -1

Aggregated Review:
### Key Points
This paper presents the adaptive sampling with approximate expected futures (ASAp) method aimed at enhancing grammar-aligned decoding for large language models (LLMs). The authors propose that ASAp improves output quality by refining the conditional probability to align with the model's original distribution while ensuring grammaticality. Central to ASAp is the iterative refinement of expected future grammaticality (EFG) estimates, which converge to exact EFG over infinite iterations. Experimental results indicate that ASAp's output distribution is closer to the original than that of greedy decoding (GCD) methods.

### Strengths and Weaknesses
Strengths:  
- ASAp facilitates more accurate grammatical predictions by considering potential future grammaticality, unlike GCD, which samples based solely on current probabilities.  
- The method is well-formalized, with useful examples that enhance understanding.  
- Empirical validation demonstrates that ASAp improves benchmark scores in code generation and structured NLP tasks.  
- The limitations of ASAp are thoroughly discussed throughout the paper.

Weaknesses:  
- The algorithm's reliance on prior samples for estimating grammatical probabilities can be computationally expensive and challenging to manage, particularly with large datasets or dynamic environments.  
- A fair comparison of decoding speed between ASAp and GCD is necessary, as ASAp's sampling process is time-consuming.  
- Section 2 may be difficult to read for those unfamiliar with context-free grammar (CFG), and the method appears slow due to the required iterations and storage of extensive prefix tables.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Section 2 by restructuring it and providing more context on CFG, possibly including a concrete example. Additionally, consider providing specific input and output examples for the SLIA and INV-BV tasks to enhance intuitiveness. To differentiate between GCD and GAD, clearer naming conventions are advisable. Addressing the computational demands of ASAp could involve exploring the possibility of preprocessing EFG estimates before decoding. Lastly, we suggest correcting minor typographical errors, such as changing "bot" to "both" in line 289, and clarifying terms like "ancestral sampling" in Algorithm 1.