ID: ficSbTieoY
Title: An In-depth Investigation of User Response Simulation for Conversational Search
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an improved user simulation system for conversational search, leveraging a fine-tuned T5 model and addressing challenges such as training blind spots and evaluation methods. The authors conduct a systematic error analysis and propose an answer-type-driven user simulation that incorporates cooperativeness levels during training and evaluation. Experimental results demonstrate the effectiveness of these considerations, showing significant improvements over existing systems and LLMs like GPT-4.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and structured, providing valuable insights through a systematic error analysis of the T5 model.
2. The introduction of an advanced approach to user response simulation enhances simulation quality by integrating QA knowledge and answer type prediction.
3. The code is open-sourced, promoting transparency and community engagement.

Weaknesses:
1. LLM-based baselines are utilized in a zero-shot setting, neglecting the potential benefits of in-context learning, which could enhance performance.
2. Important experimental details are unclear, such as the number of epochs for fine-tuning and the size of data subsets used for cooperativeness-awareness evaluation.
3. The lack of significance tests between the proposed model and stronger baselines raises questions about the validity of the claimed improvements.
4. The simulation scenario is limited to clarifying questions, which restricts the generalizability of the findings.

### Suggestions for Improvement
We recommend that the authors improve clarity by clearly naming their contributions at the end of the introduction section. Additionally, we suggest that the authors provide more details on the experimental setup, including the number of epochs for model training and the sizes of data subsets. It would also be beneficial to conduct significance tests between the proposed model and the strongest baseline to validate the improvements. Furthermore, we encourage the authors to explore the use of in-context learning for LLMs to assess its impact on performance. Lastly, expanding the analysis beyond a single metric to identify challenging examples would enhance the robustness of the findings.