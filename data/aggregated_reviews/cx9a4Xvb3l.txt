ID: cx9a4Xvb3l
Title: Privacy Assessment on Reconstructed Images: Are Existing Evaluation Metrics Faithful to Human Perception?
Conference: NeurIPS
Year: 2023
Number of Reviews: 6
Original Ratings: 6, 7, 8, 6, -1, -1
Original Confidences: 4, 4, 5, 3, -1, -1

Aggregated Review:
### Key Points
This paper presents an evaluation of existing hand-crafted image quality metrics in relation to privacy leakage in reconstructed images, revealing weak correlations with human perception. To address this, the authors propose SemSim, a learning-based measure that assesses semantic similarity between original and reconstructed images, demonstrating a higher correlation with human judgment. The study provides valuable insights into privacy leakage assessment and introduces new datasets for further research.

### Strengths and Weaknesses
Strengths:
- The paper conducts a comprehensive evaluation of traditional metrics, providing significant insights into privacy assessment.
- It effectively highlights the weak correlation between existing metrics and human perception, emphasizing the importance of the issue.
- SemSim is a novel metric that aligns closely with human evaluations, enhancing the assessment of privacy leakage.
- The authors demonstrate the generalizability of SemSim across various datasets and models.
- The paper includes insightful discussions on privacy leakage and introduces new datasets for future research.

Weaknesses:
- The paper lacks details about the FID metric, which could enhance reproducibility.
- There is insufficient discussion on the domain generalization ability of SemSim, particularly regarding training on a single set of reconstructed images.
- The use of L2 distance in SemSim raises questions about performance with alternative distance measures; an ablation study is needed.
- The definition of privacy is based on image content classification, potentially overlooking important local privacy attributes.
- The human rating collection procedure lacks detail, raising concerns about potential subjective bias.

### Suggestions for Improvement
We recommend that the authors improve the clarity and reproducibility of the FID metric by providing more information about the feature extraction models used. Additionally, the authors should discuss the domain generalization ability of SemSim, particularly regarding its performance on diverse datasets. An ablation study comparing L2 distance with alternative measures would strengthen the evaluation of SemSim. Furthermore, we suggest expanding the discussion on the definition of privacy to consider local attributes and detailing the human rating collection process to mitigate subjective bias.