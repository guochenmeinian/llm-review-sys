ID: B7QkdEnjL9
Title: Optimization and Bayes: A Trade-off for Overparameterized Neural Networks
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 4, 7, 6, 5, 5, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 2, 2, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach that bridges the gap between empirical risk minimization (ERM) and Bayesian learning problems through the introduction of Transformative Bayesian Learning (TransBL). The authors derive an algorithm-dependent PAC-Bayesian generalization bound for infinitely wide neural networks based on the KL divergence between the posterior obtained by gradient flow and a Gaussian prior. They propose an interpolation method to balance computational efficiency and predictive accuracy, while also analyzing the dynamics of the Hessian trace.

### Strengths and Weaknesses
Strengths:
- The paper provides a sound theoretical analysis on the relationship between ERM and Bayesian learning, particularly in overparameterized neural networks.
- The introduction of an interpolation mechanism by modifying weights presents an innovative solution to the trade-off between computation efficiency and generalization error.
- The analysis of KL divergence and its relation to the change in Helmholtz free energy is insightful, and the dynamics of the Hessian trace are explored comprehensively.

Weaknesses:
- The presentation lacks clarity and intuitive explanations, making it difficult for readers unfamiliar with the topic to follow.
- There is insufficient empirical validation and comparison with recent methods, which limits the practical applicability of the proposed approach.
- The assumptions regarding infinitely wide networks may restrict the generalizability of the results to real-world scenarios.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the presentation by providing more intuitive explanations and examples to aid understanding. Additionally, we suggest including a discussion on the limitations of the infinite width assumption and its implications for practical applications. To strengthen the empirical contribution, we encourage the authors to compare their method with other recent approaches in the field. Lastly, addressing the variance issues associated with importance sampling more explicitly would enhance the robustness of the paper.