ID: b60wLlkBta
Title: On the Robustness of Removal-Based Feature Attributions
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 6, 6, 7, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a theoretical analysis of the robustness of removal-based feature attributions against input and model perturbations, utilizing Lipschitz-style bounds to derive limits on attribution changes. The authors validate their theoretical findings through empirical experiments on synthetic and real-world datasets, demonstrating that conditional sampling is more robust to model perturbations than baseline or marginal samplings.

### Strengths and Weaknesses
Strengths:
- The theoretical analysis of removal-based feature attributions is technically sound, covering various aspects of robustness.
- The work provides a solid foundation for evaluating robustness among different explanation methods, addressing a crucial problem in explainable AI (XAI).
- Empirical experiments support the theoretical findings, enhancing the paper's credibility.
- The exposition is clear, and the paper is well-structured.

Weaknesses:
- The analysis is limited to a few removal-based methods, and extending it to include gradient-based explanations would strengthen the contribution.
- The practical implications of the findings remain unclear, and a technically sound robustness evaluation benchmark based on the theory is needed.
- The computational cost of analyzing robustness in high-dimensional or complex datasets is a concern, and further experimental results would enhance the paper.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the practical implications of their results, particularly how they can be operationalized in practice. Additionally, the authors should consider extending their analyses to include gradient-based explanations to broaden the impact of their work. It would also be beneficial to include more experimental results in the main paper, particularly on complex datasets, to substantiate their theoretical claims. Lastly, we suggest that the authors clearly acknowledge the transfer of formalization from prior work, such as Covert et al. (2021), to enhance the paper's transparency.