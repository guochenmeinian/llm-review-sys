ID: KSyTvgoSrX
Title: Banded Square Root Matrix Factorization for Differentially Private Model Training
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 6, 7, 7, 6, -1, -1, -1, -1
Original Confidences: 4, 5, 3, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Banded Square Root (BSR) matrix factorization, aimed at enhancing the efficiency of banded matrix factorization for differentially private machine learning applications. The authors demonstrate that the workload matrix for SGD with momentum and weight decay can be represented as a lower triangular Toeplitz matrix, allowing for efficient computation of its square root. Theoretical analysis confirms that BSR achieves asymptotically optimal approximation quality, and experimental results indicate that BSR performs comparably to state-of-the-art methods.

### Strengths and Weaknesses
Strengths:
- The discussion on SGD with momentum and weight decay is significant, revealing that the workload matrix can be efficiently factored as a lower triangular Toeplitz matrix, which has not been previously explored.
- The theoretical analysis shows that BSR can be computed efficiently for large problem sizes, ensuring both speed and accuracy.
- The paper is well-structured, with clear contributions and a compelling narrative that combines theoretical and empirical insights.

Weaknesses:
- The use of CVXPY with SCS for computing AOF is inefficient; alternatives like L-BFGS could yield better performance, as evidenced by existing implementations.
- The experimental evaluation is limited to matrix sizes up to 2000, lacking comparisons with larger sizes (10,000 or more) that would strengthen the findings.
- The post-processing step to enforce positive semi-definiteness lacks clarity, and the paper does not provide sufficient context on differential privacy.

### Suggestions for Improvement
We recommend that the authors improve the efficiency of the AOF computation by considering L-BFGS or similar methods, as this could lead to more reliable comparisons. Additionally, expanding the experimental evaluation to include larger matrix sizes (10,000 and 100,000) would provide a more comprehensive understanding of BSR's scalability. We also suggest providing a detailed explanation of the post-processing step for ensuring positive semi-definiteness and including a general introduction to differential privacy to make the paper more self-contained. Lastly, addressing the limitations of the current experimental setup and clarifying the implications of varying learning rates would enhance the paper's rigor.