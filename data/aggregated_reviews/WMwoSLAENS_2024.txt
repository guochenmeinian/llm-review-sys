ID: WMwoSLAENS
Title: AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 6, 6, 5
Original Confidences: 3, 3, 5

Aggregated Review:
### Key Points
This paper presents AutoDefense, a multi-agent framework aimed at defending large language models (LLMs) from jailbreak attacks that exploit vulnerabilities to produce harmful content. The system utilizes multiple LLM agents, each designated for specific defense tasks, to collaboratively filter and block inappropriate responses. AutoDefense is modular, allowing integration with other defense mechanisms, and demonstrates a significant reduction in attack success rates (ASR), notably decreasing GPT-3.5's ASR from 55.74% to 7.95%.

### Strengths and Weaknesses
Strengths:  
- **Novel Multi-Agent Defense Approach:** The innovative framework enhances collaborative decision-making among LLM agents, improving defense against jailbreak attacks.  
- **Flexibility and Expandability:** The modular design allows for integration with other defense mechanisms, such as Llama Guard, enhancing performance.  
- **Strong Experimental Results:** The substantial reduction in ASR across various LLMs indicates the effectiveness of AutoDefense.

Weaknesses:  
- **Potential Computation Overhead:** The multi-agent configuration may introduce significant computational costs and delays, limiting real-world applicability.  
- **Insufficient Methodological Depth:** The design lacks complexity, relying on sequentially invoked system prompts without a robust communication mechanism among agents.  
- **Limited Experimentation:** The testing primarily focuses on prompt-level attacks, neglecting token-level attacks and comparisons with other defense methods like Adversarial Training.  
- **Inconsistent Performance Metrics:** ASR increases with the number of agents in some cases, and other metrics do not consistently favor three agents, questioning the multi-agent approach's advantages.  
- **Clarity Issues:** Some sections, particularly regarding experimental setup and results, could benefit from more concise language and clearer explanations.

### Suggestions for Improvement
- We recommend that the authors improve the alignment of Tables 2 and 3 within the page margins, as they currently extend outside the boundaries.  
- The authors should add a takeaway in the introduction section to guide users on balancing efficiency and effectiveness with this method.  
- To enhance the methodological depth, consider implementing a communication mechanism among agents and employing different LLMs for various components, such as using GPT-4 for analysis and Llama Guard 3 for classification.  
- We suggest addressing the computational overhead concerns to improve the practical applicability of the framework.  
- The authors should correct typos, such as changing "GPT35Turbo" to "GPT-3.5-Turbo" in Table 2, and ensure accurate bolding in Table 7.  
- Although limitations remain, this paper is qualified for acceptance.