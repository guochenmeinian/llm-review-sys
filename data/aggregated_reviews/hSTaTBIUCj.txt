ID: hSTaTBIUCj
Title: Imagine That! Abstract-to-Intricate Text-to-Image Synthesis with Scene Graph Hallucination Diffusion
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 4, 7, 10, 5, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to text-to-image synthesis, specifically addressing the abstract-to-intricate (A2I) setting. The authors propose the scene-graph hallucination (SGH) mechanism to expand initial scene graphs derived from abstract prompts, enabling the generation of intricate images through a diffusion-based synthesizer. Additionally, the model utilizes scene graphs derived from generated images as supervised data to optimize its imaginative capabilities, focusing on enhancing the model's ability to envision input prompts, particularly abstract terms. Extensive experiments on the COCO dataset demonstrate the method's effectiveness in synthesizing images that align closely with the input prompts, showcasing significant improvements over existing models. The work emphasizes the complexity of transitioning from abstract concepts to visualizations, particularly in the context of place nouns and progressive verbs, and acknowledges the need for a more comprehensive definition of abstract terms.

### Strengths and Weaknesses
Strengths:
- The abstract-to-intricate T2I setting is a crucial area of research, addressing the limitations of existing models that require detailed prompts.
- The SGH mechanism effectively mitigates vision distraction and enhances focus on relevant scene elements.
- Comprehensive experiments and analyses validate the proposed method's performance, providing robust evidence of its effectiveness.
- The authors have effectively addressed reviewer concerns and demonstrated a commitment to improving their work.
- The proposed model shows potential for enhancing imaginative capabilities through diverse datasets and integration with large language models (LLMs).

Weaknesses:
- The experimental comparisons are limited to a manually curated dataset (COCO-A2I), which may not be sufficiently representative.
- There is an unfair comparison in T2I results, as the best baseline on COCO is not adequately discussed.
- The omission of bounding box information in training raises questions about the completeness of the scene graphs.
- Overclaims regarding the controllability of the proposed model are noted, as scene graph hallucinations may introduce unexpected concepts.
- Several writing issues, including unclear captions and inconsistent terminology, detract from the paper's clarity.
- Important citations related to scene graph synthesis are missing, which could strengthen the paper's foundation.
- There are claims in the paper that may be perceived as overstatements, such as being the first to study the novel T2I setup, which could be contested.
- The current focus on specific types of abstract terms may limit the model's applicability and understanding of broader abstract concepts.

### Suggestions for Improvement
We recommend that the authors improve the experimental setup by providing results compared to text-based enrichment methods on the COCO dataset and discussing the performance of the best T2I baselines, such as make-a-scene. Additionally, we suggest including bounding box information for visual guidance in training to enhance the model's performance. The authors should clarify the writing issues noted, particularly in the captions and terminology, and ensure that all relevant citations are included to support their claims. We encourage the authors to further enrich the proposed COCO-A2I dataset by including more diverse scenarios. Finally, a more rigorous definition of the abstract-to-intricate task and abstract terms within the context of their model would enhance the paper's clarity and impact, while exploring the integration of LLMs more thoroughly and expanding the categories of objects, attributes, and relationships in the scene graphs could enhance imaginative capabilities while mitigating hallucination risks.