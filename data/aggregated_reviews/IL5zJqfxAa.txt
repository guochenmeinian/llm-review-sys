ID: IL5zJqfxAa
Title: EmbodiedGPT: Vision-Language Pre-Training via Embodied Chain of Thought
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 8, 3, 8, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an end-to-end multi-modal foundation model for embodied AI, introducing two datasets: EgoCOT, which contains egocentric videos and structured language instructions, and EgoVQA, focusing on video question answering. The authors propose the EmbodiedGPT model, which integrates a frozen vision model, a frozen language model, an embodied-former for aligning modalities, and a policy network for action generation. The model demonstrates strong performance across various embodied tasks, including embodied control and planning, and aims to enhance interpretability through its modular design. Additionally, the authors explore how chain-of-thought training can enhance the understanding of object interactability in embodied tasks, claiming their approach differs from existing multimodal models that primarily focus on object detection. However, reviewers argue that the paper lacks sufficient novelty and contributions, noting that prior works have already investigated similar applications of large language models (LLMs) in embodied tasks. The newly added experiments on embodied tasks are criticized for being poorly defined and lacking comparisons with state-of-the-art (SOTA) methods, particularly in established benchmarks like R2R, RXR, and VLNCE.

### Strengths and Weaknesses
Strengths:
- The authors effectively address the critical challenge of obtaining high-quality embodied multi-modal data by creating the EgoCOT and EgoVQA datasets.
- The EmbodiedGPT model achieves state-of-the-art results in multiple embodied tasks, showcasing its capabilities in generating reliable planning sequences.
- The focus on improving the interpretability of large language models through a modular architecture is commendable.
- The authors propose a novel approach to multimodal chain-of-thought training and introduce the EgoCoT dataset, which they believe contributes to the field of embodied AI.
- The public release of code encourages open-source collaboration and further research.

Weaknesses:
- The novelty of the architecture is questioned, with reviewers feeling that the authors overstate their contributions.
- EmbodiedGPT may exhibit overfitting to specific domains due to biases in the training datasets, potentially limiting its generalization.
- The interpretability of the model remains a concern, as the transformer-based architecture lacks explicit memory components for accurate responses.
- The substantial computational resources required for training EmbodiedGPT may hinder accessibility for smaller organizations or individual researchers.
- The experiments lack rigorous comparisons with SOTA methods, and the settings for the embodied tasks are unclear, leading to concerns about the validity of the results.
- The paper lacks sufficient statistical analysis of human evaluation results, making it difficult to draw meaningful conclusions.

### Suggestions for Improvement
We recommend that the authors improve the clarity and coherence of the paper, particularly in the network architecture section, to better highlight innovative contributions. Detailed explanations of the training process, including the language projection and prefix language adapter updates, should be provided. Additionally, we suggest conducting more comprehensive experiments involving embodied navigation tasks to demonstrate the model's capabilities in partially observable environments. Specifically, the authors should conduct experiments on established benchmarks such as R2R, RXR, and VLNCE, and present quantitative results to substantiate their claims. Furthermore, clarifying the experimental settings and data sources used in their navigation demo would enhance the transparency and rigor of their methodology. Finally, addressing the statistical significance of the human evaluation results would strengthen the paper's claims regarding the model's performance, and a comprehensive survey of the embodied community would also bolster their position and understanding of the field.