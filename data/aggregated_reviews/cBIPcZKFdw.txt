ID: cBIPcZKFdw
Title: Strategic Apple Tasting
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 6, 6, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 2, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an online learning problem involving incentives and one-sided feedback, where a principal makes decisions for a sequence of agents who can strategically modify their contexts. The authors propose algorithms that achieve $\tilde O(\sqrt{T})$ strategic regret under stochastic contexts and $\tilde O(T^{(d+1)/(d+2)})$ regret for adversarial contexts. The study addresses both the stochastic and adversarial scenarios, contributing to the fields of online learning and algorithmic game theory.

### Strengths and Weaknesses
Strengths:
- The paper is original in studying the combination of incentives and one-sided feedback in online learning, relevant to various application domains.
- It effectively addresses multiple aspects of the problem, providing clear performance guarantees for the proposed algorithms.
- The writing is clear and accessible, making complex concepts easy to follow.

Weaknesses:
- The techniques employed are adaptations of existing methods rather than groundbreaking innovations.
- The literature review lacks discussion of closely related works in algorithmic game theory and online learning, particularly regarding repeated Stackelberg games and online Bayesian persuasion.

### Suggestions for Improvement
We recommend that the authors improve the literature review by incorporating discussions on related works, such as:
- Repeated Stackelberg games: Balcan et al. (2015) and subsequent extensions.
- Online Bayesian persuasion: Castiglioni et al. (2020, 2021).
- Online learning in principal-agent problems: Zhu et al. (2022).

Additionally, we suggest clarifying the connection between the strategic modification of contexts and the motivating examples provided, particularly in terms of why such modifications may not always be detrimental. Furthermore, addressing the computational complexity of Algorithm 3 and considering alternative structures for the policies in the adversarial setting could enhance the paper's contributions.