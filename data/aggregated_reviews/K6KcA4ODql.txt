ID: K6KcA4ODql
Title: Improving Bias Mitigation through Bias Experts in Natural Language Understanding
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a debiasing framework for natural language understanding (NLU) models that addresses biases in datasets, which can lead to discrepancies in performance across different data distributions. The authors propose using a one-vs-all classifier approach to construct a bias-only model that better captures dataset biases. The framework introduces Bias Experts, a set of binary classifiers trained alongside the main model, which improves performance on biased test sets. The experimental results substantiate the effectiveness of this approach across various challenge datasets.

### Strengths and Weaknesses
Strengths:
- The paper tackles a critical and timely issue in NLU, focusing on debiasing models without prior knowledge of biases.
- The introduction of binary classifiers as Bias Experts is a novel contribution, providing a fresh perspective on bias mitigation.
- Comprehensive evaluation on multiple NLU tasks demonstrates the proposed method's effectiveness.

Weaknesses:
- The introduction of several hyper-parameters raises concerns about tuning without a validation set, which could lead to bias leakage.
- The motivation for the proposed method requires further verification, particularly regarding the relationship between the bias experts and the main model's performance.
- The evaluation approach using BERT-Base feels outdated, and the paper lacks references to recent comparison methods and relevant literature.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the explanation regarding the advantages of one-vs-all bias-only models, particularly in section 3.2. Additionally, we suggest including ablation results on more tasks beyond HANS to better illustrate the contributions of bias amplification and the one-vs-all approach. It would also be beneficial to provide more details on the methodology for obtaining biased examples in the preliminary study. Lastly, we encourage the authors to explore performance comparisons with more recent large language models to enhance the relevance of their findings.