ID: paobkszgIA
Title: End-to-End Video Semantic Segmentation in Adverse Weather using Fusion Blocks and Temporal-Spatial Teacher-Student Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 7, 7, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel video segmentation method for adverse weather conditions using an end-to-end, optical-flow-free, and domain-adaptive approach. The authors propose a spatial-temporal teacher-student learning scheme that incorporates temporal information from adjacent frames. Additionally, they introduce a temporal weather degradation augmentation to simulate real-world weather variations. The method demonstrates state-of-the-art performance across various datasets, including Viper, Synthia, and MVSS.

### Strengths and Weaknesses
Strengths:
1. The proposed method is the first to address video semantic segmentation under adverse weather conditions, benefiting various applications in the vision community.
2. It is moderately novel and effectively end-to-end, eliminating reliance on optical flows from pretrained models.
3. The introduction of a temporal augmentation strategy enhances robustness against weather degradations.

Weaknesses:
1. The spatial loss computation lacks clarity in Figure 2, particularly regarding the inclusion of the white area.
2. The caption of Figure 3 is misleading and should clarify the display of frames and optical flows.
3. Key parameters, such as the weight smooth coefficient for EMA updating and the selection process for pseudo labels, are not adequately explained.
4. Qualitative results on MVSS appear inferior compared to image-based domain adaptation methods.
5. Inference speed comparisons should be emphasized in the main text, as they are critical for video semantic segmentation.
6. Details on temporal augmentations, such as the implementation of "foggy" areas and glare effects, are insufficient.
7. An overall loss equation, Loverall, integrating Lsup, Ltemp, and Lspatâ€‹ should be included for clarity.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the spatial loss computation in Figure 2 and revise the caption of Figure 3 to accurately describe the displayed content. Additionally, please provide explanations for the weight smooth coefficient parameter and the pseudo label selection process. It would be beneficial to enhance qualitative results on MVSS and emphasize inference speed comparisons in the main text. We also suggest including detailed descriptions of temporal augmentations and an overall loss equation to clarify the integration of different loss components. Lastly, expanding the related work section to include recent references and discussing the novelty of the proposed method in comparison to existing techniques would strengthen the paper.