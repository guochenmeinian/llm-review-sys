ID: gQeZoe2j3v
Title: Mulan: A Multi-Level Alignment Model for Video Question Answering
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a multi-level alignment approach for Video Question Answering (VideoQA), utilizing object mask generators and image captioning models to extract various levels of features. The authors propose methods for object-level, frame-level, and video-level alignment, claiming to outperform state-of-the-art methods with fewer parameters and minimal pre-training data. Extensive experiments are conducted to validate the effectiveness of the proposed method.

### Strengths and Weaknesses
Strengths:
- The proposed approach demonstrates promising performance while utilizing fewer parameters.
- The idea of aligning visual and textual modalities at multiple levels is intriguing and could enhance understanding of spatial and temporal relations.
- Experimental results indicate that the method surpasses state-of-the-art baselines.

Weaknesses:
- The novelty of the multi-level alignment approach is questioned, as similar concepts have been explored in prior works.
- Missing comparisons in experimental results, particularly in Table 1, hinder a fair evaluation against other models.
- The paper lacks clarity in certain sections, particularly regarding the loss function and parameter updates, which raises concerns about reproducibility.

### Suggestions for Improvement
We recommend that the authors improve the literature review to include a more comprehensive comparison with prior works, particularly those that have explored multi-level visual features. Additionally, we suggest including missing comparisons in Table 1 to ensure a fair evaluation of the proposed method against strong baselines. The authors should clarify the rationale behind training only the adapter's parameters and explore the potential benefits of training all model parameters. Furthermore, we encourage the authors to provide more details on the loss function and parameter updates to enhance the clarity and reproducibility of the study.