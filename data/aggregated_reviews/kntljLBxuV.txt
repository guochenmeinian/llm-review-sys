ID: kntljLBxuV
Title: LFDe: A Lighter, Faster and More Data-Efficient Pre-training Framework for Event Extraction
Conference: ACM
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents LFDe, a novel method for Event Extraction (EE) that enhances pre-training efficiency by utilizing automatically constructed weak-label data. LFDe eliminates the need for extensive labeled datasets by generating pseudo-triggers and pseudo-arguments through POS tagging and AMR, respectively. The authors introduce a prompt-based sequence labeling model (P-SLM) that employs type-aware and role-aware prompts for event detection and argument extraction. The framework demonstrates significant improvements in performance across various data scarcity levels.

### Strengths and Weaknesses
Strengths:
- The innovative use of weak-label data reduces reliance on large, manually annotated datasets, enhancing scalability in EE.
- The introduction of a prompt-based sequence labeling model redefines the task, allowing for rapid adaptation to EE without extensive representation modeling.
- LFDe requires fewer pre-training instances and shorter training periods, making it a practical solution for resource-constrained environments.

Weaknesses:
- The choice of GDELT for pre-training needs justification, and the paper lacks detailed statistics about the dataset, raising concerns about data leakage and comparability with other methods.
- The construction of the event schema integrated into prompts is unclear, including whether it is manual or automatic, and how it relates to GDELT.
- The complexity of the pipeline may lead to increased error rates and raises concerns about the accessibility of external resources.
- The experimental evaluation lacks statistical significance tests and is based on a single dataset split, which undermines the generalizability of the results.

### Suggestions for Improvement
We recommend that the authors improve the justification for using GDELT as the pre-training dataset by providing detailed statistics and addressing potential data leakage concerns. Additionally, clarity on the construction of the event schema is essential; the authors should specify whether it is generated manually or automatically and how it is derived from GDELT. To enhance the robustness of the experimental evaluation, we suggest conducting multiple dataset splits and including statistical significance tests to validate the results. Finally, providing quantitative metrics on computational efficiency, such as GFLOPs and parameter counts, would strengthen the claims regarding the model's efficiency.