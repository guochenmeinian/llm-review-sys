ID: haPIkA8aOk
Title: Adaptation with Self-Evaluation to Improve Selective Prediction in LLMs
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a selective prediction technique for large language models (LLMs) that encourages models to avoid making predictions when uncertain. The authors propose a methodology where the model is fine-tuned on task-specific data, generates multiple answers (both correct and incorrect), and trains a classifier to distinguish between them. The experiments demonstrate the method's effectiveness, achieving state-of-the-art performance on three question-answering datasets.

### Strengths and Weaknesses
Strengths:
- The proposed method is simple, effective, and easy to implement, showing strong empirical performance across multiple datasets.
- The methodology is interesting and outperforms competing baseline methodologies.
- The experiments conducted are appropriate in number and scope.

Weaknesses:
- The novelty of the method is questionable, as key components derive from previous work, limiting its originality.
- The description of metrics used in the paper is insufficient, and the training objective may inadvertently increase the likelihood of negative cases.
- The paper requires polishing, particularly in the presentation of equations and clarity regarding the generation of multiple sequences during training versus testing.
- Concerns exist regarding the method's effectiveness on larger LLMs, and the training efficiency is impacted by the need for multiple answer sampling.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the metrics used in the paper, possibly by providing citations or more detailed explanations. Additionally, the authors should reconsider the training objective in Equation 7 to avoid increasing the likelihood of negative cases. A more thorough analysis of the impact of model parameters is warranted, and the paper should explicitly address the conflict between generating multiple answers during training and the claim of avoiding multiple sequences during testing. Finally, we suggest polishing the presentation of equations and ensuring that the descriptions are clear and concise.