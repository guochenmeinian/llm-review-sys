ID: 63xeWav1lU
Title: Fine-grained Image-to-LiDAR Contrastive Distillation with Visual Foundation Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 5, 6, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to address the image-to-LiDAR contrastive learning problem for LiDAR-based point cloud segmentation. The authors propose OLIVINE, which utilizes weakly-supervised contrastive distillation to generate semantic superpixels using the Segment Anything Model (SAM) and introduces a density and category-aware sampling strategy to balance class distributions. The framework incorporates three optimization objectives: weakly-supervised contrastive distillation, self-supervised contrastive distillation, and a regularization framework based on the von Mises-Fisher (vMF) distribution. Evaluations on nuScenes, SemanticKITTI, and KITTI datasets demonstrate consistent performance improvements over existing methods. The authors also utilize semantic labels for weakly-supervised contrastive distillation, semantic-guided consistency regularization, and category-aware anchor point sampling. While the motivation has been clarified and the experimental scale expanded, concerns remain regarding the potential over-claim of the advantages of "semantic superpixels" compared to "class-agnostic superpixels."

### Strengths and Weaknesses
Strengths:
1. The work addresses a significant challenge in self-supervised representation learning for LiDAR datasets, relevant for autonomous driving and robotics.
2. The proposed method achieves state-of-the-art results on key benchmarks, including nuScenes and SemanticKITTI.
3. The ablation study effectively highlights the contributions of various components of the method.
4. The motivation is now clearer and more straightforward.
5. The experimental scale has significantly increased, providing a comprehensive evaluation across diverse datasets.
6. Technical clarifications have resolved several previous concerns.

Weaknesses:
1. The weakly-supervised contrastive distillation method has been previously utilized, and the addition of semantic categories does not significantly enhance performance over class-agnostic masks.
2. The rationale for employing the vMF distribution for consistency regularization lacks clarity and requires further theoretical justification.
3. The experimental scale and depth could be improved, particularly regarding downstream fine-tuning on datasets beyond SemanticKITTI.
4. There is a risk of over-claiming the benefits of using "semantic superpixels" over "class-agnostic superpixels," as the improvements may not be substantial.

### Suggestions for Improvement
We recommend that the authors improve the differentiation of their approach from prior works in the related work section, particularly in relation to Mahmoud et al. and Liu et al. We suggest providing a more detailed explanation of the hyperparameter settings for the vMF distribution and the reasoning behind their choices. Additionally, we encourage the authors to conduct more thorough experimental analyses on other LiDAR-based datasets, such as SemanticPOSS and Waymo, to strengthen their findings. Addressing the computational cost of the proposed method is crucial for real-time applications, and we advise discussing the generalizability of OLIVINE to other sensor types and environments. Lastly, we recommend improving the clarity of their claims regarding the contribution of "semantic superpixels" to avoid potential over-claim issues, and we suggest revising the paper for grammatical errors and enhancing clarity in the technical descriptions, particularly regarding category-aware sampling.