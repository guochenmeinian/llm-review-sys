ID: ntV5xZfzEk
Title: Constrained Binary Decision Making
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 8, 6, 6, -1, -1, -1, -1, 6, -1, -1, -1
Original Confidences: 2, 3, 4, 3, -1, -1, -1, -1, 3, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework for binary statistical decision-making (BDM), formulating BDM problems as constrained optimization tasks. The authors provide a detailed characterization of optimal solutions, recovering known results and establishing new ones. They assert that their theorem guarantees that these optimal strategies will not perform worse than alternatives, although improvements may be marginal in some cases. The framework encompasses various existing and newly proposed BDM problems, aiming to simplify the derivation of optimal strategies. The authors reference empirical validations in the machine learning domain, particularly the SCOD problem, where initially heuristic strategies were later shown to be suboptimal compared to optimal strategies. They also address the challenge of unknown data distributions, suggesting that the BDM problem can be reformulated to accommodate distributional uncertainty.

### Strengths and Weaknesses
Strengths:
- The paper introduces a novel and general framework that unifies various binary decision-making problems under a single constrained optimization formulation.
- It provides a solid mathematical foundation for optimal strategies in BDM problems, with rigorous theoretical treatment, detailed proofs, and clear characterizations of optimal strategies.
- Empirical examples from the machine learning field lend credibility to the proposed framework, and the organization and clarity of the paper are commendable, with numerous examples enhancing its accessibility.
- The authors effectively address distributional uncertainty and propose methods for estimating the OOD/ID ratio.

Weaknesses:
- The motivation for characterizing optimal solutions lacks depth, and the theoretical impact is sometimes unclear.
- The paper does not provide empirical validation of the proposed framework, which limits its practical applicability.
- There is insufficient discussion on how the framework would adapt to unknown or difficult-to-estimate data distributions.
- Computational challenges associated with solving the proposed optimization problems are not adequately addressed.

### Suggestions for Improvement
We recommend that the authors improve the motivation for their results by clarifying the connection between the selection function and the classifier in the context of selective classification. Additionally, we suggest conducting empirical experiments to validate the proposed approach against existing methods, such as those in the SCOD paper. Addressing computational complexity and providing insights into handling unknown distributions would also enhance the paper's robustness. Finally, we encourage the authors to include discussions on existing literature regarding infinite-dimensional linear programming to better contextualize their work and elaborate on potential extensions or modifications to enhance the framework's robustness in handling cases of distributional uncertainty.