ID: 68A4GE4nqf
Title: Evaluating Subjective Cognitive Appraisals of Emotions from Large Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents COVIDET-APPRAISALS, a dataset comprising 241 Reddit posts annotated for 24 emotional appraisal dimensions, each accompanied by a natural language rationale. The authors evaluate the dataset using various large language models (LLMs) to assess their performance on cognitive appraisal tasks. The results indicate that while ChatGPT performs well, other LLMs show room for improvement. The paper aims to fill a gap in emotion recognition within NLP by providing a comprehensive corpus and conducting extensive evaluations.

### Strengths and Weaknesses
Strengths:
- The dataset is novel and valuable, with detailed annotations for 24 cognitive appraisal dimensions.
- It addresses an important and underexplored task in NLP, contributing significantly to the field.
- Extensive evaluations and analyses of state-of-the-art LLMs highlight the challenges in emotion cognitive appraisal.
- Strong correlation exists in the subset annotated by two labels, indicating reliable annotations.

Weaknesses:
- The dataset size is limited to 241 Reddit posts, and the rationale for the importance of understanding subjective cognitive appraisals is unclear.
- The claim of being "the most comprehensive dataset to date" lacks supporting evidence and comparison with similar datasets.
- The experiments with LLMs are conducted under a zero-shot setup, missing opportunities to explore in-context learning or few-shot fine-tuning.
- Inconsistencies in the experimental setup, such as the number of annotators and prompting methods, require better justification.
- The human evaluation setup may overestimate performance due to pre-filtering outputs, complicating future comparisons.
- Exclusion of three appraisal dimensions from the final corpus is questionable, given the low NA rates and the significance of NA prediction.

### Suggestions for Improvement
We recommend that the authors improve the dataset size and provide a clearer rationale for the significance of understanding subjective cognitive appraisals. Additionally, we suggest supporting the claim of comprehensiveness by comparing COVIDET-APPRAISALS with other established datasets. The authors should explore different experimental setups, including in-context learning and few-shot fine-tuning, and ensure consistency in the annotation and prompting methods. Lastly, we advise reconsidering the exclusion of certain appraisal dimensions to enhance the dataset's robustness.