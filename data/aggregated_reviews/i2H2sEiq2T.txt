ID: i2H2sEiq2T
Title: A Unified Fast Gradient Clipping Framework for DP-SGD
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 6, 7, 7, 5, 6, -1, -1, -1, -1
Original Confidences: 1, 3, 3, 3, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a unified framework for the ghost clipping algorithm, enhancing its application across various neural network architectures and significantly reducing runtime and storage costs for implementing DP-SGD. The authors demonstrate that their framework allows for efficient computation of gradient norms, which is crucial for training neural networks under differential privacy. The paper includes theoretical and empirical evaluations, showing improvements over existing methods.

### Strengths and Weaknesses
Strengths:
- **Originality**: The paper introduces a novel framework for fast gradient clipping in DP-SGD, marking a significant theoretical contribution to the privacy of machine learning.
- **Quality**: The organization is commendable, with thorough explanations, mathematical derivations, and experimental results.
- **Clarity**: The content is accessible, with clear background explanations and concise presentation of results.
- **Significance**: The implications for the privacy of machine learning are substantial, providing a unified perspective on ghost clipping.

Weaknesses:
- The focus on ghost clipping raises questions about its broader applicability within the field of privacy in deep learning.
- The experimental evaluation lacks a comprehensive overview of end-to-end runtime and storage savings, limiting practical insights for practitioners.
- Insufficient discussion of related literature on DP-SGD and clipping operators, which could better contextualize the study's significance.

### Suggestions for Improvement
We recommend that the authors improve the empirical evaluation by including a broader range of layer types, such as convolutional and attention layers, to assess the overall runtime and storage savings provided by the proposed framework. Additionally, a discussion on the potential generalization of the framework beyond ghost clipping should be included, possibly in a concluding section. The authors should also clarify the assumptions regarding the loss function and layer types in Proposition 4.1, and consider providing a limitation section to address the constraints of their approach. Lastly, we suggest including code for reproducibility and addressing any discrepancies in the abstract and main text regarding performance claims.