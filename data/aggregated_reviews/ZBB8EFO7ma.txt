ID: ZBB8EFO7ma
Title: Aiming towards the minimizers: fast convergence of SGD for overparametrized problems
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 6, 6, 6, 5, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 2, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new condition called the aiming condition, which resembles quasar-convexity but offers fundamentally different convergence guarantees for SGD. Under this aiming condition, along with other regularity conditions, SGD can achieve the same sample complexity as GD. The authors demonstrate that wide neural networks exhibit this property with high probability. Additionally, the work shows a regularization condition for SGD in the interpolation regime, allowing it to achieve a fast linear convergence rate similar to deterministic gradient descent, challenging traditional assumptions that require smaller step sizes for SGD.

### Strengths and Weaknesses
Strengths:
- The aiming condition is a significant contribution, enabling SGD to match GD's sample complexity.
- The presentation is clear, with a well-structured introduction that provides a roadmap for the results.
- The work is well-motivated and organized, thoroughly comparing its results to prior works and addressing assumptions made.

Weaknesses:
- There is insufficient discussion comparing the aiming condition to existing conditions like quasar-convexity, particularly in providing examples where the aiming condition holds while quasar-convexity does not.
- The assumptions made, especially regarding the locality of SGD analysis, are too strong for non-convex landscapes, raising concerns about the practicality of the results.
- The empirical evaluation is limited, relying solely on MNIST, which may not adequately reflect the theory's applicability across different datasets and architectures.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the comparison between the aiming condition and quasar-convexity by providing more examples and intuitions regarding their differences. Additionally, clarifying the assumptions related to the locality of SGD analysis would strengthen the theoretical foundation. We also suggest including empirical evaluations on more diverse datasets, such as CIFAR10/100, and exploring various model architectures to validate the proposed conditions in practice. Lastly, it would be beneficial to highlight the technical novelties more explicitly in the paper.