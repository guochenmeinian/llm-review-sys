ID: HtMXRGbUMt
Title: Understanding and Mitigating Copying in Diffusion Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 7, 6, 4, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 1, 4, 5, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive investigation into the memorization phenomenon in diffusion models, particularly focusing on the impact of data and caption duplication during training. The authors analyze how specific captions can exacerbate memorization and propose techniques to mitigate this issue by randomizing and augmenting image captions. The findings indicate that both image complexity and caption specificity significantly influence the extent of memorization. Additionally, the paper discusses the relationship between FID scores and generation quality, emphasizing concerns about their correlation, while noting that FID scores are not the primary focus of the work. The dataset similarity score (DS) is critiqued for its application and informativeness, especially regarding duplication effects.

### Strengths and Weaknesses
Strengths:
- The paper effectively dissects various factors contributing to memorization, supported by extensive empirical experiments, making it a valuable resource for the community.
- The originality of addressing the role of text conditioning in data replication is noteworthy, and the proposed mitigation strategies are relevant.
- The structure of the paper enhances comprehensibility, with key takeaways clearly summarized.
- The authors engage constructively with reviewer feedback and express a commitment to maintaining the integrity of the review process.
- The clarification regarding the setup of the duplication factor and its impact on memorization is appreciated.

Weaknesses:
- The influence of pretraining on the results remains ambiguous, and the title may overstate the findings without including experiments from scratch.
- The reliance on dataset similarity scores as a primary metric raises concerns about their validity and interpretation, particularly regarding the threshold set at 0.5.
- Some proposed solutions lack novelty and depth, and the analysis of the impact on generation quality is insufficient.
- The correlation between FID scores and generation quality is questioned, raising concerns about the paper's direction.
- The DS score is deemed uninformative, and its application appears messy, particularly in the context of duplication and its effects on memorization.

### Suggestions for Improvement
We recommend that the authors improve clarity regarding the influence of pretraining by including results from models trained from scratch. Additionally, consider revising the title to reflect the focus on finetuned diffusion models. It would be beneficial to provide a more detailed justification for the choice of similarity score metrics and to explore alternative metrics such as Precision and Recall. We suggest enhancing the analysis of the proposed mitigation strategies, particularly their effects on generation quality, and addressing the potential overlap between memorization and mode collapse in the discussion. Furthermore, we recommend improving the clarity of the discussion surrounding the DS score, specifically addressing how duplication influences it and elaborating on why duplication does not significantly affect the DS score despite similar sampling strategies. Lastly, ensure that clarifications on caption diversity and specificity are included in the next version, and consider including a dedicated limitations section to clarify the scope of the findings.