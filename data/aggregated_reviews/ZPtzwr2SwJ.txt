ID: ZPtzwr2SwJ
Title: Learning Adversarial Low-rank Markov Decision Processes with Unknown Transition and Full-information Feedback
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 6, 6, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study of low-rank MDPs with adversarially changing losses in a full-information feedback setting. The authors propose the POLO algorithm, which achieves sublinear regret in the number of episodes \( K \) but exhibits a linear dependency on \( d \), the rank of the transition kernel. They claim to be the first to interleave representation learning, exploration, and exploitation to guarantee sublinear regret for reinforcement learning with nonlinear function approximation and adversarial losses.

### Strengths and Weaknesses
Strengths:
1. POLO is the first algorithm to achieve sublinear regret with unknown features in a full-information setting.
2. The authors provide a clear comparison with previous works, emphasizing their contribution.
3. The regret upper bound is clearly stated, and the analysis is standard and clear.

Weaknesses:
1. The full information feedback assumption is restrictive and unrealistic.
2. The extensive literature review in Section 2 could be shortened to allow for more proof sketches, which would benefit the reader.
3. The algorithm suffers from high computational costs when the state space is large, similar to previous algorithms.

### Suggestions for Improvement
We recommend that the authors improve the algorithm's computational efficiency, particularly in lines 13, 15, 16, and 17, to address the high costs associated with large state spaces. Additionally, we suggest reducing the literature review in Section 2 to make room for more detailed proof sketches. Finally, we encourage the authors to explore methods for relaxing the full-information assumption and to provide a lower bound for the representation learning component of the regret analysis.