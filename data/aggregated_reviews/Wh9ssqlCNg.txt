ID: Wh9ssqlCNg
Title: Accelerating Augmentation Invariance Pretraining
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 3, 5, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an acceleration framework for Vision Transformers (ViTs) in self-supervised contrastive learning, utilizing randomized token dropout and flexible patch scaling to reduce sequence length and enhance training efficiency. The authors analyze gradient estimation errors and propose an automated procedure for optimal acceleration scheduling. Experimental results indicate that the accelerated pretraining achieves comparable performance on visual understanding tasks while significantly reducing computational costs.

### Strengths and Weaknesses
Strengths:
- The motivation for the proposed methods is clear and reasonable.
- Extensive experiments validate the effectiveness of the approach in reducing training time while maintaining comparable performance.
- The paper is well-organized and clearly written, with effective communication through figures and tables.

Weaknesses:
- The novelty of the submission is limited, as both proposed methods have been previously explored; token dropout is a common technique, and patch scaling is derived from existing literature.
- The framework appears to have a lower ceiling for optimal performance, as evidenced by results showing that accelerated methods yield lower performance than traditional methods.
- Important metrics, such as full-finetuning top-1 accuracy on ImageNet-1K, are missing, which could enhance the paper's credibility.
- The scope is narrow, focusing primarily on MoCo-v3 without exploring broader self-supervised learning frameworks.
- The claim of a "dynamic acceleration schedule" is misleading, as the schedule is predetermined rather than adjusted in real-time during training.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their work by exploring the application of their methods beyond MoCo-v3 to other self-supervised learning frameworks. Additionally, including full-finetuning top-1 accuracy on ImageNet-1K as a critical metric would strengthen the paper's findings. Clarifying the definition of "dynamic acceleration" to accurately reflect its predetermined nature is essential. Furthermore, addressing the potential impact of the quadratic time complexity in ViTs and providing a more comprehensive discussion of limitations would enhance the overall quality of the paper.