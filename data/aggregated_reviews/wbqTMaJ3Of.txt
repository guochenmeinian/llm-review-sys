ID: wbqTMaJ3Of
Title: DPAR: Decoupled Graph Neural Networks with Node-Level Differential Privacy
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel decoupled differential privacy (DP) framework for Graph Neural Networks (GNNs), specifically through the Decoupled GNN with Differentially Private Approximate Personalized PageRank (DPAR). The authors articulate the challenges of achieving node-level DP in GNNs and demonstrate that their approach improves the privacy-utility tradeoff. The theoretical analysis and empirical results support the effectiveness of DPAR, highlighting its potential for practical applications.

### Strengths and Weaknesses
Strengths:
- The proposed methodology, combining DP-APPR and DP-SGD, is innovative and effectively addresses privacy challenges in GNNs.
- The paper is well-structured, with clear mathematical foundations and comprehensive empirical validation on real-world datasets.
- The approach allows for independent protection of graph structure and node features, enhancing flexibility in privacy protection.

Weaknesses:
- The experimental setup lacks a validation set, raising concerns about hyperparameter tuning and its impact on reported results.
- The limited aggregation from top K neighbors may not fully utilize GNN capabilities, and clarity on K values in figures is needed.
- The paper does not provide a detailed analysis of algorithmic complexity, scalability, or a broader comparison with state-of-the-art methods, which are crucial for assessing practical applicability.

### Suggestions for Improvement
We recommend that the authors improve the experimental setup by including a validation set to clarify hyperparameter tuning processes. Additionally, the authors should provide clarity on the K values used in the neighbor aggregation and report results from a wider range of baselines without DP protection for better context. A more detailed discussion on the practical aspects of implementing DPAR, including computational overhead and scalability for large-scale applications, is essential. Furthermore, we suggest including a thorough analysis of the algorithmic complexity to enhance understanding of the method's efficiency compared to existing GNN approaches. Lastly, expanding the range of comparisons with state-of-the-art methods would better position DPAR within the current research landscape.