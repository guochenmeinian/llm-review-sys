ID: nFU4xCyoe0
Title: Decomposing Complex Visual Comprehension into Atomic Visual Skills for Vision Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 4
Original Ratings: 5, 8, 7, 5
Original Confidences: 3, 5, 4, 2

Aggregated Review:
### Key Points
This paper presents the Atomic Visual Skills Benchmark (AVSBench), a dataset aimed at evaluating Vision Language Models (VLMs) on their ability to comprehend basic geometric features, termed atomic visual skills. The benchmark includes 5,073 handcrafted image-question-answer pairs covering 36 skills, such as understanding angles, boundaries, and congruence. It highlights the limitations of current VLMs, which struggle with these tasks despite their success in more complex scenarios. The authors propose that the skills evaluated are fundamental for geometric problem-solving.

### Strengths and Weaknesses
Strengths:
1. AVSBench offers a comprehensive breakdown of 36 atomic visual skills relevant to high-school level geometry, enabling granular evaluation of VLM capabilities.
2. The paper addresses a significant issue—VLMs' failures in simple visual comprehension tasks—contributing to the understanding of VLM behavior.
3. The evaluation includes several state-of-the-art VLMs, providing insights into their performance across varying task difficulties.

Weaknesses:
1. Hypothesis 1 is not directly addressed; the authors should clarify why multi-skill tasks were excluded.
2. The skill difficulties are subjectively determined without independent validation; the authors should consider using independent annotators.
3. The claim that high school geometry curricula are generally agreed upon lacks citation; the authors should either provide a reference or rephrase this claim.
4. The evaluation setup is overly complicated, as it involves using another LLM (GPT mini) to extract responses; a more streamlined approach could enhance clarity.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Hypothesis 1 by explicitly addressing the exclusion of multi-skill tasks. Additionally, we suggest employing independent annotators to validate the skill difficulty assessments. To strengthen the claim regarding high school geometry curricula, we advise providing a reference or rephrasing it to "minimal common curricular elements." Furthermore, simplifying the evaluation setup by allowing models to generate responses in a specific format could enhance the methodology. Lastly, we encourage the authors to explore fine-tuning models like Llava specifically on AVS skills to assess potential performance improvements.