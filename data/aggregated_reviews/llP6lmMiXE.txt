ID: llP6lmMiXE
Title: A General Framework for Robust G-Invariance in G-Equivariant Networks
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 7, 3, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel G-triple correlation (G-TC) layer aimed at enhancing robustness and group-invariance in group-equivariant convolutional neural networks (G-CNNs). The G-TC layer utilizes triple correlation on groups, providing a complete polynomial invariant map that retains the signal's structure while removing variations due to group actions. The authors claim that this approach improves classification accuracy over standard Max G-Pooling and demonstrates strong robustness against invariance-based adversarial attacks. The paper discusses the limitations of traditional pooling operations in G-CNNs and proposes a method to uncouple invariance from coarse-graining, supported by empirical results across various datasets. Additionally, the authors address previous reviewer concerns regarding completeness and adversarial experiments, proposing to incorporate clarifications into the final version to strengthen the paper.

### Strengths and Weaknesses
Strengths:
- The paper addresses the information loss associated with pooling operations in equivariant architectures, offering a fresh perspective on the importance of pooling.
- The introduction of the triple correlation operator is a novel contribution with potential benefits for the machine learning community.
- The overall presentation is clear, making the paper easy to read and understand, with empirical results suggesting benefits from the G-TC layer.
- The authors demonstrate a willingness to engage with reviewer feedback and clarify misunderstandings, indicating a commitment to improving their work.

Weaknesses:
- The proposed method is limited to discrete groups, making it challenging to extend to continuous groups like $SO(3)$ or $SE(3)$.
- The computational complexity of the G-TC layer is $O(|G|^2)$, which may restrict its applicability to larger groups.
- The background on signals lacks established terminology from fiber bundles, which could enhance clarity.
- The experimental setup is limited to toy datasets like MNIST, with a recommendation to explore larger-scale datasets for validation.
- Some points regarding completeness and adversarial experiments were not sufficiently clear in the original submission, suggesting a need for better articulation of these concepts.

### Suggestions for Improvement
We recommend that the authors improve the applicability of the G-TC layer by discussing potential extensions to continuous groups. Additionally, addressing the computational complexity and exploring ways to reduce it would strengthen the paper. The authors should consider revising the background section to incorporate established language from fiber bundles to enhance clarity. Expanding the experimental validation to include larger-scale datasets, such as CIFAR-10, would provide a more comprehensive evaluation of the proposed method's effectiveness. Lastly, we recommend that the authors improve the clarity of the sections on completeness and adversarial experiments in the final version to ensure that these critical aspects are well understood by readers.