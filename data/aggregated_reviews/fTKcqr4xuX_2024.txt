ID: fTKcqr4xuX
Title: Label Noise: Ignorance Is Bliss
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 7, 8, 5, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 2, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a theoretical framework for learning under multi-class, instance-dependent label noise, introducing the concept of Relative Signal Strength (RSS) to measure noise impact. It derives upper and lower bounds on excess risk and proves the minimax optimality of Noise Ignorant Empirical Risk Minimization (NI-ERM). The authors propose a two-step 'feature extraction + NI-ERM' approach, achieving state-of-the-art performance on the CIFAR-N dataset. The paper also provides experimental validation of theoretical claims, demonstrating alignment between performance changes and theoretical predictions. Additionally, the authors explore the fundamental limits in learning with label noise, focusing on the minimax risk without assuming further structure on the data. They emphasize the importance of label quality in determining the size of the set \( A_{\kappa} \) and suggest that incorporating sparsity assumptions can enhance the scalability of the RSS.

### Strengths and Weaknesses
Strengths:
1. Theoretical Depth: The introduction of RSS quantifies noise impact, allowing for precise upper and lower bounds on excess risk.
2. Combination of Theory and Practicality: The two-step approach effectively bridges theory and practice, achieving high performance with simple classifiers.
3. Surprising Results: The proof of NI-ERM's minimax optimality under high noise levels challenges conventional wisdom and achieves state-of-the-art results.
4. Experimental Validation: The paper validates theoretical claims with empirical results on real-world datasets, showing close alignment with theoretical predictions.
5. Strong Theoretical Foundation: The paper provides a robust theoretical exploration of label noise through the RSS framework, directly linking minimax risk to RSS.
6. Scalability Considerations: The exploration of sparsity assumptions enhances the applicability of the proposed method in scenarios with large class numbers.

Weaknesses:
1. Insufficient Introduction: The introduction lacks a comprehensive overview of the paper's contributions and a clearer roadmap of its theoretical and practical aspects.
2. Validity of RSS Definition: The definition of RSS is not intuitive and requires a more thorough justification to establish its representation of signal content relative to the clean distribution.
3. Practical Applicability: The practical applicability of the proposed method may be limited, potentially diminishing its relevance for researchers in label noise learning (LNL).
4. Experimental Validity Concerns: The reliance on pre-trained feature extractors may not provide a fair comparison with other methods, necessitating additional experiments for robust validation.
5. Limited Analysis of Real-World Datasets: The analysis of real-world datasets, while acknowledged as important, is beyond the current scope of the paper.

### Suggestions for Improvement
We recommend that the authors improve the introduction by providing a more detailed overview of the paper's content and contributions, including a clearer roadmap. Additionally, we suggest that the authors clarify the definition of RSS, offering a more intuitive explanation of how it represents the signal content of the noisy distribution relative to the clean distribution. To enhance practical applicability, we recommend that the authors provide more empirical validation of the RSS framework across various datasets. Furthermore, exploring the implications of label quality on the size of \( A_{\kappa} \) in more detail could enhance the paper's relevance. Finally, we suggest that the authors consider expanding the discussion on the limitations of the proposed method to better inform future research directions in LNL.