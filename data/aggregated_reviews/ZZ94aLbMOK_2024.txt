ID: ZZ94aLbMOK
Title: Recurrent neural network dynamical systems for biological vision
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 6, 9, 5, 6, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 4, 2, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents CordsNet, a hybrid architecture that integrates continuous-time recurrent neural networks (RNNs) with convolutional neural networks (CNNs) to enhance biological realism in vision models. The authors claim that CordsNet achieves performance comparable to CNNs on benchmarks like ImageNet while demonstrating greater robustness to noise. They also introduce a toolkit for analyzing these models and illustrate the model's capacity to capture time-dependent neural activity across various cognitive tasks.

### Strengths and Weaknesses
Strengths:
1. CordsNet exhibits strong connections to neural behavior and effectively addresses continuous-time modeling, potentially inspiring future biologically feasible network designs.
2. The novel approach of sharing weights between convolutional and recurrent operations is a significant advancement, as these are typically executed sequentially.
3. The introduction of analytical tools for convolutional structures in dynamical systems is promising for future research, although more detail is required.

Weaknesses:
1. The comparative analysis lacks comprehensiveness, particularly as some results do not involve models with equivalent temporal processing capabilities, and comparisons to similar temporal models like convolutional RNNs are missing.
2. The choice of image datasets raises concerns, as the discrete-time nature of the datasets may limit the advantages of continuous-time training. The benefits of intra-batch information flow should be more evident with naturally sequential images.
3. The model's advantages over existing hybrid models remain unclear, as it shares design intuitions with convolutional RNNs and lacks comparisons with state-of-the-art architectures such as CNN + vision Transformers.
4. The regularization term's effectiveness is questionable, and further ablation studies are needed to justify various design choices.

### Suggestions for Improvement
We recommend that the authors improve the comparative analysis by including models with similar temporal processing capabilities and conducting comparisons with convolutional RNNs and other relevant architectures. Additionally, we suggest that the authors clarify the advantages of their model over discrete-time models by exploring continuous-time vision tasks, such as video prediction and feature extraction. To strengthen the paper, we encourage the authors to include ablation studies that examine the impact of different design choices, such as varying the number of recurrent iterations or modifying the loss function. Finally, we advise that critical technical details currently relegated to the appendix be incorporated into the main text for better clarity and completeness.