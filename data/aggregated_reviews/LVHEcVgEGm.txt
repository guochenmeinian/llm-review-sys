ID: LVHEcVgEGm
Title: Diffusion Models and Semi-Supervised Learners Benefit Mutually with Few Labels
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 7, 6, 6, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel training strategy called dual pseudo training (DPT) that enhances semi-supervised learning and generative models through a three-stage process. First, DPT employs semi-supervised learning methods to predict pseudo-labels on a partially labeled dataset. Second, it trains a conditional generative model using both real and pseudo-labeled data to generate pseudo-images. Finally, the classifier is retrained with a dataset containing both real and pseudo images. Experimental results demonstrate that DPT achieves state-of-the-art performance on image classification tasks on CIFAR-10 and ImageNet.

### Strengths and Weaknesses
Strengths:
- The integration of semi-supervised learning with diffusion models is a novel approach that shows mutual benefits.
- DPT significantly improves performance in both generative and discriminative tasks, achieving state-of-the-art results.
- The writing is clear and the methodology is easy to follow.
- Comprehensive ablation studies in the appendix address several reviewer questions.

Weaknesses:
- The baseline diffusion method using full labels is inherently stronger than the proposed method, making claims of superiority misleading.
- Comparisons with previous works are unfair due to differing settings; the authors should align their methods with established baselines.
- Discussions on computational efficiency and wall clock time are lacking, which is critical given the known slow inference of diffusion models.
- The novelty of the approach may not be sufficiently highlighted, and the paper lacks detailed analysis of the interaction between the generative model and semi-classifier.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their claims regarding the performance of DPT compared to baseline methods with full supervision. It would be beneficial to align their experimental settings with those of previous works for fair comparisons. Additionally, we suggest including a discussion on computational efficiency and wall clock time to provide a clearer understanding of the method's practicality. The authors should also emphasize the technical novelty of their approach in the abstract and introduction. Finally, a more detailed analysis of the interaction between the generative model and semi-classifier would strengthen the paper's contributions.