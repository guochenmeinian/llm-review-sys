ID: qgmrC8jhCo
Title: Convolutional Visual Prompt for Robust Visual Perception
Conference: NeurIPS
Year: 2023
Number of Reviews: 24
Original Ratings: 3, 7, 6, 4, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method for test-time adaptation (TTA) using Convolutional Visual Prompts (CVP) to address out-of-distribution (OOD) data. The authors propose leveraging convolutional structures as inductive biases, which reduces the number of trainable parameters while enhancing model robustness against OOD corruptions. The authors argue that their approach operates under a more challenging scenario than traditional TTA methods, where model weights cannot be adjusted during testing. They demonstrate state-of-the-art performance in various tables compared to visual prompt baselines and clarify that TTA methods rely on pre-trained models from the source domain, which is essential for adaptation. Experimental results indicate that CVP improves performance on benchmark datasets and complements existing weight-adaptation methods.

### Strengths and Weaknesses
Strengths:
1. The use of convolutional operations for OOD test-time adaptation is innovative and effectively reduces required parameters.
2. The method is label-free and can be combined with other weight adaptation techniques, showing promising results across various self-supervised objectives.
3. The authors provide robust experimental results showing that their method, CVP, outperforms prior prompting strategies, especially under structured and style perturbations.
4. The paper is well-structured, with extensive empirical results and clear explanations, and addresses reviewer concerns effectively.

Weaknesses:
1. The motivation for using convolutional structures is not adequately justified, particularly regarding their effectiveness for high-level distribution shifts.
2. Comparisons with prior works are limited, and the paper does not address unimodal ViT architectures or provide guidelines for hyperparameter selection across different datasets.
3. The experimental results show only marginal improvements over existing methods, raising questions about the significance of the proposed approach.
4. The comparison with unpublished work (Gao et al. 2022) is acknowledged but not yet included, limiting the current evaluation scope.
5. There is a lack of direct comparisons between CVP and prompts with the same number of parameters, which could strengthen the argument for the convolutional structure's effectiveness.

### Suggestions for Improvement
We recommend that the authors improve the justification for choosing convolutional structures as the basis for CVP, possibly by hypothesizing their role as de-corruption operators for specific corruptions. Additionally, we suggest including comparisons with a broader range of prior works, particularly unimodal ViT architectures, and providing clearer guidelines for hyperparameter selection. We also recommend including a direct comparison of CVP with prompts that have an identical number of parameters to reinforce the significance of using convolutional structures. Furthermore, we encourage the authors to incorporate the results from their ongoing experiments combining standard VPT with other TTA methods into the paper. Lastly, clarifying the use of SSL objectives during source training for MEMO, BN, and TENT methods would enhance transparency regarding the experimental setup.