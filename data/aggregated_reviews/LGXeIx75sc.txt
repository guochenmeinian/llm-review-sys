ID: LGXeIx75sc
Title: Where's Waldo: Diffusion Features For Personalized Segmentation and Retrieval
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 4, 7, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 2, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method called Personalized Diffusion Features Matching (PDM) for personalized retrieval and segmentation tasks, utilizing pre-trained text-to-image diffusion models without requiring additional training. PDM effectively combines semantic and appearance features to accurately identify and segment unique instances, even in scenarios with multiple similar objects. The authors introduce a new benchmark dataset that addresses limitations in existing datasets, demonstrating PDM's superior performance compared to both self-supervised and supervised methods.

### Strengths and Weaknesses
Strengths:
- The innovative use of pre-trained models in a zero-shot setting is beneficial for users with limited computational resources.
- The combination of appearance and semantic similarity in the proposed method is well-motivated and technically sound.
- The paper is well-organized, clearly written, and presents insightful observations regarding self-attention and cross-attention in diffusion models.

Weaknesses:
- The logical flow before the Method Section requires adjustment for better clarity regarding the problem being addressed.
- The task form is unclear, particularly in defining the input information and its relevance.
- The authors' approach of averaging appearance and semantic features may lead to segmentation errors due to lack of weighted fusion.
- There is insufficient theoretical justification for the choice of diffusion models over other architectures, and the visualized results do not adequately capture the intended problem.

### Suggestions for Improvement
We recommend that the authors improve the logical flow prior to the Method Section to clarify the problem statement and task form. Clearly defining the task and presenting settings for different scenarios will enhance reader understanding. Additionally, the authors should consider implementing a weighted fusion of appearance and semantic features to improve segmentation accuracy. We also suggest providing a more robust theoretical justification for the choice of diffusion models, including comparisons with other state-of-the-art models. Finally, the authors should ensure that visualized results effectively demonstrate the challenges of identifying instances within the same class.