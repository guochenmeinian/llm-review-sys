ID: SCEdoGghcw
Title: Measuring Progress in Dictionary Learning for Language Model Interpretability with Board Game Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 5, 7, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents two measures to evaluate the quality of trained sparse autoencoders (SAE) in decomposing superposition features, achieving approximate L0 optimization through dynamic adjustment of the p-norm. The authors apply these techniques to two board games, Othello and chess, providing a controlled environment for testing. They introduce a warm-start technique called *p-annealing* to optimize SAE objectives and propose two new F1-based metrics: "coverage" and "board reconstruction" to assess feature recovery.

### Strengths and Weaknesses
Strengths:  
- The research direction is valuable, addressing the interpretability of SAE decompositions, which previous works did not measure directly.  
- The proposed metrics and p-annealing technique are intuitive and demonstrate superior performance compared to standard SAE objectives.  
- The paper is well-presented, with clear writing and thorough experiments that validate the applicability of SAEs for feature learning in the chosen tasks.

Weaknesses:  
- The experimental objectives are unclear, lacking comparisons of the proposed measurement methods against reconstruction loss and sparsity.  
- The rationality of the proposed measurement methods is questionable, as experimental results show no significant difference between low-level and high-level coverage.  
- The figures and captions do not align correctly, leading to confusion regarding the data presented.  
- There is insufficient qualitative analysis of the trained SAEs alongside the new metrics, which would enhance understanding of their interpretability.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the experimental objectives by explicitly comparing the advantages of the proposed measurement methods with reconstruction loss and sparsity. Additionally, we suggest addressing the discrepancies in the figures and captions to ensure accurate representation of the data. It would be beneficial to include qualitative evaluations of the trained SAEs to complement the quantitative metrics. Finally, expanding the scope of the research to include more domains and datasets would help validate the effectiveness of the proposed methods in various interpretability tasks.