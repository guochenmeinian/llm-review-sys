ID: uFXGsiYkkX
Title: BAKU: An Efficient Transformer for Multi-Task Policy Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 7, 6, 5, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a model for multi-task behavior cloning in robotics, systematically comparing various architectural components from prior works to develop a composite architecture that performs well in both simulated and real-world tasks. The authors conduct extensive experiments and detailed ablation studies, demonstrating a performance improvement of approximately 20% over baselines. The architecture, BAKU, consists of sensory encoders, an observation trunk, and an action head, showcasing its effectiveness in training generalist policies.

### Strengths and Weaknesses
Strengths:
- Strong results relative to chosen baselines in both simulated and real-world tasks.
- Thorough investigation of different viable architecture designs and comprehensive ablations.
- Clear and well-organized presentation of the work.
- Impressive performance (>90%) with limited demonstrations on real robots.

Weaknesses:
- No variance or confidence intervals reported for results in simulated environments.
- Limited number of baselines, with some being outdated.
- Conclusions about architectural choices primarily based on simulation, with real-world results showing inconsistencies.
- The novelty of the proposed architecture is limited, as it combines existing approaches without introducing new design choices.
- Statistical significance of results is questionable due to limited evaluation rollouts and random seed reliance.

### Suggestions for Improvement
We recommend that the authors improve the statistical robustness of their results by conducting evaluations across multiple random seeds and providing variance or confidence intervals for their findings. Additionally, it would be beneficial to include a more extensive comparison of performance across different data scales and to clarify the efficiency claims regarding the BAKU architecture. We suggest discussing the implications of architectural choices on inference speed and success rates in more detail, particularly when trade-offs are made for computational efficiency. Finally, sharing the code is essential for replicability, given the empirical nature of the study.