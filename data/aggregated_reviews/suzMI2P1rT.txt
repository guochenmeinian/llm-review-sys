ID: suzMI2P1rT
Title: CEIL: Generalized Contextual Imitation Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 6, 6, 6, 6, 7, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method called ContExtual Imitation Learning (CEIL), which aims to effectively address various imitation learning (IL) tasks, including learning from observations (LfO), offline IL, cross-domain IL, and one-shot IL. CEIL employs a bi-level expert matching objective that decouples the learning policy into a contextual policy and an optimal embedding, utilizing hindsight information matching principles. Empirical results demonstrate that CEIL achieves improved sample efficiency in online IL and performs well across different offline IL settings.

### Strengths and Weaknesses
Strengths:
1. The proposed method is novel and adaptable to multiple IL tasks with minimal adjustments.
2. Extensive experiments across eight different IL settings show that CEIL outperforms previous baselines in most environments.
3. The paper provides a clear presentation of ideas and a comprehensive review of existing methodologies.

Weaknesses:
1. The claim of addressing all IL settings appears overly ambitious, as only two MuJoCo tasks were evaluated online and four offline, leading to insufficient experimental evidence.
2. The relationship between the pre-defined return and the hindsight embedding function is not discussed, and the ablation study lacks insights into the effectiveness of the J_MI term.
3. The paper introduces several hyperparameters without guidance on their selection, and there is ambiguity in the notation for regularization losses.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the relationship between the return function and the hindsight embedding function to clarify their connection. Additionally, conducting an ablation study that isolates the J_MI term would enhance understanding of its contribution. We also suggest providing guidance on hyperparameter selection and clarifying the notation for regularization losses to reduce confusion. Finally, addressing the performance of CEIL in settings with only expert demonstrations would strengthen the paper's claims regarding its general applicability.