ID: C3ZHiij9QE
Title: VLMimic: Vision Language Models are Visual Imitation Learner for Fine-grained Actions
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 7, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents VLMimic, a framework for acquiring robotic skills through imitation from videos, leveraging Vision-Language Models (VLMs) and various vision tools to ground human-object interactions into actionable skills. The authors demonstrate that VLMimic achieves superior performance in both simulated and real-world manipulation tasks, with significant generalization capabilities from minimal demonstrations.

### Strengths and Weaknesses
Strengths:
1. VLMimic learns both high-level action planning and fine-grained low-level actions, a notable advancement over previous works.
2. The method shows impressive performance across real robots and diverse tasks, supported by substantial evaluations and ablation studies.
3. The writing is generally well-organized, making the paper easy to follow.

Weaknesses:
1. The scalability of the system is unclear, particularly regarding the memory cost of the knowledge bank and the speed of iterative comparisons when scaled.
2. The integration of multiple foundation models and vision tools complicates the process, relying heavily on human prior knowledge, which may limit adaptability to various interaction objects.
3. Some definitions and descriptions within the paper are vague or inconsistent, which could lead to confusion.

### Suggestions for Improvement
We recommend that the authors improve clarity by revising vague definitions, particularly regarding keypoint values and visualized interactions. Additionally, the authors should provide a more detailed discussion on the scalability of the system and the construction and access of the knowledge bank. It would also be beneficial to clarify the distinctiveness of the skills learned compared to existing frameworks, as well as to address the surprisingly low performance of baseline algorithms in evaluations.