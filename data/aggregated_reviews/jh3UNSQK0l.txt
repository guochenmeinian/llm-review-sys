ID: jh3UNSQK0l
Title: Finite-Time Analysis of Single-Timescale Actor-Critic
Conference: NeurIPS
Year: 2023
Number of Reviews: 19
Original Ratings: 6, 6, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the actor-critic algorithm's convergence under a single-timescale update, achieving a sample complexity of $\tilde{O}(\epsilon^{-2})$ under standard assumptions and $O(\epsilon^{-2})$ under i.i.d. sampling. The authors improve the convergence rate from $\tilde{\mathcal{O}}(\epsilon^{-2.5})$ to $\tilde{\mathcal{O}}(\epsilon^{-2})$, matching the rate of standard SGD for non-convex functions. The analysis extends the small-gain approach to the average-reward setting, leveraging uniform ergodicity assumptions to handle Markovian sampling. Additionally, the authors provide a thorough analysis of the continuous state space setting, emphasizing the establishment of a system of inequalities and detailing their foundational building blocks tailored for this context, contrasting their approach with that of Oleshevsky & Gharesifard (2023).

### Strengths and Weaknesses
Strengths:  
- The paper provides a notable finite sample analysis for single-timescale actor-critic under Markovian noise and infinite state space.
- The theoretical problem is well-motivated, and the proposed analysis framework establishes a sample complexity that matches the best existing results for single-timescale AC algorithms.
- The writing is clear, and the policy gradient norm error analysis is interesting.
- The authors clearly distinguish their contributions from existing literature, particularly in handling continuous state space challenges, and their detailed explanation of necessary assumptions enhances understanding.

Weaknesses:  
- The presentation lacks sufficient discussion on how the authors improved the convergence rate and why previous works failed to do so, which is crucial for appreciating the technical contribution.
- Assumption 3.4 is considered too strong, and its applicability to continuous state spaces is unclear.
- The authors introduce a new assumption regarding geometric mixing of the Markov chain, which may not be commonly applicable in practice.
- Some reviewers initially misunderstood the complexity of the continuous action setting, indicating that the paper may not have fully conveyed the challenges involved.
- The connection to existing works on single-loop AC algorithms is limited, and the discussion of the i.i.d. sampling case appears oversold.

### Suggestions for Improvement
We recommend that the authors improve the discussion on how their analysis enhances the convergence rate and clarify why prior works did not achieve similar results. Additionally, addressing the applicability of Assumption 3.4 in continuous state spaces and providing a justification for the geometric mixing assumption would strengthen the paper. The authors should also expand the related work section to include discussions on existing single-loop AC algorithms and clarify the implications of their results in comparison to these works. Furthermore, we suggest that the authors improve the clarity of their explanations regarding the complexities of the continuous state space setting to prevent misunderstandings, and further elaborate on the implications of their unique assumptions compared to existing works to enhance the paper's comprehensibility. Finally, providing more detailed explanations regarding the handling of continuous state spaces and the specific efforts made to overcome challenges in this context would be beneficial.