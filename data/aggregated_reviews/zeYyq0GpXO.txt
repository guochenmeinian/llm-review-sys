ID: zeYyq0GpXO
Title: Exploring Context Window of Large Language Models via Decomposed Positional Vectors
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 6, 7, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a detailed analysis of positional vectors within a pretrained Transformer language model, aiming to enhance understanding of length extrapolation. The authors propose two context-extending techniques, demonstrating through experiments that these methods reduce perplexity in language modeling tasks.

### Strengths and Weaknesses
Strengths:  
- The paper provides a mechanistic interpretability perspective on hidden states, potentially inspiring future research.  
- It is well-written, with main findings clearly highlighted.  
- The analysis of positional information propagation through layers is detailed and insightful, particularly illustrated in Figures 2 and 3.  
- Experiments indicate improved perplexity scores with the new methods beyond the context window.

Weaknesses:  
- The experimental results are not sufficiently convincing; further validation is needed.  
- Section 4 appears weak and may detract from the overall contribution, as its proposed context extension is less favorable compared to mainstream approaches.  
- The analysis is limited to TinyLLaMA, raising concerns about generalizability to other models.  
- Some figures, such as Figure 4, have overlapping legends and graphs.

### Suggestions for Improvement
We recommend that the authors improve the experimental design by training models from scratch using the 50B tokens budget to eliminate the ripple effect of the original rope positional embeddings. Additionally, we suggest incorporating the "needle in a haystack" experiment to better assess the models' utilization of long-context information. It would also be beneficial to clarify how the values of alpha and lambda in sections 4.1 and 4.2 were determined, and to include a discussion on the relationship between positional information and needle-in-a-haystack performance. Finally, we strongly suggest verifying the behavior of positional embeddings on widely used models such as LLaMA 3, Mistral, QWen, or Yi, and consider removing Section 4 to allocate space for more experimental analysis of positional vectors.