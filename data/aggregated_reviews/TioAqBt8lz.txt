ID: TioAqBt8lz
Title: Structure-aware Knowledge Graph-to-text Generation with Planning Selection and Similarity Distinction
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to KG-to-text generation that integrates graph-structure-aware modules with pretrained language models (PLMs). The authors propose a learnable planner to preprocess input knowledge graphs (KGs) for the PLMs, alongside a planning scorer to enhance the linearization of KG triples and a contrastive learning loss that utilizes negative examples. The method is evaluated on two benchmarks, Weblog and DART, demonstrating strong performance and the effectiveness of its components, despite relatively small gains.

### Strengths and Weaknesses
Strengths:
- The paper is well written and clearly understandable.
- The proposed model is novel and well-motivated, combining PLMs with graph-aware encoders.
- Convincing experimental results, including an ablation study and evaluation of the planner.
- Strong performance on KG-to-text benchmarks.

Weaknesses:
- The ablation study shows small effects, raising questions about the importance of the new architecture.
- The proposed graph-aware attention is similar to existing work, reducing its novelty.
- The text generation model does not utilize a pretrained LM, which is unexpected given the state-of-the-art context.
- Some equations and concepts lack clarity, leading to potential inconsistencies.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the training process for the planning scorer, ensuring that the order of predictions aligns with the text generation model. Additionally, we suggest clarifying the initialization of the relative distance matrix \( R_{ij} \) in Eq. (9) and addressing whether \( R_{ij} \) equals \( R_{ji} \). It would also be beneficial to analyze the effect of the parameter \( \lambda \) in Eq. (13) through further experiments. Furthermore, we encourage the authors to consider human evaluation to validate the improvements over previous approaches, as automatic metrics may not fully capture model performance. Lastly, exploring the diversity aspect of the KG-to-text task in experiments could enhance the study's contributions.