ID: Y13EvAJlhQ
Title: Instructive Dialogue Summarization with Query Aggregations
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel instruction-tuning method aimed at enhancing dialogue summarization models through a comprehensive three-step approach for synthesizing high-quality query-based summarization triples. The authors propose generating synthetic data from reference summaries, which is then used to instruction-tune the Flan-T5-XL model. The study demonstrates that this synthetic data-based instruction-tuning significantly improves performance across various dialogue summarization tasks, supported by extensive evaluations, including human assessments and comparisons with state-of-the-art models.

### Strengths and Weaknesses
Strengths:
- The study is well-conducted, featuring extensive evaluations, ablation studies, and a thorough analysis of results.
- The novel approach to synthetic data generation is creative and effectively addresses the scarcity of query-based dialogue summarization data.
- The paper is well-written, making it accessible and easy to understand.

Weaknesses:
- The technical contribution may be perceived as limited since the approach primarily involves prompting LLMs.
- There is a lack of empirical investigation comparing the quality of data generated when conditioning on dialogues versus reference summaries.
- The differences between instructive dialogue summarization and query-focused summarization are not clearly articulated.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the task by better defining instructive dialogue summarization and its relationship to query-focused summarization. Additionally, discussing the omission of QMSum from the datasets would enhance the paper's relevance. We also suggest conducting a formal investigation into the quality of data generated from dialogues compared to reference summaries to strengthen the claims made. Finally, including missing references to recent works on query-focused summarization would provide a more comprehensive context for the study.