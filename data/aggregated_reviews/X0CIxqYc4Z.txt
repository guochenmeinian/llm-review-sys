ID: X0CIxqYc4Z
Title: Risk-Averse Model Uncertainty for Distributionally Robust Safe Reinforcement Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 5, 6, 6, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Risk-Averse Model Uncertainty (RAMU) framework for safe reinforcement learning (RL) in uncertain environments, incorporating a distribution of transition models and coherent distortion risk measures. The authors propose a model-free implementation that avoids complex minimax optimization, demonstrating robust performance across various perturbed test environments. Theoretical equivalences to distributionally robust safe RL problems are established, and the RAMU Q function and Bellman operators are introduced.

### Strengths and Weaknesses
Strengths:
- The RAMU framework effectively addresses model uncertainty in safe RL, providing a solid foundation for practical implementation.
- The paper is well-structured, with clear theoretical underpinnings and a detailed experimental section that showcases the efficacy of the proposed method.

Weaknesses:
- The novelty of the theoretical results, particularly regarding risk duality and minimax optimization, is questioned as these concepts are well-established.
- The paper lacks clarity in defining the relationship between safety and robustness, particularly in the context of Constrained Markov Decision Processes (CMDPs).
- Experimental comparisons with existing distributionally robust methods are insufficient, focusing instead on adversarial RL and domain randomization.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the relationship between safety and robustness, particularly in the context of CMDPs, and explicitly state the contributions of their work in relation to existing literature. Additionally, including a proof of Lemma 2 in Appendix B.2 would enhance self-containment. The authors should also consider comparing their method with existing distributionally robust approaches to strengthen the empirical evaluation. Furthermore, we suggest clarifying the necessity of using coherent distortion risk measures and providing a more explicit formulation of Theorem 1 to aid reader comprehension. Lastly, highlighting the best results in Table 1 rather than their own would provide clearer insights into the performance of their method.