ID: 0uGlKYS7a2
Title: Maximizing utility in multi-agent environments by anticipating the behavior of other learners
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 6, 3, 6, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis of optimally exploiting a learning agent in zero-sum and general-sum games. The authors propose a continuous-time algorithm for zero-sum games using replicator dynamics, providing an explicit expression for the optimal utility of the exploiter agent. They also extend this to a discrete-time setting, demonstrating that the discretized strategy achieves at least the same utility and can exceed it. For general-sum games, the paper establishes that determining the optimal utility against a Best Response Algorithm is NP-hard. The authors conclude with open problems regarding polynomial-time optimizers in general-sum games.

### Strengths and Weaknesses
Strengths:
- The paper makes a significant contribution by analyzing the exploitation of mean-based learners, presenting both an impossibility result and a characterization of the zero-sum case.
- The mathematical analysis is rigorous, and the connection to optimal control is intriguing.
- The writing is clear and well-motivated, with a relevant discussion on societal impact.

Weaknesses:
- The absence of empirical simulations is notable; numerical computations of optimal strategies would enhance understanding.
- The focus on MWU and related algorithms limits applicability, and an impossibility result for no-regret algorithms would be valuable.
- The computational hardness result, while interesting, lacks surprise given existing hardness results in game theory.
- The presentation could benefit from clearer explanations and examples, particularly in the zero-sum case.

### Suggestions for Improvement
We recommend that the authors improve the organization and clarity of the presentation, ensuring that results are contextualized and clearly stated. A shorter introduction summarizing contributions without theoretical detail would enhance readability. Additionally, we suggest including empirical evaluations of the proposed algorithms to demonstrate their effectiveness. Clarifying the choice of MWU and replicator dynamics as models for the learner would add depth. Finally, addressing unclear notation and providing concrete examples in the appendix would further aid comprehension.