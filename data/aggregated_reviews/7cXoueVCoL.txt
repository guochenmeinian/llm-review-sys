ID: 7cXoueVCoL
Title: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, 5

Aggregated Review:
### Key Points
This paper presents the CodeBERTScore model, which extends the BERTScore metric for evaluating code generation by incorporating natural language input alongside generated code. The authors claim that CodeBERTScore achieves higher correlation with human preferences and functional correctness across multiple programming languages, supported by extensive empirical research. They also release pretrained models on HuggingFace, enhancing accessibility for researchers and practitioners.

### Strengths and Weaknesses
Strengths:  
- The paper addresses a significant challenge in code generation evaluation, providing a practical and open-access resource.  
- Extensive evaluation demonstrates improved correlation with human preference and functional correctness compared to existing metrics.  
- The writing is clear and the methodology is well-structured, facilitating reproducibility.

Weaknesses:  
- The contribution is seen as incremental, primarily extending BERTScore without significant novelty.  
- CodeBERTScore lacks customization for code-specific features, such as syntax and data flow information.  
- Observations indicate potential robustness issues, particularly in distinguishing between similar code implementations.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their work by exploring additional features specific to code, such as syntax and data flow information. Additionally, addressing the robustness of CodeBERTScore is crucial; the authors should investigate its performance in recognizing different implementations of functional code. Lastly, we suggest that the authors clarify their choice of base models and pre-training methods, considering alternatives like GraphCodeBERT and UniXcoder, and explain why they did not utilize contrastive learning tasks.