ID: z1nITsHKb4
Title: MMScan: A Multi-Modal 3D Scene Dataset with Hierarchical Grounded Language Annotations
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 6, 7, 9, 5, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 5, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents MMScan, a large-scale multi-modal 3D dataset designed to enhance 3D vision language tasks using LLMs and VLMs. It features 6.9 million language annotations across 5,000 scenes, supporting benchmarks for visual grounding and 3D question answering. The authors propose a top-down annotation framework that combines LLM-based language annotation with human refinement, aiming to address existing limitations in 3D scene datasets.

### Strengths and Weaknesses
Strengths:
- MMScan is the largest 3D scene understanding dataset with hierarchical language annotations, significantly benefiting multi-modal 3D perception research.
- The dataset includes both object-level and region-level annotations, which is a novel contribution compared to prior works.
- Experimental results demonstrate the dataset's utility in training models and improving performance on benchmarks.

Weaknesses:
- Many findings are not novel, as they replicate results from existing datasets like 3D-VisTA and SceneVerse.
- The dataset lacks manual validation, making it unclear whether it poses a sufficient challenge.
- There is insufficient discussion on potential biases in the dataset and a lack of comparison with the latest related works.

### Suggestions for Improvement
We recommend that the authors improve clarity regarding the annotation process, including details on manual correction and the extent of human involvement. Additionally, it is crucial to address potential dataset biases and provide a comprehensive comparison with recent datasets like SceneVerse. We suggest including a table that clearly demonstrates the performance of baseline methods on existing benchmarks and how pre-training on MMScan affects their performance. Furthermore, the authors should clarify the licensing details for the annotations and ensure that the dataset is easily accessible, as the current lack of clarity may hinder its use by the research community.