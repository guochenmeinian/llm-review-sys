ID: gzQARCgIsI
Title: End-To-End Causal Effect Estimation from Unstructured Natural Language Data
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 4, 8, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach for causal effect estimation using large language models (LLMs) to mine unstructured observational text data. The authors propose a pipeline named NATURAL, which extracts treatment, covariates, and outcomes from text, addressing limitations of current methods that struggle with unstructured data. The methodology is evaluated on six datasets, demonstrating that NATURAL estimators yield causal effect estimates close to ground truth from randomized trials.

### Strengths and Weaknesses
Strengths:
1. The problem solution for treatment effect estimation is innovative and addresses a significant gap in handling unstructured data.
2. The methodology is well-formulated, and the development of six datasets enhances the evaluation of the proposed method.
3. Empirical results indicate that NATURAL estimators produce estimates that are within a close range of ground truth values.

Weaknesses:
1. The presentation lacks clarity, with some claims poorly explained, leading to confusion.
2. Certain equations and assumptions are incorrect or overly strict, which may limit the applicability of the method.
3. The evaluation is weak, relying on limited and simplistic baselines, and does not adequately address potential biases introduced by the LLM pipeline.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their writing, particularly in sections where complex ideas are presented, such as lines 54-59. Additionally, addressing the inaccuracies in equations and assumptions, particularly regarding the binary and discrete nature of outcomes and covariates, would enhance the paper's rigor. The authors should provide clearer explanations of how covariates are extracted and their real-world implications, possibly including specific examples. Furthermore, expanding the evaluation to include more robust baselines and discussing the implications of biases in LLM outputs would strengthen the findings. Lastly, a deeper analysis of error propagation in causal effect estimation would be beneficial.