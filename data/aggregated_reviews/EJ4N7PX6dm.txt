ID: EJ4N7PX6dm
Title: Improved Pseudo Data for Machine Translation Quality Estimation with Constrained Beam Search
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new data-augmentation method for translation quality estimation (QE) using constrained beam search on a machine translation (MT) model. The authors propose generating pseudo data that enhances translation quality by manipulating generation probabilities based on original translation probabilities and positions. Experiments conducted on WMT19, WMT20, and WMT21 demonstrate significant improvements in both supervised and unsupervised scenarios compared to existing methods.

### Strengths and Weaknesses
Strengths:
- The proposed method effectively improves translation quality without requiring post-training adjustments.
- The approach addresses the "false negative" problem in pseudo data construction, yielding better pseudo labels.
- The paper is well-structured, with comprehensive experimental setups and results showing improvements over baseline methods.

Weaknesses:
- The reliance on a pre-trained MT model limits applicability, particularly for low-resource languages.
- The calculation of HTER labels using automatic scripts lacks scalability to other annotation types.
- Improvements over baselines are sometimes marginal, and significant metrics like mean absolute error (MAE) and root-mean-square deviation (RMSE) are missing.
- Certain sections, particularly the method description, are unclear and require better articulation.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing, particularly in the method section, to enhance comprehension. Specifically, they should proofread and modify expressions that may confuse readers. Additionally, we suggest including MAE and RMSE metrics in the results and conducting significance tests on the obtained results to validate the improvements. Finally, the authors should consider experimenting with other languages and annotations to demonstrate the scalability of their method.