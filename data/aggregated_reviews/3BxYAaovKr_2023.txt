ID: 3BxYAaovKr
Title: Ego4D Goal-Step: Toward Hierarchical Understanding of Procedural Activities
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: -1, 7, 7, 5, 7, -1, -1, -1, -1, -1, -1
Original Confidences: -1, 3, 3, 3, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the "Ego4D Goal-Step," a novel hierarchical dataset for understanding human activities through goal-oriented labels. It includes a large-scale collection of hierarchical action labels (goals, steps, substeps) derived from procedural videos in the Ego4D dataset, with dense annotations for 47K procedural step segments (442 hours) and high-level goal annotations for 2742 hours of videos. The authors conduct comprehensive experiments to demonstrate the dataset's utility in procedural activity understanding.

### Strengths and Weaknesses
Strengths:
- The dataset provides a large hierarchical taxonomy of goal-oriented activity labels, enhancing human activity recognition.
- Extensive experiments validate the usefulness of the annotations for various tasks, such as temporal action detection and text grounding.
- The authors implement a careful annotation process to ensure label quality and provide auxiliary information, including language summaries and step completion status.

Weaknesses:
- The tested methods are limited, with only a few works evaluated.
- The paper does not fully address the atomic actions in the proposed hierarchy, focusing primarily on goal annotations.
- The clarity regarding the data annotation process and the quality control measures for third-party workers is insufficient.

### Suggestions for Improvement
We recommend that the authors improve the coverage of the full hierarchy by incorporating atomic actions into the annotations. Additionally, we suggest providing more comprehensive information on how to access and utilize the Ego4D Goal-Step dataset, including clearer documentation on the data annotation process and quality control measures. Expanding the discussion on challenges related to the tasks and including multiple baselines for each task would enhance the paper's depth and comparative analysis. Furthermore, we encourage the authors to elaborate on the conclusions drawn regarding the performance of step/substep segments and to analyze the observed performance trends in their experiments more thoroughly.