ID: fKzSz0oyaI
Title: AVeriTeC: A Dataset for Real-world Claim Verification with Evidence from the Web
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 8, 9, 6, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 5, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents AVeriTeC, a comprehensive dataset of 4,568 real-world claims annotated with question-answer pairs and justifications, addressing issues in existing datasets such as context dependence, evidence insufficiency, and temporal leaks. The authors propose a novel evaluation scheme for verifying claims and benchmark multiple LLMs using this dataset.

### Strengths and Weaknesses
Strengths:
- The dataset is rigorously constructed, improving upon existing datasets with a richer claim format.
- A robust multi-step annotation process ensures high-quality evidence and avoids temporal leakage.
- The paper is well-structured and clearly describes the annotation process, making it replicable.
- The empirical analysis is sound, and the dataset serves as a new benchmark for fact-checking research.

Weaknesses:
- The evaluation method does not accommodate alternative lines of justification.
- Some aspects of the baseline system and model choices lack clarity.
- The dataset size is relatively small compared to commonly used datasets like FEVER.

### Suggestions for Improvement
We recommend that the authors improve the evaluation method to handle alternative lines of justification. Additionally, we suggest providing a clearer explanation for the choice of the Hungarian METEOR score over the ROUGE score in the evaluation metric section. It would also be beneficial to expand the dataset to include a broader range of domains and topics. Furthermore, we encourage the authors to clarify the differences in the baseline models used and their specific roles in the pipeline. Lastly, addressing the performance at higher evidence cutoff points with more discussion would enhance the paper's depth.