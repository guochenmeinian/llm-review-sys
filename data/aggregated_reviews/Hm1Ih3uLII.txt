ID: Hm1Ih3uLII
Title: DVSOD: RGB-D Video Salient Object Detection
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 6, 6, 7, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new dataset called DViSal for RGB-D video salient object detection, comprising 237 RGB-D videos, 175,442 RGB-D pairs, and 7,117 annotated frames with instance-level annotations. The authors propose a baseline model that incorporates multimodal and temporal fusion techniques, although these methods are derived from existing studies. The paper evaluates 11 salient object detection (SOD) models on this dataset and discusses the performance of the DVSOD model compared to SPNet, highlighting differences in evaluation metrics and saliency map characteristics. The authors emphasize the effectiveness of integrating multimodal and temporal information for improving detection performance, addressing a gap in existing research. They also acknowledge the limitations of their dataset, including the need for further exploration of inconsistencies between RGB and depth images.

### Strengths and Weaknesses
Strengths:  
1. The dataset is large-scale, diverse, and well-annotated, facilitating further research in RGB-D video salient object detection.  
2. The introduction of the DViSal dataset addresses a significant gap in RGB-D video saliency detection research.  
3. The dataset features comprehensive annotations, including instance-level and weak annotations, enhancing its utility for future studies.  
4. The paper is well-structured and clearly organized, making it easy to follow.  
5. Benchmarking experiments demonstrate the benefits of multimodal video inputs, particularly with depth maps.  
6. The authors have made efforts to address ethical concerns regarding privacy by blurring faces in the dataset.  

Weaknesses:  
1. The application of the research is limited due to the current lack of widespread devices capable of capturing RGB-D video.  
2. The proposed baseline model relies heavily on existing methods for multimodal and temporal fusion, lacking innovative approaches.  
3. The performance of the DVSOD model is relatively poor in certain metrics compared to SPNet, indicating potential areas for improvement.  
4. The contribution is somewhat constrained as the data is derived from existing datasets with added annotations.  
5. The paper lacks a detailed comparison with state-of-the-art methods in RGB-D video salient object detection.  
6. Limitations of the dataset, such as quality and diversity, are acknowledged but not sufficiently addressed in the discussion.  
7. The subjective nature of the annotation process may introduce biases, and the experimental results section does not adequately explain performance differences among models.  

### Suggestions for Improvement
1. We recommend that the authors improve the application scope by discussing the potential for wider adoption of RGB-D capturing devices.  
2. We suggest that the authors enhance the innovation of their DVSOD baseline model by developing proprietary methods for multimodal and temporal fusion rather than relying on existing techniques.  
3. We encourage the authors to include a comprehensive comparison with state-of-the-art methods in the related work section to strengthen the paper's context.  
4. We advise the authors to provide a more thorough analysis of the annotation process to address potential biases and clarify performance differences among models in the experimental results section.  
5. We recommend that the authors investigate the performance discrepancies between their model and SPNet, providing a more detailed analysis of the evaluation metrics used.  
6. To enhance the dataset's quality, we encourage the authors to explore the incorporation of synthetic data to alleviate annotation costs and improve diversity across various scenarios.  
7. Lastly, we advise that the authors mention the dataset name, DViSal, in the title or abstract for better visibility.