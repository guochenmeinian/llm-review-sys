ID: eQ6VjBhevn
Title: Frustratingly Easy Test-Time Adaptation of Vision-Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 26
Original Ratings: 3, 3, 8, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a test-time adaptation (TTA) strategy called ZERO, which critiques the commonly used Marginal Entropy Minimization (MEM) method, demonstrating that MEM often does not enhance predictive performance. The authors propose a straightforward approach that sets the temperature to zero during softmax calculations, claiming it outperforms MEM while being computationally efficient. Additionally, the paper provides a theoretical analysis of TTA methods for Vision-Language Models (VLMs) and discusses the challenges associated with using satellite imagery as a benchmark for TTA, emphasizing the need for careful consideration of domain-specific factors. The experimental results indicate that ZERO shows promise across various benchmarks, although there are concerns regarding its performance on specific datasets.

### Strengths and Weaknesses
Strengths:
1. The paper provides a clear analysis, facilitating a quick understanding of the problem addressed.
2. The proposed method (ZERO) is simple and effective, with good experimental results and a thorough discussion of several baselines.
3. The authors provide a clear theoretical foundation for their claims, demonstrating when MEM does not significantly affect predictions.
4. The simplicity of the proposed method allows for easy reproducibility and potential for widespread adoption.
5. Sections 2.2 and 2.3 offer valuable insights into the effects of MEM on marginal probability distributions and reliability perspectives.
6. The paper includes a comprehensive analysis of the performance of TTA methods across multiple datasets, revealing important insights.

Weaknesses:
1. The observations are not novel, as similar findings have been reported in prior studies.
2. The proposed method lacks flexibility and guarantees, and the experimental results are insufficient, with limited comparison methods and incomplete results across different model architectures.
3. There are concerns regarding the experimental evaluations, particularly the significant performance drop of ZERO on the EuroSAT dataset, which has not been adequately addressed.
4. The theoretical assumptions related to model calibration are questioned, with reviewers noting potential misunderstandings about calibration metrics.
5. Some claims, such as "Poor calibration is always caused by overconfidence," may be overly strong and require moderation.
6. The writing includes many uncommon terms, which can hinder comprehension.
7. Some reviewers express skepticism about the generalizability of the proposed method across different tasks and datasets.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their work by clarifying how their findings differ from existing literature. Additionally, consider providing more flexibility in the proposed method and ensuring comprehensive experimental results across various model architectures. We suggest addressing the performance drop on EuroSAT more clearly by including these findings in the main body of the manuscript rather than relegating them to the appendix. Furthermore, we recommend that the authors address the calibration concerns more thoroughly, ensuring that their theoretical claims align with the empirical evidence presented. We also encourage the authors to clarify the relationship between their proposed method and existing literature on model calibration to strengthen their argument. Lastly, we advise simplifying the language used in the paper to enhance clarity and understanding.