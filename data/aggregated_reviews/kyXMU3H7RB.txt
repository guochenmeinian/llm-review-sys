ID: kyXMU3H7RB
Title: Look Beneath the Surface: Exploiting Fundamental Symmetry for Sample-Efficient Offline RL
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 5, 5, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Time-reversal symmetry enforced Dynamics Model (TDM) and a new offline reinforcement learning (RL) algorithm, TSRL, which leverage fundamental symmetries in system dynamics for sample-efficient offline policy learning. The authors propose embedding and enforcing T-symmetry between latent forward and reverse ODE dynamics to capture essential dynamics patterns in data. Empirical results on D4RL benchmark datasets demonstrate the good generalization ability of TSRL, particularly on small datasets.

### Strengths and Weaknesses
Strengths:
- The idea of using T-symmetry to enhance offline RL performance is novel and intuitively appealing.
- The paper is well-structured and clearly presented, facilitating reader comprehension.
- Comprehensive experiments validate the proposed method's effectiveness, especially with small datasets.

Weaknesses:
- TSRL's performance is not competitive with other baselines in most Adroit human and cloned tasks.
- There is a lack of comparison with other offline RL methods utilizing data augmentation.
- The rationale for the performance gap between small and full datasets is not adequately addressed.
- The choice of the backward model does not fully align with the definition of time-reversal symmetry, raising concerns about its applicability.

### Suggestions for Improvement
We recommend that the authors improve the analysis explaining why TSRL's performance is not comparable with other baselines in most Adroit tasks. Additionally, we suggest adding comparisons with other offline RL methods that utilize data augmentation and including a discussion of related work on data augmentation methods in Section 6. Strengthening the rationale behind the proposed method's ability to improve sample efficiency in offline RL would enhance the paper's insights. Finally, we encourage the authors to explore the implications of T-symmetry in environments with fully reversible actions and clarify the potential advantages of the original T-symmetry when applicable.