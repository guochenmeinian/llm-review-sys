ID: md68e8iZK1
Title: Large Language Models Are Zero-Shot Time Series Forecasters
Conference: NeurIPS
Year: 2023
Number of Reviews: 20
Original Ratings: 4, 2, 7, 3, 5, 6, 7, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, 3, 2, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach for time series forecasting by encoding time series as numerical digits and framing the forecasting task as next-token prediction in large language models (LLMs) like GPT-3. The authors demonstrate that LLMs can effectively extrapolate time series patterns, such as seasonality, and model uncertainty using expressive distributions. They argue that LLMs excel in predicting numerical sequences due to biases from their text pre-training, which favors simple explanations. The study reveals that LLMs can integrate non-numerical text and handle missing data, achieving performance comparable to traditional time series models. The authors provide extensive evaluations across over 20 datasets and highlight significant methodological differences and performance disparities compared to the related work "PromptCast." However, the analysis lacks depth in explaining why pre-trained LLMs outperform other models in extrapolation tasks.

### Strengths and Weaknesses
Strengths:
1. The paper proposes a timely and relevant method utilizing pretrained language models for time series forecasting.
2. The encoding approach for time series data is innovative and well-structured, demonstrating careful design and insightful experiments.
3. The reported performance of LLMs in time series forecasting is compelling, suggesting significant potential for this unconventional method.
4. The paper offers impactful contributions, including a novel forecasting method and comprehensive evaluations, showcasing superior performance metrics compared to PromptCast.

Weaknesses:
1. Experimental results are insufficient to support the paper's claims, particularly as most experiments rely on virtual datasets, lacking analysis on real-world data.
2. The effectiveness of some proposed methods, such as tokenization and scale, has not been fully analyzed.
3. The contributions of the paper are unclear, with a perception that the authors primarily utilize GPT models without adequate justification for their claims.
4. The analysis is insufficient, failing to adequately explain the superior performance of LLMs compared to other models.
5. The experimental setup includes learnable parameters tuned based on forecasting error, which undermines the claim of zero-shot learning.
6. Interpretability concerns associated with LLMs compared to traditional methods like ARIMA are acknowledged but not fully addressed.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their contributions and provide a more thorough analysis of the effectiveness of their proposed methods, particularly regarding tokenization and scale. Additionally, the authors should conduct experiments on real-world datasets to strengthen their claims. We suggest restructuring the presentation to provide a high-level overview of the method before delving into details, which may enhance reader comprehension. Furthermore, we encourage the authors to explicitly discuss the limitations of their approach and the societal impacts of using LLMs for time series forecasting. We also recommend that the authors improve the depth of their analysis by explicitly discussing why pre-trained LLMs can outperform other models in time series extrapolation. It would be beneficial to clarify the implications of their experimental setup regarding zero-shot learning and provide code for result verification. Lastly, we suggest enhancing the discussion on interpretability by exploring how LLMs can be prompted or fine-tuned to offer explanations for their predictions, thereby addressing concerns related to the interpretability of LLMs versus traditional forecasting methods.