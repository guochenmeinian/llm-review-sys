ID: JBAUg7o8Yv
Title: HumanSplat: Generalizable Single-Image Human Gaussian Splatting with Structure Priors
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 5, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a 3D human reconstruction system that generates 3D Gaussians from a single RGB image, enabling rendering from any viewpoint. Unlike existing 3DGS methods that require per-instance optimization and struggle with unseen identities, the proposed system operates in a zero-shot manner. The authors utilize a 2D multi-view diffusion model and a latent reconstruction transformer, incorporating human structure priors and a hierarchical loss that integrates human semantic information. Experimental results indicate the system's robust capabilities.

### Strengths and Weaknesses
Strengths:  
- The use of diffusion-based generative models for rendering unseen viewpoints is a sound approach given the complexity of the task.  
- The latent reconstruction transformer effectively integrates human structure priors with the generative model's output.  
- The hierarchical loss enhances consistency between 3D human geometry and appearance.  
- The model demonstrates minimal reconstruction time, achieving real-time rendering of novel views.

Weaknesses:  
- The writing lacks clarity, particularly in explaining the application of the video diffusion model for novel-view synthesis and the hierarchical loss's access to target human images.  
- There is insufficient comparison with state-of-the-art methods like ICON and ECON.  
- The results on in-the-wild inputs are limited, showcasing only three examples with simple poses, necessitating more diverse human poses and identities.  
- Qualitative visual results are unsatisfactory, with low-quality renderings even for input views, indicating potential issues with model capacity or objective functions.  
- The definition of human body parts and the robustness of the method against errors in ground truth labels are unclear.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing, particularly in Sections 3.3 and 3.5, to better explain the choice of the video diffusion model and the hierarchical loss's functionality. Additionally, we suggest including comparisons with more state-of-the-art methods, such as ICON and ECON, to strengthen the evaluation. To enhance the generalizability of the work, we encourage the authors to report more results from diverse in-the-wild images featuring varied human poses and identities. Furthermore, conducting ablation studies to assess the impact of human structure priors and addressing the qualitative rendering quality would provide valuable insights into the model's effectiveness.