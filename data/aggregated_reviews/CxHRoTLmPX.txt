ID: CxHRoTLmPX
Title: Generative Verifiers: Reward Modeling as Next-Token Prediction
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 9, 8, 7, 6, 6
Original Confidences: 4, 4, 4, 4, 3

Aggregated Review:
### Key Points
This paper presents an innovative approach to enhancing the reasoning capabilities of large language models (LLMs) by training verifiers as generative models, termed Generative Verifiers (GenRM). This method utilizes next-token prediction for verification, leading to significant performance improvements in tasks such as math reasoning and algorithmic problems. The authors claim that GenRM integrates seamlessly with instruction tuning and scales favorably with dataset size, model capacity, and inference-time compute.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and easy to follow, with a clear illustration of GenRM's benefits through comprehensive experiments.
- GenRM demonstrates superior performance over traditional methods, with enhancements ranging from 16% to 64% in problem-solving tasks.
- The integration with existing LLM architectures enhances reasoning capabilities and simplifies implementation.

Weaknesses:
- The claim of seamless integration with instruction tuning lacks sufficient discussion in the main paper.
- The implementation may be complex due to the integration of advanced techniques like chain-of-thought reasoning and majority voting.
- The paper does not adequately compare GenRM with recent verification works, nor does it address potential overfitting risks associated with its reliance on next-token prediction.

### Suggestions for Improvement
We recommend that the authors improve the discussion regarding the integration of GenRM with instruction tuning, particularly in relation to Selection 2.2. Additionally, we suggest incorporating comparisons with recent papers on scaling inference-time compute and addressing the potential overfitting issues that may arise from the model's complexity. Finally, we encourage the authors to consider releasing relevant code and CoT data to the community for enhanced reproducibility and further validation of their findings.