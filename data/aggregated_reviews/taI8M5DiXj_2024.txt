ID: taI8M5DiXj
Title: When to Act and When to Ask: Policy Learning With Deferral Under Hidden Confounding
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 4, 5, 6, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a learning to defer method for policy learning with binary actions under unobserved confounding. The authors propose using the marginal sensitivity model (MSM) to bound confounding strength and compare pessimistic bounds between potential outcomes and identifiable human rewards. The final optimization employs a surrogate loss as proposed by Mozannar and Sontag (2020). While the method appears sound, it overlooks existing literature on learning to defer in policy learning contexts. The authors compare their method with a self-proposed rejection-inference baseline and a policy learning method that does not involve human input.

### Strengths and Weaknesses
Strengths:
- The paper offers a sound approach to policy learning with unobserved confounding by conservatively comparing lower bounds of potential outcomes and human rewards.
- The method demonstrates strong performance against the baselines by leveraging a more robust direct method class.
- The theoretical properties are well-explored, and the proposed method is easy to implement, with empirical validation.

Weaknesses:
- The authors neglect significant related work in learning to defer, inaccurately claiming originality in their approach.
- The method is limited to binary actions, while existing literature supports multiple actions.
- The assumptions made, particularly in Definition 1, are overly strong and may not hold in practical scenarios.
- Experimental results are limited to synthetic datasets, lacking validation with real human responses.

### Suggestions for Improvement
We recommend that the authors improve their literature review by including relevant works on learning to defer, particularly those that utilize the Inverse-Propensity-Score framework. Additionally, the authors should consider extending their method to accommodate multiple actions. The assumptions in Definition 1 should be revisited to ensure they are feasible in practical applications. For empirical studies, we suggest incorporating real-world datasets and comparing against a purely pessimistic AI baseline for a more comprehensive evaluation. Finally, the authors should clarify the introduction of Mozannar and Sontag (2020) to enhance the paper's accessibility for readers unfamiliar with that work.