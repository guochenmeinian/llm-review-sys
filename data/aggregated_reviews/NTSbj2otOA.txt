ID: NTSbj2otOA
Title: First- and Second-Order Bounds for Adversarial Linear Contextual Bandits
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 6, 5, 5, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper studies the adversarial linear contextual bandit setting, focusing on $K$ arms, stochastic contexts in $\mathbb{R}^d$, and adversarial rewards modeled as linear functions of the context. The authors propose a new algorithm, ContextEW, which achieves improved regret guarantees that scale with smaller quantities than the traditional $\sqrt{T}$, specifically a "second-order" quantity $V_T$ and a first-order bound $L_T^\star$. The paper also refines regret bounds into first-order and second-order bounds, leveraging techniques from previous works by Ito et al. (2020) and Neu-Olkhovskaya (2020).

### Strengths and Weaknesses
Strengths:
- The paper is well-written, clearly explaining the problem statement and results.
- It introduces a new algorithm for adversarial linear contextual bandits that achieves significant first and second-order bounds.

Weaknesses:
- The originality of the work is unclear; it may simply modify results from existing literature. This could be clarified in the proof sketch and technical sections.
- The discussion on computational complexity lacks clarity, particularly regarding the calculation of $\tilde{\Sigma}$ and the propagation of sampling errors.
- Key intuitions for the algorithm and analysis are not well articulated.
- The reliance on the assumption of log-concave context distributions limits the applicability of the results.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their contributions by explicitly delineating what is novel compared to existing works, particularly in the "Techniques" subsection. Additionally, we suggest enhancing the discussion on computational complexity, especially regarding how to calculate $\tilde{\Sigma}$ and the implications of using $\epsilon$-approximations. It would also be beneficial to provide numerical results to demonstrate the algorithm's performance and validate the theoretical bounds. Lastly, consider discussing the implications of the log-concavity assumption and providing examples of distributions that satisfy this condition.