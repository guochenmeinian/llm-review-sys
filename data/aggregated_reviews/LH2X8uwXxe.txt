ID: LH2X8uwXxe
Title: Unsupervised Modality Adaptation in Human Action Recognition via Cross-modal Representation Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 8, 7, 6, 7, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 5, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Unsupervised Modality Adaptation (UMA) for Human Behavior Recognition (HAR), utilizing a unified multimodal representation space to facilitate knowledge transfer between modalities. The authors propose three methods: Student-Teacher (ST), Contrastive Alignment (CA), and Cross-modal Transfer Through Time (C3T), with extensive testing on multimodal datasets that include IMU and RGB data. The C3T method is highlighted for its robustness in managing temporal noise and misalignment.

### Strengths and Weaknesses
Strengths:
1. The paper proposes three distinct methods (ST, CA, and C3T) and provides a detailed comparison of their advantages and disadvantages.
2. The methods are validated across multiple datasets, showcasing their effectiveness under various conditions.

Weaknesses:
1. The focus is primarily on RGB and IMU data, lacking exploration of other multimodal data types, such as image-text.
2. There is insufficient visualization and discussion regarding successful and failed predictions.
3. The impact of hyperparameters on performance is not adequately addressed.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the applicability of their methods to other multimodal data types beyond RGB and IMU. Additionally, enhancing the visualization of results and providing a thorough analysis of successful and failed predictions would strengthen the paper. It would also be beneficial to discuss the effects of hyperparameters on performance in more detail. Furthermore, we suggest that the authors compare different sampling strategies, such as video-level sampling (like TSN and TFCNet), clip-level sampling (like NonLocal Networks, R2+1D, SlowFast), and hybrid sampling (like V4D), to evaluate their robustness in future experiments.