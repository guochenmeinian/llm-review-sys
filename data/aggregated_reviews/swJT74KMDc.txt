ID: swJT74KMDc
Title: Optimal and efficient text counterfactuals using Graph Neural Networks
Conference: EMNLP/2024/Workshop/BlackBoxNLP
Year: 2024
Number of Reviews: 3
Original Ratings: -1, -1, -1
Original Confidences: 3, 4, 3

Aggregated Review:
### Key Points
This paper presents a fast counterfactual editing technique based on a Graph Convolutional Network (GCN) that addresses the linear sum assignment problem to identify minimal edits. The GCN generates a list of candidates comprising source words and substitutions, from which the most suitable option is selected using beam search, yielding an *approximately optimal* substitution more efficiently than methods that create optimal substitutions. The authors evaluate their method against MiCE and Polyjuice, demonstrating superior performance in three out of four evaluation metrics (*fluency*, *closeness*, and *minimality*) and in runtime. The experiments also explore various configurations, including the use of embeddings versus WordNet and the inclusion of a POS filter.

### Strengths and Weaknesses
Strengths:
- The paper addresses a timely topic in explainable NLP, focusing on efficient counterfactual editing techniques.
- It is well-written, with clear technical details and highlighted trade-offs among controllability, optimality, explainability, and runtime.
- The proposed technique outperforms existing methods in both quality and runtime, making it valuable for future research.
- Extensive experiments are presented, including qualitative comparisons in the appendix.

Weaknesses:
- The lack of a demonstration of the method's application diminishes its impact for an explainability workshop.
- The evaluation is limited to two datasets (IMDB and 20 Newsgroups), which may affect claims of generalizability.
- There is no human evaluation of the generated counterfactuals, which could enhance insights into their interpretability.

### Suggestions for Improvement
We recommend that the authors improve the abstract by including specific details about their counterfactual editing approach compared to previous works. Additionally, we suggest expanding the evaluation to include a broader range of datasets and tasks to strengthen claims of generalizability. Incorporating human evaluations of the generated counterfactuals would also provide valuable insights into their interpretability and usefulness. Finally, we encourage the authors to consider including a comparison with LLM-based counterfactual generators to validate their claims regarding computational efficiency and substitution quality.