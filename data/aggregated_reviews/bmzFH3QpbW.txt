ID: bmzFH3QpbW
Title: Privacy Protection in Personalized Diffusion Models via Targeted Cross-Attention Adversarial Attack
Conference: NeurIPS
Year: 2024
Number of Reviews: 2
Original Ratings: 6, 5
Original Confidences: 3, 3

Aggregated Review:
### Key Points
This paper presents a method that enhances privacy protection by introducing a cosine similarity loss between user-specific and class-specific tokens. The authors propose that this approach can achieve better protection with smaller noise budgets. The paper includes analyses and visualizations regarding the impact of various protection components.

### Strengths and Weaknesses
Strengths:  
* The method effectively incorporates a cosine similarity loss to improve privacy protection.  
* Experimental results indicate that the proposed method outperforms previous approaches with reduced noise budgets.  
* The paper provides valuable analyses and visualizations of different protection components' impacts.  

Weaknesses:  
* The focus on cross-attention layers has been previously explored in other works.  
* The experiments lack a crucial competitive baseline (DisDiff), which also targets cross-attention, despite its mention in the introduction.  
* Annotations in Figure 1 do not align with those in Section 3.2, such as discrepancies with the "<o>" token and "Cos($X_a$, $X_b$)".  
* The evaluation lacks clarity regarding the architecture used after training on SD 2.1 and how metrics compare between approaches using class and user-specific tokens versus those that do not.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the evaluation by specifying the architecture used after training on SD 2.1. Additionally, it is essential to explain the comparability of metrics between approaches that utilize class and user-specific tokens and those that do not. We also suggest including the competitive baseline (DisDiff) in the experiments to strengthen the analysis. Finally, please ensure that the annotations in Figure 1 are consistent with those in Section 3.2.