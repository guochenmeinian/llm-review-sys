ID: OjUumZhV3s
Title: MMed-RAG: Versatile Multimodal RAG System for Medical Vision Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 4
Original Ratings: 8, 8, 7, 8
Original Confidences: 4, 3, 3, 4

Aggregated Review:
### Key Points
This paper presents a novel multimodal RAG system designed for Med-LVLMs, featuring domain-aware retrieval, adaptive selection of retrieved contexts, and preference-based fine-tuning. The authors demonstrate substantial improvements in factual accuracy across various medical imaging domains through comprehensive experiments and ablation studies.

### Strengths and Weaknesses
Strengths:  
- The innovative use of preference pairs effectively addresses cross-modality misalignment and enhances robustness against noisy inputs, offering potential for self-improvement in Med-LVLMs.
- The method is well-supported by extensive experiments, validating the contribution of each component through an ablation study.
- The writing is clear, well-organized, and easy to follow.

Weaknesses:  
- The performance of MMed-RAG is heavily dependent on high-quality labeled datasets, which may be a limitation in medical fields lacking such resources.
- The manuscript does not explicitly discuss known bugs and limitations.
- Some technical details are unclear or missing, such as definitions for \pi_{ref} and \pi_o, and the rationale behind the exclusion of an indicator function in the SimCLR-style loss.

### Suggestions for Improvement
We recommend that the authors improve the exploration of the thresholding parameter, \gamma, for adaptive context selection and investigate the effects of different noising schedules in the cross-modality alignment section. Additionally, including experiments that compare this method with standard RAG fine-tuning on the same dataset would provide a more thorough evaluation. We also suggest providing a more general statement about the applicability of the proposed method to other RAG-based models and discussing potential issues that might arise. Clarifying the technical details mentioned, such as the definitions of \pi_{ref} and \pi_o, and ensuring consistency in the similarity matrix indices would enhance clarity. Finally, we recommend using a metric that captures general behavior across the dataset to strengthen the argument regarding the claims made in the figures.