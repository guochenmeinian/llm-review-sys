ID: sOhFyFFnxT
Title: Exploring the Precise Dynamics of Single-Layer GAN Models: Leveraging Multi-Feature Discriminators for High-Dimensional Subspace Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 5, 4, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a simplified GAN framework aimed at learning the subspace of a spiked covariance model. The authors derive precise training dynamics under specific assumptions, demonstrating that these dynamics correspond to numerical simulations. They establish that the convergence rate is often superior to previous methods utilizing a simplified discriminator. The authors extend their convergence results to scenarios where the exact subspace dimension is unknown and provide empirical results on MNIST, indicating that their method achieves higher steady state feature alignment compared to Oja's method.

### Strengths and Weaknesses
Strengths:
- **Clarity:** The authors effectively introduce the spiked covariance model and their GAN method along with its assumptions.
- **Theoretical Results:** A variety of tools are employed to characterize system dynamics, extending results to different dimensionalities of the generator and true distribution subspace.
- **Systematic Analysis:** The paper provides a thorough analysis of GAN-based methods and conventional approaches from both theoretical and empirical perspectives.

Weaknesses:
- **Clarity:** Some sections lack clarity, particularly in defining single vs. multi-feature discriminator learning and interpreting the main theorem (4.3). The utility of microscopic dynamics in section 4.2 is not adequately discussed, and the distinctions in Fig. 1 are unclear.
- **Comparison to Previous Work:** While alternative subspace methods like GROUSE are mentioned, only Oja's method is used as an experimental baseline. The paper could benefit from citations of other GAN stability analysis papers.
- **Experiments:** The empirical results could be strengthened by including convergence rate comparisons and additional GAN-related generative modeling metrics, such as FID scores.
- **Assumptions:** Many assumptions appear difficult to extend to the full GAN setting, raising concerns about their generalizability.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the introduction by explicitly defining single feature vs. multi-feature discriminator learning. A more detailed discussion on the interpretation of theorem (4.3) and the utility of microscopic dynamics in section 4.2 would enhance understanding. Additionally, we suggest including comparisons with other GAN stability analysis papers and expanding the experimental section to include convergence rates and FID scores. Further discussion on which assumptions could be relaxed in future work would also be beneficial. Lastly, consider restructuring the manuscript to highlight the novel contributions more prominently in the main text, moving repetitive content to the appendix.