ID: UvbpbEhGaw
Title: Self-Supervised Alignment with Mutual Information: Learning to Follow Principles without Preference Labels
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 6, 6, 6, 6, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents SAMI (Self-Supervised Alignment with Mutual Information), an iterative algorithm designed to align language models (LMs) with behavioral principles (constitutions) without relying on preference labels or demonstrations. SAMI optimizes the conditional mutual information between principles and self-generated responses, demonstrating significant improvements in single-turn dialogue and summarization tasks compared to pretrained and instruction-finetuned models. The method effectively scales to stronger models and generalizes to diverse principles.

### Strengths and Weaknesses
Strengths:
1. SAMI introduces a significant innovation by aligning LMs with principles without using preference labels or human demonstrations.
2. The method outperforms both the initial pretrained model and an instruction-finetuned baseline in single-turn dialogue and summarization tasks.
3. SAMI scales effectively to larger models and generalizes to principles not seen during training.
4. The ability to align LMs with minimal human oversight has practical implications for reducing the complexity of current alignment techniques.

Weaknesses:
1. The approach may face over-optimization issues, potentially producing incoherent outputs if not properly regularized, with current strategies adding complexity and being ineffective.
2. Experiments are limited to single-turn dialogue and summarization tasks, leaving questions about SAMI's performance on more complex multi-turn interactions and other tasks. There is also a noted length bias in responses.
3. The need for multiple iterations to achieve optimal performance raises concerns about resource burden, and the authors should clarify this aspect. More ablation studies and comparisons with other alignment methods are needed for a comprehensive evaluation.

### Suggestions for Improvement
We recommend that the authors improve the discussion on regularization strategies, providing specific measures that effectively mitigate over-optimization and enhance output coherence. Additionally, we suggest extending experiments to include multi-turn interactions and a broader range of tasks to assess the generalizability of SAMI. Clarifying the resource requirements and computational costs associated with multiple iterations would also be beneficial. Finally, including more ablation studies and comparisons with other alignment methods would strengthen the evaluation of SAMI's effectiveness.