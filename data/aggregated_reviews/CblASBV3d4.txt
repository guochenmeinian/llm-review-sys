ID: CblASBV3d4
Title: "Are Your Explanations Reliable?" Investigating the Stability of LIME in Explaining Text Classifiers by Marrying XAI and Adversarial Attack
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an evaluation of the stability of explanations generated by the LIME method in NLP models, demonstrating its inherent instability through varying sampling rates. The authors propose an adversarial attack algorithm, XAIFooler, which perturbs text inputs to manipulate LIME-generated explanations while adhering to several constraints. The paper identifies Rank-biased Overlap (RBO) as a suitable metric for measuring explanation similarity. The experiments show that XAIFooler outperforms baseline methods in distorting explanations while maintaining semantic similarity.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and clear, making it easy to follow.
- It provides a thorough evaluation of the inherent instability of LIME and presents convincing experimental results.
- The use of multiple metrics to assess meaning preservation and explanation dissimilarity is commendable.

Weaknesses:
- The contribution appears limited due to similarities with the Location of Mass method (Sinha et al., 2021), primarily differing in the similarity metric used.
- The necessity of certain constraints, particularly regarding the top k features in the perturbed explanation, is unclear.
- The linkage between LIME's instability and XAIFooler's effects is inadequately justified.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the differences between their work and Location of Mass (Sinha et al., 2021). Additionally, it is essential to provide a more in-depth explanation of the necessity of the constraints outlined in equation (5). We suggest investigating and discussing the sample complexity associated with LIME's linear model fitting, as this may reveal critical insights into the stability of explanations. Furthermore, we encourage the authors to coalesce discussions regarding the treatment of top features into a consistent argument, clarifying when and why they should be perturbed. Lastly, providing examples of base and perturbed documents would enhance the paper's comprehensibility.