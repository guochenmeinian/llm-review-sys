ID: 4U18ZoRXTD
Title: AV-GS: Learning Material and Geometry Aware Priors for Novel View Acoustic Synthesis
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 6, 5, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to acoustic synthesis using 3D Gaussian Splatting (3DGS) for scene representation. The framework integrates a 3D GS model, an acoustics field network, and an audio binauralizer. It captures scene geometry through a trained 3D GS model and initializes a learnable acoustic point representation using Gaussian attributes, averaging features from nearby points for acoustic modeling. Experiments on the RWAVS and Soundspaces datasets demonstrate state-of-the-art performance, supported by ablation studies.

### Strengths and Weaknesses
Strengths:
- The paper introduces a clever method leveraging point-based scene representation from 3DGS for acoustic modeling, yielding promising results.
- Thorough experiments and ablation studies validate the technical advancements and performance improvements over baselines.

Weaknesses:
- The method description lacks clarity, making it difficult to grasp the approach fully. The method figure does not enhance understanding.
- The paper's claims of learning "holistic geometry-aware material-aware scene representation" are seen as overreaching, as experiments focus solely on acoustic modeling. Visualization of PCA features of learnable acoustic points is recommended for validation.
- Major experimental results for baselines are sourced from AV-NeRF and INRAS without proper acknowledgment, raising concerns about training and testing consistency.
- The use of unit vectors in Position-guidance G condition eliminates distance information, which may be crucial.
- The potential of energy decay loss for improving results, as noted in related work, is not explored.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the method section to facilitate understanding. Address the overclaims regarding holistic scene representation by providing experimental support. Acknowledge the source of baseline results and ensure consistency in training and testing splits. Consider retaining distance information in the Position-guidance G condition and explore the use of energy decay loss for enhancement. Additionally, we suggest saving figures as PDF files instead of screenshots or PNGs for better quality.