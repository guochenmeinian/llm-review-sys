ID: 7C6cd95qvH
Title: MedRAG: Enhancing Retrieval-augmented Generation with Knowledge Graph-Elicited Reasoning for Healthcare Copilot
Conference: ACM
Year: 2024
Number of Reviews: 3
Original Ratings: -1, -1, -1
Original Confidences: -1, -1, -1

Aggregated Review:
### Key Points
This paper presents MedRAG, a retrieval-augmented generation (RAG) framework tailored for the medical domain, which integrates a four-tier hierarchical diagnostic knowledge graph (KG) with RAG models. MedRAG enhances diagnostic reasoning and decision-making by systematically retrieving relevant electronic health records (EHRs) and employing KG-elicited reasoning within large language models (LLMs) to generate accurate diagnoses, treatment recommendations, and follow-up questions. Evaluations on the DDXPlus public dataset and a private chronic pain dataset (CPDD) demonstrate MedRAG’s superior diagnostic accuracy and specificity compared to existing RAG models.

### Strengths and Weaknesses
Strengths:
- MedRAG’s use of a diagnostic KG allows for fine-grained reasoning about diseases with similar manifestations, addressing limitations in current RAG frameworks.
- The hierarchical organization of the KG enhances applicability to complex diagnostic scenarios.
- The proactive diagnostic questioning mechanism is innovative, improving diagnostic accuracy and consultation efficiency.
- Comprehensive experiments on both public and private datasets illustrate MedRAG’s adaptability.
- The framework is tested across various LLMs, showcasing generalizability and compatibility, consistently outperforming baseline models, particularly in diagnostic specificity.

Weaknesses:
- The paper lacks elaboration on how generated questions align with clinical reasoning standards, and qualitative examples or clinician evaluations are needed.
- The ablation studies do not provide detailed analysis of specific KG components, which could clarify their contributions to MedRAG’s effectiveness.
- The comparison of QWEN with LLAMA in the English corpus raises questions about fairness.
- Details regarding the construction errors in the Diagnostic Knowledge Graph and their potential impact on results are insufficient.
- The performance decrease of some models in Table 2 requires clarification.
- The testing methodology for the proactive diagnostic questioning mechanism is not adequately described.
- The main evaluation metrics focus solely on accuracy, with a lack of semantic metrics for analysis.

### Suggestions for Improvement
We recommend that the authors improve the elaboration on how generated questions align with clinical reasoning standards by providing qualitative examples or clinician evaluations. Additionally, a more detailed analysis of specific KG components should be included to identify their contributions to MedRAG’s overall effectiveness. The authors should clarify the fairness of comparing QWEN with LLAMA in the English corpus. Furthermore, the authors need to address the construction errors in the Diagnostic Knowledge Graph and their potential impact on results, and clarify the reasons behind the performance decrease of some models in Table 2. More details on the testing methodology for the proactive diagnostic questioning mechanism should be provided, and the authors should consider including semantic metrics alongside accuracy in their evaluations.