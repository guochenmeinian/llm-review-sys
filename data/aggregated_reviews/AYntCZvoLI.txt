ID: AYntCZvoLI
Title: Causal Context Adjustment Loss for Learned Image Compression
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 8, 5, 5, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 5, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to learned image compression (LIC) by introducing a Causal Context Adjustment loss (CCA-loss) aimed at enhancing the rate-distortion (RD) performance of autoregressive entropy models. The authors propose a CNN-based model with an unevenly channel-wise grouped strategy to balance inference latency and RD performance. Experimental results indicate that the proposed method outperforms existing state-of-the-art LIC techniques in both RD performance and computational efficiency.

### Strengths and Weaknesses
Strengths:
1. The introduction of CCA-loss represents a significant contribution, improving the accuracy of autoregressive entropy models.
2. The CNN-based model with uneven channel-wise grouping shows notable enhancements in RD performance and computational efficiency.
3. Comprehensive experimental validation on benchmark datasets demonstrates superior RD performance and efficiency compared to state-of-the-art methods.
4. The paper clearly articulates its contributions, including the development of CCA-loss and the efficient architecture.
5. The reduction in compression latency by over 20% compared to state-of-the-art methods highlights practical applicability.

Weaknesses:
1. The exploration of causal context models is limited, suggesting a need for more structured approaches.
2. The complexity of implementing the uneven channel-wise grouped strategy and CCA-loss function may challenge practitioners unfamiliar with deep learning techniques.
3. The paper lacks analysis on whether the causal context organization improves with CCA-loss and does not validate the method against stronger foundational compression codecs like VVC.

### Suggestions for Improvement
We recommend that the authors improve the exploration of causal context models by conducting a detailed analysis or ablation study on different organizational strategies. Additionally, extending the evaluation of CCA-loss to other architectures could demonstrate its versatility and robustness. We suggest including results from such experiments to assess the generalizability of CCA-loss across different models. Furthermore, the authors should consider validating their method against stronger codecs like VVC and reorganizing the abstract to better highlight the explicit guidance provided by CCA-loss.