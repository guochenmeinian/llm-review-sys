ID: VFhN15Vlkj
Title: Neural Polarizer: A Lightweight and Effective Backdoor Defense via Purifying Poisoned Features
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 6, 7, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a defense method against backdoor attacks by inserting a trainable neural polarizer into the backdoored model. This intermediate layer aims to purify poisoned samples by filtering out trigger information while preserving benign features. The authors leverage a bi-level optimization approach to approximate perturbation and target labels, demonstrating the effectiveness of their method through comprehensive experiments.

### Strengths and Weaknesses
Strengths:
1. The proposed method is simple yet effective, consisting of a single convolution layer followed by a batch normalization layer, facilitating easy integration into various model architectures.
2. The experiments are extensive, comparing the method against six backdoor defenses across seven attacks on three datasets, achieving state-of-the-art performance.

Weaknesses:
1. The method relies on reversing the backdoor trigger and target label, which has limited applicability, particularly for sample-specific triggers, as evidenced by previous research.
2. The novelty of the approach is constrained since trigger reversal has been previously explored, with the primary contribution being the fine-tuning of the model using the reversed trigger.
3. The paper lacks clarity on how to select appropriate layers for inserting the neural polarizer, which is crucial given its dependence on network architecture.
4. The proposed method shows a decrease in benign accuracy, a common issue in adversarial training techniques, and the authors do not adequately address how this affects benign model performance.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the selection of layers for inserting the neural polarizer, potentially providing more results using additional architectures such as VGG. Additionally, we suggest that the authors conduct experiments to visualize features before and after the neural polarizer to qualitatively analyze its effectiveness. Furthermore, addressing the implications of benign accuracy decline and exploring the method's performance under adaptive attacks would strengthen the paper. Lastly, it would be beneficial to emphasize the distinctions between their approach and previous research, particularly in relation to the use of adversarial samples versus poisoned ones.