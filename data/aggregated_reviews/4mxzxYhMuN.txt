ID: 4mxzxYhMuN
Title: Motion Forecasting in Continuous Driving
Conference: NeurIPS
Year: 2024
Number of Reviews: 19
Original Ratings: 7, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a model for motion forecasting named "RealMotion," which emphasizes continuous prediction over sequential timesteps, contrasting with traditional methods that predict independently for each timestep. The authors propose two main improvements: reorganizing data into overlapping segments and relaying context and predictions from previous timesteps to enhance current predictions. Their approach demonstrates strong performance on the Argoverse benchmark, achieving state-of-the-art results.

### Strengths and Weaknesses
Strengths:
- The paper addresses a critical issue in autonomous driving by modeling continuous contexts in motion forecasting, which has been overlooked in prior research.
- The proposed methods, particularly the relaying of historical context, are intuitive and contribute novel insights to the field.
- The experiments provide compelling evidence of the effectiveness of continuous contexts, with strong results on benchmark datasets.

Weaknesses:
- Some explanations, such as data reorganization and the use of terms like "modes," lack clarity and could benefit from simpler language and clearer definitions.
- The results, while strong, are not entirely conclusive, particularly in comparison to QCNet, where improvements are minimal except for specific metrics.
- The loss functions and certain methodological details are insufficiently detailed, leaving questions about their application and implications.

### Suggestions for Improvement
We recommend that the authors improve clarity in their explanations, particularly regarding data reorganization and the terminology used in the model. Specifically, they should simplify phrases like "we select several split points Ti along historical frame steps" to "We split sequences evenly into sub-sequences." Additionally, the authors should provide a clearer definition of the output representation of their model and elaborate on the classification loss. 

To strengthen the results, we suggest including comparisons with simple baselines that utilize longer historical data and addressing the fairness of comparisons with QCNet. The authors should also clarify the details of the loss functions and consider adding visual aids to better illustrate the architecture and interactions within the model. Finally, augmenting the figure captions to clarify the context of each scene would enhance understanding.