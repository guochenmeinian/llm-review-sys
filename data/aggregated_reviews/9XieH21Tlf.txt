ID: 9XieH21Tlf
Title: Hierarchical Decomposition of Prompt-Based Continual Learning: Rethinking Obscured Sub-optimality
Conference: NeurIPS
Year: 2023
Number of Reviews: 18
Original Ratings: 5, 7, 5, 7, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 3, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel continual learning (CIL) approach that leverages pre-trained models, specifically focusing on prompt-based techniques. The authors propose a framework that includes *within task prediction* (WTP), *task-identity inference* (TII), and *task-adaptive prediction* (TAP), demonstrating that these components are essential for effective CIL. The empirical results reveal significant performance improvements across various pre-training paradigms, highlighting the importance of addressing performance degradation in existing methods under self-supervised pre-training.

### Strengths and Weaknesses
Strengths:
1. The paper provides a well-organized analysis of state-of-the-art prompt-based approaches, presenting a unified perspective.
2. The empirical analysis effectively highlights the performance degradation of current strategies under realistic conditions, which is crucial for practical applications.
3. The theoretical insights into the hierarchical components relevant to continual learning in the context of pre-training are compelling.
4. The proposed method shows substantial improvements in continual learning performance across different pre-training paradigms.

Weaknesses:
1. The reliance on pre-trained models from ImageNet raises concerns about potential information leakage due to overlapping classes.
2. The theoretical contributions appear somewhat ambiguous, with similarities to prior work, particularly in notation and proofs.
3. The effect of prompt ensembles is not adequately discussed, and the analysis of un-/instructed representations lacks depth.
4. Some experimental results could benefit from further fine-grained analysis using specific datasets.

### Suggestions for Improvement
We recommend that the authors improve their theoretical analysis by clarifying the distinctions between their contributions and previous works, particularly regarding the notations and conditions. Additionally, the authors should discuss the implications of using pre-trained models more thoroughly, especially concerning potential information leakage. We suggest including comparisons with other parameter-efficient tuning methods such as adapters, Lora, and Prefix, as well as concurrent related works like PromptFusion and FSA. Finally, a more detailed examination of the prompt ensemble's impact and the performance on fine-grained datasets would enhance the robustness of the findings.