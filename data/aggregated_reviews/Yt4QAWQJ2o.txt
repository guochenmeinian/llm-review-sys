ID: Yt4QAWQJ2o
Title: Stylized Dialogue Generation with Feature-Guided Knowledge Augmentation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a stylized dialogue generation model that utilizes non-stylized dialogue data and stylized non-dialogue texts. The authors propose a back-translation process to create pseudo dialogue contexts for training, enhancing stylistic features through retrieved text. They introduce a set of losses, including a contrastive learning loss for retrieval performance and a KL loss to align attention distributions across queries. The contributions include explicit style signal usage, a feature-guided selection method, and experiments demonstrating superior performance over several baselines.

### Strengths and Weaknesses
Strengths:
- The problem addressed is interesting and relevant.
- The retrieval of explicit style features from a target style corpus is innovative for stylized dialogue generation.
- The design of distinct loss functions is meticulous and tailored to specific objectives.
- Experimental results indicate effectiveness compared to previous work.

Weaknesses:
- Evaluation lacks robustness; not all baselines are compared across datasets, and some are missing from tables.
- The effects of complex components in the feature-guided selection module are unclear, with ablation studies showing inconsistent improvements.
- The paper does not adequately address potential inaccuracies and hallucination issues from incorporating external knowledge.
- Important references in the field, such as RAG and ATLAS, are missing from the literature review.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by including all relevant baselines for each dataset and providing a clearer analysis of the retrieved stylized sentences' impact on performance. Additionally, we suggest conducting a more thorough ablation study to clarify the statistical significance of the improvements from the feature-guided selection module. It would also be beneficial to address the stability of training with multiple loss components and clarify the selection process for hyperparameters. Finally, we urge the authors to include missing references to RAG, ATLAS, and newer KDG methods to strengthen the literature review.