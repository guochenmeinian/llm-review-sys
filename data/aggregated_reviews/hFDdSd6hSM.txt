ID: hFDdSd6hSM
Title: Do Counterfactually Fair Image Classifiers Satisfy Group Fairness? -- A Theoretical and Empirical Study
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 5, 5, 9, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents counterfactual versions of two existing datasets, CelebA and LFW, created using in-painting models, which are annotated and filtered based on the correctness of attribute-related in-painting techniques. The authors perform experiments with classifiers trained on these counterfactual interventions and propose a theoretical framework to explain the disparities between counterfactual fairness (CF) and group fairness (GF). Additionally, they include empirical experimentation with a binarized version of the CIFAR-10 dataset. The work contributes valuable insights into the relationship between CF and GF in image classification.

### Strengths and Weaknesses
Strengths:
- The introduction of counterfactual versions of existing datasets enhances the depth of model analyses.
- The data construction process includes validation of in-painting methods through human review.
- The suite of analyses related to counterfactual and group fairness leads to useful theoretical insights.
- The authors connect their datasets to significant theoretical results and validate findings with additional experimentation using CIFAR-10.

Weaknesses:
- The impact of the new dataset is limited, with insufficient discussion on its details and composition.
- The theoretical framework and CIFAR-10 experiments do not align closely with the venue's focus on datasets and benchmarking.
- There is a lack of nuance regarding the visual representation of gender and how subjectivity in perceived gender is operationalized.
- Clarity issues arise from the extensive use of acronyms, making the paper challenging to read.

### Suggestions for Improvement
We recommend that the authors improve the discussion of the original CelebA and LFW datasets, including composition and biases, as well as details on hair lengths and co-occurring attributes. Contextualizing the work with related literature, particularly how the proposed dataset offers additional insights, would enhance relevance. Clarifying the focus on specific gender attributes and providing actionable ethical considerations regarding dataset usage would strengthen the paper. Additionally, exploring fewer acronyms and including more details on dataset construction and experimental results, such as accuracy and DEO metrics, would improve clarity and comprehensibility.