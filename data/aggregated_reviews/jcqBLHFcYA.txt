ID: jcqBLHFcYA
Title: MindGames: Targeting Theory of Mind in Large Language Models with Dynamic Epistemic Modal Logic
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a systematic approach to constructing Theory of Mind (ToM) tests for large language models (LLMs) through dynamic epistemic logic (DEL) problems. The authors propose the MindGames dataset, which evaluates LLM performance, revealing that scaling does not guarantee improved DEL inference capabilities. The study highlights the cognitive motivation behind the problem formulation and the challenges faced by even the best-performing models like GPT-4.

### Strengths and Weaknesses
Strengths:
- The MindGames dataset is a significant contribution, providing a challenging and useful testbed for assessing ToM in LLMs.
- The problem formulation is cognitively motivated and potentially generalizable to more complex social interactions.

Weaknesses:
- The paper lacks adequate situating within related work and makes claims that may overstate its novelty, particularly regarding existing ToM benchmarks.
- Writing and presentation require improvement, as terms like "epistemic logic" are not clearly defined, and complex examples may confuse non-experts.
- Experimental setups are insufficiently detailed, raising questions about the evaluation process and the parameters used in the experiments.

### Suggestions for Improvement
We recommend that the authors improve the situating of their work within the existing literature and clarify their claims regarding the novelty of the dataset. Additionally, we suggest enhancing the writing and presentation by providing clear definitions for technical terms and simplifying complex examples. Furthermore, we urge the authors to elaborate on the experimental setups, including details on the selection of sessions, hyper-parameters, and probing techniques used.