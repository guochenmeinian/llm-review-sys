ID: FTpKGuxEfy
Title: Vision Foundation Model Enables Generalizable Object Pose Estimation
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 4, 7, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents VFM-6D, a two-stage RGBD-based method for generalizable object pose estimation. The authors propose a framework that first estimates a viewpoint using image matching and then derives the NOCS map of the query image based on the matched reference image. This approach allows for accurate re-estimation of the 6D pose and 3D size of input objects. The method is evaluated on category-level object pose benchmarks such as Wild6D and CO3D, achieving state-of-the-art results.

### Strengths and Weaknesses
Strengths:
- The paper introduces a generalizable method, VFM-6D, applicable to both instance-level and category-level object pose estimation for novel categories.
- The structure of the paper is clear and easy to follow.
- Experimental results demonstrate that VFM-6D achieves state-of-the-art performance on multiple benchmarks.

Weaknesses:
- The main contribution regarding category-level object pose estimation is inadequately supported, lacking analysis on differences between reference and query images.
- Quantitative results in Tables 1, 2, and 3 are unclear, particularly regarding the input methods used for comparison.
- The necessity of the two-stage approach is not well justified, as the first stage could already provide a pose prediction.
- Implementation details are insufficient, including how reference images are sampled and the specifics of the foundation features used.

### Suggestions for Improvement
We recommend that the authors improve the analysis supporting the main contribution by clearly demonstrating how the reference and query objects differ in their experiments. Additionally, please clarify the inputs used in each method for a fair comparison in the quantitative results. It would be beneficial to provide results from the first stage to justify the necessity of the two-stage approach. Furthermore, we suggest including detailed implementation information, such as the sampling method for reference images and the specific tokens used in foundation features.