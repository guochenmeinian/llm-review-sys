ID: xNlQjS0dtO
Title: Keeping LLMs Aligned After Fine-tuning: The Crucial Role of Prompt Templates
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 7, 6, 6, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a mitigation strategy termed "Pure Tuning, Safe Testing" (PTST) aimed at addressing harmful fine-tuning issues in large language models (LLMs). The authors propose to fine-tune models without a safety prompt and to incorporate it during inference, positing that harmful knowledge acquired during fine-tuning can be mitigated at inference time. The paper includes comprehensive experiments demonstrating the effectiveness of this approach across various models and datasets.

### Strengths and Weaknesses
Strengths:
1. The paper tackles an important issue regarding harmful fine-tuning in LLMs, contributing timely insights to the field.
2. A thorough evaluation is conducted, showcasing the method's effectiveness.
3. The writing is clear, making the proposed strategy accessible to a broad audience.

Weaknesses:
1. The rationale behind the PTST approach is questioned, particularly regarding why helpfulness does not degrade when harmfulness is reduced, despite changes in prompts between fine-tuning and testing.
2. The paper does not adequately discuss concurrent findings, such as those in Vlguard Zong et al. [2024], which could enhance the context of the results.
3. The experimental results lack clarity, particularly in distinguishing safety prompts from others, leading to confusion in interpreting the data.
4. Some relevant literature on mitigation strategies is omitted, which could provide a more comprehensive background.
5. The absence of baseline comparisons with existing mitigation strategies limits the understanding of PTST's significance.

### Suggestions for Improvement
We recommend that the authors improve the explanation of why helpfulness remains stable while harmfulness decreases when changing prompts, as this is a critical aspect of the PTST strategy. Additionally, we suggest including a discussion of concurrent findings in Section 4 to contextualize the results better. To enhance clarity, consider simplifying the presentation of experimental results, perhaps by using fewer prompts or providing a more intuitive table format. We also encourage the authors to cite and discuss relevant works that have emerged recently, particularly those that propose similar mitigation solutions. Lastly, incorporating comparisons with established baselines, such as Vaccine [Huang et al., 2024], would strengthen the paper's contributions.