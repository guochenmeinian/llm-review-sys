ID: LR1nnsD7H0
Title: Neural decoding from stereotactic EEG: accounting for electrode variability across subjects
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 5, 7, 4, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a transformer architecture for decoding behavior from sEEG neural recordings, effectively addressing inter-subject variability due to electrode placement and biological differences. The proposed architecture includes six components: a CNN temporal tokenizer, a temporal attention mechanism, a hand-designed RBF-based spatial encoding, a spatial attention mechanism, a feed-forward MLP for neural representation extraction, and a multi-head regression layer to manage patient variability. The authors claim to be the first to train unified, multi-session, multi-subject models for neural decoding, differentiating their work from existing models like sEEG-Net, which focuses on pathological activity detection and operates on single-electrode data. They demonstrate significant performance improvements when training on multi-subject datasets compared to single-subject datasets, validated through experiments on data from 21 subjects. The authors acknowledge limitations in their parameterization and dataset size while emphasizing the challenges of collecting larger datasets in clinical settings.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and addresses the critical issue of data heterogeneity in sEEG recordings, which complicates the construction of large datasets.
- The architecture is clearly defined, utilizing a multi-head regression layer to model inter-patient variability, and employs spatial and temporal attention layers effectively.
- Experimental details are thorough, and results indicate that training on multi-subject datasets enhances decoding performance.
- The authors provide a clear distinction between their work and existing models, highlighting the unique contributions of their approach.
- The ablation study provides valuable insights into the architecture's components, and the authors engage constructively with reviewer feedback, indicating a willingness to improve their manuscript.

Weaknesses:
- The spatial encoding's contribution to performance is marginal, with results indicating a minimal improvement in the $R^2$ coefficient, suggesting it may not significantly affect model accuracy.
- The ablation study implies that the multi-head regression component is crucial for performance, yet this is not discussed in the main manuscript.
- Justification for separating time and space attention mechanisms is weak, and comparisons against 2-D attention mechanisms are lacking.
- Limited comparison with existing methodologies raises concerns about the reported performance gains, as the authors do not benchmark against state-of-the-art models or classical decoding methods, including relevant models like Ye & Pandarinath (2021) or sEEG-Net.
- The dataset size of 21 subjects raises concerns about the generalizability of the findings, especially compared to larger datasets in related fields.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the effectiveness of the spatial positional encoding, particularly addressing its marginal impact on performance. It would be beneficial to include a comparison against 2-D attention mechanisms to strengthen the justification for the separate attention mechanisms. Additionally, we suggest that the authors incorporate comparisons with existing state-of-the-art methods, such as SEEG-Net and classical decoding models, to provide a clearer context for their performance claims. We also recommend that the authors clarify their claim regarding being the first to train unified models for neural decoding, ensuring that the distinction between neural decoding and pathological activity detection is well articulated. To strengthen their argument regarding dataset size, we encourage the authors to explore larger, publicly available sEEG datasets and consider the potential for using other types of brain signals for their analysis. Lastly, we advise the authors to discuss the limitations of their parameterization more thoroughly in the revised manuscript and to clarify the rationale behind using different loss functions for multi-subject and single-subject models, ensuring that the training periods for both models are comparable to avoid unfair comparisons. Providing details on the test/train/validation splits used in the study would also enhance the understanding of the reported results.