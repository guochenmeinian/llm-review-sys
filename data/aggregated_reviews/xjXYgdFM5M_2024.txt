ID: xjXYgdFM5M
Title: Reasons and Solutions for the Decline in Model Performance after Editing
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 6, 8, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive analysis of the decline in performance of large language models (LLMs) following knowledge editing, identifying key factors from both data and model perspectives. The authors construct a Multi-Question Dataset (MQD) and find that perplexity related to editing objectives significantly impacts model performance. They observe a strong correlation between the L1 norm of parameter layers and editing accuracy. To address performance degradation, the authors propose a novel method called Dump for sequence (D4C), which effectively manages parameter growth and enhances model performance post-editing.

### Strengths and Weaknesses
Strengths:
- Innovative Methodological Approach: The introduction of the D4C method addresses parameter norm growth and optimizes model performance post-editing.
- Comprehensive Data Analysis: The construction of the MQD and detailed analysis of data types provide valuable insights into model editing mechanics.
- Clear Identification of Problems and Solutions: The paper identifies specific issues in knowledge editing, such as catastrophic forgetting, and offers targeted solutions.
- Empirical Validation: The experiments provide empirical evidence supporting the proposed methods, enhancing credibility.

Weaknesses:
- Generalizability of Findings: The study's focus on specific scenarios may limit the applicability of findings across different LLMs or editing tasks.
- Potential Overfitting: There is a risk of the model becoming overly optimized for edited scenarios, potentially impacting performance on unedited tasks.
- Complexity of Implementation: The D4C method may be complex to implement and integrate into existing systems.
- Unsuitable Citation Format: The citation format used is not appropriate and should be revised.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their findings by testing the D4C method across a wider range of LLMs and editing tasks. Additionally, the authors should provide evidence regarding the impact of D4C on unedited model performance to address potential trade-offs. To enhance clarity, we suggest including a section in the appendix detailing the dataset and editing objectives mentioned in Section 3. Furthermore, we encourage the authors to release the full code and the MQD dataset to improve reproducibility and visibility. Lastly, addressing the writing quality and citation format will strengthen the overall presentation of the paper.