ID: ZwQJRXLjVm
Title: Rehearsal Learning for Avoiding Undesired Future
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 6, 5, 7, 7, 5, -1, -1, -1, -1
Original Confidences: 2, 2, 3, 3, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Structural Rehearsal Models (SRMs) framework, which is akin to Structural Causal Models but focuses on rehearsation rather than strict causal relations. The authors propose using SRMs to address the Avoiding Undesired Future (AUF) problem, manipulating intermediate variables to maintain the final variable within a desired range. The algorithm is formulated for linear dependencies and one-node interventions, with experiments in toy environments demonstrating its superiority over standard reinforcement learning (RL) algorithms.

### Strengths and Weaknesses
Strengths:  
- The ideas are novel and motivated by the need for a less stringent alternative to causal models, leveraging structure without requiring strict causality.  
- The paper is well-written and structured, making it mostly easy to follow.  
- The introduction of the "rehearsation" paradigm is a significant contribution, and the PAC bound analysis is practical for quantifying uncertainty.  

Weaknesses:  
- The experiments lack a concrete case demonstrating the algorithm's advantages over causal methods, raising questions about the feasibility of using causal methods in the presented scenarios.  
- There is insufficient comparison with existing temporal causal models, such as Granger Causality Models, which could address dynamic decision-making.  
- The paper does not adequately discuss the effects of hyper-parameters on the learning and inference processes, nor does it clarify the computational costs associated with the proposed algorithm.  

### Suggestions for Improvement
We recommend that the authors improve their experimental section by including comparisons with causal methods and temporal causal models, such as Causal Bandits and Granger Causality Models. Additionally, the authors should clarify how the computation graph changes with interventions and provide a detailed analysis of the algorithm's performance under varying assumptions about sample efficiency. It would also be beneficial to include a subsection discussing the limitations of the framework, such as its focus on linear cases and toy environments.