ID: SxXN3kNTsV
Title: Offline Reinforcement Learning for Mixture-of-Expert Dialogue Management
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 6, 4, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 4, 2, 2, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a suite of offline reinforcement learning (RL) methods utilizing Mixture-of-Expert Language Models (MoE LMs) for dialogue management. The authors address challenges such as covariate shift in offline RL and the need for extensive online interactions in online RL, while also tackling the large action space issue. They propose a hierarchical MoE-LM structure, where various experts are optimized for different intents, and a dialogue management model selects expert utterances based on conversation history. The authors demonstrate that their MoE-LMs outperform state-of-the-art (SotA) offline RL methods and behavior cloning on two datasets, particularly in terms of return in simulated conversations.

### Strengths and Weaknesses
Strengths:
- Clear and detailed explanation of algorithms addressing a well-motivated problem.
- Strong empirical results showing the proposed method's superiority over baselines across different dialogue tasks.
- Human evaluation conducted with 80 workers adds credibility to the findings.

Weaknesses:
- Some claims, such as the ability of MoE-LMs to generate diverse conversations, lack substantiation; additional metrics for diversity evaluation are needed.
- The evidence for long-term planning capabilities is unclear; performance improvements should be isolated to confirm this aspect.
- Sample efficiency claims are not experimentally supported, and the implementation details are not provided for reproducibility.
- The presentation is dense, making it difficult to interpret results, particularly in tables.

### Suggestions for Improvement
We recommend that the authors improve the evaluation of diversity by including explicit metrics that assess the diversity of generated conversations. Additionally, to substantiate claims of long-term planning, the authors should isolate and evaluate this effect in their experiments. It would be beneficial to quantify sample efficiency and provide implementation details to facilitate reproducibility. We also suggest revising the presentation for clarity, particularly in the results section, and ensuring that all components of the methods are clearly defined and referenced. Finally, we encourage the authors to move the human evaluation results to the main text and provide commentary on the strengths of different approaches, including an error analysis.