ID: rYjYwuM6yH
Title: 3-in-1: 2D Rotary Adaptation for Efficient Finetuning, Efficient Batching and Composability
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 5, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents RoAd, a novel 2D rotation adaptation method for efficiently fine-tuning large language models (LLMs). RoAd aims to address the challenges of parameter-efficient fine-tuning by rotating representations, achieving impressive results across various benchmarks while reducing training parameters and computational overhead. The authors conduct comprehensive experiments demonstrating RoAd's effectiveness in multitasking and other downstream tasks.

### Strengths and Weaknesses
Strengths:
- The method is simple yet efficient, enhancing batching efficiency and composability.
- RoAd shows promising performance on small-scale language models with fewer or comparable parameters.
- The paper is well-structured, and the writing is clear, making it accessible.

Weaknesses:
- The claim regarding multitasking is inadequately supported, primarily illustrated through qualitative experiments. A comparison with ATTEMPT is recommended to substantiate RoAd's advantages.
- The logical flow, particularly in Chapter 2, is confusing, with sections 2.2 and 2.3 not closely related to section 2.1.
- RoAd's improvement on large-scale models appears limited, as shown in Table 3, where RoAd2/4 performs similarly to LoReFT with more parameters.
- The evaluation of batching efficiency lacks comparisons with other methods, such as those referenced in the paper.
- The novelty of RoAd over OFT needs clarification, as it may be perceived as a specialized case without significant technical advancement.

### Suggestions for Improvement
We recommend that the authors improve the support for their multitasking claims by including quantitative evaluations and comparisons with ATTEMPT. Clarifying the logical flow in Chapter 2 is essential, and the authors should ensure that sections are cohesively related. Additionally, we suggest that the authors explain the limited improvement of RoAd on large-scale models and consider benchmarking RoAd against LoRA with equivalent parameter counts. To enhance the evaluation of batching efficiency, comparisons with other relevant methods should be included. Lastly, the authors should clarify RoAd's novelty in relation to OFT to avoid perceptions of redundancy.