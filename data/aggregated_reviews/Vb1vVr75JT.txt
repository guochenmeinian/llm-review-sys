ID: Vb1vVr75JT
Title: UniTox: Leveraging LLMs to Curate a Unified Dataset of Drug-Induced Toxicity from FDA Labels
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 9, 7, 6, 7, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel framework for drug-induced toxicity, creating a dataset from 2,418 FDA-approved drug label documents processed by a large language model (LLM). The dataset includes concise summaries and toxicity ratings, potentially reducing the need for extensive expert review. The authors demonstrate the dataset's utility through a proof-of-concept machine learning model and validate results with human clinicians. The work is original and addresses a significant gap in drug toxicity data, showcasing the potential for frameworks like UniTox to enhance biomedical research.

### Strengths and Weaknesses
Strengths:
- The dataset is diverse, covering 2,418 drugs and eight toxicity types.
- It is uniform in terms of positive and negative toxicity examples.
- The human in vivo dataset accurately reflects drug effects and cross-toxicity information.
- High accuracy in external validation and comparisons to other models.
- Comprehensive evaluations, including cross-toxicity analysis and sensitivity studies.
- Clear organization and motivation for the research.

Weaknesses:
- The study relies solely on one type of LLM, limiting generalizability.
- Some sections, particularly the ablation study, are confusing and could benefit from clearer presentation.
- The dataset's small size raises questions about its overall utility and representativeness.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the ablation study and associated tables, particularly Table 2, by providing better captions and definitions for metrics like NPV and PPV. Additionally, we suggest benchmarking the performance of other LLMs beyond GPT to enhance dataset diversity. The authors should also clarify the completeness of toxicity ratings for the 2,418 drugs and ensure that the model's confidence in its outputs is accurately represented. Finally, expanding the dataset to include drugs from clinical trials and addressing the limitations of the current benchmarking would strengthen the overall contribution of the work.