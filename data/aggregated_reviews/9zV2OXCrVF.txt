ID: 9zV2OXCrVF
Title: k-Median Clustering via Metric Embedding: Towards Better Initialization with Differential Privacy
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 7, 6, 5, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 4, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the $k$-median problem in a discrete metric space, focusing on selecting $k$ centers from a multiset of datapoints to minimize the sum of distances to the nearest center. The authors propose a new initialization method that improves upon the $k$-median++ initialization, achieving an $O(\log \min\{k, \Delta\})$ approximation, where $\Delta$ is the ratio of the smallest to largest distances in the space. The method involves embedding the metric into a tree metric and applying a constant-factor approximation algorithm, which runs in $O(n \log n)$ time. The paper also addresses $k$-median under differential privacy (DP) constraints, introducing a mechanism that adds Laplace noise to ensure privacy while maintaining performance. Empirical results demonstrate the proposed method's efficiency compared to existing initialization techniques.

### Strengths and Weaknesses
Strengths:
- The paper tackles a significant problem in unsupervised learning, contributing to both $k$-median clustering and differentially private clustering.
- The techniques presented are novel and extend existing work in a meaningful way, particularly in the context of general metric spaces.
- The empirical results indicate a reduction in iterations and costs for both non-private and DP scenarios.

Weaknesses:
- The quantitative improvements are relatively modest, with reductions in steps and additive errors being small.
- The main contribution is primarily in speeding up existing algorithms rather than providing fundamentally new solutions.
- The experimental results lack clarity regarding the variability of the proposed methods, which is crucial for assessing their robustness.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their experimental results by including measures of variation to better demonstrate the reliability of their findings. Additionally, we encourage the inclusion of experiments varying the number of iterations, as this could provide insights into the performance of different initializations. Furthermore, we suggest clarifying the definitions and notations used throughout the paper to enhance readability and comprehension. Lastly, addressing the privacy model more explicitly in the context of the algorithm's guarantees would strengthen the paper's contributions.