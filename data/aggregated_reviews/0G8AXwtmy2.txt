ID: 0G8AXwtmy2
Title: T2Vs Meet VLMs: A Scalable Multimodal Dataset for Visual Harmfulness Recognition
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 7, 9, 7, 3, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1

Aggregated Review:
### Key Points
This paper presents the VHD11K dataset, which includes 10,000 images and 1,000 videos sourced from the internet and generative models, covering ten harmful categories. The authors propose a novel multi-agent Visual Question Answering (VQA) framework utilizing vision-language models (VLMs) to assess harmfulness through a debate mechanism. The study demonstrates strong alignment between the proposed annotation framework and human annotations, indicating the dataset's potential to enhance harmful content recognition methods.

### Strengths and Weaknesses
Strengths:  
- The originality and quality of the work are high, with a well-structured presentation and significant implications for harmful content detection.  
- The methodology for dataset collection is robust and can be adapted for various harmfulness categories.  
- The dataset shows value in improving pre-trained models against both human and VLM-generated labels.  

Weaknesses:  
- The paper lacks detailed information on the annotation procedures, including the annotators' identities, methods, and tools used, which is a significant flaw for a dataset-focused paper.  
- There are concerns regarding the accuracy of auto-generated labels, with a need for further exploration of how label accuracy affects detection performance.  
- Some categories of harm have relatively few images or videos, necessitating a more balanced distribution across categories.

### Suggestions for Improvement
We recommend that the authors improve the documentation of the annotation process by including details about who annotated the data, how the annotation was conducted, and the tools utilized. Additionally, the authors should address the variation in harmful content definitions among different annotators, particularly across categories. To enhance the dataset's utility, consider expanding the dataset beyond 11,000 items to better train harmfulness detectors from scratch rather than relying solely on fine-tuning. Lastly, we suggest that the authors include and explain limitations and ethical concerns within the main content, rather than relegating them to the appendix.