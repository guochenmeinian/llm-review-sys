ID: Xj4LJiXvlX
Title: Batch Bayesian Optimization For Replicable Experimental Design
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 6, 6, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a batch Bayesian optimization method designed for scenarios with significant noise, proposing three variants: BTS-RED-Known, BTS-RED-Unknown, and Mean-Var-BTS-RED. The framework incorporates Thompson Sampling for experiment design and determines the number of replications based on noise levels. Theoretical bounds on regret are established, demonstrating sub-linear performance. Empirical evaluations indicate that the proposed methods outperform existing Bayesian optimization algorithms in synthetic and real-world applications, particularly in Precision Agriculture and AutoML. Additionally, the authors emphasize the computational efficiency of batch Thompson sampling (TS) with large batch sizes, claiming competitive performance with standard batch TS for small batch sizes (4-20) and superior performance for larger sizes (greater than 30). They acknowledge the need for comparisons with non-TS baselines and suggest that incorporating replications into other batch BO algorithms could enhance their effectiveness.

### Strengths and Weaknesses
Strengths:
- The originality of the proposed algorithm is notable, effectively combining established ideas with strong theoretical analysis, including regret bounds and hyper-parameter justification.
- The empirical evidence, while limited, showcases the algorithm's performance, particularly in real-world settings, enhancing its practical significance.
- The computational efficiency of batch TS is well-supported by empirical evidence, and the paper provides a theoretical framework that underpins the practical implementation of the algorithm.
- New experiments on real-valued domains enhance the paper's contributions.
- The clarity of the method's explanation and the quality of figures, despite some readability issues, contribute positively to the presentation.

Weaknesses:
- The empirical evaluation is insufficient, with limited dimensionality and budget scenarios, raising concerns about the robustness of the findings.
- The focus on theory may detract from the clarity and practical implications of the work.
- The choice of using homoskedastic GPs for modeling may lead to model misspecification, and the paper lacks clarity on whether a heteroskedastic GP could provide better performance.
- Insufficient comparison with non-TS baselines leaves questions about the proposed approach's relative performance.
- The novelty of Mean-Var-BTS-RED is questioned, as it may merely represent a linearization of a multi-objective problem.
- Minor issues include unclear heuristics for budget allocation and the small size of figures, which hinder readability.
- The choice of $R^2$ and its tuning with $\kappa$ raises concerns about the universality and robustness of the scaling.

### Suggestions for Improvement
We recommend that the authors improve the empirical evaluation by including a wider range of dimensional problems and varying budget sizes to better assess the algorithm's performance. Clarifying the use of homoskedastic versus heteroskedastic GPs in the modeling process is essential, as is providing a more comprehensive comparison against parallel batch Bayesian optimization algorithms and non-TS baselines such as qUCB and q(N)EI, particularly with $n_t \geq 5$. Additionally, addressing the heuristic for handling unused budget more rigorously and enhancing figure readability would strengthen the paper. Conducting an ablation study on the modeling of $-\sigma^2$ could provide further insights into its implications. Lastly, we suggest clarifying the rationale behind the choice of $R^2$ and the tuning of $\kappa$ to address concerns regarding its universality and effectiveness, as well as discussing the implications of the regret bounds in practical scenarios and providing clearer motivations for the choice of Thompson sampling.