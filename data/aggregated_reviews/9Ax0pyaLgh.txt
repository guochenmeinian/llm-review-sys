ID: 9Ax0pyaLgh
Title: Cross-modality Data Augmentation for End-to-End Sign Language Translation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an end-to-end sign language translation system that converts sign language videos into spoken language texts without intermediate gloss. To address data scarcity, the authors propose a gloss-to-text model for multi-teacher sequence-level knowledge distillation and utilize cross-modality mix-up to bridge the modality gap. Experimental results indicate significant improvements over state-of-the-art (SOTA) methods, achieving approximately 4 BLEU points on two datasets.

### Strengths and Weaknesses
Strengths:
- The introduction of Cross-Modality Mixup and Cross-modality Knowledge Distillation effectively addresses modality gap and data scarcity issues.
- The experimental results support the claims and demonstrate improvements in translating low-frequency words and long inputs.
- The proposed method is sound and reasonable, with well-motivated loss formulations.

Weaknesses:
- The techniques introduced are not novel to the field, as they have been previously studied in speech translation.
- The reliance on CTC as a forced aligner raises concerns about its soundness, particularly regarding its tendency to produce blank outputs and potential inaccuracies.
- The analysis lacks quantitative validation for the mixup mechanism, and there is insufficient exploration of the phenomena observed in the results.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their methodology by aligning Section 2 with Figure 1 and providing a step-by-step description of the proposed method. Additionally, we suggest incorporating human evaluation results and conducting a case study to enhance the qualitative assessment of the model. To strengthen the analysis of the mixup mechanism, we advise including quantitative metrics such as word-level or sequence-level similarity. Finally, a discussion on the limitations of using CTC as a forced aligner should be included to address soundness concerns.