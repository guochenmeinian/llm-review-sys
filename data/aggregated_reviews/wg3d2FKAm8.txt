ID: wg3d2FKAm8
Title: Outlier-Robust Wasserstein DRO
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 6, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an outlier-robust Wasserstein Distributionally Robust Optimization (WDRO) framework that addresses both geometric uncertainties and non-geometric perturbations, such as adversarial outliers. The authors derive bounds on the worst-case excess risk using a new distance termed the 'outlier robust Wasserstein distance' and establish strong duality for efficient computation. Additionally, the paper presents an equivalence between point-wise adversarial attacks and $\mathsf{W}\_\infty$ perturbations for standard WDRO, defining the robust Wasserstein ball $\mathcal{B}\_\infty$ and demonstrating its equivalent representation. The theoretical contributions extend to the $p \to \infty$ limit, providing insights into conditional variance at risk and moment constraints. Empirical validation is provided through regression and classification tasks, although the experimental section could benefit from further depth.

### Strengths and Weaknesses
Strengths:
- The paper tackles the significant problem of incorporating outlier robustness into WDRO, contributing to both machine learning and optimization fields.
- The novelty of the upper and lower bounds on the min-max excess risk is noteworthy, along with the strong duality result that generalizes previous work.
- The theoretical analysis of excess risk bounds is sound, and the empirical study supports the proposed method's effectiveness.
- The theoretical contributions are well-founded, with clear mathematical formulations that extend existing results in the field.
- The paper effectively connects adversarial attacks with robust optimization frameworks, enhancing the understanding of both areas.

Weaknesses:
- The advantages of outlier-robust WDRO over standard WDRO are not convincingly demonstrated, particularly regarding the excess risk bounds.
- The discussion on parameter selection, especially for $\rho$, $\varepsilon$, and $\sigma$, is limited and requires more comprehensive elaboration.
- The paper lacks contextualization within related literature, particularly in comparing results with WDRO without TV corruption and TV robustness without WDRO.
- The experimental section lacks depth, particularly in the context of outlier detection, where the use of MNIST data could be expanded.
- The current experiments do not explore a broader range of digits or varying training flip rates, limiting the applicability of the findings.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the advantages of outlier-robust WDRO over standard WDRO, particularly by providing a tighter bound of the excess risk for WDRO under low-dimensional features. Additionally, a more thorough discussion on the selection and tuning of parameters $\rho$, $\varepsilon$, and $\sigma$ is warranted. We suggest including comparisons with other models designed for handling outliers, such as DFO, in the experimental section. Furthermore, we recommend enhancing the experimental section by incorporating a wider variety of digits from the MNIST dataset, including more than two digits as outliers. Exploring different training flip rates and using multiple digits as normal while selecting one as an outlier for comparison would strengthen the analysis. Lastly, enhancing the contextualization of the work within existing literature would strengthen the paper's contribution.