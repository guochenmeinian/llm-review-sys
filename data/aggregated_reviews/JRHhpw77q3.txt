ID: JRHhpw77q3
Title: Steering Large Language Models for Machine Translation with Finetuning and In-Context Learning
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 6
Original Ratings: -1, -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into tuning a pre-trained language model for machine translation, specifically focusing on the trade-offs between fine-tuning and few-shot prompting. The authors propose a method that integrates few-shot examples into the fine-tuning process, which enhances translation performance while preserving few-shot capabilities. The main contributions include the novel combination of in-context tuning and fine-tuning, supported by extensive experiments and analysis. Key findings indicate that while fine-tuning improves general translation quality, it can degrade few-shot performance unless few-shot examples are incorporated during the fine-tuning phase.

### Strengths and Weaknesses
Strengths:
- The paper is straightforward and easy to follow.
- Extensive experiments support the main findings, demonstrating the effectiveness of the proposed method.
- The analysis provides valuable insights into the trade-offs between fine-tuning and few-shot learning.

Weaknesses:
- The novelty of the method is limited, as it primarily relies on a single pre-trained model (LLaMa 7B), which restricts the generalizability of the conclusions.
- The evaluation lacks comprehensiveness, focusing on only one metric (COMET-22) and not exploring other relevant test sets or metrics.
- The analysis of the impact of fine-tuning on domain-specific translation features is insufficient.

### Suggestions for Improvement
We recommend that the authors improve the comprehensiveness of their experiments by including a variety of pre-trained models, such as different sizes of LLaMa and other models like MPT or Falcon. Additionally, we suggest incorporating reference-free quality evaluation metrics, such as COMET-KIWI, to provide a more robust assessment of translation quality. It would also be beneficial to analyze the effects of fine-tuning with in-domain versus general-domain examples to better understand the model's adaptation capabilities. Finally, we encourage the authors to clarify the rationale behind their choice of uniform sampling for few-shot examples and to provide baseline numbers for few-shot performance compared to zero-shot performance.