ID: 1ptdkwZbMG
Title: Closed-Loop Visuomotor Control with Generative Expectation for Robotic Manipulation
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 7, 6, 5, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents CLOVER, a closed-loop visuomotor control framework that enhances robotic manipulation through feedback mechanisms. The authors propose a text-conditioned video diffusion model for generating visual plans, an error measurement module for quantifying discrepancies between current and goal states, and a feedback-driven controller that refines actions based on real-time feedback. The framework demonstrates significant improvements in task performance on the CALVIN benchmark and in real-world scenarios.

### Strengths and Weaknesses
Strengths:
1. Originality: CLOVER uniquely combines closed-loop control principles with generative models, leveraging a text-conditioned video diffusion model for visual planning.
2. Quality: The methodology is well-articulated, detailing each component's design, including depth map generation and optical flow regularization.
3. Clarity: The paper is clearly written and logically structured, effectively using figures to illustrate complex concepts.
4. Significance: The framework addresses critical challenges in robotics, showing notable performance improvements on benchmarks.

Weaknesses:
1. Generalization: The framework's applicability across different tasks and environments is unclear, particularly regarding sub-goal replanning and the hand-designed replanning threshold.
2. Limited evaluation: The experiments are insufficient to validate the framework's robustness and generalizability, as they are confined to a single experiment with limited tasks.
3. Computational complexity: The framework's reliance on a video diffusion model and feedback mechanisms may introduce significant computational overhead, potentially impacting real-time performance.
4. Methodology clarification: Some technical aspects, particularly algorithms and implementation details, are not thoroughly explained, hindering understanding.

### Suggestions for Improvement
We recommend that the authors improve the generalization of the framework by exploring its applicability across diverse task and robot platforms. Additionally, we suggest providing a detailed analysis of the computational time during testing, as this is crucial for real-time applications. The authors should also conduct further experiments on a wider range of benchmarks and task environments to validate the framework's robustness. Lastly, we encourage the authors to clarify the methodology by elaborating on the algorithms and implementation details to enhance understanding.