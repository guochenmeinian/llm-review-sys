ID: 5sGLPiG1vE
Title: When are Lemons Purple? The Concept Association Bias of Vision-Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates the Concept Association Bias (CAB) in Visual Question Answering (VQA) tasks, revealing that models with CAB treat inputs as separate "bags of concepts" and attempt to fill in missing concepts. It finds that CAB is prevalent in vision-language models trained with contrastive losses. The authors evaluate various models, including CLIP, BLIP, BLIP-2, and OFA, and propose a fine-tuning-based solution to mitigate the identified issues.

### Strengths and Weaknesses
Strengths:  
- The paper presents a focused and interesting question, providing a thorough investigation and proposing a mitigation mechanism.  
- It includes sufficient experimental results and insights, with clear writing and structure.  
- The study deepens understanding of the zero-shot failure in VQA tasks and offers a solid evaluation of different vision-language models.

Weaknesses:  
- Some observations lack robustness, such as the correlation between CAB Score and accuracy, which could be quantified statistically.  
- The novelty is limited, as no new effective methods are proposed to address CAB, and similar works have been conducted previously.  
- Certain aspects of the experimental design may lead to reproducibility challenges due to underspecified parameters.

### Suggestions for Improvement
We recommend that the authors improve the statistical analysis of the CAB Score and its correlation with accuracy to strengthen their observations. Additionally, we suggest that the authors clarify the reasoning behind the models' poor performance on compositional questions versus individual ones. Finally, we encourage the authors to enhance the clarity of parameter settings to facilitate reproducibility.