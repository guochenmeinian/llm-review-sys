ID: 3XDDWCu8CF
Title: A Simple Baseline for Knowledge-Based Visual Question Answering
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a simpler model for Knowledge-Based Visual Question Answering (KB-VQA) that utilizes a smaller open-source LLM (LLaMA) and achieves near state-of-the-art (SOTA) performance on the OK-VQA benchmark. The authors propose a framework that leverages question-focused captioning and few-shot learning without requiring extensive training or external databases. The paper includes comprehensive ablation studies to explore various model components, demonstrating competitive accuracy compared to larger models like GPT-3.

### Strengths and Weaknesses
Strengths:
- The proposed method is simple, intuitive, and reproducible, making it accessible for future research.
- The empirical results indicate that the framework achieves competitive performance, closely matching existing black-box models.
- The thorough experiments and robust ablation studies effectively substantiate the efficacy of the proposed mechanisms.

Weaknesses:
- The paper lacks significant algorithmic novelty, primarily combining existing methods without introducing new techniques.
- Results do not surpass those of the SOTA PROPHET system, limiting the perceived innovation.
- There is a need for clearer references to related work, such as the KAT model and earlier studies on question-focused captions.

### Suggestions for Improvement
We recommend that the authors improve the novelty aspect by clearly articulating the unique contributions of their approach compared to existing methodologies. Additionally, providing performance results using larger models like GPT-4 could demonstrate the upper-bound capabilities of the framework. It would also be beneficial to include a comparative analysis across other KB-VQA datasets, such as A-OKVQA, to broaden the evaluation. Lastly, we suggest addressing the missing references and clarifying the use of MCAN within the paper.