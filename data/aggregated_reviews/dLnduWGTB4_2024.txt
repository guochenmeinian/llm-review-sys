ID: dLnduWGTB4
Title: QUEST: Quality-Aware Metropolis-Hastings Sampling for Machine Translation
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 7, 6, 6, 5, -1, -1
Original Confidences: 3, 3, 3, 4, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach called Quality-Aware Metropolis-Hastings (QUEST) Sampling, aimed at generating high-quality and diverse translations in machine translation. The authors propose a method that utilizes a proposal distribution compatible with sentence-level metrics and employs the Metropolis-Hastings MCMC algorithm. Empirical results across four WMT language pairs demonstrate that QUEST can produce diverse, high-quality hypotheses compared to ancestral sampling. However, the robustness of this approach in low-resource settings and longer sequences remains unclear.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, organized, and easy to follow.
- It introduces a novel idea for sampling high-quality, diverse hypotheses rather than relying solely on re-ranking.
- The experimental results indicate the efficiency of QUEST, particularly in high-resource scenarios.

Weaknesses:
- The approach is limited to sentence-level metrics, raising questions about its applicability to document-level metrics and low-resource languages.
- There is a risk of "gaming the metric" due to reliance on quality estimates, suggesting a need for human evaluations.
- The evaluation metrics used for QUEST are not widely recognized, and additional results from common datasets would enhance credibility.

### Suggestions for Improvement
We recommend that the authors improve the discussion on how to extend their approach to document-level metrics and address the challenges associated with longer sequences. Additionally, it would be beneficial to include human evaluations to validate the results and explore the method's performance in low-resource scenarios. Clarifying the retrieval set for high-quality translations and providing more examples would also enhance understanding. Lastly, incorporating results from other common datasets would strengthen the paper's findings.