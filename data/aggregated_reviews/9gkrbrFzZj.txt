ID: 9gkrbrFzZj
Title: OpenSTL: A Comprehensive Benchmark of Spatio-Temporal Predictive Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 6, 7, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents OpenSTL, a benchmark for spatio-temporal predictive learning that implements various classic and state-of-the-art methods, supporting multiple STL datasets such as synthetic/natural video prediction, traffic flow estimation, and weather forecasting. The authors highlight the effectiveness of recurrent-free models, particularly using MetaFormers as middle temporal modules, and provide extensive benchmark results demonstrating that while traditional recurrent methods excel in video prediction, recurrent-free methods outperform in micro-scale tasks like weather forecasting with lower computational demands.

### Strengths and Weaknesses
Strengths:
- OpenSTL addresses the need for a unified benchmark in predictive spatio-temporal learning, enhancing reproducibility in the field.
- The code is well-structured and documented, facilitating ease of use for researchers.
- The exploration of recurrent-free methods and their computational efficiency is insightful and relevant.

Weaknesses:
- The paper lacks the inclusion of robotics-related datasets such as BAIR and RoboNet, which could enrich the benchmark.
- There is insufficient analysis of the performance trends among the tested Transformer architectures, leaving beginners unclear on optimal temporal module choices.
- The discussion on limitations and future directions is brief and could be expanded for clarity.

### Suggestions for Improvement
We recommend that the authors improve the benchmark by including additional datasets like BAIR and RoboNet to broaden its applicability. Furthermore, we suggest providing a more detailed analysis of the performance of various temporal modules to guide beginners in selecting appropriate models for recurrent-free predictors. Additionally, we encourage the authors to elaborate on the limitations of the current benchmark and discuss future directions in greater detail to enhance the paper's depth.