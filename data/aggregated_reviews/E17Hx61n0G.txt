ID: E17Hx61n0G
Title: Graph Contrastive Learning with Cohesive Subgraph Awareness
Conference: ACM
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework called CTAug, which integrates cohesion awareness into graph contrastive learning (GCL). CTAug includes two main modules: a topology augmentation module that preserves cohesive subgraphs and a graph learning enhancement module that improves the encoder's ability to identify subgraph features. The authors aim to demonstrate that CTAug theoretically and empirically enhances state-of-the-art performance in graph and node representation learning.

### Strengths and Weaknesses
Strengths:
- The authors provide thorough justification for the relevance of cohesive substructures to downstream tasks.
- CTAug is simple, intuitive, and technically sound, with clear presentation.
- Experimental results show significant improvements in graph classification accuracy across various datasets.

Weaknesses:
- The technical contribution is limited, with unclear motivation for the "Unified Framework" and "Expressive Network."
- The theoretical justification is weak, primarily relying on unrelated proofs and lacking clarity on the contrastive schema.
- The experimental evaluation lacks recent baselines and does not adequately address the model's performance compared to GCL models without explicit augmentations.
- The applicability of cohesive properties to all graph types is questionable, particularly for graphs with high heterophily.

### Suggestions for Improvement
We recommend that the authors improve the theoretical analysis by providing a clearer proof for the contrastive schema between augmented graphs. Additionally, the authors should analyze the probability and extent to which cohesive subgraphs are preserved during probabilistic topology augmentation. It would be beneficial to elaborate on the limitations of their approach, particularly in contexts where cohesive subgraphs may not be relevant. Furthermore, we suggest including comparisons with recent methods in comparative learning data augmentation and clarifying the aggregation process in Equations 13 and 14. Lastly, the authors could investigate how CTAug impacts graph/node classification precision and recall.