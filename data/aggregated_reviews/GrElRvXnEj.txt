ID: GrElRvXnEj
Title: Score-based Generative Modeling through Stochastic Evolution Equations in Hilbert Spaces
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 7, 7, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Hilbert Diffusion Model (HDM), a generative model that generalizes diffusion models to infinite-dimensional state spaces using generalized stochastic differential equations (SDEs). The authors extend the concepts of score and time-reversal to this framework, applicable to infinite-dimensional diffusion models and stochastic partial differential equations (SPDEs). They utilize the Fourier Neural Operator (FNO) for learning the score and demonstrate the model's efficiency in function and image generation tasks. Additionally, the paper extends previous work to a continuous-time setting, specifically addressing the case of time-dependent coefficients. The authors clarify that the variational approach offers advantages over the semigroup approach, particularly in handling infinite-dimensional stochastic differential equations (SDEs). They also discuss the performance of the Denoising Diffusion Probabilistic Model (DDPM), noting its limitations in generating meaningful samples compared to the proposed Hierarchical Diffusion Model (HDM).

### Strengths and Weaknesses
Strengths:
- The paper provides a robust theoretical framework for Hilbert diffusion models, with well-presented ideas.
- The experiments convincingly demonstrate the model's superior performance compared to other non-noising perturbation models.
- The paper effectively extends existing frameworks to accommodate time-dependent coefficients, showcasing the variational approach's flexibility.
- The authors provide detailed experimental results, indicating improvements in model performance with increased feature sizes.

Weaknesses:
- There is insufficient discussion on the relationship between this work and existing literature on diffusion models, particularly regarding the novelty of Theorem 2.1 and the theoretical distinctions from previous works.
- The practical motivation for using infinite-dimensional diffusion models remains unclear, as the advantages of infinite resolution could also be achieved with finite-dimensional models.
- The rationale for choosing perturbations other than Gaussian noise lacks practical justification.
- The DDPM's performance is notably poor, failing to generate samples that align with the data distribution, even after extended training.
- The complexity of the variational approach may pose challenges for practitioners in the machine learning community who lack familiarity with the necessary analytical tools.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the relationship between their work and existing literature, particularly addressing how HDM differs from previous models. Clarifying the novelty of Theorem 2.1 in relation to prior studies would enhance the paper's contribution. Additionally, the authors should provide a clear motivation for the use of infinite-dimensional diffusion models, potentially by presenting examples where such models are essential. Furthermore, we suggest that the authors elaborate on the benefits of using non-Gaussian perturbations and consider including a related work section to contextualize their findings within the broader field. We also recommend that the authors improve the clarity of the advantages of the variational approach over the semigroup approach, particularly in practical applications for the ML community. Additionally, we suggest that the authors provide a more thorough discussion on the limitations of the DDPM and explore potential architectural adjustments to enhance its performance. Finally, we encourage the authors to ensure that the results regarding the DDPM and HDM are clearly presented in the revised manuscript.