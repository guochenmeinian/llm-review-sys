ID: wLiMhVJ7fx
Title: Calibrating Neural Simulation-Based Inference with Differentiable Coverage Probability
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 6, 7, 7, 7, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for calibrated simulation-based inference by introducing a calibration term in the training objective of neural posterior estimators (NPEs) and neural rejection estimators (NREs). The authors propose a regularizer that encourages well-calibrated posterior approximations, achieving competitive results in terms of coverage and expected posterior density. The method is evaluated on benchmark tasks, demonstrating good performance, particularly in log-likelihood.

### Strengths and Weaknesses
Strengths:
- The method is novel, particularly the use of a differentiable sorting algorithm for differentiating through coverage.
- The theoretical framework is rigorously developed, and empirical results are provided regarding hyperparameter impact and computational costs.
- The writing quality is high, with a clear structure and effective figures that support the paper's messages.

Weaknesses:
- The method may be computationally expensive, especially with large batch sizes, which should be clarified.
- The paper does not adequately address how overfitting is prevented, and the use of 500 epochs for training is impractical.
- Results in Appendix Fig 6 should be discussed in the main text, highlighting that the method produces conservative but not calibrated posteriors.
- The experiments are limited to low-dimensional tasks, and there is a lack of empirical evidence for high-dimensional scalability.
- The introduction of numerous symbols complicates readability; redefinitions in new sections are recommended.

### Suggestions for Improvement
We recommend that the authors improve clarity by redefining symbols in new sections and removing unnecessary abbreviations. Additionally, please clarify the computational costs associated with large batch sizes and provide empirical evidence for the method's performance in high-dimensional parameter spaces. We suggest investigating alternative metrics for performance evaluation beyond the regularizer's main metric. Furthermore, please address the poor results in Appendix Fig 6 in the main text and clarify the methods used to prevent overfitting. Lastly, consider adding a discussion on the advantages and disadvantages of sorting-based versus direct computation methods.