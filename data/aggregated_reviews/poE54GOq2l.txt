ID: poE54GOq2l
Title: SnapKV: LLM Knows What You are Looking for Before Generation
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 6, 7, 6, -1, -1, -1, -1
Original Confidences: 4, 5, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for KV cache compression in long-context scenarios, addressing high storage pressure in KV caches. The authors propose a training-free approach that utilizes an observation window to identify important KV pairs, employing pooling and topK techniques. The method is evaluated on four models—LWM-1M, Mistral-32K, LongChat-32K, and Mixtral-32K—across two tasks, LongBench and Needle In A Haystack, demonstrating a 2% drop in performance on the GovReport task and a reduction to 140K context on the Needle In A Haystack task, while achieving a 3.6x reduction in decoding stage latency.

### Strengths and Weaknesses
Strengths:
- The problem addressed is significant and practically valuable.
- The motivation is sound, supported by experimental evidence.
- The approach is simple and compatible with existing kernel methods, yielding significant accuracy improvements over prior work.

Weaknesses:
1. The experimental section is limited, testing only two benchmarks, which raises concerns about generalizability. The Needle In A Haystack task lacks comparisons with full attention and other baselines, and the context windows tested are relatively short.
2. The pooling method's justification is insufficient, and its effectiveness is unclear across different tasks, particularly non-retrieval tasks where it may degrade performance.

### Suggestions for Improvement
We recommend that the authors improve the experimental section by including additional baseline results for the Needle In A Haystack test and exploring more demanding long-context benchmarks, such as RULER and InfiniteBench. It would be beneficial to conduct experiments on longer contexts and provide results for vLLM to accurately reflect speedup improvements. Additionally, we suggest including a more detailed analysis of the pooling approach and its impacts across various tasks, particularly non-retrieval tasks. Lastly, please correct the typo in Fig. 8, where the label "without" should be changed to "with."