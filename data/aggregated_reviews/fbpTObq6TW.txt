ID: fbpTObq6TW
Title: A fast heuristic to optimize time-space tradeoff for large models
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 6, 6, 6, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper proposes an algorithm for the rematerialization problem, utilizing simulated annealing to optimize memory usage and training time in neural network training. The authors formalize recomputation as a sequence of nodes, optimizing throughput within a memory budget. The method, termed Fast Simulated Annealing Algorithm (FastSA), demonstrates significant reductions in computation overhead compared to the state-of-the-art optimizer Checkmate, particularly in memory-restricted scenarios.

### Strengths and Weaknesses
Strengths:
1. The paper is well-structured and presents a clear formulation of the problem.
2. The proposed method is novel and effectively combines the add-max segment tree with simulated annealing.
3. The evaluation is convincing, showing substantial improvements in memory reduction and runtime compared to Checkmate.

Weaknesses:
1. The contribution is somewhat incremental and does not introduce a fundamentally new problem or technique.
2. There is a lack of comprehensive comparisons with other recent algorithms, such as Moccasin and Rockmate.
3. The baseline Checkmate results are derived from an open-source solver, which may affect both runtime and solution quality.

### Suggestions for Improvement
We recommend that the authors improve the comparison of their results against the MILP-based Checkmate using Gurobi to provide a clearer benchmark. Additionally, conducting a qualitative and quantitative comparison with the Moccasin algorithm would strengthen the paper's contributions. We suggest that the authors explore profiling operator durations for more accurate cost assignments instead of assuming uniform costs. Clarifying the definitions of "FastSA" and "FastSA Only" in Figure 4, as well as the optimization time metrics presented, would enhance the paper's clarity. Lastly, addressing the limitations regarding the grouping heuristics and other GPU memory factors would provide a more comprehensive discussion of the algorithm's performance.