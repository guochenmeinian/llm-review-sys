ID: Mqx2gquLk0
Title: Learning in Markov Games with Adaptive Adversaries: Policy Regret, Fundamental Barriers, and Efficient Algorithms
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 5, 7, 6, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 3, 2, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on learning in Markov games against adaptive adversaries, focusing on the concept of "policy regret" rather than the more common external regret. The authors derive both upper and lower bounds on the complexity of learning in these games, demonstrating that achieving sublinear policy regret is impossible when the adversary is fully adaptive. They introduce the notion of "consistent adversaries" and propose algorithms that achieve sublinear policy regret under certain memory constraints.

### Strengths and Weaknesses
Strengths:
- The paper provides significant insights into the challenges of learning in Markov games, particularly highlighting the difficulties posed by adaptive adversaries.
- It establishes strong lower bounds that illustrate the complexity of minimizing policy regret in this context.
- The authors propose efficient algorithms with theoretical guarantees for scenarios where the adversary's memory is limited.

Weaknesses:
- The paper is overly dense, which negatively impacts readability; proofs are relegated to the appendix without sufficient intuition provided in the main text.
- The presentation of algorithms is compact and difficult to follow, with some details only available in the appendix.
- The concept of "consistent adversaries" requires further clarification, particularly regarding its implications for adversarial behavior and policy exploitation.

### Suggestions for Improvement
We recommend that the authors improve the paper's readability by providing more intuitive explanations of the results and algorithms in the main text, rather than relying solely on the appendix. Additionally, we suggest a more thorough discussion of the "consistent adversary" concept to clarify its implications and justify its use. Finally, addressing the concerns regarding the necessity of strong assumptions for policy regret and the relationship between the adversary's behavior and the learner's strategies would enhance the paper's clarity and impact.