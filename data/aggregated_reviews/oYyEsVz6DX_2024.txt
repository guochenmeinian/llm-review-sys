ID: oYyEsVz6DX
Title: Measuring Per-Unit Interpretability at Scale Without Humans
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 7, 5, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method for measuring per-unit interpretability of vision models, termed the Machine Interpretability Score (MIS), which automates the 2-AFC task using DreamSim. The MIS is highly correlated with human measures of interpretability and enables predictions about which units are more interpretable. The authors compute average per-unit interpretability for 835 computer vision models, revealing significant findings such as the negative correlation between accuracy and average per-unit interpretability, and the increased interpretability of deeper layers. The authors also highlight several practical applications of the MIS, including optimizing networks for interpretability, model selection based on interpretability scores, hyperparameter tuning for interpretability tools, prioritizing interpretability efforts, and reducing computational complexity in neural circuit identification. They differentiate their MIS from MAIA, emphasizing its grounding in human psychophysical setups and its ability to assess interpretability based on human perception. Preliminary results indicate that using Sparse Autoencoders (SAEs) improves interpretability scores compared to original layers.

### Strengths and Weaknesses
Strengths:  
- The paper is exceptionally clear and well-structured, addressing limitations and providing a comprehensive appendix.  
- It offers a significant contribution by solving a longstanding problem in per-unit interpretability in a scalable manner, utilizing reliable tools and methodologies.  
- The results are compelling, demonstrating the potential of MIS to automate interpretability assessments and provide insights into model behavior.  
- The authors provide numerous practical applications for their MIS, enhancing its relevance.  
- Preliminary results demonstrate the effectiveness of SAEs in improving interpretability scores.

Weaknesses:  
- The underlying task for MIS may be too simplistic, limiting its downstream applications and failing to account for the superposition phenomenon, which could hinder interpretability.  
- The empirical range of MIS values is narrow, making it difficult to derive meaningful distinctions.  
- The methods section is overly mathematical, obscuring the simplicity of the underlying approach.  
- The reliance on existing tools and frameworks raises questions about the novelty and technical contribution of the metric itself.  
- The potential impact of the work on the field remains unclear, with concerns about the optimization target and complexity.  
- The paper may not meet the high bar for "excellent impact" in multiple areas as suggested by some reviewers.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the methods section to better convey the simplicity of the approach. Additionally, it would be beneficial to demonstrate practical applications of the MIS, such as combatting spurious correlations or uncovering biases. We suggest exploring the implications of superposition on MIS and providing a more robust justification for the claim that "if we can measure it, we can optimize for it." Furthermore, addressing the limitations of the metric in terms of its applicability across different domains and its interaction with human decision-making would enhance the paper's impact. We also recommend improving the discussion section by adding potential use cases for their MIS and including additional analysis of SAEs. Clarifying the optimization target and addressing concerns about the complexity of the approach could further strengthen the paper's impact.