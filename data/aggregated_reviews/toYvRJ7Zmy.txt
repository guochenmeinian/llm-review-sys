ID: toYvRJ7Zmy
Title: Derandomized novelty detection with FDR control via conformal e-values
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 6, 5, 7, 7, -1, -1, -1, -1
Original Confidences: 4, 2, 4, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to conformal novelty detection by applying the derandomized e-value, which enhances stability compared to traditional methods using conformal p-values. The authors refine their method by adaptively weighting conformal e-values based on estimated out-of-sample accuracy. The paper demonstrates the effectiveness of this approach through simulations with both synthetic and real data, showing improved control over the False Discovery Rate (FDR).

### Strengths and Weaknesses
Strengths:  
- The paper introduces a pioneering application of e-values in conformal inference, significantly reducing randomness and improving stability in novelty detection.  
- It provides a rigorous framework for controlling FDR while aggregating results from dependent tests, which is a notable advancement in the field.  
- The clarity of presentation is commendable, and the experimental results indicate that the derandomized method can outperform traditional approaches in certain scenarios.

Weaknesses:  
- The novelty of the work is somewhat limited, as it builds on existing studies related to derandomization and e-values, making the contribution less original.  
- The presentation of ideas is convoluted, which may hinder reader comprehension.  
- The reliance on synthetic data, particularly from simple Gaussian distributions, raises concerns about the generalizability of the results to more complex real-world scenarios.  
- The method's performance varies significantly across different application regimes, and it may not consistently outperform other methods.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their presentation to facilitate better understanding of their methodologies and arguments. Additionally, the authors should emphasize the unique aspects of their approach to strengthen its originality. Including more empirical evaluations, particularly with complex synthetic data or real-world datasets, would enhance the robustness of their findings. Furthermore, we encourage the authors to explore the extension of their data-driven weighting method to more general cases beyond outlier detection, as this could broaden the impact of their research.