ID: gVTkMsaaGI
Title: Amortizing intractable inference in diffusion models for vision, language, and control
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 7, 5, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 2, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for training diffusion models to sample from an intractable posterior distribution, leveraging a prior diffusion model and an arbitrary likelihood function. The authors propose relative trajectory balance (RTB) as a training objective, enabling off-policy training and parameter-efficient fine-tuning of the prior diffusion model. The effectiveness of this approach is validated through experiments across various tasks, including vision, language modeling, and continuous control.

### Strengths and Weaknesses
Strengths:
- The proposed method effectively fine-tunes a prior diffusion model to sample from a posterior distribution, demonstrating its applicability across multiple tasks.
- The paper is well-written and organized, providing a clear theoretical justification for the RTB constraint and empirical validation through diverse experiments.

Weaknesses:
- The clarity of the off-policy nature of the data used in training is questionable; it appears that the data may be mostly on-policy with minor noise added.
- The qualitative results in the experiments do not show significant differences between the proposed method and existing baselines, raising concerns about the actual improvements in generation quality.
- There is a lack of standard deviation/error reporting for baseline results, which is critical for assessing the robustness of the findings.
- The scalability of the method is uncertain, particularly as the prior model size increases, and there is insufficient exploration of the impact of hyperparameters on performance.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the relationship between the training data and the on/off-policy distributions of the prior and posterior models. Additionally, it would be beneficial to include a discussion on the selection process for the samples presented in the results to avoid potential cherry-picking. The authors should also report standard deviations for baseline metrics to enhance the reliability of the comparisons. Furthermore, conducting ablation studies on the various stabilization and implementation techniques used would provide deeper insights into their contributions. Lastly, including experiments that test the generalizability of the RTB method to conditional constraints and exploring its scalability with larger models would strengthen the paper.