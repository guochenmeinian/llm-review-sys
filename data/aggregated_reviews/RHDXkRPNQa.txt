ID: RHDXkRPNQa
Title: Learning Rule-Induced Subgraph Representations for Inductive Relation Prediction
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 6, 4, 6, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 3, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents REST, a method for inductive link prediction over knowledge graphs that avoids node labeling and initializes only the target link representation, thereby reducing execution time and noise. REST employs edge-wise message passing through learnable functions and gated recurrent units (GRU) to iteratively update edge representations, with node updates computed via long-short term memory (LSTM) cells. The authors demonstrate that REST learns rule-induced subgraph representations and achieves strong empirical results on standard inductive link prediction benchmarks, supported by ablation studies and additional experiments on WN18RR.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and easy to follow.
- The design choices in REST, such as single-source initialization and message passing, are well-justified and empirically supported.
- The literature overview is comprehensive.
- The experimental results on inductive datasets are strong, and the ablation studies highlight the value of the model.
- The additional case study is engaging.

Weaknesses:
- Not all baseline results are reported in the experimental section, particularly for NBFNet, which may have superior performance on FB15k-237. Including these results is crucial for completeness.
- The experimental section could benefit from additional benchmarks, such as transductive versions of current datasets and OGB benchmarks for link prediction.
- The proposed modifications to standard message passing are mostly incremental, limiting the novelty of the work.
- The reliance on fixed subgraph extraction presents scalability limitations and generalization issues for longer relational paths.

### Suggestions for Improvement
We recommend that the authors improve the experimental section by including all relevant baseline results, particularly for NBFNet, and discussing potential performance variations. Additionally, we suggest incorporating further benchmarks from transductive setups and OGB datasets to enhance the robustness of the evaluation. To address the limitations of subgraph-based methods, we encourage the authors to explore the impact of the n-hop number on model performance across various data distributions and propose solutions for scalability challenges. Lastly, we advise enhancing the clarity of Section 3 by better separating mathematical expressions from the text.