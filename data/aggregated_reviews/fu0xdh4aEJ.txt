ID: fu0xdh4aEJ
Title: Bigger, Regularized, Optimistic: scaling for compute and sample efficient continuous control
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 7, 7, 8, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates the sample efficiency problem in continuous control and introduces the BRO algorithm (Bigger, Regularized, Optimistic). The authors demonstrate that strong regularization enables effective scaling of critic networks, combined with optimistic exploration, resulting in notable performance improvements. BRO achieves strong results on various continuous control benchmarks and is the first model-free reinforcement learning algorithm to learn meaningful performance in DMC dog and humanoid tasks. The study also emphasizes the importance of parameter scaling and presents BroNet, a variant of ResNet, which enhances performance through proper regularization.

### Strengths and Weaknesses
Strengths:
- The paper is easy to follow and addresses a crucial topic in the RL community, focusing on the development of robust model-free RL algorithms for continuous control.
- The authors effectively integrate established techniques into a cohesive framework, demonstrating significant performance gains.
- Extensive and solid experiments validate the proposed BRO algorithm, which achieves state-of-the-art performance across multiple complex tasks.

Weaknesses:
- The quality of figures needs improvement; exporting as PDFs instead of screenshots is recommended.
- BRONet appears to be a simplified version of ResNet, and the authors should avoid overstating its architectural differences.
- Clarity is lacking regarding how figures are plotted and the environments they represent.
- The claim that *Algorithmic improvements matter less as the scale increases* warrants further scrutiny and discussion.
- The paper lacks comparisons with recent strong model-free RL algorithms, such as TD7 and REDQ, and should include relevant references and baselines.

### Suggestions for Improvement
We recommend that the authors improve the quality of figures by exporting them as vector PDFs. Additionally, please clarify the architectural distinctions between BRONet and ResNet to avoid over-claiming. Ensure that the plotting details of figures are explicitly stated in the main text. We suggest a more nuanced discussion regarding the claim about algorithmic improvements and scaling. Finally, we encourage the authors to include comparisons with TD7, REDQ, and other relevant works like SMR and DARC to strengthen the paper's contributions.