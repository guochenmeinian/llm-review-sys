ID: Z7O1kA3pjB
Title: Summarizing Multiple Documents with Conversational Structure for Meta-Review Generation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents PEERSUM, a novel dataset for meta-review generation that incorporates inter-document relationships and conflicting information, distinguishing it from other multi-document summarization (MDS) datasets. The authors propose RAMMER, a relationship-aware multi-task meta-review generator model that leverages sparse attention and multi-task learning techniques, achieving better performance than existing baselines. The dataset and code are made available for reproducibility.

### Strengths and Weaknesses
Strengths:  
- The dataset PEERSUM is meaningful for analyzing multi-document abstractive summarization.  
- The experimental setup is strong, and the analysis of the dataset is comprehensive and credible.  
- The model shows promise in performance and offers interesting observations regarding conflict resolution.  
- Code and dataset availability facilitate reproducibility.

Weaknesses:  
- Key aspects of the relationship-aware sparse attention mechanism are unclear, and the model diagram is difficult to understand.  
- The proposed model does not adequately reflect the design of conflicts, which is a critical feature of the dataset.  
- There is insufficient analysis of the four auxiliary tasks and their roles in the multi-task design.  
- Results are not strong enough to demonstrate significant impact, and further iterations are needed.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the relationship-aware sparse attention description and enhance the model diagram for better understanding. It is essential to explicitly address how conflicts are integrated into the model design. We suggest conducting a thorough analysis of the auxiliary tasks to clarify their contributions. Additionally, providing stronger examples of real-world applications for meta-review generation would enhance the paper's impact. Finally, we advise standardizing hyper-parameter settings across all baselines to reduce potential biases in experimental results.