ID: 0AumdfLzpK
Title: A Simple Framework for Generalization in Visual RL under Dynamic Scene Perturbations
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents SimGRL, a framework designed to enhance generalization in vision-based deep reinforcement learning (RL) by addressing two critical issues: imbalanced saliency and observational overfitting. The authors propose modifications to the image encoding process, stacking frames at the feature level rather than the observation level, and introduce a novel shifted random overlay augmentation technique. Extensive experiments demonstrate that SimGRL achieves state-of-the-art performance on benchmarks like the DeepMind Control Suite, supported by the introduction of Task-Identification (TID) metrics for evaluating task-relevant features.

### Strengths and Weaknesses
Strengths:
- The proposed architectural modification effectively addresses imbalanced saliency, ensuring agents focus on salient features.
- The shifted random overlay augmentation enhances generalization by simulating dynamic backgrounds, helping agents ignore irrelevant changes.
- Comprehensive evaluation across multiple benchmarks shows superior performance and introduces quantitative metrics for assessing task relevance.

Weaknesses:
- The dependency on the quality and diversity of images for augmentation may limit performance in real-world scenarios.
- The paper does not explore the applicability of the proposed methods to robust RL algorithms that utilize single frames, which may also suffer from imbalanced saliency.
- The analysis of performance on the Video Easy benchmark is insufficiently detailed, and the implications of TID metrics could be better articulated.

### Suggestions for Improvement
We recommend that the authors improve the articulation of the motivation and contributions of the paper by including a dedicated paragraph summarizing these aspects. Additionally, a more in-depth analysis of the performance on the Video Easy benchmark is necessary. We suggest exploring the effects of different data augmentations applied independently to each frame in the stacked input. Furthermore, it would be beneficial to compare SimGRL with more recent robust RL methods under consistent augmentation settings to strengthen the paper's contributions. Lastly, addressing the limitations of the method, particularly in terms of its applicability to diverse RL environments, would enhance the overall robustness of the research.