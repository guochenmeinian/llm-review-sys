ID: KmMSQS6tFn
Title: Path-LLM: A Multi-Modal Path Representation Learning by Aligning and Fusing with Large Language Models
Conference: ACM
Year: 2024
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Path-LLM, a multi-modal path representation learning framework that integrates large language models (LLMs) with textual and topological data. The authors propose TPalign for contrastive alignment and TPfusion for dynamic fusion, addressing modality conflicts. Additionally, they introduce a Two-stage Overlapping Curriculum Learning (TOCL) strategy to enhance generalization. Experimental results demonstrate superior performance in tasks such as path ranking and travel time estimation, including in few-shot and zero-shot scenarios.

### Strengths and Weaknesses
Strengths:
1. The integration of textual and topological modalities is well-designed, addressing key limitations of single-modal path representation learning (PRL) methods.
2. The TOCL strategy effectively enhances generalization, particularly in few-shot and zero-shot scenarios.
3. Empirical results show clear performance gains over strong baselines on real-world datasets.

Weaknesses:
1. The paper does not deeply explore why certain components, such as TOCL or TPfusion, significantly contribute to performance, potentially leaving doubts about the necessity of these design choices.
2. The evaluation lacks diversity in geographic and traffic conditions, which may not fully reflect the modelâ€™s adaptability to varied real-world scenarios.
3. Concerns about computational efficiency and scalability arise from the reliance on pre-trained LLMs, especially regarding fine-tuning and memory requirements.

### Suggestions for Improvement
We recommend that the authors improve the explanation of the embedding distributions in Figure 1 and provide a clearer discussion of the experimental details. Additionally, the authors should elaborate on the design of text prompts used for obtaining text embeddings. It would be beneficial to include a broader range of datasets in the evaluation to assess the model's robustness across different traffic patterns. We also suggest that the authors clarify the specific differences between their proposed method and existing works, particularly those that also utilize multi-modal data. Lastly, addressing the computational cost and scalability of integrating LLMs into real-time transportation systems would enhance the paper's practical relevance.