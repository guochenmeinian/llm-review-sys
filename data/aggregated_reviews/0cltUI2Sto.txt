ID: 0cltUI2Sto
Title: On Occlusions in Video Action Detection: Benchmark Datasets And Training Recipes
Conference: NeurIPS
Year: 2023
Number of Reviews: 18
Original Ratings: 6, 7, 6, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into the effects of occlusions on video action detection, introducing five datasets: O-UCF, OccJHMDB, RealOccUCF, OVIS-UCF, and OVIS-JHMDB. The authors evaluate various video action detection methods, analyzing the impact of different backbones, types of occlusion, and the use of capsule networks. They propose that models perform better with static occlusions compared to dynamic ones and provide insights into the effectiveness of their model, VCAPS-Mvitv2, by demonstrating the emergence of "islands of agreement" in token representations. An improved training recipe is also proposed to enhance robustness against occlusions.

### Strengths and Weaknesses
Strengths:
- The introduction of five datasets specifically designed for evaluating video action detection under occlusion conditions is a significant contribution.
- The paper provides a thorough analysis of various factors affecting performance, including backbone architecture and occlusion types, leading to the proposal of an improved training strategy.
- The analysis of VCAPS-Mvitv2 offers valuable insights into model performance and representation learning.
- The authors have made significant revisions based on reviewer feedback, improving clarity and detail in the manuscript.

Weaknesses:
- The distinctions between the O-UCF and RealOccUCF datasets are unclear, particularly regarding the synthesis of occlusions.
- The paper's complexity and inconsistent writing may hinder readability and comprehension.
- Some experimental details and dataset annotations remain insufficiently transparent, which could affect the evaluation of results.
- Some conclusions lack strong experimental support, particularly regarding the impact of different backbones and the performance of various models.

### Suggestions for Improvement
We recommend that the authors clarify the differences between the O-UCF and RealOccUCF datasets, particularly in terms of occlusion synthesis. Additionally, including results from RealOccUCF in Tables 5 and 6 would provide insights into model performance under realistic occlusion scenarios. We suggest incorporating synthesized examples of the datasets within the paper to enhance understanding. Furthermore, a thorough language and grammar check is necessary to improve readability. The authors should also provide more detailed explanations regarding the annotations in the RealOccUCF dataset and consider simplifying complex sections to enhance clarity. Lastly, we encourage the authors to expand their exploration of model performance across different architectures beyond the ResNet series to strengthen their conclusions and focus on streamlining the content to avoid spreading the paper too thin across multiple directions.