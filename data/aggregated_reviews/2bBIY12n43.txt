ID: 2bBIY12n43
Title: A State-Vector Framework for Dataset Effects
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework for quantifying the effects of single datasets and their interactions on model performance, formulated as a state-vector framework. The authors investigate how certain datasets influence linguistic abilities, revealing findings such as negative impacts from some datasets on abilities seemingly unrelated to task nature. The framework allows for a comprehensive analysis across multiple probing tasks, providing insights into dataset transferability and the potential for responsible model development.

### Strengths and Weaknesses
Strengths:
- The framework is novel and general, allowing for the assessment of various datasets across multiple dimensions.
- Extensive experiments were conducted on two models (BERT and RoBERTa) with a thorough discussion of results, including intriguing findings like the "spill-over" effect.
- The paper is well-written and mathematically grounded, contributing significantly to understanding dataset effects.

Weaknesses:
- The framework's vector-space formulation is seen as redundant, given that the effects are derived from basic linear algebra and probability operations.
- Downstream performance metrics, such as accuracy and F1 score, are largely ignored, raising concerns about the practical implications of the findings.
- Variance in individual effects and interactions is not adequately reported, which may affect reproducibility.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the results in Tables 2-4 by explicitly showing how individual effects were calculated and including variance measures. Additionally, it is crucial to report downstream performance metrics, as this information could provide valuable context regarding the relationship between linguistic abilities and task performance. Including a discussion on transfer learning effects, such as the impact of fine-tuning on one dataset followed by another, would enhance the paper's insights. Lastly, we suggest using heatmap-like representations for statistical significance in the tables to improve presentation clarity.