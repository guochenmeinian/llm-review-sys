ID: IoizwO1NLf
Title: Skill-it! A data-driven skills framework for understanding and training language models
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 7, 8, 7, 4, -1, -1, -1, -1
Original Confidences: 3, 5, 4, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to training language models (LMs) by introducing a curriculum of tokens based on the concept of "skills," which are behaviors acquired through training on specific data subsets. The authors propose ordered skill sets that enhance learning efficiency and demonstrate that following these skill orders leads to significant reductions in validation loss across various datasets and model sizes. The paper also introduces techniques for sampling data points from skills and evaluates the method's effectiveness through comprehensive experiments.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant problem in optimizing LLM training, presenting a new framework that diverges from traditional curriculum learning by focusing on skill selection.
- The methodology is built on a solid optimization objective, leading to a fast and simple closed-form sampling rule applicable in multiple scenarios.
- Clear writing and effective definitions enhance the paper's accessibility, with well-structured examples that clarify the skill curriculum concept.
- Experimental results show that the proposed method outperforms various baselines, achieving lower validation losses and demonstrating robustness in out-of-domain settings.

Weaknesses:
- The method heavily relies on the task dependency graph, and further discussion is needed on obtaining edge weights and the robustness of the approach against errors or noise in the graph.
- Clarity is lacking in defining skills and the metrics used for comparison, particularly regarding the goal of learning a subset of skills.
- The identification of skills through metadata is not sufficiently generalized, and alternative methods, such as entropy-based approaches, could be explored.
- The computational costs associated with learning the adjacency matrix and the introduction of new hyperparameters complicate the methodology without clear justification of their necessity.

### Suggestions for Improvement
We recommend that the authors improve the discussion on obtaining edge weights for the task dependency graph and address the robustness of their approach to errors in this graph. Additionally, clarifying the definition of skills and the metrics used for comparison in the introduction would enhance understanding. The authors should consider exploring more generalized methods for skill identification beyond metadata. Furthermore, a thorough evaluation of the computational costs and hyperparameters related to learning the adjacency matrix is essential, including a hyperparameter ablation study for Skill-It to demonstrate its stability. Lastly, we suggest benchmarking against stronger baselines from the curriculum learning field to better contextualize the proposed method's performance.