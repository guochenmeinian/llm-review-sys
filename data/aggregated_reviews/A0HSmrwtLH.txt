ID: A0HSmrwtLH
Title: Testing Semantic Importance via Betting
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 6, 6, 6, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 2, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for testing feature importance in model predictions, particularly focusing on human-interpretable features. The authors propose a hypothesis testing-based approach that does not rely on a dense features dictionary and retains the original predictor, unlike existing methods. The work aims to formalize statistical importance for both local and global semantic concepts, addressing a gap in current methodologies that typically focus on input features.

### Strengths and Weaknesses
Strengths:
- The work formalizes global, local, and global conditional importance, providing a flexible framework for stakeholders to specify concepts for evaluation.
- The proposed method guarantees false positive rates through statistical significance, avoiding reliance on surrogate linear models.
- The motivation for measuring statistical significance between different semantic concepts is well-articulated, addressing user concerns about interpreting importance scores.

Weaknesses:
- The method's explanation, particularly the equations, is difficult to understand, necessitating clearer writing and more detailed explanations in the methods section.
- The evaluation lacks convincing evidence; subjective claims about feature importance should be strengthened with human evaluation.
- The experiments are limited to CLIP, raising questions about the method's applicability across other vision-language models and tasks.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the methods section by providing more detailed explanations of the equations and their implications. Additionally, the authors should conduct evaluations on diverse tasks and datasets, such as AwA2 and CUB, and include results from various backbones to strengthen their claims. A user study to assess the interpretability of semantic concepts and interventions to measure changes in model predictions would further validate the proposed method's effectiveness.