ID: zW1uVN6Mbv
Title: Unpaired Multi-Domain Causal Representation Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 7, 6, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on unsupervised learning in multiple domains where only the marginal distribution of each domain is observed. The authors propose a model with latent variables, some of which are shared across domains, and provide the first identification results under the assumption of a linear structural causal model (SCM). They demonstrate that identifying the joint distribution of observations corresponds to identifying the latent variables, with the mapping between exogenous noises and observations identified up to signed block permutation. Additionally, they identify the causal graph for the latents under certain conditions. The authors validate their findings through synthetic data experiments.

### Strengths and Weaknesses
Strengths:  
- The paper provides the first identifiability results for multiple-domain unsupervised learning, addressing a well-studied problem with significant practical applications, particularly in single-cell biology.  
- The writing is rigorous, with precise explanations of definitions, assumptions, and results.  
- The theoretical analysis is clearly articulated, and the paper is well-motivated and timely, addressing the prevalent issue of unpaired data.

Weaknesses:  
- The authors do not sufficiently contextualize how their results extend existing identification results, lacking intuitive descriptions of the necessity for these extensions.  
- The notation used is inconsistent, with capital letters for various mathematical entities, which could hinder readability.  
- The assumptions underlying the identifiability result are numerous and may not reflect real-world scenarios, raising concerns about practical applicability.  
- The paper does not adequately discuss related works in causal discovery with latent variables, particularly those addressing nonlinear transformations.  
- The identification of joint distributions lacks clarity regarding the implications of identifying parameters like $l, B$, and $P$.  
- The simulation experiments are limited in scope, considering only three shared latent variables, and could benefit from exploring more complex structures.

### Suggestions for Improvement
We recommend that the authors improve the contextualization of their results by providing intuitive descriptions of how they extend existing identification results. Additionally, we suggest enhancing the notation for clarity, possibly by using font styles to differentiate between matrices, vectors, and other entities. The authors should also consider discussing related works in causal discovery more thoroughly, particularly those that address nonlinear scenarios. Clarifying the identification process of joint distributions and expanding the simulation experiments to include more latent variables and structures would strengthen the paper. Finally, employing additional evaluation metrics, such as recall and precision, would provide a more comprehensive assessment of the causal discovery performance.