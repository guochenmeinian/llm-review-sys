ID: FasIQqsJhe
Title: Towards In-context Scene Understanding
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 5, 7, 8, 6, 8, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a self-supervised approach, Hummingbird, designed to adapt models learned via self-supervised learning (SSL) to in-context learning through a nearest neighbor retrieval mechanism. The authors propose adding attention pooling to enhance feature attention and demonstrate that Hummingbird outperforms other SSL methods in segmentation and depth estimation through extensive empirical studies.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and presents a clear methodology.
2. The concept of in-context learning via retrieval is straightforward yet effective.
3. Empirical results show strong performance compared to baseline methods.

Weaknesses:
1. The paper does not clearly define the limitations of Hummingbird in adapting to new tasks, particularly regarding what can and cannot be achieved.
2. There is a discrepancy between training and testing phases, particularly in attention mechanisms.
3. The retrieval process may not yield smooth outputs for tasks beyond segmentation.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the limitations of Hummingbird, explicitly stating what tasks it can and cannot handle under the in-context learning framework. Additionally, addressing the discrepancy between training and testing phases could enhance the model's applicability. We also suggest including the ViT-B patch size in Tables 1 and 4 for completeness. Lastly, consider discussing the implications of the retrieval process on tasks like style transfer, as well as the potential scalability of Hummingbird to larger models.