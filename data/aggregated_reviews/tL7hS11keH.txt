ID: tL7hS11keH
Title: CoAnnotating: Uncertainty-Guided Work Allocation between Human and Large Language Models for Data Annotation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents CoAnnotating, a novel framework for human and large language model (LLM) collaboration in annotating unstructured text. The framework utilizes uncertainty metrics to guide effective work allocation between humans and LLMs, aiming for higher annotation quality and lower costs. The authors explore various work allocation strategies, including random allocation and entropy-guided allocation, and conduct experiments on six classification datasets, demonstrating the framework's effectiveness in achieving cost efficiency. The study also provides insights into the reliability of LLM confidence scores and their sensitivity to prompt variations, while acknowledging limitations and suggesting avenues for future research.

### Strengths and Weaknesses
Strengths:  
- The CoAnnotating framework addresses a significant gap in literature regarding LLMs as complementary annotators, proposing a compelling solution for balancing annotation quality, cost, and scalability.  
- Comprehensive experiments on diverse datasets validate the framework's effectiveness and robustness.  
- The paper is well-structured, with thorough analysis and valuable insights into human-LLM collaboration.

Weaknesses:  
- The motivation and problem statement lack clarity, requiring a more detailed background on manual annotation challenges.  
- The focus on cost reduction overshadows the equally important quality aspect of annotations, necessitating a more balanced discussion.  
- The rationale for selected work allocation strategies is insufficiently explained, and a detailed comparison of their performance is lacking.  
- Uncertainty computation methods need clearer explanations and effectiveness discussions.  
- Evaluation is limited to six classification datasets; broader task coverage is needed for generalizability.  
- Insufficient ablation studies hinder understanding of individual component contributions.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation and problem statement by providing a detailed background on manual annotation challenges and the benefits of LLMs as annotators. Additionally, a more balanced discussion of cost and quality aspects in the framework is essential. The authors should clarify the rationale behind the selected work allocation strategies and provide a comprehensive performance comparison. A more detailed explanation of the uncertainty computation methods and their effectiveness is necessary. To enhance generalizability, we suggest extending the evaluation to include other tasks, such as sequence tagging, and a wider range of datasets. Finally, we recommend conducting ablation studies to analyze the contributions of different framework components, including prompt designs and uncertainty computation methods.