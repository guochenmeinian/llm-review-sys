ID: gYNFgDd6rv
Title: Unified Model for Code-Switching Speech Recognition and Language Identification Based on Concatenated Tokenizer
Conference: EMNLP/2023/Workshop/CALCS
Year: 2023
Number of Reviews: 3
Original Ratings: 4, 3, 4
Original Confidences: 5, 3, 5

Aggregated Review:
### Key Points
This paper presents a methodology for developing ASR systems robust to code-switched inputs using only monolingual data. The authors propose generating artificial training data by acoustically combining samples from two monolingual corpora, which aids in training a bilingual ASR decoder. An innovative aspect is the independent training and merging of subword lexica for the two languages, simplifying language identification (LID) during decoding. The experiments involve two language pairs (en-es and en-hi) and demonstrate that the system performs comparably to monolingual ASR while being more robust with code-switched inputs. However, the paper lacks a comparison with a bilingual system's performance.

### Strengths and Weaknesses
Strengths:  
- The paper is well-written and presents a clear methodology for creating synthetic code-switched ASR data.  
- Empirical results are strong, and the experimental setup is well-executed.  
- The approach to merging subword lexica is innovative and beneficial for LID.

Weaknesses:  
- The methodology lacks illustrative examples, making it difficult to follow some concepts.  
- The paper does not provide a comparison of the bilingual system's performance.  
- The terminology used to describe the artificial corpus may not accurately reflect its linguistic characteristics.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by incorporating more examples to illustrate how to create code-switched data from monolingual sources, particularly how to apply the proposed rules in practical scenarios. Additionally, the authors should clarify the grammatical structure of the code-switched dataset and ensure it adheres to the linguistic traits of code-switching. Finally, we suggest including a comparison of the bilingual system's performance to strengthen the evaluation section and revising the terminology used to describe the artificial corpus to better reflect its nature.