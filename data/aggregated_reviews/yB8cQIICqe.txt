ID: yB8cQIICqe
Title: EZ-STANCE: A Large Dataset for Zero-Shot Stance Detection
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new dataset for zero-shot stance detection, named EZ-STANCE, which includes both noun-phrase and claim targets, and encompasses a wide range of domains. The authors provide a thorough description of the dataset's collection, filtering, and annotation processes, and compare EZ-STANCE with the existing VAST dataset to highlight its scale and challenges. Additionally, the authors propose transforming zero-shot stance detection (ZSSD) into a natural language inference (NLI) task and evaluate the performance of various language models.

### Strengths and Weaknesses
Strengths:
- The dataset is substantial, comprising 30,606 annotated text-target pairs, and presents significant research opportunities.
- The authors offer a detailed analysis of the dataset and introduce two challenging subtasks: target-based ZSSD and domain-based ZSSD.
- The experiments conducted demonstrate the dataset's complexity and the improvements over prior datasets.

Weaknesses:
- The paper lacks a comprehensive review of general stance detection scenarios and does not discuss other existing datasets.
- The comparison between transformer-based models and NLI pre-trained models lacks clarity regarding model sizes and parameters, making it an unfair comparison.
- The writing quality needs improvement, with unclear figure captions and insufficient insights in the discussion.
- The rationale for converting ZSSD into an NLI task is not adequately explained, leaving questions about the dataset's advantages over existing NLI datasets.

### Suggestions for Improvement
We recommend that the authors improve the literature review by including discussions of other stance detection datasets beyond ZSSD. Additionally, the authors should clarify the purpose of transforming ZSSD into an NLI task and articulate the benefits of using their dataset in this context. We suggest enhancing the clarity and conciseness of the writing, particularly in the data collection, filtering, and annotation sections. Furthermore, the authors should provide detailed explanations of model sizes and parameters in their comparisons, ensuring a fair evaluation. Lastly, we encourage the authors to address the typos and grammatical issues noted, such as in line 022 and Table 6, to enhance overall readability.