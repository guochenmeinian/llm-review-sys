ID: UYgE9IfQIV
Title: SustainDC: Benchmarking for Sustainable Data Center Control
Conference: NeurIPS
Year: 2024
Number of Reviews: 4
Original Ratings: 7, 6, 8, -1
Original Confidences: 4, 4, 4, -1

Aggregated Review:
### Key Points
This paper presents SustainDC, a Python-based platform for benchmarking multi-agent reinforcement learning (MARL) algorithms focused on sustainable data center optimization. Key contributions include the implementation of customizable multi-agent environments for workload scheduling, cooling optimization, and battery management, which integrate real-world factors such as weather conditions and grid carbon intensity. The framework is built on the Gymnasium Env class, facilitating easy implementation and comparison of various control strategies. The authors provide heterogeneous multi-agent baselines and conduct extensive evaluations, including ablation and reward shaping experiments, contributing to a better understanding of data center operations efficiency. The authors also emphasize the importance of collecting real-world evidence to enhance the simulation and propose that continuous reinforcement learning may improve the benchmark, although its effectiveness in solving long-term equipment challenges remains uncertain.

### Strengths and Weaknesses
Strengths:
- The environment is user-friendly with excellent code quality and documentation, facilitating installation, training, evaluation, and visualization.
- The rigorous methodology includes detailed modeling of data center operations and a commendable approximation of the cooling environment in Python.
- Extensive experimentation and benchmarking across various configurations and locations demonstrate a high degree of customization and flexibility.
- The open-source nature of SustainDC promotes reproducibility and collaboration within the research community.
- The authors show a proactive approach to addressing limitations and provide satisfactory responses to feedback.

Weaknesses:
- There is a lack of validation against established modeling tools such as EnergyPlus or Modelica, and limited real-world validation of the simulations against actual data center operations.
- Potential overfitting in baseline training to the provided carbon intensity data raises concerns, and the effectiveness of continuous reinforcement learning in resolving underlying equipment challenges is debatable.
- Figure 4, which benchmarks algorithms, is somewhat confusing and less informative.
- The absence of comparative baselines with traditional non-ML control strategies limits the quantification of improvements offered by MARL approaches.
- Some sections may be technically complex for readers without a strong background in reinforcement learning and data center operations.

### Suggestions for Improvement
We recommend that the authors improve the validation of the newly implemented data center cooling model against modeling results from EnergyPlus or Modelica, as well as provide validation against real-world data center operations. Additionally, incorporating a composite score that accounts for electricity, water, carbon emissions, and task penalties would enhance the quantification and comparison of policies. Including baseline metrics from random and rule-based controllers would establish a "lower bound" for performance comparisons. Clarification on whether carbon intensity data was used as an observation for training baselines is necessary, as this could lead to overfitting. Developing data-driven simulators for carbon intensity, workload, and weather based on historical patterns would help train more robust policies and allow evaluation with actual historical data.

Furthermore, we recommend that the authors explore the long-term stability and performance of their proposed solutions and consider discussing potential privacy concerns related to operational data. A dedicated "Limitations and Future Work" section would enhance the paper's comprehensiveness, and addressing the potential for job displacement due to automation would strengthen the discussion on ethical implications. Finally, providing clearer explanations of mathematical models and including a flowchart to visualize system interactions would improve clarity.