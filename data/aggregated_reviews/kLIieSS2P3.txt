ID: kLIieSS2P3
Title: On the choice of Perception Loss Function for Learned Video Compression
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 4, 6, 5, 7, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the choice of perceptual loss functions (PLF-JD and PLF-FMD) for learned video compression, emphasizing their implications on distortion-perception optimization. The authors propose that the choice of perceptual loss significantly affects decoded reconstructions, particularly at low bit rates. The paper also explores the rated-distortion-perception tradeoff, providing theoretical insights and experimental validation, albeit on simpler datasets.

### Strengths and Weaknesses
Strengths:  
- The paper conducts thorough experiments and theoretical analyses, yielding valuable insights into the generative video compression field.  
- It presents original contributions to the understanding of the rated-distortion-perception tradeoff in video compression, with clear conclusions regarding the performance of PLF-JD and PLF-FMD.  
- The findings provide a solid guideline for optimizing learned video compression methods.

Weaknesses:  
- The datasets utilized are overly simplistic, raising concerns about the generalizability of the conclusions to more complex, real-world scenarios.  
- The experimental setup lacks diversity, as it primarily focuses on toy datasets like MNIST and KTH, which do not adequately represent video characteristics.  
- The paper does not explore perceptual quality metrics, such as LPIPS, which could enhance the evaluation of perceptual loss functions.  
- There are questions regarding the method's ability to control bit rates across different methods consistently.

### Suggestions for Improvement
We recommend that the authors improve the experimental setup by incorporating more complex datasets, such as UVG, MCL-JCV, and HEVC Class B, to validate their findings in practical applications. Additionally, we suggest that the authors explore widely used perceptual metrics, such as LPIPS, to provide a more comprehensive evaluation of the perceptual quality of their proposed methods. Furthermore, clarifying how the proposed method controls bit rates to ensure consistency across different methods would strengthen the paper's contributions.