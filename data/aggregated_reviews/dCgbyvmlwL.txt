ID: dCgbyvmlwL
Title: UDC: A Unified Neural Divide-and-Conquer Framework for Large-Scale Combinatorial Optimization Problems
Conference: NeurIPS
Year: 2024
Number of Reviews: 18
Original Ratings: 7, 5, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Unified Neural Divide-and-Conquer (UDC) framework aimed at solving large-scale combinatorial optimization (CO) problems through a novel Divide-Conquer-Reunion (DCR) training methodology. UDC introduces this method to enhance training by mitigating the negative effects of sub-optimal dividing policies. The framework employs graph neural networks for problem division and utilizes established constructive solvers for sub-problem resolution, demonstrating significant improvements in effectiveness and scalability compared to existing methods. The authors have conducted extensive experiments validating UDC's applicability across ten different CO problems, showcasing its versatility and effectiveness. Generalization experiments on the maximum independent set (MIS) problem have been performed, with plans to expand these tests to additional CO problems.

### Strengths and Weaknesses
Strengths:
1. The UDC framework integrates a novel training methodology that effectively addresses sub-optimal divide policies, improving overall solution quality.
2. The effectiveness and broad applicability of UDC were appreciated by all reviewers, with extensive experiments validating its performance across ten different CO problems.
3. The novel DCR method is recognized for addressing the challenge of sub-optimal divide policies.
4. The paper is well-structured and easy to follow, with detailed explanations regarding hyperparameters and experimental settings.

Weaknesses:
1. The novelty of the UDC framework requires further clarification, as it appears to combine existing techniques rather than introduce a fundamentally new approach.
2. The training procedure lacks clarity, particularly regarding gradient updates and the implementation of the REINFORCE algorithm.
3. UDC's solving time is relatively longer than several compared neural methods, raising questions about its efficiency and practicality.
4. The authors currently cannot compare UDC's generalization ability with learning-based algorithms due to issues with the provided code.
5. There is a need for further validation of UDC's capabilities and limitations through additional out-of-domain generalization experiments beyond TSP and CVRP.
6. The framework's generalization to a wider range of CO problems is uncertain, as most evaluated problems share similar formulations.
7. The paper lacks detailed discussions on graph sparsification, constraint handling, and the definitions of large-scale instances.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the novelty of the UDC framework by explicitly distinguishing it from existing techniques. Additionally, the authors should provide a more detailed explanation of the training procedure, particularly regarding gradient updates and the REINFORCE algorithm implementation. To address efficiency concerns, further experiments should be conducted to illustrate the relationship between solving quality, the number of conquering stages, and solving time. We also suggest that the authors resolve the code execution issues to enable comparisons of UDC with learning-based algorithms and include these baselines in future manuscripts. Furthermore, conducting generalization tests on a broader range of CO problems would help validate the capabilities and limitations of UDC. Finally, the paper should include clearer discussions on graph sparsification, constraint handling, and a formal definition of large-scale instances to enhance understanding.