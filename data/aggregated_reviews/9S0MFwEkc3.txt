ID: 9S0MFwEkc3
Title: Rethinking the Construction of Effective Metrics for Understanding the Mechanisms of Pretrained Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel self-supervised tree-topological probe aimed at interpreting the hierarchical structure learned by BERT. The authors propose this method to enhance the interpretability of pre-trained language models and improve fine-tuning performance. They provide theoretical justifications for their approach and conduct experiments primarily on BERT-large, yielding findings that suggest their probe can identify submodules needing enhancement.

### Strengths and Weaknesses
Strengths:
- The paper offers a significant theoretical contribution to the interpretability community by proposing a self-supervised probe that can assess model capabilities.
- The findings reveal insights that extend beyond existing structural probes, potentially guiding future probing methods.
- The authors validate their approach through fine-tuning experiments, demonstrating its utility in identifying and enhancing submodules.

Weaknesses:
- The empirical evidence is limited, as experiments are primarily conducted on a single model (BERT-large), lacking comparisons with other models.
- The writing is often unclear and difficult to follow, lacking a cohesive narrative that connects the motivation and findings.
- The paper does not adequately address statistical significance in its results, making claims less convincing.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing by establishing a stronger narrative structure throughout the paper. This includes articulating the importance of studying the proposed phenomena and how it benefits the broader community. Additionally, we suggest conducting further experiments on multiple models to strengthen empirical evidence and performing perturbation or sensitivity analyses to assess the robustness of the results. It would also be beneficial to include a more engaging ethics statement that connects with the presented theories and experiments. Finally, we encourage the authors to clarify technical terms and definitions, particularly in sections discussing metrics and findings, to enhance reader comprehension.