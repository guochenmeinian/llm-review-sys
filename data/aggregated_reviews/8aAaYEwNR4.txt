ID: 8aAaYEwNR4
Title: EAI: Emotional Decision-Making of LLMs in Strategic Games and Ethical Dilemmas
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 5, 4, 6, 9, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the EAI framework to evaluate the impact of emotions on large language models (LLMs) in ethical dilemmas and strategic games. The authors conduct extensive experiments with various LLMs, revealing that emotional prompts significantly influence decision-making, with negative emotions decreasing ethical behavior and cooperation, while positive emotions enhance them. The study also highlights the variability in responses to emotional prompts across different models and languages.

### Strengths and Weaknesses
Strengths:  
- The study conducts broad experiments demonstrating the effects of emotions on LLM decision-making.
- The EAI framework is well-explained and grounded in emotion literature.
- The analysis of emotional responses across languages is an interesting contribution.
- Empirical results provide a comprehensive examination of emotional influences on LLMs.

Weaknesses:  
- The paper lacks an in-depth analysis of how performance differences among LLM models arise from emotional prompts.
- There is insufficient explanation for the negative impact of emotions like 'anger' and 'disgust' on LLMs.
- The authors do not provide experiments to support claims regarding human data as the basis for LLM models.
- The novelty of the findings is questioned, as similar effects have been reported in prior studies.

### Suggestions for Improvement
We recommend that the authors improve the analysis of how different emotional prompts affect LLM performance, including a comparison of prompting strategies. Additionally, the authors should provide clearer explanations for the negative effects of certain emotions and include experiments that support the claim regarding human data. A more qualitative analysis of the reasoning provided by LLMs in response to emotional prompts would enhance the paper's depth. Finally, we suggest proposing solutions for mitigating emotional bias in LLM models to address ethical concerns.