ID: Q5nM3rpiVm
Title: Towards Better Representations for Multi-Label Text Classification with Multi-granularity Information
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a multi-label classification approach utilizing contrastive learning, dual-graded interactive learning, and constraint label relations learning to enhance performance by addressing label frequency and correlation. The authors report strong Hamming loss and F1 scores, indicating mitigation of the word/label bias issue. However, the F1 score improvement primarily results from balancing precision and recall, raising doubts about the method's competitiveness against existing techniques. The methodology includes fine-tuning a BERT classifier and employing multiple loss functions to improve text-label correlations, but lacks clarity in certain model decisions and hyperparameter optimization.

### Strengths and Weaknesses
Strengths:
- The proposed method appears effective, supported by ablation tests and hyperparameter analysis.
- The paper reports notable improvements in classification performance on standard datasets.
- The idea of enhancing text representations through multi-granularity information is interesting.

Weaknesses:
- The writing quality is poor, making it challenging to understand the proposed approach.
- There is insufficient detail in the methodology, particularly regarding the definitions of label frequency categories and transitions between equations.
- The competitive advantage of the proposed method is questionable, as existing methods may achieve similar F1 score improvements through precision/recall balancing.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing and provide more detailed explanations of the methodology, particularly regarding the definitions of label frequency categories (head-group, mid-group, tail-group) and transitions between equations. Additionally, we suggest that the authors address the potential concerns regarding the competitive advantage of their method by providing evaluation results when either the contrastive learning objective or the Constraint Label Relations Learning objective is omitted. Furthermore, we advise a careful proofreading of the manuscript to correct typos and improve overall presentation.