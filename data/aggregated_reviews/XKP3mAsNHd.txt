ID: XKP3mAsNHd
Title: Incentives in Private Collaborative Machine Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 7, 7, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 1, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on collaborative machine learning under differential privacy (DP), focusing on the incentives for multiple parties to share private sufficient statistics with a central aggregator. The authors argue that parties with less strict privacy guarantees should receive greater rewards, proposing a method that learns a posterior distribution from shared statistics and releases tempered samples to clients. The tempering level, determined by Bayesian surprise (measured via KL divergence), influences the accuracy of the samples provided. Empirical results demonstrate that the proposed reward mechanism outperforms existing methods, particularly when rewards are low. Additionally, the authors provide a detailed examination of the theoretical justifications for their results, particularly in relation to the work of Sim et al. (2020), and propose modifications to P2, P5, and P6 to clarify their implications when a grand coalition is not formed. They emphasize that maximizing total similarity is not a common objective in algorithmic game theory and acknowledge the need to ensure that this preference does not adversely affect group welfare.

### Strengths and Weaknesses
Strengths:  
The paper addresses a significant real-world issue of collaboration among data holders while ensuring privacy, proposing a reasonable incentive structure that rewards less perturbed data. The theoretical foundation, particularly the use of KL divergence as a valuation function, is novel. Empirical evaluations across various models support the incentive structure, showing that collaboration benefits parties as privacy guarantees loosen. Furthermore, the authors provide a thorough discussion on the theoretical foundations and implications of their results, and the proposed revisions to P2, P5, and P6 enhance clarity regarding the performance of coalitions when a grand coalition is not formed.

Weaknesses:  
The method relies on a strong trust model, assuming honest contributions from parties, which raises concerns about the potential for submitting misleading data to inflate rewards. While the authors acknowledge this limitation, further discussion in the main paper is encouraged. Additionally, the paper's structure may confuse readers, as it presents a bottom-up approach without clear pseudocode or a top-down overview of the overall scheme. The objective of maximizing total similarity lacks precedent in existing literature, raising concerns about its impact on group welfare, and the assumptions made in the paper may disadvantage smaller coalitions when a grand coalition does not form.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper's structure by providing a top-down overview or pseudocode that explicitly outlines the computation steps and sampling processes. Additionally, the authors should extend the discussion of trust assumptions and potential data manipulation in the main text. Clarifying the individual rationality definition in Section P4 is also necessary, as it currently appears incorrect. We encourage the authors to improve the clarity of the implications of P2, P5, and P6 when a grand coalition is not formed, ensuring that the modifications are clearly articulated in the main text. Furthermore, we suggest including a brief description of the choice of P4 in the main paper, accompanied by a simple example, rather than relegating it to the appendix, to enhance the accessibility and comprehensibility of the work. Finally, a more detailed mathematical justification for the proposed method and its applicability beyond Bayesian linear regression would strengthen the paper's contributions.