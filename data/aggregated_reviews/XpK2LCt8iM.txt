ID: XpK2LCt8iM
Title: Turn-Level Active Learning for Dialogue State Tracking
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel turn-level active learning framework for Dialogue State Tracking (DST) aimed at reducing human annotation costs. The authors propose a turn-level selection strategy based on active learning, which significantly enhances DST performance while minimizing annotation requirements. The approach is particularly innovative as it focuses on turn-level annotation, a topic that has been underexplored in the literature. The results demonstrate that the proposed method can achieve performance comparable to traditional training methods with considerably less annotated data.

### Strengths and Weaknesses
Strengths:
- The integration of active learning with turn-level annotation is a novel and rarely explored idea in the literature.
- Experimental results indicate that the proposed approach outperforms previous dialogue-level methods, with Maximum Entropy showing a ~40% reduction in Reading Cost while improving performance.
- The writing is fluent, clear, and the presentation is well-structured, making the paper easy to follow.
- Comprehensive analyses, including ablation studies and hyperparameter evaluations, provide valuable insights into the effectiveness of the proposed method.

Weaknesses:
- The paper lacks a discussion on recent advancements in DST, particularly regarding the Schema-guided DST dataset, which could enhance the generalizability of the approach.
- Practical implementation details of how to combine annotators with the on-the-fly training process remain unclear.
- The evaluation is limited to two similar datasets (v2.0 and v2.1), suggesting the need for a broader dataset comparison.
- There is no comparison of the computational costs associated with the proposed approach versus previous methods.

### Suggestions for Improvement
We recommend that the authors improve the discussion on recent progress in DST, particularly addressing the challenges posed by the Schema-guided DST dataset. Additionally, it would be beneficial to clarify the practical steps required for integrating annotators with the training process. We suggest including a comparison of the computational costs between the proposed turn-level approach and the previous dialogue-level approach. Finally, we encourage the authors to evaluate their method on a third, distinct dataset to strengthen their findings.