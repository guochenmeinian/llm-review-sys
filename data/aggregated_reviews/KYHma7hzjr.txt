ID: KYHma7hzjr
Title: Beyond Concept Bottleneck Models: How to Make Black Boxes Intervenable?
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 7, 7, 7, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for concept-based interventions on pretrained black-box neural networks, utilizing a small validation set with concept labels. The authors formalize the concept of intervenability to measure the effectiveness of these interventions and evaluate their approach across various benchmarks and architectures. The method involves training a concept probe on the model's latent space to modify representations and fine-tuning the model to enhance its susceptibility to concept interventions.

### Strengths and Weaknesses
Strengths:
- **Originality:** The approach creatively applies existing methods for novel concept-based interventions, yielding both methodological and experimental originality.
- **Quality:** The research methods are well-described, and the results are supported by data, making the approach mathematically elegant and accessible for further research.
- **Clarity:** The paper is well-structured, with clear writing and effective figures and tables that support the text.
- **Significance:** The findings demonstrate the potential for significant real-world applications, particularly in scenarios with limited concept-annotated data.

Weaknesses:
- **Clarity / Quality:** The training and validation procedure for the baseline "CBM val" is inadequately detailed, hindering the assessment of the proposed method's quality and impact.
- **Presentation:** Some passages lack clarity, and certain claims regarding results need to be softened or clarified. The presentation of Equation 4 is misleading as it neglects important terms.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the training and validation procedure for the "CBM val" baseline, detailing how it is constructed and validated. Additionally, we suggest providing a formal justification for the computational feasibility of the proposed approach rather than relying on informal statements. 

To enhance readability, consider moving technical details to a preliminary section and rephrasing complex sentences for clarity. We advise reorganizing the results section by key findings to avoid repetition and improving the clarity of figures and equations by providing context before presenting them.

Furthermore, we recommend addressing the claims made in the discussion and ensuring that all statements about results are supported by the data presented. Lastly, consider discussing the implications of the method's limitations and potential societal impacts more thoroughly.