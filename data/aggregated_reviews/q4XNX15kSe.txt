ID: q4XNX15kSe
Title: rPPG-Toolbox: Deep Remote PPG Toolbox
Conference: NeurIPS
Year: 2023
Number of Reviews: 22
Original Ratings: 8, 8, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the rPPG-Toolbox, an integrated framework designed for training and testing in remote photoplethysmography (rPPG) research. The toolbox supports multiple models and datasets, providing experimental results that facilitate reproducibility within the community. It includes pre-processing, supervised and unsupervised machine learning methods, and post-processing tools, enhancing the evaluation and comparison of rPPG methods. The authors argue that their toolbox is the first to benchmark existing rPPG datasets using both modern neural and traditional unsupervised methods, supporting five evaluation metrics and offering visualization tools. Additionally, the toolbox incorporates the PhysFormer model and addresses various concerns regarding the implementation of existing models, such as PhysNet.

### Strengths and Weaknesses
**Strengths:**
1. The rPPG-Toolbox is comprehensive, covering pre-processing, model implementations, and evaluation tools, empowering researchers to build upon existing work.
2. It offers a robust evaluation pipeline with comprehensive benchmarking across multiple datasets and supports various metrics for performance evaluation.
3. The toolbox's open-source nature and detailed documentation promote reproducibility and accessibility for the research community.
4. The authors have responded to reviewer feedback by adding new features and clarifying existing functionalities, such as subject-independent cross-validation and model input visualization.

**Weaknesses:**
1. The toolbox lacks visualization tools for BVP signals, limiting the analysis of model outputs in relation to video segments.
2. It does not support common pre-training techniques like contrastive learning, which restricts its applicability.
3. The implementation of face detection relies on a simple Haar cascade detector, which may introduce instability in detection boxes.
4. The paper assumes prior knowledge of rPPG, making it less accessible to newcomers in the field.
5. Some reviewers noted that the contributions may be perceived as minor due to the replication of existing models and methods.
6. The lack of a unified normalization method for BVP signals leads to inconsistencies across models, particularly in hyperparameter fine-tuning for PhysNet.

### Suggestions for Improvement
We recommend that the authors improve the toolbox by providing a visualization tool for BVP signals to facilitate better analysis of model outputs. Additionally, incorporating HRV-related tools would enhance its utility, as HRV is crucial in many applications. We suggest expanding the toolbox to include support for new algorithms and common pre-training techniques, thereby broadening its applicability. Furthermore, we advise the authors to reproduce and benchmark the latest models, such as PhysFormer, to ensure the toolbox remains relevant. We also recommend revising the evaluation metrics presented in benchmark tests to include more representative metrics like MAPE+RMSE and to consider using a wider band-pass filter range to accommodate real-world heart rate variations. To enhance accessibility, we suggest that the authors provide a more detailed background on rPPG and its challenges in the main text. Finally, we recommend improving the diversity of the developed methods in the toolbox to mitigate bias towards the authors' previous works and implementing a unified normalization method for BVP signals to ensure consistency across different models.