ID: BpibUh0aB3
Title: Probing the “Creativity” of Large Language Models:  Can models produce divergent semantic association?
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates the creativity of Language Models (LMs) through the Divergent Association Task (DAT), which measures the generation of semantically unrelated nouns. The authors analyze various LLMs, including GPT-4, and demonstrate that larger models perform better on the DAT, with a positive correlation between DAT scores and model surprisal. The study also examines the effects of decoding strategies and temperature on creativity assessment.

### Strengths and Weaknesses
Strengths:
- The paper provides a focused analysis of creativity in LLMs and explores various factors influencing creativity, such as surprisal and temperature.
- It proposes a computationally efficient method for assessing creativity in LLMs, building on human creativity assessment findings.

Weaknesses:
- The assumptions regarding the transfer of human creativity findings to LLMs are inadequately addressed, particularly the validation of the DAT for LLMs.
- The reliance on cosine similarity for measuring semantic divergence is critiqued for its one-dimensional nature and potential to misrepresent semantic relationships.
- The study's focus on single nouns lacks justification, particularly regarding the omission of multi-word combinations that are crucial for assessing creativity in language.

### Suggestions for Improvement
We recommend that the authors improve the validation of the DAT for LLMs by demonstrating that these models replicate human biases in generating free associations. Additionally, addressing the limitations of using cosine similarity and GLoVe embeddings for semantic distance measurement is essential. The authors should consider incorporating multi-word combinations in their analysis and provide a clearer rationale for their methodological choices. Finally, a thorough revision of the paper's writing and structure is necessary to enhance clarity and coherence.