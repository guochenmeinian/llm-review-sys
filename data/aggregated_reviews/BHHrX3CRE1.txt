ID: BHHrX3CRE1
Title: Regularity as Intrinsic Reward for Free Play
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 5, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel exploration approach called RaIR, which utilizes regularity as an intrinsic reward to guide reinforcement learning (RL) agents towards structured patterns in their environment. The authors define regularity and investigate its implementation alongside disagreement-based intrinsic rewards. They argue that RaIR encourages the discovery of regular patterns, such as stacking, even without novelty-seeking rewards, and maximizes redundancy in state descriptions, leading to improved performance on downstream tasks. The method is evaluated through experiments demonstrating its effectiveness in generating structured behaviors, including free play experiments in the Generalized Construction and Quadruped environments, and showing significant performance improvements on assembly tasks and Roboyoga poses. The authors also address philosophical concerns regarding the assumption of access to a test-time dense reward and the limitations of object-centric representations in diverse environments, providing comprehensive results for two new intrinsic motivation baselines, RND and Disagreement, while clarifying distinctions from existing literature.

### Strengths and Weaknesses
Strengths:
- The formulation of using regularity as an intrinsic reward is intuitive and well-motivated.
- The writing is clear, aiding in the understanding of the proposed method.
- Comprehensive experiments support the claims, showcasing the benefits of the proposed reward in both ground-truth and learned models.
- The authors effectively clarify previous concerns regarding RaIR and its application in various environments.
- The experimental results demonstrate significant performance improvements with RaIR+CEE-US compared to pure ensemble disagreement.
- Clear differentiation from existing methods, particularly SMiRL, enhances the paper's contribution.
- The revisions to the object-centric representation discussion add depth to the limitations section.

Weaknesses:
- The experiments section lacks clarity, particularly regarding the metrics used, which could benefit from more detailed explanations.
- The method's reliance on ground-truth internal states poses practical limitations, as such information may not be accessible in real-world scenarios.
- There is a limitation in assuming access to a test-time reward function, which may not align with fully unsupervised exploration paradigms.
- Balancing chaotic exploration from novelty-seeking rewards with regularity-seeking rewards remains challenging, and the authors do not provide a solution for this.
- The object-centric representation may not generalize well to tasks where the notion of "object" is ambiguous, potentially limiting the applicability of RaIR.
- RND shows very poor performance on assembly tasks, and Disagreement fails completely, indicating potential limitations in these approaches.
- The challenge of selecting the appropriate level of abstraction for entities in complex scenarios remains inadequately addressed.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the experiments section by providing more detailed descriptions of the metrics used. Additionally, addressing the limitations of relying on ground-truth states is crucial; exploring how the method could function without such information would enhance its applicability. We suggest investigating methods to automatically balance chaotic and regularity-seeking rewards to improve exploration efficiency. Furthermore, we recommend that the authors improve the performance of RND and Disagreement in assembly tasks, as their current results are unsatisfactory. We also suggest that the authors provide more comprehensive experimental results in new environments, including videos and detailed analyses, to better showcase the generality of RaIR as an exploration method. Lastly, including a discussion on the limitations of object-centric representations and elaborating on the challenges of selecting the right level of abstraction for entities would strengthen the paper.