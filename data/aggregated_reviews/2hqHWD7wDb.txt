ID: 2hqHWD7wDb
Title: Quantitative Convergences of Lie Group Momentum Optimizers
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 5, 7, 1, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 5, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a design and analysis of momentum-based algorithms on Lie groups, focusing on the convergence rates of ordinary differential equations (ODEs) and their discretizations, specifically Lie Heavy Ball and Lie NAG-SC. The authors demonstrate that the Lie NAG-SC achieves a locally accelerated convergence rate. The work extends optimization techniques from Euclidean spaces to Lie groups, providing a quantitative analysis of momentum optimizers and addressing the computational costs associated with traditional methods. Additionally, the paper explores advanced optimization techniques in the context of neural networks, integrating concepts from Riemannian geometry to enhance optimization efficiency and robustness in deep learning architectures.

### Strengths and Weaknesses
Strengths:
- The authors effectively apply optimization theories from general manifolds to Lie groups, yielding more analytical and tractable formulas.
- Insightful constructions of discrete energy and Lyapunov functions enhance understanding of the dynamics involved.
- The integration of momentum-based optimization with Riemannian geometry is innovative and adds significant value to the field.
- The paper provides a significant first quantitative analysis of Lie group momentum optimizers, which is important given the lack of nontrivial convex functions on many Lie groups.
- The references cited are relevant and demonstrate a thorough engagement with current literature, showcasing the authors' depth of research.

Weaknesses:
- The requirement for the manifold to be a Lie group is overly restrictive, limiting applicability to other useful manifolds like Stiefel manifolds.
- The paper lacks citations of key prior works, particularly those addressing global acceleration on Riemannian manifolds.
- The focus on local acceleration may diminish the paper's interest, as local behavior often resembles Euclidean optimization.
- The paper lacks clarity in some sections, making it difficult for readers to fully grasp the proposed methodologies.
- Certain technical details are underexplained, which may hinder reproducibility and practical application of the methods discussed.
- Limited experimental validation and comparisons with existing methods reduce the robustness of the findings.

### Suggestions for Improvement
We recommend that the authors improve the breadth of their literature review by including significant prior works, such as those by Kim and Yang (2022) and Martinez-Rubio, which provide global acceleration rates. Additionally, the authors should clarify the implications of using Lie groups versus other manifolds, particularly in practical applications. We suggest improving the clarity of their explanations, especially in the sections detailing the proposed methodologies, and providing more comprehensive technical details to enhance reproducibility and facilitate practical application of the optimization techniques discussed. Furthermore, expanding the experimental section to include comparisons with results from existing literature, particularly those that demonstrate the performance of similar algorithms, would strengthen the findings. Addressing the impact of the parameter p(a) on convergence rates and providing a more detailed discussion on the necessity of using the exponential map as the retraction would enhance the paper's clarity and depth. Lastly, correcting the typo in line 277 and providing more intuitive explanations for curvature in the context of Lie groups would improve the overall presentation.