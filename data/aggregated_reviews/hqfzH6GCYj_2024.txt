ID: hqfzH6GCYj
Title: What Representational Similarity Measures Imply about Decodable Information
Conference: NeurIPS
Year: 2024
Number of Reviews: 4
Original Ratings: 7, 6, 8, 9
Original Confidences: 4, 4, 3, 4

Aggregated Review:
### Key Points
This paper presents a framework that unifies various representational similarity measures, such as Centered Kernel Alignment (CKA), Canonical Correlation Analysis (CCA), and Procrustes Shape Distance, through the lens of linear decodability. The authors argue that representation geometry serves as a proxy for model-implemented functions, formalizing connections between representational similarity and the ability to linearly decode information across tasks. The framework is built on the Linear Representation Hypothesis, allowing the authors to define "most decodable" and "least decodable" functions.

### Strengths and Weaknesses
Strengths:
- The proposed framework is well-motivated, establishing meaningful connections between representation geometry and expressivity.
- The theoretical foundations are solid, with detailed mathematical proofs and derivations of bounds for similarity measures.

Weaknesses:
- The assumption that the distribution of decoding targets satisfies $E[zz^{\top}]=I$ may not hold in practical scenarios.
- The framework is heavily focused on linear decoders, lacking empirical validation of its effectiveness on actual neural networks or datasets.
- The presentation is difficult to navigate, making it hard to quickly grasp the main findings.

### Suggestions for Improvement
We recommend that the authors improve the paper's readability by including a summary table or figure that outlines the correspondences between different measures. Additionally, we suggest restructuring the presentation to focus on results and intuition, with proofs either moved to the Appendix or isolated in "skippable" sections. Finally, we encourage the authors to discuss the potential practical implications of their framework, as this aspect is currently missing. Empirical validation of the framework's assumptions and its application to measure similarities across models would also strengthen the paper's impact.