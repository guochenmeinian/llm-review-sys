ID: njvPjG0BfK
Title: HardCore Generation: Generating Hard UNSAT Problems for Data Augmentation
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 7, 4, 6, 7, -1, -1, -1, -1
Original Confidences: 5, 5, 5, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method called HardCore for synthesizing hard UNSAT formulas from existing distributions. The approach involves extracting a core from a seed instance, adding random clauses, and refining the formula using a Graph Neural Network (GNN) to predict and relax the UNSAT core. The method demonstrates improved generation speed and hardness preservation compared to existing techniques, particularly on LEC Internal and random K-SAT distributions.

### Strengths and Weaknesses
Strengths:  
- The method effectively balances the hardness of generated instances with generation speed, outperforming W2SAT and HardSATGEN.  
- The iterative core refinement and GNN-based core prediction are innovative and elegantly combined.  
- The similarity in solver performance on synthetic instances compared to original instances indicates effective generation.

Weaknesses:  
- The core refinement technique appears to be a post-processing step applicable to any initial formulas, raising questions about its novelty.  
- The method is limited to smaller formulas and lacks generalizability across diverse datasets.  
- The paper does not adequately address the correlation between hardness and core size, nor does it provide sufficient details on model training and dataset construction.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the core refinement process, particularly regarding the addition of literals versus clauses. Additionally, we suggest that the authors explore the generalization of their core predictor to other datasets and provide empirical evidence of its scalability. It would be beneficial to include a deeper analysis of the structural properties of generated instances and to justify the simplicity of the core refinement strategy. Finally, we encourage the authors to consider testing their method on a wider variety of datasets, such as SAT competition benchmarks, to demonstrate its robustness.