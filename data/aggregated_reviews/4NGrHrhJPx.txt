ID: 4NGrHrhJPx
Title: The Dormant Neuron Phenomenon in Multi-Agent Reinforcement Learning Value Factorization
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 6, 5, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ReBorn, a method designed to reactivate dormant neurons within the mixing network of multi-agent reinforcement learning (MARL) algorithms. ReBorn operates by transferring weights from overweight neurons to dormant neurons, ensuring that learned action preferences remain unchanged post-operation. The authors demonstrate the effectiveness of ReBorn through experiments on various environments, including SMAC and predator-prey scenarios, showing superior performance compared to existing baselines like ReDo and Reset.

### Strengths and Weaknesses
Strengths:
1. The idea of addressing dormant neurons is novel, with a well-explained motivation.
2. Experimental results across different scenarios indicate that ReBorn enhances the performance of various baselines.
3. The authors provide a theoretical proof that ReBorn does not alter learned action preferences.

Weaknesses:
1. The ReBorn operation is potentially time-consuming, particularly for large networks, raising feasibility concerns.
2. Validation of ReBorn is limited to multi-agent value-mixing algorithms, leaving its applicability to other MARL algorithms untested.
3. The motivation for scaling weights in ReBorn lacks clarity, and the authors do not address a relevant baseline that could also mitigate plasticity loss.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation behind the weight scaling approach in ReBorn. Additionally, consider comparing the running time of the baselines with their ReBorn variants to assess efficiency. It would also be beneficial to explore the applicability of ReBorn to other MARL algorithms, such as MAPPO and MADDPG. Finally, we suggest including results for the new baselines at varying replay ratios in the final revision to provide a fair comparison.