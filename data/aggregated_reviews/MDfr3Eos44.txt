ID: MDfr3Eos44
Title: MoQ: Mixture-of-format Activation Quantization for Communication-efficient AI Inference System
Conference: NeurIPS
Year: 2024
Number of Reviews: 2
Original Ratings: 7, 7
Original Confidences: 5, 3

Aggregated Review:
### Key Points
This paper presents a novel approach to quantization in low-precision deep neural networks (DNNs) by combining recent advancements in data formats and outlier clipping methods. The authors propose a mixture of formats rather than a simple mixture of precision, supported by insightful analyses in Sections 3.2 and 4.2. The work targets communication-constrained edge systems, demonstrating practical deployment potential through a lightweight calibration method that does not require backpropagation. However, the significance of improvements using the proposed method, termed MoQ, compared to static formats remains unclear.

### Strengths and Weaknesses
Strengths:
- Novelty in proposing a mixture of formats for quantization.
- Insightful analysis of format strengths and correlations between loss and accuracy.
- Targets a relevant application scenario with practical deployment considerations.

Weaknesses:
- Uncertainty regarding the significance of improvements with MoQ versus static formats, particularly due to reliance on the OHR metric.
- Lack of clarity on why MoQ sometimes yields lower OHR than static formats, raising questions about the correlation between MSE and accuracy.
- Insufficient detail on the calibration method and its relationship to weight errors, along with the absence of a public codebase.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the significance of MoQ by providing direct comparisons of accuracy on evaluation datasets, such as ImageNet, against static formats. Additionally, addressing the discrepancies noted in Table 1 regarding MoQ's performance compared to static formats would strengthen the argument for its effectiveness. Finally, enhancing the details of the calibration method and its implications for weight errors would provide a more comprehensive understanding of the approach.