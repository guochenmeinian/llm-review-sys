ID: 6DKS4tb387
Title: Gradually Excavating External Knowledge for Implicit Complex Question Answering
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a gradual knowledge excavation framework called GEEK for open-domain complex question answering, where LLMs iteratively acquire extrinsic information and reason based on historical knowledge. GEEK comprises three modules: a core model for logical reasoning and action selection, a retriever for sourcing relevant context from external corpora, and an extractor for condensing information into concise fact sentences. Experimental results on the StrategyQA benchmark demonstrate that GEEK surpasses vanilla LLMs like ChatGPT while using 94% fewer parameters, achieving a new state-of-the-art accuracy of 78.17%.

### Strengths and Weaknesses
Strengths:
- The paper proposes a well-structured pipeline model that effectively decomposes complex problems and iteratively retrieves knowledge.
- It utilizes a rigorous reasoning process, employing established retrieval algorithms and answer extractors to mitigate LLM hallucination.
- The model achieves state-of-the-art performance with a significantly smaller parameter size.

Weaknesses:
- Experiments are limited to the StrategyQA dataset, hindering broader applicability and validation of the model's effectiveness.
- There is a lack of necessary error analysis and detailed descriptions of the core model's fine-tuning process.
- The use of GPT-4 for data re-annotation raises concerns about fairness in comparison with other models.

### Suggestions for Improvement
We recommend that the authors improve the experimental scope by conducting generalization experiments on additional datasets, such as CommonsenseQA, to demonstrate the model's superiority. Additionally, we suggest performing a comprehensive error analysis to better understand the model's limitations. It is also essential to provide a detailed explanation of the fine-tuning process for the core model and clarify the implications of using GPT-4 for dataset refinement. Finally, addressing the numerous typos and improving the readability of the method sections would enhance the overall presentation of the paper.