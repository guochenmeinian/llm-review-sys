ID: YXnwlZe0yf
Title: Putnam-AXIOM: A Functional and Static Benchmark for Measuring Higher Level Mathematical Reasoning
Conference: NeurIPS
Year: 2024
Number of Reviews: 4
Original Ratings: 7, 7, 5, 5
Original Confidences: 4, 3, 4, 4

Aggregated Review:
### Key Points
This paper presents a new benchmark, Advanced Examination of Intelligence in Operational Mathematics (Putnam-AXIOMO), consisting of 236 problems that can be automatically evaluated using a "\boxed{}" command for answers. The authors address dataset contamination by mutating parts of 53 problems to prevent memorization by models. The experimental results indicate that current strong language models perform poorly on this benchmark, highlighting issues with reasoning irrelevant variations that may indicate data contamination.

### Strengths and Weaknesses
Strengths:
- The benchmark introduces challenging reasoning tasks, revealing that even strong models struggle to perform well.
- It effectively addresses training set contamination, a significant issue in current benchmarks, with the decontamination process leading to accuracy decreases for nearly all models.

Weaknesses:
- The requirement for models to use "\boxed{}" for final answers limits the expressivity of the benchmark.
- The dataset's size of only 236 examples is too small to serve as a convincing benchmark, and the evaluated models achieve low accuracy, raising concerns about effectiveness and robustness.
- Functional transformations are applied to only 53 problems, potentially reducing evaluation power and resulting in high error bars.

### Suggestions for Improvement
We recommend that the authors improve the dataset size to enhance its robustness as a benchmark. Additionally, consider developing a more hierarchical difficulty structure for the problems to better assess model capabilities. We also suggest exploring algorithmic methods to continuously edit problems, ensuring that no model can memorize them. Finally, please use larger font sizes in the plots for better readability.