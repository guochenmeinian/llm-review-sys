ID: fHxmoekQBh
Title: MaVEn: An Effective Multi-granularity Hybrid Visual Encoding Framework for Multimodal Large Language Model
Conference: NeurIPS
Year: 2024
Number of Reviews: 21
Original Ratings: 8, 6, 6, 4, -1, -1, -1, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 2, 4, -1, -1, -1, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents MaVEn, a Multi-granularity Visual Encoding framework aimed at enhancing Multimodal Large Language Models (MLLMs) in multi-image reasoning. By integrating discrete visual symbol sequences with traditional continuous representation sequences, the authors propose a dual strategy to address semantic discrepancies between visual and textual information. Additionally, a dynamic reduction mechanism is designed to improve processing efficiency for long-sequence continuous features. Experimental results indicate that MaVEn significantly enhances performance in both multi-image and single-image contexts.

### Strengths and Weaknesses
Strengths:  
1. The manuscript is well-structured and clearly articulates the innovative multi-granularity approach, which includes hybrid visual encoding and a dynamic reduction mechanism.
2. Comprehensive experiments validate the effectiveness of MaVEn across various benchmarks, demonstrating its versatility.
3. The methodology is well-explained, making it accessible for readers.

Weaknesses:  
1. The paper lacks a comparison of the proposed discrete visual symbol sequences with other techniques like VQGAN or VQVAE to substantiate their efficacy.
2. The complexity of the training pipeline may hinder practical application and maintenance.
3. There is insufficient discussion on computational complexity compared to other models, and the role of continuous tokens remains unclear, raising questions about their contribution to performance.

### Suggestions for Improvement
We recommend that the authors improve the manuscript by conducting experiments comparing the performance of different discrete representation techniques, such as VQGAN or VQVAE, to strengthen claims regarding the efficacy of the discrete visual symbol sequences. Additionally, we suggest simplifying the training pipeline to enhance usability in real-world applications and providing a detailed analysis of the computational complexity of MaVEn in comparison to other existing models. Lastly, clarifying the role of continuous tokens in the model's performance would address existing concerns and improve the overall understanding of the framework.