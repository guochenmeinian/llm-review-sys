ID: pyhv4qYCEJ
Title: Evaluating Self-Supervised Learning for Molecular Graph Embeddings
Conference: NeurIPS
Year: 2023
Number of Reviews: 26
Original Ratings: 7, 6, 7, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper evaluates Graph Self-Supervised Learning (GSSL) for molecular graph embeddings and introduces "Molecular Graph Representation Evaluation" (MolGraphEval), which includes a suite of probing tasks to benchmark GSSL methods. The authors argue that existing evaluation methodologies inadequately capture the complexity of the task landscape. They present a focused evaluation of GSSL methods specifically for molecular data, emphasizing the use of unsupervised pre-training followed by supervised fine-tuning. The authors clarify the definition of probe models and their application in assessing neural network representations. Extensive experiments involving 90,918 probe models and 1,875 pre-trained GNNs reveal significant inconsistencies in current evaluation practices and highlight the limitations of their evaluation scope, including the rationale for not including additional supervised training results.

### Strengths and Weaknesses
**Strengths:**
- The paper is well-structured, clearly written, and presents interesting experimental results.
- The proposed MolGraphEval method offers a comprehensive evaluation framework that can enhance understanding of GSSL methods.
- The paper provides a comprehensive examination of GSSL methods, particularly in the context of molecular graphs.
- The inclusion of ethical considerations and discussions on the implications of GSSL methods enhances the manuscript's relevance.
- The authors have responded thoroughly to reviewer feedback, improving clarity and depth in various sections.

**Weaknesses:**
- The evaluation is limited to a small number of GSSL methods and downstream tasks, which may not fully represent the performance landscape.
- The evaluation scope is restricted to molecular data, which may limit the applicability of findings to other domains.
- The paper lacks a comparison with other evaluation methods and GCL baselines, making it difficult to assess the relative strengths of the proposed approach.
- Some findings appear trivial, and a deeper discussion on these results is needed.

### Suggestions for Improvement
- We recommend that the authors include more GCL baselines and provide brief descriptions of the GSSL methods employed to enhance comprehension.
- The authors should consider expanding the scope of evaluation to include additional GSSL methods and tasks, as well as conducting experiments under semi-supervised or few-shot settings.
- We suggest that the authors provide more detailed comparisons with other evaluation frameworks and GCL baselines to enhance the robustness of their findings.
- Clarifying the rationale behind specific methodological choices, such as the decision to exclude certain supervised training results, would strengthen the manuscript.
- We recommend that the authors provide a more detailed discussion of the ethical and social implications of their work, including potential biases and fairness issues.
- The authors should clarify the definition of the Probe model and ensure that the information is self-contained, particularly regarding the differences between Probe models and traditional linear probes.
- We recommend that the authors include a more thorough discussion of how their findings relate to prior work and suggest future research directions based on their results.