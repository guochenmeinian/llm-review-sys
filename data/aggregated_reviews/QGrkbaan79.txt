ID: QGrkbaan79
Title: RADAR: Robust AI-Text Detection via Adversarial Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 6, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents RADAR, a framework for training a robust AI-text detector using adversarial learning. It consists of a paraphraser and a detector, both based on large language models (LLMs), which iteratively update their parameters to enhance AI-text detectability. Experimental results indicate that RADAR outperforms existing detection methods, particularly with paraphrased content, and demonstrates transferability across different LLMs.

### Strengths and Weaknesses
Strengths:
- The paper effectively revives the concept of adversarial learning, employing a straightforward yet reasonable approach with the paraphraser.
- Experiments across eight LLMs and four datasets validate RADAR's high detection performance.
- The method shows generalizability, performing well with both seen and unseen paraphrasers.

Weaknesses:
- Concerns arise regarding the quality of text generated by the AI paraphraser, particularly its semantic integrity post-paraphrasing. An experiment comparing original and paraphrased text is recommended.
- The study is limited to LLMs with a maximum parameter scale of 7b, leaving performance on larger models like GPT-3.5 or GPT-4 untested. The authors are encouraged to explore experiments on a sampled subset of datasets to mitigate costs.
- The claim that existing methods suffer a notable performance drop on paraphrased AI text is contradicted by observed improvements in certain methods.

### Suggestions for Improvement
We recommend that the authors improve the quality assessment of the paraphrased text by adding an experiment that compares the original and paraphrased versions. Additionally, conducting tests on larger models such as GPT-3.5 or GPT-4, possibly using a sampled subset of datasets, would provide valuable insights. Clarifying the experimental settings and addressing the performance trade-offs on unperturbed data, including adjustments to weight coefficients in Equation 3, would enhance the paper's rigor. Lastly, a discussion on the limitations and potential ethical implications of RADAR's application is essential for contextualizing the findings.