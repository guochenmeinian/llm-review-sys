ID: 2kTX7K6osK
Title: Benchmarking Estimators for Natural Experiments: A Novel Dataset and a Doubly Robust Algorithm
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 6, 7, 8, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 2, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the RORCO dataset, derived from natural experiments, aimed at evaluating treatment effect models. The authors benchmark over 20 estimators for treatment effect estimation, finding that doubly robust estimators generally outperform others. They propose a new doubly robust estimator, Double-Double, with double weighting, and provide the dataset and benchmark as a Python package to facilitate further research.

### Strengths and Weaknesses
Strengths:
1. The paper addresses a significant problem and offers valuable resources for the treatment effects community.
2. It features a comprehensive benchmark framework that evaluates treatment effect estimators under varying conditions.
3. The introduction of a novel dataset and a new doubly robust estimator enhances practical relevance and applicability.

Weaknesses:
1. Clarity regarding the construction of synthetic data, implicit assumptions, and details on propensity score estimation needs improvement.
2. The theoretical analysis may not be necessary for a benchmark-focused paper, and the connection between the regression and propensity score components is unclear.
3. Using a fixed prediction structure (neural network) for all estimators may limit evaluation adequacy.

### Suggestions for Improvement
1. We recommend that the authors clarify the details and implicit assumptions in the synthetic data generating processes.
2. The authors should provide more detailed descriptions of how propensity scores are estimated and consider varying the estimation methods to investigate their impact on treatment effect accuracy.
3. We suggest that the authors justify the choice of a fixed prediction structure for all estimators and explore alternative models like BART and causal forests.
4. The authors should enhance documentation by including a code sample on how to use the RORCO dataset for evaluating treatment effects.
5. We recommend that the authors address the gap between RealRORCO and RORCO regarding observed treatment effects and clarify the implications of their theoretical analysis in Section 4.