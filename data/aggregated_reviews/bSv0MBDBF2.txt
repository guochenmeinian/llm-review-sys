ID: bSv0MBDBF2
Title: Denoising Diffusion Path: Attribution Noise Reduction with An Auxiliary Diffusion Model
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 5, 6, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Denoising Diffusion Path (DDPath), a method aimed at enhancing path-based attribution in deep neural networks by leveraging the denoising capabilities of diffusion models. DDPath constructs a piece-wise linear path to ensure gradual denoising, resulting in clearer attributions. The authors demonstrate that DDPath maintains axiomatic properties and can be integrated with existing methods like Integrated Gradients. Experiments on datasets such as ImageNet and MS COCO indicate that DDPath outperforms traditional methods in producing clearer explanations and improving metrics like Insertion and Deletion scores.

### Strengths and Weaknesses
Strengths:
- The proposed DDPath effectively addresses noise accumulation in attribution methods, showcasing a strong understanding of both attribution techniques and recent advances in generative models.
- The method is clearly explained, and the mathematical exposition is precise.
- Comprehensive experiments validate the effectiveness of DDPath across various interpretation methods and classification models.

Weaknesses:
- The presentation in Section 3 is abbreviated, lacking definitions that may confuse readers unfamiliar with the topic.
- The method's reliance on a pre-trained diffusion model raises concerns about its applicability in scenarios where such models are not available or when categories are difficult to define.
- The computational cost is high due to the requirement for significantly more sampling steps (250) than traditional methods, which may limit practical applications.
- Marginal improvements in quantitative metrics raise questions about the practical significance of the enhancements, especially given the increased computational cost.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Section 3 by providing definitions for key terms, such as the lower x^', to aid reader comprehension. Additionally, please clarify the details of Algorithm 1, particularly regarding the input timestep for the pre-trained diffusion model and the classifier, and whether noisy baselines align with the noise scheduling in diffusion models. We also suggest conducting a time-complexity analysis to compare DDPath with other methods. Furthermore, consider exploring the use of denoising task weights in DTR instead of a linear scaling scheme, as this may provide a tighter connection to the diffusion model. Lastly, we encourage the authors to investigate the applicability of DDPath to non-classification models and to address the limitations regarding its reliance on pre-trained diffusion models.