ID: K9M7XNS9BX
Title: Corruption-Robust Offline Reinforcement Learning with General Function Approximation
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 6, 6, 7, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 2, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on offline reinforcement learning (RL) with general function approximation in the context of adversarial corruption. The authors propose a new algorithm, Corruption Robust PEVI (CR-PEVI), which utilizes an uncertainty-weighting technique to enhance robustness against corrupted samples in the offline dataset. The theoretical analysis demonstrates that the algorithm achieves a suboptimality bound that aligns with existing lower bounds for corrupted linear Markov decision processes. The practical implementation is evaluated on a limited set of continuous control tasks from D4RL.

### Strengths and Weaknesses
Strengths:
- The authors introduce a corruption formulation that encompasses prior formulations, improving the dependency of the corruption term from $\sqrt{\epsilon}$ to $\epsilon$.
- The theoretical contributions are solid, combining uncertainty weighting with the PEVI algorithm to address offline poisoning attacks.
- Empirical results indicate that CR-PEVI outperforms existing methods across tasks.

Weaknesses:
- The algorithm's requirement for known corruption levels limits its practical applicability, with no heuristics provided for estimating these levels.
- The experimental evaluation is restricted to only two tasks, lacking comparisons with a broader range of D4RL tasks and unfairly contrasting with non-corruption robust algorithms.
- The definition of cumulative corruption is less intuitive and not commonly used in prior works, complicating quantification.

### Suggestions for Improvement
We recommend that the authors improve the experimental section by including a wider variety of tasks from D4RL and comparing the performance of CR-PEVI against implementations of Zhang et al. instead of uncertainty-based offline RL algorithms. Additionally, we suggest providing heuristics for estimating the corruption level to enhance the practicality of the proposed approach. Clarifying the rationale behind the definition of cumulative corruption based on the Bellman operator and reporting the corruption levels for different attacks in experiments would also strengthen the paper.