ID: sNz7tptCH6
Title: Boosting the Transferability of Adversarial Attack on Vision Transformer with Adaptive Token Tuning
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 6, 5, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Adaptive Token Tuning (ATT) to enhance the transferability of adversarial attacks on Vision Transformers (ViTs). The authors propose three optimization strategies: an adaptive gradient re-scaling method to reduce token gradient variance, a self-paced patch out strategy to increase input diversity, and a hybrid token gradient truncation method to mitigate the effectiveness of the attention mechanism. Experimental results indicate that ATT significantly improves attack success rates and transferability across various models compared to existing methods.

### Strengths and Weaknesses
Strengths:
- The combination of the three strategies is novel and well-motivated, providing a fresh perspective on improving adversarial attack transferability for ViTs.
- Extensive experiments demonstrate that ATT outperforms state-of-the-art methods, achieving higher attack success rates and better transferability.

Weaknesses:
- The paper lacks ablation experiments to validate the individual contributions of the three strategies.
- The title may not accurately reflect the techniques proposed, as the methods do not align with traditional token tuning.
- Several statements require references, and some claims, such as the effectiveness of the adaptive strategy in variance reduction, lack empirical support.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the title to better reflect the techniques used in the paper. Additionally, we suggest including ablation studies to substantiate the contributions of each strategy. The authors should also provide more detailed analyses or empirical evidence regarding the claims made, particularly those related to the effectiveness of the adaptive strategy and the implications of hyperparameter settings. Furthermore, we encourage the authors to address the limitations of their work more explicitly, as this is currently lacking in the manuscript.