ID: QkLpGxUboF
Title: ProPILE: Probing Privacy Leakage in Large Language Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 7, 6, 7, 7, 7, -1, -1, -1
Original Confidences: 4, 4, 3, 4, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ProPILE, a tool designed to evaluate the risk of Personally Identifiable Information (PII) leakage from large language models (LLMs). The authors propose a probing method that includes both black-box and white-box approaches, allowing users to assess potential privacy intrusions using their own PII. The tool's effectiveness is demonstrated using the OPT-1.3B model and the publicly available Pile dataset. The authors quantify PII leakage risk through attributes such as linkability and structurality, and provide two quantifications: string match and likelihood.

### Strengths and Weaknesses
Strengths:
- The work addresses a timely and significant issue regarding privacy breaches in LLMs.
- ProPILE empowers users to assess privacy risks, fostering awareness of privacy concerns.
- The methodology is clean, and the paper is well-written with clear figures, making it easy to follow.
- The authors provide a principled solution for quantifying PII leakage risk, supported by extensive studies.

Weaknesses:
- The evaluation is limited to the OPT-1.3B model, raising questions about the tool's effectiveness with other LLMs.
- The black-box probing method may not adequately capture all PII risks, as users may be unaware of the PII used by LLMs.
- The definition of privacy is narrow, focusing on exact matches, which may overlook partial leakage.
- There is a lack of discussion on potential countermeasures against misuse of the tool and the inherent biases in the dataset used for evaluation.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by including additional models to assess ProPILE's effectiveness across various LLMs. Establishing a prompt database with diverse prompt-generating rules could enhance the black-box probing method. The authors should also broaden their definition of privacy to encompass partial leakage and discuss potential countermeasures to prevent misuse of their tool. Clarifying the definition of the soft prompt \(\theta_s\) and providing examples of probing results would further strengthen the paper. Additionally, addressing the potential generalization of the method to closed-source LLMs and the societal impacts of the research outcome would enhance the paper's depth.