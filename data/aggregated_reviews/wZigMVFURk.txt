ID: wZigMVFURk
Title: RoPINN: Region Optimized Physics-Informed Neural Networks
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 4, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel optimization method for training physics-informed neural networks (PINNs) called Region Optimized PINN (RoPINN), which extends the optimization process from isolated points to continuous neighborhood regions. The authors propose using Monte Carlo integration for discretizing continuous integrals over these regions and adaptively adjusting the region size during training based on gradient statistics. The theoretical analysis indicates that RoPINN can reduce generalization error and improve the satisfaction of high-order PDE constraints, while empirical results demonstrate its effectiveness across various benchmark problems. In response to concerns about the practical application scope of RoPINN, the authors emphasize that "theoretical assumption will not affect the practicability of algorithms" and provide extensive experimental results (5 base models on 19 PDEs) supporting RoPINN's effectiveness. They add new experiments with more sampling points and compare RoPINN with advanced quadrature methods, demonstrating that these methods require more points for better performance, which contradicts their goal of "no extra gradient calculation." Additionally, the authors offer practical guidance on hyperparameters based on their analysis.

### Strengths and Weaknesses
Strengths:
- The extension of optimization from isolated points to continuous regions is a novel approach.
- Theoretical results on generalization error, convergence rate, and sampling estimation are provided.
- RoPINN consistently enhances the performance of diverse PINNs without requiring additional backpropagation or gradient calculations.
- Extensive experimental results bolster the claims regarding RoPINN's performance across multiple challenging benchmark problems.
- The authors effectively clarify the practical applicability of their theoretical assumptions and present a clear distinction between their optimization-based approach and previous sampling methods.

Weaknesses:
- The introduction of continuous integrals appears tautological, as the loss function in PINNs is already a Monte Carlo discretization.
- The theoretical analysis should focus on the Monte Carlo approximation rather than the continuous integral for a fair comparison.
- The practical application scope is limited, and guidelines for setting hyper-parameters like initial region size and sampling points are lacking.
- The motivation for using Monte Carlo approximation over more advanced methods is not sufficiently elaborated.
- The justification for the choice of sampling points may require further elaboration.
- The comparison with advanced quadrature methods could benefit from more detailed analysis.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the theoretical analysis by focusing on the Monte Carlo approximation of the loss function rather than the continuous integral. Additionally, please include the main proof ideas of the theoretical results in the main text to enhance understanding. We suggest providing intuitive explanations for the success of region optimization, particularly regarding how sampling one point in each region decreases total loss compared to point optimization. Furthermore, we encourage the authors to elaborate on the motivation for using Monte Carlo methods and to discuss practical guidelines for users regarding hyper-parameter settings. Lastly, we recommend improving the justification for their choice of sampling points and providing a more detailed analysis in the comparison with advanced quadrature methods to strengthen the paper's arguments. Additional experiments on computational wall time would also provide a more comprehensive evaluation of RoPINN's performance.