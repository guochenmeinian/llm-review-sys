ID: pVPyCgXv57
Title: Learning to Merge Tokens via Decoupled Embedding for Efficient Vision Transformers
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 6, 5, 4, 6, -1, -1, -1, -1
Original Confidences: 5, 5, 4, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to enhance the efficiency of token merging within Vision Transformers (ViTs) through the proposed method, Decoupled Token Embedding for Merging (DTEM). DTEM introduces a lightweight embedding module that operates independently from the ViT's forward pass, allowing integration with existing ViT backbones and enabling training either modularly or end-to-end. The authors demonstrate that DTEM achieves consistent improvements in token merging efficiency across various tasks, including classification, captioning, and segmentation.

### Strengths and Weaknesses
Strengths:
1. The concept of decoupling for continuous relaxation of the token merging process is innovative, facilitating differential learning of decoupled embeddings.
2. The paper is clearly presented and easy to follow.
3. Experimental results are promising, showcasing the method's robustness and versatility across multiple domains.

Weaknesses:
1. The model training process involves numerous hyperparameters, such as step in soft grouping and m in soft merging, raising concerns about implementation complexity. Additionally, there is no ablation study on parameter m in soft merging.
2. There is a lack of ablation experiments in segmentation and captioning to validate the module's effectiveness for these tasks.
3. The overall process, despite claims of decoupling, resembles the self-attention process, particularly in end-to-end training. The authors need to provide evidence of the decoupling effect beyond classification results.
4. The paper lacks discussion and comparisons with recent related works, and the necessity of introducing additional embeddings requires more intuitive examples or in-depth analysis.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the hyperparameter determination process and conduct an ablation study on parameter m in soft merging. Additionally, we suggest including ablation experiments for segmentation and captioning tasks to substantiate the module's effectiveness. To strengthen the argument for the necessity of additional embeddings, we encourage the authors to provide more intuitive examples and a comprehensive comparison with related works. Furthermore, a detailed analysis of alternative design choices for soft grouping and soft merging would enhance the paper's depth. Lastly, expanding the discussion on experimental results would benefit readers' understanding.