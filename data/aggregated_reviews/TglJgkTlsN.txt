ID: TglJgkTlsN
Title: Improving Math Problem Solving in Large Language Models Through Categorization and Strategy Tailoring
Conference: AAAI
Year: 2024
Number of Reviews: 2
Original Ratings: 4, 5
Original Confidences: 4, 3

Aggregated Review:
### Key Points
This paper presents a method for solving mathematical problems by automatically selecting between chain-of-thought (CT) and program-of-thought (PT) prompting through a categorization model utilizing a 3-layer neural network based on word frequency features. The authors propose classifying problems into categories and strategies to enhance problem-solving.

### Strengths and Weaknesses
Strengths:  
- The approach introduces an interesting method for addressing mathematical problem-solving through categorization.

Weaknesses:  
- The categorization model is weak, relying on word frequency features, which complicates ‘answer extraction.’ A stronger sequence model, such as a Transformer, should be considered.  
- The method does not compute the posterior probability; it only uses the argmax of the output distribution, neglecting the potential benefits of incorporating the output distribution into posterior sampling.  
- The definition of the prior sampling distribution {CT, PT} lacks justification and appears arbitrary.  
- There is no empirical demonstration of how the approach reduces hallucinations in LLMs, despite claims to that effect.  
- The methodology lacks clarity, with insufficient details on the network architecture, example prompts, and other critical components, making reproducibility difficult.  
- Minor issues include references to AlphaProof and Alphageometry linking to news articles instead of original papers and broken section references.  

### Suggestions for Improvement
We recommend that the authors improve the categorization model by utilizing a stronger sequence model, such as a Transformer, to enhance ‘answer extraction.’ Additionally, we suggest incorporating the output distribution of the categorization model into the posterior sampling distribution computation. Justifying the definition of the prior sampling distribution {CT, PT} is essential. To address hallucinations, we urge the authors to provide empirical evidence demonstrating the effectiveness of their approach. Furthermore, we recommend clarifying the methodology by including detailed descriptions of the network architecture, example prompts, and ensuring the reproducibility of experimental results. Lastly, we advise correcting the references and improving the readability of tables.