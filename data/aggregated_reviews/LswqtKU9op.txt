ID: LswqtKU9op
Title: Prompt-augmented Temporal Point Process for Streaming Event Sequence
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 6, 6, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents PromptTPP, a method that integrates classical neural temporal point processes with a continuous-time retrieval prompt pool, enabling the model to learn event streams sequentially without buffering previous examples in continual learning contexts. The authors propose a TPP model that combines Prompt and Continual Learning (CL) concepts, demonstrating superior performance on two datasets. The framework includes a retrieval mechanism for dynamically selecting task-relevant prompts based on event sequences.

### Strengths and Weaknesses
Strengths:
1. The motivation for the proposed method is clear, and the experiments validate its effectiveness.
2. The paper is well-structured and easy to read, with comprehensive equations and illustrative figures.
3. The experimental results convincingly demonstrate the effectiveness of PromptTPP, and the availability of code facilitates reproduction.

Weaknesses:
1. The method description lacks clarity, particularly regarding prompt-learning details such as prompt length Lp, selection size N, and prompt pool size M.
2. The integration of PPT, CL, and PL appears somewhat unnatural, with insufficient theoretical or technical explanation of how prompt learning aids CL.
3. The paper does not provide a detailed analysis of computational complexity or a comparison with other state-of-the-art methods for modeling streaming event sequences.
4. The experiments are limited to two datasets, raising questions about the generalizability of the findings.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the method description by providing more detailed explanations of the prompt-learning-based task and its hyperparameters. Additionally, the authors should explain how the prompt learning method theoretically supports CL, rather than relying solely on experimental accuracy. It would be beneficial to include a detailed analysis of the computational complexity of the proposed framework and to conduct experiments on additional datasets to strengthen the paper's contributions. Furthermore, we suggest that the authors clarify the relationship between prompt settings and downstream tasks, and explore the potential benefits of custom methods over general methods in their experiments.