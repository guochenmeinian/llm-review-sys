ID: 6mZIF4OxSq
Title: K-HATERS: A Hate Speech Detection Corpus in Korean with Target-Specific Ratings
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel large corpus for Korean, annotated for hate speech using a fine-grained scheme that includes ratings of offensiveness, identification of targets, and rationale. The dataset, sourced from news comments, involves 405 annotators from a crowdsourcing platform. The authors propose a multitask approach for hate speech detection, demonstrating the dataset's effectiveness through various models and a case study indicating higher hate speech prevalence in hard news comments.

### Strengths and Weaknesses
Strengths:
- The introduction of a unique dataset for hate speech classification in Korean, filling a significant research gap.
- The innovative annotation scheme captures varying degrees of offensiveness and includes a cognitive reflection test to filter biased annotators.
- The paper is well-organized and presents strong performance in hate speech detection tasks.

Weaknesses:
- The discussion on implicit hate speech is unconvincing, lacking a clear distinction between implicit and explicit forms.
- Insufficient details regarding the dataset's sourcing and the inter-annotator agreement process.
- The paper does not adequately address the qualifications of annotators or the assessment of annotation quality.

### Suggestions for Improvement
We recommend that the authors improve the discussion on implicit hate speech by providing a clearer definition and differentiating between implicit and explicit forms in both annotations and evaluations. Additionally, the authors should elaborate on the dataset's sourcing, the qualifications of annotators, and the assessment of inter-annotator agreement. Clarifying the significance of the cognitive reflection test in relation to bias would also enhance the paper's rigor. Furthermore, we suggest improving the visibility of texts and numbers in Figure 6 and discussing the reasons behind misclassifications in more detail. Lastly, providing a link to the dataset and codes in the manuscript would facilitate reproducibility.