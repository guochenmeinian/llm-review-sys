ID: UkxJd64mki
Title: StrategyLLM: Large Language Models as Strategy Generators, Executors, Optimizers, and Evaluators for Problem Solving
Conference: NeurIPS
Year: 2024
Number of Reviews: 19
Original Ratings: 5, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents StrategyLLM, a novel prompting strategy designed to enhance few-shot reasoning performance in large language models (LLMs). The approach involves generating task-specific strategies through a pipeline consisting of a strategy generator, executor, and optimizer. The authors empirically evaluate StrategyLLM across various datasets and LLMs, demonstrating improved generalization compared to instance-specific methods like Chain of Thought (CoT). The results indicate that the proposed method outperforms several baseline prompting techniques. Additionally, the paper provides a detailed analysis of the StrategyLLM framework in solving complex combinatorial problems, exemplified by the arrangement of 6 distinct beads in a 2x3 grid. The authors compare the performance of StrategyLLM against zero-shot (ZS) and CoT approaches, highlighting that while ZS and CoT mismanage the considerations of rotations and reflections, StrategyLLM accurately applies the necessary logic to arrive at the correct solution of 180 distinct arrangements.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and presents a clear idea supported by thorough experimentation across multiple datasets and LLMs.
- The empirical results show significant improvements over baseline methods, and the analysis of different parameters is comprehensive.
- The authors provide a comprehensive breakdown of the problem-solving process, illustrating the advantages of StrategyLLM in handling complex reasoning tasks.
- The new experimental results clarify the necessity and importance of various facets of the StrategyLLM approach, enhancing the overall understanding of its effectiveness.

Weaknesses:
- The connection between the proposed method's superior performance and the alternatives, particularly CoT, lacks concrete examples and clear intuitions.
- The few-shot setting for StrategyLLM is ambiguous, raising questions about the accuracy of the generated strategies.
- The SolutionLLM baseline is not clearly explained, particularly regarding its definition and application.
- ZS and CoT approaches fail to adequately address the complexities of rotations and reflections, leading to incorrect conclusions.
- The paper lacks explicit articulation of the complexities involved in the problem-solving process, which could further strengthen the argument for StrategyLLM's superiority.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the relationship between StrategyLLM and CoT by providing concrete examples that illustrate the differences in performance. Additionally, we suggest clarifying the few-shot setting for StrategyLLM, specifically addressing whether the generated strategies contain incorrect solutions. It would also be beneficial to provide a clearer explanation of the SolutionLLM baseline, including what constitutes a "solution" and how it is applied to novel tasks. Furthermore, we encourage the authors to explicitly spell out the complexities in combinatorial questions and explain why StrategyLLM outperforms other approaches like CoT and ZS in these scenarios. Finally, consider conducting an ablation study to assess the necessity of the grading and optimization phases in the StrategyLLM approach.