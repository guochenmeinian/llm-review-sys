ID: qgzdGyQcDt
Title: EEVR: A Dataset of Paired Physiological Signals and Textual Descriptions for Joint Emotion Representation Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 9, 5, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on a virtual reality-based emotion dataset involving 37 participants, utilizing a mixed-methods research design. The authors propose that traditional emotion research often relies on physiological data and self-reports, which may not capture the full spectrum of daily emotions. The study employs EEVR, integrating 360-degree VR audiovisual stimuli and follow-up interviews to enhance understanding of emotional valence and arousal, thereby contributing to mental health research. Additionally, the paper provides a comprehensive analysis of emotion recognition using physiological signals and textual data, proposing a model that demonstrates significant improvements in classification accuracy, achieving 77.248% for arousal and 70.383% for valence. The results are derived from a Leave One Subject Out (LOSO) validation technique, ensuring generalizability across different participants and datasets, and include detailed confusion matrices for various input data combinations, illustrating the model's performance.

### Strengths and Weaknesses
Strengths:
1. Utilization of validated measures of emotion, including the PANAS scale and SAM scale.
2. Sound experimental protocol with baseline data, VR familiarity checks, stimulus exposure breaks, and qualitative interviews.
3. Clear process for qualitative data transcription.
4. The model shows substantial improvements in classification accuracy over physiological baselines and random results.
5. The use of LOSO validation enhances the model's generalizability to unseen participants.
6. Detailed confusion matrices provide clear insights into model performance across different data combinations.

Weaknesses:
1. Small sample size of 37 participants, limiting generalizability, particularly as the sample is restricted to ages 18-33.
2. Concerns regarding the elicitation of emotions through VR and the quality of textual descriptors.
3. Lack of comprehensive guidance on emotion recognition and potential biases in self-reported data.
4. The separation of Tables 2 and 3 may hinder clarity regarding the overall results.
5. The paper could benefit from a more explicit discussion on the implications of unique physiological baselines for emotion recognition.

### Suggestions for Improvement
We recommend that the authors improve the sample size to enhance generalizability and consider a broader age range. Additionally, we suggest that the authors compare their results with other recent datasets using different methods, such as video-based approaches, and report confusion matrices to clarify data quality. It would be beneficial to extend the analysis of qualitative data, including the number of coders involved and emerging themes. We also recommend improving clarity by combining Tables 2 and 3 in the final version of the paper. Furthermore, we suggest a more thorough discussion on the impact of individual physiological baselines on the results, which could enhance the understanding of the model's applicability in diverse settings. Finally, we encourage the authors to explore the inclusion of visual and audio modalities in future work to strengthen the dataset's applicability and insights into emotional responses.