ID: eP9auEJqFg
Title: Representation Noising: A Defence Mechanism Against Harmful Finetuning
Conference: NeurIPS
Year: 2024
Number of Reviews: 31
Original Ratings: 7, 7, 7, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents RepNoise, a novel defense mechanism aimed at mitigating harmful fine-tuning attacks (HFAs) on large language models (LLMs). The authors propose a strategy that involves mapping harmful representations to Gaussian noise, supplemented by stability and ascent loss terms to maintain model performance on benign tasks. Empirical results indicate that RepNoise effectively prevents HFAs without degrading the model's utility for harmless tasks. The authors clarify that RepNoise generalizes to unseen harmful subsets as long as they follow the same distribution as the attack set, but it is not effective against out-of-distribution attacks, as demonstrated with the HEX-PHI dataset. The paper includes a detailed analysis of the loss landscape, training trajectories, and the transition probabilities involved in fine-tuning models on harmful datasets, while also addressing the challenges posed by harmful fine-tuning.

### Strengths and Weaknesses
Strengths:
1. The importance of addressing harmful fine-tuning is well recognized, and RepNoise offers a timely solution.
2. The minimal assumptions required for implementation enhance its applicability, as control is limited to the alignment stage.
3. Experimental results are reproducible, confirming the effectiveness of the proposed method across various models and datasets.
4. The literature review is thorough, incorporating relevant works and addressing gaps in prior research.
5. The authors provide clear revisions and clarifications regarding learning rate selection and harmfulness score calculation, improving the paper's transparency.
6. The inclusion of additional baselines and metrics strengthens the evaluation of the proposed methods.
7. The authors have made significant revisions to clarify the claims of RepNoise, ensuring they match the evidence presented.

Weaknesses:
1. The paper shares similarities with Vaccine [24], and a comparative analysis is recommended in the rebuttal.
2. Implementation relies on two specific tricks that may complicate re-implementation, potentially leading to issues such as NaN loss or out-of-memory errors. A simpler method without these tricks is preferred for the main evaluation, with enhancements discussed in a dedicated subsection.
3. The absence of code with the submission diminishes the paper's credibility; providing code would enhance reproducibility.
4. Increased GPU memory usage is noted; a comparison of memory and clock time usage with SFT and Vaccine is suggested.
5. Some sections, particularly regarding the success metric and the argument about benign fine-tuning, lack clarity and may confuse readers.
6. The defense mechanism is shown to be vulnerable to variations in the fine-tuning dataset, optimizer settings, and training epochs, raising concerns about its robustness.
7. Some reviewers express skepticism regarding the distinction between in-distribution and out-of-distribution attacks, particularly concerning the HEX-PHI dataset.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the theoretical framework, particularly by defining key terms such as "representation" and "information" more precisely. Additionally, we suggest that the authors clarify the rationale behind the implementation tricks and consider simplifying the method for broader applicability. Addressing the identified weaknesses in the experimental setup and providing code would significantly enhance the paper's impact and credibility. We encourage the authors to incorporate recent literature to strengthen the context of their work. Furthermore, we recommend that the authors improve the clarity of the distinction between in-distribution and out-of-distribution attacks, particularly in relation to the HEX-PHI dataset. Finally, we suggest that the authors provide a comprehensive system evaluation comparing training time and memory usage of RepNoise with standard fine-tuning methods to better inform users about the practical implications of their approach.