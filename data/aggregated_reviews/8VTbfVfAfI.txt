ID: 8VTbfVfAfI
Title: The Grand Illusion: The Myth of Software Portability and Implications for ML Progress.
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 4, 6, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the portability of popular machine learning frameworks (PyTorch, TensorFlow, and JAX) across different hardware types (GPUs and TPUs). The authors conduct experiments revealing that many functions fail to execute or perform significantly slower on one hardware type compared to another. They claim that machine learning frameworks can lose over 40% of their key functions when ported to different hardware, suggesting that specialization in hardware may hinder innovation in machine learning research. Additionally, the authors express a commitment to updating the final manuscript based on valuable feedback received during the rebuttal period and are open to further dialogue to address any remaining concerns.

### Strengths and Weaknesses
Strengths:
- The paper addresses a critical concern regarding the lack of portability in machine learning frameworks, providing valuable insights for the ML community.
- The methodology for selecting functions for evaluation is comprehensive, and the benchmarking is executed carefully.
- The evaluation reveals significant insights about function performance across hardware types, supported by a public dataset.
- The authors demonstrate a strong willingness to engage with reviewers and incorporate feedback into their work, reflecting a collaborative approach to improving the manuscript.

Weaknesses:
- The lack of portability is a well-known issue; the paper does not convincingly argue why this evaluation is necessary or significant.
- The conclusion that "specialization of hardware impedes innovation" is not substantiated, and the paper lacks a detailed analysis of how portability affects innovation.
- The focus on framework operations rather than actual neural network workloads limits the relevance of the findings, and the standard for evaluating portability is unclear.
- The paper is difficult to follow, with unclear significance and originality in its contributions.
- There are no specific weaknesses identified in the reviews regarding the authors' willingness to engage with feedback.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their argument regarding the significance of portability in machine learning. Specifically, they should provide deeper analysis on why the lack of portability is a critical issue and how it constrains innovation. Additionally, we suggest that the authors include comparisons of function performance across different frameworks, as well as a discussion on the implications of their findings for real-world applications. To enhance reproducibility, it would be beneficial to detail the exact software versions used in their experiments. Lastly, we encourage the authors to explore the inclusion of CPU comparisons and a more thorough discussion of the limitations of their study, ensuring that all feedback is thoroughly addressed and incorporated to enhance the overall quality and clarity of the final submission.