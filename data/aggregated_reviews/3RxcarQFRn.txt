ID: 3RxcarQFRn
Title: Generative Adversarial Model-Based Optimization via Source Critic Regularization
Conference: NeurIPS
Year: 2024
Number of Reviews: 30
Original Ratings: 6, 5, 6, 7, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents GABO, a novel Bayesian optimization method designed for offline model-based optimization (MBO) problems. GABO employs a source critic actor to regulate the surrogate model, ensuring that the Bayesian optimization process remains within the in-distribution space. Additionally, the authors propose GAGA, which utilizes a penalized surrogate function to rank and select candidates, addressing the issue of out-of-distribution errors. The inclusion of the Warfarin task as a new offline MBO task is justified, emphasizing the significance of convex objectives for evaluating MBO methods. Experimental results indicate that GABO outperforms several baseline methods, including ROMO, in terms of mean rank across multiple tasks, although its performance on specific tasks raises questions about its generalizability.

### Strengths and Weaknesses
Strengths:
- The paper is the first to explore Bayesian optimization in offline MBO settings, addressing a previously unexplored area.
- The mathematical formulation appears valid, and a practical algorithm is provided.
- The use of a penalized surrogate function improves robustness in candidate selection.
- GABO demonstrates competitive performance across a range of tasks, outperforming several baselines.
- The authors effectively address reviewer concerns and clarify methodological details.

Weaknesses:
- The evaluation tasks primarily focus on discrete biological sequence design, limiting the research scope. The authors should compare GABO with methods specialized in biological sequence design, such as BIB and BootGen.
- The evaluation procedure deviates from conventional offline MBO practices, as it selects the top candidate based on a surrogate model that may yield inaccurate predictions for out-of-distribution data. The authors need to clarify their rationale for this evaluation approach.
- The performance of GABO on the Warfarin task is subpar compared to other baselines, raising questions about the method's effectiveness in this context.
- The performance of GABO on the D'Kitty task is notably poor, raising further questions about its generalizability.
- The claim regarding the utility of convex objectives in real-world tasks is met with skepticism from reviewers.
- The rationale behind the proposed method and the choice of hyperparameters lacks clarity.
- The lack of a filtering procedure in the evaluation process may limit the perceived effectiveness of GABO.

### Suggestions for Improvement
We recommend that the authors improve the scope of their research by including comparisons with appropriate baselines that focus on biological sequence design. Additionally, the authors should provide a detailed explanation of their evaluation setting changes and clarify the rationale behind the performance discrepancies observed in the Warfarin and D'Kitty tasks. It would also be beneficial to justify the choice of Bayesian optimization hyperparameters and explore the implications of using a surrogate model for candidate selection. Furthermore, we suggest that the authors include a scatter plot of candidate evaluations to provide a more comprehensive view of performance across different methods. Lastly, we encourage the authors to highlight the significance of convex objectives more convincingly in the context of offline MBO.