ID: BSYn7ah4KX
Title: Bias Amplification in Language Model Evolution: An Iterated Learning Perspective
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 3, 6, 6, 6, -1, -1, -1, -1
Original Confidences: 2, 3, 3, 2, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates iterated learning with large language models (LLMs) through a Bayesian framework, demonstrating how biases are amplified across iterations. The authors conduct experiments confirming this amplification and propose that controlling information transmission can train LLMs to exhibit desirable biases, such as helpfulness and conciseness. The paper also discusses the evolutionary process of LLMs, drawing parallels with human cultural evolution, and suggests strategies for guiding LLM behavior.

### Strengths and Weaknesses
Strengths:
- The application of the Bayesian-IL framework offers an innovative perspective on LLM evolution and bias amplification.
- The theoretical foundation is solid, supported by comprehensive experiments across various LLMs.
- The proposed strategies for guiding LLM evolution are beneficial for designing algorithms for bias mitigation.

Weaknesses:
- The theoretical results presented lack novelty, as they paraphrase established findings from prior work.
- The paper's extensive theoretical analysis detracts from the clarity of key experimental results, which are insufficiently highlighted.
- Presentation issues, such as small font sizes in tables and unclear terminology, hinder readability and comprehension.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the experimental results by emphasizing them more in the main text and providing clear definitions for terms used in tables and figures. Additionally, we suggest reorganizing Sections 3 and 4 to focus on novel aspects of the work and to avoid repeating previous literature. It would be beneficial to include a running example in the introduction to aid understanding and to summarize planned experiments before Section 5. Furthermore, the authors should address the gap between the theoretical framework and empirical evidence, ensuring that the assumptions made in the theoretical proof align with the experimental results. Lastly, we encourage the authors to explore concrete solutions for detecting and mitigating implicit biases, as well as to clarify how their proposed constraints can effectively address model collapse during iterated learning.