ID: 6sIOBDwr6d
Title: Consensus Learning with Deep Sets for Essential Matrix Estimation
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 6, 6, 8, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Noise Aware Consensus Network (NACNet) for robust essential matrix estimation using a DeepSets-based architecture. The method incorporates a two-stage noise-aware training scheme, a noise head for predicting displacement noise in inlier matches, and a classification head for distinguishing between inliers and outliers. The architecture consists of Noise-aware Consensus Blocks (NAC) that utilize set encoders to derive latent representations and classify point matches. Evaluations indicate that the proposed method outperforms existing techniques in accuracy and generalization across various datasets.

### Strengths and Weaknesses
Strengths:
1. The proposed architecture is simple yet demonstrates superior empirical performance compared to existing methods.
2. The NAC block effectively captures denoising and inlier/outlier classification, validated through ablation studies.
3. The network's end-to-end differentiability and clear architecture contribute to its robustness and usability in practical applications.
4. Extensive experiments across different datasets showcase the method's generalization capabilities.

Weaknesses:
1. The paper lacks an ablation study on the choice of set functions, which could provide insights into potential performance improvements.
2. There is insufficient discussion regarding the impact of the NACNet architecture's capacity compared to baseline methods.
3. The removal of half of the input matches for outlier pruning raises questions about the validity and adjustability of this approach.
4. The paper does not adequately address the computational efficiency of the proposed method, particularly in terms of runtime and model parameter scale.

### Suggestions for Improvement
We recommend that the authors improve the paper by including an ablation study on the choice of set functions to explore alternative architectures that may enhance performance. Additionally, an analysis comparing the capacity of the NACNet architecture with baseline methods would provide valuable context. We suggest conducting further experiments to assess the impact of varying the number of removed matches on performance and to clarify the rationale behind this approach. Lastly, we encourage the authors to discuss the computational efficiency of their method in detail, including runtime comparisons with existing techniques, to better inform potential real-world applications.