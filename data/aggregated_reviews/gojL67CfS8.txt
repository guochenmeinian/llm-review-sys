ID: gojL67CfS8
Title: Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction
Conference: NeurIPS
Year: 2024
Number of Reviews: 24
Original Ratings: 8, 8, 8, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Visual AutoRegressive modeling (VAR), a novel autoregressive generative model for images that employs a coarse-to-fine approach using next-scale prediction in a multi-resolution feature pyramid. VAR demonstrates significant improvements in performance, reducing FID from 18.65 to 1.73 and achieving 20x faster inference compared to traditional models. The authors extend scaling laws from language modeling to image generation, showing that VAR outperforms diffusion models in quality, speed, and efficiency. Additionally, the paper incorporates a residual quantization technique and addresses technical concerns regarding throughput results, interpolation methods for masking, and causal dependencies in the model. Extensive experiments validate VAR's competitive performance on ImageNet, while ablation studies clarify the contributions of various components.

### Strengths and Weaknesses
Strengths:
- The paper addresses the critical challenge of bridging the performance gap between autoregressive language models and image generation, making it highly relevant and impactful.
- The method is well-motivated, leveraging established components from large language models (LLMs), positioning VAR as a significant advancement in image generation.
- Comprehensive experiments demonstrate VAR's performance and efficiency, with detailed discussions on scaling laws and ablation studies in the appendix.
- The authors effectively respond to reviewer concerns, enhancing the clarity and robustness of their paper.
- Additional results with faster diffusion samplers strengthen the overall findings.
- The empirical analysis of throughput improvements with varying batch sizes is thorough and informative.

Weaknesses:
- The method section lacks clarity, particularly in explaining VAR's training process and tokenization. Section 3.2 is confusing, necessitating more detail on residual tokenization and transformer operations.
- Some claims, such as the FID reduction, are exaggerated when compared to weak baselines. A more realistic comparison with models like RQ-VAE would enhance credibility.
- The diffusion model baselines are also weak, suggesting that VAR's performance should be described as "competitive" rather than a significant improvement.
- There are still some confusions regarding throughput results, particularly the reported typo and the implications of batch size on performance.
- The lack of explicit ablation studies on certain techniques, such as residual quantization, raises questions about the robustness of their claims.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the method section by providing more detailed explanations of VAR's training process, residual tokenization, and transformer operations. Additionally, we suggest revising exaggerated claims in the abstract to reflect comparisons with more realistic baselines, such as RQ-VAE models. The authors should also consider using stronger diffusion model baselines for comparison to accurately represent VAR's performance. Furthermore, we recommend improving the clarity of the throughput results by ensuring all reported metrics are accurate and clearly explained. Conducting an ablation study on the "residual quantization" technique would provide further insights into its impact on model performance. Finally, addressing the limitations regarding spatial resolution and interpolation methods in more detail would enhance the paper's comprehensiveness.