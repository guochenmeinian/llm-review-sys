ID: MkD0VGShAq
Title: GazeVQA: A Video Question Answering Dataset for Multiview Eye-Gaze Task-Oriented Collaborations
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel Video Question Answering (VQA) task that incorporates video input from multiple viewing angles, focusing on assembly and disassembly tasks. The authors construct a new dataset, GazeVQA, which includes exocentric and egocentric videos along with gaze information to enhance understanding of human intentions during collaborative tasks. They also introduce the AssistGaze model, demonstrating its application within this context.

### Strengths and Weaknesses
Strengths:
- The GazeVQA dataset is large and of high video/image quality, promoting research in robot-human interaction.
- The inclusion of gaze information provides a unique perspective on human intentions.
- The implementation of the AssistGaze model and extensive experiments showcase its efficacy.

Weaknesses:
- Generalizability is questionable due to the dataset's focus on assembly and disassembly tasks with limited object variety and environments.
- The paper lacks extensive comparisons of the AssistGaze model with existing VQA models, limiting understanding of its position in the research landscape.
- There are many ungrammatical sentences and unclear explanations, which could confuse readers and affect benchmark evaluation.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of the dataset by including a wider variety of tasks and objects. Additionally, we suggest providing a more detailed comparison of the AssistGaze model with existing approaches in the VQA domain to clarify its contributions. The authors should also address the grammatical issues throughout the paper and ensure that all figures and tables are well-organized and properly captioned. Lastly, we encourage the authors to clarify how gaze data specifically benefits the VQA task with concrete examples from the dataset.