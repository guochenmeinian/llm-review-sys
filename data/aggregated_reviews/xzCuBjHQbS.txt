ID: xzCuBjHQbS
Title: Random Function Descent
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 5, 7, 6, 5, -1, -1, -1
Original Confidences: 3, 3, 2, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel gradient descent step schedule called Random Function Descent (RFD), derived from a Bayesian perspective, which connects Bayesian optimization with classical optimization. The authors explore minimizing a stochastic first Taylor approximation of random functions, particularly Gaussian processes, and derive an adaptive step size scheduler. The theoretical framework supports common heuristics like gradient clipping and warmup, validated through extensive experiments on the MNIST dataset.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written, with clear notations and visually appealing figures, making it a pleasure to read.
2. It provides a solid theoretical foundation for step size heuristics, bridging empirical practices and theoretical understanding.
3. The innovative connection between Bayesian optimization and gradient descent offers new insights into learning rate scheduling.
4. The extensive and well-organized experiments demonstrate the practical applicability of RFD, showing its potential to outperform traditional methods like Adam and SGD.

Weaknesses:
1. The justification for the "average case study" is insufficient, as the expectation of $J(w_n)$ does not generally equal that of $J(\theta)$ when $\theta$ is fixed.
2. The paper lacks a systematic literature review, limiting the evaluation of its novelty and relevance.
3. Empirical validation is confined to the MNIST dataset, necessitating broader testing across diverse datasets and models.
4. The complexity of the theoretical developments may hinder accessibility for practitioners unfamiliar with advanced optimization theory.

### Suggestions for Improvement
We recommend that the authors improve the justification for the average case study, clarifying the relationship between $J(w_n)$ and $J(\theta)$. Additionally, we suggest including a dedicated literature review section to contextualize the work within existing research. To strengthen empirical validation, we encourage the authors to conduct experiments on a wider range of datasets and models. Furthermore, simplifying the theoretical exposition could enhance accessibility for a broader audience, ensuring that the innovative aspects of RFD are clearly communicated.