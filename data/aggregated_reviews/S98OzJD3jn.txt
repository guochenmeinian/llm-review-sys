ID: S98OzJD3jn
Title: Diffusion Tuning: Transferring Diffusion Models via Chain of Forgetting
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 5, 6, 5, 6, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Diff-Tuning method, which aims to enhance the fine-tuning of pre-trained diffusion models while retaining their denoising capabilities. The authors observe that different time steps in the denoising process exhibit varying transferability, with low-noise steps being more effective for knowledge retention. Diff-Tuning shows improved convergence speed and performance compared to standard fine-tuning methods and is compatible with existing parameter-efficient techniques.

### Strengths and Weaknesses
Strengths:
- The concept of utilizing the pre-trained model as a universal denoiser for lightly corrupted data is intriguing.
- Diff-Tuning demonstrates faster training and superior performance relative to traditional fine-tuning approaches.
- The paper offers novel theoretical insights into the chain of forgetting in diffusion models.

Weaknesses:
- The novelty is somewhat limited, as similar findings regarding gradient conflicts in diffusion models have been reported in prior works. The authors need to clarify how their contributions differ from these studies.
- The robustness of Diff-Tuning across various sampling algorithms and diffusion models remains unverified.
- The motivation for using augmented datasets for knowledge retention is unclear, and the authors should consider discussing the potential benefits of knowledge distillation instead.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their contributions by explicitly highlighting the differences between their work and previous studies on diffusion models. Additionally, the authors should validate the robustness of Diff-Tuning across various sampling algorithms and diffusion models. It would be beneficial to provide more metrics for class-conditional generation to substantiate claims of improved image quality. Furthermore, we suggest that the authors explore the use of knowledge distillation as an alternative to augmented datasets for knowledge retention, as this may mitigate potential biases in the fine-tuning process. Lastly, a more detailed discussion on hyperparameter settings and their implications would enhance the paper's rigor.