ID: e0SQ6wsHjv
Title: Dynamic Tuning Towards Parameter and Inference Efficiency for ViT Adaptation
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 5, 7, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Dynamic Tuning (DyT), a method aimed at enhancing both parameter and inference efficiency for Vision Transformer (ViT) adaptation through a parameter-efficient fine-tuning (PEFT) approach. DyT incorporates a token dispatcher that dynamically determines token activation and a Mixture of Experts (MoE) adapter to improve performance while maintaining computational efficiency. The authors evaluate DyT across various visual tasks, including semantic segmentation and object detection, demonstrating its effectiveness and efficiency compared to existing PEFT methods. They clarify that the model's FLOPs may fluctuate due to the learned token dispatcher and assert that the MoE adapter's computational cost is comparable to traditional adapters. The authors also highlight the advantages of dynamic architectures in improving generalization and performance, while addressing concerns about increased training time due to the need for two forward passes.

### Strengths and Weaknesses
Strengths:
- The paper provides extensive experimental results on image and video tasks, validating the proposed method's effectiveness.
- The combination of token pruning and PEFT techniques leads to significant experimental results.
- It addresses the important issue of inference efficiency, which is often overlooked in mainstream PEFT methods.
- The dynamic architecture enhances generalization and performance, supported by previous works.
- The writing is clear and the figures are well-presented, aiding comprehension of the proposed method.
- The authors are responsive to reviewer concerns and willing to incorporate feedback into revisions.

Weaknesses:
- The novelty of DyT is questionable, as its core components, such as the token dispatcher and MoE adapter, bear similarities to prior works, including Conditional Adapters and AdaMix.
- The application of MoE appears to enhance performance only in specific tasks, and its inclusion lacks sufficient analysis, raising concerns about its overall contribution.
- Certain experimental results, particularly regarding FLOPs, are counterintuitive and require further clarification.
- The data-dependent FLOPs may not be practical under specific resource constraints, and the novelty of the token pruning and PEFT concepts may be questioned, as they are not entirely new.

### Suggestions for Improvement
We recommend that the authors improve the novelty discussion by clearly articulating how DyT differentiates itself from existing methods like Conditional Adapters and AdaMix. Additionally, we suggest providing a detailed analysis of the MoE's contribution to performance, especially in image classification tasks, and consider removing it if it does not significantly enhance the overall method. The authors should also address the discrepancies in reported FLOPs and include an ablation study on the loss function to elucidate its impact on performance. Furthermore, we recommend improving the discussion of the implications of data-dependent FLOPs, particularly regarding their practicality in resource-constrained environments. Lastly, including a thorough discussion of related works such as DynamicViT and EViT in the final version would provide valuable context for the proposed approach.