ID: OV8YUk151r
Title: HLM-Cite: Hybrid Language Model Workflow for Text-based Scientific Citation Prediction
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 6, 4, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents HLM-Cite, a Hybrid Language Model workflow for citation prediction that distinguishes core citations from superficial citations and non-citations, moving beyond a simple binary classification approach. The method efficiently handles candidate sets of up to 100K papers and demonstrates a 17.6% performance improvement over state-of-the-art methods. The authors utilize a two-stage pipeline that first retrieves high-likelihood core citations using a pretrained embedding model and then ranks them through reasoning with LLMs.

### Strengths and Weaknesses
Strengths:
- The paper expands the citation prediction task by introducing the concept of core citations, which are crucial for understanding the foundational elements of research.
- The design incorporates a retrieval module and an LLM agentic ranking module, allowing for efficient handling of large candidate sets.
- Extensive experiments validate the method's effectiveness, showing strong performance compared to existing models.
- The paper is well-structured and clearly presented.

Weaknesses:
- The definition of core citations lacks novelty, as similar classification systems have been proposed previously; the authors should acknowledge this existing body of work.
- The methodology may be overly complex, and simpler approaches, such as core-periphery algorithms from network science, could be considered.
- Some scientific language model baselines are missing from the comparisons, and statistical significance tests are not conducted to validate performance differences.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the terminology in Section 2.1 by simplifying the use of superscripts and subscripts. Additionally, we suggest that the authors acknowledge existing citation classification systems to contextualize their contributions. It would also be beneficial to include comparisons with models like SPECTER 2.0 and SciMult, and to conduct statistical significance tests to support their findings. Furthermore, consider exploring simpler baseline methods for citation prediction to demonstrate the necessity of their complex approach.