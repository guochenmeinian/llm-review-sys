ID: o3wQbxRaKo
Title: Epistemic Integrity in Large Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 2
Original Ratings: 7, 7
Original Confidences: 4, 3

Aggregated Review:
### Key Points
This paper presents the issue of miscalibration between LLMs' internal certainty and their linguistic assertiveness. The authors introduce a human-labeled dataset and a novel method to measure this mismatch, demonstrating a significant disparity between a modelâ€™s actual confidence and its output. The study reveals that current LLMs exhibit a notable difference between internal and external certainty, which influences how users perceive the results.

### Strengths and Weaknesses
Strengths:
1. The research question is compelling, offering a fresh perspective on the gap between internal certainty and linguistic assertiveness, which is crucial for improving LLM regulation and safety.
2. The study is well-executed, with robust findings across multiple datasets and a human-centered analysis through an online survey, enhancing the relevance of the results.
3. The introduction of the epistemic calibration problem is novel, and the fine-tuned GPT-4o model is well documented, with sound experiments providing strong evidence for the claims.

Weaknesses:
1. The focus on misinformation within political statements limits the generalizability of the findings; a broader scope including other domains would enhance understanding.
2. The correlation reported in Table 1 lacks clarity regarding the criteria for interpreting "strong" correlations, as p-values are missing, leaving statistical significance ambiguous.
3. The paper relies heavily on the appendix, with figures not integrated into the main text, complicating the overall readability.
4. The analysis of later figures could be better connected to the main points, and while multiple approaches to calculating internal certainty are discussed, only one is evaluated without justification for this choice.

### Suggestions for Improvement
We recommend that the authors broaden the study's scope to include other domains such as medical, legal, or scientific statements to enhance generalizability. We also suggest clarifying the criteria for interpreting correlation strengths and including p-values to establish statistical significance. Integrating figures into the main text would improve readability, and better connecting the analysis of later figures to the main arguments would strengthen the paper. Additionally, we encourage the authors to evaluate other approaches to calculating internal certainty discussed in Section 2.1.1 to provide a more comprehensive analysis.