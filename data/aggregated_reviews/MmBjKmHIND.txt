ID: MmBjKmHIND
Title: Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into the effectiveness of synthetic data generated by Large Language Models (LLMs) for text classification tasks, particularly focusing on the impact of subjectivity. The authors empirically demonstrate that tasks with higher subjectivity yield less effective synthetic training data. The study includes a variety of experiments and human evaluations, concluding that LLMs perform well on less complex datasets, such as news and reviews, compared to more subjective datasets like humor.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and provides a comprehensive analysis of the subjectivity in classification tasks.
- Empirical findings convincingly support the hypothesis that zero-shot synthetic data performs worse than few-shot data.
- The inclusion of diverse NLP classification tasks enhances the paper's contribution to the field.

Weaknesses:
- The novelty and insights are limited, making the paper more suitable for a shorter format.
- The experimental setup may seem artificial, as the authors use a smaller model for classification instead of leveraging the LLM for both data generation and classification.
- The reliance on a single LLM model raises questions about the generalizability of the results.

### Suggestions for Improvement
We recommend that the authors improve the robustness of their findings by conducting additional experiments with larger decoder-based models in the 500M-750M parameter range to validate their conclusions. Additionally, we suggest exploring the sensitivity of results to different prompts used for LLM data generation, as well as considering a setup with multiple generation chains to assess the quality of synthetic examples. Furthermore, addressing the potential artifact of LLM training data familiarity in relation to dataset subjectivity should be included in the limitations section. Lastly, we encourage the authors to make the generated data available for further evaluation by other research groups.