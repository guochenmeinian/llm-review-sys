ID: kj4MRgh2K5
Title: Transparency at the Source: Evaluating and Interpreting Language Models With Access to the True Distribution
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for training language models (LMs) on synthetic data generated from a probabilistic context-free grammar (PCFG). The authors argue that their large PCFG provides a better approximation of true English, allowing for the comparison of LM perplexities to a known lower bound. They find significant differences between causal and masked LM objectives in their correlation with true probabilities and analyze the learning dynamics of word classes during training.

### Strengths and Weaknesses
Strengths:
- The paper offers an innovative approach to evaluating LMs using synthetic data, contributing a large-scale PCFG and dataset.
- It provides a theoretical contribution through a closed-form expression for computing lower bounds on perplexity.
- The experimental analysis is thorough, revealing interesting findings about the correlation of LMs with PCFG probabilities.

Weaknesses:
- The relevance of using PCFGs as a base distribution is questioned, as they may not effectively capture natural language variation.
- The paper lacks a comparative analysis of perplexities between the synthetic corpus and natural language datasets.
- The interpretability claims regarding PCFGs are not sufficiently supported, and the training dynamics of POS tags are oversimplified.

### Suggestions for Improvement
We recommend that the authors improve the justification for using PCFGs as a base distribution by providing comparative analyses of perplexities on natural language datasets. Additionally, the authors should address the limitations of PCFGs in capturing natural linguistic phenomena and expand on how their findings can inform future interpretability research. Clarifying the methodology for comparing LM distributions with PCFG-generated data would also enhance the paper's clarity and impact.