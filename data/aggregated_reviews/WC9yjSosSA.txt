ID: WC9yjSosSA
Title: ESPVR: Entity Spans Position Visual Regions for Multimodal Named Entity Recognition
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to multimodal named entity recognition (MNER) called Entity Spans Position Visual Regions (ESPVR), which aims to effectively capture relevant visual regions for entities in text. The ESPVR module consists of two components: the Entity Span Identification (ESI) module and the Visual Regions Positioning (VRP) module. Experimental results indicate that the proposed method outperforms state-of-the-art techniques on the Twitter-2017 dataset and shows competitive performance on Twitter-2015. The authors argue that their method addresses significant challenges in existing MNER models, particularly the limitations of attention mechanisms that fail to focus on the most relevant visual areas.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and presents a clear motivation for addressing challenges in MNER.
- The ESPVR model features a rich architecture that integrates visual and textual information, employing BERT and Swin Transformer effectively.
- The methodology is supported by a comprehensive set of experiments, including quantitative and qualitative assessments.

Weaknesses:
- The motivation lacks convincing practical examples, and the argument regarding attention mechanisms is contradictory since the VRP module also relies on attention.
- The experimental results do not strongly demonstrate the effectiveness of the proposed method, with only a subset of evaluation metrics achieving state-of-the-art performance.
- The dataset used for experimentation lacks diversity, primarily relying on Twitter data, which raises concerns about the generalizability of the findings.

### Suggestions for Improvement
We recommend that the authors improve the motivation section by providing practical examples to support their arguments. Additionally, including a visualization experiment would enhance the demonstration of the ESPVR module's effectiveness in capturing relevant visual parts for text entities. The authors should also clarify the implementation details, such as the learnability of the lambda value mentioned and the relative importance of the ESI and MNER losses during joint training. Lastly, addressing the dataset's diversity and providing evidence for the model's performance on Twitter-2015 would strengthen the paper's claims.