ID: HXdAfK488A
Title: Doing Experiments and Revising Rules with Natural Language and Probabilistic Reasoning
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 4, 7, 7, 7, -1, -1, -1
Original Confidences: 4, 3, 4, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an integration of a Large Language Model (LLM) within a Sequential Monte Carlo (SMC) algorithm, where the LLM serves as both the proposal distribution and evaluator for cognitive psychology tasks, specifically Zendo and ActiveACRE. The authors demonstrate that the Online, Hard variant of SMC outperforms other SMC variants in identifying the best latent rule, while the Online, Fuzzy variant aligns more closely with human data. However, the LLM-based proposers do not surpass the InfoGain algorithm, and a random proposer outperforms the LLM methods, indicating a significant performance gap.

### Strengths and Weaknesses
Strengths:
- The proposed method effectively illustrates the benefits of combining Bayesian methods with LLMs, showcasing a novel approach to inductive hypothesis generation and experimentation.
- The paper is well-structured, with clear descriptions of methods and relevant comparisons to established baselines.

Weaknesses:
- The enhancement in problem-solving capability and alignment with human data is not convincingly demonstrated, particularly the LLM's role as an active learner, which underperforms compared to a random active learner.
- The comparison between human and model performance lacks depth, with insufficient reporting of free parameters and model fitting details.
- The evidence for the bounded rationality model presented in Figure 7 is weak, relying on limited data points.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the roles of the LLMs (proposer, evaluator, and active learner) in their method. Additionally, providing more detailed comparisons of human and model performance, including reporting scores such as BIC or cross-validation results, would enhance the analysis. We suggest including ablations that illustrate the role of natural language hypothesis spaces and addressing potential issues of particle degeneracy. Furthermore, the authors should consider adding a more realistic domain for their experiments and clarifying the description of baselines and figures for better comprehension.