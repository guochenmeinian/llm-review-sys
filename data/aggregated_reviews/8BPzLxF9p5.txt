ID: 8BPzLxF9p5
Title: Label-efficient Segmentation via Affinity Propagation
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 5, 5, 5, 5, 4, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel universal component for weakly-supervised segmentation by formulating it as an affinity propagation process. The authors propose both global and local pairwise affinity terms to generate soft pseudo labels and develop an efficient algorithm to reduce computational costs. The effectiveness of the proposed method is demonstrated through experiments on various label-efficient segmentation tasks, achieving superior performance compared to prior works.

### Strengths and Weaknesses
Strengths:
1. The framework effectively utilizes both global and local pairwise affinity terms, leading to superior performance.
2. The efficient implementation of global affinity propagation significantly reduces computational costs.
3. The approach can be easily integrated into existing segmentation networks.
4. The experiments are extensive, covering multiple label-efficient segmentation tasks.

Weaknesses:
1. The approach appears to be parameter-sensitive, with slight variations in $\zeta_s$ and $\zeta_g$ potentially causing notable fluctuations in segmentation performance. Consistency in parameter usage across tasks and datasets is questioned.
2. The overall efficiency of the framework is not intuitive; the authors should clarify whether introducing both affinity terms significantly impacts efficiency and present changes in training time with/without APro.
3. The affinity definitions based on pixel intensity may be limiting due to sensitivity to lighting and noise; incorporating deep features from self-supervised networks could be beneficial.
4. The method lacks scalability, as the affinity is fixed to low-level color differences, which may hinder performance in open-vocabulary segmentation tasks.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by providing graphical illustrations to demonstrate the global and local affinity propagation schemes. Additionally, the authors should address the novelty of their method by clearly differentiating it from existing approaches, particularly in terms of affinity modeling and the efficiency of their algorithm. It would also be beneficial to include a comprehensive comparison of their method's performance with previous approaches to highlight its advantages. Finally, the authors should explore the effects of incorporating deep features and provide runtime details in Table 7, including iterations, batch size, and device specifications.