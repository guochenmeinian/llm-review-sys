ID: pjD08dtAh0
Title: HumanVLA: Towards Vision-Language Directed Object Rearrangement by Physical Humanoid
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 6, 6, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a vision-language-action (VLA) model designed to control a humanoid for interacting with dynamic objects without relying on ground-truth state information. The authors propose a teacher-student framework where a teacher policy is trained using privileged state information and then distilled into a student policy that operates based on high-level language instructions and ego-centric images. The paper introduces a new dataset for evaluating the framework and demonstrates its effectiveness against a recent baseline.

### Strengths and Weaknesses
Strengths:
- The work is well-motivated, addressing the challenges of dynamic object interaction and the absence of ground-truth state information.
- The method shows promising results in demo videos and quantitative evaluations, with well-justified components.
- The dataset created can serve as a valuable resource for future research.

Weaknesses:
- The complexity of the system, combining multiple existing methods, raises questions about its generalizability to broader humanoid-object interactions and scenarios involving multiple objects or agents.
- There is insufficient discussion on the limitations and potential failure modes of the proposed method.
- The qualitative evaluation is lacking, with only a few demo videos provided and no baseline comparisons shown.
- The paper does not adequately address the sim2real gap or the agent's planning capabilities, particularly in novel environments.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the limitations and potential failure modes of the proposed method. Additionally, it would be beneficial to provide videos of baseline results for clearer comparisons. We urge the authors to clarify how the agent plans its path in new environments, especially given its reliance on active rendering. Furthermore, we suggest investigating the generalization capabilities of the policy to unseen tasks and environments, and providing insights into how the agent recognizes target locations without waypoint information. Lastly, we recommend scaling down claims regarding the method's capabilities in handling unseen scenarios until further evidence is provided.