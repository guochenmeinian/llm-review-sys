ID: WhE4C4fLbE
Title: CHASE: Learning Convex Hull Adaptive Shift for Skeleton-based Multi-Entity Action Recognition
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 6, 6, 4, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to address inter-entity distribution discrepancies in multi-entity action recognition through the convex hull adaptive shift method. The authors introduce CLB and MPMMD to enhance the learning process, demonstrating the method's effectiveness across various datasets and backbones. Additionally, the paper proposes CHASE, a skeleton data augmentation technique that formulates a new constraint, ICHAS, and employs a lightweight block CLB for nonlinear mapping and discrepancy minimization.

### Strengths and Weaknesses
Strengths:
1. The paper introduces an innovative idea of using implicit convex hull constraints for adaptive coordinate shifts.
2. The proposed methods are validated across multiple datasets and architectures.
3. The work contributes significantly to the skeleton-based human action recognition field.

Weaknesses:
1. The introduction lacks clarity regarding the necessity of discrepancy minimization and sample adaptive coefficients, requiring improved motivation and insights.
2. The novelty of the CLB is questionable, as its format is commonly used in existing concept learners, necessitating a clearer distinction from concept bottleneck models.
3. Section 4.2 requires deeper insights into the benefits of the proposed method and its computational complexity.
4. Presentation issues exist, including typos and unclear figure captions, which detract from the overall clarity.

### Suggestions for Improvement
We recommend that the authors improve the introduction by clearly articulating the necessity of achieving discrepancy minimization (line 54) and sample adaptive coefficients (line 52), along with enhancing the motivation and connections among proposed items (lines 57-60). 

Additionally, the authors should clarify how the CLB differs from existing concept learners, particularly in relation to the concept bottleneck models discussed in Shin et al. (2023), and explore whether using a concept learner from existing works (e.g., Wang et al. (2023)) would yield better results.

In Section 4.2, we encourage the authors to provide a more detailed analysis of why the proposed method is beneficial and to discuss the computational complexity introduced by their approach.

Lastly, we suggest revising the presentation to address typos and improve figure captions for better clarity.