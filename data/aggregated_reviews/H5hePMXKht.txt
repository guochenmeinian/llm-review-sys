ID: H5hePMXKht
Title: Reasoning in Reasoning: A Hierarchical Framework for Better and Faster Neural Theorem Proving
Conference: NeurIPS
Year: 2024
Number of Reviews: 4
Original Ratings: 9, 7, 5, 5
Original Confidences: 4, 3, 4, 3

Aggregated Review:
### Key Points
This paper presents the "Reasoning in Reasoning" (RiR) framework, aimed at enhancing neural theorem proving through hierarchical problem decomposition and goal-driven search. RiR effectively addresses complex reasoning tasks by breaking them into manageable sub-goals, thereby improving generalization and efficiency. The framework employs a planner-actor game structure and integrates offline co-training with online planning, demonstrating state-of-the-art performance on benchmarks such as LeanDojo and miniF2F.

### Strengths and Weaknesses
Strengths:  
- The hierarchical combination of decomposition and search effectively narrows the search space, enhancing performance on challenging tasks.  
- RiR shows significantly faster performance and improved accuracy compared to existing baselines, particularly on the miniF2F benchmark.  
- The authors provide code, which enhances reproducibility and credibility.  
- The paper includes substantial mathematical proofs supporting its claims.

Weaknesses:  
- The generalizability of RiR to other reasoning tasks remains unclear, necessitating further discussion in the introduction and conclusion.  
- The evaluation is limited to specific benchmarks and metrics, such as Pass@1, which may not fully validate the authors' claims of superiority.  
- The framework's reliance on accurate goal selection could lead to inefficiencies if goals are misestimated.  
- The paper lacks a thorough analysis of failure cases, which is essential for understanding limitations and guiding future improvements.  
- There is an inconsistency in the presentation of high-level planning updates in the figures.

### Suggestions for Improvement
We recommend that the authors improve the generalizability discussion of RiR in the introduction and conclusion to clarify its applicability to other reasoning tasks. We suggest incorporating empirical investigations to validate the Co-Training Advantage Conjecture and Hierarchical Planning Advantage Conjecture, enhancing the credibility of the theoretical insights. Additionally, a thorough analysis of RiRâ€™s failure cases should be included to provide a balanced view of its limitations. We also recommend comparing RiR with other existing hierarchical or goal-conditioned reinforcement learning techniques to strengthen the evaluation. Finally, the authors should expand their evaluation metrics to include Pass@5 and Pass@10 across a broader range of benchmarks, as well as provide more comprehensive execution time comparisons and results under diverse settings.