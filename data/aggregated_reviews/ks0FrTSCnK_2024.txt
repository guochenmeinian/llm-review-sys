ID: ks0FrTSCnK
Title: Rethinking Open-set Noise in Learning with Noisy Labels
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 4, 6, 5, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 2, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper extends the problem setting of learning with noisy labels (LNL) to include open-set noise, where noisy labels may originate from unknown categories, contrasting with traditional closed-set noise. The authors theoretically analyze the effects of open-set versus closed-set noise and propose detection mechanisms based on prediction entropy. They introduce two open-set noisy datasets, CIFAR100-O and ImageNet-O, and an open-set test set for the WebVision benchmark to validate their findings. Results indicate that open-set noise has distinct characteristics from closed-set noise, highlighting the necessity for comprehensive evaluation methods in the presence of open-set noise.

### Strengths and Weaknesses
Strengths:  
- The research problem is interesting and under-explored compared to closed-set noise.  
- The theoretical analysis appears solid, providing valuable insights into the nature of open-set noise.  
- The paper is well-structured and clear, facilitating understanding of complex concepts.  

Weaknesses:  
- Some technical details are difficult to follow, and the writing requires polishing.  
- The contribution from an algorithmic perspective is insufficient, lacking practical guidance on estimating the transition matrix and utilizing open-set data for model robustness.  
- The review of existing methods combining unsupervised and semi-supervised learning is not comprehensive.  

### Suggestions for Improvement
We recommend that the authors improve the clarity of technical details and enhance the overall writing quality. Additionally, the authors should provide more insights into the assumption that noisy labeling does not affect the sampling prior and clarify how the size of the open-set label space affects theoretical analysis. It would be beneficial to include discussions on the methods combining unsupervised and semi-supervised learning and to run previous baselines on easy open-set noise to establish performance benchmarks. Finally, the authors should elaborate on the method of predicting entropy values and its relation to OOD detection, as well as address the gaps in the experimental scope by testing on more varied real-world datasets.