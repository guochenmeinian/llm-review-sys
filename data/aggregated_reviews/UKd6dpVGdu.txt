ID: UKd6dpVGdu
Title: Learning to Tokenize for Generative Retrieval
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 6, 5, 7, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents GENRET, a novel document tokenization learning framework that tokenizes documents into semantic docids using a discrete auto-encoding scheme. The framework integrates a sequence-to-sequence-based document tokenization model, a generative retrieval model, and a reconstruction model, optimized through a progressive training scheme. Experimental results indicate that GENRET significantly outperforms baseline methods, particularly in generalizing to unseen documents.

### Strengths and Weaknesses
Strengths:
1. The authors address a critical issue in generative retrieval by proposing a learnable document tokenization module, which captures the semantics of documents more effectively than traditional fixed methods.
2. The integration of an auto-encoding scheme and a progressive training approach enhances the stability of the training process and the diversity of generated docids.
3. Comprehensive experiments demonstrate the method's superiority over established document retrieval techniques.

Weaknesses:
1. The method description lacks clarity, particularly regarding the optimization of the reconstruction model and the relationship between the generative retrieval model and the document tokenization model.
2. The evaluation primarily relies on quantitative measures, with a lack of qualitative analysis to support claims about the effectiveness of the learned docids.

### Suggestions for Improvement
We recommend that the authors improve the presentation of the method description, particularly in Section 3, to clarify the optimization targets of the reconstruction model and the relationship between the models. Additionally, we suggest including qualitative experiments, such as visualization analysis, to demonstrate the distribution of codebook embeddings and the diversity of generated docids compared to baselines. Furthermore, addressing the questions regarding the training of the 'GENRET w/o learning' model and the selection of the docid length \( M \) for different datasets would enhance the paper's clarity and depth.