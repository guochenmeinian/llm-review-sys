ID: PnAmH1silV
Title: On Bilingual Lexicon Induction with Large Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into bilingual lexicon induction (BLI) using large language models (LLMs), marking the first exploration of this task with multilingual LLMs. The authors compare various models, including encoder-decoder and decoder-only types, and utilize different prompting strategies in zero- and few-shot setups. The study includes comprehensive experiments across multiple language pairs, revealing strong performance for high-resource languages while highlighting challenges in low-resource scenarios. The work contributes novel techniques, such as in-context learning with nearest neighbors and prompt templates.

### Strengths and Weaknesses
Strengths:
- The paper is well-structured, detailed, and easy to follow, providing a thorough examination of LLMs for BLI.
- It includes a comprehensive set of experiments across 20 high-resource and 6 low-resource language pairs, comparing against strong baselines.
- Reviewers noted the significant contribution of explicit evaluations on BLI benchmarks.

Weaknesses:
- The selection of languages appears opportunistic rather than systematic, with a predominance of Indo-European languages; this needs clarification.
- The performance in low-resource scenarios is subpar, echoing known issues with previous BLI approaches.
- There is a lack of insights into the stability of results, with no mention of repeated experiments or the influence of randomness on outcomes.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the language selection criteria, explicitly addressing the opportunistic nature of the chosen languages. Additionally, the authors should provide insights into the stability of their results by including information on repeated experiments and standard deviations alongside mean scores in their tables and figures. Furthermore, addressing the performance of LLMs in low-resource scenarios and the potential bias towards dominant languages like English would enhance the paper's depth. Lastly, clarification of the text in Appendix D is needed for better comprehension.