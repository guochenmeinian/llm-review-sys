ID: EmYWJsyad4
Title: Conditional Mutual Information for Disentangled Representations in Reinforcement Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 7
Original Ratings: 7, 7, 8, 5, -1, -1, -1
Original Confidences: 3, 2, 4, 3, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to disentanglement in reinforcement learning (RL), addressing the challenge of spurious correlations in high-dimensional observations. The authors propose an auxiliary task termed Conditional Mutual Information for Disentanglement (CMID), which minimizes conditional mutual information between dimensions in the latent representation. This method enhances training and generalization performance of the base RL algorithm SVEA and outperforms other state-of-the-art baselines, particularly in scenarios where correlations shift.

### Strengths and Weaknesses
Strengths:
- The paper is meticulously written with a clear structure, making it easy to comprehend.
- The proposed method, CMID, is versatile and can be integrated with any model-free RL algorithm, enhancing its practical relevance.
- Experimental results provide persuasive evidence of the method's effectiveness, demonstrating improvements in training performance and zero-shot generalization.
- The analysis of agent attributions offers valuable qualitative insights into the learned representations.

Weaknesses:
- The experiments are somewhat limited, focusing primarily on four DMC tasks with minimal variations, raising concerns about generalizability.
- A significant portion of the experimental section is relegated to the appendix, making the main text less readable.
- There is a lack of direct qualitative or quantitative evaluation of the disentanglement effectiveness, which could strengthen the paper's claims.
- The computational overhead from the adversarial loss computation could be quantified for better clarity.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their experiments by evaluating the proposed method on additional RL algorithms beyond SVEA and in more complex domains with intricate correlations. Additionally, we suggest that the authors streamline the experimental section to ensure the main text is self-contained and comprehensible without frequent reference to the appendix. To enhance the evaluation of disentanglement effectiveness, we encourage the authors to conduct experiments measuring the impact of specific factors on the learned representations. Finally, quantifying the computational overhead associated with the adversarial loss would provide valuable insights into the method's efficiency.