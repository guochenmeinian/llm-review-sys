ID: X6dEqXIsEW
Title: On the Planning Abilities of Large Language Models - A Critical Investigation
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 5, 8, 8, 8, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 5, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a systematic evaluation of the planning abilities of large language models (LLMs), particularly focusing on the GPT series, across two distinct modes: autonomous planning and heuristic planning. The authors investigate LLMs' performance on standardized planning problems, revealing that while LLMs struggle as autonomous planners, they perform significantly better in heuristic mode, achieving high scores with the aid of feedback mechanisms. The study employs sophisticated prompting techniques and evaluates multiple LLMs, including GPT-4, across various benchmarks.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, clear, and provides a comprehensive evaluation method for LLM planning abilities, integrating traditional planning benchmarks and reasoners effectively.
- The choice of planning domains is relevant, and the results offer valuable insights into leveraging LLMs in practical applications.
- The prompting mechanism is sophisticated and well-justified, enhancing the overall experimental design.

Weaknesses:
- Some conclusions, such as the benefits of re-planning, lack novelty as they have been previously explored in robotics and planning literature, and the authors overlook existing algorithms that enhance LLM planning capabilities.
- The investigation does not adequately address GPT's strengths in zero-shot or few-shot settings, and the evaluation metrics may not fairly represent the model's capabilities; human evaluation should be included for a more comprehensive assessment.
- The analysis is limited to OpenAI's GPT models, neglecting open-source models like LLaMA and Vicuna, which could provide a broader understanding of planning capabilities across different LLMs.
- The experiments primarily focus on zero-shot and one-shot prompting, lacking an ablation study to explore the impact of varying the number of demonstrations on planning performance.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their conclusions by acknowledging and discussing existing algorithms that enhance LLM planning capabilities. Additionally, the authors should consider incorporating human evaluation metrics to provide a more balanced assessment of GPT's performance. Expanding the analysis to include open-source models like LLaMA and Vicuna would enrich the findings. Furthermore, conducting ablation experiments to investigate the effects of different prompting strategies on planning performance would be beneficial. Lastly, ensuring that all relevant literature is cited will strengthen the paper's contributions.