ID: NeLC3TDnvV
Title: ImageScope: Unifying Language-Guided Image Retrieval via Large Multimodal Model Collective Reasoning
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a unified framework for language-guided image retrieval (LGIR) that integrates various tasks such as text-to-image retrieval, composed image retrieval, and chat-based image retrieval. The authors propose a prompt-based three-stage framework utilizing pre-trained vision large language models (LMMs) to address the complexities of separate systems, aiming to streamline LGIR tasks while enhancing retrieval accuracy and robustness. The effectiveness of the proposed method is validated through experiments.

### Strengths and Weaknesses
Strengths:
1. The work is original and relevant, addressing a significant challenge in LGIR with a well-defined research question.
2. The proposed framework effectively unifies multiple LGIR tasks without requiring training, leveraging the capabilities of large language models.
3. The paper is clearly written and well-structured, facilitating understanding of the framework and its contributions.

Weaknesses:
1. The integration of five large pre-trained models raises concerns about system complexity and cost, potentially undermining the goal of simplifying LGIR systems.
2. The performance improvement over smaller models is modest, raising questions about whether gains are due to the innovative framework or simply the increased size of models.
3. Some sections lack clarity, which may hinder reader comprehension, particularly regarding the CoT-based semantic synthesis process and the ablation study of parameter impacts.

### Suggestions for Improvement
We recommend that the authors improve the clarity of sections that are currently difficult to understand, particularly the CoT-based semantic synthesis process and the ablation study. Additionally, addressing the concerns regarding the framework's complexity and cost is essential; specifically, the authors should justify how integrating five large models addresses the identified challenges in LGIR tasks. Furthermore, we suggest providing more detailed analysis on the parameter settings used in the framework, as well as clarifying the significance of performance gains relative to smaller models like CIReVL.