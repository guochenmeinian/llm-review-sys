ID: syj9VaxutQ
Title: A Framework for Exploring Player Perceptions of LLM-Generated Dialogue in Commercial Video Games
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a user study comparing LLM-generated dialogue with human expert-generated text within the context of the video game Disco Elysium. The authors propose a task design for evaluating GPT-4's output against human contributions, utilizing a specially designed interface and a targeted group of players to gather data. The study aims to assess the feasibility of using LLMs for generating character contributions in role-playing games, focusing on the dialogue infilling task where LLMs modify existing dialogue to fit the game state.

### Strengths and Weaknesses
Strengths:
- The task setup is meaningful and directly relevant to evaluating LLM applications in video games.
- The study effectively compares GPT-4 output with human-generated text in a well-defined context.
- The extensive data collection involved a dedicated participant group, enhancing the study's depth.

Weaknesses:
- The evaluation setup is specific to Disco Elysium, raising concerns about generalizability to other games.
- The final dataset analyzed is small, with only a hundred contributions receiving three judgments, which weakens the results.
- The heterogeneity of the rater group, influenced by play style and experience, further complicates generalizability.
- Familiarity bias among raters, who had prior experience with the game, may have affected their judgments.
- The related works section lacks references to studies comparing LLM output with human output.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their findings by discussing how this evaluation setup could be adapted for other games. Additionally, we suggest increasing the dataset size to strengthen the results and addressing the potential impact of familiarity bias in the study. The authors should also expand the related works section to include references on LLM-generated dialogue contributions. Furthermore, we encourage the inclusion of details on power analysis and demographic information about participants in the final version. Lastly, clarifying the role of Lua scripts and providing definitions for specific terms would enhance the paper's accessibility.