ID: abuQMKDVkW
Title: SARDet-100K: Towards Open-Source Benchmark and ToolKit for Large-Scale SAR Object Detection
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 8, 7, 7, 7, -1, -1, -1
Original Confidences: 5, 5, 5, 5, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the SARDet-100K dataset, a large-scale, multi-class benchmark for SAR object detection, and introduces the Multi-Stage with Filter Augmentation (MSFA) pretraining framework. The authors address the limitations of existing datasets and the inaccessibility of source codes, significantly contributing to the field of SAR object detection by providing a standardized dataset and an effective pretraining method that bridges the domain gaps between RGB and SAR datasets.

### Strengths and Weaknesses
Strengths:  
1. The creation of the SARDet-100K dataset is a significant contribution, offering a large-scale, diverse resource that was previously lacking in the field.  
2. The open-source codebase enhances reproducibility and facilitates further innovation, addressing the scarcity of public SAR datasets.  
3. The MSFA method's innovative use of traditional handcrafted features for pretraining and domain transformation is a refreshing approach compared to previous deep learning-focused methods.  
4. The paper provides thorough experiments and analyses validating the effectiveness of the proposed method.

Weaknesses:  
1. The paper lacks discussion on jointly training the DOTA and SARDet-100K datasets, which could improve detection performance.  
2. Clarification is needed regarding whether the reported metrics are for the test or validation set, and the training settings should be specified.  
3. Actual runtimes and memory usage are not reported, which is essential for a benchmark dataset and method.  
4. The introduction of handcrafted features is insufficiently detailed, potentially confusing junior researchers unfamiliar with these concepts.  
5. The category distribution in SARDet-100K is imbalanced, raising concerns about the long-tail problem affecting model performance.

### Suggestions for Improvement
We recommend that the authors improve the discussion on joint training of the DOTA and SARDet-100K datasets to enhance model performance. Additionally, please clarify whether the metrics reported are for the test or validation set and specify the training settings used. It is also crucial to include actual runtimes and memory usage in the paper. We suggest providing a more comprehensive introduction to the handcrafted features, including conceptual visualizations, to aid understanding. Lastly, consider addressing the dataset's imbalance to mitigate potential performance issues on tail categories.