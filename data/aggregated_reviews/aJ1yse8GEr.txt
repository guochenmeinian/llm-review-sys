ID: aJ1yse8GEr
Title: GlotCC: An Open Broad-Coverage CommonCrawl Corpus and Pipeline for Minority Languages
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 6, 7, 6
Original Confidences: 4, 4, 4

Aggregated Review:
### Key Points
This paper presents a new pipeline for extracting multilingual text from CommonCrawl, addressing limitations of current language identification (LID) models by covering more languages and identifying web noise to prevent misidentification. The authors propose GlotCC, a large-scale web dataset containing documents in over a thousand languages, and demonstrate an effective language identification approach on intrinsic benchmarks.

### Strengths and Weaknesses
Strengths:
- The work significantly increases the coverage of languages identified from web text without compromising computational efficiency.
- The release of GlotCC and the open-source pipeline provides valuable resources for low-resource language studies and multilingual modeling.

Weaknesses:
- The application of the proposed method to curate GlotCC lacks thorough evaluation, with no intrinsic metrics or downstream applications discussed.
- The manuscript does not compare GlotLID v3 with other language identification techniques, such as MADLAD, and lacks comprehensive evaluation metrics for GlotCC.

### Suggestions for Improvement
We recommend that the authors improve clarity regarding the specific failure modes of FastText highlighted in the introduction. In Section 2.1.2, consider evaluating a bloom filter implementation to reduce memory footprint for rare n-grams or using featurization via BPE with byte fallback. In Section 2.1.3, discuss the applicability of the identified issues to other internet sources. In Section 2.4, include comparisons of GlotLID v3 with other techniques. Additionally, in Section 3, address potential issues from relying on the OSCAR pipeline instead of modern parsers. We suggest validating the effectiveness of the steps used to curate GlotCC and providing summary statistics of related corpora. A more comprehensive evaluation of GlotLID on documents from GlotCC is necessary, as is exploring efficient deduplication methods. Finally, we encourage the authors to conduct experiments on training LLMs with GlotCC, such as continue-training Llama with its partitions and performing ablation studies.