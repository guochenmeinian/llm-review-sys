ID: F1mv2L7Rkb
Title: Invariant Anomaly Detection under Distribution Shifts: A Causal Perspective
Conference: NeurIPS
Year: 2023
Number of Reviews: 18
Original Ratings: 4, 6, 5, 4, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for anomaly detection under distribution shifts by formalizing the problem using causal inference and an information theory perspective. The authors introduce a regularization term to ensure partial distribution invariance across environments, leading to the development of Corollary 1 and the principle of partial conditional invariance. They argue that existing invariant representation learning methods, such as IRM and RedPanda, underperform in anomaly detection settings due to their focus on classifier invariance rather than data representation invariance. The authors demonstrate the effectiveness of their approach through experiments on both synthetic and real datasets, achieving significant performance improvements across various out-of-distribution scenarios, including spurious correlations and complex distribution shifts.

### Strengths and Weaknesses
Strengths:
1. The tackled problem is significant for real-life applications.
2. The proposed method is simple to implement and shows consistent improvement over existing methods.
3. The paper provides a unique formalization of anomaly detection using causal inference, contributing to the theoretical understanding of the field.
4. Empirical evaluations show substantial improvements over state-of-the-art methods in challenging scenarios, supported by rigorous experimental comparisons.

Weaknesses:
1. The novelty of the setting and mathematical formulation is questionable, as similar frameworks exist in prior works like Red PANDA and DCoDR without proper attribution.
2. The distinction between the proposed method and existing approaches like DCoDR and RedPanda could be articulated more clearly.
3. Writing quality is poor, especially in the experimental section, making it difficult to follow the experimental design and results.
4. The datasets used for evaluation are not sufficiently challenging, and some are considered niche or toy examples, limiting the generalizability of the findings.
5. Some definitions and notations are confusing, and additional clarity is needed regarding the proof of Corollary 1 and the implications of conditioning on W.

### Suggestions for Improvement
We recommend that the authors improve the writing quality, particularly in the experimental section, by providing clearer descriptions of the experimental design and results. Specifically, clarify the number of subsets in the training data and ensure that results are presented in a more interpretable format. We suggest discussing the similarities and differences with existing frameworks like Red PANDA and DCoDR to justify the novelty of the proposed method and to articulate the distinctions between their method and these existing approaches more clearly. Additionally, consider testing the method on more challenging datasets, such as Edges2Shoes and SmallNORB, to strengthen the evaluation and enhance the generalizability of the findings. Finally, provide clearer definitions and explanations for technical terms and notations used throughout the paper, and explicitly acknowledge the limitations of the datasets used and their relevance to real-world applications.