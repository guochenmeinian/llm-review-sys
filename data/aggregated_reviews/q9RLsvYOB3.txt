ID: q9RLsvYOB3
Title: FlexPlanner: Flexible 3D Floorplanning via Deep Reinforcement Learning in Hybrid Action Space with Multi-Modality Representation
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 5, 7, 5, 5, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 2, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents FlexPlanner, a flexible 3D floorplanning method utilizing deep reinforcement learning and a hybrid action space with multi-modality representation. The authors propose a novel approach that incorporates vision, graph, and sequence modalities to address challenges in 3D scenarios, achieving significant performance improvements on public benchmarks. The method effectively optimizes block positions, aspect ratios, and alignment, demonstrating strong transfer learning capabilities.

### Strengths and Weaknesses
Strengths:
1. The problem addressed is clearly articulated, highlighting the limitations of existing 2D methods in 3D scenarios.
2. The introduction of three modalities for state space representation enhances the method's capability compared to heuristic-based approaches.
3. The writing is clear, and the paper is well-organized, providing informative tables and appendices that aid understanding.
4. Experimental results show substantial improvements in alignment scores and other metrics.

Weaknesses:
1. The novelty of using three modalities is questioned; it may lack sufficient innovation, necessitating a clearer emphasis on technical contributions in the rebuttal.
2. Certain sections could benefit from additional clarity and simplification, particularly for readers unfamiliar with IC design.
3. Important design details are relegated to the appendix, which may hinder comprehension.
4. The paper lacks sufficient discussion on the baselines, particularly regarding the inclusion of more recent methods and the relevance of older baselines.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by simplifying complex sections and providing more detailed explanations of key design choices, such as the significance of the multi-modality input. Additionally, we suggest including a teaser that illustrates the challenges of applying 2D methods to 3D scenarios. It would also be beneficial to enhance the discussion of experimental results, particularly in Table 2, by providing visual comparisons and explanations for the performance of existing methods. Finally, we encourage the authors to address the concerns regarding baseline comparisons and to evaluate the sensitivity of their method to hyperparameters to improve reproducibility.