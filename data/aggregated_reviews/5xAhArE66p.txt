ID: 5xAhArE66p
Title: Temporal Understanding of Gaze Communication with GazeTransformer
Conference: NeurIPS
Year: 2023
Number of Reviews: 4
Original Ratings: 6, 6, 6, -1
Original Confidences: 4, 4, 4, 4

Aggregated Review:
### Key Points
This paper presents an end-to-end approach to gaze communication, utilizing a transformer-based architecture for atomic-level predictions and a temporal model for event-level predictions. The authors introduce a modified dataset, although the changes are primarily simplifications rather than substantial improvements. The paper lacks a thorough comparison with state-of-the-art methods, particularly with approaches like Fan et al. (2019), which is crucial for validating the proposed modifications.

### Strengths and Weaknesses
Strengths:
- The end-to-end solution is relevant and avoids the complications of decoupled models.
- The organization of the paper is clear, and the motivation for the approach is well articulated.
- Both atomic and event-level modules are reproducible, and the use of publicly available pre-trained models enhances re-implementability.
- The joint attention mechanism is well-documented, and the findings advance knowledge in the field.

Weaknesses:
- Clarity issues arise from figure visualizations and the connection between text and visuals, particularly in Figure 1.
- The evaluation is limited, relying on a single baseline dataset and lacking comprehensive comparisons with state-of-the-art methods.
- The rationale for dataset modifications and design choices, such as the use of transformers versus LSTMs, is insufficiently explained.

### Suggestions for Improvement
We recommend that the authors improve the clarity of figure visualizations and enhance the connections between text and visuals to aid reader comprehension. Additionally, we suggest that the authors conduct a more thorough evaluation by incorporating comparisons with multiple state-of-the-art methods, including applying the pre-trained model from Fan et al. (2019) on the modified dataset. Furthermore, providing a clearer explanation of the dataset modifications and the rationale behind design choices would strengthen the paper. Lastly, we encourage the authors to consider including an ablation study to explore different RNN architectures in their evaluation.