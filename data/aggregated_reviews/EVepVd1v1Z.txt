ID: EVepVd1v1Z
Title: Toward Competitive Serverless Deep Learning
Conference: ACM
Year: 2023
Number of Reviews: 2
Original Ratings: 6, 6
Original Confidences: 5, 5

Aggregated Review:
### Key Points
This paper presents SystemX, an innovative serverless solution aimed at enhancing data-parallel deep learning by addressing communication overhead and GPU utilization challenges. The authors compare SystemX with TensorFlow's MirroredStrategy, demonstrating that SystemX achieves faster time-to-accuracy and better validation loss performance with smaller batch sizes. However, the comparison may lack comprehensiveness due to SystemX's use of local SGD versus TensorFlow's synchronous training. The authors should include an experiment with synchronous aggregation in SystemX for a fairer evaluation. Additionally, the paper notes differences in aggregation methods, with TensorFlow using all-reduce and SystemX employing a parameter server architecture.

### Strengths and Weaknesses
Strengths:  
- SystemX shows superior performance and scalability in deep learning training, particularly with Local SGD.  
- The paper is well-written and aligns with the interests of the Middleware community.  
- The serverless architecture facilitates easy cloud deployment on Kubernetes, enhancing GPU resource utilization.  

Weaknesses:  
- The comparison with TensorFlow raises questions about the choice of framework, given that SystemX extends PyTorch.  
- The data partitioning across workers is unclear, which could affect the fairness of the comparison.  
- The claim of overcoming communication overhead may be misleading, as it does not fully address the trade-offs involved in synchronization frequency.  
- The terminology of a "serverless" platform that relies on a parameter server appears contradictory.  

### Suggestions for Improvement
We recommend that the authors improve the evaluation by including an experiment with synchronous aggregation in SystemX to ensure a more equitable comparison with TensorFlow. Additionally, clarify how data is partitioned across workers to address concerns about statistical heterogeneity. Consider adapting existing frameworks like that proposed by Kim et al. instead of introducing a new one. The claim regarding communication overhead should be revised to accurately reflect the trade-offs associated with synchronization frequency. Lastly, we suggest increasing the font size in figures for better readability and correcting the statement about communication overhead reduction to avoid inaccuracies.