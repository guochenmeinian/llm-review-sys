ID: eTDs4UY52h
Title: Automatic Debate Evaluation with Argumentation Semantics and Natural Language Argument Graph Networks
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method for evaluating natural language debates by integrating argumentation theory with NLP techniques. The authors propose a hybrid model that combines Graph-Network and Transformer architectures to predict debate outcomes based on argument quality. The method categorizes arguments as Conflict-free or Admissible and demonstrates superior performance compared to traditional baselines. The study also includes detailed experimental and error analyses, contributing valuable insights into the intersection of logical and linguistic knowledge in debate evaluation.

### Strengths and Weaknesses
Strengths:
- The hybrid approach is innovative and shows strong results in debate evaluation.
- The paper is well-structured, with clear explanations suitable for audiences unfamiliar with argumentation theory.
- The incorporation of error analysis enriches the findings and supports the conclusions.

Weaknesses:
- The removal of arguments with attack relations prior to scoring may lead to non-representative outcomes, as it disregards potentially valid arguments that could be poorly attacked.
- The paper lacks sufficient comparison to existing techniques in debate evaluation, making it difficult to assess its novelty and advancement over state-of-the-art methods.
- The attained F1 score, while surpassing previous results, remains relatively low and may be outperformed by newer Generative LLMs.

### Suggestions for Improvement
We recommend that the authors clarify the justification for removing arguments with attack relations, as this decision may significantly impact the model's representativeness. Additionally, we suggest that the authors expand their literature review to include relevant prior work, such as the Reasonableness dimension proposed by Wachsmuth et al. (2017) and techniques from Marro et al. (2022), to better situate their contributions. Furthermore, we encourage the authors to discuss the potential transferability of their hybrid technique to other debate domains and languages, and to consider testing simpler probabilistic models for NLP, such as a Bayesian classifier, to enhance their results.