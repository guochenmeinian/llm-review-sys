ID: LyAuNoZkGP
Title: Diffused Redundancy in Pre-trained Representations
Conference: NeurIPS
Year: 2023
Number of Reviews: 19
Original Ratings: 6, 6, 7, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the "diffused redundancy hypothesis," which posits that a random sample of neurons can achieve performance comparable to the entire layer in various downstream tasks. The authors validate this hypothesis through experiments on architectures pre-trained on ImageNet and explore factors influencing this phenomenon, including adversarial training. Additionally, the paper examines the implications of the diffused redundancy hypothesis in the context of transfer learning and adversarial training, proposing that optimizing for population-level robust loss can lead to significant accuracy discrepancies across classes, raising potential fairness concerns. The results from new experiments using random projections are noted as particularly interesting, although the overall impact of the findings remains somewhat unclear.

### Strengths and Weaknesses
Strengths:  
- The identification of diffused redundancy is a novel contribution that enhances understanding of deep neural network representations.  
- The manuscript is well-organized and clearly written, with extensive numerical experiments supporting the findings.  
- The use of metrics like Centered Kernel Alignment (CKA) to analyze the phenomenon is reasonable and adds to the study's soundness.  
- The paper addresses several reviewer concerns and presents interesting results from new experiments.  
- The exploration of the robustness-fairness tradeoff is conceptually valuable and has potential implications for future research.  

Weaknesses:  
- The claim that diffused redundancy holds for any random subset of neurons is insufficiently validated, as it relies on averaging over only five subsets.  
- The implications of the findings, particularly regarding efficiency and fairness, lack robust experimental evidence and motivation.  
- The focus on the penultimate layer limits the exploration of diffused redundancy in middle layers, and the theoretical underpinnings of the phenomenon are not adequately addressed.  
- The definition of diffused redundancy could be improved to require all subsets to exceed a certain accuracy threshold, rather than just an average.  
- The practical implications of the diffused redundancy hypothesis are perceived as weak, and the overall impact of the findings is unclear.  
- There is a need for further empirical validation, particularly regarding the effects of pretraining on diverse datasets.

### Suggestions for Improvement
We recommend that the authors improve the validation of the claim regarding the universality of diffused redundancy by testing a wider variety of neuron subsets, such as those based on principal components or variance. Additionally, we suggest conducting experiments on models pre-trained on different datasets, such as CIFAR-10, Places-365, or smaller datasets, to assess the generalizability of the phenomenon. Clarifying the definition of diffused redundancy to require all subsets to meet a specific accuracy threshold would strengthen the argument. Furthermore, addressing the implications of the findings with more experimental evidence and exploring the phenomenon in middle layers would enhance the paper's contribution. We encourage the authors to provide a clearer explanation of the fairness-efficiency trade-off and include discussions of the robustness-fairness tradeoff in future revisions, as this could enhance the paper's contributions.