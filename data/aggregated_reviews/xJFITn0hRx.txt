ID: xJFITn0hRx
Title: Auto-PINN: Understanding and Optimizing Physics-Informed Neural Architecture
Conference: NeurIPS
Year: 2023
Number of Reviews: 3
Original Ratings: 8, 5, -1
Original Confidences: 5, 3, 4

Aggregated Review:
### Key Points
This paper presents Auto-PINN, a hyperparameter optimization procedure designed for Physics-Informed Neural Networks (PINNs) solvers addressing partial differential equations (PDEs). The authors propose a systematic approach to reduce the hyperparameter search space through pre-experiments and serial optimization over a limited range. The methodology is validated through extensive numerical experiments across various PDE types, revealing that optimal hyperparameter values, such as network width and depth, are dependent on the specific PDE.

### Strengths and Weaknesses
Strengths:  
- The work addresses a significant issue in hyperparameter tuning systematically.  
- The methodology is well-structured and clearly articulated, making it accessible to the community.  
- Extensive numerical experiments support the proposed approach, demonstrating its relevance.

Weaknesses:  
- The novelty of the findings may be limited, as many observations and tuning processes are already known in the community.  
- The reliance on a non-trivial pre-experiment step for each new PDE flavor may hinder broader adoption of Auto-PINN.  
- The hyperparameter search space considered during pre-experiments is somewhat restricted, raising questions about its applicability to unique PDE problems.

### Suggestions for Improvement
We recommend that the authors improve the novelty aspect by highlighting unique contributions or insights that differentiate their work from existing literature. Additionally, consider providing clearer guidelines on how to select the hyperparameter search space during the pre-experiment step for new PDEs, which would enhance the practical applicability of Auto-PINN. Lastly, addressing the limitations of the pre-experiment requirement could facilitate easier adoption in real-world scenarios.