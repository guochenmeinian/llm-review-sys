ID: vF8ukt5l1R
Title: Self-supervised video pretraining yields robust and more human-aligned visual representations
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 6, 7, 6, 5, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a self-supervised learning (SSL) method, VITO, for video pre-training aimed at generating general visual representations applicable to both image and video tasks. The authors propose a new video dataset, VideoNet, curated to align with ImageNet's category distribution, and introduce architectural modifications to enhance contrastive learning. The model is evaluated across various downstream tasks, demonstrating competitive performance, particularly in segmentation and object detection. The revised title, “Self-supervised video pretraining yields general, robust, and more human-aligned visual representations,” aims to clarify the focus and intentions of the research. The authors have addressed reviewer concerns through additional explanations and results, leading to updated ratings from multiple reviewers.

### Strengths and Weaknesses
Strengths:
- The method is well-organized and clearly presented, making it easy to follow.
- The proposed title is clearer and better reflects the paper's focus.
- The empirical results show that VITO outperforms or is competitive with existing methods on multiple transfer tasks, indicating its effectiveness.
- The authors have provided novel results and addressed several reviewer concerns effectively.
- Comprehensive ablation studies validate the contributions of the proposed method and dataset.
- The overall assessment from reviewers has shifted positively, indicating a favorable reception of the revisions.

Weaknesses:
- The evaluation of human alignment is limited, raising concerns about the representativeness of the tasks used for this assessment.
- Some concerns remain unaddressed and are noted as future work, leading to a borderline rating from certain reviewers.
- The title and introduction may mislead readers regarding the paper's focus, as the emphasis is more on performance than on human alignment.
- Comparisons with other video-specific self-supervised methods are lacking, and the rationale for choosing MoCLR as a baseline requires further clarification.
- Despite improvements, a few reviewers maintain a cautious stance regarding their ratings.

### Suggestions for Improvement
We recommend that the authors improve the title and introduction to better reflect the paper's primary focus on performance rather than solely on human alignment. Additionally, we suggest incorporating more extensive ablation studies across all downstream tasks to clarify the influence of the proposed training method. It would also be beneficial to include comparisons with other established video-specific SSL methods and to provide a clearer justification for the choice of MoCLR as the baseline. Finally, addressing the limitations of the human alignment evaluations by exploring more comprehensive benchmarks and ensuring that all aspects of the feedback are comprehensively addressed could enhance the paper's reception.