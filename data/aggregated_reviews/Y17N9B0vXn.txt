ID: Y17N9B0vXn
Title: Towards Higher Ranks via Adversarial Weight Pruning
Conference: NeurIPS
Year: 2023
Number of Reviews: 6
Original Ratings: 7, 6, 7, 6, -1, -1
Original Confidences: 5, 5, 4, 3, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel Rank-based PruninG (RPG) method for network pruning that preserves the ranks of sparse weights in an adversarial manner, resulting in high-rank topology and enhanced performance. The authors evaluate the RPG method across various datasets and tasks, including image classification, object detection, and semantic segmentation, demonstrating that it outperforms existing state-of-the-art pruning methods in terms of accuracy and efficiency. The paper emphasizes the significance of rank preservation in network pruning and the advantages of adversarial training for improving pruned network performance.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and organized, providing clear explanations of the proposed method and experimental results.
- The RPG method is original and creatively combines rank preservation with adversarial training, addressing limitations of existing pruning methods.
- Comprehensive evaluations on multiple datasets show that the RPG method achieves superior accuracy and efficiency compared to existing methods.

Weaknesses:
- The RPG method may only outperform existing methods at high sparsity rates (90%, 95%, and 98%), with lower sparsity rates (e.g., 80%) showing diminished performance compared to WoodFisher.
- The method is limited to weight pruning, which is slower than filter pruning at equivalent rates.
- The adversarial optimization and singular value decomposition (SVD) increase computational complexity, potentially limiting practicality for large-scale networks.
- The paper lacks clarity on how the rank is determined and its implications for the pruning process.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the limitations of the RPG method, particularly regarding its performance at lower sparsity rates and its applicability to weight pruning. Additionally, we suggest including a comparison of accuracy-speed tradeoffs between the proposed method and previous structural pruning results to highlight the benefits of RPG. It would also be beneficial to provide a pseudo code for the pruning procedure and clarify how gradients are handled in the context of the regularization term. Finally, addressing the inconsistencies in baseline comparisons across tables and including computational training times for different methods would enhance the paper's clarity and rigor.