ID: WpPNVPAEyv
Title: Breaking Long-Tailed Learning Bottlenecks: A Controllable Paradigm with Hypernetwork-Generated Diverse Experts
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 7, 7, 7, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 5, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for long-tailed learning that addresses distribution shifts between training and testing data while accommodating user preferences for trade-offs between head and tail classes. The authors propose using hypernetworks to generate a diverse set of expert models, enabling adaptation to various test distributions. Extensive experiments validate the method's effectiveness and adaptability, contributing significantly to the field of long-tailed learning.

### Strengths and Weaknesses
Strengths:
1. The paper tackles the meaningful issue of test distribution invariance and user-specific preferences, making it highly practical.
2. The theoretical foundations and practical results are well-articulated.
3. Comprehensive experiments demonstrate the proposed method's superiority over existing approaches.

Weaknesses:
1. Important concepts, such as the meaning of "environment" in Section 3, require further clarification, particularly regarding minimizing empirical risks across multiple training environments.
2. The paper states "use $\alpha = 1.2$ for the Dirichlet distribution" in Section 5.1, but $\alpha$ should be a vector according to Eq.(5), necessitating a more detailed explanation.
3. The authors should consider including more competitive baselines like PaCO, DDC, and DirMixE for comparison.
4. There are typographical errors, such as in line 36 and line 95, that need correction.
5. Some figures, including Figure 1 and Figure 3, are not referenced in the text.

### Suggestions for Improvement
We recommend that the authors improve the clarity of key concepts, particularly the definition of "environment" and the rationale for minimizing empirical risks across multiple training environments. Additionally, please clarify how to ensemble the experts when the test distribution varies. We suggest providing a detailed explanation regarding the use of $\alpha$ in the Dirichlet distribution and including more competitive baselines for a robust comparison. Correcting typographical errors and ensuring all figures are referenced in the text will enhance the paper's presentation. Lastly, we encourage the authors to analyze the impact of the hyperparameters of the Dirichlet distribution on algorithm performance and to provide a concise explanation of Figure 2.