ID: QkCYv3TlGk
Title: Non-parallel Accent Transfer based on Fine-grained Controllable Accent Modelling
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework for accent and voice conversion without the need for parallel data, utilizing disentangled latent representations. The authors propose a system that generates accent embeddings from speech and separates speaker and accent information, achieving promising results in non-parallel accent transfer across two languages, English and Laos. The model reportedly achieves state-of-the-art results in various metrics, supported by thorough ablation studies and visualizations.

### Strengths and Weaknesses
Strengths:
- The proposed method demonstrates good performance and achieves state-of-the-art results in non-parallel accent transfer.
- The application of the framework to both high-resource (English) and low-resource (Laos) languages is commendable.
- Excellent ablation studies and visualizations enhance the understanding of feature contributions and accent transfer effectiveness.

Weaknesses:
- The paper contains technical flaws, such as unclear definitions and potential confusion in the use of latent variables.
- Writing quality is poor, with grammatical errors and unclear nomenclature that hinder comprehension.
- Key technical details, such as the training methodology and loss functions, are inadequately explained, making it difficult for readers to follow.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by addressing grammatical mistakes and refining the nomenclature used throughout. Specifically, definitions for terms like MI and various abbreviations should be included. Additionally, we suggest providing clearer explanations of the architectures for E_s and E_r, as well as the loss functions and parameters in the appendix for reproducibility. It would also be beneficial to compare the proposed method against parallel accent transfer techniques and clarify the training independence of models across datasets. Finally, we advise enhancing the visual representations to better align with the text and improve overall readability.