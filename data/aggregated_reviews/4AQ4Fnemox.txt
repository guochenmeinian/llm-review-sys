ID: 4AQ4Fnemox
Title: On the Exploitability of Instruction Tuning
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 6, 6, 7, 7, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents AutoPoison, an automated data poisoning pipeline designed to manipulate instruction-tuned language models through two types of attacks: content injection and over-refusal. The authors demonstrate that AutoPoison can effectively alter model behavior by poisoning a small fraction of data while maintaining a high level of stealthiness. The evaluation shows that AutoPoison outperforms hand-crafted baselines in terms of effectiveness and stealthiness.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and easy to follow, with sufficient examples for clarity.
2. The proposed threat model and pipeline for instruction tuning are novel and timely, addressing a critical area in the context of LLMs.
3. The analysis of model sizes and data poison ratios is thorough, providing insights into model vulnerabilities.

Weaknesses:
1. The evaluation of the proposed over-refusal attack lacks breadth, and the metrics used to assess stealthiness, such as perplexity and coherence, may not adequately capture the model's ability to follow instructions.
2. There is insufficient consideration of the model's faithfulness and factuality, as demonstrated by factual inaccuracies in generated outputs.
3. The paper lacks human evaluation to assess whether users can distinguish between attacked and clean models, which is crucial for understanding the attack's stealthiness.

### Suggestions for Improvement
We recommend that the authors improve the evaluation protocol for the over-refusal attack to include a broader range of metrics that better capture instruction-following ability, potentially incorporating LLM-based metrics or human evaluations. Additionally, we suggest evaluating the model's capabilities on standard benchmarks such as HELM and MMLU to assess the impact of poisoning on performance. Addressing the concerns regarding factual accuracy and the potential for hallucinations in generated outputs is also essential. Finally, a preliminary discussion on defense strategies against the proposed attacks would enhance the paper's contribution.