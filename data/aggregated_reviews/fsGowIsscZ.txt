ID: fsGowIsscZ
Title: A Diachronic Perspective on User Trust in AI under Uncertainty
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper studies how mis-calibrated confidence scores affect user trust in AI systems through monetary betting simulations. The authors find that (1) over-confident wrong responses diminish trust more than under-confident correct responses, (2) user trust is challenging to establish but easy to lose, (3) trust in one question type can transfer to others, and (4) user trust can be modeled. The research is motivated by the need to understand the dynamics of user trust in human-AI collaboration environments, utilizing a user study where trust is measured through monetary rewards.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, organized, and presents an interesting experimental design.
- The research question is significant, addressing the modeling of user trust, which is crucial for AI applications.
- The authors control for confounding factors, establishing a clean test environment.

Weaknesses:
- Many findings are expected, limiting their impact.
- The user study operates in a simplified setting, which may restrict the generalizability of the results.
- The assumption of access to an oracle for correctness information may not hold in real-world scenarios.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their findings by addressing the limitations of the simplified user study setting. Additionally, we suggest comparing traditional beta-distribution based computational trust models with their current approach, as these models are simpler and applicable in the discussed contexts. Finally, we encourage the authors to include relevant references from HCI literature on the impact of feedback on user trust, such as "No Explainability without Accountability: An Empirical Study of Explanations and Feedback in Interactive ML" by Smith-Renner et al.