ID: jfHkAEgKwH
Title: LocCa: Visual Pretraining with Location-aware Captioners
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 7, 7, 5, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 5, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents LocCa, a novel visual pretraining approach that integrates location-aware tasks into image captioning-based vision-language models. The authors propose two tasks: automatic referring expressions (AREF) for predicting bounding box coordinates from captions, and grounded captioning (GCAP) for jointly predicting box coordinates and captions from images. The experiments demonstrate that LocCa significantly outperforms standard captioning models on localization challenges while maintaining comparable performance on broader tasks.

### Strengths and Weaknesses
Strengths:
- The methodology is straightforward and elegantly unifies global and region-level caption generation without requiring complex architectural modifications.
- The paper is well-written, clear, and provides comprehensive benchmarking across various downstream tasks, achieving strong performance.

Weaknesses:
1. The objectives of LocCa, particularly in section 3.2, are somewhat confusing, especially regarding the "dual-faceted" loss. This section could benefit from clearer explanations and references to traditional approaches for better understanding.
2. The reliance on pre-existing tools like OWL-ViT for generating bounding boxes raises concerns about the quality and integrity of the training data, as it creates dependencies that may limit dataset quality.
3. The paper lacks an ablation study that isolates the impact of removing the box predictions while retaining region caption predictions, which would highlight the importance of location awareness.
4. The string-based box representation method's efficiency compared to special tokenizations for box coordinates is not adequately discussed, particularly regarding token count and decoding efficiency.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the objectives of LocCa in section 3.2, particularly regarding the "dual-faceted" loss, and consider including references to traditional approaches for context. Additionally, discussing the implications of relying on external models for data generation would enhance the paper's robustness. We suggest adding an ablation study that examines the effects of removing box predictions while retaining region captions to demonstrate the value of location awareness. Furthermore, a discussion on the efficiency of the string-based box representation compared to other methods, including an exploration of hyperparameters related to box coordinates, would be beneficial.