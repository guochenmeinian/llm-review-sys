ID: Xo1Yqyw7Yx
Title: Enabling Adaptive Agent Training in Open-Ended Simulators by Targeting Diversity
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 8, 3, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DIVA, a novel technique that applies quality diversity (QD) optimization to generate diverse training tasks for (meta) reinforcement learning (RL). The authors argue that DIVA effectively addresses challenges posed by curriculum-induced covariate shift (CICS) and enhances diversity in generated environments, particularly in scenarios where traditional simulator parameterizations fail. By handcrafting high-level task features relevant to the RL agent's learning process, DIVA collects a diverse set of parameterizations that improve agent performance across various tasks, including GridNav, Alchemy, and Racing. The experiments demonstrate significant improvements over existing baselines like robust prioritized level-replay, ACCEL, PLR, SAMPLR, CLUTR, and DRED.

### Strengths and Weaknesses
Strengths:
- The focus on high-level features relevant to downstream tasks rather than simulator parameters is a significant advancement.
- DIVA effectively generates diverse environments, addressing CICS and showing substantial improvements over existing unsupervised environment design (UED) solutions across diverse evaluation tasks.
- The authors provide a thorough comparison with existing methods, clarifying DIVA's advantages, and the evaluations are well-structured with sufficient ablation studies. The writing is clear and well-illustrated.

Weaknesses:
- The necessity of handcrafting high-level features requires expert knowledge, which may limit applicability.
- Evaluation is limited to one meta-RL method (VariBAD), and results from other methods like RL^2 would be beneficial.
- The experimental domains are simplistic, raising concerns about the generalizability of results to more complex environments.
- The reliance on specific parameterizations may limit DIVA's applicability to more complex open-ended environments, and the claim regarding DIVA's ability to leverage ill-parameterized simulators may be overstated given the nature of the environments used in the experiments.
- The introduction of a new scalability bottleneck related to feature specification could undermine the generalizability of the approach.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their findings by evaluating DIVA with additional meta-RL methods, such as RL^2, on more complex domains. Additionally, addressing the reliance on hand-tuned feature sets would enhance the technique's applicability; exploring automated feature selection could be beneficial. We suggest softening the claims regarding DIVA's capabilities to ensure they align more closely with the experimental results and addressing concerns about the potential limitations of the parameterizations used. Furthermore, clarifying the presentation, particularly in figures and terminology, would improve the paper's accessibility. Specifically, we suggest providing more detailed descriptions in Figure 1 and justifying parameter choices more thoroughly.