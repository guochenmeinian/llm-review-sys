ID: S93hrwT8u9
Title: Activation Map Compression through Tensor Decomposition for Deep Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 3, 4, 7, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for compressing activation maps in deep learning models using tensor decomposition techniques, specifically Singular Value Decomposition (SVD) and Higher Order SVD (HOSVD). The authors aim to alleviate memory bottlenecks during backpropagation, facilitating on-device learning in resource-constrained environments. The theoretical analysis includes error bounds and the impact on memory usage and computational complexity, supported by experimental results across various tasks and architectures.

### Strengths and Weaknesses
Strengths:
1. The use of tensor decomposition for activation map compression is a novel approach that effectively addresses a significant bottleneck in neural network training.
2. The method demonstrates substantial memory reduction during backpropagation, which is critical for deploying models on edge devices.
3. The paper provides a solid theoretical foundation, including error analysis and guarantees of minimal information loss.

Weaknesses:
1. The computational overhead associated with SVD or tensor decomposition for activation map compression raises concerns, particularly given the limited computational capacity of embedded devices.
2. The method may lead to severe performance degradation relative to memory reduction, and the complexity of implementing HOSVD could hinder its adoption.
3. There is insufficient explanation on how to select the appropriate rank for decomposition, which is essential for balancing memory reduction and accuracy.
4. The paper lacks detailed comparisons with other activation map compression techniques, and results show inconsistent performance between SVD and HOSVD.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the rank selection process for tensor decomposition, providing guidelines for tuning this parameter effectively. Additionally, addressing the computational overhead and potential performance degradation in more detail would enhance the paper's practical applicability. It would be beneficial to include comparisons with other methods, such as checkpointing, and to explore the implications of using quantization methods instead of compression. Finally, we encourage the authors to evaluate their method on more diverse and complex neural network architectures to demonstrate its generalizability.