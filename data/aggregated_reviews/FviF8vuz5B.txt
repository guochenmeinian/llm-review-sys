ID: FviF8vuz5B
Title: On Differentially Private Sampling from Gaussian and Product Distributions
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 6, 7, 5, 7, 7, -1, -1, -1, -1, -1
Original Confidences: 2, 2, 4, 4, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the problem of generating samples from an unknown distribution \( P \) while ensuring differential privacy. The authors propose new differential privacy sampling algorithms for multi-dimensional Gaussian distributions and a pure-DP algorithm for product distributions on the binary hypercube. The work aims to bridge the gap between differential privacy distribution sampling and learning, demonstrating that sampling is often less complex than learning.

### Strengths and Weaknesses
Strengths:  
- The paper introduces a new differential privacy sampling algorithm for multivariate Normal and product Bernoulli distributions, contributing significantly to the field.  
- It systematically investigates Gaussian distributions under various conditions, providing upper and lower bounds, and highlights that the dependence on accuracy parameters for Gaussian sampling is logarithmic, contrasting with polynomial dependence in learning tasks.  
- The writing is accessible, and the results, particularly for binary product distributions, show significant improvements over prior work.

Weaknesses:  
- The focus on Gaussian and binary product distributions limits the scope, leaving the applicability of the methods to other distributions unclear.  
- The guarantees for Gaussian distributions are sub-optimal regarding range parameters, particularly for sampling under approximate differential privacy, which raises questions about the necessity of polynomial dependence on \( R \).  
- The formulation of the sampling problem may seem artificial, as it diverges from standard practices in sampling without a known target distribution.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their algorithms by extending their analysis to a broader range of distributions or discussing potential challenges and strategies for such extensions. Additionally, we suggest clarifying the dependencies in the range parameters and addressing whether the discrete setting is inherently harder. Lastly, we encourage the authors to explicitly state the computational model used throughout the paper to enhance clarity for readers.