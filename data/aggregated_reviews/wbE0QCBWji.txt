ID: wbE0QCBWji
Title: Constructing Semantics-Aware Adversarial Examples with a Probabilistic Perspective
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 6, 7, 6, -1, -1, -1, -1
Original Confidences: 4, 4, 2, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to adversarial image generation by proposing an unrestricted attack method applicable to both targeted and untargeted attacks. The authors adopt a probabilistic perspective, treating the victim classifier and geometric constraints as distinct distributions, which allows for the preservation of the original image's semantics. The efficacy of this method is demonstrated through extensive experiments, including a human annotation study, showcasing its robustness against various adversarial defenses.

### Strengths and Weaknesses
Strengths:
1. The probabilistic approach is innovative and well-articulated, providing a solid foundation for the methodology.
2. The experimental results are impressive, particularly the human annotation experiment, which adds validation to the claims. The model's effectiveness in handling transfer attacks and adversarial defenses is noteworthy.
3. The paper introduces a significant shift from traditional norm-bounded attacks, achieving a 100% success rate against adversarially trained models, motivating further research in defense mechanisms.

Weaknesses:
1. The methodology for the human experiment lacks detail, particularly regarding the selection of reviewers for the MNIST experiment. A follow-up experiment without a reference image for the ImageNet dataset is also recommended for realism.
2. The proposed method shows lower success rates compared to NCF and cAdv in generating adversarial examples, indicating potential shortcomings.
3. The paper lacks ablation studies for rejection sampling and sample refinement techniques, and it does not discuss potential defenses against the proposed attack.
4. Standard deviations are not reported, and repeated experiments are encouraged for reliability.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the human experiment methodology, including how reviewers were selected. Additionally, conducting a follow-up experiment where human annotators identify perturbed images without a reference image for the ImageNet dataset would enhance realism. The authors should also explore targeted attacks on ImageNet to gain insights into the proposed method's robustness. Furthermore, including ablation studies for rejection sampling and sample refinement techniques would clarify their necessity. Lastly, reporting standard deviations and repeating experiments would strengthen the reliability of the findings.