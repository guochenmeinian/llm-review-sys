ID: bzXpQUnule
Title: Federated Linear Bandits with Finite Adversarial Actions
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 6, 5, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study of the linear contextual bandits problem within a federated learning framework involving $M$ clients and a central server. It assumes adversarial finite action sets and explores both asynchronous and synchronous communication scenarios. The authors propose the FedSupLinUCB algorithm, which extends the SupLinUCB and OFUL methods, achieving a regret bound of $\widetilde{O}(\sqrt{dT})$ while ensuring limited communication costs of $\mathcal{O}(\sqrt{d^3M^3}\log(d))$ for synchronous and $\mathcal{O}(dM^2\log(d)\log(T))$ for asynchronous cases. The algorithm also addresses variance-adaptive and adversarial corruption scenarios, with experimental results validating the theoretical findings.

### Strengths and Weaknesses
Strengths:  
- The paper is clearly written and well-organized, with well-defined notations and clear explanations.  
- The combination of online learning and federated learning is an innovative direction, achieving optimal regret bounds with limited communication costs.  
- The instance-dependent regret bounds for variance-adaptive and adversarial corruption scenarios are particularly noteworthy.  

Weaknesses:  
- The paper lacks a detailed definition of time-evolving and adversarial arms, which could enhance comprehension.  
- It does not sufficiently emphasize the differences between federated and traditional linear bandit problems.  
- The experimental section is limited, primarily comparing against a single baseline algorithm, and could benefit from broader evaluations.  

### Suggestions for Improvement
We recommend that the authors improve the introduction by providing a more detailed explanation of time-evolving and adversarial arms and their implications for federated linear bandits. Additionally, we suggest emphasizing the key differences from traditional linear bandit problems to strengthen the motivation for this work. Expanding the experimental comparisons to include more algorithms would also enhance the evaluation of FedSupLinUCB. Lastly, consider addressing the questions raised regarding the adversarial corruption actions and their implications for different settings.