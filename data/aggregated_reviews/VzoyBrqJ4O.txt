ID: VzoyBrqJ4O
Title: Depth Anywhere: Enhancing 360 Monocular Depth Estimation via Perspective Distillation and Unlabeled Data Augmentation
Conference: NeurIPS
Year: 2024
Number of Reviews: 22
Original Ratings: 5, 5, 5, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 5, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a technique for 360-degree monocular depth estimation that leverages unlabeled data through a two-stage process: offline mask generation for invalid regions and online semi-supervised joint training. The authors introduce "perspective distillation" to generate pixel-wise depth supervision signals and employ unlabeled data augmentation by creating synthetic stereo pairs. Experimental results demonstrate that the proposed method outperforms existing approaches on benchmark datasets, indicating its effectiveness in enhancing depth estimation accuracy.

### Strengths and Weaknesses
Strengths:
- The paper introduces innovative techniques, such as perspective distillation and unlabeled data augmentation, effectively addressing challenges in 360 monocular depth estimation.
- The method shows significant improvements in depth estimation accuracy through rigorous evaluations on benchmark datasets.
- The use of unlabeled data reduces reliance on paired depth information, which is often difficult to obtain.

Weaknesses:
- The technical contribution appears limited, as the core idea of utilizing unlabeled data has been previously proposed by DepthAnything, making the method seem more like an application of this idea.
- The complexity of the proposed method may require more computational resources and training time, potentially hindering its practicality.
- The effectiveness of the method is heavily dependent on the quality of benchmark datasets, which may limit its generalizability to real-world scenarios.
- Insufficient related work is presented, particularly regarding the latest panoramic depth estimation and completion methods.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the description regarding the indoor elements in the unlabeled data, as the current explanation is confusing. Additionally, the authors should conduct fair experiments and comparisons across various models, including non-dual-projection fusion models, to validate the applicability of their training strategy. It is crucial to ensure consistent application of alignment techniques across all methods compared to avoid unfair comparisons. Furthermore, we suggest that the authors include a discussion on the similarities and differences with related works, such as FoVA-Depth, and provide a baseline that directly projects pseudo ground truth onto equirectangular images. Finally, the authors should explore the scaling benefits of pseudo ground truth compared to real ground truth and investigate the applicability of their approach to metric depth estimation.