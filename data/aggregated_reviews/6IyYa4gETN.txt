ID: 6IyYa4gETN
Title: IMAGPose: A Unified Conditional Framework for Pose-Guided Person Generation
Conference: NeurIPS
Year: 2024
Number of Reviews: 19
Original Ratings: 4, 8, 8, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a diffusion-based pose-guided image generation method, aiming to generate images that adhere to specified poses while maintaining the appearance of the input image. The authors propose a unified framework, IMAGPose, which incorporates innovative modules such as Feature-Level Conditioning (FLC), Image-Level Conditioning (ILC), and Cross-View Attention (CVA) to enhance image generation quality across various real-world user scenarios. They assert that their method achieves competitive performance without merely modifying existing masking strategies, emphasizing the introduction of combined images as conditions for improved contextual information. The authors also combine features from a Variational Autoencoder (VAE) and a pre-trained image encoder to capture texture details, allowing for the generation of 1-3 images in a single forward step.

### Strengths and Weaknesses
Strengths:
- The combination of VAE and image encoder features enhances detail in generated images.
- The proposed IMAGPose framework effectively addresses multiple pose-guided generation scenarios, demonstrating strong performance in qualitative, quantitative, and user studies.
- The paper is described as "a fairly complete work" and "a cohesive and comprehensive study," indicating thoroughness and clarity in presentation.
- The introduction of novel modules (FLC, ILC, CVA) and a unified approach to pose-guided image generation is highlighted as a significant contribution.

Weaknesses:
- Limited novelty, as the core contributions closely resemble existing works, particularly in the formation of joint latents and the combination of VAE features with image encoder features.
- Insufficient comparative analysis with other pose-guided methods, such as Animate Anyone and ControlNet, which could provide a clearer context for the proposed method's performance.
- Concerns regarding the four-grid setting's impact on image resolution may affect output quality, as the generated sub-images are smaller than the original images, raising questions about detail preservation.
- Incorrect claims regarding the limitations of previous diffusion-based methods in extracting texture details, as some existing models have demonstrated effective encoding of such features.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their contributions by clearly distinguishing their approach from existing methods, particularly in the discussion of joint latent formation and feature combinations. Additionally, the authors should conduct a thorough comparison with relevant pose-guided image generation methods to substantiate their claims of superiority. Clarifying the inaccuracies in their statements about previous works will enhance the paper's credibility. We also suggest providing more detailed visualizations and analyses of attention maps in the final version to enhance understanding of the model's performance. Furthermore, addressing potential concerns about the four-grid setting's resolution impact on image quality could strengthen the manuscript. Lastly, we recommend providing more detailed ablation studies to elucidate the impact of each module within the IMAGPose framework and addressing potential performance issues related to reliance on OpenPose for pose detection.