ID: bJJY9TFfe0
Title: Deep Optimal Transport: A Practical Algorithm for Photo-realistic Image Restoration
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 3, 5, 6, 5, 4, -1, -1, -1, -1
Original Confidences: 5, 5, 5, 4, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an image restoration algorithm that enhances images processed by pre-trained restoration models by controlling the tradeoff between perceptual quality and mean square error (MSE). The authors propose a method based on optimal transport in the latent space, utilizing a linear transformation to approximate the optimal transport operator from the restored images to the original images. The effectiveness of the proposed method is demonstrated through experimental results across various image restoration tasks.

### Strengths and Weaknesses
Strengths:
1. The proposed method is interesting and can be viewed as a post-processing technique that balances perceptual quality (measured by Wasserstein-2 distance) and distortion (measured by MSE) through empirical first- and second-order statistics in latent space.
2. The paper is clearly written and easy to read.
3. Experimental results validate the effectiveness of the proposed method.

Weaknesses:
1. The method lacks theoretical novelty, primarily extending existing theories and approaches without significant innovation.
2. The post-processing nature may limit practical applications due to the requirement of test-time training, which may necessitate retraining under varying degradation strengths.
3. The assumption of latent representations following a Multivariate Gaussian distribution is strong and may restrict the method's applicability.
4. The method's similarity to existing optimal transport approaches raises questions about its comparative performance against one-stage restoration models.
5. The presentation of the paper is unclear in certain areas, with ambiguous definitions and concepts that require clarification.

### Suggestions for Improvement
We recommend that the authors improve the theoretical novelty by providing a more distinct contribution beyond existing work. Additionally, addressing the practical limitations of test-time training would enhance the method's applicability. We suggest evaluating the method on real-world datasets to strengthen the experimental validation. Clarifying ambiguous terms and concepts in the presentation, such as the definitions of $x^*$ and $\hat{x_0}$, would improve readability. Finally, we encourage the authors to explore and discuss how their method relates to other loss functions, such as projected distribution loss and sliced Wasserstein loss, to provide a clearer context for their approach.