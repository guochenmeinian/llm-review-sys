ID: bcVLFQCOjc
Title: DeTikZify: Synthesizing Graphics Programs for Scientific Figures and Sketches with TikZ
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 8, 8, 7, 4, -1
Original Confidences: 3, 4, 4, 4, -1

Aggregated Review:
### Key Points
This paper presents DeTikZify, a multimodal model designed to generate TikZ code from hand-drawn sketches and existing figures. The authors introduce three novel datasets: DaTikZv2, SketchFig, and SciCap++, and demonstrate that DeTikZify outperforms models like GPT-4V and Claude 3. The model employs a Monte Carlo Tree Search (MCTS) algorithm for iterative refinement, enhancing the quality of generated outputs. Evaluation metrics include code and image similarity, efficiency, and human assessments, which correlate positively with automated metrics.

### Strengths and Weaknesses
Strengths:  
- The paper is clearly written and well-structured, with high-quality experimentation and analysis.  
- It addresses a novel and significant task in generating TikZ from sketches, contributing valuable datasets and methodologies.  
- The combination of various models and the use of MCTS for iterative improvement are innovative and practical.  
- The thorough evaluation on multiple metrics strengthens the findings.

Weaknesses:  
- The potential for data leakage raises concerns about the integrity of the training and evaluation datasets.  
- The intuition and computation behind "Average Similarity" require further clarification.  
- More examples of model inference are needed to better assess performance and the contribution of MCTS.  
- The reliance on compiler diagnostics may not fully capture the quality of generated TikZ code, necessitating visual output evaluations.  
- Computational requirements may limit the model's applicability in practical scenarios.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the "Average Similarity" computation in the main text. Additionally, providing more examples of model inference, particularly without MCTS, would help gauge its contribution to output quality. Addressing concerns about data leakage and ensuring transparency regarding the training datasets is crucial. Finally, including visual examples of successful and unsuccessful cases would enhance understanding of the model's strengths and weaknesses.