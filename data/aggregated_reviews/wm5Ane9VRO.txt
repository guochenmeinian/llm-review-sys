ID: wm5Ane9VRO
Title: Maximization of Average Precision for Deep Learning with Adversarial Ranking Robustness
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 5, 8, 6, 6, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 4, 4, 2, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates the average precision (AP) issue in adversarial training, demonstrating that attacking a single image may not significantly impact final accuracy but can reduce average precision. The authors propose a novel method that combines adversarial training with AP maximization and introduces point-wise regularization variants. Empirical analyses across various datasets validate the effectiveness of these methods. Additionally, the paper presents an analysis of performance metrics across two datasets, CIFAR10_cls1 and BDD100K(rainy), detailing the values of $P(w)$, $R(w,\delta,D)$, and their combined results, supported by extensive numerical data illustrating performance trends and variations in the models tested.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and easily comprehensible.
- The proposed methods show great effectiveness across multiple datasets.
- A detailed analysis of various AdAP variants is provided.
- The authors effectively address reviewer concerns in their rebuttal, leading to improved evaluations from multiple reviewers.
- The detailed numerical results provide a clear understanding of model performance across different scenarios.

Weaknesses:
- The motivation for the importance of average precision in adversarial training is insufficiently addressed, raising questions about the relevance of the research problem. The authors should justify the focus on average precision versus accuracy in real-world scenarios.
- The rationale for proposing two regularizations, AdAP_MM and AdAP_PZ, is unclear, particularly since the first does not demonstrate a significant advantage over the latter.
- The proposed method is limited to binary and imbalanced classification settings, leaving its applicability to multi-class or balanced adversarial training uncertain.
- The determination of hyper-parameters $\lambda$, $\gamma_1$, and $\gamma_2$ lacks clarity regarding their sensitivity to different values.
- Some reviewers felt that not all concerns were fully addressed, indicating potential gaps in the analysis or explanations provided.

### Suggestions for Improvement
We recommend that the authors improve the justification for the significance of average precision in adversarial training, particularly in real-world applications. Additionally, clarify the necessity of proposing both AdAP_MM and AdAP_PZ together. The authors should also broaden the scope of their experiments to include multi-class and balanced classification settings. Furthermore, provide a detailed explanation of how the hyper-parameters $\lambda$, $\gamma_1$, and $\gamma_2$ are chosen and their sensitivity to variations. Lastly, consider incorporating stronger attack methods, such as PGD and AutoAttack, in the empirical evaluation to better support the effectiveness of the proposed methods. We also recommend improving the clarity and depth of explanations regarding the numerical results to ensure that all reviewer concerns are comprehensively addressed, along with further elaboration on the implications of the findings to enhance the overall impact of the paper.