ID: sqkGJjIRfG
Title: HASSOD: Hierarchical Adaptive Self-Supervised Object Detection
Conference: NeurIPS
Year: 2023
Number of Reviews: 21
Original Ratings: 5, 5, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a self-supervised object detection method, HASSOD, which utilizes a hierarchical adaptive clustering strategy to group regions into object masks based on self-supervised visual representations. The authors adapt the Mean Teacher framework to train a student object detector using initial and progressively refined pseudo-labels. The approach demonstrates improved performance over existing self-supervised methods, achieving notable results on datasets like LVIS and SA-1B. Furthermore, the authors propose an innovative approach to improving hierarchical pseudo-labels through enhanced DINO features, emphasizing that refined hierarchical pseudo-labels can be directly extracted from the trained teacher detector, enhancing efficiency and quality compared to clustering DINO features. Their adaptive target strategy modulates the influence of initial and improved pseudo-labels during training, reducing noise impact and increasing the quality of the final labels.

### Strengths and Weaknesses
Strengths:
- The hierarchical structure allows the detector to learn compositional relationships among objects, enhancing prediction accuracy.
- Extensive experiments yield promising quantitative results, with clear comparisons in Tables 1-3.
- The method is completely self-supervised, incurring no supervision costs beyond computational expenses for generating pseudo-labels.
- The proposed method effectively utilizes enhanced DINO features to generate high-quality hierarchical pseudo-labels.
- The Mean Teacher framework is a notable improvement over previous iterative self-training methods.
- The adaptive target strategy allows for dynamic adjustment of label quality during training.

Weaknesses:
- The writing lacks clarity, omitting critical details that hinder understanding of the method.
- The use of pre-defined thresholds for merging region features may limit the method's applicability across different datasets.
- The quality of masks without post-processing techniques like CRF is uncertain, raising questions about the robustness of the results.
- The paper does not provide sufficient analytics or ablation studies to support the findings, and the computational costs of various stages are not discussed.
- The paper remains borderline in its current state, indicating potential areas for further enhancement.
- Some reviewers noted that while concerns were addressed, the overall strength of the paper could be improved through revisions based on feedback.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing by including critical details and rigorous definitions for terms like whole, part, and subpart. Additionally, the authors should clarify the learning process of the DINO backbone and the losses used in the Mean Teacher framework. Addressing the time complexity of the grouping process and the rationale behind the choice of thresholds for clustering is essential. It would also be beneficial to include a comparison of the method's performance across various detectors beyond Cascade Mask R-CNN to demonstrate its generalizability. Lastly, providing a thorough analysis of failure cases and the computational costs associated with each stage of the process would enhance the paper's robustness. Incorporating the feedback received during the rebuttal process to strengthen their arguments and methodologies will also improve the clarity and impact of the work.