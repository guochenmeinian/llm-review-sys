ID: qyixBZl8Ph
Title: Global Update Tracking: A Decentralized Learning Algorithm for Heterogeneous Data
Conference: NeurIPS
Year: 2023
Number of Reviews: 6
Original Ratings: 5, 5, 6, 6, -1, -1
Original Confidences: 3, 1, 3, 1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel decentralized learning algorithm called Global Update Tracking (GUT), designed to mitigate the impact of heterogeneous data distribution across devices. The GUT algorithm reduces communication overhead by enabling agents to track model updates rather than gradients, storing copies of neighboring model parameters. Experiments demonstrate that GUT, particularly with Quasi-Global momentum (QG-GUTm), outperforms existing decentralized learning algorithms across various benchmarks, including CIFAR-10 and CIFAR-100.

### Strengths and Weaknesses
Strengths:
1. The proposed GUT method effectively addresses the critical issue of heterogeneous data in decentralized learning, showing good performance across multiple benchmarks.
2. The authors conduct a detailed sensitivity analysis regarding model architecture and hyper-parameters.
3. The paper is well-written, making it accessible to readers.

Weaknesses:
1. The experimental section lacks clarity regarding quantitative results on communication parameters, making it difficult for readers to understand the cost implications.
2. The introduction contains excessive descriptions of related work, obscuring the main contributions.
3. The analysis of the method's advantages over previous approaches is insufficiently detailed, particularly regarding communication overhead savings.
4. The paper does not provide a comprehensive performance comparison across all datasets, nor does it include larger-scale benchmarks or state-of-the-art models.
5. The data partitioning method is not clearly defined, and implementation details are missing.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the experimental results by providing specific quantitative comparisons of communication costs. Additionally, the authors should streamline the introduction to focus on key contributions and reduce the amount of related work discussed. A more thorough analysis explaining why tracking model updates is advantageous over gradient tracking is necessary. We also suggest including evaluations on larger benchmarks and state-of-the-art models, as well as clarifying the data partitioning method and providing necessary implementation details. Lastly, a quantitative analysis of the communication overhead associated with the GUT algorithm should be included to substantiate claims of reduced overhead.