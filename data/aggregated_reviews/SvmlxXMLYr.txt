ID: SvmlxXMLYr
Title: COUNT: COntrastive UNlikelihood Text Style Transfer for Text Detoxification
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel loss function, COUNT, aimed at enhancing text detoxification by penalizing identity mapping often seen in prior approaches. The authors propose this method to maximize the likelihood of generating non-toxic text relative to the input toxic text. The paper details how COUNT differs from Unlikelihood Training and provides experimental results demonstrating its advantages over existing models.

### Strengths and Weaknesses
Strengths:
- The proposed COUNT loss function is well justified and shows improved performance on two datasets, ParaDetox and APPDIA.
- The experimental design is sound, with clear comparisons against standard automatic evaluation metrics.
- The paper is well-written and presents its findings in a concise manner.

Weaknesses:
- The lack of human evaluation limits the robustness of the conclusions drawn from the experiments.
- The generalization of the proposed loss function is not demonstrated across multiple models, as only BART is fine-tuned.
- The absence of supplementary materials, such as code, hinders reproducibility.

### Suggestions for Improvement
We recommend that the authors improve the paper by including human evaluation to strengthen their claims. Additionally, providing examples or diagrams to illustrate the differences between COUNT, Unlikelihood Training, and standard language models would enhance understanding. A quick analysis of COUNT's computational complexity relative to other methods should also be included. Furthermore, addressing the generalization of the proposed loss function to other models and including supplementary materials would significantly aid in verifying the implementation. Lastly, we suggest a more thorough discussion of model failures and the specific cases where the proposed method may not perform optimally.