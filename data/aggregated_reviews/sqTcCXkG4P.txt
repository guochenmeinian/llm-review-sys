ID: sqTcCXkG4P
Title: Sparsity-Preserving Differentially Private Training of Large Embedding Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 6, 3, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on enhancing embedding models using Differentially Private Stochastic Gradient Descent (DP-SGD). The authors propose two algorithms, DP-FEST and DP-AdaFEST, which leverage gradient sparsity by applying noise selectively to masked dimensions. The methods are evaluated on recommendation and language understanding tasks, demonstrating significant wall-clock time reductions when comparing `sparse-backpropagation + sparse-update` against `sparse-backpropagation + dense-update`, particularly for larger vocabulary sizes. The paper addresses the challenge of maintaining gradient sparsity during DP-SGD training, which is crucial for efficiency, and clarifies the privacy guarantees of their method in relation to existing techniques.

### Strengths and Weaknesses
Strengths:  
1. The investigation into learning embedding models through DP-SGD is meaningful, and the proposed methods are intuitive.  
2. The paper is well-written, with a clear presentation that aids comprehension. The problem is well-motivated, and the experiments support the claims made.  
3. The proposed method demonstrates substantial computational speedup, achieving wall-clock time reductions of up to 200 times in specific scenarios.  
4. The authors provide a thorough comparison with existing methods, showcasing the advantages of their approach in terms of gradient size reduction and efficiency.  
5. The paper addresses privacy concerns effectively, clarifying the equivalence of privacy guarantees between their method and DP-SGD.

Weaknesses:  
1. There is a mismatch between the title and the paper's content; the title should reflect the specific scope of the work more accurately.  
2. The proposed methods lack rigorous privacy analysis, and the paper does not adequately position itself within the existing literature on sparse technologies in DP.  
3. The effectiveness of the approach may be limited to specific scenarios, particularly where the embedding layer is a significant component of the model.  
4. The claim that this study is the first to address the technical challenges of applying DP-SGD to large embedding models may be misleading without a clear definition of these challenges.  
5. The writing style could be improved for better clarity and presentation of results, particularly regarding the overall optimization efficiency.

### Suggestions for Improvement
We recommend that the authors improve the title to better reflect the scope of the work, such as "Sparsity-Preserving Differentially Private Training of Embedding Vocabularies." Additionally, we suggest including the performances of non-private baselines in the empirical experiments to provide context for the results. The authors should also conduct a formal privacy analysis of DP-FEST and DP-AdaFEST, utilizing existing results to quantify privacy guarantees. Furthermore, we encourage a more thorough discussion of related works on DP and sparse technologies to better situate this study within the current literature. Lastly, we recommend improving the clarity of claims by specifying their definition of the general technical challenges of applying DP-SGD to large embedding models and enhancing the writing style to present the results and implications of their findings more transparently, particularly in relation to the overall optimization efficiency of large-scale networks.