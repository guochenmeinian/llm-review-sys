ID: RCO9fRP8AJ
Title: ImOV3D: Learning Open Vocabulary Point  Clouds 3D Object Detection from Only 2D Images
Conference: NeurIPS
Year: 2024
Number of Reviews: 22
Original Ratings: 5, 6, 5, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel framework for open-vocabulary 3D object detection (OV-3Det) that learns exclusively from 2D images, addressing the scarcity of annotated 3D data. The authors propose a pseudo-multimodal representation that bridges the gap between 2D images and 3D point clouds, enabling effective knowledge transfer. The method involves generating pseudo point clouds from 2D images using monocular depth estimation and rendering pseudo images from these point clouds. Extensive experiments demonstrate significant performance improvements on the SUNRGBD and ScanNet datasets.

### Strengths and Weaknesses
Strengths:
1. The approach of using only 2D images to train a 3D object detector is innovative and addresses a critical bottleneck in the field.
2. The framework effectively integrates multimodal data by converting 2D images into 3D point clouds and vice versa.
3. The paper includes extensive experiments and ablation studies, showcasing significant improvements over state-of-the-art methods.
4. The authors provide the code, ensuring reproducibility.

Weaknesses:
1. The claim of creating a 3D open vocabulary object detector solely from 2D images is misleading, as results indicate that such a detector performs worse than those using real point cloud data.
2. The model architecture is unclear, particularly how 2D images and 3D point clouds are processed and merged for final predictions.
3. The pseudo point cloud generation lacks detail on accuracy and fitting of 3D boxes, and the complexity of the pipeline raises questions about the necessity of certain steps.
4. There are concerns regarding the model's generalization ability, particularly in real-world applications and outdoor datasets.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the model architecture and provide a detailed description of how 2D images and 3D point clouds are processed and merged. Additionally, the authors should address the misleading nature of the title regarding the use of only 2D images and consider modifying it. More details on the accuracy of the pseudo ground truth and the fitting process for 3D bounding boxes should be included. Furthermore, we suggest simplifying the pipeline by potentially removing the image generation step and utilizing original images directly. Lastly, a thorough discussion on the model's generalization ability and performance in real-world scenarios should be added.