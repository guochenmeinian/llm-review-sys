ID: 3G2ec833mW
Title: Addressing Negative Transfer in Diffusion Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 7
Original Ratings: 6, 7, 5, -1, -1, -1, -1
Original Confidences: 4, 5, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper discusses the use of diffusion-based generative models for various tasks, including image, video, 3D shape, and text generation. The authors argue that negative transfer, arising from competition between conflicting tasks, should be investigated in diffusion models. They observe a negative correlation between task affinity and noise levels, indicating that adjacent denoising tasks are more compatible. Evidence of negative transfer is found during training, where models trained on specific denoising tasks yield higher-quality samples than those trained on all tasks simultaneously. To mitigate negative transfer, the authors propose leveraging multi-task learning techniques and clustering denoising tasks into intervals, demonstrating improved image quality through experiments.

### Strengths and Weaknesses
Strengths:
1. The paper provides a comprehensive analysis of diffusion-based generative models, highlighting their performance across various generative tasks and identifying potential areas for improvement.
2. The authors effectively address negative transfer in diffusion models, proposing a clustering approach that adds valuable insights to multi-task learning.

Weaknesses:
1. The experiments are limited to specific datasets (FFHQ and CelebA-HQ) and types of diffusion models (Ablated Diffusion Model and Latent Diffusion Model), which may restrict the generalizability of the proposed approach.
2. The paper lacks an in-depth theoretical analysis or mathematical formulation of the clustering strategy, which would enhance understanding of the approach.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their findings by evaluating the proposed method on a broader range of datasets and diffusion models. Additionally, we suggest including a more rigorous theoretical analysis of the clustering strategy to provide deeper insights into its principles. Furthermore, it would be beneficial to compare time and GPU memory usage between the vanilla and MTL approaches, and to include random weights and linear scalarization baselines as suggested by previous studies. Finally, conducting further analysis and ablation studies to determine the optimal number of clusters in the proposed internal clustering approach would strengthen the paper.