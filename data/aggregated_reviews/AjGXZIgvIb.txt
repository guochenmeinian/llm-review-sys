ID: AjGXZIgvIb
Title: Towards Concept-Aware Large Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an exploration of how large language models (LLMs) process human concepts, specifically analyzing their ability to capture and organize these concepts. The authors reveal that while LLMs can capture concepts to some extent, they often diverge from human organization, particularly regarding transitivity. They propose two mechanisms to enhance concept-awareness in LLMs: a pre-training sketch similar to Toolformer and an off-the-shelf procedure, with the latter showing improvement in concept-awareness.

### Strengths and Weaknesses
Strengths:
- The research question is timely and significant, addressing the interaction between LLMs and human concepts.
- Behavioral experiments are straightforward, well-designed, and yield interesting results.
- The paper is clear, well-written, and presents a novel approach to developing concept-aware LLMs.

Weaknesses:
- The implementation is limited to hyponyms and hypernyms, despite broader claims about concept processing.
- The paper lacks validation of its claims on state-of-the-art LLMs, such as ChatGPT or GPT-4.
- The practical implications of the proposed approaches, particularly regarding efficiency and inference latency, are not sufficiently discussed.

### Suggestions for Improvement
We recommend that the authors improve the validation of their claims by testing on state-of-the-art LLMs like ChatGPT and GPT-4. Additionally, the authors should clarify the practical applications of their proposed methods, particularly addressing the efficiency and inference latency concerns associated with conceptBERT. Including experiments on GPT and T5 in Section 4.3 would enhance the completeness of the study. Finally, we suggest moving the pre-training engineering sketch to a later section of the paper to allow for more focus on empirical results.