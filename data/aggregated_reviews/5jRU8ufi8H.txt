ID: 5jRU8ufi8H
Title: Unlocking Tokens as Data Points for Generalization Bounds on Larger Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 7, 6, 6, -1, -1
Original Confidences: 2, 4, 3, -1, -1

Aggregated Review:
### Key Points
This paper presents token-level generalization bounds for large language models (LLMs) like LLaMA2-70B, utilizing less restrictive compression techniques such as Monarch matrices, Kronecker factorizations, and post-training quantization. The authors argue that traditional document-level bounds are inadequate at this scale and introduce a method leveraging martingales for deriving tighter bounds, which are validated empirically.

### Strengths and Weaknesses
Strengths:  
1. **Originality**: The paper introduces a novel approach to computing generalization bounds at the token level, significantly departing from the document-level bounds of prior works.  
2. **Technical Soundness**: The innovative use of martingales and non-restrictive compression methods provides a robust theoretical framework supported by empirical results.  
3. **Significance**: The ability to derive non-vacuous generalization bounds for LLMs with up to 70 billion parameters is highly significant, advancing the understanding of LLM generalization in practical contexts.  
4. **Clarity**: The paper is well-written, with clear explanations of methods and implications, making it accessible to a broader audience.  

Weaknesses:  
1. The paper lacks intuitive explanations for the proposed bounds, which may hinder understanding for readers unfamiliar with advanced statistical concepts.  
2. The left-hand side of eq. (2) uses contexts from the training data, making it somewhat hard to interpret.  
3. The main models examined are primarily from the LLaMA and GPT-2 families; more experiments on other fine-tuned LLMs would provide additional evidence.  
4. As model sizes increase, the derived bounds approach random guess performance, raising questions about their meaningfulness at larger scales.  

### Suggestions for Improvement
We recommend that the authors improve the paper by including background and a proof sketch on the utilization of martingales in the main text. Additionally, we suggest conducting more experiments on various fine-tuned LLMs to explore generalization trends further. Clarifying why the derived bounds approach random guess performance with larger models would also enhance understanding. Finally, providing more intuitive explanations for the proposed bounds would benefit readers less familiar with advanced statistical concepts.