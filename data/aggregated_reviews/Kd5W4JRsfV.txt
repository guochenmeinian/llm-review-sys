ID: Kd5W4JRsfV
Title: Layer-Neighbor Sampling --- Defusing Neighborhood Explosion in GNNs
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 6, 4, 6, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 2, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the LABOR sampling algorithm, which addresses the neighbor explosion problem (NEP) in graph neural networks (GNNs) by combining layer sampling (LADIES), neighbor sampling (NS), and Poisson sampling. LABOR calculates sampling probabilities iteratively for each layer and enhances LADIES by employing sampling without replacement. The authors derive the hidden layer variance of PLADIES, demonstrating that it can converge to zero under certain conditions, thus showing improved convergence properties. Experimental results indicate that LABOR achieves better sampling efficiency, requiring only 1/7 of the vertices to reach the same F1-score as NS while utilizing 112 times larger batch sizes during training. The authors also propose comparisons with various baseline methods, although some reviewers note that these baselines may not represent the current state-of-the-art.

### Strengths and Weaknesses
Strengths:
- LABOR provides a more accurate estimator with lower variances compared to LADIES, ensuring that sampled vertices include their neighbors.
- It demonstrates superior vertex and edge efficiency compared to NS, achieving equivalent F1-scores with fewer sampled vertices.
- The authors have effectively addressed most concerns raised in previous reviews, leading to an improved evaluation score, particularly through clarifications regarding the experiments.

Weaknesses:
- The experimental evaluation lacks sufficient detail, particularly regarding hyperparameter settings and total training time.
- Some concerns remain unresolved, including the use of outdated baselines that do not reflect the latest advancements in GNN training methods.
- The complexity of different methods is not summarized in a standalone table, which could enhance clarity.
- Some technical aspects remain unclear, and comparisons with more recent state-of-the-art methods are limited.

### Suggestions for Improvement
We recommend that the authors improve the experimental evaluation by providing detailed hyperparameter settings and explicitly reporting total training time. Clarifying the definition of "same sampling budget" in Table 2 is essential. Additionally, we suggest including a broader range of recent sampling methods for comparison, such as FastGCN and GraphSAINT, to strengthen the paper's contribution. We also recommend improving the selection of baselines to include more current state-of-the-art methods for a more persuasive comparison. Furthermore, summarizing the complexity of different methods in an independent table, independent of specific datasets, would enhance the paper's clarity and comprehensiveness. Finally, the clarity of Algorithm 1 should be enhanced by providing pseudo-code and explaining the notations used, and reconsidering the title to better reflect the contributions while avoiding subjective language in the discussion of related works would improve the paper's presentation.