ID: McrzOo0hwr
Title: Theoretical Investigations and Practical Enhancements on Tail Task Risk Minimization in Meta Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 8, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates tail risk minimization in meta-learning, presenting a novel approach that reformulates DR-MAML as a Stackelberg game. The authors provide theoretical analyses on convergence rates and generalization bounds, alongside extensive empirical evaluations that demonstrate improved robustness. The work enhances DR-MAML through more accurate quantile estimates, contributing to the understanding of distributional robustness in meta-learning.

### Strengths and Weaknesses
Strengths:  
- The paper is well-written and presents a comprehensive theoretical framework, clarifying contributions through detailed proofs and extensive experiments.  
- The reformulation of DR-MAML as a Stackelberg game allows for a unique analysis from a game-theoretic perspective, supported by both theoretical guarantees and numerical validations.  

Weaknesses:  
- The contribution is somewhat incremental and primarily focused on DR-MAML, limiting broader applicability.  
- The writing lacks clarity in certain areas, with vague definitions and unclear figures.  
- Experiments are limited, lacking comparisons to state-of-the-art methods, and improvements reported are marginal.  
- There is no discussion on time and space complexity, leaving scalability to larger neural networks uncertain.  
- Numerous typos and formatting issues detract from the overall presentation.

### Suggestions for Improvement
We recommend that the authors improve the clarity of definitions and figures, particularly by providing mathematical expressions instead of relying solely on illustrations. Additionally, we suggest including comparisons to popular meta-learning methods such as MetaCurvature and MetaOptNet on benchmark datasets. It would be beneficial to discuss time and space complexity explicitly, especially regarding scalability to large neural networks. Lastly, we advise proofreading the manuscript to correct typos and enhance overall readability.