ID: cgiP4cMBP9
Title: Fine-Grained Cross-View Geo-Localization Using a Correlation-Aware Homography Estimator
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 6, 3, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for cross-view geo-localization by aligning ground-view images with aerial-view images through homography estimation and aligning BEV images of ground cameras with satellite images for accurate 3-DoF localization. The authors propose a differentiable spherical transform to convert panoramic images into BEV images and a correlation-based homography estimator to match similar regions in the images. The method achieves state-of-the-art performance on the VIGOR and KITTI datasets at a speed of 28 FPS. The authors argue that their method outperforms recent learning-based BEV methods, particularly in localization accuracy, and addresses ground camera pose refinement through iterative updates of the residual homography between projected and reference satellite images.

### Strengths and Weaknesses
Strengths:
- The idea of using homography estimation for geo-localization is innovative and well-articulated.
- The proposed correlation-aware homography estimation module demonstrates promising results on the VIGOR and KITTI datasets.
- The authors demonstrate significant advantages in localization accuracy compared to recent methods, as shown in detailed comparative tables.
- The approach is intuitive and efficient, avoiding the complexities associated with SVD decomposition.
- The writing is clear, making the paper's motivation and methodology easy to follow.

Weaknesses:
- The flow of data in the figures is unclear, particularly in Fig 2, where parts are only connected via the correlation map. The lack of code availability raises reproducibility concerns.
- The novelty of the spherical transform compared to existing methods like inverse perspective mapping (IPM) is not sufficiently justified.
- The necessity of re-creating camera pose labels from point cloud data is questioned, as previous works have computed these directly from GPS data.
- The claim of novel contributions regarding label correction methods lacks strong experimental verification.
- The paper lacks detailed explanations on estimating camera pose from homography, including the selection of points for orientation estimation and the handling of occlusions.
- Some reviewers express skepticism about the robustness of the method in non-planar scenarios without experimental validation.
- The experiments do not consistently show improvements over baselines, and the paper does not adequately discuss the limitations of using homography estimation.
- There is insufficient discussion on the societal impact of the proposed method and the accuracy of GPS labels in the datasets used.

### Suggestions for Improvement
We recommend that the authors improve the clarity of data flow in the figures, particularly in Fig 2, and consider releasing the code to enhance reproducibility. Additionally, the authors should provide a more thorough comparison of the spherical transform with existing methods like IPM, including a discussion on the advantages of their approach. It is crucial to clarify the process of estimating camera pose from homography, particularly how to select points for orientation estimation and address occlusion issues. We also suggest including more homography-based baselines in the experiments to validate the proposed method's effectiveness. Furthermore, we recommend improving the experimental verification of claims regarding the robustness of the method in non-planar scenarios and providing clearer evidence to support the necessity of the label correction method as a novel contribution. Finally, addressing the concerns regarding the re-creation of camera pose labels and including a discussion on the societal impact and a critical evaluation of GPS label accuracy should be added to strengthen the paper's contributions.