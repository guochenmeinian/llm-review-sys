ID: As91fJvY9E
Title: End-to-end Learnable Clustering for Intent Learning in Recommendation
Conference: NeurIPS
Year: 2024
Number of Reviews: 18
Original Ratings: 4, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ELCRec, an end-to-end learnable clustering framework for intent learning in recommendation systems. It integrates user behavior embeddings into a user embedding and introduces a differentiable clustering method (ELCM) that optimizes clustering and intent alignment. The framework employs intent-assisted contrastive learning (ICL) and includes a next item prediction loss to enhance recommendation performance. The authors claim that ELCRec addresses the slow clustering speeds and limited scalability of existing methods, which often separate clustering and optimization processes. Additionally, the authors provide a series of rebuttals addressing reviewer concerns related to cluster centers for new users, proportions for loss functions, VQ/RQ-based methods, latency on the sports dataset, and time and space costs, indicating that their responses have improved the paper's quality.

### Strengths and Weaknesses
Strengths:
1. The ELCRec framework innovatively combines clustering and intent learning into a single end-to-end differentiable model, significantly enhancing efficiency and accuracy.
2. The introduction of Intent-Coupled Contrastive Learning (ICL) improves user embeddings by incorporating intent information, addressing limitations of traditional methods.
3. The provision of complete experimental code and detailed descriptions of procedures facilitates replication and validation by other researchers.
4. The authors demonstrate a willingness to engage with reviewers and address their concerns thoroughly, leading to a higher quality submission.

Weaknesses:
1. The paper lacks detailed information on how embeddings or cluster centers are assigned to new users during inference, despite claims of efficient handling of new users.
2. The training approach using next_item loss, ICL loss, and cluster loss is not clearly defined regarding the appropriate proportions, particularly the fixed ratio between next_item loss and ICL loss.
3. The increase in latency on the sports dataset is unexplained, raising concerns about the method's consistency across different datasets.
4. The paper does not adequately compare ELCRec with contemporary end-to-end training approaches based on Vector Quantization (VQ) or Residual Quantization (RQ), which is a significant oversight.
5. Some reviewers have not yet provided post-rebuttal responses, which may hinder the final evaluation process.

### Suggestions for Improvement
We recommend that the authors improve the explanation of how embeddings or cluster centers are assigned to new users during inference. Additionally, the authors should clarify the proportions of the combined training losses, particularly whether the ratio between next_item loss and ICL loss should remain fixed at 0.1. To address the latency issue observed in the sports dataset, we suggest providing a detailed analysis of the optimization process and its implications. Furthermore, we encourage the authors to include a comparative analysis of ELCRec with VQ/RQ-based methods to highlight the advantages of their approach. Lastly, we recommend that the authors improve their follow-up communication with reviewers to ensure timely feedback and continue refining their responses to any outstanding concerns to further enhance the paper's quality.