ID: OrtN9hPP7V
Title: The GAN is dead; long live the GAN! A Modern GAN Baseline
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 9, 5, 6, -1, -1, -1
Original Confidences: 5, 3, 3, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents R3GAN, a GAN baseline that modernizes architecture by replacing ad-hoc tricks with advanced designs. The authors utilize a regularized relativistic GAN loss with zero-centered gradient penalties on both real and generated data to address mode dropping and non-convergence, ensuring local convergence guarantees. R3GAN demonstrates improved stability and competitive performance against state-of-the-art models on datasets such as StackedMNIST, CIFAR-10, ImageNet-32, and FFHQ-256. The authors argue that the stagnation in GAN research is due to the foundational StyleGAN2 lacking significant architectural changes, which they aim to rectify through their proposed methodology.

### Strengths and Weaknesses
Strengths:
- The writing is clear, facilitating understanding and following of the paper.
- The simplification and optimization of the StyleGAN architecture achieve considerable performance without elaborate tricks.
- The paper provides theoretical analysis supporting the convergence of the proposed loss.
- The integration of well-known techniques into a cohesive GAN framework is a notable contribution.
- Experimental results show significant improvements over existing GANs and some diffusion models.

Weaknesses:
- The novelty of the method is somewhat limited, as both relativistic pairing GAN (RpGAN) and zero-centered gradient penalties (0-GPs) are previously proposed approaches.
- Small-scale experiments may not sufficiently validate the improvements in stability and diversity; more complex datasets are needed.
- The new baseline still requires extensive hyperparameter tuning, which varies across datasets.
- There is a lack of information regarding the training setup and hyperparameters used for diffusion models in comparative tables.

### Suggestions for Improvement
We recommend that the authors improve the scalability of the proposed model by validating its effectiveness on higher-resolution datasets and more complex tasks. Additionally, we suggest including detailed information about the training setup, hyperparameters, and inference steps for diffusion models in the supplementary materials or tables for transparent comparisons. It would also be beneficial to streamline the hyperparameter tuning process, potentially by automating adjustments based on learning rate changes. Finally, addressing the questions raised regarding activation functions, normalization techniques, and the integration of ideas from PresGAN and DDGANs could enhance the paper's contribution.