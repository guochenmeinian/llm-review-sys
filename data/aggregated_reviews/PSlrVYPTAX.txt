ID: PSlrVYPTAX
Title: Conversational Recommender System and Large Language Model Are Made for Each Other in E-commerce Pre-sales Dialogue
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an exploration of the collaboration between conversational recommender systems (CRSs) and large language models (LLMs) in E-commerce pre-sales dialogues. The authors propose two methods: "CRSs assisting LLMs" and "LLMs assisting CRSs," evaluating their effectiveness across four subtasks: intent understanding, preference elicitation, product recommendation, and response generation. The evaluation relies on the U-NEED dataset, which includes dialogues from five product categories. While the findings indicate some improvements in performance, particularly in product recommendation, the clarity of the results and the novelty of the contributions are questioned.

### Strengths and Weaknesses
Strengths:
- The paper addresses a relevant and practical topic with real-world applicability.
- The experiments cover five product categories and include important sub-tasks for conversational recommendations.
- The authors provide detailed results and analysis that could inform future research.

Weaknesses:
- The experimental setup complicates the interpretation of gains, as improvements may stem from model capacity rather than the proposed methods.
- The novelty of the findings is limited, with previous works not adequately acknowledged.
- The writing lacks clarity, with poorly defined tasks and some sections appearing messy or hard to follow.
- Significant portions of the appendix are copied verbatim from prior work.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing, particularly in defining the subtasks and ensuring coherence in the experimental section. The authors should also justify the marginal advantages of their proposed methods over single LLMs and explore alternative interaction mechanisms. Additionally, we suggest that the authors properly attribute or rewrite the plagiarized content in the appendix and acknowledge previous works that relate to their findings. Lastly, the authors should provide a more comprehensive analysis of computational overhead and consider expanding their experimental analysis beyond a single dataset.