ID: FV4ngfUlY0
Title: Non-stationary Experimental Design under Linear Trends
Conference: NeurIPS
Year: 2023
Number of Reviews: 5
Original Ratings: 6, 6, 5, -1, -1
Original Confidences: 4, 4, 3, -1, -1

Aggregated Review:
### Key Points
This paper presents a new experimental design for non-stationary experiments, assuming that expected potential outcomes are linear in time. The proposed design includes a switchback experiment and a UCB-type algorithm for multi-armed bandits, with Phase 2 leveraging insights from Phase 1 while inference relies solely on Phase 1 data. The authors discuss theoretical properties such as upper bounds on estimation error and regret, and demonstrate Pareto optimality within the design class. 

### Strengths and Weaknesses
Strengths:
- The paper explores a previously unstudied scenario, introducing a novel design.
- The derivation of the regret bound under specific assumptions is a significant contribution.
- The observation regarding the non-tradeoff for choosing $\alpha$ in $(0,1/4]$ is insightful.
- The writing is clear and the design is practical.

Weaknesses:
- The linear trend assumption lacks compelling justification, with no realistic examples provided.
- The specific class of designs requires better motivation, particularly the rationale for using a switchback design.
- The optimality of the design is contingent on the chosen class and estimation strategy, raising questions about its robustness and applicability.
- Concerns exist regarding the linearity assumption's validity and its implications for practitioners.
- The paper lacks empirical evaluations to demonstrate the algorithm's performance against naive alternatives.

### Suggestions for Improvement
We recommend that the authors improve the justification for the linear trend assumption by providing realistic examples. Additionally, the authors should clarify the motivation for the switchback design and discuss its robustness in various scenarios. We suggest incorporating a broader class of models to enhance applicability and exploring the implications of not solely relying on Phase 1 data for inference. Furthermore, we encourage the authors to include empirical evaluations demonstrating the algorithm's performance across multiple scenarios, particularly varying $\sigma_a^2$. Lastly, a discussion on extending the framework to accommodate more than two arms would be beneficial.