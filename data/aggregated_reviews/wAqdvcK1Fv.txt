ID: wAqdvcK1Fv
Title: Energy-Based Modelling for Discrete and Mixed Data via Heat Equations on Structured Spaces
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 6, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an extension of the Energy Discrepancy (ED) framework for training energy-based models (EBMs) on discrete and mixed data, eliminating the need for Markov Chain Monte Carlo (MCMC) sampling. The authors detail methods for perturbing discrete data using continuous-time Markov chains (CTMC) and propose a Monte-Carlo estimate for the ED loss. They argue that ED provides more accurate estimates of the data distribution compared to other EBM training techniques, which may produce biased estimates advantageous for certain data types. The work demonstrates improvements in training efficiency and model performance across various applications, including discrete density estimation and calibrated classification, while benchmarking ED on various discrete datasets and addressing the sensitivity of their method to the assumption of a positive data distribution across the entire space.

### Strengths and Weaknesses
Strengths:
- The paper effectively extends the ED method to discrete and mixed data, providing solid theoretical analysis and practical applications.
- It introduces a clear connection between ED and pseudolikelihood estimation, enhancing the understanding of the method's implications.
- The results show favorable performance compared to standard contrastive divergence methods, particularly on synthetic and tabular datasets.
- The authors demonstrate a solid understanding of the limitations and advantages of their method compared to other EBM techniques.

Weaknesses:
- The clarity of the motivations behind specific methodological choices is lacking, making it difficult to follow the rationale for certain perturbation processes.
- The scalability of the proposed method for large categorical values is not adequately addressed, raising concerns about its practical applicability.
- The significance of results on real-world image modeling tasks appears less impressive, and the choice of baselines for comparison could be improved.
- The paper lacks a separate benchmark for discrete columns in mixed data types.
- There is insufficient discussion on the convergence of MCMC chains during sampling, which raises concerns about sample quality.
- The authors do not employ quantitative MCMC diagnostics to assess convergence, which is critical for ensuring the accuracy of generated samples.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivations for their methodological choices, particularly regarding the selection of perturbation processes and their implications for training. Additionally, a discussion on the scalability of the method for large categorical datasets should be included to enhance practical applicability. We suggest that the authors provide a more thorough comparison with more recent baselines beyond those from 2019 to better contextualize their results. Furthermore, we encourage the authors to clarify the connections to heat equations and the rationale for using small timesteps to strengthen the manuscript. We also recommend including quantitative MCMC diagnostics to assess convergence and ensure that samples correspond to the learned distribution. Lastly, conducting a separate benchmark that models only the discrete columns would provide a clearer evaluation of the method's performance on mixed data types.