ID: YEKelYP0Et
Title: Workshop Submission: Towards Making Untrainable Networks Trainable
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 6, 5, 6
Original Confidences: 4, 2, 1

Aggregated Review:
### Key Points
This paper presents a method to make "untrainable" neural networks trainable by utilizing a source network as a guide, aligning with the traditional teacher-student framework. The authors propose that randomly initialized source networks can outperform trained ones, a notable finding that differentiates their work. However, the paper inadequately connects its method to the established teacher-student framework and lacks sufficient references to related work, particularly in knowledge distillation and model transfer. The experiments show improvements across various difficult-to-train architectures but lack benchmarking against existing teacher-student methods, making it challenging to evaluate the true contribution relative to the state-of-the-art (SOTA).

### Strengths and Weaknesses
Strengths:  
- The method introduces a novel perspective on training untrainable networks, with promising experimental results.  
- The finding that randomly initialized source networks can outperform trained ones is intriguing.

Weaknesses:  
- The connection to the teacher-student framework is not adequately addressed.  
- The related work section lacks references to existing literature, limiting context and differentiation.  
- Experiments are not benchmarked against SOTA teacher-student methods, hindering assessment of contributions.

### Suggestions for Improvement
We recommend that the authors improve their paper by adding related work references to clarify connections with existing teacher-student frameworks. Additionally, including comparisons to SOTA methods in the teacher-student paradigm would strengthen the claims of significant performance improvements. Furthermore, clarification is needed regarding the training procedure with the untrained source network, specifically whether both networks are trained in parallel or if features from the source network are used to align the target's features. Exploring alternative similarity metrics for aligning intermediate features and considering the effect of aligning only the penultimate layer features could also enhance the experimental design. Lastly, expanding the scope of target networks tested would provide insights into the scalability of the approach.