ID: AFJYWMkVCh
Title: GNNs as Adapters for LLMs on Text-Attributed Graphs
Conference: ACM
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents GraphAdapter, a novel method that leverages the predictive capabilities of large language models (LLMs) for Text-Attributed Graphs (TAGs). The authors aim to address the challenges of high computational costs and limited representation power in jointly modeling text and graph structures. They propose a parameter-efficient GNN adapter that integrates with pre-trained LLMs, demonstrating computational efficiency and an average accuracy improvement of approximately 5% across various tasks and domains.

### Strengths and Weaknesses
Strengths:
1. The paper provides a comprehensive understanding of the challenges associated with TAGs, establishing a strong rationale for the necessity of GraphAdapter.
2. It effectively addresses computational inefficiency by introducing a parameter-efficient GNN adapter, significantly reducing the number of trainable parameters.
3. The extensive node classification experiments validate the model's effectiveness, showcasing a 5% accuracy improvement.

Weaknesses:
1. The introduction lacks logical coherence and fails to clearly articulate the specific problems the proposed method addresses.
2. There is a notable absence of comparative experiments with existing LLMs, limiting the evaluation of GraphAdapter's effectiveness.
3. The paper does not adequately discuss the role of prompts in the framework, nor does it clarify the generative task depicted in the figures.
4. The reported performance of baseline models in experiments appears inconsistent with original results, raising concerns about fairness and competitiveness.
5. The paper's organization is somewhat unclear, with insufficient focus on the text-attributed graph task.

### Suggestions for Improvement
We recommend that the authors improve the logical coherence of the Introduction by clearly articulating the specific challenges their method addresses. Additionally, including comparative experiments with existing LLMs would strengthen the evaluation of GraphAdapter's performance. We suggest providing a detailed discussion on the role of prompts within the framework and clarifying the generative task in the figures. Furthermore, addressing the discrepancies in reported baseline performance and enhancing the clarity of the paper's organization would contribute to a more robust presentation. Lastly, we encourage the authors to include comparisons with popular parameter-efficient tuning methods, such as LoRA, and to provide insights on the running time and GPU costs associated with their method.