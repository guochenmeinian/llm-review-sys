ID: QSJKrO1Qpy
Title: Hodge-Aware Learning on Simplicial Complexes
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 4, 4, 2, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 2, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a convolutional architecture designed for simplicial data, leveraging Hodge decomposition principles. The authors propose a model, SCCNN, that incorporates three key properties: uncoupling lower and upper simplicial adjacencies, accounting for inter-simplicial couplings, and performing higher-order convolutions. They analyze the Dirichlet energy to address oversmoothing and provide theoretical guarantees regarding the model's stability against perturbations. The paper emphasizes the advantages of SCCNN over MPSN, arguing that it enhances learning effectiveness by maintaining the independence of gradient and curl subspaces. Empirical validation is conducted through various tasks, including forex rate prediction and simplex prediction, while the authors assert that their contributions lie in the theoretical analyses provided in Sections 3.2, 4, and 5.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written, providing a clear overview of the problem and motivation.
2. The proposed SCCNN demonstrates promising empirical performance and is supported by theoretical analysis.
3. The incorporation of Hodge theory into the learning task is original and provides valuable insights.
4. The authors effectively advocate for the SCCNN method by highlighting its theoretical foundations and practical implications for learning simplicial signals.
5. A thorough comparison with existing methods showcases the relevance of their approach.

Weaknesses:
1. The paper lacks diverse applications and comparisons with state-of-the-art graph neural network (GNN) models, limiting its practical relevance.
2. Clarity issues arise from typographical and grammatical errors, making it difficult to follow.
3. The contributions of the paper are not clearly articulated, particularly regarding the novelty of the proposed architecture compared to existing models.
4. The experimental scope is perceived as limited, lacking exploration of tasks such as clique-lifted graphs or large-scale datasets.
5. Some reviewers question the generalizability of the findings, suggesting that many standard datasets do not exhibit the orthogonal subspace decomposition.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by addressing typographical and grammatical errors throughout, particularly in the introduction and key sections. Additionally, we suggest providing more diverse applications of the SCCNN, including comparisons with widely used datasets and advanced GNN models. It would also be beneficial to clarify the definition of Hodge-aware learning early in the manuscript and to provide a more detailed discussion on the motivation behind the stability analysis. Furthermore, we recommend enhancing the experimental section by including additional tasks, such as clique-lifted graph tasks or larger-scale datasets, to demonstrate the versatility of SCCNN. Addressing the concerns regarding the perceived limitations of the experiments could also strengthen the paper's overall impact.