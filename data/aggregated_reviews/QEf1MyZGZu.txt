ID: QEf1MyZGZu
Title: Target-Aware Spatio-Temporal Reasoning via Answering Questions in Dynamic Audio-Visual Scenarios
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to audio-visual question answering (AVQA) through a target-aware joint spatio-temporal grounding network. It comprises two main components: the target-aware spatial grounding module (TSG), which identifies relevant audio-visual cues based on the query, and the single-stream joint audio-visual temporal grounding module (JTG), which simplifies the alignment of audio-visual features. The authors also introduce a cross-modal synchrony loss (CSL) to enhance synchronization between modalities. Extensive experiments demonstrate the effectiveness of the proposed approach.

### Strengths and Weaknesses
Strengths:
- The proposed single-stream alignment module is simpler than previous methods.
- The approach shows promising performance and includes thorough experimental analysis, including ablation studies.
- The introduction of CSL enhances synchronization between audio and visual modalities.

Weaknesses:
- The novelty of the approach is questioned, as the target-aware grounding module appears similar to standard attention mechanisms.
- The justification for using a single-stream network is unclear, particularly since audio and visual features are processed separately.
- The paper relies on a single dataset, which limits the generalizability of the results.
- Many symbols and terms are not defined, making the paper difficult to understand.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the manuscript by defining all symbols and terms used throughout the paper. Additionally, the authors should provide a more thorough comparison with previous works in Table 1 to strengthen their claims. It would also be beneficial to justify the use of a single-stream architecture more clearly, especially in relation to the two-stream approach. We suggest conducting experiments on multiple datasets to enhance the generalizability of the findings. Finally, addressing the minor technical errors and ensuring that all components are clearly distinguished will improve the overall readability of the paper.