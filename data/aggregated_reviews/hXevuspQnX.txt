ID: hXevuspQnX
Title: InsActor: Instruction-driven Physics-based Characters
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 7, 5, 5, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 4, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents InsActor, a framework for instruction-driven character animation that combines high-level diffusion motion planning with low-level physics-based control. The authors propose a method that generates state sequences from human instructions using a diffusion model, which are then translated into physically plausible trajectories by a skill embedding model. The approach employs a language-conditioned neural network to create physics-based human character animations intuitively. The method utilizes an inpainting strategy to ensure critical phases are captured, akin to keyframes in traditional animation. The authors demonstrate improved performance over existing methods on benchmarks like KIT-ML and HumanML3D, showcasing the ability to follow text prompts and achieve specified waypoints. Key contributions include the integration of diffusion and autoencoder models, the inpainting strategy, and a waypoint system.

### Strengths and Weaknesses
Strengths:
- The paper effectively articulates its motivations, methods, and experimental results, demonstrating that InsActor outperforms baseline methods.
- The hierarchical approach of using a diffusion model for high-level planning followed by a physics-based motion VAE is novel and offers a solid foundation for future research.
- The clever combination of inpainting with diffusion is a notable advantage, and the method does not require reinforcement learning, unlike some recent approaches.
- The use of contrastive models for evaluating animation faithfulness and diversity is commendable, as these are critical in animation.

Weaknesses:
- The novelty of the work is limited, as it appears to be a straightforward integration of existing techniques in character motion synthesis and diffusion methods.
- The qualitative results are concerning, with observed issues such as jittery and unnatural movements, which undermine the effectiveness of the proposed method.
- A significant limitation is the lack of interaction with the environment and the inability to specify objects in actions, making the system less appealing for practical use.
- Important details, such as waypoint encoding, are inadequately explained, raising concerns about user requirements for animation.
- The paper fails to address issues like foot skating and object interactions, which are critical for realistic animations.

### Suggestions for Improvement
We recommend that the authors improve the qualitative aspects of the generated motion by addressing the jittering and unnatural movements observed in the simulations. Additionally, we suggest incorporating object identification and manipulation capabilities to enhance the system's applicability. A detailed comparison with a state-of-the-art kinematic diffusion model like MDM should be included to better motivate the need for physics in text-to-motion. We also recommend providing clearer explanations of the waypoint encoding process, including user requirements for setting joint values. To strengthen the visual fidelity of the animations, we advise investigating the causes of artifacts such as foot sliding and jittering, potentially by exploring alternative physics simulators or incorporating trajectory optimization with stronger contact constraints. Lastly, including metrics like acceleration error and velocity error alongside MPJPE would provide a more comprehensive evaluation of tracking performance.