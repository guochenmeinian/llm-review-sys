ID: NQB9myZksw
Title: Robustly overfitting latents for flexible neural image compression
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 5, 7, 6, -1, -1
Original Confidences: 4, 3, 4, -1, -1

Aggregated Review:
### Key Points
This paper presents a method to enhance the compression performance of pre-trained end-to-end neural image compression techniques by fine-tuning the latents at test time using the rate-distortion loss. The authors propose a three-class rounding method, named SGA+, which extends stochastic Gumbel annealing (SGA). They demonstrate that their method achieves better rate-distortion performance than existing methods across two pre-trained models and datasets.

### Strengths and Weaknesses
Strengths:
- The proposed SGA+ method offers straightforward approximations that are easy to implement.
- The results indicate improvements in rate-distortion performance, supported by detailed ablations in the appendix.

Weaknesses:
- The motivation for the three-class rounding is unclear, and the necessity of applying the algorithm to hyper latents is not discussed.
- The method's complexity is acknowledged, with modest gains in performance.
- The authors incorrectly claim that the gradients tend to infinity at 0 for the SGA method, which is not true and undermines their argument.
- The experiments lack insight and do not convincingly demonstrate significant improvements from the proposed modifications.
- The writing quality needs enhancement, including the removal of unnecessary details and clarification of notation.
- The paper fails to provide a B-D rate gain comparison with existing methods and lacks analysis on the distribution of latents across the proposed classes.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their motivation for the three-class rounding and discuss its necessity for hyper latents. Additionally, the authors should provide a B-D rate gain analysis to quantify the average compression improvement. We suggest revising the manuscript to clarify the function used for probability generation and enhance figure readability by using vector graphics and increasing font sizes. Finally, the authors should address the confusion surrounding the gradient behavior at the corners of the SGA method and ensure that the notation is consistent throughout the paper.