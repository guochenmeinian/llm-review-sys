ID: AGVBqJuL0T
Title: Fantastic Robustness Measures: The Secrets of Robust Generalization
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 3, 7, 8, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a large-scale empirical analysis of the correlation between existing robustness measures and the robust generalization gap across various experimental settings. The authors evaluate measures based on weight-norm, margin, smoothness, flatness, gradient-norm, and robust generalization, considering factors such as model architecture, training methods, and data augmentation. The findings indicate that existing measures are highly sensitive to training setups, rendering them ineffective in predicting robust generalization. Additionally, the authors conducted linear regression analyses, revealing that 'average_ce(PGD)' consistently correlates highly with the robust generalization gap. They explored combinations of measures, identifying 'x_grad_norm' and 'pacbayes_mag_flat(PGD)' as effective predictors, and addressed the terminology used for measures, agreeing to adopt 'robustness measures' for clarity. The implications of their model choices and the importance of analyzing test data alongside training data were also discussed.

### Strengths and Weaknesses
Strengths:
1. The paper conducts extensive experiments to explore the correlation between different measures and the robust generalization gap.
2. It provides a thorough exploration of robustness measures and their predictive capabilities.
3. The authors demonstrate responsiveness to reviewer feedback, enhancing the clarity and depth of their analyses.
4. The inclusion of a 5-fold evaluation strategy adds rigor to the predictive modeling.
5. The paper presents new findings regarding robust overfitting and challenges prior beliefs about the effectiveness of popular robustness measures.

Weaknesses:
1. The lack of innovation is notable, as the authors primarily focus on existing measures without proposing new ones.
2. The contribution is limited; the finding that existing measures are ineffective does not clarify the underlying mechanisms of robust overfitting.
3. The title is non-descriptive and incendiary, which is inappropriate for an academic publication.
4. The methodology is similar to previous work, particularly Jiang et al. (2020), without adequately addressing this relationship.
5. The reliance on linear regression may limit the exploration of nonlinear relationships between variables.
6. The initial presentation of measures lacked comprehensive descriptions, which could hinder reader understanding.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their findings, particularly regarding the implications of margin maximization and the applicability of `boundary_thickness` for different adversarial training methods. A deeper analysis of causal factors influencing the generalization gap, akin to Jiang et al. (2020), would enhance the paper's contribution. Additionally, we suggest revising the title to be more descriptive and ensuring that all references are included in the introduction to provide context. The authors should clarify the evaluation metrics and their definitions within the main text to improve readability. We also recommend incorporating analyses on the test set to validate their findings further, and including detailed explanations of the dataset, attack choices, and norms in both the Introduction and the abstract to enhance transparency. Finally, we encourage the authors to provide short descriptions for each measure at their first mention in Section "4 Experiments" and to explore stronger attacks beyond PGD-10 for evaluating robustness, ensuring that the robustness gap is measured only when models are robust on the training set.