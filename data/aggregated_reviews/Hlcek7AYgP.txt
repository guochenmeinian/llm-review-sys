ID: Hlcek7AYgP
Title: Neural Embeddings Rank: Aligning 3D latent dynamics with movements
Conference: NeurIPS
Year: 2024
Number of Reviews: 19
Original Ratings: 6, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 1, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel dimensionality reduction method called Neural Embedding Ranks (NER) aimed at aligning neural dynamics with movement in brain-computer interfaces. The authors demonstrate that NER outperforms six existing dimensionality reduction techniques across various brain regions and tasks, effectively decoding all movement parameters from neural dynamics. The experiments include comparisons with CEBRA and Pi-VAE, highlighting NER's superior performance in aligning latent dynamics with hand position and direction. Additionally, the paper provides a detailed analysis of position decoding and direction classification accuracy, clarifying that the value 0.93 in Fig. 4d represents **R²** for position decoding, while Fig. 4e indicates **direction classification accuracy (%)**. The authors address confusion regarding negative R² values in velocity decoding, explaining that these arise when using linear decoders, particularly in CEBRA, due to the model's struggle with infrequent large amplitude velocities.

### Strengths and Weaknesses
Strengths:
- The experimental design is comprehensive, covering multiple brain areas (M1, PMd, S1) and various task conditions, showcasing statistical rigor.
- Extensive benchmarking against six other techniques provides a thorough evaluation of NER's performance.
- The paper includes numerous informative figures and visualizations that effectively illustrate statistical results.
- The authors provide clear explanations regarding the R² values and the implications of using linear decoders.
- The decision to use a simple linear mapping is well-justified, enhancing the clarity of the model's performance.
- NER's effectiveness is significant, demonstrating superior performance across different tasks.

Weaknesses:
- The methodology section lacks clarity, with insufficient explanations and annotations for the equations presented.
- There is limited discussion on the underlying reasons for NER's improved performance compared to similar methods like CEBRA.
- The authors do not compare their model with AutoLFADs or CTRL-TNDM, which could provide additional context for their contributions.
- The paper contains typographical errors and inconsistencies in notation, which detract from its overall presentation.
- The experiments lack an assessment of statistical significance, which is crucial for validating the results.
- The motivation for the RNC loss and its impact on performance is not sufficiently highlighted, which may lead to confusion for readers.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the methodology section by providing more detailed explanations and annotations for the equations. Additionally, a more thorough discussion on the effectiveness of the Rank and Contrast loss in comparison to other methods, particularly CEBRA, would enhance the paper's contribution. We also suggest including comparisons with AutoLFADs and CTRL-TNDM to contextualize NER's performance further. Furthermore, addressing the typographical errors and ensuring consistent notation throughout the paper will improve its presentation. Lastly, incorporating a statistical analysis of the results would strengthen the validation of the findings. Additionally, we recommend that the authors improve the motivation and explanation of the RNC loss in the camera-ready submission, clearly articulating why it was applied and how it enhances performance. Ensure that the revisions to Fig. 4e and 4f include **%** for clarity.