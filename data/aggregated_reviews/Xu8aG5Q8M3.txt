ID: Xu8aG5Q8M3
Title: LayoutGPT: Compositional Visual Planning and Generation with Large Language Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 5, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents LayoutGPT, a method designed to enhance the visual planning capabilities of Large Language Models (LLMs) by generating layouts for 2D images and 3D indoor scenes based on text conditions. The authors demonstrate that LayoutGPT can produce plausible layouts that reflect specified counts, positions, attributes, and sizes, outperforming existing text-to-image models and achieving results comparable to human users. The paper introduces a new benchmark, NSR-1K, for evaluating layout generation in terms of numerical and spatial reasoning. Additionally, the authors focus on layout planning and generation in 2D and 3D spaces, distinguishing their work from downstream image generation methods. They have engaged with reviewers to clarify concerns and have made revisions based on feedback, including testing LayoutGPT on additional datasets such as COCO2017 Panoptic and counterfactual prompts generated by ChatGPT.

### Strengths and Weaknesses
Strengths:
1. The authors propose a novel solution to the limitations of current visual generation models by utilizing LLMs for layout generation, supported by in-context visual demonstrations in a structured format.
2. LayoutGPT effectively generates reasonable layouts across multiple domains, including 2D and 3D scenes.
3. The introduction of the NSR-1K benchmark provides a valuable tool for evaluating text-to-image generation tasks.
4. The authors have effectively addressed most reviewer concerns, leading to a positive shift in ratings and demonstrating a commitment to improving the work based on feedback.
5. The inclusion of additional testing on complex text conditions enhances the robustness of the model.

Weaknesses:
1. The motivation for the study lacks clarity, with dubious claims regarding the reasoning capabilities of existing visual generative models compared to LLMs.
2. The writing contains inconsistent notations and unclear descriptions, particularly regarding the structured format and its necessity.
3. The paper does not adequately address the limitations of LLMs in handling complex visual inputs or the robustness of LayoutGPT under varying conditions.
4. Some reviewers remain skeptical about the model's performance with more complex text descriptions, indicating a need for further validation.
5. There is a lack of comparative baselines for 2D image generation, and the evaluation metrics could be more comprehensive.
6. The paper may not be directly comparable to certain related studies, which could limit its contextual relevance.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation section by providing a more robust justification for the need for LayoutGPT and addressing the discrepancies in reasoning skills between LLMs and visual generative models. Additionally, we suggest that the authors clarify the necessity of using CSS as a structured format and explore alternative representations for layout information. It would also be beneficial to include more detailed experimental evaluations, such as comparing LayoutGPT with existing layout-based methods and reporting additional metrics like MeanIoU. Furthermore, we recommend that the authors conduct more extensive experiments with complex text conditions to alleviate reviewer skepticism and clarify the distinctions between their work and related studies to strengthen the paper's positioning in the literature. Lastly, providing examples of complex text conditions and their corresponding layouts would effectively demonstrate the model's capabilities.