ID: tRjgapiCpm
Title: The Last Iterate Advantage: Empirical Auditing and Principled Heuristic Analysis of Differentially Private SGD
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 3, 3, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a heuristic approach for evaluating the privacy of DP-SGD when only the last model iteration is released, contrasting with traditional analyses that consider all intermediate updates. The authors argue that this method offers a more practical assessment for scenarios where adversaries only access the final model. The heuristic is based on a linear structure assumption and is experimentally validated, demonstrating reliable privacy leakage estimates. Additionally, the paper introduces a heuristic for hyperparameter selection based on privacy auditing, aiming to balance high utility and low privacy loss. The authors propose that hyperparameters should be calibrated to achieve a good privacy parameter $\varepsilon$, emphasizing dual privacy constraints. Theorem 1 indicates that the heuristic will always be smaller than the existing $(\epsilon, \delta)$-DP bound, although the connection between privacy auditing and the heuristic appears weak, relying primarily on empirical observations. The reviewers express a need for broader validation beyond CIFAR10 to establish the heuristic's reliability.

### Strengths and Weaknesses
Strengths:
- The premise of the paper is interesting, focusing on significant questions regarding privacy analysis in DP-SGD and hyperparameter selection.
- The paper is well-written, with a clear layout and thorough assessment of the heuristic's limitations.
- The authors provide a new analysis that critically examines the implications of releasing only the last iterate.
- The heuristic for hyperparameter selection is an innovative approach that addresses privacy concerns in machine learning.
- The authors provide a clear rationale for the dual privacy constraints and the calibration of hyperparameters.

Weaknesses:
- The linear loss function assumption, while common, raises questions about its applicability to empirical cases.
- The necessity and effectiveness of the heuristic analysis are debated, as it lacks the precision of theoretical analysis.
- The empirical study is perceived as thorough but sparse on interpretation, lacking a strong take-home message.
- The proposed heuristic may not be widely applicable to common implementations of DP-SGD without regularization.
- The connection between privacy auditing and the heuristic lacks strong theoretical justification.
- Empirical validation is limited to CIFAR10, raising concerns about the generalizability of the findings.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Table 1 and elaborate on its implications, particularly regarding the relationship between batch size and heuristic Îµ. Additionally, the authors should address the skepticism surrounding the heuristic's practical utility by providing more robust interpretations of their empirical results. It would also be beneficial to justify the linear loss assumption more thoroughly and explore the extension of their analysis to non-linear loss functions. Furthermore, we suggest improving the theoretical justification connecting privacy auditing and the heuristic, potentially by providing more robust empirical evidence across a wider range of problems and datasets. Lastly, we recommend clarifying the setup for hyperparameter selection to better articulate the balance between privacy auditing and utility maximization.