ID: 2wFVkTDGOZ
Title: Emptying the Ocean with a Spoon: Should We Edit Models?
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a position against model editing approaches aimed at improving the factuality of large language models (LLMs). The authors argue that the probabilistic nature and training objectives of LLMs are unsuitable for factual purposes, that the sheer volume of facts requiring updates makes model editing impractical, and that extensive editing could lead to catastrophic forgetting. They propose alternative methods such as retrieval-augmented generation and concept erasure as more viable solutions.

### Strengths and Weaknesses
Strengths:  
The paper provides a strong critique of existing model editing methods, highlighting issues such as fact popularity bias and robustness. It presents a well-argued case against the feasibility of model editing and discusses alternative approaches to mitigate hallucination issues effectively.

Weaknesses:  
Despite its strengths, the paper lacks empirical results and concrete examples to support its claims. The arguments regarding alternatives are somewhat superficial and resemble a literature survey rather than a critical analysis. Additionally, the paper's ambitious scope may dilute its impact, as it does not sufficiently differentiate between inherent limitations of LLMs and those specific to model editing.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their main contributions and points of novelty in the paper. It would be beneficial to provide empirical examples illustrating the issues with model editing to strengthen their argument. Additionally, we encourage the authors to refine their discussion of alternative approaches, offering more critical insights and potential solutions to the challenges identified. Finally, incorporating more theoretically grounded works and recent citations related to grounding LLM outputs would enhance the paper's credibility and depth.