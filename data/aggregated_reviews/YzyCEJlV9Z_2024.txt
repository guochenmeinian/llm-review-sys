ID: YzyCEJlV9Z
Title: Conformal Alignment: Knowing When to Trust Foundation Models with Guarantees
Conference: NeurIPS
Year: 2024
Number of Reviews: 22
Original Ratings: 6, 4, 6, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework called Conformal Alignment, which adapts conformal guarantees to large language models (LLMs) to ensure that outputs align with human values before deployment in high-stakes tasks like radiology report generation. The authors propose using an alignment predictor trained on labeled data to provide bounds on false discovery rate (FDR) error for model outputs. Additionally, the paper introduces a novel application of conformal selection to enhance the reliability of outputs from foundation models, particularly in the context of LLMs. The authors address challenges such as distribution shifts, in-context learning, and multi-task settings while emphasizing the importance of the choice of M, the number of generations for each question, in estimating uncertainty and confidence scores. Empirical results demonstrate the method's effectiveness in applications such as question answering and radiology report generation, particularly in calibrating alignment scores with more capable models.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant research problem regarding trust in LLM outputs and is well-written, effectively contextualizing related work.
- The proposed method is a practical drop-in solution for various systems with broad applicability in downstream tasks.
- The theoretical results provide rigorous statistical guarantees for the proposed method.
- The authors provide a comprehensive framework that adapts conformal selection for practical use with LLMs, addressing important challenges in the field.
- Empirical results demonstrate the effectiveness of their approach, particularly in calibrating alignment scores with more capable models.
- The inclusion of ablation studies enhances the understanding of feature importance and the robustness of the method.

Weaknesses:
- The technical novelty appears limited, as the method seems to be a direct application of prior work, particularly lacking clarity on its contributions compared to existing literature.
- There is insufficient comparison with other LLM conformal methods, which hampers the positioning of the proposed approach within the existing body of work.
- The writing lacks clarity in several areas, potentially leading to confusion regarding terminology and contributions.
- The novelty of the theoretical contributions is questioned, with concerns about overlaps with existing work, particularly regarding the algorithm's similarity to prior research.
- The paper lacks clarity in distinguishing its contributions from existing methods, which may lead to confusion among readers.
- There is a need for more explicit discussions on the limitations of the proposed method, especially concerning the handling of small sample sizes and the reliance on proxy measures for human ratings.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their contributions by explicitly distinguishing their work from prior studies, particularly [17], and summarizing the adaptations made in Theorem 3.1. Additionally, we suggest including empirical comparisons with relevant methods to better demonstrate the advantages of the proposed approach. The authors should also define key terms such as "unit" and "power" clearly and discuss how alignment with human experts is typically measured. Furthermore, we encourage the authors to elaborate on the selection of the alignment score predictor and its implications for practical applications, particularly in high-stakes environments. A dedicated limitations section that addresses the challenges of small sample sizes and the implications of using proxy measures for human ratings would enhance the paper's rigor. Lastly, we suggest conducting additional ablation studies to explore the impact of feature selection and predictor robustness in various scenarios.