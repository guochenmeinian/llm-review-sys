ID: 0JSKjdePGq
Title: When to Sense and Control? A Time-adaptive Approach for Continuous-Time RL
Conference: NeurIPS
Year: 2024
Number of Reviews: 18
Original Ratings: 6, 6, 8, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a time-adaptive reinforcement learning framework called Time-adaptive Control & Sensing (TACOS) for continuous-time systems. The authors reformulate continuous-time reinforcement learning problems into equivalent discrete-time Markov decision processes (MDPs) that can be solved using standard RL algorithms. Additionally, they introduce a model-based version, OTACOS, aimed at reducing sample complexity. The framework is shown to optimize policies while minimizing costly interactions, demonstrating improved performance and robustness across various interaction frequencies.

### Strengths and Weaknesses
Strengths:
1. The introduction of the TACOS framework creatively addresses the challenges of continuous-time dynamics while minimizing interaction costs.
2. The theoretical foundation for TACOS is robust, with a clear reformulation of continuous-time RL into discrete-time MDPs.
3. Empirical results validate the theoretical claims, showing TACOS and OTACOS outperform traditional discrete-time methods.

Weaknesses:
1. The solution's novelty is somewhat limited, primarily involving the incorporation of time into the action space.
2. Empirical validation lacks diversity, focusing mainly on controlled synthetic environments, which may limit generalizability.
3. The paper lacks consistency in reference formatting and requires more detailed explanations of certain notations and concepts.

### Suggestions for Improvement
We recommend that the authors improve the consistency of reference formatting throughout the paper. Additionally, providing more details on the learning process, including comparisons of learning curves between the equidistant and time-adaptive approaches, would enhance clarity. The authors should also address the limitations of their empirical validation by including more diverse real-world scenarios. Furthermore, clarifying the role of specific notations, such as $\pi_{\mathcal{T}}$, and providing empirical verification for claims about interaction requirements in stochastic environments would strengthen the paper. Lastly, including references to related work on real-time inference and adaptive control would provide a more comprehensive context for the contributions made.