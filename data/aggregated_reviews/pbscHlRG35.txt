ID: pbscHlRG35
Title: RealMAN: A Real-Recorded and Annotated Microphone Array Dataset for Dynamic Speech Enhancement and Localization
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 5, 7, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 2, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a dataset of multichannel recordings of speech and noise captured in various real-world locations, aimed at enhancing speech enhancement and localization research. The dataset includes recordings from a 32-channel microphone array and a loudspeaker, totaling 83 hours of speech and 144 hours of background noise. The authors propose that their dataset addresses significant limitations in existing datasets by offering greater realism, quantity, and diversity.

### Strengths and Weaknesses
Strengths:
- The dataset's realisticness, diversity, and quantity exceed many existing datasets, making it valuable for speech enhancement and localization research.
- The method for collecting speech data is clearly described, and the variety of scenes enhances its applicability.
- The high channel count allows for flexible research opportunities in variable-array processing.

Weaknesses:
- Important details regarding the data collection process are missing, such as the selection criteria for microphone and speaker locations, the nature of the speech content, and the absence of gold transcriptions.
- The use of a loudspeaker instead of real human speakers limits the dataset's realism, as it does not account for natural variations in speech directivity and movement.
- The evaluation lacks clarity on how simulated data is generated and its relation to real recordings, particularly regarding the choice of speech and noise segments.

### Suggestions for Improvement
We recommend that the authors improve the dataset documentation by including detailed descriptions of the data collection process, including how microphone and speaker locations were chosen and the types of speech recorded. Additionally, we suggest incorporating recordings of real speakers with tracking of position and head orientation to enhance realism. The authors should also clarify the generation of simulated data, including the specific RIRs used and the characteristics of the simulated noise. Finally, we encourage the authors to address the limitations of using a loudspeaker and provide a more thorough evaluation of the dataset's effectiveness in various speech processing tasks.