ID: nc9XqnaLys
Title: Combining Case-Based Reasoning with Deep Learning: Context and Ongoing Case Feature Learning Research
Conference: AAAI
Year: 2023
Number of Reviews: 2
Original Ratings: 4, 7
Original Confidences: 4, 3

Aggregated Review:
### Key Points
This paper presents a synthesis of Case-Based Reasoning (CBR) and Deep Learning (DL), aiming to merge the interpretability of CBR with the feature extraction capabilities of DL. The authors explore neural feature extraction for case retrieval in CBR systems, positing that optimal strategies can enhance CBR accuracy. The work contextualizes the advantages of both paradigms and discusses various research efforts to improve DL interpretability and CBR similarity assessments. However, the title inaccurately reflects the paper's focus, which is more developmental than a survey.

### Strengths and Weaknesses
Strengths:
1. The integration of DL's feature extraction with CBR's interpretability is a timely and relevant contribution to AI research.
2. The paper includes a short empirical analysis of neural network architectures and feature extraction effects.
3. It proposes a beneficial fusion of knowledge-engineered and DL-extracted features, facilitating synergistic integration.

Weaknesses:
1. The title does not align with the paper's focus, misleadingly labeling it as a survey.
2. The literature review lacks depth in justifying the approaches and outcomes.
3. The ongoing research lacks clarity and numerical evaluative support, with insufficient explanation of the architecture and results.
4. The impact of proposed methods on computational resources is not clearly articulated.

### Suggestions for Improvement
We recommend that the authors improve the title to better reflect the developmental nature of the work rather than labeling it as a survey. Additionally, the authors should deepen the literature review to justify their approaches and outcomes more thoroughly. Clarifying the ongoing research with more numerical evaluative support and a clearer explanation of the architecture would enhance understanding. Finally, we suggest that the authors articulate the computational resource implications of their methods, including training time and memory requirements, to provide a more comprehensive view of the integration challenges.