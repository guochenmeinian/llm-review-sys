ID: pc4GSBi1Hx
Title: LoTLIP: Improving Language-Image Pre-training for Long Text Understanding
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 5, 7, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents LotCLIP, which enhances CLIPâ€™s capability to understand long texts while maintaining performance on short texts. The authors propose integrating additional learnable corner tokens into the text encoder transformer and modifying the attention mask to restrict interactions between these tokens, promoting diversity in output feature embeddings. LotCLIP is trained on a self-constructed dataset of 100 million long texts using MLLMs and evaluated on long-text retrieval tasks as well as short-text benchmarks like image-text retrieval and classification. Additionally, the paper introduces the Dora dataset, claimed to be the largest dataset of long text-image pairs in the multi-modal learning field, facilitating improved model performance on long texts. The authors plan to implement methods to alleviate hallucinations, such as OPERA, to enhance the quality of long captions. They clarify that corner tokens are learnable embeddings similar to the [CLS] token in BERT and demonstrate their effectiveness in representing texts even without the [CLS] token. The paper also discusses the potential for surrogate tasks to assess understanding in long text-image alignment, highlighting the benefits of using long texts in contrastive learning for image understanding.

### Strengths and Weaknesses
Strengths:  
- The paper addresses the important issue of improving CLIP's understanding of long texts and introduces a straightforward modification to the training framework.  
- The large-scale dataset of 100 million long captions is valuable for training vision-language models (VLMs) with long context comprehension.  
- The introduction of the Dora dataset fills a significant gap in multi-modal learning, providing a resource for future research.  
- The innovative use of corner tokens shows promise in enhancing the processing of long captions, as evidenced by empirical results demonstrating strong performance compared to baselines such as LiT, CLIP, and SigLIP.  
- The authors effectively address reviewer concerns and clarify technical aspects, improving the overall quality of the paper.

Weaknesses:  
- Contributions are unclear; the architectural differences from previous works are minimal, and the specific benefits of corner tokens for long captions need further justification.  
- The dataset's contributions are inadequately detailed, lacking statistics and verification steps for the long captions generated by MLLMs.  
- The fairness of comparisons is questionable, as LotCLIP benefits from a pre-trained ViT backbone, suggesting the need for testing with other visual backbones.  
- Overlap in training and evaluation benchmarks may inflate performance results.  
- The comparison with LongCLIP is not directly established, and performance on a similarly scaled dataset remains unclear.  
- The reliance on standard MLLM inference for generating long texts indicates limited technical innovation.  
- The initial omission of discussions regarding the register token may necessitate substantial revisions to incorporate necessary comparisons.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their contributions by providing a more comprehensive analysis of the corner tokens and their specific advantages for long captions. Additionally, detailed statistics and verification methods for the dataset should be included to assess the quality of the long captions generated. It would be beneficial to test LotCLIP with various visual backbones to ensure fair comparisons. We also suggest addressing potential overlaps in training and evaluation datasets to validate performance claims. Lastly, a direct comparison with LongCLIP on a similarly scaled dataset should be conducted to clarify the relative performance. Furthermore, we recommend enhancing the technical innovation of the generated long texts beyond standard MLLM inference and incorporating all discussions related to the register token in the revision to emphasize its role as a crucial baseline for the proposed corner token. This inclusion will enhance the clarity and depth of the manuscript.