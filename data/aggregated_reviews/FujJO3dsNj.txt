ID: FujJO3dsNj
Title: Balancing memorization and generalization in RNNs for high performance brain-machine Interfaces
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 8, 7, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis of various neural decoders for online brain-machine interfaces (BMIs), specifically evaluating recurrent networks (RNNs), convolutional networks (CNNs), transformers, and Kalman filters. The authors demonstrate that RNNs outperform other architectures in both offline and online settings, with findings indicating that RNNs can interpolate between memorization in few-target scenarios and flexible control in many-target scenarios. The study highlights the importance of understanding the performance of different decoders in both contexts, as many researchers rely on offline metrics.

### Strengths and Weaknesses
Strengths:  
- The investigation into the performance of various neural decoders in both offline and online settings addresses a significant question in systems neuroscience.  
- The analyses are clear, informative, and well-presented, contributing valuable insights into the behavior of different decoder types.  
- The paper is well-written and covers many technical details effectively.

Weaknesses:  
- The study does not sufficiently explore the speed/accuracy trade-offs across different architectures, limiting the conclusions drawn from a single data point per architecture.  
- The limitations of the study, particularly regarding the generalizability of results and the reliance on a single monkey, are not discussed in depth.  
- Some technical terms, such as 'ReFIT,' are introduced without explanation, which may confuse readers.

### Suggestions for Improvement
We recommend that the authors improve the clarity of technical terms by providing brief explanations, such as defining 'ReFIT' upon its first mention. Additionally, we suggest exploring the range of speed/accuracy trade-offs by varying network or context sizes, and including plots that show performance against time-per-forward-pass for different architectures. It would also be beneficial to report the total number of parameters for each network and the time-per-forward-pass in the main text. Furthermore, we encourage the authors to clarify the methodology regarding the removal of initial trials in performance calculations and to consider discussing the limitations of their findings more comprehensively, particularly regarding the scalability of their results to more complex tasks. Lastly, we suggest adding a supplementary figure to illustrate the challenges of translating offline results to online settings, as this is a key strength of the paper.