ID: bE7GWLQzkM
Title: Disentangling and mitigating the impact of task similarity for continual learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 6, 6, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis of the impact of task similarity on Continual Learning (CL) using a linear teacher-student model with low-dimensional latent structures. The findings reveal that high input feature similarity coupled with low readout similarity adversely affects both knowledge transfer and retention. The authors systematically investigate how feature and readout similarity influence these processes under various gating scenarios, demonstrating that weight regularization based on the Fisher information metric enhances retention without compromising transfer.

### Strengths and Weaknesses
Strengths:
+ The paper addresses the significant issue of task similarity in continual learning through comprehensive experiments, clearly delineating the effects of various factors.
+ It is well-written and presents a nuanced exploration of task similarity's dual role in knowledge transfer and interference.
+ The theoretical insights are validated through empirical results on the permuted MNIST dataset, reinforcing the findings.

Weaknesses:
+ The theory is limited to task incremental CL with two regression tasks; generalization to more tasks or other settings, such as classification tasks, is needed.
+ The definitions of 'similarity' for feature similarity ($\rho_a$) and readout similarity ($\rho_b$) are unclear and warrant more precise treatment.
+ The experimental validation is somewhat narrow; broader validation across diverse datasets is necessary to enhance generalizability.
+ There is insufficient comparison with a wider range of existing continual learning algorithms, particularly recent advancements.
+ The paper lacks detailed guidance on practical implementation and does not sufficiently analyze the interactions between different continual learning algorithms.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the definitions for 'similarity' in the context of both feature and readout similarity, ensuring consistent terminology throughout the paper. Additionally, we suggest expanding the theoretical framework to include more tasks and different settings, such as classification tasks. To strengthen the findings, validate the results on a wider variety of datasets, including complex ones like CIFAR-100 or ImageNet. A comprehensive comparison with recent continual learning algorithms should be included to contextualize the contributions of this work. Furthermore, we encourage the authors to provide practical implementation guidelines, including code snippets and hyperparameter settings, to assist practitioners. Finally, conducting a more in-depth analysis of the interactions between different continual learning algorithms and varying task similarities would enhance the understanding of their effectiveness.