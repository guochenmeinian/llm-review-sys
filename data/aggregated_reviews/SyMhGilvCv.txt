ID: SyMhGilvCv
Title: Prompt Tuning Strikes Back: Customizing Foundation Models with Low-Rank Prompt Adaptation
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 5, 5, 5, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 5, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Low-Rank Prompt Adaptation (LOPA), a novel prompt-tuning approach that achieves parameter-efficient fine-tuning (PEFT) by constructing soft prompts from a shared task-specific component and an instance-specific component. LOPA utilizes low-rank decomposition to enhance parameter efficiency and avoids the need for server-based adapters, demonstrating effectiveness on various natural language understanding and code generation tasks.

### Strengths and Weaknesses
Strengths:
1. The method is simple, effective, and easy to implement.
2. The writing is clear and well-structured.
3. LOPA is more parameter-efficient than traditional PEFT methods like LoRA.

Weaknesses:
1. The comparison with PEFT methods is limited to LoRA, neglecting other significant methods such as Adapter-tuning and P-Tuningv2, as well as competitive methods like LPT and SPT.
2. The ablation studies lack comprehensiveness, particularly regarding the cost savings and performance trade-offs associated with low-rank decomposition.
3. The title may be misleading; "Language Models" might be more accurate than "Foundation Models" since validation was limited to natural language datasets.
4. The paper does not provide quantitative or visual verification of the offset subspace induced by LOPA.
5. The proposed method's performance is inferior to LoRA on 6 out of 7 datasets.
6. Important experimental details, such as the number of training epochs for each method, are missing.

### Suggestions for Improvement
We recommend that the authors improve the comparison by including other representative PEFT methods like Adapter-tuning and P-Tuningv2 in their experiments. Additionally, the authors should enhance the ablation studies to discuss the implications of low-rank decomposition on cost and performance. We suggest revising the title to reflect the focus on language models more accurately. Furthermore, providing quantitative or visual evidence for the changes brought about by LOPA would strengthen the analysis. Finally, addressing the performance discrepancies with LoRA and including more experimental details, such as training epochs, would enhance the paper's rigor.