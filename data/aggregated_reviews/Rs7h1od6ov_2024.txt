ID: Rs7h1od6ov
Title: Privacy-Preserving Large Language Model Inference via GPU-Accelerated Fully Homomorphic Encryption
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 6, 7, 4
Original Confidences: 3, 3, 3

Aggregated Review:
### Key Points
This paper presents a privacy-preserving inference method for user requests using Fully Homomorphic Encryption (FHE) techniques. The authors implement FHE on a third-party host containing the LLM, allowing encrypted data processing and output. They address challenges related to LLM activations not supported by FHE, providing an approximate implementation that achieves a 200x efficiency boost. The authors also contribute their implementation to the open-source library OpenFHE, specifically on the GPT-2 model. The paper includes experiments with datasets like LAMBADA and ARC, highlighting trade-offs between accuracy and performance.

### Strengths and Weaknesses
Strengths:
- The use of FHE for LLM inference is a novel solution to privacy concerns, particularly with sensitive data. The implementation of a GPU-accelerated version enhances practicality and speed, achieving impressive performance improvements. The promise of open-source code further supports the work's impact.
- The motivation for enabling user privacy in interactions with third-party LLMs is sound, and the results indicate significant speed improvements over CPU-only FHE without substantial performance degradation.

Weaknesses:
- The paper benchmarks performance using only three datasets (HellaSwag, LAMBADA, ARC), which may not represent the diversity of NLP tasks, limiting the evaluation of the model's robustness. 
- Experiments are conducted solely with GPT-2-small, raising concerns about the consistency of results with larger models and the potential for greater performance degradation due to approximated activations.
- The forward pass time remains lengthy, questioning practicality for larger, commonly used LLMs.
- There is a lack of discussion or comparison with other privacy-preserving methods, such as prompt randomization and secure multi-party computation.
- Key technical details regarding modifications to the transformer for enabling FHE are insufficiently detailed in the main text.

### Suggestions for Improvement
We recommend that the authors improve the dataset diversity by including out-of-distribution datasets to better evaluate the model's robustness. Additionally, consider conducting experiments with larger models to assess the consistency of the FHE implementation. It would be beneficial to include a discussion of adversarial attacks and malicious actors. We suggest enhancing the technical details regarding modifications to the transformer in the main text and reducing the introduction's length. Lastly, a comparison with other privacy-preserving methods would strengthen the paper's contributions.