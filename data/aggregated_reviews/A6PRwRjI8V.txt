ID: A6PRwRjI8V
Title: Generalized Semi-Supervised Learning via Self-Supervised Feature Adaptation
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 5, 6, 6, 5, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to semi-supervised learning with feature distribution mismatch (FDM-SSL) through a method called Self-Supervised Feature Adaptation (SSFA). The SSFA framework comprises a semi-supervised learning module that optimizes the classifier using a combination of supervised/unsupervised losses and a self-supervised auxiliary loss, along with a feature adaptation module that updates the feature extraction backbone to enhance pseudo-label reliability. The authors claim to demonstrate the effectiveness of SSFA through comparative experiments with existing semi-supervised learning methods.

### Strengths and Weaknesses
Strengths:
- The paper addresses the FDM-SSL problem, which has limited prior research.
- The proposed method is straightforward and shows superiority over major semi-supervised learning techniques in the FDM-SSL context.
- Extensive experiments validate the method's performance across various datasets, and the paper is well-structured and presented.

Weaknesses:
- The novelty of the problem and method is questionable, as similar issues have been previously explored, and the authors need to clarify these differences.
- The experimental comparisons with related problems and recent domain adaptation methods are insufficient, limiting the demonstration of SSFA's effectiveness.
- The method relies on common techniques in semi-supervised learning, and while the feature adaptation module is a contribution, its novelty is not sufficiently emphasized.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their claims regarding the novelty of the FDM-SSL problem by explicitly discussing how it differs from previous work. Additionally, the authors should include comparisons with existing semi-supervised domain generalization and recent domain adaptation methods to strengthen their experimental validation. It would also be beneficial to provide more technical details in the experimental settings for reproducibility. Finally, we suggest that the authors explore the implications of the shared parameters in the feature adaptation module and consider visualizations of the data gaps to enhance reader understanding.