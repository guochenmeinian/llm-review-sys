ID: yGs9vTRjaE
Title: What Can We Learn from Unlearnable Datasets?
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 7, 4, 4, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 5, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive evaluation of unlearnable examples and introduces a novel benchmark attack called Orthogonal Projection. The authors reveal that deep neural networks (DNNs) can learn useful features from unlearnable datasets, challenging the notion that linear separability of perturbations is necessary for effective learning. They argue that class-wise poisons are still under development and that their method provides a necessary baseline for comparison. The paper critiques existing methods, particularly the ISS method, for lacking theoretical guarantees, and emphasizes the empirical and theoretical advantages of the Orthogonal Projection method, which achieves higher test accuracy on class-wise OPS poison. The findings suggest that privacy may not be preserved in the presence of unlearnable examples.

### Strengths and Weaknesses
Strengths:
- The use of Deep Feature Reweighting (DFR) yields novel insights, showing that models can learn useful features from unlearnable examples, which is a significant contribution to the field.
- The Orthogonal Projection method offers a significant improvement in test accuracy compared to ISS.
- The analysis in Sections 4.2 and 4.3 provides valuable insights into the complexities of data poisoning and challenges existing assumptions about linear separability.
- The presentation is thorough, covering related works, motivations, challenges, and limitations effectively.

Weaknesses:
- The contribution of the Orthogonal Projection attack lacks clarity, particularly regarding its effectiveness compared to simpler solutions like subtracting class-wise noise.
- The experimental evidence supporting the claim that DNNs can learn from unlearnable datasets is insufficient, with concerns about the consistency of DFR's performance across datasets.
- Sections 4.2 and 4.3 are perceived as not sufficiently interesting, lacking strong connections to the more critical Section 4.4.
- The theoretical effectiveness of ISS is questioned, as the authors do not perform a DCT transform to validate their claims regarding compression methods.
- Sections 4.2, 4.3, and 4.4 appear disconnected, with weak interrelations and insufficient theoretical analysis of the proposed methods.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the Orthogonal Projection method's contribution and its comparison to simpler alternatives. Additionally, it would be beneficial to strengthen the experimental evidence supporting the claim that DNNs can learn useful features from unlearnable datasets by including more metrics beyond test accuracy, such as training loss. We suggest enhancing the connections between Sections 4.2, 4.3, and 4.4 to provide a more cohesive narrative that illustrates how earlier findings motivate the proposed techniques. Furthermore, we recommend that the authors improve the engagement and relevance of Sections 4.2 and 4.3 by explicitly linking their findings to the Orthogonal Projection method. Finally, providing a DCT transform analysis to substantiate their critique of ISS would strengthen the theoretical foundation of their claims and bolster the robustness of the findings. Expanding the evaluation to include more datasets and references would also enhance the overall impact of the paper.