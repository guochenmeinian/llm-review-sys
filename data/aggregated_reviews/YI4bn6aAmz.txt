ID: YI4bn6aAmz
Title: Conformal Prediction Sets for Ordinal Classification
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 7, 7, 5, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 5, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for ordinal classification, COPOC, which guarantees unimodal prediction distributions over ordered classes, ensuring contiguous prediction sets for uncertainty estimation via conformal prediction. The authors argue that unimodality is desirable for ordinal tasks, exemplified by predicting customer shoe sizes. Theoretical results bound the size of the fitted model's prediction set relative to the ground truth, and favorable experimental results are shown against competing methods across various metrics. The proposed approach is empirically validated on real-world datasets and synthetic datasets.

### Strengths and Weaknesses
Strengths:  
- **Originality**: The paper introduces a novel application of conformal prediction to ordinal classification, with a simple yet effective scoring function that guarantees contiguous sets under the unimodal assumption. Theoretical justifications are provided in Theorem 2, supported by empirical results.
- **Quality**: The paper is well-structured, with clear definitions and rigorous analyses of claims.
- **Clarity**: The writing is clear, and the practical motivation for the approach is well-articulated.

Weaknesses:  
- The unimodal assumption may be overstated, with limited discussion on scenarios where it might not hold. More acknowledgment of potential pitfalls in assuming unimodality would enhance the paper.
- Details regarding hyperparameter optimization in real-world experiments are lacking, which could affect confidence in the results.
- Some reviewers noted that the method may not be novel, citing similarities with prior work by Lu et al. 

### Suggestions for Improvement
We recommend that the authors improve the discussion around the unimodal assumption, particularly addressing scenarios where it may not hold and potential mitigations. Additionally, providing more details on hyperparameter optimization for the competing methods in real-world experiments would strengthen the paper's findings. It would also be beneficial to include a comparison with Lu et al. as a baseline in the revised version, clarifying the distinctions between the methods.