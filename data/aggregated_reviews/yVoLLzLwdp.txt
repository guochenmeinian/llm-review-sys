ID: yVoLLzLwdp
Title: Is ChatGPT a Financial Expert?  Evaluating Language Models on Financial Natural Language Processing
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents FinLMEval, an evaluation framework for financial language models (LLMs), comprising nine datasets tailored for financial NLP tasks. The authors compare the performance of fine-tuned auto-encoding models (BERT, RoBERTa, FinBERT) with ChatGPT, revealing that fine-tuned models generally outperform ChatGPT, particularly on proprietary datasets. The study identifies factors influencing model performance and highlights that while ChatGPT performs well, it lags behind specialized models in many scenarios.

### Strengths and Weaknesses
Strengths:
- FinLMEval provides a fair evaluation framework for financial LLMs.
- The paper fills a gap by exploring the financial understanding of ChatGPT and includes comprehensive experimental settings.

Weaknesses:
- The taxonomy of models is misleading, conflating "auto-encoding" models with LLMs.
- The paper lacks comparisons with other advanced LLMs (e.g., GPT-4, LLAMA, Alpaca) and does not include necessary baseline models for a thorough evaluation.
- The methodology lacks sufficient detail, particularly regarding the experimental setup and the chosen NLP tasks.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their model taxonomy by accurately distinguishing between encoder-only, decoder-only, and encoder-decoder architectures. Additionally, the authors should include evaluation results from other generative pre-trained LM baselines (e.g., T5, BART) and baseline models from the FLUE benchmark for a more comprehensive comparison. We also suggest providing more detailed descriptions of the experimental setup and considering the inclusion of other advanced LLMs to enhance the robustness of their findings.