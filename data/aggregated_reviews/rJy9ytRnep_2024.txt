ID: rJy9ytRnep
Title: Network Inversion for Training-Like Data Reconstruction
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 5, 7, 6
Original Confidences: 5, 4, 4

Aggregated Review:
### Key Points
This paper presents "Training-Like Data Reconstruction (TLDR)," a novel network inversion method aimed at reconstructing training-like data from trained convolutional models. The authors showcase its efficacy on standard datasets such as MNIST and CIFAR-10, introducing innovative techniques with a conditioned generator. The paper highlights significant privacy risks associated with model sharing, although it is limited to benchmark datasets and lacks extensive discussion on scalability and real-world privacy implications.

### Strengths and Weaknesses
Strengths:  
- The paper is well-written and makes complex concepts accessible.  
- It introduces innovative techniques and significantly contributes to understanding model security vulnerabilities.  

Weaknesses:  
- The research is limited to benchmark datasets, lacking depth in scalability and real-world privacy implications.  
- There is insufficient exploration of the drawbacks of relying on cross-entropy for image generation, particularly regarding mode collapse.  
- The choice of hyperparameter α in KL divergence is not clearly explained, and its impact on image quality is not discussed.  
- The discussion on the Gram matrix and orthogonality enforcement lacks thoroughness and empirical validation.  
- Qualitative analysis of generated images is insufficient, with a need for quantitative metrics like Fréchet Inception Distance (FID) or Inception Score (IS).  
- Results for CIFAR-10 are noticeably worse than for MNIST or FashionMNIST, with inadequate exploration of this issue.  
- The paper does not clarify the main differences between the proposed method and other model inversion attacks, nor does it provide comparisons to evaluate its effectiveness.  
- The paper format appears inappropriate for ICLR submission.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the potential drawbacks of relying heavily on cross-entropy, specifically addressing mode collapse. Additionally, the authors should clarify the choice of hyperparameter α in Section 3.3, demonstrating how varying α affects the quality of reconstructed images. A more thorough discussion on the Gram matrix and the conditions for orthogonality enforcement is necessary, along with empirical validation of its impact on image diversity. We suggest incorporating quantitative metrics such as Fréchet Inception Distance (FID) or Inception Score (IS) to evaluate the quality and diversity of generated images. Furthermore, the authors should explore the reasons for the poorer results on CIFAR-10 in more depth. Lastly, we recommend that the authors clarify the differences between their method and existing model inversion attacks, providing comparisons to assess its effectiveness, and ensure the paper adheres to the appropriate format for submission.