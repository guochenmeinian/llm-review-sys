ID: 2jjfRm2R6D
Title: Multi-language Diversity Benefits Autoformalization
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 7, 6, 6, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents MMA, a large multi-language dataset for autoformalizing theorem statements, utilizing a back-translation approach with GPT-4 to generate informal-formal pairs from two formal corpora (AFP for Isabelle and mathlib for Lean4). The authors demonstrate that fine-tuning LLMs like LLaMA and Mistral on MMA leads to significant performance improvements in autoformalization tasks, outperforming single-language models on the miniF2F and ProofNet benchmarks.

### Strengths and Weaknesses
Strengths:
* The paper is well-written and organized, providing a comprehensive overview of the MMA dataset, which addresses data scarcity in autoformalization.
* The experiments effectively show that multi-language data can enhance performance in single-language tasks.
* The manual evaluation and detailed discussions contribute positively to the paper's quality.

Weaknesses:
* A primary weakness is that MMA is constructed solely through zero-shot prompting, resulting in a dataset with a formalization accuracy of around 75%, indicating significant room for improvement. The authors should consider filtering errors or employing advanced prompting techniques to enhance dataset quality.
* The analysis of the impact of the ratio of different languages in the training set on model performance is insufficiently explored.
* The metrics used for evaluation, such as "loss" and "token accuracy," are limited and do not fully capture the quality of autoformalizations.

### Suggestions for Improvement
* We recommend that the authors improve the dataset quality by filtering out obvious errors in informalized statements or utilizing more advanced prompting techniques, such as few-shot or self-consistency prompting.
* We suggest conducting a more thorough investigation into the influence of the language ratio in the training set on performance, particularly how it affects results for Lean4 and Isabelle.
* We encourage the authors to expand their evaluation metrics beyond "loss" and "token accuracy" to better assess the quality of the autoformalizations, potentially including a comparison with existing methods like few-shot learning for autoformalization.