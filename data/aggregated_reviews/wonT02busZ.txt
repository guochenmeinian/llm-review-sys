ID: wonT02busZ
Title: Adversarial-Enhanced Causal Multi-Task Framework for Debiasing Post-Click Conversion Rate Estimation
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an Adversarial-Enhanced Causal Multitask (AECM) framework to address challenges in post-click conversion rate (CVR) prediction, specifically focusing on data sparsity and sample selection bias. The authors propose a novel causal estimator and a dual adversarial component to enhance CVR predictions by optimizing the imputation model and aligning distributions in click and impression spaces. The effectiveness of the proposed method is supported by extensive experiments on real-world datasets, and the authors plan to release a valuable dataset for further research in selection bias.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant issue in CVR prediction, considering selection bias and data sparsity.
- It is well-written, with clear arguments and useful figures that aid understanding.
- The extensive experimental validation demonstrates the advantages of the proposed debiasing method.
- The release of a new large-scale dataset is a notable contribution to the community.

Weaknesses:
- The contribution of extending Doubly Robust (DR) estimators may be marginal given the dense nature of the research area.
- Theorems 1 to 3 are well-known results, raising questions about the necessity of their inclusion.
- There is a lack of theoretical background for some components of the proposed method.
- The absence of online A/B testing limits the confidence in the empirical results, as practical verification is needed.

### Suggestions for Improvement
We recommend that the authors improve the theoretical foundations by providing background for each component of the proposed method. Additionally, addressing the necessity of re-proving Theorems 1 and 2 would clarify their relevance. Conducting online A/B tests would enhance the validation of the proposed approach and its practical implications. Furthermore, we suggest including significance testing in the experimental section and providing error bars to verify the statistical significance of the results. Lastly, a more comprehensive discussion of related work and methodology novelty is essential to strengthen the manuscript.