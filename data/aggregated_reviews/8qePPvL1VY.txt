ID: 8qePPvL1VY
Title: One-for-All: Bridge the Gap Between Heterogeneous Architectures in Knowledge Distillation
Conference: NeurIPS
Year: 2023
Number of Reviews: 6
Original Ratings: 5, 6, 7, 7, -1, -1
Original Confidences: 5, 5, 5, 4, -1, -1

Aggregated Review:
### Key Points
This paper presents a new heterogeneous knowledge distillation approach named OFA-KD, which aims to address the significant feature divergence observed between different model architectures. The authors propose projecting intermediate features into a unified logit space and introduce an adaptive target enhancement scheme to improve distillation performance. Extensive experiments on CIFAR-100 and ImageNet-1K demonstrate the effectiveness of the proposed method.

### Strengths and Weaknesses
Strengths:
1. The experiments are comprehensive, covering distillation between various architectures (CNN, ViT, MLP) and utilizing both CIFAR-100 and ImageNet datasets.
2. The proposed method of projecting features onto a latent space to mitigate alignment issues is reasonable and shows promising results.
3. The paper is well-written and easy to understand, with clear explanations and sufficient experimental validation.

Weaknesses:
1. The proposed method closely resembles deep supervision, yet the paper lacks a discussion on the differences, both theoretically and experimentally.
2. Improvements in some experimental settings are minimal, and comparisons with other methods, such as OFD, Review, and CRD, are incomplete.
3. The architecture used has been extensively explored in prior works, and the novelty of the proposed method is questionable. Additionally, comparisons with recent state-of-the-art methods like SemCKD are missing.
4. The introduction of additional branches increases training costs, and the authors should provide more analysis on this aspect.

### Suggestions for Improvement
We recommend that the authors improve the discussion on how their method differs from deep supervision, including theoretical and experimental comparisons. Additionally, please ensure that all relevant methods are included in the experimental comparisons, particularly OFD, Review, and CRD. It would be beneficial to compare the proposed method with recent state-of-the-art hint-based methods like SemCKD. Furthermore, we suggest providing detailed analyses on the computational resources required for the additional branches and clarifying the choice of architectures for these branches. Lastly, please address the hyperparameter selection process in practice to enhance the clarity of the methodology.