ID: aBtcfcrjM3
Title: Geometry-aware training of factorized layers in tensor Tucker format
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 6, 7, 5, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 5, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for neural network model parameter compression using Tucker decomposition, allowing for adaptive modification of tensor ranks during training. The authors provide a solid theoretical analysis, including guarantees on convergence and approximation, and demonstrate the method's effectiveness through experiments showing improved image classification accuracy and compression rates. Additionally, the paper extends the dynamic low-rank neural network training (DLRT) method to a rank-adaptive Tucker tensor format (TDLRT), which reduces computational complexity and enhances stability in gradient descent.

### Strengths and Weaknesses
Strengths:
- The writing is clear and easy to follow, with a solid theoretical foundation.
- The proposed methods address significant challenges in neural network training, such as sensitivity to parameter initialization and the need for a warm-up phase.
- Experimental results indicate favorable performance compared to existing factorization and pruning methods.

Weaknesses:
- Some claims regarding optimality are not substantiated by the results, leading to potential discrepancies between theoretical guarantees and empirical findings.
- The empirical evaluation primarily utilizes smaller models and datasets, raising concerns about the method's scalability to larger architectures.
- Certain sections assume a background knowledge of DLRT, which may hinder accessibility for some readers.

### Suggestions for Improvement
We recommend that the authors improve the clarity of sections that are difficult to follow, particularly Section 2.1. Additionally, conducting experiments on larger models or different architectures, such as transformers, would strengthen the empirical evaluation. We also suggest providing more detailed comparisons between the proposed method and standard Tucker decomposition, particularly regarding space/time complexity and convergence analysis. Finally, including data points for the proposed method across the full compression range would facilitate direct comparisons with other methods.