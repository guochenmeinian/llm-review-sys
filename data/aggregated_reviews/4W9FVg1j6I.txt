ID: 4W9FVg1j6I
Title: Structured State Space Models for In-Context Reinforcement Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 7, 5, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a modification to the S5 architecture that allows for "resetting" the recurrent state, enabling it to serve as a replacement for RNNs in reinforcement learning (RL). The authors update the scan operator to utilize the `done` flag for resetting the recurrent state and evaluate this resettable S5 on tasks from the POPGym suite and the bsuite memory task, demonstrating its ability to solve long-term memory tasks that previous methods could not. Additionally, the paper includes an extensive evaluation of the S5 architecture in RL settings, particularly focusing on its implementation in pure JAX across multiple POPGym environments. The authors have added six new environments, including “Minesweeper,” “Higher Lower,” “Count Recall,” “Autoencode,” “Multiarmed Bandit,” and “Concentration,” with plans for two additional environments, “Battleship” and “Labyrinth,” before the final submission. The results indicate that S5 achieves significantly faster runtimes compared to GRU while maintaining similar performance levels, particularly in environments that do not emphasize long-term memory.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and addresses a significant issue in training partially observable policies.
- S5 is the first model to successfully solve the challenging RepeatHard task from POPGym.
- The experimental setup is comprehensive, covering both POMDPs and meta-learning tasks.
- The implementation of additional POPGym environments enhances the empirical evaluation of S5.
- The JAX-based implementation is noted as a significant contribution, potentially expediting research in partially-observable RL.
- The results demonstrate substantial runtime advantages for S5 compared to GRU, reinforcing its practical applicability.

Weaknesses:
- The reset mechanism, which is the paper's main contribution, appears to be a trivial modification to S5, as it essentially reverts to the initial state upon receiving a `done` flag, a standard practice in recurrent models.
- The evaluation is limited to easier control tasks within POPGym, raising concerns about the generalizability of results.
- The paper lacks a limitations section, which is essential for contextualizing the findings.
- The paper is perceived as primarily an empirical evaluation, lacking in theoretical depth.
- The importance of the *resettable* aspect of S5 may be overstated, as it is influenced by other implementation details.
- Some reviewers express concerns regarding the clarity of comparisons between different S5 operators.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their contribution by providing a more substantial justification for the reset mechanism and its implications. Additionally, we suggest expanding the evaluation to include a broader range of tasks from the POPGym suite to strengthen the claims of S5's effectiveness. It would also be beneficial to include a limitations section to address potential shortcomings of the proposed method. Furthermore, we recommend that the authors improve the theoretical framework surrounding the S5 architecture to balance the empirical findings. Consider revising the section on the *resettable* aspect to reflect its actual significance more accurately. To enhance clarity, we suggest renaming the operator that lacks resets to "S5 Without Resets" or a similar term. Finally, we encourage the authors to prioritize the open-source usability of the core model to facilitate broader adoption and experimentation in future work.