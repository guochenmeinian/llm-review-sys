ID: GkBRng3Hl9
Title: Smoothed Embeddings for Robust Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 6, 8, 7
Original Confidences: 4, 5, 4

Aggregated Review:
### Key Points
This paper presents the Randomized Embedding Smoothing and Token Aggregation (RESTA) defense to enhance the robustness of large language models (LLMs) against adversarial attacks, specifically jailbreaking attacks. RESTA operates by adding noise to embedding vectors and aggregating tokens during the generation process. The primary focus is on preserving semantic information while disrupting adversarial perturbations, aiming for a superior robustness versus utility tradeoff compared to other methods. The authors evaluated their method using Vicuna-13B and Llama-2-7B models against multiple attack techniques, observing significant improvements in robustness while maintaining model utility.

### Strengths and Weaknesses
Strengths:
1. **Application-Specific Contribution:** The adaptation of randomized smoothing to LLMs for adversarial defense is a unique contribution, particularly with RESTA's focus on token aggregation and embedding smoothing.
2. **Token-Level Aggregation:** The token-level aggregation method enhances robustness by mitigating the impact of individual adversarial tokens, distinguishing it from existing defenses.
3. **Efficiency:** Response prefix smoothing minimizes computational costs by focusing the defense on the initial tokens of the generated sequence, enhancing computational efficiency.
4. **Comprehensive Evaluation:** The thorough experiments across multiple datasets and attack scenarios demonstrate the method's robustness and utility tradeoffs.

Weaknesses:
1. **Lack of Baseline Discussion:** The analysis lacks a detailed comparison with other state-of-the-art defenses beyond SmoothLLM, limiting the context of RESTA's performance.
2. **Noise Impact on Semantics:** Limited insight into how different types of noise affect the underlying semantics of embeddings could influence the model's coherence in responses.
3. **Computational Complexity:** Despite reduced costs, the method requires running multiple noisy samples in parallel, which may not be feasible for real-time applications.
4. **Limited Theoretical Exploration:** The theoretical discussion is relatively limited and could be strengthened by referencing analyses such as https://arxiv.org/abs/2202.01186.

### Suggestions for Improvement
We recommend that the authors improve the discussion of RESTA's performance by including comparisons with a broader range of state-of-the-art defenses. Additionally, providing deeper insights into the impact of noise on semantic coherence would enhance the understanding of the method's implications. To address computational complexity, exploring optimizations for real-time applications would be beneficial. Finally, we suggest expanding the theoretical exploration to include relevant analyses, which would strengthen the paper's academic rigor.