ID: 5pnhGedG98
Title: Scalable and Effective Arithmetic Tree Generation for Adder and Multiplier Designs
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 7, 8, 6, 7, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, 2, 5, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method for designing arithmetic modules, specifically adders and multipliers, by modeling tasks as single-player tree generation games using reinforcement learning (RL) techniques. The authors propose two games, AddGame and MultGame, which optimize the design space and achieve significant improvements in computational efficiency and hardware size. Experimental results demonstrate that the developed 128-bit adders and multipliers outperform existing designs, achieving up to 26% reduced delay and 30% smaller size.

### Strengths and Weaknesses
Strengths:
- The paper introduces an innovative approach that effectively applies RL techniques to optimize arithmetic module designs, distinguishing it from traditional methods.
- Experimental validation shows substantial improvements in performance metrics, confirming the method's effectiveness across various technology nodes.
- The paper is well-organized and clearly presented, facilitating understanding of complex concepts.

Weaknesses:
- The innovation appears limited to the application of RL and tree search techniques, with similarities to prior work, such as PrefixRL.
- The focus is primarily on adders and multipliers, with limited exploration of other arithmetic operations or modules.
- The scalability of the proposed methods to larger bit widths and different data types, such as floating-point, remains uncertain.

### Suggestions for Improvement
We recommend that the authors improve the introduction by providing a more detailed explanation of the states and actions for both AddGame and MultGame to enhance clarity. Additionally, the authors should address the scalability of their method to other arithmetic operations, such as exponentiation, and consider testing their approach on real industry PDKs to validate practical applicability. Furthermore, we suggest consistently using either the abbreviation 'RL' or the full term 'reinforcement learning' throughout the paper for clarity. Lastly, the authors should include a description of the logic equivalence checking process in future versions to ensure functionality correctness.