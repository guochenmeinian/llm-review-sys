ID: hR3mhI2p2K
Title: (Implicit) Ensembles of Ensembles: Epistemic Uncertainty Collapse in Large Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 2
Original Ratings: 3, 7
Original Confidences: 3, 3

Aggregated Review:
### Key Points
This paper studies how epistemic uncertainty changes as model complexity increases, proposing that larger models do not necessarily provide better uncertainty quantification due to implicit ensembling. The authors demonstrate this phenomenon empirically across various architectures, including a toy example and Wide-ResNet-28-1 models, and introduce an implicit ensemble extraction method to recover hidden ensemble structures. They also provide theoretical justification for their findings.

### Strengths and Weaknesses
Strengths:
- The question addressed is significant and relevant.
- The paper is well written and organized.
- It includes a comprehensive experimental section and provides a sufficient amount of information theoretical background.

Weaknesses:
- The phrasing is problematic, as the phenomena discussed were previously observed in a cited paper, limiting the new knowledge contributed.
- The theoretical aspect offers limited value, as the average of independent copies converging to the theoretical average is a well-known result.
- The implicit ensemble extraction method is not clearly described in the main text, making it difficult to understand without consulting the appendix.
- Figures are very small and difficult to read, hindering information retrieval.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the implicit ensemble extraction method by providing a more detailed description in the main text. Additionally, enhancing the size and clarity of the figures would facilitate better comprehension of the experimental results. Finally, including more background information, such as the Bayesian Model Averaging (BMA) of ensembles, would strengthen the theoretical foundation of the paper.