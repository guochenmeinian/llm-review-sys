ID: 8l8JVb7nUB
Title: SwiftMedSAM: An Ultra-Lightweight Prompt-based Universal Medical Image Segmentation Model for Highly Constrained Environments
Conference: thecvf
Year: 2024
Number of Reviews: 4
Original Ratings: 7, 4, 3, 5
Original Confidences: 4, 4, 4, 3

Aggregated Review:
### Key Points
We note that SwiftMedSAM is an optimized model for medical image segmentation, aimed at efficient performance in resource-constrained environments. It builds on LiteMedSAM by reducing model size and computational complexity through hyperparameter optimization of the image encoder and mask decoder. The model achieves a validation score of 0.75, indicating a trade-off between accuracy and efficiency. The paper details a series of ablations to prune the model size, including adjustments to block depth, transformer depth, MLP dimensionality, and the number of attention heads. However, the paper lacks empirical evidence supporting the efficacy of these optimizations and does not adequately compare SwiftMedSAM with other state-of-the-art models.

### Strengths and Weaknesses
We recognize several strengths in the paper, including the meaningful approach to pruning the model, which reduces both training and inference time, and the use of additional datasets to improve image balance. However, we identify weaknesses such as the lack of clarity regarding terms like “block depth” and the IoU-head depth, which could benefit from visual aids. The training methodology for the pruned models is insufficiently detailed, raising questions about initialization and weight usage. Additionally, discrepancies in reported results compared to other studies are concerning, and the paper does not convincingly demonstrate the practical impact of the proposed optimizations.

### Suggestions for Improvement
We suggest that the authors clarify the terminology used, particularly regarding “block depth” and the IoU-head depth, potentially through a more informative figure. Providing detailed information on the training process of the pruned models is essential, including whether they used randomly initialized weights or weights from larger models. We also recommend a comparative analysis with other state-of-the-art models to strengthen the paper's claims. Addressing the discrepancies in reported results and ensuring accurate calculations of model FLOPs would enhance the paper's credibility. Lastly, exploring new pre-processing or post-processing techniques could increase the novelty of the work.