ID: jSuhnO9QJv
Title: Spuriosity Rankings: Sorting Data to Measure and Mitigate Biases
Conference: NeurIPS
Year: 2023
Number of Reviews: 6
Original Ratings: 6, 7, 6, 6, -1, -1
Original Confidences: 4, 3, 4, 3, -1, -1

Aggregated Review:
### Key Points
This paper presents a method to measure and rank data by "spuriosity," which indicates the presence of spurious cues, to detect and mitigate biases in deep learning models. The authors utilize an interpretable model to identify relevant neural features and select spurious ones with limited human supervision. By ranking data based on these spurious features, the authors demonstrate benefits such as revealing less biased subsets and quantifying model bias through "spurious gaps" in accuracy. The analysis of 89 models indicates that bias is more influenced by training data than training methods, suggesting that spuriosity rankings can effectively complement existing bias mitigation strategies.

### Strengths and Weaknesses
Strengths:
1. The paper addresses a timely and significant problem, providing a scalable method to rank data by spuriosity, which aids in bias detection and mitigation.
2. The proposed approach to finetune models on low spuriosity data enhances performance on less biased instances while preserving overall accuracy, leading to more robust models.
3. The comprehensive analysis across numerous models reveals critical insights into the relationship between data and model bias.

Weaknesses:
1. The paper heavily relies on related work [42], making it less accessible for readers unfamiliar with it; a more self-contained writing style is recommended.
2. The claim regarding the identification of racial bias in the Celeb-A benchmark lacks originality, as this issue has been previously studied.
3. The definition of spuriosity appears ad hoc and may not account for distributions with long tails, potentially affecting the reliability of the measurements.

### Suggestions for Improvement
We recommend that the authors improve the self-containment of the paper to enhance accessibility for readers unfamiliar with related work [42]. Additionally, we suggest providing a quantified measure to evaluate the quality of spuriosity rankings and comparing the bias mitigation approach with existing literature to strengthen the assessment of its value. Furthermore, addressing the limitations of human supervision in identifying spurious correlations and considering alternative methods for quantifying spuriosity and spurious gaps would enhance the robustness of the proposed framework.