ID: 8iB0FJmOfV
Title: q2d: Turning Questions into Dialogs to Teach Models How to Search
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for generating dialogs from complex queries, utilizing a PaLM to transform a QA dataset into conversational formats. The authors propose a query generation model that effectively bridges conversational dialogue with factual answers from a search API. Extensive experiments demonstrate that the generated dialogs are natural, factual, and beneficial for training dialog models, showing substantial similarity to human-written dialogs.

### Strengths and Weaknesses
Strengths:  
- The paper introduces a novel method for dialog generation that enhances the performance of dialog models.  
- The experimental results are convincing, with detailed analysis and a promise to make the code and datasets publicly available.  
- The approach addresses hallucinations in conversational LLMs and provides insights into dialog/NLP research.  

Weaknesses:  
- The clarity of the paper is inconsistent, with misalignment between contributions stated in the abstract and later sections.  
- The choice of T5 as the sole model for adaptation in experiments may not convincingly represent the robustness of the approach across different models.  
- Some aspects of the experimental results, particularly regarding table 2, lack discussion and clarity.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by ensuring consistent alignment of contributions throughout all sections. Additionally, we suggest that the authors explore the application of fine-tuning to other models used as baselines to provide a clearer picture of the approach's resilience. Furthermore, we encourage the authors to comment on the performance discrepancies observed in table 2 and to address the complexity of the final dialog turns shown in figure 3, discussing how often similar cases occur in practice.