ID: shXnfALjuH
Title: FD-Align: Feature Discrimination Alignment for Fine-tuning Pre-Trained Models in Few-Shot Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 20
Original Ratings: 3, 5, 4, 3, 4, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 5, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for fine-tuning the pre-trained CLIP model for few-shot learning tasks, focusing on decoupling spurious information from causal information to enhance generalizability and mitigate overfitting. The authors propose a spurious information extractor that aligns image features with text embeddings, aiming to improve performance across various datasets. They assert that their approach retains the model's ability to extract spurious information while enhancing its performance on specific tasks. Visual evidence is provided, indicating that the fine-tuned model emphasizes the object itself more effectively than a directly fine-tuned model. The authors also claim that their method does not impact inference speed or GPU memory usage compared to existing methods. However, some results raise questions regarding the robustness of the findings.

### Strengths and Weaknesses
Strengths:
1. The paper is well-organized and clearly written, making the overall narrative easy to follow.
2. The motivation for addressing cross-domain and out-of-distribution few-shot learning is strong, and the proposed method shows promising results across multiple benchmarks.
3. The authors provide compelling visualizations that demonstrate the effectiveness of their fine-tuned model.
4. The quantitative results indicate superior performance in specific shot numbers compared to existing methods.
5. The method is claimed to maintain efficiency in inference without additional resource demands.

Weaknesses:
1. The motivation behind retaining spurious features for model robustness is not convincingly justified, and the assumption that fine-tuning leads to overfitting to spurious information requires further validation.
2. The experiments lack comprehensive comparisons with existing methods, such as CoOp and PLOT, and the choice of using ViT-B as a backbone instead of more common architectures like ResNet50 is questionable.
3. The explanation of how preserving the ability to recognize spurious features prevents overfitting is unclear and appears contradictory.
4. The choice of backbone (ViT-B/32) raises concerns about comparability with existing works, particularly the lack of results using ResNet50 and ViT-B/16.
5. Insufficient implementation details regarding algorithms like Isolation Forest and K-means hinder reproducibility, and the overall presentation could benefit from improved clarity and organization.

### Suggestions for Improvement
We recommend that the authors improve the justification for retaining spurious features by providing empirical validation, possibly through visualization techniques like Grad-CAM. Additionally, the authors should include comparisons with other parameter-efficient fine-tuning methods, such as LoRA and VPT, to strengthen their claims. Improving visualizations to explicitly demonstrate disentanglement of causal and spurious information using model explainability techniques is also suggested. Clarifying the implementation details of the Isolation Forest and K-means algorithms will enhance reproducibility. Furthermore, addressing the alignment of scores in tables and correcting typographical errors will improve the overall presentation. To strengthen the motivation section, we encourage the authors to provide a clearer rationale for the importance of distinguishing different domains in classification tasks. Lastly, we advise the authors to include results using ResNet50 and ViT-B/16 to facilitate direct comparisons with existing works.