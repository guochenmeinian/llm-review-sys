ID: rBfVlElyVW
Title: MAGNIFICo: Evaluating the In-Context Learning Ability of Large Language Models to Generalize to Novel Interpretations
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates the ability of LLMs to adapt to new expressions and meanings through in-context learning, specifically mapping natural language text to SQL semantic representations. The authors propose the MAGNIFICo dataset, which includes 24 meanings mapped to three types of textual forms: plausible words, nonce words, and adversarial words. The evaluation of various LLMs is conducted using three prompting strategies: Direct, Description, and Few-shot, revealing that LLMs perform better with plausible forms and struggle with adversarial forms and multiple interpretations. The study also highlights recency bias in dialogue contexts.

### Strengths and Weaknesses
Strengths:
- The paper presents a novel approach to word learning and compositional generalization in LLMs.
- The MAGNIFICo dataset is well-designed and contributes significantly to the evaluation of LLMs.
- The experimental design is robust, with extensive analysis across various LLMs.
- The paper is clearly written and structured.

Weaknesses:
- The analysis is limited to a single task, which lacks clear motivation.
- Some experimental sections have inadequate test data, weakening the analysis.
- The related work section is overly concise and lacks sufficient background on text-to-SQL.
- Results are scattered between the main text and appendix, requiring frequent cross-referencing.

### Suggestions for Improvement
We recommend that the authors improve the clarity of how the Descriptions were generated and ensure that the distinction between plausible, nonce, and adversarial forms is explicitly made for phrases. Additionally, we suggest expanding the dataset to include more test data for stronger analyses and comparing results with the latest models like GPT-4. The authors should also provide a clearer justification for choosing SQL as the task and enhance the related work section to better contextualize their contributions. Lastly, we advise improving the font size in figures for better readability.