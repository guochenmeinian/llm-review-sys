ID: y5ihmWxYWx
Title: Evaluating Peripheral Vision as an Input Transformation to Understand Object Detection Model Behavior
Conference: NeurIPS
Year: 2023
Number of Reviews: 4
Original Ratings: 6, 7, 7, -1
Original Confidences: 3, 3, 3, 4

Aggregated Review:
### Key Points
This paper presents a modification of the Texture Tiling Model (TTM) for real-time peripheral vision simulation, generating TTM images using uniform pooling rather than foveated pooling. The authors stitch together pre-computed uniform TTM images to approximate fixation point-dependent images, significantly speeding up the process compared to non-uniform TTM generation. They evaluate the detection performance of state-of-the-art object detectors on peripheral object detection and assess whether training on uniform TTM-transformed images enhances neural network robustness to image corruptions. However, the experiments reveal limited benefits beyond robustness for directly related corruptions.

### Strengths and Weaknesses
Strengths:
* The authors present an efficient algorithm based on TTM for creating arbitrary foveated images, achieving around 50ms per image compared to over 5 hours.
* They clearly evaluate performance degradation with increased eccentricities, validating the challenges of object detection in peripheral vision.
* The experiments differentiate performance on small and large objects, showing that large objects benefit from fine-tuning at high eccentricities.

Weaknesses:
* The results are largely unsurprising, as the performance improvements align with the nature of the TTM, providing limited insights into human vision.
* The application of the generated foveated images remains unclear, and the algorithm is not tested against human performance.
* Even with training on eccentric images, models do not outperform the best baseline DINO model.
* It is uncertain whether the authors plan to share their generated TTM dataset at various eccentricities (5, 10, 15, and 20 degrees).

### Suggestions for Improvement
We recommend that the authors improve the discussion regarding the limited insights into human vision provided by their results. Additionally, clarifying the application of the generated foveated images and testing the algorithm against human performance would enhance the paper's contributions. Finally, we suggest that the authors confirm their intentions regarding the availability of the TTM dataset at different eccentricities, as this information would be beneficial for the research community.