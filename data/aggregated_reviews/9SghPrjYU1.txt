ID: 9SghPrjYU1
Title: Minimax Optimal and Computationally Efficient Algorithms for Distributionally Robust Offline Reinforcement Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 6, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper studies robust offline reinforcement learning (RL) with function approximation in the context of $d$-rectangular linear distributionally robust Markov decision processes (DRMDPs). The authors propose two learning algorithms and establish instance-dependent upper bounds for suboptimality, demonstrating that the proposed VA-DRPVI algorithm is near-optimal up to a factor of $\widetilde{O}(\sqrt{d})$. The paper also derives an information-theoretic lower bound that may be of independent interest.

### Strengths and Weaknesses
Strengths:
1. The derivation of an information-theoretic lower bound based on the novel uncertainty function $\Phi((\Sigma_h^*)^{-1},s)$ is a significant contribution.
2. The suboptimality of the VA-DRPVI algorithm closely aligns with the derived lower bound.

Weaknesses:
1. The suboptimality bounds in Theorems 3.4 and 4.2, as well as the lower bound in Theorem 5.1, necessitate that the number $K$ of trajectories in the offline dataset scales with $\text{poly}(d,H)$, which is restrictive.
2. The computational efficiency claim is undermined by the need to calculate the minimum value over the entire space in continuous state spaces, as noted in Line 175.
3. The absence of experimental results limits the practical validation of the proposed algorithms.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by explicitly stating the focus on linear function approximation in the open questions section. Additionally, we suggest including toy experiments to validate the proposed algorithms, as this would strengthen the theoretical claims. Furthermore, we encourage the authors to address the "fail-state" assumption and its applicability in various environments, as well as to provide a more detailed comparison with existing works, particularly regarding the differences in uncertainty sets and methodologies. Lastly, we advise revising the wording in the contribution section to replace "minimax optimal" with "near-optimal" to accurately reflect the scaling of parameter $\beta_2$.