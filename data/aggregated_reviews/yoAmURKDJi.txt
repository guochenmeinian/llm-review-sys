ID: yoAmURKDJi
Title: TOA: Task-oriented Active VQA
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 5, 7, 7, 5, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 5, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to task-oriented active visual question answering (TOA-VQA) by leveraging large language models (LLMs) as implicit knowledge sources. The authors propose a sequential hypothesis-verification process that allows for dynamic decision-making through multi-round dialogues, enhancing the model's ability to focus on essential visual information. Experimental results indicate that this method outperforms baseline approaches in open-ended knowledge-based VQA.

### Strengths and Weaknesses
Strengths:
- The idea of using multi-round dialogue to extract key visual content is innovative.
- The method effectively utilizes the capabilities of LLMs, demonstrating good performance in experiments.
- The reasoning-hypothesis-verification design enhances interpretability and clarity in the answering process.
- The paper is well-structured and presents thorough experimental insights.

Weaknesses:
- Some sub-modules resemble existing models, and the reasoning-verification design may be limited.
- The reliance on ChatGPT instead of GPT-3 raises fairness concerns in experiments.
- The necessity of the hypothesis in the process is unclear, as the LLM could potentially function without it.
- The paper lacks comparisons with other task-oriented models like ViperGPT and does not explore the generalizability of the method across different datasets.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the necessity of the hypothesis in the reasoning process, possibly by conducting an ablation study that removes the hypothesis while retaining reasoning and verification. Additionally, we suggest including comparisons with ViperGPT and other datasets to demonstrate the generalization ability of the proposed method. It would also be beneficial to provide more technical details about the visual models and prompts used to facilitate reproducibility. Finally, we encourage the authors to address the limitations of the model, particularly regarding potential biases in LLM outputs.