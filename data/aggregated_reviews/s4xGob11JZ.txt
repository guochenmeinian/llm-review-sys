ID: s4xGob11JZ
Title: Robust Link Prediction over Noisy Hyper-Relational Knowledge Graphs
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents NYLON, a method for knowledge graph completion focused on noisy hyper-relational KGs, emphasizing robustness and effective handling of data noise. The authors propose a link prediction technique that integrates element-wise and fact-wise confidence assessments through a "least confidence" principle, demonstrating superior performance in experiments across three datasets compared to baseline methods.

### Strengths and Weaknesses
Strengths:
- Strong experimental performance, outperforming all baseline methods.
- The proposed methodology is robust and well-described, addressing a pertinent topic in link prediction over noisy KGs.
- Comprehensive evaluation against multiple baselines, providing valuable insights through error analysis and ablation studies.

Weaknesses:
- The confidence scores predicted by the confidence evaluator may not be well-calibrated, raising concerns about their effectiveness in resolving noisy KG instances.
- The architecture for the error detection task is unclear, and the paper lacks details on the annotation process and the number of annotators involved.
- The paper does not follow the review format with line numbers, and the title could better reflect the active learning aspect.
- The lack of publicly available code or data is a significant shortcoming, as is the omission of recent advancements in hyper-relational link prediction for baseline comparisons.

### Suggestions for Improvement
We recommend that the authors improve the calibration of the confidence scores predicted by the confidence evaluator to enhance their reliability. Additionally, the authors should discuss the architecture specifically for the error detection task and clarify how the NYLON model operates during the inference stage. It would be beneficial to include a comparison of labeling effort and to present a case study demonstrating the effectiveness of the confidence module with examples of correct and incorrect facts. Finally, we encourage the authors to include more recent baseline models in their experiments and to provide publicly accessible code and data to meet contemporary academic standards.