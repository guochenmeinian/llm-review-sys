ID: S0xrBMFihS
Title: Dense-Exponential Random Features: Sharp Positive Estimators of the Gaussian Kernel
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 3, 7, 6, 6, 4, -1, -1, -1, -1
Original Confidences: 4, 3, 2, 4, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on computing the matrix "KC," where K is a kernel matrix and C is a known constant matrix. The authors propose a class of random features designed to minimize the variance of the sample mean correlation with a closed form. The kernel is specifically a "scaled softmax kernel." Additionally, the paper introduces Dense Exponential Random Features (DERFs), which generalize previous random feature methods and demonstrate improved performance in scalable Transformer networks.

### Strengths and Weaknesses
Strengths:  
- The innovative formulation for optimizing sample variance in kernel estimation is commendable.  
- The paper is well-structured, with clear presentation of results, indicating excellent writing quality.  
- DERFs are a novel extension of GERFs, supported by sufficient discussions and experiments demonstrating their effectiveness.  
- The theoretical and experimental components yield interesting results relevant to both kernel methods and Transformers.  

Weaknesses:  
- Notation is overly complex and could be simplified significantly, potentially reducing the number of symbols by 50%.  
- The significance of the exponential kernel's application is questionable, particularly if it is primarily relevant to transformer attention.  
- Some theoretical claims lack rigorous justification, and the empirical evidence does not fully support the practical relevance of the results.  
- The computational expense of the proposed methods, particularly regarding the determinant computation, raises concerns.  

### Suggestions for Improvement
We recommend that the authors improve the clarity of notations by simplifying them and reducing redundancy. For instance, consider rewriting f^(k) as f^k or just f, and B^(k) as B_k. Additionally, we suggest providing more context on the significance of the exponential kernel beyond transformer attention and comparing its computational costs with traditional methods. To enhance the theoretical rigor, we encourage the authors to better justify the objective's appropriateness and its relationship to the actual variance of the GERF estimate. Lastly, conducting simple experiments on transformer inference could help demonstrate the practical relevance of the proposed methods.