ID: du0hvEpgj8
Title: Actively Testing Your Model While It Learns: Realizing Label-Efficient Learning in Practice
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 6, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Active Testing while Learning (ATL) framework, which efficiently collects testing samples for online model risk estimation during the active learning process. The framework enables early termination of active learning and connects Active Learning (AL) with Active Testing (AT) through a feedback mechanism that enhances model performance by transferring selected testing data points to the training dataset. The authors propose a quiz using importance sampling, combine historical quizzes for final model testing, and introduce a feedback algorithm to strengthen the model with labeled test data.

### Strengths and Weaknesses
Strengths:
1. The paper addresses two significant problems in the AL domain: efficient sampling of testing data points and the integration of AL with AT, both of which are highly relevant in AL research.
2. It introduces an unbiased estimator of model risk and a unique method to maximize the utilization of testing samples through active quizzes.
3. A comprehensive set of experiments demonstrates the superior performance of the proposed approaches compared to existing techniques.

Weaknesses:
1. The feedback mechanism, which moves data points from the testing dataset to the training dataset, introduces dependence in the selection of testing samples, potentially undermining the unbiasedness of the risk estimator.
2. The paper lacks clarity on the specific AL algorithm used in experiments, and the performance validation is limited due to the consideration of only a few algorithms.
3. There is insufficient discussion on the potential bias introduced by the feedback mechanism and the assumptions regarding the unbiasedness of the risk estimate when using estimated risks.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the potential bias introduced by the feedback mechanism and clarify how the sampling from optimal \( q_t \) is performed for quizzes. Additionally, the authors should provide a detailed algorithmic block to illustrate each step of the implementation, include absolute accuracy numbers in the experiments, and clarify the active learning strategy used. It would also be beneficial to test the design across a wider range of datasets and architectures to assess the real impact of the early stopping method. Finally, we suggest distinguishing between heuristic and principled estimates in Section 3 to enhance clarity for the reader.