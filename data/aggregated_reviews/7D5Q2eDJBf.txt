ID: 7D5Q2eDJBf
Title: Brewing Vodka: Distilling Pure Knowledge for Lightweight Threat Detection in Audit Logs
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Vodka, a lightweight threat detection framework designed to enhance detection of Advanced Persistent Threats (APTs) by leveraging knowledge distillation and graph Laplacian regularization. The authors propose innovative solutions to address challenges such as noise in provenance graphs and high detection costs. The methodology is solid, with experiments demonstrating significant improvements in detection accuracy and processing speed across multiple datasets. However, the paper lacks comprehensive validation of claims, particularly regarding the model's robustness against diverse adversarial attacks and the effectiveness of the proposed denoising methods.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and organized, facilitating clarity and comprehension.
- Vodka demonstrates good detection accuracy and lower latency, effectively addressing adversarial attacks.
- The authors provide a thorough evaluation and comparison with state-of-the-art methods, showcasing Vodka's capabilities.
- The source code is publicly available, promoting replication and further research.

Weaknesses:
- The experimental validation is limited, lacking a broader range of scenarios and comparisons with recent state-of-the-art methods.
- Hyperparameter analysis is insufficient, with no detailed ablation studies to assess the impact of key configurations on performance.
- The discussion on prior work is shallow, failing to contextualize Vodka's contributions effectively.
- Methodological details, particularly regarding knowledge distillation and graph construction, require clearer explanations.
- The evaluation of robustness against adversarial attacks is limited in scope, lacking systematic analysis.

### Suggestions for Improvement
We recommend that the authors improve the experimental validation by incorporating a broader range of datasets and scenarios, including varying types of APTs and real-world attack simulations. Additionally, conducting detailed ablation studies on hyperparameters, such as the regularization parameter in Laplacian smoothing, would provide valuable insights into model sensitivity. We suggest enhancing the discussion on prior work by providing a comprehensive review and a comparative table summarizing Vodka's strengths against existing methods. Clarity in methodological details can be improved by including step-by-step descriptions or flowcharts of the processes involved. Finally, we encourage the authors to conduct a more systematic analysis of Vodka's robustness against various adversarial attacks and to present metrics quantifying its resilience.