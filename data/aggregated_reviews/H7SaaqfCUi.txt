ID: H7SaaqfCUi
Title: Learning the Infinitesimal Generator of Stochastic Diffusion Processes
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 8, 7, 6, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 2, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for learning self-adjoint SDE generators using operator learning techniques, incorporating a compactification and novel prior knowledge inclusion. It provides statistical learning guarantees that extend those known from discrete Markov processes. The authors consider a time-homogeneous SDE with known diffusion and potentially unknown drift, aiming to derive properties from data, particularly a low-rank representation of its infinitesimal generator (IG). Theoretical results are supported by numerical experiments.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and easy to read, with a thorough background discussion and clear assumptions leading to Theorem 2.
2. It proposes a novel energy risk functional and reduced-rank estimator, establishing spectral learning bounds for generator learning.
3. The inclusion of known diffusion effects into Dirichlet forms provides an elegant method for incorporating prior knowledge.

Weaknesses:
1. The paper's complexity may hinder understanding, particularly given its notation-heavy presentation and reliance on a detailed appendix.
2. Experiments are limited to 1D toy examples, lacking practical validation against competing methods.
3. Unclear extensions to fully data-driven scenarios and the implications of sampling from an invariant distribution are not adequately addressed.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the presentation by reducing notational complexity and incorporating a lightweight version of the notation table in the main text. Additionally, we suggest including more practical examples that demonstrate the application of results to machine learning and validating the proposed method against competing approaches. It would also be beneficial to clarify the implications of using prior knowledge and the robustness of hyperparameter choices, particularly regarding $\mu$, $r$, and $\gamma$. Lastly, addressing the questions raised about the assumptions and the practical gains/losses compared to discrete-time settings would enhance the paper's depth.