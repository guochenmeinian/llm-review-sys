ID: b1XPHC7MQB
Title: Invertible Consistency Distillation for Text-Guided Image Editing in Around 7 Steps
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 6, 5, 6, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to image inversion and editing using consistency distillation, specifically targeting the challenges of applying this technique to diffusion models. The authors propose multi-boundary consistency distillation, achieving inversion in as few as 3-4 steps, and introduce a regularization term to ensure consistency between forward and backward models. The effectiveness of the method is validated on SD 1.5 and SDXL models, demonstrating promising results in fast image inversion and editing.

### Strengths and Weaknesses
Strengths:  
- The paper addresses an important problem in improving efficiency in image inversion, contributing significantly to the field.  
- The adaptation of consistency distillation for image editing tasks is a valuable research direction.  
- The experimental results indicate that the proposed method achieves impressive editing effects in fewer inference steps compared to existing models.  
- The overall framework is well-organized and easy to follow.

Weaknesses:  
- The method's description lacks clarity, particularly regarding the coupling of image and noise data necessary for training consistency distillation.  
- The reliance on two models for fast inversion and generation may be seen as ad-hoc, raising questions about the necessity of this approach.  
- The contribution may be perceived as less impactful since many techniques are derived from prior work, and the framework may not generalize well to other diffusion model acceleration methods.  
- The current experiments primarily focus on inversion methods, lacking comparisons with other training or fine-tuning approaches, and do not discuss the impact of reducing distillation steps on performance.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the method description, particularly by explaining how to obtain the necessary coupling of image and noise data for training. Additionally, we suggest including a comparison of inversion and sampling times with baseline methods in a table within the main paper. Expanding the experimental section to include comparisons with other training methods, such as instruct-pix2pix or ControlNet, would enhance the manuscript. Furthermore, we encourage the authors to discuss the potential performance degradation when decreasing the distillation steps and provide experimental results for cases with fewer steps. Lastly, we advise replacing Figure 1 with a more informative figure that summarizes the methodology effectively, as the current version detracts from the paper's professionalism.