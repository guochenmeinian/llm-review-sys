ID: 14R8QBKzFH
Title: Tight Bounds for Machine Unlearning via Differential Privacy
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 4, 4, 5, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper studies the machine unlearning problem through the lens of differential privacy (DP), proposing the use of differentially private models to eliminate the need for unlearning updates, thereby making the unlearning process independent of side information. The authors establish a tight lower bound on the number of data points that can be unlearned and introduce new proving techniques. The paper also explores the deletion capacity of differentially private machine unlearning algorithms, providing upper and lower bounds while addressing the implications of convex and strongly convex loss functions.

### Strengths and Weaknesses
Strengths:
1. The paper effectively addresses the practical issue of machine unlearning, enhancing theoretical results and closing gaps in deletion capacity bounds.
2. It employs innovative techniques from the DP literature, improving the deletion capacity lower bound and establishing key properties analogous to classical DP.

Weaknesses:
1. The connection to machine unlearning is tenuous, as the motivation to avoid side information may not hold in many scenarios where retraining requires access to the original training set.
2. The focus on theoretical analysis lacks empirical validation, limiting the practical applicability of the proposed algorithms, particularly for non-convex loss functions common in real-world models.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the connection between their results and practical unlearning applications, particularly addressing the necessity of excluding side information. Additionally, we suggest incorporating empirical experiments to validate the proposed algorithms and discussing the implications of their theoretical results in the context of real-world machine learning models. Furthermore, we encourage the authors to provide a more detailed discussion of the quantitative improvements compared to prior work and clarify the limitations regarding the assumptions on loss functions.