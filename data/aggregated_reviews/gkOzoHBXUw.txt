ID: gkOzoHBXUw
Title: Federated Fine-tuning of Large Language Models under Heterogeneous Tasks and Client Resources
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 5, 6, 7, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 2, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents FlexLoRA, a LoRA-based federated fine-tuning algorithm designed to address the challenges of heterogeneous client resources and data distributions in federated learning (FL). FlexLoRA allows for the dynamic adjustment of local LoRA ranks by employing SVD for weight distribution, thereby enhancing the global model's generalization ability. The authors propose a method that first aggregates full-size LoRA modules and then decomposes them into heterogeneous ranks based on client capabilities.

### Strengths and Weaknesses
Strengths:
1. Exploring heterogeneous LoRA ranks across clients to fully utilize their resources is an imperative research direction.
2. The method of first obtaining a full-size LoRA and then decomposing it into different ranks using SVD is simple, effective, and rational.
3. Extensive experiments and theoretical analyses support the effectiveness and scalability of the proposed method.

Weaknesses:
1. Numerous typos remain in the paper, including specific corrections needed in figures and tables.
2. The proposed FlexLoRA relies on SVD for redistribution, a method already presented in prior works, which may not constitute a novel contribution.
3. The paper lacks a detailed discussion of limitations, particularly regarding the implications of parameter-efficient fine-tuning (PEFT) techniques like LoRA.
4. The experimental setup claims to follow a cross-device setting, but the small number of clients used raises concerns about the rigor of this claim.
5. The configurations of ranks in the experiments are not very diverse, and the method's optimization for task heterogeneity is unclear.

### Suggestions for Improvement
We recommend that the authors improve the clarity and correctness of the paper by addressing the numerous typos identified. Additionally, the authors should explicitly discuss the limitations of their approach, particularly regarding the implications of PEFT methods. It would be beneficial to clarify the rationale behind using SVD for redistribution and to provide comparisons with a broader range of state-of-the-art FL methods. Furthermore, we suggest that the authors consider a more rigorous definition of the experimental setting, potentially aligning it with a cross-silo framework, and explore the adaptability of their method to more diverse rank configurations and task heterogeneity.