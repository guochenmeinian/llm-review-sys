ID: 1ZvEtnrHS1
Title: Convolutional State Space Models for Long-Range Spatiotemporal Modeling
Conference: NeurIPS
Year: 2023
Number of Reviews: 20
Original Ratings: 7, 5, 5, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ConvS5, a convolutional state-space model designed to capture long-range spatiotemporal dependencies in video data. The authors extend the S5 model to a convolutional framework, integrating convolutional inductive biases of ConvRNNs with linear, continuous-time dynamics akin to SSMs like S5. They address two technical challenges: parallelizing training across sequences and effectively modeling long-range spatiotemporal dependencies. ConvS5 allows for efficient training through parallel scans, demonstrating strong performance on benchmarks such as Moving MNIST, DMLab, Minecraft, and Habitat. The paper includes experimental results, including kernel size ablations, which support the design decisions and effectiveness of the method against strong baselines, showing that ConvS5 outperforms traditional ConvRNNs and S5 baselines in spatiotemporal modeling.

### Strengths and Weaknesses
Strengths:
- The paper is clear and well-written.
- Comprehensive experiments across various datasets highlight the method's superiority or competitiveness against state-of-the-art (SOTA) methods.
- The introduction of a novel parallel scan for convolutional recurrences and a parameterization scheme that captures long-range dependencies.
- Improved scaling in sequence length enables training on longer sequences, resulting in better and more stable generation.
- Faster inference speed while maintaining high generation fidelity.
- The paper contributes to the understanding of connections between ConvRNNs and recent SSM methods.

Weaknesses:
- The technical novelty is somewhat low, as ConvS5 is a straightforward extension of the S5 model.
- Some reviewers express reservations about the technical contributions not meeting NeurIPS standards.
- Recurrent models may have limited capacity in storing fine-grained scene details, which could hinder scalability, particularly in visually complex videos. A rigorous study on this aspect is recommended.
- The paper lacks a variety of ConvSSM variants, limiting the support for the basic idea of ConvSSMs.
- Comparisons with Transformer and ConvLSTM could be more extensive, particularly regarding quality-speed tradeoffs.
- There is insufficient explanation and experimentation regarding the design of the convolutional operator on SSMs.
- The paper may require further justification of its originality and significance to align with acceptance criteria.

### Suggestions for Improvement
We recommend that the authors improve the novelty of the work by exploring additional ConvSSM variants beyond ConvS5 to strengthen the foundational concept. It would be beneficial to conduct more extensive experiments comparing ConvS5 with efficient attention-based approaches, such as kernel-based linear attention and others. We suggest including comprehensive ablation studies that validate the rationale behind the convolutional design, particularly focusing on the effectiveness of convolutional components. Additionally, the authors should report computational metrics such as FLOPs and training efficiency for both ConvS5 and baseline models to provide clearer insights into the advantages of their approach. Furthermore, we recommend improving the clarity of how ConvS5 differs from previous contributions, emphasizing its novel aspects, and providing a more detailed discussion on the significance of the results, particularly in terms of their potential impact on the field of spatiotemporal modeling. Addressing these points will strengthen the paper's case for acceptance.