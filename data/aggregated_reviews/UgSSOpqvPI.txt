ID: UgSSOpqvPI
Title: DAMEX: Dataset-aware Mixture-of-Experts for visual understanding of mixture-of-datasets
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 5, 5, 6, 5, 6, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Dataset Aware Mixture of Experts (DAMEX) aimed at developing a universal object detector that can effectively handle a variety of datasets. The authors propose a novel MoE loss to learn the dataset index distribution, addressing issues of knowledge sharing in conventional MoE models. Extensive experiments are conducted to validate the effectiveness of DAMEX against existing methods.

### Strengths and Weaknesses
Strengths:
1. The manuscript is well-organized and motivated, providing detailed explanations of conventional MoE and its limitations.
2. The self-consistent idea of addressing knowledge distribution shifts among datasets is intuitive, with the proposed loss function $\mathcal{L}_{DAMEX}$ appearing to support this goal.
3. The experiments are comprehensive, demonstrating the method's effectiveness across various settings.

Weaknesses:
1. The contribution is limited, primarily revolving around the DAMEX loss function, which does not adequately address dataset distribution shifts, as evidenced by results in Table 1 showing imbalances among datasets.
2. The claim of outperforming state-of-the-art methods by nearly 10% AP is questionable, particularly when comparing against older models like DINO, which should not be classified as SOTA.
3. The design of assigning one expert per dataset may be restrictive, potentially leading to confusion with diverse datasets, and the performance on common benchmarks is lower than expected.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the evaluation metrics, particularly the choice of COCO-style AP over Pascal VOC style AP, to avoid confusion. Additionally, addressing the limitations of the dataset-specific routing layer and exploring the scalability of the model would enhance the manuscript. It would be beneficial to include a more nuanced discussion of the performance variations across datasets and consider incorporating recent advances in open vocabulary object detection as baselines. Furthermore, we suggest revising the manuscript for grammatical consistency and clarity to improve readability.