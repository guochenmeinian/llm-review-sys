ID: gaktiSjatl
Title: Semi-Implicit Denoising Diffusion Models (SIDDMs)
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 6, 5, 5, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Semi-Implicit Denoising Diffusion Model (SIDDM), which aims to accelerate sampling while preserving high-quality generation. SIDDM employs an implicit model to align the marginal distributions of the reverse diffusion process and models the explicit conditional distribution of the forward diffusion. A novel regularization method is introduced to enhance performance. Experiments indicate that SIDDM achieves comparable results to existing diffusion models with fewer sampling steps.

### Strengths and Weaknesses
Strengths:
1. The authors analyze the limitations of DDGAN and decompose the denoising distribution to refine the training objective, which is a reasonable approach.
2. Experiments on simulated Mixture of Gaussians and various public datasets demonstrate the method's effectiveness.
3. The provision of code for result reproduction underscores the robustness of the work.

Weaknesses:
1. Figure 1 lacks explanations for the different colored dashed lines.
2. Implementation details, such as the structure of the regression model, discriminator regularizer, and denoiser, are not adequately clarified, nor are training settings like iterations provided.
3. There are no experiments on conditional generation, which limits the submission's comprehensiveness.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Figure 1 by providing explanations for the dashed lines. Additionally, please clarify the implementation details, including the regression model structure, discriminator regularizer, and training settings. We also suggest conducting experiments on conditional generation to strengthen the submission. Furthermore, it would be beneficial to analyze the performance discrepancies observed in larger sampling steps and provide a detailed training and inference strategy for SIDDM. Lastly, discussing limitations more explicitly in the paper would enhance its depth.