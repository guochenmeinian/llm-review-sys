ID: v0GzRLvVp3
Title: Temporal Continual Learning with Prior Compensation for Human Motion Prediction
Conference: NeurIPS
Year: 2023
Number of Reviews: 26
Original Ratings: 5, 5, 5, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 5, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel multi-stage training framework called Temporal Continual Learning (TCL) for Human Motion Prediction (HMP), addressing the challenges of short-term and long-term predictions while incorporating prior information from past predictions. The authors introduce the Prior Compensation Factor (PCF) to mitigate the loss of prior information and derive an optimization objective through theoretical analysis. The TCL framework is adaptable to various HMP backbone models and datasets, with extensive experiments demonstrating its effectiveness across multiple benchmark datasets, including Human3.6M and AMASS. Additionally, the authors propose a learning mechanism for the variable α, which balances training losses across different tasks. The rebuttal includes additional results and clarifications addressing reviewers' concerns, particularly regarding the zero-shot experiments and the interpretation of α.

### Strengths and Weaknesses
Strengths:
- The introduction of the TCL framework effectively addresses the trade-off between short-term and long-term predictions in HMP, enhancing performance by utilizing prior knowledge.
- The PCF is a valuable addition that helps mitigate forgetting during multi-stage training, supported by a theoretically derived optimization objective.
- The exploration of a new pipeline for the HMP task is commendable.
- The authors have conducted extensive experiments, including new results on the AMASS dataset, which demonstrate the effectiveness of their approach.
- The rebuttal provides clarifications that address many of the reviewers' concerns, indicating a willingness to improve the manuscript.

Weaknesses:
- The writing lacks clarity in several areas, including missing periods and confusing terminology in Figure 1, which requires better illustration to clarify concepts.
- The motivation behind the design of αs is unclear, raising questions about their role in compensating for forgotten knowledge.
- The zero-shot experiment lacks sufficient challenge, as both training and testing were performed on the Human3.6M dataset.
- Experimental results are insufficient; additional datasets like AMASS should be included, and more backbone comparisons are needed in the main results.
- The manuscript suffers from issues related to clarity, including confusing explanations of the α term and missing captions in the rebuttal tables, which detracts from its professionalism.
- The paper lacks a clear discussion on the efficiency and potential costs associated with the proposed method.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing, particularly in the methods section, to avoid confusion. Specifically, please provide a clearer explanation of the concepts illustrated in Figure 1 and consider adding a figure to better differentiate between "short+long," "short only," and "short then short+long." Additionally, we suggest including more experimental settings related to the toy example in Figure 1 and providing results on the AMASS dataset to strengthen the findings. The authors should also clarify the motivation for the αs and provide intuitive explanations for the scalar representation of motion to clarify their role. Furthermore, we recommend improving the zero-shot experiment by training on Human3.6M and testing on AMASS to introduce more challenge. Please ensure that all figures and tables in the manuscript have clear captions to enhance readability. Lastly, we encourage the authors to include more recent baselines in their comparisons, consider zero-shot adaptation experiments on other datasets, and release more experiments and a demo video alongside the code to better showcase the strengths of their work and provide detailed guidance for peers.