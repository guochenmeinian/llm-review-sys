ID: PXsqbAjpQd
Title: SHOT: Suppressing the Hessian along the Optimization Trajectory for Gradient-Based Meta-Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 6, 6, 6, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a hypothesis that gradient-based meta-learning (GBML) implicitly suppresses the Hessian along the optimization trajectory in the inner loop. The authors propose an algorithm, SHOT (Suppressing the Hessian along the Optimization Trajectory), which minimizes the distance between the parameters of a target model (trained with fewer steps) and a reference model (trained with more steps) to achieve this suppression. The method is algorithm- and model-agnostic, demonstrating effectiveness in few-shot classification tasks.

### Strengths and Weaknesses
Strengths:
- The hypothesis regarding Hessian suppression is intriguing and provides a novel perspective on GBML.
- The SHOT algorithm shows impressive performance improvements and is versatile, applicable to various GBML baselines.

Weaknesses:
- The manuscript suffers from clarity issues, particularly in Section 4, where explanations are often confusing or incomplete.
- The validity of some comparisons to baselines is questionable, particularly regarding the reference model's role and the appropriateness of using a randomly initialized model for comparison.
- Insufficient discussion of the relationship to existing distillation and preconditioning methods in the literature, which could enhance the paper's context and relevance.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Section 4 by providing clearer descriptions of the proposed methods, including algorithms or pseudocode for both SHOT_p and SHOT_r. Additionally, it is crucial to clarify the role of the reference model in comparisons and to include a meta-learned baseline for more insightful evaluations. We suggest discussing the relationship of SHOT to existing distillation methods and preconditioning techniques in more detail, as this would strengthen the paper's contributions. Furthermore, we encourage the authors to provide visualizations of the optimization landscape to support claims about Hessian suppression and to include a discussion of limitations and potential societal impacts of their model.