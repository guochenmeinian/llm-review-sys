ID: 8PWvdaRQAu
Title: Contrasting with Symile: Simple Model-Agnostic Representation Learning for Unlimited Modalities
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 7, 7, 6, -1, -1
Original Confidences: 3, 2, 4, -1, -1

Aggregated Review:
### Key Points
This paper presents Symile, a novel contrastive learning objective designed to address the limitations of pairwise CLIP methods by capturing total correlation among multiple modalities. The authors derive a lower bound on total correlation using a generalized inner product and demonstrate that Symile representations serve as sufficient statistics for remaining modalities. Experiments on a multilingual dataset with 33 million samples and a clinical dataset illustrate that Symile outperforms pairwise CLIP in cross-modal classification and retrieval tasks, even in the presence of missing modalities.

### Strengths and Weaknesses
Strengths:  
- The paper is well-written, clearly stating the motivation, problem formulation, and theoretical contributions, supported by helpful figures.  
- The theoretical derivations appear valid, providing concrete results on lower bounds, optimal scoring functions, and statistical sufficiency.  
- The introduction of the multilingual dataset, Symile-M3, is significant, and the work addresses a crucial limitation of existing methods by capturing higher-order dependencies.

Weaknesses:  
- The originality is questioned, as the problem of capturing dependencies beyond pairwise mutual information is well-studied, with potential extensions of existing methods not explored.  
- The rationale for curating a new multilingual dataset instead of using established multimodal datasets is unclear, and the lack of comparisons with standard datasets weakens the submission.  
- Limited experiments focus solely on comparisons with CLIP, neglecting more recent works like ImageBind, which should be included for a comprehensive evaluation.  
- The formulation of the Symile model requires complete triplets for training, posing challenges for scalability and practical applications due to the absence of mechanisms for handling missing values.

### Suggestions for Improvement
We recommend that the authors improve the justification for creating the new multilingual dataset and include comparisons with established multimodal datasets such as VQA and GQA. Additionally, the authors should consider incorporating results from more recent works, particularly ImageBind, to strengthen the evaluation. Addressing the limitation of requiring complete triplets by extending the model to handle missing values would enhance its practical applicability. Furthermore, we suggest providing error bars in Figures 5 and 6 and clarifying the rationale behind the scoring function's formulation. Lastly, including more realistic examples in the failure analysis would improve the theoretical discussions.