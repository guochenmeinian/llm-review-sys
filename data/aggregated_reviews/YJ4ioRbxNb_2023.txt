ID: YJ4ioRbxNb
Title: A benchmark of categorical encoders for binary classification
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 1, 7, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive benchmark of categorical encoding methods for binary classification, addressing limitations in existing benchmarks. The authors find that a high number of datasets (>25) is necessary for replicability and that conclusions are heavily influenced by the model, evaluation metric, and aggregation method. They identify that one-hot, sum, binary, and WoE encodings rank significantly better than other encoders, although this does not hold for decision trees. A potential issue with AUC evaluations is noted, although it likely does not impact overall results.

### Strengths and Weaknesses
Strengths:
- The evaluation is extensive, utilizing 50 datasets and considering multiple factors in the experimental setup.
- The paper effectively illustrates how experimental design decisions affect encoder rankings, with clear figures and well-written text.
- It benchmarks a variety of encoding strategies.

Weaknesses:
- References to software packages like scikit-learn are insufficient, lacking full citations.
- Some tuning methods in Table 1 are not described, and there are question marks indicating missing information.
- Approximately 4% of experiments did not complete, and the handling of missing values is unclear.
- The assumption of applying the same encoding scheme across all features is unrealistic, which the authors acknowledge as a limitation.

### Suggestions for Improvement
We recommend that the authors improve the citations for software packages by including full references where available. Additionally, we suggest contacting the authors of the papers referenced in Table 1 to clarify the tuning methods. The authors should explicitly describe their strategy for handling missing evaluations, including whether they were ignored or imputed. Lastly, we encourage the authors to explore the feasibility of applying different encoding schemes to individual features, as this represents a significant opportunity for future work.