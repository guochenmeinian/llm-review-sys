ID: zeNwOAcb4q
Title: Estimating Transition Matrix with Diffusion Models for Instance-Dependent Label Noise
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 3, 2, 3
Original Confidences: 4, 4, 5

Aggregated Review:
### Key Points
This paper presents a method for supervised learning from noisy labels by modeling label noise with an instance-dependent label transition probability matrix. The authors propose leveraging a conditional diffusion model to generate a transition matrix conditioned on sample features. The approach involves generating pseudo paired samples $(x_i, T_i)_{i=1}^N$ using VolMinNet, training a conditional diffusion model to produce $T_i$ given $x_i$, and subsequently training a classifier based on the estimated transition matrix.

### Strengths and Weaknesses
Strengths:
1. The problem addressed is significant for the broader machine learning community.
2. The experimental settings, including baselines and ablations, are adequately provided for numerical validation.
3. The application of a diffusion model is a novel approach.

Weaknesses:
1. The technical soundness of the proposed method is questionable. The method trains a conditional diffusion model using paired samples $(x_i, T_i)$, but the pseudo transition matrix $T_i$ generated from VolMinNet is sample-independent and does not relate to the true transition matrix $T(x)$. Thus, the diffusion model can only approximate $p(T_i | x_i)$, lacking a clear connection to $p(T(x) | x)$, and cannot outperform VolMinNet.
2. The transition matrix is treated as a deterministic function of the sample, making the learning of a generative model for $p(T(x) | x)$ nonsensical, as it leads to a degenerate distribution.
3. The diffusion model training does not utilize noisy labels, limiting the extraction of information about the true transition matrix $T(x)$ beyond what is captured by the pseudo paired samples.
4. The manuscript lacks clarity on the source of performance gains in empirical results, providing no intuitive or theoretical justification for the quality of the estimator or rationale for the algorithm design.
5. The reasons for using a diffusion model to generate the transition matrix are unclear, and the construction of the diffusion process does not account for necessary properties of the transition matrix.
6. The impact of pre-trained features on the diffusion process has not been analyzed, and the training of the diffusion model raises questions about its ability to incorporate instance-dependent information.
7. The time required for diffusion training is not discussed, which may affect the significance of performance improvements.

### Suggestions for Improvement
We recommend that the authors improve the technical soundness of their method by clarifying the relationship between the pseudo transition matrix and the true transition matrix. It would be beneficial to provide a theoretical justification for the performance gains observed in the empirical results. Additionally, the authors should discuss how the diffusion process can be constructed to satisfy the properties of the transition matrix and analyze the impact of pre-trained features on the diffusion model. We also suggest including an ablation study that isolates the effects of the initialized transition matrix on classifier training. Finally, addressing the time complexity of the diffusion training process would enhance the manuscript's rigor.