ID: oQc7TOCk5G
Title: On Theoretical Limits of Learning with Label Differential Privacy
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 6, 7, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 2, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into the theoretical boundaries of learning with Label Differential Privacy (Label-DP) in both central and local models. The authors establish min-max optimal rates for excess error in multi-class classification, regression with bounded labels, and regression with unbounded labels under specific conditions. The findings indicate that while local-DP increases sample complexity by a factor of \(1/\varepsilon^2\) for classification and regression with bounded labels, it maintains the same rate for excess error compared to non-private learning. In contrast, regression with unbounded labels shows worse sample complexity dependence on excess error than non-private settings. The paper also compares these results with full local-DP and non-private learning.

### Strengths and Weaknesses
Strengths:  
The paper provides a comprehensive study of min-max rates for learning under label differential privacy across various models and settings, contributing significantly to the literature on min-max rates for both private and non-private learning. The results clarify the cost of label differential privacy and highlight sample complexity benefits over full differential privacy.

Weaknesses:  
The writing quality requires improvement, as several sections are challenging to understand. The proof techniques primarily utilize standard tools, which may not be a weakness but could benefit from clearer exposition. Specific issues include unclear notation, vague algorithm descriptions, and insufficient detail in proof outlines.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing throughout the paper. In Table 1, please include appropriate citations for prior work. Clarify the notation used, particularly around line 178 regarding the output of the mechanism for classification. Ensure that all assumptions, such as Assumption 1, are clearly defined and relevant to all contexts discussed. Additionally, we suggest enhancing the proof outlines for Theorems 1, 2, and 3 to provide more informative insights into the techniques used. Consider revising the abstract to clearly state the main challenges and contributions related to minimax rates.