ID: jD1eWpUMOf
Title: Pruning for Robust Concept Erasing in Diffusion Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 8, 5, 8
Original Confidences: 4, 1, 4

Aggregated Review:
### Key Points
This paper presents a pruning-based framework aimed at enhancing the robustness of concept erasure in text-to-image diffusion models. The authors identify the vulnerabilities of current fine-tuning methods to adversarial prompts and propose a solution that integrates pruning with concept erasure. The approach effectively prevents the reactivation of erased concepts while maintaining model performance by pruning only about 0.001% of the parameters. The experiments demonstrate significant improvements over existing state-of-the-art techniques.

### Strengths and Weaknesses
Strengths:
- Clear identification of a critical flaw in existing concept erasing methods and a direct solution to this issue.
- Innovative application of pruning techniques to concept erasure in generative models, distinguishing this work from traditional applications in classification tasks.
- Efficient method that effectively removes undesirable pathways while preserving model performance, making it suitable for real-world applications.

Weaknesses:
- Limited theoretical depth regarding the mechanisms by which specific pruned parameters contribute to robust concept erasure, leaving readers to speculate on the underlying principles.

### Suggestions for Improvement
We recommend that the authors improve the theoretical exploration of why specific pruned parameters lead to robust concept erasure to strengthen the paper's contribution. Additionally, we suggest adding more illustrations in the title of Figure 3 for clarity and repositioning it to the top of page 5 to avoid confusion. In Table 3, an explanation for why "P-ESD works worse than ESD" should be included. Finally, it would be beneficial to include an analysis of how different levels of pruning affect robustness or generation quality in the appendix.