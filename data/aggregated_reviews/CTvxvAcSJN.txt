ID: CTvxvAcSJN
Title: SceneCraft: Layout-Guided 3D Scene Generation
Conference: NeurIPS
Year: 2024
Number of Reviews: 19
Original Ratings: 5, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a layout-guided method for 3D indoor scene generation using a 3D bounding box layout and text prompts. The authors propose a two-stage approach where a 2D conditional diffusion model, DreamScene2D, is trained to synthesize rendered views based on semantic layouts and depth maps. This model is then distilled into a NeRF representation. The method demonstrates high-quality rendering and controllability, achieving realistic 3D scenes from user inputs.

### Strengths and Weaknesses
Strengths:
- The use of a 3D layout as a prior for scene generation is user-friendly and enhances scene control.
- The method achieves high rendering quality and good controllability through text prompts and scene layouts.
- The writing is clear and the structure is easy to follow.

Weaknesses:
- The key insight is similar to the recently released UrbanArchitect, which also uses layout as a prior for urban scene generation; a discussion of this similarity is needed.
- Video results and 3D visualizations (e.g., generated 3D meshes) are lacking, which would aid in illustrating the method's effectiveness.
- Quantitative results are missing; a User Study on visual quality and 3D consistency should be conducted, and metrics like FID could enhance evaluation.
- Some training details, such as memory and time requirements, are not provided.
- The method could benefit from using decomposed 3D representations for further editing and from including an automatic scene layout creation method.

### Suggestions for Improvement
We recommend that the authors improve the discussion regarding the similarities with UrbanArchitect to clarify the novelty of their approach. Additionally, providing video results and 3D visualizations would enhance the presentation of their findings. The authors should conduct a User Study to gather quantitative results on visual quality and 3D consistency, and consider using metrics like FID for evaluation. Including detailed training requirements and exploring decomposed 3D representations for editing would strengthen the paper. Finally, we suggest incorporating a method for automatic scene layout creation to further enhance the usability of the proposed method.