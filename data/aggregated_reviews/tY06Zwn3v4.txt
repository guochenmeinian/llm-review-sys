ID: tY06Zwn3v4
Title: EG-SIF: Improving Appearance Based Gaze Estimation using Self Improving Features
Conference: NeurIPS
Year: 2023
Number of Reviews: 4
Original Ratings: 7, 7, 7, -1
Original Confidences: 4, 3, 3, 5

Aggregated Review:
### Key Points
This paper presents a method for gaze estimation that addresses the variability in input image quality by categorizing training data into high-quality and low-quality subsets based on contrast and blurriness. The authors propose generating adverse samples from high-quality images for denoising purposes and utilize a combination of reconstruction loss and gaze estimation loss during training. The approach is tested on challenging datasets, demonstrating superior performance compared to existing methods. The technical contribution lies in employing a generative adversarial technique for denoising, enhancing gaze estimation accuracy.

### Strengths and Weaknesses
Strengths:
- The idea of categorizing training datasets by image quality is innovative.
- The use of image enhancement as an auxiliary task is a novel approach.
- The methodology is well-described and appears well-implemented.

Weaknesses:
- There is a typo on Page 12, in front of Table 6.
- The metric definition is missing in Table 6.
- The term “Self-improving” in the title may cause confusion regarding its meaning.
- Unclear computation methods for rmse-contrast and blurriness coefficients.
- Imprecise writing and mathematical notation, particularly in equation 2.
- The source code link is not provided.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the title by reconsidering the term “Self-improving” to avoid confusion. Please include the metric definition in Table 6's caption or text. We suggest enhancing Fig 1 by changing the histogram color to green or red and scaling the x-axis in all subplots for better visualization. In Section 3.3, we encourage the authors to elaborate on the meaning of "interpretability of learned features." In Section 4.2, we ask for clarification on the rationale behind inverting the right eye and the benefits of harmonizing features. An ablation study demonstrating the effects of dissimilar eye features would be beneficial. In Section 4.3, we recommend detailing how the values for learning rate, decay, and dropout were determined, and reporting the probabilities for brightness, contrast, saturation, and hue augmentations to facilitate reproducibility. Lastly, we expect the implementation to be made available as source code for objective assessment.