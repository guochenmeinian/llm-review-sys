ID: ZYNYhh3ocW
Title: Towards Next-Generation Logic Synthesis: A Scalable Neural Circuit Generation Framework
Conference: NeurIPS
Year: 2024
Number of Reviews: 25
Original Ratings: 6, 5, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework named T-Net for synthesizing logic circuits using differentiable neural architecture search (DNAS). The authors identify challenges in applying existing DNAS methods and propose three modifications: (1) transforming input-output examples to reduce inputs and increase outputs, (2) altering the network search space from rectangular to triangular shapes, and (3) implementing regularization to mitigate overfitting. Additionally, a circuit optimization process utilizing reinforcement learning and evolutionary algorithms is introduced. The authors report that their method significantly outperforms the top IWLS winners, achieving an average circuit size reduction of 8.78% compared to SOP, 17.02% compared to the IWLS 2022 first-place team (EPFL), and 10.7% compared to the IWLS 2023 second-place team (TUW). Although the authors do not fully outperform the IWLS 2023 first-place team (Google) due to a limited optimization time of one week versus three weeks, they note that excluding five corner cases allows their method to achieve comparable circuit sizes while using only one-third of the optimization time. Experimental results show significant improvements in correctness and circuit size compared to state-of-the-art methods.

### Strengths and Weaknesses
Strengths:
- The paper is the first to extensively explore the application of DNAS to logic synthesis, providing valuable insights into the challenges and proposing well-motivated modifications.
- The introduction of T-Net effectively addresses limitations in existing DNAS methods, enhancing accuracy and scalability in circuit generation.
- The experimental evaluation demonstrates substantial improvements over top teams from recent IWLS contests, showcasing the effectiveness of the proposed modifications.
- The paper provides a full and transparent evaluation of the method against the IWLS benchmark, demonstrating significant improvements in circuit size reduction.
- The authors have improved the mathematical presentation and included additional analyses, which enhance the clarity and depth of the manuscript.

Weaknesses:
- The paper lacks formal introductions to key concepts, such as logic synthesis and DNAS, making it challenging to follow the initial arguments. Many essential details are relegated to an appendix, which detracts from the main text's clarity.
- The motivation regarding the weaknesses of DNAS is somewhat misleading, as the issues raised have been previously addressed in the literature.
- The mathematical descriptions are unclear, and the paper does not provide sufficient context for the loss function or the evolutionary and reinforcement learning methods used.
- The contribution in terms of ML/AI may be perceived as limited, suggesting a more targeted audience for the study.
- The optimization time constraints hinder the ability to fully outperform the leading method.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the main text by integrating essential details currently in the appendix, ensuring that the paper meets the nine-page requirement and is easier to follow. Additionally, we suggest that the authors provide a more robust evaluation by including comparisons with the IWLS benchmarks and Google DeepMind's DNAS Skip to substantiate claims of state-of-the-art performance. We encourage the authors to enhance the mathematical rigor in their descriptions and clarify the implications of their modifications to DNAS. Furthermore, we recommend that the authors improve the targeted audience appeal by emphasizing the novelty of their contributions, particularly the T-shaped structure and skip connection regularization. Lastly, consider including results on all IWLS benchmarks in the paper to provide a more comprehensive view of the method's performance.