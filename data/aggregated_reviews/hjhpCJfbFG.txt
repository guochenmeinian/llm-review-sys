ID: hjhpCJfbFG
Title: Interpretable Image Classification with Adaptive Prototype-based Vision Transformers
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 6, 5, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ProtoViT, a novel method for interpretable image classification that integrates a vision transformer (ViT) backbone with a prototypical neural network framework. The authors argue that existing prototypical methods, primarily based on convolutional neural networks (CNNs), are limited by spatially rigid prototypes and struggle with geometric variations of objects. ProtoViT addresses these issues by incorporating a greedy matching algorithm and an adaptive slots mechanism, enabling the model to learn interpretable prototypes that can adapt to geometric variations. The authors provide empirical evaluations demonstrating state-of-the-art accuracy and qualitative analyses showcasing the faithfulness and coherence of the learned prototype representations.

### Strengths and Weaknesses
Strengths:
- The methods are clean and sound, supported by ample ablation experiments, and show marginally better performance than existing approaches with interpretable and coherent prototypes.
- The paper is well-written, with clear claims and effective illustrations, particularly regarding the greedy matching algorithm.
- The proposed method is validated on multiple benchmarks and includes extensive ablation studies.

Weaknesses:
- There is a lack of qualitative comparison with other ViT methods, raising concerns about the inherent interpretability of the proposed approach.
- Some sections, such as the optimization of last layers, contain unclear notation.
- The contribution of ProtoViT compared to existing ViT prototype methods is not sufficiently clarified.
- The method assumes a solid backbone model, limiting its applicability in scenarios where interpretability is needed.

### Suggestions for Improvement
We recommend that the authors improve the qualitative comparison with other ViT methods to clarify the interpretability of their approach. Additionally, we suggest revising unclear notations in Section 3.4 and providing a more detailed discussion on the contribution of ProtoViT relative to existing methods. It would be beneficial to include examples of incorrect predictions to understand the model's limitations better. Furthermore, we encourage the authors to address potential information leakage between image patches during the attention step and consider the implications of the coherence loss on prototype diversity. Lastly, conducting a user study to quantify interpretability and including metrics related to explainability would enhance the paper's contributions.