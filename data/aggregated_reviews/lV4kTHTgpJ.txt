ID: lV4kTHTgpJ
Title: Model Fusion through Bayesian Optimization in Language Model Fine-Tuning
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 7, 7, 8, 2, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents "Bayesian Optimization Model Fusion" (BOMF), a method for fusing model weights using Bayesian Optimization to enhance fine-tuning of pre-trained language models. The authors propose a two-stage Bayesian optimization framework that first identifies optimal hyperparameters for fine-tuning and then employs multi-objective Bayesian optimization to optimize model fusion. The paper highlights a significant discrepancy between loss and metric surfaces in NLP tasks and provides empirical evidence supporting the effectiveness of BOMF across various NLP tasks.

### Strengths and Weaknesses
Strengths:
- The paper introduces a novel approach to model fusion through BOMF, creatively applying Bayesian optimization to fine-tuning challenges.
- The rigorous experimental design and comprehensive evaluation demonstrate the robustness and effectiveness of BOMF.
- The paper is well-structured and easy to follow, with clear presentation of the problem and proposed solutions.

Weaknesses:
- The empirical observations regarding the discrepancy between metric and loss are based on a specific outdated model, raising questions about the accuracy computation and hyperparameter alignment.
- The performance improvements from BOMF are relatively small, and the computational efficiency compared to traditional methods is not adequately discussed.
- The individual components of the proposed method feel disconnected, leading to an under-exploration of the multi-objective Bayesian optimization for model fusion.

### Suggestions for Improvement
We recommend that the authors improve the discussion on computational efficiency, particularly the extra compute required for BOMF and how it compares to traditional fine-tuning methods. Additionally, a more in-depth hyperparameter sensitivity analysis should be included to assess the stability of BOMF under different settings. The authors should also clarify how accuracy is computed on RoBERTa and consider providing results from more recent models and datasets to ensure relevance. Lastly, we suggest that the authors explore the integration of alternative approaches like Reinforcement Learning from Human Feedback (RLHF) to address the discrepancies between loss and desired metrics more effectively.