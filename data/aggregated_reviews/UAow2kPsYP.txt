ID: UAow2kPsYP
Title: A Unified Generalization Analysis of Re-Weighting and Logit-Adjustment for Imbalanced Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 7, 8, 7, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a unified generalization analysis of loss-modification approaches for class-imbalanced learning, addressing the gap between balanced accuracy and empirical loss. The authors propose a data-dependent contraction technique to establish a fine-grained generalization bound and analyze existing methods systematically. They introduce two novel algorithms, TLA and ADRW, based on theoretical insights, and validate their effectiveness through extensive experiments on benchmark datasets.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and easy to follow.
- It provides great theoretical analysis and valuable insights.
- Novel algorithms are proposed based on the analysis.
- Extensive experiments demonstrate the effectiveness of the proposed methods.

Weaknesses:
- Code is not submitted, hindering reproducibility of results.
- The paper does not review or compare recently proposed class-imbalanced learning algorithms, which may achieve better performance than the proposed methods.
- There are numerous typos and grammatical errors throughout the text.
- The experiments are limited to the ResNet family, lacking results on different network structures.

### Suggestions for Improvement
We recommend that the authors improve the paper by submitting the code to enhance reproducibility. Additionally, the authors should review and compare their methods against recent algorithms like PACO, RIDE, and ACE in Section 4.3. We also suggest addressing the numerous typos and grammatical errors, and providing experimental results on various network architectures to strengthen the findings. Furthermore, clarifying the meaning of terms such as 'data-dependent' and providing more details on hyperparameter settings in the experiments would enhance the paper's clarity and rigor.