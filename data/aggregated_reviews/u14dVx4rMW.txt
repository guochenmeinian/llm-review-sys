ID: u14dVx4rMW
Title: ImageNetVC: Zero- and Few-Shot Visual Commonsense Evaluation on 1000 ImageNet Categories
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new dataset, ImageNetVC, comprising 4,076 high-quality QA pairs across 1,000 ImageNet categories, focusing on visual commonsense reasoning. The authors benchmark various PLMs and VaLMs on this dataset, providing insights into model performance and the factors influencing visual commonsense understanding. The dataset is claimed to be of higher quality due to manual human annotations, and the authors detail their data annotation process and experimental results.

### Strengths and Weaknesses
Strengths:
- The authors provide a well-structured dataset with thorough human annotation, enhancing its quality.
- Extensive benchmarking of popular PLMs and VaLMs reveals insightful observations regarding model performance.
- The paper is well-written and presents clear results, contributing valuable knowledge to the research community.

Weaknesses:
- The dataset size of 4,076 pairs is relatively small, and the knowledge it encompasses may not significantly differ from existing datasets like ViComTe.
- The focus on visual attributes such as color, material, and shape may not adequately capture the essence of visual commonsense reasoning.
- The rationale for category-level examination versus sample-level examination is unclear, and more qualitative examples are needed to illustrate the dataset's effectiveness.

### Suggestions for Improvement
We recommend that the authors improve the dataset's size and diversity by incorporating additional dimensions beyond color, material, shape, and component. Clarifying the necessity of category-level examination in relation to sample-level analysis would enhance the paper's coherence. Additionally, including more qualitative examples and addressing the differences between their dataset and ViComTe would strengthen their claims. Lastly, evaluating a broader range of VLM models, such as MiniGPT4 and LLAVA, could provide a more comprehensive understanding of model performance.