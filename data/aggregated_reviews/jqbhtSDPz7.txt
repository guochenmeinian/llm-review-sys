ID: jqbhtSDPz7
Title: The Art of SOCRATIC QUESTIONING: Recursive Thinking with Large Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an LLM inference pipeline called Socratic Questioning, which decomposes complex questions into simpler sub-questions to enhance answer accuracy. The authors introduce a method to integrate sub-question answers back into the reasoning process using "hints." Additionally, an explainable VQA pipeline is proposed, utilizing dynamic textual prompts tailored to specific sub-questions. Experiments demonstrate superior performance on MATH, LogiQA, MMLU, and multimodal VQA datasets compared to existing prompting methods.

### Strengths and Weaknesses
Strengths:  
- The proposed Socratic Questioning method aligns well with human reasoning styles and is intuitive.  
- The paper is well-written, providing clear insights into the recursive thinking process and its application to both language-only and multimodal tasks.  
- Experimental results indicate that the method outperforms prior approaches across diverse reasoning tasks.

Weaknesses:  
- The evaluation datasets lack comprehensiveness, with concerns about the arbitrary selection of MMLU domains and the challenging nature of the MATH dataset for chatgpt-based models.  
- The comparison with existing methods, particularly the chain of thought and self-consistency baselines, is insufficiently described.  
- The computational efficiency of the recursive prompting approach is not analyzed, and there is a need for ablation studies to assess the necessity of the QA2H module.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by including a broader range of datasets, such as StrategyQA and simpler math datasets like GSM8K, to better demonstrate the method's effectiveness. Additionally, we suggest conducting experiments to analyze the computational complexity of the proposed approach and to perform ablation studies on the QA2H module to validate its necessity. Furthermore, we encourage the authors to clarify the design of the CoT prompts and the confidence levels used in few-shot settings, as well as to provide more detailed explanations in the appendix regarding the generation of sub-questions.