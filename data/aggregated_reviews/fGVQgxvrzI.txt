ID: fGVQgxvrzI
Title: HEART: Heart Expert Assistant with ReTrieval-augmented
Conference: AAAI
Year: 2024
Number of Reviews: 4
Original Ratings: 4, 5, 9, 7
Original Confidences: 3, 4, 4, 4

Aggregated Review:
### Key Points
This paper presents a retrieval-augmented LLM approach for classifying heart defects using ECG examination records instead of direct ECG data. The authors apply a few-shot strategy with a llama2 variant pre-trained on a curated ECG notes dataset, initially observing low performance. They then fine-tune the model on their dataset of 1006 cases, achieving significant improvement. The authors incorporate a RAG strategy to enhance predictions by including context from similar cases, although they face limitations in token usage. A context fusion model based on cross-attention is proposed to further improve performance. However, the paper lacks clarity on data splitting, validation strategies, and the definition of "standard values."

### Strengths and Weaknesses
Strengths:
- The proposed retrieval augmentation effectively enhances foundation models for cardiovascular disease detection.
- The manuscript articulates the rationale and results clearly, contributing meaningfully to the field.

Weaknesses:
- The dataset lacks labels for healthy conditions and does not specify the sizes of training and testing sets.
- Technical aspects, such as the implementation of the re-ranker and the derivation of "<RAGHere>", are inadequately explained.
- The introduction of new variables, like "m" in the training process, occurs without prior explanation, complicating understanding.
- The use of the same \(W_K\) for both \(K=W_K A\) and \(V=W_K A\) raises questions without justification.

### Suggestions for Improvement
We recommend that the authors improve the abstract by providing concrete descriptions of their results. Additionally, all terms in the attention function should be defined, including the \(d_k\) scaling term. Clarification is needed regarding the removal of sentences containing "Figure" in the pre-training dataset, and the "cls" subscript in arrays should be explicitly defined. The dimensionality of the retrieved sets should be corrected to \(R^{1 \times h}\), and the learning rate should be expressed as \(10^{-4}\). Lastly, the authors should define lora_alph and lora_r in the context of LoRA with appropriate LaTeX markup.