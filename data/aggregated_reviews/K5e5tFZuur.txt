ID: K5e5tFZuur
Title: Invariant Learning via Probability of Sufficient and Necessary Causes
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 7, 7, 5, 8, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 1, 4, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to out-of-distribution (OOD) generalization by introducing the concept of 'essential causal information' and the probability of necessity and sufficiency (PNS) risk to estimate representations that satisfy this concept. The authors propose a new algorithm to minimize the PNS risk on the test domain, supported by theoretical analysis and empirical results across various datasets.

### Strengths and Weaknesses
Strengths:
1. The introduction of PNS risk for OOD generalization is both novel and interesting, with rigorous proof.
2. The method is generalizable and performs well across diverse datasets, demonstrating good experimental results.
3. The writing is clear and well-structured, aiding comprehension.

Weaknesses:
1. The example in section 2.3 does not hold, as indicated by the phrase "the fox also has long whiskers."
2. The definition of PNS in Definition 2.1 is difficult to grasp and requires further clarification.
3. There is a lack of consideration for recent methods (2021-2023) in domain adaptation, which may provide strong baselines for comparison.
4. The paper lacks a direct comparison with related works like IRM, which would clarify the differences and similarities with existing methods.
5. The empirical evaluation could benefit from more realistic datasets, such as SpuCo or those from the WILDS package.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Definition 2.1 by providing more details on the concepts of necessity and sufficiency. Additionally, addressing the example in section 2.3 to ensure its validity is crucial. We suggest incorporating a direct comparison with related works like IRM to contextualize the proposed method. Furthermore, we encourage the authors to evaluate their approach on more challenging datasets to strengthen their empirical claims. Lastly, clarifying the distribution of the $\bar{C}$ variable and discussing the limitations of the practical optimization algorithm would enhance the paper's robustness.