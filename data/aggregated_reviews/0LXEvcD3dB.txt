ID: 0LXEvcD3dB
Title: SpeechGPT: Empowering Large Language Models with Intrinsic Cross-Modal Conversational Abilities
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents SpeechGPT, a multimodal large language model with intrinsic cross-modal conversational abilities, capable of perceiving and generating multi-modal content. The authors construct SpeechInstruct, a large-scale cross-modal speech instruction dataset, and employ a three-stage training strategy that includes modality-adaptation pre-training, cross-modal instruction fine-tuning, and chain-of-modality instruction fine-tuning. The main contribution is demonstrating the model's potential based on this training strategy compared to two cascaded cross-modal conversational systems as baselines.

### Strengths and Weaknesses
Strengths:
- The introduction of the SpeechInstruct dataset, likely the first large-scale speech-text cross-modal instruction-following dataset, enhances reproducibility.
- The well-defined three-stage training process contributes to effective cross-modal transfer.
- Empirical evaluations indicate strong performance in textual tasks, speech-text cross-modal tasks, and spoken dialogue tasks.

Weaknesses:
- The proposed model may lack novelty, as it does not significantly differ from existing approaches.
- The role of each training stage is unclear, requiring more motivational detail in the methods section.
- The evaluation relies on TTS-generated audio, raising concerns about robustness and the model's performance with actual human speech.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the training stages by providing more motivational detail in the methods section. Additionally, unify the component names in the methods section and Figure 2 for consistency. To enhance robustness, we suggest investigating the model's performance with actual human speech inputs and discussing potential vulnerabilities or adversarial attacks. Finally, consider using automated metrics and human evaluations across a broader range of tasks to validate the model's performance comprehensively.