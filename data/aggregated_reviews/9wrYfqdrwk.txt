ID: 9wrYfqdrwk
Title: Diversify Your Vision Datasets with Automatic Diffusion-based Augmentation
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 7, 7, 7, 7, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ALIA (Automated Language-guided Image Augmentation), a generative data augmentation method that leverages large image captioning and language models to summarize domain descriptions and employs language-guided image editing techniques to create augmented training data. The authors demonstrate that ALIA outperforms recent data augmentation methods on fine-grained classification tasks across multiple datasets, including iWildCam, CUB, and FGVC-Aircraft.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and easy to follow.
- The novel approach of using prompts to extract domain information and class-agnostic descriptions is commendable.
- Empirical results from the iWildCam experiment show that models trained on ALIA-generated images outperform those using real samples.

Weaknesses:
- The technical contribution is limited, as many components of ALIA utilize off-the-shelf methods like BLIP, GPT-4, Img2Img, and Instruct Pix2Pix.
- ALIA's reliance on pre-trained models raises concerns about its effectiveness on unseen test domains, with no feedback mechanism for fine-tuning on target datasets.
- The method has only been tested on three datasets with similar classes, raising questions about its generalizability to more diverse datasets.

### Suggestions for Improvement
We recommend that the authors improve the discussion surrounding the choice of domain descriptions, particularly how the number of descriptions affects the quality of augmented samples. Additionally, we suggest including a quantitative analysis of the semantic and stylistic variations missing in the base dataset and whether ALIA effectively addresses these gaps. It would also be beneficial to explore the performance of ALIA on more diverse datasets, such as ImageNet, and clarify the protocols used for selecting subsets of datasets like iWildCam. Finally, we encourage the authors to analyze the impact of generated data volume on performance and consider including domain descriptors for test data to enhance robustness against domain shifts.