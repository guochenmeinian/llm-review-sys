ID: AFnSMlye5K
Title: Disentangling Interpretable Factors with Supervised Independent Subspace Principal Component Analysis
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 7, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an extension of PCA that decomposes datasets into multiple independent subspaces, leveraging the Hilbert-Schmidt Independence Criterion (HSIC) to reflect provided covariates of interest. The authors propose a method that maximizes dependence between subspaces and their corresponding covariates while minimizing dependence among the subspaces. The method is evaluated on synthetic data and real datasets, demonstrating its effectiveness in extracting interpretable subspaces.

### Strengths and Weaknesses
Strengths:  
- The manuscript is well-written and clear, making it easy to follow.  
- The proposed method is novel and extends previous work on supervised PCA, showing potential for data exploration tasks.  
- The theoretical connections and mathematical background are well-derived, and the results from genetic sequence analysis are meaningful.  

Weaknesses:  
- The impact of the parameter $\lambda$ on the embeddings is not explored, raising concerns about its significance.  
- The method lacks a guarantee for extracting latent subspaces under varying conditions, and the theoretical analysis is insufficient.  
- Comparisons are limited to PCA and supervised PCA, with no inclusion of more advanced state-of-the-art methods.  
- The explanation of simulated data results is unclear, and hyperparameter selection lacks justification.  

### Suggestions for Improvement
We recommend that the authors improve the exploration of the impact of $\lambda$ by conducting additional experiments to assess how different values affect the embeddings and results, particularly in the context of the GO results and UMAP visualizations. Additionally, we suggest including an example of an automated selection procedure for $\lambda$ to enhance usability. The authors should expand on the mathematical connections to self-supervised learning mentioned in the abstract and provide a clearer discussion of the limitations of their method, including specific scenarios where it may not perform well. Finally, we encourage the authors to include comparisons with more state-of-the-art methods to better showcase the advantages of their approach.