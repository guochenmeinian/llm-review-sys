ID: 1sq9eXwHRE
Title: Shared Recurrent Memory Improves Multi-agent Pathfinding
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 7, 7, 5, 7, -1
Original Confidences: 3, 2, 4, 4, -1

Aggregated Review:
### Key Points
This paper presents the Shared Recurrent Memory Transformer (SRMT), a novel architecture aimed at enhancing coordination in multi-agent systems within partially observable environments. The authors extend memory transformers by pooling and broadcasting individual working memories, demonstrating improved performance on a bottleneck navigation task compared to several baselines, particularly under challenging reward structures. The study is significant for addressing coordination challenges in robotics and artificial intelligence, with practical implications for real-world applications.

### Strengths and Weaknesses
Strengths:  
- Introduction of the SRMT as a novel approach for multi-agent coordination.  
- Rigorous evaluation metrics and clear presentation of results, including a well-structured document with supportive figures and tables.  
- Good motivation linking the approach to established cognitive science theories and robust evaluation across different reward structures.  

Weaknesses:  
- The limitations section lacks depth, and the justification for selected baselines appears insufficient, raising concerns about potential cherry-picking.  
- The performance comparison with other methods in multi-agent reinforcement learning (MARL) is limited, which may hinder the assessment of SRMT's true contribution.  
- The paper's reliance on a single task for experiments may not adequately demonstrate the architecture's utility.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Figure 3 to enhance understanding. Additionally, the authors should expand the limitations section to provide a comprehensive overview of the proposed approach's constraints. Including justifications for the choice of baselines and running experiments on at least one additional task would strengthen the paper and alleviate concerns regarding cherry-picking. Finally, we suggest that the authors clarify the statistical significance of performance differences between SRMT and RMT, particularly in sparse reward conditions.