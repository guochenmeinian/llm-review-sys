ID: GtEmIzLZmR
Title: Achievable Fairness on Your Data With Utility Guarantees
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 7, 6, 7, -1, -1
Original Confidences: 4, 4, 4, -1, -1

Aggregated Review:
### Key Points
This paper presents a method to estimate the accuracy-fairness trade-off curve efficiently, addressing a significant limitation in the fairness literature regarding uniform fairness requirements across diverse datasets. The authors propose the YOTO framework, which approximates the trade-off curve while reducing computational costs associated with traditional methods that require multiple model trainings. The paper also introduces a systematic approach to quantify confidence intervals for fairness and accuracy.

### Strengths and Weaknesses
Strengths:
- Originality: The paper tackles the issue of uniform fairness metrics and proposes a new framework for selecting fairness guidelines based on dataset characteristics, estimating the entire trade-off curve rather than a single point.
- Quality and Clarity: The writing is clear, the motivation is well-articulated, and the theoretical analysis is robust. The experiments span three practical applications, demonstrating rigor.
- Practical Utility: The YOTO framework provides a valuable tool for auditing model fairness and allows decision-makers to observe minimum fairness violations as model accuracy increases.

Weaknesses:
- Redundancy: Content in lines 121-126 is similar to lines 61-66 and should be summarized for conciseness.
- Introduction of YOTO: The YOTO framework should be introduced in the Preliminary section for clarity.
- Dataset Description: There is insufficient detail on dataset and experiment setup, including data size, sensitive attributes, held-out set size, and train-test split ratio.
- Data Dependency: The methodology relies on separate datasets for training and calibration, which may not be feasible with limited data.
- Statistical Assumptions: The statistical guarantees depend on assumptions that may not hold in all scenarios, potentially limiting generalizability.

### Suggestions for Improvement
We recommend that the authors improve the conciseness of the content in lines 121-126. Additionally, YOTO should be introduced in the Preliminary section to enhance clarity. The authors should provide more detailed descriptions of the dataset and experiment setup, including data size, sensitive attributes, held-out set size, and train-test split ratio. Furthermore, we suggest highlighting the values of the statistical guarantees and providing a more comprehensive evaluation or insights for model training. Lastly, the authors should clarify how they estimate confidence intervals in practice, particularly regarding sensitivity $\Delta(h_{\lambda})$, and address the differences between YOTO and similar literature.