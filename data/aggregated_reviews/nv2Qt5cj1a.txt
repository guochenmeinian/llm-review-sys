ID: nv2Qt5cj1a
Title: Membership Inference Attacks against Large Vision-Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 5, 6, 6, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 3, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to membership inference attacks (MIA) on large vision-language models (VLLMs), introducing a specific benchmark called Vision Language MIA (VL-MIA) for evaluating image and text detection. The authors propose a new pipeline for MIAs that does not require both side information, along with a detection metric called MaxRÃ©nyi-K%. The paper also discusses the implications of data security and privacy in the context of VLLMs.

### Strengths and Weaknesses
Strengths:
- The authors propose an intriguing research problem focused on the membership attack of large vision-language models.
- The introduction of a new benchmark for evaluating MIA on VLLMs and extensive evaluation results demonstrate the effectiveness of their approach.
- The overall writing is clear and easy to follow.

Weaknesses:
- The setting for detecting a description sentence is confusing, particularly the use of a black image and the omission of instructions, which raises questions about the feasibility of producing target descriptions.
- Further clarification is needed regarding dataset generation, particularly the potential bias between natural and synthetic data, and the choice of instruction text for members versus generated text for non-members.
- The evaluation dataset size is relatively small, which may limit the robustness of the results, and the paper lacks consideration of the True Positive Rate at low False Positive Rate (TPR at low FPR) metric.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the MIA setting, particularly regarding the use of a black image and the rationale behind skipping instructions. Additionally, please provide insights into the potential biases in dataset generation and the choice of text types for members and non-members. To enhance the robustness of the evaluation, consider expanding the dataset size and including standard metrics like TPR at low FPR. Finally, we suggest discussing the generalizability of the proposed methods to other VLLM architectures and datasets.