ID: 28bFUt6rUY
Title: EvolveDirector: Approaching Advanced Text-to-Image Generation with Large Vision-Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 5, 8, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents "EvolveDirector," a framework for training a text-to-image (T2I) generation model using only publicly available resources. The authors address the challenges of proprietary data by utilizing public APIs to gather text-image pairs for training. EvolveDirector employs pre-trained vision-language models (VLMs) to refine the training dataset, significantly reducing the required data volume from 10 million samples to just 100k for comparable performance. The final model, "Edgen," reportedly outperforms several advanced models and is intended for open-source release.

### Strengths and Weaknesses
Strengths:
- The innovative approach of leveraging public APIs and VLMs to access advanced T2I capabilities in an open-source context.
- Edgen demonstrates impressive performance, surpassing multiple advanced models, supported by extensive experiments and human evaluations.
- The methodology is technically sound, with clear explanations of the framework's components and training strategies, enhancing reproducibility.
- The paper thoughtfully discusses potential biases and societal impacts, indicating a responsible approach to AI development.

Weaknesses:
- The layout requires adjustment, as exemplified by Figure 1 occupying an entire page.
- Limited exploration of the insightful research questions posed, particularly regarding distillation and data annotation.
- The data construction pipeline could be enhanced by incorporating real images as ground truth.
- Confusion arises from the results in Section 4.3, where models trained without certain operations yield comparable results, questioning their necessity.

### Suggestions for Improvement
We recommend that the authors improve the layout to enhance readability, particularly by resizing Figure 1. Additionally, we suggest expanding the analysis related to the research questions to provide a more comprehensive exploration. Incorporating real images as ground truth in the data construction pipeline could strengthen the framework. Lastly, clarifying the necessity of the Discrimination, Expansion, and Mutation operations in Section 4.3 would help alleviate confusion regarding their roles in the training process.