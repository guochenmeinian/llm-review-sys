ID: yQL5tutdaH
Title: Toward a Stable, Fair, and Comprehensive Evaluation of Object Hallucination in Large Vision-Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 7, 5, 5, 7, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 5, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a systematic analysis of object hallucinations in large vision-language models (LVLMs), focusing on how instructions influence hallucinations through description lengths. The authors report a linear correlation between description lengths and hallucination levels, proposing a curve-based evaluation method named LeHaCE that incorporates the slope of this curve as a metric for a more comprehensive assessment. Extensive experiments validate the effectiveness of this approach.

### Strengths and Weaknesses
Strengths:
- The paper provides valuable insights by demonstrating that instructions affect hallucinations indirectly through description lengths, revealing an important mechanism in hallucination evaluation.
- The curve-based evaluation method is intuitively reasonable and supported by substantial experimental evidence, enhancing the persuasiveness of the findings.

Weaknesses:
- The method's effectiveness may be compromised due to varying length distributions of descriptions generated by different LVLMs, raising concerns about its consistency.
- The authors lack a large instruction set to simulate real-world applications, which would significantly enhance the evaluation's relevance.
- The claim of fairness in the proposed evaluation method is not sufficiently supported by experimental results.
- There is inadequate analysis regarding the stability of the “LeHaCE_GR” and the impact of instruction selection on the fitted curve.

### Suggestions for Improvement
We recommend that the authors improve the robustness of their evaluation method by exploring additional decoding strategies beyond beam search to validate the observed correlations. Additionally, the authors should discuss the limitations of using a fitted curve with only one instruction and consider providing a larger instruction set for more comprehensive evaluations. Further analysis on the stability of the “LeHaCE_GR” and the influence of instruction selection on the fitted curve would enhance the paper's depth. Lastly, we suggest correcting minor typographical errors and clarifying the implications of the curve's intercept within the evaluation framework.