ID: R6qMmdl4qP
Title: Dynamo-Depth: Fixing Unsupervised Depth Estimation for Dynamical Scenes
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 7, 3, 7, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a self-supervised method for monocular depth estimation in dynamic scenes, focusing on the decomposition of flow into ego-motion and independent motion. The authors propose a new architecture that separates rigid scene flow from residual scene flow and introduces a motion initialization method to enhance learning stability. Evaluations on the KITTI, Waymo, and nuScenes datasets demonstrate state-of-the-art performance, particularly in handling moving objects. The authors also evaluate depth performance through quantitative metrics and provide precision-recall curves for motion segmentation on the Waymo Open dataset, achieving over 70% precision at 70% recall. They argue that stereo information enhances depth perception, simplifying motion disentanglement, and clarify that the use of ImageNet weights is for consistent comparison rather than as frozen auxiliary pretrained networks. The authors assert that their method is the first to jointly learn motion segmentation with monocular depth, ego-motion, and independent motion from unlabeled videos.

### Strengths and Weaknesses
Strengths:  
- The proposed method achieves superior performance on the Waymo and nuScenes datasets, addressing the limitations of the KITTI dataset.  
- The paper is well-written, with clear motivations and informative discussions, particularly in Section 3.  
- An ablation study effectively illustrates the significance of the proposed motion initialization technique.  
- The joint learning of motion segmentation and monocular depth is a novel contribution in the context of unsupervised learning.  
- The precision-recall results indicate strong performance in motion segmentation.

Weaknesses:  
- The manuscript lacks sufficient technical and performance comparisons with recent self-supervised methods in depth estimation, scene flow estimation, motion segmentation, and optical flow, limiting the demonstration of the proposed method's originality and superiority.  
- The focus on motion segmentation initialization appears overly simplistic, and the paper does not adequately address the potential limitations of the proposed approach in varying contexts, such as moving cameras.  
- The rationale for not using pretrained networks could be more thoroughly justified.  
- The claim regarding the difficulty of obtaining synthetic data compared to unlabeled data may require further elaboration.  
- The discussion on multi-stage training lacks clarity regarding its limitations in disentangling motion.

### Suggestions for Improvement
We recommend that the authors improve the manuscript by including comprehensive technical and performance comparisons with recent self-supervised methods in depth estimation, scene flow estimation, motion segmentation, and optical flow on the KITTI, nuScenes, and Waymo datasets. Additionally, we suggest that the authors clarify the assumptions regarding the ground plane estimation and consider including visual odometry results, potentially following benchmarks like KITTI or TUM RGBD-SLAM, to strengthen the paper's contributions. We also recommend that the authors improve the justification for not using pretrained networks by providing more detailed comparisons and potential impacts on learning. Furthermore, we suggest that the authors clarify their stance on synthetic data acquisition challenges to strengthen their argument. Finally, we encourage the authors to elaborate on the limitations of multi-stage training in the context of motion disentanglement to enhance the reader's understanding.