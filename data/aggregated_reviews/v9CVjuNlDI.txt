ID: v9CVjuNlDI
Title: Breaking Boundaries in Retrieval Systems: Unsupervised Domain Adaptation with Denoise-Finetuning
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach for unsupervised domain adaptation in dense retrieval tasks, proposing a rerank method that integrates target domain data into rerank and retrieval modeling. The authors introduce a denoise algorithm to enhance dense retrieval performance and utilize knowledge distillation from the rerank model to improve the dense retrieval model. The method demonstrates significant improvements across various datasets (FiQA, SciFact, and TREC-COVID), indicating its effectiveness.

### Strengths and Weaknesses
Strengths:
- The paper provides a comprehensive evaluation of the proposed method on multiple datasets, showcasing superior performance compared to existing baselines.
- The denoise fine-tuning technique is a novel contribution that mitigates the impact of noisy labels.
- The method is well-structured and easy to understand, with effective ablation studies supporting its claims.

Weaknesses:
- The compared baselines are outdated, primarily from before 2022, which may undermine the competitiveness of the results.
- The complexity of the proposed method, involving multiple steps and varying hyperparameters, raises concerns about reproducibility and computational costs.
- The relationship between co-regularization and denoising is unclear, and the experimental section lacks discussions on key parameter choices and model selection for knowledge distillation.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the relationship between co-regularization and denoising. Additionally, providing more detailed discussions on the selection of parameters such as alpha and P, as well as the choice of rerank models for knowledge distillation, would enhance the paper. We suggest that the authors introduce additional evaluation metrics beyond NDCG@10 to provide a more comprehensive assessment of model performance. Exploring other cutting-edge transformer models for query generation could also strengthen the methodology. Finally, we encourage the authors to address the handling of high label noise (>10%) with explicit techniques, such as a noise-robust loss function, to improve robustness in extremely noisy scenarios.