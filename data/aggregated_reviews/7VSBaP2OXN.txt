ID: 7VSBaP2OXN
Title: Waymax: An Accelerated, Data-Driven Simulator for Large-Scale Autonomous Driving Research
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 7, 8, 6, -1, -1, -1, -1, -1
Original Confidences: 2, 5, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DriveMax, a multi-agent simulator designed for research on autonomous driving, offering utilities such as a suite of metrics, a built-in behavior model, and integration with real-world datasets. The authors provide extensive benchmarks and demonstrate the simulator's capabilities through various configurations, highlighting its efficiency in handling both single-agent and multi-agent environments.

### Strengths and Weaknesses
Strengths:  
The authors articulate the need for DriveMax effectively, showcasing its differentiable design using JAX, which opens new research opportunities. The simulator's ability to facilitate large-scale data traversal and its comprehensive benchmarks contribute significantly to autonomous driving research. The clarity of writing and the rigorous benchmarking studies enhance the paper's quality.

Weaknesses:  
There is an opportunity to better situate DriveMax in relation to other simulators, particularly in the binary comparison presented in Table 1, which may not fully capture the nuances of other simulators. Additionally, the kinematic infeasibility metric lacks clarity regarding the empirical determination of its parameters. The absence of sensor simulation is noted as a limitation, and the documentation does not sufficiently address organization, maintenance, or ethical use.

### Suggestions for Improvement
We recommend that the authors improve the contextualization of DriveMax by expanding the comparison with other simulators beyond binary values in Table 1. Clarifying the empirical procedure for determining the kinematic infeasibility parameters would enhance understanding. We suggest including an experiment to demonstrate how differentiable simulation can benefit policy learning, potentially by training a policy gradient baseline optimized via the reward function. Additionally, addressing the limitations of sim2real transfer in self-driving applications is crucial, emphasizing that policies trained in the simulator should not be deployed in real vehicles. Lastly, we encourage the authors to enhance the documentation regarding organization, maintenance, and ethical use to support reproducibility.