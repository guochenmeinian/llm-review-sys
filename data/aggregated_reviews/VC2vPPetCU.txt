ID: VC2vPPetCU
Title: Open-ended Commonsense Reasoning with Unrestricted Answer Candidates
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on open-ended commonsense QA, proposing the KEEP framework that utilizes an external knowledge graph (ConceptNet) to construct a local reasoning graph for answering questions without predefined answer options. The authors demonstrate the effectiveness of their approach through experiments on two datasets, comparing it against various zero-shot baselines.

### Strengths and Weaknesses
Strengths:  
- The idea of leveraging an external knowledge graph for open-ended commonsense QA is well-motivated and effective.  
- Experiments are carefully executed, including both human and automatic evaluations, with qualitative results aiding in understanding the proposed approach's strengths and weaknesses.  
- The paper is clearly written and easy to understand.  

Weaknesses:  
- The paper lacks stronger baselines, only comparing against zero-shot MLM and GLM models, which may not provide a comprehensive understanding of the challenges in this setting.  
- The problem definition is unclear, as the method appears to impose a predefined answer scope despite claiming otherwise.  
- The empirical results are relatively poor compared to existing models, raising questions about the relevance of the approach.  
- Evaluation methods lack detail, particularly regarding human annotators and guidelines, and the reasoning chains provided are often invalid.  

### Suggestions for Improvement
We recommend that the authors improve the paper by including stronger baselines to provide a clearer context for their results. Additionally, clarifying the problem definition to resolve contradictions regarding answer scope is essential. The authors should also consider enhancing the evaluation methodology by detailing the human evaluation process and ensuring the reasoning chains are valid and relevant. Finally, exploring the potential of instruction-finetuned LLMs with dedicated prompts could yield better performance.