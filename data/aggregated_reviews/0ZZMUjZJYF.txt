ID: 0ZZMUjZJYF
Title: Can LLMs Learn by Teaching for Better Reasoning? A Preliminary Study
Conference: NeurIPS
Year: 2024
Number of Reviews: 18
Original Ratings: 5, 7, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates whether Learning by Teaching (LbT) principles can be applied to Large Language Models (LLMs) for reasoning tasks. The authors propose three methods corresponding to different levels of human LbT: M1 focuses on improving answer quality through a scoring function based on Teaching Rationale (TR) and Teaching Answer (TA) pairs; M2 enhances LLM capabilities by leveraging student feedback; and M3 iteratively improves exemplars based on student mistakes. The authors conclude that strong teacher models can enhance performance even when teaching weaker students, and that teaching multiple students is more effective than teaching a single student. They clarify that their conclusions are not intended to generalize beyond their specific context and emphasize the importance of accurately representing their findings without exaggeration.

### Strengths and Weaknesses
Strengths:  
- The paper is well-written, methodologically sound, and presents several novel results that could significantly interest the research community.  
- The experimental analysis is robust and well-supported by evidence, demonstrating the effectiveness of LbT in improving model performance and capabilities.  
- The clear structure and informative diagrams enhance the reader's understanding.  
- The authors demonstrate a willingness to revise statements that may have tone issues, showing responsiveness to reviewer feedback.  
- They provide empirical results and a clear scope of their research, which is beneficial for understanding their contributions.

Weaknesses:  
- The concept of LbT is not novel and lacks sufficient assumptions and counterexample analysis, making it overly intuitive.  
- The authors do not adequately survey existing literature on machine teaching, leading to exaggerated claims regarding their contributions.  
- Some statements in the paper have been criticized for being overly assertive or inaccurate, leading to concerns about the tone and clarity of the authors' claims.  
- The relationship between the proposed methods (M1-M3) is unclear, and M3 is insufficiently developed to be considered a core contribution.  
- The reliance on verifiable answers limits the applicability of the LbT score, and more extensive evaluation across diverse tasks is needed.  
- The novelty of the contributions related to teaching feedback and optimization has been questioned, as these concepts are well-established in the literature.

### Suggestions for Improvement
We recommend that the authors improve their literature review to include relevant works from the machine teaching community, such as those by Cao et al. and Liu et al., to strengthen their claims. Additionally, the authors should clarify how M1-M3 collectively contribute to the paper's objectives and enhance the discussion on the limitations of teaching weak students. We suggest including a detailed error analysis to identify which types of student errors provide the most beneficial feedback to the teacher model. Furthermore, we recommend that the authors improve the tone of their statements, particularly in the abstract, by revising "Diversity in students is important" to "Diversity in students might help" and "LbT can induce weak-to-strong generalization" to "LbT might help with weak-to-strong generalization." We also suggest that the authors clarify the definition of "teaching performance" in relation to their findings and ensure that their claims are contextualized within the existing literature on machine teaching. Lastly, we encourage the authors to enhance the academic rigor of their ideas by addressing more stringent assumptions and discussing the unique contributions of their work in relation to established concepts in the field.