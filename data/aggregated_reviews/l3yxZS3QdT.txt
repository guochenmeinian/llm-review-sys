ID: l3yxZS3QdT
Title: BIRD: Generalizable Backdoor Detection and Removal for Deep Reinforcement Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 5, 5, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents BIRD (Backdoor Identification and Removal for DRL), a method for detecting and removing triggers in reinforcement learning models. The authors formulate trigger restoration as an optimization problem and introduce a novel metric for detecting backdoored policies. BIRD operates without knowledge of attack specifications or access to the training process, demonstrating effectiveness and computational efficiency across various benchmarks.

### Strengths and Weaknesses
Strengths:
- BIRD is the first approach to detect and remove backdoors from pre-trained DRL policies without prior knowledge, showcasing strong practical value.
- The paper is well-organized and clearly conveys the authors' motivation and technical details, supported by rigorous experiments and ablation studies.
- The method's innovative use of total received reward for detection distinguishes it from previous works, contributing valuable insights to adversarial RL defense.

Weaknesses:
- The reliance on access to the value function is a significant limitation, as it may not be available in practical scenarios, making the problem easier to solve than intended.
- Some statements in the paper are inaccurate or misleading, particularly regarding the injection of backdoors.
- The method's hyperparameter sensitivity raises concerns about generalizability, as it appears tailored to specific scenarios rather than a broad application.

### Suggestions for Improvement
We recommend that the authors improve the discussion surrounding the assumption of value function availability, providing practical scenarios where this holds true. Additionally, clarifying the inaccuracies in statements about backdoor injection methods would enhance the paper's precision. We suggest including more comprehensive performance metrics, such as ROC, and creating specified baselines tailored to the RL setup to strengthen the experimental results. Finally, addressing the trade-offs between detection and maintaining model performance would provide deeper insights into the method's applicability.