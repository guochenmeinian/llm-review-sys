ID: Tsb4dVtCHx
Title: High-dimensional (Group) Adversarial Training in Linear Regression
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 4, 8, 5, 4, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a non-asymptotic consistency analysis of prediction error for adversarial training under $l_\infty$ perturbation, demonstrating a convergence rate of prediction error up to a logarithmic factor. The authors prove that the group adversarial training procedure achieves a superior upper bound on prediction error compared to classic adversarial training. The paper also provides a high-dimensional analysis of linear regression in adversarial training, claiming an improved convergence rate of $1/n$ over the previous $1/\sqrt{n}$.

### Strengths and Weaknesses
Strengths:  
1. The paper applies the restricted eigenvalue condition and sparsity to deliver a convergence analysis, resulting in a better convergence rate.  
2. The authors investigate the convergence rate of group adversarial training, achieving a faster upper bound for convergence.  
3. The paper is well-written, clear, and the mathematical results appear consistent and correct.  

Weaknesses:  
1. The linear model used is too simplistic to accurately represent adversarial training, which is typically applied to deep neural networks; the authors should consider studying adversarial training on a two-layer neural network or a convex function.  
2. The convergence rate for the linear model is insufficient to effectively illustrate adversarial training behavior.  
3. The numerical experiments lack diversity in configurations, and the presentation of results could be improved, such as adding confidence intervals in Figure 1 and using a log base 10 in Figure 2.  
4. Certain claims, such as the improvement of convergence rates, require clearer justification and context in the abstract and introduction.  

### Suggestions for Improvement
We recommend that the authors improve their analysis by extending it to random feature models or other neural network architectures, such as two-layer NTK or diagonal networks. Additionally, the authors should clarify the assumptions regarding the weight vector in group adversarial training and provide more technical details in the abstract about their contributions. We also suggest enhancing the numerical experiments by testing more configurations and improving the presentation of results for better clarity.