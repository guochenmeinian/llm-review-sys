ID: 67tRrjgzsh
Title: How does Architecture Influence the Base Capabilities of Pre-trained Language Models? A Case Study Based on FFN-Wider and MoE Transformers
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 6, 6, 4, 7, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into how transformer architecture influences base capabilities, particularly focusing on the contribution ratio of Multi-Head Attention (MHA) and Feed-Forward Networks (FFN). The authors find that a wider FFN reduces the contribution ratio of MHA, negatively impacting performance on out-of-distribution (OOD) tasks. To counter this, they propose a Combination Enhanced Architecture (CEA) that optimally reallocates components of the FFN and extends this architecture to Mixture of Experts (MoE) transformers, demonstrating significant improvements in base capabilities.

### Strengths and Weaknesses
Strengths:
- The paper shifts focus from scale to architecture, providing valuable insights into transformer model optimization.
- The analysis of the contribution of FFN and MHA using mutual information and token prediction accuracy is novel and insightful.
- The application of CEA to MoE models shows practical benefits and enhances understanding of architecture impacts on performance.

Weaknesses:
- The description of CEA lacks sufficient detail, particularly regarding its structure and the rationale behind parameter choices.
- Performance improvements appear minor, and the absence of standard deviations raises concerns about result robustness.
- Some findings seem intuitive, and the analysis scope is narrower than suggested by the title, limiting the exploration of non-obvious influences.

### Suggestions for Improvement
We recommend that the authors improve the clarity and detail of the CEA description, particularly in Section 6, to enhance understanding of its structure. Additionally, it would be beneficial to include standard deviations for performance metrics to better assess robustness. The authors should also consider exploring a broader range of architectural influences and provide clearer explanations for parameter choices, such as the intermediate dimension selection. Lastly, addressing the grammar and presentation issues will strengthen the overall quality of the paper.