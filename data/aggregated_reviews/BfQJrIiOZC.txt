ID: BfQJrIiOZC
Title: Zero-shot causal learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 7, 7, 7, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a causal meta-learning framework, CaML, which estimates Conditional Average Treatment Effects (CATE) for novel interventions not seen during training. The authors frame CATE estimation for each intervention as a distinct meta-learning task. The framework is evaluated on large-scale datasets, including medical claims and cell-line perturbations, demonstrating its effectiveness. The paper also provides a theoretical analysis of CaML's zero-shot generalization bound, contributing to the field of causal inference by enabling zero-shot capabilities for CATE estimation methods previously limited to single interventions.

### Strengths and Weaknesses
Strengths:
- The proposed CaML framework offers a novel approach to estimating treatment effects for unseen interventions, framing each as a separate task.
- The evaluation on real-world datasets supports the effectiveness of the framework.
- Theoretical results are provided to bound prediction error.
- The paper includes code for reproducibility.

Weaknesses:
- The simplicity of the idea may hinder comprehension, particularly regarding the results.
- The rationale for calculating treatment effect estimates as labels rather than directly learning the model is unclear.
- The selected CATE learner (RA-Learner) may introduce bias.
- Terminology such as "potential outcomes" and "pseudo-outcome" may confuse readers.
- Some sections lack clarity, particularly regarding validation tasks and the implications of using a narrow range for certain parameters.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by revising ambiguous terminology, particularly the distinction between "potential outcomes" and "pseudo-outcome" modeling. Additionally, we suggest addressing the rationale behind the treatment effect estimates and the potential bias introduced by the RA-Learner. It would be beneficial to clarify the meaning of validation tasks and the implications of the chosen parameter ranges. Furthermore, we encourage the authors to provide a comprehensive explanation of the variations of CaML and their respective baselines in one section for better understanding. Lastly, a more detailed discussion of the potential risks and limitations of the proposed approach, particularly regarding data bias, should be included.