ID: X2R4yhtenj
Title: Effects of Human Adversarial and Affable Samples on BERT Generalization
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into the effects of two types of training samples—human adversarial (h-adversarial) and human affable (h-affable)—on the generalizability of the BERT model. The authors conduct experiments across text classification, relation extraction, and keyword detection to analyze the impact of these samples on model performance.

### Strengths and Weaknesses
Strengths:  
- The empirical study is comprehensive, focusing on two NLP tasks and utilizing representative BERT models.  
- The paper provides beneficial insights into data annotation and curation for real-world applications of BERT.  
- The authors clearly articulate their contributions and limitations.

Weaknesses:  
- The motivation behind the design of h-adversarials and h-affables is unclear, leaving readers uncertain about their significance in training.  
- The technical novelty of the proposed methods is limited, and the discussion lacks a comparison with existing data augmentation strategies.  
- The description of generating h-adversarials and h-affables is vague, and the implications of adding 10-30% extra h-adversarial samples in terms of training costs are not addressed.  
- The analysis could benefit from a more thorough evaluation of the h-adversarial and h-affable ratios using auto evaluation metrics.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation behind h-adversarials and h-affables, explicitly discussing their significance in training. Additionally, the authors should provide a clearer description of the generation process for these samples. A comparison with other data augmentation methods should be included in the experiments to enhance the paper's contributions. Furthermore, the authors should address the potential training costs associated with incorporating extra h-adversarial samples. Lastly, we suggest that the authors analyze the h-adversarial and h-affable ratios in the generalization datasets through auto evaluation metrics to strengthen their findings.