ID: akJUrevmwI
Title: Do Language Models Have a Common Sense regarding Time? Revisiting Temporal Commonsense Reasoning in the Era of Large Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an evaluation of several language models on six temporal reasoning benchmarks, employing five temporal reasoning categories for analysis. The authors propose conclusions regarding the models' abilities in temporal reasoning based on their experiments. The study serves as a comprehensive survey of eight LLMs, utilizing three prompting techniques across six datasets, and investigates model performance in various temporal reasoning tasks.

### Strengths and Weaknesses
Strengths:
- The paper offers a systematic and in-depth analysis of LLMs' temporal reasoning capabilities, providing a robust evaluation across multiple datasets.
- It identifies specific strengths and weaknesses of different models, contributing valuable insights for future research in enhancing LLMs' reasoning capacities.
- The findings are presented clearly, making them accessible to a broad audience within the NLP community.

Weaknesses:
- The evaluation scope is limited, lacking models with 10-60B parameters, including the latest GPT-4, which could provide a better understanding of LMs' temporal reasoning abilities.
- The paper does not contextualize the performance of LLMs against the best-performing fine-tuned models on each dataset, making it difficult to assess their reasoning capabilities accurately.
- Experiment details, such as the impact of temperature and the number of few-shot examples, are insufficiently specified, and the conclusions drawn from the experiments lack thoroughness.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by including more models with 10-60B parameters, specifically the latest GPT-4, to enhance understanding of temporal reasoning capabilities. Additionally, the authors should incorporate more temporal relation datasets, such as TRACIE, to provide a broader context for their findings. It is also essential to include detailed experimental parameters, such as the impact of temperature and the number of runs, to enhance reproducibility. Finally, we encourage the authors to provide a more thorough analysis of the conclusions drawn from their experiments to yield useful insights for future work.