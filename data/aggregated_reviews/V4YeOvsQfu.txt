ID: V4YeOvsQfu
Title: Temporal Conditioning Spiking Latent Variable Models of the Neural Response to Natural Visual Scenes
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 6, 7, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new model called temporal conditioning spiking latent variable models (TeCoSLVM) that utilizes spiking neurons to simulate neural responses to visual stimuli. The authors claim that this model preserves information in spike trains and adapts to temporal dependencies. Experiments with retinal data show that TeCoSLVM generates more realistic spike activities, accurately fits spike statistics, and generalizes well to longer time scales. The authors also compare their model to existing methods, highlighting its advantages in capturing spike autocorrelation and reproducing real firing rates.

### Strengths and Weaknesses
Strengths:
- The model effectively predicts spiking activity, addressing an open problem in the field.
- It incorporates an information bottleneck objective, contributing original insights to dynamic spiking models.
- The empirical results suggest improved performance in modeling single trial spike trains and scaling to long time series.

Weaknesses:
- The paper lacks clarity on the decoder's formulation and the integration of latent states into LIF neurons.
- There are questions regarding the training methodology and loss functions used for comparisons with CNNs.
- The model's ability to generalize to longer time scales is not convincingly demonstrated, raising concerns about its memory capabilities.
- The discussion of limitations is brief and could be more comprehensive.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the decoder's formulation, specifically how $\psi_{dec}$ is computed and how latent states are integrated into LIF neurons. Additionally, please clarify whether the model has access to real spike trains from previous time steps, as this is crucial for fair comparisons with CNNs. It would be beneficial to specify the loss function used for training the CNN and consider training the spiking model with Poisson loss for a more equitable evaluation. Furthermore, we suggest expanding the limitations section to provide a more thorough discussion. Lastly, addressing the conceptual questions regarding the model's architecture and its implications for sensory processing would enhance the manuscript's depth.