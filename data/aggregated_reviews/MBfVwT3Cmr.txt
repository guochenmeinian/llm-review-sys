ID: MBfVwT3Cmr
Title: Improving Analog Neural Network Robustness: A Noise-Agnostic Approach with Explainable Regularizations
Conference: NeurIPS
Year: 2024
Number of Reviews: 2
Original Ratings: 7, 4
Original Confidences: 3, 3

Aggregated Review:
### Key Points
This paper presents an exploration of regularizations aimed at mitigating the effects of Gaussian activation noise on neural network outputs. The authors provide formulations for both correlated and uncorrelated noise, emphasizing the significance of noise robustness for neural networks operating in volatile environments. The goal is to eliminate the need for explicit noise training by introducing regularization terms, while also attempting to elucidate the impact of noise on weight training. The findings indicate that for correlated noise, a straightforward method effectively removes noise influence, whereas networks subjected to uncorrelated noise still suffer notable accuracy declines (4.77% for MNIST, 7.2% for Fashion-MNIST). The paper suggests that the mechanisms employed to handle uncorrelated noise may explain the reduced accuracy. The experimental section is noted to be limited, and the theory could be expanded to include transformers.

### Strengths and Weaknesses
Strengths:  
- The paper addresses a relevant issue in neural network training regarding noise robustness.  
- It provides effective methods for managing correlated noise and demonstrates empirical results.  
- The proposed regularization functions show improved accuracy over standard training methods.

Weaknesses:  
- The explanatory perspective on weight changes under noise lacks detailed empirical backing and direct comparisons.  
- The experimental scope is limited to simpler datasets (MNIST and Fashion-MNIST).  
- The concept of "noise-aware" training is not clearly defined, and its superiority over the proposed method requires further clarification.

### Suggestions for Improvement
We recommend that the authors improve the empirical backing for their claims regarding weight changes under noise by providing detailed comparisons between noise-trained and regularization-trained networks. Additionally, we suggest expanding the experimental evaluation to include more complex networks and datasets beyond MNIST and Fashion-MNIST. It is also advisable to clarify the definition of "noise-aware" training and provide details about the test bench used for comparison. Furthermore, we encourage the authors to double-check equation (7) for clarity and discuss the potential similarities between their method for uncorrelated noise and Sharpness-Aware-Minimization (SAM), particularly regarding the goal of keeping activations in a low derivative region.