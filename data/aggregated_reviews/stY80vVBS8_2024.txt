ID: stY80vVBS8
Title: Learning-Augmented Dynamic Submodular Maximization
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 7, 6, 8, 4, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an algorithm for monotone submodular maximization under a cardinality constraint in a dynamic setting, utilizing predictions for insertions and deletions. The authors define the prediction error $\eta$ as the number of elements whose actual insertion or deletion times differ from the predicted times by more than a specified window size $w$. Their main result is an algorithm achieving a $(1/2 - \epsilon)$ approximation ratio with expected amortized update time $O(\text{poly}(\log \eta, \log w, \log k))$ and preprocessing time $\tilde{O}(n)$. The algorithm shows significant improvements in query complexity when predictions are accurate, but its performance degrades to that of existing algorithms when predictions are poor.

### Strengths and Weaknesses
Strengths:
- The problem addressed is significant and relevant to the NeurIPS community.
- The algorithm demonstrates a robust performance under low prediction error and effectively reduces query complexity.
- The presentation is clear, with good notation and a helpful warm-up algorithm.

Weaknesses:
- The requirement for all predictions to be available in advance is restrictive.
- The algorithm's performance can be worse than existing methods when $k = o(\log n)$ and $\eta = \Omega(n)$.
- The paper lacks details on how predictions are generated in practice, raising concerns about the robustness of the prediction model.
- The tightness of the results is unclear, particularly regarding the performance under perfect predictions.
- The potential trade-off between prediction accuracy and worst-case performance is not adequately addressed.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the practical generation of predictions, including potential machine learning algorithms that could be employed. Additionally, clarifying the tightness of their results, especially under perfect predictions, would strengthen the paper. We suggest exploring whether predictions can enhance the approximation ratio while maintaining the same update time as algorithms without predictions. Furthermore, addressing the implications of inaccurate predictions on update time would provide valuable insights. Lastly, we encourage the authors to clarify the assumptions regarding the length of the time horizon in the dynamic setting, particularly in relation to the use of offline algorithms.