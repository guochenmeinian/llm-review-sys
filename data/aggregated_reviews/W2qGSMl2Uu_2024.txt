ID: W2qGSMl2Uu
Title: ContextGS : Compact 3D Gaussian Splatting with Anchor Level Context Model
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 5, 7, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Context-GS, a method aimed at reducing the memory overhead of 3D Gaussian Splatting (3DGS) by introducing a multi-level anchor structure and context modeling inspired by image compression. The authors propose hierarchical anchors for improved compression performance, achieving a size reduction of 15 times compared to Scaffold-GS and 100 times compared to 3DGS, while maintaining high rendering quality. They claim significant performance improvements, achieving a 0.93dB enhancement with approximately a 3x size reduction compared to prior work. The authors emphasize that their method is not limited to anchor-based Gaussians and demonstrate a substantial improvement of around 25% over a strong entropy baseline. They argue that their work is distinct from concurrent papers, particularly HAC, due to differences in hyper-prior design and motivation, and highlight that their novelty has been recognized by other reviewers. Experimental results indicate a significant compression ratio with comparable fidelity to existing methods.

### Strengths and Weaknesses
Strengths:
- The method is novel, integrating context modeling from image compression into the 3DGS framework.
- The performance improvement is significant, with strong results in compression and rendering quality, supported by comprehensive ablation studies.
- The authors provide significant performance improvements and a notable size reduction in their method.
- The novelty of the approach is acknowledged by multiple reviewers, indicating its potential impact in the field.
- The authors address concerns regarding training time and encoding efficiency, demonstrating competitive performance with reduced training iterations.
- The overall presentation is clear and easy to follow.

Weaknesses:
- The main components of the proposed method have a limited impact on performance, with the primary compression benefit derived from existing techniques rather than the novel contributions.
- The complexity of the method and its customization to Scaffold-GS may hinder its extendability to other graphics engines.
- The encoding and decoding times are substantial, presenting a bottleneck for practical applications.
- The paper does not sufficiently address the encoding time in detail, which could lead to misunderstandings about its efficiency.
- There is a lack of references to other works that achieve state-of-the-art performance without coding techniques, which may weaken their claims.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the teaser figure to effectively convey the main idea, possibly by providing a reference scene for better understanding. Additionally, we suggest that the authors clarify the division of anchors into different levels and address the confusion surrounding the mathematical notations, particularly regarding the quantization process. It would also be beneficial to evaluate the performance without the learnable hyperprior feature to understand its impact. We further recommend that the authors improve the clarity of their encoding time reporting by providing detailed comparisons with other methods. Including references to papers that achieve state-of-the-art performance without coding techniques would strengthen their position. Lastly, further exploration of reducing training iterations could enhance the overall efficiency of their method, and a more detailed discussion of the limitations and computational costs associated with their method, particularly in comparison to previous approaches, would be beneficial.