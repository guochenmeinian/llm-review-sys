ID: 0TydpJriuR
Title: Towards Safe Machine Unlearning: a Paradigm that Mitigates Performance Degradation
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to machine unlearning, specifically the Targeted Label Noise Injection method, which aims to unlearn specific training data without accessing the remaining dataset while maintaining model performance. The authors claim that their method achieves minimal performance loss and parameter changes, supported by theoretical and empirical evidence across various datasets. However, the novelty and clarity of the proposed method could be better articulated, particularly in distinguishing it from existing techniques.

### Strengths and Weaknesses
Strengths:
- The proposed method effectively mitigates performance degradation during unlearning without requiring access to remaining training data.
- The paper includes theoretical guarantees that align well with empirical results, demonstrating state-of-the-art performance across multiple datasets.
- Extensive experiments validate the method's effectiveness on diverse architectures.

Weaknesses:
- The motivation and novelty of the approach are not clearly articulated, as it resembles existing techniques like adversarial perturbation.
- Methodological aspects, such as the reliability of confidence estimates for pseudo-labels and the impact of hyperparameters, lack sufficient clarity and justification.
- The experimental evaluation is limited in scope and does not adequately reflect real-world unlearning scenarios, with uneven comparisons against baselines.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation for the proposed method, explicitly highlighting its unique contributions compared to existing techniques. Additionally, a more detailed analysis of the reliability of confidence estimates and the impact of the hyperparameter \( \delta \) on performance across various scenarios is necessary. Expanding the experimental evaluation to include a broader range of datasets and ensuring fair comparisons with baselines would enhance the robustness of the findings. Furthermore, simplifying the presentation of theoretical results and improving the clarity of figures and tables would aid reader comprehension. Finally, addressing minor typographical and grammatical inconsistencies would improve the overall polish of the paper.