ID: WRYhaSrThy
Title: Automatic Prompt Optimization with "Gradient Descent" and Beam Search
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework, Prompt Optimization with Textual Gradients (ProTeGi), for automatic LLM prompt optimization. It iteratively applies LLM with a predefined meta-prompt over randomly sampled minibatches to generate feedback as gradients, subsequently using another meta-prompt to produce improved prompts. Bandit Selection algorithms are employed to prune candidate prompts. Empirical studies indicate that the proposed method outperforms baselines like Monte Carlo search, reinforcement learning, and AutoGPT. The paper also explores the impact of beam search and bandit algorithms on performance.

### Strengths and Weaknesses
Strengths:
- The task has significant implications in both academic and industry contexts.
- The framework is broadly applicable to various LLM-based methods, with analyses revealing interesting properties that may inspire further research.
- The paper is well-organized and easy to read, with a novel interpretation of "textual gradients" that enhances understanding.

Weaknesses:
- Important details, such as the specific feedback and editing prompts, are not clearly disclosed, limiting the framework's transparency.
- The method's applicability is primarily restricted to large language models, raising concerns about its utility for medium-sized models like T5-large or BERT-large.
- Comparisons with previous gradient-free iterative prompt search methods are insufficient, lacking qualitative and quantitative analyses.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the feedback and editing prompts, detailing their impact on the framework. Additionally, it would be beneficial to explore how textual gradients can be extracted or applied to medium-sized LMs. The authors should also provide more comprehensive comparisons with previous methods, specifically addressing what errors can be corrected by their approach that others cannot. Furthermore, we suggest including hyper-parameter tuning for baselines to enhance the robustness of experimental results. Lastly, addressing the performance drop observed in Figure 4 after several optimization steps would strengthen the paper's findings.