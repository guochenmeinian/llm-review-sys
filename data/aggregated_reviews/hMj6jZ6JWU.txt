ID: hMj6jZ6JWU
Title: Empowering and Assessing the Utility of Large Language Models in Crop Science
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 7, 7, 6, -1, -1
Original Confidences: 3, 4, 3, -1, -1

Aggregated Review:
### Key Points
This paper presents a conversational dataset that encompasses both QA and multi-turn QA scenarios within the crop science domain, along with a MCQA benchmark to evaluate the performance of various Large Language Models (LLMs). The authors propose the CROP dataset, which includes 210,038 single-turn and 1,871 multi-turn dialogues, and a benchmark of 5,045 multiple-choice questions across three difficulty levels. The experiments indicate notable enhancements in crop science-related tasks when LLMs are fine-tuned with this dataset.

### Strengths and Weaknesses
Strengths:
- The dataset construction involved domain experts, ensuring high data quality.
- The task-oriented and LLM-human integrated pipeline used for data collection is well-executed.
- The proposed benchmark effectively evaluates LLMs' fine-grained abilities in crop science.

Weaknesses:
- The performance of GPT-4 and other commercial LLMs surpasses that of the fine-tuned models on the proposed dataset, potentially limiting its significance.
- The dataset was not fine-tuned on larger models like LLaMA 70B and Qwen 72B.
- The improvements brought by CROP compared to CQIA are relatively modest, and the contribution of each to the results in Table 3 is unclear.

### Suggestions for Improvement
We recommend that the authors improve clarity by providing statistics on expert evaluations of the generated content in Section 2. Additionally, we suggest conducting experiments on larger open-source LLMs and performing an ablation study on CROP to clarify its contributions. Furthermore, addressing how geographically-related problems are handled would enhance the dataset's applicability. Lastly, we encourage the authors to consider incorporating university exam problems in crop science to strengthen the benchmark.