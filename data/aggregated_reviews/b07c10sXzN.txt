ID: b07c10sXzN
Title: Lifelong Sequence Generation with Dynamic Module Expansion and Adaptation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel framework for lifelong sequence generation (LSG) that dynamically determines whether to add new modules for acquiring knowledge from new tasks while retrieving knowledge from prior tasks to enhance adaptation. The authors propose Dynamic Module Expansion and Adaptation (DMEA), which mitigates forgetting by balancing current and past task weights through dynamic gradient scaling. Comprehensive experiments demonstrate that DMEA outperforms existing baselines, although the claim of being the first to address LSG from a human learning perspective may be overstated.

### Strengths and Weaknesses
Strengths:
- The paper is clearly written and easy to follow.
- The approach of utilizing knowledge from previous tasks is innovative in the context of lifelong sequence generation.
- Extensive experiments support the claims, showing state-of-the-art results.

Weaknesses:
- The aggressive claim regarding the novelty of the human learning perspective needs to be moderated.
- There is insufficient hyper-parameter analysis, particularly regarding the impact of $K$ on performance.
- The experimental section lacks ablation studies to identify the most impactful components of the proposed method.
- The related literature is not adequately addressed, missing comparisons with relevant recent works.

### Suggestions for Improvement
We recommend that the authors improve the methodology section to clarify the novelty of their approach relative to existing literature. Additionally, we suggest conducting more hyper-parameter analysis to illustrate how variations in $K$ and the number of samples affect performance. Including TRGP as a baseline and comparing DMEA with other continual learning methods, such as gradient projection memory, would strengthen the evaluation. Finally, we encourage the authors to perform ablation studies to determine the contributions of individual components of DMEA and to incorporate more recent references related to continual learning with pre-trained language models.