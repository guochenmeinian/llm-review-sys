ID: l2yvtrz3On
Title: Improved Sample Complexity for Multiclass PAC Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 5, 6, 7, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents improved sample complexity upper and lower bounds for multiclass classification, refining previous upper bounds to within a factor of $\log(1/\epsilon)$ from the conjectured optimal dependence on $\epsilon$, and adding a dependence of $\log(1/\delta)$ to the best lower bounds. The authors study multiclass classification through the lens of list-learning, allowing for a theorem that asserts the conjectured optimal dependence of $1/\epsilon$ holds under a conjecture about list-learning sample complexity. They introduce a technique termed "pivot shifting" that can potentially eliminate the extra log factor in multiclass complexity when it does not increase a combinatorial complexity measure by more than a constant factor.

### Strengths and Weaknesses
Strengths:  
- The paper introduces a novel boosting algorithm for list-learning, enabling a logarithmic improvement in $1/\epsilon$ and effectively applying list-learning machinery to multiclass problems.  
- It derives an explicit lower bound on sample complexity based on the DS dimension and improves the upper bound on error rate by a logarithmic factor.  
- The presentation of motivation and key results is clear, providing insights into sample complexity improvements.

Weaknesses:  
- The overall presentation is weak outside of Section 1, with hard-to-follow proof outlines and insufficient intuition in Section 3 regarding the notation-heavy definitions of pivot shifting.  
- The relationship between the theoretical bounds obtained and other data-independent complexity bounds is not discussed, limiting the demonstration of improvements from a broader perspective.  
- The technical summary is dense, and the comparison with previous work is narrow, with some reviewers noting that the improvements are relatively minor.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the presentation by including "proof intuition" sections following theorems and providing sketches for results in the appendix. This would enhance readability and understanding of the proofs. Additionally, we suggest elaborating on the relationship between the obtained theoretical bounds and other complexity bounds, such as the graph dimension, to provide a more comprehensive analysis. Lastly, consider addressing the clarity of the pivot shifting concept and its implications more thoroughly in the main text.