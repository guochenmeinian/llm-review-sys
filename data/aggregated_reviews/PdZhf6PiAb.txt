ID: PdZhf6PiAb
Title: An Information-Theoretic Evaluation of Generative Models in Learning Multi-modal Distributions
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 6, 8, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates an information theoretic approach to evaluate the diversity of generative models using Rényi kernel entropy (RKE) and relative Rényi kernel entropy (RRKE). RKE measures absolute diversity, while RRKE assesses relative diversity given the data distribution. The authors provide theoretical backing for the computational efficiency of RKE and RRKE estimators with convergence guarantees. The proposed metrics are applied to various image generative models on datasets such as CIFAR-10, tiny-ImageNet, and ImageNet-1K, demonstrating their effectiveness.

### Strengths and Weaknesses
Strengths:  
- The paper addresses the important problem of evaluating generative model diversity, offering an alternative to commonly used metrics like FID and Inception Score.  
- The proposed theorems are clearly articulated, and the application of Rényi divergence is novel.  
- The analysis of sample complexity is a valuable addition.  

Weaknesses:  
- The effectiveness of RKE and RRKE is contingent on various hyperparameters, particularly the choice of kernel, with the default being RBF, necessitating a validation step for bandwidth selection.  
- The focus on specific orders of Rényi entropies (1 and 2) limits generalization; exploring other orders could enhance the paper.  
- The paper lacks a comparative analysis of RKE and RRKE against other diversity metrics, particularly in relation to human judgment, which could be illustrated through rank-correlation measures.  
- The applicability of the proposed metrics to a broader range of generative models, such as VAEs, is not sufficiently explored.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the abstract by specifying that the RKE score estimates the number of well-separated modes. Additionally, Figure 1 should display RKE-MC for consistency with Table 1. The authors should also clarify the relationship between matrix-based Rényi entropy and sample diversity, and discuss the implications of their findings in relation to existing literature, particularly [Sanchez Giraldo et al., 2014] and [Dong et al., 2023]. Furthermore, we suggest including a discussion on the potential limitations and societal impacts of the proposed evaluation method. Lastly, exploring the use of RRKE as a regularizer during training to enhance diversity in generative models would be a valuable addition.