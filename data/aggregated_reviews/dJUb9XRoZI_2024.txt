ID: dJUb9XRoZI
Title: Constrained Diffusion with Trust Sampling
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 5, 5, 5, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 3, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method to enhance training-free loss-guided diffusion sampling through the introduction of Trust Sampling, which treats each timestep as an independent optimization problem. The authors propose techniques such as early termination and state manifold estimation to ensure robustness and constraint satisfaction during the sampling process. The method is validated through extensive experiments across various domains, demonstrating significant improvements in generation quality compared to existing techniques.

### Strengths and Weaknesses
Strengths:
1. The proposed Trust Sampling method offers a novel perspective on training-free guided diffusion, addressing key limitations of existing methods.
2. The paper is well-structured and clearly written, making it accessible to both experts and newcomers.
3. The methodology is thorough, and the experimental validation is robust, showcasing the method's effectiveness across diverse tasks.

Weaknesses:
1. The theoretical foundation of the paper is questionable, particularly regarding Equation 12, which appears to be incorrectly formulated.
2. The motivation for certain aspects, such as the correspondence of the integral to a multivariate Gaussian, lacks clarity.
3. The number of test samples in experiments is limited, and the authors did not utilize a dataset similar to DPS.
4. The proposed method requires over 500 NFE, raising concerns about efficiency.
5. The introduction of new hyperparameters raises scalability issues, and comparisons to additional baselines are insufficient.

### Suggestions for Improvement
We recommend that the authors improve the theoretical clarity of the paper by providing a correct formulation for Equation 12 and clarifying the motivation behind the integral's relation to a multivariate Gaussian. Additionally, we suggest increasing the number of test samples and utilizing a dataset similar to DPS for more robust validation. The authors should also address the efficiency concerns related to the high number of NFE and consider providing a more detailed discussion on the scalability of the introduced hyperparameters. Finally, we encourage the authors to compare their method against a broader range of baselines, including LGD-MC, to strengthen their contributions.