ID: dHIKahbV6G
Title: UMFC: Unsupervised Multi-Domain Feature Calibration for Vision-Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 19
Original Ratings: 6, 4, 3, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Unsupervised Multi-domain Feature Calibration (UMFC), aimed at enhancing the transferability of CLIP across various downstream tasks by addressing inherent model biases in its visual and textual encoders. The authors analyze CLIP's performance across different domains, focusing on its ability to encode perceptually distinct domains such as Clipart and Sketch. They argue that CLIP effectively clusters these domains in the t-SNE space and provide quantitative evidence of significant distances between domain features. The authors assert that their proposed method, UMFC, demonstrates consistent performance improvements across various models and tasks, despite some marginal declines in specific domains.

### Strengths and Weaknesses
Strengths:
1. The observation of domain-dependent performance variability in CLIP is insightful, highlighting accuracy fluctuations across different domains for the same classes.
2. The paper is well-motivated, starting with empirical observations of bias and further elaborating on the motivation from a probabilistic perspective.
3. The experiments are comprehensive, validating UMFC's efficacy across three downstream tasks with consistent performance gains.
4. The authors provide clear visual and quantitative evidence supporting the separation of domain features in the t-SNE space.
5. They effectively address concerns regarding text encoder bias and its impact on classification accuracy across different domains.
6. The method, UMFC, shows consistent performance improvements across multiple models, indicating robustness and generalization.

Weaknesses:
1. The reliance on multi-domain data for calibration limits the method's applicability in certain scenarios.
2. The comparison in test-time adaptation (TTA) is insufficient; the authors should compare UMFC with other state-of-the-art prototype-based methods like T3A.
3. The ablation study regarding the number of clusters \(M\) is inadequate, raising questions about the results if \(M\) exceeds the actual number of domains.
4. The improvements over simpler methods like CLIP-D appear minor, and the authors should clarify the performance of UMFC + CLIP-E against CLIP-D + CLIP-E.
5. The computational cost of the proposed method compared to others is not discussed, which is crucial given its use of test-time adaptation.
6. The response to the clustering methodology raises concerns about the applicability of results from high-quality datasets to more diverse, web-crawled datasets.
7. The marginal performance decline in the Real domain is not thoroughly addressed, leaving questions about the method's adaptability.

### Suggestions for Improvement
We recommend that the authors improve the comparison in TTA by including state-of-the-art prototype-based methods such as T3A. Additionally, the authors should conduct a more thorough ablation study on the number of clusters \(M\) to clarify its impact on performance. It would also be beneficial to provide a detailed analysis of the computational costs associated with UMFC, particularly in relation to other methods. Furthermore, the authors should ensure that the improvements over simpler methods like CLIP-D are clearly articulated and supported by robust comparisons. We suggest that the authors explore the implications of their findings when the pre-training dataset distribution changes, as this could affect the generalizability of their method. Lastly, addressing the marginal performance decline in the Real domain with specific strategies for hyperparameter adjustment would strengthen the overall argument for UMFC's robustness.