ID: xXRnUU7xTL
Title: SelfCodeAlign: Self-Alignment for Code Generation
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 7, 6, 5, 7, -1, -1, -1, -1
Original Confidences: 3, 2, 3, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents SelfCodeAlign, a fully transparent self-alignment pipeline for code generation in large language models (LLMs) that does not rely on extensive human annotations or distillation. SelfCodeAlign generates instruction-response pairs from seed snippets, evaluates responses with test cases, and fine-tunes models based on successful executions. The approach demonstrates superior performance over state-of-the-art methods, particularly on the HumanEval+ benchmark, and shows effectiveness across various model sizes. The authors highlight the potential of self-generated data to outperform teacher models, emphasizing the scalability and transparency of their method.

### Strengths and Weaknesses
Strengths:
- The paper identifies gaps in existing methods, particularly the lack of transparency, and adequately cites related work.
- It is technically sound, with detailed experimental results demonstrating significant performance improvements over baselines.
- The inclusion of evaluations across different model sizes strengthens the research quality.
- Ethical considerations regarding data usage are appropriately addressed.

Weaknesses:
- The originality may be questioned due to potential similarities with existing works, such as "Beyond Human Data: Scaling Self-Training for Problem-Solving with Language Models," which should be included in baseline comparisons.
- Qualitative examples in the appendix are excessively long and lack annotations, obscuring key differences and contributions. Shortening these examples and providing clearer explanations would enhance readability.
- The paper does not discuss scenarios where the methodology may fail or why the model does not achieve perfect scores.
- The reliance on seed snippets raises concerns about the diversity and representativeness of the data, which could impact accuracy.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the appendix by reducing the length of qualitative examples and including annotations to highlight their significance. Additionally, addressing the potential limitations of seed snippet diversity and discussing scenarios where the methodology may not perform well would strengthen the paper. We also suggest including comparisons with models distilled from non-disclosed data and exploring the performance of SelfCodeAlign with larger models, such as those in the GPT-4 family. Finally, providing a brief summarization of the component analysis after line 92 would enhance the presentation.