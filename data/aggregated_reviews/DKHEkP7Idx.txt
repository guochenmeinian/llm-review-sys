ID: DKHEkP7Idx
Title: Optimal Convergence Rate for Exact Policy Mirror Descent in Discounted Markov Decision Processes
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 6, 6, 6, 5, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 4, 1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis of the Policy Mirror Descent (PMD) algorithm, demonstrating a linear convergence rate that is independent of any distribution mismatch coefficient. The authors establish lower bounds indicating that this convergence rate is optimal under certain conditions, and they argue that policy-dependent learning rates are essential for achieving this rate. The work builds on prior research by simplifying the analysis and removing unnecessary terms from previous results.

### Strengths and Weaknesses
Strengths:
- The convergence result for policy mirror descent is strong and the analysis is concise.
- The removal of the distribution mismatch coefficient from the bounds is a significant improvement.
- The paper is well-structured, clearly presenting its contributions and providing a clean proof of the main result.

Weaknesses:
- The optimality claim in Theorem 4.2 is questionable, as it only holds for $k<n$, leaving open the possibility of stronger convergence rates for $k\geq n$.
- The lack of empirical validation raises concerns, especially since the results depend on a specifically designed learning rate that should be tested against other choices.
- The practical feasibility of the adaptive step-size schedule is uncertain, and the significance of the results in advancing the field of reinforcement learning is not clearly articulated.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the contribution by explicitly addressing how their results advance the theoretical understanding of PMD compared to existing methods. Additionally, we suggest conducting empirical experiments on tabular MDPs to validate the effectiveness of the proposed learning rates against other strategies. Furthermore, we encourage the authors to clarify the implications of Theorem 4.2 and consider providing qualifiers regarding its optimality. Lastly, addressing the missing recent works in the discussion would enhance the paper's comprehensiveness.