ID: HffQOS3mk8
Title: Diffusion-Based Probabilistic Uncertainty Estimation for Active Domain Adaptation
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 5, 8, 7, 6, 5, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel framework for active domain adaptation (ADA) that leverages a diffusion probabilistic model to estimate prediction uncertainty. The authors employ variational inference to model joint distributions of input data, latent codes, and labels, utilizing KL loss and adversarial training in a two-stage training process. A t-test-based strategy is introduced for selecting informative samples. Experimental results indicate that the proposed method outperforms baseline approaches on several benchmarks.

### Strengths and Weaknesses
Strengths:
- The method demonstrates improved accuracy in estimating prediction uncertainty using diffusion models, as evidenced by experimental results.
- The framework effectively captures both data-level and prediction-level uncertainties, leading to better-calibrated predictions compared to traditional methods.
- The t-test-based sample selection criterion is a comprehensive approach that considers multiple factors, enhancing the selection process.

Weaknesses:
- The combination of existing techniques, such as VAE, diffusion-based uncertainty estimation, and adversarial training, may not meet the contribution standards expected at NeurIPS.
- The diffusion-based uncertainty estimation lacks specificity for domain adaptation with distribution shifts, and results on more challenging datasets are missing.
- The marginal performance improvements over existing methods raise questions about the effectiveness of the proposed diffusion classifier compared to deterministic classifiers.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation behind the t-test-based strategy and provide justifications for the choice of classes and the definition of the t-value. Additionally, we suggest including results on more challenging datasets, such as DomainNet, to better evaluate the proposed method's performance. It would also be beneficial to clarify the theoretical justification for the diffusion-based classifier's ability to model predictive distributions and address the computational costs associated with the proposed framework. Lastly, we encourage the authors to explore the potential for generalizing the framework to scenarios without active learning to enhance its applicability.