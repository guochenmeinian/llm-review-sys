ID: kEflZNzau4
Title: Language Model is Suitable for Correction of Handwritten Mathematical Expressions Recognition
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to Handwritten Mathematical Expression Recognition (HMER), converting images of handwritten math expressions into LaTeX sequences. The authors propose a Recognition and Language Fusion Network (RLFN) that integrates recognition and language features, addressing structural and visual ambiguities in mathematical expressions. The study demonstrates that RLFN outperforms state-of-the-art (SOTA) methods on CROHME datasets, highlighting the potential for broader applications in handwriting recognition and language understanding.

### Strengths and Weaknesses
Strengths:  
- The paper is well-structured and clearly written, providing a comprehensive explanation of the proposed approach.  
- It includes ablation studies and case studies that effectively demonstrate the RLFN method's effectiveness.  
- The integration of language characteristics of LaTeX enhances the resolution of ambiguities in mathematical expressions, making it relevant to the scientific community.  
- Experimental results show significant performance improvements over existing methods.

Weaknesses:  
- The novelty of the proposed fusion network is limited, as both components are already known, and alternative combinations may yield better results without discussion.  
- The paper's language can be complex, making it difficult to grasp the problem and novelty in the introduction.  
- Data, code, and methods are not publicly available, hindering reproducibility and verification of claims.  
- Some theoretical analyses lack quantitative support, and details about hyperparameters are insufficient.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the introduction to better outline the problem and the paper's novelty, engaging the reader from the outset. Additionally, providing more details about hyperparameters and making the data and code publicly available would enhance reproducibility. We also suggest conducting a quantitative analysis to support theoretical claims regarding the language model's effectiveness. Finally, consider expanding the evaluation to include more diverse datasets and comparisons with existing frameworks like Google Lens and Socratic.