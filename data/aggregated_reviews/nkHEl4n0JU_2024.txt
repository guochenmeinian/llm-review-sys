ID: nkHEl4n0JU
Title: Visual Fourier Prompt Tuning
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 7, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Visual Fourier Prompt Tuning (VFPT), a novel approach to parameter-efficient fine-tuning (PEFT) for large-scale Transformer-based vision models. VFPT integrates Fast Fourier Transform (FFT) with prompt tuning, enabling effective adaptation to new tasks by leveraging both spatial and frequency domain information, particularly in scenarios with significant dataset disparities. The method retains the simplicity of standard visual prompt tuning while enhancing model performance across various tasks without a substantial increase in parameter count. Empirical results demonstrate that VFPT outperforms several state-of-the-art PEFT methods on benchmark datasets like VTAB-1k and FGVC, achieving 73.20% mean accuracy using only 0.66% of the total model parameters.

### Strengths and Weaknesses
Strengths:
1. The paper is well-structured and clearly written, with logical flow between sections.
2. VFPT introduces a unique integration of FFT with visual prompt tuning, effectively utilizing both spatial and frequency domain information.
3. Robust empirical results showcase VFPT's superiority over existing PEFT methods, supported by detailed comparative analyses.
4. The method has significant implications for the scalability and efficiency of Transformer-based models, making them more accessible for various applications.
5. The theoretical implications of integrating FFT within visual prompt tuning are discussed, noting improvements in optimization landscape and model interpretability.

Weaknesses:
1. A discrepancy exists between the abstract and Table 1 regarding parameter usage (0.57% vs. 0.66%), raising concerns about reported statistics' accuracy.
2. The complexity introduced by integrating FFT into prompt tuning is not thoroughly discussed, particularly regarding computational overhead during FFT operations.
3. VFPT underperforms relative to some established methods when applied to models pretrained with MAE self-supervised objectives, indicating potential limitations in its effectiveness in this context.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the parameter usage statistics to resolve the discrepancy between the abstract and Table 1. Additionally, a more thorough discussion of the computational overhead associated with FFT operations is necessary to provide a complete understanding of the method's efficiency. We suggest developing a theoretical framework to explain how integrating frequency domain information enhances generalization and exploring the impact of Fourier components on model performance. Furthermore, conducting a comprehensive analysis of computational trade-offs, including training time and memory usage, would be beneficial. We encourage the authors to extend experimentation to a broader range of architectures and to analyze the interactions between Fourier prompts and regular prompts. Lastly, including case studies on real-world applications would demonstrate VFPT's effectiveness beyond standard benchmarks.