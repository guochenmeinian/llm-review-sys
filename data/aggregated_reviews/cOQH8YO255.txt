ID: cOQH8YO255
Title: The Curious Price of Distributional Robustness in Reinforcement Learning with a Generative Model
Conference: NeurIPS
Year: 2023
Number of Reviews: 19
Original Ratings: 8, 7, 5, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on distributionally robust reinforcement learning (RL) under generative models, focusing on the statistical nature of robust Markov Decision Processes (MDPs) using total variation and chi-square divergences. The authors derive sample complexity bounds and improve upper and lower bounds, particularly for small uncertainty levels. The findings indicate that robust MDPs can be easier or harder to learn than standard MDPs depending on the choice of divergence measure. Additionally, the authors discuss the applicability of the discount factor $\gamma$ in reinforcement learning, clarifying that while many works consider the full range $\gamma \in (0,1)$, results for $\gamma \in (\frac{1}{2}, 1)$ are often viewed as sufficiently similar. They assert that their theorems can be adapted to work for the entire range $\gamma \in (0,1)$. The authors also address notation used in their work, specifically clarifying the definitions of $\lesssim$ and $\asymp$ to enhance understanding.

### Strengths and Weaknesses
Strengths:
- The theoretical results are significant for understanding the limits of distributionally robust RL, providing a comprehensive analysis of TV and chi-square divergences.
- The paper presents clear and well-structured results, with effective summarizations in tables and illustrations.
- Novel techniques are developed to improve upper and lower bounds, contributing to the field's understanding of robust MDPs.
- The authors provide a clear explanation regarding the range of $\gamma$ and its implications for reinforcement learning research.
- The clarification of notation enhances the paper's accessibility and rigor.

Weaknesses:
- A brief explanation of the improvements in bounds compared to previous techniques would enhance reader comprehension.
- The novelty of the proposed distributionally robust value iteration algorithm is unclear, as similar methods exist in prior literature.
- The paper lacks empirical experiments to validate theoretical claims, and discussions on practical implications for practitioners are insufficient.
- The initial confusion regarding the range of $\gamma$ may detract from the paper's clarity.
- Certain notations, such as $\lesssim$ and $\asymp$, were not defined in the initial draft, leading to potential confusion.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the theoretical contributions by providing a brief explanation of the reasons behind the enhancements in upper and lower bounds. Additionally, the authors should clarify the novel aspects of the distributionally robust value iteration algorithm and how it differs from existing methods. Incorporating empirical evaluations or experiments would strengthen the paper by demonstrating the practical applicability of the theoretical results. Furthermore, we suggest that the authors explicitly state the implications of using different ranges of $\gamma$ in the introduction to enhance clarity. We also recommend that the authors include the definitions of the notations $\lesssim$ and $\asymp$ in the introduction to ensure that readers can easily grasp these concepts from the outset. Lastly, a discussion on the limitations of the results, particularly regarding the ranges of $\gamma$, would be beneficial.