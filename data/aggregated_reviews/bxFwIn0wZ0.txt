ID: bxFwIn0wZ0
Title: Enabling Large Language Models to Generate Text with Citations
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for generating citations with LLMs to enhance factual correctness and verifiability. The authors propose a benchmark for citation evaluation, utilizing automatic metrics for fluency, correctness, and citation quality, which correlate well with human judgments. The study highlights the importance of citation in verifying claims made by LLMs and reducing hallucination, while also noting challenges such as the limited context window of LLMs and difficulties in synthesizing multiple documents.

### Strengths and Weaknesses
Strengths:
- The topic is highly relevant to current challenges in LLMs.
- The paper is well-written and thoroughly presents its experimental setup and analysis.
- Human evaluations add significant value to the quality assessment of the results.
- The benchmark, ALCE, is a novel contribution to the field.

Weaknesses:
- Uncertainty regarding the release of the dataset limits reproducibility.
- Lack of comparison with other baseline models makes it difficult to gauge the relative efficacy of LLMs.
- Some minor methodological details, such as citation recall measurement and kappa calculation, are unclear.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the dataset release to ensure reproducibility. Additionally, providing the code used in the experiments and the assessments performed by annotators would enhance reproducibility. The authors should clarify how citation recall is measured and address the calculation of kappa between ALCE and human judgment. Furthermore, we suggest including comparisons with existing models to better contextualize the performance of LLMs and conducting a more thorough analysis of factors like hallucinations, bias, and fairness in the generated text.