ID: owc65ImkyU
Title: Plan, Verify and Switch: Integrated Reasoning with Diverse X-of-Thoughts
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a problem-solving framework called XoT, which utilizes large language models (LLMs) and various prompting methods, including Chain of Thought (CoT), Program of Thought (PoT), and Equation-of-Thought (EoT), to enhance math reasoning tasks. XoT iteratively selects the most suitable method for each question, actively checks the validity of generated answers, and incorporates feedback from external executors. The framework is evaluated on 10 popular math reasoning datasets, demonstrating its effectiveness and the collaborative strengths of its modules.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and easy to follow.
2. The motivation for combining different prompting techniques and performing verification is clear.
3. Experimental results support the effectiveness of the proposed method, showing improvements over single prompting methods.

Weaknesses:
1. The novelty of the approach is limited, as the combination of prompting methods yields expected results.
2. The planning module does not significantly enhance performance compared to verification alone, necessitating efficiency analysis.
3. Active verification appears to decrease overall accuracy, requiring deeper analysis and ablation studies to clarify its impact.
4. The paper lacks clarity on the details of EoT and does not provide performance metrics for it in certain datasets.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the EoT method by providing detailed explanations prior to the experimental section. Additionally, the authors should consider including stronger baselines, such as self-consistency chain of thought, and explore the effects of majority voting among the three prompting methods. An analysis of the planning module's contributions and the performance of XoT with active verification in Table 3 would also enhance the paper. Finally, we suggest that the authors add experiments involving more LLMs and reasoning tasks to demonstrate the generalizability of their framework.