ID: LZ4WgwmrUJ
Title: High-dimensional Contextual Bandit Problem without Sparsity
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 5, 6, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 2, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an exploration of high-dimensional linear contextual bandits where the number of features exceeds the budget or may even be infinite. The authors propose an explore-then-commit (EtC) algorithm and an adaptive explore-then-commit (AEtC) algorithm, leveraging over-parameterized models without imposing sparsity on regression coefficients. The performance of these algorithms is evaluated through simulations, and optimal regret rates are derived, emphasizing the balance between exploration and exploitation.

### Strengths and Weaknesses
Strengths:  
- The paper addresses a novel problem in high-dimensional bandits without sparsity, introducing the EtC and AEtC algorithms based on the minimum-norm interpolating estimator.  
- The organization and presentation of the results are generally clear, and the algorithms are straightforward to implement.  
- The authors provide upper and matching lower bounds on estimation error, demonstrating the practical applicability of the adaptive algorithm.

Weaknesses:  
- The paper lacks a discussion of the lower bound for the problem, which is crucial for understanding the theoretical performance of the proposed algorithms.  
- Some assumptions, particularly Assumption 1, are strong and require more intuitive explanations. The authors should clarify the rationale behind using spectral decomposition for constructing $X^{(i)}(t)$.  
- Definitions of terms such as effective bias, effective variance, coherent rank, and benign covariance are not commonly used and need further elaboration.  
- The regret bound in Theorem 4 is dependent on an unclear parameter $\alpha$, which should be explicitly defined.  
- The introduction of the term "benign covariance" is abrupt and technical, necessitating more context for readers.

### Suggestions for Improvement
We recommend that the authors improve the discussion of the lower bound of the problem to enhance theoretical understanding. Additionally, more intuitive explanations of the assumptions, particularly Assumption 1, should be provided, including examples where these assumptions hold. We suggest that the authors elaborate on the definitions of key terms used in the paper and clarify the meaning of $\alpha$ in Theorem 4. Furthermore, the authors should consider providing a more gradual introduction to technical terms like "benign covariance" to aid reader comprehension. Lastly, a comparison of their assumptions with recent works in the field would strengthen the paper's contribution.