ID: SjiLtmZETc
Title: Bayesian Risk-Averse Q-Learning with Streaming Observations
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 7, 6, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Bayesian risk-averse Q-learning algorithm designed to address the Bayesian risk Markov Decision Process (BRMDP) framework. The authors propose a nested BRMDP formulation for the state value function and demonstrate that the difference between optimal value functions for BRMDP and the true MDP is bounded. The algorithm incorporates periodic posterior updates and Monte Carlo estimators for the risk-averse Bellman operators, showing theoretical convergence to an optimal policy. Numerical experiments illustrate the algorithm's performance in two small-scale MDPs, highlighting its advantages over risk-neutral counterparts.

### Strengths and Weaknesses
Strengths:
- The paper introduces a novel infinite horizon BRMDP formulation and provides detailed proofs for convergence and distance bounds.
- The empirical results effectively demonstrate the algorithm's performance gains and reduced variance.
- The theoretical contributions, including the proof of Theorem 4.3 regarding the uniform convergence of the Bellman operator estimator, are technically rigorous.

Weaknesses:
- The novelty of certain theorems, such as Theorem 2.2 and Theorem 2.3, is unclear, as similar results may exist in the literature.
- The empirical evaluation is limited to small-scale environments, lacking complexity and scalability considerations for high-dimensional data streams.
- The definition of "robustness" in the context of the proposed method is vague, and the relationship between risk levels and performance variations is not adequately discussed.

### Suggestions for Improvement
We recommend that the authors improve clarity regarding the novelty of their theoretical contributions by explicitly comparing them to existing literature. Additionally, enhancing the notation and formalization throughout the paper would aid readability. We suggest incorporating more complex experimental environments to better evaluate the algorithm's performance and scalability. Furthermore, a clearer definition of robustness and its implications on performance metrics should be provided, particularly in relation to the risk level parameter $\alpha$. Lastly, exploring more sample-efficient methods for obtaining unbiased Bellman operator estimators could be beneficial for applications involving high-dimensional data streams.