ID: TSdWY9GaHA
Title: CHiLL: Zero-shot Custom Interpretable Feature Extraction from Clinical Notes with Large Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a two-phase model utilizing a large language model (LLM, Flan-T5-XXL) for feature extraction from medical texts, followed by a simple linear model for label generation. The authors propose that their method enhances interpretability in medical text classification. They provide a detailed prompt set for extracting features from the Chest X-ray Dataset, which could aid in structuring unstructured medical data.

### Strengths and Weaknesses
Strengths:  
- The task is relevant and interesting, particularly in the medical domain.  
- The paper is well-written and easy to follow, with comprehensive experimental results and discussions.  
- The approach attempts to bridge LLMs and interpretable features, which is valuable for real applications.  

Weaknesses:  
- The novelty of the work is questionable, as many methods appear to be existing techniques.  
- The authors do not demonstrate that their model outperforms traditional models like TF-IDF, and the proposed model sometimes yields worse performance.  
- There is insufficient evidence to support claims of enhanced interpretability, and certain model decisions lack explanation.  
- Concerns regarding privacy implications of using LLMs with sensitive data are raised.  

### Suggestions for Improvement
We recommend that the authors improve the clarity of the methodology section to enhance understanding. Additionally, the authors should provide robust evidence demonstrating the superiority of their model over traditional methods like TF-IDF and include comparisons with topic models such as LDA. It would also be beneficial to clarify the interpretability of their model, particularly regarding the unintuitive findings related to feature importance. Finally, addressing potential privacy issues associated with using LLMs in real-world settings is essential.