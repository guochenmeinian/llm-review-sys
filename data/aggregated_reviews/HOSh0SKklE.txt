ID: HOSh0SKklE
Title: Theoretical Analysis of Weak-to-Strong Generalization
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 7, 6, 7, -1, -1, -1, -1
Original Confidences: 3, 3, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a theoretical analysis of weak-to-strong generalization, where strong models learn from weak supervisors and outperform them. The authors make precise assumptions regarding the strong student model family and weak supervisor mistakes, deriving generalization bounds for empirical risk minimization. These bounds illustrate two phenomena: pseudolabel correction and coverage expansion. The authors also propose a statistical method for empirically testing their assumptions, demonstrating applicability in sentiment analysis with a bag-of-words supervisor.

### Strengths and Weaknesses
Strengths:  
- The theoretical approach is intuitively sound, with informal intuitions provided for definitions and results.  
- The derived generalization bounds are novel and non-trivial, with detailed comparisons to existing bounds for weak supervision.  
- A rigorous statistical method and heuristic for testing assumptions in practice are presented.  
- The evaluation of assumptions and bounds in a simple empirical setting adds practical relevance.  

Weaknesses:  
- The paper becomes mathematically dense and harder to follow towards the end.  
- It lacks novel empirical insights and does not propose a new training method or practical recommendations for weak-to-strong generalization.  
- The empirical evaluation is limited to one simple case, suggesting a need for broader application of the bounds across various settings.  

### Suggestions for Improvement
We recommend that the authors improve the clarity of the mathematical exposition towards the end to enhance readability. Additionally, we suggest that the authors discuss the implications of their bounds in relation to existing methods, such as self-training, to clarify improvements in coverage and error correction. Expanding the empirical evaluation to include multiple settings would strengthen the paper, particularly in exploring the bounds' predictive capabilities in scenarios where weak-to-strong generalization may not perform well. Finally, addressing how the size of covered sets affects results and providing a final result conditioned on the entire covered set would enhance the theoretical contributions.