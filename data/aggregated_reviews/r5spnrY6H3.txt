ID: r5spnrY6H3
Title: RG-SAN: Rule-Guided Spatial Awareness Network for End-to-End 3D Referring Expression Segmentation
Conference: NeurIPS
Year: 2024
Number of Reviews: 22
Original Ratings: 8, 8, 7, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents RG-SAN, a novel method for 3D Referring Expression Segmentation (3D-RES) that integrates spatial reasoning with textual cues to accurately segment 3D objects. The authors propose a Text-driven Localization Module (TLM) and a Rule-guided Weak Supervision (RWS) strategy, achieving superior performance on the ScanRefer benchmark. The method effectively addresses spatial ambiguities and sets a new standard for precision in 3D scene understanding. Extensive ablation studies and visualizations validate the proposed modules' effectiveness. Additionally, the paper explores positional encoding in both 2D and 3D contexts, specifically within Vision Transformers (ViTs) and point clouds, illustrating how the arrangement of input tokens affects final embeddings in 2D while maintaining consistent representations in 3D despite input order changes. The authors propose to clarify the discussion on positional encoding in the supplementary material, enhancing the understanding of its role in their methodology.

### Strengths and Weaknesses
Strengths:
1. The motivation is clearly articulated, with visual aids like Figure 1 and Figure 4 enhancing understanding of spatial relationships in natural language.
2. The TLM module aligns with human cognitive processes, improving spatial reasoning and understanding of 3D scenes.
3. The RWS module demonstrates strong generalization capabilities without requiring supervision for all object nouns.
4. Comprehensive experiments on datasets like ScanRefer and ReferIt3D showcase state-of-the-art performance, supported by detailed ablation studies.
5. The appendix includes valuable comparisons of large language models (LLMs) with the RWS module, offering insights into their application in 3D-RES.
6. The paper effectively addresses the modeling of spatial positions within language space, contributing to advancements in 3D cross-modal understanding.
7. The authors have shown responsiveness to reviewer feedback, leading to improvements in clarity and rigor.

Weaknesses:
1. The paper lacks a comparison with traditional 3D Visual Grounding methods, which would provide a more complete quantitative analysis.
2. There is no direct comparison between LLM-based approaches and 3D Visual Grounding methods, leaving questions about their relative performance.
3. Details on superpoint feature extraction are insufficient, particularly regarding coverage of all targets and missing rates.
4. The layout of Tables 2 and 3 is problematic, and the font size in Figure 2 is too small for readability.
5. The text processing procedure, especially the interaction process of the DDI module, requires more detailed explanation.
6. There are concerns regarding the consistency of positional encoding treatment and the clarity of notation and equations used in the paper.
7. Some reviewers noted that the initial simplifications in formula definitions compromised the rigor of the work.

### Suggestions for Improvement
We recommend that the authors improve the comparison with traditional 3D Visual Grounding methods to provide a more comprehensive evaluation of RG-SAN's performance. Additionally, including a direct comparison between LLM-based approaches and specialized models would clarify their relative advantages. We suggest providing more details on superpoint feature extraction to address potential coverage issues. The authors should also enhance the layout of Tables 2 and 3 and increase the font size in Figure 2 for better readability. Furthermore, we recommend including a detailed description of the text processing procedure, particularly the DDI module's interaction process, in the main text. Lastly, we encourage the authors to improve the consistency of how positional encoding is handled throughout the paper and to clearly define notations and equations rather than relying on those from other works without adequate explanation. This will enhance the manuscript's clarity and rigor, addressing the concerns raised by reviewers.