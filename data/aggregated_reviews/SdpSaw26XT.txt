ID: SdpSaw26XT
Title: Mirror: A Universal Framework for Various Information Extraction Tasks
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel framework called Mirror for information extraction (IE) tasks, which reorganizes IE problems as a multi-span cyclic graph extraction problem and devises a non-autoregressive graph decoding algorithm to extract all spans in a single step. The authors have constructed a pre-training corpus with 57 datasets and conducted experiments on 30 datasets across 8 downstream tasks, demonstrating the model's compatibility and competitive performance under zero/few-shot settings. The paper also introduces discontinuous entity extraction for the first time in universal information extraction tasks.

### Strengths and Weaknesses
Strengths:
- The framework is suitable for extraction, machine reading comprehension (MRC), and classification tasks, introducing an Instruction-enhanced model based on the traditional BERT-style framework.
- Detailed experiments on extensive datasets show strong few-shot and zero-shot performance.
- The graph structure is flexible and scalable, allowing for various complex IE tasks.

Weaknesses:
- Comparisons in Table 1 lack rigor, as other frameworks can also perform MRC and classification tasks.
- The claim regarding generation-style methods failing to predict structured information locations is challenged by existing models like UIE and TANL, which effectively obtain location information.
- The impact of pre-training with classification data on model performance is unclear, and the distinction between classification and extraction tasks is not adequately addressed.

### Suggestions for Improvement
We recommend that the authors improve the rigor of comparisons in Table 1 by providing clearer distinctions between the capabilities of Mirror and existing frameworks. Additionally, we suggest conducting ablation experiments on pre-training data according to different task types to clarify the role of each pre-training task part. The authors should also address the scalability concerns of the model regarding long text inputs and the number of entity and relation types. Furthermore, the complexity of the decoding algorithm should be clearly stated, including the speed-up compared to autoregressive UIE models. Lastly, we advise revising the expression "Extractive Pretrained Language Model" to a more commonly understood term, such as "BERT-style PLM," and correcting grammatical errors throughout the text.