ID: 2NUFe4TZMS
Title: Gaussian Membership Inference Privacy
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 5, 5, 4, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel privacy definition termed Gaussian Membership Inference Privacy (GMIP), which aims to capture the information leakage of training algorithms regarding individual data points. The authors propose a theoretical framework that relaxes strict Differential Privacy (DP) assumptions, thereby enhancing model utility. The analysis includes a likelihood ratio attack on DP-SGD, demonstrating that GMIP provides tighter privacy guarantees under certain conditions compared to traditional Gaussian differential privacy (GDP). Additionally, the paper discusses the application of Berry-Esseen’s theorem to bound error rates, suggesting an error of order $\mathcal{O}(1/\sqrt{n})$, while proposing to explore the bound of Dong et al., which offers a faster convergence rate of $\mathcal{O}(1/n)$. Empirical results indicate that the proposed method significantly improves model accuracy while maintaining privacy, and the authors express gratitude for the reviewers' feedback and their willingness to make clarifications and improvements.

### Strengths and Weaknesses
Strengths:
- The paper addresses a critical issue of bounding information leakage against realistic adversaries, contributing to the understanding of membership inference attacks.
- The analytical derivation of the likelihood ratio test is novel and provides insights into the privacy-utility trade-off.
- The structure of the paper is clear and facilitates comprehension of complex concepts.
- The authors effectively address reviewer concerns, enhancing clarity in the manuscript.
- The topic is timely and relevant, focusing on inference attacks, which is appreciated by the reviewers.
- Empirical evidence suggests negligible error rates, supporting the paper's claims.

Weaknesses:
- The theoretical exploration of the relationship between f-MIP and f-DP is insufficient, limiting the understanding of the proposed method's implications.
- The assumptions regarding the gradient distribution and the model dimension may not hold in practical scenarios, potentially undermining the validity of the GMIP bounds.
- The paper lacks discussions on post-processing and the composition rule, which could enhance the practical applicability of the proposed approach.
- The manuscript could benefit from a more detailed discussion on the applicability of Dong et al.'s bound and proving technique.

### Suggestions for Improvement
We recommend that the authors improve the theoretical analysis by exploring the relationship between f-MIP and f-DP in greater depth. Additionally, clarifying the assumptions regarding the gradient distribution and model dimension is essential to ensure the robustness of the GMIP bounds. We suggest extending the FPR and TPR ranges in the plots to capture more relevant adversary objectives. Furthermore, including discussions on post-processing and the composition rule would enhance the practical utility of the proposed framework. Lastly, we encourage the authors to provide experimental results using real machine learning models accessed solely through APIs to validate the proposed privacy definitions under more realistic conditions. We also recommend that the authors improve the clarity of their discussion regarding Berry-Esseen’s theorem and its implications for error bounding, as well as explore the applicability of the bound and proving technique from Dong et al. to strengthen their findings.