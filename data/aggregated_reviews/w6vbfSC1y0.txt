ID: w6vbfSC1y0
Title: Self-Calibrated Tuning of Vision-Language Models for Out-of-Distribution Detection
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 3, 5, 4, 7, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 5, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Self-Calibrated Tuning (SCT), a novel framework aimed at improving out-of-distribution (OOD) detection using CLIP-based methods. SCT addresses the issues of unreliable OOD features extracted from in-distribution (ID) data by dynamically adjusting the influence of OOD regularization based on ID prediction uncertainty. The authors propose modulating factors in the learning objective to enhance the calibration of OOD features, demonstrating SCT's effectiveness through empirical evaluations on ImageNet-1k.

### Strengths and Weaknesses
Strengths:
1. The paper is well-motivated and clearly written, with a strong justification for the use of SCT.
2. It provides a timely analysis of the challenges posed by incorrect OOD features.
3. SCT shows strong empirical performance across various OOD detection methods.
4. The authors conduct extensive experiments, demonstrating SCT's effectiveness on both official benchmarks and challenging OOD tasks.

Weaknesses:
1. The technical contribution is relatively incremental, primarily focusing on weighting loss components without significant novelty.
2. The empirical performance gains of SCT appear minimal, particularly in traditional benchmarks like CIFAR.
3. There is insufficient discussion regarding the calibration of OOD features, and the lack of visualizations or quantitative metrics to support claims of improved calibration is noted.
4. The method's reliance on heuristics raises questions about its theoretical foundation and optimality.
5. The paper lacks comparisons with state-of-the-art methods, and results on ID-like data are not competitive.

### Suggestions for Improvement
We recommend that the authors improve the theoretical analysis of SCT to clarify its optimality and address the heuristic nature of the method. Additional evaluations against traditional CIFAR benchmarks should be included to strengthen empirical claims. We suggest incorporating visualizations of calibration results post-training and adding quantitative metrics such as Expected Calibration Error (ECE) to support calibration claims. Furthermore, a more comprehensive discussion on the advantages of SCT compared to post-hoc methods and the rationale behind the choice of modulating functions would enhance the paper's depth. Lastly, clarifying the validation set used for hyperparameter tuning would provide greater transparency.