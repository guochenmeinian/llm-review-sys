ID: tPgagXpvcV
Title: Any2Graph: Deep End-To-End Supervised Graph Prediction With An Optimal Transport Loss
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 7, 8, 7, 7, 6, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Any2Graph, a generic framework for end-to-end supervised graph prediction (SGP) that utilizes a novel loss function, the Partially Masked Fused Gromov-Wasserstein (PMFGW) loss. The framework is designed to handle various input data types and produce graphs of arbitrary size and node ordering. The PMFGW loss is differentiable and permutation invariant, allowing for effective graph comparisons. The authors demonstrate Any2Graph's superior performance on synthetic and real-world datasets, showcasing its versatility across different applications.

### Strengths and Weaknesses
Strengths:  
- The paper addresses a significant problem in supervised graph predictions, potentially benefiting numerous applications.  
- It is well-written, effectively motivating the problem and articulating the proposed framework.  
- The PMFGW loss is well-formulated and shows strong performance across various metrics compared to existing solutions.  
- Comprehensive experiments highlight the high performance of Any2Graph and provide insights into its properties.  

Weaknesses:  
- The computational performance results lack comprehensiveness; understanding how training time scales with an increase in M would enhance practicality assessments.  
- There is limited discussion on failure cases produced by Any2Graph.  
- The paper does not adequately address the distribution of continuous outputs or the impact of varying thresholds on predicted graphs.  
- The evaluation lacks sufficient ablation studies, which would clarify the contributions of different components of the framework.  
- Inconsistencies in notation and limited analysis of the maximum node size's influence on efficiency and expressiveness are noted.

### Suggestions for Improvement
We recommend that the authors improve the comprehensiveness of the computational performance results by providing insights into how training time scales with an increase in M. Additionally, including an analysis of failure cases and the distribution of continuous outputs would enhance the paper's depth. We suggest conducting ablation studies to better understand the impact of different components of the framework. Furthermore, addressing the inconsistencies in notation and providing a more thorough analysis of the maximum node size's influence on model performance would strengthen the paper.