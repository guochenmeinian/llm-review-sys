ID: ZQzm0Z47jz
Title: Rethinking the Role of Token Retrieval in Multi-Vector Retrieval
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 7, 6, 8, 6, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 5, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Contextualized Token Retriever (XTR), which enhances multi-vector retrieval by modifying the training objective and scoring mechanism of ColBERT. The authors demonstrate that the traditional cross-entropy loss in ColBERT inadequately reduces token-level scores when average scores are low, impacting precision. To address this, they simulate token retrieval during training by masking document token scores for tokens not among the top \(k_{train}\) for a given query token. At search time, only retrieved tokens are used, with scores for missing tokens estimated from kNN retrieval.

### Strengths and Weaknesses
Strengths:
- The paper effectively addresses a well-defined problem with a novel solution, showing strong applicability to multi-vector retrieval systems.
- The analysis and results are robust, particularly given that the paper does not rely on distillation from cross-encoders.
- Extensive experiments demonstrate XTR's competitive performance on multiple benchmarks, achieving state-of-the-art results in zero-shot retrieval.

Weaknesses:
- Several claims in the paper are inflated or unsupported, particularly regarding the efficiency of XTR compared to ColBERT, which lacks empirical latency measurements.
- The comparison with ColBERT does not account for optimizations in newer models like ColBERTv2 and PLAID, which could misrepresent XTR's efficiency.
- The writing lacks clarity in certain sections, making it difficult to understand the problem statement and experimental setups.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the introduction by explicitly stating the problem of document retrieval. Additionally, the experimental section should include separate sub-sections for datasets, model comparisons, and experimental settings to enhance coherence. To strengthen claims regarding efficiency, we suggest including empirical latency measurements and comparisons with recent implementations of ColBERT-like methods. Furthermore, we advise the authors to tone down inflated claims in the abstract and throughout the paper, particularly regarding the efficiency of XTR relative to existing models. Lastly, exploring the performance of XTR with other architectures beyond T5 would provide a more comprehensive evaluation of its applicability.