ID: 2UZXqt9hpK
Title: Beyond Labels and Topics: Discovering Causal Relationships in Neural Topic Modeling
Conference: ACM
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents CRNTM, a Causal Relationship-Aware Neural Topic Model designed to uncover causal relationships between supervised information and latent topics while generating high-quality topics. The model employs a Directed Acyclic Graph (DAG) and Structural Causal Models (SCM) to represent these relationships. The authors argue that this approach enhances interpretability in neural topic modeling. The experimental results indicate that CRNTM outperforms existing methods in terms of topic quality and interpretability.

### Strengths and Weaknesses
Strengths:
- The proposed method, CRNTM, is novel and interesting, with sound design and execution.
- Comprehensive experiments demonstrate the model's superiority in topic quality and interpretability compared to state-of-the-art models.
- The paper is well-written, with clear figures and tables that enhance readability.

Weaknesses:
- The claim that causal relationships between supervised information and latent topics have not been explored in prior work may not be entirely accurate; hierarchical topic models could also model such relationships.
- The paper fixes the number of topics rather than employing techniques like tuning or cross-validation to determine it.
- Some technical components, such as SCM, could benefit from more intuitive explanations for readers unfamiliar with causal modeling.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the meaning of causal relationships between topics, providing clarity on what "influence" entails in this context. Additionally, the authors should include specific examples demonstrating the practical utility of topic modeling with causal relationships. Clarifying the role of supervised information in the model's performance is essential. We also suggest justifying the choice of Dirichlet distributions over Gaussian distributions for modeling latent topics. To enhance accessibility, we encourage the authors to simplify complex concepts in Sections 3.2 and 3.3 and reserve detailed formulas for the appendix. Lastly, including additional baselines, such as CatE, and conducting experiments on downstream applications like document classification would strengthen the paper.