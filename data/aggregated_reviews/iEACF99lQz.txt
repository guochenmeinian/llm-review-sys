ID: iEACF99lQz
Title: Merging Generated and Retrieved Knowledge for Open-Domain QA
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a compatibility-oriented knowledge merging framework (COMBO) designed to merge retrieved and LLM-generated knowledge in open-domain QA. The authors propose 'compatible scores' based on a consistency discriminator and an evidentiality discriminator to identify compatible pairs of passages. Experimental results indicate that COMBO outperforms direct merging baselines, particularly in high-conflict scenarios, and the framework is supported by thorough experimental evaluations and ablation studies.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, with clear explanations and visually appealing illustrations that enhance understanding.
- The experimental evaluation is robust, demonstrating consistent performance improvements across various datasets, including both single-hop and multi-hop scenarios.
- The mathematical derivation of compatibility, evidentiality, and consistency is clear, and the intuition behind the design choices is well articulated.

Weaknesses:
- The performance gain over the "Random Matching" method is minimal and not statistically significant, raising concerns about the practicality of the approach given the additional training required.
- The improvements over direct merging are incremental, and the upper bound of performance suggests limited room for further enhancement.
- The necessity for separate training of the discriminators on each dataset introduces additional complexity and may limit the framework's applicability across different datasets.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the performance gain compared to the "Random Matching" method to provide a more comprehensive perspective on the method's efficacy. Additionally, clarifying the statistical significance of the improvements over "Random Matching" would strengthen the paper. The authors should also consider addressing the transferability of the discriminators across datasets and explore the potential for filtering pairs with zero evidentiality. Finally, reporting F1 scores, as they are more stable and reliable than EM, would enhance the evaluation metrics presented in the paper.