ID: Qms9kWnbpP
Title: Expressivity of Spiking Neural Networks through the Spike Response Model
Conference: NeurIPS
Year: 2023
Number of Reviews: 3
Original Ratings: 8, 7, 6
Original Confidences: 4, 1, 1

Aggregated Review:
### Key Points
This paper presents a theoretical exploration of the expressive power of Spiking Neural Networks (SNNs) in comparison to Artificial Neural Networks (ANNs), particularly focusing on Continuous Piecewise Linear (CPWL) mappings, including ReLU functions. The authors characterize the number of 'linear regions' in the input domain as a measure of expressivity and demonstrate that SNNs can reproduce the output of any ReLU ANN under specific conditions, achieving certain CPWL functions with fewer layers and computational units. The results are positioned as beneficial for designing architectures for neuromorphic hardware.

### Strengths and Weaknesses
Strengths:
1. The paper addresses a significant gap in the SNN community by studying the expressiveness of SNNs compared to ANNs.
2. The theoretical results, particularly Theorem 2, are deemed important.

Weaknesses:
1. The absence of simulation results, even on simple datasets, weakens the claims made in the paper.
2. The spiking model assumption may diverge from common experimental practices in SNN research.
3. The paper lacks a detailed discussion on its relevance to neuromorphic hardware design and simplifies certain aspects that may reduce practical applicability.

### Suggestions for Improvement
We recommend that the authors improve the paper by including numerical simulations to strengthen their claims, particularly regarding the expressivity of SNNs. Additionally, we suggest providing a deeper discussion on the implications for neuromorphic hardware design. Clarifying the choice of $$\delta$$ and defining $$N$$ more explicitly would enhance clarity. Furthermore, we encourage the authors to consider adding a limitations section in the conclusion, despite page constraints, and to explore potential experiments that could validate their theoretical findings, such as the scaling of linear regions in multi-layer SNNs.