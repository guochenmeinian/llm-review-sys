ID: NrCPBJSOOc
Title: DACO: Towards Application-Driven and Comprehensive Data Analysis via Code Generation
Conference: NeurIPS
Year: 2024
Number of Reviews: 4
Original Ratings: 6, 6, 6, -1
Original Confidences: 4, 4, 4, -1

Aggregated Review:
### Key Points
This paper presents the DACO dataset, comprising 440 databases and 1942 queries designed to facilitate complex data analysis through reasoning steps and code interaction. The dataset aims to address challenges in data analysis by leveraging large language models (LLMs) for query generation and evaluation. The authors demonstrate the dataset's utility by assessing various models, showcasing its potential to enhance data-driven decision-making processes.

### Strengths and Weaknesses
Strengths:
1. The DACO dataset provides a useful collection of queries requiring complex data analysis, utilizing code and multiple reasoning steps.
2. The dataset includes human annotations for query steps, enhancing the quality of automated annotations.
3. The introduction of a high-quality test set and the assessment of diverse models contribute significantly to the field.

Weaknesses:
1. The reliance on the GPT family of models for both dataset generation and evaluation raises concerns about potential biases.
2. Inclusion of tables with only 2 rows in the dataset is questionable, as it limits the complexity of queries that can be formulated.
3. The evaluation metric based on helpfulness may introduce subjectivity, and the performance of models is heavily dependent on the quality of human annotations.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the source descriptions for the 440 databases and provide examples in the appendix to aid reader understanding. Additionally, we suggest that the authors clarify the implementation details of the CodeGeeX2-6B with RLHF, including presenting RLHF samples for training. Furthermore, we encourage the authors to consider constructing the benchmark in a reverse manner by analyzing code that manipulates datasets, allowing a code model to describe the steps and overall queries. Lastly, we advise the authors to explore a more detailed comparison with existing agent-based approaches to enhance the robustness of their findings.