ID: 7LZ4tZrYlx
Title: Bounding training data reconstruction in DP-SGD
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 6, 5, 4, 8, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 3, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an exploration of training data reconstruction robustness in the context of DP-SGD, identifying a significant gap between existing lower and upper bounds on reconstruction error. The authors propose a tighter lower bound and a stronger attack, demonstrating the influence of hyper-parameters on reconstruction error. The study also introduces two new reconstruction attacks and a novel upper bound for attack success, significantly improving upon previous works. Furthermore, the authors propose adding an explicit threat model section to clarify misunderstandings and intend to incorporate all received feedback into the final version.

### Strengths and Weaknesses
Strengths:
- Originality: The paper introduces new theoretical analyses and attacks for training data reconstruction in DP-SGD.
- Clarity: The writing is well-structured and easy to follow.
- Significance: The practical implications of understanding ML models' robustness to reconstruction attacks are substantial.
- Quality: The empirical evaluation is extensive and supports the theoretical contributions.
- The consolidation of discussions is commendable, and the intention to clarify misunderstandings through an explicit threat model is a positive step.

Weaknesses:
- Presentation: Some assumptions and key novelties are vague, and the threat model lacks structure.
- Narrow scope: The proposed attack is limited to DP-SGD, potentially restricting its applicability.
- Clarity issues: Sections 3.1 and 3.2 are difficult to follow, and the significance of contributions is not clearly articulated.
- Lack of discussion on limitations and societal impacts.
- The current lack of a threat model section may lead to misunderstandings.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the threat model by providing a structured presentation, including separate sections for methods and baselines. Additionally, the authors should clarify the assumptions underlying the proposed attack and justify its practicality, particularly regarding the strong prior assumption. We suggest enhancing the discussion of the real-world implications of the findings, especially in the introduction. Furthermore, we encourage the authors to address the computational cost of the proposed methods and provide insights into the accuracy of the Monte Carlo estimates used for the bounds. Lastly, a discussion on the fuzzy boundary between reconstruction and attribute inference attacks should be included to clarify the novelty of the work.