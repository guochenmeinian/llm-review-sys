ID: Ur00BNk1v2
Title: GenArtist: Multimodal LLM as an Agent for Unified Image Generation and Editing
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 6, 5, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method utilizing an MLLM (GPT-4) as a task planner for image editing tasks, employing a catalog of off-the-shelf models as tools. The planner constructs a task tree, executes tasks, performs verification, and can backtrack. The authors claim contributions of a unified image generation and editing system, a planner capable of task tree construction and verification, and tool selection capabilities. The paper introduces a multi-modal agent for image generation and editing that decomposes tasks into subproblems, incorporating a self-correction module with verification feedback. Extensive experiments demonstrate promising results across benchmarks.

### Strengths and Weaknesses
Strengths:  
- The concept of using a strong planner to facilitate image editing aligns well with intuition and shows substantial improvements in quantitative evaluations.  
- The paper is well-written, with clear illustrations and strong results on benchmarks, demonstrating the effectiveness of the proposed method.  
- The authors conducted ablation studies, providing evidence for the importance of various components in the system.

Weaknesses:  
- The paper lacks citations for relevant works, such as Gupta et al.'s "Visual Programming: Compositional Visual Reasoning Without Training."  
- There is no comparison with other MLLMs, and contributions could be further refined.  
- The evaluation primarily relies on traditional metrics that may not align with human preferences, and there is insufficient analysis of common error cases or tool execution issues.  
- The initial image generation process may limit overall quality, and the paper does not adequately address limitations or provide technical details about the underlying model.

### Suggestions for Improvement
We recommend that the authors improve the paper by including comparisons with one or two additional MLLMs to better contextualize performance. It would also be beneficial to conduct deeper analyses of common error cases and more fine-grained ablation studies on tool execution. We suggest evaluating the system on additional benchmarks, such as GenAI-Bench and DreamBench++, to enhance the robustness of the findings. Furthermore, please clarify which version of GPT-4 was used for reproducibility and consider using the latest GPT-4o for all experiments, documenting the precise version in the paper. Lastly, we encourage a more thorough discussion of potential limitations related to initial image quality and editing artifacts.