ID: RMfiqfWAWg
Title: On Giant's Shoulders: Effortless Weak to Strong by Dynamic Logits Fusion
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 4, 7, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a dynamic logit fusion method aimed at enhancing the weak-to-strong generalization paradigm by adaptively allocating weights among a series of task-specific small models during decoding. The authors propose an objective that minimizes the Kullback-Leibler divergence between the logits of a small model before and after fine-tuning, thereby improving performance across various benchmarks. The experiments validate the method's effectiveness in both single-task and multi-task scenarios.

### Strengths and Weaknesses
Strengths:
- The article effectively reevaluates existing logit arithmetic methods, emphasizing the importance of fusion weights and the limitations of using a single small model.
- By employing constrained optimization, the method autonomously learns fusion weights, approximating the results of fine-tuning large foundational models.
- Comprehensive experiments demonstrate significant improvements in performance, generalization, and robustness.

Weaknesses:
- The theoretical foundation of the proposed method is undermined by assumptions lacking clear supporting evidence, particularly in Section 3.2.
- Multi-task experiments do not consistently show superiority, especially for CNN/DM, and performance on unseen tasks is not significantly improved.
- Evaluations are conducted solely in a 0-shot setting, raising questions about how results might differ in a 5-shot scenario.

### Suggestions for Improvement
We recommend that the authors improve the theoretical justification for their optimization problem, clarifying why matching KL divergence is the appropriate objective. Additionally, transparency regarding the computational cost of their method is essential, particularly concerning the feasibility of updating the parameter $\alpha$ at each decoding step. It may be beneficial to explore updating $\alpha$ less frequently, such as every 100 tokens. Furthermore, we suggest including a baseline for multi-task tuning in the experiments and providing a clearer description of the optimization method in the main text. Lastly, conducting experiments with smaller models than 7B could enhance understanding of the method's robustness across varying model sizes.