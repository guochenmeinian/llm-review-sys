ID: VJuSeShdZA
Title: Hidden in Plain Sight: Evaluating Abstract Shape Recognition in Vision-Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 7, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 1, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents IllusionBench, a collection of three datasets aimed at evaluating the shape recognition capabilities of vision-language models (VLMs). The authors demonstrate that while humans can identify abstract shapes with high accuracy, state-of-the-art VLMs struggle in zero-shot settings, often focusing on scene elements instead. The study finds that in-context learning does not significantly enhance performance, although fine-tuning CLIP models shows promise for recognizing shapes and generalizing across new domains. Additionally, the paper includes a comparative analysis of various models in predicting background and shape accuracy across different contexts and shot configurations, with results indicating significant variability in accuracy depending on the model and the number of shots used.

### Strengths and Weaknesses
Strengths:
- The paper introduces a novel benchmark for evaluating VLMs' capabilities in recognizing abstract shapes, filling a gap in existing datasets.
- It provides a thorough analysis of zero-shot recognition, few-shot learning, and domain generalization capabilities of VLMs.
- The dataset is publicly available on Hugging Face, promoting accessibility for future research.
- The paper offers a detailed evaluation of multiple models, presenting clear performance metrics and using statistical measures (Mean Â± SE) to enhance the credibility of the results.

Weaknesses:
- The paper lacks a comprehensive discussion of prior works, particularly overlooking HallusionBench, which affects the assessment of originality.
- Some analyses and conclusions drawn from the experiments may be questionable, and the writing could be clearer, with several formatting and typographical issues present.
- Certain models, such as llava16-7b, demonstrate consistently low accuracy across various configurations, raising questions about their effectiveness.
- The variability in performance across different models and configurations may complicate the interpretation of results.

### Suggestions for Improvement
We recommend that the authors improve the discussion of prior works, particularly HallusionBench, to better contextualize their contributions. Additionally, we suggest addressing the limitations of the human evaluation process, as the accuracy may be overreported due to priming effects. It would be beneficial to include an ablation study on prompt sensitivity, as the current results may be influenced by ineffective prompting. Furthermore, establishing a baseline for VLMs' ability to classify raw shapes before they are turned into illusions would strengthen the analysis. We also recommend that the authors improve the discussion on the implications of the observed performance variability among models and provide a more in-depth analysis of the factors contributing to the low accuracy of certain models, particularly llava16-7b. Lastly, we advise enhancing the clarity of the writing and fixing formatting issues, such as the missing reference on line 124 and the low resolution of Figure 8.