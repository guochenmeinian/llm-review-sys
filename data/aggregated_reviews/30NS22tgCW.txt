ID: 30NS22tgCW
Title: Optimal Scalarizations for Sublinear Hypervolume Regret
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 5, 6, 6, 7, -1, -1, -1, -1
Original Confidences: 2, 3, 2, 2, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on non-linear scalarization techniques for multi-objective optimization, specifically focusing on hypervolume scalarizations with random weights. The authors prove that this approach achieves optimal sublinear hypervolume regret bounds of $O(T^{-1/k})$ and derive a matching lower bound. They propose an optimization algorithm for multi-objective linear bandits and support their theoretical findings with empirical results, demonstrating the superior performance of non-linear scalarizations compared to linear alternatives and other standard multi-objective algorithms.

### Strengths and Weaknesses
Strengths:  
- The paper provides both theoretical and empirical analyses of hypervolume scalarization performance.  
- The proposed theoretical results are interesting and non-trivial, and the setting is well justified.  
- The authors thoroughly compare their contributions to previous work, and Lemma 5 offers good insight into the advantages of hypervolume scalarization.

Weaknesses:  
- There is significant overlap with prior work (Golovin and Zhang, 2020), and the authors should clarify their contributions relative to this reference.  
- The applicability of hypervolume regret in multi-armed bandit settings is questionable, particularly with finite action sets.  
- The authors' assumption regarding the reference point in hypervolume calculations may limit the generalizability of their results.  
- The paper does not adequately address the limitations of hypervolume as a scalarization method, including its dependency on the reference point and coverage of the Pareto front.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their contributions by explicitly summarizing the differences from Golovin and Zhang (2020). Additionally, the authors should provide a theoretical comparison of hypervolume scalarization with other scalarization methods, such as Chebyshev scalarization, to clarify how hypervolume regret scales with different functions. Furthermore, we suggest that the authors address the limitations of hypervolume in practical applications and consider providing concrete examples of scalarization to enhance readability.