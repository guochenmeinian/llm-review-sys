ID: EmxpDiPgRu
Title: Honesty Is the Best Policy: Defining and Mitigating AI Deception
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 8, 8, 7, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive theory of deception for learning agents in games, defining deception as intentionally causing a false belief that is not believed to be true. The authors operationalize belief as acceptance based on agent behavior and propose a causal notion of intention, critiquing Halpern and Kleiman-Weiner’s definition. They develop a formal account of deception in AI systems, particularly those lacking interpretable representations of mental states, grounded in structural causal games (SCGs). The authors conduct experiments with reinforcement learning (RL) agents and large language models (LLMs), demonstrating that agents can deceive according to their definition when no mitigation is present. Additionally, they explore instances of negative deception, such as causing ignorance, and propose a criterion for deception in structural causal games, applying it to an RL toy model and an LLM fine-tuning experiment.

### Strengths and Weaknesses
Strengths:  
- Originality: The authors provide an overarching theory of deception for learning agents, extending existing discussions in the literature.  
- Quality: The theoretical definitions and results are robust, integrating relevant philosophical and cognitive scientific literature, with proofs and clear explanations addressing non-intuitive issues in prior formalizations.  
- Clarity: The inclusion of additional examples and experiments, particularly with ChatArena, has strengthened the paper's arguments, although some sections remain dense.  
- Significance: The experiments illustrate the robustness of the theory, with findings on LMs claiming ignorance being particularly important, and the graphical criteria for diagnosing strategic scenarios of deception are intuitive and practical.

Weaknesses:  
- The critique of H&KW’s definition of intention is unconvincing; the authors' argument does not adequately address the intuitive understanding of intention.  
- The definition of deception is ambiguous, lacking clarity on who causes the false belief and who holds it.  
- The operationalization of belief and intention is not sufficiently clear, leading to confusion about the definitions and their implications in the experimental context.  
- The LLM experiments are presented inadequately, lacking sufficient detail for reproducibility and clarity in results, and the lack of statistical analysis in the experimental results diminishes the significance of the findings.  
- The definition of negative deception remains contentious, with some reviewers questioning whether it constitutes true deception.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their definition of deception to specify who is causing the false belief and who holds it. Additionally, we suggest enhancing the presentation of the LLM experiments by providing more detailed descriptions of the experiment setup and results, ensuring that all relevant information is accessible without needing to reference the appendix. It would also be beneficial to clarify how the deception criteria apply to the experiments, particularly in relation to the SCG formalism. 

We encourage the authors to address potential limitations of their formalism more explicitly, particularly in terms of how it aligns with human notions of belief. Furthermore, we recommend improving the discussion surrounding negative deception to address the concerns raised about its classification. Clarifying the distinction between "belief is unidentifiable," "does not have a true belief," and "ignorance" would enhance understanding. 

To improve the presentation of the zero-shot vs. few-shot experiments, we suggest creating a two-column table that clearly delineates descriptions and corresponding prompts or answers for GPT-4. Additionally, including more statistical analysis of the experimental results, such as standard deviations over multiple random seeds, would strengthen the significance of the findings. Expanding the experiments to include different settings, such as various fine-tuning methods, would also be beneficial. Lastly, we encourage the authors to provide a more concrete description of the RL fine-tuning process, possibly through additional examples or visual aids, to better convey the quality and significance of their findings.