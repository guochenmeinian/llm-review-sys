ID: ZizwgYErtQ
Title: Contextual Active Model Selection
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 4, 5, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Contextual Active Model Selection (CAMS) method aimed at the online contextual active model selection problem, where the learner selects the optimal pre-trained model for each data point while minimizing labeling costs. The authors propose a CAMS algorithm that integrates a contextual model selection mechanism with an active query strategy, supported by theoretical analyses of regret and query complexity in both adversarial and stochastic settings. Empirical evaluations demonstrate that CAMS significantly reduces labeling effort while maintaining or improving accuracy across benchmark tasks.

### Strengths and Weaknesses
Strengths:
- The integration of contextual model selection with an active query strategy is a novel approach that effectively addresses model selection challenges while minimizing labeling costs.
- The paper provides rigorous theoretical guarantees, including detailed proofs and analyses of regret and query complexity.
- Empirical results are strong, showing significant reductions in labeling effort while maintaining or improving accuracy across various benchmarks.

Weaknesses:
- The method lacks a discussion on handling dynamic updates to the set of classifiers, limiting its robustness and adaptability in practical applications.
- The empirical evaluation could benefit from more recent and complex datasets, as well as comparisons with a broader set of state-of-the-art methods.
- Some mathematical notations are dense and could be clarified further, particularly regarding the derivation and intuition behind specific choices.
- The effectiveness of CAMS is heavily reliant on the quality of pre-trained models, and the theoretical guarantees are derived under strong assumptions.

### Suggestions for Improvement
We recommend that the authors improve the discussion on how CAMS handles scenarios where the set of pre-trained classifiers is not fixed or continuously updated. Additionally, the authors should consider including more recent and complex datasets in their empirical evaluations and broaden their comparisons to include state-of-the-art methods. Clarifying the mathematical notations and providing more detailed explanations of the derivations would enhance understanding. Finally, the authors should explore the stability of empirical results across multiple runs to provide a clearer picture of the method's reliability.