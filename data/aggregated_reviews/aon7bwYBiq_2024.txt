ID: aon7bwYBiq
Title: Differentially Private Graph Diffusion with Applications in Personalized PageRanks
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 8, 5, 5, 4, -1
Original Confidences: 4, 3, 2, 3, -1

Aggregated Review:
### Key Points
This paper presents a novel graph diffusion framework that ensures edge-level differential privacy (DP) by injecting Laplace noise into the diffusion process, leveraging Privacy Amplification by Iteration (PABI). The authors provide a rigorous theoretical analysis of privacy guarantees, including a new method for tracking privacy leakage using the âˆž-Wasserstein distance. Empirical evaluations demonstrate that the proposed method outperforms existing baselines in the context of Personalized PageRank (PPR) computation, achieving better privacy-utility trade-offs.

### Strengths and Weaknesses
Strengths:
- The paper addresses an important problem in graph learning with privacy, proposing a novel algorithmic method that could impact various graph problems.
- The theoretical guarantees for privacy are well-established, enhancing the credibility of the work.
- Extensive empirical analysis shows significant improvements over prior methods, particularly under stringent privacy conditions.

Weaknesses:
- The paper lacks theoretical lower bounds demonstrating the tightness of the method.
- The complexity of implementation due to advanced theoretical constructs may hinder practical adoption.
- The focus on a single application (PPR) limits generalizability, and scalability concerns for large graphs are not adequately addressed.
- The paper is difficult to read, overloaded with advanced mathematical terms that are not well-defined, making it less accessible.

### Suggestions for Improvement
We recommend that the authors improve the accessibility of the paper by providing more intuitive explanations of the approach, including a paragraph on Figure 1 and simplified presentations of key results. Additionally, including pseudocode in the appendix could enhance clarity. To address scalability, we suggest conducting further experiments or discussions on computational efficiency. Finally, we encourage the authors to explore the potential for extending their framework to node differential privacy or other graph diffusion processes beyond PPR, as well as discussing the implications of parameter tuning on performance.