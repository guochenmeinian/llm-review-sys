ID: jA235JGM09
Title: Jailbroken: How Does LLM Safety Training Fail?
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 5, 6, 6, 6, 6, 8, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an examination of "jailbreak" attacks against large language models (LLMs) such as GPT-4 and Claude v1.3, identifying two primary failure modes: competing objectives and mismatched generalization. The authors conduct empirical evaluations to analyze the success of these attacks and propose hypotheses regarding the underlying causes of these vulnerabilities. The paper aims to initiate a discussion on improving safety training for LLMs.

### Strengths and Weaknesses
Strengths:
1. The paper addresses a timely and significant topic, providing a comprehensive examination of vulnerabilities in LLMs to jailbreak attacks.
2. The authors present intuitive and compelling hypotheses, supported by well-designed empirical experiments, and derive valuable defense implications from their analysis.

Weaknesses:
1. The paper lacks rigor in defining key concepts, such as what constitutes a jailbreak attack, and fails to quantify its statements adequately.
2. The empirical studies do not sufficiently distinguish themselves from existing research, lacking in-depth formalism and robust evaluations.
3. The results do not directly support the claims regarding the causes of jailbreaks, and the analysis could benefit from clearer organization and more detailed discussions.

### Suggestions for Improvement
We recommend that the authors improve the clarity and rigor of their definitions, particularly regarding jailbreak attacks and safety training concepts. Additionally, we suggest conducting more in-depth experiments and ablations on safety training to provide concrete evidence supporting their claims. The dataset discussion in Section 2.2 should be organized more clearly to enhance comprehension. Finally, addressing the relationship between competing objectives and mismatched generalization in greater detail would strengthen the paper's arguments.