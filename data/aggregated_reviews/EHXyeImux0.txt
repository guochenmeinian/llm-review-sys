ID: EHXyeImux0
Title: Data Mixture Inference Attack: BPE Tokenizers Reveal Training Data Compositions
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 7, 5, 6, 5, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the novel task of data mixture inference, aiming to uncover the composition of pretraining data for large language models (LLMs) by leveraging the ordered merge rules learned by BPE tokenizers. The authors formalize the problem and propose a solution using linear programming, enhanced by computational optimizations that make the inference feasible. They demonstrate the method's effectiveness through controlled experiments with known data mixtures and apply it to widely used LLMs, revealing significant insights into their training data composition.

### Strengths and Weaknesses
Strengths:
- Originality: The paper introduces the previously understudied problem of data mixture inference, providing a compelling method to address it.
- Quality: The task is well formalized, and the proposed method is technically sound, with convincing evaluations in controlled setups and applications to other models.
- Clarity: The paper is clearly written and well-organized, enhancing its accessibility.
- Significance: The attack reveals proprietary information about model training data, which is valuable to the field.

Weaknesses:
- Generalizability: The attack is specifically tailored to BPE tokenizers, limiting its applicability to other tokenization methods.
- Experimental Baselines: The reliance on random guessing as the sole baseline is na√Øve; more sophisticated baselines are needed to demonstrate the method's superiority.
- Theoretical Analysis: The theoretical underpinnings of the proposed algorithm lack guarantees for convergence and robustness against sampling errors.

### Suggestions for Improvement
We recommend that the authors improve the theoretical analysis by providing convergence guarantees for the proposed algorithm and exploring the impact of different preprocessing techniques on the effectiveness of the attack. Additionally, the authors should include results from more sophisticated baselines, such as leveraging encoding efficiency or perplexity metrics, to better contextualize the performance of their method. Furthermore, elaborating on potential defenses against the attack would enhance the significance of the work, particularly regarding the implications of knowing the composition of pretraining data and how it could facilitate targeted data poisoning attacks.