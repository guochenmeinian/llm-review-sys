ID: CyzZeND3LB
Title: PAC-Bayes-Chernoff bounds for unbounded losses
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 7, 7, 7, 6, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 2, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new oracle PAC-Bayesian bound that is valid for unbounded losses and allows for exact optimization of the free parameter $\lambda$, incurring only a logarithmic penalty in the number of data points. The authors recover existing bounds and enhance them by introducing model-dependent assumptions, linking their findings to regularization techniques. They also derive new bounds based on input-gradients by integrating their theory with log-Sobolev-type inequalities.

### Strengths and Weaknesses
Strengths:
- The exact optimization of the free parameter $\lambda$ is a significant contribution, potentially useful in various contexts.
- The proofs utilize general bounded cumulant generating function (CGF) assumptions, which are weaker than typical bounded loss assumptions, accommodating model-dependent scenarios.
- The paper provides PAC-Bayesian bounds with a stronger dependence on the posterior distribution, enhancing the practical relevance of PAC-Bayesian theory.

Weaknesses:
- The comparison of main results with existing bounds, particularly those using grids and union bounds, is unclear and should be explicitly detailed.
- Including examples where the new bounds outperform existing ones would strengthen the paper.
- Additional technical background on the generalized inverse would improve readability, as it is a key technical component.
- Clarification is needed regarding the log-Sobolev inequalities mentioned, as they appear stronger than standard inequalities.
- There may be an error in Theorem 1 regarding the term $1/(\lambda n)$, which should possibly be $1/\lambda$.

### Suggestions for Improvement
We recommend that the authors improve clarity by explicitly comparing their results with existing PAC-Bayesian bounds that lack a $\log(n)$ penalty or free parameters for unbounded losses. Including concrete examples demonstrating the superiority of the new bounds would enhance the paper's impact. Additionally, providing more technical background on the generalized inverse and clarifying the nature of the log-Sobolev inequalities would aid comprehension. We also suggest revisiting the statement of Theorem 1 to correct the potential error regarding the term $1/(\lambda n)$.