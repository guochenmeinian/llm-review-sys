ID: 1RVUxlrFJZ
Title: Can Retriever-Augmented Language Models Reason? The Blame Game Between the Retriever and the Language Model
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive evaluation of reasoning in retriever-augmented language models (RA-LMs), utilizing existing reasoning datasets, EntailmentBank and StrategyQA, augmented with distraction statements. The authors characterize the strengths and weaknesses of both the retriever and language modeling components through controlled evaluations. Key findings indicate that similarity-based retrieval mechanisms are limited in selecting useful statements for reasoning, language models struggle even with noise-free statements, and performance drops when retrieved statements are insufficient. The authors also explore multi-hop retrieval, which enhances performance in larger models but fails to generalize to smaller ones.

### Strengths and Weaknesses
Strengths:
- The controlled evaluation of RA-LMs addresses an understudied topic effectively.
- Experiments are thorough, and results support the conclusions.
- The paper is well-written and organized, providing insightful findings.

Weaknesses:
- The main text lacks sufficient detail on the method for creating distraction statements, which is critical for understanding the results.
- The novelty of findings is limited, as many issues are already known in the literature.
- All models are evaluated without fine-tuning, which limits understanding of their performance capabilities.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the method for creating distraction statements by moving it to the main text and providing a detailed characterization with examples. Additionally, we suggest enhancing the description of multi-hop retrieval to clarify its distinction from the ground truth statement setting. To strengthen the paper, consider discussing any conjectures regarding why language models do not exhibit perfect reasoning even with oracle statements. Finally, we encourage the authors to cite relevant literature, such as the COMPS and Surface Form competition papers, to contextualize their findings better.