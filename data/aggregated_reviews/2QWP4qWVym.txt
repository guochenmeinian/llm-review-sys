ID: 2QWP4qWVym
Title: Fairness Evaluation with Item Response Theory
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Fair-IRT framework, which innovatively applies Item Response Theory (IRT) to evaluate fairness in machine learning models. The authors propose a methodology that treats predictive models as respondents and individuals as test items, focusing on the "Situation Test Score" (STS) as a fairness metric. The main contributions include a methodological workflow for fairness evaluation and empirical validation using simulated models and real-world datasets, specifically the Adult and Law School datasets.

### Strengths and Weaknesses
Strengths:
- The application of the IRT framework to fairness evaluation is novel and provides a promising approach to understanding fairness in machine learning.
- The paper effectively combines theoretical derivations with practical experiments, offering interpretable insights into fairness metrics.
- The framework's ability to disentangle sources of unfairness through flatness analysis of Item Characteristic Curves (ICCs) and the Rasch beta IRT model is a significant contribution.

Weaknesses:
1. The choice of models evaluated is crucial, yet the paper lacks a detailed discussion on how this selection impacts the validity of inferred parameters ($\theta, \delta, \alpha$).
2. Assumption 1 is vague; it should be clarified how it enables the estimation of the $\theta, \delta, \alpha$ parameters.
3. The estimation details for the parameters $\theta, \delta, \alpha$ and the computation of $STS_{ij}$ are insufficiently described, particularly regarding Algorithm 1 and the definitions of "loss" and "3-parameter beta IRT."
4. The primary fairness measure, STS, is critiqued for being trivial and not the most relevant for machine learning contexts; alternative fairness metrics should be explored.
5. The extensions to demographic parity and equal opportunity lack meaningful differentiation from STS, necessitating a reevaluation of these claims.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the selection process of the evaluated models to address potential validity issues of the inferred parameters. Additionally, we suggest clarifying Assumption 1 with technical details on its implications for estimating the $\theta, \delta, \alpha$ parameters. The authors should provide more comprehensive details on the estimation process for these parameters and the computation of $STS_{ij}$, including the definitions of key terms in Algorithm 1. To enhance the framework's applicability, we encourage the authors to incorporate alternative fairness metrics and demonstrate their method using these metrics. Lastly, we advise revisiting the extensions to demographic parity and equal opportunity to ensure they are meaningfully distinct from the STS measure.