ID: vM5VnNQ4n7
Title: Exploiting Correlated Auxiliary Feedback in Parameterized Bandits
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 5, 4, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study of a variant of the parameterized bandits problem where the learner has access to auxiliary feedback correlated with the observed reward. The authors propose a method that utilizes this auxiliary feedback to create a reward estimator with improved confidence bounds, leading to reduced regret. They clarify that their algorithm does not require reward samples to estimate auxiliary functions, which can be derived from historical auxiliary feedback. The authors characterize the regret reduction based on the correlation coefficient and validate their approach through numerical experiments. They also extend control variate theory to contextual bandit problems, providing both theoretical and empirical results. The paper addresses a significant gap in bandit literature by incorporating auxiliary feedback, which is often available in real-life applications, and discusses the construction of unbiased estimators for auxiliary functions, acknowledging the challenges posed by bias in practical applications.

### Strengths and Weaknesses
Strengths:
1. The setting explored is relevant and realistically challenging, addressing the use of auxiliary feedback for online decision-making.
2. The organization of the paper is commendable, with sound theoretical results and a comprehensive literature review connecting their work to prior research.
3. The paper is well-written and easy to follow, effectively applying control variate theory to improve reward estimation.
4. The theoretical framework demonstrates how correlated auxiliary feedback can lead to performance improvements in parameterized bandit algorithms.

Weaknesses:
1. The description of the algorithm (OFUL-AF) lacks clarity, appearing as a rephrasing of steps without clear connections to prior derivations.
2. The selection procedure for the number of auxiliary feedback $q$ is not sufficiently detailed, requiring further clarification beyond Remark 1.
3. The regret bound in Theorem 2 includes hidden constant terms that need elaboration regarding their magnitude and impact.
4. The authors acknowledge the challenge of unknown auxiliary feedback functions, yet further explanation on obtaining unbiased estimators is necessary.
5. The assumptions regarding unbiased estimators of auxiliary functions may not hold in all real-world scenarios, potentially limiting the applicability of the proposed method.
6. There is a lack of theoretical quantification of the relationship between bias in auxiliary feedback and regret, which could provide deeper insights into the method's robustness.
7. The terms $a(e)$ and $\rho_e$ in Theorem 3 need clearer definitions, and their implications within the regret bound should be discussed.
8. The experiments are overly simplified, lacking variation in the dimension of auxiliary feedback and not addressing the infinite arm setting in contextual bandits.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the algorithm description by explicitly linking each step to prior derivations. Additionally, provide more details on the selection of the number of auxiliary feedback $q$ and elaborate on the hidden constant terms in the regret bound. Address the challenge of obtaining unbiased estimators for auxiliary feedback functions more thoroughly. We suggest quantifying how bias in estimated auxiliary feedback affects regret to enhance the theoretical framework. Clarify the definitions and implications of the terms $a(e)$ and $\rho_e$ in Theorem 3. Finally, consider expanding the experimental settings to include varying dimensions of auxiliary feedback and discuss the extension of the algorithm to infinite arm settings in contextual bandits. Conducting experiments on real-world data could also validate the applicability of the proposed method and explore necessary modifications for practical implementation.