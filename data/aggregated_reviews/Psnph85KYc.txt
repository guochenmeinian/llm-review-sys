ID: Psnph85KYc
Title: Interpretable Graph Networks Formulate Universal Algebra Conjectures
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 6, 4, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel application of Artificial Intelligence (AI) in Universal Algebra (UA), proposing a methodology that integrates equational and topological characterizations with graph neural networks (GNNs) to explore UA conjectures. The authors introduce an algorithm for generating AI-ready datasets based on UA conjectures and an interpretable graph network layer (iGNN) to enhance transparency and explainability. Experimental results indicate that interpretable graph networks improve interpretability without sacrificing accuracy, validate existing conjectures, and identify subgraphs that may lead to new conjectures. The paper claims to generate the first dataset for UA, marking a significant contribution to the field.

### Strengths and Weaknesses
Strengths:
- The paper proposes a complete pipeline for dataset generation and interpretable prediction using GNNs, addressing a previously unexplored area in UA.
- The introduction of the iGNN enhances model interpretability and successfully identifies relevant subgraphs.
- The empirical results demonstrate the effectiveness of the proposed methods, with clear motivation and well-structured writing.

Weaknesses:
- The methodology is limited to finite lattices, potentially restricting insights into infinite algebraic structures.
- The focus on topological properties may exclude non-structural properties that could benefit from other interpretable models.
- Concerns regarding the scalability of the dataset generation algorithm and the meaningfulness of semantic concepts acquired via one-hot embeddings were raised.
- Comparisons with recent works are lacking, and the dataset generation process is described as straightforward.

### Suggestions for Improvement
We recommend that the authors improve the scalability of the dataset generation algorithm and clarify how it controls label distribution. Additionally, it would be beneficial to include comparisons with recent general graph explanation methods, such as GSAT, to strengthen the evaluation of the proposed method. We suggest providing results in a table format for better readability and addressing the limitations regarding the representation power of iGNNs, particularly in relation to tasks that may require more complex concept embeddings. Lastly, we encourage the authors to elaborate on how their methodology could integrate with existing theorem provers like Mace4 and Prover9, as this could enhance the practical implications of their work.