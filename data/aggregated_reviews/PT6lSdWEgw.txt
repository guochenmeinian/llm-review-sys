ID: PT6lSdWEgw
Title: Toxicity in Multilingual Machine Translation at Scale
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates "added toxicity" in machine translation (MT), focusing on translations from English into 164 languages using the HolisticBias dataset. The authors analyze the causes of added toxicity through layer-wise attention weight contributions and robustness measures, finding that low-resource languages exhibit higher levels of added toxicity. They provide three suggestions for mitigating toxicity: curating training data, reducing hallucinations, and enhancing translation robustness.

### Strengths and Weaknesses
Strengths:
- The authors conducted extensive experiments across a large set of language pairs.
- The paper is well-written and accessible, with strong analysis in the human evaluation section.
- It presents a detailed empirical study that contributes significantly to the understanding of added toxicity in MT.

Weaknesses:
- The statistical findings are not sufficiently convincing, with some results lacking clarity and precision.
- Certain experimental decisions are inadequately justified, and key citations are missing.
- The organization of the paper could be improved, particularly in the methodology and experimental settings.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their statistical results and provide more detailed justifications for their experimental choices. Additionally, addressing the missing citations, particularly regarding human evaluation, would strengthen the paper. We suggest reorganizing the methodology section for better clarity and ensuring that all terms and axes in figures are clearly defined. Finally, we encourage the authors to clarify their assumptions regarding the relationship between hallucination and low source contribution.