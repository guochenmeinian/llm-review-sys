ID: KgcuY2KIkf
Title: Systematic word meta-sense extension
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the "Systematic Word Meta-Sense Extension" (SWORME) framework, which aims to systematically expand word meanings to convey new semantic domains through analogical and associative chaining. The authors propose two new learning objectives to fine-tune pretrained language models, focusing on systematic metaphorical relations between polysemous words. The framework is empirically validated using a SWORME usage dataset, demonstrating improved performance in figurative language tasks, particularly with analogical chaining outperforming associative chaining.

### Strengths and Weaknesses
Strengths:
- The SWORME framework offers a novel method for systematically extending word meanings, enhancing language models' understanding of language nuances.
- The paper is well-written, with a clear connection to established theories of lexical semantics and robust empirical results.
- The approach is grounded in linguistic and cognitive science, making it straightforward to implement and understand.

Weaknesses:
- The scalability of the approach to larger models and diverse datasets is uncertain, as sense-tagged datasets are not common and can be expensive to create.
- The overall goal of the paper is somewhat unclear, particularly regarding whether it aims to test BERT's properties or to learn about sense alternations and productivity.
- The qualitative analysis is brief, and the task may not adequately address non-documented meaning alternations.

### Suggestions for Improvement
We recommend that the authors clarify the overall goal of the paper in the introduction, specifying whether it focuses on testing language models or understanding sense alternations. Additionally, we suggest that the authors explore potential performance regressions on non-figurative language tasks compared to original language models. To enhance clarity, the authors should provide more examples of different sense alternations and elaborate on the rationale behind token substitution earlier in the paper. Finally, addressing the challenges of dataset creation and its implications for the framework's applicability would strengthen the discussion.