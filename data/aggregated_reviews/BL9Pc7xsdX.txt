ID: BL9Pc7xsdX
Title: Fast Model DeBias with Machine Unlearning
Conference: NeurIPS
Year: 2023
Number of Reviews: 22
Original Ratings: 5, 6, 7, 8, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an approach to removing biases from trained models without full retraining or requiring large annotated datasets. The proposed method, Fast Model Debiasing (FMD), involves three steps: identifying biased attributes, determining contributing examples using influence functions, and applying an unlearning procedure via a Newton step to mitigate the influence of harmful samples. The authors claim that their method outperforms certain baselines on simple datasets. Additionally, the paper proposes a new post-processing method based on unlearning techniques aimed at enhancing individual fairness in machine learning models, while acknowledging the complexities and potential conflicts with group fairness. The manuscript includes supplementary results in NLP domains but faces challenges in demonstrating applicability to diverse vision applications due to difficulties in generating counterfactual images.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant issue in model bias and provides useful motivation for understanding biases in neural networks.
- The proposed method makes fewer assumptions than previous approaches and demonstrates empirical superiority over some baselines.
- The authors provide a comprehensive rebuttal and demonstrate a commitment to improving the manuscript based on reviewer feedback.
- The proposed method shows promise in enhancing individual fairness through innovative post-processing techniques.
- The structure of the paper is generally clear, and the proposed method can be implemented as a separate API for practical applications.

Weaknesses:
- Clarity issues exist in several sections, including imprecise statements and undefined variables in equations.
- The term "unlearning" is misapplied when referring to external samples; "debiasing" may be a more appropriate term.
- The experimental setup lacks confidence intervals, making it difficult to assess statistical significance, and the choice of baselines is questionable.
- The reliance on approximated counterfactual samples, particularly in datasets like CelebA, raises concerns about the completeness of the bias metric.
- The paper lacks a thorough discussion on the accuracy of influence score estimation in deeper networks, which could impact the method's performance.
- Important baseline methods, such as those proposed in [A4], are missing from the analysis.
- The experiments are conducted on simple datasets, raising concerns about the generalizability of the results to more complex models and datasets.

### Suggestions for Improvement
We recommend that the authors improve clarity by defining all variables and terms used in equations, particularly in sections discussing biased-effect evaluation and influence functions. Additionally, we suggest replacing the term "unlearning" with "debiasing" to avoid confusion. The authors should include confidence intervals in their experimental results and provide a rationale for the choice of baselines. They should also address the limitations of using approximated counterfactual samples in CelebA more extensively, outlining implications and strategies for addressing incompleteness in bias metrics. A deeper discussion on the accuracy of influence score estimation in deeper networks is necessary to mitigate concerns regarding performance. Finally, the authors should incorporate the missing baseline method [A4] and clarify the differences between their approach and this baseline to provide a more comprehensive view of their method's advantages. Expanding experiments to include more complex datasets and models, such as ImageNet or COCO, would strengthen the paper's contributions. A flow figure illustrating the FMD procedure could enhance understanding.