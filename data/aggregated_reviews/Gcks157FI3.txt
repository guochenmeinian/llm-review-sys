ID: Gcks157FI3
Title: MeshXL: Neural Coordinate Field for Generative 3D Foundation Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 6, 5, 4, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents MeshXL, a mesh generation model based on Neural Coordinate Fields (NeurCF), which encodes discretized coordinates of mesh vertices into a sequence of tokens. The authors propose an end-to-end transformer model trained on multiple datasets to generate high-quality 3D meshes. The method shows promise in outperforming existing baselines in both quantitative and qualitative results.

### Strengths and Weaknesses
Strengths:
- The approach leverages large-scale datasets and modern large language model techniques, producing high-quality 3D meshes.
- The paper establishes a fair evaluation metric, considering both generation scores and 3D mesh quality from a graphics perspective.

Weaknesses:
- The method's sequence length limitation restricts it to handling only 800 faces, making it challenging to generate complex meshes.
- The paper lacks clarity on the novelty of its contributions compared to prior works like PolyGen and MeshGPT, particularly regarding the advantages of single-stage training.
- There is insufficient evaluation of mesh quality, with metrics focusing on shape representation rather than triangulation quality, watertightness, and avoidance of self-intersections.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by providing a more detailed analysis of how their method differs from existing approaches like PolyGen and MeshGPT, particularly regarding the benefits of single-stage training. Additionally, we suggest incorporating objective metrics for evaluating mesh quality, such as the ratio of watertight meshes and triangulation quality. Addressing the potential generation of artifacts by integrating domain knowledge from traditional remeshing techniques would also enhance the robustness of the method. Finally, a time analysis of sampling and memory consumption should be included to provide a clearer understanding of the model's efficiency.