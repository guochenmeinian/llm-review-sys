ID: zv4UISZzp5
Title: IDGen: Item Discrimination Induced Prompt Generation for LLM Evaluation
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 7, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for generating dynamic prompts to evaluate large language models (LLMs), aiming to highlight performance gaps among different models. The authors introduce a prompt synthesis framework that includes two models for measuring question discriminative power and difficulty, utilizing “instruction gradient” and “response gradient” methods. The study claims to produce more challenging and discriminative prompts compared to existing datasets, validated through experiments with multiple state-of-the-art models.

### Strengths and Weaknesses
Strengths:
- The work addresses a significant issue in LLM evaluation, providing timely insights as models evolve.
- The generated prompts are shown to be more challenging than baseline datasets, indicating their potential to effectively assess model capabilities.
- The release of over 3,000 questions enhances the dataset available for LLM evaluation.

Weaknesses:
- The reliance on LLMs to modify seed data raises concerns about the quality and reliability of the generated prompts, as errors may accumulate through the pipeline.
- The paper lacks clarity in its structure, making it difficult to follow, with many concepts inadequately described or referenced.
- There is insufficient validation of the generated test set's effectiveness compared to human-annotated datasets, and the diversity of the data used is not analyzed.

### Suggestions for Improvement
We recommend that the authors improve the clarity and flow of the paper to enhance readability, addressing the structural issues that hinder comprehension. Additionally, we suggest providing detailed descriptions of the “instruction gradient” and “response gradient” methods, as these are central to the question generation process. It would also be beneficial to include experiments that verify the robustness of each step in the data generation pipeline and to clarify how prompts are generated in relation to individual language models. Furthermore, we encourage the authors to explore the potential biases introduced when using a single LLM for data generation and consider employing a panel of LLMs as evaluators to mitigate this issue.