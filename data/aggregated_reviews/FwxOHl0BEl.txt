ID: FwxOHl0BEl
Title: Neural Network Reparametrization for Accelerated Optimization in Molecular Simulations
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 6, 6, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel neural network reparameterization approach as an alternative to traditional coarse-graining methods for molecular simulations. The authors propose a model that dynamically adjusts system complexity, allowing for increased degrees of freedom when necessary, thereby enhancing energy minimization and convergence. By fitting a neural network to map reduced space to fine-grained space, the approach maintains continuous access to fine-grained modes and eliminates the need for force-matching. The framework incorporates arbitrary neural networks, such as GNNs, achieving significant improvements in molecular simulations, particularly in optimizing energy minimization and convergence speeds.

### Strengths and Weaknesses
Strengths:
1. The proposed neural network reparameterization eliminates force-matching and non-unique back-mapping issues in traditional coarse-graining methods, showing potential for enhancing molecular simulations.
2. The innovative use of the Hessian matrix provides a precise framework for identifying slow modes, capturing essential collective motions without requiring an encoder-decoder for fine-grained to coarse-grained mapping.
3. The model's ability to dynamically adjust effective degrees of freedom results in more accurate representations of the system by effectively exploring the energy landscape.
4. The authors provide solid mathematical derivation and demonstrate promising experimental results on synthetic systems and protein folding simulations.

Weaknesses:
1. The manuscript lacks organization, making it difficult to follow; the introduction and background should be restructured to clarify the key challenge and contributions.
2. The absence of a high-level overview of the workflow and unclear roles of neural network reparameterization and Hessian in the overall approach lead to confusion.
3. Critical details, such as GNN training specifics and loss function, are missing, hindering the assessment of the method's soundness.
4. The neural network model does not introduce novel ML techniques, raising questions about its necessity compared to simpler methods.
5. The experimental section lacks clarity regarding settings, results, and conclusions, and the literature review is insufficient.

### Suggestions for Improvement
We recommend that the authors improve the manuscript's organization by restructuring the introduction and background to first present the key challenge and contributions, while moving detailed discussions to the Methods section. Additionally, we suggest providing a clear high-level overview of the workflow, including a flowchart or algorithm illustrating the coarse-graining process and GNN structure. The authors should include crucial details about GNN training and the loss function to enhance the assessment of their method's soundness. A more thorough justification for the use of a neural network over simpler methods is necessary. Furthermore, the authors should clarify the experimental settings and results, and strengthen the literature review by citing relevant works on optimization in molecular systems.