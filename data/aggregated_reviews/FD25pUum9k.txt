ID: FD25pUum9k
Title: Faithfulness and the Notion of Adversarial Sensitivity in NLP Explanations
Conference: EMNLP/2024/Workshop/BlackBoxNLP
Year: 2024
Number of Reviews: 3
Original Ratings: -1, -1, -1
Original Confidences: 4, 4, 4

Aggregated Review:
### Key Points
This paper presents a faithfulness test for model explainers that evaluates their sensitivity to adversarial inputs, utilizing a distance measure based on Pearson correlation. The authors conduct comprehensive experiments on six post-hoc explainers across three text classification datasets, revealing that perturbation-based methods exhibit greater sensitivity to adversarial examples (AEs) than vanilla gradient-based methods. The work addresses critical issues in evaluating explanation faithfulness, particularly the out-of-distribution (OOD) problem and the bias towards single explanation approaches.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, structured, and motivated, making a significant contribution by introducing sensitivity to adversarial input as a metric for evaluating explainers.
- The experimental design is comprehensive, showcasing a variety of explanation methods and yielding important findings regarding the sensitivity of different explainers to adversarial inputs.
- The work tackles important challenges in explanation evaluation, providing a novel perspective on adversarial sensitivity.

Weaknesses:
- The experiments are limited to two similar models, BERT and Distill BERT, and it would be beneficial to explore the approach with other models.
- The definition of adversarial sensitivity is questioned, as it relies on assumptions that may not hold true in all cases. Additionally, some notation and design choices lack clarity, which could hinder reproducibility.
- The results and discussion sections could be better structured, with some results not sufficiently discussed and certain evaluation choices needing reconsideration.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their definitions and notations, particularly regarding adversarial sensitivity and the assumptions underlying it. Explicitly defining the model in Definition 1 and ensuring that all notation is well-defined would enhance reader understanding. Additionally, we suggest including an example or figure to illustrate adversarial examples and their expected behavior with explainers. Simplifying unnecessary mathematical notations and merging equations could improve readability. Furthermore, evaluating the approach with a broader range of models would strengthen the findings. Lastly, we advise restructuring the results and discussion sections for better coherence and ensuring that all results are thoroughly analyzed, particularly in relation to the implications of the findings.