ID: fOQunr2E0T
Title: Compositional Generalization Across Distributional Shifts with Sparse Tree Operations
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 7, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel representation called Sparse Coordinate Trees (SCT) that enhances the efficiency of Differentiable Tree Machines (DTM) by improving parameter and memory usage. The authors demonstrate that SCTs facilitate efficient tree operations through bit-shifting and indexing, and they apply pruning to maintain sparsity. The method is adapted for sequential tasks, expanding its applicability beyond traditional tree structures. Additionally, the authors analyze the sDTM model, addressing concerns regarding whitespace and the clarity of experimental purposes. They propose to enhance the exposition by clarifying the role of transformers in the control flow mechanism and differentiable synthesized programs. Experimental results indicate that SCTs outperform previous methods in various tasks, although some performance inconsistencies are noted, particularly in comparisons between DTM and sDTM on the SCAN task.

### Strengths and Weaknesses
Strengths:
- The paper is professionally written and clearly structured.
- Significant reductions in parameters and memory usage are achieved compared to the original DTM.
- The efficiency of operations is notably improved.
- A comprehensive suite of experiments is conducted across multiple task types, showcasing the advantages of sDTM.
- The authors have effectively clarified concerns and improved the clarity of the paper.
- The storyline through the experimental section has been enhanced, making the benefits of the model more apparent.
- The novelty of the work, particularly in relation to DTM, is now clearer.

Weaknesses:
- The descriptions of the left, right, and cons functions lack clarity, which is central to the methods.
- The experimental section suffers from excessive white space, and the presentation of results could be more concise.
- The dataset used in Table 1 does not provide a meaningful challenge, as many methods achieve near-perfect scores.
- Comparisons to DTM are limited, raising questions about performance differences beyond resource efficiency.
- The capability differences between DTM and sDTM remain unclear from the current experiments.
- The method shows poor performance on specific tasks, such as MCD and length experiments, and the presentation of results is inconsistent.
- Some reviewers feel that the results have not improved sufficiently across the board to justify a higher rating.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the left, right, and cons functions to better convey their roles in the methodology. Additionally, we suggest reducing white space in the experimental section and enhancing the presentation of results to make better use of space. It would be beneficial to include DTM in more experiments, particularly in the SCAN task comparison, to clarify performance differences and illuminate capability differences between DTM and sDTM. Furthermore, we encourage the authors to address the potential for sDTM to get stuck in local optima in the camera-ready version and to provide more detailed evaluations of the datasets used. Finally, addressing the poor performance on specific tasks and ensuring consistent presentation of results across tables would strengthen the paper.