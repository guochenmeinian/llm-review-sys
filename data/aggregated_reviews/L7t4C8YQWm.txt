ID: L7t4C8YQWm
Title: Globally Interpretable Graph Learning via Distribution Matching
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel globally interpretable graph learning problem, aiming to provide global interpretations that allow for model recovery. The authors propose a Graph Distribution Matching (GDM) approach, which aligns feature distributions between original and interpretation graphs. The paper analyzes existing global interpretation methods, revealing limitations in model fidelity, and demonstrates that GDM effectively preserves predictive logits while achieving high accuracy. The significance of GDM lies in its potential to enhance transparency for model developers and understanding for consumers.

### Strengths and Weaknesses
Strengths:
- The introduction of a model fidelity metric evaluates the trustworthiness of interpretation graphs.
- The GDM approach synthesizes interpretive graphs from a distribution matching perspective, preserving intermediate GNN information.
- Experimental results validate GDM's effectiveness over baselines, with qualitative analyses confirming the correlation of generated graphs with human-intelligible patterns.

Weaknesses:
- The optimization problem in Eq. (2) is confusing, particularly regarding the differences between GDM and GDM-Ensemble.
- The connection between the distribution matching loss in Eq. (4) and MMD needs clarification, especially concerning the feature space.
- The necessity of feature matching regularization in real-world graphs requires further validation, as indicated by results in Table 5.
- The large number of parameters raises concerns about computational and storage demands, particularly for high-edge graphs.
- The definitions of model fidelity, model utility, and predictive accuracy are vague, weakening the credibility of results.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the optimization problem in Eq. (2) and explicitly outline the differences between GDM and GDM-Ensemble. Additionally, we suggest providing a detailed explanation of the connection between the distribution matching loss and MMD, particularly regarding the feature space. Further results should be included to validate the necessity of feature matching regularization. We also encourage the authors to add a space cost analysis for the model and clarify the experimental settings for obtaining ground truth graph patterns. Finally, we recommend visualizing different snapshots of the learned graph structure to enhance the ablation study.