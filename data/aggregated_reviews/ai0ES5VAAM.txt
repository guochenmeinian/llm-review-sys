ID: ai0ES5VAAM
Title: Inverting cognitive models with machine learning to infer preferences from fixations
Conference: NeurIPS
Year: 2023
Number of Reviews: 4
Original Ratings: 6, 8, 4, -1
Original Confidences: 3, 3, 4, 5

Aggregated Review:
### Key Points
This paper presents a novel method to infer individual preferences from observable behavior, specifically scanpaths, by generating synthetic data through a cognitive model and training a neural network on this data. The authors demonstrate that combining synthetic and real behavioral data enhances performance compared to using only real data. They also explore the estimation of utilities from eye-tracking data, employing simulated gaze data and various neural network architectures to reconstruct these utilities.

### Strengths and Weaknesses
Strengths:
* The evaluation of both synthetic-only training and fine-tuning with human data provides a reasonable estimate of the synthetic-to-real distribution difference.
* The reported accuracy on human data indicates that pre-training with synthetic data is advantageous, and the analysis shows that eye gaze data is beneficial beyond just knowing the final choice.
* A range of neural network architectures (LSTM, GRU, Transformer) are tested, with results included in the appendix, which is a positive aspect.

Weaknesses:
* The rationale and applicability of the cognitive model remain unclear due to the anonymous reference; including the full reference in third person would not compromise anonymity.
* While model inputs and outputs are described, section 2.3 lacks clarity and would benefit from graphical representations.
* The paper requires more foundational gaze considerations, which diminishes its overall contribution, and the significance of the approach is perceived as low.

### Suggestions for Improvement
We recommend that the authors improve the description of the data generation process and provide the full reference for the cognitive model used. Clarifying the number of participants behind the 2,965 trials would enhance the study's foundation. A deeper exploration of trial durations, eye tracker accuracy, and the event detection method is necessary for better understanding. Additionally, it is crucial to clarify whether the goal is to establish individual-specific relationships or a generalized cross-subject model, and to ensure a distinct split of participants between training and validation sets. We also suggest presenting correlations with ground truth data to capture underlying relationships more effectively and investigating the predictive outcomes around the pivotal time point relative to choice "0" for improved model predictability. Addressing these concerns will solidify the study's contributions and enhance its potential impact in the field.