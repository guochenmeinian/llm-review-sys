ID: oLoqHRbXYE
Title: Self-Taught Recognizer: Toward Unsupervised Adaptation for Speech Foundation Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 6, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Self-TAught Recognizer (STAR), a novel approach that enhances automatic speech recognition (ASR) systems by leveraging unlabeled data for domain adaptation. The method introduces a STAR Indicator, which integrates token-level quality assessments during decoding without requiring ground truth labels. The authors propose that STAR improves robustness in diverse target domains, supported by extensive experiments demonstrating its effectiveness. The paper is well-structured and the authors plan to release the code for reproducibility.

### Strengths and Weaknesses
Strengths:
- The proposed method is novel and well-articulated.
- Comprehensive experiments and analyses are provided.
- The presentation is clear and easy to follow.

Weaknesses:
- Concerns arise regarding STAR's performance compared to true-label models, particularly in real-world scenarios where organizations may afford limited transcription data.
- The paper lacks details on the specific layers or heads of attention weights used for the STAR Indicator and whether the confusion matrix was compared across layers.
- The methodology for uncertainty estimation, while novel, is not entirely original, and the evaluation is limited to specific models like Whisper, raising questions about broader applicability.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding which layers or heads of attention weights are utilized for the STAR Indicator, particularly in relation to Equation 5. Additionally, it would be beneficial to include comparisons of the confusion matrix across different layers. To enhance understanding, we suggest conducting experiments to determine how many hours of true-label data are equivalent to STAR's performance. Furthermore, addressing the limitations of the method in the main text, including discussions on latency, resource requirements, and scenarios where UDA may fail, would strengthen the paper. Lastly, we encourage the authors to explore the inclusion of cross-attention scores and provide more details on the threshold tuning for different corpora.