ID: eJU3FLg242
Title: T$^3$RD: Test-Time Training for Rumor Detection on Social Media
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents T3RD, a novel approach to enhance rumor detection in low-resource settings through test-time training. The authors propose a framework that employs self-supervised learning (SSL) as an auxiliary task during the test-time phase, facilitating model calibration for test samples. Additionally, a feature alignment technique is introduced to balance knowledge from training and test datasets. Extensive experiments validate the effectiveness of the proposed method on real-world low-resource rumor data.

### Strengths and Weaknesses
Strengths:
- The work addresses a critical issue in low-resource rumor detection, making it highly relevant to the social media landscape.
- The approach is innovative, utilizing test-time training in a well-structured manner rather than merely combining existing technologies.
- Experimental results are comprehensive, demonstrating superior performance compared to state-of-the-art methods.
- The paper is well-organized and clearly articulates the proposed methodologies and findings.

Weaknesses:
- The scalability of the proposed framework is not fully illustrated; testing on additional GNN-based models would enhance this aspect.
- The choice of datasets lacks justification, particularly regarding their relevance to COVID-19 and generalizability to other contexts.
- There is insufficient discussion on the model's applicability to different types of rumors and datasets.
- The manuscript does not adequately address reproducibility, including the release of the model and documentation of hyperparameter tuning.
- The comparison with other state-of-the-art models is limited, neglecting notable architectures like BERT and RoBERTa.

### Suggestions for Improvement
We recommend that the authors improve the justification for their dataset choices and discuss their implications for generalizability. Additionally, providing clear definitions and operational criteria for key terms such as 'rumors' and 'misinformation' would enhance clarity. We suggest that the authors conduct further experiments on additional GNN-based models to demonstrate the scalability of their framework. Addressing reproducibility by releasing the model and including detailed documentation on hyperparameter tuning is essential. Finally, we encourage the authors to expand their comparisons with other state-of-the-art models, particularly BERT and RoBERTa, and to clarify the impact of their proposed training strategy versus the backbone used.