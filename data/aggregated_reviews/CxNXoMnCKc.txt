ID: CxNXoMnCKc
Title: PrivacyLens: Evaluating Privacy Norm Awareness of Language Models in Action
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 7, 7, 8, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel framework, PrivacyLens, for evaluating privacy leakage in language model (LM) agents' actions. It introduces a data construction pipeline that expands sensitivity seeds into vignettes, which are then used to assess the LM's ability to predict actions without leaking sensitive information. The framework evaluates the interaction of LMs with tools like email and calendar applications, highlighting discrepancies between LMs' stated privacy norms and their actions in agentic setups.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and articulates the problem, dataset generation, and evaluation framework clearly.
- PrivacyLens is a robust framework that effectively identifies privacy leakage in state-of-the-art LMs, providing insights into the tradeoff between helpfulness and privacy awareness.
- The inclusion of marginalized groups in the dataset and the focus on real-world scenarios enhance the relevance of the research.

Weaknesses:
- The evaluation framework relies heavily on post-deployment data leakage risks, neglecting privacy considerations at the dataset curation and model training stages.
- The dataset is limited in scope, supporting only English and being USA-centric, which may not capture the diversity of privacy norms globally.
- The authors fail to incorporate several recent privacy regulations and frameworks, such as GDPR and California's CCPA, which are crucial for a comprehensive understanding of privacy norms.

### Suggestions for Improvement
We recommend that the authors improve the evaluation framework by incorporating assessments of data protection measures during the dataset curation and model training stages. Additionally, the authors should include recent normative privacy frameworks, such as NISTâ€™s Privacy Framework and GDPR, to enhance the comprehensiveness of their analysis. It would also be beneficial to explore the safety-helpfulness tradeoff more deeply by conducting experiments with varying levels of conservativeness in agent instructions. Furthermore, the authors should clarify the definitions of key terms like 'seeds' and 'vignettes' earlier in the paper and consider the implications of using a temperature of 0 in evaluations. Lastly, we suggest providing more detailed documentation and examples to facilitate user understanding of the PrivacyLens framework.