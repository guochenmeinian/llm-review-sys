ID: VpGFHmI7e5
Title: Patch n’ Pack: NaViT, a Vision Transformer for any Aspect Ratio and Resolution
Conference: NeurIPS
Year: 2023
Number of Reviews: 7
Original Ratings: 6, 6, 5, 6, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an efficient training technique for Vision Transformers, termed Patch n’ Pack, which packs multiple images of varying resolutions into a single sequence for batch processing. The authors propose NaViT, a modified architecture that leverages this technique, demonstrating its effectiveness through extensive experiments on the JFT-4B dataset and various downstream tasks. The method achieves notable efficiency in pretraining and improved accuracy across different image resolutions during inference.

### Strengths and Weaknesses
Strengths:
1. The adaptation of general-purpose Transformers to handle different input image resolutions addresses a fundamental research problem, making the proposed technique significant for the community.
2. The comprehensive experiments showcase impressive efficiency gains during pretraining.
3. The paper is well-structured and easy to follow, with high-quality presentation.

Weaknesses:
1. While packing examples into a single sequence is not novel in the literature, it is a new approach for ViT training.
2. Pretraining on JFT-4B is resource-intensive, complicating comparisons with subsequent works; experiments on ImageNet-1K would enhance the study.
3. The memory cost implications of the proposed Patch n’ Pack method remain unclear.
4. The architecture design of NaViT lacks sufficient detail for readers to fully grasp its components.
5. The novelty of the combined techniques—sequence packing, variable aspect ratio, and token dropping—requires clearer articulation against existing works.

### Suggestions for Improvement
We recommend that the authors improve the clarity of NaViT's architecture by providing a detailed introduction to its essential components. Additionally, we suggest including experiments on ImageNet-1K to facilitate comparisons with FlexViT and reporting memory consumption during pretraining. A more candid discussion of the limitations, particularly regarding compute overhead and architectural changes needed for example packing, would enhance the manuscript. Finally, addressing the relationship between "Patch n' Pack" and "Self-attention cost" would clarify the method's efficiency claims.