ID: 6ZXrvoIox1
Title: Beating Adversarial Low-Rank MDPs with Unknown Transition and Bandit Feedback
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 6, 6, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on online learning in low-rank Markov Decision Processes (MDPs) with adversarial losses and derives regret guarantees for three algorithms. The first is a model-based algorithm achieving $T^{2/3}$ regret under unknown loss feature vectors, utilizing a two-stage design with initial reward-free exploration. The second and third algorithms are model-free, both ensuring $T^{5/6}$ regret; the second assumes unknown loss features while the third assumes known features and adapts to adversarial strategies. The paper is notable for being the first to provide results for low-rank MDPs with adversarial (linear) losses under bandit feedback.

### Strengths and Weaknesses
Strengths:
- The paper addresses a novel and challenging problem, providing strong theoretical results and sound analyses.
- It effectively combines recent advancements in representation learning and low-rank MDPs, contributing valuable insights into regret bounds in a new setup.
- The introduction of a lower bound clarifies the limitations of low-rank structures compared to tabular MDPs.

Weaknesses:
- The computational cost of the proposed algorithms is significant, particularly for the oracle-efficient algorithms, and requires more discussion on complexity.
- The presentation lacks clarity in several areas, particularly regarding the definition of the "oracle," the implications of the regret bounds, and the challenges posed by adaptive adversaries.
- The first algorithm's design is similar to existing methods, which may underplay its novelty, and the paper lacks detailed explanations in critical sections.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the presentation by addressing the following questions:
1. Clearly define the "oracle" referenced throughout the paper and its relation to the VoX algorithm.
2. Explain the commonality of the $\Omega(\sqrt{A})$ regret in low-rank MDP literature versus its uniqueness due to adversarial losses.
3. Clarify the role of $\delta$ in Theorem 4.1 and ensure consistent notation throughout the paper.
4. Provide a smoother transition in Section 5 regarding the assumptions made for adaptive adversaries and elaborate on the specific challenges faced in this setting.
5. Consider moving Algorithm 4 to the appendix if it lacks novel modifications to save space for more informative content.
6. Include sketched proofs for deriving regret bounds in the main body to enhance understanding.
7. Discuss the computational complexity of the proposed algorithms in more detail.
8. If applicable, cite conference versions of references instead of arXiv when available.