ID: ghIBaprxsV
Title: Hierarchical Semi-Implicit Variational Inference with Application to Diffusion Model Acceleration
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 3, 6, 6, 6, 7, 6, -1, -1, -1
Original Confidences: 2, 3, 4, 4, 4, 2, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Hierarchical Semi-Implicit Variational Inference (HSIVI), an extension of Semi-Implicit Variational Inference (SIVI) that incorporates multiple layers of latent variables to enhance the expressiveness of variational posteriors. HSIVI utilizes interpolating distributions between prior and target data to progressively train conditional layers, thereby accelerating sampling in diffusion models. The authors claim that HSIVI can produce high-quality samples comparable to or better than existing fast diffusion model samplers with fewer function evaluations, as demonstrated through empirical results on datasets like CIFAR-10 and CelebA.

### Strengths and Weaknesses
Strengths:
- The paper is well-structured, clearly written, and effectively motivates the problem.
- HSIVI is a novel combination of established techniques, showing improved performance in sampling and distribution approximation.
- The empirical results indicate significant enhancements in sample quality across various tasks.

Weaknesses:
- The novelty of HSIVI compared to related work is insufficiently demonstrated, particularly in relation to existing methods like those by Yu and Zhang.
- The experimental section lacks depth, with limited diversity in the cases tested and no empirical failure cases provided.
- There is a need for more detailed discussions on related works and the implications of the training procedure, particularly regarding memory usage and computational complexity.

### Suggestions for Improvement
We recommend that the authors improve the novelty demonstration by including more related works and comparisons, such as cascaded diffusion models and diffusion Schr√∂dinger bridges. Additionally, enhancing the experimental section with a broader range of cases and empirical failure scenarios would strengthen the evaluation. It would also be beneficial to clarify the implications of the training procedure, particularly regarding memory requirements and the potential downsides of not training parameters jointly. Finally, providing code for reproducibility and discussing the computational complexity of HSIVI in comparison to existing methods would significantly enhance the paper's impact.