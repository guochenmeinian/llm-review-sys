ID: 716PvHoDct
Title: VPGTrans: Transfer Visual Prompt Generator across LLMs
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 6, 9, 4, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the transferability of a visual prompt generator (VPG) across various vision-language language models (VL-LLMs) to mitigate the high computational costs associated with training these models. The authors propose a two-stage transfer learning framework, VPGTrans, which includes a projector warm-up stage and a vanilla fine-tuning stage. Extensive experiments demonstrate the feasibility and effectiveness of VPG transfer, showing that smaller LLMs can lead to improved performance and reduced training costs. The paper also introduces two new state-of-the-art VL-LLMs, VL-LLaMA and VL-Vicuna.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and presents a comprehensive empirical study that effectively demonstrates the proposed method's efficiency.
2. The exploratory nature of the research provides valuable insights into the transferability of VPGs, which has significant implications for future research in multimodal large language models (MM-LLMs).
3. The proposed VPGTrans method is straightforward yet effective, yielding numerous meaningful findings that could guide future investigations.

Weaknesses:
1. The reliance on a well-functioning VPG model raises concerns about the transfer efficacy and efficiency if the quality of the existing VPG is subpar.
2. The evaluation is limited to captioning and VQA tasks, lacking broader coverage across different VL tasks and benchmark datasets.
3. The method's simplicity may lead to over-reliance on empirical tuning without sufficient theoretical support.
4. The comparison of training time between VPGTrans and traditional methods lacks fairness, as it does not account for the training time of the original smaller VL-LLM.
5. The paper's complexity in writing and the intricate training pipeline may pose challenges for practical implementation.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing to enhance understanding. Additionally, the authors should explore the impact of the existing VPG model's quality on transfer efficacy and provide insights into the theoretical foundations of the VPGTrans method. Expanding the evaluation to include a wider range of VL tasks and datasets would strengthen the findings. We also suggest that the authors conduct a more rigorous comparison of VPGTrans with traditional VPG transfer methods, including a detailed analysis of operational efficiency, execution time, and costs. Finally, clarifying the changes made to visual soft prompts during transfer and detailing the warm-up training process for the linear projector would provide valuable insights.