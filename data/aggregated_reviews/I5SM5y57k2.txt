ID: I5SM5y57k2
Title: On Robust Streaming for Learning with Experts: Algorithms and Lower Bounds
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 5, 6, 6, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 2, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper studies the memory complexity of the expert learning problem against an adaptive adversary. The authors propose a deterministic algorithm that achieves a memory usage of $\tilde O\left(\frac{nM}{RT}\right)$ and a randomized algorithm that uses $\tilde O\left(\frac{n}{R\sqrt{T}}\right)$ space. They also establish a lower bound of $\Omega\left(\frac{nM}{RT}\right)$ for any algorithm achieving regret $R$ with high probability. The work aims to characterize the memory-regret trade-off in this context.

### Strengths and Weaknesses
Strengths:
1. The paper addresses an important question regarding memory requirements against adaptive adversaries, marking a novel contribution to the field.
2. The algorithms presented are intuitive and well-explained, with a clear structure that enhances readability.

Weaknesses:
1. The proofs lack rigor in certain areas, with some claims appearing sloppy, particularly regarding constants in theorems.
2. The writing requires significant improvement, including the elimination of typos and unnecessary repetitions, and clarification of notations.
3. The results are limited to a discrete prediction setup, and the algorithms are relatively simple modifications of existing literature.

### Suggestions for Improvement
We recommend that the authors improve the rigor of their proofs, particularly clarifying the origin of constants in their claims. The writing should be revised to eliminate typos and redundancies, and to ensure consistent notation throughout the paper. Additionally, we suggest that the authors strengthen their results by exploring more specific algorithms tailored to the expert learning problem, as well as comparing their best randomized algorithm with the deterministic one in experiments. Finally, it would be beneficial to clarify the assumptions regarding the number of mistakes by the best expert and to discuss the implications of these assumptions on the generalizability of their results.