ID: gzCS252hCO
Title: Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 5, 8, 5, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Voicebox, a non-autoregressive flow-matching model designed for speech infilling, leveraging audio context and text. Voicebox can perform various tasks, including zero-shot text-to-speech synthesis, noise removal, content editing, and style conversion, utilizing a large-scale dataset of 50,000 hours of speech. The authors propose that Voicebox demonstrates superior performance compared to baseline methods across multiple speech generation tasks. Additionally, the paper includes a comparative analysis of flow-matching (FM) with optimal transport (OT) against other generative models, including token-based autoregressive models and regression-based non-autoregressive models. The authors assert that FM w/ OT demonstrates superior training and inference efficiency, supported by new experiments that confirm its performance advantages over FM w/ diffusion and score-matching (SM) w/ diffusion. They also address concerns regarding data size by comparing their model, Voicebox, trained on a subset of LibriTTS, with YourTTS, showing significantly better results.

### Strengths and Weaknesses
Strengths:
- The model effectively abstracts various speech tasks into a unified framework, showcasing versatility.
- It is trained on an extensive dataset, enabling in-context learning for speech style.
- The experimental results are comprehensive and demonstrate impressive performance across tasks.
- The authors provide empirical evidence demonstrating the effectiveness of FM w/ OT, achieving the best performance metrics in various training and inference scenarios.
- The inclusion of additional experiments enhances the robustness of the findings, particularly regarding data size and model efficiency.

Weaknesses:
- The originality of the work is questioned, as it appears to combine existing techniques without sufficient novelty.
- Comparisons with baseline models, particularly in zero-shot TTS, are deemed unfair due to differences in training datasets and model configurations.
- The audio quality in demo pages is criticized, and the presentation of results lacks clarity in certain areas.
- There is a noted gap in speaker similarity and sample diversity between the flow-matching and regression models.
- The authors did not initially compare all scenarios involving FM w/ OT, FM w/ diffusion, and SM w/ diffusion, which could have strengthened their claims.

### Suggestions for Improvement
We recommend that the authors improve the originality of the work by conducting more thorough comparisons with recent TTS models and speech editing techniques. Specifically, the authors should compare the conditional normalizing flow with diffusion-based models to validate their claims regarding performance advantages. Additionally, we suggest that the authors ensure all models are trained on the same dataset for fair comparisons and clarify the methodology used for generating audio samples. Improving the audio quality in demos and providing a more detailed discussion on how Voicebox handles various speech components would enhance the paper's clarity and impact. Furthermore, we recommend that the authors improve the comparison by including all scenarios (FM w/ OT, FM w/ diffusion, SM w/ diffusion) to verify the superiority of FM w/ OT for speech generative tasks. Lastly, we suggest adding the inference speed for each model in the final revision to provide a more comprehensive evaluation of performance and exploring the potential benefits of replacing HiFi-GAN with BigVGAN to improve audio quality.