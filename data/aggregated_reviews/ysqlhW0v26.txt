ID: ysqlhW0v26
Title: A Unifying Perspective on Multi-Calibration: Game Dynamics for Multi-Objective Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 4, 6, 6, 7, 5, -1, -1, -1
Original Confidences: 3, 4, 3, 1, 2, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to multicalibration by leveraging game dynamics and no-regret learning algorithms, modeling multicalibration as a multi-objective learning problem. The authors propose three dynamics: no-regret no-regret (NRNR), no-regret best-response (NRBR), and best-response no-regret (BRNR), which establish multicalibration algorithms that match or improve existing sample complexity rates. The work extends these dynamics to multi-group and multi-distribution learning, introducing an optimal multi-group learning algorithm based on NRNR dynamics. Empirical results validate the theoretical claims, particularly highlighting the performance of the Optimistic Hedge in NRNR dynamics. Overall, the paper contributes a unified, game-theoretic framework for multicalibration, enhancing the understanding and application of fairness notions in machine learning.

### Strengths and Weaknesses
Strengths:
- The paper introduces a novel perspective on multicalibration using game dynamics and no-regret algorithms, presenting it as a multi-objective learning problem.
- It provides a technically sound approach with rigorous mathematical derivations and well-proved theorems.
- The presentation is generally clear, with effective use of tables to aid understanding.

Weaknesses:
- There is a gap between theoretical development and empirical results, with the experimental evaluation limited to a few standard datasets, which may not sufficiently test the robustness of the proposed algorithms.
- The paper lacks detailed descriptions of the proposed algorithms, and the empirical section could be expanded to include comparisons with more baseline or state-of-the-art algorithms.
- The discussion of limitations and potential negative societal impacts is insufficient.

### Suggestions for Improvement
We recommend that the authors improve the empirical evaluation by designing more comprehensive experiments that test a wider range of scenarios, including diverse datasets and real-world use cases. Additionally, providing more detailed descriptions and pseudocode for the proposed algorithms would enhance clarity. A clearer empirical comparison with existing methods would help to highlight the authors' contributions more effectively. Furthermore, we suggest including a more explicit discussion of the limitations of the proposed methods and their potential societal impacts, particularly regarding computational complexity and the implications of misapplication in fairness contexts.