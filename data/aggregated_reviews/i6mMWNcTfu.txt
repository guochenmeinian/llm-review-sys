ID: i6mMWNcTfu
Title: ShiftAddViT: Mixture of Multiplication Primitives Towards Efficient Vision Transformer
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 6, 7, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 5, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ShiftAddViT, an efficient accelerating framework for vision transformers that reparameterizes pre-trained ViTs using a combination of additive and shift operations instead of traditional multiplication. The authors develop a new mixture of experts (MoE) system to maintain accuracy post-reparameterization and introduce a latency-aware load-balancing loss term for dynamic token allocation. Extensive experiments on various 2D/3D Transformer-based vision models demonstrate the method's superiority and efficiency.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and presents a systematic design solution for vision transformer architectures, making it easy to follow.
- The conversion of multiplication to additive and shift operations is a promising technique for model compression and acceleration.
- Extensive experiments, including detailed latency comparisons, effectively demonstrate the method's effectiveness across different tasks.

Weaknesses:
- The complexity of ShiftAddViT arises from its reliance on the MoE design to maintain accuracy, which may not be suitable for algorithm-focused conferences.
- The contributions of the multiplication-less solution and MoE appear somewhat independent, raising questions about their necessity in the context of the paper.
- Implementation details are often unclear, and comparisons with existing models like DeiT may not be fair due to architectural modifications.

### Suggestions for Improvement
We recommend that the authors clarify the most significant contributions of the paper, particularly the relationship between the multiplication-less solution and the MoE framework. Additionally, we suggest providing a more detailed explanation of the reparameterization process and its mathematical equivalence to existing methods. It would be beneficial to include comparisons with quantized ViT models and to address the effectiveness of the "Shift" method in classification tasks. Finally, we encourage the authors to elaborate on the implementation details and the impact of their method on larger-scale models.