ID: 8i6px5W1Rf
Title: Evaluating alignment between humans and neural network representations in image-based learning tasks
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 5, 6, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an evaluation of the alignment between human cognitive processes and neural network representations in image-based learning tasks, specifically through the analysis of 77 pretrained neural network models. The authors investigate how these models predict human behavior in category learning and reward learning tasks, identifying that larger contrastive training datasets and multimodal data enhance predictions of human behavior. The authors also introduce a novel behavioral benchmark for comparing human and machine performance.

### Strengths and Weaknesses
Strengths:
- The paper introduces two novel tasks to evaluate human-model alignment.
- It demonstrates that larger contrastive training datasets and multimodal data improve predictions of human behavior.
- The analysis of factors influencing model alignment is thorough and well-articulated.
- The manuscript is well-written and easy to follow, with excellent visuals that enhance understanding.

Weaknesses:
- Claims regarding multimodality's superiority in predicting human performance may be overstated, with potential confounding factors not fully explored.
- Some sections lack clarity and detail, making it difficult to assess the methods used.
- The analysis of alignment methods is weak, lacking model diversity and statistical analysis.
- There is insufficient comparison to existing alignment metrics, and the potential bias from using the THINGS database for both training and evaluation raises concerns.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Section 3 by explicitly defining terms and methodologies used, particularly regarding the intercept and statistical tests. Additionally, the authors should provide more detail on the training of the linear probe and the generative task representation. To strengthen the analysis of alignment methods, we suggest including a broader range of models and conducting statistical tests to assess significance. Addressing the potential bias in using the THINGS database by diversifying evaluation datasets or justifying its use would also enhance the paper. Finally, we encourage the authors to conduct a comprehensive comparison of their new alignment metric with existing metrics to validate its effectiveness.