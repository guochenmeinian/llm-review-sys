ID: CgJJvuLjec
Title: PAPR: Proximity Attention Point Rendering
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 4, 8, 6, 8, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel point-based rendering approach, PAPR, that utilizes a differentiable renderer with proximity attention to learn a point cloud from RGB images. The method effectively addresses the vanishing gradient issue by leveraging relative distances, allowing for high-fidelity rendering and enabling various applications such as geometry editing and object manipulation. The proposed framework demonstrates significant improvements over existing point-based methods and vanilla NeRF in terms of geometry reconstruction and novel view synthesis.

### Strengths and Weaknesses
Strengths:
- The design of the transformer-based point renderer is innovative, treating ray direction as the query and point positions as keys, which enhances integration efficiency.
- The method effectively deforms a point cloud from a simple shape to complex surfaces, facilitating scene editing and achieving impressive results.
- The paper is well-written, with clear motivation and illustrative figures, and the proposed components are thoroughly evaluated.

Weaknesses:
1. The paper lacks a discussion on computational complexity, particularly regarding the gradient computation for all points, which may significantly increase the computation time compared to existing methods.
2. There is an incorrect remark regarding prior work [44], which can render colored and shaded points, and additional relevant papers should be cited for comparison.
3. The necessity of using a convolutional U-Net raises concerns about potential flickering and inconsistencies during camera movement, which should be addressed.

### Suggestions for Improvement
We recommend that the authors improve the discussion on computational complexity, including a breakdown of the algorithm's complexity and comparisons of training and inference speeds with standard NeRF. Additionally, please clarify the inaccuracies regarding the prior work mentioned and include relevant citations. We also suggest addressing the potential flickering issues caused by the U-Net and exploring alternative architectures that may mitigate this problem.