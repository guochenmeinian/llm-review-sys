ID: 01I55gys19
Title: Few-Class Arena: A Benchmark for Efficient Vision Model Selection and Dataset Difficulty
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 5, 5, 5, -1, -1, -1
Original Confidences: 4, 3, 3, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Few-Class Arena (FCA), a benchmark tool designed for evaluating efficient image classification models in the few-class regime (2-10 classes). The authors propose a scalable data loading approach and introduce a novel Silhouette-based similarity score (SimSS) to measure dataset difficulty. While the work addresses a significant gap in benchmarking few-class scenarios, concerns arise regarding potential overfitting, limited intra-class variability, and the absence of uncertainty measures, comprehensive comparisons with state-of-the-art (SOTA) methods, and ablation studies.

### Strengths and Weaknesses
Strengths:
1. FCA systematically explores the few-class regime, providing a unified benchmark that facilitates evaluation across various models (CNNs and Transformers) and datasets.
2. The introduction of SimSS offers a novel approach to assessing dataset difficulty, demonstrating a high correlation with model performance.

Weaknesses:
1. The interpretations based on experimental results are questionable, particularly regarding overfitting and the susceptibility of results to random fluctuations due to the small number of test classes.
2. The paper lacks comprehensive comparisons with existing SOTA methods, limiting the novelty and practical utility of the proposed solutions.

### Suggestions for Improvement
1. We recommend that the authors include a comprehensive comparative analysis of the FCA benchmark and SimSS with relevant SOTA approaches, such as few-shot learning, meta-learning, and domain adaptation methods.
2. We suggest addressing overfitting by reporting confidence intervals and uncertainty estimations, and validating observed trends with additional experiments.
3. To enhance clarity and comprehensiveness, we advise including visual aids like tables and pipeline diagrams, and expanding the scope of experiments to cover various few-class scenarios beyond ImageNet1K.
4. We recommend that the authors clarify the justification for selecting specific model architectures for few-class applications instead of fine-tuning smaller many-class models.