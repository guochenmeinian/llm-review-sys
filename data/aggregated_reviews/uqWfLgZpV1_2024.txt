ID: uqWfLgZpV1
Title: On the Necessity of Collaboration for Online Model Selection with Decentralized Data
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 8, 5, 6, 6, -1, -1
Original Confidences: 2, 3, 4, 1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on regret minimization in distributed settings with multiple clients, focusing on the necessity of collaboration among clients for online model selection under computational constraints. The authors propose a new federated learning algorithm, FOMD-OMS, and establish upper and lower bounds on regret. They conclude that collaboration is unnecessary without computational constraints but essential when clients' computational costs are limited to \(o(K)\), where \(K\) is the number of hypotheses. The paper introduces three new techniques: an improved Bernstein's inequality for martingales, a federated online mirror descent framework, and the decoupling of model selection from prediction.

### Strengths and Weaknesses
Strengths:
1. The paper makes a strong contribution by proposing an algorithm that enhances previous bounds on computation and communication costs.
2. It provides a rigorous theoretical analysis of collaboration necessity in federated learning for online model selection.
3. The extensive experimental studies support the theoretical bounds, and the paper is well-written.

Weaknesses:
1. The motivation for federated learning in online model selection is not clearly articulated, lacking details to justify its practical applications.
2. The communication cost for \(o(K)\) is discussed but could benefit from a clearer explanation of the choice of \(J\) and its implications.
3. The paper does not sufficiently differentiate itself from previous works on federated online bandits, which could enhance understanding of its unique contributions.
4. The mathematical density makes the paper difficult to follow at times; a clearer presentation of theorems and proofs is needed.

### Suggestions for Improvement
We recommend that the authors improve the articulation of the motivation for federated learning in the context of online model selection, providing more details on practical applications. Additionally, we suggest discussing the choice of \(J\) and its impact on communication costs in the abstract and introduction. A detailed comparison with previous works on federated online bandits should be included to clarify the unique aspects of this work. Finally, we advise restructuring the paper to enhance readability by motivating theorems and relegating dense mathematical proofs to an appendix.