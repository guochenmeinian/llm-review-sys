ID: XEUc1JegGt
Title: An Inductive Bias for Tabular Deep Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 6, 6, 7, 5, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 5, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an exploration of inductive biases for deep learning applied to tabular data, introducing a novel inductive bias termed frequency reduction. The authors argue that tabular datasets are best described by functions with high frequency and propose transformations to reduce the relevance of these high-frequency components. They evaluate their approach using several real-world datasets, demonstrating its effectiveness in bridging the performance gap between deep learning and tree-based methods.

### Strengths and Weaknesses
Strengths:
- The paper provides a clear explanation of the performance gap between deep learning and tree-based methods on tabular data.
- The introduction of the frequency reduction inductive bias offers a unique perspective and is easy to implement without requiring complex model architectures.
- Empirical evaluations demonstrate the effectiveness of the proposed method across various benchmark datasets.

Weaknesses:
- The empirical evaluations are limited to low-dimensional datasets, which may not fully capture the challenges faced in high-dimensional, low-sample-size scenarios.
- The use of normalized accuracy and AUC metrics in the main text lacks justification, especially when unnormalized metrics are used in the supplemental material.
- The paper does not adequately compare the proposed method with other existing methods or provide a detailed analysis of the impact of transformations on model interpretability.
- The writing quality and structure of the paper could be improved, particularly in the experiments section, which is too brief.

### Suggestions for Improvement
We recommend that the authors improve the empirical evaluations by including more diverse and high-dimensional datasets to better assess the generalizability of their approach. Additionally, clarify the rationale for using normalized metrics in the main text while employing unnormalized metrics in the supplemental material. The authors should also include comparisons with other tree-based models and architectures, such as XGBoost, and provide a more thorough theoretical analysis of the proposed inductive bias. Furthermore, we suggest that the authors conduct controlled experiments, possibly using synthetic data, to validate their claims regarding spectral bias and its impact on performance. Lastly, enhancing the clarity and structure of the writing, particularly in the experiments section, would benefit the overall presentation of the paper.