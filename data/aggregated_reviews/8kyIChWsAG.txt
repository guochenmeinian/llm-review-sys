ID: 8kyIChWsAG
Title: When Does Optimizing a Proper Loss Yield Calibration?
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 9, 7, 4, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel characterization of calibration in machine learning models, particularly focusing on deep neural networks (DNNs) and logistic regression. The authors introduce a local optimality condition that is necessary and sufficient for calibration, linking it to the concept of post-processing with 1-Lipschitz functions. They establish that the post-processing gap can be bounded by smooth calibration error, providing insights into why modern DNNs exhibit better calibration compared to earlier models. The authors assert that logistic regression is often well-calibrated, although this claim is empirical and not guaranteed. They also highlight that many modern neural networks, including GPT-4, are well-calibrated out-of-the-box, while acknowledging that even well-calibrated models may benefit from further post-hoc calibration, as demonstrated by findings in Mukhoti et al. (2020).

### Strengths and Weaknesses
Strengths:
- The introduction of the post-processing error and its connection to smooth calibration is both novel and significant, offering plausible explanations for improved calibration in current deep learning models.
- The paper engages with relevant literature, providing empirical evidence for claims about model calibration and acknowledges the complexity of model calibration and the need for post-hoc calibration.
- The paper is technically sound, with well-motivated definitions and intuitive justifications for results, making the theory accessible.
- The clarity of presentation is commendable, as the authors effectively scale the complexity of concepts throughout the paper.

Weaknesses:
- There are potential gaps between the theoretical claims and existing literature, particularly regarding the calibration of models discussed by Guo et al. (2017), which the authors do not adequately address.
- The claim regarding logistic regression's calibration may mislead readers into thinking it is a novel contribution, and the assertion about modern neural networks lacks rigorous statistical backing, potentially overstating their calibration status.
- The paper lacks experimental validation of the local optimality condition for modern architectures, which would strengthen the theoretical claims.
- Important references related to the dual mapping and calibration concepts are missing, which could enhance the paper's credibility and context.
- The focus on binary classification limits the practical applicability of the findings, although this does not significantly undermine the paper's impact.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the calibration claims made in relation to Guo et al. (2017) to clarify the differences in model architectures and their calibration properties. Additionally, we suggest that the authors provide more robust statistical evidence to support their assertions about the calibration of modern neural networks. Incorporating experimental analysis to validate the local optimality condition in practical settings would enhance the robustness of the theoretical results. The authors should also ensure that key references are included to acknowledge prior work relevant to their findings. Finally, expanding the scope beyond binary classification would increase the applicability of their results to a broader range of machine learning scenarios.