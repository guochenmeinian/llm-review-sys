ID: KIysY1fMCJ
Title: Aspect-to-Scope Oriented Multi-view Contrastive Learning  for Aspect-based Sentiment Analysis
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a scope-assisted multi-view graph contrastive learning framework (A2SMvCL) aimed at improving Aspect-Based Sentiment Analysis (ABSA) by addressing noise introduced by attention mechanisms and dependency trees. The authors propose a model that integrates syntactic and semantic knowledge through graph-based methods and employs contrastive learning to differentiate between aspect-related and unrelated sentiment representations. Experiments on six benchmark datasets demonstrate that A2SMvCL outperforms existing state-of-the-art methods.

### Strengths and Weaknesses
Strengths:
- The proposed approach achieves state-of-the-art results on multiple datasets, indicating its effectiveness in the ABSA task.
- The paper is well-structured and clear, making it easy to follow.
- It introduces a comprehensive framework that effectively extracts high-quality features and can potentially be extended to other tasks.

Weaknesses:
- The techniques employed are not novel, as syntactic and semantic features, graph-based approaches, and contrastive learning are already prevalent in existing ABSA research.
- The complexity of the approach arises from combining existing techniques with minor modifications, lacking significant innovation.
- Important technical details are missing, including hyper-parameter tuning methods and the potential for overfitting due to small test set sizes.
- The requirement for extra annotation of scope labels raises concerns about labor costs and fairness in comparisons with baseline methods.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the connection between the identified noise issues and the chosen model components, particularly regarding the use of graphs and contrastive learning. Additionally, we suggest providing detailed explanations of hyper-parameter tuning and the impact of dependency quality on model performance. Addressing the concerns about the annotation of scope labels and their potential effect on the method's effectiveness is also crucial. Finally, including a more comprehensive discussion of related studies would strengthen the paper's foundation.