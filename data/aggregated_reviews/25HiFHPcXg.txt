ID: 25HiFHPcXg
Title: CAPro: Webly Supervised Learning with Cross-modality Aligned Prototypes
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 5, 5, 6, 6, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a unified prototypical contrastive learning framework, named Cross-modality Aligned Prototypes (CAPro), aimed at enhancing webly-supervised learning by addressing semantic noise. CAPro utilizes web data across modalities to create semantically-correct textual and visual prototypes. The authors propose text matching to leverage textual prototypes for noise-robust estimation and introduce collective bootstrapping (CB) to provide smoother label references. Extensive experiments on WebVision1k and NUS-WIDE validate the effectiveness of CAPro.

### Strengths and Weaknesses
Strengths:
- The concept of integrating visual and textual prototypes to address webly supervised learning is both interesting and promising.
- The motivation is clear, and the paper is well-written.
- The code is released, and the ablation study appears extensive.

Weaknesses:
- Equations (5), (6), and (7) closely resemble those in [28], necessitating a discussion on their differences and advantages.
- The total objective loss function includes four hyper-parameters, yet only \(\lambda_{bts}\) is discussed in the ablation study. The authors should clarify how to determine the values of these hyper-parameters and their robustness.
- The reported result for NCR in Table 1 appears incorrect, raising concerns about the proposed method's performance.
- The framework figure is overly complex, lacking clear module divisions and consistent symbol introductions, complicating understanding.
- The performance improvement is marginal compared to existing sophisticated WSL baselines like MoPro, despite the complexity of the proposed method.
- Several typos and unclear statements are present, such as the definition of 'concept definition texts' and the phrase 'with visual guidance from image neighbors'.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the differences between their approach and existing techniques, particularly regarding semantic noise and noisy correspondence. Additionally, clarifying the distinctions between their KNN-graph mechanism and related works would enhance understanding. The authors should also simplify the framework figure for better clarity and provide a more explicit algorithm for the training process. Addressing the hyper-parameter selection process and ensuring accurate performance reporting in Table 1 is crucial. Lastly, we suggest correcting typos and clarifying unclear statements to improve overall readability.