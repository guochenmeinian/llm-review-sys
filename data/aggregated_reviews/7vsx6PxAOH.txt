ID: 7vsx6PxAOH
Title: All-in-One Image Coding for Joint Human-Machine Vision with Multi-Path Aggregation
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 5, 7, 6, -1, -1
Original Confidences: 4, 2, 3, -1, -1

Aggregated Review:
### Key Points
This paper presents a unified image compression method utilizing Multi-Path Aggregation (MPA) for joint human-machine vision tasks. The authors propose a lightweight predictor to allocate features into main and side paths, enabling the reuse of shared features through fine-tuning a limited number of parameters. Experimental results indicate that the proposed method achieves state-of-the-art performance across various tasks.

### Strengths and Weaknesses
Strengths:
1. The authors provide an innovative unified image compression method with multi-path aggregation that supports multiple human-machine vision tasks with shared features.
2. Experimental results demonstrate that MPA achieves performance comparable to state-of-the-art methods in both task-specific and multi-objective optimization.
3. The paper is well-written, clearly articulating the problem, proposed method, and significance of contributions.

Weaknesses:
1. The experimental results lack comparisons with the basic TinyLIC model and other state-of-the-art unified models regarding parameter amounts, time complexity, and computational complexity.
2. The effectiveness of the predictor is not convincingly verified, as indicated by a minimal performance improvement of only 0.19% bitrate reduction.
3. The proposed two-stage training strategy is complex, introducing numerous training losses and hyperparameters, which may hinder generalization and usability.

### Suggestions for Improvement
We recommend that the authors improve the experimental section by including comparisons with the TinyLIC model and other relevant state-of-the-art unified models to provide a more comprehensive evaluation. Additionally, we suggest that the authors conduct more extensive experiments to validate the effectiveness of the predictor module. It would also be beneficial to clarify whether the proposed MPA can be applied to other fundamental vision tasks, such as object detection, and to explore its sensitivity to hyperparameter changes. Finally, we encourage the authors to compare MPA with parameter-efficient fine-tuning methods like LoRA to assess relative performance.