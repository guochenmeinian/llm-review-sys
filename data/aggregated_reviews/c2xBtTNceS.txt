ID: c2xBtTNceS
Title: Inverse Reinforcement Learning for Text Summarization
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach using Inverse Reinforcement Learning (IRL) to enhance text summarization by automatically determining the optimal weighting of multiple reward functions. The authors propose four types of sub-rewards combined into a reward function and validate their method through experiments on CNN/DailyMail and WikiHow datasets. The results indicate that the IRL method generates summaries closer to reference summaries and outperforms Maximum Likelihood Estimation (MLE) and Reinforcement Learning (RL) in several evaluation metrics.

### Strengths and Weaknesses
Strengths:
- The authors introduce a novel application of IRL in text summarization, which is a rare contribution in this field.
- Comprehensive experiments demonstrate the effectiveness of the proposed method, supported by detailed analysis.

Weaknesses:
- The contribution of adding sub-rewards is questioned, as the IRL method itself is not novel, and the paper lacks a comparison to a baseline model maximizing multiple rewards with fixed weights.
- There are limited details about the training process, including hyperparameter settings and training stability, which could hinder reproducibility.
- The computational efficiency of the IRL method is a concern, as it may incur significant costs during training and inference.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their contribution by explicitly comparing their method to a baseline that maximizes multiple rewards using fixed weights. Additionally, providing more details about the training process, including hyperparameter settings and stability, would enhance reproducibility. The authors should also address the computational efficiency of their approach and consider benchmarking their method against other large language models beyond BART to strengthen their claims. Finally, including relevant citations, such as Pasunuru et al. (2020), and discussing the advantages of their method over existing work would provide a more comprehensive context for their contributions.