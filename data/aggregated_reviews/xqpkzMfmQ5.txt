ID: xqpkzMfmQ5
Title: Data curation via joint example selection further accelerates multimodal learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 7, 7, 7, 8, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel data curation method called Joint Example Selection (JEST) for large-scale multimodal training. The core idea of JEST is to compute joint learnability of samples in batches, leveraging contrastive objectives to reveal data dependencies. The main contributions include: (1) the introduction of Learnability Scoring to combine hard learner and easy reference metrics for selecting informative examples; (2) batch-level example selection that considers data dependencies; and (3) a significant reduction in computation compared to state-of-the-art methods.

### Strengths and Weaknesses
Strengths:
1. The paper addresses a critical problem in data curation and proposes an efficient joint selection scheme.
2. It is well-organized, clearly written, and easy to understand.
3. The proposed method accelerates large-scale training, achieving up to 10 times fewer FLOPs and 13 times fewer examples compared to the state-of-the-art SigLIP.

Weaknesses:
1. The method relies on small, well-curated datasets that specify the distribution, which may limit its applicability.
2. The paper does not introduce a new dataset or benchmark, raising questions about its suitability for the Datasets and Benchmarks Track.
3. The analysis of the method's underlying principles and comparisons with existing works could be more comprehensive.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the explanation regarding the choice of the reference model and its relation to learnability scoring. Additionally, providing more experimental results across diverse datasets and reference models would strengthen the paper's impact. We also suggest exploring alternative formulations for learnability scoring and considering more general cases in their analysis. Finally, a comparison with a broader range of existing works would enhance the paper's relevance and rigor.