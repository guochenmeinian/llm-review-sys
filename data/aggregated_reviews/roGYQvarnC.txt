ID: roGYQvarnC
Title: ConRad: Image Constrained Radiance Fields for 3D Generation from a Single Image
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 5, 7, 6, 7, 6, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 5, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Image Constrained Neural Radiance Fields (ConRad), a novel approach for 3D reconstruction from a single RGB image that incorporates a hard constraint based on the reference view. The method optimizes a neural radiance field to ensure that the input image is accurately rendered in the reference view, eliminating the need for training in that view. The authors demonstrate that ConRad produces high-quality 3D reconstructions that are more consistent and faithful to the input compared to existing methods like RealFusion and NeuralLift-360.

### Strengths and Weaknesses
Strengths:
1. The proposed method is simple, effective, and introduces an innovative hard constraint that enhances the optimization of single image-conditioned NeRFs.
2. The paper is well-structured, clearly written, and provides comprehensive qualitative and quantitative analyses demonstrating the method's effectiveness.
3. The ablation studies are methodologically sound and illustrate the efficacy of the proposed modules.

Weaknesses:
1. The method exhibits blurriness in views other than the reference view, limiting its effectiveness in those areas.
2. The claim that the proposed method simplifies the generation of consistent 3D models requires more experimental support, particularly through ablation studies comparing the hard constraint with traditional reconstruction losses.
3. There are ambiguities in the explanation of certain technical components, such as the visibility depth parameterization and the handling of background during training.
4. The paper lacks sufficient qualitative comparisons with all baselines and does not adequately address the training time and efficiency of the proposed method.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the explanation regarding the visibility depth parameterization and provide an ablation study on the choice of the parameter $\eta$. Additionally, the authors should include more qualitative comparisons with all baselines in the supplementary materials and clarify how background handling is managed during training. It would also be beneficial to report the training times for ConRad and compare them with those of original Dreamfusion or Dreambooth3D to assess efficiency. Finally, addressing the blurriness in non-reference views and exploring the impact of varying hyperparameters within ConRad would strengthen the paper.