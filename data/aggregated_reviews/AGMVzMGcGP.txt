ID: AGMVzMGcGP
Title: Active Bipartite Ranking
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 7, 4, 7, 6, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 1, 2, 3, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an active learning framework for the bipartite ranking problem, proposing an algorithm called active-rank that aims to minimize the distance between the ROC curve of the ranking function and the optimal one, evaluated with respect to the sup norm. The authors provide a theoretical analysis that guarantees the distance can be made arbitrarily small with high probability, although the evaluation is conducted solely on synthetic data. The methodology is theoretically sound, with sample complexity bounds established under specific assumptions about the posterior distribution.

### Strengths and Weaknesses
Strengths:
- The proposed methodology is theoretically sound, with a clear presentation of the theoretical framework and statistical guarantees supporting the algorithm.
- The paper is well-written, with clear notation and in-depth theoretical analysis.
- The active-rank method demonstrates strong empirical performance on synthetic data, aligning with theoretical expectations.

Weaknesses:
- The practical applicability of the proposed method is questionable, particularly regarding high-dimensional data, as the algorithm is primarily tested in a one-dimensional setting.
- The experiments are limited to synthetic data, lacking behavioral observations on real datasets, which may hinder practical insights.
- The paper is difficult to follow for readers unfamiliar with the topic, and the presentation could be improved, particularly regarding figure clarity and labeling.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper to make it more accessible to a broader audience, possibly by providing additional context or explanations for complex concepts. It is essential to extend the evaluation of the active-rank algorithm to real-world datasets to demonstrate its practical effectiveness. Additionally, we suggest that the authors clarify how the criterion changes after the removal of a data point, considering the interdependence of points in the active set. A theoretical comparison between active and passive learning complexities should also be included to better contextualize the contributions of the proposed method. Lastly, improving the presentation of figures, including proper labeling and clearer legends, would enhance the overall readability of the paper.