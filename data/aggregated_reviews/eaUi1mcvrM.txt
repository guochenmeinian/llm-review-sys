ID: eaUi1mcvrM
Title: INSTRUCTSCORE: Towards Explainable Text Generation Evaluation with Automatic Feedback
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents InstructScore, a novel metric for evaluating text generation that generates detailed error reports, including error type, location, severity, and explanations. The metric is based on a LLaMa backbone, fine-tuned on synthetic data from GPT-4, which also provides corrective feedback to ensure consistency in error reporting. The authors demonstrate that InstructScore outperforms existing automatic evaluation metrics across various tasks, including Machine Translation and common sense reasoning, by correlating automatic metrics with human evaluations.

### Strengths and Weaknesses
Strengths:
- The paper effectively utilizes LLM feedback to enhance NLG evaluation, providing human-like reasoning and error analysis.
- It discusses failure modes in evaluation and proposes solutions through the InstructScore metric.
- The method shows impressive performance across diverse text generation tasks, indicating its robustness.
- The approach offers a more granular understanding of errors compared to traditional scoring methods.

Weaknesses:
- The reliance on synthetic training data from GPT-4 raises concerns about the generalizability and independence of the metric.
- Some comparisons with existing metrics, such as BLEURT, may be unfair due to differences in model capacity and evaluation setups.
- The explanation aspect of the error reports is under-explored, with human evaluations indicating inaccuracies in some cases.
- The process for collecting synthetic data is complex and not clearly articulated, making reproducibility challenging.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the data collection process to enhance reproducibility. Additionally, consider addressing the potential over-reliance on GPT-4 by exploring alternative baselines for generating error reports. It would also be beneficial to provide more detailed insights into the practical utility of the explanations in the error reports. Finally, we suggest that the authors clarify whether the system can identify error-free hypotheses to avoid generating unnecessary error reports.