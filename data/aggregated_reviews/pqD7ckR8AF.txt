ID: pqD7ckR8AF
Title: SuperDeepFool: a new fast and accurate minimal adversarial attack
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 6, 6, 6, 7, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents SuperDeepFool (SDF), a novel family of adversarial attacks designed to evaluate the robustness of deep neural networks against minimal L2 perturbations. The authors propose that SDF generalizes the DeepFool (DF) attack by incorporating a projection step, achieving superior effectiveness and computational efficiency across datasets like MNIST, CIFAR10, and ImageNet. The authors demonstrate that SDF not only outperforms existing methods but also enhances adversarial training, contributing to improved robustness of image classifiers.

### Strengths and Weaknesses
Strengths:
1. The paper introduces an innovative method leveraging geometric properties of minimal L2 adversarial perturbations, providing a fresh perspective on adversarial attacks.
2. SDF achieves a better trade-off between computational cost and attack efficiency, supported by theoretical analysis.
3. Comprehensive experimental validation illustrates SDF's superiority across various benchmarks and datasets.
4. The method enhances the robustness of classifiers through adversarial training, showcasing practical applicability.

Weaknesses:
1. The focus on L2 perturbations may limit the relevance of the threat model in real-world scenarios.
2. The novelty of the approach is somewhat diminished as it builds on the existing DeepFool attack, which may affect the perceived contribution.
3. Clarity issues exist in the presentation, with some definitions and comparisons lacking precision.
4. The method is limited to a white-box threat model, which is less practical than black-box models.

### Suggestions for Improvement
We recommend that the authors improve clarity by addressing the minor issues in the presentation, such as the incomplete sentence on Line 123 and the inconsistent notation for classifiers. Additionally, we suggest discussing the relationship between SDF and previous works that leverage decision boundary geometry to enhance the novelty of the contribution. To strengthen the evaluation, we encourage the authors to explore the generalization of SDF to black-box attacks and other norms, as well as to provide a more detailed comparison with adversarial training and the rationale behind chosen perturbation sizes.