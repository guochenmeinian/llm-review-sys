ID: LnJ2EGKTXh
Title: Robo-Instruct: Simulator-Augmented Instruction Alignment For Finetuning CodeLLMs
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 8, 4, 7, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ROBO-INSTRUCT, a framework aimed at generating synthetic training data for fine-tuning small language models to create domain-specific robot programs. It comprises two main components: ROBOSIM, which validates programs through angelic execution and dynamic world synthesis, and INSTALIGN, which aligns instructions with the generated programs. The authors demonstrate that fine-tuning the Codellama-Python-7B model with ROBO-INSTRUCT leads to significant performance improvements over various open-source and proprietary models. Additionally, the paper explores leveraging recent advances in large language models (LLM) and vision-language models (VLM) for service mobile robots, proposing that their method of embodied code synthesis could enhance applications in this domain. However, skepticism is expressed regarding the broad applicability of this work to other robotic applications, as most mobile robot actions are predefined high-level primitives.

### Strengths and Weaknesses
Strengths:
- The paper is well-organized and clearly articulates complex concepts, ensuring accessibility for readers.
- It provides a thorough literature review and substantiates claims with experimental results, demonstrating the effectiveness of ROBO-INSTRUCT through empirical data.
- The novel approach of using a pseudo-simulator to track world states enhances the validation of generated programs.
- The paper addresses an important area of research in service mobile robots and acknowledges the challenges of embodied code synthesis, providing context and clarification that enhances understanding.

Weaknesses:
- The reliance on SELF-INSTRUCT for initial program generation may introduce biases, potentially affecting the diversity and quality of the outputs.
- While ROBO-INSTRUCT shows promising benchmark results, its applicability to real-world tasks remains untested, as real environments often present challenges not captured by benchmarks.
- The contribution may not be sufficiently novel, given existing works in the field, and the performance gains are limited compared to models like GPT-4.
- The improvement in performance (4% increase in pass@1 score) from distilling GPT-4 does not appear significant compared to heuristic baselines, and the results do not meet the effectiveness threshold necessary for the proposed method to be considered a substantial advancement in the field.

### Suggestions for Improvement
We recommend that the authors improve the robustness of ROBO-INSTRUCT by conducting thorough evaluations in real-world robot programming scenarios to assess its generalizability. Additionally, addressing the potential biases introduced by SELF-INSTRUCT could enhance the diversity and correctness of generated programs. We also suggest providing metrics to demonstrate that ROBO-INSTRUCT preserves diversity alongside correctness, as this would strengthen the claims made in the paper. Furthermore, the authors should aim to demonstrate more significant advancements over existing heuristic baselines and consider addressing the limitations of transferring their approach to low-level skills in embodied domains to strengthen the applicability of their findings.