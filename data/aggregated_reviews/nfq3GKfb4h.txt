ID: nfq3GKfb4h
Title: Preference Learning of Latent Decision Utilities with a Human-like Model of Preferential Choice
Conference: NeurIPS
Year: 2024
Number of Reviews: 18
Original Ratings: 7, 4, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new approach to preference learning using two models: the Computationally Rational Choice Surrogate (CRCS) and its variant LC-CRCS, which incorporates contextual effects. The authors utilize variational inference to approximate intractable computations from a state-of-the-art cognitive model (Howes et al., 2016), demonstrating improved performance over existing methods in predicting human preferences and capturing contextual choice effects.

### Strengths and Weaknesses
Strengths:
- The paper addresses a relevant topic in preference learning and effectively integrates a cognitive model to enhance computational tractability.
- It is well-motivated, clearly written, and balances mathematical rigor with intuitive explanations.
- The empirical evaluation is thorough, employing diverse datasets and rigorous statistical testing to validate the model's performance.

Weaknesses:
- Limited applicability due to the requirement for specific data types and prior knowledge of parameters, which may not be readily available.
- The experimental focus on negative log-likelihoods (NLLs) raises questions about the practical significance of the results; additional metrics like accuracy would provide a clearer picture of the model's contributions.
- Technical implementation details are not sufficiently articulated, leading to confusion regarding the necessity of explicit feature engineering and the choice of network architectures.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the acronym CRCS earlier in the paper and ensure that the parameters $w$ are clearly defined as observed only by the modeled user. Including a graphical model to visualize the relationships between observed and unobserved variables would enhance understanding. Additionally, we suggest providing the number of parameters for each model in Table 1 and detailing the network architectures for $\hat{u}$ and $\hat{q}$. An ablation study on prior distributions and other hyperparameters, such as the number of layers in the networks, would strengthen the paper by demonstrating their impact on performance. Finally, addressing the choice of metrics beyond NLLs would provide a more comprehensive evaluation of the model's effectiveness.