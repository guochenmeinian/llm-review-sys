ID: jYIknUIgkd
Title: Moral Responsibility for AI Systems
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 7, 6, 7, 3, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 1, 3, 2, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a formalized definition of moral responsibility applicable to AI systems, focusing on causal and epistemic conditions. The authors propose a counterfactual ‘Necessary Element of a Sufficient Set’ (CNESS) definition of causation and integrate existing definitions of epistemic responsibility. They assert that causation is a necessary condition for moral responsibility and aim to extend responsibility from a binary variable to a real-valued degree, bridging philosophical concepts with practical applications in AI. The authors acknowledge the need for clearer contextualization within existing literature and express a willingness to refine their definitions and scope, particularly regarding the distinction between moral and causal responsibility.

### Strengths and Weaknesses
Strengths:
- The paper advances a novel formalization of responsibility, clearly contrasting it with existing definitions.
- It effectively incorporates strengths from various components to formulate a robust definition of responsibility.
- The authors demonstrate a clear commitment to refining their definitions and contextualizing their work within the existing literature.
- The writing is clear and well-organized, with illustrative examples that clarify complex concepts.
- They effectively argue for the necessity of causation in moral responsibility, aligning with established philosophical views.

Weaknesses:
- The paper lacks a strong connection to practical applications in AI, making it seem out of scope for NeurIPS.
- There is insufficient engagement with a broader range of philosophical perspectives on moral responsibility.
- The discussion on blame and praise is incomplete, leaving potential implications unexplored.
- The connection between causal and moral responsibility is not distinct enough, and the relationship to human values is weak.
- The paper makes broad claims that lack sufficient contextualization, leading to potential misinterpretations about the scope of their definitions.
- There is a perceived unwillingness to engage with existing arguments regarding the separation of causal and moral responsibility, which could undermine the paper's claims.

### Suggestions for Improvement
We recommend that the authors improve the practical application of their proposed concept by explicitly discussing how it can be integrated into real-world AI systems. This could involve detailing how degrees of responsibility and autonomy relate to AI capabilities. Additionally, we suggest that the authors contextualize their work more thoroughly within existing literature on accountability and liability in AI, addressing how their framework differs from or builds upon these perspectives. We urge the authors to engage more thoroughly with the cited works on causal and moral responsibility, particularly those by Hu, Kohler-Hausmann, and Kasirzadeh & Smart, to clarify their position and address potential criticisms. Finally, we encourage the authors to explore the implications of their framework regarding blame and praise to provide a more comprehensive understanding of moral responsibility in AI contexts.