ID: URI2aAQiQC
Title: SpikeBERT: A Language Spikformer Trained with Two-Stage Knowledge Distillation from BERT
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 6, 6, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents SpikeBERT, a spiking-based BERT model for text classification that utilizes LIF spiking neurons and surrogate gradients for backpropagation. The authors propose a two-stage distillation process combining pre-training with BERT and task-specific fine-tuning. Experimental results demonstrate that SpikeBERT achieves higher accuracy than previous spike-based models and lower energy consumption compared to non-spiking BERT. However, the accuracy is reported as lower but comparable to a standard fine-tuned BERT classifier. Additionally, the authors have made revisions in response to reviewer feedback, specifically modifying the energy consumption formula and recalculating data in Table 2, aiming to address concerns raised in the previous review and providing further details in their Official Comments titled **Theoretical Energy Consumption**.

### Strengths and Weaknesses
Strengths:
1. The proposed method is novel and relevant to the community, generating significant interest.
2. The technical sections are clearly described, and the writing is commendable.
3. The experiments yield promising results, particularly in energy efficiency and performance.
4. The authors demonstrate responsiveness to reviewer feedback by implementing specific recommendations and providing detailed explanations in their comments.

Weaknesses:
1. The design decisions, such as the choice of LIF neurons and architectural parameters, are not discussed in detail.
2. Scalability issues arise when increasing the depth of SpikeBERT, unlike non-spiking BERT.
3. The novelty and technical contributions are limited, with modifications from Spikformer being minor and knowledge distillation being a common practice.
4. The experimental validation is insufficient, lacking benchmarks against efficient BERT variants and broader language processing tasks.
5. The review does not indicate any remaining issues or areas that require further attention, leaving the overall assessment somewhat incomplete.

### Suggestions for Improvement
We recommend that the authors improve the discussion on design decisions in Section 3, specifically addressing the choice of LIF neurons and architectural parameters. Additionally, the authors should explore the scalability of SpikeBERT to acquire emergent abilities similar to non-spiking large language models. It would be beneficial to benchmark SpikeBERT against efficient BERT variants to clarify its practical efficiency. Finally, we suggest evaluating SpikeBERT on a wider range of tasks, such as GLUE, RACE, and SQuAD, to provide a more comprehensive assessment of its performance. Furthermore, we recommend that the authors explicitly state how the modifications enhance the research's validity and address any potential remaining concerns from the reviewers.