ID: dJZ3MvDw86
Title: Data Augmentations for Improved (Large) Language Model Generalization
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 5, 7, 5, 7, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents counterfactual data augmentation strategies aimed at enhancing the robustness of text classifiers, particularly in safety-critical applications like healthcare. The authors propose using a Large Language Model (LLM) to generate counterfactual data, leveraging auxiliary data to improve model performance. The experiments demonstrate that the proposed method effectively addresses out-of-distribution generalization issues, showing promising results in clinical diagnosis prediction tasks.

### Strengths and Weaknesses
Strengths:
1. The research addresses a significant issue in training robust classifiers for safety-critical applications, with positive experimental results indicating practical value.
2. The model demonstrates good performance without the typical trade-off between out-of-distribution generalization and in-distribution accuracy.
3. The paper is well-written, with detailed experimental settings that enhance clarity.

Weaknesses:
1. The novelty of the proposed method appears limited, primarily differing from existing methods by the introduction of auxiliary data, which may not represent a substantial technical advancement.
2. The experimental comparisons are somewhat basic; incorporating methods like IRM and GroupDRO could strengthen the evaluation.
3. Important aspects regarding model bias and robustness in safety-critical contexts require further clarification.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their approach by clearly articulating how their method differs from existing literature on counterfactual data augmentation. Additionally, consider including more sophisticated competitors in the experiments, such as IRM and GroupDRO, to provide a more robust evaluation. We also suggest expanding the discussion on the implications of using an LLM, particularly regarding potential biases and the importance of selecting an appropriate LLM. Clarifying the quality and identification of auxiliary data in practice would also enhance the paper's contributions. Finally, addressing the limitations of the causal graph specification and discussing the realism of generated counterfactual instances would strengthen the overall argument.