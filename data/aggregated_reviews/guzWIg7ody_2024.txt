ID: guzWIg7ody
Title: Nonparametric Classification on Low Dimensional Manifolds using Overparameterized Convolutional Residual Networks
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 8, 4, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a theoretical study of ConvResNets trained with weight decay for nonparametric classification, focusing on their ability to adapt to smooth target functions on low-dimensional manifolds. The authors prove that ConvResNets can efficiently learn these functions without succumbing to the curse of dimensionality. Additionally, the paper analyzes the ConvResNeXt architecture, which generalizes existing ConvResNets and demonstrates that weight decay training enforces sparsity, allowing effective learning in high-dimensional spaces.

### Strengths and Weaknesses
Strengths:  
1. The paper provides novel theoretical guarantees for ConvResNets in nonparametric classification, resolving the minimax optimal rate under conditional class probability.  
2. The analysis shows that the rate of convergence for learning Besov functions depends solely on intrinsic low dimensions, effectively addressing the curse of dimensionality.  
3. The theoretical framework is well-developed and clear, contributing significantly to deep learning theory.

Weaknesses:  
1. The literature review is insufficient, as recent studies on minimax optimal nonparametric classification using DNNs are not adequately addressed.  
2. The benefits of the parallel paths in the ConvResNeXt model are not fully explored, raising questions about their necessity compared to increased depth alone.  
3. The assumption that data lies precisely on a low-dimensional manifold may not reflect real-world scenarios, where data often surrounds such manifolds with noise.  
4. The paper does not sufficiently discuss limitations or potential negative societal impacts of the proposed work.

### Suggestions for Improvement
We recommend that the authors improve the literature review by incorporating recent studies on minimax optimal nonparametric classification using DNNs. Additionally, clarify the practical benefits of the parallel paths in the ConvResNeXt model, particularly in relation to existing findings on depth and width trade-offs. It would also be beneficial to address the implications of the assumption regarding data lying on a low-dimensional manifold and explore the potential generalization of their analysis to other architectures beyond convolutional networks.