ID: KOVWXcrFIK
Title: Fast Attention Requires Bounded Entries
Conference: NeurIPS
Year: 2023
Number of Reviews: 6
Original Ratings: 6, 7, 3, 6, -1, -1
Original Confidences: 3, 4, 4, 2, -1, -1

Aggregated Review:
### Key Points
This paper presents a theoretical exploration of the attention computation problem, demonstrating that the existence of a fast algorithm for approximately computing the attention matrix depends on the bound of the entry value \( B \). The authors show that when \( B = o(\sqrt{\log n}) \), their proposed algorithm can compute the attention matrix with \( 1/\text{poly}(n) \) error in time \( n^{1+o(1)} \). Conversely, under the Strong Exponential Time Hypothesis (SETH), they prove that no \( O(N^{2-q}) \) time algorithm can achieve \( 1/\text{poly}(n) \) approximation error.

### Strengths and Weaknesses
Strengths:
- The results are interesting and correct, providing an improved hardness result.
- The observation regarding the dependency of a sublinear algorithm's existence on the entry value is noteworthy.
- The paper is well-written and easy to follow, with a clear explanation of the basic intuitions and ideas behind the approach.

Weaknesses:
- The proposed algorithm appears somewhat incremental, lacking significant novelty in both the method and the techniques used.
- There is a notable absence of practical evaluation; simulation results demonstrating the algorithm's effectiveness on benchmark datasets would enhance the work.
- Some claims, particularly in theorem 4.6, are ambiguous due to the use of numerous constants without clear definitions or relationships.

### Suggestions for Improvement
We recommend that the authors improve the emphasis on the technical contributions of their work, clarifying how their results advance the field beyond existing literature. Additionally, we suggest including simulation results to validate the theoretical claims and demonstrate the practical applicability of the proposed algorithm. Finally, we encourage the authors to clarify ambiguous claims in their theorems, particularly regarding the constants used, to enhance the rigor of their theoretical assertions.