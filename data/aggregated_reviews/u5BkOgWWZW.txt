ID: u5BkOgWWZW
Title: Explaining Datasets in Words: Statistical Models with Natural Language Parameters
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 6, 5, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework to generate explanations for various text datasets by parameterizing data distributions with natural language predicates. The authors develop a model-agnostic algorithm that optimizes predicate parameters using gradient descent and discretizes them through language models. The framework is applied to clustering, time-series modeling, and multi-class classification tasks, demonstrating its effectiveness on real-world datasets, including user chat dialogues.

### Strengths and Weaknesses
Strengths:
1. The proposed framework effectively generalizes classical Bayesian text analysis methods, enhancing their relevance in the context of large language models (LLMs).
2. Comprehensive experiments are conducted across multiple datasets and tasks, showcasing the method's versatility.
3. The paper is well-written and presents its findings clearly.

Weaknesses:
1. The absence of pure LLM baselines limits the evaluation of the proposed method's advantages over direct prompting. For instance, in clustering, comparing the method with GPT-4 explanations would provide clearer insights.
2. The generated explanations primarily consist of topic descriptions, raising questions about the method's ability to handle more complex datasets, such as those requiring theorem-based explanations in STEM contexts.
3. The motivation for explaining text datasets is not clearly articulated, and the practical applications of the method beyond those demonstrated remain vague.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation behind the need to explain text datasets, specifying potential applications beyond those currently discussed. Additionally, we suggest including comparisons with more baseline methods to substantiate the benefits of the predicate-conditioned distribution. It would also be beneficial to explore the scalability of the method by testing on larger datasets and to address the limitations of using a single text embedding model by evaluating robustness across various embeddings. Lastly, we encourage the authors to report variance in results from experiments conducted across multiple seeds for a more comprehensive analysis.