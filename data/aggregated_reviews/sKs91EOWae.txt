ID: sKs91EOWae
Title: Boosting Asynchronous Decentralized Learning with Model Fragmentation
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to enhancing asynchronous decentralized learning through model fragmentation. The authors propose dividing the global model into smaller, independent fragments that can be updated asynchronously by different nodes, thereby reducing the need for frequent global synchronizations. The method aims to balance computational loads and alleviate communication bottlenecks in heterogeneous data distributions. Experimental results indicate that this fragmentation technique can lead to faster convergence times and improved performance, particularly in scenarios with significant straggling factors.

### Strengths and Weaknesses
Strengths:  
- The proposed algorithm effectively applies concepts from asynchronous decentralized learning relevant to Web systems.  
- The theoretical analysis of convergence guarantees from the perspective of global rounds is commendable.  
- Sensitive results demonstrate good performance, particularly in Section 5.3.  
- The problem is articulated clearly and succinctly.  

Weaknesses:  
- The model fragmentation strategy is oversimplified, lacking specific details on how the model should be fragmented and which components are involved.  
- There is insufficient analysis of communication overhead, particularly regarding latency and network variability's effects on asynchronous updates.  
- The method may not scale effectively in highly heterogeneous environments, as it does not address varying computational power and communication capabilities among nodes.  
- The paper lacks rigorous mathematical proof or theoretical analysis to substantiate claims regarding convergence guarantees.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the model fragmentation process by specifying the model backbone used in experiments and detailing the rationale for selecting specific layers or components for partitioning. Additionally, addressing the heterogeneity among nodes and personalizing communication rounds, possibly by incorporating the Novel Client-Communication Weight Selection approach from SWIFT, would enhance the paper's relevance. The authors should also explain the relatively low test accuracy of 70% on CIFAR-10 and provide proof of the convergence rate similar to the approach used in SWIFT. Further demonstrating the advantages of this method over SWIFT through theoretical proof or additional experimental analysis would significantly strengthen the contributions of the paper. Lastly, a thorough comparison of convergence rates and communication efficiency between the proposed method and SWIFT is essential for a comprehensive evaluation.