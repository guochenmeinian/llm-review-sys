ID: K1EG2ABzNE
Title: Image Reconstruction Via Autoencoding Sequential Deep Image Prior
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 6, 7, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Autoencoding Sequential Deep Image Prior (aSeqDIP), an innovative extension of untrained Deep Image Prior (DIP) methods designed to mitigate overfitting without the need for additional training data. The authors propose a novel approach where the network input is updated to the network output every two iterations, rather than adding noise in each iteration. Experimental results indicate that aSeqDIP demonstrates superior robustness to overfitting and improved reconstruction accuracy compared to existing DIP methods and trained diffusion models. The authors also integrate an input-adaptive auto-encoding term to enhance robustness specifically in denoising tasks, providing additional experiments and clarifications in response to reviewer feedback that showcase significant improvements in PSNR performance.

### Strengths and Weaknesses
Strengths:
- The significance of untrained neural networks is highlighted, particularly in scenarios with limited training data, contributing to the mitigation of overfitting.
- The originality of the approach is supported by experimental evidence showcasing its effectiveness in reconstruction accuracy and robustness.
- The authors effectively address reviewer concerns and provide additional experimental results that enhance the clarity and robustness of their findings.
- The paper is clearly written, with well-designed experiments and ablation studies addressing key hyperparameters.

Weaknesses:
- The absence of results for overfitting robustness in denoising tasks is a significant gap, as the implications of Proposition 3.1 in noisy scenarios remain unexamined.
- The usefulness of Proposition 3.1 is questioned, particularly regarding its implications for denoising tasks, where it may lead to convergence on suboptimal solutions.
- The performance of learning-based "SOTA" baselines is inadequately discussed, with no details on training sets provided, raising concerns about their validity.
- The paper does not sufficiently compare aSeqDIP with other DIP-based models that address overfitting, such as those referenced in the reviews.
- The novelty of using image inputs in DIP is questioned, as similar approaches have been previously documented.
- The provided code only addresses MRI reconstruction, and discrepancies between the implementation and the paper's description are noted, particularly regarding data consistency and loss computation.

### Suggestions for Improvement
We recommend that the authors improve the experimental evaluation by including results for overfitting robustness in denoising tasks to clarify the implications of Proposition 3.1. Additionally, a discussion on the usefulness of Proposition 3.1 in the context of denoising should be included. It is crucial to address the performance of the learning-based baselines by providing details on the training sets used and discussing their results more thoroughly. We also suggest that the authors include a more comprehensive comparison with existing DIP-based methods that tackle overfitting, specifically those highlighted in the reviews. Furthermore, clarifying the distinctions between aSeqDIP and prior works, particularly regarding the input structure and the necessity of external denoisers, would strengthen the manuscript. Lastly, addressing the discrepancies in the code implementation, particularly regarding the steps involving data consistency and loss computation, is essential to ensure alignment with the proposed methodology. Incorporating a discussion on the limitations of their approach in relation to the cited works would also enhance the paper's contribution to the field.