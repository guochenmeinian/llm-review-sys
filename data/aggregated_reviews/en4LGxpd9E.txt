ID: en4LGxpd9E
Title: Getting ViT in Shape: Scaling Laws for Compute-Optimal Model Design
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 6, 7, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an empirical investigation into the design of large vision transformers (ViTs), focusing on optimizing model shapes (width, depth, MLP size) under a fixed training budget. The authors discover that it is feasible to create parameter and inference cost-optimal models that are competitive with or outperform larger models across various tasks. The study introduces a star-sweep strategy to explore the shape space efficiently, significantly reducing computational requirements compared to traditional methods.

### Strengths and Weaknesses
Strengths:
- The paper effectively leverages predictable power-law behavior in test performance to optimize the shape of vision transformers, achieving similar performance with smaller models.
- The extensive experimental setup validates the proposed architecture across multiple benchmarks, demonstrating its robustness beyond image classification.
- The writing is generally clear, and the optimization method represents a notable advancement over previous approaches.

Weaknesses:
- The paper lacks originality, primarily presenting empirical findings without novel theoretical contributions. 
- Definitions of key terms, particularly compute **t**, are inconsistent and unclear, complicating reader comprehension.
- The analysis is not reproducible due to the lack of open-sourced datasets and code, and the limitations regarding compute costs and assumptions are inadequately discussed.

### Suggestions for Improvement
We recommend that the authors improve the clarity of definitions, particularly for compute **t**, and ensure consistent usage throughout the paper. Additionally, the authors should elaborate on the scaling parameters and provide clearer explanations for figures, especially Figure 1 and Figure 3, to enhance reader understanding. Addressing the reproducibility issue by open-sourcing the dataset and code is crucial. Furthermore, we encourage the authors to discuss the limitations of their work in greater detail, particularly regarding compute costs and the implications of their empirical findings across different vision applications.