ID: 5SIz31OGFV
Title: Inconsistency, Instability, and Generalization Gap of Deep Neural Network Training
Conference: NeurIPS
Year: 2023
Number of Reviews: 6
Original Ratings: 5, 6, 4, 6, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1

Aggregated Review:
### Key Points
This paper presents new notions of inconsistency and instability to estimate the generalization gap of deep neural networks, correlating these measures with well-trained models. The authors conduct extensive empirical studies demonstrating that inconsistency is more predictive of the generalization gap than other metrics. Theoretical results are provided, including a theorem linking these notions to mutual information in generalization bounds.

### Strengths and Weaknesses
Strengths:
1. The introduction of three novel measures for assessing the generalization gap in neural networks.
2. Extensive empirical validation showing strong correlations between instability, inconsistency, and the generalization gap.
3. Clear organization and writing throughout the manuscript.
4. Empirical findings indicate that inconsistency outperforms disagreement in predicting generalization.

Weaknesses:
1. Limited novelty in the proposed measures, as inconsistency and instability closely resemble existing definitions of disagreement, with only a shift from one-hot predictions to softmax confidence scores.
2. The theoretical contribution, particularly Theorem 2.1, lacks a uniform convergence-based generalization bound and does not adequately relate to training sample size, which diminishes its significance.
3. Some empirical conclusions appear speculative, particularly regarding the conditions under which inconsistency and instability are predictive.

### Suggestions for Improvement
We recommend that the authors improve the novelty discussion by clarifying the differences and advantages of their definitions compared to existing measures of algorithm stability. Additionally, we suggest enhancing the theoretical results in Theorem 2.1 to establish clearer connections to existing literature on information-theoretic generalization bounds. A more rigorous correlation analysis of the $\mathcal{C}_P/\mathcal{D}_P$ metrics, along with a detailed comparison of inconsistency and disagreement, would strengthen the empirical claims. Finally, including legends in all figures and clarifying the training errors for models in each experiment would enhance the manuscript's clarity.