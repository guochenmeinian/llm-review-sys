ID: 46WcPRhRwG
Title: Evaluating and Enhancing the Robustness of Code Pre-trained Models through Structure-Aware Adversarial Samples Generation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper studies the resilience of code models to adversarial attacks, proposing a series of novel attacks that incorporate code structure, which current methods overlook. The authors evaluate these attacks across multiple code models and tasks, demonstrating that adversarial training enhances model robustness against these attacks. Additionally, the authors introduce evaluation techniques for generating imperceptible adversarial samples by targeting identifier tokens and abstract syntax tree (AST) structures.

### Strengths and Weaknesses
Strengths:
- The authors propose several novel attacks that consider the structure of the code.
- The generated adversarial code is imperceptible to humans.
- Extensive experiments on code understanding and code generation tasks are presented.
- The methodology is intuitive, and the experimental results are promising.

Weaknesses:
- The necessity and advantage of considering code structure are not clearly articulated.
- There are no comparisons with current approaches, leaving the advantages of the proposed attacks unclear.
- The manuscript lacks clarity, with missing references to figures and appendix material.
- Some claims do not align with experimental results, raising soundness concerns.
- Important details regarding adversarial training and the composition of training data are missing.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their motivation for considering code structure in adversarial attacks. Additionally, the authors should include comparisons with existing methods to better illustrate the advantages of their proposed attacks. It is crucial to address the inconsistencies in claims and results, particularly regarding the accuracy of models under attack. The authors should also provide detailed information about the adversarial training process and the data composition used. Finally, we suggest clarifying the classification of code summarization within the context of code generation tasks.