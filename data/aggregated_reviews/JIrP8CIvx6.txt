ID: JIrP8CIvx6
Title: Improving Sequential Model Editing with Fact Retrieval
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a retrieval-augmented framework for sequential model editing (SME), aiming to continuously correct mistakes in pre-trained language models (PLMs) while preserving performance on previous edits. The authors propose a system that utilizes a "fact-patch memory" for storing edits and related factual information, alongside a fact-aware contrastive learning method for effective retrieval. The framework demonstrates enhanced efficiency and scalability, particularly on the FEVER and ZsRE datasets, addressing the practical challenge of updating PLMs without degrading overall performance.

### Strengths and Weaknesses
Strengths:
- The paper tackles the significant issue of efficiently correcting factual errors in PLMs, relevant for their deployment in real-world applications.
- The retrieval-augmented framework is innovative and intuitive, allowing for the storage and retrieval of prior edits.
- Experimental results indicate substantial improvements in efficiency, scalability, and edit retention compared to previous SME methods.
- The writing is clear, and the background adequately covers relevant prior work.

Weaknesses:
- The datasets employed are somewhat artificial, and more analysis on real-world mistakes would better illustrate the approach's benefits.
- Additional ablation studies are needed to clarify the sources of performance gainsâ€”whether they stem primarily from retrieval or fact representations.
- Efficiency gains plateau after a certain number of edits, suggesting potential limitations in scalability that warrant further discussion.
- The reliance on access to related factual knowledge raises questions about its criticality in practical applications.
- Some aspects of the framework, such as the contrastive learning methods, lack novelty, and the overall performance improvements may be seen as incremental.

### Suggestions for Improvement
We recommend that the authors improve the paper by providing analysis on real-world PLM mistakes to better assess practical performance. Additionally, conducting further ablation studies would help clarify the contributions of retrieval versus fact representations to the observed improvements. It would also be beneficial to discuss the scalability limits beyond the tested thousands of edits and to evaluate the necessity of related factual knowledge for maintaining performance. Lastly, enhancing the clarity of the paper with guided examples could improve readability and comprehension.