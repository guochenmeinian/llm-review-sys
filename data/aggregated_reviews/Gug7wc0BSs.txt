ID: Gug7wc0BSs
Title: Value-Based Deep Multi-Agent Reinforcement Learning with Dynamic Sparse Training
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 5, 6, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Multi-Agent Sparse Training (MAST) framework, which addresses computational overhead in Multi-agent Reinforcement Learning (MARL) by enhancing value learning through the Soft Mellowmax Operator, a hybrid TD-(Î») schema, and a dual replay buffer mechanism. MAST significantly reduces computational redundancy while maintaining performance. The authors also introduce dynamic sparse training (DST) to MARL, demonstrating that direct application of DST does not yield optimal results, thus necessitating the MAST framework. Extensive empirical validation indicates that MAST can reduce computational requirements by up to 20x with minimal performance loss.

### Strengths and Weaknesses
Strengths:
- The paper introduces the novel application of DST to MARL, addressing inherent problems with direct application.
- It is well-written, clear, and provides solid theoretical foundations for the proposed methods.
- Comprehensive evaluation and ablation results enhance understanding of the method and its design decisions.
- The empirical results are promising, showing superiority over common baselines.

Weaknesses:
- The focus on a single benchmark (StarCraft II) limits generalizability; applying MAST to other benchmarks is necessary.
- The comparison with existing single-agent RL sparse training methods, such as "Sokar et al., 2022" and "Wang et al., 2019", is lacking.
- An ablation study to quantify the contributions of the two novel designs to performance improvement is needed.
- The overhead introduced by the new design is not discussed, and limitations of the method require further analysis.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their findings by applying MAST to additional benchmarks beyond StarCraft II. Additionally, a comparison with existing single-agent RL sparse training methods should be included to contextualize the performance of MAST. An ablation study is necessary to clarify the contributions of the two novel designs to performance improvements. Furthermore, discussing the overhead introduced by the new design and providing a more thorough analysis of the method's limitations would enhance the paper's rigor. Lastly, we suggest adopting a uniform citation style to improve the readability of related work.