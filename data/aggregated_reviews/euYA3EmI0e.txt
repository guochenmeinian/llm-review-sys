ID: euYA3EmI0e
Title: Learning to Correct Noisy Labels for Fine-Grained Entity Typing via Co-Prediction Prompt Tuning
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a co-prediction prompt tuning approach aimed at correcting incorrect labels in fine-grained entity typing (FET). The authors propose a label-cleaning method utilizing co-prediction prompts and large language models (LLMs) like ChatGPT to generate weakly labeled training data. Extensive experiments demonstrate the method's effectiveness across various noise scenarios and types of annotated data.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and organized, with a clear high-level intuition of the method.
- The proposed "co-predict" mechanism is novel and effective, outperforming existing methods on public datasets.
- The approach shows improvements on different types of noisy training data, including distantly annotated data.

Weaknesses:
- The proposed method's reliance on the pretrained language model's capability raises questions about the choice of BERT-base over more advanced models like LLaMa or ChatGLM.
- There is a lack of evaluations on the corrected labels themselves, and the rationale for BERT's ability to correct human-annotated labels is unclear.
- The experimental analysis is incomplete, particularly regarding the sensitivity of the model to various parameters and thresholds.

### Suggestions for Improvement
We recommend that the authors improve the experimental section by including evaluations on the corrected labels and providing a detailed analysis of the "co-predict" mechanism, including comparisons with contrastive learning approaches. Additionally, we suggest that the authors clarify the rationale for using BERT-base and consider adopting a state-of-the-art backbone model. Furthermore, addressing the sensitivity of the model to the decreasing schedule of coefficient Î³ and the threshold in Eq. (7) through additional experiments would enhance the robustness of the findings. Lastly, we encourage the authors to rectify typographical errors and clarify ambiguous sections, such as the verbalizer selection process.