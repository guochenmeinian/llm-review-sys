ID: 0OtGfwj8eB
Title: Reinforcement Replaces Supervision: Query focused Summarization using Deep Reinforcement Learning
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on Query-focused Summarization (QfS) utilizing Reinforcement Learning (RL) models. The authors propose several innovations: 1) Scheduled Sampling to address the conflict between RL and Teacher Forcing in Transformers, 2) a novel reward mechanism based on the Cluster Hypothesis, 3) the RPEDT dataset for training passage embedding models, and 4) the RQFT dataset for analyzing QfS methods. The extensive experimental results indicate the effectiveness of the proposed methods.

### Strengths and Weaknesses
Strengths:  
- The introduction of a new RL-based method that resolves the conflict of RL in Transformers with Teacher Forcing.  
- A novel passage embedding-based reward mechanism using the Cluster Hypothesis.  
- The creation of two new datasets that could serve as valuable resources for future research.  

Weaknesses:  
- The paper relies on only two outdated baselines from 2019 and 2020, which may not reflect the current state-of-the-art techniques.  
- The experimental results for the two baselines on the new datasets are not reported.  
- Building rewards based on ROUGE and evaluating on ROUGE raises concerns about self-fulfilling prophecy.  

### Suggestions for Improvement
We recommend that the authors improve the paper by including comparisons with more recent baselines, such as BART-LS, BART-Large SegEnc, and BART-Large SegEnc + SOCRATIC Pretraining, particularly using common QfS evaluation datasets like QMSum and SQuALITY. Additionally, we suggest clarifying the rationale behind using ROUGE for both reward construction and evaluation, and ensuring that the reported results are statistically significant. Furthermore, please address the underspecified parameter settings and consider releasing the research artifacts for the community. Lastly, we advise correcting typographical errors noted in the review.