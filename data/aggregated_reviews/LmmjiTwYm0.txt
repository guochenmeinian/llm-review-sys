ID: LmmjiTwYm0
Title: What functions can Graph Neural Networks compute on random graphs? The role of Positional Encoding
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 7, 7, 6, 7, 5, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 1, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a theoretical study of node classification on latent position random graphs, extending the understanding of Graph Neural Networks (GNNs) and their expressive power. The authors characterize the function space generated by equivariant GNNs, analyze the impact of positional encodings (PEs), and propose normalization techniques to enhance generalization across graphs of varying sizes. The work also introduces new concentration inequalities relevant to filtered random matrices.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant topic, focusing on node classification rather than the more common graph-level tasks in GNN theory.
- It employs novel techniques and bounds, such as USVT estimators, which are of independent interest.
- The writing is clear and well-organized, with detailed proofs provided in the supplementary material.

Weaknesses:
- The paper lacks self-containment in certain areas, such as the definitions of graph shift matrices and the intuition behind latent position random graphs.
- Some claims, like the assertion that "medium or large graphs are never isomorphic," are overstated and could be moderated.
- The connection between theoretical results and practical implementations of GNNs is not sufficiently established, particularly regarding the normalization techniques proposed.

### Suggestions for Improvement
We recommend that the authors improve the self-containment of the paper by providing clearer definitions and intuitions for key concepts, such as graph shift matrices and latent position random graphs. Additionally, we suggest that the authors clarify their claims regarding graph isomorphism and ensure that the terminology used is consistent throughout the paper. It would also be beneficial to explicitly state the focus on node classification in the abstract and introduction, as this is a critical aspect of the study. Finally, we encourage the authors to strengthen the connection between their theoretical findings and practical applications, possibly through more extensive experiments or discussions that relate their analysis to commonly used GNN architectures.