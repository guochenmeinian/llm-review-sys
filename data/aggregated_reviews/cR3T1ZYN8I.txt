ID: cR3T1ZYN8I
Title: A Hitchhiker's Guide to Fine-Grained Face Forgery Detection Using Common Sense Reasoning
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 7, 7, 5, 6, -1, -1, -1
Original Confidences: 4, 4, 5, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to deepfake detection by framing the task as a Visual Question Answering (VQA) multi-label problem, leveraging Vision and Large Language Models (VLLMs). The authors develop three evaluation protocols and conduct extensive comparisons across multiple datasets, revealing both the potential and limitations of VLLMs in fine-grained detection scenarios. The work introduces a new benchmarking dataset, aiming to enhance explainability in deepfake detection.

### Strengths and Weaknesses
Strengths:
- The authors present an innovative use of VLLMs for deepfake detection, employing four VLLMs and seven datasets for a comprehensive evaluation.
- The paper is well-organized, with clear motivation, background, and analysis, making it easy to follow.
- The writing style is engaging, with effective use of diagrams and tables to illustrate the evaluation framework.

Weaknesses:
- VLLMs demonstrate high performance primarily on SeqDeepFake and R-splicer, which are not widely used datasets, raising concerns about generalizability.
- The paper lacks detailed descriptions of the datasets and the annotation process, which could enhance clarity.
- There is insufficient analysis of the detection performance, and the rationale behind using Common Sense Reasoning is not well explained.

### Suggestions for Improvement
We recommend that the authors improve the analysis of the experimental results, particularly by including comparisons with commonly used datasets such as DFFD, FaceForensic++, and DFDC. Additionally, the authors should clarify how labels for fine-grained detection were obtained in the DFDC, CelebDF, and WildDF datasets. It would be beneficial to explore the performance of more powerful VLLMs, such as GPT-4 and Gemini, and to provide a deeper analysis of the implications of using Common Sense Reasoning in their approach. Lastly, we suggest that the authors clarify the metrics used for evaluation, particularly how binary classification prediction scores are derived from LLM outputs.