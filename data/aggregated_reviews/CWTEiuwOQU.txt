ID: CWTEiuwOQU
Title: Understanding Permutation Based Model Merging with Feature Visualizations
Conference: NeurIPS
Year: 2024
Number of Reviews: 4
Original Ratings: 4, 6, 6, 6
Original Confidences: 3, 3, 4, 4

Aggregated Review:
### Key Points
This paper presents an exploration of feature visualization methods to analyze how randomly initialized image classifiers, trained on the same dataset, activate similar features. The authors investigate the effects of model alignment through permutation and linear regression, producing visualizations that illustrate how merging original and aligned models influences feature responses. The analysis indicates that while different models often detect similar features, alignment is not guaranteed.

### Strengths and Weaknesses
Strengths:
- Feature visualizations are a promising tool for understanding model alignment.
- Visualizations with varying sparsity levels provide insight into the effects of sparsity on feature detection.

Weaknesses:
- The abstract and conclusion lack specificity regarding the implications of the results.
- The paper relies solely on feature visualizations, which do not convey statistical relevance or overall model behavior; incorporating aggregate metrics like CLIP-$\delta$ and Kendall-$\tau$ would enhance the statistical grounding.
- Figure 3 should include model 2 after permutation for comparative analysis.
- The architecture analysis is limited to AlexNet and ResNet; transformer-based architectures should also be included.
- The broader implications for practical applications like transfer learning or federated learning are not addressed.
- The results are not convincingly rigorous, lacking quantitative analysis and relying on qualitative assessments of feature similarity.

### Suggestions for Improvement
We recommend that the authors improve the abstract and conclusion to provide clearer insights into the results. Incorporating aggregate metrics such as CLIP-$\delta$ and Kendall-$\tau$ across multiple layers would strengthen the statistical foundation of the findings. Additionally, including model 2 after permutation in Figure 3 would facilitate better comparison. We suggest expanding the architecture analysis to include transformer-based models and addressing the practical implications of the work. To enhance the rigor of the results, we advise the authors to adopt more quantitative analysis methods, such as comparing neural representations using established metrics. Finally, clarifying the intuition behind the stratified dataset split and ensuring that figure labels are clear would improve the overall presentation.