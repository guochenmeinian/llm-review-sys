ID: g5v3Ig6WVq
Title: Auslan-Daily: Australian Sign Language Translation for Daily Communication and News
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 7, 8, 6, 8, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 3, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Auslan-Daily dataset, a large-scale collection of over 45 hours of Auslan sign language videos, aimed primarily at sign language translation (SLT) while also supporting tasks such as signer detection and isolated sign language recognition (ISLR). The dataset features multi-grained annotations and is derived from diverse sources, including educational TV series and news programs. It establishes a benchmark for evaluating SLT models, addressing challenges such as diverse signers and environments that affect model accuracy. The authors acknowledge the absence of Continuous Sign Language Recognition (CSLR) due to high annotation costs and compare Auslan-Daily with existing datasets, emphasizing its unique contributions and the need for further evaluation methods.

### Strengths and Weaknesses
Strengths of the dataset include its large scale, comprehensive annotations, and support for multiple sign language tasks. The diversity of topics and environments, along with the inclusion of multi-signer scenarios, enhances its utility. The authors provide a clear rationale for their methodological choices, such as the use of AlphaPose for keypoint extraction. However, weaknesses are noted in the low performance metrics for SLT and ISLR, raising concerns about model robustness and the effectiveness of the annotation process. The lack of continuous gloss annotations currently limits the dataset's applicability for CSLR tasks.

### Suggestions for Improvement
We recommend that the authors clarify the total number of signers, ensuring it is accurately represented across training, development, and test sets. Additionally, the authors should provide a verification protocol for the annotation process to address potential errors. It would be beneficial to include comparisons with existing Auslan datasets to contextualize the contributions of Auslan-Daily. We suggest expanding the evaluation methods in Section 5.2 to better demonstrate the dataset's challenges and consider including dual-modality baselines to enhance the evaluation framework. To address the limitations of ISLR accuracy, we encourage the authors to consider expanding the dataset to include more examples per sign to improve training efficacy. Lastly, we recommend detailing the iterative human-in-the-loop procedure for continuous gloss annotations to provide clarity on future improvements and exploring dual-modality models to strengthen the paper's findings.