ID: 75v88kyyko
Title: Hierarchical clustering with dot products recovers hidden tree structure
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 7, 5, 7, 6, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to hierarchical agglomerative clustering (HAC) by utilizing the dot product as a similarity measure instead of traditional distance metrics. The authors propose a statistical model that guarantees recovery of the underlying tree structure under certain conditions, with theoretical results indicating that performance improves with high-dimensional data. Additionally, the paper discusses the challenges of utilizing Neighbor-Joining (NJ) methods for generating rooted trees, which are essential for the authors' model, algorithm, theory, and performance measure. The authors clarify that NJ typically outputs unrooted trees, complicating the definition of most recent common ancestors, which is crucial for their analysis. The performance metric, Kendall ranking correlation, is asserted to be inapplicable to unrooted trees due to the variability in node merging order based on root selection. The paper includes empirical analyses and provides code for reproducibility.

### Strengths and Weaknesses
Strengths:
- The paper combines methodological simplicity with deep insights, making it accessible to a broad audience.
- The theoretical results, particularly Theorem 1 and Theorem 2, are well-explained and provide significant contributions to the understanding of hierarchical clustering.
- The authors effectively address the limitations of their method and share code for community use, enhancing the paper's impact.
- The authors provide a clear rationale for their focus on rooted trees, emphasizing the importance of most recent common ancestors in their methodology.
- They effectively address the limitations of existing NJ implementations in relation to their specific requirements.

Weaknesses:
- The presentation could be improved, particularly in clarifying the generative model and its comparison to existing models.
- There are concerns regarding the assumption of i.i.d. data with a single cluster, which may lead to model misspecification in datasets with multiple clusters.
- The empirical analysis lacks a diverse set of benchmark methods, limiting the evaluation of the proposed approach.
- The authors appear to overlook the potential applicability of their performance metric to unrooted trees, as suggested by the reviewer.
- There is a lack of exploration regarding principled methods for root selection in NJ implementations.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the generative model and explicitly compare it to other hierarchical clustering models to enhance reader understanding. Additionally, addressing the concerns regarding the assumption of i.i.d. data with a single cluster would strengthen the paper. We suggest including more benchmark methods in the empirical analysis to provide a comprehensive evaluation of the proposed algorithm. Furthermore, we recommend that the authors improve their discussion on the applicability of the Kendall ranking correlation metric to unrooted trees, considering the reviewer's insights on calculating distances based on edge lengths. Lastly, we suggest that the authors explore and articulate a more transparent approach for root choice in NJ methods to enhance hierarchy recovery and comparison.