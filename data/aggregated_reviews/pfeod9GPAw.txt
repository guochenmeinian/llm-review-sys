ID: pfeod9GPAw
Title: Extractive Summarization via ChatGPT for Faithful Summary Generation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an evaluation of ChatGPT's performance on extractive summarization, exploring the effectiveness of in-context learning and chain-of-thought reasoning. The findings indicate that while ChatGPT achieves lower ROUGE scores compared to fine-tuning methods, it performs better on LM-based evaluation metrics. The authors propose that using an extract-then-generate framework enhances summary faithfulness significantly compared to abstractive-only baselines.

### Strengths and Weaknesses
Strengths:
- The paper addresses an important and underexplored area of extractive summarization using ChatGPT.
- It provides practical insights, particularly regarding the extract-then-generate approach, which improves summary faithfulness.
- The study is well-structured, with thorough experiments conducted across diverse datasets.

Weaknesses:
- The paper lacks clarity in introducing key concepts like "in-context" and "chain-of-thought" learning, which are crucial for understanding the results.
- The evaluation is limited to ChatGPT, making it insufficient to draw broader conclusions about large models in extractive summarization.
- The comparison of factual consistency between generated and extracted summaries is not meaningful, as extracted summaries inherently maintain factual accuracy.
- There is a need for human evaluation to validate the improvements in summary quality and factuality.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by providing detailed explanations of "in-context" and "chain-of-thought" learning in the introduction. Additionally, the authors should consider including a broader range of models for comparison to strengthen their claims. Conducting a manual evaluation of a subset of results would enhance the paper's contributions. Furthermore, we suggest discussing the trade-offs of choosing ChatGPT over fine-tuning methods to provide a more comprehensive analysis. Lastly, removing the task formulation section could free up space for more critical discussions.