ID: K5mUJTBMDY
Title: Enhancing Question Answering on Charts Through Effective Pre-training Tasks
Conference: EMNLP/2024/Workshop/BlackBoxNLP
Year: 2024
Number of Reviews: 2
Original Ratings: -1, -1
Original Confidences: 3, 4

Aggregated Review:
### Key Points
This paper presents a study on question-answering from charts, incorporating an evaluation component and a pretraining experiment. It identifies limitations in two models, MatCha and DePlot + LLM, particularly in understanding visual properties and numerical reasoning. The authors propose additional training tasks to enhance model performance, resulting in modest gains.

### Strengths and Weaknesses
Strengths:  
- The paper effectively identifies error patterns in models using a new checklist evaluation suite for ChartQA.  
- It proposes actionable pre-training tasks to address these identified issues.  

Weaknesses:  
- The paper lacks depth and detail, particularly in the evaluation component and the discussion of findings.  
- There is insufficient clarity regarding whether the models were pretrained or finetuned on the new tasks.  
- The results section is brief and does not adequately discuss the findings despite careful dataset selection.  
- Larger models, such as GPT-4, are not evaluated.

### Suggestions for Improvement
We recommend that the authors improve the depth of the evaluation component by providing a more detailed discussion of the findings, particularly regarding the properties tested by the different templates and the specific errors made by the models. Additionally, clarity on the distinction between pretraining and finetuning is essential; the authors should explicitly detail the training process and whether original datasets were reused. Finally, expanding the results section to include a more comprehensive analysis of the findings would enhance the paper's contribution.