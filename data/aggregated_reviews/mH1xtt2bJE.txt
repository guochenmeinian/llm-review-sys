ID: mH1xtt2bJE
Title: MaNo: Exploiting Matrix Norm for Unsupervised Accuracy Estimation Under Distribution Shifts
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 7, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents MANO, a method for estimating test accuracy of pre-trained neural networks on out-of-distribution (OOD) samples without ground-truth labels. The authors propose a novel approach that normalizes logits and utilizes the Lp norm of the normalized logits matrix as an estimation score, inspired by the low-density separation assumption. Theoretical and empirical analyses indicate that MANO outperforms existing methods across various distribution shifts and architectures.

### Strengths and Weaknesses
Strengths:
1. The paper provides a solid theoretical analysis linking logits to model uncertainty and generalization performance, supported by the low-density separation assumption.
2. It introduces MANO as a training-free method for estimating test accuracy, demonstrating resilience to various calibration scenarios.
3. Extensive empirical studies across multiple benchmarks show that MANO consistently outperforms state-of-the-art methods in different distribution shift scenarios.

Weaknesses:
1. The universality of the Low-Density Separation (LDS) assumption in practical applications is questioned, particularly in specific scenarios or datasets where it may not hold.
2. The mathematical advantages of the SoftTrun normalization strategy compared to traditional softmax are unclear, raising concerns about reliance on particular data distributions.
3. Performance improvements over existing methods appear minor in many instances, and there is a need for additional uncertainty measures to assess significance.
4. The method's translation into practical estimated accuracy is not adequately addressed, and the justification for selecting hyperparameter $\eta=5$ lacks robustness.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the universality of the Low-Density Separation assumption, particularly in practical applications. Additionally, the authors should clarify the specific mathematical advantages of the SoftTrun normalization strategy over traditional softmax and provide comparative results with the softmax-based MANO baseline method. Conducting an ablation study on the impact of varying $\eta$ would strengthen the argument for its selection. Furthermore, the authors should report performance using the absolute estimation error metric for unsupervised accuracy estimation and include discussions on key related works in the field.