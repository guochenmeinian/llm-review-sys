ID: Bou2YHsRvG
Title: Code-Switching with Word Senses for Pretraining in Neural Machine Translation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel sense-pivoted pretraining method for addressing the polysemy problem in neural machine translation (NMT). The authors propose a code-switched pretraining strategy that leverages word sense-specific information from Knowledge Bases, moving beyond traditional sense-agnostic translation lexicons. Experimental results on WMT'13 and FLORES 200 demonstrate significant improvements in translation quality across varying resource settings, with notable gains in medium and low resource scenarios.

### Strengths and Weaknesses
Strengths:
- The paper is well-organized and clearly written, making the ideas accessible.
- The proposed method effectively addresses the core weaknesses of existing approaches by integrating Word Sense Disambiguation into NMT pretraining.
- Comprehensive experiments validate the effectiveness of the method across different language pairs and resource levels.

Weaknesses:
- Some experimental results lack sufficient explanation, particularly regarding underperformance in certain settings, such as en-fr and fr-en.
- The applicability of the method is limited by the availability of WSD resources and knowledge graphs for various languages and domains.
- The experimental configuration for resource settings deviates from standard practices, raising questions about the robustness of the findings.

### Suggestions for Improvement
We recommend that the authors improve the explanations for the underperformance of their method in specific experimental settings, particularly in Figure 3. Additionally, we suggest that the authors provide a more comprehensive analysis of their experimental outcomes to clarify the extent of performance improvements attributed to their pretraining method. To enhance the validation of WSP-NMT, we encourage the authors to conduct comparison experiments between sense-appropriate and sense-mismatched sentence pairs, potentially incorporating a contrastive loss approach. Lastly, we advise revising the expression "posit" in Point 5 of Section 4.2 for clarity and style.