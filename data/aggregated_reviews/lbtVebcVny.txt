ID: lbtVebcVny
Title: Revisiting De-Identification of Electronic Medical Records: Evaluation of Within- and Cross-Hospital Generalization
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the de-identification of clinical notes in a cross-hospital context, utilizing a manually PHI-annotated corpus from three Chinese hospitals. The authors evaluate fine-tuned Chinese BERT-based models, revealing significant performance drops in cross-hospital settings compared to within-hospital scenarios, particularly for identifying specific named entities such as location and patient information. The authors also explore domain generalization techniques, finding that only Stochastic Weight Averaging and text smoothing yield slight improvements.

### Strengths and Weaknesses
Strengths:
- The main contribution is the valuable corpus constructed, which addresses the scarcity of clinical corpora, especially in cross-hospital and non-English contexts.
- The paper effectively highlights the generalization gap in deep learning models, demonstrating the challenges in PHI identification across different hospitals.

Weaknesses:
- The techniques employed are standard, and the paper lacks a thorough analysis of the factors contributing to the generalization gap, particularly the similarities and differences in data from various hospitals.
- The authors chose to develop their own medical BERT-based model (HM-BERT) without comparing it to existing pre-trained models, limiting the analysis of model performance.
- The conclusion that cross-hospital results are worse than in-hospital results is expected and lacks novelty.
- Insufficient error analysis makes it difficult to assess the significance of different types of errors in PHI identification.

### Suggestions for Improvement
We recommend that the authors improve the analysis of the generalization gap by investigating the specificities of the CCKS dataset and exploring the reasons behind the performance drop. Additionally, the authors should consider comparing their HM-BERT model with existing pre-trained medical models, such as that of Zhang et al. (2020). We also suggest including a detailed error analysis, possibly with a table showing the percentage of errors for each PHI category, to clarify the relevance of different types of errors. Furthermore, please move some pretraining details from the appendix to the main section for better context, and clarify the differences between "BERT-wwm" and BERT-base-chinese. Lastly, the authors should address the identified typos and include the missing references to enhance the paper's rigor.