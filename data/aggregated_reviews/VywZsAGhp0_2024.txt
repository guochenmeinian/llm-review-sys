ID: VywZsAGhp0
Title: Deep Graph Neural Networks via Posteriori-Sampling-based Node-Adaptative Residual Module
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 4, 7, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to address over-smoothing in Graph Neural Networks (GNNs) through the Posterior-Sampling-based, Node-Adaptive Residual module (PSNR). The authors propose that the limitations of previous residual methods stem from their inability to adapt to higher-order neighborhood information. The PSNR module learns node-adaptive residual coefficients via posterior inference using a graph encoder, demonstrating its effectiveness through theoretical analysis and extensive experiments.

### Strengths and Weaknesses
Strengths:
- The method of using node-level coefficients for residual connections is innovative.
- The paper is well-written, making complex concepts accessible.
- The theoretical foundations and motivations for the PSNR module are compelling.
- Extensive experimental validation across various scenarios showcases the robustness of the PSNR module.

Weaknesses:
- The discussion of related works is limited, focusing only on residual methods. A brief overview of other GNN methods for over-smoothing alleviation, such as GPR-GNN, is necessary.
- Key state-of-the-art baseline methods on heterophilic datasets, like GPR-GNN and ACM-GNN, are not included in the performance comparison.
- The performance of the vanilla initial residual module appears similar to PSNR for deeper architectures, raising questions about the justification for the more complex PSNR module. Additionally, the baseline init-res-GCN is missing from Table 3.
- Reported performance metrics for baselines like GCN and GCNII do not align with original papers, necessitating clarification from the authors.
- The empirical study of the residual coefficients lacks depth; it would be beneficial to analyze how coefficients vary with node degree and layer depth.

### Suggestions for Improvement
We recommend that the authors improve the discussion of related works by including a broader overview of GNN methods addressing over-smoothing. Additionally, the authors should incorporate key baseline methods on heterophilic datasets into their performance comparisons. To justify the complexity of the PSNR module, the authors need to clarify its advantages over the initial residual module. We also suggest that the authors ensure the reported performance metrics for baseline methods align with original studies and provide a detailed empirical analysis of how residual coefficients change with node degree and layer depth. Lastly, the authors should polish the manuscript for consistency in formula numbering and enhance the technical descriptions for better reader comprehension.