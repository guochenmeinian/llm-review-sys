ID: 1VsVZm4DLg
Title: All Things Considered: Detecting Partisan Events from News Media with Cross-Article Comparison
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an approach to detecting partisan events in news articles, focusing on how media ideology influences event selection. The authors propose a new NLP task for partisan event detection and introduce a latent variable model to identify partisan events, supported by a modest annotated dataset of 828 events from 50 articles on two political issues. The study aims to deepen the understanding of media bias by analyzing the presence and absence of events in news coverage.

### Strengths and Weaknesses
Strengths:
- The investigation of media bias at the event selection level is a significant societal challenge, and the proposed methods are innovative.
- The introduction of a new annotated dataset and latent variable models demonstrates potential for advancing research in this area.
- The paper is well-written and presents a clear motivation for the study.

Weaknesses:
- The experimental settings are underspecified, leading to confusion regarding the task format and evaluation metrics.
- The dataset is limited in size and scope, derived from only two political issues, which may restrict the generalizability of findings.
- The model shows only marginal improvement over a minimal baseline, raising concerns about its practical applicability.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the experimental settings by providing a detailed task definition section at the beginning of Section 3, explicitly outlining the evaluation format. Additionally, including the percentage of partisan events in the train/test/dev splits would help contextualize baseline performance. To enhance the discussion on media bias, we suggest elaborating on the relationship between ideology, agenda setting, and framing bias, particularly how event selection bias contributes to this analysis. Finally, addressing the low inter-annotator agreement and expanding the dataset could strengthen the study's findings and implications.