ID: DVjyq5eCAD
Title: Chasing Fairness Under Distribution Shift: A Model Weight Perturbation Approach
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 7, 6, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 2, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to addressing fairness in machine learning models under distribution shifts by establishing a theoretical connection between distribution shift, data perturbation, and model weight perturbation. The authors propose the Robust Fairness Regularization (RFR) method, which aims to ensure fairness transference under distribution shifts. Experimental results demonstrate that the RFR method achieves a better fairness-accuracy tradeoff compared to existing baselines across both synthetic and real datasets.

### Strengths and Weaknesses
Strengths:
1. The paper tackles a significant problem of fairness under covariate shift, providing a strong theoretical foundation linking data and model perturbations.
2. The insights drawn from optimal transport to optimize worst-case scenarios within the model weight perturbation ball are novel and well-articulated.
3. The experiments conducted are thorough, showcasing the method's effectiveness in balancing fairness and accuracy.

Weaknesses:
1. The theoretical motivation, particularly Theorem 2.3, lacks clarity regarding the relationship between the magnitudes of input and weight perturbations, which raises concerns about practical applicability.
2. The method is primarily tested on neural network architectures, potentially limiting its generalizability to other algorithm types, such as decision trees.
3. The paper focuses on a single fairness metric—Demographic Parity—without acknowledging the broader spectrum of algorithmic fairness.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the theoretical framework, particularly in addressing how to select the perturbation parameter $\rho$ in a principled manner without access to the target distribution. Additionally, we suggest including comparisons of the weight perturbation method against input perturbation methods to strengthen the theoretical claims. It would also be beneficial to expand the discussion on the limitations of the approach, particularly regarding the implications of using a single fairness metric and the differences between algorithmic fairness and broader socio-technical fairness. Finally, we encourage the authors to clarify the experimental observations, especially regarding the statistical significance of results and the performance of baselines under varying conditions.