ID: 2MiTZxLFA9
Title: GRACE: Discriminator-Guided Chain-of-Thought Reasoning
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a step-wise decoding method for multi-step reasoning, utilizing a discriminator to evaluate the correctness of each generated step in a chain of thought (CoT). The authors propose that this approach addresses the limitations of existing voting methods, which require generating the entire CoT, thus consuming more resources. The method demonstrates empirical gains across various symbolic reasoning datasets, showing its effectiveness in improving task performance.

### Strengths and Weaknesses
Strengths:
1. The use of a discriminator for step-wise decoding is novel and addresses high probability scores assigned to incorrect steps by language models.
2. The method shows clear empirical improvements over baselines like greedy decoding and Self-Consistency.
3. The paper is well-written and provides sufficient detail to clarify key concepts.

Weaknesses:
1. The reliance on training data for the discriminator raises concerns about the method's applicability to tasks with limited data.
2. The motivation for preferring step-wise voting over CoT voting is insufficiently discussed.
3. The proposed method's dependency on models that provide logits limits its applicability to certain language models.

### Suggestions for Improvement
We recommend that the authors improve the motivation for step-wise voting by thoroughly discussing its practical benefits, particularly in real-life applications. Additionally, it would strengthen the paper to demonstrate whether the discriminator can transfer to other tasks without further training or can be effectively trained with minimal data. We also suggest including qualitative analyses to illustrate how the discriminator selects correct steps and addressing the limitations of relying on human-annotated reasoning steps for positive examples. Lastly, consider conducting experiments with larger language models like GPT-3 to assess the method's relevance in the context of evolving model sizes.