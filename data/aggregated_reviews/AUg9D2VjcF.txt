ID: AUg9D2VjcF
Title: One Sample Fits All: Approximating All Probabilistic Values Simultaneously and Efficiently
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 6, 6, 6, 7, -1, -1, -1, -1
Original Confidences: 2, 1, 1, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel framework called One-Sample-Fits-All (OFA) for efficiently approximating probabilistic values, including Beta Shapley and weighted Banzhaf values. The authors propose an algorithm that maximizes sample reuse while avoiding variance amplification, allowing for the simultaneous approximation of multiple probabilistic values. The framework includes two estimators: OFA-A, optimized for all probabilistic values on average, and OFA-S, tailored for specific values. The empirical results indicate that OFA-A achieves the fastest known convergence rate for Beta Shapley values.

### Strengths and Weaknesses
Strengths:
1. The introduction of the OFA framework addresses a significant gap in the literature by providing efficient approximations for a wide range of probabilistic values.
2. The use of (ϵ,δ)-approximation to derive convergence rates adds strong theoretical backing to the proposed method.
3. The OFA-A estimator demonstrates superior time complexity for certain probabilistic values, indicating computational efficiency.

Weaknesses:
1. The algorithm approximates "any" probabilistic value rather than "all" simultaneously, requiring reruns for different values.
2. The variances and biases of the estimations are not thoroughly examined, focusing only on whether variances will increase based on the range/value of $m_s$.
3. Key principles like "maximum sample reuse" and "one-for-all estimators" lack formal definitions.
4. The empirical results are limited to small datasets, raising concerns about scalability to larger, real-world datasets.
5. The significance of the contribution relative to existing work achieving $O(n/\epsilon^2 \log (n/\sigma))$ remains unclear.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their algorithm's capabilities by explicitly stating that it approximates "any" probabilistic value rather than "all" simultaneously. Additionally, a thorough examination of the variances and biases in the estimations should be included. We suggest providing formal definitions for key principles such as "maximum sample reuse" and "one-for-all estimators." To enhance the empirical validation, we encourage the authors to test their framework on larger datasets and discuss the challenges of scaling their method in real-world applications. Finally, a dedicated section discussing the limitations of the proposed approach, beyond the brief mention in Proposition 3, would strengthen the paper.