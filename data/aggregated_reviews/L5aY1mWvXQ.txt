ID: L5aY1mWvXQ
Title: Rethinking Evaluation Strategy for Temporal Link Prediction through Counterfactual Analysis
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 5, 6, 4, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel evaluation approach for Temporal Link Prediction (TLP) models, focusing on counterfactual analysis to assess model performance on temporally distorted data. The authors introduce techniques to distort temporal graphs, enabling the creation of distorted test splits applicable to various datasets. Additionally, they propose two new metrics, average time difference (ATD) and average count difference (ACD), to comprehensively measure predictive performance.

### Strengths and Weaknesses
Strengths:
- The introduction of counterfactual analysis for evaluating TLP models is innovative and addresses significant gaps in existing evaluation strategies.
- The paper is well-written and easy to follow, with clear presentation of ideas.
- The proposed distortion techniques can be applied to any temporal graph dataset, enhancing the method's utility.
- The new metrics ATD and ACD provide a more nuanced assessment of model performance.

Weaknesses:
- The rationale behind the performance drop observed with distortion methods is not adequately explained, raising questions about the validity of the evaluation.
- The proposed distortion strategies lack theoretical grounding and are not compared with existing attack methods in dynamic graph learning.
- The experiments are limited to only three datasets and five baselines, which are outdated and insufficient for robust evaluation.
- A related work section is missing, and the implementation of baseline methods is not integrated with the main repository, complicating reproducibility.

### Suggestions for Improvement
We recommend that the authors improve the theoretical justification for why the distortion methods lead to performance drops in TLP models. Additionally, the authors should compare their distortion strategies with existing attack methods to provide context. Expanding the experiments to include more datasets and state-of-the-art baselines would strengthen the findings. We also suggest including a related work section to discuss how this research fits within the broader context of TLP studies. Finally, integrating the implementations of baseline methods with the main repository would facilitate reproducibility of results.