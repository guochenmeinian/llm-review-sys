ID: rI7kbFTSpr
Title: Towards Reliable Model Selection for Unsupervised Domain Adaptation: An Empirical Study and A Certified Baseline
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 7, 6, 7, 5, -1, -1
Original Confidences: 2, 4, 2, 4, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive re-evaluation of model selection methods for unsupervised domain adaptation (UDA), revealing that most existing methods risk selecting the worst-case model. The authors propose a novel ensemble-based method, EnsV, which effectively avoids this issue and consistently outperforms other model selection techniques across various benchmarks. The extensive empirical study includes evaluations of eight existing methods across twelve UDA techniques, emphasizing the importance of reliability in model selection.

### Strengths and Weaknesses
Strengths:
- The paper provides a thorough empirical evaluation of multiple model selection methods and introduces the EnsV method, which effectively avoids worst-case selections.
- The methodology is rigorous, and the experiments are comprehensive, making significant contributions to the field of UDA.
- The clarity of the paper is high, with a well-structured presentation of the methodology and results.

Weaknesses:
- The proposed ensemble method may be overly simplistic, lacking depth in analysis and practical applicability, particularly regarding the computational cost of fully training all candidate models.
- Limitations of the study are not explicitly discussed in the main text, despite being mentioned in the checklist.

### Suggestions for Improvement
We recommend that the authors improve the discussion of limitations within the main text to provide clearer insights into the constraints of their approach. Additionally, exploring the performance of the ensemble method with a limited number of candidates, such as 3, 5, or 7, could enhance understanding of its practicality. Furthermore, we suggest investigating the iterative refinement of the candidate pool by removing the worst-performing model to potentially improve model selection outcomes. Addressing scalability concerns and optimizing the method for large datasets would also enhance its applicability in real-world UDA tasks.