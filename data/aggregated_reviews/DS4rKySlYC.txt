ID: DS4rKySlYC
Title: Causal Interpretation of Self-Attention in Pre-Trained Transformers
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 5, 6, 7, 5, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Attention-Based Causal Discovery (ABCD), establishing a formal link between a pre-trained self-attention layer and a causal graph underlying a sequence of symbols. The authors derive an algorithm to recover the causal structure of a linear-Gaussian Structural Causal Model (SCM) solely from the weights of a pre-trained attention layer. They propose a complete pipeline for generating causal explanations from models like BERT, demonstrating that ABCD outperforms traditional methods using attention matrices for input-output relations.

### Strengths and Weaknesses
Strengths:  
- The ABCD method is reasonable and relies on sound partial correlation CI-testing.  
- The paper provides a unique perspective on causal discovery, effectively deriving covariances and establishing a connection between attention and CI-testing.  
- The proposed pipeline for causal explanations is practical and applicable, showcasing immediate utility in downstream tasks.

Weaknesses:  
- The reliance on unsupervised training assumptions limits applicability to models like BERT, excluding decoder-only models.  
- The lack of comparative evaluation against standard methods and benchmarks raises concerns about the robustness of the findings.  
- The usability of generated causal explanations in practical applications remains unclear, and several sections, including Theorem 1, contain incomplete or vague descriptions.

### Suggestions for Improvement
We recommend that the authors improve the empirical evidence presented in the paper, ensuring a thorough reconsideration of the results. Clarifying the usability of causal explanations in automated settings would enhance the practical relevance of the work. Additionally, we suggest providing a more detailed discussion of the assumptions, particularly regarding the linear Gaussian SCM, and formalizing the requirements for the deepest attention layer to ensure clarity. Addressing the missing explanations for figures and tables, as well as including a related work section, would strengthen the overall presentation. Finally, a careful read-through to correct typos and improve clarity in sections that appear less carefully written is advisable.