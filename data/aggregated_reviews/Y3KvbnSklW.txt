ID: Y3KvbnSklW
Title: A Diagonal State Space Model on Loihi 2 for Efficient Streaming Sequence Processing
Conference: NeurIPS
Year: 2024
Number of Reviews: 2
Original Ratings: 9, 8
Original Confidences: 3, 5

Aggregated Review:
### Key Points
This paper presents a novel implementation of the Diagonal State Space Model (S4D) on Intel’s Loihi 2 neuromorphic processor, demonstrating its efficiency for token-by-token sequence modeling tasks. The authors provide a comprehensive performance comparison against recurrent and convolutional implementations on GPU, covering key metrics like energy, latency, and throughput across various datasets. The energy savings achieved by Loihi 2, particularly in token-by-token processing (1000x less energy consumption), validate the potential of neuromorphic processors in streaming and real-time tasks. Additionally, the work shows the first published implementation of state-space models on neuromorphic hardware, evaluating a modified version of S4D for three time series classification tasks (sMNIST, psMNIST, and sCIFAR-10). While model performance is close to state-of-the-art, the implementation is significantly more energy-efficient and faster than a reference implementation on a Jetson Orin Nano GPU.

### Strengths and Weaknesses
Strengths:  
- High-quality research demonstrating efficient realizations of SSMs on neuromorphic hardware.  
- Well-written and comprehensible paper.  
- Includes detailed energy and latency results with a fair comparison to Jetson Orin Nano, highlighting scenarios where both systems excel.  

Weaknesses:  
- Lack of clarity regarding which model size (small or large) is used for each benchmark in tables 1 and 2.  

### Suggestions for Improvement
We recommend that the authors improve clarity by specifying which model size (small or large) corresponds to each benchmark in tables 1 and 2. Additionally, considering the performance limitations on Jetson due to TensorRT’s lack of support for complex tensors, what improvements would the authors anticipate if a fully optimized Jetson implementation were available? Furthermore, are there any quantization alternatives to post-training fake quantization, and how do they affect performance?