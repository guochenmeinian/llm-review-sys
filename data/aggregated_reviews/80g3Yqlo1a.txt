ID: 80g3Yqlo1a
Title: Fast Scalable and Accurate Discovery of DAGs Using the Best Order Score Search and Grow Shrink Trees
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 4, 5, 6, 5, -1, -1, -1, -1
Original Confidences: 2, 1, 2, 1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the best order score search (BOSS) algorithm and grow-shrink trees (GSTs) for learning directed acyclic graphs (DAGs) in machine learning and causal discovery. BOSS demonstrates state-of-the-art performance in accuracy and execution time, particularly for problems with highly connected variables. The authors validate BOSS using resting-state fMRI data, showcasing its practical effectiveness and efficiency compared to the existing Greedy Sparsest Permutation (GRaSP) algorithm. The paper also introduces GSTs, which cache results from grow and shrink subroutines, enhancing the efficiency of various structure learning algorithms.

### Strengths and Weaknesses
Strengths:
- The introduction of GSTs provides a novel approach for efficiently storing information necessary for running grow and shrink algorithms, compatible with multiple permutation-based structure learning methods.
- The paper is well-written, with clear explanations and illustrative figures and tables, facilitating understanding of the proposed algorithm.
- BOSS is compared against other algorithms like GRaSP, fGES, PC, and DAGMA, demonstrating high accuracy and improved scalability, indicating its potential value in structure learning.

Weaknesses:
- There is insufficient discussion on the limitations of BOSS and GSTs, particularly regarding assumptions like causal sufficiency and their impact on accuracy and scalability. The applicability of BOSS to diverse data types beyond fMRI is also not explored.
- Validation on real-world data is limited; broader testing on various datasets could enhance the robustness of the findings.
- The paper lacks a thorough examination of the computational complexity of the algorithm and the implications of initial permutations under certain conditions.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the limitations of the BOSS algorithm and GSTs, including assumptions made and their potential effects on performance. Additionally, exploring the applicability of BOSS to other data types, such as financial data or electronic health records, would provide a more comprehensive understanding of its utility. Expanding validation to include diverse real-world datasets would strengthen the findings. 

We also suggest including a section on the ethical implications of the work, addressing potential biases in data and the consequences of incorrect predictions. Clarifying the scalability of the proposed techniques, particularly regarding the computational complexity and the conditions under which initial permutations matter, would enhance the paper's clarity. Lastly, we encourage the authors to provide more insight into the interpretation of results and the rationale behind their conclusions.