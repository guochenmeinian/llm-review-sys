ID: 0YdEK1Dnbn
Title: Does Safety Training of LLMs Generalize to Semantically Related Natural Prompts?
Conference: NeurIPS
Year: 2024
Number of Reviews: 2
Original Ratings: 7, 7
Original Confidences: 4, 4

Aggregated Review:
### Key Points
This paper presents a method to identify adversarial prompts, termed jailbreaking prompts, that successfully elicit unsafe outputs from safety-tuned LLMs while remaining similar to natural prompts. The authors hypothesize that safety-tuning does not generalize equally to answer and question generation, defining a set of unsafe answers and finding prompts that trigger these outputs. The evaluation of the proposed Response Guided Question Augmentation (ReG-QA) method demonstrates its effectiveness in assessing the generalization of safety fine-tuning in LLMs.

### Strengths and Weaknesses
Strengths:  
- The paper is well-structured, with clear definitions and explanations.  
- The originality of the ReG-QA method provides a novel approach to probing LLMs beyond typical adversarial attacks.  
- The findings raise significant questions regarding the generalization capabilities of safety alignments in LLMs, suggesting areas for future improvement.

Weaknesses:  
- The analysis lacks depth regarding the phenomenon of safety training not generalizing from answer to question generation.  
- There is insufficient discussion on why certain subjects perform better or worse in terms of jailbreak effectiveness compared to paraphrasing.  
- The choice of using Palm2-Otter solely for Q->A generation is not justified, and performance comparisons with other unaligned models are missing.

### Suggestions for Improvement
We recommend that the authors improve the discussion surrounding the phenomenon of safety training not generalizing from answer to question generation, including insights into why current defenses fail. Additionally, we suggest contrasting the performance of the ReG-QA method with unaligned question generators to provide a more comprehensive analysis. Evaluating the performance of other unaligned base models would also enhance the study. Finally, we encourage the authors to explore the reasons behind the varying effectiveness of different subjects in jailbreak scenarios compared to paraphrasing.