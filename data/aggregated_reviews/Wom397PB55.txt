ID: Wom397PB55
Title: TheoremQA: A Theorem-driven Question Answering Dataset
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents TheoremQA, a theorem-driven question-answering dataset aimed at evaluating AI models' abilities to apply theorems in solving complex scientific problems. The dataset includes 800 high-quality questions based on over 350 theorems across various fields, including Mathematics, Physics, Electrical Engineering & Computer Science, and Finance. The authors propose a comprehensive evaluation of 16 large language models (LLMs) using innovative prompting strategies like Chain-of-Thoughts (CoT) and Program-of-Thoughts (PoT), providing insights into model performance and limitations.

### Strengths and Weaknesses
Strengths:
- TheoremQA is the first dataset of its kind, offering a valuable resource for researchers focused on theorem-driven question-answering.
- The thorough evaluation of 16 LLMs reveals both strengths and weaknesses in their capabilities to integrate theorems and understand multimodal inputs.
- The methodology is sound, employing innovative prompting strategies to guide LLMs effectively.

Weaknesses:
- The dataset exhibits an imbalanced distribution, with more than half of the questions focused on Mathematics, which may limit its applicability across other fields.
- The paper lacks detailed examples of the prompts used in experiments, making it difficult to fully assess the effectiveness of the employed strategies.

### Suggestions for Improvement
We recommend that the authors improve the dataset's balance by including a more even distribution of questions across all fields represented. Additionally, we suggest that the authors include detailed examples of the prompts used in their experiments, particularly in the appendix, to enhance the transparency and evaluative capacity of their methodology.