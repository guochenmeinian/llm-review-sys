ID: 1mGD6ZLTwv
Title: Assessing Privacy Risks in Language Models: A Case Study on Summarization Tasks
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a detailed investigation of membership inference (MI) attacks on large language models (LLMs) specifically within the context of summarization tasks. The authors propose a method that utilizes black-box access to determine if a sample was part of the training data, leveraging text similarity and model output stability under various modifications. The evaluation across multiple datasets, including SAMsum, CNN and Daily Mail, and MIMIC, demonstrates that summarization models are vulnerable to exposing data membership, even without access to reference summaries. The paper also discusses potential safeguards against such attacks.

### Strengths and Weaknesses
Strengths:  
- The paper is well-written, clear, and easy to comprehend.  
- It presents a novel task formulation and extensive experimentation, including ablation studies that highlight the impact of overfitting, data size, and model architecture.  
- The results appear generalizable across different datasets, and plausible defense mechanisms against MI attacks are proposed.  

Weaknesses:  
- The rationale for focusing on summarization rather than other tasks, such as machine translation, is not adequately explained.  
- The use of BART-Base and Flan-T5 models may not reflect the most current advancements in model architecture.  
- The augmentation strategies employed, while effective, may lack diversity and could benefit from exploring different approaches.  
- Minor typographical errors are present, such as the incorrect use of "lunch" instead of "launch."

### Suggestions for Improvement
We recommend that the authors improve the justification for focusing on summarization over other tasks, such as machine translation, to clarify the significance of their choice. Additionally, consider employing more advanced models to enhance the robustness of the findings. We suggest diversifying the augmentation strategies beyond word synonym replacement, sentence swapping, and back translation, perhaps by summarizing from overlapping segments of the input document. Lastly, we encourage the authors to thoroughly proofread the paper to correct typographical errors and enhance overall presentation.