ID: xOJUmwwlJc
Title: Proximity-Informed Calibration for Deep Neural Networks
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 6, 7, 7, 6, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 5, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper quantifies and proposes a mitigation for miscalibration in DNN training, particularly focusing on 'unusual' examples, defined by their average distance to their K=10 nearest neighbors. The authors introduce a new proximity-aware calibration metric, PIECE, which captures calibration issues not addressed by the standard ECE metric. They also propose a mitigation method, ProCal, available in two variations for continuous and discrete confidence scores, which adjusts uncalibrated probability scores based on the model's miscalibration on examples with a specific average distance.

### Strengths and Weaknesses
Strengths:
- The paper is clearly written, logically structured, and provides good explanations, with a strong motivation stemming from experiments leading to theory-driven proposals and further verification.
- The original miscalibration problem is relevant and well-motivated, with the proposed metric and mitigations being simple yet effective, potentially leading to their adoption.
- The empirical investigation into proximity bias is novel, with extensive experiments across numerous models and datasets.

Weaknesses:
- The characterization of 'atypical' examples could be improved, as the relationship to underrepresented categories is not always clear.
- The ProCal method's naming could be more precise, suggesting the use of ProCAL-C and ProCAL-D for clarity.
- The analysis of ProCal's effectiveness lacks depth, particularly regarding its performance in conjunction with certain methods, which requires a more thorough explanation.
- Some algorithmic and implementation details are insufficiently detailed, particularly in Section 5.1, and the experimental setup could be clearer.

### Suggestions for Improvement
We recommend that the authors improve the characterization of 'atypical' examples to clarify their relationship to underrepresented categories. Additionally, consider renaming the ProCal variations to ProCAL-C and ProCAL-D for clarity. A more thorough analysis of ProCal's effectiveness, especially regarding its performance with various methods, should be included. Furthermore, we suggest enhancing the presentation of algorithm details in Section 5.1 and clarifying the experimental setup, particularly the computation of ECE and ACE.