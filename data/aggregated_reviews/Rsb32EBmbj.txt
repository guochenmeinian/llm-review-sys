ID: Rsb32EBmbj
Title: Exploring Adversarial Robustness of Deep State Space Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 5, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into the effectiveness of traditional Adversarial Training (AT) methods on State Space Models (SSMs). The authors find that pure SSMs are not suitable for AT, while attention-based SSMs learn adversarial features more effectively. They propose that adaptive parameterization in Mamba, contrary to intuitive expectations, is detrimental to the adversarial robustness (AR) of SSMs. Their findings indicate that adaptive parameterization does not yield performance gains over S4 and DSS and may even result in negative gains. Additionally, the introduction of Attention into SSMs has led to robustness overfitting (RO) issues, limiting the anticipated benefits. The paper develops a theoretical proof and applies Adaptive Scaling (AdS) to enhance robust generalization in SSMs, with experiments primarily conducted on MNIST and CIFAR-10 datasets. The authors suggest that regularization and adaptive scaling strategies could mitigate these issues.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written, with a clear storyline and motivation.
2. The exploration of trustworthiness in SSMs is an important and under-explored topic.
3. The theoretical proof of the generalization bound is clearly articulated.
4. The paper provides a thorough theoretical analysis supported by experimental validation, elucidating the negative impact of adaptive parameterization and Attention on AR.
5. The authors have conducted evaluations on larger datasets, enhancing the robustness of their findings.
6. The revisions made in response to reviewer feedback demonstrate a commitment to improving the paper's quality.

Weaknesses:
1. The evaluation dataset is limited in size, lacking representation; findings would be more convincing with larger datasets like CIFAR-100 or Tiny-ImageNet.
2. The adversarial training methods employed lack novelty; classic methods like PGD-AT and TRADES could be supplemented with more efficient variants such as Free-AT and YOPO to enhance performance.
3. The claim regarding robust overfitting is unclear, as the results suggest minimal differences in performance metrics.
4. The initial presentation may have caused confusion regarding the conclusions drawn from the results.
5. The complexity introduced by Attention mechanisms may not have been adequately addressed in the original manuscript.

### Suggestions for Improvement
We recommend that the authors improve the empirical evaluation by including larger datasets such as CIFAR-100 and Tiny-ImageNet to enhance the representativeness of their findings. Additionally, consider integrating more novel adversarial training methods, such as Free-AT and YOPO, to assess their impact on SSM performance. Clarifying the robust overfitting claim with more comprehensive analysis and results, particularly regarding the influence of different activation functions in AdS, would strengthen the paper's arguments. Furthermore, we suggest improving the clarity of the presentation to better convey the novelty and implications of the findings. Incorporating regularization techniques into the design of adaptive SSM parameterization to control perturbation errors and exploring adaptive scaling strategies that maintain low model complexity to avoid RO issues while enhancing AR would also be beneficial.