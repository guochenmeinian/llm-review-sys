ID: OGQWZ3p0Zn
Title: Inserting Anybody in Diffusion Models via Celeb Basis
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 5, 6, 7, 5, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 5, 4, 2, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method for personalizing pre-trained text-to-image models using a single facial photograph. The authors propose constructing a "celeb basis" from the embedding space of a pre-trained text encoder, optimizing the weights of this basis to generate unique identity embeddings while locking other parameters. The method demonstrates superior concept combination abilities and the potential for generating highly customized images compared to existing methods. The authors plan to release their code.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and clearly conveys its main concepts.
2. The approach of constructing a celeb basis from the text embedding space is innovative and effective.
3. The results indicate improved visual quality and concept composition compared to previous methods like DreamBooth and Custom diffusion.

Weaknesses:
1. The reliance on a celeb name basis may restrict the model's expressiveness, as it is unclear what distribution of face, age, and gender was used, which is essential for assessing robustness.
2. The paper lacks an ablation study comparing the use of PCA for finding the celeb basis, making it difficult to evaluate PCA's necessity in the method.
3. The quality of generated images, such as those in Figure 5, shows distortion and low fidelity, indicating a need for further analysis.

### Suggestions for Improvement
We recommend that the authors improve the expressiveness of the personalized model by providing a clearer distribution of face, age, and gender used in the celeb basis. Additionally, we suggest conducting an ablation study to evaluate the impact of PCA on the model's performance. To enhance the quality of generated images, we encourage the authors to analyze and address the distortions observed in the results. Furthermore, sharing results from images with poor alignment would provide valuable insights into the method's robustness. Lastly, we recommend exploring the generalizability of the framework beyond face generation, potentially including examples of non-face image generation.