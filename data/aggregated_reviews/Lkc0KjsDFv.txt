ID: Lkc0KjsDFv
Title: CS-Isolate: Extracting Hard Confident Examples by Content and Style Isolation
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 3, 7, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 2, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method, CS-Isolate, aimed at extracting hard confident examples from noisy datasets by disentangling content and style factors. The authors argue that the entanglement of style information with content factors complicates the identification of hard examples near the decision boundary. Their approach employs various data augmentation techniques to modify style factors while keeping content factors consistent, and they support their claims with theoretical analysis and empirical results across multiple datasets.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant issue in machine learning regarding the extraction of hard confident examples from noisy labels.
- The proposed method offers innovative insights into disentangling style and content factors, which may enhance the identification of hard examples.
- The organization and visual aids in the paper facilitate understanding of complex concepts, and the method achieves state-of-the-art performance on benchmark datasets.

Weaknesses:
- The novelty of the approach is questioned, as it appears to be a minor variation of existing methods in disentangled representations.
- The experimental design lacks clarity, particularly regarding the levels of label noise, which hampers the comparability of results.
- There is insufficient empirical support for the claim that style factors are primarily responsible for the difficulty in identifying hard examples.
- The paper does not adequately discuss limitations or provide a comprehensive evaluation on larger datasets or real-world label noise.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the experimental design by explicitly stating the noise levels used in their evaluations, as vague terms like "random 1" and "random 2" are insufficient. Additionally, we suggest including visualizations of the extracted content and style factors to substantiate their claims and enhance reader comprehension. The authors should also consider expanding their experiments to include larger datasets, such as Clothing1M, and various types of label noise to strengthen their findings. Furthermore, a dedicated section discussing the limitations of their method, including computational requirements and sensitivity to hyperparameters, would provide a more balanced perspective. Lastly, we encourage the authors to clarify ambiguous sentences and ensure that all technical details, such as the derivation of the Evidence Lower Bound (ELBO), are adequately addressed in the main text.