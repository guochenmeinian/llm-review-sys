ID: U2Mx0hSRwA
Title: Ordered Momentum for Asynchronous SGD
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 5, 5, 3, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Ordered Momentum (OrMo) method, which enhances asynchronous stochastic gradient descent (ASGD) by integrating momentum based on the iteration index of gradients. The authors provide theoretical proofs demonstrating the convergence of OrMo for non-convex problems, marking a significant advancement as it does not rely on the bounded delay assumption. Empirical results validate that OrMo outperforms standard ASGD and other asynchronous momentum variants in terms of convergence rates.

### Strengths and Weaknesses
Strengths:
1. The OrMo method is a novel contribution to ASGD, proving convergence without the bounded delay assumption.
2. The paper includes comprehensive experimental validation, demonstrating OrMo's superior convergence performance.
3. Detailed algorithm implementation and open access to experimental code enhance reproducibility.
4. Clear experimental settings and results indicate significant performance improvements over baseline methods.

Weaknesses:
1. The generalization ability of OrMo requires further testing across diverse datasets and application scenarios.
2. The paper lacks a detailed discussion on the computational resource requirements for OrMo, particularly regarding the caching of ordered momentum on the server.
3. The re-ordering method resembles staleness control but lacks a thorough comparison with existing methods.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the computational resource requirements of the OrMo method, particularly regarding the storage costs associated with caching ordered momentum. Additionally, we suggest that the authors explore the effects of asynchronous delays on convergence, as this is crucial for understanding the performance of ASGD algorithms. It would also be beneficial to extend the theoretical analysis to adaptive learning rates or decreasing learning rates, which are more commonly used in practice. Lastly, we encourage the authors to include comparisons with standard synchronous SGD with momentum and other penalty function methods in their experimental results to provide a clearer context for OrMo's performance.