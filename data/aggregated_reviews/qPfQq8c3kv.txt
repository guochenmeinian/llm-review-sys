ID: qPfQq8c3kv
Title: High-quality argumentative information in low resources approaches improve counter-narrative generation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an approach to enhance counter-narrative generation against hate speech by incorporating human-annotated argumentative aspect information. The authors propose that current methods primarily utilize hate speech text without considering contextual argumentative structures. They collect four types of argumentative information and demonstrate that this additional context improves performance, particularly in low-resource languages like Spanish. The study also reveals that smaller models can outperform larger ones in this task, suggesting a potential shift in model selection for such applications.

### Strengths and Weaknesses
Strengths:  
- The paper addresses a critical application of NLP in generating counter-narratives against hate speech, with clear motivation and significant contributions to the NLP community through the construction of two datasets.  
- The methodology is sound, and the findings indicate that enriching input data with argumentative information can enhance the performance of smaller models over larger ones.  
- The authors provide a critical perspective on traditional evaluation metrics, avoiding uninformative scores.

Weaknesses:  
- The paper lacks detailed descriptions of the annotation process, including reliability testing and the qualifications of annotators, which raises concerns about subjectivity.  
- The few-shot learning experiments are limited, with only two examples used at a time, which may restrict the model's learning potential.  
- The justification for not finetuning the Flan-T5 XL model is insufficient, and the rationale for selecting Flan-T5 over other generative models is unclear.  
- The discussion on ethical implications and the clarity of evaluation criteria is superficial, needing further elaboration.

### Suggestions for Improvement
We recommend that the authors improve the description of the annotation process, including details on reliability testing, payment, and annotator qualifications. Additionally, consider expanding the few-shot learning experiments to include more examples to better assess model performance. We suggest providing a clearer justification for the choice of Flan-T5 and addressing the limitations of not finetuning the Flan-T5 XL model. Furthermore, we encourage the authors to include a paragraph discussing the ethical implications of their work and to clarify the scoring mechanism used in evaluations, potentially formalizing it mathematically. Lastly, we advise restructuring the discussion section into subsections to enhance readability and comprehension.