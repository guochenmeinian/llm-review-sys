ID: KmdlUP23qh
Title: Generalizing Importance Weighting to A Universal Solver for Distribution Shift Problems
Conference: NeurIPS
Year: 2023
Number of Reviews: 20
Original Ratings: 8, 7, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Generalized Importance Weighting (GIW) method aimed at addressing distribution shift problems, particularly when the support of the training distribution does not fully encompass that of the test distribution. The authors investigate the shortcomings of existing importance weighting techniques in these scenarios and propose a theoretically justified objective that enhances classifier consistency. The experiments conducted provide empirical support for the effectiveness of the proposed method, demonstrating its advantages over traditional approaches.

### Strengths and Weaknesses
Strengths:
- The problem setting is significant and relevant, as it addresses common real-world scenarios where existing methods fail.
- The paper contributes a novel principle regarding classifier-consistency objectives in the context of distribution shift.
- The experimental design is robust, with a comprehensive selection of baselines that validate the proposed method.

Weaknesses:
- The practical scenarios outlined could be better justified, particularly regarding the frequency of training distribution support containing test distribution support.
- The terminology in Figure 2 may cause confusion, necessitating clearer labeling.
- The motivation for introducing risk consistency from label-noise literature lacks depth and should be better contextualized.
- The impact of one-class classifier performance on the proposed method remains unclear, requiring further experimental analysis.
- The experiments are limited to smaller datasets and models, with a lack of evaluation on larger datasets like ImageNet or more complex architectures.

### Suggestions for Improvement
We recommend that the authors clarify the motivation behind the importance of the support shift issue and address whether it has been overlooked or deemed insignificant by previous researchers. Additionally, we suggest providing a more thorough explanation of the assumption regarding classifier knowledge transfer between training and test distributions. The authors should also consider discussing the implications of their findings in relation to the more general definition of importance weighting, as well as comparing their approach with transfer learning and domain adaptation techniques. Finally, we encourage the authors to expand their experimental analysis to include larger datasets and modern architectures to enhance the robustness of their findings.