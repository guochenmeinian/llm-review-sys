ID: URkFX1jmOd
Title: Night-to-Day Translation via Illumination Degradation Disentanglement
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 4, 5, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an approach, N2D3, for night-to-day image translation, involving two stages: illumination degradation disentanglement and degradation-aware contrastive learning. The first stage decomposes an image into darkness, well-lit areas, light effects, and highlight regions, while the second stage applies contrastive learning to these nighttime degradations. The authors introduce a photometric model that assumes materials are uniform and homogeneous within a local area, simplifying the reflectivity function $R_{\\infty}(λ,x)$ to $cR(λ)$. They also introduce a material spatial distribution function $C(x)$ to model complex nighttime scenes, which is essential for accurately representing nighttime environments. Extensive experiments on the BDD100K and Alderley datasets demonstrate that N2D3 outperforms existing methods, achieving state-of-the-art performance in visual quality and downstream tasks. The paper includes ablation studies showing that while performance improves with refined classification into four clusters, a physical prior enhances segmentation and overall performance.

### Strengths and Weaknesses
Strengths:  
- The paper addresses the critical problem of night-to-day image translation in computer vision.  
- The authors provide comprehensive experimental validation, showing improved performance metrics such as FID and downstream task performance.  
- The introduction of the material spatial distribution function $C(x)$ enhances the model's applicability to complex scenes.  
- The use of the Kubelka-Munk theory for different degradation types and the patch-based image translation is novel.  
- The ablation studies demonstrate the effectiveness of the proposed physical prior in improving performance.  
- The authors clarify the distinction between settings using three and four clusters for disentangling light effects.

Weaknesses:  
- The paper has a significant omission of a key citation, violating academic integrity, particularly concerning the derivation of the color invariant term.  
- Clarity of the method sections is lacking; explanations for Eqs (1) to (5) and the motivation for the degradation-aware reweighting (DAR) are unclear.  
- The model struggles with maintaining semantic consistency in night-to-day translation, which could be improved.  
- The explanation of the four-category segmentation lacks clarity, raising concerns about scalability and the method's foundation for future work.  
- The ablation studies are insufficient, lacking depth in analyzing the impact of using four versus three types of degradation.  
- The paper suffers from poor presentation, including inconsistent citation styles and missing key citations.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the method sections by providing rigorous definitions and visualizations of well-lit areas and light effects. Additionally, the authors should include proper citations for previous work where applicable. To address the missing citation issue, the authors must explicitly cite the original work by Geusebroek et al. in relevant sections and clarify the rationale behind the omission. We suggest improving the explanation of the four-category segmentation to address scalability concerns and consider exploring the alternative of learning a per-pixel curve for different regions to enhance semantic consistency. Furthermore, we urge the authors to revise the presentation by ensuring consistent citation styles, including all key citations, and clarifying theoretical assumptions and notations throughout the paper. Finally, conducting more thorough ablation studies to verify the impact of the four degradation categories and comparing the proposed method with more recent techniques for unpaired image-to-image translation would enhance the paper's coherence and technical soundness.