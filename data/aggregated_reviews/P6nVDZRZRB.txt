ID: P6nVDZRZRB
Title: Are Uncertainty Quantification Capabilities of Evidential Deep Learning a Mirage?
Conference: NeurIPS
Year: 2024
Number of Reviews: 21
Original Ratings: 5, 6, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a critique and analysis of the Evidential Deep Learning (EDL) framework, identifying its limitations in accurately representing aleatoric and epistemic uncertainties. The authors propose a unified objective function that encompasses various EDL methods and highlight the inadequacies of these methods in practical applications, particularly in out-of-distribution (OOD) detection. They introduce a Bootstrap-distill method aimed at integrating model uncertainty to improve uncertainty quantification. Additionally, the paper analyzes EDL approaches' asymptotic behavior and their interpretation as OOD detection algorithms based on energy-based models, validated through extensive experiments on image classification tasks, specifically CIFARs and TinyImageNet.

### Strengths and Weaknesses
Strengths:
- The paper provides a comprehensive critique of EDL methods, revealing their similarities and limitations.
- It introduces a novel unified objective function that consolidates multiple EDL approaches, enhancing conceptual clarity.
- The empirical validation through experiments on benchmark datasets supports the claims regarding EDL weaknesses.
- The discussion on EDL's relationship with energy-based models (EBMs) contributes to a deeper understanding of uncertainty quantification.
- The authors effectively clarify the computational efficiency of their distillation-based method compared to classical EDL methods.
- The paper is clearly written, making the concepts intuitive and accessible.

Weaknesses:
- The critique of EDL's inability to represent uncertainties lacks novelty and depth, as it reiterates known issues without sufficient theoretical backing.
- The Bootstrap-distill method's theoretical justification is weak, and its practical implications remain unclear.
- The paper's density leads to insufficient clarity on implementation details, particularly regarding distillation methods.
- Key comparisons with state-of-the-art (SOTA) OOD detection methods are missing, limiting the contextual relevance of the proposed model.
- The experimental evaluation is limited to image classification tasks, lacking evidence to support the applicability of the findings in other domains, such as text or graph data, and regression tasks.
- The evaluation relies solely on ResNet18 and VGG16 models; incorporating more recent architectures would enhance the robustness of the results.
- The analysis of bootstrap distillation lacks depth, and comparisons with Bayesian methods are insufficiently explored.
- The evaluation of the proposed model is limited, particularly regarding the behavior of aleatoric and epistemic uncertainties, which may not align with expected theoretical outcomes.
- Some aspects of the distillation process and its implications are not clearly articulated, potentially leading to misunderstandings.

### Suggestions for Improvement
We recommend that the authors improve the theoretical justification for the Bootstrap-distill method to ensure it reliably expresses epistemic and aleatoric uncertainties. Additionally, consider providing clearer implementation details and justifications for the proposed model's behavior in uncertainty quantification. We suggest including comparisons with SOTA OOD detection methods to strengthen the claims regarding the efficacy of the proposed approach. Furthermore, we recommend improving the experimental evaluation by including additional domains, such as text and regression tasks, to demonstrate the generalizability of their findings. Incorporating state-of-the-art models beyond ResNet18 and VGG16 would also provide a more comprehensive assessment of their approach. We advise conducting a more thorough analysis of bootstrap distillation, comparing it extensively with both Bayesian and EDL methods to substantiate its advantages. Lastly, clarifying the behavior of aleatoric uncertainty with varying sample sizes and across different datasets, as well as incorporating results from larger datasets such as CIFAR100, Tiny-Imagenet, and ImageNet, would strengthen the practical implications of their work.