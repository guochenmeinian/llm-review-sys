ID: JDAQwysFOc
Title: Non-convolutional graph neural networks.
Conference: NeurIPS
Year: 2024
Number of Reviews: 21
Original Ratings: 6, 6, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel random walk-based graph neural network (GNN) called Random Walk with Unifying Memory (RUM), which utilizes recurrent neural networks (RNNs) to integrate topological and semantic features from graphs. The authors argue that RUM overcomes common issues associated with convolution-based GNNs, such as limited expressiveness, over-smoothing, and over-squashing. Theoretical and empirical analyses demonstrate RUM's competitive performance on various node- and graph-level tasks, asserting its advantages in efficiency and scalability.

### Strengths and Weaknesses
Strengths:
1. RUM introduces a unique non-convolutional approach to GNNs, enhancing graph representation through random walks and RNNs.
2. The paper is generally well-organized and presents a clear contextualization of its contributions relative to existing literature.
3. The theoretical and empirical results substantiate RUM's advantages over traditional convolutional GNNs.

Weaknesses:
1. Empirical gains with RUM are marginal, and in some instances, it performs worse than baseline models.
2. The paper lacks a detailed exploration of how varying random walk lengths affect RUM's performance across different tasks.
3. There is insufficient discussion regarding RUM's limitations compared to expressive GNNs, particularly concerning upper bounds on the Weisfeiler-Lehman (WL) test.

### Suggestions for Improvement
We recommend that the authors improve the organization and clarity of the paper by reducing unnecessary hyper-references, particularly in Sections 1 and 2, and by streamlining supplementary demonstrations to enhance readability. Additionally, we suggest proofreading the manuscript to correct grammatical errors. The authors should elaborate on the impact of random walk length on RUM's performance and identify optimal lengths for various graph types. Furthermore, a more thorough comparison with Graph Transformer architectures, including discussions on computational costs and performance limitations, would strengthen the paper.