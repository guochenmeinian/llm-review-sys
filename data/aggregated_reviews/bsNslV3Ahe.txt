ID: bsNslV3Ahe
Title: Learning Dynamic Attribute-factored World Models for Efficient Multi-object Reinforcement Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 6, 5, 4, 7, 6, 5, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 4, 2, 4, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Dynamic Attribute Factored RL (DAFT-RL) framework, which aims to enhance compositional generalization in reinforcement learning by learning class template graphs and interaction pattern graphs for objects. The authors demonstrate that their approach allows for effective policy learning and generalization to novel configurations, outperforming state-of-the-art methods across multiple benchmarks. Additionally, the authors propose a framework that does not require pre-defined attributes and can potentially extend to unknown classes. They conducted further ablation studies on a single object class and end-to-end training, addressing concerns raised by reviewers, and performed experiments in the OpenAI-Fetch environment with seven objects, showing consistent performance improvements over baseline methods. However, the technical contribution is viewed as marginal, with skepticism about its applicability to real-world problems outside of toy environments.

### Strengths and Weaknesses
Strengths:
- The proposed attribute-level factorized world model is a significant advancement over traditional object-wise models, enhancing compositionality.
- The paper is well-written, with clear explanations and supportive figures.
- Strong experimental results show that DAFT-RL outperforms various baseline methods, particularly in scenarios requiring generalization.
- Comprehensive ablation studies highlight the importance of major components in the model.
- The authors clarified key aspects of their framework and conducted additional experiments, which were positively acknowledged by some reviewers.
- The method shows consistent performance improvements in controlled environments, particularly in multi-object interactions.

Weaknesses:
- The model's reliance on class labels for learning class template graphs may not be feasible for real-world applications, necessitating extensive labeling efforts.
- The assumption that attributes are accessible is questionable, particularly for recent object-centric representation models.
- The reward function's object-level definition limits its applicability to more complex tasks involving relationships between objects.
- Action binding is inadequately discussed, particularly regarding its effects on multiple objects.
- Clarity issues arise in the presentation, particularly in defining hyper-parameters and the multi-phase training process.
- The technical contribution is considered marginal, with doubts about the novelty and real-world applicability of the approach.
- Performance gains in the Robogym tasks were not significant compared to existing methods, indicating potential limitations in broader contexts.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the limitations of their model, particularly regarding the assumptions of class templates and attribute accessibility. Additionally, clarifying the action binding mechanism and how it can affect multiple objects would enhance understanding. We suggest including more comprehensive ablation studies on the design choices for each module, particularly the dynamic interaction graph and action binding network. Furthermore, we recommend that the authors improve the novelty of their approach by clearly distinguishing it from existing concepts in the literature. Applying their method to real-world problems and demonstrating its effectiveness in those contexts would strengthen their claims regarding scalability and applicability. Finally, addressing the clarity of writing, especially in Section 2 and Figure 1, and including a tailored benchmark that aligns with the environments evaluated would benefit readers' comprehension and enhance the robustness of their findings.