ID: i3PecpoiPG
Title: Expression Sampler as a Dynamic Benchmark for Symbolic Regression
Conference: NeurIPS
Year: 2023
Number of Reviews: 3
Original Ratings: 7, 7, -1
Original Confidences: 4, 3, 3

Aggregated Review:
### Key Points
This paper presents a new, dynamic benchmark framework for evaluating and comparing symbolic regression (SR) methods, utilizing a symbolic expression sampler. The framework generates novel SR tasks based on priors learned from a limited set of real-world equations, extending existing benchmark approaches in a meaningful direction. The analysis incorporates both mean squared error (MSE) and recently proposed evaluation metrics such as symbolic solution rate and normalized edit distance (NED).

### Strengths and Weaknesses
Strengths:  
- The concept of learning domain-specific prior distributions from existing functions to create numerous benchmark tasks relevant to real-world problems is innovative and addresses limitations of prior benchmark suites.  
- The results are promising and the work is well motivated.

Weaknesses:  
- The extent to which the solutions found transfer to the original domain remains unclear, raising questions about the generalizability of the conclusions.  
- The paper requires improvements in clarity and consistency, particularly in terminology and formatting.

### Suggestions for Improvement
We recommend that the authors improve the consistency of names used throughout the paper (e.g., "AI Feynman" vs "AIFeynman" and "GP-GOMEA" vs "GPGOMEA"). Clarifications are needed for structure formats like (0, 1, 1, 2, 2) and terms in Tables 1-3, such as OR, CI, coef, and p. The authors should revise sentences for grammatical accuracy, such as changing "The higher the value of each complexity, the lower the algorithm’s performance on each performance metric." to "The higher the value of each complexity is, the lower the algorithm’s performance on each performance metric is." Additionally, we suggest referencing Table A1 and splitting it into multiple sub-tables for better readability. For future work, consider exploring diverse SR problems with wider ranges of values, such as SRSD [19], and applying a normalized form of MSE, as the fixed input/output value ranges in this study may limit the applicability of the findings. Lastly, we encourage the authors to provide a link to their code in the Abstract/Paper to enhance accessibility and reproducibility.