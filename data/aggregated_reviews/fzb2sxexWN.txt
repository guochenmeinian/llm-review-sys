ID: fzb2sxexWN
Title: Semi-automatic Data Enhancement for Document-Level Relation Extraction with Distant Supervision from Large Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for augmenting document-level relation extraction (DocRE) datasets through automated annotation, specifically addressing the false negative issue in the DocRED dataset. The authors propose a pipeline that integrates in-context learning (ICL) with large language models (LLMs) and a natural language inference (NLI) filtering step to create DocDNRE, enhancing the existing dataset with an additional 2078 triples. The experimental results indicate that the proposed method effectively improves recall in relation extraction.

### Strengths and Weaknesses
Strengths:
- The paper introduces a novel relation triple generation method that effectively utilizes LLMs and NLI models.
- The experimental results demonstrate the potential of the DocGNRE dataset to alleviate the false negative problem in existing datasets.

Weaknesses:
- The claims regarding the general applicability of the method are not sufficiently supported, as it primarily addresses the false negative issue specific to DocRED.
- There is a lack of detail regarding the human evaluation process, which is crucial for validating the quality of the annotations.
- The paper contains several typos and awkward phrasing that detract from its clarity.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their claims about the method's general applicability by providing evidence or applying it to other DocRE datasets. Additionally, the authors should include more comprehensive details about the human evaluation process, such as annotator backgrounds and inter-annotator agreement. We suggest rewriting the abstract and contributions section to clearly state that the method does not annotate new documents but rather re-labels existing ones, and to mention the specific extension of DocRED and the number of new relations added. Furthermore, we advise addressing the typos and awkward phrases throughout the paper, and consider using human-readable names for relation types in figures. Lastly, the title should better reflect the contributions by emphasizing the semi-automatic recovery of missed relation annotations.