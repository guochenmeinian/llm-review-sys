ID: SQouRKRIXY
Title: MomentDiff: Generative Video Moment Retrieval from Random to Real
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 5, 7, 7, 6, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 5, 3, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to video moment retrieval (VMR) through a generative framework called MomentDiff, which utilizes a diffusion-based localization model. MomentDiff generates accurate temporal boundaries by sampling random spans and refining them iteratively, effectively addressing location biases. The authors introduce two "anti-bias" datasets to evaluate the influence of location distribution shifts and validate their approach through experiments on three public datasets, demonstrating its effectiveness.

### Strengths and Weaknesses
Strengths:
1. The generative perspective for VMR is innovative and addresses location bias effectively.
2. The introduction of two anti-bias datasets is a significant contribution to the research community.
3. The experimental results on multiple datasets validate the proposed method's effectiveness.

Weaknesses:
1. The decision not to experiment with ActivityNet Captions, despite its relevance, raises questions about dataset selection.
2. The paper lacks direct comparisons with other methods that address location biases, such as CharadesCD and ActivityNet-CD.
3. Comprehensive evaluations against various moment retrieval methods, including supervised and zero-shot approaches, are necessary for a thorough assessment.

### Suggestions for Improvement
We recommend that the authors improve their dataset selection by including ActivityNet Captions and provide justifications for excluding datasets like CharadesCD. Additionally, we suggest conducting comparisons with other moment retrieval methods to enhance the evaluation of MomentDiff. Clarifying the methodology for integrating audio features and elaborating on the hyperparameter selection process would further strengthen the paper. Lastly, addressing the questions regarding the diffusion process and span generation would enhance clarity and rigor.