ID: ugqx9tgyum
Title: Incorporating Test-Time Optimization into Training with Dual Networks for Human Mesh Recovery
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 5, 6, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method for Human Mesh Recovery (HMR) that integrates test-time optimization into the training process, inspired by meta-learning principles. The authors propose a dual-network architecture to align training and test-time objectives, enhancing the starting point for test-time optimization. Experimental results demonstrate that this method outperforms state-of-the-art HMR approaches, achieving higher accuracy and better generalization to test samples.

### Strengths and Weaknesses
Strengths:
1. The authors introduce an innovative approach by incorporating test-time optimization into the training phase, addressing a gap in existing HMR methods.
2. The proposed method integrates seamlessly with existing HMR models using a dual-network structure, ensuring minimal additional computational load during training.
3. The paper is well organized and written, with clear explanations and helpful diagrams.

Weaknesses:
1. The performance improvement over existing methods is not significant, particularly when comparing results with PLIKS, where unfair comparisons arise due to differences in training datasets.
2. Some experimental results lack clarity, such as the performance of EFT after several optimization steps, which requires further explanation.
3. The paper does not provide statistical significance for experimental results, as suggested by the NeurIPS Paper Checklist.
4. The contextualization relative to prior work, particularly Kim et al. (2022), needs improvement to accurately reflect the novelty of the meta-learning component.

### Suggestions for Improvement
We recommend that the authors improve the contextualization of their work relative to Kim et al. (2022) to clarify the contributions of their meta-learning approach. Additionally, please provide a quantitative comparison using the same training/testing data for both methods and highlight the differences in results. We suggest including statistical significance for the main experimental results, such as standard deviation or standard error. Furthermore, consider reorganizing and simplifying dense figures, particularly Fig. 1, to enhance clarity. Lastly, we encourage the authors to include a discussion of limitations in the main text, as well as a more comprehensive overview of broader impacts.