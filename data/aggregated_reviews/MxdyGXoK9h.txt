ID: MxdyGXoK9h
Title: Boosting Weakly Supervised Referring Image Segmentation via Progressive Comprehension
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 7, 5, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Progressive Comprehension Network (PCNet) for weakly-supervised referring image segmentation (WRIS), which aims to localize target objects by progressively incorporating target-related textual cues. The authors propose a Conditional Referring Module (CRM) that refines text-to-image response maps in multiple stages, utilizing a Large Language Model (LLM) to decompose complex descriptions into actionable cues. Additionally, the paper introduces Region-aware Shrinking (RaS) loss and Instance-aware Disambiguation (IaD) loss to enhance cross-modal alignment and differentiate target objects from others in the image.

### Strengths and Weaknesses
Strengths:
1. The motivation for the work is clear, effectively leveraging LLMs for progressive localization.
2. The integration of multiple Conditional Referring Modules and the novel implementation of RaS and IaD losses demonstrates innovation.
3. The experimental results show superior object localization performance across three benchmarks, particularly after refinement with SAM.

Weaknesses:
1. The results in Table 1 only report outcomes refined by SAM, leaving out results from FreeSOLO, which raises questions about comparative performance.
2. The multi-stage approach may increase training and inference time, necessitating a time comparison.
3. The implementation of the Conditional Referring Module lacks novelty, as it relies on common cross-attention mechanisms.
4. Insufficient ablation studies on multiple datasets limit the comprehensive evaluation of the proposed method.

### Suggestions for Improvement
We recommend that the authors improve clarity by providing results refined by FreeSOLO in Table 1. Additionally, a time comparison for model training and inference should be included to address concerns about increased complexity. The authors should clarify the classification loss concept and the meaning of the âŠ™ symbol in Equation 5. Expanding ablation studies to include datasets like RefCOCO+ and RefCOCO would strengthen the evaluation. Lastly, we suggest reordering the tables for better logical flow and ensuring that all ablation experiments specify the datasets used.