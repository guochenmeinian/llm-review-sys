ID: wkwGedn19x
Title: Scaling White-Box Transformers for Vision
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 7, 6, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents CRATE-α, an enhanced variant of the CRATE (Coding RATE Transformer) architecture, aimed at improving scalability while preserving mathematical interpretability. The authors propose minimal yet strategic modifications to the sparse coding block and a refined training recipe, demonstrating CRATE-α's effectiveness through extensive experiments, particularly on ImageNet classification tasks. The CRATE-α-B model achieved an 83.2% accuracy, significantly outperforming the previous best CRATE-B model. Additionally, the paper analyzes the performance of CRATE-α in comparison to ViT, highlighting a potential improvement of 7% in accuracy. The authors acknowledge the limitations of their work, particularly regarding the additional FLOPs required for CRATE-α to achieve comparable performance with ViT as scale increases. The paper explores the architecture's performance across various model sizes and tasks, including supervised classification and unsupervised semantic segmentation, while emphasizing the importance of fair comparisons in the field of computer vision.

### Strengths and Weaknesses
Strengths:
- The paper introduces a novel architecture, CRATE-α, that effectively enhances scalability while maintaining interpretability.
- It provides substantial empirical evidence, including comparative results on ImageNet and a thorough analysis of training behaviors across different model scales.
- The focus on interpretability is a notable strength, as it addresses a common trade-off in scaling deep learning models.
- The authors demonstrate a candid acknowledgment of the limitations of their work, including the additional FLOPs required for CRATE-α.

Weaknesses:
- The proposed architecture's performance on other tasks, such as NLP, remains unaddressed.
- There is insufficient discussion on the generalizability of results to other datasets and real-world applications.
- The paper is heavily reliant on intricate mathematical formulations, which may hinder understanding; clearer diagrams and illustrations are needed.
- The comparison of results in Figure 1 (Right) and Table 1 lacks equity due to differing training processes and data, weakening the paper's conclusions.
- The inability to provide new experimental results under more equitable settings during the discussion phase is a limitation.
- CRATE-α still lags behind state-of-the-art models like ViT, requiring nearly double the training FLOPs for comparable accuracy.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the presentation by incorporating diagrams to illustrate the modifications made to the architecture and to better define the organization of Section 4. Additionally, we suggest expanding the discussion on the generalizability of results to other datasets and real-world applications. It would also be beneficial to include a comparison of CRATE-α with state-of-the-art models in terms of computational costs, number of parameters, and inference speed. Furthermore, we encourage the authors to explore the performance of CRATE-α on NLP tasks and to provide more insights into the practical benefits of its interpretability beyond scaling. Lastly, we recommend including more equitable experimental results in the paper to enhance its quality; if such changes are not feasible at this stage, we believe the current rating is fair and reasonable.