ID: 7txPaUpUnc
Title: Identifying Functionally Important Features with End-to-End Sparse Dictionary Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 5, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents two new types of sparse autoencoders (SAEs) trained with novel loss functions, L_{e2e} and L_{e2e + ds}. The L_{e2e} loss penalizes the KL divergence between the original model and the SAE-inserted model, contrasting with traditional SAE training that optimizes MSE. The L_{e2e + ds} loss further minimizes the MSE of downstream layers compared to the original model. Both new SAEs demonstrate improved L0 vs. CE tradeoffs over naive SAEs, with L_{e2e + ds} achieving comparable downstream reconstruction loss. Interpretability remains consistent with local SAEs, and geometric properties are similar.

### Strengths and Weaknesses
Strengths:
- The new SAE techniques represent a Pareto improvement on L0 vs. CE loss and may integrate with recent advancements like gated SAEs.
- The geometric analysis of SAE features is compelling, with e2e + ds showing reproducibility across seeds and less feature splitting.
- The interpretability of features is maintained at levels comparable to local SAEs, as verified by automated tests.

Weaknesses:
- The primary evaluation metrics (CE loss and downstream reconstruction error) are also the ones being optimized, raising concerns about Goodhart's law. Additional metrics for downstream SAE quality are necessary.
- Feature shrinkage appears more pronounced with the new methods, and later layer reconstructions for e2e + ds are inferior to local SAEs, complicating feature similarity assessments.
- The contribution lacks groundbreaking findings, with no new insights into interpretability and increased computational demands for e2e SAEs.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by incorporating additional metrics for downstream SAE quality beyond CE loss. Consider exploring measures of downstream SAE functional importance that do not rely on CE loss. Clarifying why the original SAE does not learn certain features that e2e + ds does would enhance understanding. We also suggest investigating the training of an SAE using KL divergence combined with local reconstruction error to address concerns about variance explained. Quantifying the differences between e2e + ds and local SAEs in relation to inter-seed distances would provide valuable context. Finally, a clearer discussion of the tradeoff between learning functionally important features and maintaining model behavior would strengthen the paper.