ID: OVmOQs85Xb
Title: Dynamic Open-book Prompt for Conversational Recommender System
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel Dynamic Open-book Prompt approach for conversational recommendation, leveraging historical user experiences to enhance prompt-based interactions. The authors propose methods to integrate past recommender runs into the prompt representation learning process, specifically through enhancing node embeddings, recommender-item graph structure, and message-passing steps with current user utterances. Experimental results on the ReDial dataset indicate significant performance improvements over existing methods, particularly in Recall@k metrics.

### Strengths and Weaknesses
Strengths:
- The conversational recommendation task is timely and relevant, attracting attention in the NLP community.
- The proposed DOP approach intuitively adds knowledge outside the conversation context, showing statistically significant gains in recommendation tasks.
- The authors conduct a thorough ablation study to justify their architectural choices.

Weaknesses:
- The paper lacks clarity, presenting the architecture in a fragmented manner, leading to confusion about key concepts like "recommender nodes."
- Evaluation metrics primarily focus on Dist-n scores, which may not adequately reflect generation quality; additional metrics like BLEU and human assessments are necessary.
- The positioning of the paper is unclear, as it emphasizes prompt-based approaches while primarily developing a multi-part recommender system.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the architecture by providing a cohesive framework description, potentially borrowing visual elements from related works for better context. Additionally, we suggest incorporating a broader range of evaluation metrics, including BLEU and human assessments, to substantiate the generation performance claims. To enhance the robustness of their findings, supplementary experiments should be conducted to explore nuanced performance variations and practical applicability of the proposed methods. Lastly, addressing the choice of pre-trained language models and their relevance to the proposed approach would strengthen the paper's justification.