ID: V49Jx2Lj04
Title: IfQA: A Dataset for Open-domain Question Answering under Counterfactual Presuppositions
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a dataset for question answering focused on counterfactual reasoning, aimed at enhancing AI systems' counterfactual reasoning abilities. The authors establish performance baselines using state-of-the-art models, demonstrating that existing systems struggle with the counterfactuals presented. The paper includes a detailed annotation process to ensure dataset quality and provides examples of counterfactual questions derived from Wikipedia facts.

### Strengths and Weaknesses
Strengths:
- The paper addresses a novel area in NLP, specifically counterfactual reasoning, which is crucial for advancing question answering models.
- The dataset and baseline metrics are valuable resources for the NLP community, with thorough insights into the dataset construction and model performance.
- The annotation process is well-detailed, enhancing the dataset's reliability.

Weaknesses:
- Heavy reliance on Wikipedia may limit the dataset's applicability in diverse contexts.
- Evaluation metrics and results are not clearly presented, making it difficult to assess the proposed approach's effectiveness.
- There is a lack of analysis on the similarity of questions, which could impact annotation quality.
- Overlap with other tasks, such as common-sense QA, suggests a need for broader domain inclusion or a more specific focus.

### Suggestions for Improvement
We recommend that the authors improve the clarity of evaluation metrics and results to better gauge the effectiveness of their approach. Additionally, consider conducting an analysis on the similarity of questions, potentially including clustering methods like word embeddings or WMD to ensure diverse annotations. It may also be beneficial to expand the dataset to include counterfactuals from other domains, such as mathematics or corporate decision-making, or to refine the dataset's focus to "Event-based counterfactual open-domain QA." Lastly, addressing the identified typos on lines 42-43 and 501 would enhance the paper's presentation.