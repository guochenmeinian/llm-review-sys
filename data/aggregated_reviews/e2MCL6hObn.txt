ID: e2MCL6hObn
Title: Likelihood-Based Diffusion Language Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 5, 7, 7, 5, 6, 5, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 2, 5, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework named Plaid, which focuses on training a Diffusion Language Model (LM) using Variational Lower Bound (VLB) loss. The authors propose several enhancements to the training procedure and model architecture, including categorical reparametrization and self-conditioning methods. They conduct an ablation study comparing their model to a reimplemented CDCD, demonstrating that Plaid 1B outperforms GPT-2 124M in terms of negative log-likelihood (NLL). The authors also provide samples from Plaid 1B, showcasing its capabilities in conditional and unconditional sampling. Furthermore, the paper includes a thorough evaluation of NLLs using equation 5, reflecting the infinite-timestep limit of the NLL bound, and proposes using a naive sampling algorithm with a high number of steps (4000) to approximate this limit. The authors acknowledge the existence of more efficient sampling algorithms for diffusion models and express interest in exploring these in future work. They clarify that while CDCD is not used for training, they can compute an NLL bound for it and will update the draft to clarify their evaluation approach.

### Strengths and Weaknesses
Strengths:
- The proposed improvements on VLB loss are beneficial, as evidenced by NLL results in the ablation study.
- Categorical reparametrization effectively combines advantages from score interpolation objectives and VLB loss without imposing heuristic constraints.
- The paper is well-organized and generally clear.
- The authors provide a clear methodology for evaluating NLLs and articulate their approach to sampling effectively.
- They acknowledge the limitations of their current methods and express a willingness to explore more efficient algorithms in future work.
- The clarification regarding the CDCD model and its evaluation adds depth to the manuscript.

Weaknesses:
- The weightings A and B in Section 4.1 are overly artificial, lacking justification for their selection.
- Insufficient details on pre-trained embeddings and human resources used for crowd work in Section 4.1.
- The evaluation of sample quality is inadequate; NLL alone does not reflect the quality of generated samples.
- Limited comparison with other diffusion models and insufficient exploration of the effects of sampling steps on quality and inference speed.
- The paper lacks a discussion on limitations, particularly regarding the complexity and resource demands of the Plaid framework compared to autoregressive models.
- The absence of human evaluation is noted as a significant gap in the study.
- There are inefficiencies in the network parameters that could be addressed in further revisions.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their experimental design by providing explanations for the chosen weightings in Section 4.1 and including detailed information on pre-trained embeddings and human resources. Additionally, it is crucial to evaluate sample quality quantitatively using metrics beyond NLL, such as human evaluations or perplexity assessments. We suggest conducting ablations at multiple model scales to validate conclusions and including comparisons with other diffusion language models to contextualize Plaid's performance. Furthermore, we recommend incorporating human evaluation to strengthen their findings and addressing the inefficiencies in the network parameters through further revisions. Lastly, a discussion on the limitations of the Plaid framework, particularly regarding its parameter efficiency compared to autoregressive models, would enhance the paper's depth.