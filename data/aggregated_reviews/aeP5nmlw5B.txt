ID: aeP5nmlw5B
Title: WebCode2M: A Real-World Dataset for Code Generation from Webpage Designs
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents WebCode2M, a large-scale dataset with 2.56 million instances that pairs webpage designs with corresponding HTML/CSS code, addressing the need for high-quality training data in automated webpage code generation. The authors propose a filtering strategy to ensure dataset quality and introduce TreeBLEU, a novel metric for evaluating structural hierarchy recall, alongside a baseline model called WebCoder, fine-tuned on the dataset.

### Strengths and Weaknesses
Strengths:
1. The introduction of WebCode2M significantly contributes a large-scale, real-world dataset that is quality-controlled.
2. The TreeBLEU metric offers a new approach for assessing structural hierarchy recall in webpage code generation tasks.
3. The analysis section demonstrates the dataset's efficacy through the training of a VLM.

Weaknesses:
1. The significance of the dataset is questionable, as GPT-4o performs similarly, raising concerns about its unique contribution.
2. The effectiveness of the training set is not convincingly demonstrated, particularly regarding Table 3 and the potential domain overlap of training and test sets.
3. The calculation of certain metrics, such as TreeBLEU, lacks clarity, and the authors do not propose this metric, as it has been used in previous work.
4. The claim that a VLM trained with WebCode2M outperforms on the same dataset does not adequately prove its effectiveness without evaluation on other benchmarks.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the mathematical calculations related to TreeBLEU, particularly the definition of set S(t) and the evaluation of 1-height sub-trees. Additionally, detailing the training process of the ViT model would enhance understanding. To strengthen the dataset's significance, we suggest evaluating the VLM on external benchmarks to demonstrate its effectiveness. Furthermore, addressing instances of widow words in the text and enhancing image resolution in the dataset comparison section could improve readability and clarity. Lastly, including specific examples of how TreeBLEU aligns with HTML DOM structures and considering semantic tags in subtree matching rules would enrich the metric's representation.