ID: QDG2q5MYHV
Title: A Gradient Accumulation Method for Dense Retriever under Memory Constraint
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 6, 7, 5, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 2, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ContAccum, a method for training with contrastive loss that enhances memory efficiency and stability in scenarios with limited resources. The authors build on GradAccum by introducing dual memory banks for both queries and passages, allowing for the effective use of past representations without backpropagating gradients to previous mini-batches. This approach increases the number of positive and negative samples available for each mini-batch, addressing the challenges posed by memory constraints.

### Strengths and Weaknesses
Strengths:
- The proposed method improves upon DPR and GradAccum in 11/12 tasks with 11GB memory and 9/12 tasks with 24GB memory.
- ContAccum outperforms DPR in low-memory settings, with accuracy gaps reaching up to 11%.
- Comprehensive ablation studies validate the effectiveness of balancing gradients using dual memory banks.
- The paper is well-organized, with clear explanations and coherent narrative flow.

Weaknesses:
- The specificity of the method to dense retrievers is unclear, lacking background on dense retrievers and general applicability to other contrastive learning scenarios.
- A detailed analysis of how ContAccum overcomes GradCache's limitations is missing.
- The introduction of DPR is absent, which is problematic given its frequent reference in the experimental section.
- Numerous typos and formatting issues detract from the overall presentation.

### Suggestions for Improvement
We recommend that the authors improve the background section to clarify the method's applicability beyond dense retrievers. Additionally, a comparative experiment in high-resource settings involving GradAccum, GradCache, and ContAccum would strengthen the claims regarding performance. The authors should also address the numerous typos and formatting errors throughout the paper to enhance clarity and professionalism. Finally, providing a clearer explanation of the overhead associated with the memory bank in terms of Bytes would be beneficial for understanding its impact on memory usage.