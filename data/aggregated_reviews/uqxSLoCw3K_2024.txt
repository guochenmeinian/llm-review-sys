ID: uqxSLoCw3K
Title: Mixture of Demonstrations for In-Context Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 6, 6, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Mixture of Demonstrations (MoD) framework, which partitions the demonstration pool into clusters managed by experts to enhance in-context learning (ICL) in large language models (LLMs). The authors propose a training strategy that utilizes coordinate descent and contrastive loss to optimize the retriever model, allowing for improved demonstration selection. Experimental results indicate that MoD outperforms existing methods across various NLP tasks, demonstrating its practical value.

### Strengths and Weaknesses
Strengths:
- The paper offers a clear goal of optimizing demonstration selection for ICL.
- It introduces a novel expert-wise training strategy and provides extensive experiments across 12 NLP tasks, showcasing the effectiveness of the method.
- The MoD framework achieves state-of-the-art performance compared to existing baselines.

Weaknesses:
- The method's computational complexity is high, requiring iterative training of multiple retrievers, which may limit its practical application.
- There is a lack of analysis on the total FLOPs of MoD compared to previous work, and important hyperparameter analyses and ablation studies are missing.
- The use of cosine similarity for determining relevance lacks justification, and the paper does not clarify the application of coordinate descent within the framework.
- The reliance on labeled data for validation reduces the significance of the method, especially given the potential for zero-shot applications of LLMs.

### Suggestions for Improvement
We recommend that the authors improve the analysis of the total FLOPs of MoD compared to previous methods to address efficiency concerns. Additionally, we suggest including a comprehensive hyperparameter analysis and conducting ablation studies to clarify the impact of various factors, such as the number of iterations for retriever training and the effects of different embedding models. Furthermore, we encourage the authors to justify the use of cosine similarity in determining relevance and to provide clearer explanations of the coordinate descent application within the framework. Lastly, we suggest reframing the method to focus on creating new labeled datasets from benchmark datasets, enhancing its significance in the context of LLMs.