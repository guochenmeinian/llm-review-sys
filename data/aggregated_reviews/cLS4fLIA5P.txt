ID: cLS4fLIA5P
Title: WebUOT-1M: Advancing Deep Underwater Object Tracking with A Million-Scale Benchmark
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 7, 6, 7, 6, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 5, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents WebUOT-1M, the largest public underwater object tracking (UOT) benchmark dataset, comprising 1.1 million frames from 1,500 video clips across 408 target categories. The authors propose OKTrack, an omni-knowledge distillation framework designed to enhance UOT models by transferring knowledge from open-air domains. The dataset includes high-quality annotations and language prompts for video sequences, expanding its application areas. The authors evaluate WebUOT-1M using 30 different deep trackers, providing a comprehensive analysis of its utility as a benchmark for UOT research.

### Strengths and Weaknesses
Strengths:
- The dataset is large-scale and diverse, significantly surpassing previous UOT datasets.
- High-quality annotations are provided, which are beneficial for training object tracking models.
- The paper is well-written and presents a clear methodology and evaluation.

Weaknesses:
- The necessity of including 408 target categories is questioned, as single-object VOT does not prioritize object categories.
- The effectiveness of training on the large dataset is debated, with concerns about the marginal improvements observed.
- There are inconsistencies in experimental results, particularly regarding the performance of retraining versus distillation methods.
- The baseline tracker lacks integration of language annotations, which raises questions about its relevance to the proposed method.

### Suggestions for Improvement
We recommend that the authors improve the justification for including a large number of target categories, considering the focus of single-object tracking. Additionally, the authors should clarify the necessity of the large-scale underwater dataset for training, especially in light of existing general tracking datasets. We suggest enhancing the clarity of experimental results, particularly addressing the discrepancies between retraining and distillation performance. Furthermore, we encourage the authors to integrate language processing into the baseline tracker or provide a clear rationale for its absence, ensuring coherence between the proposed method and the baseline. Lastly, we recommend that the authors conduct a comparative analysis with existing work, such as EventVOT, to highlight the uniqueness of their contributions.