ID: kyPpQwMx3T
Title: Random Propagations in GNNs
Conference: NeurIPS
Year: 2024
Number of Reviews: 4
Original Ratings: 6, 8, 6, 6
Original Confidences: 4, 4, 4, 4

Aggregated Review:
### Key Points
This paper presents an extended abstract on random propagation in graph neural networks (GNNs), proposing the Random Propagation GNN (RAP-GNN) framework to address computational inefficiencies. By employing random weights in GNN layers and training only the final classifier, the authors claim a reduction in training time by approximately 50% while maintaining competitive accuracy in node and graph classification tasks on smaller datasets like Cora and Citeseer. The framework's effectiveness is evaluated through various randomness strategies and ablation studies.

### Strengths and Weaknesses
Strengths:
- The use of random weights significantly enhances efficiency compared to traditional backpropagation training.
- RAP-GNN maintains competitive performance despite training only the final classifier alongside pretrained embeddings.
- The paper provides clear motivation for random initialization and explores various randomness strategies, with appropriate baselines reported.

Weaknesses:
- The evaluation lacks datasets that are larger and commonly used in GNN scalability studies, limiting the demonstration of RAP-GNN's utility.
- The inference process is complicated by the need for majority voting (M > 1), potentially creating bottlenecks in real-time applications.
- The term "random propagation" may confuse readers, as it primarily refers to random weight initialization rather than feature propagation through random edges.
- The paper does not clarify the data requirements for pre-training the joint classifier and GNN head, nor does it explore tasks beyond classification.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by including larger datasets and tasks such as link prediction to validate the effectiveness of RAP-GNN more comprehensively. Additionally, clarifying the number of independent voter models used in the experiments and providing results for a single voter count (M = 1) would strengthen the argument regarding inference time. Furthermore, discussing the relevance of adding noise to features and the implications of removing GNN layers during training could enhance the paper's contribution to the field.