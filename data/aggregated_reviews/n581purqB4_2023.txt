ID: n581purqB4
Title: AbdomenAtlas-8K: Annotating 8,000 CT Volumes for Multi-Organ Segmentation in Three Weeks
Conference: NeurIPS
Year: 2023
Number of Reviews: 24
Original Ratings: 7, 9, 7, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 5, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the AbdomenAtlas-8K dataset, which comprises 8,448 annotated CT volumes and employs a novel active learning approach to enhance annotation efficiency. The authors propose that their method significantly reduces manual annotation time from approximately 30.8 years to just three weeks by combining multiple AI models for initial segmentations. The dataset features per-pixel annotations for eight organs, sourced from over 26 hospitals worldwide, and aims to facilitate advancements in medical imaging research, particularly in the early detection of diseases like pancreatic cancer. The authors also provide a detailed analysis of segmentation performance, reporting significant improvements in the segmentation of specific organs and addressing challenges faced during the annotation process.

### Strengths and Weaknesses
**Strengths:**
- The proposed algorithm demonstrates a substantial reduction in annotation time and effort, allowing radiologists to focus on only 400 of the 8,448 volumes.
- The accuracy of AI-generated annotations is favorably compared to those made by medical professionals, with significant improvements reported in segmentation metrics for certain organs.
- The dataset is larger and more diverse than existing datasets like TotalSegmentator, potentially enhancing generalizability and clinical applicability.
- The authors have provided a clear plan for future competitions and publications to further the dataset's impact in the medical imaging community.

**Weaknesses:**
- The dataset of 8,000 annotated CT images is not yet available, and the timeline for its release is unclear.
- The term "pseudo labels" is not defined, and the JHH dataset is referenced without adequate clarification.
- Low inter-annotator agreement raises concerns about the reliability of AI-generated annotations for certain organs, and the reduction of anatomical labels from 104 to 8 limits the dataset's clinical applicability.
- There is insufficient evidence presented to demonstrate that the proposed labels are superior to existing ones, particularly in terms of performance metrics, and the methodology for the assignment of annotators is not adequately detailed.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the dataset's availability timeline and provide a detailed explanation of the JHH dataset. Additionally, defining "pseudo labels" would enhance understanding. The authors should investigate the low inter-annotator agreement and discuss potential biases introduced by the AI annotations. Furthermore, we encourage a more comprehensive comparison with existing datasets in the related works section to clarify the unique contributions of this research. It would be beneficial to provide more robust comparisons demonstrating the superiority of the proposed labels over existing datasets, including detailed performance metrics. We suggest including a clearer comparison of the annotation procedures across hospitals to address concerns about variability and its impact on performance. Lastly, we encourage the authors to expand the number of annotated classes in AbdomenAtlas-8K and continue refining their literature review to ensure a balanced presentation of the strengths and limitations of both datasets.