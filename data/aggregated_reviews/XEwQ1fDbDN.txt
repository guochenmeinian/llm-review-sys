ID: XEwQ1fDbDN
Title: Examining Inter-Consistency of Large Language Models Collaboration: An In-depth Analysis via Debate
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the FORD framework, designed to enhance the reasoning capabilities of Large Language Models (LLMs) through structured debates among multiple agents. The authors investigate inter-consistency among LLMs and their collaborative potential across various scenarios, including fair, mismatched, and roundtable debates. Empirical results demonstrate that while the FORD method can yield minor performance improvements in certain contexts, it may also lead to performance degradation when LLMs with differing base performances engage in debate.

### Strengths and Weaknesses
Strengths:
1. The paper systematically evaluates inter-consistency among LLMs, a novel area of research.
2. Innovative concepts, such as the INCON measure, are introduced.
3. Comprehensive experiments across seven datasets provide robust findings.
4. The writing is clear and accessible.

Weaknesses:
1. Some sections of the paper lack clarity and require further explanation.
2. The reliance on closed-source models raises concerns about reproducibility.
3. Inconsistencies in conclusions and terminology are present.
4. The experimental comparison with existing methods is inadequate.

### Suggestions for Improvement
We recommend that the authors improve the clarity of key concepts, particularly regarding the role of the judge in the FORD framework and the process for obtaining debate summaries. Additionally, we suggest enhancing the experimental comparison by including baselines such as retrieval-enabled LLMs and addressing the performance implications of mismatched debates. Finally, we encourage the authors to provide more detailed information on the reproducibility of their results, especially considering the closed-source nature of the models used.