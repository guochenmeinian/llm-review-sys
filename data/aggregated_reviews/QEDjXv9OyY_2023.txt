ID: QEDjXv9OyY
Title: YouTube-ASL: A Large-Scale, Open-Domain American Sign Language-English Parallel Corpus
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 9, 5, 5, 7, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 5, 3, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a large-scale American Sign Language (ASL) translation dataset, YouTube-ASL, comprising over 2500 signers and approximately 1000 hours of video. The dataset is evaluated against the How2Sign dataset, demonstrating improved precision over state-of-the-art (SOTA) methods. The authors explore pretraining versus non-pretraining modes, providing insights into the dataset's properties and its potential for advancing ASL translation research. Additionally, the paper includes a comprehensive discussion of prior sign language datasets and methods, addressing suggestions for additional citations. The authors clarify that they already cite three of the seven suggested papers and explain the omission of "ISLTranslate" due to its late release. They plan to include references to the OpenHands unlabelled ISL dataset and CISLR isolated sign classification dataset, noting their similarity in approach to OpenASL.

### Strengths and Weaknesses
Strengths:
- The dataset is significantly larger than existing ASL datasets, with 2519 signers, making it a valuable resource for research.
- The evaluation methodology is robust, comparing results on How2Sign and showcasing generalization capabilities through pretraining and zero-shot modes.
- The paper is well-written, clearly articulating the dataset's construction, limitations, and relation to prior work.
- The authors provide a thorough overview of existing datasets and methods, demonstrating awareness of the field and clarifying the rationale behind citation choices.

Weaknesses:
- The dataset's reliance on YouTube links raises concerns about stability and accessibility, as videos may be deleted over time.
- The authors utilize a simplistic model for ASL-English translation, lacking exploration of more advanced SOTA architectures.
- The alignment of video and text is inadequately addressed, with insufficient verification of the accuracy of video segmentation based on captions.
- The dataset's instability is highlighted as a significant concern, indicating potential issues with reliability.

### Suggestions for Improvement
We recommend that the authors improve the justification for their data filtering choices, particularly regarding the exclusion of videos based on duration. Clarifying the criteria for what constitutes well-aligned captions would enhance the dataset's credibility. Additionally, we suggest that the authors explore more sophisticated ASL translation models and provide a thorough error analysis to understand the BLEU scores better. Finally, addressing the dataset's long-term accessibility and potential copyright issues would strengthen the paper's contributions. We also recommend that the authors improve the dataset's stability to address the concerns raised and ensure that all relevant works are cited appropriately, particularly those that may have been released after the submission deadline.