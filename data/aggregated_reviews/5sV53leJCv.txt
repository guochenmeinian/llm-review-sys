ID: 5sV53leJCv
Title: Module-wise Training of Neural Networks via the Minimizing Movement Scheme
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 5, 6, 6, 5, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new training method for module-wise training of neural networks, addressing the stagnation problem often encountered in layer-wise training. The proposed method improves accuracy and reduces memory usage, particularly in constrained settings. The authors explore the connection between neural network training and optimal transport theory, providing theoretical insights and demonstrating effectiveness across various architectures, including ResNets and Transformers.

### Strengths and Weaknesses
Strengths:
1. The methodology effectively addresses the stagnation issue, leading to enhanced model accuracy and reduced memory usage.
2. The theoretical analysis connecting the proposed regularization with optimal transport is intellectually stimulating.
3. The manuscript is well-structured and clearly articulated.

Weaknesses:
1. The paper lacks a detailed convergence analysis, which is essential for reinforcing the reliability of the proposed approach.
2. A more comprehensive ablation analysis is needed to explore the impact of variations in the regularization penalty.
3. The claim regarding early modules overfitting is not sufficiently supported by experimental results, especially given that early layers may underfit on large datasets like ImageNet.
4. The introduction of an additional regularization term increases computational complexity, potentially leading to longer training times.

### Suggestions for Improvement
We recommend that the authors improve the experimental results by including a detailed convergence analysis to clarify the reliability of the training process. Additionally, a more comprehensive ablation study should be conducted to assess the effects of different regularization penalties. It would also be beneficial to provide a comparison of the training time between their proposed method and other related methods to address concerns about computational complexity. Lastly, we suggest clarifying the principle of finding Tau and ensuring that notations are properly introduced for better reader comprehension.