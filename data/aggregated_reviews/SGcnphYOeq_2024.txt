ID: SGcnphYOeq
Title: Parameter-free Clipped Gradient Descent Meets Polyak
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 7, 5, 3, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an extension of the convergence results for the Polyak stepsize under the $(L_0, L_1)$-smooth condition, demonstrating a convergence rate of $\mathcal O(\tfrac{L_0}{T} + \tfrac{LL_1^2}{T^2})$. The authors introduce a horizon-dependent stepsize factor of $1/\sqrt{T}$ to mitigate the dependency on the optimal function value $f^*$, resulting in a slower rate of $\mathcal O(\tfrac{L_0+\sigma^2}{\sqrt{T}} + \tfrac{LL_1^2}{T}+\tfrac{LL_1^2\sigma^4}{L^2_0 T})$. The paper also explores the relationship between Polyak stepsize and gradient clipping, asserting that the Polyak stepsize can be interpreted as a form of gradient clipping.

### Strengths and Weaknesses
Strengths:
- Clear and well-explained theoretical results.
- The analysis of Polyak step sizes under $(L_0,L_1)$-smoothness appears novel and relevant.
- The paper is well-presented and easy to follow, with relevant experiments that cover main problem classes.

Weaknesses:
- The convergence rate of the inexact Polyak stepsize is slow, specifically $1/\sqrt{T}$, which is problematic.
- The dependency on the estimate of the key parameter $f^*$ is not as effective as in D-Adaptation/T-DoG.
- Comparisons with stochastic methods are misleading since the proposed method is deterministic.
- Stochasticity is not adequately addressed, despite its relevance to the experiments.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the relationship between Polyak stepsize and gradient clipping, ensuring that the results are presented as primarily concerning Polyak stepsize. Additionally, we suggest that the authors consider using the successive halving strategy from Hazan and Kakade (2019) to potentially achieve better convergence rates without the $1/\sqrt{T}$ factor. It would also be beneficial to clarify the experimental setup regarding the comparison of deterministic and stochastic methods, including batch sizes used. Finally, we advise the authors to explicitly discuss the implications of the $1/\sqrt{T}$ factor on performance and to bridge the theory/practice gap, particularly in the context of stochastic settings.