ID: 8HwI6UavYc
Title: ReplaceAnything3D: Text-Guided Object Replacement in 3D Scenes with Compositional Scene Representations
Conference: NeurIPS
Year: 2024
Number of Reviews: 19
Original Ratings: 3, 5, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for text-guided object replacement in 3D scenes using an Erase-and-Replace strategy, which involves two main stages: first, removing the specified object with a language-based model and fine-tuning a NeRF model based on inpainted images; second, replacing the object by optimizing the NeRF model with generated or customized images. The authors also propose methods for localized scene editing using Bubble-NeRF rendering, incorporating HiFA loss and timestep annealing from the HiFA framework to enhance visual quality. They compare their method against existing Gaussian splatting and NeRF techniques, claiming improved results, while also addressing reproducibility issues and providing detailed training commands.

### Strengths and Weaknesses
Strengths:
- The paper is straightforward and easy to follow.
- The proposed method shows promising quality in results.
- It introduces a novel Erase-and-Replace strategy that optimizes background and foreground NeRF separately, yielding realistic outcomes.
- Extensive experiments demonstrate performance improvements over state-of-the-art methods.
- The authors provide comprehensive training commands and address reproducibility issues, demonstrating transparency in their methodology.
- They validate their choice of HiFA components through new ablation studies, enhancing the rigor of their claims.

Weaknesses:
- The main weakness lies in the lack of novelty, as the method does not significantly advance the field of 3D editing.
- The approach appears to merely combine existing methods without addressing unresolved challenges in the domain.
- Some editing results exhibit artifacts, such as cutting edges in clothing edits.
- The method is limited to specific editing tasks and is time-consuming to train.
- The use of `--downscale-factor 2` in training commands led to degraded results, raising concerns about the reliability of the comparisons.
- The distinction between SDS loss and IDU methods may not be clearly articulated, leading to potential misunderstandings regarding their theoretical differences.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their contributions by addressing unresolved challenges in 3D editing. Additionally, conducting ablation studies to clarify the impact of HiFA's loss on results would strengthen the paper. We suggest providing clearer comparisons with existing methods using the same prompts and datasets to ensure fair evaluations. Furthermore, we urge the authors to address the artifacts observed in the results and clarify the assumptions regarding object sizes during the replacement process. We also recommend improving the clarity of the discussion regarding timestep annealing, as it was not mentioned in the main paper but may significantly impact generation quality. Lastly, we suggest reducing the frequency of phrases like "adopt HiFA" and "utilize HiFA," opting instead for more precise terminology to accurately reflect the components integrated into their model, and updating Figure 10 with results from the original settings to ensure a fair comparison with the baselines.