ID: MSsQDWUWpd
Title: Analysis of Corrected Graph Convolutions
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 6, 7, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper studies the effects of removing the top eigenvector of the adjacency matrix in graph convolutions, particularly within the Contextual Stochastic Block Model (CSBM). The authors theoretically demonstrate that this removal is beneficial, providing several theoretical statements on misclassification ratios and achieving linear separation. Experiments validate the advantages of omitting the smooth eigenvector for CSBM. The paper also explores oversmoothing in GNNs and presents a corrected convolution approach that enhances performance on real-world datasets.

### Strengths and Weaknesses
Strengths:
* The background, literature review, and preliminaries are well-presented.
* The theoretical analysis is thorough and comprehensive, with rigorous results.
* Experiments support the theoretical claims, showing improved results from removing the dominant eigenvector.

Weaknesses:
* The paper's structure is confusing, particularly in Section 4, where theorems are presented without proofs, and proof sketches are provided later.
* The implications of the theoretical statements are unclear, and additional details on symbols would enhance understanding.
* The practical application of removing the top eigenvector appears limited, as it merely exchanges one dominating signal for another.
* The synthesized data may not adequately illustrate the complexities of multi-class scenarios, and the analysis could benefit from clearer definitions and comparisons with practical performance.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper's structure by providing proofs for theorems in a more accessible manner. A focused discussion on either $\hat{A}$ or $\tilde{A$} alongside Theorem 4.1 or Theorem 4.2 would enhance accessibility. Additionally, clearly stating all symbols and elaborating on theoretical implications would aid comprehension. To strengthen practical relevance, we suggest including figures that compare theoretical bounds with empirical performance, particularly in multi-class settings. Finally, consider refining terminology, such as using "k rounds of aggregation" instead of "convolution," to avoid confusion.