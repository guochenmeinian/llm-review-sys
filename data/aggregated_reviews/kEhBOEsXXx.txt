ID: kEhBOEsXXx
Title: HPE: Answering Complex Questions over Text by Hybrid Question Parsing and Execution
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Hybrid Question Parser and Execution (HPE) framework, which aims to answer complex questions over text by merging neural networks and symbolic methods. The HPE framework consists of two main components: the H-parser, which generates an intermediate representation called H-expression, and the H-executor, which processes this representation to answer simpler questions. The authors demonstrate that the HPE framework achieves state-of-the-art (SOTA) results across various datasets, including MuSIQue and HotPotQA, and enhances interpretability by revealing the reasoning process behind answers.

### Strengths and Weaknesses
Strengths:
- The HPE framework combines neural and symbolic approaches, providing a structured and interpretable method for question answering.
- Extensive experiments show that HPE outperforms existing methods in supervised, few-shot, and zero-shot settings.
- The modular design allows for better generalization with limited training data, enhancing adaptability.

Weaknesses:
- The pipeline approach may lead to error propagation, where mistakes in the H-parser affect the final answer.
- The current set of operations in the H-expression may not cover all complex question types, necessitating retraining for new reasoning types.
- The significance of performance improvements compared to other models is unclear, particularly regarding the impact of pretraining on results.

### Suggestions for Improvement
We recommend that the authors improve the analysis of how each component contributes to overall performance, particularly in comparison to other models like FiD. Additionally, addressing how the framework deals with errors from the semantic parsing model is crucial. To enhance robustness, we suggest exploring beam search to mitigate exposure bias during multi-hop reasoning. Furthermore, the authors should consider empirical comparisons against Chain-of-Thought (CoT) approaches, particularly with self-consistency and instruction-tuned models, to clarify the practical advantages of HPE. Lastly, we urge the authors to update the references to include relevant 2023 citations and expand the related work section for a more comprehensive context.