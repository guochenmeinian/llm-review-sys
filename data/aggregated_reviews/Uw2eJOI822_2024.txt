ID: Uw2eJOI822
Title: Renovating Names in Open-Vocabulary Segmentation Benchmarks
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method called RENOVATE for automating the renaming of class names in segmentation datasets to enhance open-vocabulary segmentation. The authors propose a framework that utilizes image captioning to generate contextual words for class names, followed by employing GPT-4 to create a pool of candidate names. A segmentation model is then trained to select the most appropriate candidate names based on the mIoU metric. The effectiveness of the renovated names is demonstrated through improved performance in training open-vocabulary models and refining evaluation benchmarks.

### Strengths and Weaknesses
Strengths:  
- The paper addresses the significant issue of imprecise class names, which directly impacts open-vocabulary task performance.  
- The automation of the renaming process reduces manual labor, showcasing a practical application of foundation models.  
- The writing is clear and logical, making the paper easy to follow.  
- Experiments indicate that renovated names enhance model training and evaluation.

Weaknesses:  
- The exploration of noise types and rates in class names is insufficient; thorough statistics are needed to clarify performance bounds.  
- The methodology for sorting candidate names based on visual context lacks clarity, particularly regarding the number of ground-truth masks required.  
- The reliance on GPT-4 and image captioning raises concerns about the quality of candidate names and the potential need for additional verification.  
- The focus on segmentation tasks limits the generalizability of conclusions to other tasks like classification or detection.  
- The evaluation is limited to a single architecture, which may not adequately represent the broader applicability of the findings.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the noise types and rates in class names, providing thorough statistics to support their claims. Additionally, the authors should clarify the methodology for sorting candidate names, particularly regarding the number of ground-truth masks needed and the consistency of visual alignment. It would be beneficial to discuss the quality assurance measures for candidate names generated by GPT-4 and image captioning. We also suggest expanding the scope of the study to include classification and detection tasks to assess the generalizability of the findings. Lastly, the authors should consider evaluating the renaming model against stronger baselines that can also perform candidate selection, such as those based on CLIP embeddings.