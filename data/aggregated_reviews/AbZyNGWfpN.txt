ID: AbZyNGWfpN
Title: Expanding Sparse Tuning for Low Memory Usage
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 7, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 5, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents SNELL, a method for fine-tuning vision models that achieves low memory usage while maintaining high performance. It extends matrix decomposition from a kernel perspective and introduces a novel sparsification mechanism for parameter selection. Experimental results demonstrate that SNELL effectively balances memory efficiency and performance across various large-scale vision models.

### Strengths and Weaknesses
Strengths:
1. The method is novel, achieving low memory requirements and high performance, which is crucial for practical applications.
2. It enables data-dependent parameter selection in low-resource scenarios, potentially advancing model editing research.
3. Extensive experiments on large-scale models like ViT-L and ViT-H validate SNELL's performance and memory efficiency.
4. The kernel perspective provides new insights into LoRA, promoting further improvements.
5. The paper is well-written and easy to follow.

Weaknesses:
1. The kernel function should be introduced in the method section rather than the experiment section.
2. Implementation details for Figure 4(a) should be referenced in the main text for easier access.
3. The authors need to clarify why memory savings are more significant for larger models in Figure 3(b).
4. A comparison between SNELL and other visual PEFT methods, such as MOSA and VQT, is lacking.
5. The competition-based sparsification mechanism lacks clarity and demonstration of its competitive aspects.
6. Memory usage comparisons with LoRA and Adapter show minimal advantages for SNELL, necessitating a more comprehensive explanation.
7. The paper does not report the number of trainable parameters, which is a critical evaluation metric.

### Suggestions for Improvement
We recommend that the authors improve the introduction of the kernel function in the method section for clarity. Additionally, please ensure that implementation details for Figure 4(a) are easily accessible in the main text. We suggest providing an explanation for the significant memory savings observed in larger models and including comparisons with other visual PEFT methods like MOSA and VQT. We also encourage the authors to clarify the competition-based sparsification mechanism and its implications. A more comprehensive discussion on memory usage advantages over existing methods is necessary, along with reporting the number of trainable parameters to enhance the evaluation of SNELL.