ID: Jo9P7hrDdy
Title: SpEL: Structured Prediction for Entity Linking
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a structured prediction approach to entity linking, aiming to connect text to entities represented by surface forms. The authors propose several contributions, including a new structured prediction framework, a context-sensitive prediction aggregation strategy, an in-domain mention vocabulary, a fine-tuning method on tokenized sequences, improved model efficiency, and enhancements to the GERBIL platform for reproducible experiments. The results indicate that the proposed method outperforms prior approaches, particularly in scenarios without a predefined candidate set.

### Strengths and Weaknesses
Strengths:  
- The proposed structured prediction technique is effective and outperforms existing methods.  
- The implementation with GERBIL ensures reproducibility.  
- The paper introduces innovative methods that enhance entity linking performance.  

Weaknesses:  
- The context-sensitive prediction aggregation strategy is only evaluated in settings where the correct answer is included in the candidate set, limiting its applicability to real-world scenarios.  
- The in-domain fixed vocabulary may oversimplify the problem, as it does not adequately address the complexities of real-world data.  
- The paper lacks sufficient detail for reproducibility, particularly regarding code availability and parameter settings.  
- The experimental section is limited to a single dataset, and there is no analysis of the impact of different underlying language models.

### Suggestions for Improvement
We recommend that the authors improve the evaluation of the context-sensitive prediction aggregation strategy by including results from scenarios where the correct answer is not part of the candidate set. Additionally, the authors should clarify the motivation behind using an in-domain fixed vocabulary in real-world applications. To enhance reproducibility, we suggest that the authors provide code and supplementary data. Expanding the experimental section to include multiple datasets and analyzing the influence of different language models, such as comparing SPEL's performance with RoBERTa versus BERT, would also strengthen the paper. Furthermore, we encourage the authors to address the lack of consideration for other LLMs in their evaluation and to include relevant references to recent advancements in few-shot learning techniques.