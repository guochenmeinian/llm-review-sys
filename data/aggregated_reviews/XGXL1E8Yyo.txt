ID: XGXL1E8Yyo
Title: DreamWaltz: Make a Scene with Complex 3D Animatable Avatars
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 4, 4, 5, 4, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 5, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for generating animatable avatars from text prompts, building on DreamFusion by incorporating articulated NeRF and the SMPL body model. The authors propose a two-stage pipeline that generates a static avatar and learns its deformation properties for animation, utilizing 3D-consistent occlusion-aware score distillation sampling to enhance generation quality. Performance evaluations indicate that the proposed method outperforms existing techniques, although concerns about novelty and visual quality persist.

### Strengths and Weaknesses
Strengths:
- The paper addresses the complex challenge of creating neural avatars from text prompts and demonstrates the extension of DreamFusion to articulated humans.
- The proposed 3D-consistent Score Distillation Sampling and occlusion culling methods are technically sound and effective.
- The paper is well-structured and presents a clear methodology.

Weaknesses:
- The main limitation is the lack of novelty, as the approach primarily combines existing methods without significant technical contributions.
- A simple baseline for comparison is missing, which is crucial for validating the contributions of animatable avatars.
- The visual quality of generated avatars is limited, with noticeable artifacts in animations and a lack of pose-dependent changes.
- The paper does not adequately discuss limitations or societal impacts, nor does it provide sufficient implementation details.

### Suggestions for Improvement
We recommend that the authors improve the novelty of the work by clearly articulating unique contributions beyond existing methods. Additionally, including a simple baseline, such as extracting a static mesh using MarchingCube and rigging it with SMPL, would enhance validation. The authors should address the visual quality issues by refining the animation process to reduce artifacts and demonstrate pose-dependent changes. Furthermore, providing detailed implementation specifics, including batch size and learning rates, would strengthen the paper. Lastly, discussing limitations and potential societal impacts is essential for a comprehensive evaluation of the work.