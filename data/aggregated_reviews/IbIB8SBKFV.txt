ID: IbIB8SBKFV
Title: Improving Alignment and Robustness with Circuit Breakers
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 7, 6, 4, 8, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel technique called "short circuiting" aimed at enhancing model robustness against harmful outputs while maintaining helpfulness. The method involves training a model's hidden representation on harmful prompts to be orthogonal to its original representations, ensuring that harmful inputs lead to off-distribution outputs. An additional loss term preserves benign behavior on normal prompts. The authors evaluate the Llama-3 model and its short-circuited version in the context of harmful request handling, demonstrating that while the original Llama-3 model is compromised under certain harmful requests, the short-circuited model successfully mitigates some harmful outputs but struggles with others that are less distinct. The authors provide detailed insights into dataset composition, including the inclusion of refusal data points to maintain the model's ability to refuse harmful requests, and discuss the intuition behind short-circuiting, which involves remapping harmful representations to incoherent outputs. The technique achieves state-of-the-art performance against adversarial attacks across various models and benchmarks.

### Strengths and Weaknesses
Strengths:
- The short circuiting method is highly effective and general, significantly improving robustness against harmful information while retaining helpfulness.
- The approach addresses a critical problem in AI safety with immediate applicability to existing large-scale multi-modal models.
- The authors provide clear examples of model behavior under harmful requests, illustrating the effectiveness of the short-circuiting approach.
- The paper includes a comprehensive evaluation against various attack models, enhancing the robustness of the proposed defense mechanism.
- The authors acknowledge and plan to address concerns regarding the clarity of their loss function and the curation of harmful requests.

Weaknesses:
- The paper's presentation and organization require improvement, with many experimental details omitted.
- There is uncertainty regarding the method's effectiveness against harmful outputs not included in the fine-tuning data.
- The harmful knowledge remains in the model, raising concerns about potential misuse.
- The checklist claims to specify compute resources, but this information is missing.
- There is a lack of clarity regarding the specific internal representations used in the loss function, which raises questions about the effectiveness of the proposed method.
- The omission of harmful requests from the short-circuit set may lead to misinterpretations of the harmfulness of certain responses when context is removed.
- The authors do not fully address concerns about the robustness of their defense against adaptive attacks, particularly regarding the potential for single-shot adversarial prompts.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Section 3 by providing more intuition on the rationale behind short circuiting, particularly how it aims to position hidden representations off-distribution. The Loss subsection should clearly indicate which loss method is employed and detail which internal representations are utilized and how they relate to harmful states. Additionally, clarify the statement about removing harmful user requests from the Short Circuit Set, as it contradicts the goal of including such requests. 

We suggest condensing lengthy prose in Section 3, focusing on crucial details like the layers trained with LoRA, and merging Section C.1 into Section 3 for coherence. The results section should emphasize numerical outcomes over qualitative descriptions of short circuiting's virtues. It may be beneficial to include a non-representation engineering baseline to demonstrate that the method does not overfit to training data. Sections 4.1, 4.2, and 4.3 would benefit from introductory paragraphs to contextualize the problem setup.

Furthermore, we encourage the authors to provide more detailed explanations of the short circuit and retain datasets, including sample sizes and the nature of "extra refusal data points." Elucidate the various attack types listed in the results, and include the attack and experimental settings from the referenced GitHub repository to enhance the comprehensiveness of their evaluation. Lastly, we advise the authors to thoroughly investigate and document any potential vulnerabilities in their short-circuiting method to ensure its claimed robustness against adaptive attacks.