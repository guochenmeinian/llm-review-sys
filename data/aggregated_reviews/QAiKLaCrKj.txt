ID: QAiKLaCrKj
Title: Cherry on Top: Parameter Heterogeneity and Quantization in Large Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 5, 5, 7, -1, -1, -1, -1
Original Confidences: 4, 3, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel quantization technique for large language models (LLMs) called CherryQ, which identifies a small subset of parameters termed "cherry parameters" that significantly impact model performance. The authors propose an optimization strategy that retains full precision for cherry parameters while quantizing the remaining parameters to lower precision. The method demonstrates improved perplexity and downstream task performance compared to existing quantization approaches. The paper also discusses the empirical study on parameter importance and the use of a straight-through estimator for gradient handling.

### Strengths and Weaknesses
Strengths:
1. The paper provides valuable insights into parameter heterogeneity in LLMs, addressing an important issue.
2. The experimental results are extensive and well-structured, showcasing the effectiveness of CherryQ across various models and tasks.

Weaknesses:
1. The method's reliance on back-propagation may introduce computational and memory overhead, particularly in resource-limited scenarios, as noted in Section 8.
2. The recalculation of the Fisher information matrix at each step could lead to significant fluctuations in parameter importance, potentially causing cyclic errors that are not adequately addressed.
3. The assessment model for weight importance, based on Optimal Brain Damage, overlooks synergistic effects between weights, which could affect quantization outcomes.
4. There is a discrepancy in the presentation of weight importance metrics, leading to potential confusion in cherry parameter identification.
5. The improvement in perplexity over OmniQuant is marginal, and its omission in QA evaluations raises questions about the completeness of the analysis.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the methodology by addressing the computational overhead associated with back-propagation in resource-limited environments. Additionally, the authors should explore methods to manage the cyclic errors arising from the fluctuating parameter importance due to frequent updates. We suggest incorporating a more comprehensive analysis of the synergistic effects between weights in the assessment model. To enhance clarity, we advise revising the presentation of weight importance metrics to avoid confusion. Finally, we encourage the authors to provide a more detailed comparison with OmniQuant and include inference speed results to substantiate claims of efficiency improvements.