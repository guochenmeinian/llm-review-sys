ID: tacb2bFZcm
Title: UPS: Unified Projection Sharing for Lightweight Single-Image Super-resolution and Beyond
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 4, 4, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Unified Projection Sharing (UPS), a novel algorithm for lightweight single-image super-resolution (SISR) that decouples feature extraction from similarity modeling using a unified projection space. The proposed method achieves state-of-the-art performance across various benchmarks and demonstrates robustness for unseen data, with potential applications in additional image restoration tasks.

### Strengths and Weaknesses
Strengths:
1. The paper is clearly written and well organized, providing new insights into lightweight SISR.
2. The UPS algorithm shows superior performance compared to existing lightweight SISR methods across multiple benchmarks.
3. The method effectively reduces computational demands while improving performance, with promising results for broader image restoration applications.

Weaknesses:
1. The authors did not conduct experiments outside of the lightweight model, and optimization perspectives suggest potential for improved performance in various situations.
2. There is a lack of actual latency comparison; differences in network structure may lead to inaccuracies in assessing model efficiency based solely on parameters and FLOPs.
3. The similarity calculation methods have been discussed in past studies, necessitating a more thorough comparison with state-of-the-art models.
4. The paper lacks experimental evaluation in more complex real-world scenarios, and inference efficiency must be included in comparisons with CNN and Transformer-based methods.

### Suggestions for Improvement
We recommend that the authors improve their experimental evaluation by including comparisons with state-of-the-art models and conducting experiments beyond the lightweight model. Additionally, we suggest providing a detailed analysis of inference efficiency and addressing the similarities with existing methods in the literature. It would also be beneficial to report quantitative results on the DIV2K dataset and clarify the implications of modifying the activation function in relation to performance. Lastly, we encourage the authors to explore potential improvements in training strategies and loss functions to enhance model performance further.