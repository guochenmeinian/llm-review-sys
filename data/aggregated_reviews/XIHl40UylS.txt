ID: XIHl40UylS
Title: STEER: Unified Style Transfer with Expert Reinforcement
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a unified framework for arbitrary style transfer, generating pseudo data using expert language models, filtering this data based on a score function considering style, fluency, and semantic meaning, and employing a reinforcement learning algorithm named Quark for training. The authors propose replacing the scalar reward with a vectorized reward function. Experimental results demonstrate that the framework significantly outperforms compared baselines on an 11-style dataset. The authors also introduce the STEER approach, which allows for a broader range of source styles through expert-guided pseudo-parallel data generation and reinforcement learning.

### Strengths and Weaknesses
Strengths:
- The framework achieves good results without relying on large language models.
- The experimental design is robust, with results validated across multiple datasets.
- The model shows the efficacy of reinforcement learning in training conditional generative models, contributing novel insights to the field.

Weaknesses:
- The evaluation metric used for filtering data and as a reward function may create an unfair advantage, as it directly optimizes against the evaluation metric while baselines do not.
- The approach does not fully realize transferring from arbitrary unknown styles, as it requires stylistic data as input.
- The reliance on automatic metrics for human evaluation weakens the credibility of the results, particularly regarding style control.

### Suggestions for Improvement
We recommend that the authors improve the clarity around the evaluation metric used in line 226 and address its implications on fairness in comparison to baselines. Additionally, the authors should consider using human metrics for evaluating style control to enhance the credibility of their findings. It would also be beneficial to clarify how the augmented score \( V \) is calculated and whether it accurately reflects style transfer quality. Finally, we suggest that the authors provide more details on the performance of the model with out-of-domain styles to strengthen their claims.