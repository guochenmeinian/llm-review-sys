ID: Bkrmr9LjeI
Title: Learning to Discover Skills through Guidance
Conference: NeurIPS
Year: 2023
Number of Reviews: 18
Original Ratings: 6, 6, 4, 7, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DISCO-DANCE, an algorithm for unsupervised skill discovery in reinforcement learning (RL). It enhances the mutual information reward of DIAYN with a guidance reward that directs indistinguishable or unconverged skills towards potentially under-explored states, thereby broadening state coverage. The authors evaluate DISCO-DANCE in 2D navigation, Ant maze, and DMControl suites, demonstrating superior performance compared to baseline methods in most benchmarks.

### Strengths and Weaknesses
Strengths:
- The main idea of finding and following a guide policy is clearly illustrated, particularly in Figure 1.
- The authors provide open-source code and detailed experimental setups, ensuring reproducibility.
- Extensive discussions in the appendix address algorithm limitations and comparisons with other baselines, enhancing reader understanding.
- Promising experimental results are reported.

Weaknesses:
- The focus on common benchmarks undermines the claim of addressing unsupervised discovery in complex environments, as locomotion tasks like AntMaze and DMC are not particularly challenging.
- The method's reliance on random walk processes for exploration may hinder efficiency, especially in high-dimensional state spaces.
- The selection of guide skills may not generalize well, particularly in environments where skills cannot access certain areas.

### Suggestions for Improvement
We recommend that the authors improve the experimental evaluation by including comparisons with additional baselines such as DADS, MUSIC, and LSD, particularly in more challenging environments like manipulation tasks. Additionally, we suggest clarifying how new skills are integrated into the skill-latent-conditioned policy, especially regarding input dimension changes. The authors should also consider providing a more sample-efficient method for measuring state density and addressing the potential limitations of the random walk process in complex environments. Finally, linking meaningful results from the appendix to the main body would enhance the paper's clarity and impact.