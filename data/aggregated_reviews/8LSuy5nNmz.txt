ID: 8LSuy5nNmz
Title: Multilingual Generation and Answering of Questions from Texts and Knowledge Graphs
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a multilingual (Brazilian Portuguese and Russian) and multimodal (knowledge graph and natural language) approach to Question Generation (QG) and Question Answering (QA). The authors leverage synthetic data generation and machine translation to create QG-QA data aligned with graphs and texts, demonstrating that their method outperforms a baseline approach adapted from English. The framework aims to enhance question coverage, QA consistency, and correlation to human judgments.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant problem by extending QG-QA research to multilingual and multimodal contexts.
- The proposed method shows improvements over the baseline, indicating its effectiveness in generating questions and answers across different languages and modalities.
- The innovative use of synthetic data generation and machine translation contributes to the development of QG-QA models.

Weaknesses:
- The evaluation of the proposed method lacks depth; more extensive experimental results and additional metrics are needed.
- Limitations and potential biases associated with synthetic data generation and machine translation are insufficiently discussed.
- The paper's presentation is complex and difficult to follow, which may hinder reader comprehension.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by providing more extensive experimental results, including additional metrics and comparisons against alternative approaches. Further analysis of the limitations and potential biases of synthetic data generation and machine translation should be included to ensure the reliability of the proposed method. Additionally, discussing the practical implications and applications of the method in real-world scenarios would enhance the paper's quality. To clarify the data generation process, consider integrating the KELM dataset with generation results from other language models to expand lexical representations. Providing comprehensive examples of KG QA training samples would also be beneficial. Lastly, we suggest adding more comparison methods to strengthen the persuasiveness of the results and addressing the complexity of the presentation to improve reader understanding.