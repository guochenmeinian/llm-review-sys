ID: T5Cerv7PT2
Title: Simplifying Constraint Inference with Inverse Reinforcement Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 5, 6, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for reducing the tri-level optimization of inverse constrained reinforcement learning (ICRL) to a bi-level optimization, leveraging the equivalence between ICRL and inverse reinforcement learning (IRL). The authors provide solid empirical results demonstrating that this bi-level reformulation yields better performance due to a simpler optimization landscape. Additionally, the paper includes updates and clarifications in response to reviewer feedback, particularly highlighting the inclusion of confidence intervals and improved figures for better clarity. The authors assert that IRL methods Pareto-dominate, although this claim is questioned by one reviewer, who suggests that it implies each method should perform at least as well as the baseline across all tasks. The authors also acknowledge the distinction between Imitation Learning (IL) and Inverse Reinforcement Learning, noting that IRL learns a reward function alongside expert behavior.

### Strengths and Weaknesses
Strengths:
- The paper provides solid empirical results that validate the proposed method.
- The inclusion of confidence intervals enhances the clarity of the results.
- The authors have effectively addressed most reviewer concerns, leading to improved scores.
- It addresses a fundamental question in ICRL, showing that ICRL can be approached using IRL algorithms.
- The clarity of the paper makes it easy to follow, demonstrating a clear understanding of the distinctions within the IL and IRL frameworks.

Weaknesses:
- The core contribution, the simplification from tri-level to bi-level, is considered trivial and can be further exploited.
- The claim that IRL methods Pareto-dominate may be misleading without sufficient justification.
- The experimental results exhibit high variance, raising concerns about their reliability.
- There is a minor inconsistency in color-coding between figures that could hinder comparison.
- The analysis of results is inconsistent, particularly regarding the reporting of evaluation metrics and the lack of detailed analysis for figures.

### Suggestions for Improvement
We recommend that the authors improve the theoretical justification for the claim that the bi-level formulation achieves better results than the tri-level formulation. A theoretical proof supporting this assertion would strengthen the contribution. Additionally, we suggest that the authors improve the justification for the claim that IRL methods Pareto-dominate by ensuring that each method performs at least as well as the baseline across all tasks considered. Furthermore, the authors should fully report both feasible rewards and violation rates in their experiments to avoid bias and provide a comprehensive analysis. Clarifying the modifications made to prior methods and ensuring consistent statistical reporting, such as using confidence intervals instead of standard deviation, would enhance the credibility of the results. Lastly, we recommend harmonizing the color-coding between Figures 1 and 2 to facilitate easier comparison and addressing the clarity of the mathematical formulations, ensuring proper punctuation after equations to improve the overall presentation.