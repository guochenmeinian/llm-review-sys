ID: 2z9o8bMQNd
Title: Conversation Understanding using Relational Temporal Graph Neural Networks with Auxiliary Cross-Modality Interaction
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Relational Temporal Graph Neural Network with Auxiliary Cross-Modality Interaction (CORECT), a novel framework aimed at enhancing Emotion Recognition in Conversations (ERC) by capturing conversation-level cross-modality interactions and utterance-level temporal dependencies. The authors propose CORECT as a solution to existing limitations in multimodal ERC, demonstrating its effectiveness through extensive experiments on real-world datasets such as IEMOCAP and CMU-MOSEI.

### Strengths and Weaknesses
Strengths:
- The proposed CORECT framework effectively addresses limitations of existing methods and captures both temporal dependencies and cross-modal interactions.
- Extensive experiments validate the model's performance, showing consistent superiority over state-of-the-art baselines.
- The paper is well-structured, presenting the methodology and results clearly.

Weaknesses:
- The contribution of the paper is difficult to follow and appears incremental, with similarities to prior works.
- The evaluation relies solely on publicly available datasets, which may not fully validate the model's generalization.
- There is a lack of complexity analysis and computational efficiency assessment for practical implementation.
- The paper contains numerous writing mistakes and requires improvements in clarity and fluency.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their contributions to make them more accessible. It is essential to update the related work section with more recent references and conduct significance tests in the experimental section to verify the proposed method's effectiveness. We encourage the authors to perform a complexity analysis to assess the computational efficiency of CORECT. Additionally, addressing the limitations of the proposed model in detail would enhance the paper's rigor. We also suggest incorporating error analysis to evaluate model performance under various scenarios and including visual aids in the introduction to better illustrate the motivation. Finally, we advise proofreading the manuscript to correct typos and improve overall writing quality.