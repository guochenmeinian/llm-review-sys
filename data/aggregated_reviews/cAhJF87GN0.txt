ID: cAhJF87GN0
Title: Explainable Brain Age Prediction using coVariance Neural Networks
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 5, 4, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework for predicting brain age using Variational Neural Networks (VNNs), focusing on cortical thickness features and emphasizing an explanation-driven perspective rather than solely performance-driven metrics. The authors argue that existing methods primarily focus on predicting chronological age, which they contend is a noisy measure of brain age, particularly in neurodegeneration contexts. They demonstrate that VNNs provide anatomical interpretability by identifying significant brain regions associated with the brain age gap in Alzheimer's disease (AD). The methodology is well-structured, leveraging the covariance matrix of the data and employing a linear model to correct for age bias, revealing a correlation between residuals and specific eigenvectors. Results indicate robustness across multiple datasets and model variations, with consistent performance metrics and anatomical interpretability. However, the authors acknowledge the lack of comparisons with existing performance-driven baselines, which raises concerns regarding the robustness of their findings.

### Strengths and Weaknesses
Strengths:
1. The paper addresses a critical issue in Alzheimer's disease research, enhancing understanding of the brain age gap.
2. The use of VNNs offers a novel approach with improved interpretability, a significant advantage over traditional complex models.
3. The choice of cortical thickness features is justified, aligning with biological relevance and enhancing model effectiveness.
4. Results indicate robustness across multiple datasets and model variations, with consistent anatomical interpretability.
5. The authors effectively address reviewer concerns and clarify their methodological approach.

Weaknesses:
1. The specific learning rate of 0.059 for the Adam optimizer raises concerns about potential overfitting; the authors should justify this choice or test a range of learning rates.
2. The reliance on a single dataset with a limited sample size restricts the model's generalizability; testing on additional datasets is recommended.
3. Insufficient comparisons with existing performance-driven baselines hinder the ability to assess the robustness of findings convincingly.
4. Some references are not cited within the main text, potentially affecting clarity and comprehensiveness.
5. The reliance on interpretability and generalization as metrics of robustness may not align with all reviewers' expectations.

### Suggestions for Improvement
We recommend that the authors improve the justification for the chosen learning rate by providing an analysis or testing a range of rates to demonstrate model robustness. Additionally, testing the model on more diverse datasets, such as the Human Connectome Project (HCP), would enhance generalizability. We also suggest including comparisons with simpler baseline models, such as linear regression, to clarify the advantages of the proposed approach. Furthermore, we recommend providing a more comprehensive comparison with existing performance-driven baselines to better establish the robustness of their findings. Ensuring all relevant references are cited within the main text would enhance clarity, and expanding the discussion on the limitations of their approach and how it relates to existing work would strengthen the paper's contributions.