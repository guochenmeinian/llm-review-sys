ID: 7fScrgJ3An
Title: DistillNeRF: Perceiving 3D Scenes from Single-Glance Images by Distilling Neural Fields and Foundation Model Features
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 5, 6, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a self-supervised learning framework named DistillNeRF for understanding 3D environments from limited 2D observations, specifically for autonomous driving. The framework utilizes per-scene optimized Neural Radiance Fields (NeRFs) and features distilled from pre-trained 2D foundation models like CLIP and DINO. The model predicts 3D feature volumes from single-frame multi-view camera inputs, facilitating tasks such as scene reconstruction, novel view synthesis, and zero-shot 3D semantic occupancy prediction. Experimental results on the NuScenes dataset indicate that DistillNeRF outperforms existing methods. Additionally, the paper includes ablation studies analyzing key components of a sparse voxel representation, demonstrating that removing any component leads to a drop in PSNR, thus highlighting the importance of each element. Notably, the addition of depth distillation from offline NeRF significantly improves performance, and the authors assert that their methods outperform state-of-the-art techniques like UniPAD and SelfOcc.

### Strengths and Weaknesses
Strengths:
1. The methodology is robust, combining offline per-scene NeRF training with a distillation stage that generalizes across scenes.
2. The paper is well-structured, clearly explaining the methodology with detailed descriptions of the model architecture, training process, and experiments, supported by effective figures and tables.
3. The ablation studies effectively demonstrate the importance of each component in the sparse voxel representation, showcasing the potential impact of the proposed methods.

Weaknesses:
1. The paper lacks information on computational complexity and inference speed; including training time for both per-scene EmerNeRF and DistillNeRF would aid in assessing efficiency.
2. Experiments are limited to the NuScenes dataset; testing on the Waymo dataset would enhance claims regarding the method's generalizability.
3. The ablation studies are unclear, particularly regarding the meaning of “Ours” in the tables and the absence of a full model test.
4. The discussion on distilling foundation models is incomplete, lacking comparisons with simple baselines and clarity on the reported results.
5. The authors' tone in responses has been perceived as combative, which may detract from constructive dialogue, and there is ambiguity regarding their commitment to incorporating suggested details into the paper, particularly concerning loss terms.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the ablation studies by explicitly defining “Ours” and including tests for the full model and its components. Additionally, we suggest that the authors report the training time and inference speed for all methods to better evaluate efficiency. Including experiments on the Waymo dataset would strengthen the generalizability claims. We encourage the authors to provide a more detailed discussion on the distillation of foundation models, including comparisons with simpler baselines and clearer explanations of the reported results. Furthermore, we recommend that the authors improve the tone of their responses to foster a more collaborative atmosphere and clarify their intentions regarding the inclusion of loss terms in the paper, explicitly stating that they will amend the submission to include these essential details. Clear communication about what will be incorporated into the paper is crucial for addressing reviewer concerns effectively.