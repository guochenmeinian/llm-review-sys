ID: DztaBt4wP5
Title: Membership Inference on Text-to-Image Diffusion Models via Conditional Likelihood Discrepancy
Conference: NeurIPS
Year: 2024
Number of Reviews: 20
Original Ratings: 7, 6, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel membership inference attack (MIA) for text-to-image diffusion models, introducing the Conditional Likelihood Discrepancy (CLiD) metric. The authors argue that conditional overfitting is more pronounced than unconditional overfitting, leading to the development of two practical methods, CLiD_th and CLiD_vec, which leverage KL divergence to measure membership. The results indicate that these methods outperform existing baselines, particularly in real-world training scenarios. The authors also emphasize the importance of realistic training scenarios and assert that their approach is effective across various step/image ratios, countering concerns about overfitting. They address the assumption that data owners have complete prompt sets, claiming their method remains robust even with partial prompts and when text annotations are rephrased.

### Strengths and Weaknesses
Strengths:
- The investigation into membership inference for diffusion models addresses a significant issue with societal implications.
- The introduction of CLiD represents a meaningful contribution, demonstrating superior performance compared to existing methods.
- The experiments are comprehensive, revealing insights about the reliance of current MIAs on overfitting and the importance of distribution consistency.
- The authors provide substantial evidence demonstrating the effectiveness of their method across multiple step/image ratios.
- They acknowledge and address potential limitations in their assumptions regarding data availability and prompt completeness.
- The paper aims to guide future research towards more realistic and practical MIA scenarios.

Weaknesses:
- The foundational assumption of having access to groundtruth conditions for membership inference is unrealistic, limiting the practical applicability of the proposed method.
- The baseline comparisons may be unfair, as similar conditional mechanisms could enhance the performance of existing methods not included in their default implementations.
- The evaluation setups do not reflect real-world scenarios, as they involve high step/image ratios that lead to overfitting, raising concerns about the validity of the results.
- The novelty of the finding regarding condition discrepancy is questioned, as it has been partially addressed in prior work.
- The assumption that data owners have full prompt sets is criticized as overly optimistic, potentially misguiding future research.

### Suggestions for Improvement
We recommend that the authors improve the realism of their evaluation setups by using lower step/image ratios and expanding the training dataset scale to better reflect practical scenarios. Additionally, we suggest incorporating prompt searching mechanisms to enhance the robustness of their method, as this could provide a more realistic assessment of membership inference capabilities. Furthermore, addressing the limitations of the foundational assumptions and including empirical results on benchmark datasets like CelebA and CIFAR would strengthen the paper's contributions. We also recommend that the authors improve clarity regarding the implications of their findings on future MIA research, explicitly stating that the success observed in their over-training and real-world training setups may lead to hallucinations of MIA success, and these setups should not be the basis for future work. Lastly, we suggest revising the introduction and experiments sections to emphasize the significance of their findings in realistic settings, particularly regarding the limitations of existing evaluation methods.