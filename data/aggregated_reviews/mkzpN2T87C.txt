ID: mkzpN2T87C
Title: Non-asymptotic Global Convergence Analysis of BFGS with the Armijo-Wolfe Line Search
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 6, 8, 6, -1, -1, -1, -1
Original Confidences: 4, 4, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a unified non-asymptotic convergence analysis of the BFGS method with Armijo-Wolfe line search, demonstrating two converging stages: (1) a linear global convergence rate independent of the condition number when the Hessian is Lipschitz continuous, and (2) a superlinear convergence rate when the unit step length meets the Armijo-Wolfe line search condition. The analysis also explores iteration complexity using a log bisection algorithm.

### Strengths and Weaknesses
Strengths:
- The non-asymptotic global convergence rate improves upon previous literature, with a rigorous theoretical framework and clear assumptions and proofs.
- The innovative use of a log bisection algorithm is noteworthy.
- The explanations of theoretical results enhance reader comprehension of the methodology and results.
- The paper's unified analysis of global and superlinear convergence, along with complexity analysis, contributes significantly to optimization literature.

Weaknesses:
- The claim of “presenting the first explicit” in the abstract is overly strong.
- The authors should clarify the condition “with $B_0 = L I$” in Line 4 for precision.
- The abstract's structure may confuse readers by presenting linear convergence before superlinear convergence.
- More intuitive explanations regarding the convergence rate comparison with reference [38] could be beneficial.
- The initialization schemes mentioned in Line 217 are impractical as they require unknown parameters $L$ or $\mu$.
- Redefinition of $\tilde B_0$ in Line 227 lacks clarity.
- The convergence of $\hat \rho_t$ should be to 1/2 instead of 1 in Line 237.
- The notation in $\delta_2$ in Equation 23 needs adjustment.
- Additional insights into the finite number of iterations discussed in Lemma 6.3 would enhance understanding.
- The upper bound in (26) may be excessively large when $t$ is not sufficiently large, necessitating clearer presentation of convergence transitions.
- The term $C_0$ should refer to the suboptimality of the initial iterate in Line 273.
- The distinction of convergence stages in Section 6 is not adequately presented.
- The rationale for using the log bisection algorithm over other line search methods should be addressed.
- Inclusion of numerical experiments to illustrate different convergence stages and performance with various initializations would strengthen the paper.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the abstract by restructuring it to avoid confusion regarding the presentation of linear and superlinear convergence. Additionally, please clarify the condition “with $B_0 = L I$” in Line 4 and provide a more intuitive explanation regarding the convergence rate comparison with reference [38]. It would be beneficial to address the impracticality of the initialization schemes mentioned in Line 217 and to redefine $\tilde B_0$ in a clearer manner. We suggest that the authors adjust the convergence of $\hat \rho_t$ to 1/2 in Line 237 and make the notation in $\delta_2$ larger in Equation 23. Further insights into the finite number of iterations in Lemma 6.3 and the upper bound in (26) would enhance the paper's clarity. We also encourage the authors to comment on the choice of log bisection algorithm and to include numerical experiments to validate theoretical findings.