ID: YcmGuwdLoU
Title: Real-Time Motion Prediction via Heterogeneous Polyline Transformer with Relative Pose Encoding
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 6, 6, 4, 6, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for future motion prediction in autonomous driving agents, focusing on computational efficiency suitable for real-time deployment. The authors propose a new attention mechanism, KNARPE, and a hierarchical transformer architecture, HPTR, which introduces a pairwise-relative input representation. These innovations allow the model to achieve state-of-the-art (SOTA) performance comparable to agent-centric models while maintaining the efficiency of scene-centric models, as demonstrated through empirical comparisons on the Waymo and Argoverse 2 datasets. The authors argue that their method outperforms HiVT, which employs an agent-centric representation and standard attention, particularly in scalability for real-time motion prediction scenarios involving numerous agents.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, with clear notation and easy-to-follow explanations, especially compared to prior works.
- The proposed method effectively mitigates the computational challenges of agent-centric approaches, achieving good performance with lower costs.
- The computational efficiency is thoroughly measured, including GPU memory consumption and inference times.
- The method shows competitive performance on standard benchmarks and includes theoretical comparisons to existing models like WayFormer.
- The authors provide a clear differentiation between their method and HiVT, emphasizing novel contributions in scalability and efficiency.
- The rebuttal addresses reviewer concerns comprehensively, leading to improved ratings from some reviewers.
- The authors intend to release the code publicly, which would benefit the research community.

Weaknesses:
- While the paper claims SOTA performance with scalable computational costs, comparisons are primarily made against WayFormer, lacking broader evaluations against other relevant methods like GoRela and ProphNet.
- The performance metrics for WayFormer appear low, raising questions about the validity of the results presented.
- The complexity of the proposed architecture introduces a large space of design choices and hyper-parameters, complicating the model's training and efficiency claims.
- There is insufficient analysis of how the proposed method compares to GNN-based approaches and other relevant models in terms of efficiency.
- The paper lacks clarity regarding the evaluation protocols compared to baseline methods, which may lead to confusion.
- There is insufficient detail on the specific variants of baseline methods used in comparisons, particularly regarding efficient attention architectures.

### Suggestions for Improvement
We recommend that the authors improve the comparative analysis by including evaluations against other relevant methods, particularly GoRela and ProphNet, to substantiate claims of efficiency and performance. Additionally, we suggest providing a clearer explanation of the low performance of WayFormer in Table 2 and addressing the potential confusion surrounding the contributions of Figure 1. It would also be beneficial to include ablation studies on the relative pose encoding to quantify its impact on performance. Furthermore, we recommend improving the clarity of the evaluation protocol by explicitly specifying how it differs from those used in baseline papers. Including a separate baseline subsection in Section 4 that details the baselines considered for the efficiency analysis, highlighting similarities and differences with the original papers, would enhance transparency in comparisons. Lastly, we encourage the authors to clarify the implementation details of the KNARPE operation and the significance of the post-processing techniques mentioned in the paper.