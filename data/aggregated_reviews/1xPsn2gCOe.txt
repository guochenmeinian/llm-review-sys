ID: 1xPsn2gCOe
Title: Computing a human-like reaction time metric from stable recurrent vision models
Conference: NeurIPS
Year: 2023
Number of Reviews: 7
Original Ratings: 6, 8, 7, 8, -1, -1, -1
Original Confidences: 4, 4, 5, 3, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new measure of visual artificial network computation time, $\xi_{cRNN}$, which reflects the time-averaged uncertainty of a convolutional RNN trained with an evidential deep learning loss. The authors analyze the dynamics of this network across various classification tasks, finding that $\xi_{cRNN}$ correlates well with human reaction times and shares qualitative features with them. The study aims to bridge the gap between deep learning models and human decision-making processes by incorporating temporal variability.

### Strengths and Weaknesses
Strengths:
- The paper addresses a critical aspect of human behavior—decision-making time—by integrating recent machine learning concepts, marking a significant step towards understanding temporal variability.
- The breadth of tasks analyzed and the inclusion of both qualitative and quantitative analyses enhance the study's robustness.
- The clear presentation and intuitive figures contribute to the paper's accessibility.

Weaknesses:
- While there are strong correlations between $\xi_{cRNN}$ and human reaction times, the mechanistic similarity is less evident, as $\xi_{cRNN}$ measures uncertainty rather than computation time. This raises questions about the model's ability to represent the tradeoff between computation and decision-making seen in human behavior.
- The approach may not generalize well beyond classification tasks, limiting its applicability to more complex real-world scenarios.
- The metric's reliance on attractor dynamics may artificially constrain uncertainty, questioning its relevance for tasks with ambiguous stimuli.

### Suggestions for Improvement
We recommend that the authors improve the mechanistic interpretation of $\xi_{cRNN}$ by comparing it with models that explicitly incorporate adaptive computation time, such as those discussed in Graves et al. and Pascanu et al. Additionally, the authors should explore the potential for their metric to generalize beyond classification tasks, perhaps by investigating its application to more naturalistic stimuli. Clarifying how the proposed metric relates to other architectures, such as convolutional LSTMs, would also enhance its broader applicability. Furthermore, we suggest that the authors condition their analyses on dot distance and other intricate features to better demonstrate how these factors correlate with human reaction times. Lastly, addressing the limitations of the metric in relation to neural activity and considering alternative approaches, such as reinforcement learning for adaptive stopping criteria, could provide valuable insights.