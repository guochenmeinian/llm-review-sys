ID: ecPIg6o84Z
Title: Image-aware Evaluation of Generated Medical Reports
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 3, 6, 4, 6, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel evaluation metric, VLScore, for automatic medical report generation that integrates both textual and clinical aspects by mapping reports and corresponding images to a joint visual-textual space to measure similarity. The authors demonstrate that VLScore outperforms existing metrics on the ReXVal dataset and a newly proposed dataset with specific perturbations.

### Strengths and Weaknesses
Strengths:
1. The proposed method improves correlation with radiologistsâ€™ judgments by 20%, showcasing its effectiveness.
2. The introduction of a new dataset with perturbed samples allows for detailed comparisons and enhances the evaluation of the proposed metric.
3. The approach addresses significant limitations of existing metrics in capturing medical correctness and nuanced differences in report generation.

Weaknesses:
1. The evaluation process relies heavily on a shared image-text space, raising concerns about the reliability of measuring similarity based on distance in this space.
2. The proposed metric's effectiveness is contingent on the performance of multi-modal embedding models, which may not be universally available.
3. The scope is limited to chest X-ray images, and the paper does not sufficiently address generalizability to other imaging modalities or datasets.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the generation process for the perturbed dataset, specifically detailing the extent of content deletion and its impact on relevance results. Additionally, we suggest conducting supplemental studies that include image perturbations to assess the metric's performance in "Image-aware evaluation of generated reports." It would also be beneficial to provide runtime comparisons of VLScore with NLG and CE metrics, as well as justifications for the selection of multi-modal embedding models. Finally, we encourage the authors to report evaluations of existing methods using VLScore to strengthen the paper's contributions.