ID: oML3v2cFg2
Title: When Demonstrations meet Generative World Models: A Maximum Likelihood Framework for Offline Inverse Reinforcement Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 8, 6, 7, 7, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a two-level maximum likelihood framework for offline inverse reinforcement learning (IRL), addressing the challenges of distribution shift and covariate shift in offline imitation learning. The authors propose a method that first learns a dynamic model from expert demonstrations and then formulates a maximum likelihood objective to recover both the reward function and the policy. The approach includes theoretical guarantees regarding the optimality of the recovered reward function based on dataset coverage and provides empirical evaluations on D4RL benchmarks, demonstrating significant improvements over existing baselines.

### Strengths and Weaknesses
Strengths:
- The paper is well written, clearly organized, and presents a novel formulation for offline IRL.
- It provides extensive theoretical justifications and empirical evaluations, showing statistically significant improvements in most tasks.
- The analysis of the surrogate objective and its relation to the true upper-level objective is well articulated.

Weaknesses:
- The assumption of ergodicity raises concerns about coverage requirements.
- The connection between the MLE objective and policy error is not clearly established.
- The training description for behavior cloning (BC) lacks clarity, and there is no discussion on hyperparameter tuning.
- The experiments do not address performance with fixed rewards or on smaller datasets, which is crucial for validating claims about covariate shift.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the training description for BC by specifying what "train the algorithm until convergence" entails and whether validation checks are employed. Additionally, we suggest including results on a few expert demonstrations to verify claims regarding covariate shift. It would also be beneficial to discuss the implications of model uncertainty more thoroughly, both theoretically and through experimental results. Finally, we advise adding a conclusion section that summarizes the findings and discusses limitations of the current method.