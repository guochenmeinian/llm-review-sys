ID: MfGRUVFtn9
Title: Unveiling and Mitigating Backdoor Vulnerabilities based on Unlearning Weight Changes and Backdoor Activeness
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 5, 8, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Two-Stage Backdoor Defense (TSBD) method that leverages two key observations: the correlation of weight changes during clean and poison unlearning, and the heightened activity of neurons in backdoored models. The authors propose a defense strategy involving the reinitialization of neurons with significant weight changes followed by activeness-aware fine-tuning. Extensive experiments validate the effectiveness of the proposed method against various backdoor attacks.

### Strengths and Weaknesses
Strengths:  
1. The paper is well-written and presents clear insights into backdoor defense, making it easy to follow.  
2. The proposed method demonstrates effectiveness across multiple attacks, supported by comprehensive experimental results.  
3. The methodology is rigorously evaluated, providing a thorough analysis of the proposed defense.

Weaknesses:  
1. The design principle of TSBD closely resembles that of RNP, with similar performance metrics, raising questions about the novelty of the approach.  
2. The computational overhead of the proposed method is not adequately analyzed, which may affect its practicality.  
3. The paper lacks a discussion on its limitations and does not provide sufficient clarity on the differences between TSBD and RNP.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the core technical differences between TSBD and RNP, as the current explanations are unconvincing. Additionally, an analysis of the computational overhead and efficiency of the proposed method compared to existing defenses should be included. We suggest that the authors provide a more detailed discussion on the limitations of their method and address the scalability and generalizability of TSBD across different datasets and model architectures. Finally, including experiments that demonstrate the trade-off between efficiency and accuracy in Activeness-Aware Fine-Tuning would enhance the understanding of the method's practical implications.