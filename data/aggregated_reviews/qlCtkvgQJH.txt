ID: qlCtkvgQJH
Title: LogiCoT: Logical Chain-of-Thought Instruction Tuning
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an instruction-tuning dataset aimed at enhancing logical reasoning capabilities in language models. The authors construct this dataset by prompting GPT-4 to generate chain-of-thought explanations, which are then used to fine-tune the LLaMA-7B model. The results indicate significant performance improvements on reasoning benchmarks compared to the base model and other instruction-tuned models, including ChatGPT and GPT-4.

### Strengths and Weaknesses
Strengths:
- The paper identifies a critical gap in instruction-tuning LLMs by focusing on logical reasoning.
- It contributes a novel dataset that could enhance instruction understanding for logical tasks.
- The resulting model demonstrates substantial performance improvements on general reasoning benchmarks, indicating the dataset's effectiveness.

Weaknesses:
- There is insufficient evaluation of the dataset quality, particularly regarding the fidelity of GPT-4 generated reasoning chains.
- The rationale behind the selection of instruction types and the conversion process from existing datasets lacks clarity.
- The experimental design raises concerns, including potential data contamination and the need for clearer comparisons with baseline models.

### Suggestions for Improvement
We recommend that the authors improve Section 3 by providing a rationale for the selection of the eight instruction types, including design principles or relevant citations. Additionally, the authors should clarify the conversion process of examples from chosen datasets into these types. In Section 4, we suggest including more comprehensive comparisons against additional finetuned LLaMA models to substantiate claims regarding the superiority of logic-related data. Furthermore, we advise conducting a human evaluation of the dataset quality to support claims about the reasoning chains generated by GPT-4. Lastly, we encourage the authors to enhance the paper's presentation by addressing issues related to unsupported claims and improving clarity in figures and tables.