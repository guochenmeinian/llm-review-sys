ID: jWqkEB3wJP
Title: RobustEmbed: Robust Sentence Embeddings Using Self-Supervised Contrastive Pre-Training
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents RobustEmbed, a self-supervised method for learning robust sentence embeddings through the application of dropout and adversarial perturbations to generate hard positives for contrastive learning. The proposed method optimizes a loss function that encourages similarity among original, dropout, and perturbed embeddings while diverging the dropout and perturbed embeddings. Experimental results indicate that RobustEmbed improves upon baselines across various tasks, including semantic textual similarity, transfer learning, and text classification.

### Strengths and Weaknesses
Strengths:
- The paper is well written and easy to follow.
- The proposed method is straightforward, effectively maximizing similarity among embeddings.
- Experimental results are thorough, demonstrating gains in both robustness and performance on downstream tasks.

Weaknesses:
- The improvements on semantic textual similarity and transfer tasks appear marginal.
- The evaluation lacks comparison with strong state-of-the-art methods and recent baselines, such as USCAL.
- The novelty is limited, as the adversarial methods used (FGSM and PGD) are well-known; specific designs for sentence embeddings could enhance originality.
- The evaluation methodology raises concerns about the relationship between robustness in classification tasks and sentence embeddings, suggesting a need for a new evaluation benchmark.

### Suggestions for Improvement
We recommend that the authors improve the experimental design by including at least 1000 examples for adversarial robustness testing and comparing their method against basic adversarial training methods like PGD or FreeLB. Additionally, the authors should clarify the framing of PGD and FGSM in the context of their method and provide more intuitive evaluations of the sentence embeddings, such as measuring uniformity and alignment. To enhance the novelty, the authors should explore how to ensure that adversarial perturbations are semantically meaningful. Finally, we suggest developing a new evaluation benchmark specifically designed for direct assessments of sentence embeddings.