ID: G5RwHpBUv0
Title: Pick-a-Pic: An Open Dataset of User Preferences for Text-to-Image Generation
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 8, 7, 6, 6, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 5, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Pick-a-pic, a large and open dataset of human preferences for model-generated images, which is utilized to train a scoring function called PickScore based on CLIP. The authors find that PickScore correlates better with real user preferences than existing scoring methods and can enhance the quality of generated images through improved output selection.

### Strengths and Weaknesses
Strengths:
- The proposed dataset addresses a significant gap in image generation research by incorporating human preferences, a crucial evaluation metric.
- The dataset is crowdsourced from real users, contains numerous examples, and is open-sourced.
- PickScore demonstrates a high correlation with human preferences, providing a valuable alternative to existing evaluation metrics.
- The potential application of PickScore to improve image generation models is promising.

Weaknesses:
- A more comprehensive analysis of the prompts used in Pick-a-pic is needed, including diversity and word distribution comparisons with datasets like COCO or DreamBench.
- There is a concern that public user preferences may be biased towards certain aspects of generated images, such as interestingness, while neglecting others like faithfulness to prompts. An analysis of these biases would be beneficial.
- The paper's final results show only about 70% alignment with human preferences, which raises questions about the model's effectiveness and the quality of human ratings.
- The impact of training on synthetic images versus real images needs further exploration, particularly regarding the applicability of the scoring function in real-world scenarios.

### Suggestions for Improvement
We recommend that the authors improve the analysis of user prompts in the Pick-a-pic dataset to assess diversity and compare it with existing datasets. Additionally, the authors should provide a detailed examination of potential biases in user preferences and consider discussing the implications of the model's performance relative to human ratings. Further exploration of the model's applicability to real images and the use of parameter-efficient fine-tuning methods, such as LoRA or prompt/adaptor learning, could enhance the technical contribution of the paper. Lastly, clarification on the "superhuman" performance of PickScore and the correlation issues with FID would strengthen the paper's findings.