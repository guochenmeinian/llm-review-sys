ID: QBbc0L5Zpb
Title: Riemannian Black Box Variational Inference
Conference: NeurIPS
Year: 2024
Number of Reviews: 2
Original Ratings: 5, 8
Original Confidences: 3, 3

Aggregated Review:
### Key Points
This paper presents a gradient-free computational algorithm for approximate Bayesian inference, specifically targeting scenarios where gradients of the likelihood are unavailable. The authors consider a mean-field variational distribution with each marginal belonging to an exponential family, learning natural parameters iteratively through natural gradient steps. The approach aims to address constraints on parameters, such as ensuring positive definite covariance matrices, by employing natural gradient descent in a Riemannian manifold. However, the paper raises questions about the clarity of certain concepts related to Riemann manifolds and the implications of approximations made in the methodology.

### Strengths and Weaknesses
Strengths:
- The paper addresses the interesting question of performing variational inference (VI) without gradients of the likelihood.
- It effectively highlights the viability of natural gradient updates and the use of Riemann manifolds to manage parameter constraints.

Weaknesses:
- The title is misleading, as the use of Riemann gradient descent has been previously proposed, and it should focus on the specific problem of gradient-free VI.
- There is a lack of novelty; while the paper discusses an approximation technique for gradients, it does not sufficiently address the effectiveness of this approximation or its impact on evaluating the joint density.
- The experimental results lack convincing evidence of the method's performance.

### Suggestions for Improvement
We recommend that the authors improve clarity by providing explanations of Riemannian manifold concepts for non-technical audiences, including examples of why retractions are available in closed form. Additionally, a proper derivation for the approximation used in Theorem 1 should be included, along with a discussion comparing it to actual joint density computations. The authors should also clarify the notation between $h_{\theta_i}$ and $h_i$, correct the flipped variables in Algorithm 1, and discuss the advantages of substituting the joint density in detail. Furthermore, we suggest enhancing the experimental section by including more challenging problems and a broader range of baseline comparisons, as well as visualizations to illustrate the method's behavior and uncertainty estimates. Lastly, we urge the authors to correct the numerous typos and syntax errors to improve readability.