ID: YTo9KGNZ3U
Title: Measuring and Mitigating Constraint Violations of In-Context Learning for Utterance-to-API Semantic Parsing
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents improved metrics for measuring constraint violations in natural language to API semantic parsing, particularly within the context of in-context learning using large language models (LLMs). The authors aim to generate APIs that effectively address tasks based on natural language utterances and a limited set of training examples. The study introduces two solutions for mitigating constraint violations: selecting in-context examples that align with the test utterance and employing constrained decoding to guide LLM generation towards valid API names and arguments. Experiments on the TOPv2 benchmarks validate the proposed metrics and mitigation strategies.

### Strengths and Weaknesses
Strengths:  
- The introduction of metrics to assess constraint violations is valuable for understanding API semantic parsing performance.  
- The proposed mitigation techniques, including fetching similar queries and constrained decoding, effectively reduce constraint violations.  
- The experimental results support the utility of the proposed metrics and strategies.  
- The paper provides useful analysis of constraint violations in leading LLMs and references relevant recent work.

Weaknesses:  
- The mitigation strategies lack novelty, as they are established techniques in the literature.  
- The scope is narrow, focusing solely on in-context learning for a single dataset, which may limit generalizability.  
- There are questions regarding the exhaustiveness of the presented list of constraints and the applicability of the proposed strategies to other learning paradigms.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their mitigation strategies by exploring less common approaches to address constraint violations. Additionally, we suggest expanding the scope of the study to include multiple datasets and learning paradigms to enhance generalizability. Clarifying the differences between API calls and semantic parsing tasks, as well as providing details on the modifications made to the TOPv2 dataset, would strengthen the paper. Finally, addressing the completeness of the constraint categories presented would provide a more robust framework for future research.