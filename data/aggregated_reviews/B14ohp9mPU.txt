ID: B14ohp9mPU
Title: On Evaluation of Bangla Word Analogies
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents two word analogy datasets for the low-resource Bangla language: one by translating the existing English resource (Mikolov et al., 2013) and another built from scratch, considering Bangla linguistic properties. The authors evaluate various classical and transformer-based word embedding models, finding that the latter outperforms the former, although overall performance remains low, indicating a need for further improvement in Bangla word representation quality. The new dataset is a significant contribution for future evaluations in Bangla NLP.

### Strengths and Weaknesses
Strengths:
- The paper introduces a new evaluation dataset for the low-resource Bangla language, supporting the development of NLP tools.
- It covers a diverse set of relations and evaluates various word representation methods, including a fine-grained analysis of 12 word analogy relationship types.
- The writing is clear and accessible.

Weaknesses:
- The dataset construction details are insufficiently explained, lacking clarity on how related word pairs were selected and the background of annotators.
- The paper does not adequately motivate the importance of word-level tasks like analogy, particularly in the context of current NLP trends focusing on larger models.
- The experiments yield low accuracy results, raising concerns about dataset representativeness and balance, and the potential benefit of merging the two datasets is not explored.

### Suggestions for Improvement
We recommend that the authors improve the description of the dataset construction process by providing more details on how word pairs were selected and the annotators' qualifications. Additionally, we suggest that the authors address the significance of word-level tasks in the context of recent NLP developments. To enhance the results, consider merging the two datasets and enriching them with more word analogies. Furthermore, clarify the terminology used for evaluation metrics (top-1, top-3, etc.) and provide more information about the bnBART model and its training dataset.