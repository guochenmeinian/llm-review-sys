ID: 8UWPQboDq9
Title: Multi-Task Learning of Query Generation and Classification for Generative Conversational Question Rewriting
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Multi-task Learning (MTL) approach for conversational question answering, focusing on the simultaneous tasks of identifying context-dependent follow-up questions and rewriting them into self-contained forms. The authors utilize BART and T5 models, demonstrating improvements over single-task learning (STL) in passage retrieval on the OR-QuAC test set. The study is noted for its well-defined task and effective methodology, although it lacks novelty compared to existing literature.

### Strengths and Weaknesses
Strengths:  
- The task and motivations are well-defined, with comprehensive experiments showing robust results.  
- The combination of follow-up identification and question rewriting is an interesting contribution that improves passage retrieval.  
- The authors provide a good comparison of models using significance testing, and the computational budget and training details are reported.

Weaknesses:  
- The scope of experiments is limited, focusing only on English and lacking variations in retrieval methods and larger models.  
- The idea of joint text generation and classification is straightforward and lacks novelty, with similarities to existing works.  
- The experimental results section is cluttered, and the evaluation metrics used (ROUGE-1 and BLEU) are criticized for their limitations.

### Suggestions for Improvement
We recommend that the authors improve the breadth of their experiments by including different retrieval and reranking methods, as well as testing larger models to assess the significance of potential improvements from their MTL approach. Additionally, we suggest a broader discussion of related works that address dynamic states in conversations, such as concepts and intents. Clarifying the differences between tests in the experimental results section and considering alternative evaluation metrics like BERTScore or BLEURT would enhance the robustness of the study. Finally, addressing the formatting issues, such as the placement of table captions, is necessary to meet submission guidelines.