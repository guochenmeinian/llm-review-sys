ID: cCYvakU5Ek
Title: The geometry of hidden representations of large transformer models
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 7, 6, 9, 5, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into the geometry of hidden representations in transformer models trained via self-supervised tasks, focusing on intrinsic dimension (ID) and neighborhood overlap. The authors demonstrate that as data progresses through transformer layers, both ID and neighborhood overlap exhibit characteristic changes that correlate with the semantic organization of representations. The findings suggest that identifying layers with optimal semantic content could enhance downstream task performance. The analysis includes experiments on protein sequences and image data, revealing distinct patterns in ID evolution across layers.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant gap in the literature by exploring hidden representations in transformers, particularly in the context of self-supervised learning, which is increasingly relevant in NLP and vision.
- The analysis is thorough, with the use of intrinsic dimension and neighborhood overlap metrics reinforcing each other's conclusions, enhancing the credibility of the results.
- The work offers practical insights for identifying transformer layers that capture the most semantic content, bridging theoretical findings with practical applications.

Weaknesses:
- The experiments are limited to self-supervised tasks based on data reconstruction, raising questions about the generalizability of the findings to other training methods, such as supervised learning.
- Many claims rely on qualitative comparisons of ID curves, and incorporating more quantitative measures could strengthen the analysis and facilitate broader comparisons with other models and datasets.
- The organization of the discussion around figures can lead to reader disorientation; a more concise presentation of key takeaways would improve clarity.

### Suggestions for Improvement
We recommend that the authors improve the comprehensiveness of their experiments by including ablation studies to disentangle the effects of model architecture from training methods. Additionally, incorporating more quantitative measures for comparing ID curves would enhance the robustness of their claims. We suggest that the authors streamline the discussion of figures to better highlight main findings, potentially allowing for the inclusion of further experiments. Lastly, clarifying the definition of "semantically rich representation" and ensuring figures are positioned closer to their corresponding analyses would enhance readability.