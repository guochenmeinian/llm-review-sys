ID: IIfdKVyeVh
Title: Vicarious Offense and Noise Audit of Offensive Speech Classifiers: Unifying Human and Machine Disagreement on What is Offensive
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a noise audit of nine offensive speech classifiers on over 92 million YouTube comments, highlighting significant variations in results. The authors propose a dataset annotated with political perspectives on offense and vicarious offense, and analyze the agreement between human and machine moderators on offensive content. 

### Strengths and Weaknesses
Strengths:
- The release of a novel dataset valuable for research on vicarious offense.
- The annotation process is well articulated.
- Comprehensive experimental evaluation comparing machine and human moderators, yielding informative results.

Weaknesses:
- Low agreement among machine moderators due to training on different datasets; a concatenation of datasets or evaluation of more public APIs like the Perspective API is recommended for better noise audit results.
- Presentation issues in the last sections hinder clarity.
- Insufficient justification for the choice of machine moderators and their training data.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the last two sections to enhance readability. Additionally, please cite the Appendix subsections and Table 1 within the main text for easier reference. Consider reorganizing the presentation of results, such as moving the ChatGPT findings to the Results section and ensuring consistent notation for vicarious offense throughout the paper. It would be beneficial to include an example case of vicarious offense in the introduction and to explore the temporal evolution of findings. Lastly, we suggest providing a detailed rationale for not using the Perspective API and including self-alignment as a baseline for comparison in RQ2.