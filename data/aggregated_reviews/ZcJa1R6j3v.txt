ID: ZcJa1R6j3v
Title: Large Language Models Are Semi-Parametric Reinforcement Learning Agents
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 5, 4, 4, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework called REMEMBERER, which integrates a persistent experience memory with Reinforcement Learning with Experience Memory (RLEM) to enhance the capabilities of Large Language Models (LLMs) in decision-making tasks. The authors propose that this setup allows LLMs to learn from past interactions without the need for fine-tuning. The framework is evaluated on two RL task sets, WikiHow and WebShop, demonstrating improved performance over previous state-of-the-art models.

### Strengths and Weaknesses
Strengths:  
1. The innovative approach of combining LLMs with RL is compelling and addresses typical limitations associated with fine-tuning.  
2. The paper is well-structured, with clear writing and effective illustrations.  
3. Extensive empirical results validate the effectiveness of the proposed method.

Weaknesses:  
1. Clarity is a significant issue; the paper is difficult to read and understand, particularly regarding the Q-learning implementation and the use of specific terms like "flattening."  
2. The discussion on the necessity of using RL over other methods is insufficient, leaving questions about the choice of methodology.  
3. The paper lacks a limitations section and does not adequately explore the impact of different configurations of the REMEMBERER system.  
4. The applicability of the proposed method to tasks with extensive observation spaces remains unclear, and the ablation studies are insufficient.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by providing detailed explanations of the Q-learning process, including the architecture used and the significance of terms like "flattening." Additionally, we suggest that the authors include a limitations section to address potential shortcomings of their approach. It would be beneficial to expand the discussion on why RL is preferred over alternative methods, possibly including comparative analyses with similar approaches. Furthermore, we encourage the authors to conduct more thorough ablation studies to better understand the influence of various configurations on performance. Lastly, addressing the adaptability of the proposed method to different observation types, such as image or vector-based data, would enhance the comprehensiveness of the work.