ID: h3CGHf7457
Title: Multi-modal Queried Object Detection in the Wild
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 4, 7, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents MQ-Det, an innovative approach for open-vocabulary object detection that integrates both textual descriptions and visual exemplars as category queries. The authors propose a Gated Class-scalable Perceiver to enhance object detection by applying cross-attention to language and vision inputs. The method is validated through extensive experiments on LVIS and ODinW datasets, demonstrating state-of-the-art performance. Additionally, the authors introduce a vision-conditioned masked language prediction strategy to address learning inertia, ensuring effective integration of visual information. The authors also emphasize a "finetuning-free" approach, proposing to replace "zero-shot" terminology with "finetuning-free" for clarity, which is a positive step. However, there is a need for clearer presentation of the zero-shot setup.

### Strengths and Weaknesses
Strengths:
- The paper effectively combines textual and visual information, addressing significant challenges in open-vocabulary detection.
- The proposed GCP module and training techniques are novel and have broader applicability beyond this study.
- The experimental results convincingly demonstrate the effectiveness of the proposed method.
- The proposed method is innovative and well-structured, with a commendable intention to clarify terminology.

Weaknesses:
- The claims regarding training efficiency are overstated; the authors should clarify the additional training time and data required for MQ-GLIP.
- The zero-shot evaluation may violate the task definition by improperly using exemplar images, which could misrepresent the model's performance.
- The full-shot performance of MQ-Det is subpar compared to existing methods, and the authors need to provide clearer explanations for this discrepancy.
- The current terminology may confuse readers, necessitating clearer definitions and consistent usage throughout the manuscript.
- The absence of a column in Table 1 indicating the number of examples used without finetuning may hinder reader comprehension.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the training efficiency claims by explicitly stating the additional time and data required for MQ-GLIP. Additionally, the authors should address the potential violation of the zero-shot setting by clarifying the use of exemplar images in their evaluations. It would also be beneficial to provide a detailed explanation for the observed subpar full-shot performance in comparison to other methods. Furthermore, we suggest conducting separate evaluations for base and novel classes to better assess the model's generalization capabilities. To enhance clarity, we recommend that the authors ensure consistent usage of the "finetuning-free" terminology throughout the manuscript, including a clear definition in the introduction and experiment chapters. Lastly, please include a column in Table 1 that indicates the number of examples each method utilizes without finetuning to improve reader understanding.