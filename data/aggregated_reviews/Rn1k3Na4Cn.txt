ID: Rn1k3Na4Cn
Title: CLAD-ST: Contrastive Learning with Adversarial Data for Robust Speech Translation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method called CLAD-ST, which enhances cascade speech-to-text (AST) translation by improving the robustness of neural machine translation (NMT) against speech recognition (ASR) outputs. The authors propose using contrastive learning alongside cross-entropy training to align ASR outputs with gold-reference transcriptions, demonstrating effectiveness in experiments on English-German and English-French language pairs. The method is noted for its simplicity and data efficiency, as it does not require a triplet of speech-transcription-translation data.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and easy to follow.
- The proposed method is intuitive and integrates easily into existing MT model training, yielding significant improvements over baseline methods.
- The approach is data-efficient, requiring minimal changes to the NMT architecture.

Weaknesses:
- The reliance on human transcripts limits applicability in scenarios where such transcripts are hard to obtain.
- The experimental setup is limited to only two high-resource language pairs, raising concerns about the generalizability of the findings.
- The NMT model used is relatively small, which may affect the scalability of improvements from the contrastive loss.

### Suggestions for Improvement
We recommend that the authors expand the experimental setup to include lower-quality ASR systems and non-English source language pairs to better assess the method's robustness in diverse scenarios. Additionally, we suggest addressing the potential impact of noise levels in ASR transcripts during training and exploring alternative approaches for obtaining sentence representations, such as mean or max pooling. Finally, we encourage the authors to clarify claims regarding the elimination of the need for parallel ST data and to consider including comparisons with recent works on cascade AST to strengthen the paper's contributions.