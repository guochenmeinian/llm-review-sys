ID: 8qu52Fl1Dt
Title: NeuroClips: Towards High-fidelity and Smooth fMRI-to-Video Reconstruction
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 7, 8, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents NeuroClips, a framework for reconstructing high-fidelity videos from fMRI data. It integrates pixel-level and semantic-level visual learning through the Perception Reconstructor (PR) and the Semantics Reconstructor (SR), ensuring smoothness and high-quality keyframes. The framework achieves significant advancements in semantic precision and pixel-level matching, improving SSIM by 128% and spatiotemporal metrics by 81%. The validation procedure is well-structured, and the framework's design is innovative, addressing limitations of previous methods in fMRI-to-video reconstruction. Additionally, the paper includes a comparative analysis of NeuroClips against MinD-Video using new metrics ST-SSIM and ST-PSNR, demonstrating that NeuroClips significantly outperforms MinD-Video in terms of video reconstruction capabilities. The authors argue that traditional metrics like Fr√©chet Video Distance (FVD) may not fairly assess their model due to the freezing of pre-trained parameters in Animatediff, emphasizing the importance of CLIP representations for evaluating semantic consistency.

### Strengths and Weaknesses
Strengths:
- The dual-component approach of the Semantics Reconstructor and Perception Reconstructor is a novel contribution that effectively handles both high-level semantics and low-level perceptual details.
- The introduction of ST-SSIM and ST-PSNR metrics provides valuable insights into video reconstruction performance.
- NeuroClips shows superior performance in semantic consistency compared to MinD-Video.
- The voxel-selective paradigm enhances the comprehensiveness of neurobiological perspectives.
- The paper provides a comprehensive overview of existing methods and a thorough explanation of the NeuroClips framework, ensuring reproducibility.
- The validation metrics are clearly divided, enhancing understanding of the framework's performance.
- The introduction of the SR allows for longer video generation, marking a significant advancement in the field.

Weaknesses:
- The multi-fMRI fusion strategy lacks detailed implementation and rationale, which could benefit from clearer exposition.
- The framework does not account for scene changes in videos, potentially hindering its ability to capture rapid transitions.
- Evaluation is limited to a specific dataset with only three patients, which may not represent the diversity of real-world fMRI data.
- The neurobiological justification for keyframe usage is ambiguous, and the paper would benefit from updated references and clearer explanations.
- The reliance on frozen pre-trained classifiers limits the adaptability of the model to new categories.
- The low-n study design raises concerns about the generalizability of the findings.
- Some conclusions regarding neurobiology remain debatable.

### Suggestions for Improvement
We recommend that the authors improve the description of the multi-fMRI fusion strategy by providing more detailed implementation and rationale. Additionally, addressing the limitations regarding scene changes in the video reconstruction is crucial; conducting ablation studies could elucidate how NeuroClips decodes fMRI signals. The authors should mention the limited dataset in the Discussion or Conclusion to acknowledge its impact on generalizability. Clarifying the neurobiological justification for keyframe usage and updating references will enhance the paper's significance. Furthermore, we suggest including the specific impact of hemodynamic delay on reconstruction quality and considering alternative evaluation metrics beyond PSNR and SSIM, such as Visual Information Fidelity metrics. We also recommend improving the clarity of explanations regarding the computational overhead of video generation models and providing more discussions and deeper insights on the trade-off between semantic and perception reconstruction. Lastly, we encourage the authors to ensure that all ethical considerations are clearly articulated in the final version of the paper.