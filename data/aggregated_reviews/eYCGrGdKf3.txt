ID: eYCGrGdKf3
Title: Unleash the Potential of Image Branch for Cross-modal 3D Object Detection
Conference: NeurIPS
Year: 2023
Number of Reviews: 19
Original Ratings: 5, 4, 5, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel cross-model 3D detector, BiProDet, which enhances the representation ability of point clouds by leveraging image domain information through a point-to-pixel bidirectional propagation strategy and introducing normalized local coordinate (NLC) map estimation as an auxiliary training task. The BiProDet achieves significant improvements on the KITTI 3D detection benchmark, particularly for distant or occluded objects, and ranks first for the cyclist class. The authors conduct extensive ablation experiments to validate their approach.

### Strengths and Weaknesses
Strengths:
- The introduction of the NLC map estimation as a 2D auxiliary task effectively enhances the cross-modal detector's performance by providing relative pixel positions.
- The novel point-to-pixel feature propagation mechanism allows 3D geometric features from LiDAR to improve 2D image learning.
- The ablation study is well-designed and extensive, validating the effectiveness of the proposed methods.

Weaknesses:
- The motivation for the proposed point-to-pixel method is weak, as it is primarily a fusion strategy already explored in existing works like BEVFusion.
- The specific 2D auxiliary tasks have been previously examined in TiG-BEV, making the novelty of this aspect limited.
- Comparisons with closely related works, such as EPNet++, and recent BEV representation methods are missing, which could strengthen the paper's claims.

### Suggestions for Improvement
We recommend that the authors improve the motivation section to clearly articulate the unique contributions of the point-to-pixel method beyond existing fusion strategies. Additionally, we suggest including comparisons with related works like EPNet++ and recent BEV-based methods to substantiate the novelty and effectiveness of their approach. Furthermore, conducting experiments on the NuScenes dataset would enhance the robustness of their findings and provide a broader context for their results.