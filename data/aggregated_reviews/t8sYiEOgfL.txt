ID: t8sYiEOgfL
Title: PMG : Personalized Multimodal Response Generation with Large Language Models
Conference: ACM
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a personalized multimodal generation model that learns user preferences by analyzing historical behaviors across various modalities. It generates explicit keywords and implicit embeddings to represent these preferences, utilizing a weighted sum to blend similarities to user preference keywords and target item keywords for response generation. A diffusion model is then employed for image generation.

### Strengths and Weaknesses
Strengths:
1. The paper proposes a novel and intriguing idea for personalized multimodal generation, likely to attract attention from the generative AI and recommendation communities.
2. The algorithm is straightforward and well-explained.
3. Case studies showcasing generated images reveal promising results, potentially serving as a benchmark for future research.

Weaknesses:
1. Experiments are limited to a single image generation task, failing to demonstrate the model's generalizability to other data sources.
2. The absence of case studies focused on generated explicit keywords is a significant oversight.
3. Some experimental setup details are unclear, such as dataset division and the rationale behind specific choices in keyword generation.
4. The algorithm's efficiency is questionable, particularly with a 5-second response time in scenarios like emoticon generation.
5. The approach resembles style transfer rather than generating actual target item images, which may misalign with practical recommendation scenarios.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of the model by conducting experiments across diverse image generation tasks. Additionally, including case studies that focus on generated explicit keywords would enhance the paper's depth. Clarifying the experimental setup, including dataset division and the reasoning behind specific methodological choices, is essential. To address efficiency concerns, the authors should explore optimizing response times. Finally, we suggest providing a comparison with similar techniques to contextualize the approach better and considering human evaluation metrics to assess user satisfaction with personalized versus non-personalized items.