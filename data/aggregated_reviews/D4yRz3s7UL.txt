ID: D4yRz3s7UL
Title: DeSparsify: Adversarial Attack Against Token Sparsification Mechanisms
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 6, 6, 6, 7, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, 4, 2, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DeSparsify, a novel adversarial attack targeting the availability of vision transformers that utilize token sparsification (TS) techniques. The authors demonstrate that TS mechanisms, designed for computational efficiency, introduce a new attack surface that can be exploited to compromise model availability while maintaining classification accuracy. The attack is evaluated on three TS techniques (ATS, AdaViT, and A-ViT) and two vision transformer architectures (DeiT and T2T-ViT) using ImageNet and CIFAR-10 datasets. Various attack variants, including single-image, class-universal, and universal perturbations, are explored, along with their transferability between TS techniques.

### Strengths and Weaknesses
Strengths:
- The paper addresses a previously unexplored vulnerability in token sparsification mechanisms, presenting a novel adversarial attack.
- A comprehensive evaluation is conducted across multiple TS techniques and transformer models, providing robust insights.
- The findings have practical implications for real-world applications, particularly in resource-constrained environments, and the proposed countermeasures add practical value.

Weaknesses:
- The evaluation is limited to vision transformers, neglecting other domains like natural language processing (NLP) and speech recognition, which reduces the broader impact of the findings.
- Proposed countermeasures are not compared with existing adversarial defenses, making it difficult to assess their effectiveness and computational overhead.
- The transferability analysis is restricted to different TS mechanisms within vision transformers, lacking exploration of applicability across diverse architectures and tasks.
- The contribution to the field is minimal due to the narrow focus and limited exploration of broader applicability, with practical feasibility assumptions for the attack being unrealistic.

### Suggestions for Improvement
We recommend that the authors improve the scope of the evaluation by exploring the applicability of DeSparsify to a wider range of models and tasks beyond vision transformers. Additionally, a thorough comparison of the proposed countermeasures with existing adversarial defense mechanisms would enhance the understanding of their effectiveness. The authors should also expand the transferability analysis to include diverse architectures and tasks. Furthermore, simplifying the methodology could improve clarity and practical feasibility. Lastly, including more detailed experimental results or case studies demonstrating the effectiveness of the proposed countermeasures would strengthen the paper.