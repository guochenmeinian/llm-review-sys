ID: sXD4idbnBw
Title: Why Differentially Private Local SGD -- An Analysis of Synchronized-Only Biased Iterate
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 7, 4, 5, 3, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 5, 2, 3, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study of Differentially-Private Local Stochastic Gradient Descent (DP-LSGD) and compares its performance with Differentially-Private Stochastic Gradient Descent (DP-SGD). The authors provide convergence results for FedAvg under bounded variance and gradient assumptions, demonstrating that DP-LSGD converges faster to a neighborhood of stationary points through numerical experiments. The paper claims that DP-LSGD improves upon existing algorithms by achieving a better utility-privacy tradeoff.

### Strengths and Weaknesses
Strengths:  
- Originality: The paper offers a novel analysis of DP-LSGD, considering both clipping and DP-noise, leading to improved convergence rates over FedGD.  
- Significance: DP-LSGD outperforms DP-SGD with faster theoretical convergence to stationary points.  
- Clarity: Theorems and assumptions are clearly stated, with adequate numerical justification provided.

Weaknesses:  
- Assumption 4.1 regarding bounded clipping error may be too strong, potentially undermining the paper's significance.  
- The comparison with FedAvg is deemed unfair since it analyzes local GD updates rather than local SGD updates.  
- The fairness of numerical comparisons is questioned, particularly regarding hyper-parameter choices and their optimality.  
- Theoretical results on the relationship between parameters $c$, $\eta$, and $B$ lack clarity, and the authors should provide numerical justification for different choices.  
- Assumptions 4.1 and 4.2 are seen as restrictive, and the empirical evaluation is limited to specific datasets.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Assumption 4.1 and discuss its implications more thoroughly. Additionally, the authors should provide a more equitable comparison with FedAvg by addressing the differences in update types. It is crucial to report how hyper-parameters are chosen and whether they are optimal for the algorithm. We suggest conducting numerical experiments to explore the relationship between $B$, $c$, and $\eta$ more comprehensively. Finally, the authors should expand their empirical evaluation to include a wider range of datasets to strengthen their claims.