ID: IwMfHn68Hg
Title: Semi-Supervised Anomaly Detection through Denoising-Aware Contrastive Distance Learning
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel framework for semi-supervised anomaly detection (AD) called CAD (Contrastive distance learning). The authors propose a two-stage anomaly denoising and expansion strategy along with a parameterized bilinear tensor distance metric to enhance model performance, addressing challenges in handling unlabeled anomalies and the effectiveness of distance measures in high-dimensional data. Extensive experiments on 10 diverse real-world datasets demonstrate CAD's superiority over state-of-the-art models, particularly in scenarios with noisy data.

### Strengths and Weaknesses
Strengths:
- The introduction of a denoising-aware contrastive distance learning framework is a significant contribution, effectively combining supervised and unsupervised learning to address data contamination issues.
- Comprehensive experiments across 10 datasets show significant improvements in detection accuracy, especially in highly imbalanced scenarios.
- The inclusion of ablation studies provides valuable insights into the contributions of each component of the CAD framework, enhancing credibility.
- The relevance of anomaly detection across various fields, such as healthcare and finance, underscores the method's impact.

Weaknesses:
- The paper lacks discussion on the training efficiency of the proposed methodology compared to baselines.
- The model's performance is sensitive to hyperparameters like the anomaly threshold factor $\alpha$ and loss weight $\lambda$, necessitating extensive tuning.
- The denoising strategy assumes specific noise levels in unlabeled data, which may not generalize well to datasets with unknown contamination rates, potentially leading to limited benefits in low contamination cases.
- There is limited theoretical justification for the choice of hyperparameters, with a need for more discussion on their impact across different datasets.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the training efficiency of CAD compared to baseline methods. Additionally, consider providing insights into the theoretical motivation behind the specific values chosen for $\alpha$ and $\lambda$, and whether these were guided by empirical optimization or theoretical insights. For datasets with low contamination, we suggest adapting CAD to enhance performance in cleaner datasets. Furthermore, we encourage the authors to explore the computational efficiency and approximate training times observed in their experiments, and to consider practical adjustments for real-time anomaly detection. Lastly, integrating an adaptive mechanism for handling variable contamination levels in the denoising strategy would enhance robustness.