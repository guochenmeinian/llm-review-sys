ID: tYCLmx9RgE
Title: On the Limitation of Backdoor Detection Methods
Conference: NeurIPS
Year: 2023
Number of Reviews: 2
Original Ratings: 7, 1
Original Confidences: 3, 2

Aggregated Review:
### Key Points
This paper presents a significant exploration of backdoor attacks in machine learning, addressing a critical issue as AI and machine learning models gain traction across various domains. The authors propose a no-free-lunch theorem, asserting that universal backdoor detection is impossible except for very small alphabet sizes. The paper includes a comprehensive literature review, demonstrating a strong grasp of prior research in the field, and highlights the implications of the findings for both attackers and defenders in machine learning security.

### Strengths and Weaknesses
Strengths:  
- The paper tackles an important and timely topic in machine learning security.  
- It provides a thorough literature review, indicating a deep understanding of existing work.  
- The findings have meaningful implications for the security landscape of machine learning.

Weaknesses:  
- The theoretical focus lacks evaluation in real-world defense scenarios, which could enhance the paper's soundness.  
- The notation "TV" is not defined, making it difficult for some reviewers to fully engage with the content.  
- The dependence on the definition of $P_b$ raises concerns, as the paper does not adequately address conditions under which a backdoor attack is meaningful.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their notation, particularly by formally defining "TV" to aid understanding. Additionally, we suggest that the authors address the critical issues surrounding the distribution of $P_b$ and its relationship to $P_0$, providing conditions under which a backdoor attack is valid. This would strengthen the theoretical claims made in the paper and enhance its overall impact.