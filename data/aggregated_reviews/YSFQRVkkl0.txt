ID: YSFQRVkkl0
Title: Implicit Regularization in Over-Parameterized Support Vector Machine
Conference: NeurIPS
Year: 2023
Number of Reviews: 20
Original Ratings: 5, 6, 6, 8, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 2, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a regularization-free algorithm for high-dimensional support vector machines (SVMs) by integrating over-parameterization with Nesterov's smoothing method, which induces implicit regularization. The authors propose an over-parameterized hinge loss function and estimate true parameters using regularization-free gradient descent. The method's computational efficiency is enhanced by Nesterov's approach, particularly regarding the stopping criterion and complexity reduction. Theoretical findings are supported by numerical experiments, demonstrating the advantages of implicit regularization in sparse SVMs compared to explicit \( l_1 \) regularization. Additionally, the authors explore implicit regularization in SVMs through a specific empirical loss function, although clarity issues arise regarding the constraints and definitions used. The definition of \( \beta^* \) does not align with experimental results, raising questions about its validity as a minimizer of the population hinge loss. The authors acknowledge the need for a sensitivity analysis regarding the parameter \( \gamma \) and plan to include additional numerical results in the revision.

### Strengths and Weaknesses
Strengths:
- The manuscript presents an interesting finding regarding over-parameterized SVMs, showing that re-parameterizing the sparse unknown parameter \( \beta \) leads to implicit regularization effects.
- The theoretical analysis is clear and easy to follow.
- The theoretical results are validated through comprehensive numerical simulations.
- The authors demonstrate a commitment to addressing reviewer feedback and improving the clarity of their paper.
- They plan to include a sensitivity analysis for \( \gamma \), which is crucial for understanding the robustness of their method.

Weaknesses:
- The proposed algorithm is not directly designed for the original model but rather a modified version, raising concerns about potential explicit regularization effects.
- Assumption 1 is relatively strict, requiring the design matrix to satisfy \( \delta \)-incoherence and sub-Gaussianity, which may not hold for real datasets.
- The empirical effectiveness of the proposed algorithm is insufficiently discussed, and the importance of sparsity in SVM is not adequately addressed.
- The paper contains several unclear expressions and missing constraints that hinder comprehension, particularly regarding the minimization of \( \mathcal{E}(a, b) \).
- The absence of submitted code prevents reproducibility of numerical experiments, which is a significant concern.
- There are numerous typographical errors and inconsistencies in notation that suggest a rushed writing process.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the potential explicit regularization effects introduced by the update of \( \mu \) in Algorithm 1. Additionally, it would be beneficial to discuss whether Assumption 1 holds for real data, as well as to provide a more thorough examination of the empirical effectiveness of the proposed algorithm. Furthermore, we suggest including a comparison of the strength of the \( \delta \)-incoherence assumption with the RIP assumption and clarifying the significance of sparsity in SVMs in the context of classification performance. We also recommend that the authors improve the clarity of the minimization process by explicitly including the constraint \( a \odot c = \beta \) in the relevant sections. The definition of \( T^* \) should be clearly stated with precise values rather than asymptotic notations. We suggest proofreading the manuscript thoroughly to correct typographical errors and enhance overall readability. Lastly, the authors should include the code for reproducing numerical experiments to facilitate validation of their results, and highlighting the sensitivity of the method with respect to \( \gamma \) is essential for the paper's acceptance.