ID: m0vfXMrLwF
Title: Learn to Categorize or Categorize to Learn? Self-Coding for Generalized Category Discovery
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 5, 7, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel perspective on categorization, framing it as an optimization problem to find optimal solutions. The authors propose a self-supervised method capable of discovering new categories at test time by assigning concise category codes to data instances, effectively capturing the hierarchical structure in real-world datasets. The method aims to improve category representation in deep learning models and demonstrates effectiveness across multiple datasets.

### Strengths and Weaknesses
Strengths:
1. The paper introduces a unique conceptualization of categories as solutions to optimization problems.
2. It is well-structured and easy to follow, with a reasonable experimental design.
3. The proposed method is novel and shows effectiveness in fine-grained recognition tasks.

Weaknesses:
1. The method's complexity, characterized by five hyperparameters in the loss functions, complicates tuning; an automated tuning approach may be beneficial.
2. The absence of ablation studies limits understanding of individual hyperparameters' impacts on performance.
3. Comparisons with recent state-of-the-art methods are lacking, which could provide a more comprehensive evaluation.

### Suggestions for Improvement
We recommend that the authors improve the empirical validation of their method's generalizability across various scenarios, particularly on the ImageNet-100 dataset. Additionally, we suggest simplifying the model's hyperparameter tuning process, possibly through automation. Incorporating ablation studies to analyze the effects of each hyperparameter on performance would enhance the understanding of the model's dynamics. Finally, we encourage the authors to include comparisons with recent methods such as PromptCAL, Modeling Inter-Class and Intra-Class Constraints, Generalized Category Discovery with Decoupled Prototypical Network, and Supervised Knowledge May Hurt Novel Class Discovery to strengthen their evaluation.