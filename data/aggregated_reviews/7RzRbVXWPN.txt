ID: 7RzRbVXWPN
Title: AfriSenti: A Twitter Sentiment  Analysis Benchmark for African Languages
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new Twitter benchmark for sentiment analysis across 14 African languages, detailing the dataset creation and challenges in data collection and annotation. The authors provide experimental results with baseline models, discussing the performance of pre-trained language models and their effectiveness in zero-shot learning for specific languages.

### Strengths and Weaknesses
Strengths:
- The dataset is a valuable resource for sentiment analysis in African languages, contributing significantly to the NLP community.
- Detailed descriptions of data collection challenges enhance understanding for researchers working with low-resource languages.
- The release of full annotations alongside majority-vote labels supports methodologies and inter-annotator agreement studies.

Weaknesses:
- Limited explanation of imbalanced data distribution, particularly the absence of training samples for 'orm' and 'tir' languages.
- Insufficient detail on experimental results; only F1 scores are reported without per-label precision and recall.
- Lack of innovation in implementation for NLP development.

### Suggestions for Improvement
We recommend that the authors improve the explanation of the imbalanced data distribution in Table 6, specifically addressing the absence of training samples for 'orm' and 'tir' languages. Additionally, we suggest providing more detailed experimental results, including per-label precision and recall in Table 8. It would be beneficial to include explicit sentiment categories in the text, as well as detailed information on model fine-tuning, including tuning parameters and system architecture. Addressing the reasons for testing the cross-lingual system only on 'orm' and 'tir' languages, and providing statistics on code-switching and code-mixing would enhance the paper. Finally, clarifying the availability of trained models for researchers would be advantageous.