ID: kQPzFiwVIu
Title: Synthetic Programming Elicitation for Text-to-Code in Very Low-Resource Programming and Formal Languages
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 7, 4, 5, 8, -1, -1, -1
Original Confidences: 4, 4, 2, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach called Synthetic Programming Elicitation and Compilation (SPEAC) to enable large language models (LLMs) to generate syntactically valid code for very low-resource programming languages (VLPLs). The authors propose creating a hallucinated library within a high-resource language that can be compiled into the VLPL, demonstrating that SPEAC outperforms existing methods in producing syntactically correct programs. Empirical results indicate that SPEAC achieves full syntactic correctness on 78% of benchmarks, significantly improving upon traditional methods.

### Strengths and Weaknesses
Strengths:
- The paper addresses a novel problem of generating code for VLPLs, an area that is relatively unexplored.
- The empirical evaluation demonstrates the effectiveness of SPEAC compared to other baselines, showing impressive results.
- The framework integrates LLM program generation with formal methods for checking program correctness, which is both innovative and effective.

Weaknesses:
- The paper lacks important details regarding the computation of the semantic score, including whether it is computed automatically or manually.
- It fails to consider existing code generation approaches that leverage self-repair or self-debugging capabilities.
- The evaluation is limited to a single case study on UCLID5, which restricts the generalizability of the findings.
- The organization of the paper is poor, with a disorganized presentation in Section 2 and the experimental results appearing too late in the text.

### Suggestions for Improvement
We recommend that the authors improve the clarity and organization of the paper, particularly in Section 2, by focusing on LLMs for code generation rather than benchmarks. Additionally, the authors should present the experimental setup, results, and analysis more prominently and earlier in the paper. It would be beneficial to include more diverse experiments, particularly comparing SPEAC with other methods such as iterative fixing of unparsable code and many-shot prompting techniques. Furthermore, the authors should provide more details on the computation of the semantic score and consider broader validation across multiple VLPLs to enhance the generalizability of their findings.