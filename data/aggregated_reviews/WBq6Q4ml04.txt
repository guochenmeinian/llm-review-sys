ID: WBq6Q4ml04
Title: Top-Ambiguity Samples Matter: Understanding Why Deep Ensemble Works in Selective Classification
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 4, 4, 8, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates the performance of ensemble models compared to member models, demonstrating that ensemble methods can achieve lower selective risk under certain conditions. The authors categorize data into high-ambiguity and low-ambiguity samples, revealing that ensembling high-ambiguity samples improves selective risk, while low-ambiguity samples yield results similar to member models. The authors provide theoretical proofs and empirical evidence to support their claims.

### Strengths and Weaknesses
Strengths:
1. The paper offers a theoretical understanding of ensemble models, potentially enlightening future algorithm design.
2. The assumptions made are more realistic compared to other theoretical frameworks.
3. Extensive empirical experiments enhance the paper's readability and elucidate motivations and assumptions.

Weaknesses:
1. The proof does not convincingly demonstrate the ensemble model's behavior, as it relies heavily on the limit $\lim_{t\to 1^-}$, which does not align with experimental results.
2. Section 4 lacks clarity, particularly regarding the ambiguity measurements and the definitions of terms such as "correlated predictive probability distributions" and "definite samples."
3. The experimental validation is insufficient, relying on a single backbone and ensemble for each task, which does not convincingly verify assumptions.
4. The discussion around Figure 2 is difficult to digest, and the relationship of Figures 5 and Table 1 to the overall analysis is unclear.

### Suggestions for Improvement
We recommend that the authors improve clarity in Section 4 by defining key terms and explaining the ambiguity measurements more thoroughly. Additionally, conducting more experiments across diverse datasets and architectures would strengthen the validation of assumptions 1, 2, and 3. We also suggest providing a version of Figure 2 with real data to justify assumptions and unifying the color scheme between Figures 2 and 4 for better comprehension. Finally, addressing the relationship between the results in Figure 5 and the theoretical claims would enhance the paper's coherence.