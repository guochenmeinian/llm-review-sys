ID: ZGMkOikEyv
Title: DetectRL: Benchmarking LLM-Generated Text Detection in Real-World Scenarios
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 6, 5, 8, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DetectEval, a benchmark aimed at evaluating the limitations of current state-of-the-art LLM-generated text detection methods. The authors collected a dataset comprising texts from various domains, including human-written and LLM-generated content, and systematically benchmarked the robustness of zero-shot and supervised detectors. The experimental results indicate that existing detectors struggle in complex real-world scenarios.

### Strengths and Weaknesses
Strengths:
- The paper addresses a timely topic and contributes a new evaluation set for LLM-generated content.
- The dataset is extensive and covers multiple domains and language models.
- The tasks considered are moderately challenging, including various detection scenarios.

Weaknesses:
- The main claim regarding the benchmark's applicability to real-world scenarios is questionable, particularly concerning the focus on adversarial attacks.
- The presentation of results is hindered by readability issues in tables and figures.
- The paper lacks inclusion of recent state-of-the-art detectors and clarity on how LLM-generated texts were constructed.

### Suggestions for Improvement
We recommend that the authors improve the motivation and main claims of the paper, particularly regarding the relevance of adversarial attacks to real-world scenarios. Additionally, the authors should include more recent state-of-the-art approaches in their benchmarks and enhance the presentation of results for better readability. Clarifying the dataset generation process and providing more detailed information on the supervised techniques at the start of section 3 would also strengthen the paper. Finally, revising Table 6 for better visualization and ensuring that the best performance is reported in Tables 2 and 3 would improve clarity.