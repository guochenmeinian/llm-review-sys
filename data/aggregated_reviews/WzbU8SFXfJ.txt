ID: WzbU8SFXfJ
Title: Personalized Image Generation with Large Multimodal Models
Conference: ACM
Year: 2024
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Pigeon, a novel framework for personalized image generation that leverages large multimodal models (LMMs). The authors address a significant gap in recommender systems by proposing personalized content generation, particularly for images, as an underexplored direction. The framework introduces a two-stage preference alignment scheme to handle data scarcity and incorporates masked preference reconstruction and pairwise preference alignment. Empirical evaluations demonstrate Pigeon’s superiority in generating personalized stickers and movie posters, showcasing strong quantitative and qualitative results.

### Strengths and Weaknesses
Strengths:
- The introduction of innovative modules for noise handling, preference extraction, and multimodal integration enhances personalized image generation.
- Comprehensive quantitative and human evaluations provide clear metrics and baselines, demonstrating the framework's robustness.
- The work highlights practical implications and economic value, particularly in e-commerce and advertising.

Weaknesses:
- The computational overhead of Pigeon’s modules and the two-stage alignment process is not thoroughly discussed, limiting real-world feasibility understanding.
- The focus on stickers and movie posters may restrict the framework's generalizability; broader datasets could strengthen claims.
- The model does not account for dynamic user preference evolution, potentially impacting long-term performance.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation behind the proposed framework and its differentiation from ordinary recommendation systems. Additionally, a clearer discussion on computational efficiency and the potential overhead from multi-stage optimization is necessary. The authors should also explore the generalization of the method to unseen images and evolving user preferences, and provide more details on the human evaluation study, including participant numbers and scenarios. Finally, elaborating on how the model ensures consistent semantic alignment with diverse datasets would enhance the paper's rigor.