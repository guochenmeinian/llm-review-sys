ID: LLETO26Ga2
Title: Disentanglement via Latent Quantization
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 5, 7, 5, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 5, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for learning disentangled representations through latent quantization, specifically the QLAE model, which utilizes discrete representation learning techniques for unsupervised disentanglement. The authors focus on constructing a quantized latent space that aligns with the compositional nature of data, distinguishing their approach from VQ-VAE by emphasizing the functional relationships of learned representations to data sources. They introduce a new evaluation metric, InfoMEC, which assesses modularity, explicitness, and compactness in the learned representations. The authors claim that their method outperforms existing benchmarks in terms of modularity while remaining competitive in compactness across several datasets. They acknowledge that individual latent traversals may not fully capture the effects of varying camera height, but their visualizations demonstrate changes in camera height with latent interventions. The authors assert that using learned codebook values for interventions yields fewer low-quality generations compared to linear interpolation and plan to revise the manuscript to include joint visualizations of all latents encoding a source.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, with clear definitions of mathematical notations and a solid theoretical motivation based on ICA literature.
- The introduction of the InfoMEC metric addresses significant shortcomings in existing evaluation methods for disentangled representations.
- The experimental results demonstrate improvements in modularity and explicitness, indicating the effectiveness of the proposed approach.
- The authors provide a comprehensive rebuttal addressing reviewer concerns.
- The proposed method shows improved disentanglement properties compared to VQ-VAE, supported by empirical results.
- The use of learned codebook values for interventions enhances the quality of visualizations.

Weaknesses:
- The manuscript lacks clarity in some parts, with confusing notations and insufficient discussion of the proposed method's limitations.
- The proposed method closely resembles VQ-VAE, raising questions about its novelty.
- The assumption that real-world data is generated in a compositional manner is not convincingly supported.
- The evaluation of the proposed method relies solely on the InfoMEC metric, with no comparisons to other established metrics, limiting the robustness of the findings.
- Some reviewers remain uncertain about the individual contribution of the disentanglement method and its evaluation score.
- Concerns persist regarding the novelty of the approach, given its reliance on existing techniques.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the manuscript by refining confusing notations and providing a more thorough discussion of the limitations of their approach, particularly regarding the need to define the size of the quantization. Additionally, we suggest including comparisons with existing disentanglement metrics beyond InfoMEC to validate the effectiveness of their method. It would also be beneficial to clarify the relationship between compositionality and their quantized representation, ensuring that claims are well-supported by empirical evidence. Furthermore, we recommend that the authors improve clarity on the unique contributions of their disentanglement method compared to VQ-VAE, particularly in terms of evaluation metrics and qualitative properties. Providing further empirical evidence to substantiate the effectiveness of their approach in disentangling representations would enhance the manuscript's impact. Lastly, we encourage the authors to visualize the latent space of their model and provide traversal reconstructions for all datasets tested to enhance the interpretability of their results.