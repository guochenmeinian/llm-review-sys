ID: xymhWyiZOp
Title: On the Use of Anchoring for Training Vision Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 7, 7, 8, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a critical analysis of anchored training, revealing that increasing the reference set size does not enhance performance, a limitation not mitigated by existing inference strategies. The authors propose a reference-masking regularization technique to address this issue, demonstrating its effectiveness across various datasets and models, including CIFAR-10, CIFAR-100, and ImageNet. The study also explores the interaction of the proposed method with data augmentation and noisy labels, providing a comprehensive evaluation of its impact on out-of-distribution generalization, calibration, and anomaly rejection.

### Strengths and Weaknesses
Strengths:
1. The paper is well-structured and clearly written, making complex concepts accessible.
2. It identifies a significant limitation in current anchoring techniques and proposes a straightforward solution that consistently improves performance.
3. Extensive experiments validate the proposed method across different architectures and datasets, showcasing its robustness.

Weaknesses:
1. The reference set selection strategy and sizes used in experiments are not adequately explained.
2. The impact and novelty are somewhat limited due to a lack of comparisons with non-anchored training methods.
3. Minor issues include unclear performance decrease indicators in tables and the need for error bars in figures.

### Suggestions for Improvement
We recommend that the authors improve the explanation of the reference set selection strategy and sizes used in their experiments to enhance clarity. Additionally, including comparisons with state-of-the-art OOD/uncertainty methods would strengthen the impact of the findings. It would also be beneficial to explore the applicability of the proposed method in other domains beyond vision, such as text or graph data. Lastly, addressing minor formatting issues and providing a clearer definition of abbreviations would enhance the overall presentation.