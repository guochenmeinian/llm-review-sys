ID: MjD9Y05Q6i
Title: LG-CAV: Train Any Concept Activation Vector with Language Guidance
Conference: NeurIPS
Year: 2024
Number of Reviews: 4
Original Ratings: 6, 7, 5, -1
Original Confidences: 4, 5, 3, -1

Aggregated Review:
### Key Points
This paper presents the LG-CAV model, which trains Concept Activation Vectors (CAVs) without labeled data by leveraging pre-trained vision-language models like CLIP. The authors propose several techniques to enhance CAV quality, including Gaussian Alignment (GA), Concept Ensemble (CE), and Deviation Sample Reweighting (DSR), along with an Activation Sample Reweighting (ASR) method for model correction. Experiments demonstrate that LG-CAV achieves superior performance in concept accuracy and concept-to-class accuracy compared to existing methods across various datasets and architectures.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and presents a clear methodology.
2. The use of vision-language models allows for effective training of CAVs without labeled data.
3. The introduction of GA, CE, and DSR modules significantly enhances LG-CAV quality.
4. The method is applied to model correction, improving target model performance.
5. The experimental results indicate substantial improvements in both concept accuracy and concept-to-class accuracy.

Weaknesses:
1. The framework's ability to handle unseen classes in a generalized setting remains unclear, particularly regarding novel category detection.
2. The selection of the similarity threshold for concept relevance is not well-explained.
3. The evaluation of concept-to-class accuracy requires human assessment, but the methodology for this evaluation lacks detail.
4. The improvements over baseline methods appear limited, and some proposed modules seem heuristic without sufficient theoretical justification.
5. The reliance on pre-trained models like CLIP raises concerns about generalizability and accessibility for various tasks.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the framework's capability to address unseen classes, particularly in novel category detection scenarios. Additionally, the authors should provide a more detailed explanation of how the similarity threshold is determined for concept relevance. It is also essential to elaborate on the human evaluation process for concept-to-class accuracy. Furthermore, we suggest that the authors justify the heuristic nature of certain modules theoretically and discuss the generalizability of LG-CAV beyond the specific pre-trained models used. Lastly, a more thorough analysis of the computational costs and training times compared to traditional CAV methods would enhance the paper's completeness.