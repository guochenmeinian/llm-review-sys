ID: 46jtDC6gXu
Title: AsyncDiff: Parallelizing Diffusion Models by Asynchronous Denoising
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 7, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents AsyncDiff, an acceleration framework for diffusion models that transforms the traditional sequential denoising process into an asynchronous one. The authors propose that the high similarity of hidden state features in consecutive sampling steps allows for the output of the preceding component at time step t-1 to serve as an approximation for each U-Net component, enabling fully asynchronous parallel denoising. Experiments demonstrate that AsyncDiff significantly accelerates the denoising process for text-to-image generation and is applicable to video generation models like AnimateDiff and SVD.

### Strengths and Weaknesses
Strengths:
1. The writing is clear and well-structured, effectively explaining the limitations of previous methods and introducing a novel asynchronous denoising approach.
2. Thorough comparisons with baseline methods, such as Distrifusion, show clear improvements in generation quality and efficiency.
3. The versatility of AsyncDiff is evidenced by experiments on various versions of Stable Diffusion and video generation models.
4. The authors address communication cost concerns, demonstrating they are significantly lower than model execution time.

Weaknesses:
1. The analysis of the similarity of hidden states lacks detail, including whether this similarity can be quantitatively measured and if it is specific to the U-Net architecture or applicable to other models like Diffusion Transformers.
2. A comparison with the original model using a number of DDIM steps that achieve a similar speedup would strengthen the argument for AsyncDiff.
3. Some concepts, such as the “dependency chain” in ABS, are not well explained, and a discussion of the differences between AsyncDiff and Distrifusion is insufficient.
4. Questions remain about the method's scalability with more GPUs and its effectiveness on low-end devices.

### Suggestions for Improvement
We recommend that the authors improve the analysis of hidden state similarities by providing quantitative measurements and clarifying whether this phenomenon is specific to U-Net or applicable to other architectures. Additionally, including a comparison with the original model using a number of DDIM steps that achieve a similar speedup would enhance the argument for AsyncDiff. We also suggest providing clearer explanations for concepts like the “dependency chain” and a more detailed discussion of the differences between AsyncDiff and Distrifusion. Finally, addressing the scalability of AsyncDiff with more GPUs and its performance on low-end devices would strengthen the paper.