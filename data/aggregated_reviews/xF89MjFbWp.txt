ID: xF89MjFbWp
Title: Kullback-Leibler Maillard Sampling for Multi-armed Bandits with Bounded Rewards
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 6, 5, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis of the KL-Maillard Sampling (KL-MS) algorithm, a bandit algorithm derived from the MED algorithm by Honda & Takemura (2011) for Bernoulli distributions, extended to general bounded distributions. The authors propose a sampling strategy based on KL divergence that allows for explicit computation of arm selection probabilities, beneficial for off-policy evaluation. They provide both optimal instance-dependent and minimax bounds for the algorithm, demonstrating that the worst-case guarantees scale with the standard deviation of the best arm. The paper also highlights a refined analysis of the "under-exploration" term in regret analysis, leading to a significant improvement in the minimax ratio.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, clear, and technically sound, with detailed proofs and a comprehensive literature review.
- The simplification of the asymptotic optimality analysis for Bernoulli distributions compared to the original MED algorithm is noteworthy, and the novel worst-case optimality result adds value.
- The refined analysis of the "under-exploration" term provides a substantial contribution, improving the minimax ratio without altering the algorithm.

Weaknesses:
- The rebranding of MED as KL-MS is questionable, as the algorithm closely resembles the original MED for Bernoulli distributions, raising concerns about the necessity of this change.
- The analysis appears to differ from the original work mainly in the treatment of term (F3), which, while interesting, may not represent a significant theoretical advancement.
- The paper lacks clarity in certain experimental comparisons, particularly regarding the regret performances of KL-MS versus other algorithms.

### Suggestions for Improvement
We recommend that the authors improve the justification for rebranding MED as KL-MS, clarifying the distinctions and motivations behind this choice. Additionally, we suggest that the authors better highlight the novel contributions of their analysis, particularly the treatment of term (F3), to emphasize its significance. It would also be beneficial to include a more comprehensive comparison of regret performances in the experimental section, addressing the concerns raised about the clarity of the results. Finally, we encourage the authors to provide clearer visual representations in the appendix to enhance the readability of the figures.