ID: bHgkT0sUy6
Title: Discovering Creative Behaviors through DUPLEX: Diverse Universal Features for Policy Exploration
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 5, 6, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DUPLEX, an algorithm designed to learn diverse yet high-performance policies for context Markov decision processes, particularly in hyper-realistic racing simulators. The authors argue that previous state-of-the-art methods in reinforcement learning (RL) lacked perceptible diversity while maintaining competitive behavior. DUPLEX builds upon the state-of-the-art DOMiNO by incorporating context into the MDP and extending the diversity objective to be context-conditioned. It introduces three techniques to stabilize training: a dynamic scaling parameter to balance extrinsic and intrinsic rewards, a lower bound to promote high-performance policies, and a SAC-inspired entropy term for stabilizing successor feature estimation. Experimental results demonstrate that DUPLEX effectively learns diverse and high-performing policies in both the complex GranTurismo environment and standard MuJoCo domains with out-of-distribution (OOD) physics. The research showcases visibly diverse driving styles and demonstrates near-optimal performance by combining diversity and multitask generalization, which has practical applications for the Gran Turismo player community, enhancing user engagement through diverse opponents. The authors clarify the role of entropy in their algorithm, emphasizing its importance in minimizing critics' biases.

### Strengths and Weaknesses
Strengths:  
1. The authors effectively motivate the need for diverse high-performance policies, highlighting its significance in research and practical applications.  
2. The paper introduces several novel algorithmic strategies for stabilizing diversity-seeking policy training, including balancing rewards and implementing a lower bound for near-optimality.  
3. Impressive results are achieved in complex tasks like GranTurismo, along with comprehensive ablation studies that enhance reproducibility and demonstrate the algorithm's superiority.  
4. The algorithm shows robust performance in OOD tasks, providing practical applications for gaming and self-play in RL.  
5. The authors effectively combine insights from different research areas, showcasing visibly diverse driving strategies.

Weaknesses:  
1. The clarity of the paper requires improvement, particularly regarding the logical connection between diversity in multi-context settings and human-level task execution.  
1.1. The claim of finding diverse policies maximizing expected return in every context lacks enforcement and clarity.  
1.2. The discussion on universal estimators appears disconnected from the main objectives of the paper.  
1.3. Section 4 is challenging to follow; a preview or diagram could enhance understanding of the algorithm's components.  
1.4. The design of Equation 5 needs stronger justification, and alternative designs should be explored.  
1.5. The rationale for using an entropy term in stabilizing successor feature estimation is weak, as it does not clearly relate to the instability caused by Q-learning.  
2. The selection process for features, termed "cumulants," is not discussed, raising concerns about reproducibility and the algorithm's dependence on sophisticated feature choices.  
3. The writing quality of the paper requires improvement for better clarity.  
4. The motivation behind the design of the heuristic lambda is not sufficiently explained, which may hinder reader understanding.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by explicitly linking the importance of diversity in multi-context settings to human-level task execution. Additionally, we suggest enforcing the claim regarding diverse policies maximizing expected returns in every context and clarifying the role of universal estimators in the context of finding diverse policies. To enhance Section 4, consider providing a preview or diagram to illustrate the connections between algorithm components. We also urge the authors to justify the design of Equation 5 more robustly and explore simpler alternatives. Strengthening the motivation for the entropy term in successor feature estimation is essential, as its current justification appears tenuous. Furthermore, we recommend improving the writing quality for better coherence and clarity. We suggest including a detailed explanation of the motivation behind the design of the heuristic lambda in the next version of the paper. Finally, we strongly recommend providing detailed information on the selection of features and conducting ablation studies to assess the impact of different feature choices on the algorithm's performance.