ID: AO5MjDuHpr
Title: Tree of Attributes Prompt Learning for Vision-Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 21
Original Ratings: 6, 4, 8, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Tree of Attributes Prompt learning (TAP), which utilizes structured knowledge graphs generated by large language models (LLMs) to enhance prompt learning. The authors propose a hierarchical "concept-attribute-description" structure to improve the performance of vision-language models (VLMs) in zero-shot and few-shot classification tasks. The method incorporates specialized "domain expert" prompt tokens and a vision-conditional pooling module to extract instance-specific text features. Experimental results indicate that TAP outperforms existing methods, including TaskRes, by an average of 2.6% across multiple datasets. The authors conducted robustness experiments with Qwen2-7B-Instruct, demonstrating maintained performance levels without manual editing during the human review stage. They clarify their approach to determining learning rates for vision and text encoders, adjusting them based on the number of attributes in the datasets.

### Strengths and Weaknesses
Strengths:
- The approach of distilling structured knowledge from LLMs for prompt learning is novel and compelling.
- The design effectively captures fine-grained attributes using vision expert tokens and a vision-conditional pooling layer.
- The hierarchical structure of attribute generation can be applied to other tasks, and the experimental results demonstrate improved performance over unstructured descriptions.
- The model demonstrates strong performance in generating descriptions without the need for manual editing.
- TAP consistently outperforms TaskRes across various datasets, indicating its effectiveness.
- The authors provide a clear rationale for their learning rate adjustments based on dataset characteristics.

Weaknesses:
- The method's effectiveness is heavily dependent on the quality of the tree of attributes generated by GPT-3.5-turbo, with no analysis on robustness across different LLMs or prompts.
- The loss function includes model regularization, but its effectiveness is not discussed.
- The clarity of certain figures and equations, such as Figure 2 and Equation (5), is lacking, and some terms require further explanation.
- The initial omission of TaskRes as a baseline may have led to confusion regarding comparative performance.
- The explanation of learning rate determination could have been clearer in the original submission.

### Suggestions for Improvement
We recommend that the authors improve the robustness analysis of the tree of attributes by testing against various LLMs and generation prompts. Additionally, the authors should clarify the effectiveness of the model regularization in the loss function. It would be beneficial to enhance the clarity of Figure 2 and provide detailed explanations for terms in Equation (5). Furthermore, addressing the questions regarding the differences between pooling methods and the adaptive number of attributes would strengthen the paper. Lastly, we suggest improving clarity regarding the inclusion of baselines in future submissions to avoid confusion and providing a more detailed explanation of the learning rate determination process to enhance understanding of the methodology. Incorporating reliable knowledge sources could also mitigate potential hallucination issues in attribute generation.