ID: MCj7DLkYqS
Title: Adversarial Attacks on Online Learning to Rank with Click Feedback
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 6, 5, 5, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study of reward poisoning attacks on UCB bandit algorithms with binary feedback, applying the designed attack to the online-learning-to-rank (OLTR) problem. The authors propose an attack algorithm that maintains binary rewards while targeting the PBM-UCB and CascadeUCB algorithms under two threat models. The paper also introduces a general attack strategy for arbitrary click models, achieving O(log T) sub-optimal item selections with O(log T) attack cost. Empirical evaluations support the effectiveness of the proposed attacks.

### Strengths and Weaknesses
Strengths:
1. The paper addresses a timely topic by studying data poisoning attacks on ranking algorithms, highlighting unique challenges compared to multi-armed bandits.
2. The theoretical analysis is robust, demonstrating that UCB-style ranking algorithms are vulnerable to poisoning attacks in both position-click and cascade-click scenarios.
3. Extensive empirical evaluations provide convincing results for the proposed attack strategies.

Weaknesses:
1. The critical assumption in Section 4.3 regarding O(log T) sub-optimal item selections is not clearly defined and is hidden within Theorem 4.
2. Theorem 4 lacks intrigue and specificity, as it relies on the O(log T) assumption, which may be too restrictive. A broader assumption of no-regret ranking algorithms could be more appropriate.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the assumption in Theorem 4 by making it more prominent and explicitly defining it. Additionally, we suggest exploring whether the O(log T) sub-optimal item selections are critical or if the results can be extended to arbitrary no-regret ranking algorithms that guarantee o(T) suboptimal item selections. Furthermore, we encourage the authors to provide a more intuitive explanation of the attack methods, particularly regarding the necessity of the sophisticated probability calculations compared to simpler approaches.