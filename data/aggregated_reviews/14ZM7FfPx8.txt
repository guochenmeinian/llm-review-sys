ID: 14ZM7FfPx8
Title: Towards Understanding the Dynamics of Gaussian-Stein Variational Gradient Descent
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 7, 5, 6, 3, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a theoretical investigation of Gaussian-Stein Variational Gradient Descent (Gaussian-SVGD) for Gaussian Variational Inference (GVI), analyzing its dynamics and providing convergence rates for both mean-field and finite-particle settings. The authors propose two algorithmic frameworks for density-based and particle-based implementations of Gaussian-SVGD, demonstrating its convergence to the best Gaussian approximation in KL-divergence for non-Gaussian targets. Additionally, the paper introduces the first deterministic particle-based algorithm for GVI, addressing practical issues in the field and providing theoretical results for Gaussian targets along with empirical evidence of superior performance. The authors argue against criticisms regarding the practicality of bilinear kernels and emphasize the significance of their uniform-in-time propagation of chaos result. They also compare Gaussian-SVGD with other algorithms on examples like Gaussian targets and Bayesian logistic regression, while outlining future research directions.

### Strengths and Weaknesses
Strengths:  
- The paper is well-written, with clear mathematical articulation and a well-structured presentation.  
- The authors effectively relate their work to existing literature, highlighting significant contributions, particularly new convergence rates and a novel deterministic particle-based algorithm.  
- The balance between theoretical results and practical algorithm usability makes the work relevant to the ML community.  
- The authors provide appealing theoretical results and empirical evidence supporting their claims, presenting a general framework that unifies previous algorithms using bilinear kernels.  

Weaknesses:  
- The motivation for using Gaussian-SVGD over standard SVGD is insufficiently addressed, particularly for non-Gaussian targets.  
- The introduction of regularized SVGD lacks clear justification.  
- Certain definitions, such as the kernel in Definition 2.2, are not adequately defined, and there are minor errors in equations.  
- The simulation section is weak, with limited models and insufficient detail, suggesting a need for a more comprehensive study.  
- The absence of SVGD in comparative experiments is surprising, and the paper does not adequately discuss the theoretical limitations of the work.  
- The authors admit the lack of a discrete-time finite-particle bound for general targets, and some reviewers question the practicality of their proposed methods and the relevance of their theoretical insights.

### Suggestions for Improvement
We recommend that the authors improve the motivation for Gaussian-SVGD by clearly articulating its advantages over standard SVGD, especially in non-Gaussian contexts. Clarifying the rationale behind introducing regularized SVGD would enhance understanding. Additionally, we suggest defining the kernel $K(\cdot,y)$ in Definition 2.2 and correcting the notation in equation (1) by replacing $\rho$ with $\rho_t$. Expanding the simulation section to include more complex models and detailed parameters would strengthen the empirical validation. Including SVGD in the comparative analysis would provide a more comprehensive evaluation. Furthermore, we encourage the authors to add comparisons to OGD-implemented GVI in practical scenarios, such as with minibatching or on larger-scale datasets. Addressing the concerns regarding the practical implications of bilinear kernels and the significance of their theoretical results more comprehensively would also be beneficial. Finally, a more thorough discussion of the theoretical limitations and practical implications of the results is necessary.