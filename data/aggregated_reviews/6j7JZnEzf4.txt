ID: 6j7JZnEzf4
Title: Language Models with Rationality
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a system called "REFLEX" that enhances language models' interpretability in question-answering tasks by constructing belief graphs. The authors propose a rational layer, separate from the language model, which consists of belief graphs that represent system beliefs and their logical relationships. The implementation and experiments demonstrate that the consistency of the belief network can be significantly improved without sacrificing answer accuracy across three datasets.

### Strengths and Weaknesses
Strengths:
- The belief graph facilitates richer logical relations and context-dependent belief generation, benefiting reasoning tasks.
- The method is clearly described, with thorough quantitative and qualitative analyses, including error analysis and case studies of reasoning successes and failures.
- The system achieves a notable performance increase (~10%) in generating accurate belief graphs compared to baseline models.

Weaknesses:
- The belief graph may not accurately reflect the model's internal rationale, as language models' generated text can diverge from their internal beliefs.
- The choice of datasets for evaluation may hinder comparisons with previous works, raising questions about the portability of the approach to other domains.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their approach by evaluating it on a broader range of datasets beyond those aligned with the base model's training. Additionally, we suggest addressing the potential discrepancies in belief representation by exploring methods to enhance the faithfulness of the belief graphs, such as propagating updated beliefs back to the model during inference or designing pretraining tasks aimed at improving model consistency. Furthermore, clarifying the numerical discrepancies in dataset sizes and providing detailed failure category analyses would strengthen the paper's contributions.