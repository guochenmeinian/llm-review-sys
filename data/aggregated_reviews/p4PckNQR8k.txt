ID: p4PckNQR8k
Title: How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 6, 6, 4, 7, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 3, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into how GPT-2 small computes the "greater than" function by analyzing its circuit. The authors isolate computational units causally related to this function using a method called "path patching," demonstrating that the identified subnetwork is necessary and approximately sufficient for making plausible predictions. The study extends beyond mathematical tasks to adjacent tasks involving "greater than" relations, contributing to the understanding of pre-trained language models (LMs).

### Strengths and Weaknesses
Strengths:
1. Novel approach to understanding LMs through circuit analysis.
2. Extensive experiments and clear presentation of findings.
3. Strong scientific validity with thoughtful consideration of confounders.

Weaknesses:
1. Limited generalizability of findings to larger models and other tasks beyond the "greater than" relationship.
2. The contributions are difficult to distinguish from previous work, and the impact could be enhanced by clarifying the unique contributions and how the analysis framework can be applied to other skills.
3. The task formulation is constrained, as it evaluates GPT-2's ability to perform a two-digit greater-than operation with a given prefix, raising questions about the generalizability of the results.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their contributions by explicitly stating what is novel compared to previous work and providing a detailed explanation of how researchers can apply the proposed analysis framework to investigate other emergent skills of LMs. Additionally, we suggest expanding the scope of tasks studied beyond the "greater than" relationship to strengthen the generalizability of the findings. Improving the presentation by clearly introducing essential information and moving technical details to the appendix would enhance readability. Finally, addressing the limitations regarding the task formulation and providing a control task for smaller numbers would help substantiate claims about the model's capabilities.