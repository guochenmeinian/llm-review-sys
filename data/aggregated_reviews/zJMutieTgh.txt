ID: zJMutieTgh
Title: Inference Attacks Against Face Recognition Model without Classification Layers
Conference: NeurIPS
Year: 2023
Number of Reviews: 21
Original Ratings: 5, 8, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel inference attack algorithm for face recognition models lacking classification layers, consisting of two stages: membership inference and model inversion. The membership inference attack evaluates distances between intermediate features and batch normalization parameters to ascertain if a face image is part of the training dataset. The model inversion stage reconstructs sensitive data using a pre-trained generative adversarial network (GAN) guided by the attack model. The authors demonstrate the effectiveness of their approach in a white-box scenario. Additionally, the paper investigates the effectiveness of membership inference attacks on face recognition models under differential privacy constraints, proposing a method that achieves a higher Attack Success Rate (ASR) compared to a baseline heuristic attack algorithm across various privacy budget settings. The authors provide experimental results showing that their approach maintains effectiveness even with larger privacy budgets while exploring the implications of using Batch Normalization (BN) in black-box attack scenarios.

### Strengths and Weaknesses
Strengths:
1. The paper introduces a novel two-stage attack algorithm for face recognition models without classification layers.
2. The proposed method outperforms state-of-the-art techniques and can recover identities of some training members.
3. The authors provide comprehensive experimental results that validate the effectiveness of their proposed attack method against DP-SGD.
4. The writing is clear, and the techniques are well-explained, with promising experimental results addressing a relevant issue regarding privacy leakage in large-scale face recognition applications.

Weaknesses:
1. The evaluation lacks thorough comparisons with more state-of-the-art techniques to substantiate claims of superiority.
2. The attack success rate in scenarios with lower privacy budgets is significantly reduced, raising concerns about the practical applicability of the method in such contexts.
3. The paper does not provide code implementation, which limits reproducibility.
4. The model performance in experiments is relatively low; higher accuracy models (e.g., ResNet200/VIT-Large on WebFace260M) should be utilized.
5. Claims regarding the novelty of using batch normalization for membership inference are misleading, as this has been explored previously.
6. The reliance on the performance of pre-trained GANs for model inversion attacks may limit the generalizability of the findings.
7. The paper lacks a theoretical analysis, and the assumptions regarding membership information are overly strong.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by including comparisons with additional state-of-the-art techniques to validate the effectiveness of their method. Additionally, providing code implementation would enhance reproducibility. We suggest conducting experiments with higher accuracy models to better demonstrate the attack's potential. Clarifying the novelty of their approach in relation to existing literature on batch normalization and membership inference would strengthen their claims. We urge the authors to address the implications of lower privacy budgets and explore potential strategies to enhance attack performance in these scenarios. Lastly, we recommend clarifying the limitations of using pre-trained GANs in their methodology and removing misleading statements regarding theoretical analysis while addressing the assumptions made about membership information more rigorously.