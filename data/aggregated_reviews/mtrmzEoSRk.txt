ID: mtrmzEoSRk
Title: Multilingual self-supervised speech representations improve the speech recognition of low-resource African languages with codeswitching
Conference: EMNLP/2023/Workshop/CALCS
Year: 2023
Number of Reviews: 2
Original Ratings: 3, 4
Original Confidences: 4, 5

Aggregated Review:
### Key Points
This paper presents a comprehensive exploration of the transcription of a low-resource African-English code-switch speech dataset. The authors propose multiple experimental settings, including the use of only code-switched data, monolingual data, fine-tuning with language-specific casing, language-specific tags, and multitask settings involving language identification (langID) and automatic speech recognition (ASR). They demonstrate the significance of code-switched data for fine-tuning, which effectively reduces the word-error rate.

### Strengths and Weaknesses
Strengths:
- The paper demonstrates a thorough exploration of various experimental approaches.
- It provides an in-depth analysis of results with precise explanations.
- The writing is generally clear and well-structured.

Weaknesses:
- The paper contains several typographical errors (e.g., "Speed" should be "speech," "EngZul" should be "Eng-Zul," and "15 000" should be "15,000").
- The authors mention using MSE loss for training language identification classification, but this is not adequately explained.
- The different experimental settings lack proper explanation.
- Performance improvements appear primarily attributed to the addition of 2-3 gram language models.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by correcting typographical errors and ensuring that all terms are consistently presented. Additionally, we suggest expanding the Related Work section to provide a more comprehensive context. The authors should also clarify the explanation of their experimental settings and provide more detail on the role of MSE loss in language identification. Finally, we advise completing the caption for Table 4 to enhance clarity.