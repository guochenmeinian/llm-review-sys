ID: R6wXP7txer
Title: The Utility of “Even if” Semifactual Explanation to Optimise Positive Outcomes
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 3, 7, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework for "semi-factual" explanations aimed at applicants who receive positive decisions, detailing actions they could take to maintain those decisions. The authors utilize a causal model to assess the utility gain, plausibility, diversity, and robustness of the suggested actions. They argue that while semi-factuals (SFs) have gained popularity, their utility in machine learning remains unclear, as noted in prior literature. The authors conducted a user study demonstrating the effectiveness of their SF optimization framework, which includes a gain function, actionability constraints, and structural causal models (SCMs). They provide a comprehensive comparison to existing methods, highlighting significant advancements in theoretical contributions, user studies, and considerations of causality and categorical features. The effectiveness of their approach is further demonstrated through experiments and a human study, indicating that their method produces more useful explanations compared to existing baselines.

### Strengths and Weaknesses
Strengths:
- The incorporation of causal models in semi-factual explanations is a promising direction.
- The framework is comprehensive, addressing key desiderata for semi-factual explanations.
- The user study provides compelling evidence of the practical utility of the proposed method.
- The authors offer a thorough comparison with prior work, showcasing substantial improvements in various aspects.

Weaknesses:
- Clarity issues persist in the formalism, particularly in Sections 3 and 4, with specific confusion around the definitions and roles of objects A, S, P, and the distinction between causal and non-causal domains.
- The paper appears to draw heavily from existing literature on causal algorithm recourse, raising questions about its novelty.
- Some cited works are not directly related to explainable AI (XAI), which may dilute the relevance of the literature review.
- The distinction between categorical and continuous features in the context of SFs could be elaborated further.
- Presentation quality is inconsistent, with numerous typos and unclear language, particularly in the Introduction.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the formalism in Sections 3 and 4 by explicitly defining terms such as A, S, and P, and clarifying the distinction between causal and non-causal approaches. Additionally, we suggest enhancing the Introduction by providing a tighter context for previous work, clearly distinguishing between counterfactuals and semi-factuals, and justifying strong claims made throughout the paper. We also recommend improving the clarity of the literature review by focusing on more directly relevant works in XAI. Furthermore, we suggest providing a more detailed discussion on the implications of categorical versus continuous features in their framework to enhance understanding of their contributions. Finally, a thorough proofreading is necessary to address typos and improve overall presentation quality.