ID: opaRhDvQRD
Title: Forgetting, Ignorance or Myopia: Revisiting Key Challenges in Online Continual Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 6, 7, 8, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive analysis of Online Continual Learning (OCL), identifying two critical challenges: model ignorance and myopia. In response, the authors propose the Non-sparse Classifier Evolution (NsCE) framework, which incorporates non-sparse maximum separation regularization and targeted experience replay techniques to enhance model performance and throughput. The authors also provide theoretical guarantees from a PAC-Bayes perspective, contributing valuable insights into the robustness and generalization of their method.

### Strengths and Weaknesses
Strengths:
1. The paper effectively highlights the limitations of existing OCL methods, particularly regarding model throughput and the concepts of ignorance and myopia.
2. The empirical evaluation is thorough, demonstrating significant improvements in model performance and throughput.
3. The introduction of myopia as a challenge in OCL is innovative, and the theoretical analysis adds depth to the discussion.
4. The proposed method is straightforward, easy to implement, and has shown effectiveness in experiments.

Weaknesses:
1. The constraints on memory buffer accesses resemble laboratory conditions rather than real-world applications; examples of realistic scenarios would enhance the discussion.
2. The authors do not provide a clear strategy for improving model throughput or its relationship with pre-trained models.
3. Important experimental results in the Appendix should be included in the main text for better validation of the proposed methods.
4. Some claims, such as the impact of the $max()$ function on outliers, require further justification.

### Suggestions for Improvement
We recommend that the authors improve the discussion by providing examples of real-world scenarios where the imposed constraints on memory buffer accesses are applicable. Additionally, more analysis on strategies to enhance model throughput and its connection to pre-trained models is needed. We suggest including key experimental results from the Appendix in the main text to strengthen the validation of the proposed methods. Furthermore, the authors should clarify the justification for the $max()$ function's sensitivity to outliers and provide insights into the observed discrepancies in performance metrics. Lastly, addressing the typos and grammatical errors throughout the paper will enhance clarity and professionalism.