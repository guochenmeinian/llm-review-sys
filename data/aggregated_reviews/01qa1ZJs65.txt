ID: 01qa1ZJs65
Title: Bridge the Modality and Capability Gaps in Vision-Language Model Selection
Conference: NeurIPS
Year: 2024
Number of Reviews: 30
Original Ratings: 5, 4, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a zero-shot image classification strategy that selects the most suitable Pre-Trained Vision Language Model (VLM) from the VLM Zoo, utilizing only the text data of the target dataset without access to images. It identifies two main challenges: the “Modality Gap” and the “Capability Gap,” which complicate the selection of VLMs. To tackle these issues, the authors propose a method called SWAB, which employs a transportation matrix to assess the relevance between open-source and target datasets and transfers useful VLM statistics accordingly. Extensive experiments validate the effectiveness of the proposed method across various image classification datasets. Additionally, the paper analyzes ModelGPT's performance in relation to ImageNet, suggesting that its $R_5$ could be lower due to reliance on a Linear Regression Model that predicts performance based on various metrics. The authors argue that the performance prediction depends on a weighted sum of scores from the ImageNet Baseline and performance metrics from text samples generated by LLMs. They highlight a significant modality gap between image and text features, which limits the correlation between text-based metrics and actual model performance. Evidence supporting this includes an analysis of consistency between text top-1 accuracy and actual model accuracy, showing that their method effectively bridges the modality gap, although the improvement in the $R_5$ metric is minimal and may not be statistically significant.

### Strengths and Weaknesses
Strengths:
- The originality of the paper lies in applying Language-Only VLM Selection in a zero-shot context, addressing a significant gap in the literature.
- The methods are well-motivated, and the paper includes extensive experiments demonstrating the proposed method's effectiveness.
- The clarity of writing and the quality of figures enhance the paper's readability.
- The authors provide a clear rationale for the limitations of using text metrics to predict model performance.
- The experimental results demonstrate the effectiveness of their method in bridging the modality gap.

Weaknesses:
- The reliance on open-source datasets for VLM selection may limit the method's practicality and raise concerns about benchmark leakage and zero-shot data restrictions.
- The impact of open-source datasets on performance is not thoroughly analyzed, particularly regarding category differences between datasets.
- The paper lacks a discussion of limitations, particularly concerning the unrealistic assumptions in its settings and the focus solely on classification tasks.
- The improvement in the $R_5$ metric is marginal and may not be robust, as it could fall within the error bars of the methods used.

### Suggestions for Improvement
We recommend that the authors improve the analysis of the impact of open-source datasets on the proposed method's performance, particularly in cases where category distributions differ significantly. Additionally, we suggest including a discussion of the limitations of the work, addressing the concerns raised about the reliance on open-source data and the implications for zero-shot classification. Furthermore, we encourage the authors to explore ensemble learning approaches, such as selecting the top-k VLMs for a complementary combination, rather than solely focusing on the most suitable model. Lastly, we recommend that the authors improve the robustness of their findings by conducting additional experiments to assess the statistical significance of the observed improvements in the $R_5$ metric and clarifying the implications of the modality gap on the predictive capabilities of text-based metrics.