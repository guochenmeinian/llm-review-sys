ID: ir6WWkFR80
Title: Punctuation-level Attack: Single-shot and Single Punctuation Can Fool Text Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 4, 7, 7, 5, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to adversarial attacks on text models, termed punctuation-level attack, which utilizes punctuation perturbations such as insertion, displacement, deletion, and replacement. The authors introduce Text Position Punctuation Embedding (TPPE) as an embedding method and Text Position Punctuation Embedding and Paraphrase (TPPEP) as a search method to optimize the attack's efficiency and reduce time complexity. The effectiveness of the proposed methods is demonstrated through experiments on various tasks, including summarization, semantic-similarity scoring, and text-to-image tasks, showing that the attack is less perceptible to humans and has a reduced semantic impact compared to traditional perturbations.

### Strengths and Weaknesses
Strengths:
1. The punctuation-level attack expands the scope of adversarial textual attacks, minimizing human perceptual impact.
2. The proposed methods, TPPE and TPPEP, enhance efficiency and reduce computational costs, supported by a comprehensive mathematical analysis.
3. Experimental results demonstrate the effectiveness and versatility of the punctuation-level attack across various datasets and state-of-the-art models.

Weaknesses:
1. The paper lacks discussion on whether large language models (LLMs) can be fooled and the reasons behind the failure of pre-trained language models (PLMs) on punctuation.
2. There is no exploration of defense mechanisms against punctuation-level attacks, which limits the contribution to enhancing model robustness.
3. The attack's success rate is primarily promising on CoLA, which is not an ideal dataset for evaluation due to its linguistic correctness requirements.
4. Punctuation modifications can alter original labels in certain tasks, necessitating a discussion of potential negative cases.
5. The experimental evaluation is limited to a few tasks, lacking comprehensive insights across diverse NLP scenarios.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the potential for LLMs to be fooled by punctuation-level attacks and explore the reasons why PLMs fail in this context. Additionally, we suggest including a section on defense strategies against punctuation-level attacks to enhance the paper's contribution to the community. It would be beneficial to provide a more comprehensive evaluation across a broader range of tasks to validate the proposed methods further. We also encourage the authors to discuss the implications of punctuation modifications on original labels and include qualitative analyses to support claims of semantic imperceptibility. Lastly, we recommend addressing the inconsistencies in notation and reorganizing sections for clarity.