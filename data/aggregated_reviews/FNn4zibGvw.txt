ID: FNn4zibGvw
Title: Hyperbolic VAE via Latent Gaussian Distributions
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 6, 6, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel Gaussian manifold generative autoencoder (GM-VAE) that utilizes a statistical manifold formed by univariate Gaussian distributions, introducing a pseudo-Gaussian manifold normal distribution for improved sampling and training stability. The authors propose a hyperbolic distribution using KL divergence as a local approximation of the geodesic distance, facilitating fast computation of KL divergence and sampling. Empirical results indicate that GM-VAE outperforms state-of-the-art baselines in density estimation and achieves comparable results in model-based reinforcement learning tasks.

### Strengths and Weaknesses
Strengths:
1. The GM-VAE model represents a significant improvement over traditional VAE architectures, supported by a solid theoretical foundation.
2. Experimental results demonstrate the superiority of GM-VAE on various image datasets, showcasing its computational efficiency.
3. The paper is well-written and presents a clear motivation for the proposed method.

Weaknesses:
1. The experimental results in model-based RL tasks are only comparable to competitors, lacking clear superiority.
2. The use of relatively small-scale image datasets raises questions about the generalizability of the findings.
3. The paper does not adequately discuss the limitations of the proposed method, particularly regarding the influence of the introduced approximation on modeling capabilities.

### Suggestions for Improvement
We recommend that the authors improve the empirical demonstration of numerical stability, as this is a claimed main benefit of the proposed method. Providing quantitative analysis and visualizations of the stability would strengthen the claims. Additionally, the authors should clarify the tuning process for the curvature parameter and the $\beta$ parameter in practice, addressing potential overfitting concerns. Enhancing the preliminaries section and providing a more concrete definition of the Poincare half-plane model, including standard operations, would improve readability. Finally, we suggest testing the GM-VAE on larger-scale datasets and including numerical error analysis to substantiate claims of reduced numerical instability.