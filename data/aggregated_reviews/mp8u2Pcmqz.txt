ID: mp8u2Pcmqz
Title: DuQuant: Distributing Outliers via Dual Transformation Makes Stronger Quantized LLMs
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 8, 7, 8, 8, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DuQuant, a novel quantization method tailored for large language models (LLMs) that effectively addresses the challenges posed by "massive outliers" in activations. The authors demonstrate that existing quantization techniques, such as SmoothQuant and OmniQuant, struggle with these outliers, leading to performance degradation. DuQuant employs a sequence of orthogonal rotation and permutation transformations to redistribute outliers, resulting in improved quantization outcomes. Theoretical analyses and experiments validate the method's efficacy, showing state-of-the-art performance across various benchmarks, including Llama and Vicuna models.

### Strengths and Weaknesses
Strengths:
- The exposition is clear, with well-motivated steps and straightforward theoretical applications to real-world implementations.
- Experimental results indicate that DuQuant outperforms previous state-of-the-art quantization methods while reducing time and memory costs.
- The method effectively addresses the issue of massive outliers, providing a theoretically grounded approach to low-precision quantization.

Weaknesses:
- Certain desirable properties, such as memory consumption reduction, are not adequately highlighted in the main body, being relegated to appendix E.
- Speedup measurements are limited to pre-filling; end-to-end speedup for open-ended generation is not provided.
- The novelty of applying rotation transformations is questioned, as similar concepts were introduced in QuaRot, which should be compared more thoroughly.

### Suggestions for Improvement
We recommend that the authors improve the visibility of memory consumption reduction results by integrating them into the main body of the paper. Additionally, it would be beneficial to compute and present end-to-end speedup metrics for open-ended generation tasks to provide a more comprehensive evaluation of the method's performance. We also suggest including a detailed comparison with QuaRot in the main text, as it is a relevant baseline. Lastly, clarifying the construction of the rotation matrix and addressing the inconsistencies in result reporting across models would enhance the paper's clarity and rigor.