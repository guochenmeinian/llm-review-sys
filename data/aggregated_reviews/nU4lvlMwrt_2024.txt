ID: nU4lvlMwrt
Title: Toward Real Ultra Image Segmentation: Leveraging Surrounding Context to Cultivate General Segmentation Model
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 7, 3, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents SGNet, a framework designed to address the challenges of ultra image segmentation (UIS) by leveraging surrounding context information to enhance segmentation results. The authors propose that SGNet can be integrated with any segmentation model, improving performance on high-resolution images. The method has been validated across five diverse datasets, demonstrating significant improvements in segmentation accuracy and efficiency.

### Strengths and Weaknesses
Strengths:  
1) The paper identifies and addresses two intrinsic problems in UIS, providing a novel solution.  
2) SGNet has been evaluated on a wide range of datasets, showcasing its effectiveness in various applications, including medical and remote sensing.  
3) The proposed method is simple, effective, and shows advantages across different general segmentation models.  
4) The contribution of each module within SGNet has been clearly evaluated, demonstrating its efficacy.

Weaknesses:  
1) There is a lack of evaluation on human subjects, particularly in areas like fingers and ears.  
2) The discussion on limitations is insufficient, failing to address potential challenges such as matting or segmentation quality with JPEG artifacts.  
3) The contribution of SGNet is viewed as incremental, with some aspects having been previously proposed in other segmentation tasks.  
4) The computational cost of SGNet is noted to be high.  
5) The evaluation of speed is limited, only including one lightweight version of the model.  
6) The clarity of the surrounding branch's description is inadequate.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by including segmentation results on human subjects, particularly in challenging areas. Additionally, the authors should expand the limitations section to address potential issues such as matting and the impact of JPEG artifacts on segmentation quality. To strengthen the contribution claim, we suggest comparing SGNet with other plug-and-play methods rather than solely with task-specific strategies. Furthermore, a more comprehensive evaluation of speed, including results from multiple model versions, would enhance understanding of the method's overhead. Lastly, clarifying the description of the surrounding branch and its architecture would improve the paper's clarity.