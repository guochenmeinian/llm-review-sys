ID: fbbbbfhAxC
Title: Cross-lingual Transfer Can Worsen Bias in Sentiment Analysis
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis of how social biases transfer across languages during cross-lingual transfer learning for sentiment analysis, focusing on five languages. The authors investigate bias transfer in both pretraining and finetuning data, revealing that multilingual pretraining significantly impacts biases, with both gender and racial biases being susceptible to transfer. The study highlights the importance of understanding bias in multilingual NLP, especially as models are increasingly used in non-English contexts.

### Strengths and Weaknesses
Strengths:
- The paper provides a thorough analysis of gender and racial bias in sentiment systems across multiple languages, controlling for different sources of bias.
- It combines sentiment analysis and cross-lingual training, offering insights into bias dynamics in multilingual settings.
- The experimental setup is sound, and the writing is clear, with a well-structured presentation of results.

Weaknesses:
- There are no examples of racial/immigrant bias subjects in other languages, making it difficult to identify specific groups studied.
- The training procedure raises concerns, particularly regarding the finetuning of ZS-XLT on additional data, which may influence results.
- The results in Section 6 lack consistency with those in Figure 4, and the authors do not provide a list of demographic and emotion words used for counterfactual pairs.
- The paper would benefit from stronger statistical testing to support claims about bias effects.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the terms "weak and strong gender agreement" in lines 494-505, as they are not standard and may confuse readers. Additionally, please provide the list of demographic and emotion words used for counterfactual pairs to enhance transparency. We suggest including results from prior work (Keung et al., 2020) in Appendix B for comparison and testing the performance claims more rigorously. Furthermore, consider addressing the assumptions regarding gender effects based on syntactic signals across languages, as this could strengthen the argument. Lastly, we advise improving the legibility of figures, particularly by using different symbols in addition to colors and ensuring that all labels are adequately sized.