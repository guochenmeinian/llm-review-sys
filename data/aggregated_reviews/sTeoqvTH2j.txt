ID: sTeoqvTH2j
Title: HiCL: Hierarchical Contrastive Learning of Unsupervised Sentence Embeddings
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a hierarchical contrastive learning framework (HiCL) aimed at enhancing unsupervised sentence representation learning by leveraging both local segment-level and global sequence-level relationships. The authors claim that HiCL reduces training time by encoding shorter segments before aggregating them for global representation. Experimental results indicate that HiCL outperforms existing methods like SimCSE, ESimCSE, and SNCSE across seven semantic textual similarity datasets.

### Strengths and Weaknesses
Strengths:
- The paper introduces a novel hierarchical approach to contrastive learning, which is a significant contribution to the field of NLP.
- It provides a comprehensive intrinsic analysis and is well-written, facilitating reader understanding.
- The proposed method shows improved encoding efficiency, which could be beneficial for longer documents.

Weaknesses:
- The motivation for using shorter segments in contrastive learning is not sufficiently strong, and the efficiency claims may not be directly related to contrastive learning.
- The performance improvements are marginal, and the reproduction of baseline models falls short of previously reported results.
- The paper lacks clarity regarding the encoder's integration with BERT and RoBERTa, and the overall research goal is ambiguous.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper, particularly in explaining how the encoder is integrated with BERT and RoBERTa, and clarify the research goalâ€”whether it is focused on sentence embedding or addressing specific NLP problems. Additionally, we suggest providing a stronger motivation for the use of local contrastive loss and exploring the hierarchical structure and semantics of segments more thoroughly. To enhance robustness, we recommend applying the method to a broader range of NLP tasks beyond semantic textual similarity. Finally, we advise reporting confidence intervals for performance comparisons to substantiate claims of statistical significance.