ID: XNGsx3WCU9
Title: Visual Data Diagnosis and Debiasing with Concept Graphs
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 6, 5, 4, 5, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ConBias, a novel framework for diagnosing and mitigating inherent biases in visual datasets. The method involves three main steps: Concept Graph Construction, Concept Diagnosis, and Concept Debiasing. By representing datasets as knowledge graphs of object co-occurrences, the authors identify imbalances and generate images for under-represented concepts using Stable Diffusion. Extensive evaluations demonstrate that ConBias enhances generalization performance across various datasets, outperforming existing methods.

### Strengths and Weaknesses
Strengths:
- The paper introduces an original approach to dataset debiasing that combines diagnosis and balancing strategies, improving robustness in binary classification tasks.
- Experimental results across multiple datasets provide strong justification for the proposed method, showing significant performance improvements.
- The manuscript is well-structured and clearly written, facilitating understanding of the ConBias pipeline.

Weaknesses:
- The reliance on metadata for graph construction limits applicability in scenarios where such data is unavailable, raising concerns about the method's generalizability.
- The experimental scope, primarily focused on binary classification tasks, may not adequately demonstrate the method's effectiveness in more complex multi-class scenarios.
- The technical novelty of the graph construction and bias diagnosis processes is questioned, as they appear to rely heavily on counting mechanisms rather than advanced learning techniques.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of ConBias by addressing scenarios with unlabeled data, potentially leveraging large multimodal models for concept generation. Additionally, we suggest expanding the experimental evaluation to include multi-class classification tasks to better assess the method's scalability. Further justification for the choice of dataset debiasing over feature space methods would strengthen the paper, along with a detailed comparison of computational complexity with existing methods. Lastly, clarifying the differences in experimental results compared to previous works, such as the ALIA paper, would enhance the manuscript's credibility.