ID: pTCZWSDltG
Title: CorresNeRF: Image Correspondence Priors for Neural Radiance Fields
Conference: NeurIPS
Year: 2023
Number of Reviews: 24
Original Ratings: 5, 5, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents "CorresNeRF: Image Correspondence Priors for Neural Radiance Fields," which proposes a novel set of losses to enhance NeRF performance under sparse input conditions. The authors leverage an out-of-the-box matching strategy between image pairs to enforce geometric constraints during implicit representation training, introducing reprojection and depth losses. Extensive experiments validate the effectiveness of these additional losses, demonstrating improved reconstruction quality and easy integration into existing NeRF techniques. Additionally, the paper evaluates NeuRIS using the DTU dataset, revealing that NeuRIS performs similarly to or worse than the baseline NeuS method, while CorresNeRF significantly outperforms both. The performance of NeuRIS is highly sensitive to the quality of normal priors, which are less reliable than high-quality image correspondences, making CorresNeRF a more practical solution. The authors conducted fair comparisons and visualized normals to support their findings, confirming their observations with the author of NeuRIS, who acknowledged the inaccuracies of the pre-trained normal priors on the DTU dataset.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and straightforward.
- The approach is simple and integrates easily into most NeRF-based methods, yielding improved results.
- The technique is effective under sparse view constraints, with limited computational overhead due to fast matching strategies.
- Extensive experiments show significant improvements in novel view synthesis and surface reconstruction metrics.
- Comprehensive evaluation of NeuRIS against baseline methods.
- Clear visualization and analysis of normal priors, enhancing understanding of performance issues.
- Confirmation of findings through communication with the original authors of NeuRIS.

Weaknesses:
- The simplicity of the approach raises questions about its novelty, as the losses are not fundamentally new but yield effective results. The contributions may appear limited, although the quality of results could justify acceptance.
- The performance of CorresNeRF under common scenarios with more images remains unexplored.
- The effectiveness of the method is contingent on the accuracy of image correspondences, which can be problematic in challenging conditions.
- The paper lacks comprehensive comparisons with state-of-the-art methods like SparseNeuS, MVSNeRF, and GeoNeRF.
- NeuRIS's performance is heavily reliant on the accuracy of normal priors, which are inadequate for the DTU dataset.
- Lack of full configurations and documentation in the NeuRIS codebase limits reproducibility.

### Suggestions for Improvement
We recommend that the authors improve the paper by conducting an ablation study with an increasing number of images to analyze how the method scales and if improvements hold in denser scenarios. Additionally, a detailed comparison with existing methods, particularly SparseNeuS, would strengthen the paper's claims. Clarifying the robustness of the correspondence matching process, especially under varying noise levels and occlusions, is essential. Further exploration of alternative loss types, such as epipolar losses, could enhance the methodology. Lastly, providing insights into the computational efficiency and resource requirements of CorresNeRF would help understand its practical implications. For NeuRIS, we recommend that the authors improve its robustness by exploring alternative normal priors that are more suited to the DTU dataset. Furthermore, providing complete configurations and documentation for running experiments with the DTU dataset in the NeuRIS codebase would enhance reproducibility and usability.