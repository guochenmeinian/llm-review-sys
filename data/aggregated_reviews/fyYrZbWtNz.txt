ID: fyYrZbWtNz
Title: Rethinking Imbalance in Image Super-Resolution for Efficient Inference
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 7, 3, 5, 7, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 5, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Weight-Balancing Super-Resolution (WBSR) framework that reformulates the super-resolution (SR) task as an imbalanced distribution transfer learning problem. The authors introduce a Hierarchical Equalization Sampling (HES) strategy to address data distribution imbalances, a Balanced Diversity Loss (BDLoss) function to optimize learning in texture-rich regions, and a gradient projection dynamic inference strategy for efficient inference. Extensive experimental results indicate that the proposed method achieves comparable or superior performance to existing approaches while reducing computational costs by approximately 34%.

### Strengths and Weaknesses
Strengths:
1. The framework effectively addresses imbalances in model learning without altering the original model structure or training data.
2. The Balanced Diversity Loss function enhances model learning by focusing on texture regions and minimizing redundant computations, leading to efficient training.
3. The paper is well-written, with extensive quantitative experiments that clarify the significance of the proposed method.

Weaknesses:
1. The proposed method offers incremental contributions and is not the first to explore imbalance in image SR, as noted in previous works.
2. The experimental section lacks a comprehensive comparison with the latest related works and transformer-based SR backbones.
3. Some grammatical errors and unclear descriptions, particularly regarding the HES sampling method and the backbone network used, need correction for clarity.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the network structure used in the gradient dynamic projection method and provide a more detailed description of the HES sampling method. Additionally, we suggest adding more comparative experiments with recent related works to substantiate the claims made. To enhance organization and clarity, please include appropriate explanations for the experiments and notations in the results tables. Finally, consider testing the proposed methods on a broader range of datasets to validate robustness across diverse scenarios.