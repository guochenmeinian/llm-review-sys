ID: 3ofe0lpwQP
Title: DisDiff: Unsupervised Disentanglement of Diffusion Probabilistic Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 21
Original Ratings: 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 2, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper proposes a method named DisDiff for unsupervised disentanglement of diffusion probabilistic models (DPMs) to enhance interpretability. The authors introduce two constraints, invariant condition and variant condition, to facilitate disentanglement. The method is evaluated on synthetic datasets and CelebA, demonstrating some effectiveness in disentangled representation learning. Additionally, the paper presents a derivation of mutual information upper bounds through a series of propositions. The authors propose an estimator \( I_\theta \) that serves as an upper bound for the mutual information \( I(z^c, z^k) \) under certain conditions, utilizing Gaussian distributions and conditional sampling to detail the relationships between various distributions and their estimators.

### Strengths and Weaknesses
Strengths:
- The combination of disentangled representation learning and diffusion-based models addresses an important and challenging problem.
- The proposed method shows promising results on synthetic datasets and real-world applications, indicating its potential significance.
- The authors provide a comprehensive and detailed proof of their propositions, enhancing the clarity of their methodology.
- The derivation includes multiple propositions that systematically explore the conditions under which the estimator can be applied.

Weaknesses:
- The derivation of the reverse diffusion process (Eq. 5, 6, 7) is missing.
- The distinction between the proposed model and latent diffusion models is unclear.
- The authors fail to consider Diff-AE and PDAE as baselines in their experiments.
- Image generation experiments against Diff-AE and PDAE are necessary to enhance robustness.
- The generation process for Figure 3 lacks clarity and requires detailed explanation.
- The mathematical definitions and formulations are often unclear, leading to misunderstandings about the proposed method.
- Claims regarding the uniqueness of their contribution to disentanglement tasks in DPMs are overstated, as recent work has addressed similar problems.
- There is some ambiguity in Proposition 4 regarding whether \( I_\theta \) serves as a lower bound in certain cases, which requires clarification.
- The "triangular" objective mentioned in the proof sketch lacks a clear explanation, potentially confusing readers.

### Suggestions for Improvement
We recommend that the authors improve the clarity of mathematical definitions and formulations to enhance understanding. Specifically, provide a complete derivation of the reverse diffusion process and clarify the differences between the proposed model and latent diffusion models. Additionally, include Diff-AE and PDAE as baselines in experiments and conduct image generation experiments to strengthen the findings. We also suggest revising the claims regarding the novelty of the work to accurately reflect the existing literature. Furthermore, we recommend improving the clarity of Proposition 4 by explicitly stating the conditions under which \( I_\theta \) serves as an estimator with a bounded error. We encourage the authors to provide a clearer explanation of the "triangular" objective in the proof sketch and to include the detailed proofs in the paper or appendix for better illustration. Finally, ensure that the generation process for Figure 3 is well-explained and that all notations are used correctly throughout the paper.