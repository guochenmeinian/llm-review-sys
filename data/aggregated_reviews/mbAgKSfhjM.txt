ID: mbAgKSfhjM
Title: USCILab3D: A Large-scale, Long-term, Semantically Annotated Outdoor Dataset
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 6, 6, 8, 5, -1, -1, -1
Original Confidences: 3, 3, 4, 5, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a large-scale, semantically annotated outdoor dataset, USCILab3D, collected using a mobile robot equipped with five cameras and a 32-beam LIDAR. The dataset comprises 1.4 million point clouds and 10 million images, annotated with state-of-the-art models like GPT-4 and Grounded-SAM. It focuses on intricate urban environments, enabling precise 3D labeling and supporting diverse applications in computer vision and robotics. The authors evaluate novel view synthesis methods on this dataset, providing insights into its performance and applicability.

### Strengths and Weaknesses
Strengths:
- The dataset's scale and diversity surpass previous datasets, offering extensive multi-view imagery and high-quality semantic annotations across 267 categories.
- The use of foundation models for annotation enhances the dataset's utility, providing rich semantic information valuable for various downstream tasks.
- The paper is well-structured and clearly explains the dataset collection process, making it easy to follow.

Weaknesses:
- The dataset is limited to the USC campus, which may restrict its applicability to other environments.
- Potential inaccuracies in machine-generated annotations could affect the dataset's reliability.
- The experimental design for novel view synthesis lacks clarity, as it compares a single method across different datasets, complicating the assessment of dataset quality.

### Suggestions for Improvement
We recommend that the authors improve the evaluation of the dataset by exploring additional novel view synthesis methods beyond 3D Gaussian Splatting. Furthermore, providing more details on the computation of incorrect pixel labels in Figure 5 is essential for understanding the dataset's accuracy. 

To enhance the paper, discuss the necessity of fine-grained semantic labels and their potential applications, such as object detection and urban planning. A direct comparison of semantic classes across different datasets would also strengthen the contribution of fine-grained annotations. 

Additionally, incorporating strategies to correct inaccuracies in Grounded-SAM outputs would improve annotation quality. Lastly, including ground truth trajectories and details about the mobile platform's specifications would be crucial for practical navigation applications.