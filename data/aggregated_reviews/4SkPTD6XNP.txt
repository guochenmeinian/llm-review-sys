ID: 4SkPTD6XNP
Title: Cal-DETR: Calibrated Detection Transformer
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 7, 6, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 2, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method to enhance the calibration performance of transformer-based object detectors, specifically Deformable DETR and UP-DETR. The authors propose a way to quantify uncertainty in logits using the variance from different transformer decoder layers, downscaling logits with high uncertainty. They also introduce a mixup approach for logits associated with positive queries, creating a prototype from the mean of these logits. The method shows significant improvements across various datasets.

### Strengths and Weaknesses
Strengths:
- The proposed method is a training-time approach, eliminating the need for an additional validation set.
- Calibration performance improvements are notable, consistently outperforming existing methods across multiple datasets.
- The intuitive approach to uncertainty estimation does not add complexity to the detection architecture.
- The paper is clearly written and easy to follow.

Weaknesses:
- The logit mixup strategy closely relates to a cited work, lacking explicit discussion of its novelty and contribution in the context of object detection.
- The impact of the number of detections on calibration performance is not addressed, raising questions about the validity of the calibration measures used.
- The reliability of the estimated uncertainties is not substantiated, leaving doubts about their applicability.

### Suggestions for Improvement
We recommend that the authors improve the discussion of the logit mixup strategy by explicitly comparing it to the cited work, clarifying its contributions to object detection. Additionally, please provide details on the average number of detections per image for the various models in Table 1, and clarify any thresholding applied during DECE estimation. We also suggest confirming the process for obtaining prototypical representations during training and making it explicit in the paper. Furthermore, consider explaining the choice of a fixed mixing coefficient in contrast to sampling from a distribution. Lastly, please define how labels are obtained after smoothing to enhance clarity.