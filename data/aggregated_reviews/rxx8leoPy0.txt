ID: rxx8leoPy0
Title: Med-HVL: Automatic Medical Domain Hallucination Evaluation for Large Vision-Language Models
Conference: AAAI
Year: 2024
Number of Reviews: 4
Original Ratings: 4, 6, 7, 6
Original Confidences: 5, 3, 4, 4

Aggregated Review:
### Key Points
This paper presents two automatic metrics, CHAIR and DVH, for evaluating the hallucination degree of large vision-language models (LVLMs) in the medical domain. The authors define hallucination in this context, distinguishing between Object Hallucination, which involves inaccuracies about objects, and Domain Knowledge Hallucination, focusing on diagnostic inaccuracies. They also introduce a tool called Med-HVL for detecting and evaluating these hallucinations, with an initial evaluation conducted using LLaVA-Med on the MedICAT dataset.

### Strengths and Weaknesses
Strengths:
- The paper addresses a critical issue of evaluating LVLM hallucinations in a clinical context, which is well-motivated.
- The proposed metrics are relevant and tailored to the medical domain, contributing to the understanding of LLM biases.

Weaknesses:
- The term "domain knowledge hallucination" is limited to diagnosis and does not encompass other medical concepts, suggesting a more appropriate term would be "diagnosis hallucination."
- The evaluation is restricted to LLaVA-Med, weakening the argument's generalizability.
- There is a lack of human evaluation to validate the reliability of model-derived metrics.
- Clarifications are needed regarding the combination of cosine similarity and ICD-10-based distance, and potential leakage of ground truth diagnosis in enhanced prompts.
- The figure presented is not referenced in the text, and there are inconsistencies in terminology that could lead to confusion.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the manuscript and address the limitations of their proposed metrics. Specifically, consider expanding the definition of "domain knowledge hallucination" to include other medical concepts. Additionally, we suggest incorporating human evaluations to validate the reliability of the metrics, particularly regarding LLM-based NER and the reasonableness of cosine similarity and thresholds. It would also be beneficial to compare the proposed metrics with existing ones like RadGraph and CheXBert. Lastly, ensure that figures are properly referenced in the text and clarify any ambiguous terminology to enhance understanding.