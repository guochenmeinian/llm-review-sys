ID: XEBHsJpFY9
Title: Culturally Aware Natural Language Inference
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a culturally aware NLI dataset, CALI, derived from English texts in the US and India, aimed at exploring how NLP models respond to cultural context. The authors analyze the dataset and evaluate the performance of various models, revealing that while current systems possess some norm knowledge, they struggle with context recognition and appropriate inferences. The paper categorizes the influence of cultural norms across lexical, semantic, pragmatic, and script elements, providing a nuanced understanding of cultural variations in language understanding.

### Strengths and Weaknesses
Strengths:
- The paper addresses an important issue of cultural awareness in NLP, relevant for diverse user interactions.
- The CALI dataset offers a valuable resource for evaluating cultural awareness in inference tasks.
- The categorization of cultural influences on language understanding provides insightful analysis.
- Experiments highlight limitations in current models' cultural awareness.

Weaknesses:
- The focus on only two cultural groups (US and India) limits the generalizability of findings.
- Heavy reliance on GPT-3 for data generation raises concerns about biases and artifacts, which are insufficiently analyzed.
- The majority vote for labels risks marginalizing minority perspectives; better aggregation methods should be explored.
- The writing lacks clarity, with unclear task definitions and abrupt introductions of concepts like the Linguistic Dimension.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Sections 3 and 5.1, ensuring that key concepts are easily understood. We suggest providing a quantitative analysis using the categories developed in Section 4 and clarifying the takeaways from the evaluation of LLMs. Additionally, we encourage the authors to explore the cultural insights derived from annotator judgments across the two cultures and to address biases related to gender, race, and other intersectional factors more thoroughly. We also recommend including a clear diagram outlining the data creation pipeline and ensuring that ethical considerations, including IRB approval, are explicitly addressed in the paper.