ID: ZZS9WEWYbD
Title: A Definition of Continual Reinforcement Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 7, 4, 4, 7, 7, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 2, 3, 4, 2, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a formal framework for continual reinforcement learning (CRL), establishing mathematical definitions for environments and agents. The authors aim to clarify the concept of CRL by introducing operators that describe an agent's learning behavior, specifically the "generates" and "reaches" operators. They provide examples to illustrate these concepts and explore the implications of their framework for future research in continual learning. Additionally, the authors propose a definition of "learning" and "convergence" that relies on an arbitrary reference object, which reviewers find intriguing and warranting further formalization. The work is seen as potentially impactful for future research in the field.

### Strengths and Weaknesses
Strengths:
- The mathematical definitions offer valuable insights into continual learning and may inspire new research directions.
- The writing is clear and precise, making complex ideas more accessible.
- The framework is original and has the potential to open new perspectives on long-term learning behavior in agents.
- The authors have effectively addressed previous concerns, leading to a positive reassessment of the paper.
- The ambition and utility of the work are recognized, with potential to inspire further technically-grounded research.
- Clarifications regarding the agent basis and its implications for training power have resolved initial concerns.

Weaknesses:
- The abstract is overly simplistic and does not provide sufficient information about the paper's contributions.
- The paper lacks a comprehensive literature review, missing connections to existing continual learning research.
- The training process and the concept of agent basis are not clearly articulated, which may hinder understanding.
- Some reviewers noted that analyzing plasticity through a toy task could enhance the paper's appeal.
- There remains a semantic debate regarding the use of the term "insight," which some reviewers feel could be better articulated.

### Suggestions for Improvement
We recommend that the authors improve the abstract to provide a more informative overview of the paper's contributions. Additionally, we suggest including a broader literature review to contextualize the work within existing continual learning frameworks. Clarifying the training process in Section 4.2 with pseudocode and enhancing the explanation of the agent basis would also be beneficial. We further recommend that the authors provide a formalization of the conjecture regarding the definition of continual learning. Considering an analysis of plasticity using a toy task could strengthen their arguments. Finally, we encourage the authors to reconsider the terminology used, particularly the term "insight," to ensure clarity and alignment with the paper's goals.