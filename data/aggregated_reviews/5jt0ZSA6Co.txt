ID: 5jt0ZSA6Co
Title: HYSYNTH: Context-Free LLM Approximation for Guiding Program Synthesis
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 7, 6, 7, -1, -1, -1, -1
Original Confidences: 5, 3, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents HYSYNTH, a hybrid program synthesis approach that enhances traditional bottom-up search with an LLM-guided prior distribution, modeled as a probabilistic context-free grammar (PCFG). The focus is on addressing complex programming by example (PBE) tasks in unfamiliar domain-specific languages (DSLs) where LLMs struggle to generate programs directly. HYSYNTH leverages LLM-generated programs to train a PCFG, which then guides the synthesis process. Experimental results demonstrate that HYSYNTH outperforms both standard LLM generators and non-LLM-based synthesizers across various domains, including grid puzzles, tensor manipulations, and string manipulations.

### Strengths and Weaknesses
Strengths:
- The proposed hybrid approach effectively combines formal program synthesis efficiency with LLM capabilities.
- It requires only a small PCFG extracted from a few LLM samples, making it lightweight and robust compared to training new models for each DSL.
- The method is versatile, applicable across multiple domains, and shows substantial performance improvements in experiments.
- The problem is well-motivated, with thorough discussions on limitations and related work.

Weaknesses:
- The datasets used are small and domain-specific, raising concerns about scalability to more complex programs, such as those involving loops or general-purpose programming.
- The cost of sampling from LLMs is noted, but a comparative analysis of costs across different models (GPT-3.5, GPT-4, DeepSeek) is lacking.
- The simplicity of using PCFG as an approximation model raises questions about its effectiveness, particularly regarding the depth of patterns captured from LLM samples.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the direct sampling baseline by specifying the number of samples drawn from the LLM and the methods used to ensure diversity in sampling. Additionally, we suggest including the time taken to draw samples from the LLM in the experimental results to provide a fair comparison across methods. To address concerns about the PCFG's effectiveness, we encourage exploring whether a simpler surrogate model could yield comparable results. Finally, we recommend investigating the potential benefits of using prompting techniques, such as in-context examples, to enhance the performance of pure LLMs in specific domains.