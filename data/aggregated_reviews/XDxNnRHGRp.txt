ID: XDxNnRHGRp
Title: How Language Models Prioritize Contextual Grammatical Cues?
Conference: EMNLP/2024/Workshop/BlackBoxNLP
Year: 2024
Number of Reviews: 3
Original Ratings: -1, -1, -1
Original Confidences: 3, 4, 3

Aggregated Review:
### Key Points
This paper presents a study on how encoder-based (BERT) and decoder-based (GPT-2) language models handle gender agreement when multiple gender cue words are present. The authors utilize two interpretability techniques—context-mixing via Value-Zeroing and activation patching—to analyze the influence of these cues on model outputs. Results indicate that BERT relies more on earlier cues, while GPT-2 focuses on cues closer to the final prediction.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and clear, making it easy to follow.
- The experimental methodology is rigorous and effectively demonstrates how different architectures manage gender agreement cues.
- The use of two complementary interpretability tools strengthens the study's conclusions and enhances understanding of the underlying mechanisms.

Weaknesses:
- The practical implications of the findings are unclear, and the paper would benefit from a more detailed motivation for the relevance of this study.
- There is a lack of discussion on why different architectures rely on cues differently.
- The generalizability of the findings beyond BERT and GPT-2 is uncertain; including additional models could strengthen the conclusions.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the practical implications of their findings, particularly regarding the relevance of studying gender agreement in language models. Additionally, we suggest including a discussion on the varying reliance on cues by different architectures and exploring the implications of these differences. Finally, consider testing additional models to enhance the generalizability of the results, as well as addressing cases with multiple referents of the same gender in the text.