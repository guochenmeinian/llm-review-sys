ID: FDzQQTPqEJ
Title: Squared Neural Families: A New Class of Tractable Density Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 5, 6, 7, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 2, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents SNEFY, a tractable probabilistic model derived from squaring the Euclidean norm of a neural network and normalizing it with respect to a base measure $\mu$. The authors focus on scenarios where a closed-form solution for the normalizing constant can be obtained, characterized by specific settings outlined in Table 1. The normalization constant is computed as a trace of a PSD matrix, quadratic in the number of neurons, with elements derived from a kernel function applied to the neural net's weights and biases. The model is trained using maximum likelihood estimation and evaluated on three 2D datasets, a spherical manifold, and a low-dimensional astronomy dataset.

### Strengths and Weaknesses
Strengths:
- The introduction of new NNKs.
- Tractable marginalization and conditioning.
- Connection with exponential families and kernel-based methods for nonnegative functions.
- Clear writing and contextual placement within related literature.

Weaknesses:
- SNEFY exhibits slow training times and performs similarly to GMMs when used as a prior for Normalizing Flows.
- Limited experimental evaluation, raising questions about the model's expressivity; the 2D densities tested are relatively simple.
- Sampling is restricted to rejection sampling, leading to high computational costs.
- The manuscript's exposition could be improved, with redundant introductions of concepts and unclear table presentations.

### Suggestions for Improvement
We recommend that the authors improve the experimental evaluation by investigating more complex 2D densities, as suggested in [1], to better demonstrate the model's expressivity. Additionally, we urge the authors to elaborate on the challenges of sampling and consider providing a clearer discussion on the practical trade-offs when using different values of m and n. The presentation of empirical results should be revised to enhance clarity, including making the best results bold in tables and ensuring all tables are referenced in the main text. Finally, we suggest addressing the order of introducing "conditional SNEFY" and "marginal SNEFY" for better logical flow.