ID: SoLebIqHgZ
Title: ARTree: A Deep Autoregressive Model for Phylogenetic Inference
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 7, 8, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ARTree, a novel approach for phylogenetic tree reconstruction that combines deep autoregressive models with Graph Neural Networks (GNNs). The authors demonstrate that ARTree outperforms existing methods, particularly Subsplit Bayesian Networks (SBNs), in terms of KL divergence to the true distribution obtained via MCMC. Unlike SBNs, ARTree does not depend on presampled tree topologies, allowing it to explore the entire tree-topology space. The paper also evaluates ARTree's performance against benchmark datasets, showing its effectiveness in variational Bayesian phylogenetic inference (VBPI). Additionally, the authors analyze various variational inference (VI) approaches, focusing on runtime comparisons and addressing concerns regarding the runtime of ARTree and the minimal increase of the Evidence Lower Bound (ELBO) between ARTree and VPBI.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant challenge in Bayesian phylogenetic inference by proposing a sophisticated variational distribution for tree topologies.
- ARTree's design and experiments contribute meaningfully to the field, showcasing its strong representative power compared to existing methods.
- The added analysis on runtime comparisons significantly enhances the paper, providing clarity on the performance and efficiency of different VI approaches.
- The writing is generally clear, making the complex ideas accessible.

Weaknesses:
- The paper lacks references to relevant works such as VaiPhy and VCSMC, which are important for contextualizing ARTree's contributions.
- There is insufficient discussion on how ARTree reduces the need for domain expertise compared to SBNs.
- The evaluation of tree topologies simulated by ARTree is not clearly articulated, particularly regarding the likelihood of non-simulated topologies.
- The initial response did not adequately address the runtime concerns related to ARTree, which could mislead readers about the trade-offs between performance and runtime.
- The explanation regarding the minimal increase in ELBO between ARTree and VPBI could benefit from further clarity on the underlying model differences.
- The experimental results lack standard deviations, which raises questions about the reliability of the reported metrics.

### Suggestions for Improvement
We recommend that the authors improve the literature review by including references to VaiPhy and VCSMC, as these works are closely related and relevant. Additionally, the authors should clarify how ARTree diminishes the requirement for domain expertise compared to SBNs, as this point is currently ambiguous. It would also be beneficial to explicitly discuss how ARTree computes the likelihood of tree topologies not simulated by the model. Furthermore, we suggest including standard deviations in the experimental results to enhance the transparency and reliability of the findings. Lastly, we recommend that the authors improve the clarity of the runtime comparisons by ensuring that the trade-offs between performance and runtime are explicitly stated in the paper, and further elaborate on the factors contributing to the minimal increase in ELBO, specifically addressing the implications of different \(Q(\tau)\) and \(Q(q|\tau)\) models. Including this information will enhance the discussion and provide readers with a more comprehensive understanding of the results.