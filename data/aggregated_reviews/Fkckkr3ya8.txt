ID: Fkckkr3ya8
Title: Faith and Fate: Limits of Transformers on Compositionality
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 7, 7, 7, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper studies the compositional reasoning capability of Transformer models through three tasks: multi-digit multiplication, logic grid puzzles, and a dynamic programming problem. The authors propose a formalization called computation graphs to quantify compositional complexity, which is evaluated using various Transformer models (GPT-3, ChatGPT, GPT-4) under zero-shot, few-shot, and finetuning techniques. The findings indicate that all models experience a significant decline in performance as compositional complexity increases. Additionally, the paper identifies that Transformer models often produce partially correct predictions based on limited input features and struggle with generalization in out-of-distribution scenarios. The authors provide a theoretical justification for the observed failures in longer reasoning tasks.

### Strengths and Weaknesses
Strengths:
- The selection of three representative compositional tasks and the introduction of computation graphs effectively quantify complexity.
- The use of state-of-the-art Transformer models allows for insights that may be universal across existing models.
- The paper presents new insights into the behavior of Transformer models, including the classification of errors and the identification of restoration errors.
- The theoretical analyses proposed illustrate the limitations of Transformer models in a formal manner.

Weaknesses:
- The results are somewhat expected given the known limitations of large language models on complex reasoning tasks.
- The evaluation is limited to three tasks and one specific algorithm for each, which may not fully represent the capabilities of Transformer models with other algorithms.
- Finetuning is only performed on GPT-3, raising concerns about the generalizability of findings to larger models like ChatGPT or GPT-4.
- Some claims, particularly regarding linearized subgraph matching, lack clarity and may not be directly tied to the internal dynamics of Transformer models.
- The theoretical justification appears oversimplified and does not adequately address the nuances of Transformer architectures.

### Suggestions for Improvement
We recommend that the authors improve the discussion on how their findings relate to existing literature, particularly regarding the insights from "Making transformers solve compositional tasks" and "Grokking: Generalization beyond Overfitting on Small Algorithmic Datasets." It would be beneficial to clarify the extent of their conclusions, especially regarding the generalization to all Transformer models based on evaluations of only GPT-style models. Additionally, we suggest including more details about the experimental setup in the main paper to enhance interpretability. Finally, addressing the limitations of the theoretical justification and exploring potential methodologies for improving Transformer performance on multi-step compositional problems would strengthen the paper.