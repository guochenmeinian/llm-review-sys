ID: bqXduvuW5E
Title: ProteinInvBench: Benchmarking Protein Inverse Folding on Diverse Tasks, Models, and Metrics
Conference: NeurIPS
Year: 2023
Number of Reviews: 20
Original Ratings: 6, 8, 8, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ProteinBench, a comprehensive benchmark for structure-based protein design that facilitates systematic comparisons of state-of-the-art methods in inverse folding. The benchmark includes datasets from CATH4.2, CATH4.3, PDB, and CASP15, and introduces a broader set of evaluation metrics beyond traditional reconstruction/recovery metrics. The authors propose multiple deep learning models and evaluation metrics, including diversity, sc-TM, confidence, robustness, and efficiency, to assess model performance. Additionally, the authors plan to include physics-based methods and additional protein folding models like AlphaFold and OpenFold for a more comprehensive evaluation. They clarify the confidence score metric, which measures predictive probabilities of amino acid sequences, and explore the impact of scaling model parameters on performance. The manuscript also incorporates results from AlphaFold2 to enhance the robustness of findings.

### Strengths and Weaknesses
Strengths:  
- The manuscript provides a significant resource for the protein design community, addressing the need for standardized benchmarks.  
- It includes diverse datasets and multiple evaluation metrics, enhancing the robustness of the benchmark.  
- The authors demonstrate a commitment to improving the benchmark by planning to include physics-based methods and additional protein folding models.  
- The clarification of the confidence score metric and its correlation with recovery rates enhances the understanding of model performance.  
- The authors have addressed reviewer comments thoroughly, leading to improvements in the manuscript.  
- The inclusion of AlphaFold2 results demonstrates a commitment to enhancing the reliability of their findings.  

Weaknesses:  
- Data availability issues, such as dead links and inconsistencies in naming conventions across various platforms, hinder the accessibility of the benchmark.  
- The paper lacks a thorough discussion of prior benchmarks and relevant literature, particularly regarding the Atom3D dataset.  
- Some acronyms, like 'sc-TM', are not defined, which may confuse readers unfamiliar with the terminology.  
- The confidence metric's applicability for method comparison may require further justification, as it can be method-dependent.  
- The rationale for omitting perplexity in favor of confidence scores is not explicitly discussed, which may leave readers seeking clarification.  
- The variance in TM scores when using ESMFold raises concerns about the robustness of the results.  

### Suggestions for Improvement
We recommend that the authors improve data accessibility by ensuring functional links for dataset downloads and providing a maintenance plan for long-term availability. Additionally, we suggest that the authors explicitly discuss the relationship of their work to prior benchmarks, particularly the Atom3D dataset. Clarifying the distinction between general structure-based protein design and the specific task of predicting amino acid identities, referred to as "inverse folding," would enhance reader comprehension. Furthermore, we encourage the authors to benchmark physics-based methods alongside deep learning models to provide a more comprehensive evaluation. We recommend improving the clarity of the confidence score metric by discussing its method-dependent nature and considering additional processing for comparisons. We suggest including a Maintenance Plan section in the manuscript to outline how the dataset will be updated regularly. We advise that the authors expand the discussion of related work in the paper, utilizing the extra page available for revisions, and ensure that all acronyms are defined upon first use to aid clarity for all readers. Lastly, we recommend that the authors improve the discussion surrounding the choice of using confidence scores instead of perplexity, providing explicit reasons for this decision, and consider including more protein folding models for a more comprehensive comparison of structure predictions.