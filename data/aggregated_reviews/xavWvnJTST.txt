ID: xavWvnJTST
Title: Feedback control guides credit assignment in recurrent neural networks
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 7, 6, 5, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 2, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an exploration of the relationship between feedback control and learning in recurrent neural networks (RNNs), specifically focusing on how feedback control enhances the adaptation of RNNs to perturbations during a motor control task. The authors propose that feedback control allows for faster adaptation without plasticity, improves the reliability of approximations to the recurrent time-variant learning (RTRL), and incorporates second-order information into weight updates. The findings suggest that feedback signals align well with the optimal global gradient, enhance the network's ability to weigh current information during perturbations, and indirectly inject second-order information.

### Strengths and Weaknesses
Strengths:
- The paper addresses an important and understudied question regarding the interplay between feedback and learning.
- The writing is clear, and the experiments are well-designed and executed, supporting the claims made.
- The alignment of feedback signals with the true gradient is a significant result that aids in understanding feedback mechanisms.

Weaknesses:
- The chosen task may not adequately demonstrate "out of equilibrium dynamics," as it primarily involves reaching a static target, which could limit the conclusions drawn about trajectory learning.
- The claim of biological relevance is undermined by the use of backpropagation through time (BPTT) during pretraining, which is not biologically plausible.
- The paper lacks clarity in defining key terms, such as "inference learning," and some experimental claims are not convincingly supported by the data.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the introduction by explicitly defining key terms like "inference learning" and ensuring that the key findings are clearly articulated. To strengthen the claims regarding trajectory learning, the authors should consider selecting a more complex task than simply reaching a static target, such as a limit cycle. Additionally, we suggest that the authors clarify the relationship between feedback control and biological plausibility, particularly regarding the reliance on BPTT. It would be beneficial to include a BPTT-c/RTRL-c baseline to disambiguate the effects of feedback control from approximate gradient estimation. Lastly, we recommend revising the title to reflect the use of RNNs as models rather than implying they are biological circuits.