ID: O2UwxfhY1P
Title: On the Comparison between Multi-modal and Single-modal Contrastive Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a theoretical analysis comparing single-modal and multi-modal contrastive learning. The authors prove that single-modal contrastive learning generally performs worse on test datasets after training, while multi-modal learning exhibits better generalization. They develop a unified framework to analyze optimization dynamics and generalization capabilities, emphasizing the role of signal-to-noise ratio (SNR) in the effectiveness of these learning methods. Theoretical findings are supported by small-scale simulated experiments.

### Strengths and Weaknesses
Strengths:
- The paper explores an important topic in contrastive learning and contributes a theoretical framework that enhances understanding of single-modal versus multi-modal approaches.
- It identifies SNR as a critical factor influencing generalization and demonstrates that multi-modal learning benefits from the cooperation of modalities.
- The authors provide a detailed theoretical analysis, including convergence guarantees and generalization bounds, supported by synthetic experiments.

Weaknesses:
- The proof contains significant issues, including:
  1. Problems with Assumption 4.1, such as incorrect use of big-O notations and unrealistic requirements on data dimensions.
  2. Undefined variables and unclear distinctions in assumptions, particularly regarding SNR.
  3. Theorems 4.2 and 4.3 lack clarity and proper definitions.
  4. Confusing definitions of loss derivatives and unproven lemmas used in subsequent proofs.
  5. Poor organization of the proof structure, making it difficult to follow connections between lemmas and the main text.
  6. The experimental validation is limited to synthetic data, lacking real-world dataset applications.

### Suggestions for Improvement
We recommend that the authors improve the clarity and correctness of the proofs by addressing the issues outlined in the weaknesses section, particularly the unrealistic assumptions and undefined variables. Additionally, we suggest that the authors provide more intuitive explanations of their theoretical results to enhance accessibility. Including discussions on practical strategies for improving existing contrastive learning methods based on their insights would also strengthen the paper. Finally, we encourage the authors to validate their findings with experiments on real-world datasets to enhance the paper's impact.