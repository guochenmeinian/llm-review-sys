ID: 93qSRpucpN
Title: Robust Guided Diffusion for Offline Black-box Optimization
Conference: NeurIPS
Year: 2024
Number of Reviews: 31
Original Ratings: 6, 5, 6, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents RGD, a novel method for integrating classifier guidance into classifier-free guidance diffusion models aimed at solving offline black-box optimization (BBO) problems. The authors propose a Proxy Refinement procedure that minimizes KL divergence between the Proxy distribution and diffusion distribution regarding \(y\). Additionally, the paper introduces a proxy-enhanced sampling module that integrates two key components: (1) proxy-free diffusion guidance, which does not rely on proxy gradients, and (2) explicit proxy guidance, which directs the sampling process toward high-property regions by optimizing the scalar strength parameter \(\omega\). Experimental results and ablation studies demonstrate that RGD outperforms state-of-the-art baselines, validating the effectiveness of its components and the innovative use of diffusion-derived distribution priors for proxy refinement.

### Strengths and Weaknesses
Strengths:
- The idea is intuitive and well-articulated, making it easy for readers to grasp the limitations of prior methods and the advantages of RGD.
- The paper is well-organized and includes strong experimental results and detailed ablation studies that enhance the credibility of the proposed method.
- The integration of proxy-free diffusion guidance and explicit proxy guidance effectively addresses the risk of overfitting while enhancing model robustness.
- The regularization of the proxy using the diffusion model is an interesting approach, and optimizing the alpha parameter in an offline manner aligns well with the offline setup.
- The innovative use of diffusion-derived distribution priors for proxy refinement is a significant advancement over previous methods.

Weaknesses:
- The technical contribution appears incremental, extending previous work without sufficient discussion on the relationship with existing literature.
- Some technical details are unclear, particularly regarding the computation of \(p_\theta(\hat{\boldsymbol{x}} | y)\) and the derivation of Equation (10).
- The derivation of Equation (10) has raised concerns regarding its reliance on Tweedieâ€™s formula, which may not have been adequately clarified.
- The additional proxy training and refinement procedures increase computational costs and introduce numerous hyperparameters, raising concerns about potential overfitting in offline BBO tasks.
- The paper lacks comparisons with relevant approaches and does not adequately address the out-of-distribution problem.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the technical details, particularly in the computation of \(p_\theta(\hat{\boldsymbol{x}} | y)\) and the derivation of Equation (10). Please explicitly detail how Equation (10) is derived from the reparametrization of \(X_t\) and the approximation of the Gaussian noise \(\epsilon \approx -\sigma(t) \cdot s_\theta(x_t)\). Additionally, provide a comprehensive discussion on the relationship between RGD and prior work, especially the paper "Diffusion Models for Black-Box Optimization," and incorporate a citation to the seminal work DDPM to provide a clearer conceptual framework for readers. 

We suggest including time comparisons with baselines to address the computational cost concerns and elaborating on how the proposed method mitigates overfitting risks. Furthermore, it would be beneficial to clarify the selection process for the initial designs and the handling of discrete tasks. Lastly, ensure that all relevant comparisons with existing methods are included in the results section to enhance the paper's robustness.