ID: Rllg9nOasE
Title: Multi-modal brain encoding models for multi-modal stimuli
Conference: NeurIPS
Year: 2024
Number of Reviews: 22
Original Ratings: 7, 6, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 2, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach using cross-modal and multi-modal models to align brain activity with naturalistic stimuli. The authors evaluate several unimodal Transformer models and investigate the impact of removing unimodal features from multi-modal representations on brain alignment. The study finds that multimodal models significantly outperform unimodal counterparts in certain language- and vision-related regions of the fMRI dataset. Additionally, the paper identifies two routes for establishing multimodal representations: simultaneous (joint) training (TVLT) and modality-specific training followed by cross-modal learning (IB-Concat). Both models achieve high brain alignment results, yet they exhibit different sensitivities to unimodal information loss, with TVLT showing less sensitivity and IB-Concat's performance degrading with unimodal input loss. These findings provide testable predictions for future empirical experiments in Cognitive Neuroscience.

### Strengths and Weaknesses
Strengths:
- The paper provides thorough imaging data analysis, including a detailed dataset description, comprehensive method comparisons, and clear results summarization, enhancing the study's robustness and transparency.
- The writing is clear and accessible, making complex methodologies and findings understandable for readers.
- The rigorous comparison of methods, including various variations, highlights the strengths and weaknesses of each approach.
- The paper offers significant insights into multimodal representation in the brain and generates novel testable predictions that can guide future empirical research.

Weaknesses:
- Figure captions lack detail; for instance, "Residual analysis" is vague, and Figure 5's colorbar range misrepresents the percentage.
- The feature removal process is confusing, and there is skepticism about its effectiveness. A probing analysis is recommended to establish feature removal reliability.
- The paper does not consider baseline comparisons with randomly initialized models, which is crucial for understanding architectural bias.
- The train-test settings may lead to information leakage due to temporal relationships, and the data collection process should be blocked to avoid inter-data correlation.
- There appears to be some confusion regarding the evaluation process among reviewers, which may affect the clarity of feedback.

### Suggestions for Improvement
We recommend that the authors improve figure captions for clarity and detail. Additionally, we suggest providing a more intuitive explanation of the feature removal process and conducting a probing analysis to verify its effectiveness. The authors should consider including baseline comparisons with randomly initialized models to characterize architectural bias. Furthermore, addressing potential information leakage in train-test settings and blocking data collection to avoid inter-data correlation would strengthen the study. Lastly, we encourage the authors to clarify the claim regarding language as a sensory modality and provide a more detailed analysis of the performance with and without alignment of video and audio stimuli. Improving communication clarity regarding the evaluation process will also help avoid misunderstandings among reviewers and enhance the manuscript's impact.