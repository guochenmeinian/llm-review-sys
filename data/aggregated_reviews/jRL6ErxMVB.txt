ID: jRL6ErxMVB
Title: Learning Better with Less: Effective Augmentation for Sample-Efficient Visual Reinforcement Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 5, 6, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive analysis of data augmentation (DA) in visual reinforcement learning (RL), introducing two methods: Random PadResize (Rand PR) and Cycling Augmentation (CycAug). The authors conduct extensive experiments on the DeepMind Control suite and CARLA, demonstrating that CycAug enhances sample efficiency while addressing the challenges of DA in RL. The paper also proposes guidelines for maximizing DA's potential, focusing on spatial diversity and multi-type DA fusion schemes.

### Strengths and Weaknesses
Strengths:
1. The attributes of data augmentation are systematically categorized and well-studied, supported by extensive experiments.
2. Rand PR is a novel augmentation method that retains all information, addressing the challenges of augmentation in RL.
3. CycAug effectively mitigates disturbances caused by excessive variations, showcasing thoughtful consideration of augmentation strategies.
4. The writing is clear and well-structured, facilitating comprehension of key concepts and methodologies.

Weaknesses:
1. The paper lacks novelty, as the properties of data augmentation and the problem of hardness in RL are well-known issues.
2. The performance improvements of the proposed methods are limited, with sample efficiency closely resembling DrQ-v2, raising questions about the universality of the improvements.
3. There is a lack of ablation studies or qualitative analysis to isolate the contributions of each component of the proposed methods.
4. The paper does not compare the proposed methods with existing DA techniques explicitly designed for visual RL, limiting the understanding of their strengths and limitations.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their contributions by addressing the well-known issues of DA in RL more innovatively. Additionally, we suggest incorporating more extensive experiments across a broader range of environments, such as Habitat or AI2THOR, to validate the generalizability of their findings. We also encourage the authors to include ablation studies that analyze the individual contributions of Rand PR and CycAug, as well as comparisons with existing DA techniques like Spectrum Random Masking or PlayVirtual. Lastly, providing a clearer discussion of the limitations of the proposed methods would enhance the paper's comprehensiveness.