ID: XmS9J3Lvip
Title: Towards Formality-Aware Neural Machine Translation by Leveraging Context Information
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method to enhance machine translation quality by utilizing a formality classifier to regularize attention mechanisms, thereby improving the model's reliance on formality markers. The authors propose a global loss function that emphasizes the importance of lexical items relevant to formality-controlled translation. Empirical tests show BLEU score improvements and favorable human preferences for the proposed method across two translation directions (En -> Ja, En -> Ko). The evaluation of attention patterns indicates a stronger alignment with human formality rationales compared to standard models.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and effectively contextualizes the proposed method.
- The approach of leveraging model rationales to regularize training is novel and interesting.
- The upweighting of specific lexical items in the loss function is a significant contribution.
- Promising human evaluation results provide preliminary evidence of the method's effectiveness.
- The evaluation of attention patterns suggests a strong alignment with human intuition.

Weaknesses:
- The evaluation lacks rigor, raising doubts about the method's effectiveness for formality-controlled MT.
- BLEU is not suitable for evaluating granular phenomena like formality markers, and important details about human evaluation are omitted.
- The use of SacreBLEU with the 13a tokenizer for Japanese and Korean may yield non-comparable results.
- The evaluation merges document-level datasets not specific to formality, missing opportunities for granular assessment.
- The proposed method's reliance on reference translations limits practical applicability.

### Suggestions for Improvement
We recommend that the authors improve the evaluation rigor by conducting statistical significance testing with bootstrap resampling and reporting standard deviations for both baselines and the proposed method. Additionally, creating a dedicated formality test set would better highlight the improvements achieved. We suggest including neural metrics such as chrF and COMET to complement BLEU scores, as they correlate better with human judgment. Furthermore, the authors should analyze the overhead introduced by extracting token-level formality scores and provide compute-matched baselines. Lastly, clarifying the sensitivity of training convergence to hyperparameter choices and addressing the use of the formality classifier during evaluation would enhance the paper's robustness.