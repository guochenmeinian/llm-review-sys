ID: ocxVXe5XN1
Title: Generalization Bounds via Conditional $f$-Information
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 6, 7, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel framework for generalization bounds using conditional f-information, deriving bounds for bounded and unbounded loss scenarios. The authors propose that their approach improves upon existing bounds by utilizing a quadratic Taylor expansion of various f-divergences, demonstrating the potential looseness of previous conditional mutual information (CMI) bounds. Empirical comparisons validate the tightness of the proposed bounds against existing literature.

### Strengths and Weaknesses
Strengths:
- **Clear presentation**: The paper is well-structured, with definitions and theorems clearly articulated.
- **Empirical validation**: Despite its theoretical nature, the paper includes compelling empirical studies that showcase the effectiveness of the proposed bounds across various datasets.

Weaknesses:
- The results focus on expected generalization error, lacking high-probability guarantees, which are deemed more critical.
- Some derived bounds lead to tautological statements, raising questions about their practical significance.
- The motivation for using f-divergences over KL divergence is not sufficiently clarified, and the proofs may not offer new insights compared to existing literature.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the expected generalization error definition on page 3, ensuring it accurately reflects the intended formula. Additionally, in the “Other Fast-Rate Bound Cases” section, the authors should provide concrete examples where \( \mathbb{E}[\Delta L^2_i] \lesssim \text{Var}(L_i^{+}) \) holds. To enhance the presentation, we suggest including a comparative table in the appendix that systematically contrasts their bounds with prior work, making it easier for readers to grasp the advantages of their contributions. Finally, the authors should address the circularity of their bounds and clarify the significance of including terms like \( \Delta L_i^2 \) in their results.