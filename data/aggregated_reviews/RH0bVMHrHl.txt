ID: RH0bVMHrHl
Title: Mirror Gradient: Towards Robust Multimodal Recommender Systems via Exploring Flat Local Minima
Conference: ACM
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel gradient strategy, Mirror Gradient (MG), aimed at enhancing the robustness of multimodal recommender systems by guiding model parameters towards flat local minima during optimization. The authors provide both theoretical analysis and empirical validation, demonstrating MG's effectiveness across various multimodal recommendation models. The approach is positioned as a potentially groundbreaking method that can complement existing robust training techniques.

### Strengths and Weaknesses
Strengths:
1. The idea of approximating flat local minima through alternative updating parameters with different learning ratios is intriguing and regularizes second-order derivation with first-order gradients.
2. The theoretical bound is intuitive, and the proof is easy to follow.
3. The analysis of robustness in multimodal recommender systems exhibits novelty, supported by strong theoretical backing and extensive empirical experiments.

Weaknesses:
1. The paper lacks a clear connection to the web, appearing more aligned with general machine learning rather than specifically addressing recommender systems.
2. There is insufficient statistical analysis, and the paper does not compare MG with other flat local minima methods.
3. The explanation of the MG strategy and its comparison with other methods is not detailed enough, leaving some aspects unclear.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the MG strategy by providing a more detailed explanation and comparison with existing methods, including regularization techniques like L1 and L2. Additionally, conducting experiments on information noise and adjustment under varying levels, as suggested in Tables 4 and 5, would enhance the empirical validation. It would also be beneficial to clarify the relationship of MG to previous methods in the related work section and to provide implementation details using PyTorch or TensorFlow to aid reproducibility. Finally, addressing the hyperparameter settings in the experiments and comparing MG with other flat local minima approaches would strengthen the paper's contributions.