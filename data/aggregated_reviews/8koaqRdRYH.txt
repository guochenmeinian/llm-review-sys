ID: 8koaqRdRYH
Title: Improving Neural Network Surface Processing with Principal Curvatures
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 6, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the use of principal curvature as a surface representation to enhance performance in modern neural network architectures for 3D tasks. The authors propose that intrinsic properties of curvatures facilitate more effective learning compared to traditional representations like point coordinates. They conduct evaluations comparing the performance of networks utilizing curvatures against those using other intrinsic properties, demonstrating superior results in several task categories.

### Strengths and Weaknesses
Strengths:
- The paper provides a comprehensive overview of classic surface representations and popular architectures in geometric deep learning.
- It effectively demonstrates performance improvements across three distinct neural network pipelines, highlighting the computational efficiency of curvature-based descriptors.

Weaknesses:
- The novelty of using surface curvature in neural networks is limited, as this approach is not entirely new.
- The paper inadequately addresses inherent limitations of using curvatures, such as their sensitivity to noise and the challenges of orienting normals in point clouds.
- Section 3 is overly lengthy and lacks clarity, with mathematical presentations being disorganized and definitions not properly indexed.
- The analysis of the performance reduction in classification tasks is insufficient, and there is no benchmarking against transformer-based architectures.

### Suggestions for Improvement
We recommend that the authors improve the clarity and organization of Section 3 by properly indexing mathematical formulations and providing clearer definitions. Additionally, we suggest including a discussion on the limitations of using curvature, particularly regarding orientation dependencies and noise sensitivity. It would also be beneficial to benchmark against transformer-based architectures and provide a more thorough analysis of the performance discrepancies observed in classification tasks. Lastly, addressing the questions raised about the ability of Delta Net and Diffusion Net to compute Gaussian curvature from principal curvatures would enhance the paper's depth.