ID: eXNyq8FGSz
Title: Active Learning of General Halfspaces: Label Queries vs Membership Queries
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 7, 7, 5, 7, 6, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 3, 3, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper studies the problem of actively learning non-homogeneous half-spaces under Gaussian distribution, focusing on two models: label queries and membership queries. It establishes that in the pool-based model, active learners cannot outperform passive learners in terms of label complexity unless exponentially many unlabeled examples are drawn. Conversely, it demonstrates that in the membership query model, an active learner can surpass the passive learner, indicating a separation between these two models. The paper provides a nearly tight lower bound for label queries and an efficient upper bound for membership queries.

### Strengths and Weaknesses
Strengths:
- The paper addresses an important open problem in learning theory, providing a novel result regarding the limitations of learning non-homogeneous half-spaces under standard label queries.
- The method proposed is technically sound and non-trivial, with clear writing and well-defined notations.
- The organization of the paper is effective, offering sufficient motivation and background information.

Weaknesses:
- The conclusion regarding the pool-based model's limitations is not fully convincing, as it lacks explicit dependence on $\epsilon$ in Theorem 1.1, raising questions about the tightness of the lower bound.
- The paper's technical complexity increases towards the end, making it harder to follow, particularly in section 3.
- There is a lack of discussion on future research directions and potential extensions of the results to broader distributions.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the introduction to better relate the upper and lower bounds. It would be beneficial to provide a "technical overview" section to separate high-level ideas from technical details. Additionally, including examples in section 3 could enhance understanding, and moving some lemmas to the appendix may help streamline the presentation. We also suggest adding a conclusion section to discuss future research directions and the possibility of extending results to more general distributions, such as log-concave distributions. Finally, addressing minor typographical errors would improve the overall quality of the paper.