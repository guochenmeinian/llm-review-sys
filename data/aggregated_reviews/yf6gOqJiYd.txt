ID: yf6gOqJiYd
Title: CodeUnlearn: Amortized Zero-Shot Machine Unlearning in Language Models Using Discrete Concept
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 7, 1, 7, 6, 5
Original Confidences: 3, 5, 3, 4, 2

Aggregated Review:
### Key Points
This paper presents a novel algorithm for zero-shot machine unlearning, termed **CodeUnlearn**, which utilizes a codebook of the model's output to remove specific concepts without retraining. The authors propose a framework that combines discrete codebook features with Sparse Autoencoders (SAEs) to effectively address challenges faced by traditional unlearning techniques, such as high computational costs and limited scalability. The methodology is well-structured, supported by mathematical formulations, and includes experimental validation demonstrating the effectiveness of CodeUnlearn on various topics.

### Strengths and Weaknesses
Strengths:
- The use of discrete codebooks for unlearning is innovative and has not been previously applied to large language models (LLMs).
- The method is scalable and avoids the computational costs associated with retraining, making it suitable for large models.
- The paper provides clear experimental validation with appropriate metrics (BLEU, METEOR, BERTScore) that illustrate the method's practical utility.

Weaknesses:
- The paper exceeds the page limit set by submission guidelines.
- There is a lack of experimentation on standard datasets, leaving the effectiveness of the proposed algorithm unclear.
- The memory size of the codebook is not specified, raising concerns about scalability.
- The granularity of the unlearning process is not sufficiently explored, and the impact on synonyms and related concepts requires more analysis.
- The computational efficiency of the method is not thoroughly analyzed, and its generalization to other architectures beyond T5 is unclear.

### Suggestions for Improvement
We recommend that the authors improve the paper's adherence to submission guidelines by reducing its length. Additionally, conducting experiments on standard NLP benchmarks would clarify the effectiveness of the proposed algorithm. The authors should provide details on the memory size of the codebook to address scalability concerns. Expanding the discussion on the granularity of unlearning and the impact on related concepts would enhance the work's generalizability. A detailed analysis of computational overhead and a comparison with state-of-the-art methods would strengthen the claims of scalability. Finally, the authors should clarify how the method can be generalized to architectures beyond T5 to increase its relevance.