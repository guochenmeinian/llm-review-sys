ID: yiXZZC5qDI
Title: From Trojan Horses to Castle Walls: Unveiling Bilateral Data Poisoning Effects in Diffusion Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to poisoning attacks on diffusion models (DMs) by solely altering the training data, as opposed to modifying the training process or optimization objectives. The authors demonstrate that inserting a trigger into training images and changing their labels leads to DMs generating images misaligned with prompts and amplifying trigger patterns. The study reveals significant insights into the vulnerabilities of DMs and proposes defensive strategies, including the 'Castle Walls' concept, which leverages trigger amplification for detecting poisoned data.

### Strengths and Weaknesses
Strengths:
- The paper addresses a critical issue regarding the risks of poisoned data in DMs trained on publicly available datasets.
- The discovery that DMs can generate target class images with triggers absent in training data is intriguing.
- The research is well-structured, with comprehensive experimental analysis and clear communication of findings.

Weaknesses:
- The experimental evaluation is limited to three datasets (CIFAR-10, ImageNette, and Caltech15), raising concerns about generalizability.
- The paper lacks clarity in conveying the main take-away message, making it difficult to grasp its implications.
- The proposed defense method using "poisoned DMs" is impractical, as it requires prior training on poisoned data before classifier training.
- The absence of error bars in experiments raises questions about the robustness of the results.

### Suggestions for Improvement
We recommend that the authors improve clarity by explicitly stating the main take-away message and ensuring that the experimental results are easily accessible, particularly those in the appendix. Additionally, we suggest expanding the evaluation to include more datasets, such as ImageNet1K and CIFAR-100, to enhance generalizability. To strengthen the findings, please include statistical measures like confidence intervals to validate the robustness of the results. Furthermore, we encourage the authors to provide detailed guidelines for the practical implementation of the 'Castle Walls' defensive strategies in real-world scenarios. Lastly, discussing the broader societal implications of data poisoning would enrich the paper's impact.