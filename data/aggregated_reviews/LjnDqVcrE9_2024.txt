ID: LjnDqVcrE9
Title: ControlMLLM: Training-Free Visual Prompt Learning for Multimodal Large Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 3, 4, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a training-free method to integrate visual prompts into multimodal large language models (MLLMs) using learnable latent variables. The authors propose optimizing these variables to enhance attention responses to visual tokens during inference, thereby improving the model's focus on specific visual regions. The approach is empirically validated on referring classification tasks, leveraging the foundation of LLaVA.

### Strengths and Weaknesses
Strengths:
- The proposed method does not require additional training for unseen datasets.
- The paper is generally clear and easy to follow, with helpful figures illustrating attention maps.
- The approach is theoretically plug-and-play with different foundation models and demonstrates effective out-of-domain generalization.

Weaknesses:
- The writing quality is poor, with inconsistent use of abbreviations and grammatical errors throughout the text.
- The paper lacks novelty, presenting an incremental advancement without innovative contributions.
- Experimental results are insufficient, lacking comparisons with numerous baselines such as LLaVA1.5, LLaVA-NeXT, Monkey, and Qwen-VL.
- The generalization ability of the method is not fully verified, raising concerns about its applicability beyond LLaVA and its sensitivity to hyperparameters.
- The motivation for the study is insufficient, with a need for clearer and more comprehensive prompt descriptions.

### Suggestions for Improvement
We recommend that the authors improve the writing quality by ensuring consistent use of abbreviations and correcting grammatical errors. Additionally, the authors should enhance the novelty of their work by incorporating more innovative elements. We suggest including a broader range of experimental baselines to validate the effectiveness of the proposed method. Furthermore, it would be beneficial to discuss the generalization ability of the method more thoroughly and address the potential limitations related to the reliance on segmentation models and hyperparameter sensitivity. Finally, we advise the authors to clarify the motivation for their study and consider the implications of incorrect region signals during optimization.