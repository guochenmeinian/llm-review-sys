ID: k4EP46Q9X2
Title: Unveiling the Potential of Robustness in Selecting Conditional Average Treatment Effect Estimators
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 8, 8, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for selecting a conditional average treatment effect (CATE) estimator using a distributionally robust metric (DRM) that is nuisance-free and robust against selection bias. The authors derive the optimization objective for DRM, propose a tractable relaxation using observed data, and conduct extensive benchmarking against existing model selection criteria. Additionally, the paper explores consistent estimators for CATE using k-NN as an instantiation of the T-learner, arguing that distribution shifts primarily affect CATE estimation in low-sample regimes, while universal function approximators can consistently estimate treatment effects in large-sample contexts. The paper is deemed interesting and thought-provoking, warranting a higher evaluation score.

### Strengths and Weaknesses
Strengths:
- The DRM criterion significantly contributes to CATE model selection by eliminating the need for training additional nuisance models, which can lead to sub-optimal choices.
- The theoretical formulation of DRM is compelling, linking the upper bound to the distribution shift between treatment and control groups.
- The paper is well-structured, with clear methodology and thorough experimental validation.
- It provides valuable insights into the consistency of k-NN as a CATE estimator and engages with relevant literature, enhancing its academic rigor.

Weaknesses:
- The introduction lacks clarity regarding the key research question and the limitations of previous methods, making it non-informative.
- Misleading statements confuse unit-level treatment effects with conditional treatment effects, necessitating clearer distinctions.
- The empirical analysis is limited by the use of only three base ML models, which restricts the diversity of CATE estimators considered.
- High variance in baseline performance raises concerns about the robustness of comparisons, and the paper lacks transparency in the experimental setup.
- The discussion lacks consideration of recent concurrent works that address similar problems in CATE model selection and validation.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the introduction by explicitly defining the key research question and illustrating the limitations of previous methods with examples. Additionally, please ensure that the distinction between CATE and unit-level treatment effects is clearly articulated. To enhance the empirical analysis, consider training a larger number of CATE estimators to provide a more comprehensive evaluation of the DRM criterion's performance. Furthermore, clarify the experimental setup for baseline metrics and address the high variance in results by providing detailed insights into performance trends across datasets. We also recommend incorporating discussions on the recent concurrent paper from ICML 2024, which utilizes a total variation distance to bound the counterfactual term of the PEHE risk and compares it with integral probability metrics. Additionally, we suggest expanding the discussion on the usage of Wasserstein distance in the proposed DRM method and conducting a comparative analysis of the advantages and disadvantages of using IPM (such as Wasserstein or MMD) and f-divergence versus KL-divergence.