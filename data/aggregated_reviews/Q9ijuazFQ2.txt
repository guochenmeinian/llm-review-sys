ID: Q9ijuazFQ2
Title: MMLSCU: A Dataset for Multi-modal Multi-domain Live Streaming Comment Understanding
Conference: ACM
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel multimodal, multi-domain live streaming comment dataset named MMLSCU, aimed at analyzing user comments to enhance live streaming quality. The authors propose an end-to-end model utilizing the Chain of Thought (CoT) framework to perform tasks such as audience comment intent detection and streamer policy suggestion. The dataset includes four annotation types and serves as a significant resource for the live streaming research community.

### Strengths and Weaknesses
Strengths:
- The paper addresses a novel problem in mining user comments within online live streaming, contributing to research through a newly annotated dataset that is open-sourced.
- The integration of multimodal data (video, audio, text) and the use of pre-trained encoders enhance the model's reasoning capabilities.
- Empirical results demonstrate the advantages of the proposed method over unimodal approaches.
- The clarity of the paper's structure and illustrations aids reader comprehension.

Weaknesses:
- The reliance on comment content alone for generating explanations may lead to unreliable outcomes, even after manual filtering.
- The annotation process for streamer policy suggestions is subjective, potentially misrepresenting viewer intentions.
- The multi-turn conversation process for generating suggestions is inefficient due to multiple Large Language Model (LLM) inferences.
- The dataset's size (200 clips) may limit fine-grained analysis, and the paper lacks details on the specific LLM used and the model's fine-tuning process.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the dataset annotation process, particularly for comment explanations and streamer policy suggestions. Additionally, consider optimizing the multi-turn CoT process into a single-turn approach to enhance computational efficiency. It would also be beneficial to provide more comprehensive details on the experimental comparisons and the specific LLM employed in the model. Lastly, addressing the criteria for distinguishing user suggestions from general conversation would strengthen the paper's contributions.