ID: zTSlm4nmlH
Title: Beta Diffusion
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 6, 7, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel diffusion model utilizing beta distributions to address the limitations of Gaussian assumptions in both forward and reverse processes. The authors introduce a forward noising process conditioned on initial data samples, leading to a bi-variate beta distribution with marginals that are also beta distributions. They propose to reverse this distribution by learning the conditional distribution and optimizing it through a KL divergence upper bound (KLUB), which is shown to outperform the standard ELBO in certain contexts. The methodology is demonstrated on synthetic datasets, showcasing the model's ability to effectively generate range-bounded data. Additionally, the authors explore KLUB-based objectives in the context of beta diffusion, acknowledging the applicability of KLUBs to Gaussian diffusion while limiting their claims to beta diffusion models. They plan to include CIFAR10 results and discussions comparing their work with references [1-5].

### Strengths and Weaknesses
Strengths:
- The work is clearly presented and easy to understand.
- It explores alternatives to Gaussian diffusion, contributing to the discussion on non-additive noise diffusion models.
- The proposed KLUB offers a new objective function that enhances the beta diffusion process.
- Experimental results indicate the model's effectiveness in synthetic settings.
- The authors effectively addressed previous concerns, leading to a higher score and recommendation for acceptance.
- They demonstrate a clear understanding of KLUBs and their theoretical grounding, particularly in relation to beta diffusion models.
- The commitment to include additional experiments and clarifications, such as the ablation study on the concentration parameter, enhances the paper's rigor.

Weaknesses:
- The paper lacks evaluation on real-world datasets, limiting its practical applicability.
- There is insufficient discussion of related works, particularly recent studies that also utilize beta distributions in diffusion processes.
- The experiments primarily focus on synthetic datasets, raising questions about the model's performance on more complex, non-toy datasets.
- The manuscript does not adequately address the limitations of the proposed approach.
- The portrayal of KLUBs as a general optimization method for diffusion models may be misleading, as it primarily improves beta diffusion.
- Certain aspects, such as the relationship between beta diffusion and the Jacobi process, require further clarification.

### Suggestions for Improvement
We recommend that the authors improve the discussion of related work, particularly by including comparisons to recent studies that also explore beta diffusion models. Additionally, we suggest incorporating real-world data evaluations to demonstrate the practical utility of the proposed methods. The authors should clarify the rationale behind hyperparameter choices and provide more comprehensive ablation studies to explore the design space of beta diffusion. Furthermore, we recommend improving the clarity of claims regarding KLUBs, explicitly stating that their effectiveness is primarily for beta diffusion models. Please ensure that the related work discussion and CIFAR10 experiments are included in the revised paper, along with a detailed comparison with references [1-5]. Finally, we suggest emphasizing the following points: closed-form forward processes, convergence to $Beta(0, \eta)$, the relationship between forward vs. reverse KL and KLUB vs. -ELBO, and the connection with [Pavel et al. 2023]. A thorough discussion of the limitations of the work would also enhance the manuscript's depth and rigor.