ID: 26QVTwbqyN
Title: Query2GMM: Learning Representation with Gaussian Mixture Model for Reasoning over Knowledge Graphs
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Query2GMM, a method utilizing Gaussian Mixture Models (GMM) for logical query answering over knowledge graphs. The authors propose a multi-modal distribution approach to represent queries and knowledge graph entities in a shared embedding space, enhancing the representation of complex answer sets. The method incorporates a novel Wasserstein Distance metric and demonstrates its effectiveness through extensive experiments on benchmark datasets, outperforming state-of-the-art methods in many cases.

### Strengths and Weaknesses
Strengths:
- The method is novel and technically valuable for logical query answering.
- The paper is well-motivated and grounded in recent literature.
- Strong experimental results, particularly from extensive ablation studies.
- Clear and logical presentation of the work.

Weaknesses:
- The role of cardinality is not adequately demonstrated, and the principle behind its action requires further clarification.
- Some sentences are repetitive and lack conciseness.
- The related work section is positioned at the end, which may hinder understanding.
- The empirical evaluation lacks clarity regarding the origin and characteristics of the queries presented in Table 1.

### Suggestions for Improvement
We recommend that the authors improve the explanation of the mechanism of cardinality's role in modeling multi-modal Gaussian mixture distribution learning for reasoning. Additionally, please clarify how the new mixed Wasserstein distance accurately models the reasoning process. We suggest moving the related work section to the front of the paper to address questions that arise during the reading. It would also be beneficial to empirically back up claims regarding the inadequacy of logical pattern matching methods for incomplete knowledge. Furthermore, please clarify the origin and characteristics of the queries in Table 1 to enhance the assessment of the solution's usefulness. Lastly, consider addressing the lack of interpretability and uncertainty in preserving the properties of First-Order Logic operations in your neural models.