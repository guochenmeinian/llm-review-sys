ID: 2vywag2lVC
Title: Last-Iterate Global Convergence of Policy Gradients for Constrained Reinforcement Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 4, 6, 5, 7, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a primal-dual method, C-PG, to address the constrained reinforcement learning (RL) problem, extending it to C-PGAE and C-PGPE for cases involving risk measures. The authors provide a theoretical analysis demonstrating global last-iterate convergence guarantees for C-PG and validate the proposed algorithms through numerical examples. The paper also explores policy-based methods in constrained RL, establishing convergence under gradient domination assumptions.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and easy to follow, with clear descriptions of the problem setup, theorems, and assumptions.
- The theoretical results, particularly regarding last-iterate convergence, contribute meaningfully to the literature, even if not entirely novel.
- The numerical experiments validate the theoretical claims, supporting the proposed methods.

Weaknesses:
- The technical novelty is limited, as the primal-dual method and regularization terms are well-established in constrained optimization, leading to marginal theoretical contributions.
- Section 4 lacks clarity and appears as an add-on without substantial theoretical results, diminishing its significance.
- The experimental scenarios are relatively simple, and the paper does not sufficiently address the dimension-free property of the proposed algorithm or the impact of the regularization term on convergence rates.

### Suggestions for Improvement
We recommend that the authors improve the clarity and significance of Section 4 by providing more general theoretical results. Additionally, the authors should discuss the proof ideas for Theorems 3.1 and 3.2 in the main text. It would also be beneficial to include more complex experimental results, such as cost constraints on MuJoCo, and to clarify the contribution of the parameter-based hyperpolicy. Finally, addressing the questions regarding the dimension-free property and the impact of the regularization term on convergence rates would strengthen the paper.