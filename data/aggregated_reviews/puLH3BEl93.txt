ID: puLH3BEl93
Title: Improving Zero-shot Reader by Reducing Distractions from Irrelevant Documents in Open-Domain Question Answering
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method to enhance open-domain question answering (QA) by addressing hallucination issues caused by irrelevant documents. The authors propose Hallucination-aware Answer Selection (HAS) as part of a two-stage pipeline, which includes an "unanswerable" instruction to prompt the model to abstain from answering when context is insufficient and a score regulation mechanism to adjust answer confidence based on document relevance. Empirical results demonstrate significant improvements in exact match (EM) scores, achieving increases of up to 231%.

### Strengths and Weaknesses
Strengths:
- The proposed HAS method shows clear empirical efficacy in mitigating hallucination, with substantial EM improvements across various datasets.
- The approach is validated through experiments on multiple models, indicating robustness to irrelevant document addition.

Weaknesses:
- The novelty of the method is questioned, as similar techniques have been explored in prior works, and the clarity of the abstention mechanism is lacking.
- The choice of models (FLAN-T5-XL and OPT-IML-MAX) may limit the generalizability of results, as larger and more popular models were not tested.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the abstention mechanism description to elucidate what constitutes the unanswerable set. Additionally, we suggest exploring larger models to assess the performance of HAS, as well as considering alternative frameworks that leverage LLM capabilities more effectively. Finally, we advise revising the title to better reflect the focus on filtering irrelevant documents rather than directly addressing hallucination in LLMs.