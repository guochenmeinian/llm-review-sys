ID: 4L3RfWnDzL
Title: Object-centric Learning with Cyclic Walks between Parts and Whole
Conference: NeurIPS
Year: 2023
Number of Reviews: 18
Original Ratings: 6, 7, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to unsupervised object-centric learning by introducing a contrastive cyclic walk loss, diverging from traditional reconstruction loss methods. The authors leverage this loss to establish correspondence between object features and pixel features, demonstrating the method's effectiveness through extensive experiments across three object-centric learning tasks. The approach is noted for its memory and computational efficiency compared to reconstruction-based methods. Additionally, the paper highlights an experiment on CLEVRTex, showcasing the performance of Slot Attention when combined with a deeper CNN backbone. The authors acknowledge potential limitations due to domain shifts when using a frozen DINO encoder pre-trained on ImageNet and differentiate their approach from the Invariant Slot Attention by introducing cyclic walks between slots and feature maps as supervision signals, eliminating the need for decoders.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant problem in unsupervised object-centric learning with a novel method that effectively utilizes contrastive cyclic walks.
- The experiments are rigorous, covering a wide range of datasets and metrics, showcasing the method's effectiveness.
- The writing is clear, and the key ideas are well-conveyed through figures.
- The experiment provides valuable insights into the performance of Slot Attention on CLEVRTex.
- The authors' approach introduces innovative supervision signals to enhance slot representation quality without requiring decoders.

Weaknesses:
- The absence of reconstruction loss may lead to a loss of crucial object information for downstream tasks, and relevant experiments to explore this are lacking.
- There is no discussion regarding scenarios where the number of slots exceeds the number of objects, which could lead to redundant slot assignments.
- Missing comparisons with certain baselines, such as KMeans clustering on frozen DINO features, limit the evaluation of the Slot Attention module's contribution.
- The performance on CLEVRTex is inferior compared to Slot Attention, which may limit the method's applicability for semantic segmentation.
- The paper does not adequately clarify the method's focus on semantic segmentation, nor does it attempt to surpass the 91.3% score of Slot Attention on CLEVRTex.

### Suggestions for Improvement
We recommend that the authors improve the paper by including experiments that predict object properties from slot features to assess the impact of omitting reconstruction loss. Additionally, a discussion on the implications of having more slots than objects in the scene should be included. We suggest adding visualizations of the model's performance on the Movi-C and Movi-E datasets, as well as clarifying how to compute the mask from $M_{x,\hat{s}}$. Furthermore, we recommend that the authors improve the discussion of their results by incorporating recent findings, particularly the performance of Slot Attention with a ResNet encoder. The authors should clarify the method's primary focus on semantic segmentation and consider strategies to exceed the 91.3% FG-ARI benchmark. Lastly, it would be beneficial to cite the Invariant Slot Attention paper and elaborate on the distinctions between their approach and the proposed invariant slot attention method in Section 2 of the revised version.