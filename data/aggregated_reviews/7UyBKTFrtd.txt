ID: 7UyBKTFrtd
Title: Interpreting CLIP with Sparse Linear Concept Embeddings (SpLiCE)
Conference: NeurIPS
Year: 2024
Number of Reviews: 18
Original Ratings: 7, 6, 6, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method called SpLiCE, which enhances the interpretability of CLIP's vision-language representations by transforming them into sparse linear combinations of human-interpretable concepts through dictionary learning. The authors claim that this approach allows for interpretability without significantly compromising downstream performance, particularly in zero-shot classification tasks. They demonstrate the method's utility across various datasets and applications, including spurious correlation detection, bias detection, and model editing. However, reviewers express concerns regarding the accuracy-interpretability tradeoff, noting that a 4% drop in accuracy at high sparsity levels is significant, and the experimental setup for probing and the interpretability of the residual error are also points of contention.

### Strengths and Weaknesses
Strengths:
- The work addresses a crucial challenge of achieving interpretability without sacrificing performance, which is essential for practical adoption by practitioners.
- The paper is well-written, with a clear methodology and relevant focus on CLIP representations, enhancing its applicability to the community.
- The proposed method, SpLiCE, is characterized as effectively navigating the interpretability-accuracy Pareto frontier, and the inclusion of additional results and discussions enhances the paper's clarity and depth.

Weaknesses:
- The claim of providing interpretability "at no cost" to performance is misleading, as results indicate a significant accuracy drop in zero-shot classification with increased sparsity, contradicting the paper's core assertions.
- The paper lacks a comprehensive exploration of alternative existing solutions for sparse dictionary learning, limiting its technical contributions and insights.
- The assumptions made regarding the nature of CLIP representations are not adequately justified, raising concerns about their validity in practice.
- The probing experimental setup lacks clarity, and the interpretability of the residual error remains questionable.

### Suggestions for Improvement
We recommend that the authors improve the discussion surrounding the performance trade-offs associated with sparsity, explicitly addressing the accuracy costs observed in their experiments and clarifying the accuracy-interpretability tradeoff in the abstract and main text by stating that there is at least a "small" cost to performance. Additionally, we suggest conducting more extensive evaluations on standard zero-shot datasets to validate their claims and including a brief discussion of previous studies on sparsity levels in the results section to aid in interpreting Figure 3. The authors should also provide a richer exploration of alternative techniques for sparse representation learning, including comparisons to methods like non-negative KSVD and sparse autoencoders. Furthermore, we encourage the authors to conduct human evaluations to substantiate claims of improved interpretability and to clarify the probing experimental setup in Appendix C.1 to ensure that the performance retention of CLIP is accurately represented. Lastly, we advise considering omitting the residual error argument if it does not contribute to interpretability and revising the presentation to reduce unnecessary formalizations and enhance clarity, particularly by moving some technical details to supplementary materials.