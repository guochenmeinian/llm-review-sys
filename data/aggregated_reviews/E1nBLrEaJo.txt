ID: E1nBLrEaJo
Title: On the Benefits of Public Representations for Private Transfer Learning under Distribution Shift
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 7, 7, 6, 6, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into the use of public pretraining to enhance differentially private model training, particularly under distribution shifts such as concept shift. The authors demonstrate significant accuracy improvements and provide a theoretical framework that models public data as arising from a sequence of linear regression tasks, with features lying in a low-dimensional subspace. They develop a two-stage algorithm for public-private linear regression and analyze its performance through empirical results on simulated data.

### Strengths and Weaknesses
Strengths:
- The authors effectively highlight the limitations of existing public pre-training techniques, particularly in scenarios where public and private data distributions differ.
- The focus on concept shift as a general type of distribution shift is commendable.
- The writing style is clear, establishing research gaps and presenting a thorough alternative direction.
- Theorems are well-presented with Proof Sketches that enhance understanding.

Weaknesses:
- There is a strong assumption regarding the learnability of the shared low-dimensional representation across public and private data.
- The theoretical model appears overly simplistic and does not fully reconnect with the empirical results, leaving a gap in understanding the relationship between theory and practice.
- The experiments are limited to image classification, lacking exploration of additional data modalities.

### Suggestions for Improvement
We recommend that the authors improve the connection between their theoretical model and empirical results, possibly by comparing their model to other common models in the meta-learning literature. Additionally, exploring the nature of representations learned when public and private data are used independently could validate the assumption of a common representation space. Expanding the experimental scope to include various data modalities would also enhance the paper's contribution.