ID: NmlnmLYMZ4
Title: When does perceptual alignment benefit vision representations?
Conference: NeurIPS
Year: 2024
Number of Reviews: 18
Original Ratings: 6, 5, 4, 8, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates the benefits of aligning vision model representations with human perceptual judgments to enhance performance across various computer vision tasks. The authors propose image-level and patch-level learning objectives for fine-tuning pretrained models like CLIP and DINO on the NIGHTS dataset, which comprises human similarity judgments over synthetic image triplets. The results indicate that this alignment improves performance in tasks such as semantic segmentation, depth estimation, retrieval-augmented generation, counting, and instance retrieval, while also revealing that mid-level supervision is particularly beneficial.

### Strengths and Weaknesses
Strengths:
- The experimental evaluation is comprehensive, covering a wide range of tasks and utilizing multiple state-of-the-art models, which supports the main findings.
- The concept of aligning vision models with human perceptual judgments is innovative and well-articulated.
- The analysis provides nuanced insights into how different levels of perceptual judgments impact model performance.

Weaknesses:
- The paper lacks a conclusion section, and there are minor issues with citations and reference ordering.
- The evidence presented does not fully clarify how perceptual alignment affects model features as general-purpose representations.
- The investigation of CNN-based models is absent, and the effects of perceptual alignment on various downstream tasks are not sufficiently explored.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the contribution of local versus global alignment in their experiments. Additionally, more experiments on advanced vision-language models (e.g., Llava, MiniGPT-4, instructBLIP) should be included. It would also be beneficial to provide empirical analysis on why mid-level alignment yields better representations compared to other levels. Furthermore, addressing the performance drop in fine-grained classification tasks and clarifying the impact of dataset variations on model performance would enhance the paper's robustness. Lastly, we suggest including a conclusion section to summarize the findings and implications of the study.