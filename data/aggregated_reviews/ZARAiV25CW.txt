ID: ZARAiV25CW
Title: Generalized Bayesian Inference for Scientific Simulators via Amortized Cost Estimation
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 7, 6, 6, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach for simulation-based inference (SBI) by utilizing amortized cost estimation (ACE) through neural networks to estimate a generalized cost in generalized Bayesian inference (GBI). The authors demonstrate that ACE enhances computational efficiency without sacrificing performance across various evaluation metrics. They conduct extensive benchmarking across different dimensions and include real intracellular recordings, showcasing the method's applicability.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and maintains a clear structure, making it easy to follow.
- The proposed method is a valuable contribution to the field, addressing important issues in simulation-based inference and model misspecification.
- The experiments cover a wide variety of tasks, including a case study with the Hodgkin-Huxley simulator, and the authors have open-sourced their code to aid reproducibility.

Weaknesses:
- The visual presentation of Figure 2 could be improved for clarity, particularly in subfigure C.
- Propositions 1 and 2 appear forced, lacking compelling results, and their proofs are not sufficiently emphasized.
- The reliance on the neural estimator to generalize from limited simulations raises concerns about practical applicability, especially in higher-dimensional problems.
- The experimental results are difficult to interpret, with unclear definitions and inconsistencies in metrics presented in figures.

### Suggestions for Improvement
We recommend that the authors improve the visual clarity of Figure 2 and revisit the presentation of Propositions 1 and 2 to enhance their significance. Additionally, a more thorough examination of the effects of sample size on ACE training would be beneficial. Clarifying the definitions of terms used in figures, particularly in Figure 3, and ensuring consistency in metrics would greatly aid reader comprehension. Finally, addressing the implications of the hyperparameter $\beta$ and exploring its role in the context of GBI would strengthen the paper's contributions.