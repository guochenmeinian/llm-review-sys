ID: x6cOcxRnxG
Title: Neural Ideal Large Eddy Simulation: Modeling Turbulence with Neural Stochastic Differential Equations
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 8, 6, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a neural SDE model for Large Eddy Simulation (LES) flow fields, motivated by the ideal LES approach, which learns a data-driven closure term. The model captures the variability and fine-scale structure of fully-resolved DNS solutions that are typically lost in LES filtering. The authors propose a data-driven method to approximate the closure term, enhancing temporal resolution through latent space evolution and stochastic propagation. The model demonstrates competitive performance against Filtered DNS references and outperforms baseline models.

### Strengths and Weaknesses
Strengths:
- The paper is excellently motivated and embedded in theoretical context, making a valuable contribution to the field of stochastic modeling for turbulence.
- The proposed method shows superior performance in terms of squared error and accuracy of turbulent kinetic energy spectrum compared to several baselines.

Weaknesses:
- The term "closure model" is used loosely in the introduction, with only one cited reference defining it appropriately in the context of RANS and LES.
- The model's training relies solely on a single reconstruction loss, lacking prior regularization in latent space, which may hinder capturing physical dynamics.
- The evaluation is limited to a single Kolmogorov flow scenario, with insufficient benchmarks against recent deep learning-based methods and a lack of stable evaluations across multiple tests.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the term "closure model" in the introduction and ensure that the definition aligns with established literature. Additionally, we suggest merging clarifications from lines 211-213 into the introduction to avoid misleading interpretations. Including figures that illustrate flow predictions at various steps and comparing DNS with filtered data would enhance reader understanding. To address the model's training limitations, we encourage the authors to incorporate additional benchmarks that demonstrate the advantages of stochasticity and to evaluate scalability by excluding certain wave numbers. Finally, expanding the evaluation to include multiple scenarios beyond turbulence and additional learned baselines would strengthen the paper's contributions.