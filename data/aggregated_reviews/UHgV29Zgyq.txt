ID: UHgV29Zgyq
Title: Asking Multimodal Clarifying Questions in Mixed-Initiative Conversational Search
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on multimodal clarification for conversational search, introducing a novel dataset called Melon that incorporates images to enhance user query clarification. The authors propose a multimodal query clarification model named Marto, which aims to improve document retrieval by integrating textual and visual data. The research investigates four key questions, demonstrating that multimodal clarification can enhance retrieval performance and user response accuracy.

### Strengths and Weaknesses
Strengths:
1. The motivation for integrating images into query clarification is well-argued, and the dataset construction process is detailed and appears to yield high-quality results.
2. The paper is well-written and organized, with clear descriptions of the proposed task and retrieval system.
3. The experimental design is robust, with significant findings that support the research questions, particularly regarding the benefits of multimodal clarification.

Weaknesses:
1. The definition and implementation of the answer function $A(t, f, q, I)$ are insufficiently addressed, potentially impacting the analysis of image variations.
2. The model lacks a design to assess the relevance of retrieved images, which could lead to misalignment with user intent.
3. Justifications for the choice of retrieval methods within Marto are unclear, particularly regarding the use of generative retrieval for document retrieval.
4. The paper does not adequately explore the potential of large language models in conversational search, missing opportunities for comparative analysis.

### Suggestions for Improvement
We recommend that the authors improve the clarity and implementation of the answer function $A(t, f, q, I)$ to enhance the analysis of multimodal clarification effects. Additionally, the authors should incorporate a mechanism to evaluate the relevance of retrieved images to ensure alignment with user intent. We suggest providing more explicit justifications for the retrieval methods employed in Marto, particularly the rationale behind using generative retrieval. Lastly, we encourage the authors to compare their models with recent large language models, such as GPT-4 or Llama2, to strengthen their findings.