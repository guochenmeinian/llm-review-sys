ID: 4k5BcBYKAS
Title: GTA: Gated Toxicity Avoidance for LM Performance Preservation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a model-agnostic gating method aimed at reducing toxicity in language generation while maintaining performance in terms of topic consistency and grammar. The authors propose a binary toxic classifier to refine toxic tokens into non-toxic ones. Extensive experiments across three datasets demonstrate that gated detoxifiers achieve comparable toxic reduction while preserving generation quality.

### Strengths and Weaknesses
Strengths:
- The motivation is intuitive, supported by a solid literature review and necessary preliminaries.
- The proposed gated detoxifier is simple and generalizable, with well-organized experiments addressing clear research questions.
- The method effectively retains model performance while reducing computational overhead.

Weaknesses:
- The main contributions are limited, with the gating mechanism lacking necessary technical details, such as the training of the toxic classifier and the gating threshold.
- Performance gains, particularly in the Toxicity metric, are not remarkable.
- The term "detoxifier" is confusing, as it overlaps with existing terminology in toxic-to-non-toxic style transfer.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the term "detoxifier" to avoid confusion with existing literature. Additionally, the authors should provide more technical details on the training of the toxic classifier and the gating mechanism. We suggest enhancing the writing style for better readability, addressing the numerous language errors noted by reviewers. Finally, evaluating the proposed method on more recent language models, such as FlanT5 and Llama, would strengthen the contribution and relevance of the work.