ID: RatT4hCcVf
Title: Casual Insights into Parler's Content Moderation Shift: Effects on Toxicity and Factuality
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a data-driven investigation of user behavior changes on Parler following its content moderation policy changes post-de-platforming in 2021. The authors propose a quantitative evaluation framework for assessing content moderation effectiveness, utilizing a quasi-experimental Difference-in-Difference (DiD) analysis to measure changes in toxicity and the factuality of shared content. The findings indicate a reduction in toxic content and an increase in the credibility of shared links, addressing significant questions regarding content governance on social media.

### Strengths and Weaknesses
Strengths:
- The paper is the first to analyze user behavior changes on Parler after content moderation policy changes, providing a valuable framework for future research.
- It employs statistical methods to validate hypotheses, ensuring the reliability of findings.
- The analysis highlights important trends, such as the reduction in toxic content and increased credibility of shared information.

Weaknesses:
- The methodology section is overly focused, with insufficient emphasis on the implications of the findings and the broader theoretical context.
- The paper does not adequately address the inconsistency between the observed decrease in toxic content and the increase in links from questionable sources.
- There is a lack of discussion regarding the limitations and biases of the Google Perspective API, particularly its potential instability in detecting implicit toxicity.
- The representativeness of the post-policy change dataset is questionable, as it only includes 432k active users out of an original 4M.

### Suggestions for Improvement
We recommend that the authors improve the discussion on why the reinstatement of a platform is significantly different from previous de-platforming studies and clarify the broader impacts of toxicity. Additionally, the authors should address the questions regarding the definition of toxicity, the mechanisms behind content moderation changes, and the potential biases in their methodology. It would be beneficial to conduct a cross-platform comparison to explore the effects of user migration on toxicity trends. Finally, we suggest including a more granular temporal analysis to distinguish between the effects of policy changes and external events, as well as validating toxicity scores through random manual sampling to enhance reliability.