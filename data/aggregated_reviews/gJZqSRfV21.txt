ID: gJZqSRfV21
Title: ReLM: Leveraging Language Models for Enhanced Chemical Reaction Prediction
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ReLM, a framework that predicts chemical reactions by integrating graph neural networks (GNN) and large language models (LLM). The authors propose a Confidence Score Strategy to enhance the effectiveness of LLMs by generating questions and answers from similar reactions, which are then used as prompts. The framework demonstrates improved results across various GNN and LLM combinations, supported by thorough ablation studies. The paper is well-written and provides good code availability.

### Strengths and Weaknesses
Strengths:
- The paper introduces a novel in-context learning framework that effectively combines LLM and GNN methods.
- The confidence score strategy enhances robustness and interpretability, contributing to the overall effectiveness of the approach.

Weaknesses:
- The choice of baselines is confusing; the necessity of ReLM for introducing textual knowledge when pre-training an in-house GNN is required raises questions about its use case.
- The novelty of the methodology appears limited, primarily focusing on prompt design, with insufficient explanation regarding the rationale behind the confidence score assignments.
- The experimental setups do not adequately demonstrate how the integration of reaction type and condition information improves prediction accuracy.

### Suggestions for Improvement
We recommend that the authors clarify the choice of baselines and address the necessity of ReLM in the context of pre-trained GNNs. Additionally, we suggest providing a more detailed explanation of the confidence score strategy, particularly the reasoning behind the selected score ranges. It would be beneficial to include examples that illustrate how reaction conditions impact predictions, as well as to expand the range of K values in experiments to assess LLM performance with varying candidate options. Lastly, we encourage the authors to explore generating confidence scores for each candidate and to include examples of reaction types and conditions in the appendix for better context.