ID: ScPgzCZ6Lo
Title: GC-Bench: An Open and Unified Benchmark for Graph Condensation
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 8, 6, 6, 7, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive benchmark, GC-Bench, designed to evaluate the effectiveness, transferability, and efficiency of graph condensation (GC) methods. The authors systematically assess 12 state-of-the-art GC algorithms across 12 diverse graph datasets, addressing both node-level and graph-level tasks. Key observations include the limitations of current methods regarding transferability, the influence of structural properties, and the significant impact of initialization strategies on convergence speed. The authors also provide an open-source library to promote reproducible research and identify critical research gaps for future exploration.

### Strengths and Weaknesses
Strengths:
1. The paper offers a thorough evaluation framework for GC methods, covering multiple dimensions such as effectiveness, transferability, and efficiency.
2. It provides valuable insights into the limitations of existing GC methods, particularly regarding the relationship between condensation ratios and performance.
3. The identification of research gaps, such as the need for task-agnostic GC methods and improved handling of complex graph structures, directs future research efforts.
4. The evaluation includes diverse performance metrics, enhancing the understanding of GC methods.

Weaknesses:
1. The benchmark could be improved by including a wider variety of datasets, particularly more heterogeneous graphs commonly used in recommendation systems.
2. More detailed comparisons between the performance of different GC methods across various datasets would benefit readers.
3. The exploration of structural properties like heterophily and homophily on GC performance is limited and could be expanded.
4. The paper lacks a theoretical framework to understand the trade-offs between dataset size, information condensation, and preservation.

### Suggestions for Improvement
1. We recommend that the authors enhance the analysis of experimental results to yield more insightful findings.
2. We suggest providing a more in-depth discussion on the impact of graph structure, particularly for heterogeneous graphs, and consider including additional distinctive experiments.
3. We encourage the authors to improve the descriptions of Figure 3(c) and Figure 4 for clarity, particularly regarding color differentiation and dataset scale influences.
4. We recommend including a simple feature-based baseline for condensation to assess the impact of structural information versus node presence.
5. We suggest evaluating the performance of condensed graphs in practical applications, such as training and tuning GNN models.
6. We recommend addressing the convergence analysis for methods like DosCond and KiDD, which are known to have convergence issues during training.