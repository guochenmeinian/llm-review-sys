ID: PSDXcYjrkO
Title: Towards Comprehensive Detection of Chinese Harmful Memes
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 7, 4, 8, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the first Chinese harmful meme dataset, TOXICN MM, comprising 12,000 samples with fine-grained annotations for meme types. The authors propose a baseline detector, Multimodal Harmful Knowledge Enhancement (MHKE), which integrates contextual information from meme content to enhance the model's understanding of harmful memes. The work includes initial experiments and error analysis, highlighting the challenges of detecting harmful memes in a Chinese context. The authors also emphasize the potential value of the dataset for future research and propose to mitigate annotator subjectivity and disagreement through careful selection of harmful memes based on psychological consensus. Additional experiments assess the influence of LLMs on caption generation and the impact of prompt examples on detection performance. The authors clarify several terms that may have caused confusion, such as "MHKE," "knowledge introduction," and "intuitively integrating."

### Strengths and Weaknesses
Strengths:
- The dataset fills a significant gap in Chinese multimedia safety detection.
- The construction of the first Chinese harmful meme dataset is a notable contribution.
- The experiments are well-designed and reproducible, providing a solid foundation for future research.
- The authors have effectively addressed annotator subjectivity and disagreement.
- Additional experiments enhance the understanding of LLMs' influence on caption generation.
- Clear communication of revisions and clarifications has been positively noted by other reviewers.

Weaknesses:
- The definitions of potential harms are vague and difficult to operationalize, raising concerns about subjectivity in labeling.
- The inter-annotator agreement (IAA) for harmfulness determination is low, with limited discussion on this issue.
- The writing lacks clarity and idiomatic expression in several areas, affecting overall readability.
- Some terms used in the paper may still lead to confusion among readers.

### Suggestions for Improvement
We recommend that the authors improve the clarity and idiomatic expression of the writing, particularly in the sections discussing MHKE and annotator selection. Additionally, we suggest providing more detailed explanations of the harms associated with each type of meme to emphasize the necessity of detection. Addressing the subjective nature of harmful memes by including examples of harmless cases would help clarify the boundaries between harmful and non-harmful content. Furthermore, we encourage the authors to explore the influence of different LLMs on caption generation and consider using Chinese LLMs for better cultural relevance. We also recommend that the authors work with native English speakers to refine the writing further. Lastly, please ensure that the added results are prominently displayed in the final version and that all LLM-generated captions are open-sourced as promised.