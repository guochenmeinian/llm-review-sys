ID: ScyHOFza1l
Title: Simulating Message Passing via Spiking Neural Networks Using Logical Gates
Conference: NeurIPS
Year: 2024
Number of Reviews: 2
Original Ratings: 3, 4
Original Confidences: 3, 3

Aggregated Review:
### Key Points
This paper presents a method for implementing XOR and Equality factor nodes within a spiking neural network (SNN) framework, focusing on Bernoulli message passing. The authors propose a straightforward approach that utilizes basic logical gates, yielding results that closely align with traditional sum-product message-passing models. While the paper touches on aspects of Bayesian inference, its primary focus is not on uncertainty quantification or decision-making.

### Strengths and Weaknesses
Strengths:
1. The proposed method is easy to implement, primarily involving combinations of basic logical gates.
2. Experimental results for Bernoulli messages are close to the ground truth.
3. The work addresses a significant problem in computational neuroscience by linking probabilistic inference methods with biologically plausible neural implementations.
4. The authors demonstrate good scientific reasoning and originality in creating factor nodes for Bernoulli message passing using a limited number of spiking neurons.

Weaknesses:
1. The writing and presentation do not meet conference standards, with fundamental grammar errors and incorrect citation formats. The paper lacks sufficient credit to previous works and features inconsistent table and figure presentations.
2. The method's simplicity, based on textbook logical operations, may limit its applicability to more complex inference tasks.
3. The authors do not provide theoretical justification or experimental demonstration for the claim of requiring a minimum number of neurons and synaptic connections, nor do they compare their solution with baseline methods.
4. The empirical evaluation is limited, and the conclusions drawn are not sufficiently persuasive. The potential for the SNN framework to operate under other stochastic environments is not explored.

### Suggestions for Improvement
We recommend that the authors improve the writing quality and presentation to meet conference standards, addressing grammar errors and citation formats. Additionally, the authors should expand the scope of their work by demonstrating the method's applicability to a simple decision-making task requiring probabilistic inference. An analysis of how their method scales to larger graphical models and its performance under various noise levels would strengthen the paper. Furthermore, we suggest that the authors explore uncertainty quantification in the context of their SNN implementation to enhance the discussion on its relevance to biological neural systems.