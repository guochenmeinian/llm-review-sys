ID: Ah2Q8mLH96
Title: Optimal Excess Risk Bounds for Empirical Risk Minimization on $p$-Norm Linear Regression
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 7, 6, 5, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study of the excess risk of empirical risk minimization (ERM) for $p$-norm linear regression, extending known results for $p=2$ to the range $p \in (1,\infty) \setminus \{2\}$. The authors provide high probability excess risk bounds for both realizable and non-realizable cases, with specific assumptions on moments. The results are divided into three parts: bounds for the realizable case, bounds for the non-realizable case with $p \in (2,\infty)$, and additional assumptions for $p \in (1,2)$. The proof techniques draw from existing literature, combining various approaches to validate the results. Additionally, the paper presents a theoretical framework regarding sample complexity in relation to specific distributions, proposing that $O(d)$ samples are sufficient to recover the target, although this claim requires clarification to account for distribution-specific constants.

### Strengths and Weaknesses
Strengths:
- The paper is the first to provide high probability excess risk bounds for ERM in the $p$-norm regression setting for $p \in (1,\infty) \setminus \{2\}$, aligning with existing asymptotic bounds.
- The motivation and background of the problem are well-articulated, and the theoretical results are connected to prior work.
- The proof ideas are presented clearly, enhancing the understanding of the methodology.
- The authors acknowledge the need for clarification regarding the dependence of $\rho$ on the dimension and agree to include this discussion in the paper.

Weaknesses:
- The case for $p \in (1,2)$ requires additional assumptions that may not be necessary, leaving this aspect of the paper only partially resolved.
- The proof strategy is not adequately discussed until later sections, which may hinder comprehension.
- Some statements, particularly in the proof section, are unclear or poorly articulated, leading to confusion regarding their implications.
- The claim in the abstract regarding $O(d)$ samples is imprecise and requires modification to avoid misleading interpretations.
- The initial omission of the dependence on distribution-specific constants in the abstract may lead to misunderstandings about the sample complexity.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the proof section by discussing the proof strategy earlier in the paper. Additionally, it would be beneficial to provide a clearer justification for the extra assumptions in the $p \in (1,2)$ case, potentially addressing whether they are indeed necessary. We also suggest including definitions or references for terms like $\rho$ and $\sigma_p^2$ within the theorem statements for better accessibility. Furthermore, we recommend that the authors improve the abstract by revising the statement to: "... , $O_\rho(d)$ samples are enough to exactly recover the target with high probability, where the $O_\rho$ notation hides dependence on a distribution specific *parameter* $\rho$ (as well as on the confidence level)." This adjustment will enhance clarity and align with standard notation in the literature. Lastly, ensure that the discussion on the dependence of $\rho$ on the dimension is adequately addressed in the paper.