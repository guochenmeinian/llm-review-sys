ID: Q3CRHnttxW
Title: Approximate Allocation Matching for Structural Causal Bandits with Unobserved Confounders
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 7, 5, 4, 6, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 2, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents two primary contributions to the causal bandit problem with unobserved confounders: 1) a lower bound on the regret any algorithm can achieve, and 2) an upper bound on the regret of a newly proposed algorithm that generalizes across interventions using allocation matching. The authors study structural causal bandits, providing theoretical results on attainable regret and demonstrating the algorithm's superior empirical performance through synthetic experiments.

### Strengths and Weaknesses
Strengths:
- The paper introduces a causal bandit algorithm with a regret guarantee for cumulative regret in general graphs, which is a novel contribution that is likely to interest the community.
- The writing is generally clear, and the organization of background material is effective.

Weaknesses:
- The experiments are based on synthetic data from small graphs, limiting insights into performance across varying graph sizes and intervention sets.
- The exposition of theoretical contributions is dense, lacking clarity in presenting the advantages of the proposed algorithm over existing methods, particularly in the comparison with [20].
- Some prose is clunky, with several typos noted, indicating a need for proofreading.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the theoretical contributions by providing close-form or approximate values for the factors discussed in the paper. Additionally, we suggest including a discussion on how the regret bound scales with graph size and intervention set size. To enhance the empirical analysis, consider using more robust baseline algorithms like Thompson sampling or KL-UCB instead of vanilla UCB. Furthermore, we encourage the authors to clarify the computational efficiency of the algorithm, particularly regarding the scalability with larger graphs, and to moderate claims about empirical performance against stronger baselines. Lastly, we advise a thorough proofreading to address clunky prose and typos.