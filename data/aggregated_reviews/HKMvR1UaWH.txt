ID: HKMvR1UaWH
Title: SYMPTOMIFY: Transforming Symptom Annotations with Language Model Knowledge Harvesting
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents SYMPTOMIFY, a dataset of annotated vaccine adverse reaction reports aimed at enhancing the efficiency of human annotators in healthcare decision-making. The dataset includes over 800,000 reports, reasoning-based explanations, and background knowledge sourced from language model knowledge harvesting. The authors evaluate various baselines across different learning paradigms, providing insights for future comparisons and benchmarking.

### Strengths and Weaknesses
Strengths:
1. The SYMPTOMIFY dataset incorporates explanations and background information, enhancing the quality and utility for symptom recognition.
2. The dataset's substantial size (over 800,000 entries) offers a valuable resource for the research community.
3. The experiments are innovative and timely, addressing rare symptoms and zero-shot scenarios, and utilizing the Falcon-7B-Instruct model.
4. The method expands existing research on symptom recognition and has the potential to advance medical decision-making.
5. The paper provides valuable insights and evaluation results for various baselines, guiding future research.
6. The authors effectively leverage Large Language Models (LLMs) to make AI a supportive tool rather than a replacement for human annotators.

Weaknesses:
1. The quality of annotations is questionable, as they should ideally be verified by professionals rather than crowdsourced workers, raising concerns about reliability.
2. The evaluation of the proposed method is limited; more extensive evaluations and ablation studies are needed.
3. Some experimental results are poor, with F1 scores as low as 1.34, indicating potential issues with model settings or code.

### Suggestions for Improvement
We recommend that the authors improve the evaluation of the proposed method by conducting more extensive evaluations and ablation studies. Additionally, we suggest that the authors clarify the annotation process and ensure that verification of annotations is performed by trained professionals. Furthermore, addressing the specific questions raised regarding the dataset's statistics and the agreement between annotators will enhance the paper's clarity and reliability. Lastly, we advise correcting the identified typos and adjusting the title to better reflect the methodology used in the study.