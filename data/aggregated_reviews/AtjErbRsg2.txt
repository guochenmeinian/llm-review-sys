ID: AtjErbRsg2
Title: Reconstruct Before Summarize: An Efficient Two-Step Framework for Condensing and Summarizing Meeting Transcripts
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a two-step framework for the abstractive summarization of meetings, termed Reconstruct Before Summarize (RbS). The method first selects key points (anchor tokens) in a self-supervised manner and then summarizes using the Relative Position Bucketing algorithm, enhancing memory and computational efficiency. Evaluations on AMI and ICSI datasets demonstrate that RbS achieves state-of-the-art performance on various metrics (Rouge-1/2/L) compared to several baselines. The authors conduct an ablation study to assess the contributions of anchor tokens, scoring methods, and bucketing to the overall performance.

### Strengths and Weaknesses
Strengths:
- The proposed method offers a novel approach for long input summarization, achieving state-of-the-art results among non-LLM methods.
- The anchoring and bucketing techniques contribute to reduced time complexity.
- The paper is well-structured, with clear visualizations and a thorough analysis of experimental results.

Weaknesses:
- The methodology description lacks clarity, particularly regarding the summarization process after embedding aggregation.
- The reported computational efficiency relies on high-end hardware (8 A100 GPUs), which may not reflect typical usage scenarios.
- The limitation section is overly focused on LLMs, neglecting other potential comparisons, such as linguistic-based approaches.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the methodology, particularly in explaining how the final summary is generated after embedding aggregation. Additionally, reporting computation times on more accessible hardware would provide a fairer assessment of efficiency. The authors should consider expanding the limitations section to include comparisons with linguistic-based approaches and explore data augmentation methods to enhance generalization. Lastly, conducting statistical testing to support the significance of the reported results would strengthen the findings.