ID: DmakwvCJ7l
Title: Data-Centric Learning from Unlabeled Graphs with Diffusion Model
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 5, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a data-centric approach to graph property prediction tasks, leveraging a diffusion model to utilize unlabeled graphs effectively. The authors propose two objectives to enhance the model's denoising process, aiming to generate task-specific graph examples and labels. Experimental results indicate that this method outperforms fifteen existing techniques across various graph property prediction tasks, demonstrating that the generated labeled examples are more effective than those derived from self-supervised learning.

### Strengths and Weaknesses
Strengths:
1. The proposed method introduces a novel approach to graph property prediction by employing a diffusion model, distinguishing it from traditional methods.
2. Empirical results show that the method surpasses existing techniques in self-supervised learning, semi-supervised learning, and graph data augmentation.

Weaknesses:
1. The discussion surrounding the graph diffusion model is inadequate; a clearer comparison with existing methods is necessary to clarify the contributions of this work.
2. The interpretability of knowledge transfer from unlabeled graphs is insufficiently supported by the limited case studies presented.

### Suggestions for Improvement
We recommend that the authors improve the discussion of the graph diffusion model by clearly delineating its similarities and differences with existing methods [1,2]. Additionally, we suggest providing more comprehensive evidence to support claims regarding the transfer of concepts from unlabeled graphs to downstream tasks. Furthermore, addressing the potential overfitting issue as indicated in the experimental results would strengthen the paper. Lastly, a more thorough literature review, particularly regarding pseudo-labeling and self-supervised learning models, would enhance the context and depth of the study.