ID: DylSyAfmWs
Title: Be like a Goldfish, Don't Memorize! Mitigating Memorization in Generative LLMs
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 5, 6, 4, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel technique called "goldfish loss" aimed at mitigating memorization in large language models (LLMs) by excluding certain tokens from loss computation during training. The authors employ two drop functions to determine which tokens to exclude, ensuring consistent token exclusion across duplicate documents using a hashing approach. Experiments demonstrate that goldfish loss significantly reduces verbatim memorization rates without adversely affecting benchmark performance, although many scores are near chance levels.

### Strengths and Weaknesses
Strengths:
- The goldfish loss is a straightforward and effective method for reducing memorization, distinct from existing post-training techniques.
- The hashing mechanism for handling duplicate passages is innovative and enhances the practical application of goldfish loss.
- Empirical evidence supports the effectiveness of goldfish loss in extreme memorization scenarios with minimal impact on downstream tasks.

Weaknesses:
- The lack of theoretical guarantees regarding memorization prevention raises concerns about the robustness of the method.
- The paper does not adequately discuss the computational complexity introduced by the hashing mechanism, which could affect its practical implementation.
- Benchmark scores are often close to chance levels, making it difficult to assess the true impact of goldfish loss on performance.

### Suggestions for Improvement
We recommend that the authors improve the theoretical framework surrounding goldfish loss to provide guarantees against memorization. Additionally, a more detailed analysis of the computational overhead associated with the hashing mechanism would strengthen the paper. We suggest including a broader range of benchmarks, particularly those that are more sensitive to small-scale performance, to better evaluate the impact of goldfish loss on downstream tasks. Finally, clarifying the implications of using copyrighted data in the context of this work is essential to address potential ethical concerns.