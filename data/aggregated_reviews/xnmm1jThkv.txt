ID: xnmm1jThkv
Title: Hybrid Top-Down Global Causal Discovery with Local Search for Linear and Nonlinear Additive Noise Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 6, 5, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper studies the structure learning problem for additive noise models (ANM) in both linear and nonlinear settings, proposing a hybrid constraint-based approach to learn the directed acyclic graph (DAG) by leveraging local ancestral relationships. The algorithm includes ordering search and edge discovery, with correctness demonstrated through simulations comparing it to other methods.

### Strengths and Weaknesses
Strengths:
- The proposal effectively addresses the high computational complexity and challenges in nonparametric regression and conditional independence (CI) tests associated with ANMs, showing potential for efficient solutions.
- The introduction of the method is well-written and accessible to researchers in the field.

Weaknesses:
- The main contribution, which is the exploitation of local structure to reduce nonparametric regression and CI tests, lacks explicit formal statements and comparisons to existing methods like RESIT.
- The experiments are preliminary, requiring additional setups to validate the proposal's superiority, including various graph types, edge counts, noise levels, and recovery criteria.
- Runtime results are presented in the appendix, raising questions about their relevance, and there is a lack of significant empirical improvement.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their main contributions by providing explicit formal statements and comparisons with existing methods, such as RESIT. Additionally, we suggest expanding the experimental setups to include diverse graph types, varying edge counts, and different noise levels, as well as incorporating benchmarks like CAM and GSGES. Furthermore, we encourage the authors to clarify the runtime results and establish statistical guarantees regarding sample complexity and sparsity.