ID: 7TKKvwyQef
Title: DialGuide: Aligning Dialogue Model Behavior with Developer Guidelines
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Dialguide framework, which includes three tasks: guideline retrieval, response generation, and response entailment verification. The authors construct two datasets, Dialguide-BST and Dialguide-Safety, from existing datasets Blended Skill Talk and ProsocialDialog. The experiments validate the effectiveness of guidelines in generating dialogue responses, showing promising results. The paper proposes a new dialogue task, DIALGUIDE, with a human-annotated dataset aimed at generating responses aligned with provided guidelines.

### Strengths and Weaknesses
Strengths:  
- The use of guidelines to direct dialogue model responses is innovative and promising.  
- The annotated dataset is valuable and contributes to the field.  
- The paper is well-written and presents a fair experimental design.  

Weaknesses:  
- The transferability of the dataset is questionable due to its specific task design, which may limit broader applicability.  
- The reported results, while decent, raise concerns about the competitiveness of recent models fine-tuned on this dataset.  
- The contribution of using prompts for model performance improvement is unclear, especially without open-sourcing the labeled data.  
- Some tasks rely solely on the Dialguide-BST dataset, and there is no validation of guideline generalization.

### Suggestions for Improvement
We recommend that the authors improve the task structure by using task three as a test for task two, allowing for a pipeline approach. Additionally, consider training a single model to accomplish all three tasks simultaneously. Address potential security concerns regarding malicious guidelines and clarify the rationale for using InstructDial as the base model over other instruction-tuned models like Vicuna. It would also be beneficial to explore the length of dialogue history for input and enhance the adversarial test set to increase challenge while maintaining quality. Finally, ensure that all experiments clearly correspond to claims of the model's generalization capabilities.