ID: B8mdHlqNfw
Title: Large Language Models and Multimodal Retrieval for Visual Word Sense Disambiguation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an exploration of visual word sense disambiguation (VWSD) through various methodologies, including the use of large language models (LLMs) for phrase enhancement, transforming the task into text-to-text and image-to-image retrieval, and employing a learning-to-rank (LTR) model alongside chain-of-thought (CoT) prompting. The authors find that LLMs effectively enhance context, unimodal approaches do not surpass text-enhanced methods, and the LTR model yields the best results. The study provides a comprehensive comparison of state-of-the-art models and introduces novel reasoning aspects through CoT.

### Strengths and Weaknesses
Strengths:
- The paper is well-structured and presents comprehensive experiments, validating the proposed methods effectively.
- It provides substantial insights into VWSD and explores the utility of LLMs for phrase enhancement.
- The experimental framework is robust, with consistent results across various settings.

Weaknesses:
- The methodology lacks new insights compared to existing works presented at the VWSD workshop, with many approaches already explored by other teams.
- The novelty of the proposed methods appears limited, and the paper does not delve deeply into the nuances of the VWSD task.
- The authors do not adequately discuss why certain models perform better than others, and the ablation study does not clarify the importance of different components.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their work by providing deeper insights and discussions on the intricacies of the VWSD task. Additionally, we suggest that the authors utilize the CoT method more effectively to enhance VWSD results and consider conducting a more detailed analysis of model performance to elucidate the reasons behind varying outcomes. Furthermore, clarifying the computations in the Method section and ensuring a consistent strategy for the task would strengthen the paper. Lastly, correcting minor presentation issues, such as the error in Table 3, would enhance clarity.