ID: okV4KG4kMg
Title: Can Language Models Laugh at YouTube Short-form Videos?
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the ExFunTube dataset, a multimodal humor video dataset that utilizes large language models (LLMs) to analyze humorous content through both visual and audio signals. The authors propose a zero-shot video-to-text prompting framework aimed at enhancing the LLM's understanding of humor in videos. The dataset includes annotated timestamps for humorous moments and text explanations, demonstrating the potential for improved humor recognition.

### Strengths and Weaknesses
Strengths:
1. The authors have created an innovative dataset that captures both textual and visual nuances of humor.
2. The paper employs state-of-the-art models and techniques, showcasing its relevance.
3. Thorough experiments and evaluations are conducted, indicating a robust research approach.
4. The modular framework allows for easy integration of future SOTA models.

Weaknesses:
1. Audio information is underutilized, which could limit the system's understanding and overall performance.
2. The justification for model selection lacks detail, and potential pitfalls of the chosen models are not adequately addressed.
3. The dataset's humor interval annotations are imbalanced, and the quality of the annotations is not fully evaluated.
4. Some content in the dataset may be uncomfortable for viewers, raising ethical concerns.

### Suggestions for Improvement
We recommend that the authors improve the utilization of audio information to enhance the system's comprehension. Additionally, provide a more detailed justification for the selected models and address potential pitfalls associated with them. To strengthen the dataset, consider adding videos without humor intervals to balance the annotations. Ensure that the quality of the dataset annotations is thoroughly evaluated and clearly presented. Lastly, we suggest including a content warning regarding potentially uncomfortable material in the dataset to inform users.