ID: xFtuNq23D5
Title: Boosting Spectral Clustering on Incomplete Data via Kernel Correction and Affinity Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 5, 7, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an imputation-free framework aimed at enhancing spectral clustering on incomplete data through two novel approaches. The authors propose a kernel correction method that ensures the kernel matrix estimated from incomplete data is of higher quality, along with a new affinity learning method that utilizes â„“p-norm to create an intrinsic affinity matrix with adaptive extensions. Additionally, the paper includes a comparative analysis of the KSL-Sp and AKLSR algorithms, highlighting AKLSR's faster running speed due to its explicit update steps, which leads to quicker convergence. The authors enhance AKLSR by incorporating a PSD constraint, resulting in AKLSR-PSD, which is partially validated through results on the Umist dataset. The performance of the KC method across varying missingness ratios is also addressed, demonstrating its superiority over baseline methods, particularly under high missing ratios.

### Strengths and Weaknesses
Strengths:
- The originality of the proposed imputation-free framework and its two approaches is commendable, contributing significantly to the field.
- The clarity of presentation regarding the framework and methods is satisfactory, facilitating understanding of the proposed techniques.
- The kernel correction algorithm is novel and theoretically sound, with potential applications in various domains.
- The inclusion of additional experimental results and comparisons enhances the paper's contributions.
- The exploration of the trade-off between efficiency and performance is a valuable addition.
- The detailed analysis of the KC method's performance across different missingness levels provides significant insights.

Weaknesses:
- The advantages of the proposed method in addressing incomplete data are not clearly articulated, particularly in Section 3 regarding the recovery of missing data.
- The methods for calibrating the distance matrix in Section 3.1 are not universally applicable to spectral clustering tasks, which may dilute the novelty of the paper.
- The experiments rely on small-scale datasets; larger multi-view datasets should be included to validate clustering performance.
- The improvements demonstrated in experiments are not substantial, with metrics like RE_K of KC being relatively low.
- The comparison with recent methods is insufficient, limiting the comprehensiveness of the experimental results.
- The performance of AKLSR compared to KSL-Sp raises questions about its advantages, particularly when AKLSR performs worse in some metrics.
- The evaluation is based on a single missingness value, limiting the robustness of the conclusions.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the advantages of their method in dealing with incomplete data, particularly in Section 3. A more focused discussion on the distance calibration methods in Section 3.1 would enhance the paper's coherence. Additionally, incorporating larger multi-view datasets in the experiments would strengthen the validation of clustering performance. The authors should also consider including more recent methods for comparison to provide a more comprehensive evaluation of their approach. Furthermore, we recommend that the authors improve the clarity of the advantages of AKLSR over KSL-Sp, particularly in light of its performance metrics. Finally, including results across a wider range of missingness values would provide a more comprehensive evaluation of performance. Addressing the running time of the kernel correction algorithm and exploring optimizations, such as computing only the top k eigenvectors, could enhance the practical applicability of their method.