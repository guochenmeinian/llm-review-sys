ID: SFCZdXDyNs
Title: Déjà Vu Memorization in Vision–Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 4, 7, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates training data memorization in Vision-Language Models (VLMs), particularly focusing on contrastive learning with OpenCLIP. The authors propose a method and metrics to measure déjà vu memorization, utilizing a private Shutterstock dataset and a filtered LAION-50M, and evaluate their findings on ImageNet. The study concludes that memorization is present and explores various mitigation strategies.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and addresses a significant issue in VLMs, proposing new metrics and mitigation strategies.
- It includes extensive experimentation, providing insights into the memorization phenomenon and its implications for downstream applications.

Weaknesses:
- **W1**: The work fails to adequately distinguish memorization from learning, raising questions about the interpretation of results. The authors' assertion that differences in model performance are solely due to memorization lacks sufficient discussion on how learning may also contribute.
- **W2**: The mitigation experiments do not sufficiently address the multi-modal nature of VLMs, particularly regarding the potential impact of image data augmentation on memorization.
- **W3**: Clarity issues exist, particularly with Figure 1, which is difficult to interpret, and the term 'the adversary' in line 233 lacks context.

### Suggestions for Improvement
We recommend that the authors improve the discussion on how memorization is distinguished from learning, providing clarity on the implications of their findings. Additionally, the authors should explore the role of image data augmentation in mitigating memorization. We suggest revising Figure 1 for better clarity and providing context for the term 'the adversary' to enhance understanding. Finally, including comparisons with baseline methods could strengthen the validity of the proposed metrics.