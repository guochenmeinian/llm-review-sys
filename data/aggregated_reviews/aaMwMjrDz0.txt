ID: aaMwMjrDz0
Title: Conditional Natural Language Inference
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the task of conditional Natural Language Inference (Cond-NLI), which extends traditional NLI by focusing on token-level decisions regarding contradictions, entailments, and neutrality between hypotheses and premises. The authors propose a new architecture, the Partial-Attention NLI Model (PAT), which predicts NLI labels for divided hypothesis segments and combines these for final predictions. Additionally, they introduce a new dataset, BioClaim, specifically designed for this task. The proposed method demonstrates an 8% improvement over the best NLI-based baseline in predicting conditional markers.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and easy to follow.
- The proposed PAT architecture effectively explains model decisions in NLI.
- The new dataset addresses limitations of existing NLI datasets, particularly regarding lexical overlap.
- A thorough set of experiments is provided, showcasing the performance of GPT models in a zero-shot setting.

Weaknesses:
- The writing is confusing in several sections, including the introduction and methods, which may hinder comprehension for readers.
- The inter-annotator agreement for the dataset is low (Cohen's kappa of 0.46), and its impact on results needs further discussion.
- The framing of the Cond-NLI task raises questions about the semantic structures involved, particularly regarding token annotations.
- The evaluation of the proposed model lacks comparisons with existing benchmarks for explainable NLI.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing, particularly in the introduction and methods sections, to enhance reader comprehension. Additionally, the authors should discuss the implications of the low inter-annotator agreement on the dataset more extensively. We also suggest that the authors address the inconsistencies raised regarding token annotations in Table 1 and provide a more thorough evaluation of PAT against existing explainable NLI benchmarks. Finally, clarifying the dataset's availability for public use would be beneficial.