ID: 4Zt7S0B0Jp
Title: Chain-of-Thought Reasoning Without Prompting
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 4, 6, 8, 8, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into the inherent reasoning capabilities of large language models (LLMs) through a method called CoT-decoding, which explores alternative top-k tokens in the decoding process. The authors propose that this approach reveals Chain-of-Thought (CoT) reasoning paths without the need for explicit prompting, demonstrating that LLMs possess intrinsic reasoning abilities. Empirical evaluations indicate that CoT-decoding significantly improves model performance compared to traditional greedy decoding.

### Strengths and Weaknesses
Strengths:
- The introduction of CoT-decoding provides an effective alternative to prompt engineering, revealing LLMs' reasoning capabilities without explicit prompts.
- The results show substantial improvements over greedy decoding, indicating practical benefits of the proposed method.
- The paper is well-written, with clear explanations and illustrations of the CoT-decoding process.

Weaknesses:
- The primary contribution appears to lack novelty, as it mainly involves selecting a decoding path from pre-generated options.
- The motivation for the study is unclear, particularly regarding the nature of the prompting used and the claim that CoT-decoding enhances reasoning capabilities.
- The method may struggle with tasks requiring identification of correct answer spans, limiting its practical applicability.
- The comparison between CoT-decoding and greedy decoding is unfair, as CoT-decoding requires generating multiple paths, increasing computational costs.
- The empirical evidence is limited to a narrow set of benchmarks, necessitating broader testing across diverse datasets and more complex tasks.
- The evaluation of models is too narrow; including mainstream models like GPT-3.5, GPT-4, and various open-source models would strengthen the findings.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the study's motivation and address the concerns regarding the novelty of the contribution. It would be beneficial to broaden the scope of experiments to include more complex reasoning tasks and diverse benchmarks, such as the MATH benchmark. Additionally, we suggest including a wider range of models in the evaluation to provide a more robust assessment of the method's effectiveness. Finally, a more detailed comparative analysis with other decoding and prompting strategies would help contextualize the contributions of CoT-decoding.