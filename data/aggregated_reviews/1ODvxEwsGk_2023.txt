ID: 1ODvxEwsGk
Title: Diverse Community Data for Benchmarking Data Privacy Algorithms
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 7, 8, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive examination of subpopulation diversity in deidentified datasets, focusing on the challenges posed by generative ML algorithms. The authors propose a formal definition and analysis of subpopulation dispersal, identify challenges for generative approaches, and provide a benchmark dataset along with results from various deidentification techniques. The paper emphasizes the importance of understanding how diverse subpopulations are represented in synthetic data, which can lead to privacy violations. In an updated version, the authors address feedback regarding the division between theory and benchmark sections, clarity of privacy evaluations, and the need for a more comprehensive related works section. They propose a clearer connection between theoretical concepts and empirical evaluations, particularly regarding subgroup dispersal and privacy metrics, while highlighting the importance of diverse communities in benchmarking data to identify potential issues with deidentification algorithms.

### Strengths and Weaknesses
Strengths:
- The formal definition and analysis of subpopulation dispersal is a significant contribution.
- The goal of experimentally assessing generative algorithms for synthetic data is timely and relevant.
- The authors have effectively clarified the connection between theory and empirical evaluations, enhancing the understanding of subgroup dispersal and its implications.
- The expansion of the benchmark data description and the introduction of new metrics provide a more robust framework for evaluating privacy.
- The paper provides a clear introduction, well-defined terms, and a well-organized appendix, with an improved related works section that situates the project within the broader field.

Weaknesses:
- The paper feels like two separate works: one focused on theoretical modeling and the other on empirical evaluation, leading to an incoherent narrative.
- The handling of privacy evaluations remains complex, particularly in comparing differentially private and non-differentially private algorithms.
- Some theoretical aspects, while moved to the appendix, may still be perceived as overly abstract.
- The related works section is minimal and lacks depth in discussing how the contributions differ from existing literature.
- The introduction could benefit from a clearer outline of the paper's structure.
- The connection between theoretical insights and empirical results is insufficiently articulated.

### Suggestions for Improvement
We recommend that the authors improve the coherence of the paper by integrating the theoretical and empirical sections more effectively. Consider relocating extensive proofs to the appendix and replacing them with illustrative examples to enhance readability. Additionally, we suggest improving the clarity of the privacy evaluation section, particularly in comparing differentially private and non-differentially private algorithms, to enhance understanding for readers. Further simplification of theoretical concepts in the main text could improve accessibility. A more comprehensive discussion of how the proposed metrics relate to existing benchmarks and their practical applications would strengthen the paper. Clarifying the relationship between the theory and empirical results, particularly regarding the implications of subpopulation dispersal, would also be beneficial. Lastly, we recommend including a more explicit outline of the paper's structure in the introduction to guide readers through the contributions and expanding the related works section to provide a deeper comparison with existing approaches for contextualizing the contributions.