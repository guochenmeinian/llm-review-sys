ID: esy7pkZmKn
Title: Doubly-Robust Self-Training
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 4, 6, 7, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 5, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a simple yet effective modification to the original loss for self-training by re-weighting terms, resulting in a doubly robust loss function. This approach aims to balance the use of pseudo-labels based on their reliability, enhancing performance in scenarios where the predictor's accuracy varies. The authors provide a theoretical analysis and empirical evaluations on image classification and 3D object detection tasks, demonstrating improvements over standard self-training methods.

### Strengths and Weaknesses
Strengths:
- The method is simple, intuitive, and novel, with a clear theoretical foundation.
- The paper is well-written, providing thorough explanations and analyses of the proposed approach.
- Empirical results show improvements over standard self-distillation in both classification and object detection tasks.

Weaknesses:
- The experimental results raise doubts about the method's effectiveness, particularly regarding the use of curriculum-based loss and the accuracy of baselines.
- There is a lack of comparison with other semi-supervised methods, limiting the assessment of the proposed approach's impact.
- The analysis is primarily based on simplistic models, and its applicability to complex deep networks remains unclear.
- Practical methods for addressing distribution mismatch are not sufficiently detailed, and experiments on this aspect are lacking.

### Suggestions for Improvement
We recommend that the authors improve the experimental section by including comparisons with various state-of-the-art semi-supervised methods, such as MixMatch and FixMatch, to better contextualize their results. Additionally, conducting experiments on benchmark datasets like ImageNet1k and CIFAR100 would provide a more comprehensive evaluation of their method's effectiveness. The authors should also clarify the practical implementation of their proposed loss in the context of distribution mismatch and provide empirical results to support their claims. Finally, addressing the concerns regarding the stability of the loss function during training and refining the theoretical analysis to account for over-parameterized networks would strengthen the paper.