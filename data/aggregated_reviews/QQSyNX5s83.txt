ID: QQSyNX5s83
Title: DN-4DGS: Denoised Deformable Network with Temporal-Spatial Aggregation for Dynamic Scene Rendering
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 5, 5, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel framework for modeling dynamic scenes through a Denoised Deformable Network, which enhances rendering performance by employing a two-stage deformation prediction method to suppress noise. The authors introduce a Noise Suppression Strategy (NSS) and a Decoupled Temporal-Spatial Aggregation Module (DTS) to effectively aggregate temporal and spatial features. Experimental results demonstrate substantial improvements over previous state-of-the-art methods, particularly in rendering quality.

### Strengths and Weaknesses
Strengths:  
- The proposed Temporal Aggregation and Spatial Aggregation methods are sensible and effectively improve dynamic reconstruction capabilities.  
- Detailed ablation studies validate the effectiveness of each component, showing superior performance compared to existing methods.  
- The design of the dual-deformation network is commendable, and the authors provide clear intuitions about their approach.

Weaknesses:  
- The paper lacks citations for relevant recent works, such as "Spacetime Gaussian Feature Splatting for Real-Time Dynamic View Synthesis" and "Real-time Photorealistic Dynamic Scene Representation and Rendering with 4D Gaussian Splatting."  
- Visualization comparisons on the HyperNeRF dataset are inadequate, as they do not include necessary references and suffer from misalignment issues due to inaccurate camera poses.  
- The choice of D-4DGS as a baseline is questionable, as its Hexplane disrupts smoothness, affecting performance.  
- The method's novelty is unclear, as it primarily involves a two-stage deformation prediction without explicit denoising operations.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the method description, particularly regarding the concatenation of features and the role of the embedding $\gamma_{i}$. Additionally, we suggest including more comprehensive comparisons with recent works to strengthen the paper's position in the field. It would be beneficial to provide visual results and address the limitations of the HyperNeRF dataset in the context of rendering metrics. Finally, we encourage the authors to explore the implications of using D-4DGS as a baseline and consider alternative explanations for the method's effectiveness beyond noise reduction in the canonical space.