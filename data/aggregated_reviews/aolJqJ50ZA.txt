ID: aolJqJ50ZA
Title: Explore the Way: Exploring Reasoning Path by Bridging Entities for Effective Cross-Document Relation Extraction
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents PILOT, an enhanced method for cross-document relation extraction that identifies relationships between head and tail entities across multiple documents by utilizing bridging entities. Unlike traditional methods, PILOT employs a dense retriever trained on Wikipedia data to source relevant documents containing these bridging entities, which are then re-ranked to optimize the reasoning path. Experiments demonstrate that PILOT achieves improved performance on the CodRED benchmark dataset compared to existing approaches.

### Strengths and Weaknesses
Strengths:
- The paper proposes a coherent narrative and provides a comprehensive model description, detailing the path construction process.
- PILOT shows performance improvement over state-of-the-art baselines in the CodRED task, indicating its effectiveness.
- The use of bridging entities for constructing reasoning paths is a novel approach that enhances understanding of cross-document relations.

Weaknesses:
- The modeling conflates the concepts of entities and their Wikipedia/Wikidata text, raising questions about generalizability to open-world relation extraction.
- The evaluation lacks statistical testing for significance, particularly for closely related results.
- The reliance on ChatGPT for evaluation instead of human analysis is questionable, given the current limitations of LLMs in such contexts.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their conceptual approach, particularly in distinguishing between entities and their associated text. Additionally, we suggest conducting statistical significance testing to support claims regarding the performance of PILOT. The authors should also consider alternative evaluation methods beyond ChatGPT to ensure robust assessment of their results. Furthermore, a more detailed description of the CodRED dataset and the extraction process for text snippets would enhance the paper's clarity. Lastly, addressing the potential neglect of important context in the scoring function would strengthen the overall model.