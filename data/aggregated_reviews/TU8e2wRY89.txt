ID: TU8e2wRY89
Title: Collaborative Large Language Model for Recommender Systems
Conference: ACM
Year: 2023
Number of Reviews: 3
Original Ratings: -1, -1, -1
Original Confidences: -1, -1, -1

Aggregated Review:
### Key Points
This paper presents CLLM4Rec, a generative recommender system that integrates large language models (LLMs) with the ID paradigm of recommender systems. It aims to bridge the semantic gap in current systems by enhancing LLM vocabulary with user/item ID tokens and utilizing a soft+hard prompting strategy during pretraining. The authors propose a mutual regularization strategy and a recommendation-oriented finetuning strategy, which significantly improve recommendation effectiveness and efficiency, as evidenced by experiments on multiple real-world datasets.

### Strengths and Weaknesses
Strengths:
1. The integration of the ID-based paradigm with LLMs marks a notable advancement in research.
2. The introduction section is well-written and informative.
3. The comprehensive review of LLM and LLM4RS is impressive.
4. The proposed prompt tuning method is innovative and promising.
5. The paper is generally well-structured and easy to understand.

Weaknesses:
1. The problem description lacks clarity and essential details, making it somewhat confusing.
2. The framework appears to be a collection of engineering tricks rather than a cohesive structure with theoretical support.
3. The experimental design is flawed, with insufficient attention to sensitivity analysis and a lack of comprehensive validation, such as ablation studies.
4. The term "Large Language Models" is misapplied, as the models used (GPT-2 and T5) do not meet the criteria for LLMs.
5. Data pollution concerns arise due to the overlap between training and test datasets.
6. The absence of relevant text-based recommendation baselines, such as P5, is notable.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the problem description by including essential steps and necessary formulae. Additionally, we suggest providing a theoretical analysis for each component in the framework to strengthen its cohesiveness. The authors should also enhance the experimental section by conducting more comprehensive validation, including ablation studies and interpretability analysis. Furthermore, we advise the authors to reconsider their terminology regarding "Large Language Models" and address potential data pollution issues. Lastly, we recommend including relevant baselines like P5 to provide a more robust comparison of their approach.