ID: 3roesJsPcd
Title: Ask, Acquire, Understand: A Multimodal Agent-based Framework for Social Abuse Detection in Memes
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a multimodal, agent-based framework that integrates large language models (LLMs) and a large multimodal model (LMM) for detecting social abuse in memes. The authors propose a method that utilizes multi-agent capabilities to adaptively identify abusive content without human interaction, employing a vision expert for enhanced image analysis. The framework demonstrates effectiveness through experiments on benchmark datasets, achieving state-of-the-art performance in accuracy and F1 scores.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant issue in digital media by focusing on social abuse detection in memes, which is of high practical relevance.
- The integration of LLMs and LMMs showcases a certain level of originality and innovation in the approach.
- The experimental evaluation is thorough, providing detailed performance comparisons and illustrative examples that validate the framework's effectiveness.

Weaknesses:
- The innovation in the framework's design is limited, as it does not adequately address the specific challenges of the task and relies heavily on existing techniques.
- The connection between the proposed method and the identified shortcomings of existing approaches is not clearly articulated.
- The experimental setup lacks a comprehensive comparison with other state-of-the-art models, which diminishes the reliability of the results.
- Clarity issues exist in the presentation of figures and the case study, impacting the overall readability and understanding of the methodology.

### Suggestions for Improvement
We recommend that the authors improve the clarity in the introduction and methodology sections by explicitly linking the proposed framework to the specific challenges it aims to address. Additionally, we suggest conducting a more thorough experimental evaluation that includes comparisons with a broader range of state-of-the-art models, such as DisMultiHate and ExplainHM, to enhance the reliability of the findings. Furthermore, we encourage the authors to clarify the rationale behind the choice of two discussion rounds and explore the effects of varying this number on performance. Lastly, addressing the clarity of figures and ensuring the accuracy of the text will enhance the overall presentation of the paper.