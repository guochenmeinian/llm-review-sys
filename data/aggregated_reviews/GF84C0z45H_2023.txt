ID: GF84C0z45H
Title: GenImage: A Million-Scale Benchmark for Detecting AI-Generated Image
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 9, 6, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 2, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the GenImage dataset, which comprises approximately 2.6 million annotated images (1.3 million real and 1.3 million synthetic) generated by various state-of-the-art GAN and diffusion models. It serves as a benchmark for evaluating detection algorithms for generated images, proposing two evaluation tasks: cross-generator image classification and degraded image classification. The authors provide a comprehensive analysis of the dataset, including the performance of existing detectors and the generalization capabilities across various generative models. They acknowledge the limitations of their dataset, particularly its focus on eight types of generators, and plan to include a related work section and additional experiments to evaluate the dataset's performance on new generative models.

### Strengths and Weaknesses
Strengths:
- The dataset addresses a critical gap in existing benchmarks by including diverse data from diffusion models.
- The analysis highlights the failure of current detection models to transfer between GAN and diffusion models, emphasizing the need for this benchmark.
- The authors provide detailed hyperparameter information for various generative models.
- The dataset demonstrates strong generalization performance across multiple detectors and generative models.
- The paper is well-written, clear, and organized, making it accessible for researchers.
- The authors have committed to enhancing the dataset by adding a hidden test set and maintaining a leaderboard.

Weaknesses:
- The related work section lacks some of the latest approaches, which could be included in the final version.
- The dataset primarily focuses on single-class images, limiting the complexity of scenes represented.
- The dataset's focus on only eight generative models raises concerns about scalability and generalization to future models.
- The evaluation does not analyze the performance of different generative models in detail or propose new detection methods.
- The initial contribution level of the dataset is perceived as borderline accept due to the ease of collecting fake image datasets.

### Suggestions for Improvement
We recommend that the authors improve the related work section by including the latest approaches that may not have been published at the time of submission, such as DIRE, once the code is available. Additionally, in Section 4.2 (Frequency Analysis), the authors should cite Durall et al. (2020) to explain the artifacts in GANs and consider using their 1D visualization for Figure 2. To enhance the dataset's generality, we suggest generating more complex, multi-object content for high-resolution images and richer scenes. Furthermore, a detailed discussion of the limitations of the dataset, including its performance against new generative models, should be added. Finally, we encourage the authors to provide clearer visualizations in the frequency analysis section and ensure that the final version addresses all reviewer comments effectively.