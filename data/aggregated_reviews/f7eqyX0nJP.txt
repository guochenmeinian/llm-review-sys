ID: f7eqyX0nJP
Title: ZEROTOP: Zero-Shot Task-Oriented Semantic Parsing using Large Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a prompting method for zero-shot semantic parsing using large language models (LLMs), specifically the ZEROTOP method. The authors propose a two-step approach: first, prompting the LLM to describe user intent, followed by using a sentence encoder to match this description to available intents. The method incorporates an abstainer model to handle slot filling, allowing the LLM to abstain from generating values when none are present in the user utterance. The paper demonstrates that generating intent descriptions improves similarity scores compared to using intent labels directly.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and easy to follow, with clear explanations of the proposed method.
- The combination of abstractive and extractive question-answering, along with fine-tuning on public QA datasets, is well-motivated and shows promising results on the MTOP dataset.
- The authors provide interesting solutions to challenges faced in zero-shot parsing, particularly regarding LLM hallucination and bias towards frequent labels.

Weaknesses:
- Experiments are limited to a single dataset (MTOP), which restricts the generalizability of the findings.
- The absence of a "conclusion" section makes the paper feel incomplete.
- The manual crafting of questions for slot values adds overhead to the proposed approach.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their findings by conducting experiments on additional datasets and exploring alternate models for the abstainer fine-tuning. Additionally, we suggest adding a "conclusion" section to provide a clearer summary of the paper's contributions. Including the crafted questions for each slot in the appendix would enhance transparency and reproducibility. Finally, we encourage the authors to consider discussing the potential for a truly zero-shot agent capable of determining when a user utterance is irrelevant for the given schema.