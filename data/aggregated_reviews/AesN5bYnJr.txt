ID: AesN5bYnJr
Title: No-Regret Online Prediction with Strategic Experts
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 6, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on online decision-making with predictions from strategically behaving experts. At each time-step, K experts provide beliefs about a binary outcome, and a learner selects m experts to minimize loss based on their true beliefs. The authors explore two settings: one with modular utility functions and another with submodular utility functions. They adapt the Follow the Perturbed Leader (FTPL) algorithm for modular settings and propose an "online distorted greedy algorithm" for submodular settings, both achieving no-regret and incentive compatibility. Empirical evaluations on NFL game predictions show similar performance for both algorithms.

### Strengths and Weaknesses
Strengths:
- The authors are the first to address the strategic m-expert problem, motivated by practical applications like forecasting competitions.
- The theoretical analysis includes novel contributions, such as a sufficient condition for perturbation distribution in modular settings and an adaptive regret bound for the WSU algorithm.
- The writing is clear, facilitating understanding of the contributions.

Weaknesses:
- The absence of a lower bound is a significant weakness, especially given the exp-concave loss function, as it lacks evidence for the claim regarding regret rates.
- The experimental results are limited due to insufficient comparisons with relevant baselines, diminishing their impact.
- The paper could benefit from additional background on the non-strategic m-expert problem in the related work section.

### Suggestions for Improvement
We recommend that the authors improve the paper by providing a discussion on the regret lower bound for the problem. Additionally, including theoretical rates and the regret of the naive application of the WSU algorithm in the experimental section would enhance the analysis. It would also be beneficial to clarify the current state of the non-strategic m-expert problem in the related work. Finally, we suggest normalizing the regret curves in the experimental results to better illustrate the algorithms' performance.