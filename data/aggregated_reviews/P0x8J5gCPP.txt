ID: P0x8J5gCPP
Title: The Poorest Man in Babylon: A Longitudinal Study of Cryptocurrency Investment Scams
Conference: ACM
Year: 2024
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Crimson, a system developed for real-time detection of cryptocurrency investment scam websites using Certificate Transparency logs and large language models (LLMs). Over an eight-month period, the system identified 43,572 unique scam sites and provided insights into scammer behavior, including patterns in web design and hosting. The study highlights gaps in existing blacklists and emphasizes the potential of automated systems like Crimson to combat cryptocurrency fraud. However, the paper raises significant concerns regarding its detection methodology, particularly its reliance on predefined keywords and clustering techniques, which may be vulnerable to adaptive scammers. The generalizability of the methodology to other types of scams and the ethical implications of automated interactions with scam websites are also inadequately addressed.

### Strengths and Weaknesses
Strengths:
- Well-written and articulated, providing a clear discussion of how Crimson operates.
- Investigates various aspects of investment scam websites, including hosting providers and financial losses.
- Large-scale measurement and valuable empirical data contribute useful insights into cryptocurrency scam operations.

Weaknesses:
- Heavy reliance on keyword filtering introduces evasion vectors and raises concerns about robustness and evasion resistance.
- The classification accuracy of 88% is inadequate for a security detection system, lacking standard ML metrics for proper evaluation.
- The empirical analysis suffers from sampling bias and lacks justification for clustering parameters.
- Insufficient discussion of ethical implications and the potential biases introduced by the keyword-based approach.

### Suggestions for Improvement
We recommend that the authors improve the robustness of the detection methodology by incorporating adaptive detection methods, such as machine learning models trained on evolving scam behaviors. Additionally, the authors should analyze potential evasion techniques and their impact on detection rates, and provide complete classification metrics, including precision/recall and ROC curves. A thorough discussion on the ethical implications of automated interactions with scam sites is necessary, including safeguards to prevent misuse. Finally, the authors should clarify the motivation behind the use of common libraries like jQuery and address the limitations of their empirical analysis, particularly regarding sampling bias and the validation of clustering parameters.