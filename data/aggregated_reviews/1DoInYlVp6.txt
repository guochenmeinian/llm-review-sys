ID: 1DoInYlVp6
Title: Can Better Solvers Find Better Matches? Assessing Math-LLM Models in Similar Problem Identification
Conference: AAAI
Year: 2024
Number of Reviews: 3
Original Ratings: 7, 6, 5
Original Confidences: 3, 3, 4

Aggregated Review:
### Key Points
This paper presents a novel evaluation strategy for models specialized in mathematical reasoning, focusing on their ability to identify similar problems rather than solely measuring accuracy. The authors utilize the NLP4PLP dataset of probability word problems, evaluating three Math-LLMs: Qwen, DeepSeekMath, and Mathstral. They report metrics including accuracy, inconsistency, and recall@10, revealing that while these models demonstrate good accuracy, their internal representations primarily encode linguistic rather than mathematical similarity.

### Strengths and Weaknesses
Strengths:  
- The evaluation approach emphasizes semantic understanding over mere accuracy, contributing significantly to the field of mathematical reasoning and AI explainability.  
- The results indicate that even math-tuned models heavily rely on linguistic features rather than mathematical semantics.

Weaknesses:  
- The evaluation is limited to a small dataset of probability-related problems, raising questions about the generalizability of the findings to other mathematical domains.  
- There is a lack of theoretical analysis or hypotheses explaining the observed reliance on linguistic features in the models' representations.

### Suggestions for Improvement
We recommend that the authors clarify how pairs for the inconsistency metric are defined and consider evaluating the impact of pairs where both examples could not be solved. Additionally, it would be beneficial to explain how problem embeddings are extracted, as this could significantly impact the evaluation. An ablation study on the layers of the models could provide insights into the distribution of linguistic versus mathematical information. Furthermore, we suggest expanding the dataset to include a broader range of mathematical problems and incorporating a theoretical analysis to explain the reliance on linguistic features in the models' representations. Lastly, we advise improving the organization of the paper, particularly by elaborating on the experimental procedure and clarifying the rationale for using embedding similarity to measure semantic similarity.