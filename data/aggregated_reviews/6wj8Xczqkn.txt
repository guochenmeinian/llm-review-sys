ID: 6wj8Xczqkn
Title: INarIG: Iterative Non-autoregressive Instruct Generation Model For Word-Level Auto Completion
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new model, the Iterative Non-autoregressive Instruct Generation (INarIG), for word-level auto-completion (WLAC) in computer-assisted translation. The model utilizes an iterative non-autoregressive decoder to predict characters as conditional masked language models, enhancing performance through pre-training and multi-task learning strategies. Evaluation results on two language pairs demonstrate significant improvements over previous methods, particularly in handling low-frequency words.

### Strengths and Weaknesses
Strengths:  
- The method is well-described, with justified design decisions and substantial improvements over prior approaches.  
- The experiments are thorough, including ablation studies and analyses addressing model performance with low-frequency words and various pre-training strategies.  
- The model achieves state-of-the-art results on standard datasets, particularly excelling in low-frequency word prediction.

Weaknesses:  
- The paper lacks a latency analysis, which is critical for online applications, as the model's inference requires multiple runs for subword predictions.  
- There is limited novelty, as several components have been previously applied in other contexts, and the paper may not sufficiently differentiate itself from similar works.  
- The results regarding decoding speed and complexity are missing, which are essential for practical applications.

### Suggestions for Improvement
We recommend that the authors improve the paper by including a latency analysis to address the inference speed of the model, particularly in online settings. Additionally, a comparative analysis with similar models, such as Ailem et al. (2022), should be provided to validate the proposed model's advantages. Lastly, we suggest that the authors clarify the decoding speed and complexity in the paper, as this information is crucial for real-world applications.