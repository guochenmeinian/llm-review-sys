ID: sx0xpaO0za
Title: Meta-in-context learning in large language models
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 5, 4, 7, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on "meta in-context learning" (MetaICL) in large language models (LLMs), particularly focusing on GPT-3, GPT-4, and MPT-30B, while also conducting initial experiments with other open-source models like LLaMa 2. The authors demonstrate that LLMs can recursively enhance their in-context learning abilities through exposure to multiple tasks, illustrated using a one-dimensional regression task and a two-armed bandit task. They note that MetaICL shows surprising results, particularly with MPT-30B achieving the lowest mean squared error (MSE). However, the paper raises questions about the novelty of this approach compared to traditional in-context learning and existing literature on domain adaptation, such as "Prompting GPT-3 To Be Reliable" and "MetaICL: Learning to Learn In Context."

### Strengths and Weaknesses
Strengths:
1. The paper effectively highlights the meta-in-context learning capability of LLMs, showcasing its recursive improvement through task demonstrations.
2. The writing is clear, and the experimental setup is well-structured, making it easy to follow the authors' analyses.
3. The authors provide valuable insights into the performance of different models in the context of MetaICL and acknowledge the limitations of their experiments, proposing future research directions.

Weaknesses:
1. The definition of a task is overly narrow, limiting the analysis to simple numerical problems, which may not generalize to more complex language tasks.
2. The paper lacks a dedicated method section, making it difficult to discern the novel contributions from previous work.
3. The experiments primarily focus on GPT-3, GPT-4, and MPT-30B without adequate comparison to benchmark datasets or other LLMs, raising questions about the generalizability of the findings.
4. The performance of MetaICL appears to be negatively impacted in certain tasks, raising questions about its overall effectiveness.
5. The analysis of context length constraints and their influence on results is not fully explored.

### Suggestions for Improvement
We recommend that the authors improve the definition of a task to encompass a broader range of applications, particularly in natural language processing. Conducting experiments on more realistic tasks, such as dialog generation and question answering, would provide valuable insights into the applicability of meta-in-context learning. Additionally, we suggest including a dedicated method section to clarify the novel aspects of the approach and to compare the results with benchmark datasets from the GPT-3 paper. Addressing the similarities with existing works, particularly "MetaICL: Learning to Learn In Context," would also enhance the paper's contribution to the field. Furthermore, we recommend that the authors improve the analysis of why MetaICL performs well with MPT-30B but not with other models, potentially exploring the suitability of the linear function learning benchmark for text-optimized models. Investigating the impact of allowing ICL to utilize a similar context length as MetaICL to assess its accuracy would also be beneficial. Finally, we encourage the authors to examine whether the pretraining objective from Min et al. (2022) is necessary for optimal MetaICL performance, potentially including this analysis in the supplementary material.