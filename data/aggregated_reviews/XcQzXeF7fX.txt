ID: XcQzXeF7fX
Title: On Calibrating Diffusion Probabilistic Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 5, 7, 7, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates the calibration of diffusion probabilistic models (DPMs) by introducing a calibration term to adjust the learned score, which is often uncalibrated. The authors demonstrate that this calibration technique can improve model likelihood and reduce score matching loss, with empirical results showing lower FIDs when using the proposed method. The paper also discusses the martingale nature of the data score term and provides theoretical justifications for the calibration approach.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, presenting a clear and concise calibration method that is theoretically sound and practically applicable to various DPMs.
- Empirical evaluations indicate that the calibration technique effectively enhances model likelihood and reduces score matching loss.
- The authors provide a solid theoretical foundation, including the derivation of concentration bounds and the optional stopping theorem for data scores.

Weaknesses:
- The reliance on model likelihood and FID as the primary metrics for generative performance is a significant limitation, as FID can be misleading with smaller sample sizes.
- The empirical results lack a direct demonstration of the calibration's impact on generative quality, with generated images presented in a way that makes it difficult to discern differences.
- The paper does not adequately address the computational and memory costs associated with the calibration method, nor does it compare against other existing calibration techniques.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Section 3.4 to better articulate the relationship between dataset bias and the calibration technique. Additionally, we suggest incorporating more comprehensive empirical results, including visual comparisons of generated images before and after calibration, to substantiate claims of improved quality. It would also be beneficial to include a discussion of the computational and memory overheads associated with the calibration method, as well as comparisons with other existing calibration approaches to strengthen the paper's contributions.