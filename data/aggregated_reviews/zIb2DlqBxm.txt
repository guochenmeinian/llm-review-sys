ID: zIb2DlqBxm
Title: PHD: Pixel-Based Language Modeling of Historical Documents
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents PHD, a pixel-based language model designed for analyzing historical documents without relying on OCR. The main contributions include: 
1. A novel method for generating synthetic scans that mimic historical documents for pretraining, addressing the lack of large historical datasets.
2. Pretraining PHD on both synthetic scans and real historical newspapers from the 18th-19th centuries.
3. Evaluating PHD on image reconstruction, clustering, language understanding tasks like GLUE, and question answering on SQuAD and a historical QA dataset.
4. Demonstrating PHD's effectiveness in understanding language and its potential for NLP tasks involving historical documents.
5. Releasing datasets, models, and code to support future research.

The paper explores the application of pixel-based language modeling to process historical scans directly, bypassing the noise introduced by OCR.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, clearly articulating the motivation, approach, experiments, results, and limitations.
- It presents a novel application of pixel-based language models to historical document analysis, which is an intriguing direction for processing historical texts.
- The release of new datasets, models, and code could significantly benefit the research community.

Weaknesses:
- A significant portion of the pretraining data consists of modern text, which may hinder the model's adaptation to historical contexts. 
- The evaluation tasks primarily involve modern text, with limited historical evaluation data, which may not adequately assess performance.
- The clustering analysis lacks clarity regarding its purpose and effectiveness.
- The choice of a 16-pixel height for patches may not be optimal for varying scanning resolutions, and the evaluation of pixel-based completions requires more robust quantitative methods.

### Suggestions for Improvement
We recommend that the authors improve the diversity of historical data in the pretraining set to enhance model adaptation. Additionally, incorporating more historical evaluation data would provide a better assessment of performance. We suggest clarifying the purpose of the clustering analysis and including examples of cropping issues in the evaluation. A discussion comparing the efficiency of PHD and BERT, particularly regarding the encoding of text, would also be beneficial. Finally, testing the generalizability of the trained models across different scanning resolutions would strengthen the paper.