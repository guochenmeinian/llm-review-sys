ID: 2ltOkbo67R
Title: Contextual Multinomial Logit Bandits with General Value Functions
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 5, 6, 4, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an exploration of contextual multinomial logit (MNL) bandits with general value functions, addressing both stochastic and adversarial contexts. The authors propose an epoch-based algorithm utilizing an offline regression oracle, achieving various regret bounds: $T^{2/3}$ for finite and linear classes with uniform exploration, improving to $\sqrt{T}$ with better exploration. In adversarial settings, the algorithm achieves $T^{5/6}$ and $T^{3/4}$ with uniform and improved exploration, respectively, and $\sqrt{T}$ using Thompson sampling. Notably, the algorithms do not depend on $\kappa$, enhancing their dependency on $B$.

### Strengths and Weaknesses
Strengths:
- The paper is the first to consider a general value function for MNL bandits, significantly expanding the scope of MNL problems.
- It introduces innovative techniques that may inspire future research and applications.
- The methods applied to linear cases demonstrate improved statistical and computational efficiency compared to prior works.

Weaknesses:
- The regret bound exhibits superlinear dependency on $K$ for $\sqrt{T}$, raising concerns about its tightness.
- The absence of regret lower bounds complicates the assessment of the achieved upper bounds' tightness.
- There is a lack of empirical validation to support theoretical claims, limiting practical applicability.
- Several terms and mathematical notations are introduced without proper definitions, leading to potential confusion.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their definitions and notations, particularly for Err_log, Reg_log, and ERM, as well as the definition of |F| in Lemma 3.1. Additionally, we suggest including empirical experiments to validate theoretical findings, which would enhance the paper's impact. Addressing the computational inefficiency of the Feel-Good Thompson sampling algorithm and providing insights on the implications of $\kappa$ and its absence in the regret bounds would also strengthen the paper. Finally, we encourage the authors to better organize the presentation of their results, focusing on the most significant contributions.