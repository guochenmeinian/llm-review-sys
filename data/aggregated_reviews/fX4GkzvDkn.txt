ID: fX4GkzvDkn
Title: MultiGPrompt for Multi-Task Pre-Training and Prompting on Graphs
Conference: ACM
Year: 2023
Number of Reviews: 3
Original Ratings: -1, -1, -1
Original Confidences: -1, -1, -1

Aggregated Review:
### Key Points
This paper presents MultiGPrompt, a novel framework for multi-task pre-training and prompting aimed at enhancing few-shot learning on graphs. The authors propose a dual-prompt mechanism to transfer both task-specific and global pre-trained knowledge, addressing task interference through the use of pretext tokens. Experimental results on six benchmark datasets demonstrate the framework's superior performance in few-shot node and graph classification compared to existing methods.

### Strengths and Weaknesses
Strengths:
1. The extension of the "pre-training and prompting" paradigm to graph learning is significant and well-motivated.
2. The techniques introduced, including composed and open prompts as well as pretext tokens, are intuitive and reasonable.
3. The evaluation protocol is comprehensive, incorporating various baselines and conducting ablation studies and hyperparameter analyses.

Weaknesses:
1. The framework's applicability to edge-level tasks, such as link prediction, remains unclear, as experiments focus solely on node and graph classification.
2. The absence of statistical significance tests raises concerns about the reliability of the performance differences observed between MultiGPrompt and baseline models, particularly given subtle gaps in results.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of MultiGPrompt by demonstrating its performance on the link prediction task, specifically on datasets like Cora and Citeseer. Additionally, conducting statistical significance tests to compare MultiGPrompt with the strongest baseline in Table 2 and each ablation version in Table 3/Figure 5 would enhance the robustness of the findings. Furthermore, providing a theoretical analysis of the number of tunable parameters in MultiGPrompt could complement the empirical efficiency analysis presented in Section 5.4.