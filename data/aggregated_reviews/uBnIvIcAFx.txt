ID: uBnIvIcAFx
Title: Vera: A General-Purpose Plausibility Estimation Model for Commonsense Statements
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents VERA, a general-purpose plausibility estimation model for commonsense statements, trained on a large-scale dataset of correct and incorrect commonsense assertions from QA datasets and knowledge bases. The authors demonstrate that VERA outperforms existing models in commonsense problem-solving, filtering LM-generated knowledge, and detecting errors made by ChatGPT. The model serves as a versatile tool for the NLP community, functioning as both a reward model and a classifier.

### Strengths and Weaknesses
Strengths:
- The VERA model is significant for the NLP community, showcasing superior performance compared to existing models, including GPT-4, in various tasks.
- The paper is well-organized and clearly presents the research content.
- The empirical results are promising, with VERA effectively detecting erroneous commonsense statements.

Weaknesses:
- The paper's content feels incomplete, particularly regarding the ablation analysis, which should be moved to the main text for clarity.
- The training objectives are complex, and the lack of hyper-parameter details raises concerns about reproducibility.
- The novelty of the method is questioned, as training a discriminative model for verification is not a new concept.
- The experimental comparisons lack robustness, particularly in calibration methods applied solely to VERA without ablation studies on their impact.

### Suggestions for Improvement
We recommend that the authors improve the completeness of the paper by including the ablation analysis in the main text to enhance understanding. Additionally, providing explicit details about hyper-parameters would aid reproducibility. The authors should consider including a simple baseline comparison with a GPT-2 cross-entropy score and address the role of context in commonsense inference. Furthermore, the authors should clarify the rationale behind using a real-valued score for plausibility estimation and include a quantitative error analysis across different commonsense knowledge dimensions. Lastly, we suggest that the authors provide more rigorous statistical backing for claims regarding the effectiveness of the two-stage training process.