ID: qS1ip2dGH0
Title: The Shifted and The Overlooked: A Task-oriented Investigation of User-GPT Interactions
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis of user queries to LLMs, specifically through the ShareGPT dataset, to identify discrepancies between real-world user needs and traditional NLP benchmarks. The authors propose a methodology for automatically labeling and clustering these queries using GPT-4, which reveals shifting trends and challenges in NLP. The study aims to provide a roadmap for bridging the gap between user demands and academic benchmarks.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant issue: the need for NLP benchmarks to reflect real-world scenarios.
- It offers a comprehensive analysis of user-GPT interactions compared to existing NLP datasets, identifying critical gaps.
- The annotation approach for domain and task identification is reasonable and aligns with human evaluation.
- The insights into task diversity and marginalized user groups provide valuable direction for future research.

Weaknesses:
- The focus on only two sources, ShareGPT and Huggingface datasets, may not capture the full spectrum of real-world scenarios.
- Ethical implications of aligning LLMs with user needs are not sufficiently addressed.
- The paper lacks discussion on LLM performance for newly identified tasks, which would clarify task difficulty.
- The reliance on GPT-4 for annotation raises reproducibility concerns, and the analysis is limited to a small subset of available datasets.

### Suggestions for Improvement
We recommend that the authors improve the paper by expanding the dataset sources beyond ShareGPT and Huggingface to better represent real-world scenarios. Additionally, addressing the ethical implications of aligning LLMs with user needs would strengthen the discussion. The authors should also include an analysis of LLM performance on the newly identified tasks to provide insights into their difficulty. Finally, clarifying the criteria for selecting and prioritizing task types from the silver-tagged dataset would enhance the paper's contributions.