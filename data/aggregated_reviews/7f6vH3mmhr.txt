ID: 7f6vH3mmhr
Title: Multi-Agent Learning with Heterogeneous Linear Contextual Bandits
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 6, 5, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on heterogeneous multi-agent contextual bandit problems, proposing the H-LinUCB algorithm, which coordinates agents by pooling data until a dissimilarity threshold is reached. The authors demonstrate that H-LinUCB is optimal in scenarios of high similarity or dissimilarity among tasks. The paper also explores a multi-agent linear contextual bandit setting with a central server, where agents have different unknown parameters constrained by a known $\ell_2$-norm bound. The proposed UCB-based algorithm collaborates initially and then learns individually, with theoretical regret bounds provided.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and organized, addressing a significant area of interest in multi-agent learning.
- The theoretical analysis is rigorous, and the results are strong, particularly in the context of heterogeneous settings.
- The proposed algorithm shows improvements over existing methods by adapting coordination based on dissimilarity levels.

Weaknesses:
- The experimental section is relatively weak, lacking scenarios where H-LinUCB distinctly outperforms other algorithms.
- The introduction of the proposed algorithm is difficult to follow, with many new variables introduced without adequate explanation.
- The algorithm's reliance on the known dissimilarity parameter $\epsilon$ raises concerns about its practicality in real-world applications.

### Suggestions for Improvement
We recommend that the authors improve the experimental section by including scenarios where H-LinUCB uniquely succeeds or achieves the best regret, or at least discuss the challenges in demonstrating this. Additionally, we suggest clarifying the introduction of the proposed algorithm in Section 4.1 by providing explanations for new variables. Furthermore, we encourage the authors to address the practicality of assuming $\epsilon$ is known and consider discussing alternative methods for determining when to stop coordination based on $\epsilon$.