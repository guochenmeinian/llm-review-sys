ID: xax5eWeObb
Title: Practical Equivariances via Relational Conditional Neural Processes
Conference: NeurIPS
Year: 2023
Number of Reviews: 7
Original Ratings: 2, 7, 8, 6, -1, -1, -1
Original Confidences: 4, 5, 4, 3, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an extension of conditional neural processes (CNPs) that incorporates relational structures to model equivariance, aiming to enhance performance in high-dimensional scenarios. The authors propose a method that utilizes relational information while discarding absolute information, demonstrating its effectiveness through various empirical tasks, including synthetic regression and Bayesian optimization.

### Strengths and Weaknesses
Strengths:
1. The paper is well-organized and presents a clear motivation for incorporating equivariance into CNPs, with robust theoretical results supported by proof.
2. The proposed models are shown to be translation-equivariant and perform comparably or better than existing CNP and GNP models across a diverse range of tasks.

Weaknesses:
1. The motivation for using relational inductive biases is unclear, lacking specific scenarios where relational information is necessary.
2. The novelty of the work is limited, as similar concepts have been explored in prior research, particularly regarding equivariance in neural processes.
3. The analysis is incomplete; the significance of KL divergences reported in the results is not well explained, and the paper lacks comparisons with other equivariant CNPs.
4. The definition of equivariance is incorrect, and the runtime complexity of the proposed method is higher than that of traditional CNPs, which undermines one of the motivations for developing CNPs.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation for relational inductive biases in the Introduction, specifying scenarios where this information is critical. Additionally, we suggest providing a more thorough discussion of the novelty of the approach in relation to existing literature, particularly concerning the Set Transformer. The authors should also clarify the meaning of KL divergences in their results and include comparisons with other equivariant CNPs to strengthen their analysis. Finally, we advise revisiting the definition of equivariance to ensure it aligns with established standards and addressing the runtime complexity concerns to highlight the advantages of their approach.