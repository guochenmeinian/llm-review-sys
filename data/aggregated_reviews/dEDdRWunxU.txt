ID: dEDdRWunxU
Title: Fed-CO$_{2}$: Cooperation of Online and Offline Models for Severe Data Heterogeneity in Federated Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 7
Original Ratings: 6, 6, 5, 5, -1, -1, -1
Original Confidences: 2, 3, 2, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to address both label and feature skew in federated learning (FL) through a framework called Fed-CO2. The authors propose a dual model structure, where each client maintains an online model for general knowledge and an offline model for personalized knowledge. The framework incorporates intra-client and inter-client knowledge transfer mechanisms to enhance model cooperation and performance across diverse datasets.

### Strengths and Weaknesses
Strengths:
- The cooperation mechanism between online and offline models effectively addresses data heterogeneity.
- The Fed-CO2 framework comprehensively tackles both label and feature skew within a unified approach.
- Extensive experiments demonstrate that Fed-CO2 outperforms various existing personalized federated learning algorithms.

Weaknesses:
- The model's complexity may hinder implementation, especially with a large number of clients.
- The performance is still dependent on the quality of training data, which may not be consistent in federated settings.
- The paper lacks clarity on scalability regarding increased data, feature dimensions, or client numbers.
- The writing quality needs improvement, with grammatical issues and inconsistent notation.
- The motivation for personalizing batch normalization parameters is unclear, and definitions for label and feature skew are missing.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing by addressing grammatical issues and ensuring consistent notation throughout the paper. Additionally, we suggest providing formal definitions for label and feature skew in the main body. The authors should also clarify the motivation behind personalizing batch normalization parameters and consider including theoretical guarantees to strengthen the paper's contributions. Furthermore, conducting additional experiments to evaluate the performance of the online and offline models in various settings, such as the DomainNet dataset, would enhance the robustness of the findings.