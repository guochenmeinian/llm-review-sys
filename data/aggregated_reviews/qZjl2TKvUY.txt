ID: qZjl2TKvUY
Title: One Risk to Rule Them All: A Risk-Sensitive Perspective on Model-Based Offline Reinforcement Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 6
Original Ratings: 6, 6, 7, 6, -1, -1
Original Confidences: 4, 4, 2, 5, -1, -1

Aggregated Review:
### Key Points
This paper presents a model-based offline reinforcement learning (RL) algorithm, 1R2R, that aims to address risk-averse decision-making by incorporating both aleatoric and epistemic uncertainties. The authors propose a method that learns a posterior distribution over Markov Decision Process (MDP) transitions using an ensemble of neural networks and samples successor states from the worst-case perturbation of the learned model, effectively modeling the Bellman equation for dynamic risk. The algorithm demonstrates superior performance in both deterministic and stochastic environments.

### Strengths and Weaknesses
Strengths:
- The method is clearly articulated, and the high-level concepts are well-explained.
- The paper is well-structured and reader-friendly, providing a concise introduction to relevant background and related work.
- Extensive experiments validate the proposed approach, showcasing its effectiveness in challenging environments.

Weaknesses:
- The method appears to primarily target dynamic risk but shows performance in risk-neutral and static risk objectives without clear justification, leading to concerns about its theoretical grounding.
- The ablation studies are simplistic; they should explore the contributions of pessimism regarding aleatoric and epistemic uncertainties separately.
- The approach may lack flexibility compared to previous methods that address distributional shift and risk-sensitivity independently.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the introduction by explicitly stating how risk-averse RL reduces both epistemic and aleatoric uncertainties. Additionally, we suggest expanding the ablation experiments to include comparisons of computational costs with methods using distributional value functions and to differentiate between dynamic and static risk measures. Furthermore, we encourage the authors to discuss the advantages of 1R2R over existing baselines like RAMBO in more depth. Finally, addressing the theoretical guidance on model selection for capturing epistemic uncertainty would enhance the paper's robustness.