ID: hCg4w8L8Dt
Title: Knowledge Distillation for High Dimensional Search Index
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 5, 7, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method called KDindex for learning lightweight indexes through knowledge distillation from high-quality approximate nearest neighbor search (ANNS) models. The authors propose a framework that incorporates ranking-oriented loss functions and additional constraints to enhance the approximation quality. They provide a detailed analysis of KDindex's performance across various datasets, including SIFT1M and GIST1M, and clarify discrepancies between recall numbers due to different search methods. The effects of hyper-parameters B and W on storage and search latency are discussed, noting that larger B increases latency while W has minimal impact. The authors also address the complexity of the balance strategy versus its marginal performance improvement and provide insights into the time complexity of KDindex compared to AQ, PQ, and OPQ methods. Experimental results demonstrate that KDindex achieves significant improvements over baseline quantization methods and previous learning-based approaches.

### Strengths and Weaknesses
Strengths:
- KDindex shows strong empirical performance, outperforming existing learnable quantization-based indexes and some state-of-the-art ANNS methods.
- The experimental section includes comprehensive ablation studies and sensitivity analyses, providing insights into the effectiveness of various components.
- The authors provide a thorough explanation of the discrepancies in performance metrics and the rationale behind hyper-parameter choices.
- Detailed analysis of the balance strategy's complexity and its impact on retrieval performance is commendable.
- The paper demonstrates good generalization of KDindex across different similarity functions.

Weaknesses:
- The paper lacks discussion of related work, such as Poeem, JPQ, and MoPQ, and does not compare with Distill-VQ or state-of-the-art ANN algorithms in benchmarks.
- The balance strategy employed does not appear to significantly enhance performance and adds complexity to the training process.
- Presentation issues exist, including unclear descriptions of the test-time inference process and missing information on indexing time and limitations of the proposed method.
- The choice of optimal hyper-parameters lacks clarity regarding their applicability across all datasets.
- The paper does not include experiments with larger datasets like 10M SIFT, which could enhance the findings.

### Suggestions for Improvement
We recommend that the authors improve the literature review by including discussions on related works like Poeem, JPQ, MoPQ, and Distill-VQ, along with comparisons to state-of-the-art ANN algorithms such as NGT-qg and Vamana. Additionally, we suggest providing a clearer explanation of the test-time inference process and including indexing time metrics. It would also be beneficial to add a Limitations section to address potential drawbacks and societal impacts of the proposed method. Furthermore, we recommend that the authors improve clarity by explicitly stating the criteria for selecting hyper-parameters B = 8 and W = 256, and whether this setting is optimal across all datasets. We also suggest including a comparison of training times for KDindex with and without the balance strategy in Table 3 to better illustrate the trade-offs involved. Finally, we encourage the authors to consider conducting experiments with larger datasets to strengthen their conclusions and address the potential limitations of their work regarding different document corpora.