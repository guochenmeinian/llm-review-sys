ID: vt2qkE1Oax
Title: Learning Segmentation from Point Trajectories
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 7, 6, 6, 5, 6, -1, -1
Original Confidences: 4, 3, 4, 4, 5, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel loss function designed to enhance video object segmentation by integrating both instantaneous optical flow and long-term point tracking information. The authors propose that this approach allows for the grouping of trajectories into low-rank matrices, enabling a more effective representation of object motion. The method demonstrates superior performance compared to existing techniques in motion-based segmentation across various datasets, including synthetic and real-world benchmarks.

### Strengths and Weaknesses
Strengths:
1. The authors address significant issues in the field, providing an original contribution that, while incremental, is well-motivated.
2. The proposed method is detailed, reproducible, and effectively evaluated through comprehensive experiments.
3. The mathematical derivation of the loss function is clearly explained, making it accessible even to those without a deep mathematical background.

Weaknesses:
1. The main contribution regarding the loss functions lacks clarity, particularly in relation to its effectiveness across different segmentation methods.
2. The paper does not adequately clarify the specific segmentation tasks targeted, particularly distinguishing between multi-object and binary segmentation.
3. The resolution of some figures is low, and there is insufficient comparison regarding inference speed.
4. The assumption of rigid objects may limit the applicability of the proposed method to general video segmentation tasks.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the proposed method by clearly stating its name or acronym in the comparison tables instead of using "ours." Additionally, the authors should provide a more detailed discussion of the specific segmentation tasks addressed, particularly in the experiment section. Including comparisons with models that do not rely on optical flow for self-supervision would enhance the evaluation of the proposed method. Furthermore, we suggest that the authors analyze the impact of long-term point trajectories on performance, particularly in scenarios involving occlusions or non-rigid objects. Lastly, exploring the integration of appearance information in segmentation could provide valuable insights into the method's effectiveness.