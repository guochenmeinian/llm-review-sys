ID: hHKBiMPfCj
Title: Rectifying Open-Set Object Detection: Proper Evaluation and a Taxonomy
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 7, 6, 7, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new taxonomy of Open Set Object Detection (OSOD) formulations, identifying weaknesses in existing frameworks, particularly OSOD-I and OSOD-II. The authors argue that OSOD-I is limited as it only addresses known objects misclassified as unknown, while OSOD-II is ill-posed due to its vague definition of "objects." They propose a novel formulation, OSOD-III, which specifies that unknown objects must belong to the same super-class as known classes. The authors advocate for using Average Precision as a more suitable evaluation metric and introduce a benchmark based on this new formulation, revealing that current OSOD methods often underperform compared to simple baselines. Additionally, the paper analyzes failure modes in tested detectors for OSOD-III tasks, revealing that while detectors achieve high recall for unknown instances, they often misclassify known instances as unknown. The authors conducted experiments applying Non-Maximum Suppression (NMS) both within categories and across known and unknown predictions, highlighting that aggressive NMS reduces Average Precision (AP) for both categories. They argue that the misclassification issue stems from poorly calibrated confidence scores between known and unknown categories and assert that metrics like WI and AOSE are not valid for OSOD-II/III. Their newly constructed dataset is structured hierarchically, unlike COCO and PASCAL-VOC.

### Strengths and Weaknesses
**Strengths:**
- The paper tackles a significant yet underexplored problem in OSOD, providing a clear and structured analysis of existing formulations.
- It effectively highlights the inadequacies of previous metrics and proposes a well-defined new formulation and benchmark.
- The presentation is clear, with helpful visual aids that clarify the distinctions among various formulations.
- The thorough analysis of misclassification issues in OSOD-III emphasizes the challenges of distinguishing between known and unknown instances.
- The inclusion of additional experiments and results strengthens the benchmark for the new OSOD setting.
- The authors address reviewer concerns by providing supplementary material and clarifying the limitations of existing metrics.

**Weaknesses:**
- The evaluation metrics proposed, such as A-OSE and WI, are criticized for being based on single operating points and requiring arbitrary confidence thresholds.
- The paper lacks a thorough analysis of why existing methods fail in the new OSOD-III setting, limiting its impact on future research.
- There is insufficient discussion of the limitations of the proposed formulation, particularly regarding its applicability in diverse scenarios like autonomous driving.
- The analysis lacks depth in exploring the implications of the new OSOD setting compared to open-vocabulary detection.
- The paper does not sufficiently detail the challenges posed by the new setting or suggest future research directions.
- There is a need for more models to be included in the experiments to enhance the robustness of the findings.

### Suggestions for Improvement
We recommend that the authors improve their analysis of experimental results to provide insights into why current state-of-the-art methods perform poorly in the OSOD-III setting. Additionally, we suggest incorporating Non-Maximum Suppression (NMS) in their evaluations to potentially enhance performance outcomes. The authors should also consider discussing the implications of their formulation in broader contexts, especially in applications like autonomous driving, where detecting all unknown objects may be critical. Furthermore, we recommend that the authors improve the analysis of the implications of the new OSOD setting and explicitly outline the challenges it presents, as well as potential future research directions. Incorporating more models into the experiments would provide a broader evaluation of the proposed methods. Finally, including a limitation section would strengthen the paper by addressing the broader applicability of the proposed super-class concept and clarifying the significance of the findings in relation to open-vocabulary detection, potentially including a summary metric, such as the harmonic mean of AP for known and unknown instances, to enhance the clarity of the results.