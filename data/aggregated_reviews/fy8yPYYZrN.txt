ID: fy8yPYYZrN
Title: Learning Scalable Structural Representations for Link Prediction with Bloom Signatures
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for link prediction in graphs by utilizing Bloom signatures to learn scalable structural representations. The authors propose that this approach enhances the expressiveness of traditional message-passing mechanisms in graph neural networks (GNNs) by efficiently encoding node neighborhoods. Extensive experiments demonstrate the method's effectiveness and efficiency compared to existing hash-based techniques, showing significant improvements in scalability and computational speed.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and easy to understand.
- Bloom hashing theoretically approximates pairwise heuristics and learns relations in an end-to-end manner.
- The proposed method shows effective link prediction performance with reduced storage requirements.
- Comprehensive experimental validation across various datasets highlights the method's versatility and effectiveness.

Weaknesses:
- The paper lacks theoretical illustrations of the expressiveness of MPNN with Bloom signatures compared to vanilla GNNs.
- Important experiments are missing, particularly regarding the impact of hash function selection and embedding size.
- There are inconsistencies in evaluation metrics across datasets, complicating comparative analysis.
- Insufficient analysis of data distribution and limitations of Bloom signatures is provided.
- The authors do not report space overhead or discuss the limitations of structural features that cannot be constructed by Bloom filters.

### Suggestions for Improvement
We recommend that the authors improve the theoretical analysis of MPNN with Bloom signatures to clarify its expressiveness over standard GNNs. Additionally, the authors should include experiments addressing the impact of different hash functions and embedding sizes. A consistent set of evaluation metrics across datasets would enhance clarity in performance comparisons. Furthermore, we suggest providing a detailed explanation of data distribution patterns and the limitations of Bloom signatures, including a discussion on structural features that cannot be reconstructed. Lastly, reporting space overhead and addressing the inference speed in real-world applications would strengthen the paper's claims of scalability.