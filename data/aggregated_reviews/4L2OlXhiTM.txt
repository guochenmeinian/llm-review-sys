ID: 4L2OlXhiTM
Title: FIRAL: An Active Learning Algorithm for Multinomial Logistic Regression
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 7, 6, 6, 6, 7, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel active learning algorithm called FIRAL for pool-based active learning in multinomial logistic regression. The authors establish that the excess risk is bounded by the Fisher Information Ratio and propose an algorithm to optimize this ratio, ensuring performance guarantees. Theoretical analysis and extensive experiments validate the proposed approach, demonstrating its superiority over existing methods in terms of classification error.

### Strengths and Weaknesses
Strengths:
1. The proposed algorithm is grounded in solid mathematical theory, providing asymptotic bounds for excess risk under sub-Gaussian assumptions.
2. Experimental results convincingly show that FIRAL outperforms competitive methods, including strong baselines.

Weaknesses:
1. The manuscript is highly technical, making it challenging to read and understand.
2. There is insufficient comparison with existing methods regarding computational efficiency and novelty, particularly in relation to previous works [11] and [14].
3. The algorithm's complexity remains high, which may deter practical implementation.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the manuscript by simplifying technical explanations and enhancing the introduction of related work. Specifically, highlight the novelty of the approach compared to [11] and [14], clarifying the self-concordant properties and the challenges in applying existing analyses to logistic regression. Additionally, provide a more detailed discussion on how to obtain the labeled dataset $S_0$ and its influence on the algorithm's performance. Address the assumptions in Theorem 3 more explicitly, and consider conducting an ablation study on hyperparameters, such as \(\eta\). Finally, we suggest including comparisons with uncertainty-based active learning methods and exploring applications to more complex classifiers.