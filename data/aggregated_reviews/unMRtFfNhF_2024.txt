ID: unMRtFfNhF
Title: Data Debugging is NP-hard for Classifiers Trained with SGD
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 5, 3, 3, -1, -1
Original Confidences: 2, 4, 4, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the computational complexity of data debugging, specifically identifying subsets of training data that enhance model accuracy on a given test point. The authors propose that for linear classifiers trained with SGD, the debugging task is NP-hard for general loss functions, while solvable in linear time for linear loss functions. Additionally, it is NP-hard for hinge-like loss functions with more than two features.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, with a clearly motivated problem.
- The proofs are succinct, correct, and demonstrate creativity.

Weaknesses:
- The focus is limited to linear classifiers, which is overly restrictive.
- Many proofs contain "magic constants," complicating understanding and intuition.
- The constructions for hardness results are contrived and not reflective of practical classifier training.
- There is a complete lack of empirical evaluation, raising concerns about the applicability of theoretical results.

### Suggestions for Improvement
We recommend that the authors improve the clarity and exposition of the proofs to enhance logical flow and understanding. Additionally, consider generalizing results beyond adversarial loss functions and training orders, as these assumptions may not hold in practical scenarios. We urge the authors to analyze more commonly used loss functions, such as binary cross-entropy, and to provide empirical evaluations, even on toy datasets, to substantiate the theoretical claims. Furthermore, addressing the applicability of results under standard initialization schemes and perturbations would strengthen the paper's contributions.