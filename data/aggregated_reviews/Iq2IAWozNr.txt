ID: Iq2IAWozNr
Title: Smoke and Mirrors in Causal Downstream Tasks
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 6, 7, 8, 6, -1, -1, -1, -1, -1
Original Confidences: 3, 1, 3, 2, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive examination of biases in Randomized Controlled Trials (RCTs) that can invalidate causal estimates. The authors propose a theoretical framework that highlights how common choices in the literature may lead to biased estimates, supported by empirical results from a novel RCT involving garden ants (Lasius neglectus) and microparticle application. They introduce two new benchmark datasets, including an Ant Dataset and CausalMNIST, and provide representation desiderata for accurate causal queries.

### Strengths and Weaknesses
Strengths:
- The paper addresses an important and under-explored area of causal inference, facilitating further research.
- It identifies crucial sources of bias and offers potential solutions, supported by extensive experimental evidence across numerous models.
- The authors have created a new dataset and benchmark, enhancing the practical applicability of causal representation learning.

Weaknesses:
- The literature review is limited to the last two years, neglecting relevant prior works.
- The theoretical argumentation for proposed solutions is minimal, and the empirical validation of these solutions is insufficient.
- The presentation of the dataset is limited, lacking visualizations and details on the dataset collection process.
- The main theoretical analysis focuses on binary classification, which may not generalize well, and the paper attempts to cover too much, leading to a lack of clarity in some sections.

### Suggestions for Improvement
We recommend that the authors improve the literature review by incorporating relevant prior works to provide a more comprehensive context. Additionally, the authors should enhance the theoretical argumentation for their proposed solutions and provide more experimental evidence on how to overcome identified biases. It would be beneficial to include more detailed visualizations and explanations of the dataset collection process. Furthermore, we suggest clarifying the theoretical analysis to ensure it is accessible and applicable to a broader range of real-world settings. Lastly, the authors should elaborate on the advantages of their proposed dataset over existing benchmarks for causal questions.