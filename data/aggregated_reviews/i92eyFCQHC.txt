ID: i92eyFCQHC
Title: WildVision: Evaluating Vision-Language Models in the Wild with Human Preferences
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 6, 4, 8, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a benchmarking study of vision-language models (VLMs) through the development of the WildVision-Arena (WV-Arena) platform and the WildVision-Bench dataset. The dataset includes over 20,000 multimodal conversations and 8,000 votes, facilitating a comprehensive analysis of VLM performance. The authors propose a dual evaluation approach that combines human judgments and a model-based evaluation using GPT-4, which ensures robustness and efficiency. Significant findings include a high Spearman correlation of VLM outputs with human preferences, while also detailing failure cases in top-performing models regarding contextual cues, spatial reasoning, and hallucinations. The authors address concerns about the dataset's safety and diversity, which are maintained through rigorous filtering processes, including manual reviews and the use of an NSFW detector. However, the accessibility of the WV-Bench benchmark for global users remains unclear, as it relies on a commercial product.

### Strengths and Weaknesses
Strengths:
- The study addresses an important yet underexplored area of VLMs and human preferences.
- The development of the WV-Arena platform and WildVision-Bench dataset is a commendable effort that provides valuable resources for VLM research.
- The dataset is derived from a large and diverse pool, ensuring representativeness.
- The dual evaluation method enhances the reliability of the benchmark.
- The authors demonstrate a commitment to safety and diversity through thorough curation processes.

Weaknesses:
- The dataset size of 500 samples is relatively small, limiting the robustness of the findings.
- The construction and safety measures of the dataset are inadequately described, necessitating further clarification.
- Concerns remain regarding the accessibility of closed-source models like GPT-4 for general users.
- The proposed solutions for copyright issues may not sufficiently address potential risks, as noted by reviewers.
- The reliance on GPT-4 as a judge model raises questions about the potential benefits of incorporating human judges.

### Suggestions for Improvement
We recommend that the authors improve the discussion regarding how post-processing engineering components of VLMs affect their conclusions. Additionally, the authors should explore cases where VLM outputs do not align with human preferences to provide a clearer understanding of the limitations of their method. It is crucial to address the accessibility of the WV-Bench benchmark and clarify the evaluation speed and quota limitations associated with using commercial software. Furthermore, we suggest including detailed discussions on the accessibility of GPT-4 and the measures taken to mitigate copyright issues in the main paper. Lastly, we recommend moving the limitations discussion from the supplementary material to the main text for better visibility and understanding.