ID: RhE01dqo8u
Title: Feature Selection in the Contrastive Analysis Setting
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 4, 7, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for feature selection in a contrastive analysis setting, termed "Contrastive Feature Selection." The authors aim to identify salient features in a target dataset that are absent in a background dataset, leveraging principles of Information Theory. The proposed approach involves a two-step procedure: training an autoencoder on the background data followed by a feature selection module to capture additional information from the target data. The paper includes empirical results on semi-synthetic and real-world datasets, demonstrating the method's effectiveness.

### Strengths and Weaknesses
Strengths:
1. The introduction of a "contrastive feature selection" method is novel and well-justified.
2. The authors provide experimental validation against popular baselines in feature selection.
3. The method relies solely on weak supervision, enhancing its applicability.
4. The results indicate superior performance for downstream tasks, and code is provided for reproducibility.

Weaknesses:
1. The architecture of the representation and reconstruction networks is unclear and lacks specific details.
2. There is no ablation study to assess the impact of omitting the background dataset.
3. The paper does not analyze how different populations of background and target datasets affect results.
4. Limited evaluation on practical classification tasks, with most datasets having fewer than ten classes.
5. The theoretical analysis lacks clarity, raising concerns about performance guarantees.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the architecture by specifying the exact layers of the background representation encoder and the reconstruction networks. Additionally, conducting an ablation study to evaluate the method's performance without the background dataset would strengthen the analysis. We suggest including experiments on more diverse classification tasks with greater than ten classes to validate the method's effectiveness. Furthermore, providing a clearer definition of mutual information $I$ and discussing the implications of different dataset populations would enhance the theoretical foundation of the work. Lastly, addressing the limitations related to the assumptions made in the method, particularly regarding feature independence, would improve the paper's robustness.