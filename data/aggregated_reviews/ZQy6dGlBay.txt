ID: ZQy6dGlBay
Title: A Benchmark Dataset for Event-Guided Human Pose Estimation and Tracking in Extreme Conditions
Conference: NeurIPS
Year: 2024
Number of Reviews: 30
Original Ratings: 7, 6, 8, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Event-guided Human Pose Estimation and Tracking in extreme conditions dataset (EHPT-XC), which utilizes event cameras to address human pose estimation under challenging scenarios like motion blur and low light. It is the first dataset specifically designed for multi-human pose estimation using event and RGB data. The authors propose a triplet camera system to capture synchronized data and benchmark various baseline methods on this dataset. Additionally, the authors argue that event cameras significantly outperform RGB cameras in dynamic environments and propose various modality fusion methods, demonstrating performance improvements through experimental results. The integration of wireless signals for low-light pose estimation is also highlighted, along with a comprehensive dataset comparison that includes event-only results.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and clearly articulates the motivation for using event cameras in extreme conditions.
- The dataset is a significant contribution, being the first of its kind for multi-human pose estimation and tracking.
- The methodology for data collection and synchronization is sound, and the dataset encompasses diverse environments.
- The use of event cameras for human pose estimation in extreme conditions is innovative and addresses significant limitations of RGB methods.
- The authors provide experimental results showcasing the effectiveness of different fusion techniques, enhancing the robustness of their approach.
- The inclusion of comprehensive dataset comparisons in Table 1, along with newly added event-only results, strengthens the paper's contributions.

Weaknesses:
- The extreme imaging conditions primarily affect the RGB camera, not the event stream, which raises concerns about the dataset's construction.
- The benchmark experiments do not yield meaningful insights for the community, as the use of event streams to enhance HPE performance is already well-explored.
- The baseline methods for 2D HPE lack novelty, and the documentation of the dataset is insufficient.
- The paper lacks clarity on handling redundant background events, which could impact the quality of pose estimation.
- There are inconsistencies regarding the application of low-light degradation across RGB and event cameras, which may mislead readers.
- The need for clearer communication regarding the use of ND filters in the experimental setup has been highlighted.

### Suggestions for Improvement
We recommend that the authors improve the dataset by including wireless-based pose datasets in Table 1 and discussing their relevance. Additionally, providing quantitative or qualitative outcomes for event-only-based pose estimation would enhance comparisons among RGB, Event, and RGB+Event modalities. It is also advisable to offer processing code for better reproducibility. Furthermore, the authors should clarify the practical applications of their work and address the limitations of manual annotation errors, the artificial creation of motion blur, and the lack of exploration in modality fusion methods. We suggest that the authors improve the clarity regarding the handling of redundant background events to enhance the robustness of their methodology. Lastly, we recommend that the authors explicitly state how the same low-light degradation is applied to both RGB and event cameras, particularly in relation to the ND filter usage, and provide a more detailed discussion on the novelty of their benchmark experiments.