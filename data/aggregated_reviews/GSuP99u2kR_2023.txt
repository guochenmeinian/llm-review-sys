ID: GSuP99u2kR
Title: LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day
Conference: NeurIPS
Year: 2023
Number of Reviews: 18
Original Ratings: 5, 7, 7, 9, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a data pipeline for vision-language instruction-tuning in the biomedical domain, creating a new dataset for training vision-language models that are applied to downstream biomedical tasks such as medical Visual Question Answering (VQA). The main contributions include: 
- A data pipeline utilizing GPT-4 for generating instruction-tuning data without manual annotation.
- A novel dataset for instruction-tuning vision-language models in the biomedical domain.
- Vision-language models and checkpoints obtained from training on this dataset and fine-tuning on downstream VQA datasets. Additionally, the authors evaluate LLaVA-Med, a model designed for generating instruction-following data in biomedical contexts, proposing a methodology that includes both closed-set and open-set evaluations, focusing on the performance of various large language models (LLMs) as teachers. They address concerns regarding the transparency of training procedures for proprietary models like GPT-4 and explore the potential of open-source models such as LLaMA-2-70B-Chat. The authors also discuss the limitations of their methodology, particularly regarding societal impacts and challenges of reproducibility due to the unavailability of code and data.

### Strengths and Weaknesses
Strengths:
- The paper explores the underutilized area of multi-modal foundational models for biomedical applications, which is relevant to the research community.
- The resources provided, including the dataset and model checkpoints, are valuable for further biomedical applications.
- The methodology is sound, with a range of experiments conducted, including an ablation study to assess the dataset's components.
- The authors provide a thorough analysis of the performance differences between proprietary and open-source models, highlighting the capabilities of GPT-4 and LLaMA-2-70B-Chat.
- The paper includes new subsections that address potential negative societal impacts and methodological limitations, enhancing its depth.
- The authors have conducted additional experiments and provided detailed tables to support their findings.

Weaknesses:
- The use of GPT-4 to generate training data raises concerns about the reliability of the answers, as it may include background knowledge not inferable from the provided image and question.
- The training methodology, particularly the freezing of encoders, may not be optimal, and the benefits of stage 1 training are questioned.
- Important experimental details, such as hyper-parameters and evaluation protocols, are inadequately reported.
- The evaluation of closed-set questions lacks clarity, particularly regarding the application of constraints.
- There is insufficient discussion on the types of errors made by the model and how human perceptions of the generated instructions may vary.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the training data generation process, particularly addressing the potential for GPT-4 to introduce biases or inaccuracies in the answers. We suggest exploring alternative training setups, such as training both encoders in stage 1, to assess performance improvements. We encourage the authors to provide more detailed experimental information, including hyper-parameters and random seeds, to enhance reproducibility. Additionally, we recommend improving the clarity of the evaluation process for closed-set questions by explicitly detailing any constraints applied. We suggest including a deeper analysis of the types of errors made by the model and conducting a study on human perceptions of the generated instructions. Finally, we advise the authors to discuss the limitations of their methodology and the potential societal impacts of deploying LLaVA-Med in practice, revising their discussion on the limitations of stage-1 training to reflect the findings from their ablation studies more accurately.