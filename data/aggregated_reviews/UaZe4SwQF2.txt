ID: UaZe4SwQF2
Title: Gender Biases in Automatic Evaluation Metrics for Image Captioning
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new investigation into gender biases in model-based automatic evaluation metrics for image captioning. The authors construct a dataset, PAO-EVALBIAS, which includes profession, activity, and object concepts related to stereotypical gender associations. They demonstrate that existing evaluation metrics contain biases and propose a hybrid similarity evaluation metric, a linear combination of CLIPScore and CIDEr, aimed at reducing bias while maintaining correlation with human judgments.

### Strengths and Weaknesses
Strengths:
- The paper introduces a valuable dataset, PAO-EVALBIAS, and conducts sufficient experiments to support its claims.
- The motivation for the study is clear and significant, and the results are presented in an accessible manner.
- The combination of n-gram matching-based and model-based metrics is innovative and opens avenues for future research.

Weaknesses:
- The paper lacks clarity in certain sections, particularly regarding motivation and the advantages of the proposed method over existing metrics.
- There is insufficient discussion on potential gender bias introduced during dataset creation, and the analysis of the effectiveness of the hybrid metric is not thorough.
- The writing contains grammatical errors and issues with citation formatting, which detract from the overall quality.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by elaborating on the motivation behind their approach and the advantages of their method compared to existing evaluation metrics. Additionally, a more thorough analysis of how combining CLIPScore and CIDEr mitigates gender bias is necessary. We suggest conducting generalization experiments on other models, such as CLIP, to evaluate the significance of model structure on gender bias encoding. Lastly, we encourage the authors to address grammatical issues and ensure consistent citation formatting throughout the paper.