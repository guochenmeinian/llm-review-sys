ID: awIpKpwTwF
Title: LEACE: Perfect linear concept erasure in closed form
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 4, 7, 7, 6, -1, -1, -1, -1
Original Confidences: 4, 5, 3, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a concept erasure procedure that accounts for representation distortion during debiasing, building on iterative nullspace projection approaches with a regularization component. The authors propose that achieving E[X|Z]=E[X] is sufficient to protect information from a linear adversary, leading to a closed-form solution for the objective function. Experiments demonstrate that LEACE achieves comparable debiasing performance while maintaining lower distortion in learned representations.

### Strengths and Weaknesses
Strengths:
1. The paper proves that E[X|Z]=E[X] prevents linear adversaries from extracting information about the protected attribute.
2. It provides a closed-form optimal solution for linear debiasing with an L2 regularization constraint.
3. The experimental results indicate that LEACE achieves debiasing performance on par with previous methods while retaining significant information.

Weaknesses:
1. The rationale for using MSE reconstruction loss E[X-\hat{X}] as a measure of retained information is unclear. The authors should address whether a trivial baseline of normalizing data within each class achieves E[X|Z]=E[X] and its implications for debiasing.
2. The closed-form result closely resembles that of RLACE; an analytical discussion on their differences and implications for debiasing performance is warranted.
3. The paper does not report reconstruction loss in the results section, making it difficult to evaluate the proposed approach's efficacy. Justification for using rank as the primary metric over MSE loss is needed.
4. The paper should include comparisons with prior works like LAFTR, which utilize similar reconstruction losses, to clarify the advantages of projection-based methods over adversarial ones.
5. The experimental section lacks robustness; comparisons with RLACE and INLP are missing, and word embedding debiasing performance is not reported.
6. The organization and writing can be improved, particularly by condensing theoretical results and providing more context on the debiasing setup.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the rationale behind using MSE reconstruction loss and address the potential trivial baseline for achieving E[X|Z]=E[X]. An analytical discussion contrasting the closed-form results with RLACE should be included. Additionally, the authors should report reconstruction loss alongside rank to better evaluate the proposed method's efficacy and justify the choice of metrics. Including comparisons with prior works like LAFTR would enhance the understanding of the proposed method's advantages. Strengthening the experimental section with more comprehensive comparisons and improving the organization and clarity of the writing will also benefit the paper.