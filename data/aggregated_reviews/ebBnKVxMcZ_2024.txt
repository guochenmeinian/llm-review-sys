ID: ebBnKVxMcZ
Title: Confidence Calibration of Classifiers with Many Classes
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 4, 3, 6, 7, 6, 3, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 2, 4, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Top-versus-All (TvA) approach for confidence calibration in neural network classifiers, particularly addressing the challenges posed by multiclass problems. The authors reformulate the calibration task into a binary classification problem, which allows for the application of standard calibration methods more effectively. The proposed method aims to enhance the performance of calibration techniques like Temperature Scaling and Vector Scaling by better utilizing calibration data and reducing overfitting. The paper includes extensive experiments demonstrating the method's scalability and effectiveness across various datasets and models.

### Strengths and Weaknesses
Strengths:  
- The TvA approach is straightforward and easy to implement, requiring minimal changes to existing calibration methods.  
- It significantly enhances the performance of standard calibration techniques, consistently improving Expected Calibration Error (ECE) across diverse datasets.  
- The method scales well to classifiers with a large number of classes, addressing limitations in traditional calibration methods.  
- The paper provides a comprehensive overview of existing methods and their limitations, presenting a clear motivation for the proposed approach.  

Weaknesses:  
- The theoretical contribution of the TvA approach could be further strengthened, as it builds upon established methods rather than introducing novel elements.  
- There is a lack of comparison with state-of-the-art (SOTA) post hoc and train-time calibration methods, which may limit the perceived effectiveness of the proposed method.  
- The evaluation metrics are limited, focusing primarily on ECE and AUROC without exploring other relevant metrics.  
- The method's performance on larger models, such as LLMs, is not convincingly demonstrated, raising questions about its scalability.  

### Suggestions for Improvement
We recommend that the authors improve the theoretical justification of the TvA approach by providing more rigorous proofs and analyses. Additionally, we suggest including comparisons with SOTA post hoc methods and train-time calibration techniques to better contextualize the proposed method's performance. Expanding the evaluation metrics to include ACE, MCE, and PIECE would provide a more comprehensive assessment of the method's effectiveness. Finally, we encourage the authors to conduct experiments on larger models to validate the scalability and applicability of the TvA method in diverse neural architectures.