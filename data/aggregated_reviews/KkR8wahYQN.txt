ID: KkR8wahYQN
Title: FaMeSumm: Investigating and Improving Faithfulness of Medical Summarization
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents methods to enhance the fidelity of medical summarization systems by introducing two objectives for fine-tuning: a contrastive objective and a novel MKI objective that encourages the generation of medical concepts. The authors evaluate their approach against baseline models (BART, T5, mT5, and PEGASUS) and demonstrate improved performance on various datasets, supported by both automated metrics and human evaluations.

### Strengths and Weaknesses
Strengths:
- The paper provides a well-structured solution to a significant issue in summarization systems, with clear writing and thorough experimental analysis.
- The introduction of the MKI objective is novel and intuitively justified, showing improvements in factuality during human evaluations.
- The authors conduct extensive testing across multiple datasets and include qualitative error analyses.

Weaknesses:
- Section 3.1 lacks clarity, particularly regarding the impact of modifying reference summaries through sentence extraction.
- The experimental design does not adequately compare FaMeSumm with other contrastive learning methods, and the benefits of the MKI objective are not well-motivated.
- The ablation studies are incomplete, failing to isolate the effects of the new selection strategy and the MKI loss term.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Section 3.1 by elaborating on how changes in summary length affect summarization capacity. Additionally, we suggest conducting a pair-wise comparison annotation between CLIFF and FaMeSumm to better assess performance differences. The authors should also provide a clearer motivation for the MKI objective and consider a simpler version that emphasizes medical terms through higher cross-entropy weights. Furthermore, an ablation study on the types of corruptions made to positive and negative sets would enhance the understanding of their contributions. Lastly, addressing the omission of relevant prior work on contrastive learning for summarization would strengthen the paper's foundation.