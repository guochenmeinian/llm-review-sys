ID: Vn0FWRImra
Title: Nearly Minimax Optimal Submodular Maximization with Bandit Feedback
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 5, 5, 4, 7, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into stochastic bandit submodular maximization, focusing on the minimax regret bounds. The authors clarify that the minimax regret can be characterized by the minimum of two known bounds: a $\sqrt{T}$ regret upper bound from naive multi-armed bandit (MAB) considerations and a $T^{2/3}$ regret upper bound from the greedy maximization procedure. They propose a new notion of regret, termed robust greedy regret, and demonstrate that a UCB-based algorithm can achieve this minimax regret. Additionally, the paper addresses lower bounds for combinatorial multi-armed bandit (CMAB) problems under submodular rewards. The authors also discuss the appropriateness of $R_{gr}$ as a measure of regret, arguing that the offline greedy procedure yields an optimal approximation rate and justifying the direct measurement of regret against it. They explain that the stop level $l$ is chosen to minimize worst-case regret, making the algorithm nearly minimax optimal, although it may not be the exact optimal stop level due to large gaps in expected rewards.

### Strengths and Weaknesses
Strengths:  
- The paper introduces a new lower bound for bandit submodular maximization, marking a significant contribution to the field.  
- The authors provide a clear comparison with related work and present original problem instances for their lower bound proof.  
- The proposed algorithm effectively combines known strategies, showcasing insights into the problem's complexity.  
- The authors provide a thorough justification for using $R_{gr}$ as a measure of regret, and the explanation of the stop level $l$ and its relation to minimax optimality is well-articulated.  

Weaknesses:  
- The explanation of the lower bound and its relation to existing algorithms lacks clarity, particularly regarding the role of regret minimization algorithms.  
- The paper contains several typographical errors and instances of unclear notation, which detract from its overall presentation.  
- The justification for using robust greedy regret over traditional $\gamma$-regret is not sufficiently rigorous, and the implications of this choice are not fully explored.  
- Some reviewers feel that the authors' responses do not fully address their questions and concerns, and there is a lack of engagement with the specific feedback provided by the reviewers in the latest version of the paper.  

### Suggestions for Improvement
We recommend that the authors improve the clarity of the explanation surrounding the lower bound, particularly in relation to existing algorithms and the role of regret minimization techniques. Additionally, we suggest providing a more detailed discussion of how $\hat{f}$ is computed in Section 3 to enhance understanding. The authors should also address the potential impossibility of comparing with $S^{k,\mathbf{0}}$ in noisy settings and consider presenting a lower bound for this scenario. Furthermore, we advise a thorough proofreading of the manuscript to correct typographical errors and improve overall readability. Lastly, we encourage the authors to explore the implications of their new regret definition more rigorously, particularly in relation to existing literature on $\gamma$-regret, and to improve their responses to the reviewers' concerns by directly addressing the specific questions raised. It may also be beneficial to ensure that all changes made in the current version are clearly highlighted and explained to facilitate a better understanding of the revisions.