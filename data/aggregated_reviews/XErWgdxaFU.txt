ID: XErWgdxaFU
Title: Textual Training for the Hassle-Free Removal of Unwanted Visual Data: Case Studies on OOD and Hateful Image Detection
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 6, 6, 6, 6, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a text-only training method for detecting out-of-distribution (OOD) and hateful images, utilizing a novel loss function and an additional embedding layer over frozen CLIP encoders. The authors demonstrate that training solely on textual data can effectively identify undesirable visual content, achieving performance improvements over baseline methods across various datasets.

### Strengths and Weaknesses
Strengths:  
- The approach of using only textual data for hate detection is innovative, avoiding ethical issues associated with sourcing hateful images.  
- The paper provides sufficient experimentation and ablation analysis, validating the effectiveness of training solely on text data.  
- Implementation details are clearly outlined, and code is provided for reproducibility.  
- The method is efficient, requiring minimal computational costs during inference.  

Weaknesses:  
- The writing structure could be enhanced, particularly regarding the clarity of the textual synthesis aspect.  
- The trainable embedding learning process lacks clarity, especially concerning the alignment of image embeddings with frozen embeddings during testing.  
- The related work section is not comprehensive, omitting relevant methods like NegLabel and CLIPN, which should be included for comparison.  
- The authors do not explore the application of their method to other pretrained models or tasks beyond OOD and hateful image detection.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the trainable embedding learning process and provide a detailed explanation of how the learned embeddings are utilized for images. Additionally, we suggest conducting experiments using pretrained video-text models to assess performance changes in related video detection tasks. The authors should also expand the related work section to include a discussion of NegLabel and CLIPN, providing benchmarks and a critical analysis of their advantages. Finally, we encourage the authors to explore potential applications of their method beyond OOD detection and hateful image detection, possibly extending it to multi-class classification tasks.