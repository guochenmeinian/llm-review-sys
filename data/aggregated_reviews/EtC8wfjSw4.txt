ID: EtC8wfjSw4
Title: Human Raters Cannot Distinguish English Translations from Original English Texts
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on human annotators' ability to distinguish between text originally written in English and text translated from other languages. The authors propose four research questions and demonstrate that this task is challenging for humans, despite better performance by automatic classifiers. The findings indicate low inter-annotator agreement, suggesting that humans struggle to identify translated sentences effectively.

### Strengths and Weaknesses
Strengths:
- The research question is highly interesting and relevant.
- The paper is well-written and clearly presented.
- The experiments are statistically sound and corroborate the findings.

Weaknesses:
- The contribution and novelty of the work are perceived as lightweight.
- The motivation behind the research questions is insufficiently articulated.
- Details regarding the annotators' training and the methodology are lacking.
- The corpus used could have been better selected to differentiate between original and translated texts.

### Suggestions for Improvement
We recommend that the authors improve the motivation for their research questions by linking them to cognitive aspects of language perception. Additionally, providing more details on the annotators' training and the filtering process would enhance clarity. It would be beneficial to explore the performance of automatic classifiers on the same datasets to compare their findings with human annotators. We also suggest incorporating seminal references on translation studies to strengthen the introduction. Lastly, addressing the specific indicators that annotators used to identify translationese could provide deeper insights into the study's findings.