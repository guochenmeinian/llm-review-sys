ID: W5Clq1bSrR
Title: Toward Understanding Generative Data Augmentation
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 6, 5, 7, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 2, 4, 3, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a theoretical study of generative data augmentation (GDA), focusing on the generalization properties when training with augmented datasets. The authors propose a theorem that bounds the generalization error based on the divergence between the original and augmented distributions, as well as the generalization error of the mixed distribution. Empirical contributions include studies on a Gaussian mixture model and ResNets trained on CIFAR-10, demonstrating that generative models, particularly diffusion models, are beneficial when augmentations are not used.

### Strengths and Weaknesses
Strengths:
- The topic is topical and potentially impactful.
- The writing is very good, with clear mathematical notation and explanations.
- The results of the theorem are natural and intuitive, providing novel insights into GDA.

Weaknesses:
- A major assumption is that the distribution learned by the generative model is dependent on the sampled training set, which may not hold true in practice. Removing this assumption could simplify theoretical derivations.
- The use of Gaussian mixture models is not particularly relevant to practical applications.
- The theoretical results may not extend to deep neural networks effectively.
- The experiments on CIFAR-10 lack depth and do not convincingly connect to the proposed theories.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the explanations in Theorems 3.2 and 3.3, particularly regarding "constant-level improvement" and the self-containment of the paper. Additionally, we suggest reorganizing the paper to enhance readability and coherence, as well as including more comprehensive experiments beyond CIFAR-10 to strengthen the empirical validation of their theoretical findings. It would also be beneficial to clarify the practical implications of the stability bound and how it can be utilized to advance existing generative data augmentation methods.