ID: Ct0zPIe3xs
Title: Saving 100x Storage: Prototype Replay for Reconstructing Training Sample Distribution in Class-Incremental Semantic Segmentation
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 6, 8, 7, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 4, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a memory-efficient replay-based class-incremental semantic segmentation (CISS) method called STAR. The authors propose strategies to address distribution disparities between single-step training samples and the complete dataset, thereby reducing network bias. Key contributions include the prototype replay strategy, background repetition strategy, old-class feature maintaining loss (OCFM), and similarity-aware discriminative loss (SAD). Experimental results on benchmarks such as VOC 2012 and ADE 20K demonstrate the method's effectiveness and efficiency, achieving state-of-the-art performance while significantly reducing storage requirements.

### Strengths and Weaknesses
Strengths:
- The motivation for addressing distribution discrepancies is well-articulated and relevant.
- The proposed methods are innovative and effectively tackle the identified problems while maintaining low storage costs.
- The experimental validation is thorough, showcasing the method's performance across multiple datasets.

Weaknesses:
- The detailed procedure of the proposed method is not clearly outlined, making it difficult for readers to understand; an algorithmic representation is recommended.
- There are grammar errors and unclear explanations that may hinder comprehension, such as unclear references to datasets and incorrect verb forms.
- The novelty of the prototype replay strategy is not sufficiently distinguished from existing methods, and concerns about the effectiveness of stored prototypes are raised.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the method's description by including an algorithm to outline the detailed procedure. Additionally, please clarify the ground-truth definitions and objective function equations related to the multiple binary cross-entropy (mBCE) loss. Address the grammar issues and ensure that all terms are correctly used, particularly in Section 1 and Section 2.3. Finally, we suggest that the authors explicitly differentiate their prototype replay strategy from existing methods and include relevant related works to strengthen the context of their contributions.