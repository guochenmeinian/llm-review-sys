ID: DsN7tHNo78
Title: Manipulation Intention Understanding for Accurate Zero-Shot Composed Image Retrieval
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 4, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents De-MINDS, a framework for Zero-Shot Composed Image Retrieval (ZS-CIR) that integrates intention-based pseudo-manipulation descriptions to enhance image retrieval accuracy. The authors introduce intent-CC3M, a dataset generated through chain-of-thought prompting by a Multi-modal Large Language Model (MLLM), and a manipulation intention understanding network utilizing learnable queries. The experimental results indicate significant performance improvements across four ZS-CIR tasks compared to state-of-the-art models.

### Strengths and Weaknesses
Strengths:
- The introduction of intent-CC3M as a dataset for training mapping networks to align intention-relevant visual information is innovative and impactful.
- The De-MINDS framework demonstrates significant performance improvements over state-of-the-art models across multiple ZS-CIR tasks.
- The approach effectively addresses the challenge of understanding manipulation intentions in user descriptions, crucial for accurate image retrieval.
- Comprehensive ablation studies provide insights into the contributions of different components of the proposed method.

Weaknesses:
- The concept of "intention" is unclear, with insufficient explanation of its role in the model and the pseudo-manipulation descriptions lacking distinctiveness from rewritten captions.
- The proposed model architecture lacks novelty, primarily adding a Q-Former after the CLIP encoder without citing relevant existing work.
- Experimental comparisons are limited, as the authors only evaluate one CLIP variant and do not include evaluations on other datasets like CIRCO and GeneCIS.
- The paper lacks experimental evidence supporting claims about caption redundancy affecting retrieval accuracy and does not explore the performance of De-MINDS with longer text encoders.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the "intention" concept and provide a more detailed explanation of how it is integrated into the pseudo-manipulation descriptions. Additionally, we suggest including evaluations with multiple CLIP variants and other relevant datasets to strengthen the comparative analysis. The authors should also justify the choice of CC3M as the base dataset for intent-CC3M more clearly and explore the impact of the number of learnable queries in their ablation studies. Finally, addressing the retrieval speed of De-MINDS in comparison to other models would enhance the paper's effectiveness.