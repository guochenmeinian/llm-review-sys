ID: CY1xatvEQj
Title: DiffSketcher: Text Guided Vector Sketch Synthesis through Latent Diffusion Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 3, 7, 7, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DiffSketcher, a stroke-based rendering model that utilizes a pre-trained text-to-image diffusion model to generate vectorized sketches from text prompts. The authors optimize a set of BÃ©zier curves using an extended version of the score distillation sampling (SDS) loss, allowing for the integration of raster-level diffusion models in the optimization of a parametric vectorized sketch generator. The method demonstrates the ability to produce sketches at varying levels of abstraction.

### Strengths and Weaknesses
Strengths:
- The paper introduces a novel approach to synthesizing vector graphics through stroke-based rendering.
- It effectively leverages a pre-trained diffusion model without the need for retraining, allowing for text-controlled painting content.
- The results are convincing, showing "human-like" sketches and addressing an underexplored area of text-to-sketch synthesis.

Weaknesses:
- The novelty is questionable, as the model's capabilities largely stem from the pre-trained diffusion model, with the differentiable rasterizer primarily serving as a fitting process.
- Comparisons with existing methods are insufficient; the authors should include more robust image-to-sketch rendering methods for a fair evaluation.
- The omission of a critical citation to the related work "VectorFusion" is a significant oversight.
- The writing quality could be improved, particularly in defining abbreviations upon first use and clarifying technical terms.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their work by proposing enhancements to the diffusion models or raster-to-vector algorithms rather than merely combining existing techniques. Additionally, the authors should include comparisons with stronger baseline methods and ensure that all relevant literature, particularly "VectorFusion," is cited appropriately. To enhance clarity, we suggest that the authors define abbreviations at their first mention and provide a more thorough discussion of the limitations of their approach, including potential failure cases. Furthermore, we encourage the authors to elaborate on the benefits of using the Augmentation SDS loss and clarify the role of the VAE decoder in their method.