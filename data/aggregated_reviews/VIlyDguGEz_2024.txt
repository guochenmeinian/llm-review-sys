ID: VIlyDguGEz
Title: Learning Where to Edit Vision Transformers
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 6, 7, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach for editing Vision Transformers (ViTs) to correct predictive errors, specifically addressing subpopulation shifts. The authors propose a learning-to-learn methodology utilizing a hypernetwork that identifies and modifies a small set of critical parameters in response to erroneous samples. This method emphasizes localized edits, ensuring minimal disruption to unrelated model functions while generalizing corrections to similar errors. The paper introduces new benchmarks to validate the proposed framework, demonstrating significant improvements over existing techniques.

### Strengths and Weaknesses
Strengths:  
- The innovative use of a hypernetwork to identify editing locations in ViTs addresses a gap in the literature on efficient and localized model editing.  
- The method is rigorously validated through new benchmarks, showing substantial improvements in predictive reliability, particularly relevant for applications like autonomous driving and medical imaging.  
- The paper is well-organized and clearly written, making it accessible to readers familiar with the field.  

Weaknesses:  
- The success of the proposed method heavily relies on the hypernetwork's ability to accurately predict edit locations; misidentifications could lead to suboptimal edits, affecting model reliability.  
- The motivation and influence of the CutMix technique are not clearly discussed, raising questions about its effectiveness compared to other data augmentation methods.  
- The application of the proposed method appears limited to plain ViTs, with insufficient exploration of hierarchical ViTs like Swin and PVT.  
- The computational cost of training the hypernetwork may be high, raising concerns about efficiency compared to full fine-tuning.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the motivation and effectiveness of the CutMix technique, comparing it with other data augmentation methods. Additionally, we suggest exploring the application of the proposed method to hierarchical ViTs to broaden its applicability. The authors should also provide more detailed information on the computational complexity and resource requirements of their method, clarifying how it compares to existing methods in terms of efficiency. Finally, addressing the scalability of the hypernetwork for larger models would strengthen the paper's contributions.