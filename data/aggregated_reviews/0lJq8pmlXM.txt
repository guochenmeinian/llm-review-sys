ID: 0lJq8pmlXM
Title: ScribbleGen: Generative Data Augmentation Improves Scribble-supervised Semantic Segmentation
Conference: thecvf
Year: 2024
Number of Reviews: 3
Original Ratings: 7, 6, 5
Original Confidences: 4, 4, 3

Aggregated Review:
**Key Points:**
We note that the paper proposes a method utilizing diffusion models for generative data augmentation in scribble-supervised semantic segmentation. It analyzes various schemes to combine real and synthetic datasets, demonstrating effectiveness through experiments and ablation studies. However, it overlooks closely related works that also explore synthetic data for semantic segmentation, particularly those employing diffusion models.

**Strengths and Weaknesses:**
Strengths include being the first to leverage diffusion models for this specific task and achieving better results that narrow the gap between weakly-supervised and fully-supervised segmentation. However, weaknesses are evident in the costly fine-tuning of ControlNet, limited novelty in the method, and a lack of analysis on bad cases and limitations. Additionally, the role of text conditioning is not clearly supported by experiments, and more results with other weakly-supervised methods would enhance the paper.

**Suggestions for Improvement:**
We suggest that the authors compare and discuss related works [1][2][3] in the paper. Including visualized analyses of bad cases would aid understanding. Furthermore, we recommend providing additional results with other weakly-supervised semantic segmentation methods and clarifying the impact of text conditioning on the proposed approach. Lastly, we inquire about the results using a fixed encode ratio $\lambda =0.4$ and adaptive $\lambda$ with RLoss [38], as well as the outcomes in a low-data regime with $\lambda = 0.4$.