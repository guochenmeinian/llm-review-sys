ID: g8S53BmXE6
Title: Linker-Tuning: Optimizing Continuous Prompts for Heterodimeric Protein Prediction
Conference: NeurIPS
Year: 2023
Number of Reviews: 5
Original Ratings: 3, 4, 5, 4, -1
Original Confidences: 5, 4, 5, 4, -1

Aggregated Review:
### Key Points
This paper presents a strategy for predicting heterodimeric protein structures using ESMFold, incorporating glycine linkers and a learnable embedding layer. The authors propose that their method, which fine-tunes only the embedding layer with a weighted distogram loss, achieves comparable performance to existing linker-based strategies. Evaluations are conducted on three datasets, although one is deemed irrelevant.

### Strengths and Weaknesses
Strengths:
1. The writing is clear and the proposed method is reasonable and intuitive.
2. The method shows slight performance improvements over direct linker usage (TMscore 0.62 to 0.65).
3. The novelty of leveraging prompt tuning for heterodimer prediction is well-founded and logical.

Weaknesses:
1. The idea of using ESM models for protein complex prediction has been previously explored, with more effective implementations lacking in discussion or comparison in this paper.
2. The necessity of linkers for folding multimers is questioned, as modifying position indices could suffice, potentially introducing unnecessary geometrical constraints.
3. Performance improvements are marginal, raising doubts about the reliability of the proposed method, particularly in the context of the VH-VL docking benchmark, which lacks relevance.
4. The methodology may be limited in applicability to pre-trained language models, with concerns about overfitting and the reliability of results from the antibody dataset.

### Suggestions for Improvement
We recommend that the authors improve the robustness of their benchmarks and provide discussions and comparisons with existing methods, particularly Zhu et al. (2023). Clarifying the definition of the Gap model and its implications for performance would enhance understanding. Additionally, addressing the high standard deviation in RMSD and providing boxplots for all benchmarks would strengthen the analysis. Finally, exploring the generalizability of the link-tuning idea across different protein structure prediction models could significantly enhance the manuscript's impact.