ID: MEa0cQeURw
Title: NeuroGraph: Benchmarks for Graph Machine Learning in Brain Connectomics
Conference: NeurIPS
Year: 2023
Number of Reviews: 19
Original Ratings: 6, 6, 7, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents NeuroGraph, a comprehensive benchmark dataset for graph-based neuroimaging, along with computational tools for converting fMRI datasets into static and dynamic graph representations. The authors propose a generalized dynamic Graph Neural Network (GNN) architecture to evaluate various GNN convolutions, addressing the limitations of existing dynamic GNN codebases. The manuscript discusses the expansive design space for graph construction, highlighting the implications of different parcellation methods, connectivity metrics, and preprocessing steps on the resulting brain graphs. The authors demonstrate that a combination of correlation-based node features, numerous Regions of Interest (ROIs), and sparser graphs yields superior results for tasks such as age prediction, sex classification, and activity classification. They benchmark various configurations of node features and graph dimensionality, providing guidelines for future research.

### Strengths and Weaknesses
Strengths:
1. The study effectively addresses both static and dynamic graphs.
2. It offers a clear conceptual explanation and thorough documentation.
3. The datasets compiled are extensive, enabling the application of novel graph machine learning methods.
4. The paper contributes significantly to the field by introducing a Python tool, NeuroGraph, for preprocessing fMRI data and constructing brain graphs.
5. The use of the Schaefer atlas for defining ROIs is justified, and the authors acknowledge the potential for incorporating other atlases.
6. The authors effectively demonstrate the advantages of adding correlation as node features.

Weaknesses:
1. The datasets may be limited in scope, potentially restricting the techniques benchmarked.
2. Several technical details, such as the nomenclature of symbols in Table 1 and the representation of edges in the generated graph, are not adequately addressed.
3. The authors do not explore alternative parcellation methods for defining ROIs or the use of independent component analysis (ICA) for feature extraction.
4. The explanation of the distinction between dynamic and static graphs lacks depth and clarity.
5. Limitations regarding the encoding of neuroimaging data in graph form and potential information loss are not sufficiently addressed in the main text.
6. The paper is noted to be difficult to follow, with suggestions to better integrate supplemental material into the main body.
7. Some reviewers remain unconvinced by the terminology used in addressing research questions.

### Suggestions for Improvement
We recommend that the authors improve the dataset by utilizing a larger sample size for more comprehensive benchmarking and exploring additional features from the raw BOLD signal, such as volumetric characteristics and levels of activation. We suggest clarifying the explanation of the split between dynamic and static graphs by expanding Section A.3 and Section 3.2, and addressing the limitations of the current encoding methods in the main text. Additionally, we encourage the authors to provide runnable results for the transformer-based baseline in Section 3.4 and to better articulate the implications of their findings in relation to existing literature on graph machine learning and neuroimaging. Furthermore, we advise that the authors address the existing literature on neuroimaging datasets more comprehensively and ensure that all relevant citations are included. Lastly, we recommend correcting the terminology regarding "research questions" to accurately reflect hyperparameter selection outcomes and providing more exhaustive discussions on the points raised to further strengthen their paper.