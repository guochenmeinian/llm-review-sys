ID: 5yZiP9fZNv
Title: Amortized Reparametrization: Efficient and Scalable Variational Inference for Latent SDEs
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 5, 6, 7, 3, -1, -1, -1, -1
Original Confidences: 2, 3, 2, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for inference in latent stochastic differential equations (SDEs) that enhances computational efficiency by utilizing a reparameterization scheme. The authors propose splitting computations into parallelizable chunks, allowing for effective integration via expectations over a uniform random variable. This approach leverages the linearity of the SDEs, where mean and covariance matrices characterize the data across time marginals, thus eliminating the need for individual trajectory evaluations. The authors clarify the implicit assumption that the matrix $A$ is symmetric, emphasizing that this does not impact the results since $A$ is not directly parameterized; instead, the parameters $m$ and $S$ are explicitly defined as functions of time. The paper includes experiments on synthetic and real time series data, demonstrating the method's utility in terms of function evaluations and accuracy, while also utilizing automatic differentiation to compute $\frac{dm}{dt}$ and $\frac{dS}{dt}$ for estimating the Evidence Lower Bound (ELBO), contrasting their approach with prior methods that require solving ODEs.

### Strengths and Weaknesses
Strengths:
- The transformation of sequential computations into parallelizable expectations is innovative, leading to significant computational speed-ups.
- Empirical results indicate increased stability and superior performance on real datasets compared to baseline methods.
- The clarification of the symmetry assumption of matrix $A$ enhances the rigor of the manuscript.
- The use of automatic differentiation for estimating the ELBO is a notable methodological advancement.
- The paper is well-written, with an intuitive presentation of the proposed method.

Weaknesses:
- The method's applicability is limited to SDEs with known marginal descriptions, specifically assuming a Markov Gaussian process, which may not hold for most SDEs.
- The experimental evaluation is restricted to two synthetic datasets and one real dataset, raising questions about the generalizability of the findings.
- The paper lacks clarity on the implications of the interpolation technique used and does not sufficiently explore the impact of the linear SDE assumption on model expressiveness.
- There remain issues with the clarity of the presentation, which need further improvement.
- The discussion on the window parameter, while partially addressed, requires additional elaboration to ensure its importance for performance is fully communicated.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the assumptions regarding the Gaussian nature of the latent distribution, providing clarity on where this assumption holds. Additionally, expanding the experimental evaluation to include more diverse datasets, particularly non-affine SDEs, would strengthen the findings. A comparison with backpropagation through the solver, as opposed to the adjoint method, should be included to assess the proposed method's performance comprehensively. Furthermore, clarifying the interpolation's effect on sample path quality and providing a systematic evaluation of how the number of evaluations influences performance would enhance the paper's rigor. Lastly, we suggest including a more comprehensive discussion on the window parameter in the revision, as it is crucial for achieving good performance, and addressing the limitations related to the observation model and the encoder's role in the proposed framework is essential for a more robust contribution.