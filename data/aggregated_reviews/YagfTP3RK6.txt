ID: YagfTP3RK6
Title: Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress?
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 7, 6, 6, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 3, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a logical suggestion to the AI safety community to consider the correlation between safety benchmarks and overall model capabilities during the evaluation and development of safety methods. The authors propose a method for quantifying this correlation by "distilling" current LLM capability benchmarks into a capabilities component through PCA on a benchmarks x models matrix. The paper argues that many safety benchmarks are highly correlated with general capabilities benchmarks, indicating that improvements often arise from scaling rather than addressing specific safety concerns. The authors suggest that future safety benchmarks should report their correlation with capabilities to ensure meaningful safety measures.

### Strengths and Weaknesses
Strengths:
- The broad message and suggestions within the paper are valuable contributions to the research community.
- The use of spectral analysis and PCA demonstrates methodological rigor and provides a framework for understanding the relationship between safety and capabilities.
- The paper is well-written and covers a wide range of benchmarks, ensuring broad applicability of findings.

Weaknesses:
- The distinction between the two principal contributions of the paper is unclear, complicating interpretation.
- The definition of safety is vague, relying on loose descriptions rather than rigorous conceptualization, which misleads the framing of findings.
- The paper lacks detailed methodologies or specific examples for better benchmarks, reducing its immediate impact.

### Suggestions for Improvement
We recommend that the authors improve clarity by clearly delineating the two contributions of the paper. A discussion section that incorporates results from Section 4 would enhance understanding. Additionally, the authors should provide a more explicit and rigorous definition of safety, potentially drawing from psychometrics research to better conceptualize the constructs being measured. Engaging with work on construct reliability and validity issues in ML evaluation would also strengthen the paper. Furthermore, we suggest conducting causal analysis to determine if improvements in capabilities directly cause improvements in safety metrics and exploring non-linear methods to capture the correlation between capability and safety. Lastly, providing code for reproducibility and a detailed explanation of the spectral analysis methodology would benefit readers.