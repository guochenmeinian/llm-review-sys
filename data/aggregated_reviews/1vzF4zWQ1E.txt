ID: 1vzF4zWQ1E
Title: Rethinking Bias Mitigation: Fairer Architectures Make for Fairer Face Recognition
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 8, 6, 8, 6, 7, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 4, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel framework (NAS+HPO) aimed at mitigating biases in face recognition (FR) by exploring the impact of neural architectures and hyperparameters on fairness. The authors conduct extensive experiments demonstrating that certain architectures, such as DPN, achieve Pareto-optimal performance in terms of both accuracy and fairness. The proposed method is shown to generalize across different datasets and protected attributes, challenging conventional bias mitigation strategies that typically focus on post-processing or dataset balancing.

### Strengths and Weaknesses
Strengths:
1. The proposed method is well-motivated by experiments showing the significance of architectures and hyperparameters for fairness.
2. The paper provides a fresh perspective on bias mitigation by focusing on fairer neural architectures.
3. Extensive empirical analysis reveals that the new model configurations learn more robust features, improving performance over standard methods.
4. The results indicate that the proposed method is Pareto-optimal compared to existing bias mitigation techniques.
5. The paper is well-written, easy to follow, and includes code for reproducibility.

Weaknesses:
1. The generalization of Pareto-optimal results to different datasets is unclear, as Table 2 only presents performance results without confirming Pareto-optimality.
2. The reported performance should be verified on authoritative datasets like Ms1m, Glint360, and webface260m, as smaller datasets may not reflect performance in larger contexts.
3. Some experimental design choices, such as the selection of SMAC3 for optimization and the training on gender-balanced subsets, require further justification.
4. The analysis lacks detailed discussion on the operations constituting the architecture that performed well across datasets.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the generalization results by including fairness-performance metrics for cross-dataset evaluations. Additionally, we suggest providing a more detailed discussion on the choice of optimization methods and the significance of the selected architecture operations. Clarifying the rationale for training on a gender-balanced subset and ensuring hyperparameters are consistently tuned across models would enhance the robustness of the experimental design. Finally, addressing the visualization of results and including confusion matrices could provide deeper insights into the improvements achieved through the NAS paradigm.