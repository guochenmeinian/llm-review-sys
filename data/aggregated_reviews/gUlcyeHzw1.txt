ID: gUlcyeHzw1
Title: Learning Provably Robust Estimators for Inverse Problems via Jittering
Conference: NeurIPS
Year: 2023
Number of Reviews: 7
Original Ratings: 5, 6, 7, -1, -1, -1, -1
Original Confidences: 3, 4, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the introduction of Jittering to inverse problems, aiming to enhance robustness against l2-worst-case scenarios. The authors provide analytical results supporting robust estimation under reasonable assumptions and validate their findings through empirical experiments, demonstrating effectiveness at a lower computational cost compared to adversarial training. The work focuses on linear estimators and shows that while Jittering may not yield optimally robust estimators for general inverse problems, the performance gap remains small in practice.

### Strengths and Weaknesses
Strengths:
- The motivation for developing a provable robust estimator is commendable.
- The assumptions made in the study are reasonable.
- The results demonstrate promising performance and present a neat and elegant idea.

Weaknesses:
- The numerical implementation of the algorithm lacks clarity, particularly regarding the unknown energy levels of signals and noise.
- Experimental results are limited, raising concerns about potential cherry-picking due to the small number of images presented.
- Some analytical results are difficult to relate to practical applications, leading to confusion in understanding their implications.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the algorithm's implementation, providing a more systematic discussion rather than fragmented mentions in Section 4. Additionally, we suggest expanding the experimental results to include a larger test set and more comprehensive metrics to support claims about robustness and reconstruction quality. It would also be beneficial to clarify the relationship between the theoretical results and practical applications, particularly regarding the assumptions made about variables like $\sigma_c$ and $\sigma_z$. Furthermore, we encourage the authors to justify the choice of a linear model over a non-linear model, such as U-net, and to provide numerical evidence supporting the relevance of their findings across different model types. Lastly, we advise including a detailed complexity analysis and addressing the computational aspects involved in hyper-parameter tuning to enhance the paper's overall rigor and applicability.