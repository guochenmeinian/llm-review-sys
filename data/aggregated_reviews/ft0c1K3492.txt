ID: ft0c1K3492
Title: SciRepEval: A Multi-Format Benchmark for Scientific Document Representations
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the SciRepEval benchmark, which includes 25 tasks across four formats, with 11 tasks being new. The authors evaluate existing methods and introduce a Multi-Format embedding approach that utilizes different embeddings based on task formats, demonstrating improved performance and generalizability of scientific document representations.

### Strengths and Weaknesses
Strengths:  
- The paper introduces a comprehensive and diverse benchmark for evaluating scientific document representations.  
- It provides a well-executed analysis of the generalizability of state-of-the-art models and presents a new approach that enhances performance.  
- The manuscript is well-written, clearly outlining its focus and contributions.

Weaknesses:  
- The work may be perceived as incremental, lacking significant novelty.  
- The motivation for multi-format representation learning is not sufficiently elaborated, and the implications of storing separate models could be better addressed.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the importance of multi-format representation learning and clarify the rationale behind it. Additionally, addressing the potential storage costs associated with maintaining separate models would strengthen the paper. Given the extensive content, we suggest considering the possibility of splitting the paper into separate publications for clarity and focus.