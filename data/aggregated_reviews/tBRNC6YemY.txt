ID: tBRNC6YemY
Title: Gorilla: Large Language Model Connected with Massive APIs
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 6, 6, 6, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Gorilla, a fine-tuned LLaMA model that outperforms GPT-4 in generating API calls and adapts effectively to document changes through a document retriever, addressing hallucination issues. The authors introduce APIBench, a new dataset for evaluation, encompassing APIs from HuggingFace, TorchHub, and TensorFlow Hub. Gorilla's integration with a retrieval system enhances the accuracy of tool usage and documentation updates, promising more reliable outputs from large language models (LLMs).

### Strengths and Weaknesses
Strengths:
- The paper details a system that connects extensive APIs to generate corresponding API calls from text instructions, significantly simplifying machine learning software development.
- APIBench is constructed by scraping a large corpus of ML APIs, providing an evaluation framework that measures functional correctness using AST subtree-matching metrics, contributing to the evaluation of ML API mastering techniques.
- The writing is clear, with a comprehensive comparison to related works, a well-structured methodology, and thorough experiments and analyses.

Weaknesses:
- The paper lacks performance comparisons with more specific methods, such as other LLMs for tool calling, which could further highlight Gorilla's contributions.
- Contributions and potential impacts on the community are not sufficiently illustrated.
- Some writing details require improvement, such as omitting "the" in "the our method" and replacing "AST" with "Abstract Syntax Tree" upon first mention.

### Suggestions for Improvement
We recommend that the authors improve the performance comparison by including fine-tuned versions of other models, such as Toolformer, to better contextualize Gorilla's advancements. Additionally, the authors should enhance the clarity of their contributions and outline the broader impact on the community. We also suggest refining writing details for grammatical accuracy and clarity, particularly in the specified instances. Furthermore, a more robust error analysis is needed to understand common error types and their relationship with API categories and input complexity. Lastly, a comprehensive limitations section should be included to address potential issues such as data contamination and the risks associated with unreliable APIs.