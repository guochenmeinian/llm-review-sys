ID: eC5qdC4ZTQ
Title: Unlock the Intermittent Control Ability of Model Free Reinforcement Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 5, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method called Multi-step Action Representation (MARS) to tackle intermittent control problems in reinforcement learning (RL), where communication disruptions hinder the interaction between decision-makers and executors. MARS encodes sequences of actions into a compact latent space, enabling RL algorithms to optimize smoother motion policies. Empirical results indicate that MARS significantly enhances learning efficiency and performance across both simulated and real-world tasks compared to existing baselines. Additionally, the authors provide an enhanced comparison between MARS and existing state-of-the-art (SOTA) methods, specifically focusing on multi-step decision-making policies. They introduce six additional challenging scenarios and increase the seed number to 8, resulting in improved performance stability. The findings indicate that while the proposed method outperforms ACT in most scenarios, there remains a notable gap compared to MARS, which is highlighted through a discussion of ACT's technical focus on direct construction of multi-step decision-making policies via imitation learning.

### Strengths and Weaknesses
Strengths:  
1. The paper addresses an important yet under-explored problem of intermittent control in RL.  
2. The method is straightforward, and the performance improvements are significant.  
3. The paper provides a thorough explanation of MARS, including the encoding and decoding processes, and demonstrates effectiveness through various experiments.  
4. The introduction of new challenging scenarios and an increased seed number enhances performance stability and provides valuable insights into the strengths and weaknesses of the proposed approach.  
5. The authors effectively streamline sections of the paper to enhance clarity and reduce redundancy.  

Weaknesses:  
1. The method resembles simpler delay MDPs without adequately comparing it to existing delay MDP methods.  
2. The experimental comparisons are limited to basic baselines, and the number of tasks is somewhat restricted.  
3. Some notation and presentation aspects are unclear, leading to potential confusion.  
4. The proposed method still shows a performance gap compared to MARS, particularly in longer interval settings.  
5. Original ACT struggles with stability during longer time steps, indicating a need for further refinement in this area.  

### Suggestions for Improvement
We recommend that the authors improve the comparison with existing delay MDP methods to provide a clearer context for MARS's contributions. Additionally, we suggest enhancing the comparison by providing a more convincing analysis of the performance gap between ACT and MARS, particularly in longer interval scenarios. Expanding the range of experimental tasks would strengthen the validation of MARS's effectiveness. We also recommend revising unclear notations and streamlining Section 4 to enhance clarity and conciseness. Furthermore, addressing the limitations regarding long action sequences more thoroughly would benefit the discussion, and enhancing ACT's online learning capabilities for extended intervals would be beneficial. Incorporating the newly added experiments into the main text would enrich the empirical results and improve readability.