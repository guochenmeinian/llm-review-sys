ID: WariAWh7Ih
Title: On Calibration of LLM-based Guard Models for Reliable Content Moderation
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 8, 8, 8
Original Confidences: 4, 2, 4

Aggregated Review:
### Key Points
This paper presents an exploration of the confidence calibration problem in the context of guard models, applying various calibration techniques to well-known models. The authors highlight the issue of overconfidence in large language models (LLMs), particularly under adversarial conditions, and provide operational insights for organizations utilizing model guard systems. The clarity of the science and motivation is commendable, making it a solid submission for the workshop.

### Strengths and Weaknesses
Strengths:  
- Valuable comparison between calibration techniques in guard models.  
- High-quality work with clear writing and an impressive range of models and datasets.  
- Insightful qualitative analysis, particularly regarding model behavior on edge inputs.  

Weaknesses:  
- Using a single validation set to determine the optimal temperature for all test datasets may lead to suboptimal results.  
- Lack of context or comparison to ground the interpretation of ECE values.  
- The term "reliability" is overloaded and lacks a clear operational definition in the context of guard models.  

### Suggestions for Improvement
We recommend that the authors improve the opening phrase to clarify that LLMs pose risks through misuse rather than being at risk themselves. Additionally, please clarify the operational definition of "reliability" within guard models, specifying whether it includes only calibration metrics like ECE or also robustness and stability across datasets. 

We suggest examining the assumption of using a single temperature parameter, T, derived from the XSTest set for all datasets, as this may not adequately calibrate models across different characteristics. Including an analysis of false positive and false negative rates alongside ECE would enhance the evaluation. 

Furthermore, we recommend providing estimates of the computational costs and latency introduced by BC compared to TS, and clarifying the ideal batch size for calibration. Discussing the implications of calibration responsibility—whether it should be on providers or consumers—could also add depth to the paper. 

Lastly, addressing the absence of bins for confidence < 0.5 in reliability diagrams and grounding ECE values with a reference for interpretation would strengthen the analysis. Please correct the typo "cnotent" as well.