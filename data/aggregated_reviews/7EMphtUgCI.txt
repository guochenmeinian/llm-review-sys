ID: 7EMphtUgCI
Title: AVIS: Autonomous Visual Information Seeking with Large Language Model Agent
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 6, 7, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel visual question answering (VQA) framework that utilizes large language models (LLMs) to select external tools in multiple stages for information extraction. The authors gather human decision data to develop a decision graph and create in-context examples to guide the LLM in API selection and query construction. The experiments validate the proposed method's effectiveness on two knowledge-based VQA benchmarks, OK-VQA and Infoseek.

### Strengths and Weaknesses
Strengths:  
1. The experimental results are solid, demonstrating the framework's advantages and improvements in each sub-module.  
2. The novel approach of guiding tool selection through human demonstration provides insights into LLM weaknesses.  
3. The transition graph enhances interpretability and allows for a dynamic decision-making process, improving the system's adaptability.  
4. The motivation is clear, and the writing is easy to follow.

Weaknesses:  
1. The LLM used is PALM, while comparison methods utilize GPT series models; results with GPT models would better demonstrate the framework's effectiveness.  
2. The reliance on human guidance requires significant labor and may be challenging to generalize to other tasks.  
3. There is a lack of error analysis, which would benefit the community by identifying sources of errors.  
4. The inclusion of uninformative outputs in working memory may impact results, and the framework's handling of non-informative outputs needs clarification.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of the framework by conducting experiments on the A-OKVQA dataset. Additionally, we suggest including error analysis to identify potential sources of errors, such as prompts, the LLM, or the transition graph. To enhance the framework's robustness, we advise addressing how it manages uninformative outputs and providing an average step count required to address a single VQA sample. Finally, we encourage the authors to compare their framework with ViperGPT using GPT-3 or 3.5 to assess its performance against weaker LLMs.