ID: 9ZDdlgH6O8
Title: UltraEdit: Instruction-based Fine-Grained Image Editing at Scale
Conference: NeurIPS
Year: 2024
Number of Reviews: 23
Original Ratings: 6, 6, 6, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 2, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents UltraEdit, a large-scale dataset for instruction-based image editing, featuring approximately 4 million editing samples. UltraEdit addresses limitations in existing datasets by incorporating a broader range of editing instructions, utilizing real images for diversity, and supporting region-based editing with high-quality annotations. The authors demonstrate that models trained on UltraEdit achieve state-of-the-art results on benchmarks like MagicBrush and Emu-Edit. Furthermore, the authors provide a comprehensive response to reviewer feedback, emphasizing their commitment to improving the manuscript based on critiques received, highlighting the open-sourcing of their dataset, and ensuring adherence to safety standards in its creation.

### Strengths and Weaknesses
Strengths:
- The paper clearly articulates the motivation behind creating UltraEdit, addressing drawbacks in existing datasets.
- An automated data generation pipeline allows for scalable creation of a large dataset.
- Promising experimental results indicate that diffusion-based editing models trained on UltraEdit outperform previous methods.
- The authors demonstrate a proactive approach in addressing reviewer concerns, showing appreciation for the feedback received.
- The commitment to open-sourcing the dataset and ensuring safety standards enhances the credibility of the research.

Weaknesses:
- The dataset lacks explicit support for multi-turn editing, although it shows some effectiveness in this area.
- There is insufficient discussion on how noise from sources like Grounding DINO and SAM is mitigated, which could affect dataset quality.
- The use of an Img2Img diffusion pipeline for generating source images may introduce complexities that impact editing fidelity.
- Potential biases in LLM-generated editing instructions are not adequately addressed.
- Some reviewers express uncertainty regarding the results due to a lack of accessible evidence during the rebuttal period.
- The limitations on PDF uploads during the rebuttal may hinder the reviewers' ability to fully assess the authors' claims.

### Suggestions for Improvement
We recommend that the authors improve the dataset by explicitly supporting multi-turn editing scenarios. Additionally, a more thorough exploration of noise mitigation strategies in the dataset is necessary. The authors should consider using original real images directly for editing rather than relying solely on generated images to enhance fidelity. Furthermore, addressing the potential biases in LLM-generated instructions is crucial to ensure a more reliable editing process. We also recommend that the authors improve the accessibility of supplementary materials to provide clearer evidence for their results. Clarifying the process for accessing uploaded files would help alleviate reviewer concerns regarding the evaluation of the paper. Finally, we encourage the authors to conduct controlled experiments comparing models trained on UltraEdit with those trained on existing datasets to better highlight the dataset's significance.