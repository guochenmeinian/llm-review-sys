ID: aCHq10rQiH
Title: CREATOR: Tool Creation for Disentangling Abstract and Concrete Reasoning of Large Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the CREATOR framework, which enables Large Language Models (LLMs) to create their own tools for solving mathematical and tabular word problems. The authors discretize the framework into four stages: (1) creation of a programmatic tool, (2) deciding how to use the tool for the current problem, (3) executing the program with the chosen tools, and (4) rectifying any syntactic errors or returning the output. The framework is evaluated on two benchmarks (MATH and TabMWP) and shows improved performance compared to existing methods. The paper also introduces the Creation Challenge dataset, emphasizing the necessity of LLMs' tool creation ability.

### Strengths and Weaknesses
Strengths:
- The framework empowers LLMs to create their own tools, addressing limitations in current approaches.
- Evaluation on challenging benchmarks demonstrates the benefits of leveraging LLMs for knowledge transfer and improved performance.
- The paper is well-written and presents a novel approach to tool creation.

Weaknesses:
- The Creation Challenge dataset is underspecified, lacking sufficient details for evaluating its validity.
- The experimental settings regarding tool re-use are unclear, leading to potential misrepresentation of the framework's capabilities.
- The execution ability and correctness of the LLM's tool creation remain questionable, with insufficient evaluations to support claims.

### Suggestions for Improvement
We recommend that the authors improve the specification of the Creation Challenge dataset, including statistics on diversity and types of questions. Additionally, clarify how the framework determines the number of tools to create for each query and whether tool re-use is implemented. The authors should provide more details on the experimental settings related to tool re-use and address how the model accesses previously created tools. Furthermore, insights into the execution-accuracy gap in Table 3 would enhance understanding of failure cases. Lastly, a discussion on the transferability of created tools and a mechanism to verify this would strengthen the paper's contributions.