ID: Vcw3vzjHDb
Title: Lean Workbook: A large-scale Lean problem set formalized from natural language math problems
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 8, 6, 7, -1, -1, -1, -1
Original Confidences: 5, 4, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an autonomous pipeline for translating contest-level math problems into formal Lean code, achieving high accuracy verified through multiple stages, including human expert evaluation. The authors propose a method that utilizes active learning to address data sparsity, resulting in a curated dataset of approximately 57K formal-informal theorem pairs, which can be used for theorem proving and NTP tasks.

### Strengths and Weaknesses
Strengths:  
- The paper effectively addresses learning in data-sparse scenarios, with a natural and complete workflow.  
- The performance evaluation is thorough, and the curated datasets are valuable for the AI mathematics field, relevant to broader AI challenges.  
- The active-learning framework is sound, with human assessment confirming 93.5% correctness in the dataset.

Weaknesses:  
- The brute-force strategy for theorem generation may lower difficulty, raising concerns about its limitations.  
- The paper lacks verification of the dataset's effectiveness in improving current LLMs and does not provide sufficient formal solutions for the auto-formalization process.  
- Quality control details are insufficient, with a small number of problems evaluated for accuracy.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the limitations of their brute-force strategy in Sec. 4.1, particularly regarding the potential impact on theorem difficulty. Additionally, clarify whether minimizing Type-1 errors is a goal and provide insights into the observed frequency of Type-2 errors. We suggest increasing the number of evaluated problems to at least 50 per type for more robust quality assessment and including detailed error analysis to identify weaknesses in the translation model. Furthermore, we encourage the authors to elaborate on related works, particularly in dataset curation and evaluation, and to consider comparisons with similar tasks in the MMA paper.