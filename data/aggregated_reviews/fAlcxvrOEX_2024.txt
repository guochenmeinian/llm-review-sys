ID: fAlcxvrOEX
Title: AdjointDEIS: Efficient Gradients for Diffusion Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 7, 5, 7, 6, -1, -1, -1
Original Confidences: 4, 3, 2, 2, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an adjoint sensitivity method, AdjointDEIS, for efficiently calculating gradients of diffusion SDE models, addressing the memory-intensive nature of naive backpropagation. The authors propose specialized solvers for both the adjoint probability flow ODE and the adjoint diffusion SDE, validated through a face morphing application. The method utilizes the Taylor expansion of the log-SNR parameter and the exact integral formula of derivatives related to the probability flow ODE.

### Strengths and Weaknesses
Strengths:
- The paper is well written, with clear explanations and proofs.
- The derivations for both the probability flow and SDE formulations are comprehensive.
- The specialized solvers leverage existing literature, demonstrating practical applications.

Weaknesses:
- The experimental validation is limited, with only a single application to face morphing, raising concerns about the significance and generalizability of results.
- Comparisons in experiments lack control over the number of function evaluations (NFE), making it difficult to assess performance conclusively.
- Some technical details, such as a missing factor in equation (3.1) and assumptions around equation (2.5), need clarification.

### Suggestions for Improvement
We recommend that the authors improve the experimental scope by including additional applications, such as data assimilation or inverse problems, to demonstrate the versatility of their method. It would also be beneficial to provide a proof of convergence rates or empirical studies of convergence rates for the proposed solvers. Additionally, clarifying the rationale for selecting the face morphing application and ensuring that empirical comparisons are made on an apples-to-apples basis regarding NFE would strengthen the paper. Lastly, addressing minor technical comments, such as the missing factor in equation (3.1) and the assumptions in equation (2.5), would enhance clarity.