ID: bg6fVPVs3s
Title: Guiding a Diffusion Model with a Bad Version of Itself
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 7, 7, 8, -1, -1, -1
Original Confidences: 5, 4, 5, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel conditioning method called autoguidance, which serves as an alternative to Classifier-Free Guidance (CFG). The authors propose guiding the diffusion model generation using a lower-quality version of the model instead of an unconditional model, aiming to enhance image quality without sacrificing data diversity. The paper includes a thorough comparison of CFG and autoguidance on the ImageNet dataset, demonstrating the effectiveness of the new approach.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and clear, with a thorough analysis of CFG behavior and its limitations.
- The use of an intuitive toy model supports empirical findings and could benefit future research.
- The proposed method is simple yet powerful, significantly improving state-of-the-art generation quality.

Weaknesses:
- The results do not clearly demonstrate the distribution coverage seen in the toy example, as the low-quality model appears to provide low-frequency guidance, sacrificing diversity for quality.
- The method requires training two distinct models, unlike CFG, which only requires one. This raises concerns about generalization and the necessary training data size for the lower-quality model.
- More visual examples are needed to illustrate how diversity changes with guidance scale, and the method is not readily applicable to pretrained diffusion models like Stable Diffusion.

### Suggestions for Improvement
We recommend that the authors improve the clarity of results by including the Inception score alongside the FID in Table 1 and providing a complete table of FID and IS values at various omega settings for a fair comparison with CFG. Additionally, we suggest visualizing the distributions of $p_0$, $p_1$, and $p_1/p_0$ in the autoguidance setting to enhance understanding. Including precision/recall curves for autoguidance versus CFG would also provide valuable insights into the impact on quality and diversity. Lastly, we encourage the authors to explore the use of a quantized model as the low-quality model and to provide more examples of generated images to facilitate comparison with CFG.