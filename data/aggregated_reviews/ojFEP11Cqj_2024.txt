ID: ojFEP11Cqj
Title: NRGBoost: Energy-Based Generative Boosted Trees
Conference: NeurIPS
Year: 2024
Number of Reviews: 19
Original Ratings: 9, 4, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 4, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an energy-based generative boosting method, NRGBoost, which aims to maximize the log-likelihood functional delta through a second-order expansion. The authors propose a boosting algorithm that utilizes deltas as steps in log-likelihood, employing linear search for performance enhancement instead of fixed scaling. The method initializes with a uniform function and employs trees as weak learners to derive the objective, aligning closely with second-order methods like XGBoost. The use of MCMC for sampling from Q(x) is noted, with Gibbs sampling allowing one-dimensional sampling while maintaining others constant. The paper demonstrates impressive results in generating samples from MNIST using decision trees, despite the challenges posed by the dataset's complexity. Additionally, the authors provide a comparative analysis of various machine learning methods, focusing on tree-based models and neural networks. They propose DEF models as an enhancement over Density Estimation Trees (DET) with algorithmic improvements like bagging and the use of KL divergence. However, DEF models exhibit slower training times and consistently lower performance compared to NRGBoost, which scales better with tree depth. The authors introduce a memorizing baseline to evaluate the performance of learning empirical distributions, revealing that memorization alone does not guarantee superior performance.

### Strengths and Weaknesses
Strengths:  
- The method is sound, novel, and interesting, achieving good image data samples with trees.  
- The presentation is well-structured and clear.  
- The literature review is comprehensive, providing context for the proposed approach.  
- The authors provide a clear rationale for their choice of models and improvements, particularly with DEF models.  
- The introduction of a memorizing baseline adds depth to the analysis of performance metrics.  
- The authors demonstrate a commitment to fairness in benchmarking and welcome feedback for further improvement.

Weaknesses:  
- The evaluation lacks a distribution metric, relying solely on ML efficiency, which is inadequate.  
- The experimental settings raise questions regarding robustness and computational cost.  
- Some relevant benchmark methods are missing, and the significance of performance claims is not supported by tests.  
- DEF models consistently underperform compared to NRGBoost, raising concerns about their viability as a baseline.  
- The slow training times and poor performance of the GOGGLE method hinder meaningful comparisons.  
- The reliance on existing literature for neural network hyperparameter tuning may limit the robustness of the results.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by incorporating distribution metrics such as the Wasserstein distance or MMD distance to assess sample diversity and quality. Additionally, please provide evidence supporting claims of robustness to hyperparameters and clarify the computational cost compared to benchmarks. It would also be beneficial to summarize variance evaluations in a single table for easier comparison. Lastly, ensure that all relevant benchmark methods are included and that significance tests for performance claims are conducted. Furthermore, we suggest that the authors improve the benchmarking of all methods to ensure a fair comparison, particularly by addressing the performance issues associated with DEF models. We encourage the authors to explore alternative hyperparameter tuning strategies for neural networks to enhance their experimental setup. For the GOGGLE method, we recommend investigating optimizations that could reduce training times and improve performance metrics, enabling a more equitable comparison with other methods.