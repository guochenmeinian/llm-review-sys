ID: 3HpgVs22UJ
Title: Adaptive $Q$-Aid for Conditional Supervised Learning in Offline Reinforcement Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 7, 7, 6, 3, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an offline reinforcement learning framework that integrates return-conditioned supervised learning (RCSL) with Q-learning, resulting in the Q-aided Conditional Supervised Learning (QCS) algorithm. The authors demonstrate the advantages of their approach through extensive experiments on various offline datasets, showing that QCS significantly outperforms existing methods. The primary contributions include identifying the strengths and weaknesses of RCSL and Q-learning in different settings and proposing a novel method to enhance performance.

### Strengths and Weaknesses
Strengths:
1. The problem addressed is significant, as enhancing RCSL with Q-learning capabilities is vital for optimal policy pursuit.
2. The analysis and experiments provide valuable insights into RCSL and Q-learning, leading to the natural optimization of the proposed QCS method.
3. Empirical results indicate promising performance across multiple datasets and domains.

Weaknesses:
1. The definition of the degree of Q-aid as w(R($\tau$)) is flawed; it should reflect the optimality of the behavior policy, as a higher return does not guarantee a superior policy.
2. The analysis of the Q-Greedy Policy is somewhat redundant, as the focus should be on integrating Q-learning into GCSL.
3. The experimental section lacks detail, necessitating the inclusion of more information from the appendix into the main paper.

### Suggestions for Improvement
We recommend that the authors improve the definition of the degree of Q-aid to accurately reflect the optimality of the behavior policy. Additionally, we suggest that the authors streamline the analysis of the Q-Greedy Policy to focus on the integration of Q-learning into GCSL. Furthermore, we encourage the authors to expand the experimental section by incorporating more details from the appendix to enhance clarity and comprehensiveness.