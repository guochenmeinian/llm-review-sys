ID: zkPxoyPeva
Title: Gradient Estimation For Exactly-$k$ Constraints
Conference: NeurIPS
Year: 2023
Number of Reviews: 2
Original Ratings: 7, 7
Original Confidences: 4, 3

Aggregated Review:
### Key Points
This paper presents theoretical and experimental analysis for gradient estimation under exactly-k constraints. The authors propose closed-form estimation for specific cases, demonstrating that their estimator outperforms the empirical state-of-the-art (SOTA) when utilizing ensemble techniques.

### Strengths and Weaknesses
Strengths:  
The paper is well-structured and presents a valuable contribution to the field, with a method that shows improved performance over existing techniques.

Weaknesses:  
The discussion on the algorithm's applicability is limited, and there is a lack of sensitivity analysis and computational burden assessment for the proposed methods.

### Suggestions for Improvement
We recommend that the authors improve the paper by providing sensitivity analysis to strengthen the comparison to the SOTA. Additionally, the authors should include a computation burden analysis (resources, time, etc.) for each method to demonstrate the efficiency of the new estimator. Furthermore, we suggest adding a discussion section in the appendix to clarify their empirical contributions and outline potential future applications for the estimator.