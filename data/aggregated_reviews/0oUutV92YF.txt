ID: 0oUutV92YF
Title: ProtGO: Function-Guided Protein Modeling for Unified Representation Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ProtGO, a knowledge distillation-based framework that incorporates Gene Ontology (GO) knowledge to learn a unified, multi-modal embedding for proteins. The authors demonstrate that ProtGO achieves improved performance on various tasks, such as folding classification and GO term classification, by leveraging additional function information. The model simplifies inference by eliminating the need for GO terms during this phase.

### Strengths and Weaknesses
Strengths:
1. ProtGO introduces a novel method that utilizes function information, indicating enhanced performance.
2. The teacher-student approach allows for simplified inference without additional function inputs.
3. Benchmark experiments show that ProtGO significantly outperforms state-of-the-art baselines.

Weaknesses:
1. The method does not adequately address existing baselines, such as Protst, which also utilizes function information but relies solely on protein sequences post-alignment.
2. The ablation study is unclear, particularly regarding the performance of ProtGO without a teacher model and the trivial improvement from the teacher-student module compared to the backbone GNN.
3. The necessity of domain adaptation is questioned, and the absence of an ablation study on this aspect is noted.
4. The experiments are limited to small benchmarks; results on larger datasets would enhance the generalizability of the proposed method.

### Suggestions for Improvement
We recommend that the authors improve the baseline comparisons by including Protst and other powerful methods across all modalities (sequence, structure, GO). Additionally, we suggest clarifying the differences between the backbone GNN model and other baselines in the ablation study. To strengthen the results, the authors should conduct experiments on larger-scale benchmarks and consider binding affinity prediction as a downstream task. Finally, we encourage the authors to explore the effectiveness of each part of the GO terms through comprehensive downstream experiments and to provide more detailed information about error bars in the results.