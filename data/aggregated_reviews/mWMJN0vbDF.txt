ID: mWMJN0vbDF
Title: Towards Faithful Sign Language Translation
Conference: NeurIPS
Year: 2023
Number of Reviews: 6
Original Ratings: 6, 5, 4, 5, 5, -1
Original Confidences: 5, 4, 4, 5, 5, -1

Aggregated Review:
### Key Points
This paper presents a novel framework for sign language translation (SLT) called MonoSLT, which integrates multiple SLT subtasks and proposes alignment and consistency constraints to enhance faithfulness in translation. The authors conduct experimental analyses that demonstrate the method's state-of-the-art (SOTA) performance on two widely adopted SLT benchmarks using only keypoint inputs. The work addresses critical issues such as the relationship between SLT and sign language recognition (SLR) performance and the lack of faithfulness in current SLT models.

### Strengths and Weaknesses
Strengths:
1. The paper identifies significant problems in SLT, particularly the lack of faithfulness and the inconsistent trends between SLR and SLT, which can inspire future research.
2. The method is well-motivated by in-depth analyses, particularly illustrated in Figure 3.
3. The introduction of code-switching is novel and may inspire future cross-modality modeling for SLT.
4. The framework achieves competitive performance with a lightweight model using only keypoint inputs.

Weaknesses:
1. Methodological concerns arise regarding the sharing of classifiers in the model, requiring further discussion on the design choices.
2. There is insufficient discussion or comparison regarding gloss embeddings and mixup techniques from recent literature.
3. The motivation for code-switching between visual and gloss embeddings lacks clarity, and its applicability to contextual embeddings is unexplored.
4. Experimental results show inconsistencies in performance between sentence-wise and token-wise code-switching, needing further explanation.
5. The paper lacks objective metrics to measure faithfulness in SLT, relying on BLEU and ROUGE, which may not adequately capture this aspect.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the classifier design in Figure 2, clarifying the rationale behind using shared versus separate classifiers. Additionally, the authors should include a comparison with recent works on gloss embeddings and mixup techniques to strengthen their claims. Further clarification on the motivation for code-switching between visual and gloss embeddings is necessary, as well as an exploration of its potential application to contextual embeddings. We suggest that the authors provide a more thorough analysis of the experimental results, particularly regarding the performance discrepancies observed in code-switching methods. Finally, we urge the authors to develop or identify suitable metrics to quantitatively evaluate the faithfulness of SLT models, moving beyond traditional evaluation methods.