ID: m5106RRLgx
Title: Are More LLM Calls All You Need? Towards the Scaling Properties of Compound AI Systems
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 5, 8, 5, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into how the number of function calls in language model (LM) inference systems affects performance, specifically through two designs: Vote and Filter-Vote. The authors find a U-shaped performance curve, where easy queries benefit from more function calls, while hard queries may suffer. Theoretical and empirical analyses are conducted, revealing that additional LM calls can lead to non-monotonic performance based on query difficulty. The authors propose a method to determine the optimal number of LM calls to maximize performance.

### Strengths and Weaknesses
Strengths:  
- The paper provides novel insights into the relationship between task difficulty, LM calls, and model behavior.  
- The writing is clear and easy to follow, with a well-defined scope.  
- Both theoretical analysis and empirical experimentation are well-executed, supporting the main claims.  

Weaknesses:  
- The results are not surprising, as the underlying problem is straightforward when viewed without the LLM context.  
- The empirical results are inadequately presented; only a few case studies are shown instead of overall results from all datasets.  
- The focus is limited to two simple inference system designs, which may diminish the significance of the findings.  
- The determination of query difficulty is overly simplistic and not model-agnostic, potentially reducing the findings' applicability.

### Suggestions for Improvement
We recommend that the authors improve the presentation of empirical results by including overall results from all datasets in the experiment section, if page limits allow. Additionally, consider expanding the analysis to include more diverse benchmarks beyond multiple-choice tasks. We also suggest that the authors clarify the robustness of their results regarding LLM outputs and explore additional robustness tests, such as shuffling option orders or adding input perturbations. Finally, we encourage the authors to address the limitations of their difficulty categorization and explore more nuanced measures for determining the optimal number of LM calls.