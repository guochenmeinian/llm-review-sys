ID: RMmgu49lwn
Title: Image Understanding Makes for A Good Tokenizer for Image Generation
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 5, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel framework that leverages image understanding (IU) models to enhance image generation (IG) performance through a token-based generation approach and a feature reconstruction objective. The authors demonstrate that tokenizers with strong IU capabilities, particularly the VQ-KD model, outperform traditional methods like VQGAN and FSQ across various metrics and datasets. The paper includes extensive experiments and analyses to validate its claims.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and systematically organized, making it easy to follow.
- It effectively merges IU and IG models, demonstrating the effectiveness of this approach.
- Extensive quantitative experiments validate the proposed method's superiority.

Weaknesses:
- The paper makes excessive and unjustified claims regarding its novelty in combining IU with IG.
- Observations in Section 3.4 require further justification, particularly regarding the relevance of VQ-KD's superiority to quantization and codebook usage.
- There is a lack of qualitative analysis and visualizations, which are crucial for an image generation method.
- The experiments are limited to specific datasets, and the generalizability of the findings is not adequately explored.

### Suggestions for Improvement
We recommend that the authors improve the justification for their claims regarding the novelty of their work and provide a more comprehensive comparison with existing methods. Additionally, we suggest including more qualitative results and visualizations to enhance the persuasiveness of the findings. Expanding the dataset range to include higher resolution and quality datasets, as well as conducting detailed ablation studies, would strengthen the paper's conclusions. Lastly, we encourage the authors to clarify the theoretical support for the VQ-KD tokenizer and address the computational efficiency of their approach.