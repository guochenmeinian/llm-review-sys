ID: 559NJBfN20
Title: Language Models are Weak Learners
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 7, 6, 4, 4, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 2, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to utilizing large language models (LLMs) as weak learners within boosting frameworks for tabular data classification. The authors propose a method called LLM Summary Boosting, which generates text descriptions of tabular data samples to create weak classifiers that can be integrated into a boosting algorithm. The experimental results indicate that this approach outperforms traditional tree-based boosting methods and demonstrates effectiveness in scenarios with limited data availability.

### Strengths and Weaknesses
Strengths:
1. The paper effectively combines the concepts of weak learners and LLMs, presenting a unique methodology for tabular data classification.
2. It provides clear guidelines for converting tabular data into text descriptions, allowing for minimal manual engineering.
3. Extensive experiments validate the proposed method's performance across various datasets, showcasing its advantages over existing techniques.

Weaknesses:
1. The method may struggle with high-dimensional tabular data and irrelevant features, potentially introducing noise in text descriptions.
2. The focus on numerical features limits the discussion on generating text descriptions for ordinal and categorical features, which requires a more systematic approach.
3. The reliance on commercial APIs raises concerns about reproducibility, cost implications, and potential biases in the evaluation methodology.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the applicability of their method to high-dimensional data and provide a systematic approach for generating text descriptions for all feature types, including ordinal and categorical. Additionally, we suggest addressing the limitations of using commercial APIs in more detail, including their impact on reproducibility and potential biases. Clarifying the empirical results in tables and enhancing the presentation by highlighting key findings would also strengthen the paper. Finally, we encourage the authors to explore the use of open-source models to enhance the robustness of their findings.