ID: xapBkUt0yf
Title: CompoundPiece: Evaluating and Improving Decompounding Performance of Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a multi-lingual data collection focused on compounds and their boundaries, aiming to develop systems for automatic compound boundary identification. The authors compile a benchmark of compounds from 56 languages, define two decompounding task variants, and propose a self-supervised method for compound segmentation. The dataset, comprising 255K compound words, is extensive and promises utility for future research.

### Strengths and Weaknesses
Strengths:
- The paper addresses an important task relevant to many languages and extends the scope to a diverse set of languages.
- It proposes a novel self-supervised learning method for segmentation, leveraging hyphen usage effectively.
- The experimental setup is sound, yielding strong results across various settings, and the paper is well-structured.

Weaknesses:
- The data collection process has limitations, including a bias towards short words and assumptions about hyphen usage.
- There is a lack of extrinsic evaluation, making it unclear if improved compound segmentation translates to better downstream performance.
- The discussion of linguistic implications and broader impacts of the method is minimal.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the bias in selecting non-compounds and the implications of hyphen usage in different languages. Additionally, addressing the lack of extrinsic evaluation is crucial; we suggest including downstream task assessments to validate the practical impact of the proposed methods. Finally, we encourage the authors to expand the discussion on the linguistic implications of their findings and consider follow-up experiments to enhance the robustness of their results.