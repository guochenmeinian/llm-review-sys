ID: sJUCMYtgIK
Title: Augmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Mixture-Of-Memory Augmentation (MoMA), a method designed to enhance the zero-shot generalization ability of large language models (LLMs) by retrieving augmentation documents from multiple information corpora, referred to as "external memories." The authors evaluate MoMA on several tasks from the BEIR benchmark, demonstrating that it outperforms other dense retrieval methods. The paper introduces a learning mechanism for training the augmentation component and empirically shows the effectiveness of memory mixture in improving generalization across new domains.

### Strengths and Weaknesses
Strengths:
- The proposed method is novel and well-motivated, addressing the challenge of zero-shot document augmentation.
- Consistent improvement in results across various benchmarks, with strong generalization performance.
- The "plug-n-play" nature of MoMA makes it widely applicable and of interest to the NLP research community.
- Extensive evaluation and detailed ablation studies support the claims made.

Weaknesses:
- Concerns regarding the efficiency of the method when the target corpus is large, as performance gains are heavily reliant on its inclusion.
- Lack of clarity on whether the information retrieval task is supervised or unsupervised, leading to confusion.
- MoMA's performance is inferior to BM25 on certain datasets, such as Signal-1M and SciFact, without sufficient analysis provided for this discrepancy.

### Suggestions for Improvement
We recommend that the authors improve clarity regarding the nature of the information retrieval task, explicitly stating whether it is supervised or unsupervised. Additionally, we suggest providing a thorough analysis of the performance of MoMA compared to BM25 on datasets where it underperforms, such as Signal-1M and SciFact. Furthermore, we encourage the authors to consider setting up a dense retrieval baseline using the ST5-EncDec variant of Sentence-T5, ensuring that retrieved variants come from different sources. Lastly, addressing the questions about the in-domain results on MSMARCO and the performance of the trained augmentation component $f^a()$ in isolation would enhance the paper's comprehensiveness.