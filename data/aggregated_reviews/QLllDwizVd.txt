ID: QLllDwizVd
Title: Where2Explore: Few-shot Affordance Learning for Unseen Novel Categories of Articulated Objects
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 6, 6, 6, 5, 6, -1, -1, -1
Original Confidences: 4, 4, 4, 5, 2, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel task of cross-category few-shot learning for articulated object manipulation and introduces the Where2Explore framework. The framework measures semantic similarity of local geometries, interacts with novel category objects based on this similarity, updates the affordance estimation network, and manipulates the target object. Experimental results indicate that the proposed method outperforms existing approaches, with successful demonstrations on a real robot.

### Strengths and Weaknesses
Strengths:
1. The formulation of cross-category few-shot affordance learning is valuable for robotic applications.
2. The framework effectively utilizes geometric similarity to guide exploration of novel object categories, supported by a well-designed similarity learning pipeline.
3. The motivation for efficient few-shot learning is compelling, and the training strategy for cross-category geometry-aware affordance similarity is straightforward and effective.

Weaknesses:
1. Experimental results lack statistical measures such as standard deviation, particularly regarding variance from few-shot learning instance selection.
2. Despite outperforming baselines, the success rate remains unsatisfactory, and the discussion of results, including failure cases, is insufficient.
3. The assumption that similar geometries indicate similar affordances across novel categories may not be robust.
4. The method is limited to two actions (push and pull), and the action definitions are not clearly validated against real data.

### Suggestions for Improvement
We recommend that the authors improve the statistical reporting in experimental results by including standard deviations. Additionally, a more thorough discussion of the results, including failure cases, should be added to provide context for the low success rates. The authors should clarify the assumption regarding geometric similarity and affordance, potentially providing empirical support. Expanding the action set beyond push and pull, and ensuring that action definitions are validated against real data, would enhance the robustness of the framework. Furthermore, we suggest that the authors elaborate on the similarity learning process, including how Eq(1) is utilized, and clarify the stopping criteria for few-shot training. Lastly, a more comprehensive discussion of limitations, including the simulation-to-real gap and the need for more extensive real-world evaluations, is essential for strengthening the paper's contributions.