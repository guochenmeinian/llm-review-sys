ID: No52399wXA
Title: IPMix: Label-Preserving Data Augmentation Method for Training Robust Classifiers
Conference: NeurIPS
Year: 2023
Number of Reviews: 22
Original Ratings: 5, 4, 7, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents IPMix, a novel data augmentation strategy that combines fractals with original images at multiple levels (image, patch, and pixel) to enhance model robustness and safety metrics without compromising clean accuracy. The authors propose that IPMix outperforms existing methods such as AugMix and other pixel-level techniques by improving performance in classification, robustness, anomaly detection, and calibration. Evaluations are conducted on CIFAR-10, CIFAR-100, ImageNet, and their shifted versions, demonstrating significant improvements over AugMix and various data augmentation baselines. Additionally, IPMix is characterized by its plug-and-play nature, allowing for easy integration with existing models.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and easy to understand, with clear methodology and thoughtful comparisons.
- Extensive evaluations and ablation studies validate the robustness of IPMix across multiple metrics, including adversarial perturbations and anomaly detection.
- IPMix shows significant performance improvements over AugMix and other pixel-level methods, particularly in robustness and safety metrics.
- The method is label-preserving and plug-and-play, allowing for easy integration with existing models.
- Experimental results indicate strong performance even on smaller models, with potential resource savings when applied to larger architectures.

Weaknesses:
- ImageNet results show only minor improvements over PixMix, raising questions about the inherent limitations of synthetic data mixing for diversity generation.
- The efficacy of IPMix on larger models and large-scale datasets like ImageNet remains a concern, with limited improvements noted in initial experiments.
- The paper lacks comparisons with other augmentation methods like DeepAugment and does not evaluate performance against natural distribution shifts or recent benchmarks.
- The motivation for using unlabeled synthetic images is insufficiently explained, and the technical contributions of IPMix may not be clearly articulated, leading to questions about its novelty compared to existing literature.
- The organization of the paper could be improved for clarity.

### Suggestions for Improvement
We recommend that the authors improve the discussion around the motivation for using unlabeled synthetic images, providing clearer theoretical or practical justifications. Additionally, including comparisons to DeepAugment and evaluations against natural distribution shifts like ImageNet-V2 and ObjectNet would strengthen the findings. We suggest that the authors clarify the technical contributions of IPMix, emphasizing its unique aspects compared to existing methods. Furthermore, including comprehensive results from experiments on larger models, such as ResNet-50, would convincingly demonstrate IPMix's effectiveness on large-scale datasets. Lastly, revising the abstract and introduction to better reflect the novelty and contributions of the proposal in relation to existing literature would enhance the manuscript's impact.