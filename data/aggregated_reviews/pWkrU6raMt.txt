ID: pWkrU6raMt
Title: SubseasonalClimateUSA: A Dataset for Subseasonal Forecasting and Benchmarking
Conference: NeurIPS
Year: 2023
Number of Reviews: 29
Original Ratings: 6, 6, 7, 9, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 2, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the SubseasonalClimateUSA dataset, designed for training and benchmarking subseasonal forecasting models across the contiguous United States. It builds upon the SubseasonalRodeo dataset by offering new variables, a broader geographical scope, and regular updates. The authors benchmark various models, including simple baselines and machine learning approaches, to evaluate their performance in forecasting key atmospheric variables over a subseasonal timeframe. The paper also focuses on improved deterministic forecasting for temperature and precipitation, adopting evaluation protocols from the Subseasonal Climate Forecast Rodeo competitions. The authors clarify the use of 14-day averaged temperature and precipitation measurements from NOAA datasets as ground truth for model evaluation and outline their progressive training and validation protocol for model forecasting.

### Strengths and Weaknesses
Strengths:
1. The dataset integrates seven meteorological data sources, providing machine-learning-ready Python Pandas DataFrames.
2. It covers the entire contiguous USA, enhancing the previous SubseasonalRodeo dataset.
3. The documentation is clear, and the GitHub repository appears actively maintained.
4. Extensive benchmarking is conducted, including comparisons with 17 state-of-the-art forecasting models and plans to incorporate additional recent models like PanguWeather and Graphcast.
5. The authors demonstrate a clear understanding of the differences between their dataset and the SubseasonalRodeo dataset, emphasizing the advantages of their approach.

Weaknesses:
1. The dataset lacks novelty compared to the SubseasonalRodeo, presenting primarily incremental improvements.
2. The benchmark section does not introduce new benchmarks compared to an earlier version of the paper submitted two years prior.
3. The resolution of the dataset is considered coarse for predicting extreme events, and the averaging of ACC and RMSE metrics may not be suitable for such events.
4. Some reviewers expressed concerns regarding the novelty of the dataset component within the context of the NeurIPS Track Datasets and Benchmark.
5. There is a need for more discussion on why simpler baselines may outperform more complex models, which could enhance the paper's depth.

### Suggestions for Improvement
We recommend that the authors improve the dataset's resolution to better accommodate extreme event predictions, potentially aligning with the 0.25-degree resolution of ERA5 datasets. Additionally, consider incorporating percentile-related metrics or probability density functions for evaluating extreme events. Clarifying the ground truth used for metrics computation and the training setup, including the specific years for training and validation, would enhance transparency. We suggest including a detailed discussion on the standardization of data sources and the interpolation methods used, as well as providing error bars or measures of variance in benchmark results. It would also be beneficial to articulate the intended use of the dataset for the community and suggest specific benchmarks for users to target. Furthermore, we recommend improving the clarity of the differences between the SubseasonalClimateUSA and SubseasonalRodeo datasets in the main text and incorporating the training setup details from the appendix into the main body of the paper. Lastly, including a discussion on the performance of simple baselines compared to more complex models and considering the addition of extVAE to their benchmark suite, acknowledging its unpublished status, would enhance the paper's depth and utility.