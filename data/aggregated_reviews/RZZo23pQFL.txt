ID: RZZo23pQFL
Title: SSA-Seg: Semantic and Spatial Adaptive Pixel-level Classifier for Semantic Segmentation
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 5, 2, 5, -1, -1, -1, -1
Original Confidences: 3, 5, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel Semantic and Spatial Adaptive (SSA) classifier aimed at addressing limitations in current pixel-level classifiers for semantic segmentation, specifically issues of feature deviation in the semantic domain and information loss in the spatial domain. The authors employ coarse masks from fixed prototypes to adjust these prototypes towards the centers of the semantic and spatial domains in test images. Additionally, they introduce an online multi-domain distillation learning strategy to guide this adaptation. Experimental results demonstrate that the SSA classifier significantly enhances segmentation performance across three benchmark datasets with minimal computational cost increase.

### Strengths and Weaknesses
Strengths:
1. The proposed SSA classifier effectively offsets fixed prototypes towards the centers of the semantic and spatial domains.
2. The design of multi-domain knowledge distillation enhances the primary classifier by conveying accurate semantic and structural information.
3. The method shows significant performance improvements on ADE20k, PASCAL-Context, and COCO-stuff-10K with negligible computational overhead.

Weaknesses:
1. The paper lacks evaluation on high-resolution datasets like Cityscape and does not provide key details such as memory usage and input image resolution for training and inference.
2. The term "new branch" in the context of online multi-domain distillation is unclear, and there is insufficient detail regarding the "Teacher classifier."
3. The paper does not adequately address the assumption that objects of the same class should be located in specific regions of the image, which may not hold in real-world scenarios.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the "new branch" concept in the online multi-domain distillation section and provide more details about the "Teacher classifier." Additionally, the authors should evaluate their method on high-resolution datasets like Cityscape and include comparisons of memory usage and input image resolutions. To enhance the paper's credibility, we suggest conducting comprehensive comparisons with previous mask-level classification models, including metrics such as parameters, FPS, and FLOPs. Furthermore, the authors should clarify the evidence supporting the claim of large intra-class variance in pixel features and consider visualizing the results using t-SNE to strengthen their arguments. Lastly, addressing the assumptions regarding spatial relationships in segmentation could improve the robustness of the proposed method.