ID: z8gM4ZfK8l
Title: Improving Cross-lingual Transfer through Subtree-aware Word Reordering
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a source-sentence reordering method aimed at bridging the gap between typologically distant languages in cross-lingual transfer. The authors learn reordering rules based on Universal Dependencies and apply them at all levels of the syntactic tree. Extensive experiments demonstrate the method's effectiveness, particularly for low-resource languages, across various tasks and settings, including zero-shot and few-shot scenarios.

### Strengths and Weaknesses
Strengths:
- The proposed method is simple, effective, and enhances post-hoc interpretability.
- Extensive experiments across diverse tasks and languages yield comprehensive results.
- The "Related work" section is informative and well-structured.
- The initiative to discuss the method's shortcomings in detail is commendable.

Weaknesses:
- Insufficient comparison with related works, particularly with Rasooli and Collins (2019) and Aufrant et al. (2016).
- The effectiveness of the proposed settings (STANDARD and ENSEMBLE) varies across tasks and languages, necessitating further investigation.
- Some analyses lack depth, and the interpretation of results may overlook important linguistic nuances.

### Suggestions for Improvement
We recommend that the authors improve the comparison with related works, particularly clarifying the differences with Rasooli and Collins (2019) and including Aufrant et al. (2016) to address potential methodological choices. Additionally, we suggest quantifying the typological and word-order distance between languages to formalize observed performance trends. The authors should also address the interpretability of their method more explicitly in the paper. Furthermore, enhancing the analysis of results, particularly for tasks like relation classification, and providing clearer explanations for performance variations in closely related languages would strengthen the paper. Lastly, we encourage the authors to refine the presentation of results in tables for better readability and clarity.