ID: uXJlgkWdcI
Title: PACE: Pacing Operator Learning to Accurate Optical Field Simulation for Complicated Photonic Devices
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 6, 7, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel neural operator, PACE, designed for electromagnetic field simulation, claiming improved accuracy, efficiency, and speed compared to existing methods, particularly NeurOLight. The authors introduce a two-stage learning process that enhances performance and provide a dataset for optical field simulations of complex devices. Additionally, the paper contributes a new parameter-efficient cross-axis factorized neural operator and a new learning flow for solving challenging PDE cases. The authors emphasize that no single model can address all PDE scenarios and demonstrate significantly better accuracy than state-of-the-art work on a challenging multi-scale PDE problem, despite the absence of the original dataset for direct comparison.

### Strengths and Weaknesses
Strengths:
- The paper is well-structured, clearly articulating the challenges in optical field prediction for complex devices.
- The introduction of the PACE operator effectively addresses these challenges, demonstrating strong performance against NeurOLight and other machine learning PDE solvers.
- The authors validate their improvements through well-designed ablation studies and provide a valuable dataset for future research.
- The authors effectively address most reviewer concerns with additional experiments and clarifications.
- The paper provides significant insights into improving neural operators for challenging PDE cases, with promising results in accuracy compared to state-of-the-art models.

Weaknesses:
- The work may be too specialized for a broader ML conference, potentially better suited for a photonics journal.
- The interpretation of error metrics is unclear, and the paper lacks explicit definitions for the metrics used in various tables.
- There are concerns regarding the fairness of speed comparisons, particularly if GPU-based methods are compared against CPU-only algorithms.
- The speedup claims lack one-to-one comparisons regarding accuracy and computational time/hardware.
- The terminology used, such as "divide-and-conquer," could be improved for clarity, with "coarse-to-fine" being a more appropriate description.
- The writing contains several typographical errors and unclear sentences, which detract from the overall clarity.

### Suggestions for Improvement
We recommend that the authors improve the clarity of error metric definitions and explicitly state the metrics used in tables. Additionally, please provide a more detailed discussion on the speed comparisons to ensure fairness, particularly regarding CPU versus GPU usage. We suggest avoiding exaggerated language and ensuring that all claims are substantiated with appropriate evidence. The authors should clarify the term "PACE" and consider using "complex" instead of "complicated" for consistency with existing literature. We also recommend rephrasing "divide-and-conquer" to "coarse-to-fine" or framing it as an iterative model, as well as reconsidering the use of "human learning" to avoid hyperbole. Lastly, we encourage the authors to enhance the visual clarity of figures and ensure that all relevant metrics, such as Flops and testing time, are included in Table 1, and to proofread the paper for the typos mentioned and any others that may have been overlooked.