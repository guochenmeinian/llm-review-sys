ID: LE4AN1FGjJ
Title: Degraded Polygons Raise Fundamental Questions of Neural Network Perception
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 9, 7, 4, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a computer vision benchmark dataset created by degrading regular polygons through the removal of edges or corners, aiming to evaluate neural networks' shape recognition capabilities and explore the misalignment between deep learning vision models and human vision. The authors find that networks pretrained on ImageNet perform better with edge degradation than corner degradation, contrasting with human performance. This discrepancy highlights significant differences in how machines and humans perceive shapes. The study contributes to discussions on model biases and robustness in machine learning and proposes a minimum viable task using simple geometric shapes to induce this misalignment. The paper includes new figures with confusion matrices and error bars to enhance the analysis of model behavior.

### Strengths and Weaknesses
Strengths:  
- The paper effectively highlights the intriguing differences in perception between humans and neural networks, particularly regarding shape recognition.  
- The experimental setup is well-motivated and utilizes standard networks, providing valuable insights into model behavior.  
- The dataset and code are publicly accessible, promoting reproducibility.  
- The paper is well-written, organized, and motivated, providing clear insights into the misalignment phenomenon.  
- The introduction and related work sections have been revised to better articulate the significance of the dataset and its implications for understanding human-machine vision discrepancies.  
- The inclusion of confusion matrices and error bars in the revised figures enhances the clarity and reproducibility of the results.

Weaknesses:  
- The significance and generalizability of the findings are unclear, particularly regarding their applicability to real-world scenarios.  
- The basic nature of the presented data raises questions about its applicability to real-world classification problems.  
- The GradCAM analysis does not provide new insights beyond what is already discussed in the paper, and the validity of the Grad-CAM experiments is questionable, as concerns about the stability of CAM methods remain unaddressed.  
- The dataset is perceived as simplistic, raising questions about its contribution to the benchmark and datasets track.  
- The lack of examples of actual data in the supplemental material limits the reader's understanding of the dataset's practical implications.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the significance of their findings by discussing how these insights can be applied in practical machine learning contexts. Additionally, providing confusion matrices for all experiments would enhance understanding of classification errors between humans and CNNs. We suggest incorporating examples of the actual data in the paper and supplemental material, as this would better illustrate the dataset's characteristics and the challenges faced by CNNs compared to human perception. Furthermore, a more thorough description of the fractal pretraining process would be beneficial, and we urge the authors to clarify the importance of the GradCAM analysis and consider exploring the Gestalt literature to enrich the theoretical framework of their study.