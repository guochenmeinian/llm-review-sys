ID: 5ZlfgzLEjn
Title: The Art of Knowing When to Stop: Analysis of Optimal Stopping in People and Machines
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 5, 4, 7
Original Confidences: 3, 3, 3

Aggregated Review:
### Key Points
This paper presents an investigation into the optimal stopping problem in a discovery game, utilizing a Bayesian learning approach to model human decision-making based on behavioral experiment data. The authors also explore the performance of LLMs in this context, providing insights into human cognitive processes and the limitations of current LLMs as cognitive models.

### Strengths and Weaknesses
Strengths:
- The paper addresses a novel and relevant research question about human decision-making in combinatorial innovation.
- It features a well-defined task and formalization, allowing for rigorous comparisons between human behavior and heuristic models.
- The empirical data from human experiments is compelling, revealing systematic deviations from rationality and establishing benchmarks for heuristic models.
- The proposed Bayesian heuristic models fit the empirical data well, suggesting that simple cognitive processes may be employed in complex problems.
- The initial exploration of LLMs as cognitive models opens interesting avenues for future research.

Weaknesses:
- The LLM experiments are limited, focusing on a specific prompting technique without exploring alternative strategies or architectures.
- There is a lack of in-depth analysis regarding the limitations of LLM behavior and no specific strategies for improvement are suggested.
- The paper does not adequately discuss the broader implications of its findings for interventions in human decision-making or future research directions.
- References are not listed in numerical order, which is a distracting formatting error.
- The novelty of the heuristic models is not fully articulated in relation to existing decision-making models.
- The evaluation of LLMs is restricted to ChatGPT, lacking a systematic assessment of other models and prompt engineering effects.
- The theoretical implications of the findings regarding human heuristics in optimal stopping are underexplored.

### Suggestions for Improvement
We recommend that the authors expand LLM experiments by exploring a wider range of prompting techniques, including chain-of-thought prompting, and consider using different LLM architectures. Additionally, analyze LLM behavior in depth by investigating the reasons behind observed performance, potentially through attention weights or intermediate representations, and propose strategies for enhancing LLM performance in this task. The authors should elaborate on the broader implications of their findings for developing interventions to improve human decision-making in combinatorial innovation. Furthermore, ensure that references are listed in the correct numerical order and adhere to NeurIPS formatting guidelines. Clearly articulate the novelty of the proposed Belief Update Systems in relation to existing decision-making models in cognitive science. Conduct a more systematic evaluation of various LLMs, including those beyond ChatGPT, and investigate the impact of prompt engineering techniques on their performance. Finally, explore the theoretical implications of the findings, particularly regarding the learnability and adaptability of human heuristics in optimal stopping.