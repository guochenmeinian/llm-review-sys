ID: ePKuQQwCGm
Title: Targeted Unlearning with Single Layer Unlearning Gradient
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 5, 7, 6
Original Confidences: 2, 4, 4

Aggregated Review:
### Key Points
This paper presents a novel machine unlearning method named SLUG, which focuses on efficiently unlearning targeted information by updating a single layer in a model. The authors propose a strategy that identifies relevant layers for unlearning and applies weight updates only to these layers, computing the gradient just once to reduce computational costs. The experiments demonstrate competitive results with alternative approaches on Stable Diffusion, particularly when training the language model behind CLIP.

### Strengths and Weaknesses
Strengths:
- The method is efficient, requiring only one-time gradient computation.
- It offers a novel perspective on the trade-off between unlearning and retaining, considering layer importance and gradient alignment.
- The innovative approach simplifies the unlearning process by isolating changes to a single layer, reducing computational overhead and preserving model performance.

Weaknesses:
- The figures outlining results are not explained clearly enough, making interpretation difficult.
- The paper lacks quantitative results for all unlearned identities, relying on 'Elon Musk' as a single example, which is less convincing.
- There is no ablation study comparing the one-time gradient computation against typical SGD methods, which is necessary for validation.
- The focus on layer-level importance without empirical clarification on why finer-grained parameter levels are not considered limits the analysis.
- The experiments are confined to a single architecture (ViTs), raising questions about the method's effectiveness on other architectures like CNNs.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the figures and provide detailed explanations of the results, particularly for Fig. 2. Additionally, including quantitative results for all unlearned identities would strengthen the paper's argument. An ablation study comparing the one-time gradient computation with traditional methods should be included to justify the approach. The authors should also clarify the rationale for focusing on layer-level importance and consider exploring the Pareto optimal when unlearning multiple conflicting concepts. Finally, expanding the evaluation to include various architectures, such as CNNs, would enhance the robustness and applicability of the SLUG method.