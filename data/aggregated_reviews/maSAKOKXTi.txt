ID: maSAKOKXTi
Title: Generative Evolutionary Strategy For Black-Box Optimization
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 3, 7, 4, 4, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 2, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Generative Evolution Optimization (GEO) algorithm aimed at black-box optimization in high-dimensional spaces. The authors propose GEO as a combination of Evolution Strategy (ES) and Generative Surrogate Networks (GSN), claiming it addresses the limitations of existing methods like Bayesian optimization while maintaining linear time complexity. The paper discusses the methodology, outlines the goals of GEO, and provides experimental results demonstrating its effectiveness on benchmark functions.

### Strengths and Weaknesses
Strengths:  
- The paper introduces a novel approach that integrates ES and GSN, addressing significant challenges in optimizing high-dimensional, non-convex problems.  
- The technical design and explanation of GEO are clear and well-structured, making the paper easy to follow.  
- The experimental evaluation shows GEO's potential in optimizing various target functions while maintaining O(N) complexity.  

Weaknesses:  
- Some claims, such as the O(N) complexity, lack adequate justification, and the paper does not sufficiently cite related works.  
- The experimental evaluation is limited to a few benchmark functions, which undermines the robustness of the findings.  
- The paper does not provide empirical evidence or case studies to support the claimed applications of GEO in other areas of machine learning.  
- Limitations of the GEO method are not clearly outlined, and the tendency of GEO to collapse towards one side during optimization is not adequately analyzed.  

### Suggestions for Improvement
We recommend that the authors improve the clarity of the theoretical foundations and provide more rigorous derivations to support the validity of GEO. Additionally, the authors should include a broader range of benchmark functions in the experimental evaluation to enhance confidence in the results. We suggest providing empirical evidence or case studies to substantiate the claims regarding GEO's applications in other machine learning domains. Furthermore, a detailed discussion of the limitations of GEO and an analysis of the collapse tendency during optimization would strengthen the paper's contributions. Lastly, we encourage the authors to clarify the parameter settings and experimental conditions to improve reproducibility.