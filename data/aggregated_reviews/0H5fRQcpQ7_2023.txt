ID: 0H5fRQcpQ7
Title: RoboHive: A Unified Framework for Robot Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 18
Original Ratings: 6, 7, 8, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents RoboHive, a unified robot learning framework that integrates existing reinforcement learning (RL) environments and introduces new features, such as a unified robot class for sim2real applications, enhanced physics fidelity, and benchmark metrics. The authors propose a multi-task environment suite with diverse single-step and multi-step tasks, multiple scene options, and enhanced modalities including state, proprioception, and exteroceptive observations. RoboHive also introduces RoboSet, a large open-source robotics dataset designed to facilitate pre-training and offline learning research. The framework supports seamless transitions between simulated and real robots, establishing a new standard for robot learning benchmarks and enhancing usability for researchers.

### Strengths and Weaknesses
Strengths:
- RoboHive integrates various robot learning tasks under a unified architecture, facilitating reproducibility for researchers.
- It offers a diverse collection of environments and tasks, enhancing algorithmic research in reinforcement learning and imitation learning.
- The platform provides high physics fidelity and visual richness, improving realism in robotic tasks.
- Comprehensive documentation and ease of installation through a simple `pip install robohive` command lower barriers for new users.
- The framework includes a teleoperation interface for collecting demonstrations, which is absent in some original environments.

Weaknesses:
- The paper reads more like a promotional message than a scientific document, lacking technical implementation details.
- There is insufficient novelty, as the framework primarily reimplements existing environments without introducing new tasks or methods for evaluating learning quality.
- The framework lacks a curriculum of tasks with increasing complexity, limiting scalability and novelty compared to existing tools.
- Many tasks are either solvable with high success rates or deemed non-solvable, raising concerns about the diversity and interrelation of tasks across different suites.
- The paper does not adequately address the extendability to more complex tasks, particularly in the multi-task suite.

### Suggestions for Improvement
We recommend that the authors improve the paper by including:
1. A detailed description of the simulation engine and physical engine, including their limitations (e.g., graspability, contact points).
2. Comprehensive information on the reinforcement learning methods and specifics of the training process.
3. A brief explanation of how to customize environments and tasks effectively.
4. Additional performance metrics and comparisons with previous approaches, particularly regarding simulation speed and the integration of delays and dynamic errors in sim-to-real scenarios.
5. A structured progression of task complexity in the task curriculum to enhance the framework's novelty and usability.
6. Clearer results for multi-step tasks in the baselines section to address concerns regarding task interrelation and scalability.