ID: haHIji0yFt
Title: $SE(3)$  Equivariant Convolution and Transformer in Ray Space
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 6, 5, 5, 7, 5, -1, -1, -1, -1
Original Confidences: 1, 2, 3, 3, 1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents methods for SE(3) equivariant convolution and transformer layers that operate in ray space, aiming to enhance 3D reconstruction and neural rendering. The authors demonstrate that their approach can establish SE(3) reconstruction of signed distance functions and neural radiance fields, achieving robust results without transformation augmentation. The theoretical foundation is based on group theory, providing a new perspective on ray neighborhoods and equivariance constraints in neural rendering.

### Strengths and Weaknesses
Strengths:
- The paper establishes a solid theoretical framework for equivariance in ray space, which is a significant contribution to the field.
- The proposed SE(3)-equivariant convolution and transformer effectively handle geometric priors, improving robustness to coordinate frame transformations.
- Experimental results indicate that the method outperforms existing techniques in various tasks, demonstrating adaptability and effectiveness.

Weaknesses:
- The presentation lacks clarity and is not self-contained, requiring a major rewrite to enhance understanding.
- The methods section lacks an overview and jumps into dense exposition, making it difficult to follow.
- Qualitative results are limited, and comparisons are primarily made against IBRNet, neglecting other relevant methods like NeRF and Equivariant NeRF.
- Some mathematical explanations may be excessive and detract from the main narrative, complicating the reading experience.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by adding a comprehensive background section that covers key concepts such as ray space and relevant baseline methods. The methods section should begin with a clear overview of the neural components and equivariance constraints. Additionally, we suggest including more qualitative comparisons across various state-of-the-art methods and expanding the experimental evaluation to include other relevant baselines. Finally, consider streamlining mathematical explanations to enhance readability and focus on the core contributions of the paper.