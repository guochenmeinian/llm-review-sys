ID: APGXBNkt6h
Title: When Do Transformers Shine in RL? Decoupling Memory from Credit Assignment
Conference: NeurIPS
Year: 2023
Number of Reviews: 7
Original Ratings: 6, 7, 8, 7, -1, -1, -1
Original Confidences: 5, 4, 2, 3, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive investigation into the metrics for measuring memory dependency in partially observable environments. The authors propose two versions of a T-Maze environment to isolate memory effects and analyze the impact of memory architecture on tasks requiring long- and short-term memory. They find that transformer-based policies outperform recurrent policies in long-term memory tasks but show no advantage in short-term memory tasks. The authors also define memory length and credit assignment length, providing a framework for understanding their effects on reinforcement learning (RL) tasks.

### Strengths and Weaknesses
Strengths:
- The definitions of memory length and credit assignment length are intuitive and sound.
- Theoretical contributions are high quality, and the empirical experiments are well-designed, providing significant insights into decision transformer research.
- The paper is accessible, rigorous, and timely, addressing a unique and interesting question in the field.

Weaknesses:
- The scalability of the proposed metrics is unclear, particularly for complex environments, and the computation of optimal policies may require human demonstrations.
- The relevance of the proposed environments is questionable, as existing benchmarks like MiniGrid-Memory already provide similar characteristics.
- The interpretation of results could be improved, particularly regarding the performance of LSTMs and transformers in various tasks, and the clarity of certain definitions and figures needs enhancement.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their definitions, particularly regarding the observation space for the Active/Passive T-Mazes. Additionally, providing more context on the computation of optimal policies in complex environments would strengthen the paper. We suggest including a significance test for the results presented in Figure 4 and clarifying the meaning of "optimal policies that lack (long-term) credit assignment." Furthermore, addressing the potential solutions to the credit assignment problem when using transformers could add valuable insights. Lastly, we encourage the authors to make their code publicly available for reproducibility.