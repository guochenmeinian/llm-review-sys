ID: 00Sx577BT3
Title: The Well: a Large-Scale Collection of Diverse Physics Simulations for Machine Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 4
Original Ratings: 6, 7, 7, -1
Original Confidences: 3, 4, 4, -1

Aggregated Review:
### Key Points
This paper presents "the Well," a comprehensive dataset of numerical solutions to dynamical systems, totaling 15TB, aimed at benchmarking neural network methods. It includes 16 distinct datasets across various scientific domains, structured as uniformly sampled N-D arrays, facilitating easy integration into machine learning pipelines. The authors propose a PyTorch interface for training and evaluation, alongside initial baselines evaluated using the Variance Scaled Root Mean Squared Error (VRMSE) metric. The dataset's construction is supported by domain experts, ensuring high-quality ground truth data.

### Strengths and Weaknesses
Strengths:
* The dataset encompasses a wide range of time-varying dynamical systems, providing substantial data volume and diversity.
* The clear and comprehensive supplementary material details the data generation process and technical specifications.
* The manuscript is well-written, with a compelling application relevant to various scientific fields.

Weaknesses:
* The dataset lacks performance and runtime comparisons with traditional numerical solvers, which could provide valuable context.
* Some problems are generated in 2D, which may not accurately reflect real-world applications that require 3D representations.
* The evaluation metrics, particularly VRMSE, may not be suitable for all problems, especially those with chaotic dynamics.

### Suggestions for Improvement
We recommend that the authors improve the dataset by including performance benchmarks and runtime comparisons with traditional numerical solvers. Additionally, addressing the dimensionality of the generated problems, particularly for shear flows and Rayleigh-BÃ©nard problems, would enhance applicability. Clarifying the evaluation metrics used, especially the rationale for VRMSE, and providing explicit definitions for the surrogate model's tasks would strengthen the manuscript. Lastly, including a link to the benchmarking library and elaborating on design choices for standardized evaluation would improve usability for researchers.