ID: zAQK5r1enm
Title: Decision Stacks: Flexible Reinforcement Learning via Modular Generative Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 20
Original Ratings: 3, 4, 7, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for offline reinforcement learning (RL) using generative models, specifically introducing Decision Stacks (DS) to modularize the joint distribution of time-induced trajectories. The authors propose three independent generative models for observations, rewards, and actions, allowing for parallel learning and improved expressivity. Evaluations are conducted on D4RL benchmarks in both MDP and POMDP environments, demonstrating that DS outperforms previous methods by generating superior plans. However, concerns remain regarding the uniqueness of the proposed method, the justification of design choices, and the superficiality of evaluation tasks. The authors claim their framework guarantees expressivity and flexibility, yet lack rigorous proofs or empirical demonstrations to substantiate these claims. Additionally, the analysis of the model's flexibility is insufficient, as it does not explore the Cartesian product of various models comprehensively.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and clear, making it accessible to a broad audience.
- The modular approach allows for independent training of generative models, enhancing flexibility and expressivity.
- Extensive evaluations and visualizations support the claims of improved performance across various environments.
- The authors conducted a broader sensitivity analysis that demonstrates the method's consistent performance across varying POMDP settings.
- The modular design allows for flexibility in architecture parameterization and compositional transfer, which is a notable feature of the proposed method.

Weaknesses:
- The novelty of the proposed method is limited, with performance improvements potentially attributed to confounding factors like larger model sizes.
- The decision to ignore temporal causality in favor of different token types lacks sufficient motivation and theoretical justification.
- Empirical results, particularly in D4RL locomotion tasks, do not demonstrate significant improvements to justify the additional computational complexity.
- The paper does not adequately address the implications of the chosen decomposition order of observations, rewards, and actions.
- The uniqueness of the method is questioned, with insufficient rational justification for design choices leading to increased model complexity.
- The evaluation tasks are perceived as overly simplistic, lacking depth in analysis and rigorous support for claims made in the paper.
- There is a lack of in-depth discussion regarding the structural advantages of the diffusion model and transformer in handling different data modalities.

### Suggestions for Improvement
We recommend that the authors improve the theoretical analysis surrounding the modular expressivity claims, including experiments that demonstrate the ability to transfer to new environments. Additionally, we suggest conducting more controlled experiments to isolate the effects of model size on performance. A clearer explanation of the rationale behind the decomposition of trajectory components and the choice of generative models would enhance the paper's clarity. We also recommend that the authors improve the justification of their design choices, particularly addressing the increased complexity and the neglect of temporal and causal dependencies. Furthermore, enhancing the depth of their evaluation tasks to provide a more rigorous analysis of their method's performance would be beneficial. We encourage the authors to include theoretical proofs or empirical evidence to substantiate claims regarding expressivity and flexibility. Finally, a more thorough discussion of the structural advantages of the diffusion model and transformer in handling various data modalities would strengthen the paper.