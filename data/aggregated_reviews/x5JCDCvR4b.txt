ID: x5JCDCvR4b
Title: Stochastic Distributed Optimization under Average Second-order Similarity: Algorithms and Analysis
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 4, 5, 5, 8, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 1, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on finite-sum minimization in a distributed setting, focusing on communication efficiency among a central node and multiple client nodes. The authors propose two algorithms: SVRS, which achieves a communication cost of $\widetilde{O}(n + \sqrt{n} \delta/\mu)$, and AccSVRS, which improves upon previous results with a cost of $O((n + n^{3/4} \sqrt{\delta/\mu})\log|\epsilon|)$. The paper's assumptions include the convexity of functions and a notion of "second-order similarity" among them, allowing for reduced communication without requiring all Hessian information from clients. The authors also provide lower bounds to validate the optimality of their results.

### Strengths and Weaknesses
Strengths:  
- The paper effectively addresses an important problem in distributed optimization, presenting a coherent narrative and clear writing.  
- The proposed algorithms demonstrate significant improvements in communication complexity, with the theoretical results being well-supported.  
- The inclusion of lower bounds enhances the completeness of the analysis.

Weaknesses:  
- The scope of the assumption $\delta \geq \sqrt{n} \mu$ is unclear, and further elaboration is needed.  
- The removal of the logarithmic factor and the implications of component-wise strong convexity versus total strong convexity require more intuitive explanation.  
- The literature review lacks completeness, particularly regarding existing works on Hessian similarity and variance reduction techniques.  
- The paper's theoretical analysis relies heavily on strong convexity assumptions, limiting its applicability.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the assumption $\delta \geq \sqrt{n} \mu$ and provide examples where this holds. Additionally, we suggest including a more intuitive discussion on the significance of the logarithmic factor removal and the differences between component-wise and total strong convexity. The authors should also enhance the literature review by incorporating relevant works on Hessian similarity and variance reduction. Lastly, we advise providing real datasets in the experiments to complement the synthetic data and adjusting the parameter $\delta$ in the experiments to better illustrate the effect of similarity.