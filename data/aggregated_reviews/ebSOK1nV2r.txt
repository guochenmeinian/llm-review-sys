ID: ebSOK1nV2r
Title: Answering Questions by Meta-Reasoning over Multiple Chains of Thought
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a meta-reasoning framework, termed Multi Chain Reasoning (MCR), aimed at enhancing the reasoning capabilities of large language models (LLMs) for multi-hop question answering (QA) tasks. MCR prompts LLMs to conduct a second round of reasoning over multiple reasoning chains generated through chain-of-thought (CoT) prompting, allowing the selection of the most relevant evidence for reliable answer generation. The authors demonstrate MCR's effectiveness through experiments on seven multi-hop reasoning datasets, showing that it outperforms existing baselines, including self-consistency.

### Strengths and Weaknesses
Strengths:
- The motivation for a second round of reasoning to select relevant evidence is clear and well-articulated.
- The proposed method is novel, and the comprehensive experiments validate its effectiveness over strong baselines.
- The paper is well-written, with a clear presentation of contributions and a detailed analysis of performance improvements.

Weaknesses:
- The method may not be considered novel by some, as it resembles an engineering practice of prompting LLMs with a second round of CoT.
- Improvements over baseline methods are marginal, and the approach is computationally intensive, requiring two rounds of LLM processing.
- There are unanswered questions regarding the performance of the retriever and the sensitivity of MCR to various factors.

### Suggestions for Improvement
We recommend that the authors improve the novelty aspect of their work by clearly distinguishing MCR from existing methods and emphasizing its unique contributions. Additionally, providing statistics on the input sequence lengths for both MCR and baseline models would enhance clarity. It would also be beneficial to explore how the performance of MCR varies with different numbers of reasoning chains and to investigate the impact of temperature on final performance. Lastly, we encourage the authors to consider generalizing their findings to other domains beyond multi-hop reasoning.