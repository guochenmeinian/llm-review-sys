ID: g27BggUT3L
Title: LART: Neural Correspondence Learning with Latent Regularization Transformer for 3D Motion Transfer
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 5, 5, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents LART, a 3D Transformer framework for 3D motion transfer that distinguishes itself by not requiring joint annotation or pre-defined correspondence between source and target meshes. By preserving motion metrics and controlling synthetic motions in latent space, LART achieves accurate motion synthesis. The method is evaluated using the AMASS dataset, demonstrating high learning efficiency with only a few samples needed to generate visually plausible motions. 

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and presents information clearly.
2. A novel latent geometric regularization is proposed for synthesizing realistic dynamic results.
3. The method successfully extends its applicability beyond human motion transfer to animal motion transfer.
4. It achieves good performance in both quantitative and qualitative evaluations.

Weaknesses:
1. The authors should provide more detailed explanations of specific terms and blocks, particularly the SPAdaIN block, including its purpose and relevance in the decoder.
2. The design of the cross-attention mechanism in Fig 2 lacks clarity and requires more detailed implementation descriptions.
3. The "geometry adaptive 3D feature encoder" appears to involve geometry only in positional embedding; a geometry-aware design should be considered.
4. An ablation study on the three positional embedding methods in Fig 3 is missing; performance analysis is essential as supplementary Table 7 only reports loss without analysis.
5. While visualizations are included, a demo video would enhance the showcase of the visualizations' quality.

### Suggestions for Improvement
We recommend that the authors improve the explanation of the SPAdaIN block and its relevance in the decoder. Additionally, clearer descriptions of the cross-attention mechanism's implementation are necessary. The authors should consider incorporating a geometry-aware design in the encoder beyond positional embedding. An ablation study analyzing the three positional embedding methods is crucial for substantiating claims. Lastly, we suggest providing a demo video to better illustrate the quality of the visualizations.