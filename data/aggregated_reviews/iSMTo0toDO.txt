ID: iSMTo0toDO
Title: SubgDiff: A Subgraph Diffusion Model to Improve Molecular Representation Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 4, 5, 6, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents SubgDiff, a diffusion model designed to enhance molecular representation learning by integrating substructural information into the diffusion process. Key technical contributions include subgraph prediction, expectation state diffusion, and k-step same-subgraph diffusion, aimed at improving the understanding of molecular properties related to 3D conformation. The authors claim superior performance on various downstream tasks, particularly in molecular force predictions.

### Strengths and Weaknesses
Strengths:
- Incorporating substructural information into the diffusion model is a novel and intriguing exploration.
- The paper is well-organized, and the experiments demonstrate the effectiveness of SubgDiff across a range of molecular prediction tasks.

Weaknesses:
- The denoising process requires better explanations, particularly regarding the starting topology of \( R^T \) and how to sample \( s_t \).
- The application of SubgDiff to molecular property prediction/classification does not showcase its strengths, missing state-of-the-art results in Section 5.1, and lacking comparisons in Section 5.2.
- The authors directly use baseline results from the MoleculeSDE paper, which are significantly lower than those reported in the original work.
- The method is more akin to a graph diffusion model than a molecular representation learning model, which should be explicitly stated in the abstract or introduction.
- The paper lacks an ablation study to evaluate the contributions of each component of SubgDiff.
- The complexity of the model, including multiple diffusion stages, may complicate training and optimization, raising concerns about computational efficiency and overfitting.

### Suggestions for Improvement
We recommend that the authors improve the explanations of the denoising process and clarify the requirements for starting with a topology in \( R^T \). Additionally, the authors should provide a detailed comparison of their results with state-of-the-art methods in Section 5.1 and include explanations for COV-R and MAT-R in Section 5.2. It would be beneficial to conduct an ablation study to assess the impact of different components and hyperparameters, particularly the selection of \( k \) in the k-step same-subgraph diffusion. Furthermore, the authors should discuss the trade-offs between model complexity and performance more thoroughly, including the rationale for using 5000 diffusion steps and the implications for computational costs. Lastly, integrating more chemical intuition and domain knowledge into the design and motivation of the method would strengthen the paper.