ID: HjeKHxK2VH
Title: WaterMax: breaking the LLM watermark detectability-robustness-quality trade-off
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 7, 8, 6, 5, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a watermark technique called WaterMax, designed to differentiate between LLM-generated and human-written texts. WaterMax employs a watermark detector to select outputs based on the lowest p-value, introducing a novel perspective in text watermarking without a formal generator. The work discusses the balance between watermark detectability, quality, and robustness, supported by theoretical proof and experimental validation.

### Strengths and Weaknesses
Strengths:
1. WaterMax provides a groundbreaking research perspective in text watermarking, lacking an official watermark generator.
2. The method achieves high text quality with minimal distortion while maintaining detectability.
3. Enhanced robustness is attainable through detector upgrades.
4. The superiority of WaterMax is validated both theoretically and experimentally.

Weaknesses:
1. The experimental dataset is limited to high-entropy text generation, neglecting the need for watermarking in LLM-generated code.
2. The computational complexity is concerning, with WaterMax reportedly requiring five times the runtime of other methods for watermarked generation.
3. The method's reliance on generating multiple outputs for selection may compromise diversity and quality.

### Suggestions for Improvement
We recommend that the authors improve the dataset by including low-entropy tasks, such as code generation, to evaluate the detector's performance. Additionally, we suggest conducting experimental comparisons with SemStamp to contextualize WaterMax's strengths. To address computational concerns, we encourage the authors to provide clearer quantification of efficiency degradation and explore the use of larger models for evaluating text quality. Lastly, we advise the authors to clarify their stance on the use of LLMs for quality assessment and consider alternative evaluation methods if necessary.