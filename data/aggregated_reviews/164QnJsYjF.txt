ID: 164QnJsYjF
Title: Dense Associative Memory Through the Lens of Random Features
Conference: NeurIPS
Year: 2024
Number of Reviews: 18
Original Ratings: 7, 4, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an iterative random feature Dense Associative Memory Model (DenseAM), termed DrDAM, which serves as a kernel approximation of standard DenseAMs through random feature decomposition. The authors analyze the time complexity and approximation error of DrDAM, benchmarking against the standard DenseAM (MrDAM). They evaluate the approximation accuracy of DrDAM's energies and gradients, as well as its retrieval accuracy, emphasizing its iterative nature as a novel contribution to the field. Additionally, the paper interprets the energy function of Dense Associative Memory (DAM) using a kernel approximated by kernel-specific random feature maps, allowing for the condensation of stored patterns into a tensor with a size independent of the number of patterns. This facilitates the incorporation of new patterns without altering the parameter space's dimensionality, and the authors provide bounds for the approximation error in the gradient descent procedure utilizing their energy approximation.

### Strengths and Weaknesses
Strengths:
- **Originality**: The paper introduces DrDAM, expanding the understanding of DenseAMs and offering a novel approach beneficial to the ML and associative memory community.
- **Significance**: The work provides a concrete iterative algorithm, representing a significant advancement over prior studies.
- **Theoretical Contribution**: It includes an efficiency and approximation analysis of DrDAM.
- **Experimental Contribution**: The authors explore various aspects of DrDAM and provide reproducible code.
- The idea of employing kernel approximation to address the computational limitations of DAMs is commendable.
- The paper is well-written, and the concepts are clearly articulated.

Weaknesses:
- The paper appears rushed, affecting the overall contribution.
- **Experiments**: Current results lack comparisons with established baselines and ablation studies, and the numerical experiments are limited and not entirely convincing.
- **Clarity**: Some theoretical results are difficult to interpret due to typos and a need for improved mathematical clarity.
- **Motivation**: The motivation and problem statement require more convincing articulation.
- **Related Works**: The discussion on related works is limited and could be expanded to better position the contribution within existing literature.
- A significant limitation is the requirement for very large feature sizes (Y) to achieve a good approximation, which may restrict practical applications.

### Suggestions for Improvement
We recommend that the authors improve the experimental section by including comparisons with established baselines and conducting more ablation studies. Additionally, enhancing the clarity of theoretical results through proofreading and clearer definitions would be beneficial. The motivation and problem statement should be articulated more convincingly to clarify the advantages of distributed representation. We suggest expanding the related works section to include discussions on prior studies that connect DenseAMs with kernel methods, which would help contextualize the contribution within the existing literature. Furthermore, we recommend improving the numerical experiments to provide more convincing evidence of their claims, including a plot that shows the theoretical prediction from eq. 12 compared to the actual error. A plot illustrating the results as a function of K would enhance clarity. To aid reader comprehension, we suggest ensuring that the variable p in Algorithm 1 and at the beginning of Section 3 denotes the same concept. Lastly, the authors should discuss the limitations of their work more thoroughly, particularly the implications of requiring a large feature size Y for accuracy, and refine their terminology regarding efficiency while addressing the fixed-point convergence issues raised in the reviews.