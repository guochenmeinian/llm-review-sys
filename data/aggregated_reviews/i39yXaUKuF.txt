ID: i39yXaUKuF
Title: Segment Any Point Cloud Sequences by Distilling Vision Foundation Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 6, 7, 8, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Seal, a novel framework that utilizes 2D vision foundation models (VFMs) for self-supervised representation learning on large-scale 3D point clouds. Seal is designed to extract informative features from automotive point cloud sequences, emphasizing scalability, consistency, and generalizability. The authors demonstrate its effectiveness through extensive experiments across 11 datasets, showing superior performance compared to previous state-of-the-art methods in both linear probing and fine-tuning tasks.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and comprehensible, with clear motivation and methodology.
2. It represents the first attempt to leverage large-scale vision models for 3D point cloud segmentation, showcasing significant potential for 3D feature learning.
3. Extensive experiments validate the robustness of the proposed method across various segmentation datasets.

Weaknesses:
1. The approach does not strictly qualify as unsupervised pretraining due to reliance on additional data, which may misalign with the definitions of other methods.
2. The knowledge distillation from large 2D models appears limited, as the method primarily provides semantic supervision signals, suggesting that additional image-LiDAR pairs could enhance performance.
3. The novelty of the contributions may be perceived as limited, as the use of VFMs for segmentation is already a well-explored topic.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the distinction between unsupervised pretraining and their approach, ensuring alignment with the definitions of existing methods. Additionally, we suggest that the authors explore the use of more image-LiDAR pairs during pretraining, particularly on datasets like nuScenes, to potentially enhance the information gain and overall performance. Finally, we encourage the authors to conduct experiments on indoor point cloud datasets to broaden the applicability of their framework beyond automotive scenarios.