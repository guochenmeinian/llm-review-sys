ID: aDLmRMb0K9
Title: Spectral Entry-wise Matrix Estimation for Low-Rank Reinforcement Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 6, 6, 8, 6, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a thorough analysis of matrix estimation problems in low-rank bandit and reinforcement learning (RL) scenarios. The authors investigate spectral-based matrix estimation methods, demonstrating their effectiveness in accurately recovering singular subspaces with minimal entry-wise error. Building on these findings, the paper introduces a regret minimization algorithm for low-rank bandit problems and a best policy identification algorithm for reward-free RL in low-rank Markov Decision Processes (MDPs). Additionally, the authors address the independence of entries in the matrix \(E_{i,j}\) and the independence of \(\xi_t\) across various \(t\)s, proposing that their entry-wise bounds are stronger than existing works due to their entry-wise nature.

### Strengths and Weaknesses
Strengths:  
1. The paper addresses the complex task of deriving entry-wise error for low-rank matrix estimation, particularly in correlated noise scenarios, extending existing results to bandit and RL settings. The employed techniques, including leave-one-out arguments and Poisson approximation, showcase technical expertise.  
2. The overall significance of the work and results is compelling, with the entry-wise bounds proposed being stronger and scaling similarly to existing works, enhancing the paper's value.  
3. Despite its theoretical nature, the writing is clear and accessible, enhancing comprehension.

Weaknesses:  
1. The necessity of deriving entry-wise error in low-rank matrix estimation for bandit and RL settings is not adequately justified. The primary goal in low-rank bandit problems is to identify the best entry quickly, emphasizing the selection of the arm with the highest reward rather than minimizing entry-wise error for the entire matrix.  
2. The focus in low-rank bandit and MDP scenarios should be on minimizing regret. Existing approaches have achieved minimax regret bounds, yet the paper primarily discusses sub-optimal methods, relegating superior results to supplementary materials.  
3. The absence of numerical experiments to evaluate the proposed regret minimization algorithm against benchmark methods is a significant drawback. Comparisons of regret upper bounds alone do not provide a comprehensive understanding of algorithm performance.  
4. The concept of "entry-wise" is not completely standard and requires further clarification. The independence issue, while addressed, may not feel significant enough to some reviewers.

### Suggestions for Improvement
We recommend that the authors improve the justification for deriving entry-wise error in low-rank matrix estimation within bandit and RL contexts, providing detailed explanations and extensive numerical experiments. Additionally, it is crucial to compare the paper's results with state-of-the-art approaches in the discussion of related work, ensuring a fair and objective analysis. Furthermore, incorporating numerical experiments to evaluate the proposed algorithms against benchmarks would enhance the paper's credibility and provide a clearer understanding of their practical performance. We also suggest that the authors clarify the independence of entries in \(E_{i,j}\) and provide a more standard definition of "entry-wise" to enhance understanding and comparison with other works.