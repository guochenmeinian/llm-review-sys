ID: BRpi8YAfac
Title: Passive learning of active causal strategies in agents and language models
Conference: NeurIPS
Year: 2023
Number of Reviews: 7
Original Ratings: 7, 8, 7, 7, -1, -1, -1
Original Confidences: 3, 5, 4, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive analysis of whether agents trained on passive data can learn active causal strategies during evaluation. The authors demonstrate that agents can infer causal structures from passive data, enabling them to intervene appropriately during testing, even without prior exposure to such interventions. A formal "existence proof" for active causal learning is provided, supported by experiments in a causal Directed Acyclic Graph (DAG) environment, a pixel-based shapes environment, and few-shot prompting of a language model. The findings suggest that agents can generalize causal strategies from passive data, particularly when explanations accompany the training data.

### Strengths and Weaknesses
Strengths:
- The paper challenges existing assumptions in the causality literature, showing that generalizable strategies for causal experimentation can be learned from passive data generated by expert actions.
- The experiments are technically sound and well-executed, providing clear empirical evidence for the claims made.
- The writing is clear, with well-structured arguments and effective diagrams that enhance understanding.

Weaknesses:
- The initial claim regarding the generalizability of strategies may be overstated, as it relies on the assumption of a finite DAG representation, which may not reflect real-world complexities.
- The paper is predominantly empirical and lacks a robust theoretical framework to support the hypothesis, particularly regarding the nature of exploration strategies versus exploitation strategies.
- The role of explanations in learning is not clearly defined, and examples are insufficiently detailed in the main text.

### Suggestions for Improvement
We recommend that the authors improve the theoretical grounding of their claims by providing a more satisfactory explanation of why generalizable exploration strategies can be learned from observational data. Additionally, conducting ablation experiments to dissect the importance of the exploration phase would strengthen the argument for its necessity. The authors should also clarify the term "explanations" and provide explicit examples in the main paper, discussing the effects of different explanation mediums on performance. Finally, we suggest including heuristic baselines in the odd-one-out and LLM experiments to validate the robustness of the learned strategies and to address potential concerns regarding the generalizability of the findings.