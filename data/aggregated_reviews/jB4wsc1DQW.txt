ID: jB4wsc1DQW
Title: Hierarchical Adaptive Value Estimation for Multi-modal Visual Reinforcement Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 3, 7, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Hierarchical Adaptive Value Estimation (HAVE) framework for multi-modal visual reinforcement learning, focusing on fusing modalities in value function estimation. The authors propose a local modality-customized value estimation (LVE) paradigm that dynamically adjusts the importance of each modality, combined with a task-contextual re-fusion process for better global value estimation. The algorithm is evaluated on the CARLA simulator, demonstrating improved performance in autonomous driving tasks.

### Strengths and Weaknesses
Strengths:
1. The writing is clear and well-structured, making the paper easy to follow.
2. The proposed algorithm features a novel decomposition of the global value function into a weighted combination of modality-specific value functions, addressing issues of modality dominance.
3. The experimental results show promising improvements in multi-modal vision-based RL tasks under various conditions.

Weaknesses:
1. The decomposition of the Q-network lacks novelty, as the approach resembles existing methods in multi-agent RL without sufficiently highlighting differences in information processing for vision-based tasks.
2. The experimental setup is limited to the CARLA environment, raising concerns about the generalizability of the results to other multi-modal RL scenarios.
3. The paper lacks rigorous theoretical analysis and ablation studies, particularly regarding the necessity of the dynamic fusion mechanism and the impact of the auxiliary loss term.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their approach by clearly articulating the distinctions between their method and existing multi-agent RL techniques. Additionally, conducting experiments across a broader range of environments and modalities, including text and voice, would enhance the generalizability of their findings. We also suggest incorporating more in-depth theoretical analyses, such as convergence properties and the optimization of lower bounds, to strengthen the paper's contributions. Finally, performing ablation studies on the design of the re-fusion mechanism and the auxiliary loss term would provide valuable insights into the effectiveness of their proposed framework.