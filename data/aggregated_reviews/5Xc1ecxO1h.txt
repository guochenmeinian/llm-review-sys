ID: 5Xc1ecxO1h
Title: Tree of Thoughts: Deliberate Problem Solving with Large Language Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 6, 8, 5, 8, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Tree of Thoughts (ToT), a novel framework for enhancing problem-solving in large language models (LLMs) by utilizing a tree-like structure for reasoning. The authors demonstrate ToT's effectiveness through extensive experiments on three diverse tasks: the Game of 24, creative writing, and crossword puzzles. The framework addresses challenges associated with traditional left-to-right decoding by allowing for exploration, backtracking, and simultaneous consideration of multiple reasoning paths. The results indicate that ToT significantly outperforms various baseline methods, including Chain of Thought (CoT) and In-context Learning (ICL).

### Strengths and Weaknesses
Strengths:
- The ToT approach is well-motivated, effectively addressing limitations of autoregressive decoding.
- The four-step formulation is novel and clearly articulated.
- Extensive experiments convincingly demonstrate ToT's superiority over existing methods.

Weaknesses:
- The paper lacks evaluation of critical properties such as cost efficiency and execution time compared to baselines.
- Additional comparisons are needed to assess whether running simpler methods multiple times could be cheaper or faster than ToT.
- The application scope is limited, with a need for broader task evaluation to establish generalizability.

### Suggestions for Improvement
We recommend that the authors improve the evaluation of ToT by including data on its cost and execution time compared to baselines, ideally through graphical representations or tables. Additionally, providing estimates on how many times a baseline would need to run to find a solution compared to ToT would enhance understanding of its efficiency. We suggest exploring the potential for adapting ToT to a wider range of tasks and considering comparisons with methods like least-to-most prompting or decomposed prompting. Lastly, we encourage the authors to clarify the applicability of ToT to more general NLP reasoning datasets and to document all experimental details in an appendix to facilitate reproducibility.