ID: HsvZUde6wT
Title: Asking Clarification Questions to Handle Ambiguity in Open-Domain QA
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an innovative approach to handling ambiguous questions (AQ) in open-domain QA by introducing the CAmbigNQ dataset, which includes clarification questions (CQs) for 5,653 AQs. The authors propose a method that generates CQs before producing answers, contrasting with traditional disambiguated question (DQ) generation. The study establishes benchmark performance on three tasks: ambiguity detection, clarification generation, and clarification-based question answering, highlighting the challenges in these areas.

### Strengths and Weaknesses
Strengths:
- The authors introduce a novel method that aligns more closely with real-world applications by prioritizing clarification questions.
- The creation of the CAmbigNQ dataset is a valuable contribution to the research community.
- The paper is well-written and effectively communicates its concepts.

Weaknesses:
- The motivation for generating CQs is questionable, as 33% of participants preferred not to generate them, raising concerns about their necessity.
- There is insufficient comparison with state-of-the-art (SoTA) methods, which is essential for evaluating the proposed approach's effectiveness.
- Methodological questions remain, particularly regarding evaluation metrics and the necessity of CQ generation for end-to-end performance.

### Suggestions for Improvement
We recommend that the authors improve the experimental design by ensuring consistent model usage across comparisons, as differences in model capacity may skew results. Additionally, conducting experiments with ground truth CQs would clarify the performance issues observed. We suggest including comparisons with SoTA models to strengthen claims about the challenges posed by the tasks. Furthermore, we encourage the authors to explore alternative templates for generating CQs to enhance naturalness and fluency. Addressing the questions regarding the methodology and the observed discrepancies in performance metrics will also bolster the paper's robustness.