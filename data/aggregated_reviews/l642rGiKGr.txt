ID: l642rGiKGr
Title: Adversarial Robustness Unhardening via Backdoor Attacks in Federated Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 2
Original Ratings: 6, 6
Original Confidences: 3, 4

Aggregated Review:
### Key Points
This paper presents a novel attack that combines backdoor and adversarial attacks, specifically targeting federated learning (FL) systems. The authors propose an "Adversarial Robustness Unhardening" (ARU) attack, which aims to undermine the robustness of models trained with federated adversarial training by coordinating train-time and test-time attacks. The method involves injecting a backdoor into the target model during FL through model replacement with an extracted non-robust model, which subsequently disrupts the adversarial training of the global model. Experiments validate the effectiveness of the proposed methods.

### Strengths and Weaknesses
Strengths:
- The novel idea of coordinating train-time and test-time attacks is compelling.
- The evaluation of ARU's impact on model robustness is thorough.
- The concept of extracting a non-robust model during training is interesting.

Weaknesses:
- It remains unclear whether the attack is classified as a backdoor or adversarial attack.
- The minimum number of malicious clients required to compromise the global model is not specified.
- More advanced and robust aggregation rules should be tested beyond trimmed mean and median.
- FL is still centralized learning due to the presence of a central parameter server.
- The distinction between ARU and ARU-Extract (ARU-E) needs clarification.
- Alternative backdoor attacks that could be utilized for ARU, aside from model replacement, should be explored, as model replacement may be easily detected by the server.

### Suggestions for Improvement
We recommend that the authors clarify whether the attack is a backdoor or adversarial attack. Additionally, the authors should specify the minimum number of malicious clients needed to break the global model. We suggest testing more advanced aggregation rules beyond trimmed mean and median. Furthermore, the authors should address the centralized nature of FL and provide a clear distinction between ARU and ARU-E. Lastly, we encourage the authors to explore other backdoor attack methods that could be employed for ARU to avoid detection by the server.