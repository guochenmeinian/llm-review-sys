ID: ghF1EB6APx
Title: Cross-Modal Conceptualization in Bottleneck Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method called Cross-Modal Conceptualization in Bottleneck Models (XCBs) to enhance traditional Concept Bottleneck Models (CBMs). By utilizing text descriptions accompanying images, XCBs automate the concept induction process, avoiding manual annotation. The authors propose a mechanism to synchronize concepts between visual and textual data, demonstrating improvements in interpretability, disentanglement of concepts, and model robustness compared to conventional CBMs.

### Strengths and Weaknesses
Strengths:  
- The novelty of matching two modalities' latent representations for CBMs enhances model explainability.  
- Comprehensive evaluation and clear presentation of motivation, proposed ideas, and analysis.  
- The approach reduces dependence on image shortcuts, improving model robustness and reliability.  

Weaknesses:  
- The method's efficacy relies heavily on the quality of textual descriptions; poor quality text may degrade performance.  
- There are concerns about potential performance degradation when concepts from both modalities are learned, especially if one modality is of low quality.  
- The model's handling of redundant information in textual data, particularly in medical datasets, is unclear.

### Suggestions for Improvement
We recommend that the authors improve the discussion on how the model addresses ambiguities or inconsistencies in the text. Additionally, the authors should clarify the computational demands of implementing the proposed method. It would be beneficial to elaborate on how the model ensures quality representations when one modality is inferior and how it effectively manages redundancy in textual data, especially in medical contexts.