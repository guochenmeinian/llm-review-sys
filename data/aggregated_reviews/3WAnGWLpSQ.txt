ID: 3WAnGWLpSQ
Title: Why Does Sharpness-Aware Minimization Generalize Better Than SGD?
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 7, 8, 6, 5, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a theoretical examination of Sharpness-Aware Minimization (SAM) in feature learning, addressing the challenge of overfitting in large neural networks. The authors identify that traditional methods like Gradient Descent (GD) and Stochastic Gradient Descent (SGD) struggle with unstable training and overfitting, while SAM shows improved generalization, particularly in the presence of label noise. The core contribution is a theoretical framework explaining why SAM outperforms SGD, especially in two-layer convolutional ReLU networks, and demonstrating conditions for benign overfitting. The findings are supported by experiments on synthetic and real data.

### Strengths and Weaknesses
Strengths:
- **Addressing a Significant Issue**: The authors tackle the critical problem of overfitting in large neural networks, making their work timely and relevant.
- **Theoretical Contributions**: The paper provides a robust theoretical analysis of SAM's advantages over SGD, enhancing understanding of neural network generalization.
- **Comprehensive Study**: An in-depth comparison of SAM and SGD using diverse data strengthens the validity of the findings.
- **Novelty**: The claim of being the first to demonstrate benign overfitting with mini-batch SGD could signify a notable contribution.
- **Clarity and Organization**: The paper is well-structured, with a clear overview of the literature and detailed contributions.

Weaknesses:
- **Limited Scope**: The focus on two-layer convolutional ReLU networks may restrict the generalizability of findings to other architectures.
- **Presentation Could Be Enhanced**: The paper requires polishing; for example, the y-axis in Figure 2 lacks clarity, and terminology inconsistencies exist.
- **Partial Theoretical Results**: The absence of a corresponding harmful overfitting regime for SAM in the theoretical results makes the comparison incomplete.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the y-axis in Figure 2 and standardize the use of terms like 'P-1' and 'P' throughout the paper. Additionally, we suggest providing a more extensive evaluation of potential limitations and discussing the implications of the learning rate on model performance. It would also be beneficial to explore the behavior of SAM in relation to large learning rates and to clarify the connection between SAM and the sparse coding problem. Lastly, we encourage the authors to enhance the related work section by discussing other techniques affecting generalization, such as label noise and large learning rates.