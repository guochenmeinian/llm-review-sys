ID: GpS0FkYOGv
Title: NPCS: Native Provenance Computation for SPARQL
Conference: ACM
Year: 2023
Number of Reviews: 6
Original Ratings: -1, -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents NPCS, a novel query rewriting method for computing how-provenance annotations for SPARQL query results. NPCS operates directly on existing SPARQL engines and utilizes spm-provenance semirings to support both monotonic and non-monotonic queries. The authors claim that NPCS is the first 100% SPARQL-based solution for how-provenance, which can significantly improve runtime performance compared to existing solutions like SPARQLProv. The evaluation demonstrates that NPCS outperforms SPARQLProv by a factor of 25 across various datasets.

### Strengths and Weaknesses
Strengths:
- The paper addresses an important problem and is well-motivated and written.
- NPCS is the first native approach for how-provenance, applicable to existing SPARQL engines.
- The evaluation on large datasets is insightful, showing significant performance improvements.
- The source code and experimental setup are publicly available, enhancing reproducibility.

Weaknesses:
- The scientific contribution compared to SPARQLProv remains unclear, particularly regarding the elimination of the post-processing phase.
- The experimental evaluation lacks comparisons with other systems like TripleProv, which raises questions about the robustness of the findings.
- Some rewritings and formal definitions are unclear, and the paper would benefit from additional examples and clarifications.
- Minor editorial errors and inconsistencies in terminology detract from clarity.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the scientific contribution by providing detailed explanations on how NPCS eliminates the post-processing phase present in SPARQLProv. Additionally, we suggest including comparisons with TripleProv in the experimental evaluation to strengthen the findings. The authors should also clarify the rewriting rules and provide concrete examples of the rewritten queries in the GitHub repository to enhance understanding. Furthermore, addressing minor editorial errors and ensuring consistent terminology will improve the paper's readability.