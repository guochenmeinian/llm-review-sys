ID: nIuJXuSdhn
Title: Can LLMs Facilitate Interpretation of Pre-trained Language Models?
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an exploration of how large language models (LLMs), particularly ChatGPT, can be utilized to annotate latent concepts within pre-trained language models (pLMs). The authors focus on latent concept learning by clustering embeddings from pLMs and generating concept labels through ChatGPT, which are then validated for precision. The main contributions include scaling up concept labels for comparative analysis across various pLMs and enhancing the understanding of neuron activation in relation to linguistic phenomena. The paper also introduces a resource, Transformers Concept-Net, containing 39K annotated concepts, which is expected to aid future interpretability research.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant challenge in NLP—interpreting pLMs—by leveraging LLMs for annotation, which is a novel approach.
- The methodology is sound, combining clustering with prompt engineering for annotations, and the experiments demonstrate the accuracy of ChatGPT annotations compared to human annotations.
- The release of a large dataset of annotated concepts will facilitate further research in this area.

Weaknesses:
- The main contribution and novelty are not clearly articulated, particularly regarding the advantages of using ChatGPT over human annotations.
- The neuron analysis is difficult to understand, and the methodology lacks detailed descriptions of the clustering process and parameters.
- The comparison of ChatGPT annotations with human-annotated concepts is based on a limited sample size, which may not capture the full complexity of latent concepts.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the neuron analysis to make it more accessible to readers unfamiliar with the topic. Additionally, we suggest providing more detailed descriptions of the clustering process, including the dataset, clustering algorithm parameters, and the specific prompts used for ChatGPT annotations. To strengthen the paper, consider expanding the discussion on the limitations of the analysis, particularly regarding the small sample size and the reliance on ChatGPT as the sole annotator.