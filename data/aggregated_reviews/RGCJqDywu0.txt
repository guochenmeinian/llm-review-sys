ID: RGCJqDywu0
Title: Distinctiveness Maximization in Datasets Assemblage
Conference: ACM
Year: 2024
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to dataset assemblage aimed at maximizing distinctiveness under budget constraints. The authors define distinctiveness maximization as the count of unique tuples across datasets and propose a greedy algorithm with machine learning (ML)-based distinctiveness estimation to efficiently approximate the solution. The method addresses the computational challenges of exact distinctiveness calculation, proving the problem to be NP-hard, and demonstrates significant improvements in efficiency and scalability through experiments on real-world datasets.

### Strengths and Weaknesses
Strengths:
- The paper introduces a novel problem formulation that extends traditional cardinality estimation to multi-dataset, multi-query settings.
- The proposed ML-based algorithm achieves significant runtime improvements while maintaining high accuracy.
- Comprehensive experiments validate the method's effectiveness and scalability across diverse scenarios.
- The approach integrates well into data preparation pipelines, addressing real-world constraints.

Weaknesses:
- The layout of the article is overly compressed, making it difficult to follow.
- The introduction lacks a compelling narrative and clearer articulation of practical use cases for distinctiveness maximization.
- Limited theoretical details on the ML-based estimation model and its training process hinder reproducibility.
- The method's reliance on user-provided queries may be too restrictive, and the paper does not adequately discuss the limitations of the approach.

### Suggestions for Improvement
We recommend that the authors improve the layout of the article to enhance readability. Additionally, we suggest providing a clearer articulation of practical use cases for distinctiveness maximization and expanding the introduction to include a more compelling narrative. The authors should elaborate on the theoretical underpinnings of the ML-based estimation model, including details on the training set and model architecture. Furthermore, we encourage the authors to consider integrating dynamic updates to the dataset pool and to expand the range of baselines to include heuristic and non-ML-based methods for a more comprehensive comparison. Lastly, the authors should validate the method's performance on text-centric datasets and explore the implications of query complexity on the proposed solution.