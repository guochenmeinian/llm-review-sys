ID: SWU8YLlFVH
Title: Neural Sampling in Hierarchical Exponential-family Energy-based Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 8, 3, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a hierarchical exponential family energy-based model (HEE) as a biologically plausible mechanism for neural inference and learning. The authors describe the model's learning and inference processes, emphasizing the use of fast interneurons for log-partition functions and an adaptation mechanism to enhance sampling efficiency. Extensive numerical results demonstrate the model's generation quality and its alignment with representations observed in biological visual systems. Additionally, the authors propose a method for generating observations by sampling pairs from the distribution \( p_\theta(\mathbf{x},\mathbf{z}) \), distinguishing between joint generation, which requires a search space of \( O(m*n) \), and marginal generation, which has a combined search space size of \( O(m+n) \). They provide a comparison of their method against IEBM, highlighting improvements in image generation quality and efficiency when using a CNN structure over a fully connected structure.

### Strengths and Weaknesses
Strengths:  
1. The paper effectively combines theoretical analysis with extensive numerical results, showcasing multiple desired properties of the model, including the acceleration effect of the adaptation mechanism.  
2. The authors highlight relevant aspects of their model for the neuroscience community, providing insights into the potential advantages of neural mechanisms in Bayesian inference.  
3. The paper offers a clear distinction between joint and marginal generation methods, providing valuable insights into the search space complexities.  
4. The empirical results demonstrate that the CNN structure outperforms the fully connected structure in both quality and training efficiency.

Weaknesses:  
1. While well-written, the paper's comparison with neuroscience is limited to established experimental findings; a discussion on potential experimental predictions of the model would enhance its relevance.  
2. The clarity of the exposition is lacking, particularly regarding the rationale behind modeling choices and experimental results, which could confuse readers.  
3. The lack of a comprehensive and controlled comparison with IEBM limits the ability to fully assess the proposed method's effectiveness.  
4. The experimental details provided are insufficient for a thorough evaluation of the results.

### Suggestions for Improvement
We recommend that the authors improve the discussion by highlighting several possible experimental predictions of their model to strengthen its connection to neuroscience. Additionally, clarifying the rationale behind modeling choices, such as the use of Langevin dynamics and the identification of latent variables with neural physiology, would enhance comprehension. The authors should also provide more detailed descriptions of the experimental methods and results, including specific comparisons with other energy-based models to validate their claims. Furthermore, we recommend including a proper (and well-controlled) comparison between the proposed method and IEBM, along with a more comprehensive report on the results, particularly regarding the CNN structure's performance, in the revised version. Finally, addressing clarity issues in the presentation, particularly in sections discussing previous work and the biological implications of their model, would significantly improve the paper's accessibility.