ID: G99BSV9pt5
Title: Relational Concept Bottleneck Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 7, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Relational Concept Bottleneck Models (R-CBMs), which merge Concept Bottleneck Models (CBMs) and Graph Neural Networks (GNNs) to enhance interpretability in relational domains. R-CBMs achieve competitive performance compared to black-box models, support logic-based explanations, and respond effectively to test-time interventions. The authors evaluate R-CBMs across various experimental settings, demonstrating their robustness in challenging scenarios, including out-of-distribution testing and limited data availability.

### Strengths and Weaknesses
Strengths:
1. The integration of GNNs with CBMs is a novel approach that enables the learning of relational data.
2. Experimental results show strong and consistent improvements, particularly in generalization and efficiency.
3. The writing is clear, making the paper an enjoyable read, with well-articulated motivations and examples.

Weaknesses:
1. The related work section is insufficient and should include interpretable methods and additional baselines for comparison, particularly against post-hoc models and original CBMs.
2. The definition of concepts in datasets is not clearly articulated, raising questions about scalability and the handling of larger datasets.
3. The interpretability claims may be undermined by the GNN-like components, which are typically considered black-box models.
4. The choice of datasets, particularly WN18RR over FB15k-237, is questionable, and the paper lacks comparisons with simpler yet effective baselines.

### Suggestions for Improvement
We recommend that the authors improve the related work section by including relevant interpretable methods and additional baselines, such as those from the post-hoc literature. It would be beneficial to clearly define the concepts for each dataset and address how these definitions scale with larger datasets. We suggest conducting experiments to evaluate the model's performance on FB15k-237 and including comparisons with simpler baselines like ComplEx-N3. Additionally, the authors should clarify the learning process of symbolic rules and the implications of GNN components on interpretability.