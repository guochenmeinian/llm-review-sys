ID: 6cWDg9t3z5
Title: Universal Rates of Empirical Risk Minimization
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 9, 5, 6, 7, 7, -1, -1, -1, -1, -1
Original Confidences: 4, 1, 3, 2, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an exploration of universal learning rates for Empirical Risk Minimization (ERM) in the context of realizable binary classification. The authors build on previous work, demonstrating that the universal rate of convergence for ERM can be categorized into four distinct cases: $\exp(-n)$, $1/n$, $\log(n)/n$, or arbitrarily slow, depending on the properties of the hypothesis class. The work includes a comprehensive analysis of these rates, supported by examples, and introduces new combinatorial complexity measures relevant to the hypothesis class.

### Strengths and Weaknesses
Strengths:  
The paper makes valuable contributions to statistical learning theory, particularly in understanding ERM, which is widely used in practice. The exposition is clear, with helpful examples that ground the theoretical results. The characterization of all possible universal learning rates by ERM is a significant achievement.

Weaknesses:  
A primary limitation is the restrictive assumption of realizability and the exclusive focus on binary classification. Additionally, the writing occasionally closely mirrors previous work, which may detract from originality. There is also a minor gap in the combinatorial characterization of the expected rates $1/n$ versus $\log(n)/n$, though this is discussed in Remark 3.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the limitations of the work, particularly regarding the characterization of when a class is universally learnable by ERM, as this would enhance the paper's depth. Additionally, clarifying the definition of "worst-case" ERM and elaborating on the computational advantages of ERM compared to the algorithms used by Bousquet et al. (2021) would be beneficial. Finally, we suggest providing more intuitive framing for the examples in Section 1.1 to enhance reader comprehension.