ID: GLA4ablO3M
Title: FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents FACTSCORE, a novel scoring mechanism for evaluating the factuality of long-form text generated by large language models (LLMs). FACTSCORE assesses the percentage of atomic facts in generated text supported by a predefined knowledge source, enabling fine-grained evaluation. The authors also propose an automatic estimation method for FACTSCORE, addressing the challenges of manual annotation. The analysis of 12 LLMs reveals correlations between factual accuracy and model size, training data, and instruction tuning.

### Strengths and Weaknesses
Strengths:
- FACTSCORE offers a new approach to evaluating factuality, improving upon existing sentence-level methods.
- The paper is well-organized, with clear explanations throughout.
- The experimental evaluation is rigorous, providing interesting insights into the performance of various LLMs.
- Plans for open-source release are a significant positive aspect.

Weaknesses:
- The application of findings in Section 4 lacks clarity regarding their implications for understanding model factuality.
- The limited scope of analysis, focusing solely on biographies and Wikipedia, raises questions about the generalizability of results.
- The simplicity of the FACTSCORE metric may oversimplify complex discussions about what constitutes a fact and its support by knowledge bases.

### Suggestions for Improvement
We recommend that the authors improve the clarity of how findings in Section 4 contribute to a deeper understanding of model factuality. Additionally, addressing the generalizability of results beyond biographies and Wikipedia is essential. We suggest that the authors evaluate the validity of FACTSCORE by considering cases where correct facts are not included in knowledge sources. Furthermore, exploring the impact of providing the Wikipedia page in the prompt for biography generation could yield valuable insights. Lastly, we encourage the authors to explicitly acknowledge the limitations of the small-scale experiments conducted during the rebuttal in the Limitations section of the revised submission.