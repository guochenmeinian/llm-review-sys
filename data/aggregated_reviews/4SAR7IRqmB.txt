ID: 4SAR7IRqmB
Title: On the Complexity of Teaching a Family of Linear Behavior Cloning Learners
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 4, 6, 7, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 2, 2, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper "Optimal Teaching of Linear Behavior Cloning Learners" introduces the TIE (Teach using Iterative Elimination) algorithm, which efficiently constructs an optimal teaching set for a family of consistent linear behavior cloning (BC) learners. The algorithm aims to demonstrate actions that induce the target policy across all learners, transforming the problem into a finite set-cover problem, which is NP-hard for larger action spaces. The authors provide empirical validation across various environments, showing TIE's effectiveness in producing smaller teaching sets compared to baseline methods.

### Strengths and Weaknesses
Strengths:  
- **Algorithmic Innovation:** TIE systematically eliminates unnecessary states to induce the target policy, simplifying the optimal teaching problem.  
- **Theoretical Guarantees:** The paper establishes that TIE achieves near-optimal teaching dimensions, supported by proofs demonstrating its efficiency in covering the version space.  
- **Empirical Validation:** TIE consistently outperforms baseline methods like Teach-All and Teach-Random across diverse environments, showcasing its practical applicability.  

Weaknesses:  
- **Computational Complexity:** The efficiency of TIE may diminish with larger state and action spaces, as it relies on solving NP-hard set cover problems.  
- **Assumption of Known Features:** The algorithm presumes knowledge of effective feature representations, limiting applicability in cases with poorly defined features.  
- **Generalization to Non-linear Learners:** The focus on linear BC learners restricts the method's applicability to more complex models, necessitating significant adaptation for broader use.  
- **Insignificant Community Contribution:** The assumption of consistent learner properties imposes strict constraints, and the contributions in Sections 3.1 and 3.2 lack rigorous analysis and significant conclusions.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the computational complexity of TIE, particularly regarding its scalability with larger state and action spaces. Additionally, the authors should clarify the implications of the assumption of known feature representations and consider extending their approach to accommodate non-linear learners. We suggest including stronger empirical baselines and exploring popular approximation algorithms for set cover to provide a more comprehensive evaluation of TIE's performance. Lastly, we encourage the authors to elaborate on the significance of their contributions and address the limitations more thoroughly in the paper.