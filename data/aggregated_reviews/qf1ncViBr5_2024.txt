ID: qf1ncViBr5
Title: einspace: Searching for Neural Architectures from Fundamental Operations
Conference: NeurIPS
Year: 2024
Number of Reviews: 18
Original Ratings: 4, 6, 6, 4, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents "einspace," a novel neural architecture search (NAS) space based on a parameterized probabilistic context-free grammar (CFG). Einspace aims to overcome the limitations of traditional NAS methods by providing a highly expressive search space that can accommodate a diverse range of architectures, including convolutions and attention mechanisms. The authors demonstrate the efficacy of einspace through experiments on Unseen NAS datasets and NAS-Bench-360, showing that it can discover novel architectures that outperform existing models in certain cases. The authors are also integrating feedback received during the review process and are working towards evaluating a Bayesian Optimization (BO) search strategy on their search space.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and clearly motivated, making it easy to follow.
- It introduces a unique search space that supports a wide range of operations and architectures, including state-of-the-art models.
- The authors provide code to enhance reproducibility and facilitate future research.
- The work is recognized for its strong potential, and the authors are open to feedback and willing to improve the paper based on reviewer suggestions.

Weaknesses:
- The novelty of einspace is questioned, as it does not significantly differ from existing CFG-based search spaces, and the fundamental operations are common in prior work.
- The evaluation is limited, lacking comparisons to natural baselines and larger datasets, which raises concerns about the practical applicability of the method.
- The search strategies employed, such as random and evolutionary search, are noted to be sample inefficient, and the paper does not adequately address the computational costs involved.
- There may be unresolved concerns that need further clarification.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the contribution by explicitly distinguishing einspace from previous works, particularly in terms of its novelty and expressiveness. Additionally, the authors should conduct more comprehensive evaluations, including comparisons to natural baselines and on larger datasets like ImageNet, to substantiate the claims regarding the effectiveness of einspace. It would also be beneficial to explore more sample-efficient search strategies, such as Bayesian optimization, and to provide a detailed analysis of the computational costs associated with the search process. Finally, including parameter and FLOPs counts in the results would enhance the understanding of the architectures discovered. We also suggest that the authors thoroughly integrate all feedback from the review process and clearly address any remaining concerns.