ID: 3e8rcsIO7H
Title: Dense Retrieval as Indirect Supervision for Large-space Decision Making
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel solution called Dense Decision Retrieval (DDR) aimed at addressing challenges in large label spaces for discriminative natural language understanding (NLU) tasks. The authors propose a bi-encoder retrieval architecture that retrieves entries from a decision thesaurus instead of predicting fine-grained decisions as logits. Experimental results indicate that DDR outperforms baseline methods in multi-label classification, entity typing, and intent classification tasks.

### Strengths and Weaknesses
Strengths:
- The proposed task of large-space decision making is significant and may address real-world challenges.
- The DDR model shows consistent improvements over baseline methods across various tasks.
- The paper is well-written, and the experiments are comprehensive.

Weaknesses:
- The experimental tasks lack direct relevance to decision making, relying heavily on specific tasks rather than a general construction method for the thesaurus.
- The technical novelty and contribution of the method appear limited.
- There are issues with readability due to missing descriptions and typos.

### Suggestions for Improvement
We recommend that the authors improve the generalization of the proposed solution by providing further justification for its limitations outside the scope of Wikipedia or WordNet. Additionally, please clarify the relevance of the experimental tasks to "decision making." In section 3.2, we suggest elaborating on the reasons for not exploring the LLM approach for thesaurus construction. Furthermore, consider discussing whether a generation-based framework could be a more promising solution compared to a retrieval-based framework, given the capabilities of recent LLMs. Lastly, addressing the readability issues and providing a detailed discussion on thesaurus construction and its impact on performance would enhance the paper's quality.