ID: isTf3yTW4E
Title: Routing in Sparsely-gated Language Models responds to Context
Conference: EMNLP/2024/Workshop/BlackBoxNLP
Year: 2024
Number of Reviews: 3
Original Ratings: -1, -1, -1
Original Confidences: 2, 4, 2

Aggregated Review:
### Key Points
This paper presents an investigation into how context influences token assignment to experts in sparsely gated expert layers, specifically within a MoE model (Switch). The authors demonstrate that routing is context-sensitive, with words in similar contexts being assigned to the same experts more frequently than those in different contexts. The study reveals that context sensitivity varies by model components, being stronger in the encoder than the decoder and increasing with the number of experts.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, with clear illustrations and a comprehensive background.
- It effectively explores the mechanistic aspects of an important class of models, aligning well with the workshop theme.
- The experimental design is well-motivated, and the separate analyses of the encoder and decoder enhance interpretability.

Weaknesses:
- The findings are limited by a narrow selection of models and datasets; while deep investigations in simple settings are valuable, broader scope should not be excluded.
- The motivation for the research is somewhat implicit, and the practical implications for future research and interpretability are not clearly articulated.

### Suggestions for Improvement
We recommend that the authors improve the scope of their study by including a wider selection of models and datasets. Additionally, providing qualitative examples to contextualize numerical results, particularly interesting failure modes where context did not aid in routing, would enhance the paper's depth. Clarifying the motivation for the research and its implications for future work in the interpretability field would also strengthen the paper. Lastly, please correct the identified typos, including "conditional computation" in line 095 and "token choice" in line 152.