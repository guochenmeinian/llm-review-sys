ID: Dx88A9Zgnv
Title: NaturalBench: Evaluating Vision-Language Models on Natural Adversarial Samples
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 7, 9, 6, -1, -1, -1
Original Confidences: 4, 4, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents NaturalBench, a benchmark comprising images and captions that form “natural adversarial examples” to evaluate vision-language models (VLMs). The authors propose a semi-automatic framework to collect these samples, addressing significant issues in current benchmarks, such as blind model performance and data leakage. The dataset includes over 10,000 human-verified visual question answering (VQA) samples, demonstrating that existing VLMs struggle with these adversarial examples, performing only slightly better than random guessing.

### Strengths and Weaknesses
Strengths:
- The benchmark is well-motivated and utilizes real images instead of synthetic ones.
- A thorough annotation protocol ensures high inter-annotator agreement.
- The dataset is robust against blind solutions and highlights the performance gap between VLMs and human capabilities.
- The evaluation protocol effectively prevents blind solutions by requiring models to rely on visual inputs.

Weaknesses:
- The performance consistency between deterministic and stochastic methods is unclear, raising questions about model adherence to instructions.
- The paper lacks a URL for accessing the dataset, which hinders reproducibility.
- The comparison to human performance may be biased due to potential prior exposure to images or questions.
- The dynamic evaluation section does not clarify the quality of automatically generated datasets or whether humans were involved in filtering questions.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the performance discrepancies between deterministic and stochastic methods. Additionally, providing a URL for dataset access is crucial for reproducibility. To address potential biases in human performance evaluation, we suggest implementing measures to prevent prior exposure to images or questions. Lastly, we encourage the authors to elaborate on the quality of the dynamically generated dataset and the role of human verification in this process.