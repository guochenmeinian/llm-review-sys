ID: WCnJmb7cv1
Title: Learning to Assist Humans without Inferring Rewards
Conference: NeurIPS
Year: 2024
Number of Reviews: 21
Original Ratings: 4, 5, 5, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Empowerment via Successor Representations (ESR), a method designed to enhance human-agent collaboration by maximizing the human collaborator's ability to influence their environment. The authors argue that inferring a human's reward function can be challenging, motivating the development of an assistive agent that focuses on empowerment rather than direct support. The paper formulates empowerment and connects it to reward maximization, providing an implicit approach to estimate empowerment through learned representations. Additionally, the authors present a theoretical framework connecting mutual information maximization to minimizing regularized regret in human-AI collaboration. They propose that while Lemma 2 establishes a relationship between maximizing mutual information and regret minimization, it does not fully apply to the empowerment notion used in the paper. New experimental results demonstrate that ESR significantly outperforms a related prior work, AvE, and a random baseline across various tasks, as well as showing improved performance in the Overcooked environment against various baselines.

### Strengths and Weaknesses
Strengths:
- The formulation of empowerment is novel and promising, with the use of learned representations to estimate empowerment being a new approach.
- The paper provides a solid theoretical foundation for the relationship between mutual information and regret minimization.
- Experimental results demonstrate that ESR outperforms AvE by substantial margins in the tested domains, and new results show improved performance over existing baselines in the Overcooked environment.

Weaknesses:
- The claims in the paper require stronger grounding, particularly regarding the proof in Section 3.3, which lacks clarity on its assumptions and applicability.
- The connection between the theoretical results and the practical algorithm is not clearly articulated, leading to potential confusion.
- The evaluation is limited, as it only compares ESR against AvE and a random agent, neglecting comparisons with actual human users or other goal inference methods.
- Several typographical errors and vague claims detract from the overall clarity and academic rigor of the paper.

### Suggestions for Improvement
We recommend that the authors improve the grounding of their claims, particularly by clarifying the assumptions in the proof of Section 3.3 and addressing the applicability of their results in various scenarios. Additionally, the authors should improve the clarity of the connection between the theoretical results and the practical algorithm by explicitly acknowledging the differences in discounting functions, conditioning of mutual information, and the role of the successor representation. Emphasizing the crucial link between the restricted set of skills and the mutual information objective will enhance understanding. We also suggest conducting user studies to validate their findings with actual human collaborators and comparing ESR against more diverse baselines, including those that involve goal inference. Furthermore, providing more detailed explanations of the experimental results, including qualitative insights into how the agent increases empowerment, and addressing the clarity of notation and definitions throughout the paper would be beneficial. Lastly, ensuring that all typographical errors are corrected and subjective language is revised to maintain an academic tone would enhance the overall presentation.