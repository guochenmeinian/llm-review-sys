ID: MtRvzJBsBA
Title: LRM-Zero: Training Large Reconstruction Models with Synthesized Data
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 6, 5, 7, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Zeroverse, a synthetic dataset designed for training large feed-forward 3D reconstruction models. The authors propose LRM-Zero, trained using Zeroverse, which achieves performance comparable to GS-LRM trained on the Objaverse dataset. The use of entirely synthesized data is significant for the community, as it alleviates the challenges associated with collecting real-world 3D models. However, LRM-Zero's performance is often inferior to GS-LRM, particularly on the OmniObject3D dataset, and Zeroverse introduces stability issues during training. The paper also discusses the limitations of the related works section, emphasizing the need to cite prior methods in 3D reconstruction.

### Strengths and Weaknesses
Strengths:
- The paper is clearly written and presents a novel approach to using synthetic data for 3D reconstruction.
- Zeroverse allows both NeRF and 3DGS models to achieve results comparable to those trained on Objaverse.
- The ablation study effectively demonstrates the impact of different augmentations.

Weaknesses:
- LRM-Zero's performance is generally worse than GS-LRM, especially in PSNR on OmniObject3D.
- The stability of training with Zeroverse is questionable, requiring careful tuning of settings and hyperparameters.
- The related works section lacks adequate discussion of established methods in 3D reconstruction, particularly multi-view stereo techniques.

### Suggestions for Improvement
We recommend that the authors improve the related works section by including discussions on prior 3D reconstruction methods, particularly multi-view stereo techniques. Additionally, it would be beneficial to provide qualitative comparisons of reconstructed objects from models trained on real versus synthetic data to better illustrate performance differences. We also suggest exploring the effects of fine-tuning LRM-Zero on high-quality captured scenes to enhance performance and investigating the impact of using different texture datasets on training outcomes. Lastly, clarifying the reasons behind the performance dip with sparse input views would strengthen the paper's contributions.