ID: Z2L7F0nekb
Title: Meta-Learning with Neural Bandit Scheduler
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 6, 7, 7, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 5, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a task scheduling framework named BASS, which utilizes contextual bandits to optimize task selection in meta-learning. The authors propose a methodology that balances exploration and exploitation, addressing performance bottlenecks in meta-models. Theoretical analysis demonstrates the convergence of the regret bound, and empirical results indicate that BASS outperforms baseline methods, particularly in scenarios with task imbalance or noise.

### Strengths and Weaknesses
Strengths:
1. The application of contextual bandits for task scheduling in meta-learning is novel and well-motivated.
2. The paper is well-written, with clear definitions and a structured presentation that aids comprehension.
3. The authors provide a thorough theoretical analysis and conduct experiments across multiple datasets, demonstrating the effectiveness of BASS.

Weaknesses:
1. The computational efficiency of BASS is not adequately discussed; there is a lack of quantitative comparisons regarding computation costs.
2. The method's scalability remains unclear, particularly concerning the input of one neural network into another.
3. The experimental results show marginal improvements on standard datasets, raising questions about the method's generalizability.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the computational burden of BASS by including wall clock times or performance plots as a function of time. Additionally, clarifying how BASS scales with larger neural networks would strengthen the paper. We suggest incorporating a broader range of datasets in the experiments to validate the method's performance across various categories. Furthermore, detailing the initialization settings in Algorithm 1 and providing a clearer explanation of the regret bounds would enhance the theoretical foundation of the work.