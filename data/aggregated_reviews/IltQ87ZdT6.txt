ID: IltQ87ZdT6
Title: Improved Bayes Risk Can Yield Reduced Social Welfare Under Competition
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 6, 6, 7, 6, 5, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 2, 3, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis of how competition among machine learning model providers affects social welfare and predictive accuracy, emphasizing that social welfare can be non-monotonic in improvements to data representations. The authors investigate the implications of scaling laws in a competitive market, demonstrating that enhancements in data representation quality may not necessarily lead to improved predictive accuracy, modeled as social welfare. The study includes theoretical frameworks and empirical evaluations, particularly focusing on binary and multi-class classification tasks, and utilizes the CIFAR-10 dataset. A user choice model is proposed, which simplifies the decision-making process of users while assuming model providers are homogeneous.

### Strengths and Weaknesses
Strengths:  
- The paper is well-written and organized, facilitating reader comprehension of its findings.  
- It provides a comprehensive review of related work, linking various research threads on algorithmic decisions and competition.  
- The theoretical analysis reveals an intriguing phenomenon where increased representation quality can lead to decreased social welfare, supported by empirical evaluations.  
- The work is pioneering in studying the impact of competition among model providers on social welfare, providing preliminary evidence supporting the robustness of results despite simplifying assumptions.  
- The paper encourages interdisciplinary dialogue between the scaling laws community and platform competition community.

Weaknesses:  
- The theoretical and empirical analyses assume all model providers share the same representation, which is unrealistic in practice.  
- The user choice model is overly simplistic, potentially limiting the applicability of results.  
- The focus on binary and multi-class classification may limit the generalizability of the findings, as users might not need to switch between providers for simple decisions.  
- Assumptions regarding model-provider actions do not encompass other relevant factors like data collection and pricing.  
- The paper lacks a thorough evaluation of the proposed framework and a detailed discussion of the implications for real-world decision-making scenarios, particularly regarding generative tasks.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their assumptions regarding model representation, particularly addressing the implications of all providers sharing the same representation. Additionally, we suggest enhancing the user choice model by incorporating a more nuanced representation of user decision-making that accounts for platform heterogeneity. Expanding the experimental analysis beyond binary and multi-class classification to include generative tasks and more diverse datasets would enhance the robustness of the findings. Furthermore, we encourage the authors to broaden the scope of model-provider actions to include data collection and pricing strategies. A more detailed discussion on the relationship between data representation quality and social welfare, as well as the implications for real-world applications, should be included. Finally, we urge the authors to refine the framing of their work in relation to scaling laws to avoid potential misunderstandings about its contributions and to further engage with the scaling laws community to broaden the discussion on the societal impacts of competing ML systems.