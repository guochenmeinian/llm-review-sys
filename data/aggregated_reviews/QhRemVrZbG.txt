ID: QhRemVrZbG
Title: LIVE: Learnable In-Context Vector for Visual Question Answering
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 5, 4, 8, 7, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Learnable In-Context Vector (L-ICV) method aimed at enhancing in-context learning performance for multimodal models in Visual Question Answering (VQA) tasks. The authors propose that L-ICV distills essential task information from demonstrations into a single vector, thereby reducing computational costs while improving accuracy. Experimental results indicate that L-ICV outperforms random 32-shot demonstrations and significantly lowers computation costs. However, the evaluation is limited to a small set of models and datasets, raising concerns about generalizability.

### Strengths and Weaknesses
Strengths:
- The topic is significant for the community, and the proposed method is a valuable exploration.
- The writing is clear and comprehensible.
- L-ICV effectively reduces computational costs, requiring fewer FLOPs and less inference time compared to traditional methods.

Weaknesses:
- The evaluation is restricted to one model (IDEFICS-9B) and two datasets (VQAv2, OKVQA), which questions the method's generalizability.
- The increase in ICL performance is relatively modest, raising doubts about the practical benefits given the training resources used.
- The paper lacks comparisons with classical methods like RICE and MMICES, which could provide a clearer context for L-ICV's performance.
- The method requires additional training and optimization efforts, which may hinder its adoption, especially with limited demo data.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by including a broader range of models and datasets to enhance the generalizability of L-ICV. A comprehensive comparison with classical methods such as RICE and MMICES should be conducted to better position L-ICV within the current state-of-the-art. Additionally, exploring the potential performance of L-ICV when trained with RICE samples instead of randomly selected demos would be beneficial. To further enhance the method's practicality, we suggest minimizing the dataset, tuning, and optimization efforts required to achieve competitive performance. Lastly, addressing the questions regarding the trade-offs between training and inference costs, as well as the implications of using a shared bias vector across layers, would strengthen the paper's contributions.