ID: sIsbOkQmBL
Title: CultureLLM: Incorporating Cultural Differences into Large Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 25
Original Ratings: 6, 5, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents CultureLLM, a pipeline designed to enhance the cultural awareness of Large Language Models (LLMs) through a three-stage process: sampling, semantic data augmentation, and fine-tuning. The authors investigate its effectiveness across nine languages and eight culture-related tasks, including offensive language detection, hate speech detection, stance detection, toxicity detection, threat detection, bias detection, abusive language detection, and spam detection. They argue that these tasks are inherently culture-related due to varying cultural norms and historical contexts that influence language interpretation. The methodology relies on the World Value Survey (WVS) as seed data, generating additional training data through semantic augmentation, and demonstrates significant improvements in performance while mitigating catastrophic forgetting. The authors also acknowledge challenges in multi-culture evaluation due to limited language and cultural datasets.

### Strengths and Weaknesses
Strengths:
- The paper features solid experiments that effectively investigate the proposed method's performance.
- It is well-organized and easy to read, addressing an important issue in LLMs regarding cultural biases.
- The authors provide a thorough justification for why various detection tasks are culture-related, highlighting the importance of cultural context in language interpretation.
- The approach of using existing survey data for data collection is both simple and reasonable.
- The paper includes new experimental results demonstrating the authors' method outperforming GPT-3.5-turbo across multiple culture-related tasks, which strengthens the paper's contributions.

Weaknesses:
- The reliance on a human-annotated dataset (WVS) limits the method's applicability and may introduce bias, particularly as most evaluation tasks focus on anti-social detection.
- The assumption that language equates to culture oversimplifies the complexity of cultural diversity, potentially leading to biased models.
- The small size of the seed dataset (50 samples) may not adequately capture cultural nuances.
- The comparison with other culture-specific LLMs lacks fairness due to differing architectures and pre-training data.
- There are unresolved concerns regarding the fundamental assumption of using language as a proxy for culture and the fairness of comparisons made in the experiments.
- Clarifications are needed on the selection criteria for the 50 seed data and the methodology for obtaining token probabilities, as there are inconsistencies in the explanations provided.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the relationship between the evaluated tasks and the fine-tuning data, particularly regarding the relevance of WVS data to tasks like hate speech detection. Additionally, we suggest expanding the seed dataset to better represent cultural diversity and addressing the oversimplification of equating language with culture. It would also be beneficial to provide more detailed experimental parameters, such as fine-tuning hyperparameters and the languages of input samples. We further recommend improving clarity regarding the selection criteria for the 50 seed data to eliminate any perceived contradictions and providing a more detailed explanation of how token probabilities were obtained, particularly addressing concerns about the limitations of the API used. Finally, we encourage the authors to explore a broader range of culture-related tasks beyond anti-social language detection to better demonstrate the model's capabilities and enhance the robustness of their findings and comparisons.