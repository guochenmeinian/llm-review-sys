ID: uZedGmxGUg
Title: EasyTPP: Towards Open Benchmarking the Temporal Point Processes
Conference: NeurIPS
Year: 2023
Number of Reviews: 24
Original Ratings: 5, 7, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents EasyTPP, a comprehensive benchmark for evaluating temporal point processes (TPPs) in continuous-time event sequences. EasyTPP addresses the lack of standardization in evaluating TPP models by providing an open-source benchmark that includes eight highly cited neural TPP models, commonly used evaluation metrics, and datasets. The contributions of EasyTPP include a comprehensive implementation of neural TPP models, a benchmarking pipeline for transparent comparisons, and support for multiple machine learning libraries such as PyTorch and TensorFlow. The authors also propose a central library aimed at facilitating research in TTPs and event sequence modeling, acknowledging the need for insights into the novelty of their work and future research opportunities. They highlight that the current focus on architectural design in the field may be limiting, as performance on standard datasets appears to be saturating, and propose several new research directions, including the development of foundation models for event sequence modeling and the integration of external information sources.

### Strengths and Weaknesses
**Strengths:**
- The benchmarking of TPP facilitates reproducibility and accelerates research in the domain.
- The code implementation is consistent and comprehensive, supporting both TensorFlow and PyTorch.
- The library provides a unified data format and a suite of evaluation methods, significantly easing the data processing burden for future researchers.
- The paper provides a detailed analysis of datasets, including their characteristics and challenges for TPP modeling.
- The authors have demonstrated a commitment to maintaining and expanding the library, welcoming community contributions.
- Extensive experimental results are presented, offering valuable insights into model performance.

**Weaknesses:**
- The novelty of the contributions is limited, as no new benchmark datasets or evaluation tasks are developed.
- The benchmark lacks natural event datasets, such as earthquake datasets.
- Some applicable TPP models are excluded from evaluation, limiting the comprehensiveness of the benchmark.
- The paper lacks new datasets and evaluation tasks, relying on previously used resources.
- The novelty and contributions of the work were not clearly articulated in the initial submission, leading to concerns about the limitations of existing TTP modeling paradigms.
- The analysis of experimental results could be improved by discussing limitations of existing TPP modeling paradigms.

### Suggestions for Improvement
We recommend that the authors improve the reproducibility results by explaining how the reimplemented methods compare to the original papers under controlled settings. Additionally, the authors should clarify what new insights or conflicts with existing literature arise from their benchmarking. It would also be beneficial to provide more guidance for newcomers to the domain and experienced researchers in TPP. Furthermore, we suggest revising Figure 8 for clearer visual comparison between TensorFlow and PyTorch implementations. We recommend that the authors improve the clarity of their contributions in the introduction to better articulate the novelty of their work. Additionally, the authors should expand the evaluation to include a broader range of TTP models beyond neural networks. It would be beneficial to include a detailed analysis of the limitations of current TTP modeling paradigms and discuss potential future research directions. Finally, we suggest enhancing the presentation of figures and tables for better visibility and comprehension, particularly for novice readers, and including natural event datasets to enhance the relevance and applicability of the benchmark.