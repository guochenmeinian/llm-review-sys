ID: PyJ78pUMEE
Title: Just Adjust One Prompt: Enhancing In-Context Dialogue Scoring via Constructing the Optimal Subgraph of Demonstrations and Prompts
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a systematic method leveraging in-context learning of LLMs for dialogue evaluation at both dialogue and turn levels across multiple dimensions. The method involves inverting prompts from the training set, training a prompt selector, and identifying an optimal subgraph during inference. Experiments conducted on five datasets demonstrate the method's effectiveness compared to various baselines. The authors propose a dynamic dialogue evaluation method that adapts to novel evaluation dimensions using ICL-enhanced prompt generation and querying the LLM multiple times with diverse demonstrations.

### Strengths and Weaknesses
Strengths:
- The paper is well-constructed, providing a wealth of information and sound experimental design.
- The proposed method shows promising results, correlating well with human scoring and outperforming existing benchmarks.
- The technical writing is clear, and the experiments are thoughtfully documented, with comprehensive baselines.

Weaknesses:
- The method appears time-consuming, and a detailed inference time comparison with other methods is lacking.
- There is an over-reliance on LLMs, which may introduce biases and sensitivity issues.
- The performance on long conversations and out-of-domain dialogues is unclear, and the paper could benefit from a simpler writing style.
- Results show only marginal improvements in some cases, raising questions about the statistical significance of the findings.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the abstract to better convey the findings. Additionally, providing a detailed inference time comparison with other methods would be beneficial. The authors should also consider conducting experiments on longer conversations and out-of-domain dialogues to assess the method's robustness. Furthermore, it would be helpful to report a smaller-scale sanity check using another model to validate the findings. Lastly, addressing the notation consistency and clarifying the use of decoding parameters in the experimental section would enhance the paper's clarity.