ID: eAQZ9jTVIf
Title: Weak-to-Strong Confidence Prediction
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 3, 3, 5
Original Confidences: 4, 4, 3

Aggregated Review:
### Key Points
This paper investigates the ability of smaller language models (LLMs) to predict the accuracy of larger models, proposing a framework where an evaluator model estimates the correctness of answers generated by a generator model. The authors aim to enhance uncertainty quantification and detect hallucinations in LLMs, presenting experimental results from two datasets, TriviaQA and MMLU, to demonstrate the effectiveness of their approach.

### Strengths and Weaknesses
Strengths:
1. The evaluator model's ability to function locally without access to the larger model's internals is highly practical for sensitive applications.
2. The paper evaluates performance using a comprehensive range of metrics, including AUROC, F1 score, accuracy, and selective accuracy, showcasing robustness across different model configurations.

Weaknesses:
1. The paper suffers from numerous grammatical errors, hindering comprehension.
2. The novelty of using a smaller LLM for confidence estimation is unclear, and the paper does not adequately support claims made in the abstract regarding existing methods.
3. The experimental setup is limited, focusing on only two datasets and lacking comparisons with state-of-the-art confidence estimation methods.
4. The discussion on why smaller models might effectively estimate confidence for larger models is insufficient.
5. The performance variability across tasks raises questions about the generalizability of the proposed framework.

### Suggestions for Improvement
We recommend that the authors improve the clarity and coherence of the writing to enhance comprehension. Additionally, the authors should clarify the unique contributions of their approach compared to existing methods. Expanding the experimental setup to include more datasets and comparisons with state-of-the-art methods would strengthen the paper's claims. The authors should also provide a more detailed explanation of why smaller models can effectively estimate confidence and discuss strategies for addressing data imbalance issues. Finally, further investigation into the generalizability of the framework across various tasks would be beneficial.