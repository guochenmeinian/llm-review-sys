ID: PyAzL6Z802
Title: Multilingual estimation of political-party positioning: From label aggregation to long-input Transformers
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents NLP experiments for automatic scaling analysis of party manifestos using label aggregation and long-input Transformer-based models. The authors propose two approaches: a label aggregation method and a direct classification method based on the entire manifesto. The study evaluates the performance of these methods in both cross-country and diachronic settings, providing insights into the challenges of predicting party positions on the RILE scale.

### Strengths and Weaknesses
Strengths:  
- The paper utilizes an interesting dataset and compares various approaches, providing a thorough evaluation of the methods.  
- It offers promising results with state-of-the-art models and presents a clear analysis of errors, which can serve as a foundation for future research.  
- The authors convincingly argue the relevance of their tasks for understanding political dynamics and public opinion shifts.

Weaknesses:  
- The practical relevance of the results is limited, as the approach primarily generates high-level classifications without insights into specific policy stances.  
- The classifier's performance is notably weak at the edges of the left-right spectrum, which is crucial for political analysis.  
- There is a lack of comparison with previous work on multilingual political text scaling, leaving questions about the relative performance of the proposed methods.

### Suggestions for Improvement
We recommend that the authors improve the motivation for their work by discussing the practical implications of predicting party positions on specific issues rather than just high-level classifications. Additionally, we suggest that the authors address the limitations of their approach by providing a more detailed comparison with previous multilingual scaling methods, clarifying the comparability of RILE scores with other scaling approaches. Finally, we encourage the authors to explore the potential impact of using automatically extracted sentences instead of quasi-sentences on their results.