ID: mKPbcJAb83
Title: SoftTiger: A Clinical Foundation Model for Healthcare Workflows
Conference: AAAI
Year: 2024
Number of Reviews: 4
Original Ratings: 3, 7, 7, 9
Original Confidences: 3, 5, 3, 4

Aggregated Review:
### Key Points
This paper presents the development of SoftTiger, a finetuned large language model (LLM) based on the open-source TigerBot. The authors achieve this through supervised finetuning using a dataset of general text, a clinical dataset, and a novel clinical workflow dataset consisting of instruction pairs for three tasks on the MIMIC-IV dataset, with outputs generated by GPT-4 and validated by physicians. The results indicate improved accuracy on automated evaluation benchmarks.

### Strengths and Weaknesses
Strengths:
- The work exemplifies early finetuning of large (70B) open-source LLMs across multiple GPUs.
- The selection of three clinical data structuring tasks demonstrates a clear potential for clinical impact.
- The paper includes a well-articulated section on the administrative burden on physicians.
- Structuring outputs in IPS or FHIR format optimizes future integration into e-health systems.

Weaknesses:
- The MIMIC data user agreement restricts sharing of data or derivatives, limiting public release of SoftTiger and its dataset, though hosting on PhysioNet is possible.
- The evaluation and training data are solely from MIMIC-IV, which may not represent broader clinical contexts.
- The performance of GPT-4 on the task and inter-annotator agreement are not discussed, raising concerns about the validity of the training and evaluation process.
- Claims regarding the challenges of LLM clinical adaptation lack substantiation, particularly regarding the input length constraint and the assertion about vocabulary size.

### Suggestions for Improvement
We recommend that the authors improve clarity by providing detailed explanations of the evaluation methods, particularly how next-token prediction is conducted. Additionally, the authors should specify the use of Azure or Amazon for MIMIC data sharing in the "Ethical Considerations and Reproducibility Statement." It would be beneficial to include the exact FHIR structures for the subtasks in the appendices and to clarify the training framework by providing hyperparameters and definitions for acronyms like PP and DP. Lastly, we suggest including expert reviews of the final evaluation data and the LLM-as-judge strategy to enhance the rigor of the evaluation process.