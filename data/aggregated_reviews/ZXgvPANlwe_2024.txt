ID: ZXgvPANlwe
Title: PoisonedParrot: Subtle Data Poisoning Attacks to Elicit Copyright-Infringing Content from Large Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 2
Original Ratings: 8, 7
Original Confidences: 3, 4

Aggregated Review:
### Key Points
This paper presents an attacking strategy that induces LLMs to generate copyrighted data by feeding poisoned data during the training phase. The poison samples, created using a sliding window approach over copyrighted text fragments, lead LLMs to produce similar copyrighted outputs. The authors demonstrate the effectiveness of this strategy on the BookMIA dataset using LLaMA-7B, revealing a significant vulnerability in state-of-the-art LLMs. The paper is coherent and well-written, effectively identifying gaps in the literature and drawing parallels between poisoning attacks in LLMs and those in computer vision and text identification models. Furthermore, it shows that existing defense strategies are inadequate against this simple attack, prompting the research community to focus on developing better defenses.

### Strengths and Weaknesses
Strengths:
1. The paper proposes a novel and effective attacking strategy for LLMs, uncovering a major vulnerability.
2. It is well-written and encourages the research community to develop improved defense strategies.

Weaknesses:
1. The paper would benefit from presenting a defensive strategy alongside the PoisonedParrot attack, as a simple attacking strategy without a defense could be misused by malicious attackers.
2. The work lacks complexity and could use more experiments to further substantiate its claims.

### Suggestions for Improvement
We recommend that the authors improve the paper by including a defensive strategy to accompany the PoisonedParrot attack, addressing the potential for misuse. Additionally, we suggest incorporating more experiments to enhance the complexity and robustness of the findings.