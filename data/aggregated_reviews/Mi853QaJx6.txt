ID: Mi853QaJx6
Title: On the Worst Prompt Performance of Large Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 6, 6, 6, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new benchmark, RobustAlpacaEval, aimed at studying the robustness of large language models (LLMs) to prompt variations, specifically focusing on semantically equivalent prompts rather than task-level instructions. The authors conduct extensive experiments on multiple LLMs, revealing significant variability in model performance and challenges in predicting the worst-performing prompts. The findings highlight a substantial gap between the best and worst performance, indicating that current prompt consistency methods offer limited improvements.

### Strengths and Weaknesses
Strengths:
- The paper addresses a highly relevant issue regarding prompt sensitivity, providing valuable insights for the practical deployment of LLMs.
- The introduction clearly articulates the motivation behind the research, effectively setting the context for the study.
- Comprehensive evaluations across various LLMs demonstrate the variability in performance, closely mirroring real-world scenarios.

Weaknesses:
- The paper lacks effective solutions to mitigate the identified prompt variability issue, which would enhance its contribution.
- There is inconsistency between the textual descriptions and visual representations regarding the focus on task-level versus case-level inputs.
- The experimentation scope is limited, as it does not include advanced models like GPT-4, nor does it explore prompts in languages other than English.
- The methodology may introduce biases due to reliance on gpt4_turbo as the evaluator, and the implications of this should be discussed.
- The definition of "worst" and "best" performance is not clearly articulated, leading to potential confusion regarding the implications of paraphrasing.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the definitions for "worst" and "best" performance, ensuring reproducibility in their findings. Additionally, we suggest incorporating a discussion on the potential biases introduced by using gpt4_turbo as the evaluator. The authors should consider expanding the experimentation to include more advanced LLMs and diverse languages to enhance the generalizability of their results. Furthermore, exploring whether a diverse set of prompts in the SFT stage could improve the model's worst prompt performance would add depth to the study. Lastly, we encourage the authors to propose potential strategies for mitigating the identified prompt variability issue.