ID: VRRvJnxgQe
Title: NoiseGPT: Label Noise Detection and Rectification through Probability Curvature
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 6, 5, 6, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents NoiseGPT, a method that employs Multimodal Large Language Models (MLLMs) for detecting and rectifying label noise in datasets. The approach utilizes a token-wise Mix-of-Feature (MoF) technique and an In-Context Discrepancy (ICD) measure to identify noisy samples and improve classification accuracy. The authors propose a method that does not require training deep neural networks (DNNs), effectively addressing varying output distributions to separate clean and noisy samples. Experiments demonstrate the effectiveness of NoiseGPT, achieving an AUROC of over 0.92 on the ILSVRC12 dataset and showing improved performance on various synthetic and real-world datasets, outperforming existing methods like Pro-Mix and DivideMix in precision, recall, and F1 score metrics.

### Strengths and Weaknesses
Strengths:
1. The paper introduces a novel application of MLLMs for label noise detection, leveraging the concept of probability curvature and the zero-shot capabilities of models like CLIP.
2. Comprehensive experiments across multiple datasets validate the effectiveness of NoiseGPT in detecting and rectifying label noise.
3. The methodology is well-organized, with detailed explanations and pseudocode enhancing reproducibility.
4. The proposed methods show promising results, with extensive experimental results, including comparisons on the WebVision dataset and additional experiments with different LLM backbones.

Weaknesses:
1. The novelty of the approach is limited due to prior exploration of probability curvature in existing works, which should be discussed in the related work section.
2. There is insufficient ablation study and baseline comparisons to demonstrate the performance of each component of NoiseGPT, particularly regarding the use of CLIP as a label corrector.
3. The paper lacks a thorough discussion on the scalability of the method to large datasets, given the computational demands of generating multiple perturbations.
4. Some reviewers questioned the complementarity of performance comparisons between NoiseGPT and other state-of-the-art methods.
5. Two reviewers did not participate in the discussion phase, which may limit the breadth of feedback.

### Suggestions for Improvement
We recommend that the authors improve the discussion of related works, particularly those exploring probability curvature and label noise detection, to clarify the novelty of their contribution. Additionally, the authors should conduct more ablation studies to illustrate the performance of individual components of NoiseGPT and include comparisons with baseline methods, such as CLIP. Furthermore, we suggest that the authors elaborate on the scalability of their method, addressing the computational costs associated with multiple perturbations and exploring strategies to mitigate these costs. Lastly, we recommend improving the clarity of performance comparisons with other state-of-the-art methods to address reviewer concerns and engaging all reviewers in the discussion phase to gather a wider range of feedback.