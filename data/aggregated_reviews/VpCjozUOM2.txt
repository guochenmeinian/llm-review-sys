ID: VpCjozUOM2
Title: Chanakya: Learning Runtime Decisions for Adaptive Real-Time Perception
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 6, 6, 6, 5, 5, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 2, 1, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Chanakya, a learned approximate execution framework designed for real-time perception that optimally balances accuracy and latency. Chanakya utilizes both intrinsic and extrinsic contexts to inform runtime decisions and employs a novel reward function to enhance learning. The framework's performance is evaluated across various edge devices and runtime conditions, demonstrating superiority over static policies and adaptability to new hardware and action spaces.

### Strengths and Weaknesses
Strengths:
1. The paper effectively addresses the optimization of accuracy and latency for real-time tasks, with a well-defined reward function that considers the characteristics of video sequences.
2. Extensive experimental results validate Chanakya's performance improvements, showcasing its applicability across different hardware and configurations.
3. The writing is clear and the organization of the paper facilitates understanding.

Weaknesses:
1. Certain experimental settings, such as the offline upper bound and the reinforcement learning training method, lack clarity.
2. The novelty of the approach is limited, as prior work on RL techniques for multi-objective optimization is not sufficiently addressed.
3. The scalability of Chanakya with increasing search space size is unclear, and comparisons to non-RL-based approaches are absent.

### Suggestions for Improvement
We recommend that the authors improve the clarity of experimental settings, particularly regarding the offline upper bound and the RL training method. Additionally, we suggest incorporating a more comprehensive discussion of prior work on RL techniques for multi-objective optimization to highlight the novelty of their approach. To enhance scalability understanding, we encourage the authors to evaluate Chanakya's performance with expanded search spaces and provide comparisons to non-RL-based methods. Lastly, including more diverse experimental results beyond detection tasks would strengthen the paper's contributions.