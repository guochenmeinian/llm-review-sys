ID: hKxi3KoSO2
Title: Multimodal Knowledge Graph Error Detection with Disentanglement VAE and Multi-Grained Triplet Confidence
Conference: ACM
Year: 2024
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel task in multimodal knowledge graphs: error detection across modalities. The authors propose a new framework, KGDMC, and introduce a Disentanglement VAE alongside Multi-Grained Triplet Confidence (MTC) modules to identify modality and triplet errors. They construct two datasets for this task and demonstrate the effectiveness of their approach through extensive experiments.

### Strengths and Weaknesses
Strengths:
- The introduction of the multimodal knowledge graph error detection task is significant and well-articulated.
- The constructed datasets are valuable resources for the research community.
- The use of Disentanglement VAE for capturing semantic consistency across modalities is logically sound and shows performance improvements.

Weaknesses:
- The evaluation relies on only two well-known datasets, lacking more contemporary multimodal datasets.
- Some baseline models used in the evaluation are not entirely convincing, raising concerns about their reliability.
- The definitions of errors and the problem statement lack clarity, making it difficult to assess the assumptions made in the methodology.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the problem definition and the precision of error definitions to enhance understanding. Additionally, we suggest incorporating more recent multimodal datasets, such as Wikidata5M, to strengthen the evaluation. The authors should also clarify the choice of TransE over other KGE methods and address the potential randomness introduced by negative sampling in their experiments. Furthermore, we advise proofreading the paper for grammatical issues and typographical errors, particularly in figures and tables.