ID: mpL9ikuYez
Title: Proto-lm: A Prototypical Network-Based Framework for Built-in Interpretability in Large Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework named proto-lm aimed at enhancing interpretability in large language models by utilizing prototypical networks. The authors propose selecting prototype sentences for each category and estimating similarity scores for input tokens based on these prototypes, which serve as attribution weights. The framework retains competitive performance while providing interpretable predictions. The authors conduct extensive evaluations, including a comprehensive ablation study, to assess the effectiveness and quality of the generated explanations.

### Strengths and Weaknesses
Strengths:  
- The paper offers a novel approach to interpretability by integrating prototypical networks, which is recognized as a significant contribution.  
- Extensive evaluation through diverse experiments and a comprehensive ablation study enhances understanding of the method's internal workings.  
- The framework demonstrates improvements in multi-class classification and natural language inference tasks, alongside the quality of explanations generated.

Weaknesses:  
- The method's similarity to existing frameworks, particularly those by Friedrich et al. (2021) and Koh (2020), raises concerns about its novelty.  
- Prototype selection lacks clarity, with no explanation of whether prototypes are chosen automatically or manually, and how this affects generalizability across different datasets.  
- Experiments primarily focus on sentiment classification and NLI tasks, limiting insights into the method's adaptability to other applications.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the selection process of prototypes, addressing whether they are selected automatically or by humans, and discussing the completeness of the chosen prototypes. Additionally, conducting comparisons with other interpretable models, such as concept bottleneck and integrated gradients, would strengthen the experimental results. We suggest exploring the robustness of hyper-parameters across different tasks and investigating the method's performance with decoder-only language models. Finally, addressing class imbalance in the prototypical space selection would enhance the discussion of the framework's applicability.