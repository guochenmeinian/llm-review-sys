ID: tllpLtt14h
Title: Einsum Benchmark: Enabling the Development of Next-Generation Tensor Execution Engines
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 7, 7, 7, 8, -1
Original Confidences: 3, 4, 4, 4, -1

Aggregated Review:
### Key Points
This paper presents a benchmark dataset of einsum operations that encompasses a wide range of tensor expressions relevant to real-world problems. The authors propose preliminary benchmarks, data generators, and converters to facilitate further data creation. The experiments reveal optimization and compatibility improvement opportunities in popular einsum libraries, such as NumPy, PyTorch, TensorFlow, and JAX, highlighting issues related to scalability, tensor size discrepancies, sparsity, and datatype support. The work aims to provide insights into how tensor processing libraries should be benchmarked and improved, given their significance in AI/ML workloads.

### Strengths and Weaknesses
Strengths:
- The work addresses an important problem and has the potential for high impact.
- The manuscript is well-presented and easy to follow.
- The dataset is extensive, and the experimental design is thorough.
- The paper offers interesting observations regarding the effect of contraction paths on performance and asymmetry in tensor sizes.

Weaknesses:
- The dataset primarily focuses on complex einsums, lacking simpler expressions that are widely used.
- The benchmark is only evaluated on a single hardware platform, limiting its applicability.
- The paper does not adequately connect its findings on I/O complexity with broader literature in high-performance computing.

### Suggestions for Improvement
We recommend that the authors improve the dataset by including benchmarks that focus on simpler, more standard einsums, such as vanilla matrix-matrix multiplication. Additionally, we suggest adding GPU performance evaluations to enhance the benchmark's relevance. It would also be beneficial to discuss I/O complexity in Section 4.2, connecting it to existing literature on performance optimization. Furthermore, including 2-3 sample benchmark einsum problems with their metadata and tensor size specifications would make the paper more self-contained. Lastly, we encourage the authors to clarify how "seven inference queries" is derived, as this could enhance understanding of the dataset's construction.