ID: oqqmjw1BD1
Title: Bridging the Gap between Synthetic and Authentic Images for Multimodal Machine Translation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method to bridge the gap between synthetic and authentic images in multimodal machine translation (MMT) by feeding both types of images to the MMT model. The approach minimizes the disparity in their representations using Optimal Transport (OT) theory and ensures output distribution consistency through Kullback-Leibler (KL) divergence. Key contributions include the introduction of synthetic images during training, an optimal transport-based training objective, and a prediction consistency loss to enhance model consistency. The experimental results indicate state-of-the-art performance on the Multi30K En-De and En-Fr datasets, demonstrating the method's effectiveness without relying on authentic images during inference.

### Strengths and Weaknesses
Strengths:
- The innovative approach effectively addresses the dependence on authentic images in MMT.
- Comprehensive evaluation against various baseline models and datasets enhances the validity of the findings.
- Clear writing and organization facilitate understanding of the proposed method.

Weaknesses:
- Concerns about the novelty of the method, as the objectives and consistency concepts have been previously utilized in other visual-text models.
- Heavy reliance on synthetic images during training raises questions about the robustness of the approach, with potential sensitivity to the quality and diversity of these images.

### Suggestions for Improvement
We recommend that the authors improve the novelty aspect by clearly distinguishing their contributions from existing methods in the literature. Additionally, addressing the robustness concerns related to the reliance on synthetic images is crucial; the authors should explore the impact of varying the quality and diversity of synthetic images on model performance. Finally, conducting a manual evaluation to assess how many translations benefit from incorporating images would provide a more comprehensive understanding of the visual information's impact on translation quality.