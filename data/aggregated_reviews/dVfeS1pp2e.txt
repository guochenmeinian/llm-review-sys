ID: dVfeS1pp2e
Title: Strong and Efficient Baselines for Open Domain Conversational Question Answering
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on open-domain conversational question answering, highlighting limitations in the dense passage retrieval + fusion-in-decoder architecture. The authors propose a retriever-reranker-reader approach, which includes a fast reranker to balance speed and performance, and demonstrate improvements in state-of-the-art results on two datasets while achieving a 60% reduction in latency. The paper also discusses the necessity of fewer inputs for the reader and the importance of considering conversation history in the retriever's output.

### Strengths and Weaknesses
Strengths:
- The paper provides a clear identification of limitations in existing frameworks and proposes a simple yet effective solution.
- Sufficient experiments support the claims, with results on various alternative designs and an ablation study demonstrating the effectiveness of the reranker.
- The writing is clear and the methodology is well-structured.

Weaknesses:
- The novelty of the proposed method is questioned, as similar reranking approaches exist, such as Re2G, which the authors do not adequately address.
- There is a lack of discussion on hyper-parameter tuning, which may limit the generalizability of the results.
- Inconsistent results are noted across different datasets, raising concerns about the robustness of the findings.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the novelty of their approach by explicitly comparing it to existing methods like Re2G and addressing the similarities and differences. Additionally, the authors should provide a detailed explanation of hyper-parameter settings to enhance reproducibility. Clarifying the impact of the Semantic Reranker on latency and addressing the inconsistencies in results across datasets would strengthen the paper. Finally, we suggest reorganizing complex symbols and notations in Section 2 for better clarity.