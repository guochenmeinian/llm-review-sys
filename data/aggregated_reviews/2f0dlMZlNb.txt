ID: 2f0dlMZlNb
Title: Effective Targeted Attacks for Adversarial Self-Supervised Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 7, 7, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new adversarial attack method called TARO for self-supervised learning, which aims to enhance robustness by utilizing targeted attacks instead of traditional untargeted ones. The authors propose a scoring method for selecting target samples, demonstrating that this approach leads to significant improvements in adversarial robustness for positive-pair-only self-supervised learning frameworks like SimSiam and BYOL.

### Strengths and Weaknesses
Strengths:
1. The paper identifies a critical issue with current adversarial self-supervised learning methods, highlighting the inadequacy of untargeted attacks for achieving good downstream robustness.
2. The proposed TARO method shows substantial improvements over positive-only untargeted attacks.
3. The writing is clear, and the definitions and arguments are well-structured.

Weaknesses:
1. The individual contributions of TARO's components are not adequately analyzed, raising questions about the significance of the scoring function versus the targeted attack itself. The authors should consider adding a baseline that uses random sample selection to clarify this.
2. The paper does not sufficiently address the distinction between training loss and adversarial sample loss, which has been explored in prior works, thus limiting its novelty.
3. The comparison of TARO is limited to only RoCL and ACL, neglecting other relevant unsupervised adversarial training methods. A broader comparison is necessary to validate the effectiveness of the score function.
4. The clarity of the "Visualization of embedding space" section and Figure 3 is lacking, as it does not convincingly demonstrate whether targeted attacks yield more boundary samples than untargeted ones.

### Suggestions for Improvement
We recommend that the authors improve the analysis of TARO's components by including a baseline that selects random samples from the batch. Additionally, the authors should clarify the relationship between training loss and adversarial sample loss, referencing relevant literature. Expanding the comparison to include a wider range of unsupervised adversarial training methods would strengthen their claims regarding the effectiveness of the score function. Lastly, enhancing the clarity of the visualization section and Figure 3 would improve the overall presentation of the results.