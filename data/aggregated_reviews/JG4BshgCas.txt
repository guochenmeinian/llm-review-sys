ID: JG4BshgCas
Title: Generalizing to Unseen Domains for Regression
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 5, 3, 6, 7, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to domain generalization for regression tasks (DGR), addressing the unique challenges posed by disjoint labeling spaces across domains. The authors propose a margin-aware meta-learning framework that mitigates sampling bias by weighting queries based on their distance to support samples. They evaluate their method against various feature alignment techniques and meta-learning models, demonstrating its effectiveness on multiple datasets.

### Strengths and Weaknesses
Strengths:
1. The authors clearly articulate the relationship between the margin between support and query samples and the difficulty of query tasks.
2. The proposed weighting strategy for meta-learning in regression tasks is straightforward and well-founded.
3. Extensive experiments across diverse datasets, including toy examples and real-world applications, validate the proposed method.

Weaknesses:
1. The demonstrated relationship between margin and task hardness is somewhat obvious and lacks novelty.
2. The evaluation is limited to one baseline meta-learning model (MLDG), making it difficult to ascertain whether improvements stem from the proposed weighting or the framework itself.
3. Clarification is needed on whether MAMR is specifically applied to the MAML framework, as inner and outer loop updates suggest this; further exploration of its applicability to other meta-learning algorithms is warranted.
4. The paper could benefit from using different backbone models in experiments.
5. The assertion regarding multi-step adaptation not being necessary for DGR is misleading, as frameworks like learn2learn show that MAML performs well with fewer adaptation steps.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their theoretical contributions by providing a more in-depth discussion of the significance of using meta-learning for DGR. Additionally, we suggest including comparisons with multiple meta-learning models, such as ANIL and Neural Processes, to better evaluate the proposed method's effectiveness. Clarifying the application of MAMR within the MAML framework and exploring its performance with various meta-learning algorithms would strengthen the paper. Furthermore, we encourage the authors to discuss the implications of their method on imbalanced datasets and to provide examples of such datasets. Lastly, including a toy experiment to illustrate potential failures of feature alignment techniques in DGR tasks would enhance the paper's robustness.