ID: xTgM7XLN9P
Title: Compact Neural Volumetric Video Representations with Dynamic Codebooks
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 7, 6, 4, 7, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for compressing volumetric videos using a dynamic codebook that optimizes feature representation by merging low-importance codes and dynamically adjusting the codebook over time. The authors propose a two-stage compression process: the first stage constructs a codebook based on feature contributions to reconstruction, while the second stage selects and optimizes features per temporal segment. Experimental results indicate that this approach achieves state-of-the-art (SOTA) rendering quality and compression efficiency, significantly reducing training time compared to existing methods.

### Strengths and Weaknesses
Strengths:
- The method achieves SOTA accuracy and compression performance with improved efficiency.
- The dynamic codebook effectively reduces spatial and temporal redundancy while maintaining rendering quality.
- The paper is well-structured, utilizing clear headings and visual aids to enhance comprehension.

Weaknesses:
- Writing clarity could be improved, and the evaluation is limited to only two scenes.
- Experimental details and results are incompletely reported, leading to confusion about the methodology.
- The novelty of the dynamic codebook approach is questioned, as it appears to focus primarily on engineering aspects rather than introducing fundamentally new concepts.
- The method introduces additional hyperparameters, complicating practical application.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing, particularly in the description of the method and the clustering algorithm, which should be detailed in the main text rather than supplementary materials. Including specific implementation details, such as how accumulated score contributions are utilized and the definition of temporal fragments, would enhance understanding. Additionally, providing insights into training times and comparisons with other models would clarify the efficiency claims. We suggest addressing the limitations of the dynamic codebook, particularly regarding hyperparameter tuning, and exploring its applicability to other explicit representations. Finally, a more comprehensive evaluation of the model's performance across various datasets would strengthen the contribution of the paper.