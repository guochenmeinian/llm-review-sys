ID: qRbhKhqp0b
Title: The Past, Present and Better Future of Feedback Learning in Large Language Models for Subjective Human Preferences and Values
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive survey of 95 papers from ACL and arXiv, focusing on aligning large language models (LLMs) with subjective human preferences and values. It categorizes the literature into past and present research, while also providing future perspectives. The authors identify five key challenges: non-universality of preferences and values, inconsistent conceptualization, feedback incompleteness, feedback operationalization, and representativeness of feedback sources. The paper offers insightful analysis and recommendations for future research in this evolving field.

### Strengths and Weaknesses
Strengths:
- The review is well-written, organized, and based on a thorough selection of relevant papers.
- It effectively highlights important challenges in incorporating human feedback into LLMs, raising awareness of the subjectivity and incompleteness of human preferences and values.
- The process of paper selection is clearly explained, and the limitations section adds depth to the work.

Weaknesses:
- The sections on the past, present, and future are imbalanced, with the past section being too condensed and the future section overly extensive.
- Some paragraphs contain excessive citations, leading to disjointed sentences, particularly in the initial pages.
- Clarity and wording could be improved in several minor areas, including the conceptualization of LLMs and the explanation of "Input" and "output" keywords in Table 1.

### Suggestions for Improvement
We recommend that the authors improve the conceptualization of LLMs to accurately include encoder-only models like BERT. Additionally, we suggest addressing the dependency between representativeness and finer-grained modeling of feedback, as this clarification could enhance the discussion. It would also be beneficial to provide contextualization paragraphs at the beginning of each section, particularly for the "past" and "present" discussions, to improve flow and coherence. Lastly, we encourage the authors to normalize mentions of "language models" to "LLMs" throughout the paper for consistency.