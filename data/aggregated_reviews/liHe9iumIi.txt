ID: liHe9iumIi
Title: FewViewGS: Gaussian Splatting with Few View Matching and Multi-stage Training
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 3, 6, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents FewViewGS, a method for regularizing sparse view 3D Gaussian Splatting (3DGS) from unseen viewpoints without relying on pre-trained depth estimators. The authors propose to reproject pixels to an unseen view and calculate losses at corresponding pixels identified through image matching. They argue that their approach diverges significantly from SPARF, particularly in its ability to mitigate overfitting, as evidenced by superior performance metrics on 3DGS. The authors highlight that their semantic loss using VGG outperforms DINOv2 and CLIP due to better detail retention. The initialization process for 3D Gaussians is clarified as involving both SfM and MVS, countering claims that it does not estimate camera poses. Experimental results on LLFF, DTU, and Blender datasets indicate that the proposed method achieves competitive or superior performance compared to existing state-of-the-art methods while also achieving reduced training times.

### Strengths and Weaknesses
Strengths:
- The method can outperform existing baselines without the need for additional depth estimators.
- The approach effectively addresses overfitting and maintains multi-view consistency.
- Visualization results are strong and demonstrate the effectiveness of the approach.
- The use of correspondence priors and VGG for semantic loss enhances performance and detail retention.
- The integration of RoMa and VGG results in significantly reduced training times and improved performance metrics.
- The paper is well-organized and includes extensive ablation studies.

Weaknesses:
- The main contribution shares insights with SPARF, which also utilizes image matching for supervision on unseen views, limiting the novelty of this work. 
- The multi-stage training approach is a common composition of "initialization + regular training + refinement."
- Proposed equations contain numerous manual factors and lack a solid mathematical foundation, appearing more as engineering attempts than technical contributions.
- The response to critiques is perceived as evasive, failing to adequately address significant concerns raised by reviewers.
- Experiments are insufficient; details on initialization methods and geometry visualizations are lacking, and the impact of the reprojection operation on training time is unclear.
- There are questions regarding the clarity and accuracy of the initialization process, particularly in relation to the use of the FSGS code.
- Performance improvements are limited compared to current methods, and while this work avoids some pre-trained models, it introduces dependencies on VGG features and RoMa matching.
- There are errors in the paper, including unclear elements in equations and incorrect citation information.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their contributions by clearly differentiating their method from SPARF and providing a more in-depth analysis of their multi-stage training strategy. Additionally, we suggest clarifying the mathematical foundations of the proposed equations and reducing reliance on manual hyperparameters. The authors should enhance their experimental section by including comprehensive details on initialization methods, geometry visualizations, and the impact of training time. Furthermore, we encourage the authors to provide clearer documentation regarding the initialization process, specifically detailing the role of 'tools/colmap_llff.py' in the context of SfM and MVS to clarify any misunderstandings. Lastly, addressing the errors in the paper, particularly in equations and citations, is essential for clarity and accuracy.