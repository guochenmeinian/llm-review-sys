ID: oW1XWv6Oll
Title: Empowering Federated Graph Rationale Learning with Latent Environments
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Environment-aware Data Augmentation (EaDA) method, which addresses the federated graph rationalization problem by inferring latent environments. The method includes the Environment-aware Rationale Extraction (ERE) module and the Local-Global Alignment (LGA) module, which enhance understanding and implementation. EaDA ensures client data privacy through prototype learning and mitigates performance degradation from data heterogeneity using contrastive learning to align local and global rationale representations.

### Strengths and Weaknesses
Strengths:
- The paper provides a clear background and well-designed illustrations of the EaDA framework.
- The proposed method is extensively evaluated across various aspects, demonstrating promising experimental results.
- The approach addresses a relevant problem in federated learning and graph rationalization.

Weaknesses:
- The overall contribution appears restrictive, with unclear innovations compared to existing designs.
- The complexity of the EaDA method may lead to prolonged training times and high resource consumption, especially with limited client resources.
- The model's performance is sensitive to the choice of the number of environments (k), which could limit adaptability to varying data distributions.
- Writing issues exist, including inconsistent terminology (LDA and LGA) and insufficient detail in captions and descriptions.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the contributions by explicitly discussing how the data heterogeneity problem is uniquely addressed in graph rationalization compared to other tasks. Additionally, we suggest optimizing the LGA module to reduce reliance on the ERE module and consider introducing auxiliary mechanisms for greater flexibility. To enhance the model's adaptability, it may be beneficial to implement dynamic adjustment mechanisms for selecting the optimal number of environments (k) during training. Furthermore, including additional evaluation metrics such as runtime efficiency and model convergence rate could provide a more comprehensive assessment of the method's advantages. Lastly, we encourage the authors to refine the writing for clarity, particularly in the use of terminology and the presentation of figures and tables.