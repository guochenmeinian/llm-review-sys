ID: uJ3qNIsDGF
Title: Exploring Geometry of Blind Spots in Vision models
Conference: NeurIPS
Year: 2023
Number of Reviews: 19
Original Ratings: 7, 7, 8, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an exploration of the output space of vision models, specifically addressing the phenomenon of under-sensitivity through the proposed Level Set Traversal (LST) algorithm. The LST algorithm transforms a "source" input image into a visually distinct image while maintaining the prediction of the source class, revealing the existence of "blind spots" in neural networks. The authors provide both theoretical analysis and empirical evaluations on datasets like ImageNet and CIFAR-10, demonstrating that LST can identify paths of high confidence between source and target images, particularly in adversarially trained models. Additionally, the paper includes a comprehensive rebuttal that addresses reviewer concerns and demonstrates the generalizability of the experimental results beyond the initially chosen five ImageNet classes. The authors assert that their methodology, particularly the LST algorithm, maintains high confidence across the entire path and include additional results on wall-clock timing and discussions of failure cases.

### Strengths and Weaknesses
Strengths:
- The originality of the LST algorithm allows application across various network architectures, improving upon previous methods limited to specific architectures.
- The clarity of the method's explanation and its effectiveness in finding high-confidence paths between visually distinct images is commendable.
- The theoretical analysis and empirical results are solid, contributing valuable insights into model under-sensitivity.
- The rebuttal effectively addresses reviewer concerns and enhances the paper's credibility.
- The inclusion of additional results and discussions provides a more complete understanding of the methodology and its implications.
- The authors' responsiveness to feedback is commendable, as evidenced by the increased support for acceptance.

Weaknesses:
- The algorithm's computational cost is not clearly contextualized; a wall clock time estimate for the 200-400 iterations required per image would be beneficial.
- The evaluation is limited to a small number of target images, raising concerns about potential overfitting.
- There is a lack of metrics measuring the confidence of LST outputs independently, which is crucial for validating the algorithm's effectiveness.
- The text may require reworking for improved clarity and comprehensiveness in the camera-ready version.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the computational cost by providing a wall clock time estimate for the LST algorithm's iterations. Additionally, expanding the evaluation to include more target images would strengthen the findings and mitigate concerns about overfitting. It would also be beneficial to include a metric that measures the confidence of LST outputs independently, particularly for the results presented in Table 1. Furthermore, we suggest including a figure that visualizes the images along the path from the source to the final generated image, which would enhance understanding of the level sets. Lastly, clarifying the significance of the star-like structure discovered in the level sets and its implications for model training would greatly benefit the paper's impact. We also recommend improving the clarity and comprehensiveness of the text in the camera-ready version, and incorporating the additional presented experiments and results on wall-clock timing and failure cases to further enhance the paper's completeness.