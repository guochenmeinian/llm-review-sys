ID: gaXAjtHic2
Title: On Private and Robust Bandits
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 8, 6, 7, 6, -1, -1, -1, -1, -1
Original Confidences: 4, 1, 3, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on private and robust multi-armed bandits (MABs) with heavy-tailed and contaminated rewards. The authors establish a minimax lower bound that characterizes the information-theoretic limits of regret concerning privacy budget, contamination level, and heavy-tailedness. They propose a meta-algorithm based on a private and robust mean estimation sub-routine (PRM) that achieves nearly-optimal regrets. The paper also includes simulations to support the theoretical findings.

### Strengths and Weaknesses
Strengths:
1. The problem of private and robust bandits is well-motivated.
2. The upper bounds nearly match the lower bounds, indicating a solid contribution.
3. The writing is clear and engaging.
4. The connection between privacy and robustness through truncation is intriguing.

Weaknesses:
1. There is a lack of clarity regarding the last term in Theorems 6.2 and 6.12, particularly as contamination approaches zero, which raises questions about the term's behavior.
2. The presentation is somewhat lacking, making the paper difficult to follow. A more thorough problem statement is needed to describe the agent-environment interaction clearly.
3. The relationship between privacy and the setting is not well articulated, leaving questions about whose privacy is being defended and from whom.
4. The significance of the results may not meet conference standards due to the perceived narrowness of the setting.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the last term in Theorems 6.2 and 6.12 by discussing potential methods to address it. Additionally, we suggest including a concise, self-contained description of the problem statement that outlines the interaction between the agent and the environment, replacing the Preliminaries section. A more explicit discussion of the privacy aspect, detailing the adversary's knowledge and the privacy goals, would enhance accessibility. Furthermore, we encourage the authors to articulate the significance of their results more clearly and to explore the synergy between privacy and heavy-tailed rewards in bandit settings.