ID: XIScpCMUse
Title: MVInpainter: Learning Multi-View Consistent Inpainting to Bridge 2D and 3D Editing
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 4, 7, 5, 6, -1, -1
Original Confidences: 3, 4, 3, 3, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method for multi-view consistent inpainting, addressing the 3D object editing task as a multi-view 2D inpainting challenge. The authors propose using the MVInpainter model, which incorporates motion priors and reference key/value concatenation to ensure cross-view consistency without requiring explicit camera poses. The method is evaluated on various datasets, demonstrating effectiveness in object removal, insertion, and replacement.

### Strengths and Weaknesses
Strengths:
1. The approach of framing 3D object editing as multi-view generation is innovative.
2. The selection of diverse training datasets for MVInpainter-F and MVInpainter-O effectively decomposes the object replacement task.
3. Extensive experiments validate the method's performance, including long sequence generation and 3D scene reconstruction.

Weaknesses:
1. The title suggests a focus on 3D editing, yet the techniques primarily address 2D images or videos, lacking explicit 3D representation.
2. The design choices, particularly in the utilization of domain-adapted LoRA and temporal transformers, lack novelty.
3. The clarity of the training, inference, and evaluation settings is insufficient, leading to confusion regarding specific tasks and setups.
4. Some assumptions in the methodology are heuristic and may not be robust across diverse use cases.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by reorganizing the introduction of techniques and providing detailed explanations of training, inference, and evaluation settings. Specifically, clarify the input-output pairs during training and explicitly outline the tasks and datasets used in experiments. Additionally, consider revising the title to better reflect the focus on 2D inpainting rather than 3D editing. Address the robustness of the mask adaptation design and provide more comprehensive figures to enhance understanding. Lastly, elucidate the differences between the proposed priors and existing methods like AnimateDiff and Flow Grouping.