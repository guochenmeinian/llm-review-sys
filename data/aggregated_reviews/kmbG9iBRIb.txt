ID: kmbG9iBRIb
Title: Accountability in Offline Reinforcement Learning: Explaining Decisions with a Corpus of Examples
Conference: NeurIPS
Year: 2023
Number of Reviews: 23
Original Ratings: 4, 5, 6, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Accountable Batched Controller (ABC), which aims to learn a controller from batched datasets containing time-series observations, actions, and value estimates, particularly in high-stakes applications like healthcare. The authors propose a POMDP formalism and impose linearity assumptions to derive analytical properties regarding model error. ABC introduces a novel example-based approach to interpretable policy learning, emphasizing accountability in decision-making scenarios. The authors argue that example-based explanations are more insightful for human-machine cooperation than traditional feature-based interpretability methods. ABC enhances understanding of policy decisions by providing reference examples that clarify the rationale behind decisions, particularly in critical applications like cancer treatment. The paper also provides a comprehensive analysis of various decision-making methods in reinforcement learning (RL), focusing on their conservation, low-data performance, adaptability, and reward-free capabilities. ABC demonstrates conservative decision-making through minimal convex hulls and excels in low-data regimes, while also being adaptable to user specifications without retraining.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant issue of ensuring safety and accountability in machine learning applications, particularly in high-stakes domains like healthcare.
- Clear articulation of assumptions and logical arguments supporting the thesis, along with a strong theoretical foundation for the method.
- Positive evaluation results in critical domains, demonstrating ABC's effectiveness across various batched control tasks.
- Theoretical justification for ABC's conservation through Propositions 3.8 and 3.10, highlighting its adaptability and performance in low-data scenarios.

Weaknesses:
- The paper does not adequately address offline reinforcement learning, making it challenging to contextualize within relevant prior work.
- Missing several offline reinforcement learning baselines, with some chosen baselines lacking access to the same information as ABC.
- The results section relies on simplistic computational examples and qualitative descriptions, lacking robust tests to demonstrate accountability.
- The assumption of linearity in mapping from belief to value may not hold in complex tasks, and the optimization problem appears ill-defined.
- The focus on high-stakes decision-making may limit the applicability of the method in conventional offline reinforcement learning settings.
- Some reviewers found the presentation of the paper confusing, suggesting that the organization could be improved for clarity.

### Suggestions for Improvement
We recommend that the authors improve the contextualization of their work by explicitly addressing how it differs from offline reinforcement learning and including relevant baselines. Additionally, we suggest providing a more rigorous evaluation of accountability through clearer tests and possibly incorporating human-subject experiments. The authors should also clarify the implications of their linearity assumption and enhance the discussion around the optimization problem, including conducting additional experiments to explore its limitations. Improving the organization of the paper to enhance clarity, particularly by providing a high-level roadmap and clearer motivations in the introduction, would be beneficial. Addressing the concerns regarding the focus on high-stakes scenarios could broaden the appeal of the method. Lastly, further comparisons with offline reinforcement learning baselines and enhancing the motivation and problem definitions will strengthen the paper's contributions and meet the expectations of the reviewers.