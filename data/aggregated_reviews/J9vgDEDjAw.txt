ID: J9vgDEDjAw
Title: UDAPDR: Unsupervised Domain Adaptation via LLM Prompting and Distillation of Rerankers
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents UDAPDR, a novel unsupervised domain adaptation method for neural information retrieval models. The authors propose a three-stage pipeline that utilizes a large language model (LLM) for generating synthetic queries, which are then adapted into prompts for a smaller LLM to produce extensive synthetic data. Multiple rerankers are trained on this data and distilled into a single efficient retriever model. The method shows improved retrieval accuracy in zero-shot settings across various datasets, including LoTTE and BEIR.

### Strengths and Weaknesses
Strengths:  
- The method effectively improves out-of-distribution generation of neural retrievers without increasing test-time latencies.  
- It demonstrates computational efficiency compared to previous adaptation methods that require millions of synthetic queries, proving effective with only thousands.  
- Comprehensive evaluation and ablation studies support the claims made regarding the method's effectiveness.

Weaknesses:  
- The novelty of the approach is questioned, as some prompts used have been seen in prior works.  
- The computational cost of Flan-T5 XXL is considered significant, and the long-term viability of relying on large models like GPT-3 is uncertain due to potential hardware advancements.  
- The claim regarding the sufficiency of "only 1000s of synthetic queries" lacks strong empirical support.

### Suggestions for Improvement
We recommend that the authors improve the novelty aspect by providing a clearer distinction between UDAPDR and existing methods like "promptagator," demonstrating its effectiveness and cost-efficiency. Additionally, it would be beneficial to explore the performance of training a first-stage retrieval model directly using the generated synthetic set. Clarifying the impact of prompt selection on overall performance and providing quantitative results alongside qualitative findings would enhance the paper's persuasiveness. Finally, addressing the computational cost of Flan-T5 XXL and discussing the implications of future hardware advancements on the method's viability would strengthen the paper.