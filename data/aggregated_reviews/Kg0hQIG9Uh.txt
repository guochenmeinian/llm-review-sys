ID: Kg0hQIG9Uh
Title: LLAVIDAL: Benchmarking \underline{L}arge \underline{LA}nguage \underline{VI}sion Models for \underline{D}aily \underline{A}ctivities of \underline{L}iving
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 7, 4, 6, -1, -1, -1
Original Confidences: 3, 3, 3, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel ADL-X dataset that includes human pose, action-related objects, their locations, and trajectories, alongside video descriptions to enhance the performance of LLVM in understanding daily activities of living videos. The authors propose an instruction fine-tuned LLVM called LLAVIDAL, which achieves state-of-the-art performance on these videos. The contributions include curating a multi-view instruction dataset, developing a model based on fine-tuning language vision models, and proposing a benchmark for evaluating understanding of daily activities.

### Strengths and Weaknesses
Strengths:
- The paper identifies a performance gap in current LLVM models for daily activities and creates a scalable ADL-X dataset to address this.
- Thorough experiments demonstrate effective integration of new signals, such as human pose and object trajectories, enhancing the instruction tuning of LLAVIDAL.
- The proposed model outperforms existing video-based LLVM models and is well-written and easy to follow.

Weaknesses:
- The clarity of the writing needs improvement, particularly regarding the definition of the video instruction dataset and its differentiation from similar datasets like Ego4D and HowTo100M.
- The novelty of the approach is considered incremental, as it resembles prior works but is limited to a specific domain.
- Details regarding the semi-automatic labeling process and the structure of the dataset are insufficiently discussed.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing by explicitly defining what constitutes a video instruction dataset and how ADL-X differs from existing datasets. Additionally, the authors should enhance the discussion of related work within the main paper rather than relegating it to supplementary materials. It would be beneficial to provide more details on the semi-automatic labeling process and the dataset's structure. Furthermore, we suggest exploring alternative representations of the skeleton data to better convey semantic information to the language model. Lastly, including example intermediate results from the components would strengthen the paper.