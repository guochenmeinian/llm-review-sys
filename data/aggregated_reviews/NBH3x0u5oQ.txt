ID: NBH3x0u5oQ
Title: MixEdit: Revisiting Data Augmentation and Beyond for Grammatical Error Correction
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents two metrics, Affinity and Diversity, that characterize pseudo data for grammatical error correction (GEC). Based on these metrics, the authors propose a novel data augmentation method called MixEdit, which generates label-preserving grammatical errors and achieves state-of-the-art results on English and Chinese benchmark datasets. The paper aims to understand the optimal conditions for GEC systems benefiting from data augmentation and provides insights into the underlying mechanisms of previous methods.

### Strengths and Weaknesses
Strengths:
- The introduction of interpretable metrics (Affinity and Diversity) provides a statistical perspective on GEC data augmentation.
- The experiments demonstrate the effectiveness of MixEdit across multiple languages, achieving state-of-the-art performance.
- The paper quantifies the relationship between data augmentation metrics and performance, offering valuable insights.

Weaknesses:
- The utility of the proposed metrics is questionable, particularly regarding the inconsistent trend observed with the Diversity metric.
- The paper suffers from clarity issues, including inconsistent notation and a lack of discussion on how MixEdit achieves its metrics.
- The logical flow of the paper is inconsistent, presenting the method and results before discussing the metrics.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by using consistent notation for variables throughout. Additionally, a more thorough exploration of how to quantify "appropriate diversity" is necessary to strengthen the argument regarding the utility of the metrics. We suggest that the authors provide a performance plot to illustrate the sensitivity of MixEdit to hyperparameters alpha and beta. Furthermore, including experiments on other realistic datasets beyond BEA-train would enhance the validity of the findings. Lastly, revisiting the discussion on sampling efficiency mentioned in the introduction would provide a more comprehensive understanding of the proposed method.