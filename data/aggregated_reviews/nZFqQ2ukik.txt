ID: nZFqQ2ukik
Title: Topology Preserving Regularization for Independent Training of Inter-operable Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 4
Original Ratings: 7, 7, 6, -1
Original Confidences: 4, 5, 2, -1

Aggregated Review:
### Key Points
This paper presents a novel solution to the zero-shot stitching problem in neural networks by proposing a topology-preserving regularization method. The authors utilize the "topological loss" from Moor et al. 2020 to enable model-stitching of autoencoders through linear transformations. The methodology is technically sound, employing persistent homology to maintain topological features in latent spaces, which facilitates stitching across independently trained models. The numerical experiments conducted on MNIST and FashionMNIST demonstrate clear benefits over previous methods, although the scalability to more complex tasks remains untested.

### Strengths and Weaknesses
Strengths:  
S1: The use of topological loss to enhance latent representation interpretability and facilitate model stitching is innovative.  
S2: The method achieves an MSE for the stitched model that is close to that of the original non-stitched model.  
S3: Figure 1 effectively illustrates the proposed approach.  

Weaknesses:  
W1: The experiments appear to be based on a single run for each model, raising concerns about reproducibility.  
W2: There is no discussion on the impact of the additional loss on training time; if it does not significantly increase training time, this should be explicitly stated.  
W3: The evaluation is limited to simple datasets, and there is a lack of comparison with other geometric regularizations, which questions the generalizability of the approach to more complex tasks.  

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the training time associated with the additional loss and explicitly state its impact if negligible. Additionally, we suggest providing more comprehensive evaluations on larger, more challenging datasets to strengthen the claims of the paper. Further reasoning on the theoretical foundations of why the approach works would also enhance the manuscript.