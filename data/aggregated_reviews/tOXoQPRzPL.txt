ID: tOXoQPRzPL
Title: An Image is Worth 32 Tokens for Reconstruction and Generation
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 8, 6, 7, 4, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 5, 5, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents TiTok, a novel 1D image tokenization method that significantly reduces the number of tokens needed for image representation compared to traditional 2D approaches. The authors argue that the fixed grid structure of 2D tokenizers limits flexibility and efficiency. TiTok employs a two-stage training strategy using proxy codes from an off-the-shelf MaskGIT-VQGAN model, achieving state-of-the-art performance on the ImageNet 256x256 benchmark with faster generation times. The method demonstrates that as few as 32 tokens can effectively reconstruct images while learning semantic-rich representations.

### Strengths and Weaknesses
Strengths:
1. The innovative use of 1D representation allows for a substantial reduction in token numbers, enhancing training and inference efficiency.
2. Comprehensive experiments validate the method's performance across various model sizes and token counts, showing superior results compared to existing models.
3. The paper is well-structured and accessible, with publicly available codes and models.

Weaknesses:
1. The two-stage training method lacks clarity, particularly regarding the role of proxy codes and the specifics of the warm-up phase.
2. Insufficient analysis of the advantages of 1D tokens over 2D tokens, particularly in terms of masking effects and the implications for generative tasks.
3. The paper does not adequately address the potential limitations of using fewer tokens, such as the loss of information and the ability to encode 2D relationships.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the two-stage training process, specifically detailing how the warm-up phase operates and the implications of using proxy codes. Additionally, we suggest conducting a thorough analysis comparing the advantages and disadvantages of 1D versus 2D tokens, including the effects of masking and potential limitations in information retention. Finally, providing more visual examples of generated images could enhance the reader's understanding of the model's capabilities and diversity.