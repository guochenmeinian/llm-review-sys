ID: In4L79U5n7
Title: $\textit{``Don't Take This Out of Context!''}$ On the Need for Contextual Models and Evaluations for Stylistic Rewriting
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the significance of contextual modeling for stylistic rewriting generation and evaluation, proposing a new evaluation metric, CtxSimFit. The authors demonstrate that human preferences align more closely with contextual rewrites compared to non-contextual ones, and they explore various rewriting tasks across different contexts. The evaluation of existing metrics reveals a lack of correlation with human judgment, underscoring the need for context in both rewriting and evaluation stages.

### Strengths and Weaknesses
Strengths:
- The paper introduces the concept of contextual style transfer, which aligns better with human preferences than previous non-contextual approaches.
- It thoroughly investigates non-contextual evaluation metrics, revealing their lack of correlation with human annotations and proposing improvements through context integration.
- The CtxSimFit metric, which considers semantic similarity and cohesiveness, shows superior results and is a valuable contribution to the evaluation community.
- The paper is well-organized, clearly written, and features informative tables and figures.
- The experimentation is sound, covering three tasks with extensive analysis.

Weaknesses:
- There is a lack of empirical validation regarding the sensitivity of the CtxSimFit metric to the relative weight hyperparameter alpha.
- Insufficient evidence supports the claim that existing automatic text revision metrics are not correlated with human preference beyond specific evaluations of formality, toxicity, and sentiment.
- The choice of large language models (LLMs) and in-context learning is not adequately justified, raising questions about their applicability to smaller models.
- Definitions of formal linguistic concepts such as "Coherence" and "Cohesiveness" are unclear.
- There is a need for clarification regarding the NSP head and the rationale for setting alpha to 0.5 in the formula.

### Suggestions for Improvement
We recommend that the authors improve the empirical validation of the CtxSimFit metric's sensitivity to the hyperparameter alpha and provide a theoretical exploration of its underlying meaning. Additionally, we suggest offering clearer evidence to support claims regarding the correlation of existing metrics with human preferences beyond specific tasks. The authors should clarify their choice of LLMs and in-context learning, ensuring the applicability of their findings to smaller models. We also recommend providing precise definitions for "Coherence" and "Cohesiveness," and offering further clarification on the NSP head and the rationale behind the choice of alpha in their formula.