ID: PKcCHncbzg
Title: Relationship Prompt Learning is Enough for Open-Vocabulary Semantic Segmentation
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 4, 7, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Relationship Prompt Network (RPN) aimed at open-vocabulary semantic segmentation (OVSS), which extends the capabilities of existing vision-language models (VLMs) like CLIP to pixel-level predictions. The authors claim that RPN achieves state-of-the-art performance with significantly fewer parameters (approximately 3M) compared to other methods. The proposed RPN integrates a Relationship Prompt Module (RPM) to enhance image-text correlations and employs various training techniques, including mixture-of-experts and prompt learning. Experimental results indicate that RPN outperforms several existing methods, such as ZegCLIP, MaskCLIP, and FreeSeg.

### Strengths and Weaknesses
Strengths:
- **Performance.** The proposed RPN outperforms several published methods, including ZegCLIP, MaskCLIP, and FreeSeg.
- **Inference efficiency.** RPN is trained with fewer learnable parameters and demonstrates reduced computation in FLOPs during inference.

Weaknesses:
- **Unclear unique contributions.** The paper does not clearly articulate its unique contributions to the field, as the techniques employed are combinations of existing methods without significant new insights.
- **Presentation issues.** Numerous typos and unclear claims detract from the paper's clarity, including ambiguous terminology and insufficient explanations of figures and tables.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their unique contributions by explicitly stating how their approach differs from existing methods and providing theoretical or empirical justifications for their claims. Additionally, addressing the numerous typos and confusing claims is essential for enhancing the paper's presentation. We suggest including a more detailed discussion on the relationship between the model's relational abilities and its performance in open-vocabulary tasks, as well as conducting ablation studies on hyper-parameters and the selection of experts in the mixture-of-experts framework. Finally, providing clearer explanations and legends for figures and tables would significantly enhance the reader's understanding.