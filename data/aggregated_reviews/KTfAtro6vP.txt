ID: KTfAtro6vP
Title: Reinforcement Learning with Fast and Forgetful Memory
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 4, 8, 7, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 2, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new memory model for reinforcement learning agents, called Fast and Forgetful Memory (FFM), specifically designed for partially observable Markov decision processes (POMDPs). The memory aggregates past data using an exponentially weighted summation with learnable parameters, enabling the computation of the Markov state through advanced gating mechanisms. The authors evaluate FFM on two POMDP benchmarks, demonstrating improvements over baseline models like GRU.

### Strengths and Weaknesses
Strengths:
- The memory design is inspired by computational psychology, providing a novel approach to memory in reinforcement learning.
- FFM is lightweight and efficient, with a well-explained theoretical foundation and extensive empirical analysis.

Weaknesses:
- The novelty of the approach is questionable, as the main contribution (Eq. 11) closely resembles Eq. 1 from prior work. The performance of non-learned decay also raises doubts about the necessity of learning the decay.
- The literature review lacks consideration of memory-augmented neural networks (MANN) specifically designed for reinforcement learning, which would provide a more relevant comparison.
- Experimental results are not convincing, with unclear performance differences between FFM and GRU, and the ablation study suggests limited performance gains from the complex design.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their contribution by clearly distinguishing FFM from existing models, particularly in terms of the learnable decay mechanism. Additionally, we suggest including comparisons with MANNs tailored for reinforcement learning, rather than general memory models. To strengthen the experimental validation, consider testing FFM on well-established RL benchmarks like MuJoCo and Atari, and provide a more thorough ablation study to justify the design choices, particularly regarding the necessity of the exponential decay mechanism and the outer product architecture. Lastly, clarify the inductive biases and their relevance to both RL and supervised learning contexts.