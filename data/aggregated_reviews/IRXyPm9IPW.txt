ID: IRXyPm9IPW
Title: Multimodal Large Language Models Make Text-to-Image Generative Models Align Better
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 6, 7, 4, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents VisionPrefer, a large-scale, high-quality, and fine-grained preference dataset designed to enhance text-to-image generative alignment. The dataset incorporates multiple preference aspects, including prompt-following, aesthetic, fidelity, and harmlessness, and is annotated using multimodal large language models (MLLMs). The authors propose a reward model, VP-Score, which demonstrates competitive correlation with human preferences. The experimental results validate the effectiveness of both VisionPrefer and VP-Score.

### Strengths and Weaknesses
Strengths:  
1. The use of MLLMs as human-aligned preference annotators for text-to-image generation is a reasonable and innovative approach.  
2. VisionPrefer's comprehensive annotations contribute to generating images that align more closely with human preferences.  
3. The fine-tuned text-to-image generation model shows improved performance across various aspects due to fine-grained feedback.  
4. The paper is well-organized and presents substantial experiments and analyses.

Weaknesses:  
1. The qualitative results demonstrating the benefits of fine-grained feedback could be complemented with quantitative metrics.  
2. Annotations for VisionPrefer are only available in the appendix, which could be more intuitively presented in the main paper.  
3. VP-Score exhibits slower convergence compared to other baselines, raising questions about its efficiency and practicality; the authors should investigate this issue.  
4. Despite its scale, VisionPrefer does not consistently improve performance across all datasets, suggesting potential limitations in the annotation design or preference modeling approach.

### Suggestions for Improvement
We recommend that the authors improve the paper by providing quantitative metrics to support qualitative findings regarding fine-grained feedback. Additionally, including examples of annotations in the main text would enhance clarity. The authors should investigate the reasons behind VP-Score's slower convergence and suggest optimizations to improve its efficiency. Furthermore, a detailed analysis of the inconsistencies in performance across different datasets is necessary, along with a breakdown of strengths and weaknesses to better align with human preferences.