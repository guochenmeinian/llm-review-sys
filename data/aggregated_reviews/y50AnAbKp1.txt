ID: y50AnAbKp1
Title: CSOT: Curriculum and Structure-Aware Optimal Transport for Learning with Noisy Labels
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 6, 5, 6, 7, 5, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 4, 5, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel formulation of Optimal Transport (OT), termed Curriculum and Structure-Aware Optimal Transport (CSOT), aimed at addressing noisy label learning. The authors propose a method that incorporates both inter- and intra-distribution structures of samples to enhance pseudo-label generation. Additionally, they introduce an efficient computational method for CSOT, demonstrating superior performance on various benchmarks compared to existing methods.

### Strengths and Weaknesses
Strengths:
1. The paper introduces a novel OT formulation that provides a fresh perspective on noisy label learning.
2. It effectively considers both global and local structures of sample distributions, which may lead to improved performance.
3. The proposed method shows strong empirical results across different datasets, validating its effectiveness.

Weaknesses:
1. The novelty of the proposed method is limited as it primarily applies existing OT-based pseudo-labeling strategies to noisy label learning without significant innovation.
2. The loss function lacks clear innovation, relying on existing terms and failing to reflect the method's integrity.
3. The paper does not adequately address the alignment of global and local structures, and the ablation studies presented are not convincing.
4. The structure of the article is confusing, which may weaken its contribution, and the introduction of key concepts is abrupt.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the loss function to better reflect the integrity of their method and highlight its innovative aspects. Additionally, we suggest providing a more detailed ablation study to clarify the contributions of the prediction-level and label-level constraints. To enhance the paper's structure, consider a clearer presentation of the methodology and the overall training process, including how the proposed methods are integrated at each training epoch. Finally, we encourage the authors to include comparisons with baseline algorithms such as UNICON and to analyze the sensitivity of hyperparameters to strengthen their findings.