ID: i0RfSS9CUU
Title: Active Learning Principles for In-Context Learning with Large Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a systematic study of various methods for selecting exemplars for in-context learning (ICL) in few-shot learning, focusing on model family, size, task type, and evaluation metrics. The authors analyze methods based on active learning principles, specifically uncertainty, diversity, similarity, and random sampling. Key findings indicate that 1) semantically similar samples yield the best performance, 2) diversity shows promise, and 3) uncertain samples do not enhance performance for smaller models, although larger models may benefit from them. The study contributes to understanding ICL selection and provides a thorough empirical analysis.

### Strengths and Weaknesses
Strengths:
- The paper is clearly written and addresses an important problem in the context of large language models (LLMs).
- The experiments and analyses are well-designed, enhancing confidence in the findings.
- The results are relevant and could serve as a reference for future research.

Weaknesses:
- The novelty of the findings is questionable, as many results confirm previously established knowledge, particularly regarding similarity and diversity.
- The use of different clustering methods for diversity and similarity may obscure proper assessment.
- Contradictory conclusions arise from varying evaluation metrics, indicating a need for further investigation into optimal combinations of exemplars.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their contributions by explicitly differentiating their approach from existing literature, particularly regarding the novelty of treating ICL selection as an active learning problem. Additionally, we suggest conducting an ablation study comparing SentenceBERT embeddings with modern alternatives like SimCSE and DiffCSE to understand their impact on similarity results. It would also be beneficial to explore how varying the number of demonstrations \( k \) affects the performance of the studied methods and to clarify the implications of contradictory findings across different metrics. Finally, consider developing a novel selection procedure that optimally combines similarity and diversity principles.