ID: XhNlBvb4XV
Title: Deep Insights into Noisy Pseudo Labeling on Graph Data
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 5, 5, 7, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an in-depth analysis of pseudo labeling (PL) within graph learning models, focusing on error bounds and convergence properties. The authors propose a cautious pseudo labeling methodology that assigns labels based on confidence and multi-view consistency. Extensive experiments validate that this strategy enhances graph learning, outperforming alternative PL methods in link prediction and node classification tasks.

### Strengths and Weaknesses
Strengths:
1. The paper provides a theoretical analysis of how the PL strategy affects convergence properties in graph neural networks (GNN).
2. The proposed cautious pseudo labeling methodology is supported by extensive experimental validation, demonstrating its effectiveness.
3. The error bound analysis is practical and useful for understanding the implications of noisy labels in graph training.

Weaknesses:
1. There may be inaccuracies in Theorem 2.5 regarding the covariance between the cross-entropy loss and the PL strategy.
2. The clarity of the paper is hindered by unclear notation and numerous typographical errors.
3. The analysis and conclusions presented are somewhat general and not specifically tailored to graph contexts, and the novelty of the proposed solutions is questioned.
4. Additional experiments are necessary to evaluate performance across various configurations and sample sizes, particularly in link prediction.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by addressing unclear notation and correcting typographical errors. Additionally, we suggest providing more details on the multi-view teachers, including the types of data augmentation used. It would be beneficial to include a performance comparison with previous PL methods in link prediction tasks and to clarify the assumptions made when applying the proposed approach to benchmark datasets. Finally, we encourage the authors to explore the applicability of their methodology to datasets with imbalanced class distributions or varying noise types.