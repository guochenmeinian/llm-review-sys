ID: vXnGXRbOfb
Title: Towards Open Respiratory Acoustic Foundation Models: Pretraining and Benchmarking
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 7, 7, 5, 6, -1, -1, -1, -1
Original Confidences: 3, 5, 3, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents OPERA, an open respiratory acoustic foundation model that includes a comprehensive analysis of respiratory sounds such as coughing and breathing. The authors constructed a large-scale respiratory audio dataset (136K samples, 440 hours) and benchmarked the model on 19 downstream tasks, demonstrating its effectiveness and superiority over existing models in the field.

### Strengths and Weaknesses
Strengths:
- The paper has a clear motivation and solid data curation process.
- The evaluation across a wide range of health tasks is comprehensive and commendable.
- The curated dataset is extensive, providing a robust foundation for model training.
- The pretrained models outperform existing models on 16 out of 19 tasks, indicating their effectiveness and potential for real-world applications.

Weaknesses:
- The scale of the dataset is insufficient for a true foundation model, lacking detailed demographic and medical condition information.
- There is no evaluation of zero-shot capabilities in the proposed benchmark.
- A more detailed analysis of model performance on unseen tasks is necessary to assess learned features and biases.
- The comparison with existing audio foundation models lacks fairness due to differences in training data and architecture.

### Suggestions for Improvement
We recommend that the authors improve the analysis of model performance on unseen tasks to understand the credibility of predictions and potential biases. Specifically, they should address why the performance of OPERA-CT is low on the lung function estimation task compared to the GT variant. Additionally, a more equitable comparison with existing audio foundation models should be made by training them on the same dataset used for the proposed models. 

We suggest that the authors consider revising the terminology from "foundation models" to "pre-trained models" to better reflect the model size, as the current model has fewer than 100M parameters. Furthermore, the authors should provide a thorough explanation of the demographics and range of medical conditions represented in the dataset, including a discussion on how to mitigate biases against under-represented individuals. Finally, all data should be consolidated into a single, permanent repository to ensure accessibility and compliance with open science principles.