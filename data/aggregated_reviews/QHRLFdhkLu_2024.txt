ID: QHRLFdhkLu
Title: Reference Trustable Decoding: A Training-Free Augmentation Paradigm for Large Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Reference Trustable Decoding (RTD), a novel paradigm that enables large language models (LLMs) to adapt to new tasks without fine-tuning, while also reducing inference costs compared to in-context learning (ICL). RTD constructs a reference datastore from training examples and optimizes the LLM’s final vocabulary distribution by retrieving relevant samples based on the last-hidden states of the input. Experimental results demonstrate RTD's effectiveness across various benchmarks, indicating its potential as a new method for enhancing LLM performance.

### Strengths and Weaknesses
Strengths:  
1. The proposed method is well-motivated, addressing the limitations of ICL and fine-tuning in model adaptation. The paper is clearly written, with effective visual aids such as Figure 2.  
2. Comprehensive experimental evaluations showcase RTD's effectiveness across multiple tasks, highlighting its potential for combined usage with traditional methods.  
3. The methodology is clearly explained, and the authors provide a thorough analysis of hyperparameters and their impact on performance.  

Weaknesses:  
1. The description of RTD's application in language generation tasks is unclear, particularly regarding how retrieved samples adapt the vocabulary distribution after the first token.  
2. Performance gains appear unstable, with some datasets showing RTD underperforming compared to 5-shot ICL. The paper lacks a discussion on the specific tasks for which RTD is suitable.  
3. A detailed comparison with baseline methods is missing, particularly regarding the selection process for examples in “5-shot ICL.” This is crucial for understanding the advantages of leveraging the last hidden state space.  

### Suggestions for Improvement
We recommend that the authors improve the clarity of RTD's application in language generation tasks, particularly how the method adapts vocabulary distribution during autoregressive generation. Additionally, the authors should discuss the specific tasks for which RTD is most effective and provide a more detailed comparison with baseline methods, including the selection criteria for examples in “5-shot ICL.” Finally, addressing the challenges of compressing large reference datastores and providing potential solutions would enhance the paper's robustness.