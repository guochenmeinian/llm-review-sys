ID: n5R6TvBVcX
Title: WildTeaming at Scale: From In-the-Wild Jailbreaks to (Adversarially) Safer Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 6, 5, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents WILDTEAMING, an automatic red-teaming framework that mines user-chatbot interactions to identify novel jailbreak tactics against large language models (LLMs). The authors propose a scalable method for generating synthetic safety training data, resulting in WILDJAILBREAK, a large-scale open-source synthetic safety dataset containing 262K prompt-response pairs aimed at enhancing model safety. They demonstrate the interplay of data properties and model capabilities during safety training, showing that WILDJAILBREAK improves model safety without compromising general capabilities. The work differentiates itself from existing benchmarks by providing larger-scale, higher-quality sequential instruction-tuning data that includes both harmful and benign queries, addressing the limitations of prior safety training resources.

### Strengths and Weaknesses
Strengths:
1. The originality of WILDTEAMING in mining jailbreak tactics from real-world interactions and composing them into diverse attacks is commendable.
2. The creation of WILDJAILBREAK as an open-source resource significantly contributes to safety training, providing a balanced dataset of harmful and benign queries.
3. The methodology is rigorous, with thorough evaluations and comparisons to multiple strong baselines, demonstrating the effectiveness of the approach.
4. The authors effectively address reviewer concerns and demonstrate a commitment to improving their work based on feedback.
5. WildTeaming's approach to generating diverse adversarial attacks is innovative and grounded in real-world data, enhancing the robustness of model safety evaluations.

Weaknesses:
1. The paper lacks sufficient details on how tactics are selected for constructing final jailbreak prompts, raising questions about the semantic rationality of the constructed prompts.
2. Some evaluation metrics, particularly the similarity-based metric for diversity, are vague and require further justification to prove their rationality.
3. The ethical implications of releasing a dataset of harmful queries and the potential for misuse are not adequately addressed.
4. The reliance on automated methods may overlook certain nuanced vulnerabilities that manual approaches could identify.
5. The evaluation framework primarily focuses on specific harmful responses, potentially limiting the exploration of diverse harm categories.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the methodology by providing detailed explanations of how tactics are selected for constructing jailbreak prompts. Additionally, we suggest including a dedicated section on ethical considerations, addressing potential misuse of the WILDJAILBREAK dataset and safeguards implemented to prevent unintended harm. Furthermore, conducting a comparative study between WILDTEAMING-generated jailbreaks and those created by human experts could provide valuable insights into the effectiveness of the approach. We also recommend expanding the discussion on the limitations of automated methods in capturing nuanced vulnerabilities and ensuring that the results of the new defense baselines and the discussion of internal and external defenses are thoroughly integrated into the final manuscript to enrich the overall contribution. Lastly, we encourage the authors to analyze the effectiveness of different jailbreak tactic categories across various model architectures to identify patterns in model vulnerabilities.