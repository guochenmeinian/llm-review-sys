ID: LJ4CYEagg3
Title: Spatially-Guided Temporal Attention (SGuTA) and Shifted-Cube Attention (SCubA) for Video Frame Interpolation
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 4, 5, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 2, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents two transformer architectures, Spatially-Guided Temporal Attention (SGuTA) and Shifted-Cube Attention (SCubA), aimed at improving video frame interpolation (VFI) by addressing computational complexity and memory requirements. The authors conduct extensive experiments demonstrating that these methods achieve state-of-the-art results in terms of peak signal-to-noise ratio (PSNR) while maintaining a reduced parameter count. SGuTA introduces a novel approach for self-attention computation in VFI, utilizing $head_j=V_j softmax({Q^T_jK_j \over d})$ instead of the conventional $head_j=softmax({{Q}_j{K}_j^T \over d})V_j$. This method effectively captures cross-dimensional recurrence, enhancing performance in linear motion scenarios while demonstrating adaptability across various motion types. The authors also introduce a half-overlapping embedding strategy to balance computational efficiency and memory usage, acknowledging the need for more qualitative results and general conclusions.

### Strengths and Weaknesses
Strengths:
- The proposed attention mechanisms enhance interpolation quality and exhibit linear computational complexities, making them deployable.
- The paper provides a clear motivation for modifying transformers for VFI tasks and presents comprehensive experimental results that support the effectiveness of the proposed methods.
- SGuTA shows adaptability across different motion scenarios, particularly excelling in linear motion.
- The authors have open-sourced the relevant code, contributing to reproducibility.

Weaknesses:
- The paper lacks significant theoretical contributions and does not adequately position the proposed methods within the existing literature, leading to confusion regarding the necessity of both SGuTA and SCubA.
- Experimental comparisons are limited and potentially unfair, as they do not follow standard protocols used in previous VFI works, raising questions about the validity of performance claims.
- The paper lacks sufficient qualitative results and general conclusions to fully support its claims.
- The explanation of the inference and training processes may be confusing for some readers.
- The writing requires improvement for clarity, particularly in the methodology section, and the introduction of new acronyms in the title is discouraged.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the introduction by positioning their work relative to existing literature on transformer architectures for VFI, thereby justifying the need for both SGuTA and SCubA. Additionally, the authors should provide a more comprehensive evaluation by including comparisons with recent works on single-frame interpolation and addressing the fairness of their experimental setups. It would be beneficial to clarify the specific contributions of SGuTA and SCubA, possibly by discussing scenarios where each method is preferable. Furthermore, we suggest that the authors include inference time comparisons for all evaluated methods to provide a more holistic assessment of performance and computational efficiency. Lastly, the authors should consider revising the methodology section for better clarity and coherence, avoiding the introduction of new acronyms in the title, and enhancing the descriptions of the inference and training processes to improve reader comprehension. Including more qualitative results and general conclusions would also substantiate the claims made regarding SGuTA's performance across various motion scenarios.