ID: 9CMOrofB75
Title: Evaluating the design space of diffusion-based generative models
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 5, 6, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper analyzes the training and sampling errors of diffusion models, focusing on noise level weighting during training and discretization during sampling. The authors propose theoretical bounds on training error and sample complexity, providing insights into hyper-parameter selection and convergence analysis. Notably, the work extends previous results in the literature, particularly regarding variance-preserving and variance-exploding cases. Additionally, the authors adapt existing tools to theoretically guarantee the generation capability of diffusion models, specifically addressing the denoising score matching problem. They clarify that while the sampling process has been well-studied, the integration with score training remains unresolved due to unique properties of the input and output data structures. The authors emphasize the need for new techniques to address these challenges, particularly in relation to the non-interpolation nature of the model and specific scaling requirements of the data. They provide a qualitative analysis of error bounds influenced by various hyperparameters, data distributions, and network structures, while acknowledging the limitations of their current approach.

### Strengths and Weaknesses
Strengths:
- The paper presents a clear qualitative analysis of noise level schedules, particularly in Figure 1, and is the first theoretical work to adapt sampling discretization schedules based on training score errors.
- The convergence analysis is comprehensive and aligns with existing literature, offering beneficial insights for hyper-parameter selection.
- The paper offers a novel theoretical framework for analyzing diffusion models, addressing previously uncombined aspects of sampling and score training.
- The authors provide a detailed explanation of the unique challenges posed by the denoising score matching problem, enhancing the understanding of their contributions.
- The rebuttal effectively clarifies several complex points, leading to improved reviewer satisfaction and increased scores.

Weaknesses:
- The theoretical results are complex and difficult to interpret, lacking clear practical guidance. The connection between theoretical findings and practical design choices appears tenuous.
- Some claims lack substantiation, such as the assertion regarding the NTK's applicability and the implications of Theorems 1 and 2.
- The dependence of the upper bound on hyperparameters, model capacity, and sample size remains unclear, particularly regarding the independence from network depth and width as iterations increase.
- The proof sketch for the improved theorem is not sufficiently detailed, which may hinder verification of correctness.
- The qualitative nature of the error analysis may limit practical applicability, as it does not provide concrete comparisons between schedules.
- The paper does not adequately discuss limitations, particularly regarding generalization errors and the assumptions made about network architecture.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their theoretical results by providing informal versions that highlight key qualitative features. Simplifying the derived bounds to summarize core algebraic dependencies on hyper-parameters would enhance readability. Additionally, including experimental validation to support theoretical claims, particularly regarding exponential convergence, would strengthen the paper. We also suggest addressing the limitations more thoroughly, particularly the implications of the high-dimensional data assumption and the lack of a discussion section. Clarifying the relationship between empirical and population losses, as well as the application of the central limit theorem, would be beneficial. Furthermore, we recommend improving the clarity of the dependence on hyperparameters in the upper bound, particularly how model capacity and sample size influence the results. Providing a more intuitive proof sketch for the improved theorem to facilitate verification would also be advantageous. Lastly, including a dedicated limitations paragraph in the next version, discussing the constraints of the current model architecture and the focus on optimization and sampling errors without addressing generalization errors, would enhance the paper's comprehensiveness.