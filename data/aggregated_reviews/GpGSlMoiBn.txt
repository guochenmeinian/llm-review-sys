ID: GpGSlMoiBn
Title: Ask Me in English Instead: Cross-Lingual Evaluation of Large Language Models for Healthcare Queries
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents XLingEval, a framework for evaluating large language models (LLMs) in healthcare queries across multiple languages. The authors propose three fundamental criteria for assessment: correctness, consistency, and verifiability. Through extensive experiments involving four major languages (English, Spanish, Chinese, and Hindi) and three expert-annotated health Q&A datasets, the study reveals significant disparities in LLM performance, highlighting the need for improved cross-lingual capabilities. Additionally, the paper introduces XLingHealth, a cross-lingual benchmark for evaluating LLMs in the healthcare context, emphasizing the importance of equitable access to healthcare information.

### Strengths and Weaknesses
Strengths:
- The research quantifies language disparities in LLM performance, crucial for understanding challenges related to linguistic diversity.
- The paper provides a universal multilingual LLM measurement framework, with open-source code contributing to the field.
- The focus on correctness, consistency, and verifiability offers a comprehensive approach to assessing LLMs in healthcare.

Weaknesses:
- The paper does not clearly differentiate XLingEval from existing cross-language measurement frameworks like XNLI, MLQA, XTREME, and XGLUE.
- The scope is limited to the medical field, raising questions about the broader applicability of the term 'medical' and its potential extension to other domains.
- Human validation is only applied to the correctness criterion, which could benefit from similar validation for consistency.

### Suggestions for Improvement
We recommend that the authors improve the differentiation of XLingEval from other existing frameworks by providing a detailed comparison. Additionally, consider expanding the scope of the research beyond healthcare to explore its applicability in other critical domains. We suggest incorporating human validation for the consistency criterion to enhance the robustness of the findings. Finally, we encourage the authors to clarify the motivation behind selecting correctness, consistency, and verifiability as key metrics, potentially by referencing prior work in the field.