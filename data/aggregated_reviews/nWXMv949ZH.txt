ID: nWXMv949ZH
Title: Logic-LM: Empowering Large Language Models with Symbolic Solvers for Faithful Logical Reasoning
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework that integrates large language models (LLMs) with symbolic solvers to enhance logical problem-solving capabilities. It incorporates a self-refiner in the reasoning process to iteratively refine valid logic forms, with the final answer derived from a result interpreter. The method is evaluated on four datasets, demonstrating its effectiveness in logical reasoning tasks.

### Strengths and Weaknesses
Strengths:
- The experimental results indicate significant improvements over standard and chain-of-thought (CoT) settings across multiple models and datasets.
- The paper is well-written and clearly structured, making it easy to follow the proposed methodology.
- The neurosymbolic approach effectively separates the roles of the language model and the symbolic solver, potentially inspiring future research.

Weaknesses:
- The originality of parsing natural language into symbolic forms is questionable, as it resembles existing autoformalization tasks in mathematical reasoning.
- The complexity of the first-order logic (FOL) representation may hinder understanding and debugging of the pipeline.
- The reliance on synthetic datasets raises concerns about the generalizability of the findings to more complex, real-world applications.

### Suggestions for Improvement
We recommend that the authors improve the clarity of how to select and designate from the three sets of grammar (deductive reasoning, first-order logic, and constraint optimization) for specific reasoning questions. Additionally, the authors should address how the framework deals with error propagation and provide a more in-depth analysis of the performance on datasets like Entailmentbank. Including examples of the benefits of self-refinement and clarifying the potential applications of the FOL representation would also enhance the paper's impact. Finally, we suggest incorporating comparisons with few-shot methods and off-the-shelf text-to-symbolic formulating approaches to strengthen the experimental evaluation.