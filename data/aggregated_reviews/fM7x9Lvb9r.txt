ID: fM7x9Lvb9r
Title: Controllable Contrastive Generation for Multilingual Biomedical Entity Linking
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to multilingual biomedical entity linking (MBEL) by framing the task as a generative sequence-to-sequence problem. The authors propose a prompt-based controllable contrastive generation framework that summarizes multidimensional UMLS information into natural language sentences. Their method includes contrastive learning and ablation studies, demonstrating improved performance over state-of-the-art (SOTA) models across multiple datasets. However, the paper lacks clarity in certain areas, particularly regarding the novelty of the generative approach and the specifics of the Trie tree-based decoding.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant problem in MBEL and proposes an innovative framework that combines several techniques.
- Experimental results indicate improved performance over baseline models, supported by thorough evaluations across multiple datasets.
- The approach leverages summarization to enhance entity linking across various languages.

Weaknesses:
- The novelty of the generative approach in biomedical entity linking is not adequately justified, as similar concepts exist in prior work.
- Key methodological details, such as the implementation of the Trie tree decoding and the rationale for combining constative loss with NLL, are unclear.
- The evaluation is based on a limited subset of data, raising questions about the significance of the reported results.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their methodology, particularly regarding the Trie tree-based decoding and the modifications made to UMLS. Additionally, the authors should provide a more robust justification for the combination of constative loss and NLL, and clarify whether indirect and uninformative examples are introduced by their method. We suggest expanding the evaluation to include the entire XL-BEL dataset and providing more detailed statistics on training and validation data. Furthermore, we encourage the authors to explore different configurations of their model, such as the performance of models without controllable decoding and the mapping of outputs to CUIs. Lastly, addressing the related work more comprehensively would strengthen the paper's contributions.