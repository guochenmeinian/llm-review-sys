ID: ja20BpFAPa
Title: DC-Gaussian: Improving 3D Gaussian Splatting for Reflective Dash Cam Videos
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 6, 5, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for reconstructing 3D Gaussian Splatting (3DGS) from dash cam videos, addressing challenges posed by obstructions on windshields. The authors propose an adaptive image decomposition to separately model transmission and obstruction images, with the former represented in 3DGS and the latter in 2D space, conditioned by car positions. An optimized opacity map is used to blend these images, demonstrating superior performance compared to existing methods like Zip-NeRF and 3DGS across various datasets.

### Strengths and Weaknesses
Strengths:
- Originality: The paper tackles a novel problem of reconstructing driving scenes from dash cam footage, a setting that has been largely overlooked.
- Quality: Results indicate high rendering quality and effective decomposition of transmission and obstruction images.
- Clarity: The manuscript is well-structured and easy to follow, with clear diagrams.

Weaknesses:
- The opacity map's independence from car position contradicts Fresnel's law, which relates opacity to light distribution.
- The observations in Section 3.3 may overly constrain the algorithm's generalization capabilities.
- The novelty of the method is moderate, as it incorporates components from existing works.
- The evaluation lacks clarity regarding datasets, including the number of scenes, frame counts, image quality, and dynamic objects present.

### Suggestions for Improvement
We recommend that the authors improve the modeling of the opacity map to account for car position and light distribution, enhancing its realism. Additionally, we suggest clarifying the opacity loss calculation in Eq. 8 and providing visualizations related to the reconstructed 3DGS. It would be beneficial to include more comprehensive details about the evaluation datasets, such as scene diversity and dynamic elements. Lastly, we encourage the authors to present a comparison of rendering speeds against baseline methods to better assess practical applicability.