ID: 4AuEQ1FfUf
Title: How Does Black-Box Impact the Learning Guarantee of Stochastic Compositional Optimization?
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 5, 7, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 2, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a systematic analysis of the generalization error and optimization error for stochastic compositional optimization problems, specifically in black-box cases. The authors propose generalization upper bounds for two methods, SCGD and SCSC, under both convex and non-convex settings, establishing the first generalization bound in the SCO literature for non-convex cases. Additionally, the paper discusses the zeroth-order extension of SCGD/SCSC, providing new insights into their excess risk bounds.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and organized, making it easy to follow.
2. It provides a systematic generalization and optimization analysis for stochastic compositional optimization problems, with convergence rates for various black-box cases.
3. The results include a significantly sharper generalization bound for SCGD and SCSC compared to existing work, and the analysis of how estimation distance and the number of estimation directions affect the excess risk bound is noteworthy.

Weaknesses:
1. The technical challenge of extending the theoretical analysis from white-box to black-box cases is not clearly discussed, particularly regarding the key technical tools employed.
2. Assumption 5 for non-convex analysis appears overly strong, as it implies that any stationary point is a global optimal point.
3. Inconsistencies in Table 2 regarding the optimization bounds for black-box methods create confusion, particularly concerning omitted terms involving \(T, n, m\).
4. The proofs for Theorems 3 and 4 are nearly identical, leading to redundancy that could be reduced for clarity.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the technical challenges of extending the theoretical analysis from white-box to black-box cases, specifically detailing the key technical tools used. Additionally, we suggest revisiting Assumption 5 to evaluate its strength in the context of non-convex analysis. Clarifying the discrepancies in Table 2 regarding the optimization bounds and ensuring consistent notation would enhance understanding. Finally, we encourage the authors to reduce redundancy in the proofs of Theorems 3 and 4, highlighting the main differences to improve readability.