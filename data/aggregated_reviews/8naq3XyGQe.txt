ID: 8naq3XyGQe
Title: Choose Your Anchor Wisely: Effective Unlearning Diffusion Models via Concept Reconditioning
Conference: NeurIPS
Year: 2024
Number of Reviews: 4
Original Ratings: 7, 7, 7, 8
Original Confidences: 4, 3, 3, 5

Aggregated Review:
### Key Points
This paper presents "concept reconditioning" as a method for "unlearning" knowledge in diffusion models, aiming to remove information while preserving utility. The authors propose a novel objective function for unlearning, where the noise estimator in the diffusion model aligns with noise associated with an "alternative" concept. Empirical evaluations on the UnlearnCanvas benchmark demonstrate improvements over existing unlearning baselines, supported by ablation studies and sensitivity analyses that validate the loss formulation and alternative concept selection strategy.

### Strengths and Weaknesses
Strengths:
* The method CORE utilizes noise predicted by a pre-trained model to compute unlearn and retain loss, distinguishing it from previous methods.
* The experiments on the UnlearnCanvas dataset effectively demonstrate the proposed method's effectiveness.
* The paper is well-written, with clear explanations of preliminaries and logical design choices.

Weaknesses:
* The paper lacks a principled explanation for using a noise predictor from the pre-trained model as the target.
* There is no evaluation of the method's efficiency compared to others, despite claims of efficiency.
* The objective in Eq. 2 is unclear regarding its appropriateness for unlearning, raising concerns about the potential for generating images from the "forget" concept.
* The use of retaining data $\mathcal{D}_r$ raises privacy concerns that could undermine the proposed method.

### Suggestions for Improvement
We recommend that the authors improve Figure 1 to visualize the differences between their method and similar ones, highlighting distinctions in objectives. The abstract should be revised to clearly emphasize the novelty of CORE. Additionally, providing a principled explanation for the use of a noise predictor would strengthen the paper. We suggest including an evaluation of the method's efficiency compared to other approaches and adding detailed analyses of catastrophic retaining and unlearning rebound for sequential unlearning. Furthermore, experiments on unlearning multiple styles or objects simultaneously would enhance the study. Lastly, addressing the privacy concerns regarding the use of retaining data $\mathcal{D}_r$ is crucial for the method's viability.