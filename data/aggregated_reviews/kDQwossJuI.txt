ID: kDQwossJuI
Title: Limits, approximation and size transferability for GNNs on sparse graphs via graphops
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 6, 5, 3, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 1, 2, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper analyzes the transferability and approximation qualities of Graph Neural Networks (GNNs) when applied to graphs or Graph Signal Operators (GSOs) sampled from graph limit objects, known as graphops. The authors demonstrate that a sequence of graphs sampled from a graphop converges according to a well-known metric. They introduce graphop neural networks as a tool for analysis, showing that applying a GNN to such sequences yields outputs that converge to those from the graphop neural network applied to the graphop itself. The paper also explores the theoretical perspective of GNN generalization to different graphs, including sparse graphs, and develops quantitative bounds on the distance between finite GNNs and their limits on infinite graphs.

### Strengths and Weaknesses
Strengths:
- The paper presents a novel integration of graphops and GNNs, generalizing results for graphs converging to a graphon.
- It tackles the critical problem of GNN size transferability, with a promising theoretical analysis applicable to real-world sparse graphs.
- The rigorous mathematical proofs support claims and have implications for practical GNN applications.

Weaknesses:
- The quality of writing and presentation is poor, leading to comprehensibility issues; none of the theorems are self-contained, and notational errors are prevalent.
- The assumptions made, such as graphops being self-adjoint yet non-linear, are problematic, and some assumptions appear overly restrictive.
- The paper lacks clear organization, with confusing presentation of assumptions and insufficient discussion of practical implications and real-world applications.

### Suggestions for Improvement
We recommend that the authors improve the clarity and organization of the paper, ensuring that all theorems are self-contained and addressing notational issues. It would be beneficial to clarify the assumptions made, particularly regarding the nature of graphops and the chosen notion of convergence. We suggest including real-world application examples and conducting experiments on synthetic graphs of variable sizes to demonstrate the implications of the theorems. Additionally, a more comprehensive comparison with existing methods and a detailed discussion of the limitations and potential ethical implications of the proposed approach would enhance the paper's contribution.