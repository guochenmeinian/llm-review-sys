ID: KTR33hMnMX
Title: Aligning Optimization Trajectories with Diffusion Models for Constrained Design Generation
Conference: NeurIPS
Year: 2023
Number of Reviews: 20
Original Ratings: 6, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on diffusion models for constrained topology design, introducing Diffusion Optimization Models (DOMs) that utilize a method called "trajectory alignment" (TA) to align predictions from a noise/score estimator with intermediate topologies from a physics-based optimization process. The authors evaluate DOM on optimized topologies using the SIMP solver, demonstrating improvements in quality and efficiency over previous data-driven methods. Additionally, the paper explores conditional and unconditional sampling using DOM with TA, providing distance matrices between samples to illustrate variability and diversity in generated designs. The authors acknowledge the need for further empirical validation of TA's theoretical underpinnings and provide a large dataset capturing 500K intermediate optimization stages and 100K optimized topologies, along with comprehensive experimental results, including in-distribution and out-of-distribution analyses.

### Strengths and Weaknesses
Strengths:
* The subject of generative modeling under constraints is intriguing.
* The introduction of a regularization mechanism (TA) that addresses constrained generative design problems is innovative.
* The concept of aligning the sampling process of a diffusion model with a physics-based trajectory is worth exploring.
* The provision of a large-scale dataset tailored for iterative optimization is a significant contribution.
* The paper demonstrates the efficacy of DOM with TA as a robust generative model, showcasing its ability to generate diverse samples.
* The inclusion of distance matrices provides empirical evidence for the variability in generated designs, supporting the claim that DOM is a proper generative model.
* Comprehensive experimental results enhance the credibility of the findings.

Weaknesses:
* The proposed method lacks mathematical soundness; the modified training objective ($\mathcal{L}_{DOM}$) does not guarantee a proper diffusion model, and the alignment of trajectories with different time axes is questionable.
* The method may only work due to the deterministic nature of the mapping from constraints to optimal topology, leading to a regressive rather than generative task.
* The connection to consistency models is misleading, and the claim that DOM "respects constraints" is unsubstantiated.
* The manuscript contains vague statements and concepts introduced without adequate context, and some sections are verbose and redundant.
* The focus on application details detracts from the methodological contribution, potentially limiting the appeal to a broader machine learning audience.
* There is a lack of theoretical evidence for TA, which raises concerns about the generalizability of the findings beyond the specific context of topology optimization.

### Suggestions for Improvement
We recommend that the authors improve the mathematical justification for the modified training objective and clarify the theoretical foundations of TA. Additionally, the authors should provide a clearer distinction between technical contributions and domain-specific knowledge to enhance readability and accessibility for a broader audience. It would be beneficial to include comparisons against a ground truth solver like SIMP and to demonstrate the generative capabilities of DOM by generating multiple topologies for the same constraints. We suggest including visualizations of both conditional and unconditional samples in the appendix to enhance clarity and understanding. Finally, addressing the concerns regarding the generalizability of the method to other problems would strengthen the paper's impact.