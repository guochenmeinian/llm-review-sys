ID: 3zYmlmkIuK
Title: Asynchronous Multi-Agent Reinforcement Learning with General Function Approximation
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 7, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on multi-agent reinforcement learning (MARL) where agents cooperate through asynchronous communications with a central server to learn a shared environment. The authors propose two algorithms: Asynchronous-NLin-UCB for contextual bandits and Asynchronous-NLSVI-UCB for episodic MDPs, achieving near-optimal regret with low communication complexity. The authors establish a regret bound of $\tilde{O}(\sqrt{\text{dim} T})$ and characterize communication complexity as $\tilde{O}(M^2 \text{dim})$. 

### Strengths and Weaknesses
Strengths:
- The problem of asynchronous MARL with general function approximation is both interesting and important.
- The authors provide a solid theoretical foundation, including proofs and a detailed background on related literature, which aids in understanding their contributions.
- The proposed algorithms generalize previous results under linear settings and introduce a novel communication criterion based on uncertainty estimators.

Weaknesses:
- Some techniques appear derived from previous works, such as the bonus function oracle, necessitating a clearer discussion of technical novelty.
- The relationship to low switching RL and RL with delayed feedback is not adequately explored.
- There are concerns regarding the communication complexity bound in Theorem 5.1, specifically whether it should be $O((1+M\alpha)^2 / \alpha)$ and the choice of $\alpha=1/M$.
- Clarity issues exist regarding the definitions of certain terms and the oracle for computing bonus terms, as well as minor typographical errors.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the technical novelty by explicitly discussing the originality of their methods compared to previous works. Additionally, we suggest that the authors briefly address the connections to low switching RL and RL with delayed feedback. To enhance the communication complexity analysis, please clarify the bounds in Theorem 5.1 and consider the implications of choosing $\alpha=1/M$. Furthermore, we encourage the authors to define all relevant terms clearly, particularly $\tilde{\beta}_1$ and $\tilde{\beta}_2$, and to correct typographical errors noted in the reviews.