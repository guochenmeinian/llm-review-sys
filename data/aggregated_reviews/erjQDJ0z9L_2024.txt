ID: erjQDJ0z9L
Title: Discovering Preference Optimization Algorithms with and for Large Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 6, 6, 7, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DiscoPOP, an algorithm for discovering preference optimization loss functions using Large Language Models (LLMs). The authors propose an LLM-driven objective discovery process that iteratively prompts LLMs with previously evaluated performance metrics. Experiments demonstrate that DiscoPOP achieves higher evaluation scores than existing objectives across various benchmarks, indicating its effectiveness.

### Strengths and Weaknesses
Strengths:
- The method is innovative, automating the exploration and updating of loss functions, which is both interesting and novel.
- DiscoPOP shows impressive results across multiple benchmarks, highlighting its potential for effective objective function discovery.
- The paper is well written, organized, and easy to understand, with interesting insights into the discovered objective functions.

Weaknesses:
- The paper lacks clarity regarding the main results it aims to present, leading to confusion about its focus on either the discovery method or the properties of DiscoPOP.
- Insights into DiscoPOP are primarily presented as hypotheses, lacking sufficient experimental support to substantiate claims about optimality.
- The discovery method's details are vague, particularly regarding the frequency of objective refinement versus regurgitation, which requires further investigation.
- The alignment between the discovered objective function and the evaluation process is misaligned, which could affect the validity of the results.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by explicitly stating whether the focus is on the discovery method or DiscoPOP's properties. If DiscoPOP is the focus, the authors should provide more rigorous studies on its properties. Additionally, further experimentation is necessary to support claims about the optimality of the discovered objectives. We suggest enhancing the description of the discovery method to include more details on the frequency of refinement versus regurgitation. Finally, aligning the discovered objective function with the evaluation process would strengthen the findings.