ID: 6XPPfZkhKi
Title: HAP: Structure-Aware Masked Image Modeling for Human-Centric Perception
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 6, 5, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Human structure-Aware Pre-training (HAP) method that integrates human structure priors into the masked image modeling (MIM) training strategy for human-centric perception tasks. The authors demonstrate the method's advantages across five human-centric perception tasks using twelve benchmark datasets. The approach is characterized as simple and intuitive, with extensive experiments validating its effectiveness.

### Strengths and Weaknesses
Strengths:
- The authors effectively analyze the limitations of the current MIM training strategy and propose the incorporation of human structure priors, which is both intuitive and appropriate.
- The application of structure-invariant alignment loss enhances feature representation, showcasing a straightforward yet promising approach.
- The extensive experiments and ablation studies provide solid evidence of the proposed method's superiority.
- The paper is well-organized, with clear presentation and informative visualizations.

Weaknesses:
- The technical originality of the method is limited, as it primarily combines existing techniques in masked image modeling.
- Insufficient analysis of how pose estimation methods like OpenPose or AlphaPose affect HAP's performance is noted.
- The lack of experiments addressing occlusions in 3D human pose and shape estimation limits the demonstration of HAP's advantages.

### Suggestions for Improvement
We recommend that the authors improve their analysis of the impact of pose estimation methods on HAP's performance, possibly by conducting experiments with OpenPose or AlphaPose. Additionally, incorporating experiments that address occlusions in 3D human mesh estimation would further highlight the strengths of HAP. We also suggest that the authors provide a clearer baseline comparison, such as pretraining on LUPerson to regress 2D keypoints, and explore the effects of using different pose estimation methods. Lastly, we advise the authors to reconsider their claims regarding the novelty of the Structure Alignment Loss and clarify the implications of using 2D keypoints in a self-supervised context.