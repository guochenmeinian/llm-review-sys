ID: jXs6Cvpe7k
Title: Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 8, 7, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 2, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Robust Prompt Optimization (RPO), a novel method for defending large language models (LLMs) against jailbreaking attacks. The authors formalize a minimax optimization objective that incorporates adversarial threats and propose the RPO algorithm, which optimizes a suffix for LLM prompts to ensure safe outputs. RPO demonstrates significant improvements in attack success rates on models like GPT-4 and LLaMA-2, achieving state-of-the-art performance while maintaining low inference costs and transferability to black-box models. The paper includes both theoretical analysis and extensive empirical evaluations.

### Strengths and Weaknesses
Strengths:
- Proposes the first formal optimization objective for defending LLMs against jailbreaking attacks, integrating adversarial considerations directly into the defense.
- Provides a solid theoretical foundation and extensive empirical evaluation, demonstrating RPO's effectiveness and robustness.
- The method is lightweight and easily deployable, making it practical for real-world applications.

Weaknesses:
- Limited discussion of computational costs and the resources required for RPO optimization, including runtime and scalability with model sizes.
- Lack of ablation studies to explore the impact of various components of RPO on performance.
- Insufficient exploration of potential negative impacts, such as false positives on benign queries.
- Limited comparisons to other optimization-based defenses and insufficient analysis of transfer learning capabilities.
- Absence of human evaluation to assess the perceived safety and quality of outputs.
- Lack of in-depth analysis of learned defensive suffixes and multi-turn interaction scenarios.
- No discussion on potential adaptive attacks against RPO and how the defense might evolve over time.

### Suggestions for Improvement
We recommend that the authors improve the paper by including a section on computational requirements, comparing RPO's runtime and resource usage to existing defenses. Conducting ablation studies would help clarify the impact of different components on overall performance. Additionally, including a discussion on potential limitations and negative impacts, particularly regarding false positive rates for benign queries, would enhance the paper's comprehensiveness. We suggest including comparisons to adversarial training methods and conducting experiments on transfer learning between models of varying sizes and architectures. A human evaluation study to assess output safety and quality is also advised. Furthermore, providing a justification for the chosen loss function and experimenting with alternatives could yield valuable insights. Analyzing the learned suffixes using interpretability techniques and extending evaluations to multi-turn interactions would strengthen the findings. Lastly, outlining potential adaptive attacks and discussing the expected longevity of the defense would provide a more robust framework for understanding RPO's effectiveness.