ID: AMIJEupsNq
Title: 3D-Aware Visual Question Answering about Parts, Poses and Occlusions
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 5, 9, 6, 6, -1, -1, -1, -1
Original Confidences: 4, 2, 2, 5, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the concept of 3D-aware Visual Question Answering (VQA) and introduces a new dataset called "Super-CLEVR-3D." The authors propose a model named "PO3D-VQA," which integrates probabilistic neural symbolic program execution with deep neural networks, utilizing 3D generative representations of objects. Experimental results indicate that PO3D-VQA outperforms existing methods, although a significant performance gap remains compared to 2D VQA benchmarks, emphasizing the need for further exploration in 3D-aware VQA.

### Strengths and Weaknesses
Strengths:
- Originality: The introduction of the Super-CLEVR-3D dataset extends an existing 2D dataset with 3D-aware questions, establishing a novel benchmark for evaluating 3D-aware VQA models.
- Quality: Comprehensive experimental results demonstrate the superiority of PO3D-VQA over existing methods.
- Clarity: The paper clearly articulates the motivation, defines the task of 3D-aware VQA, and thoroughly describes the proposed dataset and model.
- Significance: The work highlights the importance of understanding the 3D structure of visual scenes in VQA, showcasing improvements in accuracy and advancing the field.

Weaknesses:
- The model only uses images as input, neglecting more suitable formats like point clouds or multi-view images for 3D scenarios.
- The source of ground truth information regarding pose and occlusion is unclear; it is uncertain if they are included in the Super-CLEVR dataset.
- The design of PO3D-VQA appears weak, resembling a combination of Neural Meshes and P-NSVQA.
- The performance of the model using only language and oracle object representation raises questions about whether accurate object detection is necessary for the task.
- The comparison with scene graph-based methods lacks clarity regarding the advantages of the neural symbolic approach over deep graph networks.
- The paper does not adequately discuss the limitations or potential biases of the Super-CLEVR-3D dataset, nor does it address the scalability of the proposed model for larger, more complex scenes.

### Suggestions for Improvement
We recommend that the authors improve the model by considering the use of point clouds or multi-view images as input to better suit 3D scenarios. Clarifying the source of ground truth information for pose and occlusion in the Super-CLEVR dataset is essential. Strengthening the model design of PO3D-VQA to differentiate it more clearly from existing methods is advisable. Additionally, evaluating the model's performance using only language and oracle object representation could provide insights into its reasoning capabilities. A thorough comparison with scene graph-based methods should be included to elucidate the advantages of the proposed approach. We also recommend a detailed discussion on the limitations of the Super-CLEVR-3D dataset and an exploration of the model's scalability with larger scenes. Finally, analyzing failure cases of existing 2D VQA models on 3D-aware questions could provide valuable insights into the strengths of the 3D-aware approach.