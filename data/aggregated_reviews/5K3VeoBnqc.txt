ID: 5K3VeoBnqc
Title: AED: Adaptable Error Detection for Few-shot Imitation Policy
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 7, 7, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Adaptable Error Detection (AED) problem, focusing on detecting error behavior of robot policies in unseen environments. The authors propose a new benchmark with 322 base and 153 new environments, addressing three main challenges: the absence of observable abnormal behavior in training data, difficulty in detecting errors due to complex backgrounds, and the need for timely policy termination upon error detection. The proposed PrObe architecture integrates a pattern extractor and flow generation, utilizing a pattern loss, temporal contrastive loss, and classification loss to predict error probabilities. The experiments demonstrate that PrObe achieves superior performance compared to baseline models.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, with a coherent narrative and effective motivation for the research problem.
- Schematic illustrations enhance the understanding of AED and PrObe.
- The unique challenges of AED distinguish it from previous tasks, establishing its significance in the field.
- PrObe's design principles are validated through comprehensive evaluations, showing improved visual separability and error detection timing.

Weaknesses:
- The Preliminaries section lacks mathematical notation, which could enhance clarity.
- The average difference metric in Figure 4 may not provide an adequate comparison; a more informative assessment is recommended.
- PrObe's effectiveness is only demonstrated with image data, raising concerns about its applicability to proprioceptive data used in robotic manipulation tasks.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the Preliminaries section by incorporating mathematical formulations for key components such as the feature encoder and task-embedding network. Additionally, we suggest revising the average difference metric in Figure 4 to compare performance against the worst-performing method for a more meaningful evaluation. To strengthen the applicability of PrObe, we encourage the authors to conduct experiments using proprioceptive sensor data and provide empirical validation of its effectiveness in that context. Furthermore, we advise separating the contributions of the novel benchmark and PrObe for clarity in the paper.