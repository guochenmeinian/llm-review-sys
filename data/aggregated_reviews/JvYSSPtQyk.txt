ID: JvYSSPtQyk
Title: DASpeech: Directed Acyclic Transformer for Fast and High-quality Speech-to-Speech Translation
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 8, 5, 5, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DASpeech, a non-autoregressive direct speech-to-speech translation model utilizing a two-pass architecture. The first pass employs a linguistic decoder based on DA-Transformer, while the second pass utilizes an acoustic decoder based on FastSpeech 2. Experiments on the CVSS benchmark indicate that DASpeech achieves comparable or superior performance to the state-of-the-art model Translatotron 2, with a speedup of up to 18.53x compared to autoregressive models. The model also demonstrates the ability to preserve the speaker's voice during translation.

### Strengths and Weaknesses
Strengths:
1. The proposed approach effectively combines existing models, achieving competitive performance with significantly faster inference speeds.
2. The model's ability to preserve voice is a notable feature for authentic communication.
3. The thorough comparison to previous methods enhances the credibility of the results.

Weaknesses:
1. The novelty of the approach is limited, heavily relying on prior work without significant technological breakthroughs.
2. The experimental results primarily focus on English-French translation, which may not adequately represent performance across languages with different syntactic structures.
3. The efficiency analysis lacks depth, and comparisons to autoregressive models may not be entirely fair given the nature of non-autoregressive models.

### Suggestions for Improvement
We recommend that the authors improve the novelty of the work by addressing unique challenges specific to speech-to-speech translation. Additionally, we suggest expanding the evaluation to include more language pairs, particularly those with significant syntactic differences, such as English-German. To enhance the analysis of efficiency, we recommend providing more detailed comparisons with other state-of-the-art non-autoregressive models. Finally, we encourage the authors to include an ablation study to clarify the contributions of each component in the model.