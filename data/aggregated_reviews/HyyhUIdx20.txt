ID: HyyhUIdx20
Title: Bandit-Driven Batch Selection for Robust Learning under Label Noise
Conference: NeurIPS
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: 2, 3, 3, 4

Aggregated Review:
### Key Points
This paper presents an approach to batch selection using combinatorial bandit algorithms to address label noise in training deep neural networks. The authors propose a novel algorithm that integrates the Multi Armed Bandit (MAB) theory with Learning with Noisy Labels (LNL) methods, specifically unifying the "Follow the Perturbed Leader" (FPL) method with a metric from the Active Bias method. Empirical results indicate that FPL outperforms other methods like Active Bias and Exp3 in noisy label settings, with performance benefits increasing alongside noise levels. However, the evaluation is limited to a single architecture and dataset (CIFAR-10).

### Strengths and Weaknesses
Strengths:  
- The paper addresses an important problem of label noise in real-world datasets, proposing a novel and efficient algorithm for batch selection in Stochastic Gradient Descent training.  
- The empirical results demonstrate tangible benefits in accuracy under noisy conditions without significant computational overhead.  

Weaknesses:  
- The novelty of the algorithm is undermined by a lack of clarity regarding the LNL metric's calculation and its application in the final algorithm.  
- The experiments are limited to one dataset, and results in noise-free settings do not show significant improvements.  
- There is insufficient discussion of related work, particularly regarding other approaches to data distillation and automated curriculum learning.  
- The explanation for FPL's advantage over Exp3 is vague and requires further elaboration.

### Suggestions for Improvement
We recommend that the authors improve clarity on how the LNL metric is calculated and confirm its use in the final algorithm. Additionally, conducting experiments with alternative reward metrics would strengthen the findings, especially since the performance of Exp3 and FPL is similar in noiseless conditions. Expanding the experimental evaluation to include datasets with natural label noise would enhance the robustness of the claims. Furthermore, we suggest incorporating a more thorough discussion of related literature, particularly works that address data distillation and automated curriculum learning. Lastly, providing a deeper analysis of the reasons behind FPL's performance advantage over Exp3 would be beneficial.