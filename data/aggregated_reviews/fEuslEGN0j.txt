ID: fEuslEGN0j
Title: Fine-tuned LLMs Know More, Hallucinate Less with Few-Shot Sequence-to-Sequence Semantic Parsing over Wikidata
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an approach to enhance the factuality of large language models (LLMs) by grounding them in Wikidata through the introduction of a novel semantic parser, WikiSP, and the creation of the WikiWeb-Questions dataset. The dataset serves as a benchmark for knowledge-base question answering (KBQA) and includes semantic parses over Wikidata. The authors propose a two-step methodology where WikiSP generates SPARQL queries, which are then supplemented by responses from GPT-3, effectively reducing hallucination and improving answer accuracy.

### Strengths and Weaknesses
Strengths:
- The introduction of the WikiWeb-Questions dataset provides a valuable resource for training and evaluating semantic parsers in the context of Wikidata.
- The paper presents the first effective few-shot sequence-to-sequence semantic parser for Wikidata, demonstrating its capability to reduce hallucination in LLMs.
- The extensive evaluation of the semantic parser offers insights into its performance and highlights categories of errors, guiding future research.

Weaknesses:
- The experiments are limited to a single self-collected dataset, lacking comparisons with other established KBQA datasets (e.g., WebQuestions, GrailQA).
- The paper does not provide sufficient details on the development of the dataset, including the reliability of the manual conversion process and the diversity of the dev set.
- Some sections, such as the recovery from named entity disambiguation (NED) errors, lack clarity and could benefit from examples.

### Suggestions for Improvement
We recommend that the authors improve the paper by conducting experiments on additional KBQA datasets to better understand the effectiveness of the proposed method. Additionally, we suggest including a more detailed explanation of the dataset creation process, particularly regarding the reliability of the manual conversion and the diversity of the dev set. Providing examples in the appendix, especially for complex sections like NED error recovery, would enhance clarity. Finally, we encourage the authors to consider including an ablation study that examines the impact of removing the entity linking stage from the pipeline.