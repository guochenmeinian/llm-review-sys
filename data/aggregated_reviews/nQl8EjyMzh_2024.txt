ID: nQl8EjyMzh
Title: On conditional diffusion models for PDE simulations
Conference: NeurIPS
Year: 2024
Number of Reviews: 19
Original Ratings: 7, 6, 6, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on forecasting temporal dynamics associated with forward PDE problems using diffusion models. The authors propose various strategies for approximating the score function of trajectories, including both simultaneous and autoregressive sampling methods. They suggest incorporating observational information to enhance the prediction process and evaluate the proposed methods on two types of PDEs, focusing on both forecasting and data assimilation tasks. Additionally, the authors acknowledge the flexibility of their framework and propose to include Amortised Kolmogorov results and algorithm pseudocode in the revised manuscript. They discuss performance comparisons between MSE-trained U-Net and modern U-Net architectures, indicating that while the modern U-Net performs better for guided models, the MSE-trained U-Net is comparable or superior for amortised cases.

### Strengths and Weaknesses
Strengths:
1. The writing is clear and self-contained.
2. Comprehensive empirical studies on different components and hyperparameters support the claims.
3. The universal amortized model is effective and flexible, addressing issues in common amortized models.
4. The application of reconstruction guidance in the diffusion process shows potential for hybrid forecasting systems.
5. The authors demonstrate a willingness to incorporate feedback and improve the manuscript.

Weaknesses:
1. Many techniques in the framework are not novel, with some concepts previously introduced in related works.
2. The empirical performance does not surpass many existing data-driven forecasting models, raising questions about the balance between flexibility and performance.
3. The paper lacks detailed comparisons between MSE-trained U-Net and modern U-Net, which could clarify performance differences.
4. There are concerns regarding hyperparameter tuning and convergence that need further exploration.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the performance of the proposed method compared to existing models, particularly addressing the limitations of the autoregressive sampling approach and its computational cost. Additionally, including a comparison to classical inverse problem solvers would provide valuable context. We suggest enhancing the forecasting evaluation with probabilistic metrics and providing algorithms or pseudocode for clarity on the methods' training and inference processes. Furthermore, we recommend including the Amortised Kolmogorov results and algorithm pseudocode in the appendix. It is crucial to run a comparison using an MSE-trained modern U-Net as an alternative forecasting baseline to eliminate architectural differences as a factor in performance discrepancies. Finally, further investigation into the ablation window size, missing convergence, and hyperparameter tuning would benefit readers.