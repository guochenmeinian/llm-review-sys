ID: 4sDHLxKb1L
Title: HiBug: On Human-Interpretable Model Debug
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 5, 6, 7, 3, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents HiBug, a novel model-debugging method for deep learning classifiers that identifies misclassified samples and spurious correlations. The authors propose a method that integrates attribute assignment to training data using a pre-trained large language model (LLM) and a vision-language model (VQA). By performing K-means clustering on embeddings from the VQA, representative samples are selected to derive attribute values iteratively. HiBug identifies "rare case bugs" and "spurious correlation bugs" by evaluating validation accuracy drops and measuring linear correlations between generated attributes and ground truth data. The method includes a model repair mechanism that selects unlabeled data with high validation error rates and generates new data using class names and attribute values. Experimental results demonstrate HiBug's effectiveness in discovering bugs and improving model performance. Additionally, the paper provides a detailed analysis of HiBug, addressing its functionalities and potential applications.

### Strengths and Weaknesses
Strengths:
- The paper addresses the important problem of automatically identifying rare samples and spurious correlations in deep learning models.
- The method effectively leverages pre-trained models to minimize human intervention, enhancing its practicality.
- The authors provide a comprehensive overview and engage effectively with reviewer feedback, demonstrating a willingness to improve the work.

Weaknesses:
- The paper lacks a clear distinction between its contributions and those of existing work, particularly Domino, which also identifies rare cases and correlations. The authors should clarify the differences and challenges that set HiBug apart.
- Some definitions and motivations, such as the choice of BLIP over other models, are inadequately discussed. The computation process for linear correlation is unclear, and the accuracy measure for erroneous correlations is not well explained.
- The scalability and effectiveness of the attribute identification process and the K-means clustering step are not sufficiently addressed, raising concerns about their reliability.
- The paper lacks a discussion on possible malfunctions of HiBug, which is a critical aspect that should be addressed.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the contributions of HiBug compared to existing methods like Domino, emphasizing key differences and challenges. Additionally, the authors should provide a more detailed motivation for choosing BLIP and clarify the computation process for linear correlation, including how accuracy measures are derived. It would be beneficial to address the scalability of the attribute identification step and the effectiveness of the K-means clustering used for representative image selection. Finally, we recommend that the authors discuss potential malfunctions of HiBug to enhance the overall analysis and reliability of the findings, as well as the implications of bias in the attribute assignment process.