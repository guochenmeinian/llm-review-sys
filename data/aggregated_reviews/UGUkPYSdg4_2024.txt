ID: UGUkPYSdg4
Title: Distribution-Aware Data Expansion with Diffusion Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 5, 4, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a training-free data augmentation method called DistDiff, based on diffusion models, which utilizes hierarchical prototypes to approximate real data distributions. The authors propose an energy-based guidance approach to generate distribution-consistent samples, demonstrating significant improvements in data expansion tasks across various datasets. The experimental results indicate that the proposed method achieves state-of-the-art (SOTA) performance compared to existing baselines.

### Strengths and Weaknesses
Strengths:
1. The novel use of hierarchical prototypes as constraints in the generation process is innovative and addresses the poison phenomenon associated with diffusion models.
2. The paper is well-structured and easy to follow.
3. The proposed method shows SOTA performance against multiple baselines.

Weaknesses:
1. The baselines do not include recent works, such as Brandon et al. and Khawar et al., which should be considered for a comprehensive evaluation.
2. The datasets employed may be insufficient, particularly lacking the inclusion of ImageNet, which is necessary for a robust assessment of the proposed method.
3. The manuscript lacks clarity on the selection and generation of hierarchical prototypes, and the claims regarding efficiency are not sufficiently supported by data.

### Suggestions for Improvement
We recommend that the authors improve the baseline comparisons by including recent works like Brandon et al. and Khawar et al. to enhance the evaluation's comprehensiveness. Additionally, the authors should consider using ImageNet as a dataset to validate the performance of DistDiff, as the current datasets may not provide a complete picture. Furthermore, we suggest that the authors provide a detailed explanation of the prototype generation process to bolster the credibility of their method. To substantiate claims of efficiency, we recommend adding a comparison table detailing DistDiff's computational time and resource usage against other methods. Lastly, the authors should clarify the rationale behind the selection of K prototypes and consider providing an ablation study for K=1 to elucidate its impact on performance.