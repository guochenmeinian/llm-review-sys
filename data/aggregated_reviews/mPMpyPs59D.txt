ID: mPMpyPs59D
Title: Best of Three Worlds: Adaptive Experimentation for Digital Marketing in Practice
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a critical examination of Adaptive Experimental Design (AED) in industrial contexts, particularly addressing challenges under non-stationary conditions, contrasting it with traditional A/B/N testing methods. The authors propose a novel AED framework that integrates a cumulative gain estimator with an always-valid inference mechanism and an elimination-based algorithmic approach. This framework aims to efficiently identify optimal treatments, minimize opportunity costs, and withstand time variations, supported by theoretical guarantees and empirical evidence from production systems.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant problem relevant to online experimentation in non-stationary environments.
- It is well-written, with clear arguments and useful case studies that illustrate the motivation for the work.
- The proposed method demonstrates empirical effectiveness across various realistic non-stationary situations.
- The framework provides theoretical guarantees regarding its performance in time-varying scenarios.

Weaknesses:
- The technical novelty of the provided guarantees appears limited, resembling straightforward statistical calculations or known results.
- The empirical results are derived solely from real-world experiments, lacking synthetic experiments that could allow for broader comparisons under controlled conditions.
- The title may be too broad, potentially obscuring the paper's specific contributions.
- The paper lacks a separate “Related Works” section to contextualize the proposed method within existing AED literature.
- Some claims are insufficiently substantiated, relying on anecdotal evidence rather than robust data.

### Suggestions for Improvement
We recommend that the authors improve the accessibility of the paper by explicitly linking their methods to key concepts such as Valid Inference and Identify the Counterfactual, potentially using diagrams or flowcharts. Additionally, we suggest including a “Related Works” section to clarify how the proposed method differs from existing approaches. To enhance reproducibility, the authors should provide more details about the datasets used in their evaluations and consider incorporating synthetic experiments for broader applicability. Finally, we encourage the authors to clarify the title to better reflect the paper's focus and contributions.