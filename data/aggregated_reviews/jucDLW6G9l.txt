ID: jucDLW6G9l
Title: Deep Reinforcement Learning with Plasticity Injection
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 7, 5, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper studies the loss of plasticity in deep reinforcement learning (RL) and proposes a method called "Plasticity Injection" to mitigate this issue without increasing trainable parameters or affecting predictions. The authors demonstrate that their approach can enhance agent network size during training to address performance plateaus, thereby saving computational costs. Additionally, the method serves as a diagnostic tool, minimizing confounding factors like exploration. The results indicate that plasticity loss negatively impacts the performance of double DQN, and plasticity injection can often break performance plateaus.

### Strengths and Weaknesses
Strengths:
- The focus on plasticity loss in continual deep RL is compelling, with a methodology that aids both analysis and mitigation.
- The proposed method allows for network size adjustments during training without retraining or affecting predictions.
- The paper is well-structured, effectively introducing the problem and discussing related works.
- The potential for future research into dynamically growing networks is particularly exciting.

Weaknesses:
- The methodology addresses symptoms rather than the root cause of plasticity loss, which may require deeper exploration within the deep-learning toolbox.
- Full-sweep experiments could enhance understanding by eliminating exploration confounding in smaller domains.
- Some experimental details, such as task definitions and state selection, lack clarity, which could aid in understanding results.
- The method introduces additional computational costs and complexity, with only marginal benefits compared to simpler alternatives.

### Suggestions for Improvement
We recommend that the authors improve the clarity of experimental details, particularly regarding task definitions and state selection in Figure 1. Additionally, conducting full-sweep experiments in manageable finite environments could provide insights into plasticity loss without exploration confounding. The authors should also consider addressing the computational costs associated with the proposed method and explore alternative approaches, such as adding a single new head with a scalar multiplier, to reduce complexity while maintaining effectiveness. Finally, a broader testing of the Plasticity Injection method across various environments would strengthen the findings.