ID: XOotfgPiUF
Title: FreeMask: Synthetic Images with Dense Annotations Make Stronger Segmentation Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 27
Original Ratings: 4, 7, 6, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for generating densely annotated synthetic images using generative models to enhance the training of semantic segmentation networks. The authors propose a filtering criterion to suppress noisy samples and a re-sampling technique based on mask-level hardness to prioritize harder examples. The effectiveness of the method is evaluated through experiments on datasets like ADE20K and COCO, demonstrating improvements in segmentation performance. Additionally, the authors enhance the performance of fully-supervised real-image baselines by utilizing synthetic data from FreestyleNet, coupled with their proposed processing techniques. They provide evidence that using synthetic pairs without processing does not improve performance and can even degrade it. Their filtering and hardness-aware synthesis strategies significantly boost performance, achieving an increase of **+1.8 mIoU** compared to the baseline and outperforming FreestyleNet by as much as **+5.0 mIoU** when scaling the number of synthetic images.

### Strengths and Weaknesses
Strengths:
- The paper is well-structured and clearly written, making it easy to understand.
- The proposed methods for noise filtering and image re-sampling are reasonable and have shown effectiveness in improving segmentation performance.
- The experiments cover multiple performance aspects, providing valuable insights for future research in synthetic pre-training.
- The authors provide comprehensive experimental evidence supporting the necessity of their processing techniques for improving performance.
- The proposed methods demonstrate a significant performance increase over existing approaches, particularly in challenging scenarios.
- The authors effectively address reviewer concerns and show responsiveness to feedback.

Weaknesses:
- There is potential conflict between filtering hard pixels and re-sampling hard masks, which requires more in-depth analysis.
- The performance gains appear modest given the complexity of the proposed method, which involves multiple heavy processing steps.
- The novelty of the re-sampling strategy is questioned, as it resembles existing techniques like Online Hard Example Mining (OHEM).
- The filtering strategy lacks robustness, and quantitative results demonstrating its effectiveness are needed.
- The paper does not adequately compare the proposed method with existing approaches, such as DatasetGAN and BigDatasetGAN.
- Some reviewers express lingering doubts about the extent to which the improvements are attributable to the authors' methods versus FreestyleNet.
- There is a need for further clarity on the novelty and distinctiveness of their filtering strategies compared to existing methods in the literature.

### Suggestions for Improvement
We recommend that the authors improve the analysis of the conflict between filtering and re-sampling strategies to clarify their interactions. Additionally, the authors should provide a more detailed discussion on the modest performance gains relative to the complexity of their method. We suggest including quantitative comparisons with existing methods to highlight the novelty of their approach. Furthermore, the authors should enhance the robustness of their filtering strategy and provide empirical evidence of its effectiveness. Lastly, we recommend that the authors improve the clarity of their explanations regarding the novelty of their filtering strategies in relation to existing techniques in label-efficient learning and provide more detailed discussions on the effectiveness of their method across varying dataset sizes to further substantiate their claims.