ID: yBVLXvJ1sb
Title: Error Discovery By Clustering Influence Embeddings
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 7, 7, 6, 7, 6, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 3, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for discovering subsets of a test set in multi-class classification tasks where a model misclassifies examples due to a common root cause. The authors propose a factorized low-rank approximation of a bilinear influence function, parameterized by the Hessian of the loss function, to create influence embeddings. These embeddings are utilized to cluster test examples using k-means, allowing for the identification of problematic training examples and slices of the test set with specific failure properties. Empirical results indicate that the method outperforms existing slice discovery techniques.

### Strengths and Weaknesses
Strengths:
- The problem addressed is significant and well-motivated.
- The method is easy to understand and appears scalable.
- Empirical evidence supports the method's suitability for the problem.
- The paper is generally well-written and structured.

Weaknesses:
- The methodological contribution seems limited compared to Schioppa et al. [2022].
- The choice of k-means for clustering lacks justification, and alternative algorithms like DBSCAN could be more effective.
- The theoretical results are somewhat overstated; further elaboration on Lemma 1 and Section 3.5 is needed.
- The background section's notation is introduced in an unclear manner, particularly regarding the Hessian's definition.
- The results section is poorly organized, and some figures do not effectively aid understanding.

### Suggestions for Improvement
We recommend that the authors improve the justification for using k-means as the clustering algorithm and consider validating results with additional clustering methods such as spherical k-means or hierarchical clustering. The authors should also clarify how the subset of the training set is selected for FactorHessian and provide a more detailed discussion of hyperparameter choices, including the values of P, D, and K. Additionally, we suggest reorganizing the results section to enhance readability and including a limitations section in the main text for better accessibility. Finally, addressing potential ethical concerns regarding the method's application would strengthen the paper.