ID: NnXznLurw5
Title: Human spatiotemporal pattern learning as probabilistic program synthesis
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 5, 6, 6, 7, 7, -1, -1, -1, -1, -1
Original Confidences: 2, 4, 4, 4, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a "Language of Thought" (LoT) model aimed at understanding how humans learn concepts from limited data through a visual sequence prediction task. The authors compare the LoT model's performance against baseline models, including Bayesian ridge regression and Gaussian Processes, finding that the LoT model aligns closely with human learning patterns. The study contributes to both machine learning and cognitive science by exploring the inductive biases underlying human predictions. Additionally, the authors propose technically sophisticated improvements to the modeling of behavior and have made updates to clarify the paper's contributions, particularly for readers unfamiliar with the subject. The inclusion of additional experiments, such as the LSTM model and ablations of the LoT model, is anticipated to enhance the paper's depth.

### Strengths and Weaknesses
Strengths:
- The investigation addresses a significant problem relevant to both machine learning and cognitive science.
- The LoT model appears to fit the data well, suggesting its potential as a tool for understanding human cognition.
- The paper is well-written and presents a clear experimental methodology.
- The authors provided a detailed and engaging rebuttal, addressing reviewer concerns effectively.
- The updates to the baselines using the same inference algorithms enhance the paper's clarity and rigor.
- The proposed improvements to modeling behavior are technically sophisticated and contribute to the paper's novelty.

Weaknesses:
- The rationale for the chosen 2-dimensional pattern learning task is unclear and seems arbitrary.
- The experimental evaluation lacks robust baselines, with many considered models being overly simplistic for human cognition.
- The description of methods, particularly the inference procedure and grammar of the LoT model, is insufficiently detailed.
- There are no error bars in the experimental results, which raises concerns about the robustness of the findings.
- There is a need for a more explicit discussion of limitations in the final version.
- Some reviewers expressed concerns about the motivation for the chosen task and the empirical evaluation of the proposed models.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the task's relevance by providing a stronger justification for the choice of the 2-dimensional pattern learning task. Additionally, consider including more suitable baseline models, potentially incorporating non-Bayesian approaches, such as pre-training a neural network on a synthetic sequence corpus. An ablation study could elucidate which components of the LoT model are critical for performance, and a more detailed description of the inference algorithm and grammar is necessary. Furthermore, including error bars in the experimental evaluation would enhance the reliability of the results. We also recommend that the authors include a discussion of limitations in the final version. It is crucial to present the results of the additional experiments, such as the LSTM model and the ablations of the LoT model, even if they must be included in the Appendix due to space constraints. Lastly, we suggest that the authors clarify the statistical methods used to assess the robustness of results, specifically by conducting multiple independent runs with different random seeds to calculate standard errors or confidence intervals.