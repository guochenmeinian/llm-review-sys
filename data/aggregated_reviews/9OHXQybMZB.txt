ID: 9OHXQybMZB
Title: Aligning Model Properties via Conformal Risk Control
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 7, 5, 7, 4, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method that connects conformal risk control (CRC) to define prediction sets that satisfy a specific property with a probability of \(1 - \alpha\). The authors generalize CRC to multidimensional parameters and apply this to property testing, particularly focusing on monotonicity and concavity. The approach aims to align trained models with user-defined properties, offering potential applications in model explainability and fairness.

### Strengths and Weaknesses
Strengths:
- The idea is novel, opening new avenues for black-box modifications of models.
- The methodology is well-developed and presented in an accessible manner, engaging audiences unfamiliar with CRC or property testing.
- The paper is well-written, with solid theoretical foundations and convincing examples of monotonicity and concavity.

Weaknesses:
- Notations could be introduced more clearly, particularly the mathematical representation of property \(\mathcal{P}\).
- Sections 2.1 and 3.2 lack clarity and explicit mathematical formulations, which may confuse readers.
- There are minor typographical errors and inconsistencies in notation, such as the use of \(\mathrm{Min}\) instead of \(\min\) and the definition of minimal values.
- The connection between monotonicity/concavity and alignment in AI remains underexplored.

### Suggestions for Improvement
We recommend that the authors improve the introduction of notations to enhance clarity, particularly for \(\mathcal{P}\). Additionally, we suggest rewriting sections 2.1 and 3.2 to provide clearer mathematical formulations and reduce verbosity. It would be beneficial to ensure consistent use of notation throughout the paper and address typographical errors. Furthermore, we encourage the authors to explore real-world applications of their method, particularly in relation to alignment in AI, to strengthen the connection between their theoretical contributions and practical implications.