ID: WffhOhYvZ0
Title: SolarCube: An Integrative Benchmark Dataset Harnessing Satellite and In-situ Observations for Large-scale Solar Energy Forecasting
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 7, 7, 8, 7, -1
Original Confidences: 4, 4, 2, 3, -1

Aggregated Review:
### Key Points
This paper presents a dataset for solar energy forecasting, integrating data from 19 study areas and establishing three benchmarks: (1) image-based short-term forecasting, (2) point-based short-term forecasting, and (3) point-based long-term forecasting. The authors benchmark various methods and provide evaluation metrics. The dataset is motivated by the need for high-quality solar irradiance data, combining satellite imagery and ground observations, which enhances the operationalization of models for solar energy forecasting.

### Strengths and Weaknesses
Strengths:
- The task is well-motivated, establishing a clear connection between the dataset and its applications.
- The methods and evaluation are comprehensive, with thoughtful setups, such as the effective comparison with a persistence model and the rationale for data splitting.
- The dataset's integration of multiple data modalities is novel and relevant, providing a significant resource for the solar energy forecasting community.

Weaknesses:
- Some data preparation aspects lack clarity, particularly regarding the ground-truth generation and its known errors.
- The choice of metrics, specifically the use of rRMSE/rMBD, may not adequately reflect performance across different times of day.
- Certain surprising results in the data could benefit from further exploration, and the similarities among methods make it challenging to identify a clear "winning" model.

### Suggestions for Improvement
We recommend that the authors improve the explanation of data preparation, particularly how ground-truth is derived and its associated errors. It would be beneficial to integrate these considerations into the evaluation metrics. Additionally, we suggest that the authors clarify the rationale behind using only rRMSE/rMBD and consider reporting performance metrics that account for the practical implications of forecasting accuracy at different times of day. 

Further, we encourage the authors to explore the surprising findings in Tables 1 and 3 more thoroughly, as these may yield valuable insights. It would also be helpful to report measurement errors associated with the dataset to better differentiate model performances. 

Lastly, we advise expanding the discussion on spatial/geographical inequities in data quality and the potential biases present in the dataset, as well as introducing terms like "Mean Bias Deviation" (MBD) in the text for clarity.