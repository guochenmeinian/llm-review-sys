ID: rIOTceoNc8
Title: Graph Coarsening with Message-Passing Guarantees
Conference: NeurIPS
Year: 2024
Number of Reviews: 18
Original Ratings: 6, 5, 7, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 1, 4, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the theoretical guarantees of graph coarsening for Graph Neural Networks (GNNs), proposing a new directed message-passing operation tailored for coarsened graphs. The authors provide theoretical proofs for linear variants of GNNs and demonstrate that their approach outperforms alternative methods on small datasets. The work addresses significant challenges in graph coarsening and offers comprehensive theoretical guarantees.

### Strengths and Weaknesses
Strengths:  
1. The results are highly beneficial for the field of graph coarsening, particularly Theorem 2, which illustrates the loss gap between coarsened and original graphs.  
2. The proposed message-passing operation is novel and appears natural.  
3. The literature review is thorough, and the theoretical analysis is reasonable.  
4. The model performs well on datasets like Cora and Citeseer.  

Weaknesses:  
1. The overall structure of the paper is somewhat loose, and the experimental section is limited to small datasets, primarily Cora and Citeseer, which may not adequately demonstrate the method's effectiveness.  
2. The theoretical analysis is confined to linear networks, and extending it to more complex GNNs remains unaddressed.  
3. There is a lack of intuitive explanations for certain concepts, such as $S^{MP}_c$ and $\overline{C}_{\Pi}$.  
4. The selected coarsening ratio is significantly larger than in existing works, and the practical applicability of the proposed method may be limited to homogeneous datasets.

### Suggestions for Improvement
We recommend that the authors improve the overall structure of the paper for clarity and coherence. Additionally, we suggest providing more intuitive explanations for key concepts like $S^{MP}_c$ and $\overline{C}_{\Pi}$. To enhance the experimental evaluation, we encourage the authors to test their method on larger and more diverse datasets, such as ogbn-arxiv, and to explore its applicability to various GNN architectures beyond linear models. Furthermore, clarifying the distinction between graph pooling and coarsening, as well as addressing the implications of the selected coarsening ratio, would strengthen the paper. Lastly, we advise including a more detailed complexity analysis for the computation of $Q^+$.