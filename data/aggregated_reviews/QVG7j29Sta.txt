ID: QVG7j29Sta
Title: Accuracy is Not All You Need
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 5, 6, 3, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis of quantized language models, introducing "flips" as a metric to measure the differences in model predictions before and after quantization. Flips quantify transitions from correct to incorrect predictions and vice versa, revealing that while accuracy may remain stable, significant changes in model behavior occur. The authors demonstrate this phenomenon through comprehensive experiments across multiple benchmarks and quantization techniques. Additionally, the paper evaluates the performance of a quantized model compared to a baseline model across various problem-solving scenarios, highlighting discrepancies in calculations and reasoning.

### Strengths and Weaknesses
Strengths:
1. The introduction of flips provides a novel perspective on evaluating LLM compression techniques, emphasizing that accuracy alone is insufficient.
2. The correlation between flips and KL-divergence strengthens the argument for using flips as a complementary metric.
3. The review effectively identifies specific instances where the quantized model outperforms the baseline model, providing clear examples of correct and incorrect responses.
4. The detailed breakdown of errors in both models enhances understanding of their respective limitations.

Weaknesses:
1. The theoretical foundation of flips is underdeveloped; a more detailed theoretical framework is needed.
2. The evaluation lacks diversity in models and tasks, limiting the generalizability of findings.
3. The experiments do not include error bars or statistical significance tests, which would enhance the reliability of results.
4. The baseline model exhibits significant errors in reasoning, leading to incorrect conclusions in multiple cases.
5. The quantized model also demonstrates misunderstandings, particularly in interpreting problem requirements, which affects its overall accuracy.

### Suggestions for Improvement
We recommend that the authors improve the theoretical insights surrounding flips to provide a stronger foundation for their metric. Additionally, expanding the evaluation to include a wider variety of models and tasks, such as GSM8K and Hendrycks' MATH, would enhance the robustness of the findings. We also suggest incorporating alternative evaluation setups for MCQ tasks, such as using log probabilities and negative log-likelihood, to further substantiate the claims. Furthermore, we recommend improving the baseline model's reasoning capabilities to ensure it accurately interprets problem statements and performs calculations correctly. Lastly, enhancing the quantized model's understanding of contextual relationships within problems would help reduce misinterpretations and improve accuracy in responses. Including error bars or conducting statistical significance tests would also help quantify the reliability of the reported results.