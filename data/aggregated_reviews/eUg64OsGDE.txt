ID: eUg64OsGDE
Title: CountGD: Multi-Modal Open-World Counting
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 5, 4, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to multi-modality open-world object counting by repurposing Grounding DINO, an open-vocabulary object detector, into an object counting model called CountGD. The authors propose using visual exemplars as additional tokens, allowing interaction between exemplars and image/text features. The method demonstrates strong counting performance on the FSC-147 dataset, excelling particularly in text-conditioned scenarios.

### Strengths and Weaknesses
Strengths:
1. The concept of open-world object counting with text and/or visual exemplars is promising for real-world applications.
2. The authors provide a straightforward method to adapt Grounding DINO for object counting by treating visual exemplars as text tokens.
3. CountGD achieves strong performance on the FSC-147 dataset, surpassing previous state-of-the-art results.

Weaknesses:
1. The claim of introducing the first open-world counting model is inaccurate, as PseCo also supports text and visual exemplars.
2. The method's ability to handle dense objects is questionable, given the limitation of 900 object queries, which may not suffice in real-world scenarios.
3. Comparisons in Table 1 are potentially misleading due to the use of test-time normalization and adaptive cropping, which may inflate performance metrics.
4. The inability to output bounding boxes diminishes the model's utility, as Grounding DINO is expected to localize objects.
5. There is a lack of comparison with the baseline Grounding DINO, which is necessary to validate the effectiveness of the proposed modifications.

### Suggestions for Improvement
We recommend that the authors improve the accuracy of their claims regarding the novelty of their model by acknowledging existing work like PseCo. Additionally, it would be beneficial to evaluate the proposed method's performance on images with varying object densities and report detailed results. We suggest including comparisons with the original Grounding DINO to substantiate the effectiveness of the proposed adaptations. Furthermore, addressing the limitations regarding bounding box outputs and providing clarity on the visualization process would enhance the paper's contributions. Lastly, we encourage the authors to explore the interaction between text and visual exemplars more deeply and to provide case studies of model failures in the appendix.