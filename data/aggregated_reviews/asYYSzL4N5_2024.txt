ID: asYYSzL4N5
Title: BAN: Detecting Backdoors Activated by Adversarial Neuron Noise
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 7, 6, 7, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel detection and defense method for backdoored models, named BAN (Backdoors activated by Adversarial neuron Noise). The method is motivated by the observation that existing state-of-the-art trigger-inversion methods, such as BTI-DBF, depend on strong backdoor features, which may not always be present. BAN identifies neurons responsible for backdoor functions by leveraging the increased sensitivity of backdoored models to adversarial noise compared to benign ones. The method optimizes a sparse neuron mask based on the model's loss behavior, aiming to decouple benign and backdoor features. Evaluations demonstrate that BAN outperforms existing approaches and shows robustness against adaptive attacks.

### Strengths and Weaknesses
Strengths:
- The proposed defense method enhances feature decoupling between benign and backdoor features, yielding strong results on evaluation benchmarks.
- The paper is well-written, clearly presenting the proposed method within the context of existing research and articulating open research problems.
- The comprehensive evaluation includes comparisons against various attacks and defenses, highlighting the method's effectiveness and robustness.

Weaknesses:
- The evaluation is limited to common CNN architectures, and the effectiveness of BAN on ViT architectures is not demonstrated.
- The focus on dirty label attacks overlooks the method's performance on clean-label attacks; including 1-2 clean-label attacks would strengthen the results.
- Some contributions, particularly the feature decoupling process, need clearer differentiation from existing literature, such as the method by Xu et al. 

### Suggestions for Improvement
We recommend that the authors improve the evaluation by demonstrating the effectiveness of BAN on ViT architectures to support efficiency claims. Additionally, including evaluations on clean-label attacks would provide a more comprehensive assessment of the method's performance. We suggest clarifying the unique contributions of the paper, particularly in relation to existing methods like that of Xu et al. Furthermore, enhancing the clarity of captions in figures and tables, increasing font sizes for better readability, and correcting minor typographical errors would improve the overall presentation. Finally, addressing the questions regarding the relationship between neuron noise and benign model behavior, as well as the impact of hyperparameter choices, would strengthen the paper's arguments.