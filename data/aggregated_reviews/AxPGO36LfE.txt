ID: AxPGO36LfE
Title: X-SNS: Cross-Lingual Transfer Prediction through Sub-Network Similarity
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method that utilizes sub-network similarity between languages as a proxy for predicting compatibility in zero-shot cross-lingual transfer. The authors evaluate their approach across five tasks from the XTREME benchmark, demonstrating that sub-network similarity can effectively select better source languages compared to previous methods. The experimental results indicate that the proposed method outperforms existing techniques.

### Strengths and Weaknesses
Strengths:
- The paper introduces a novel language similarity measure that is relevant to the NLP community.
- Comprehensive evaluations across multiple tasks show the utility of the proposed method.
- The writing is clear and well-organized.

Weaknesses:
- Some details and experiments are missing, leading to clarity issues regarding the proposed framework.
- The method's effectiveness across a wider range of tasks remains unclear.
- The approach appears to perform poorly in certain settings, such as with mT5, and lacks sufficient explanation for these results.

### Suggestions for Improvement
We recommend that the authors improve clarity regarding what is meant by "external resources" in Line 18. Additionally, it would be beneficial to clarify the necessity of Step 3 in Figure 2 and whether similarity can be derived solely from Step 2 outputs. The authors should provide citations for previous work that necessitates extra training of base models and clarify the choice of Wikipedia as the general domain set instead of CC-100. 

We suggest including a random classifier definition in Line 304 and comparing the proposed method with all six metrics provided by lang2vec, as previous studies indicate that the 'feature' metric may not be the best for predicting cross-lingual transfer performance. The authors should also explain the rationale behind using different baselines in Tables 2 and 3 and address whether X-SNS can handle cases where adding a new language worsens results. 

Further, we recommend providing details on the amount of data used for fine-tuning when considering multiple source languages and whether the conclusions hold for other multilingual models like Bloom or XLS-R. An analysis of failure cases could highlight the limitations of X-SNS and offer insights for improvement. Finally, including the time cost of X-SNS and clarifying how the source language set is defined would enhance the paper's comprehensiveness.