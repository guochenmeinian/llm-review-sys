ID: 6H8Md75kAw
Title: Certified Minimax Unlearning with Generalization Rates and Deletion Capacity
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 7, 6, 6, 6, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for machine unlearning in minimax models using Hessian-based updates, focusing on the theoretical analysis of error and sensitivity to deleted data. The authors propose an algorithm that improves deletion capacity from \(O(n/d^{1/2})\) to \(O(n/d^{1/4})\) and analyze generalization rates in various settings, including strongly convex-strongly concave and convex-concave cases. The work emphasizes the importance of minimax models in the context of privacy and machine learning.

### Strengths and Weaknesses
Strengths:
1. The paper is well-structured and clearly written, making the narrative easy to follow.
2. The proposed unlearning update is simple and effective within a restricted setting.
3. The motivation for the study is strong, particularly regarding privacy implications.
4. The work introduces a timely and relevant topic in machine learning, addressing a gap in minimax unlearning.

Weaknesses:
1. The presentation contains notational errors, such as a missing parenthesis in Equation (5) and unclear definitions for variables in Lemma 2.
2. The analysis is limited to strongly convex-strongly concave loss functions, which may not reflect practical scenarios in modern learning.
3. The paper lacks preliminary experimental results to validate theoretical claims and does not sufficiently explore the relationship between certified unlearning in STL and minimax models.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their notation and definitions, particularly for variables like \(m\), \(\rho\), and \(l\). Additionally, we suggest including a discussion on the practical implications of their work in the introduction or conclusion, as well as considering the inclusion of small toy experiments to verify theoretical results. Furthermore, we encourage the authors to explore the possibility of weakening the strongly convex-strongly concave conditions and to provide a clearer distinction between certified unlearning in STL and minimax models. Lastly, we advise reorganizing the presentation to highlight the strongest results and their implications more effectively.