ID: R8SolCx62K
Title: Exploitation of a Latent Mechanism in Graph Contrastive Learning: Representation Scattering
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 9, 9, 8, 9, -1, -1, -1
Original Confidences: 4, 5, 4, 5, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel exploration of representation scattering as a key mechanism in various graph contrastive learning (GCL) frameworks. The authors define this concept in embedding space, consisting of a center $\mathbf{c}$, a subspace $\mathbb{S}$, and two constraints termed representation scattering. They investigate the relationship between this concept and mainstream GCL frameworks through rigorous derivations and experiments, leading to the development of a new GCL framework called SGRL. This framework incorporates a contrastive loss that effectively distances representations from the mean center, demonstrating superior performance in experiments.

### Strengths and Weaknesses
Strengths:
1. The paper addresses a significant gap in understanding the mechanisms behind GCL frameworks, contributing valuable insights to the field.
2. The proposed SGRL framework is technically sound, supported by rigorous theorems and extensive experimental validation.
3. The writing is clear and comprehensive, with thorough explanations and a well-structured presentation.

Weaknesses:
1. The discussion on how existing methods fail to fully utilize representation scattering lacks depth, focusing more on their shortcomings.
2. The necessity of the topological aggregation constraint is questionable, as the encoder already aggregates neighbor information.
3. The use of two non-shared parameter encoders in SGRL is insufficiently justified; sharing parameters may enhance performance by reducing divergences.

### Suggestions for Improvement
We recommend that the authors improve the discussion on how existing GCL methods fail to leverage representation scattering, providing a more in-depth analysis. Additionally, consider justifying the inclusion of the topological aggregation constraint or exploring its redundancy. We suggest that the authors clarify the rationale behind using two encoders with non-shared parameters, potentially exploring the benefits of parameter sharing. Furthermore, including a comparison with existing augmentation-free contrastive methods could enrich the analysis. Lastly, providing more detailed explanations of specific symbols and including an algorithm flowchart would enhance clarity.