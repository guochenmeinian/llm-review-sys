ID: nUo7HJDqx2
Title: Prompting Multilingual Large Language Models to Generate Code-Mixed Texts: The Case of South East Asian Languages
Conference: EMNLP/2023/Workshop/CALCS
Year: 2023
Number of Reviews: 2
Original Ratings: 4, 4
Original Confidences: 4, 4

Aggregated Review:
### Key Points
This paper investigates the quality of synthetic code-mixed data generated by prompting multilingual large language models (MLLMs) in a zero-shot setup for seven languages/language-pairs: English - Indonesian, Malay, Chinese, Tagalog, Vietnamese, Tamil, and Singlish. The authors present a moderate amount of data across various topics and perform analyses and evaluations at different levels. The findings indicate that publicly available instruction-tuned models (BLOOMZ, Flan-T5-XXL) struggle to produce quality code-mixed data, while ChatGPT demonstrates superior performance. The study provides significant contributions and guidelines for improving MLLM performance in generating code-mixed text.

### Strengths and Weaknesses
Strengths:  
- The idea and data creation are timely and relevant, addressing the scarcity of manually labeled datasets for code-mixing in low-resourced languages.  
- The paper is well-written, clearly structured, and presents evaluations and results effectively.  
- The discussion section elaborates on implications for LLMs and future directions for synthetic data creation.  

Weaknesses:  
- The paper lacks a comparison of quality in a zero-shot setup versus a few-shot setup.  
- Some evaluations, such as mistakes from prompts like "imagine you are a Malaysian speaker ... using both English and Chinese," are less compelling.  
- It would be beneficial to include evaluations for specific NLP tasks using the generated datasets.

### Suggestions for Improvement
We recommend that the authors improve the paper by including a comparison of the quality of synthetic data in both zero-shot and few-shot setups. Additionally, consider enhancing the evaluation section by addressing less interesting evaluations and incorporating assessments for specific NLP tasks that utilize the generated datasets.