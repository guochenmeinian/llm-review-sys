ID: scAXKWMJR3
Title: Automated Few-Shot Classification with Instruction-Finetuned Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents AuT-Few, a method that automates prompt generation for few-shot learning, eliminating the need for hand-crafted prompts. The authors conduct extensive empirical studies across 12 datasets, demonstrating that AuT-Few outperforms the previous state-of-the-art (SOTA) T-Few by 2 points on 8 tasks, while also showing robustness to various models and out-of-domain datasets. The paper proposes a retrieval approach for template design and two methods for answer choices: template-tailored and topic-specific. The authors also explore the feasibility of fusing methods IA3 and LoRA, contributing to the parameter-efficient fine-tuning (PEFT) community.

### Strengths and Weaknesses
Strengths:
- The paper provides a comprehensive analysis of prompt types, offering valuable insights for future research.
- AuT-Few effectively removes the need for manual prompt design, which can significantly reduce human intervention.

Weaknesses:
- The improvement over T-Few is limited, as AuT-Few only outperforms it on 4 out of 12 datasets, raising concerns about the robustness of the claims.
- The rationale for the increased training time and computational costs compared to SOTA models is inadequately explained.
- There is a lack of analysis regarding the impact of the quality of prompt collections on template retrieval.

### Suggestions for Improvement
We recommend that the authors improve the explanation of the necessity for automatic prompt generation, especially in light of the robustness of instruction-tuned LLMs. Additionally, we suggest providing a detailed analysis of the inference time, as it appears significantly longer than previous models, which may detract from the model's effectiveness. Furthermore, we encourage the authors to clarify the meaning of "inverted handcrafted answer choices" and to analyze the odd automated choices presented in the appendix to enhance understanding of their performance. Lastly, we recommend addressing the logical discrepancy between the robustness of instruction-tuned LLMs and the motivation for automating prompt selection within the paper's structure.