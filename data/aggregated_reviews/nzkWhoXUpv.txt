ID: nzkWhoXUpv
Title: Individual Arbitrariness and Group Fairness
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 7, 7, 8, 7, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper explores the interaction of predictive multiplicity with fairness interventions, noting that models subjected to common fairness interventions often exhibit increased predictive multiplicity within the Rashomon set. The authors provide theoretical exploration and empirical evidence, proposing ensembling as a method to mitigate multiplicity. They also address arbitrariness in automated decision-making, suggesting that fairness interventions can exacerbate this issue, and propose an ensemble algorithm that utilizes multiple classifiers to reach a majority decision.

### Strengths and Weaknesses
Strengths:
- The observation that fairness interventions can increase predictive multiplicity is novel and significant.
- The paper is well-presented and contributes meaningfully to the discourse on arbitrariness and fairness in machine learning.
- The theoretical and empirical results are compelling, and the paper is well-written with clear figures that aid understanding.

Weaknesses:
- The discussion around "confidence" in Section 4.2 lacks clarity; further explanation on how classifier confidence impacts multiplicity and its relevance pre- and post-ensembling is needed.
- The philosophical implications of arbitrariness are not sufficiently justified; examples do not clearly articulate why arbitrariness is harmful.
- Presentation issues exist, including inconsistent notation in equations and unclear transitions between binary and multiclass classification.
- Proposition 3.1's applicability to fairness metrics beyond accuracy parity is uncertain, and the paper's focus on random forest models limits its generalizability.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the discussion on classifier confidence in Section 4.2, providing more context on its impact on multiplicity. Additionally, we suggest that the authors strengthen the justification for why arbitrariness is detrimental, particularly in their examples. The presentation should be polished to ensure consistent notation and clearer transitions between concepts. Finally, we encourage the authors to clarify the generalizability of Proposition 3.1 to other fairness metrics and to consider exploring additional model classes beyond random forests.