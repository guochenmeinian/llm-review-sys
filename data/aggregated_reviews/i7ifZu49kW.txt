ID: i7ifZu49kW
Title: Improving Neural Machine Translation by Multi-Knowledge Integration with Prompting
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a unified framework for enhancing neural machine translation (NMT) by integrating multiple types of knowledge, including sentences, terminologies, and translation templates, into the translation process. The authors propose using this knowledge as prefixes for the encoder and decoder, which allows the model to learn effectively without requiring changes to the architecture or additional training for specific domains. Experimental results on English-Chinese and English-German translation tasks demonstrate that the proposed method outperforms baseline models, although the improvements in BLEU scores are not substantial compared to methods like kNN-MT.

### Strengths and Weaknesses
Strengths:
- The method is straightforward, robust, and relatively easy to understand.
- Experimental results indicate significant improvements in translation quality and exact match accuracy compared to baselines.
- The approach allows for domain adaptation without retraining.

Weaknesses:
- The novelty of the work is limited, appearing as a supplement to previous methods like Priming-NMT.
- The paper lacks sufficient comparison with the latest methods, particularly Language Model-based approaches such as LLaMA.
- The terminology match accuracy may introduce bias, as it relies on the same terminology extraction method used during evaluation.
- The necessity of the proposed method is not convincingly established, especially in light of existing large language models that can incorporate external knowledge.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their contributions by clearly distinguishing their method from existing approaches and demonstrating its unique advantages. Additionally, the authors should provide a more comprehensive comparison with recent methods, including Language Model-based approaches. To address potential biases, we suggest revising the evaluation methodology to ensure that terminology match accuracy does not unfairly favor methods that utilize terminology knowledge. Finally, the authors should clarify the implications of using translation templates in terms of inference speed and consider the impact of noisy external knowledge on their method's performance.