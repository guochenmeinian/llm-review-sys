ID: OuIGwpTQic
Title: Inducing Human-like Biases in Moral Reasoning Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 4
Original Ratings: 5, 4, 6, 6
Original Confidences: 1, 2, 2, 2

Aggregated Review:
### Key Points
This paper presents an investigation into the alignment of large language models (LLMs) fine-tuned for moral reasoning with human brain activity, utilizing fMRI data. The authors conduct comprehensive experiments and provide analyses, including the first measurement of the similarity between biological brain representations and LLMs. However, the study finds that fine-tuning does not significantly enhance brain alignment on moral reasoning tasks, and the claim that results could inform future work lacks substantial support.

### Strengths and Weaknesses
Strengths:  
- The study is original, being the first to align LLMs with human brain activity during moral reasoning using fMRI data.  
- It offers a new perspective on the AI alignment problem in complex cognitive tasks.  
- The paper is well-structured and includes clear justifications for ethical considerations.

Weaknesses:  
- The significance of the findings is diminished by the lack of substantial improvement in brain alignment through fine-tuning methods.  
- The assertion regarding the need for more data on moral reasoning appears self-evident and lacks new insights.  
- There are inconsistencies in the results, particularly regarding accuracy on the ETHICS benchmark, and some typographical errors are present.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their claims by better motivating the relevance of aligning representations for moral reasoning tasks to Theory of Mind (ToM) and AI alignment. Additionally, we suggest combining Sections 1 and 2 to enhance accessibility for a broader audience. Further analysis on how insights from the experiments could apply to future studies or real-world applications would strengthen the paper. Lastly, addressing the observed "unlearnability" and the methods of representing fMRI data could provide deeper insights into the challenges faced.