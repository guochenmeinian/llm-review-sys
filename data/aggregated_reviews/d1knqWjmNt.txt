ID: d1knqWjmNt
Title: Optimality of Message-Passing Architectures for Sparse Graphs
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 6, 7, 7, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study of a specific graph convolutional architecture within the context of a contextual stochastic block model (CSBM), focusing on node classification with informative features. The authors propose a local Bayes-optimal classifier and demonstrate its implementation through a message-passing architecture. Key contributions include identifying the Bayes-optimal classifier for node clustering, specializing it for Gaussian features, and showing that the local classifier is nearly optimal for GCN architectures under certain conditions. Additionally, the paper analyzes message-passing algorithms in relation to community structure in graphs, emphasizing finite-dimensional features. The authors clarify that their notion of locality pertains to local-weak topology and that empirical per-node risks can be interpreted as a global notion of optimality. They conducted experiments in both new graph settings and semi-supervised settings, obtaining consistent results while acknowledging the need for comparisons with previous message-passing algorithms for large-dimensional features.

### Strengths and Weaknesses
Strengths:
- The paper identifies a setting where specific GCN architectures are provably optimal.
- It employs local weak convergence theory to illustrate how Bayes-optimal classifiers aggregate information across features and graph structure.
- The results are rigorous, with clear proofs and a thorough analysis of finite size bounds.
- The authors provide a clear explanation of the local-weak topology and its implications for global optimality.
- They conducted additional experiments in semi-supervised settings, demonstrating the robustness of their findings.
- The response to reviewer comments indicates a willingness to clarify and improve the manuscript.

Weaknesses:
- The Bayes-optimal classifier for the tree model is somewhat obvious, and the paper does not convincingly demonstrate that GCN architectures initialized without informative weights converge to this classifier.
- The focus on locally tree-like graphs limits the applicability of the findings to more complex real-world networks.
- The clarity of the presentation is lacking in several areas, including the definition of terms and the experimental setup.
- Some reviewers were unable to reproduce the results, raising concerns about the accuracy of the AMP algorithm.
- The parameterization used in the experiments was questioned, suggesting potential discrepancies in the implementation.
- The motivation for the chosen settings was deemed insufficiently articulated, which may detract from the paper's relevance to practical applications.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by explicitly defining terms and ensuring that the analysis is accessible, particularly regarding the local nature of the analysis and its implications. Additionally, we suggest that the authors include numerical simulations comparing their classifier with other estimators in non-locally tree-like settings to strengthen the paper's applicability. It would also be beneficial to discuss the scalability of the proposed method and provide more experimental results on existing benchmarks to validate the claims made. Furthermore, we recommend that the authors improve the clarity of the experimental setup by specifying what constitutes a training batch and whether the network sees all node labels in the training graph. We also suggest including a discussion on the motivation for their chosen settings to better articulate their relevance to real-world applications. Providing a detailed comparison with previous message-passing algorithms for large-dimensional features could enrich the manuscript, and we encourage the authors to clarify the parameterization used in their experiments to address reproducibility concerns. Finally, addressing the limitations of focusing solely on locally tree-like graphs would enhance the paper's impact.