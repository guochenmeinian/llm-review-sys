ID: gktA1Qycj9
Title: CigTime: Corrective Instruction Generation Through Inverse Motion Editing
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 6, 5, 5, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 5, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to generating corrective instructional text based on motion editing and generation models, specifically targeting applications in sports coaching and motor skill learning. The authors propose a method that utilizes a user's current motion (source) and the desired motion (target) to generate text instructions, leveraging a dataset of motion triplets (source motion, target motion, and corrective text) and a fine-tuned large language model (LLM) for instruction generation. The method demonstrates improved performance over traditional approaches, which often require extensive manual annotations.

### Strengths and Weaknesses
Strengths:
1. The paper introduces an innovative task of generating motion corrective instructions, which is both interesting and potentially impactful.
2. The authors compile a dataset that supports their approach, although it is unclear if it will be publicly available.
3. The writing is clear, and the method is easy to follow, with comprehensive evaluations demonstrating its effectiveness.

Weaknesses:
1. The reliance on motion inputs, which are difficult to obtain, may lead to estimation errors that limit the applicability of the method.
2. The data-generating pipeline's dependence on the motion-editing model raises concerns about error accumulation and overfitting.
3. The overall technical contribution appears limited, as the method seems to extend existing text-to-motion techniques without addressing significant challenges unique to this task.

### Suggestions for Improvement
We recommend that the authors improve the evaluation of the data quality generated by their pipeline, particularly addressing potential hallucinations from the LLM. Additionally, the authors should clarify their comparison strategies with baseline methods, ensuring fairness in the evaluation of different LLMs. It would be beneficial to provide detailed experimental settings for the Llama-3-8B-LoRA and discuss the implications of their division of motion instructions based on upper and lower body. Furthermore, we suggest that the authors explore continuous representations for motion tokens rather than discrete indexes to capture detailed spatial and temporal information. Lastly, addressing the potential social impact of their method would strengthen the paper's contribution.