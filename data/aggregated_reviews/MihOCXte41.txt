ID: MihOCXte41
Title: EDT: An Efficient Diffusion Transformer Framework Inspired by Human-like Sketching
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 6, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 1, 5, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Efficient Diffusion Transformer (EDT) framework, which aims to mitigate the high computational demands of transformer-based Diffusion Probabilistic Models (DPMs). The EDT features a lightweight architecture, a classifier-free Attention Modulation Matrix (AMM) inspired by human sketching, and a token relation-enhanced masking training strategy. Extensive experiments demonstrate that EDT significantly reduces training and inference costs while achieving superior performance in image synthesis, as evidenced by a lower FID score of 34.27 compared to existing models like MDTv2-S. Additionally, a comparative analysis of images generated by the EDT-XL model with and without the AMM plugin highlights that the addition of AMM does not negatively affect the original quality and improves realism in certain areas. The proposed masking training strategy outperforms MDT's masking strategy, particularly at higher mask ratios, demonstrating superior image reconstruction capabilities.

### Strengths and Weaknesses
Strengths:  
1. The introduction of a classifier-free approach and a focus on token relationships enhances the efficiency of transformer-based DPMs.  
2. The lightweight architecture and the Attention Modulation Matrix yield specific quantitative improvements in image quality.  
3. The visual analysis effectively illustrates the improvements in image realism with the AMM plugin.  
4. The proposed masking training strategy shows significant advantages over MDT's approach, particularly in reconstructing images at higher mask ratios.  

Weaknesses:  
1. The reliance on a pre-trained VAE may affect categorization accuracy for certain classes.  
2. The paper lacks details on the number of epochs or time estimates required for EDT to achieve its results.  
3. The evaluation primarily uses ImageNet, limiting the generalizability of findings across diverse datasets.  
4. The absence of experiments demonstrating the AMM's integration into other methods raises questions about its claimed versatility.  
5. The review lacks a detailed quantitative assessment to complement the qualitative results presented.  
6. There is limited discussion on the implications of the findings for broader applications or future research.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the limitations of their work, particularly regarding the computational trade-offs. Additionally, please provide a broader range of datasets, such as CelebA-HQ and Lsun-Churches, to validate the robustness of the EDT framework. It would also be beneficial to include experiments that showcase the AMM's effectiveness when integrated into various existing models. Furthermore, clarifying the motivation behind the lightweight design and enhancing the analysis of the MVD-v2 masking mechanism with additional figures would strengthen the paper. Lastly, ensure that qualitative results are included in the main text rather than relegated to the appendix for better visibility, and include a quantitative assessment to support the qualitative findings. Expanding the discussion on the implications of the results for broader applications and future research directions would also be advantageous.