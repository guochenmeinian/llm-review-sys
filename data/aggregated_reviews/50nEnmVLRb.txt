ID: 50nEnmVLRb
Title: Gaussian Process Bandits for Top-k Recommendations
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 6, 5, 5, 8, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel algorithm for top-k recommendation using bandit feedback, specifically leveraging Gaussian Process Upper Confidence Bound (GP-UCB) with a weighted Kendall kernel. The authors aim to enhance user satisfaction by focusing on the overall quality of recommendations rather than individual items. The proposed method improves computational complexity from \(O(T^4)\) to \(O(T^2)\) and derives an upper bound on cumulative regret, demonstrating sublinear regret through synthetic experiments that outperform several baselines.

### Strengths and Weaknesses
Strengths:
- Extends the literature on top-k recommendations with a GP-UCB algorithm.
- Well-organized and clearly presented, with detailed experimental results.
- Achieves state-of-the-art performance in top-k recommendation tasks and improves computational efficiency.

Weaknesses:
- The approach lacks scalability to real-world problems, as empirical evaluations are limited to small item sets (n â‰¤ 50) and short horizons (T < 500).
- The theoretical contribution needs clarification, particularly regarding its novelty compared to Krause & Ong (2011).
- The algorithm's reliance on a local search approach for the acquisition function does not account for the approximation in regret analysis, and the use of an approximate posterior creates discrepancies with theoretical analysis.

### Suggestions for Improvement
We recommend that the authors improve the theoretical analysis by clarifying the novelty of their contribution compared to Krause & Ong (2011). Additionally, the authors should address the scalability concerns by evaluating their algorithm on larger item sets and longer horizons. It would be beneficial to provide a detailed discussion on the choice of the Kendall kernel, including its advantages over other kernels. Furthermore, we suggest that the authors consider comparing their method with existing works on top-k combinatorial bandits with full-bandit feedback, such as Rejwan and Mansour (2020), to highlight the differences and novelty of their approach. Lastly, we encourage the authors to rephrase the statement regarding assumptions about the objective or reward for clarity.