ID: E5r96sfKO0
Title: AutoTrial: Prompting Language Models for Clinical Trial Design
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, 3

Aggregated Review:
### Key Points
This paper presents a study on generative language models for designing clinical trials, specifically focusing on the generation of inclusive and exclusive criteria. The authors propose a novel prompting-based framework, trained from scratch using existing clinical trial announcements, which outputs both the criteria and the reasoning steps involved in their generation. The method, named AutoTrial, incorporates instruction prompt tuning, scalable knowledge incorporation via in-context learning, and multi-step reasoning, demonstrating superior performance against strong baselines.

### Strengths and Weaknesses
Strengths:
- The paper introduces a novel task in clinical trial design, potentially aiding drug development.
- It effectively communicates the motivation for clinical trial protocol design.
- The proposed model outperforms many strong baselines and includes a comprehensive evaluation of various metrics.
- The ablation study highlights the contributions of different model components.

Weaknesses:
- The paper is dense and difficult to follow, particularly for readers unfamiliar with prompting techniques.
- Key details regarding the implementation and experimental setup are lacking, such as the number of runs and hyperparameters.
- The coverage of the external knowledge base may not be sufficient for all queries, and the reproducibility of results is questionable due to insufficient detail.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by addressing the missing details in Section 3, particularly regarding the input components and the maximum context length. It is crucial to provide references for claims made in the introduction to support the novelty of their work. Additionally, the authors should ensure that the data and code will be made available, as this is essential for reproducibility. Lastly, we suggest revising the neural prompt section to enhance accessibility for readers who are not experts in prompting techniques.