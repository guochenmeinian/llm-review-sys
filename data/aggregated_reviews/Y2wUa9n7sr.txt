ID: Y2wUa9n7sr
Title: VISTA: Visual-Textual Knowledge Graph Representation Learning
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 8
Original Ratings: -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to knowledge graphs through the introduction of visual-textual knowledge graphs (VTKGs), where triplets are explained by images and entities and relations are described in detail. The authors propose a method called VISTA for knowledge graph representation learning, utilizing ViT for visual feature extraction and BERT for textual feature extraction. Extensive experiments demonstrate that VISTA outperforms ten state-of-the-art (SOTA) methods across four real-world datasets.

### Strengths and Weaknesses
Strengths:
- The introduction of VTKGs is an innovative step that enriches knowledge graph representation.
- The creation of benchmark datasets with visually explainable triplets is a significant contribution.
- VISTA shows promising results in knowledge graph completion tasks, supported by comprehensive experiments.

Weaknesses:
- The paper's writing lacks clarity, particularly in the initial sections, making it difficult to grasp the method's overview.
- The experimental setup may lack practical application, as the use of triple images during training is not feasible during testing.
- The quality of the constructed VTKG is uncertain due to potential error accumulation in the dataset merging process, and validation of each pipeline step is missing.
- Some claims and experimental results require further support and clarity, particularly regarding the effectiveness of incorporating image information.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing, especially in the introductory sections, to enhance understanding of the proposed method. Additionally, we suggest conducting an ablation study to quantitatively validate the effectiveness of incorporating image information into triplets. It would also be beneficial to provide more detailed validation of the VTKG quality and the experimental setup, including the handling of triple images during testing. Finally, addressing the concerns regarding the originality of VISTA and ensuring that all necessary datasets and code are made available for reproducibility would strengthen the paper.