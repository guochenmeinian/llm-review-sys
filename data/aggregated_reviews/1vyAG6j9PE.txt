ID: 1vyAG6j9PE
Title: Unexpected Improvements to Expected Improvement for Bayesian Optimization
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 8, 7, 7, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 4, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a critical examination of the numerical pathologies associated with Bayesian expected improvement (EI) acquisition functions, particularly their vanishing gradients, which hinder optimization. The authors propose a reformulated acquisition function, LogEI, which enhances numerical stability while maintaining comparable optima to EI. Theoretical bounds on the approximation error between qEI and qLogEI are established, and empirical results demonstrate that LogEI significantly outperforms EI across various tasks, suggesting its potential as a drop-in replacement.

### Strengths and Weaknesses
Strengths:
- The paper addresses a previously neglected aspect of Bayesian optimization, focusing on acquisition function optimization and the numerical issues tied to EI.
- The proposed modifications to EI, including improvements for Monte Carlo Parallel EI and Constrained EI, show strong empirical performance and theoretical backing.
- The clarity of presentation and the extensive numerical experiments bolster the claims made regarding the superiority of the proposed methods.

Weaknesses:
- The treatment is limited to acquisition functions exhibiting vanishing gradient issues, which may restrict its applicability.
- There is insufficient theoretical support for the claim that LogEI and EI share similar optima, particularly given the substantial performance differences observed in experiments.
- The paper lacks references to existing work on LogEI and does not adequately address its relevance in high-dimensional settings.

### Suggestions for Improvement
We recommend that the authors improve the theoretical justification for the similarity between LogEI and EI, potentially by providing additional lemmas or examples that clarify their relationship. Additionally, we suggest including citations and comparisons to existing implementations of LogEI in related work to enhance the novelty of the approach. Expanding the discussion on the relevance of LogEI in high-dimensional problems, particularly regarding the distinction between zero-value and constant-value acquisition functions, would also strengthen the paper. Finally, addressing the adaptation of LogEI for noisy tasks and including performance benchmarks on conventional low-dimensional tasks would provide valuable insights for future research.