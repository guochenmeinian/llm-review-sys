ID: adjZtG9bDM
Title: Evaluation of African American Language Bias in Natural Language Generation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a thorough investigation into the understanding of African-American English (AAE) by large language models (LLMs) compared to Standard American English (SAE). The authors assess various LLMs on two tasks: (1) conversion between American English variants and (2) masked span prediction for AAE. They find that LLMs infer toxicity more frequently in AAE text, indicating potential biases, and demonstrate a poorer understanding of AAE compared to SAE. The authors also contribute a dataset of AAE text samples, which is valuable for future research.

### Strengths and Weaknesses
Strengths:
- The paper provides a comprehensive evaluation of LLMs' understanding of AAE through well-designed tasks.
- It includes a broad range of LLMs and tuning paradigms, offering a detailed perspective on performance.
- The methodology and results are clear and well-supported by data, contributing significantly to the field.

Weaknesses:
- The paper lacks information about the demographics of annotators and human evaluators, which may affect interpretation.
- The experimental setting is questioned, particularly the validity of comparing results from different test data.
- The motivation for focusing on AAE is unclear, and the definition of "bias" may be misleading.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation and importance of the study, particularly regarding the focus on AAE. Additionally, it would be beneficial to include demographic information about annotators and evaluators in a datasheet. We urge the authors to reflect on the definition and usage of "bias" in the paper to ground it in experienced harms, enhancing the impact of their findings. Furthermore, please report the generation hyperparameters used and the results for FlanT5 without finetuning, as well as clarify the rationale for using debertalargemnli for BERTScore.