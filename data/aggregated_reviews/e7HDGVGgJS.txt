ID: e7HDGVGgJS
Title: Uncertainty Quantification and Calibration for Audio-driven Disease Diagnosis
Conference: NeurIPS
Year: 2024
Number of Reviews: 2
Original Ratings: 9, 6
Original Confidences: 3, 5

Aggregated Review:
### Key Points
This paper presents a novel framework for incorporating uncertainty quantification (UQ) into audio-driven disease diagnosis models. It addresses a crucial limitation of deep learning models, which often lack the ability to quantify confidence in predictions, leading to overconfident and erroneous diagnoses. The authors propose a unified approach that integrates UQ with audio-driven disease detection using a Dirichlet density approximation and independent kernel distance learning. Validation on two medical audio detection datasets, ICBHI and COSWARA, demonstrates significant decreases in calibration error and state-of-the-art performance on the ICBHI4 dataset.

### Strengths and Weaknesses
Strengths:
- The paper is one of the first to address UQ in audio classification.
- It improves model reliability by producing confidence scores that align closely with accuracy values.
- The method requires minimal modifications to existing audio encoder architectures and is computationally efficient.
- The framework shows generalizability across large public respiratory disease datasets.

Weaknesses:
- The primary section spans 9 pages, contributing to a total of 26 pages when including the appendix, references, and NeurIPS checklist.
- The writing is difficult to follow due to formatting issues, particularly with citations.
- Limited experimental details are provided regarding hyperparameter tuning, training details, and validation strategies.
- There is no explicit comparison of the proposed method's performance with existing UQ methods like dropout and ensemble models.

### Suggestions for Improvement
We recommend that the authors condense the paper to meet the 4-page extended abstract requirement. Additionally, we suggest improving the clarity of the writing by addressing formatting issues, especially in citations. To enhance the experimental rigor, the authors should provide more details on hyperparameter tuning, training protocols, and validation strategies. Finally, we encourage the authors to include explicit comparisons with existing UQ methods to better contextualize their contributions.