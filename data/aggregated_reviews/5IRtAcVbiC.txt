ID: 5IRtAcVbiC
Title: e-COP : Episodic Constrained Optimization of Policies
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 5, 4, 7, -1, -1, -1, -1
Original Confidences: 5, 2, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a policy optimization algorithm for constrained Reinforcement Learning (RL) in a finite horizon setting, termed e-COP. The authors develop a policy difference lemma for finite horizon MDPs and combine several concepts to propose the e-COP algorithm, which demonstrates superior numerical stability compared to existing solutions. The algorithm's optimality is established under specific assumptions, and extensive simulations indicate its performance exceeds that of current methods.

### Strengths and Weaknesses
Strengths:  
- The paper is well-written and clear, making it easy to follow.  
- The proposed algorithm shows strong empirical performance and introduces the novel concept of quadratic damping penalty in safe RL.  
- Extensive benchmarking against state-of-the-art algorithms is conducted, with e-COP outperforming most baselines.

Weaknesses:  
- The use of a quadratic penalty term for stability near the constraint boundary is heuristic and lacks strong theoretical justification.  
- The approximation of $\rho_{\pi}$ using the empirical distribution from the previous episode is questionable, particularly in finite horizon settings.  
- The algorithm's novelty is limited, as it incorporates existing ideas without significant innovation.  
- There are issues with clarity in the presentation, including typos and unclear definitions in equations.  
- The paper does not adequately address the limitations of the proposed algorithm.

### Suggestions for Improvement
We recommend that the authors improve the theoretical justification for using a quadratic penalty term and clarify how the time-dependent state occupation distribution is computed. Additionally, addressing the limitations of the algorithm in a dedicated section would enhance the completeness of the paper. We suggest revising the presentation to correct typos and clarify ambiguous statements, particularly in Algorithm 2 and Equation 8. Finally, including results from ablation studies to demonstrate the importance of the quadratic damping penalty would strengthen the contribution of the paper.