ID: KoSSEp6Du5
Title: E.T. Bench: Towards Open-Ended Event-Level Video-Language Understanding
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 8, 6, 6, 8, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 5, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive video understanding benchmark, E.T. Bench, aimed at evaluating Video-LLMs through multiple tasks such as referring, grounding, dense captioning, and complex understanding, with a focus on event-level and time-sensitive comprehension. The authors propose a new baseline model, E.T. Chat, along with an instruction-tuning dataset, E.T. 164K. The benchmark's originality lies in its careful filtering for event-level assessment, and extensive evaluations demonstrate the effectiveness of the proposed model and dataset.

### Strengths and Weaknesses
Strengths:
1. The paper is well-structured, clearly introducing the motivation and detailing the benchmark's construction.
2. E.T. Bench provides a robust evaluation framework for assessing event-level understanding capabilities, supported by a well-defined 3-level task taxonomy.
3. The novel timestamp processing design and multi-event instruction-tuning dataset effectively address existing model limitations.

Weaknesses:
1. The dataset may challenge accurate ranking of Video-LLMs due to separate evaluations on multiple subsets, lacking a unified metric for overall performance.
2. Other baseline models may not be tuned on similarly defined tasks, leading to potentially unfair comparisons.
3. The writing contains typos and overclaims regarding the performance of image- and video-LLMs, particularly in relation to the E.T. Chat model.

### Suggestions for Improvement
We recommend that the authors improve the writing by proofreading for typos and clarifying claims regarding model performance, especially the expected gap between commercial LLMs and E.T. Chat. Additionally, we suggest expanding the benchmark to include more diverse tasks, such as multi-modal reasoning or causal inference, and providing a direct comparison with other time-sensitive Video-LLMs to strengthen the argument for E.T. Chat's effectiveness. Furthermore, enhancing figure presentations for clarity, such as using histograms instead of word clouds and illustrating notations in figures, would improve the overall presentation.