ID: dl4e3EBz5j
Title: GlotLID: Language Identification for Low-Resource Languages
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a language identification method focused on low-resource languages, covering 1665 languages and curating a dataset for training language identification models. The authors propose a fastText model trained on this dataset and provide a comparison with strong baseline models. The paper emphasizes the importance of corpus creation for low-resource languages and includes extensive experiments and analyses to support its claims.

### Strengths and Weaknesses
Strengths:
- The dataset, GlotLID-M, includes a diverse range of languages and is not sourced from web scraping, addressing data quality issues.
- The paper is well-structured and clearly outlines the motivation and methodology, with careful justification for evaluation measures.
- The authors plan to release the code and data, enhancing reproducibility.

Weaknesses:
- The UDHR-based test set raises concerns about potential contamination from training data, and key details about the test set are unclear.
- The paper over-claims the number of languages supported by the model, lacking clarity on the distribution of training data across languages.
- The evaluation relies solely on off-the-shelf models, limiting the contribution's novelty.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the test set details, ensuring that it is explicitly stated that the UDHR test set does not appear in the training data. Additionally, the authors should provide a precise list of sources used for dataset construction and clarify the decision rules applied. It would be beneficial to include statistical deviation across multiple runs and examples illustrating where the proposed method outperforms existing methods. Furthermore, we suggest that the authors address the disparity in language support by detailing the number of languages with sufficient training data and revising the evaluation metrics to account for "undetermined" labels. Lastly, enhancing the readability of the appendix and expanding on the architecture of the fastText model would strengthen the paper.