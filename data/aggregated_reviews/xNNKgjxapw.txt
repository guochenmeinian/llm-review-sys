ID: xNNKgjxapw
Title: Ensuring User-side Fairness in Dynamic Recommender Systems
Conference: ACM
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the FAir Dynamic rEcommender (FADE), a framework aimed at ensuring user-side fairness in dynamic recommendation systems. The authors propose a fairness loss integrated with the Differentiable Hit to tackle the gradient vanishing issue found in the NeuralNDCG method, enhancing efficiency. However, the paper raises concerns about the effectiveness of its proposed modules, such as the BPR-based loss, and the relevance of the fine-tuning technique to user fairness.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and presents an important research problem.
- The theoretical analysis effectively compares fine-tuning and retraining concerning generalization error under distribution shift.
- The incremental fine-tuning balances fairness and utility, and extensive experiments demonstrate FADE's ability to mitigate performance disparities.

Weaknesses:
- The paper lacks relevant references and fails to clarify the relationship between fairness and theorems presented.
- Only F1/NDCG@20 results are reported, with a need for additional metrics and graphical representations of baseline comparisons.
- Sections 3.3 and 3.4 appear unrelated to the main discussion, and the use of existing methods does not demonstrate clear novelty.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the relationship between fairness and theorems in the proofs, specifically pointing out relevant lines. Additionally, the authors should include more baseline comparisons, such as the IPS method, and clarify the rationale behind the metric change from DPD to PD. It would also be beneficial to expand the discussion in Section 3.1 to better align with recommendation systems and to provide results with different lengths and additional fairness metrics. Finally, we suggest addressing the sequential nature of the data and exploring the derivation of optimal retraining intervals for minimizing regret.