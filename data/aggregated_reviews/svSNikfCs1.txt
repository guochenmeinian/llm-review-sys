ID: svSNikfCs1
Title: Exploiting Asymmetry for Synthetic Training Data Generation: SynthIE and the Case of Information Extraction
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for generating synthetic training data for information extraction (IE) using large language models (LLMs), specifically addressing the challenges of structured output in closed information extraction tasks. The authors propose a systematic approach to sample triplets from a knowledge graph and generate corresponding text, demonstrating the high quality of the synthetic data compared to human-curated datasets like REBEL. The paper includes extensive experiments and human evaluations, validating the effectiveness of the synthetic data generation method.

### Strengths and Weaknesses
Strengths:  
- The paper is well-written and organized, providing a clear methodology for synthetic data generation.  
- It demonstrates that model-generated training data can outperform human-curated data in closed information extraction tasks, contributing valuable evidence to the field.  
- The authors conduct a thorough comparative analysis, ensuring a robust validation of their approach.  

Weaknesses:  
- The reliance on LLMs for dataset generation may introduce noise and limit the method's effectiveness for certain models.  
- The task and data scope may be narrow, potentially restricting audience interest.  
- The model trained on synthetic data underperformed compared to existing baselines, raising concerns about the acceptability of this performance loss.

### Suggestions for Improvement
We recommend that the authors improve the robustness of their method by addressing the potential noise introduced by LLMs and exploring alternative generation strategies. Additionally, we suggest expanding the scope of the tasks and datasets to attract a broader audience. It would also be beneficial for the authors to provide a detailed analysis of the samples where their model succeeded compared to REBEL, clarifying the reasons for performance discrepancies.