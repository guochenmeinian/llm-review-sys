ID: BCA9NMZkLS
Title: BERTs are Generative In-Context Learners
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 7, 7, 7, 3, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the capabilities of masked language models (MLMs), specifically DeBERTa, as in-context learners, suggesting that they can perform comparably to autoregressive models like GPT-3 in certain tasks. The authors propose generative inference techniques that allow MLMs to generate text and rank sequences by likelihood. The findings indicate that while DeBERTa excels in tasks such as text completion and SuperGLUE, it underperforms in machine translation compared to GPT-3.

### Strengths and Weaknesses
Strengths:
- The paper challenges the prevailing focus on autoregressive models, highlighting the potential of MLMs as generative in-context learners.
- Limitations of the proposed techniques are acknowledged, providing constructive future directions.
- The writing and visuals are clear, enhancing readability.

Weaknesses:
- The experimental comparisons may be biased, as MLMs have access to more context than autoregressive models, potentially skewing results in tasks requiring long-term dependency resolution.
- The choice of models for comparison, particularly using OPT against DeBERTa, may mislead readers due to OPT's known performance issues.
- The proposed modifications to MLMs lack technical depth and novelty, raising questions about the overall contribution of the work.

### Suggestions for Improvement
We recommend that the authors improve the fairness of comparisons by devising a technique that removes all right context during sequence ranking. Additionally, consider using more recent generative models such as Llama-2, Llama-3, Phi-2, and Phi-3 for comparisons, and include other masked LMs like BERT and T5 to strengthen the argument regarding DeBERTa's performance. Furthermore, we encourage the authors to provide a more technically robust discussion of their modifications and to clarify the implications of their findings on in-context learning. Lastly, addressing the limitations of the sampling procedures and providing a comprehensive evaluation of different sequence-scoring methods would enhance the paper's rigor.