ID: fqWbXPX99P
Title: CT-GAT: Cross-Task Generative Adversarial Attack based on Transferability
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for generating universal adversarial attacks across various NLP tasks using a model called CT-GAT. The authors aim to reduce reliance on victim model information by constructing adversarial samples from transferable features. The experiments demonstrate promising attack performance, indicating the method's effectiveness.

### Strengths and Weaknesses
Strengths:
- The core idea is intuitive and easy to follow.
- The research topic is interesting and important, with thorough evaluations across multiple datasets and tasks.
- The method shows high transferability and query efficiency.

Weaknesses:
- There are formatting errors, such as Table 3 being incorrectly labeled as Fig 3.
- Key technical details about the CT-GAT model and its training process are inadequately explained.
- The clarity of figures and certain sections, such as the objective of Figure 1 and the explanation of transferability, is lacking.
- The perturbation bounds of the attack are not explicitly controlled, raising questions about the validity of success rates.
- The discussion of potential defenses against the attack is insufficient and could be improved.

### Suggestions for Improvement
We recommend that the authors improve the clarity of figures and provide a more detailed explanation of the training process, including the loss functions used for different tasks. Additionally, the authors should clarify the objective of Figure 1 and enhance the explanation of how CT-GAT ensures transferability. It would also be beneficial to explicitly control the perturbation bounds and discuss more effective defense approaches, such as adversarial training. Lastly, we suggest adding quantitative analysis to evaluate the relationship between transferability and attack success rates.