ID: tYdR1lTWqh
Title: Reversing the Forget-Retain Objectives: An Efficient LLM Unlearning Framework from Logit Difference
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 6, 6, 7, -1, -1, -1, -1, 5, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, -1, -1, -1, -1, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an efficient framework for unlearning in Large Language Models (LLMs) called "Unlearning from Logit Difference" (ULD). ULD addresses challenges such as degeneration and catastrophic forgetting by introducing an assistant LLM with reversed learning objectivesâ€”remembering the documents to forget while forgetting the retained knowledge. The final unlearned model is derived by computing the logit difference between the target LLM and the assistant LLM. Experiments demonstrate that ULD improves training efficiency, achieving intended forgetting while preserving overall capabilities, and reduces training time by over threefold compared to baseline methods.

### Strengths and Weaknesses
Strengths:  
- Originality: The introduction of an assistant LLM with reversed learning objectives is a novel approach to LLM unlearning.  
- Quality: The method is rigorously evaluated through extensive experiments, demonstrating clear advantages over existing methods.  
- Clarity: The paper is well-organized and clearly explains the proposed method and its benefits.  
- Significance: The approach addresses critical challenges in LLM unlearning, making it highly relevant for privacy and data management.

Weaknesses:  
- Inference Latency: The involvement of an assistant LLM during inference may lead to higher latency, although this can be mitigated through parallelization.  
- Data Augmentation: The method's effectiveness relies on augmented data for forget and retain documents, which may require additional effort.  
- Limited Datasets: The experiments are conducted only on TOFU and Harry Potter datasets, suggesting a need for more diverse datasets and cross-domain continual learning.  
- Hallucination Problem: The method exhibits severe hallucination issues, producing false answers during forget queries.  
- Presentation: Results in large tables are difficult to parse, and sections exceed the page limit.

### Suggestions for Improvement
We recommend that the authors improve the clarity of results presentation, possibly through visualizations or plots to enhance readability. Additionally, we suggest addressing the hallucination problem in forget queries, as this significantly impacts user trust. The authors should also consider expanding experiments to include more datasets, such as RealToxicPrompts and WPU, to validate the method's effectiveness across different domains. Finally, we encourage the authors to clarify the significance of their contributions regarding unbounded forgetting loss and under-representative retain knowledge, ensuring that claims are well-supported and not oversimplified.