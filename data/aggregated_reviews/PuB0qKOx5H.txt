ID: PuB0qKOx5H
Title: Towards Group-aware Search Success
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: 0, 1, -1, -1
Original Confidences: 4, 3, 3, 4

Aggregated Review:
### Key Points
This paper presents a new metric called Group-aware Search Success (GA-SS) to evaluate search result quality across different demographic groups. The authors propose a mathematical framework that integrates static and stochastic ranking policies, along with user browsing models, to compute GA-SS. They also introduce the Group-aware Most Popular Completion (gMPC) ranking model to account for demographic variations in user intent. The metric is empirically validated using two real-world datasets—query auto-completion and movie recommendations—demonstrating the importance of stochasticity and the complex interactions among search success metrics.

### Strengths and Weaknesses
Strengths:
1. The assumption that search success is achieved only when all demographic groups find success is reasonable and well-motivated, with a solid definition and derivation of the proposed metric.
2. Validation through a toy example and two real-world datasets supports the proposed metric, particularly the correlation analysis in Section 5.5, which shows GA-SS differs from DA-SS.

Weaknesses:
1. The computation of GA-SS relies on user intents, which are difficult to obtain in real situations, limiting the metric's applicability.
2. Some calculations in Figure 2 are confusing; for instance, GA-SS within query should be 0 for both queries if the respective demographic groups are not satisfied.
3. Section 3.3 appears irrelevant to the paper's main topic.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the novelty of their contribution, particularly in relation to the work of Diaz et al. (reference [9]). It is essential to explicitly state how their work integrates or modifies existing approaches, especially concerning item exposure and fairness evaluation. Additionally, we suggest that the authors relate their work to the TREC fairness track and clarify why those datasets are not applicable. The authors should also articulate the intended role of the experiments and what they aim to demonstrate regarding group-related preferences. Finally, we advise elaborating on the ethical implications of their evaluation approach, particularly concerning potential biases in movie recommendations based on gender.