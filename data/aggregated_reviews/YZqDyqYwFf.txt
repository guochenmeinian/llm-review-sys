ID: YZqDyqYwFf
Title: A Closer Look at System Message Robustness
Conference: NeurIPS
Year: 2024
Number of Reviews: 1
Original Ratings: 7
Original Confidences: 4

Aggregated Review:
### Key Points
This paper presents an exploration of the robustness of system messages in large language models (LLMs), particularly their vulnerability to adversarial attacks like prompt injection. System messages are intended to guide LLM behavior by establishing rules that should override user inputs. However, these guidelines are frequently disregarded in adversarial contexts. The authors develop a new dataset, SUDO, along with benchmarks (RULES, Gandalf, TensorTrust) to evaluate system message robustness and fine-tune LLMs for better compliance. The paper is deemed practically useful for the research community.

### Strengths and Weaknesses
Strengths:  
- The introduction of the SUDO dataset, derived from real-world system prompts and encompassing both benign and adversarial user messages, is a notable contribution. Its design addresses a broad spectrum of scenarios, including tool-assisted LLMs, enhancing its practical applicability.  
- The authors offer a clear and structured evaluation framework with benchmarks such as RULES, Gandalf, and TensorTrust.  

Weaknesses:  
- The paper does not adequately investigate the generalization of these methods across various LLM types. While Mistral-7B is relevant, including performance data from different model families (e.g., Llama) would be beneficial.  
- The SUDO dataset, although valuable, is relatively small (13.9K training samples and 3.8M tokens), and the authors should discuss its limitations more thoroughly.  
- The authors should add a paragraph addressing the trade-offs in deploying robust models, such as potential increases in inference time, memory usage, or hardware costs, to enhance the paper's practical completeness.  
- There is a lack of discussion regarding potential adversarial bypasses; insights into whether more sophisticated attacks could exploit existing vulnerabilities would be valuable.  

### Suggestions for Improvement
We recommend that the authors improve the exploration of generalization across different LLM families by including performance metrics from models such as Llama. Additionally, we suggest a more thorough discussion of the limitations of the SUDO dataset due to its size. It would also be beneficial to include a paragraph on the trade-offs associated with deploying robust models, particularly concerning inference time, memory usage, and hardware costs. Finally, we encourage the authors to discuss potential adversarial bypasses and the implications of more sophisticated attacks on their findings.