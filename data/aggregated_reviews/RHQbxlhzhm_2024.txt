ID: RHQbxlhzhm
Title: FastSurvival: Hidden Computational Blessings in Training Cox Proportional Hazards Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 4, 9, 7, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an alternative optimization method for the Cox proportional hazards model, deriving quadratic and cubic upper bounds on the loss and minimizing these bounds with respect to a single model parameter at a time, akin to coordinate descent. The authors validate their method on standard survival analysis benchmarks and apply it to a feature selection problem involving highly correlated features. 

### Strengths and Weaknesses
Strengths:  
- The topic of survival analysis with large datasets and high dimensionality is relevant to the community.  
- The prose is generally clear, making the background information accessible to non-experts.  
- The proposed algorithm demonstrates faster convergence by exploiting higher-order derivatives and surrogate functions.

Weaknesses:  
- The paper does not make a significant contribution to the literature, as the runtime reduction results for computing derivatives are trivial.  
- Experimental results on runtime improvements are misleading, particularly regarding the Flchain dataset, which shows unreasonable convergence times.  
- Several mathematical inaccuracies and unclear definitions exist, such as the treatment of derivatives and the claim of monotonic loss decrease.

### Suggestions for Improvement
We recommend that the authors improve the clarity of definitions, particularly in equation (6), where $\ell$ should be consistently defined. Additionally, we suggest providing a mathematical justification for the robustness of the method against highly correlated features and addressing the inaccuracies in the probabilistic interpretations of derivative expressions. It would also be beneficial to include comparisons with O(n) gradient descent frameworks like fastCPH and to clarify the preprocessing steps used in their experiments. Finally, we advise the authors to justify their claims regarding the novelty of minimizing cubic surrogate functions and to ensure that all mathematical assertions are rigorously supported.