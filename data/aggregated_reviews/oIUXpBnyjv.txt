ID: oIUXpBnyjv
Title: LightZero: A Unified Benchmark for Monte Carlo Tree Search in General Sequential Decision Scenarios
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 7, 6, 7, 7, 9, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents LightZero, a PyTorch-based framework that offers a clean and comprehensive implementation of various MCTS/MuZero-like algorithms. It integrates nine algorithm types and supports over twenty environments, including Atari and Go. The authors provide a thorough analysis of the challenges associated with general MCTS-like decision-making solvers and detail the modular implementation of each algorithm component. Extensive experiments validate the correctness of the implementation, yielding useful insights into algorithm performance. The authors also propose GoBigger as a real-world application inspired by Agar.io and discuss its performance across different player modes, as well as the application of LightZero to UAV swarm management. They acknowledge the need for improved documentation and have released the framework on GitHub, with ongoing enhancements.

### Strengths and Weaknesses
**Strengths:**
1. Clean implementations of a wide range of complex MCTS/MuZero-like algorithms.
2. Comprehensive integration of multiple algorithms and environments.
3. Thorough analysis of challenges in general decision-making solvers.
4. Extensive experiments yielding useful insights into algorithm performance.
5. Practical application of LightZero in real-world scenarios like UAV management.
6. Modular design allows for separate study of components, enhancing usability.
7. Commitment to addressing grammatical errors and enhancing clarity in the manuscript.

**Weaknesses:**
1. Limited discussion on failure cases, which could provide valuable insights for algorithm selection.
2. The paper does not sufficiently explore the impact of the number of players on algorithm performance.
3. Some findings may not contribute new scientific discoveries, as they are already known within the community.
4. Clarity issues and grammatical mistakes detract from the overall presentation.
5. The arbitrary nature of algorithm ratings needs improvement.
6. Limited exploration of fail cases and the need for more extensive experiments in challenging benchmarks.

### Suggestions for Improvement
We recommend that the authors improve the discussion on failure cases to enhance understanding of algorithm selection and tuning. Additionally, the authors should extend their analysis on how the number of players influences RL performance, particularly in cooperative versus competitive environments. A more in-depth exploration of how game properties affect algorithm behavior is also suggested. Furthermore, we encourage the authors to clarify the framework's components and their mapping to specific algorithms, as well as address clarity issues and grammatical errors throughout the manuscript. We also recommend improving the clarity of algorithm ratings to enhance quantitative scoring and conducting more extensive experiments on complex benchmarks to validate the robustness of LightZero. Finally, we suggest refining the documentation further to facilitate user understanding and integration of new algorithms.