ID: LlcygqLdwO
Title: Visual-TCAV: Explainability of Image Classification through Concept-based Saliency Maps
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 8, 5, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Visual-TCAV, a method that combines TCAV with saliency maps to provide both local and global explanations for image classifiers. The authors propose learning a Pooled-CAV per concept from feature maps of a selected network layer and integrating this with integrated gradients (IG) to localize concepts within images. They analyze the impact of layer selection on local and global explanations across various CNN models pretrained on ImageNet and validate their method using a dataset with known ground-truth features.

### Strengths and Weaknesses
Strengths:
- The method enhances TCAV by adding localization capabilities, improving the explanation of black-box CNN classifiers.
- The paper is well-written, with a clear presentation and thorough experimentation, including a validation experiment that demonstrates the method's effectiveness.
- The investigation of layer selection provides valuable insights into concept activation across different layers.
- Qualitative results indicate strong localization abilities, and the method is relatively fast for generating explanations.

Weaknesses:
- The novelty of the method is limited, as similar localization techniques exist, and comparisons to these methods are lacking.
- The requirement for users to manually curate example images for concept identification restricts the method's applicability.
- The analysis does not extend to ViTs or datasets beyond ImageNet, limiting generalizability.
- The use of generative models for certain concepts lacks justification, raising questions about their necessity.

### Suggestions for Improvement
We recommend that the authors improve the discussion of the limitations related to the manual selection of concepts, particularly in specialized domains where concepts may be difficult to define. Additionally, we suggest including comparisons to existing methods that localize CAVs to strengthen the paper's contribution. The authors should also consider extending their analysis to ViTs and other datasets to demonstrate the generalizability of their approach. Lastly, clarifying the necessity of using generative images and providing a rationale for their inclusion would enhance the paper's robustness.