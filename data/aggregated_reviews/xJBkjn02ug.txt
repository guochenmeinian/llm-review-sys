ID: xJBkjn02ug
Title: MuGSI: Distilling GNNs with Multi-Granularity Structural Information for Graph Classification
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a GNN knowledge distillation framework aimed at enhancing the expressiveness of MLPs for graph classification tasks. The authors propose a multi-granularity distillation strategy that includes graph-level, subgraph-level, and node-level losses to align knowledge between the teacher GNN and student MLP. The effectiveness of the proposed MuGSI framework is evaluated across multiple benchmark datasets.

### Strengths and Weaknesses
Strengths:
1. The paper is well-organized and easy to follow, with clear visualizations.
2. The study addresses a meaningful and under-explored application of knowledge distillation in graph classification.
3. Comprehensive experiments validate the effectiveness of the proposed method.

Weaknesses:
1. The technical contributions are limited, as the multi-granularity structural information is represented trivially using the ReadOut function.
2. The motivation for focusing on graph classification rather than node-level tasks is not clearly articulated.
3. The individual components of the distillation loss are not novel, and performance improvements over baseline models appear marginal.
4. The datasets used for evaluation are not sufficiently large, and there is a lack of detailed discussion on their characteristics.
5. The computational complexity of the proposed method is not adequately addressed.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation behind their work, particularly in relation to the advantages of graph classification over node-level tasks. Additionally, the authors should provide a more detailed description of the clustering method used and ensure that the node feature augmentation is more innovative. We encourage the authors to include larger datasets, such as ogbg-molpcba and ogbg-ppa, in their evaluations and to conduct experiments that create distribution shifts based on established criteria. Furthermore, a more thorough comparison with existing KD frameworks for graph classification, along with a discussion of computational complexity and limitations, would enhance the paperâ€™s impact.