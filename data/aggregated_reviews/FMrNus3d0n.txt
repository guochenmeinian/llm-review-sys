ID: FMrNus3d0n
Title: GuardT2I: Defending Text-to-Image Models from Adversarial Prompts
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 5, 7, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents GuardT2I, a novel moderation framework designed to enhance the robustness of Text-to-Image (T2I) models against adversarial prompts. GuardT2I employs a fine-tuned conditional large language model (LLM) to map text embeddings to explicit prompts for effective detection of NSFW themes, while maintaining the quality of generated images. Extensive evaluations demonstrate that GuardT2I significantly outperforms existing commercial solutions like OpenAI Moderation and Microsoft Azure Moderator across various adversarial scenarios.

### Strengths and Weaknesses
Strengths:
- GuardT2I introduces an innovative approach to adversarial prompt filtering in commercial T2I generative models.
- The paper is well-written, with clear motivation and comprehensive evaluations, including detailed implementation setups.
- The proposed method is extensible and compatible with other LLM architectures, and it effectively addresses the detection of adversarial prompts.

Weaknesses:
- There is a lack of direct comparison between GuardT2I and other defense mechanisms, such as SafetyChecker and Safe Latent Diffusion, which is necessary to report the gap in performance.
- The settings of Table 6 are not clearly explained, particularly regarding the inference time of GuardT2I versus SafetyChecker, leading to confusion.
- The selection of evaluated adversarial prompts lacks motivation, as notable attacks like Ring-A-Bell and QF Attack are not included.
- The impact of GuardT2I on benign text prompts has not been evaluated, raising concerns about its effect on standard T2I generation tasks.

### Suggestions for Improvement
We recommend that the authors improve the paper by including a direct comparison of GuardT2I with other defense mechanisms to clarify its advantages and limitations. Additionally, please provide a clearer explanation of the settings in Table 6, particularly regarding inference times. It is also essential to justify the selection of adversarial prompts and consider including evaluations of notable attacks that were omitted. Finally, we suggest conducting an evaluation of GuardT2I's impact on benign text prompts to ensure it does not adversely affect standard T2I generation tasks.