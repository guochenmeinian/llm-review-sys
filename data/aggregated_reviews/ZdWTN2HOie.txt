ID: ZdWTN2HOie
Title: Stochastic Amortization: A Unified Approach to Accelerate Feature and Data Attribution
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 6, 5, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a stochastic amortization framework designed to accelerate computationally expensive explainable machine learning (XML) tasks by training models with noisy but unbiased labels. The authors propose obtaining noisy estimates of feature attributions (e.g., Shapley values) through sampling permutations and training a regression model to predict these estimates. The method is evaluated against ground-truth attribution values across various datasets, demonstrating effectiveness in improving performance over traditional methods.

### Strengths and Weaknesses
Strengths:
- The paper clearly articulates its motivations and approach, providing a well-structured theoretical analysis and empirical validation.
- The use of an amortized model enhances performance, showing significant speedups and applicability to large-scale datasets.
- Comprehensive experiments across multiple XML tasks consistently demonstrate the benefits of the proposed method.

Weaknesses:
- The related work section lacks a direct comparison with prior works, particularly regarding the specific nature of "amortization" and its distinction from existing methods.
- Experimental results do not include baselines from previous amortization techniques, limiting the context for evaluating the proposed method's performance.
- Concerns arise regarding the trustworthiness of neural network approximations for prediction explanations, as the accuracy of these approximations is not sufficiently validated.

### Suggestions for Improvement
We recommend that the authors improve the related work section by providing a more explicit comparison with prior methods, particularly clarifying the unique aspects of their approach to amortization. Additionally, including baseline comparisons with existing amortization techniques in the experimental results would strengthen the paper's contributions. We suggest addressing the concerns regarding the trustworthiness of the neural network approximations by providing a clearer validation of their accuracy and faithfulness to ground-truth explanations. Finally, we encourage the authors to clarify the relationship between Theorem 1 and the main claims regarding the efficiency of stochastic amortization to avoid potential confusion among readers.