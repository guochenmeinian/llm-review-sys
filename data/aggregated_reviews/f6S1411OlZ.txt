ID: f6S1411OlZ
Title: Towards a Unified Framework for Reference Retrieval and Related Work Generation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a unified framework, URWG, that integrates reference retrieval and related work generation using large language models (LLMs). The authors propose a method that reformulates queries and retrieves documents to enhance related work generation. Experimental results demonstrate that URWG outperforms baseline models in both generation and retrieval metrics across two widely used datasets.

### Strengths and Weaknesses
Strengths:  
1. The framework is innovative, combining reference retrieval and related work generation effectively.  
2. The paper is well-written and presents strong experimental results.  
3. It achieves state-of-the-art results on the TAS2 and TAD datasets, showcasing intellectual merit in its joint learning approach.  

Weaknesses:  
1. The paper lacks several important lexicon-aware baselines in Table 3, such as SPLADE v2, SPLADE++, and LED, and does not include methods post-2021.  
2. There is insufficient comparison with similar technologies, particularly regarding the Lexicon-Enhanced Dense Retrieval (LER) system, which resembles existing Dense Learning Representations (DLRs).  
3. The evaluation does not clearly attribute improvements to the conceptual framework versus the LLM itself, and human evaluations suggest that ChatGPT may perform better in certain contexts.

### Suggestions for Improvement
We recommend that the authors improve the comparison by including missing lexicon-aware baselines and clarifying the relationship between LER and existing technologies. Additionally, we suggest enhancing the evaluation by conducting a cross-domain generalization study to demonstrate the system's robustness. The authors should also provide more detailed analyses of the human evaluation results, particularly regarding the performance of ChatGPT versus their proposed system. Finally, consider allocating more space for results and error case analysis in the main body of the paper while condensing the methods section.