ID: ixVAXsdtJO
Title: Open Visual Knowledge Extraction via Relation-Oriented Multimodality Model Prompting
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 7, 4, 7, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents OpenVik, a novel framework for open visual knowledge extraction, which includes an open relational region detector and a format-free visual knowledge generator. The method aims to generate format-free knowledge by prompting a large multimodality model with detected regions of interest. The authors explore data enhancement techniques to diversify the generated knowledge and provide extensive evaluations demonstrating the correctness and uniqueness of the extracted knowledge across various visual reasoning applications.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and easy to understand.
- The comprehensive evaluation, including traditional generative metrics and in-depth knowledge quality assessments, validates the effectiveness of OpenVik.
- The visual representation of the data through figures and charts enhances readability and understanding of the proposed method.

Weaknesses:
- The technical depth is weak, requiring more detailed explanations and justifications for the approach, particularly regarding the necessity of OpenVik in the context of existing multimodal models.
- The experiments are insufficient, lacking comprehensive comparisons with contemporary models and detailed ablation studies.
- The implementation details, particularly for the open relational region detector, are complex and inadequately described, which may hinder reproducibility.

### Suggestions for Improvement
We recommend that the authors improve the technical depth by providing more detailed explanations of the model's components and their unique contributions compared to existing methods. Additionally, further experimental analysis is needed, including comprehensive comparisons with contemporary models and a more thorough ablation study to clarify the distinctions between OpenVik and its predecessors. We also suggest incorporating clearer explanations of the evaluation settings and implementation details directly in the main body of the paper to enhance accessibility for readers.