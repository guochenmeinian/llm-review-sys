ID: gsott1UXlq
Title: Transparent Networks for Multivariate Time Series
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 5, 5, 6, 4, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 1, 2, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Generalized Additive Time Series Model (GATSM), which is designed to handle multivariate time series data while emphasizing transparency and interpretability. GATSM utilizes independent networks for feature representation and a temporal attention module to learn temporal patterns, achieving performance comparable to black-box models across various datasets. The authors demonstrate that GATSM outperforms existing generalized additive models and provides interpretable predictions.

### Strengths and Weaknesses
Strengths:
- GATSM's focus on transparency offers clear insights into decision-making, which is vital for high-stakes applications like healthcare.
- The evaluation across multiple datasets, including Energy, Rainfall, and AirQuality, showcases the model's robustness and generalization capabilities.
- The paper provides extensive details about the experimental setup, enhancing reproducibility.

Weaknesses:
- The mechanism of multi-head attention in learning temporal patterns is unclear, particularly regarding the input transformation from $x$ to $\tilde_x$.
- The addition of attention to the NBM is inadequately motivated, raising questions about the necessity of learning an additional set of parameters.
- The experimental results lack strong baselines, such as DLinear, and the evaluation metrics for different tasks are not clearly distinguished, leading to confusion.
- The model's scalability is limited due to the need for numerous feature functions, especially with high-dimensional data.

### Suggestions for Improvement
We recommend that the authors improve clarity regarding the multi-head attention mechanism and its role in capturing temporal patterns. Additionally, we suggest providing a stronger motivation for the integration of attention in the NBM and considering the inclusion of more advanced black-box models for comparison. To enhance the experimental results, we advise the authors to present distinct evaluation metrics for different tasks and clarify the results in the tables. Finally, incorporating qualitative experiments or occlusion methods could strengthen the interpretability claims of GATSM.