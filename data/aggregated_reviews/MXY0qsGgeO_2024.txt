ID: MXY0qsGgeO
Title: ReNO: Enhancing One-step Text-to-Image Models through Reward-based Noise Optimization
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 3, 4, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Reward-based Noise Optimization (ReNO), a method aimed at enhancing text-to-image (T2I) generation through the optimization of initial noise in one-step models using human preference signals. The authors demonstrate that ReNO achieves performance improvements comparable to multi-step diffusion models while maintaining computational efficiency, with optimization times ranging from 20-50 seconds. User studies indicate that ReNO-optimized models are preferred over popular models like SDXL and PixArt-$\alpha$. The authors claim that ReNO consistently outperforms existing open-source T2I models across various benchmarks. However, the approach is limited to one-step diffusion models, raising concerns about its generalizability and novelty.

### Strengths and Weaknesses
Strengths:
1. The approach optimizes initial noise during inference, improving image quality and adherence to complex prompts.
2. ReNO demonstrates competitive performance against various benchmarks and proprietary models without requiring retraining.
3. Extensive experiments validate the method's effectiveness across multiple challenging benchmarks.
4. The rebuttal effectively addresses previous concerns and includes additional analyses, such as a diversity study and comparisons with existing models.

Weaknesses:
1. The paper lacks novelty, as optimizing initial noise has been previously explored, and the reliance on an ensemble of reward models limits generalizability.
2. Comparisons to other optimized approaches are insufficient, raising questions about the robustness of the results.
3. The method's focus on one-step diffusion models restricts its applicability, and the potential for reduced output diversity is not adequately analyzed.
4. The reliance on an ensemble of reward models may hinder performance in specific scenarios, and the user study's fairness is questioned due to the inherent advantages of the optimized approach.

### Suggestions for Improvement
We recommend that the authors improve the clarity and organization of the paper, particularly by restructuring sections to ensure that background information precedes relevant discussions. Additionally, we suggest that the authors conduct more thorough comparisons with other optimization methods, such as DOODL and D-Flow, to contextualize the advantages of ReNO. Addressing the potential impact on output diversity and the robustness of reward models would also enhance the paper's depth. Furthermore, we recommend that the authors improve the clarity of their motivation and contributions in the Abstract and Introduction, emphasizing that their primary goal is to maximize T2I model performance under resource constraints. Finally, exploring ways to optimize multiple noises simultaneously could broaden the applicability of the method beyond single prompts.