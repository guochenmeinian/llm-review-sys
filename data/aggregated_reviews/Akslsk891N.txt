ID: Akslsk891N
Title: Towards Anytime Classification in Early-Exit Architectures by Enforcing Conditional Monotonicity
Conference: NeurIPS
Year: 2023
Number of Reviews: 30
Original Ratings: 6, 5, 4, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on early-exit classification networks in the context of anytime prediction tasks, focusing on achieving conditional monotonicity of prediction confidence scores across different exits. The authors propose a method called Product Anytime (PA) to enhance this monotonicity, demonstrating its effectiveness through empirical results. The paper conducts a comparative analysis of monotonicity in budgeted dynamic inference settings, evaluating the performance of PA against existing models like MSDNet. While the authors report that MSDNet generally outperforms PA in terms of accuracy at most budgets, its non-monotonic behavior raises concerns, particularly as performance declines with increased FLOPs. The authors clarify their focus on anytime prediction, where monotonicity is crucial, and plan to include additional experimental results and theoretical insights in the camera-ready version. They also address the scalability of their method, particularly in large-scale settings like ImageNet, although concerns remain regarding the effectiveness of the evaluation metrics used, particularly Expected Calibration Error (ECE).

### Strengths and Weaknesses
Strengths:
1. The problem addressed is both interesting and significant in the field of early-exit networks.
2. The proposed method is theoretically sound and well-justified.
3. Comprehensive experiments are conducted across multiple architectures and datasets, validating the findings regarding the performance of MSDNet and PA.
4. The authors acknowledge the limitations of their current analysis and commit to enhancing the manuscript with additional comparisons and theoretical insights.

Weaknesses:
1. Confusing results on CIFAR datasets raise questions about the validity of the IMTA method compared to MSDNet, leading to reproducibility concerns.
2. The paper lacks a discussion on how improved monotonicity translates to better performance in anytime prediction tasks.
3. The evaluation of the proposed method's application at training time is insufficiently explored.
4. Certain design choices lack justification, and comparisons with other methods, such as frozen backbone models, are needed.
5. The reliance on ECE as a primary metric is debated, with suggestions that it may not be optimal for the anytime setting.
6. Concerns about the method's scalability arise from its performance on ImageNet compared to CIFAR datasets.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the results on CIFAR datasets, particularly regarding the performance of IMTA versus MSDNet. Additionally, the authors should discuss how the proposed monotonicity impacts the anytime prediction task and suggest metrics for measuring this performance. It would be beneficial to conduct experiments on more recent multi-exit models, such as L2W-MSDNet, and to evaluate the proposed method's effectiveness during training. Further justification for design choices and comparisons with alternative methods should be included. We also suggest including a detailed analysis of ECE results in a dedicated section, discussing its relevance and limitations in the context of their work. Lastly, we encourage the authors to explore alternative metrics, such as the Expected Maximum Decrease in ground-truth probability (EMD), to better quantify performance improvements and clarify the implications for practical deployment scenarios.