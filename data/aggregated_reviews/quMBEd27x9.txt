ID: quMBEd27x9
Title: Performance Scaling via Optimal Transport: Enabling Data Selection from Partially Revealed Sources
Conference: NeurIPS
Year: 2023
Number of Reviews: 22
Original Ratings: 6, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a two-stage estimator for optimizing data selection in machine learning, addressing the challenge of collecting data from multiple sources under budget constraints. The authors propose a method that first estimates the relationship between dataset proportions and validation loss using Optimal Transport, and then optimizes the data proportions to enhance model performance. Additionally, the authors introduce a framework for predicting model performance based on data composition and quantity, distinguishing between "performance scaling with data composition" and "performance scaling with data quantity." They clarify that their approach utilizes power laws rather than log functions, focusing on residual error as the prediction variable. The experimental results validate the effectiveness of this approach, demonstrating improved performance through informed data selection.

### Strengths and Weaknesses
Strengths:  
- The paper is well-written, with a clear and logical flow of ideas, providing a comprehensive description of the employed method.  
- The topic is timely and relevant, with the optimal transport perspective on data selection being novel and interesting.  
- The proposed framework offers a significant contribution to both academia and industry by improving data selection strategies under budget constraints.  
- The authors provide a clear differentiation between their approach and existing iterative data acquisition frameworks, highlighting practical considerations in large-scale model training.  
- The use of power laws and the focus on residual error as a prediction variable are well-articulated.  
- The authors demonstrate a strong commitment to improving the manuscript based on reviewer feedback.

Weaknesses:  
- The assumption that data from different providers share the same distribution may weaken the results' persuasiveness, as such scenarios are uncommon. A real-world scenario to support this assumption would be beneficial.  
- The practicality of the validation data assumption is questionable, as real testing data and its distribution are often unknown.  
- Some figures, particularly Figure 5, lack clarity in color interpretation and axis meanings, making them difficult to comprehend.  
- The paper makes potentially incorrect statements regarding related literature, particularly concerning power laws and the use of logarithmic learning curves without sufficient motivation.  
- There are confusing statements regarding related literature, particularly concerning scaling laws and the use of "black-box" functions.  
- The distinction between one-shot performance prediction and iterative data acquisition may not be sufficiently clear to all readers.  
- The reliance on similar assumptions from other studies is insufficient to substantiate the practical importance of the findings, leading to a maintained critical score from one reviewer.  
- The experiments primarily utilize simplified baselines, necessitating comparisons with more relevant methods to validate design decisions.

### Suggestions for Improvement
We recommend that the authors improve the clarity of figures, particularly Figure 5, by enhancing color interpretation and providing clearer axis labels. Additionally, we suggest presenting a real-world scenario to support the assumption of identical data distributions across providers. The authors should also clarify the motivation for using logarithmic learning curves over power laws and provide a more thorough comparison with related literature on data collection strategies. Furthermore, we recommend improving the clarity of their terminology by adopting "functional relationship between model performance and data composition" and reserving "scaling" for scaling laws. Enhancing the discussion of related literature on scaling laws, particularly regarding log relationships and power law relationships, would also be beneficial. Finally, we encourage the authors to validate their method against more relevant baselines and to provide a more robust argument for the practical importance of their findings, rather than relying solely on the assumptions made in other studies.