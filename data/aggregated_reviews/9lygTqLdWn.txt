ID: 9lygTqLdWn
Title: Multi-body SE(3) Equivariance for Unsupervised Rigid Segmentation and Motion Estimation
Conference: NeurIPS
Year: 2023
Number of Reviews: 20
Original Ratings: 5, 6, 6, 6, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 2, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for simultaneously segmenting rigid parts and estimating part-level transformations from multi-body point cloud inputs. The authors propose a framework that extracts equivariant features, aggregates them into invariant features for segmentation, and applies an equivariant motion estimation head to derive SE(3) motions. The model is trained unsupervised, leveraging the consensus among 3D scene flow, motion segmentation, and transformations. Experiments demonstrate the model's generalizability in open-set motion and category-agnostic part segmentation, achieving superior performance on SAPIEN, OGC, and KITTI datasets compared to previous baselines. The model effectively utilizes rigidity constraints for segmentation in point clouds, showing significant improvements over existing methods on larger datasets such as KITTI-Det and SemanticKITTI.

### Strengths and Weaknesses
Strengths:
- The identification of invariant segmentation and equivariant motion estimation as generalization problems is insightful, and the use of equivariant backbones is well-suited.
- The novel approach of bootstrapping the learning process with initial scene flow helps avoid local minima, enabling unsupervised learning through inherent consistency in multi-body registration.
- Extensive experiments across diverse datasets validate the method's applicability, showcasing impressive accuracy with reduced computational costs.
- The model shows significant improvements over existing methods on larger datasets.
- The authors are responsive to feedback, indicating a willingness to enhance clarity and detail in their manuscript.
- Additional visualizations have been provided to illustrate the model's performance and failure cases.

Weaknesses:
- The clarity of the unsupervised training strategy is lacking, particularly regarding the loss function and the role of the weighted-Kabsch algorithm.
- The generalization capability of the segmentation head is questionable, as the rationale for achieving category-agnostic segmentation without canonical labels is not adequately explained.
- Concerns remain regarding the model's generalizability, particularly when trained on SAPIEN and tested on KITTI-SF due to differences in point cloud characteristics.
- The experimental section lacks clarity, particularly in the relationship between point-level invariance and open-set motion generalization, and the ordering of sections could be improved.
- The related works section is currently too summarized and lacks depth.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the unsupervised training strategy by explicitly detailing the loss function and the role of the weighted-Kabsch algorithm in the main text. Additionally, the authors should address the concerns regarding the generalization of the segmentation head by providing a clearer explanation of how the model can consistently index parts in novel shapes. We suggest enhancing the experimental section by clarifying the relationships between invariance and generalization, and consider reordering sections for better flow. Furthermore, we recommend that the authors improve the related works section by providing a more comprehensive overview of existing literature on deep learning applied to dynamic point clouds. Finally, we encourage the authors to include more visualizations across all tested datasets, particularly highlighting transformations and challenging cases, to strengthen the presentation of their results and address concerns regarding point cloud coordinate differences.