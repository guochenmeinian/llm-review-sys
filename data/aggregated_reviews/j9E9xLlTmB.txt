ID: j9E9xLlTmB
Title: Analyzing Cognitive Plausibility of Subword Tokenization
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents "chunkability" as a new evaluation paradigm for subword tokenization, aimed at assessing the cognitive plausibility of subword tokenizers in relation to human lexical decision times and accuracy. The authors propose that chunkability can be correlated with processing difficulty, where higher chunkability indicates easier processing, greater accuracy, and reduced reading times. The study evaluates several popular subword tokenization algorithms, including Byte-pair encoding, WordPiece, and Unigram, and finds that BPE and WPC show better predictive performance.

### Strengths and Weaknesses
Strengths:  
- The paper introduces a novel perspective on evaluating subword tokenizers through cognitive plausibility, which is a significant contribution to the field.  
- The research rationale is well-defined, raising important questions about the cognitive alignment of tokenizer algorithms with human processing.  
- The writing is clear, and the focus on cognitive aspects is particularly relevant to the topic.

Weaknesses:  
- The analysis lacks depth in controlling for confounding variables such as frequency, which could enhance the correlation with human metrics.  
- The methodology is not original and confirms known results without introducing new insights.  
- The presentation of chunkability could be improved by introducing it earlier in the paper.

### Suggestions for Improvement
We recommend that the authors improve the analysis by incorporating a regression analysis that controls for potential confounds like frequency, as this is crucial for validating their findings. Additionally, we suggest rescaling the y-axes in Figures 1 and 2 for consistency and acknowledging the relatively low correlations reported. Significance testing should be included to compare differences in correlation between models. We also encourage the authors to present an alternative statistic, such as Goodman-Kruskal, to address the limitations of Pearson's correlation. Furthermore, a discussion regarding the segmentations in Table 1 is necessary to clarify the cognitive plausibility claims, particularly regarding the mismatch between proposed tokens and morphemes. Lastly, we suggest addressing the potential impact of word length on the chunkability metric and exploring metrics that do not factor in length as explicitly.