ID: ZKVxABGJ6r
Title: PanoGRF: Generalizable Spherical Radiance Fields for Wide-baseline Panoramas
Conference: NeurIPS
Year: 2023
Number of Reviews: 24
Original Ratings: 7, 3, 4, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 5, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents PanoGRF, a method for synthesizing novel panoramas from wide-baseline panoramas by integrating 360-degree scene priors into Spherical NeRF. The authors emphasize the importance of training a robust generalizable model for novel view synthesis using wide-baseline panoramas. PanoGRF enhances spherical depth quality by utilizing a custom spherical depth estimation method guided by a monocular depth estimator, effectively addressing occlusion issues and outperforming existing methods such as MVSNeRF and NeuRay. The evaluation includes thorough comparisons and an ablation study, revealing that fine-tuning did not enhance rendering quality, suggesting potential overfitting due to wide-baseline images.

### Strengths and Weaknesses
Strengths:
- The paper effectively synthesizes ideas from prior work, particularly NeuRay, into a novel approach for panoramic view synthesis.
- PanoGRF's spherical representation provides a comprehensive field of view, improving feature aggregation and depth estimation.
- The integration of 360-degree monocular depth enhances the quality of spherical depth, addressing significant occlusion challenges.
- Comprehensive evaluation with quantitative and qualitative results shows substantial improvements in rendering quality.
- The paper includes extensive comparative experiments demonstrating PanoGRF's superiority over existing methods.
- Clear presentation and well-structured supplementary materials enhance understanding of the methodology and results.

Weaknesses:
- The work is largely an adaptation of NeuRay to spherical coordinates, raising concerns about its novelty and contribution.
- Some reviewers express concerns regarding the novelty of the approach, suggesting that it primarily adapts existing methods rather than introducing fundamentally new concepts.
- The video demonstration is limited to planar movement, leaving questions about the method's capability for full 6DOF motion.
- The discussion of limitations is brief, lacking exploration of failure cases and potential improvements in view synthesis results.
- Per-scene optimization methods with depth priors may lead to overfitting, as noted in the supplementary materials.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their contribution by clearly articulating how their method offers new insights beyond simply adapting existing techniques. Additionally, consider including a comparison with earlier general radiance field approaches, such as GRF, to contextualize the work. To strengthen the demonstration of PanoGRF's advantages, we suggest conducting further experiments comparing it with naive solutions using sparse monocular input. To address the limitations, we recommend expanding the discussion on failure cases and exploring the method's performance in generating views beyond the baseline. Finally, we encourage the authors to clarify the design choices made in the method, particularly regarding the aggregation of panorama views and the determination of depth candidates, and to release the code upon acceptance to facilitate further research in panorama-related applications.