ID: sEvU6r8e7N
Title: RefGPT: Dialogue Generation of GPT, by GPT, and for GPT
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents RefGPT, a method for constructing instruction data to generate truthful and customized dialogues using powerful LLMs, specifically GPT-4. The authors propose two large datasets, RefGPT-Fact and RefGPT-Code, which consist of 176k dialogue sessions. The method enhances dialogue authenticity by incorporating reference messages into the input prompts, leading to improved truthfulness and customization in generated dialogues. An automatic evaluation framework using GPT-4 is introduced to assess the quality of the generated data.

### Strengths and Weaknesses
Strengths:
- The contribution of two large instruction datasets to the NLP community, potentially enhancing LLM fine-tuning.
- Insightful prompt design that allows for fine-grained control over dialogue structure and style.
- The innovative use of GPT-4 as a referee for automatic evaluation of instruction data.

Weaknesses:
- Uncertainty regarding the actual performance boost of fine-tuned LLMs using the proposed datasets, as comparative experiments with strong baselines are lacking.
- Reliance on GPT-4 for data quality evaluation raises concerns about potential biases and the need for human evaluation.
- The methodology, while effective, is not novel as adding external textual information to reduce hallucinations is a common practice.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their claims regarding the effectiveness of RefGPT in reducing hallucinations, as the current assertions may be overstated. Additionally, conducting comparative experiments with LLaMa fine-tuned on self-instruct and a stronger baseline would enhance the paper's credibility. We suggest including human evaluations alongside GPT-4 assessments to validate the quality of the RefGPT datasets. Furthermore, providing more details on the construction of dialogue content pools and clarifying ambiguous sections, particularly in the evaluation setup, would improve the paper's comprehensibility. Lastly, addressing the commonality of the methodology in the discussion of novelty would strengthen the overall argument.