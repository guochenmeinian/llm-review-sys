ID: 6KDZHgrDhG
Title: Compositional Automata Embeddings for Goal-Conditioned Reinforcement Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 5, 8, 6, 5, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an extension of goal-conditioned reinforcement learning (RL) to support temporally-extended goals specified as compositions of deterministic finite automata (cDFAs). The authors propose generating cDFA embeddings to be utilized by a universal value function approximator (UVFA) for learning general policies. They introduce a graph neural network architecture for embedding cDFAs via message passing and develop a *reach avoid derived* DFA (RAD-DFA) task distribution for pretraining these embeddings. Experimental results demonstrate that pretraining on this distribution yields generalizable embeddings and effective cDFA-conditioned policies across various task classes, particularly in the environments of Letterworld and Zones. The authors also show that frozen pretrained embeddings outperform finetuning, enhancing cDFA embeddings and generalization.

### Strengths and Weaknesses
Strengths:
- The introduction of compositional DFAs provides a more general framework for multi-task descriptions, and the method for encoding these objectives is straightforward.
- The work integrates three established research areas: temporal logic task specifications, goal-conditioned RL, and graph neural networks, showcasing originality in their combination.
- The paper is well-written, with clear explanations and figures that effectively illustrate key concepts, including the design of the RAD pretraining distribution.
- Mathematical formulations and coherent explanations enhance the clarity and quality of the work, supported by helpful figures and experiments illustrating the proposed approach's effectiveness.
- The significance of temporal logic instruction following is emphasized, with potential applications in multitask, lifelong learning, and safe RL.

Weaknesses:
- The approach closely resembles LTL2Action, with modifications that may be seen as incremental rather than groundbreaking, and it mischaracterizes LTL2Action's applicability.
- The paper can be difficult to follow due to overloaded notations and conventions, particularly in the description of RAD pretraining and task nomenclature.
- The paper's mathematical definitions contain inaccuracies, such as the incorrect MDP definition and unclear reward function specifications.
- The experiments do not adequately compare with state-of-the-art methods, limiting the assessment of the proposed approach's effectiveness.
- The reliance on UVFAs raises concerns about generalization and optimality, particularly in complex task scenarios, and the paper lacks rigorous theoretical justification for its claims. Additionally, the performance in the more realistic environment of Zones is weaker, raising concerns about generalizability.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by elaborating on figure captions and providing a clearer explanation of the DFA modifications in Section 3.1. We suggest improving the clarity of mathematical definitions, particularly the MDP formulation and reward function specifications, to ensure accurate representation of the proposed framework. It would also be beneficial to include a more detailed discussion on the limitations of using symbolic specifications and how the framework might enable safety and correctness in policy learning. Furthermore, we encourage the authors to conduct direct comparisons with existing baselines from the literature to contextualize their findings better. Investigating the scalability of the task embedding space and providing empirical evidence regarding its limitations, particularly in relation to complex DFAs with Boolean expressions, would enhance the significance of the work. Lastly, including examples of the simplest and most complex DFAs from the defined distributions would enhance the understanding of the experimental results.