ID: P9V2jcotAF
Title: Beyond Shared Vocabulary: Increasing Representational Word Similarities across Languages for Multilingual Machine Translation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method to enhance multilingual machine translation (MT) by constructing a word similarity graph from word-aligned parallel text and integrating a graph neural network (GNN) after the word embeddings. The authors propose that this approach improves representation similarity of lexical translations, achieving significant BLEU score increases (+2.3 on IWSLT and +1.1 on WMT30). The method is evaluated across two datasets, demonstrating effectiveness in improving translation quality and word similarity benchmarks.

### Strengths and Weaknesses
Strengths:
- The approach is well-conceived and shows clear improvements in BLEU scores with a low memory footprint.
- The experiments are comprehensive, covering various language pairs and including ablation studies that enhance the paper's value.
- The presentation is mostly clear, and the authors provide sufficient technical details for reproducibility.

Weaknesses:
- The evaluation relies solely on tokenized BLEU, which is difficult to reproduce; alternative metrics like sacreBLEU and BLEURT or COMET should be included.
- The necessity of using GNN for this task is questioned; simpler alternatives like random substitutions or contrastive learning could be considered.
- Important related work is omitted, and the paper does not adequately address the potential biases introduced by the word alignment model.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by using sacreBLEU and reporting additional metrics such as BLEURT or COMET. Additionally, consider including comparisons with simpler methods like random substitutions or contrastive learning to validate the choice of GNN. It would also be beneficial to address the omission of relevant literature and to clarify the methodology regarding the use of word aligners, potentially incorporating more advanced models like SimAlign or AwesomeAlign. Lastly, we suggest exploring solutions for rare words that do not appear in the word alignments to enhance the model's robustness.