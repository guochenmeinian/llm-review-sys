ID: OLEQJoAED6
Title: Don't Always Say No to Me: Benchmarking Safety-Related Refusal in Large VLM
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 6, 5, 4, 4, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an evaluation of the safety-related refusal capabilities of Large Vision-Language Models (LVLMs), focusing on their ability to distinguish between safe and unsafe prompt-image pairs. The authors propose a benchmark dataset, LVLM-SAFER, which is manually inspected and covers various safety-related topics. Extensive experiments are conducted across 9 closed-source and 23 open-source LVLMs, revealing significant shortcomings in refusal accuracy and proposing a prompt-engineering baseline to enhance LVLMs' refusal behavior.

### Strengths and Weaknesses
Strengths:
1. The paper addresses a relevant and interesting question regarding the safety of LVLMs, particularly concerning unnecessary rejections.
2. The introduction of the LVLM-SAFER benchmark provides a comprehensive evaluation framework for safety-related refusal capabilities.
3. The experiments encompass a diverse range of models and safety alignment methods, yielding valuable insights into LVLM performance.

Weaknesses:
1. The classification of some rejections as "false refusals" is debatable, particularly when safe text prompts accompany disturbing images.
2. Certain prompts do not necessitate visual input, potentially undermining the multimodal safety evaluation.
3. The paper lacks a related work section, limiting its contextualization within existing literature.

### Suggestions for Improvement
We recommend that the authors improve the clarity and consistency of prompt design to avoid reliance on language shortcuts. A thorough discussion on the criteria for determining unsafe images is necessary, as well as a more robust ethical consideration section that addresses potential risks associated with dataset sourcing. Additionally, we suggest unifying the prompt templates used in experiments and providing clearer definitions for evaluation metrics to enhance reader comprehension. Finally, addressing the limitations of the dataset and its legal implications is crucial for transparency and ethical integrity.