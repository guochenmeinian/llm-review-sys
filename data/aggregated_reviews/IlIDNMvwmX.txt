ID: IlIDNMvwmX
Title: LM-HT SNN: Enhancing the Performance of SNN to ANN Counterpart through Learnable Multi-hierarchical Threshold Model
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 7, 7, 7, 6, -1, -1, -1
Original Confidences: 5, 4, 4, 5, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel Learnable Multi-hierarchical Threshold (LM-HT) model for spiking neural networks (SNNs) that dynamically adjusts input current and membrane potential leakage, thereby enhancing SNN performance to match that of artificial neural networks (ANNs). The LM-HT model integrates seamlessly with ANN-SNN conversion frameworks, improving performance under low time latency. The authors provide extensive experimental validation, demonstrating state-of-the-art results across various datasets.

### Strengths and Weaknesses
Strengths:  
- The introduction of the LM-HT model significantly enhances SNN performance through dynamic regulation.  
- The model's integration with ANN-SNN conversion frameworks leads to improved performance under low time latency.  
- Theoretical analysis offers a new perspective on the relationship between LM-HT, traditional spiking models, and quantized ANNs.  
- Extensive experimental results validate the model's superior performance across multiple datasets.  

Weaknesses:  
- The checklist should be placed after the appendix.  
- The authors should compare their results with those from papers [1][2], which achieve strong results using the MS-ResNet-34 backbone on large ImageNet datasets.  
- The scalability of the LM-HT model to different SNN backbones is not addressed; experiments on more backbones (MS-ResNet [3] and Spikformer [4][5]) are recommended.  
- The implications of reparameterizing the LM-HT model to a single-threshold model for neuromorphic hardware deployment are not fully explored.  
- Reporting only the best accuracy is less significant; the authors should provide mean accuracy and standard deviation over multiple seeds.  
- The motivations for using multi-precision spikes should be clarified for a broader audience.  
- The analysis of the Temporal-Global Information Matrix (T-GIM) and its impact on learning is insufficient.  
- The authors need to clarify the benefits of the LM-HT model during training and its reparameterization for inference.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivations behind the LM-HT model, particularly from biological and performance perspectives. Additionally, the authors should conduct experiments on various SNN backbones to demonstrate the model's scalability. We suggest providing mean accuracy and standard deviation for statistical significance and clarifying the advantages of the reparameterization approach compared to training a single-threshold model. Furthermore, a more detailed discussion on the equivalence of gradient calculation between the LM-HT model and quantized ANNs is warranted. Lastly, the authors should ensure that the checklist is positioned correctly and address minor typographical errors in the manuscript.