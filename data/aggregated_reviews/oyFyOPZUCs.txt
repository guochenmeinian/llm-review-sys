ID: oyFyOPZUCs
Title: Language-based Action Concept Spaces Improve Video Self-Supervised Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 24
Original Ratings: 5, 6, 5, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel language-based self-supervised learning framework (LSS) for video representation learning, adapting the CLIP model to the video domain. The authors propose a teacher-student self-supervised learning framework that distills knowledge from text action concepts using CLIP's text encoder. The method employs two self-supervised learning objectives: concept distillation and concept alignment, achieving state-of-the-art results on multiple action recognition benchmarks. However, the reliance on labeled information from datasets like Kinetics-400, UCF-101, and HMDB-51 raises questions about the self-supervised nature of the approach.

### Strengths and Weaknesses
Strengths:
- The paper introduces a new paradigm for transferring CLIP knowledge to the video domain, achieving impressive performance across multiple datasets.
- The evaluation is extensive, demonstrating strong results in zero-shot and linear probing settings.
- The writing is generally clear, and the methodology is well-presented.

Weaknesses:
- The claim of being self-supervised is undermined by the use of labeled information from training datasets, which may violate the self-supervised learning premise.
- Comparisons with existing methods are unfair, as LSS leverages pre-trained CLIP weights while others do not.
- The experiments are limited to the same action classes used in training, raising concerns about generalization to unseen actions.
- The absence of ablation studies on the uniform distribution prior regularization and text-to-video retrieval benchmarks limits the understanding of the method's effectiveness.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their claims regarding the self-supervised nature of their method by addressing the reliance on labeled information. Consider constructing action concepts in a dataset-agnostic manner to enhance the fairness of comparisons with other self-supervised methods. Additionally, we suggest including ablation studies on the uniform distribution prior regularization and conducting experiments on text-to-video retrieval to substantiate claims about the method's capabilities. Finally, addressing the writing quality and ensuring comprehensive explanations of the methodology for generating action labels would strengthen the paper.