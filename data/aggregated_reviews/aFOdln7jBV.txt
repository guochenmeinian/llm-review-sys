ID: aFOdln7jBV
Title: An Accelerated Gradient Method for Convex Smooth Simple Bilevel Optimization
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 6, 6, 8, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel optimization algorithm, AGM-BiO (Accelerated Gradient Method for Bilevel Optimization), aimed at solving simple convex smooth bilevel optimization problems. The authors achieve optimal convergence rates by integrating Nesterov's acceleration with the cutting-plane method. The algorithm is validated through theoretical analysis and numerical experiments, demonstrating improved iteration complexity and convergence guarantees.

### Strengths and Weaknesses
Strengths:
- The paper achieves an optimal rate for an important problem class.
- The presentation is clear and well-structured, with comprehensive literature review and explicit convergence rate dependencies.
- The proposed algorithm is easy to implement and demonstrates the best-known complexity bounds for both suboptimality and infeasibility.

Weaknesses:
- The focus on simple bilevel optimization limits the scope, as both levels are convex and deterministic, with access to full gradients rather than stochastic ones.
- The contribution appears incremental since the main techniques have been previously studied, and the complexity results only slightly outperform existing ones.
- The convergence results for the modified algorithm (Algorithm 2) are not formally stated, which could enhance clarity.

### Suggestions for Improvement
We recommend that the authors improve the scope of their work by addressing the limitations of extending their technique to non-simple cases, particularly when additional variables are introduced. Additionally, we suggest formally stating the convergence results for Algorithm 2 in a theorem to provide a clear reference point for readers. Furthermore, clarifying the mathematical formulation for "more general settings with parameterized lower-level problems" in line 27 or referring to an appendix would enhance understanding. Lastly, addressing how to guarantee Eq. (5) in implementation with unknown parameters and exploring the unique challenges of applying the accelerated gradient method to simple bilevel problems would strengthen the paper.