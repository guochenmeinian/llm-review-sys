ID: Sk2duBGvrK
Title: Understanding Generalizability of Diffusion Models Requires Rethinking the Hidden Gaussian Structure
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 6, 7, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comparison of diffusion models trained on natural image datasets with their Gaussian approximations, evaluating the quality of this approximation in memorization and generalization regimes. The authors propose that the learned score functions exhibit linearity, suggesting an inductive bias towards capturing Gaussian structures in the training data. They investigate the generalizability of diffusion models, particularly focusing on the inductive bias associated with learning Gaussian structures. The findings indicate that diffusion models can generalize well, particularly when model capacity and training time are reduced, and that models succeed in generalizing when they learn the mean and covariance of the data distribution, rather than merely memorizing data. The authors conduct experiments to assess the impact of dataset size, model scale, and training time on generalizability, revealing that diffusion models can achieve strong generalization even with smaller datasets. They also discuss the relationship between their findings and existing literature on denoising and Bayes estimators.

### Strengths and Weaknesses
Strengths:
- The paper makes several novel empirical observations, particularly regarding the linearity of denoisers and their approximation to Gaussian functions.
- It provides a thorough exploration of the inductive bias in diffusion models and their ability to generalize from limited data.
- Experimental results demonstrate the potential for strong generalization with smaller datasets, contributing valuable insights to the understanding of diffusion models.

Weaknesses:
- A significant portion of the content is considered obvious by those with a signal/image processing background, particularly regarding well-known concepts like the Wiener filter.
- The analysis is limited to a few generative models and a specific face dataset, raising questions about the generalizability of the findings to more diverse datasets.
- The paper lacks quantitative measures of generalization and memorization, and the connection between linearity and generalization is not well substantiated.
- The use of RMSE measurements without normalization raises concerns about the validity of empirical claims.
- The novelty of Theorem 1 is not clearly articulated in relation to prior work, which may lead to confusion regarding its significance.
- The authors' assertion that strong generalization can be achieved with small datasets contradicts existing literature, which suggests larger datasets are necessary.

### Suggestions for Improvement
We recommend that the authors improve the depth of their analysis by incorporating a wider variety of datasets to assess the generalizability of their findings. Additionally, we suggest including quantitative measures of generalization and memorization in their experiments to strengthen their claims. Clarifying the definition of "inductive bias" in the context of their work is essential, as is providing detailed information about the experimental setup, including training procedures and hyperparameters. Furthermore, we encourage the authors to discuss the implications of their findings more thoroughly, particularly regarding the relationship between Gaussian structures and the performance of diffusion models. We also recommend that the authors improve the clarity of their inductive bias argument by elaborating on why learning the first two moments is considered a bias and how this finding is surprising. Addressing the concerns regarding the use of RMSE by providing a more detailed justification for their choice and discussing the implications of normalization on their conclusions would be beneficial. Additionally, the authors should clarify the novelty of Theorem 1 by explicitly linking it to previous works in denoising and Bayes estimators. Lastly, we encourage the authors to emphasize the role of larger datasets in generating high-quality images while maintaining their argument about the potential for generalization from smaller datasets.