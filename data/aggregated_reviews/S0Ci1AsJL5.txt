ID: S0Ci1AsJL5
Title: Gaussian Approximation and Multiplier Bootstrap for Polyak-Ruppert Averaged Linear Stochastic Approximation with Applications to TD Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 5, 7, 6, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents advancements in the theoretical understanding of the linear stochastic approximation (LSA) algorithm, establishing the Berry–Esseen bound for the normal approximation of Polyak-Ruppert averaged iterates with an optimal rate using an aggressive step size of $\alpha_k \approx k^{-1/2}$. It also demonstrates the non-asymptotic validity of confidence intervals through a novel multiplier bootstrap procedure, marking a first in this domain. The practical utility of these theoretical results is illustrated through applications in temporal difference (TD) learning for reinforcement learning.

### Strengths and Weaknesses
Strengths:  
1. **Theoretical Advancements**: The paper establishes the Berry–Esseen bound for Polyak-Ruppert averaged iterates, providing a tighter bound than previous works.  
2. **Good Clarity**: The paper is well-written and easy to follow, with a correct proof (though not meticulously checked).  
3. **Novel Contributions**: The contributions, particularly the first Berry-Esseen bound for general linear stochastic approximation, are novel and exciting.  

Weaknesses:  
1. **Strong Assumptions**: The requirement that $\epsilon(z)$ is uniformly bounded is a strong assumption that may limit the applicability of the results.  
2. **Missing References**: There are missing references related to statistical inference for nonlinear stochastic approximation that should be cited.  
3. **Discussion on Lower Bounds**: The paper lacks a discussion on the tightness of derived upper bounds and potential lower bounds, which could enhance understanding of their efficacy.  
4. **Complex Presentation**: The analysis is difficult to follow due to the number of symbols and equations, which may distract readers.  

### Suggestions for Improvement
We recommend that the authors improve the generality of their results by relaxing the assumption that $\epsilon(z)$ is uniformly bounded to weaker conditions, such as finite moments. Additionally, we suggest including the missing references on statistical inference for nonlinear stochastic approximation to strengthen the paper's foundation. We encourage the authors to discuss the tightness of the derived upper bounds and explore potential lower bounds to provide a more comprehensive understanding. Furthermore, we advise moving unnecessary terms or inequalities to the appendix to enhance clarity and readability. Lastly, we recommend including a plot of $C k^{-1/4}$ for comparison in the numerical experiments to better illustrate convergence rates.