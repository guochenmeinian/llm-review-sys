ID: kzJ9P7VPnS
Title: LP-3DGS: Learning to Prune 3D Gaussian Splatting
Conference: NeurIPS
Year: 2024
Number of Reviews: 25
Original Ratings: 5, 4, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for pruning Gaussians in 3D Gaussian Splatting (3DGS) using a learnable mask based on a Gumbel-Sigmoid function. The authors aim to optimize the pruning process while maintaining high image fidelity, eliminating the need for multiple training sessions to find an appropriate pruning ratio. They claim that their approach can achieve effective pruning within an empirical interval of 0.5 to 0.8, requiring only one round of training and maintaining rendering quality comparable to unpruned models. However, reviewers express concerns regarding the effectiveness of the method, suggesting that it should demonstrate superiority over random pruning in a significant percentage of scenes. The method shows promise in reducing the number of Gaussians without compromising reconstruction quality, thus improving rendering speed.

### Strengths and Weaknesses
Strengths:
- The use of the Gumbel-Sigmoid function allows for a differentiable approach to binarizing input values.
- The authors provide a learnable and automatic method for determining pruning ratios, which is claimed to be more efficient than manual tuning.
- The paper is well-structured and easy to follow, making it accessible for practitioners.
- Extensive experiments on various benchmarks demonstrate the method's potential, with reported results indicating that the learned pruning ratios maintain rendering quality similar to unpruned models while achieving substantial model size reduction.

Weaknesses:
- The technical contributions are limited, primarily revolving around the application of Gumbel-Sigmoid without significant novel insights.
- The definition of "optimal" pruning ratio is vague, and the results do not convincingly support the claim of achieving optimality.
- Reviewers find the evaluation results vague and request clearer evidence of the method's effectiveness, particularly in demonstrating that it outperforms random pruning in over 50% of scenes.
- The claim of "almost no rendering quality drop" is criticized as being too vague, necessitating more precise metrics and definitions.
- Comparisons with existing methods are insufficient, particularly regarding performance metrics from original papers.
- Clarity issues in figures and tables hinder understanding, and the writing requires refinement.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Figure 2 and provide a more detailed explanation of why pattern (b) in Figure 3 is superior to (a). Additionally, we suggest including performance metrics from original papers for comparison in the experiments section. The authors should clarify the definition of "optimal" pruning and provide theoretical analysis to support their claims. We also encourage the authors to improve their evaluation by providing clearer evidence that their method outperforms random pruning in at least 50% of scenes, as this would substantiate the effectiveness of their approach. Furthermore, we suggest that the authors specify the value range for rendering quality and compression rates in their tables to enhance clarity. We encourage the authors to define a more rigorous metric for the trade-off between compression ratio and rendering quality, such as a specific PSNR threshold, to strengthen their claims. Finally, we advise refining the writing for clarity and correcting inaccuracies in the figures and tables.