ID: 3mCr7ZNdSw
Title: Privacy without Noisy Gradients: Slicing Mechanism for Generative Model Training
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 6, 4, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a slicing privacy mechanism for training generative models that avoids noisy gradients by injecting noise into random low-dimensional projections of private data. The authors introduce the smoothed-sliced $f$-divergence and a kernel-based estimator, enabling the training of generative models without adversarial training. Empirical results indicate that the proposed method generates higher quality synthetic data compared to existing techniques.

### Strengths and Weaknesses
Strengths:
- The introduction of the slicing privacy mechanism and smoothed-sliced $f$-divergence offers a novel approach to privacy-preserving generative model training, effectively addressing the limitations of noisy gradient methods.
- The paper is underpinned by strong theoretical foundations, including privacy guarantees and statistical consistency of the smoothed-sliced $f$-divergence.
- Extensive experiments demonstrate the method's effectiveness in generating high-quality synthetic data across various datasets, outperforming baseline methods.

Weaknesses:
- The baseline algorithms used for comparison, such as DP-SGD and PATE, may be outdated for the context of synthetic tabular data generation, as more recent variants exist.
- The proposed method is primarily tested on tabular data, raising questions about its applicability to other data types like images or text.
- The discussion on the similarity to MMD-based methods is insufficient, and the lack of sensitivity analysis is a notable omission.

### Suggestions for Improvement
We recommend that the authors improve the empirical comparison by including more recent baseline algorithms, particularly those that have shown advancements in the field. Additionally, the authors should expand their experiments to include diverse data types beyond tabular data to validate the method's scalability. A discussion on the limitations of the proposed approach should be added for completeness. Finally, we suggest clarifying the relationship and differences between "slicing and smoothing" and addressing the necessity of adding noise to synthetic data, as it may impact model utility.