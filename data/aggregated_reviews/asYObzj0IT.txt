ID: asYObzj0IT
Title: Comparing Prompt-Based and Standard Fine-Tuning for Urdu Text Classification
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comparison between prompt-based and standard fine-tuning methods for Urdu text classification, utilizing five datasets that include both Urdu and Roman Urdu characters for tasks such as emotion detection and offensive language detection. The authors demonstrate that the prompt-based method consistently outperforms the standard fine-tuning approach across three pre-trained multilingual language models (BERT-Multilingual, DistilBERT, XLM-RoBERTa) in a few-shot setting.

### Strengths and Weaknesses
Strengths:
- The paper addresses the under-researched area of Urdu, a low-resource language, and provides comprehensive experimental results across five datasets.
- The prompt-based method shows consistent superiority over standard fine-tuning, which is significant for low-resource language applications.

Weaknesses:
- The rationale for selecting Urdu over other low-resource languages is unclear.
- The claims regarding the prompt-based method capturing unique linguistic characteristics of Urdu lack supporting experiments or analyses.
- The paper does not adequately describe the fine-tuning procedure, which hampers reproducibility, and the evaluation metric of accuracy is questioned, particularly for unbalanced datasets.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their rationale for choosing Urdu as the focus language. Additionally, it is essential to provide qualitative and/or quantitative evidence supporting the claim that the prompt-based method captures unique linguistic characteristics of Urdu. If further experiments are not feasible within the paper's constraints, we suggest toning down the associated claims. 

To enhance reproducibility, please include detailed descriptions of the fine-tuning procedure, including the source of the pre-trained models and hyper-parameters such as batch size, learning rate, and optimization methods. Furthermore, we encourage the authors to compare the prompt-based method's performance in a zero-shot setting and analyze conditions under which standard fine-tuning may outperform the prompt-based approach as sample sizes increase. 

Lastly, we suggest providing parallel English translations for the Urdu text in Figure 1 and addressing the accuracy concerns by reporting F1 scores alongside accuracy metrics.