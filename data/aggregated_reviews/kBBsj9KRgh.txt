ID: kBBsj9KRgh
Title: SAME: Uncovering GNN Black Box with Structure-aware Shapley-based Multipiece Explanations
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 6, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents SAME, a novel method for explaining Graph Neural Networks (GNNs) that utilizes an expansion-based Monte Carlo tree search (MCTS) to explore structure-aware connected substructures. The authors claim that SAME provides explanations comparable to the theoretically optimal Shapley value and demonstrate its effectiveness through experiments on various datasets, showing improvements over existing state-of-the-art methods. The authors also clarify that the SAME algorithm is polynomial due to MCTS and propose a definition for structure-awareness in GNN explanation methods, emphasizing the need for clear communication to avoid misunderstandings. They address concerns regarding the definitions of properties related to "Multiple explanations" and "Node-wise / Substructure-wise / Global importance," proposing modifications to enhance clarity.

### Strengths and Weaknesses
Strengths:
- Theoretical foundation: SAME is grounded in a robust theoretical framework, enhancing the credibility of the proposed method.
- Structure-aware explanations: The use of MCTS allows for the exploration of multi-grained connected substructures, resulting in more informative explanations.
- Improved performance: Experimental results indicate that SAME outperforms previous methods in fidelity performance, with improvements ranging from 7.01% to 42.3%.
- Clarification of polynomial nature: The authors' clarification on the polynomial nature of the SAME algorithm is appreciated.
- Enhanced definitions: The proposed definition of structure-awareness and revisions to property definitions improve understanding and address previous concerns.

Weaknesses:
- Limited discussion of limitations: The paper lacks a comprehensive exploration of the limitations of SAME, particularly regarding its applicability to different graph types and datasets.
- Insufficient comparison with alternative methods: The paper does not provide a thorough comparison with other explanation techniques, which would enhance understanding of SAME's relative performance.
- Generalizability concerns: There is no explicit discussion on how SAME adapts to different GNN architectures, which could limit its applicability.
- Theoretical complexity and computational efficiency: The paper does not adequately analyze the theoretical complexity or scalability of SAME, which is crucial for understanding its practical use.
- Incomplete addressing of property definitions: Some concerns regarding property definitions and their connections to related works remain inadequately addressed, and the terminology used in the "Multiple explanations" property may still cause confusion.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the algorithm and its contributions, particularly the game-theoretic approach and the differences between SAME and SubgraphX. Additionally, we suggest providing a more detailed discussion of the limitations and potential drawbacks of SAME, as well as a thorough comparison with alternative explanation methods. The authors should clarify the generalizability of SAME to various GNN architectures and provide a detailed analysis of its computational complexity and scalability. Furthermore, we recommend that the authors improve the explanation of the "and" and "or" scenarios in the "Multiple explanations" property to avoid misunderstandings and provide further clarification on why property 8 does not imply property 6, particularly in cases where \( G_{ex}^{i} \) is a single node. Lastly, we encourage the authors to ensure that all definitions are precise and unambiguous to enhance reader comprehension.