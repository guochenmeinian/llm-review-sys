ID: lk7SW0bH4x
Title: ProbTS: Benchmarking Point and Distributional Forecasting across Diverse Prediction Horizons
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 8, 8, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ProbTS, a benchmark tool designed to evaluate both point-based and probabilistic forecasting methods across various datasets and forecasting horizons. It benchmarks an extensive range of methods, analyzing their performance based on dimensions such as trend, seasonality, and non-Gaussianity. The authors propose that deep learning methods outperform traditional statistical methods, while XGBoost remains competitive. Notably, the paper discusses the limitations of auto-regressive methods in longer horizons and non-auto-regressive methods in shorter horizons, suggesting potential for future hybrid approaches.

### Strengths and Weaknesses
Strengths:  
* The paper is well-written, structured, and clear, facilitating understanding.  
* It includes a comprehensive benchmarking of various forecasting methods, providing valuable insights into their performance.  
* The reproducibility is enhanced by publicly sharing the code on GitHub and completing the reproducibility checklist.  
* The introduction of useful metrics for time series characteristics, such as non-Gaussianity, adds depth to the analysis.  

Weaknesses:  
* The abstract and title suggest a general framework, but the introduction emphasizes a focus on deep learning methods, which may mislead readers regarding the inclusion of non-deep learning baselines.  
* The framework's extendability is not clearly communicated, and it should be emphasized that it can integrate with other frameworks like GluonTS or DarTS.  
* The selection of datasets is limited, and the definitions of long-term and short-term forecasting scenarios are not clearly articulated.  
* The fairness of the model comparisons is questionable due to potential normalization effects on performance.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the abstract and introduction to better highlight the inclusion of non-deep learning baselines. Additionally, the authors should emphasize the framework's extendability and integration capabilities with other platforms in the main text. Clearly defining long-term and short-term forecasting scenarios in the problem formulation is essential for reader comprehension. Furthermore, addressing the fairness of model comparisons in detail will strengthen the paper's claims. Lastly, expanding the dataset selection and providing more information on computational budgets and the characteristics of the datasets used would enhance the robustness of the study.