ID: tauoKi9IWO
Title: LLMDet: A Third Party Large Language Models Generated Text Detection Tool
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 6
Original Ratings: -1, -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents LLMDet, a framework designed to classify the source of text generated by large language models (LLMs) such as GPT-2 and LLaMA. The authors propose a method to estimate proxy perplexity using n-gram probabilities, claiming that LLMDet satisfies four principles: specificity, safety, efficiency, and extendibility. The method is evaluated against eight large language models, demonstrating that the proxy perplexity is comparable to true perplexity and that LLMDet operates more efficiently than previous detectors.

### Strengths and Weaknesses
Strengths:
- The method is efficient and intuitive, with promising results from extensive experiments.
- LLMDet provides a multi-class classification capability, distinguishing between different LLMs.
- The paper contributes valuable insights into the detection of machine-generated text and the characteristics of LLMs.

Weaknesses:
- There is a lack of performance comparison with other approaches and on out-of-domain data.
- The writing quality is inconsistent, with grammatical errors and unclear terminology.
- The claim regarding LLMDet's speed compared to other methods lacks sufficient supporting data.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their writing by addressing grammatical mistakes and ensuring consistent terminology throughout the paper. Additionally, we suggest including performance comparisons with other detection methods and on out-of-domain data to strengthen the evaluation. It would be beneficial to clarify how the real perplexity is calculated and to address the robustness of LLMDet in black-box settings. Finally, we encourage the authors to provide more detailed explanations regarding the implications of their findings, particularly concerning the adaptability of their method to different LLMs and potential adaptive attacks.