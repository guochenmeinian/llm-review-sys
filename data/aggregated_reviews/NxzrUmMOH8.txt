ID: NxzrUmMOH8
Title: A Method for Assessing Inference Patterns Captured by Embedding Models in Knowledge Graphs
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an empirical investigation into the inference patterns learned by various Knowledge Graph embedding (KGE) models, focusing on their ability to capture logical inference patterns such as inversion, transitivity, and symmetry. The authors propose a methodology that utilizes the partial completeness assumption (PCA) to generate counter-evidence during training. The study evaluates multiple KGE models and identifies both their strengths and weaknesses in capturing these inference patterns.

### Strengths and Weaknesses
Strengths:
- The paper identifies properties of various KGE models and clarifies inference patterns that are challenging to learn.
- It provides a comprehensive analysis of KGE methods and their performance on different inference patterns.
- The inclusion of negative triples using PCA is a notable contribution that enhances the understanding of KGE capabilities.

Weaknesses:
- The selection criteria for inference patterns and the validity of those patterns, particularly those derived from AMIE, require further discussion.
- The small number of triples constituting each pattern raises concerns about the validity and generalizability of the results.
- The writing lacks clarity in certain areas, particularly regarding the explanation of jointly and independently embedded patterns and the handling of negative examples.

### Suggestions for Improvement
We recommend that the authors improve the selection criteria for inference patterns and provide a more detailed discussion on the validity of the inference patterns produced by AMIE. Additionally, consider using synthetic data to enhance the clarity of model properties. It would be beneficial to increase the number of triples per pattern to strengthen the generalizability of the results. We also suggest clarifying the methodology for splitting examples into train/test/valid sets and providing more comprehensive explanations of PCA and the confidence thresholds used in the analysis. Finally, addressing the clarity issues in the writing, particularly regarding the arrows coding and the interpretation of results, would significantly enhance the paper's readability.