ID: 5oEVdOd6TV
Title: Cross-Scale MAE: A Tale of Multiscale Exploitation in Remote Sensing
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 7, 6, 3, 3, 3, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 5, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a self-supervised method called Cross-Scale MAE, based on ViT masked auto encoders (MAE), aimed at enhancing representations in remote sensing models. It incorporates scale augmentation to learn features at various scales without requiring multiscale aligned data, while imposing a constraint that leverages information consistency across multiscale images. The method combines both discriminative and generative approaches, demonstrating improved performance on downstream tasks compared to existing methods like SatMAE and Scale-MAE. The model's computational efficiency is enhanced through the use of xFormers.

### Strengths and Weaknesses
Strengths:
1. The Cross-Scale MAE method is well-articulated, effectively combining discriminative and generative approaches to achieve scale-invariant representations. The cross-scale consistency loss maximizes information across scales while minimizing shared information between images at different locations, enhancing the decoder's ability to retrieve semantic information.
2. Experimental results indicate that Cross-Scale MAE outperforms competing methods across various datasets, with rigorous ablation studies demonstrating the impact of each proposed loss term.
3. The computational efficiency analysis in the Appendices is commendable, contributing to the overall understanding of the model's performance.

Weaknesses:
1. While the proposed method generally outperforms SatMAE, the consistency of results is not uniformly demonstrated, as indicated by the standard deviations in the appendices. Including standard deviations in the main document would strengthen the reliability of the findings.
2. The omission of comparisons with the GFM model, which could provide additional context and relevance to the proposed method, is noted. Furthermore, the lack of clarity regarding the specific problem addressed by the model diminishes its impact.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the problem statement and explicitly define the semantic understanding of remote sensing image tasks, such as classification and change detection. Additionally, we suggest including performance curves for Scale-MAE in Figure 3 and conducting experiments with random scale ratios during training to enhance robustness. The authors should also clarify the definitions of terms and symbols in the figures and equations, particularly in Figure 2 and Eq. 3. Finally, we encourage the authors to discuss the limitations of their approach, including potential negative societal impacts, and to commit to publishing the code and pre-trained models for reproducibility and public accessibility.