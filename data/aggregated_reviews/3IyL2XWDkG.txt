ID: 3IyL2XWDkG
Title: CAMEL: Communicative Agents for "Mind" Exploration of Large Language Model Society
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 4, 8, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents CAMEL, a role-playing framework where two LLMs (an AI user and an AI assistant) collaborate to complete tasks prompted by a human. The framework demonstrates improved performance on complex tasks compared to a GPT-3.5-turbo single-shot baseline, as evaluated by both human and GPT-4 assessments. The authors also analyze challenges in multi-agent conversations, including role flipping and conversation deviation, which could inform future research on multi-agent collaboration.

### Strengths and Weaknesses
Strengths:  
1. The introduction of a role-playing framework allows for auto-prompting between agents, potentially enhancing research on complex prompting methods.  
2. The evaluation highlights significant challenges in multi-agent collaboration, which could be valuable for future studies involving multiple language models.  

Weaknesses:  
1. The baseline comparison is insufficient, as the proposed method resembles existing techniques like chain-of-thought reasoning and lacks clarity on the prompts used for the single-shot baseline. Additionally, the evaluation using GPT-4 raises concerns about potential biases in summarization and error propagation.  
2. Important details are missing, such as the data sources for the constructed dataset and the rationale for their selection. The authors should provide specific analyses rather than referring to the appendix.  

### Suggestions for Improvement
We recommend that the authors improve the clarity of the baseline comparisons by including more detailed evaluations against methods like React, highlighting the pros and cons of each approach. Additionally, the authors should specify the prompts used for the single-shot baseline and clarify the evaluation process involving GPT-4 to address potential biases. Furthermore, we suggest providing a more comprehensive analysis of the dataset construction and the rationale behind the chosen tasks. Lastly, enhancing the clarity of figures and addressing potential role/task misalignments would improve the overall readability and understanding of the framework.