ID: 1uirUsR9E7
Title: Explaining V1 Properties with a Biologically Constrained Deep Learning Architecture
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 6, 7, 5, 5, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the incorporation of biologically inspired filtering and normalization components into deep convolutional networks (DCNs) to enhance alignment with V1 neural responses. The authors integrate center-surround receptive fields, local receptive fields, tuned divisive inhibition, and cortical magnification into DCNs trained on downscaled ImageNet-64x64. An extensive ablation study demonstrates the importance of these components for improving V1 alignment, with the best-performing model showing significant advancements in Brainscore's V1 model alignment. The authors also explore the robustness of these models against perceptual distortions.

### Strengths and Weaknesses
Strengths:
- The authors propose a novel combination of biologically inspired components that align well with primate early visual mechanisms, explained clearly for readers unfamiliar with the computations. 
- The model significantly outperforms previous state-of-the-art (SOTA) models in explaining neural activity and tuning properties, supported by multiple simulations with different random seeds.

Weaknesses:
- There is a notable drop in image classification accuracy, which the authors should address, as models that better represent biological neural activity often suffer from this issue.
- The scope of the work appears limited, raising questions about whether the improvement in V1 alignment is sufficient as the sole major contribution.
- The authors should provide intuition on how each explored component enhances neural predictivity and whether these components can improve model-brain alignment across different architectures.

### Suggestions for Improvement
We recommend that the authors improve the discussion surrounding the drop in classification accuracy, providing insights into why this occurs. Additionally, it would be beneficial to expand the scope of the work to include a more comprehensive evaluation of the contributions of each component. We suggest including a model with just adversarial training as a baseline and clarifying the decision-making process behind the architectural component selection. Furthermore, discussing the theoretical framework that underpins the observed effects of the architectural components would enhance the paper's depth. Lastly, we encourage the authors to tone down claims of "unprecedented explanation" of V1, given the modest improvements reported.