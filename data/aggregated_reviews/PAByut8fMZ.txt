ID: PAByut8fMZ
Title: A Quality-based Syntactic Template Retriever for Syntactically-Controlled Paraphrase Generation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to syntactically-controlled paraphrase generation (SPG) by introducing the Quality-based Syntactic Template Retriever (QSTR) and the Diverse Templates Search (DTS) algorithm. The QSTR model ranks syntactic templates based on their compatibility with source sentences, while the DTS algorithm enhances diversity in generated paraphrases. The authors demonstrate substantial performance improvements on both automated and human evaluations across datasets such as QQP-Pos and ParaNMT-small, and they also show that the method aids in data augmentation for downstream tasks like paraphrase detection.

### Strengths and Weaknesses
Strengths:
- The paper addresses the critical issue of selecting appropriate templates for SPG, providing an intuitive and scalable solution.
- The proposed methods effectively tackle the challenge of low diversity in generated paraphrases.
- Comprehensive evaluation includes a variety of baselines, automated metrics, and human assessments, enhancing the credibility of the findings.

Weaknesses:
- Some sections of the paper are poorly written, particularly regarding the explanation of template choices and their significance.
- The task definition lacks clarity, particularly concerning the use of exemplar-as-template as a baseline.
- The comparison with strong baselines from previous work is insufficient, making it difficult to attribute performance gains solely to the proposed methods.
- The manual evaluation does not adequately assess syntactic controllability, which is central to the task.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by providing more detailed explanations regarding the template choices and their implications. Additionally, we suggest refining the task definition to align better with standard practices in controlled paraphrase generation. It would be beneficial to include stronger baselines in the comparisons to validate the effectiveness of the proposed methods. Furthermore, we advise incorporating a separate evaluation of syntactic controllability in the manual evaluation scores to address this critical aspect of the task.