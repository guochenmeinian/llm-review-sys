ID: iif9mGCTfy
Title: Frequency-domain MLPs are More Effective Learners in Time Series Forecasting
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 5, 6, 6, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents FreTS, a framework for time series forecasting that leverages channel-wise and time-wise dependency learning in the frequency domain. The authors propose a frequency-domain MLP structure that processes the real and imaginary parts of frequency components interactively. Experimental results across 13 benchmarks indicate that FreTS outperforms state-of-the-art methods.

### Strengths and Weaknesses
Strengths:
- The two-stage framework and frequency-domain MLP module exhibit novelty.
- Comprehensive experimental results demonstrate the potential of the proposed method.

Weaknesses:
- The authors do not adequately motivate their method theoretically or in relation to prior work, failing to define key terms like "point-wise mappings" and "information bottleneck."
- The claim of a "global view" lacks clarity on how it differs from existing MLP and Transformer methods in capturing long-range dependencies.
- The assertion regarding “energy compaction” is not substantiated by experimental evidence.
- The related work section is poorly organized and lacks a comprehensive summary of previous methods.
- The presentation of the method is unclear, particularly regarding the rationale for the Frequency Temporal Learner and the design of the frequency-domain MLP.
- Additional experiments are necessary to demonstrate the benefits of the proposed approach, such as learned global periodic patterns and robustness to noise.
- Certain phrases lack clarity and require refinement.

### Suggestions for Improvement
We recommend that the authors improve the theoretical motivation for their method by clearly defining and explaining "point-wise mappings" and "information bottleneck," and elaborating on how existing methods are affected by these issues. The authors should clarify how their method captures long-range dependencies compared to previous approaches. We suggest providing experimental evidence to support the claim of “energy compaction.” Additionally, the authors should reorganize the related work section for better clarity and completeness. We encourage a more thorough discussion of the rationale behind the Frequency Temporal Learner and the design of the frequency-domain MLP. Further experiments should be included to highlight the advantages of the proposed approach, particularly regarding global periodic patterns and noise robustness. Lastly, we advise refining unclear phrases to enhance overall clarity.