ID: SVchy5VlnI
Title: Leveraging Diffusion-Based Image Variations for Robust Training on Poisoned Data
Conference: NeurIPS
Year: 2023
Number of Reviews: 2
Original Ratings: 7, 6
Original Confidences: 4, 3

Aggregated Review:
### Key Points
This paper presents a method that utilizes synthetic variations generated from a diffusion model as a train-time augmentation within a student-teacher framework. The authors demonstrate that the student model, trained using knowledge distillation, achieves high accuracy on benign images while showing robustness to backdoor triggers. The experimental results are validated on two datasets, ImageNette and ImageNet-100, with five different poison variants of BadNets and blended images.

### Strengths and Weaknesses
Strengths:
- The authors clearly articulate their hypothesis regarding the effectiveness of their method on less visible trigger patterns, enhancing the interest in the results.
- The experimental setup is well-structured, with Table 1 effectively illustrating the significant reduction in attack success rates while maintaining clean accuracy.

Weaknesses:
- The paper lacks a diverse array of potential triggers, particularly for highly visible and blended triggers, which could strengthen the findings.
- There is confusion regarding the utility of a potentially poisoned teacher model for training the student model, and the implications of removing the student-teacher framework are not explored.
- The high cost of training a diffusion model and the necessity for a large dataset are notable drawbacks.

### Suggestions for Improvement
We recommend that the authors improve the diversity of triggers by including colored grids or larger trigger sizes for highly visible triggers, and exploring less recognizable images for blended triggers. Additionally, we suggest conducting an ablation study to assess the significance of the student-teacher framework by training the student model normally on synthetic variations. It would also be beneficial to clarify whether synthetic variants can be generated without labels and to address the surprising results regarding the Blended Hello Kitty attack on ImageNet-100. Finally, we advise adding citations for relevant works that discuss backdoor behavior and correcting minor typographical errors.