ID: W5If9P1xqO
Title: ClimSim: A large multi-scale dataset for hybrid physics-ML climate emulation
Conference: NeurIPS
Year: 2023
Number of Reviews: 28
Original Ratings: 9, 9, 10, 8, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the ClimSim dataset, designed for training hybrid machine learning (ML) models on high-fidelity climate simulations. The dataset comprises over 5.7 billion pairs of physical states across various variables, facilitating the development of ML models that can enhance traditional climate simulations. The authors provide baseline experiments and benchmark methods, including a comprehensive overview of preprocessing steps and metrics for performance assessment. The dataset is hosted on the HuggingFace platform, ensuring accessibility for researchers. The authors also express a commitment to maintaining and expanding the dataset through future releases, incorporating feedback to enhance the manuscript's clarity and usability.

### Strengths and Weaknesses
Strengths:
- The dataset is extensive, addressing the data-hungry nature of ML methods, and is the largest and most physically comprehensive for hybrid-ML research.
- It includes a variety of relevant variables and detailed preprocessing steps, enhancing its utility for diverse climate science applications.
- The authors provide solid benchmark models and a well-organized documentation, including Python scripts for reproducibility.
- The paper is well-organized and clearly written, with comprehensive explanations of results and methodologies.
- The authors have actively addressed reviewer suggestions, enhancing the manuscript's clarity and usability.

Weaknesses:
- Some clarity issues exist regarding input/output sizes and terminology, which may confuse readers.
- The analysis of baseline results lacks thoroughness, particularly in discussing the performance of different methods.
- The manuscript primarily tests on a low-resolution dataset, limiting the demonstration of the dataset's full potential.
- The code repository was initially unclear and lacked sufficient documentation for non-domain experts.
- Some inconsistencies in baseline model comparisons remain, particularly regarding optimization parameters and loss functions.
- There is a lack of specific details regarding the dataset expansion and future enhancements.

### Suggestions for Improvement
We recommend that the authors improve clarity by explicitly stating input/output sizes and terminology throughout the paper. Additionally, including more thorough analysis of the baseline results, such as joint density plots and error bars, would enhance the understanding of model performance. Testing on a subset of the high-resolution dataset would provide a better sense of the dataset's capabilities. Furthermore, considering multi-scale metrics, such as the Anomaly Correlation Coefficient (ACC), in the evaluation would enrich the assessment of climate data. We also suggest improving the documentation on the GitHub repository to provide clearer guidelines for non-domain experts, particularly in the preprocessing section. It would be beneficial to include a discussion of operational constraints, such as memory and computational budgets, in the assumptions and metrics catalog. Lastly, we recommend providing more specific information about the planned expansions of the dataset and detailing how future feedback will be integrated into ClimSim.