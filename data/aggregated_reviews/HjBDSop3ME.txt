ID: HjBDSop3ME
Title: Consonant is all you need: a compact representation of English text for efficient NLP
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for representing English text using only consonants, aiming to reduce vocabulary size, out-of-vocabulary rates, and training time. The authors demonstrate that their vowel-less representations yield comparable performance to traditional methods across various NLP tasks. The paper also discusses a technique for retrieving vowel information to produce human-readable text outputs.

### Strengths and Weaknesses
Strengths:
- The proposed method is straightforward to implement and can be easily integrated with existing NLP models.
- The effectiveness of the approach has been validated through extensive experiments across multiple tasks.

Weaknesses:
- The reduction in vocabulary size and model parameters is not substantial.
- The study lacks comparisons with contemporary methods such as generative decoder models and other strategies for embedding size reduction, like dimensionality reduction and quantization.
- The reliance on a secondary vowel-retrieval step may limit the method's applicability and could increase computational requirements.

### Suggestions for Improvement
We recommend that the authors improve the paper by including comparisons with alternative strategies for reducing embedding size, such as those mentioned in the reviews. Additionally, we suggest that the authors expand their experiments to include modern transformer-based models, as the current architecture is outdated. Furthermore, addressing the limitations associated with the vowel-retrieval process and its impact on efficiency and performance in generation tasks would enhance the paper's robustness.