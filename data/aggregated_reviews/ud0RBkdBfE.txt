ID: ud0RBkdBfE
Title: Convergence Analysis of Split Federated Learning on Heterogeneous Data
Conference: NeurIPS
Year: 2024
Number of Reviews: 23
Original Ratings: 5, 8, 5, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the first comprehensive theoretical analysis of split federated learning (SFL), addressing convergence rates under various conditions, including strongly convex, general convex, and non-convex objectives, as well as full and partial client participation. The authors analyze two variants, SFL-V1 and SFL-V2, and conduct experiments comparing SFL with federated learning (FL) and split learning (SL). The paper aims to enhance understanding of SFL performance, guiding implementation and optimization choices. Experimental results provide insights into the impact of the cut layer on SFL and demonstrate the superiority of SFL-V2 over SFL-V1 and FL.

### Strengths and Weaknesses
Strengths:
- The paper fills a significant gap in the literature by providing the first theoretical convergence analysis of SFL.
- It offers a thorough discussion of convergence rates across different settings, with mild assumptions that are widely accepted in the federated learning community.
- The consideration of practical aspects like partial client participation is commendable.
- The presentation and organization are strong, and extensive experiments validate the theoretical findings, revealing significant insights and comparisons between SFL variants and FL.

Weaknesses:
- The introduction lacks theoretical or experimental evidence to support claims about high latency in split learning.
- There are inconsistencies between theoretical results and experimental observations, particularly regarding the performance of SFL under strong heterogeneity and the impact of the cut layer on performance.
- The related work section is too brief, and the empirical comparisons could benefit from more advanced federated learning algorithms beyond basic implementations.
- Limited exploration of hyper-parameter tuning for FedOpt and reliance on training set performance curves raise concerns.

### Suggestions for Improvement
We recommend that the authors improve the theoretical analysis by providing justifications for the assumptions made, particularly regarding the necessity of certain bounds and the impact of removing them. Additionally, clarify the discrepancies between theory and experiments, especially concerning the performance of SFL compared to FL and SL under high heterogeneity. It would be beneficial to expand the related work section and include a summary table of convergence rates for clarity. Furthermore, consider refining the empirical analysis by comparing SFL with more advanced algorithms and ensuring that the presentation of results is clearer and more accessible. Lastly, we suggest enhancing the robustness of the convergence results, conducting hyper-parameter tuning for FedOpt, and including performance curves for both training and test sets in the final version.