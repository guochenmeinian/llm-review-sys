ID: ytTfonl9Wd
Title: Expressivity-Preserving GNN Simulation
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 4, 8, 7, 7, 6, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 2, 4, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for simulating non-standard message-passing networks (MPNs) using standard MPNs through graph transformations. The authors investigate the expressive power of these transformations, demonstrating that standard message-passing algorithms can simulate many advanced graph neural networks (GNNs) under certain conditions. They define both strong and weak simulation and provide empirical evidence showing that their approach often outperforms the architectures it aims to simulate.

### Strengths and Weaknesses
Strengths:  
- The paper is well-structured and easy to read, with formal definitions that clarify the concepts.  
- The experimental results are convincing and well-presented, demonstrating the effectiveness of the proposed methods across multiple benchmarks.  
- The work contributes novel insights into the expressivity of various forms of graph neural networks.

Weaknesses:  
- Section 3 contains results that are largely known within the graph learning community, raising questions about its necessity in the main paper.  
- The proof of Theorem 4.1 relies heavily on specific details of "Structure-to-graph encoding," which narrows the applicability of the results.  
- The introduction lacks a coherent definition of "simulation," and the explanation of graph transformations is insufficient until later sections.

### Suggestions for Improvement
We recommend that the authors improve the coherence of the introduction by providing a formal definition of "simulation" before discussing it further. Additionally, clarifying how to convert relational structures to graphs would enhance the paper's practical applicability. Including a running example, such as the CWN case, could help illustrate the struct2graph conversion intuitively. Furthermore, we suggest that the authors address the readability issues by optimizing the organization of the introduction and background sections, ensuring that the contribution section is concise and clear. Lastly, we encourage the authors to provide more detailed explanations of terms like "nested aggregation" and to clarify the notation used throughout the paper.