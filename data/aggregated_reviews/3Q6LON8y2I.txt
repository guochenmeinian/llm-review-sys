ID: 3Q6LON8y2I
Title: Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an exploration of the re-ranking capabilities of LLMs, specifically ChatGPT, in information retrieval. The authors propose a permutation generation approach to re-rank passages and introduce a permutation distillation technique to distill the ranking capabilities of LLMs into smaller models. The paper includes comprehensive experiments on various benchmarks, including a newly constructed dataset, NovelEval, demonstrating that LLMs can outperform supervised rankers like monoT5.

### Strengths and Weaknesses
Strengths:
- The topic is novel and has the potential to inspire further research.
- The experiments are rich and comprehensive, providing valuable insights.
- The writing is clear and well-structured.

Weaknesses:
- The permutation generation method lacks a clear definition and appears heuristic.
- There are several spelling and grammatical errors throughout the paper.
- The proposed methods may not be sufficiently novel compared to existing works.
- The comparison with baseline methods may be unfair, as some comparisons are incomplete or lack rigor.

### Suggestions for Improvement
We recommend that the authors improve the clarity and definition of the permutation generation method to avoid appearing heuristic. Additionally, addressing the spelling and grammatical errors is essential for enhancing the paper's professionalism. We suggest providing a more rigorous comparison of the proposed methods against appropriate baselines, ensuring that all relevant results are included. Furthermore, conducting additional experiments to assess the sensitivity of the sliding window parameters would provide valuable guidance for implementation. Lastly, we encourage the authors to clarify the role of the RankNet loss in their supervised learning baseline to better understand the sources of performance improvement.