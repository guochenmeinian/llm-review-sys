ID: OxoP1qFotz
Title: Quality > Quantity: Synthetic Corpora from Foundation Models for Closed-Domain Extractive Question Answering
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for generating pre-training data tailored for closed-domain extractive question answering (QA) tasks by utilizing generative language models (LMs). The authors propose targeted pre-training to create task-specific datasets for COVID-QA and RadQA, achieving new benchmarks and demonstrating improvements over existing solutions. The study investigates the effectiveness of prompting generative LLMs with domain-specific entities to produce relevant synthetic data, supported by extensive experiments and analyses.

### Strengths and Weaknesses
Strengths:
- The paper is well-structured and clearly written, providing a comprehensive end-to-end flow for creating LMs for closed-domain tasks.
- It introduces a novel framework that addresses significant challenges in specialized domains, supported by robust experimental results.
- The authors conduct thorough ablation studies and analyses, yielding actionable insights for future research.

Weaknesses:
- The motivation for token filtering in experiments is unclear, and the authors do not adequately address potential information leakage from generative LMs.
- The comparison with baseline methods, particularly using noisy Wikipedia articles, lacks fairness; alternative baselines should be considered.
- There is insufficient qualitative analysis to validate hypotheses, and results over multiple runs with statistical measures are not presented.
- The choice of base models for experimentation raises questions, particularly regarding the absence of clinically fine-tuned versions and other models like Longformer or BigBird.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their experimental design by providing detailed explanations for token filtering and discussing measures to mitigate information leakage. Additionally, the authors should consider including more robust baselines beyond Wikipedia articles, such as retrieval methods or data augmentation techniques. We suggest incorporating qualitative examples to support key hypotheses and presenting results over multiple runs with mean and standard deviation. Finally, the authors should clarify their choice of base models and consider experimenting with clinically fine-tuned versions or alternative architectures that may enhance performance in the clinical domain.