ID: GJtP1ZEzua
Title: D4Explainer: In-distribution Explanations of Graph Neural Network via Discrete Denoising Diffusion
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 6, 5, 6, 7, -1, -1, -1, -1
Original Confidences: 4, 5, 3, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents D4Explainer, a method addressing the critical issue of explainable Graph Neural Networks (GNNs) by providing in-distribution explanations for both counterfactual and model-level scenarios. The authors propose integrating generative graph distribution learning into the optimization objective, enabling the generation of diverse counterfactual graphs and the identification of discriminative graph patterns. The empirical results demonstrate promising performance, although certain clarifications are necessary for better comprehension.

### Strengths and Weaknesses
Strengths:
- D4Explainer innovatively integrates graph diffusion for generating counterfactual and model-level explanations, a novel combination of previously explored components.
- The experimental results are robust and well-substantiated across various settings.
- The manuscript is generally well-organized and clearly articulates the motivations behind the proposed method.

Weaknesses:
- Some sections require clarification, particularly regarding technical details and the derivation of key equations.
- Experiments are limited to small graphs (â‰¤10 nodes) and do not account for continuous edge attributes, which are common in real applications.
- The evaluation metrics lack comprehensiveness, with insufficient reporting on standard deviations and other important metrics like validity and proximity.

### Suggestions for Improvement
We recommend that the authors improve the clarity of technical details, particularly in the derivation of Equation (2) and the explanation of Figure 1. Additionally, we suggest conducting experiments on larger graphs and incorporating continuous edge attributes to enhance applicability. The authors should also include a broader range of evaluation metrics, such as validity and proximity, and ensure that standard deviations are reported. Furthermore, we encourage the authors to clarify how the model can conditionally generate counterfactual explanations and to provide empirical evidence supporting claims about in-distribution graph generation. Lastly, including CLEAR as a baseline in the experiments and discussing its differences with the proposed framework would strengthen the related works section.