ID: UixTytSVOl
Title: Cross-modal Representation Flattening for Multi-modal Domain Generalization
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 6, 6, 5, -1, -1, -1
Original Confidences: 4, 5, 3, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an extension of unimodal flatness analysis to multi-modal domain generalization (MMDG) for the first time, proposing the Cross-Modal Representation Flattening (CMRF) method. CMRF constructs a shared representation space and employs cross-modal knowledge distillation to mitigate competition and inconsistency in flatness across modalities. Experimental results indicate that CMRF significantly outperforms baseline methods, achieving an average improvement of up to 3.52% in the video-audio modality combination. The authors identify modality competition and discrepant uni-modal flatness as primary challenges in MMDG and validate their approach through extensive experiments on benchmark datasets.

### Strengths and Weaknesses
Strengths:
1. The introduction of the CMRF method is novel and effectively addresses challenges in MMDG.
2. The paper provides a thorough analysis of modality competition and discrepant uni-modal flatness, which are critical for multi-modal generalization.
3. Comprehensive evaluations demonstrate the effectiveness of the proposed methods.
4. The writing is clear and accessible.

Weaknesses:
1. The paper lacks clarity on how to extract knowledge from mixed representations and transfer it to each modality.
2. There is insufficient quantitative analysis on inter-modal competition and the effectiveness of mitigation strategies.
3. The practical implementation aspects, such as computational requirements and scalability, are not discussed in detail.
4. The paper does not adequately evaluate loss flatness for multi-modal data, and empirical evidence supporting the effectiveness of the proposed method is lacking.

### Suggestions for Improvement
We recommend that the authors improve the clarity of how knowledge is extracted from mixed representations and transferred to each modality. Additionally, we suggest providing more quantitative analysis on inter-modal competition and validating the effectiveness of the proposed mitigation strategies. Further, the authors should include a detailed discussion on the practical implementation aspects, including computational requirements and scalability. Lastly, we encourage the authors to present empirical evidence demonstrating the optimization of loss flatness in multi-modal data.