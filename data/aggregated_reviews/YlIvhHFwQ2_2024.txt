ID: YlIvhHFwQ2
Title: DreamScene4D: Dynamic Multi-Object Scene Generation from Monocular Videos
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 7, 5, 7, 5, -1, -1, -1, -1
Original Confidences: 5, 5, 3, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DreamScene4D, a novel approach for generating realistic 4D scene representations from complex multi-object videos with significant object motions. It employs a "decompose-recompose" strategy, segmenting videos into individual objects and background, and factorizes 3D motion into camera motion, object-centric deformations, and object-to-world-frame transformations. The method demonstrates effectiveness on challenging datasets such as DAVIS and Kubric, showing significant improvements over existing video-to-4D generation methods.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written, with clear figures illustrating the system.
2. The methodology is novel and effective, particularly the factorization of 3D motions.
3. Comprehensive comparisons and ablation studies convincingly demonstrate improvements over prior methods.

Weaknesses:
1. The method requires significant human involvement due to its multi-step nature.
2. The recomposition stage's sensitivity to depth estimation performance raises concerns about accuracy.
3. Artifacts in constructed 3D assets due to segmentation and inpainting operations are observed.
4. Insufficient analysis of computational complexity and reliance on external depth estimation are noted.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the video scene decomposition process to address potential artifacts in the background. Additionally, the authors should explain how temporal consistency is maintained between object and camera motion. It would be beneficial to include comparisons with relevant baselines such as Animate124 and 4Diffusion, and to evaluate the method's robustness to depth estimation inaccuracies. Finally, we suggest providing visualizations of the 3D Gaussians to enhance understanding of spatial representations and to address the potential causes of artifacts and misalignments in the scene.