ID: tsIKrvexBd
Title: Leveraging Tumor Heterogeneity: Heterogeneous Graph Representation Learning for Cancer Survival Prediction in Whole Slide Images
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 5, 5, 5, 5, -1, -1, -1
Original Confidences: 4, 5, 4, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ProtoSurv, a heterogeneous graph model designed for survival prediction from Whole Slide Images (WSIs). The model incorporates three main components: a multi-layer GCN for structural representation, a prototype representation method to capture pathological priors, and a prior-guided fusion method to aggregate features. The authors conducted experiments on TCGA datasets, demonstrating ProtoSurv's effectiveness and providing ablation studies to justify the model's components.

### Strengths and Weaknesses
Strengths:
- The paper is clear and well-structured, making it easy to follow.
- The motivation to address intratumoral tissue heterogeneity through a heterogeneous graph is compelling.
- The experiments validate the effectiveness of ProtoSurv against several state-of-the-art methods.

Weaknesses:
- The prototypes used in the histology view are preselected rather than learned, which may limit the model's adaptability and generalization to new data.
- The model's reliance on fixed node types and multi-prototypes restricts its ability to learn from unknown factors that could influence patient outcomes.
- The design of the main modules lacks novelty, as the Structure View and Histology View are based on widely studied concepts.
- The model contains a large number of hyper-parameters, complicating its application to new datasets.

### Suggestions for Improvement
We recommend that the authors improve the adaptability of the model by allowing the prototypes in the histology view to be learned during training rather than preselected. Additionally, we suggest refining the claims in the abstract regarding the SPBD's role in addressing overfitting, as it primarily tackles pseudo-bag mislabeling. To enhance the evaluation, we recommend including comparisons with popular aggregation baselines such as ABMIL and TransMIL. Furthermore, we encourage the authors to discuss the computational requirements and scalability of the model, particularly concerning the heavy use of cross-attention mechanisms. Lastly, we suggest conducting more fine-grained ablation studies, such as examining the impact of using fewer layers in the Structure View and sharing learnable parameters across categories in the Histology View.