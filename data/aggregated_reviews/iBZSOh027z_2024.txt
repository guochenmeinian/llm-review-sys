ID: iBZSOh027z
Title: Similarity-Navigated Conformal Prediction for Graph Neural Networks
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 6, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper addresses the challenge of unreliable uncertainty estimates in semi-supervised node classification tasks using Graph Neural Networks. The authors propose a method to aggregate non-conformity scores based on feature similarity and structural neighborhood, enhancing the efficiency of prediction sets and singleton hit ratios. The proposed algorithm, SNAPS, demonstrates its effectiveness through extensive experiments, producing more compact prediction sets while maintaining finite-sample coverage guarantees.

### Strengths and Weaknesses
Strengths:  
1. The paper is well-motivated, clearly demonstrating that nodes with high feature similarity or direct connections tend to share labels.  
2. It provides a theoretical guarantee that the proposed method consistently generates smaller prediction sets than basic non-conformity score functions while maintaining the marginal coverage rate.  
3. The experimental analysis is thorough, including ablation studies and comparisons with state-of-the-art methods, and the paper is clearly written and well-structured.  

Weaknesses:  
1. The paper lacks a detailed analysis of the scalability and computational cost of the algorithm, particularly regarding how it scales with the number of nodes and edges.  
2. The focus on transductive learning limits applicability to inductive learning scenarios, which are prevalent in real-world tasks.  
3. The computational demands of calculating pairwise similarity for large-scale graph data are significant, and the sampling method used to mitigate this is not adequately detailed.  
4. The necessity of using feature similarity as an additional calibration method is not convincingly justified, given the minor differences in feature similarity between identical and different labels.  
5. The success of the method relies heavily on the empirical selection of hyperparameters, which may restrict broader application.  

### Suggestions for Improvement
We recommend that the authors improve the discussion on the scalability and computational cost of the algorithm, particularly in relation to the number of nodes and edges. Additionally, we suggest expanding the applicability of the method by exploring its performance in inductive learning scenarios and on heterophily graphs. It would be beneficial to provide more details on the sampling method used for pairwise similarity calculations. Furthermore, we encourage the authors to justify the use of feature similarity more convincingly and to explore alternative similarity metrics that incorporate structural information. Lastly, we recommend addressing the empirical selection of hyperparameters more thoroughly, including reporting results with calibration set sizes that match training/validation set sizes.