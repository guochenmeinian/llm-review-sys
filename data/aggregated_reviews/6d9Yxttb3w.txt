ID: 6d9Yxttb3w
Title: Offline Imitation Learning with Variational Counterfactual Reasoning
Conference: NeurIPS
Year: 2023
Number of Reviews: 27
Original Ratings: 7, 4, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents OILCA, a novel framework for offline imitation learning that generates counterfactual data to augment scarce expert data. The method employs a Structural Causal Model (SCM) perspective and consists of four main steps: pretraining a heuristic expert policy, training a conditional VAE with expert and supplementary data, generating counterfactual states through do-interventions, and applying an offline imitation learning method on the augmented dataset. OILCA demonstrates superior performance across various environments compared to multiple baselines, indicating its potential as a valuable augmentation technique for offline imitation learning. The authors also address challenges of generalization and spurious correlations, showing that their method can effectively utilize augmented data to improve policy performance, even when counterfactual reasoning is not perfect. Empirical results demonstrate significant performance gains over a baseline pretrained policy across various tasks, including the DeepMind Control Suite, where the method shows consistent performance improvements and robustness to the selection of the auxiliary variable \(c\). However, while counterfactual data augmentation shows improvements over other baselines, it still lags behind the performance achieved with golden expert data.

### Strengths and Weaknesses
Strengths:
1. The proposed method is sound and can be integrated with various offline imitation learning methods, providing a novel approach to generating counterfactual samples.
2. The authors effectively convey the motivation and high-level process of the algorithm, supported by clear pseudocode and well-structured writing.
3. Empirical results show that OILCA significantly outperforms multiple baselines, enhancing performance across both in-distribution and out-of-distribution datasets.
4. The theoretical analysis provides a solid foundation for understanding the relationship between sample size and counterfactual reasoning errors, addressing generalization, a critical issue in the imitation learning and reinforcement learning communities.
5. The method effectively incorporates uncertainty through Gaussian perturbation, enhancing the robustness of the model.

Weaknesses:
1. The related work section lacks depth, missing discussions on generative models and existing methods like FIST, PARROT, and CEIP that address similar problems.
2. OILCA's complexity, involving multiple networks and training processes, raises concerns about potential instability and resource usage, with no computational resource or training time reported.
3. The pseudocode requires clarification, particularly regarding variable assignments and the do-intervention process, which could confuse readers.
4. The relationship between generalization and spurious correlations is not clearly articulated, leading to confusion regarding the relevance of spurious features in the experiments.
5. The choice of the variable \(c\) for disentangled representation learning raises concerns about its empirical applicability and accessibility in real-world scenarios.
6. Counterfactual data augmentation does not consistently outperform golden expert sampling, indicating room for improvement.
7. The paper lacks detailed descriptions of the simulated environments, which may lead to misunderstandings regarding the need for strong supervision.

### Suggestions for Improvement
1. We recommend that the authors expand the related work section to include discussions on generative models and relevant studies that address similar challenges in offline imitation learning.
2. We suggest providing a detailed explanation of the concerns regarding OILCA's complexity and potential instability, as well as addressing the questions posed about the counterfactual reasoning process.
3. We encourage the authors to modify the pseudocode for clarity, ensuring that variable assignments and the do-intervention process are explicitly defined.
4. We recommend that the authors strengthen their claims regarding robustness by providing empirical evidence and clarifying the relationship between sub-optimal datasets and spurious features.
5. We recommend improving clarity regarding the relationship between generalization and spurious correlations, possibly by providing references or experimental support for their claims. Additionally, we suggest removing ambiguous statements about spurious correlations if they are not explicitly investigated in the paper.
6. Regarding the selection of the variable \(c\), we advise the authors to explore alternative choices and compare their performance, particularly in the context of the DeepMind Control Suite, where the use of random seeds as \(c\) may not be intuitive.
7. We recommend that the authors improve the clarity of the environment descriptions to prevent misconceptions about the necessity of strong supervision and provide full results in future revisions to enhance the soundness and impact of their work for general readers.
8. Lastly, we suggest conducting experiments to compare the performance gap when increasing the expert data proportion using both the golden expert and the proposed method, as this would greatly enhance the understanding of the method's performance and its implications.