ID: c5WOU7p4ES
Title: PLASTIC: Improving Input and Label Plasticity for Sample Efficient Reinforcement Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 7, 6, 7, 8, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the generalization and plasticity of deep reinforcement learning (RL) agents, proposing a method that integrates Sharpness-Aware Minimization (SAM) with weight resetting. The authors demonstrate that this combination enhances adaptability to input changes and improves the ability to adapt to new targets. Empirical evaluations on Atari 100k show consistent performance improvements when applying SAM+Resets to Data-Efficient Rainbow (DER) and Data-regularized Q (DrQ). However, the benefits of SAM are less evident in the DeepMind Control Suite (DMC).

### Strengths and Weaknesses
Strengths:
- The paper provides a thorough empirical investigation, with claims supported by sharpness metrics and ablation studies.
- It presents a clear and well-structured narrative, making it enjoyable to read.
- The combination of SAM and resetting mechanisms is novel and well-justified through experiments.

Weaknesses:
- The choice of DER as a baseline is questioned, as it may yield smaller improvements compared to stronger algorithms like SPR.
- The paper lacks scalability results for various settings, raising concerns about the generality of findings.
- Several minor issues exist, such as placeholder values in Table 1 and potentially misleading bolding of results in Table 2.

### Suggestions for Improvement
We recommend that the authors improve the empirical evaluation by including stronger baseline algorithms, such as SPR, to assess the true impact of SAM. Additionally, conducting scalability tests across all settings would enhance the generality of the findings. Clarifying the distinction between "adaptability" and "plasticity" in the paper is essential, as is addressing the minor issues in the tables. Finally, we suggest expanding the explanation of why SAM and resets enhance adaptability, particularly in relation to the intriguing results observed in Figure 2a.