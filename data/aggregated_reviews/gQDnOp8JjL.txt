ID: gQDnOp8JjL
Title: Negative Sampling in Next-POI Recommendations: Observation, Approach, and Evaluation
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a hard-negative sampling model training scheme for next-POI recommendations, introducing the Degree of Positiveness (DoP) to enhance the sampling process by considering user preferences and geographical distances. The authors validate the disadvantages of random-negative sampling and demonstrate the effectiveness of their approach through comprehensive experiments, showing improvements over state-of-the-art models.

### Strengths and Weaknesses
Strengths:
1. The paper provides an in-depth validation of random-negative sampling's drawbacks, supported by plots.
2. The novelty of the hard-negative sampling scheme and the definition of DoP is noteworthy, integrating user preferences and geographical distances.
3. The experiments are well-designed and yield promising results, with open-sourced code for reproducibility.

Weaknesses:
1. The proposed method lacks novelty, as the DoP is a simple combination of existing concepts regarding hardness and geographical distance.
2. The two-step sampling strategy is inefficient, requiring calculations for all items, which negates the efficiency of sampling-based methods.
3. The experimental baselines are insufficient; competitive negative sampling methods should be included rather than relying solely on random sampling.
4. The presentation is confusing, with excessive italics and a lack of clarity in the training steps, which could benefit from pseudo code.
5. The paper does not adequately explain how hard-negative sampling influences the training process or provide sufficient analysis on the complexity and efficiency of the proposed method.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the presentation by reducing the use of italics and providing a clearer structure for the training steps, possibly through pseudo code. Additionally, the authors should include a more thorough literature review and comparison with existing hard-negative sampling techniques to better position their contribution. To enhance the efficiency of their method, we suggest exploring the use of softmax loss instead of the current sampling-based loss. Furthermore, the authors should validate their method on a wider range of datasets with varying densities and provide more details on dataset statistics and preprocessing for reproducibility. Lastly, including ablation studies would strengthen the analysis and support the claims regarding the proposed method's effectiveness.