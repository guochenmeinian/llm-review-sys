ID: cmJiEqniEc
Title: Detecting Backdoors with Meta-Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 2
Original Ratings: 7, 6
Original Confidences: 3, 3

Aggregated Review:
### Key Points
This paper presents a novel backdoor detection method utilizing meta-models, specifically training transformers. It involves flattening a suspicious network into chunks, treating each as a token, which are then classified through a transformer decoder. The authors conduct experiments across various settings, both iid and ood, demonstrating the method's effectiveness. Additionally, the meta-model is extended to tasks of network interpretability, showing proficiency in this area.

### Strengths and Weaknesses
Strengths:
- The use of meta-models for backdoor detection is a novel concept, supported by solid technical details.
- The proposed method outperforms baselines across different settings and poisoning methods.
- Promising results are also presented for model interpretability tasks.

Weaknesses:
- Increasing the architecture size (e.g., to 10 million parameters) will lead to a proportional increase in tokens, potentially demanding significant computational resources.
- The paper contains minor grammatical errors and some complex language that may hinder understanding.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by refining the English and addressing grammatical issues. Further explanation of RASP and Tracr is necessary to assist readers unfamiliar with these tools, as they are integral to the paper. Additionally, we suggest providing more detailed descriptions of the experiments, including the parameters used for training and inference, as well as the motivation behind individual experiments to better highlight the findings.