ID: Ou1VRZ4j4y
Title: Learning Multi-agent Behaviors from Distributed and Streaming Demonstrations
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 7, 5, 5, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on uncovering the incentives and behaviors of a cooperative multiagent system (MAS) optimizing for an objective under constraints. The authors propose a distributed optimization framework where multiple learners observe separate trajectories of the MAS and infer the parameters of the MAS's reward functions and policies. This is formulated as a bi-level optimization problem, with the inner problem solving for a joint policy given a reward function in the dual, and the outer problem learning the reward function via maximum likelihood estimation. The authors demonstrate that consensus is achievable and provide a convergence rate, showing that the agreed policy has sublinear regret concerning constraint violation. The approach, MA-BIRDS, is validated through experiments in both discrete and continuous domains, showing performance comparable to centralized methods with shorter runtimes.

### Strengths and Weaknesses
Strengths:  
The authors effectively explain their complex setup and solution, acknowledging prior work while detailing their contribution to inferring MAS behaviors through a distributed, online approach. They provide solid theoretical analysis and experimental comparisons against strong baselines.

Weaknesses:  
The motivation for the distributed problem could be stronger, as experiments indicate centralized approaches perform similarly or better. The theoretical convergence rates appear independent of the number of learners, and there is a lack of empirical evidence demonstrating the benefits of distributed learning, particularly regarding parallelism.

### Suggestions for Improvement
We recommend that the authors improve the motivation for the distributed approach by discussing potential downsides of centralizing data, such as privacy concerns, communication overhead, and robustness to failures. Additionally, we suggest including experiments that vary the number of learners to showcase the advantages of distributed learning. Addressing the online efficiency of the proposed algorithm, particularly concerning the soft-Q learning/soft actor-critic methods, would also enhance the paper. Lastly, a more comprehensive literature review and clarification on the challenges of extending single-loop bi-level optimization to decentralized cases would strengthen the contribution.