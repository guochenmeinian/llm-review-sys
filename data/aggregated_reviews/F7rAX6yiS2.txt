ID: F7rAX6yiS2
Title: DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 8, 7, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents "DiReCT: Diagnostic Reasoning for Clinical Notes via Large Language Models," which introduces a novel dataset and benchmark aimed at evaluating the diagnostic reasoning capabilities of large language models (LLMs) in healthcare. The dataset comprises 521 clinical notes annotated by physicians and includes a diagnostic knowledge graph. The authors propose that while strictly adhering to the knowledge graph may simplify diagnostics, it may limit the LLM's reasoning potential. They argue that in cases of insufficient observations, LLMs can still leverage reasoning capabilities, although evidence for this claim is requested. The authors emphasize interpretability and provide comprehensive evaluation metrics for assessing LLM reasoning abilities, drawing parallels between their method and the entailment tree framework, suggesting that explanations enhance the LLM's decision-making by associating observations with diseases.

### Strengths and Weaknesses
Strengths:
- The development of a dataset with human clinician annotations addresses a critical need for evaluating diagnostic reasoning in the medical field.
- The dataset and benchmark are highly relevant to real-world clinical scenarios, enhancing the interpretability of AI-driven medical applications.
- The authors demonstrate a thoughtful integration of structured knowledge with LLM reasoning, aiming to enhance diagnostic accuracy.
- The paper includes a thorough evaluation of various LLMs, providing insights into their performance in clinical reasoning.
- The response to reviewer comments reflects a commitment to transparency and improvement, including plans to outline limitations and include additional experimental results.

Weaknesses:
- The methodology for diagnosis directly by the LLM raises questions, as the diagnostic knowledge graph could potentially streamline the process through entity linking.
- The dataset construction lacks transparency, particularly regarding how many data points were amended and the rationale behind these modifications.
- Notational clarity is inconsistent throughout the paper, making it challenging for readers to navigate the content.
- There is a lack of empirical evidence supporting claims about the LLM's reasoning capabilities in scenarios with insufficient observations.
- The distinction between observation identification and reasoning iterations may not be clearly articulated, potentially leading to confusion about the framework's processes.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the diagnostic process by explicitly detailing the rationale for allowing LLMs to make diagnoses directly rather than following the knowledge graph. Additionally, providing a Datasheet For Datasets that outlines the construction process and statistics on amended data points would enhance transparency. We suggest including a table of notations with definitions to aid readability and better aligning figures with their corresponding notations. Furthermore, we recommend evaluating model performance under common clinical constraints, such as incomplete information, to better reflect real-world scenarios. We also recommend improving the clarity of the relationship between observation identification and reasoning iterations in their framework. Additionally, including experimental results that demonstrate the LLM's reasoning capabilities when observations are insufficient would be beneficial. It would also be advantageous to clearly represent the limitations discussed in the reviews within the paper and incorporate the additional experimental results in the supplementary section while updating the main text to reference these findings, particularly regarding the reasoning halts before final diagnoses due to lack of observations.