ID: qAP6RyYIJc
Title: Stealth edits to large language models
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 6, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel algorithm for *stealth edits* in large language models (LLMs), enabling selective corrections of known hallucinations without altering overall model behavior. The authors introduce the concept of *intrinsic dimension* as a metric for evaluating the ease of editing network blocks and propose two methods: in-place editing of model parameters and the insertion of a *jet-pack module* for multiple edits. The paper provides theoretical guarantees for edit selectivity and empirical validation across various datasets, revealing vulnerabilities in LLMs to targeted manipulations. Additionally, the authors acknowledge the need for clearer framing regarding the limitations of their work, particularly to avoid misconceptions about its efficacy in manipulating model parameters. They have conducted additional experiments demonstrating that their edits do not adversely affect model performance across various domains.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, clearly articulating the problem and presenting a significant and novel contribution to the field.
- The concept of *intrinsic dimensionality* is valuable for understanding selective edits and identifying vulnerabilities in LLMs.
- The empirical evaluation is rigorous, covering various architectures and scenarios, demonstrating the effectiveness of the proposed methods.
- The work introduces valuable techniques that could benefit future research.
- Additional experiments provide evidence that the proposed edits maintain model performance across different tasks.

Weaknesses:
- The motivation surrounding *stealth* could be better defined, particularly regarding the detection of malicious alterations.
- The limitations of the jet-pack approach in terms of stealthiness and generalizability are not adequately addressed.
- The empirical results show a gap between theoretical expectations and actual performance, particularly concerning false positive rates and edit success across different layers.
- The framing of "hallucination" may be misleading and should be clarified to avoid overgeneralization.
- The definition of "stealth" lacks a user-centric perspective, as it does not fully account for performance evaluations that practitioners typically conduct.
- Short sequence lengths in the experiments limit understanding of the model's performance on longer inputs.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation for *stealth edits*, particularly in defining stealth in relation to detectable alterations in model weights. Additionally, we suggest providing a more thorough evaluation of the jet-pack approach's stealthiness and generalizability, including comparisons with existing methods like ROME and GRACE. It would also be beneficial to address the observed discrepancies between theoretical expectations and empirical results regarding false positive rates and edit success. Furthermore, we recommend that the authors improve the clarity of the abstract by explicitly stating the limitations of their work to prevent misconceptions about its capabilities. We suggest redefining "stealth" from the user's perspective, ensuring that it aligns with common evaluation practices such as perplexity assessments across various tasks. Finally, we encourage the authors to explore longer sequence lengths in their experiments to better assess the impact of their techniques on model quality.