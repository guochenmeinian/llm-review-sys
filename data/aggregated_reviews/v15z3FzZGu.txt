ID: v15z3FzZGu
Title: Adapter Pruning using Tropical Characterization
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach for adapter pruning by leveraging tropical characteristics, formulated as an optimization problem to identify row-sparse projection matrices. The authors aim to minimize the distance of tropical hypersurfaces before and after pruning, demonstrating the method's effectiveness on five NLP classification datasets. The proposed approach outperforms magnitude-based baselines, contributing to the field of parameter-efficient tuning methods.

### Strengths and Weaknesses
Strengths:
- The paper addresses an important problem in NLP research related to parameter-efficient learning.
- The proposed method is elegant and rooted in linear algebra, preserving the tropical adapter hypersurface.
- Experimental results indicate potential performance enhancements for pre-trained language models in specific tasks.

Weaknesses:
- The motivation for pruning based on tropical hypersurfaces is unclear, lacking a thorough discussion of its significance.
- The paper does not include state-of-the-art baselines for comparison, and the configuration of the adapter is inadequately explored.
- Several typos, grammar issues, and unclear notations detract from the clarity of the presentation.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation behind using tropical hypersurfaces for pruning and provide a comparison with other pruning methods. Additionally, the authors should investigate and clearly define the bottleneck dimensions used in their experiments and discuss their influence on pruning ratios. We also suggest enhancing the explanation of Algorithm 1 and ensuring that all notations are well-defined. Finally, addressing the identified typos and improving the overall presentation will strengthen the paper.