ID: 04DbUMZGMD
Title: ESCNet: Entity-enhanced and Stance Checking Network for Multi-modal Fact-Checking
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the first large-scale, multi-domain Chinese multi-modal fact-checking dataset, comprising 46,000 claims and divided into Collected Chinese Multi-modal Fact-Checking (CCMF) and Synthetic Chinese Multi-modal Fact-Checking (SCMF) sub-datasets. The authors propose ESCNet, an innovative model that integrates a Multi-modal Feature Extraction Module, Stance Transformer, and Entity-enhanced Encoder, aiming to enhance semantic reasoning and knowledge representation in fact-checking. The experimental results demonstrate the effectiveness of ESCNet, setting a new standard in the field.

### Strengths and Weaknesses
Strengths:
- The construction of the first large-scale CCMF and SCMF benchmarks is a significant contribution.
- Experimental results validate the robustness of ESCNet against various state-of-the-art baselines.
- The paper is well-structured and presents clear reasoning.

Weaknesses:
- The writing lacks clarity, making it difficult to follow the justification for different model components.
- The technical details, particularly regarding the knowledge-enhanced distance measurement and the Multi-modal Feature Extraction Module, require further elaboration.
- The focus on Chinese data may limit the model's applicability to other languages.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing, particularly in justifying the roles of different components of ESCNet. Additionally, we suggest expanding the section on dataset construction to detail the pre-processing choices and their implications for dataset quality. It would also be beneficial to address how the ESCNet model can be adapted for other languages and to clarify the workings of the knowledge-enhanced distance measurement. Finally, consider providing the code and datasets publicly to enhance accessibility and facilitate further research.