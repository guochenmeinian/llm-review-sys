ID: EmOIP3t9nk
Title: ImageBrush: Learning Visual In-Context Instructions for Exemplar-Based Image Manipulation
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 5, 6, 4, 7, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 5, 5, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel image editing framework called ImageBrush, which utilizes exemplar-based visual prompting for image manipulation. The authors propose a diffusion-based generative model that incorporates user-provided example images as instructions, allowing for complex editing tasks without relying on textual descriptions. The work aims to expand the potential applications of image manipulation, emphasizing the importance of capturing editing intentions effectively. The framework is evaluated through various experiments, demonstrating its effectiveness and generalization capabilities across different tasks. Additionally, the authors clarify previous concerns regarding unfair comparisons with existing methods like Visual Prompting and video inpainting tasks.

### Strengths and Weaknesses
Strengths:
- The proposed method introduces a unique approach to image manipulation using visual instructions, which may enhance user experience.
- The framework shows strong performance in downstream tasks and generalizes well compared to existing methods that require task-specific models.
- The authors provide extensive experimental results and a new metric for evaluating image manipulations.
- The proposed method demonstrates potential for novel interactive systems in image editing, which could enhance user engagement and application scope.

Weaknesses:
- The reliance on example pairs for editing can be impractical for users, as finding suitable pairs for specific tasks may be challenging.
- The method's abstract nature may complicate achieving precise manipulations, as users may struggle to identify the necessary example pairs.
- The evaluation metrics and comparisons with existing methods, particularly Visual Prompting, lack comprehensiveness and clarity.
- Figure 3 lacks clarity, which may hinder reader comprehension; a more intuitive graphical representation is needed.
- The Interface module requires further investigation to fully realize its potential and effectiveness in guiding editing intentions.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their claims regarding originality, particularly in relation to existing work on visual prompting. It would be beneficial to adopt a more restrained tone and emphasize concepts like "progressive inpainting." Additionally, the "Related Work" section should include references to "Visual Prompting" and "In-context learning" for a more thorough literature survey.

We suggest conducting comparisons against existing in-context learning methods, such as Visual Prompting, to validate the proposed framework's effectiveness. Furthermore, qualitative results for the interface design module should be included to substantiate its practical utility. 

To enhance the clarity of figures and tables, we recommend providing more detailed captions and explanations, particularly for Figure 3 and the novel evaluation metric. We also recommend improving Figure 3 by adopting a histogram-like graph or a line graph for clearer interpretation, similar to examples in related literature. Lastly, addressing the limitations and potential ethical concerns in greater detail, including examples of failure cases, would strengthen the paper's overall contribution.