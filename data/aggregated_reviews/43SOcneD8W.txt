ID: 43SOcneD8W
Title: Chain-of-Thought Tuning: Masked Language Models can also Think Step By Step in Natural Language Understanding
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an approach called "Chain-of-Thought Tuning (CoTT)" aimed at enabling masked language models (MLMs) to perform step-by-step reasoning in natural language understanding (NLU) tasks. The CoTT framework consists of two steps: generating an intermediate step and label based on input text, followed by predicting the final result using both the text and the intermediate step. The authors demonstrate that CoTT outperforms baseline methods in hierarchical classification and relation extraction tasks, achieving state-of-the-art results.

### Strengths and Weaknesses
Strengths:
- The proposed CoTT technique introduces a novel two-step reasoning framework that facilitates step-by-step thinking in MLMs.
- The paper is well-written, with a clear motivation for transferring Chain-of-Thought (CoT) concepts from large language models (LLMs) to MLMs.
- The introduction of an intermediate step enhances the explainability of the model.

Weaknesses:
- The evaluation is limited to only two NLU tasks, which raises questions about the generalizability of the CoTT framework.
- The performance gains reported are marginal compared to simpler prompt tuning methods, indicating that the contributions may be incremental.
- Key components of the proposed framework, such as Counterfactual-based Contrastive Learning (CCL) and Probability Rectification (PR), appear to be minor adaptations of existing methods.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by including a wider range of NLU tasks to strengthen the generalizability of the CoTT framework. Additionally, we suggest providing concrete examples of prompt templates to clarify the proposed method, particularly regarding the convertible slot in Section 4. The authors should also address the marginal performance gains by comparing CoTT with relevant baselines for in-context learning of larger language models. Furthermore, clarifying the motivation for introducing contrastive learning and providing details on the training and inference costs would enhance the paper's rigor. Lastly, we encourage the authors to explore the potential of combining CoTT with knowledge-enhanced MLMs for improved performance.