ID: nRp0XhTf61
Title: InternLM-XComposer2-4KHD: A Pioneering Large Vision-Language Model Handling Resolutions from 336 Pixels to 4K HD
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 5, 3, 8, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents InternLM-XComposer2-4KHD, a large vision-language model capable of processing images at up to 4K HD resolution. The model features a dynamic resolution adaptation mechanism that preserves aspect ratios, enhancing its understanding of complex image-text interactions. It demonstrates significant performance improvements, outperforming models like GPT-4V and Gemini Pro in 10 out of 16 benchmarks. The authors also highlight the model's potential impact on the field of multimodal large language models (MLLMs).

### Strengths and Weaknesses
Strengths:
1. The paper introduces a substantial enhancement in large vision-language models, showcasing significant performance improvements across multiple benchmarks.
2. The dynamic resolution design is noteworthy, allowing for adaptable image resolutions while maintaining critical detail.
3. The writing is commendable, with informative charts and examples effectively illustrating the model's capabilities.

Weaknesses:
1. The paper lacks optimizations for accelerating high-resolution training, limiting broader applicability due to heavy computational resource requirements.
2. There is insufficient analysis of the model's inference efficiency, making it difficult to justify the computational costs against performance gains.
3. The introduction repetitively emphasizes adaptability to 4K resolution without clear problem statements or motivational examples, leading to ambiguity in understanding the challenges addressed.
4. While the work advances vision-language understanding, it raises questions about the model's proficiency with complex visual content, as presented examples do not convincingly demonstrate its ability to interpret intricate visuals.

### Suggestions for Improvement
We recommend that the authors improve the analysis of inference efficiency to clarify the computational costs associated with high-resolution inputs. Additionally, providing clearer problem statements and motivational examples in the introduction would enhance reader comprehension. To strengthen the paper's impact, we suggest including further insights or evidence regarding the model's ability to process complex visual content. Finally, we encourage the authors to release more detailed training information, such as loss figures, to aid future research in high-resolution training methodologies.