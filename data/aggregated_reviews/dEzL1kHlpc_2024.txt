ID: dEzL1kHlpc
Title: Has My System Prompt Been Used? Large Language Model Prompt Membership Inference
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 8, 6, 5
Original Confidences: 4, 4, 3

Aggregated Review:
### Key Points
This paper presents Prompt Detective, a novel training-free statistical method for verifying the usage of proprietary system prompts in third-party language models (LLMs). The authors employ membership inference techniques to detect prompt involvement by comparing high-dimensional text representations. They claim effectiveness in black-box settings, supported by extensive experiments demonstrating robustness across various LLMs and prompt similarity levels. The methodology utilizes statistical comparisons of response distributions, enhancing detection without requiring model retraining.

### Strengths and Weaknesses
Strengths:  
- The innovative use of membership inference for detecting proprietary prompt usage in LLMs addresses limitations of existing training-based techniques, particularly in black-box scenarios.  
- The structured workflow and statistical analysis enhance robustness and adaptability across different models and deployment conditions.  
- Extensive experiments validate the method's reliability and accuracy across various architectures and prompt similarities.  

Weaknesses:  
- The assumption that similar prompts can be detected solely through statistical distribution comparisons may oversimplify the complexities of LLM responses, particularly in edge cases with inherent biases.  
- Insufficient comparisons with existing state-of-the-art techniques for prompt detection, such as adversarial testing or model-specific approaches, limit the paper's depth.  
- The originality is constrained by reliance on established techniques, and the implications of fine-tuning on the method's effectiveness are not adequately discussed.  

### Suggestions for Improvement
We recommend that the authors improve their analysis by testing other Transformer-based embeddings, particularly those from GPT models, to enhance the method's applicability. Additionally, a discussion on the impacts of fine-tuning on Prompt Detective is essential, as fine-tuned LLMs may present significant biases affecting detection. A detailed analysis of computational costs regarding query frequency, model access, and performance trade-offs would provide practical insights for commercial implementation. Finally, we urge the authors to expand the discussion on safety and privacy implications, including recommendations for ML/AI practitioners to protect intellectual property.