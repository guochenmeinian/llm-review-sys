ID: HwO1mNluoL
Title: Mitigating Biases in Blackbox Feature Extractors for Image Classification Tasks
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 6, 5, 8, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method for addressing biases in blackbox feature extractors used in image classification tasks, specifically through a clustering-based adaptive margin loss that does not require prior knowledge of bias attributes. The authors investigate existing debiasing techniques and demonstrate the effectiveness of their approach across multiple benchmarks, emphasizing its practical applicability in scenarios where feature extractor weights are inaccessible.

### Strengths and Weaknesses
Strengths:
- The paper shows originality and practical relevance, tackling a challenging problem with a novel and effective clustering-based adaptive margin loss.
- The methodology is well-written and clearly presented, with comprehensive details in the introduction and methodology sections.
- Extensive experimental validation across diverse datasets, including CIFAR, Waterbirds, and CelebA, highlights the method's effectiveness and efficiency.

Weaknesses:
- A deeper theoretical analysis of the proposed method's effectiveness is needed to enhance scientific rigor.
- The applicability of the method is uncertain, as it relies on the assumption that biases in the downstream dataset align with those in the pretrained model, which is difficult to verify a priori.
- The organization of the manuscript, particularly in section 3, is somewhat confusing, and critical design decisions lack clarity, such as the selection of the clustering algorithm and the value of $\lambda$.

### Suggestions for Improvement
We recommend that the authors improve the theoretical analysis of their method to bolster scientific rigor. Additionally, clarifying the conditions under which their approach is applicable would enhance its practical utility. Specifically, the authors should provide more details on how to identify scenarios where the bias alignment assumption holds. Furthermore, we suggest expanding the experiments to explore the impact of varying the proportion of the majority group across all datasets, as well as including standard deviations for competing methods in the tables to provide a more comprehensive comparison.