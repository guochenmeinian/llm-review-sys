ID: 4uylA0mUkk
Title: Data Factors for Better Compositional Generalization
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis of the relationship between dataset complexity and compositional generalization in seq2seq models. The authors propose that increased dataset complexity enhances generalization due to factors such as diverse patterns that hinder surface memorization and larger dataset sizes that complicate simple memorization. The study also examines how varying example difficulties within datasets influence generalization performance.

### Strengths and Weaknesses
Strengths:
- The paper systematically analyzes the effects of dataset complexity on generalization abilities, providing valuable insights into model performance.
- The proposal that augmenting datasets with new vocabulary can significantly enhance performance is intriguing and intuitively appealing.
- The experiments are well-designed, and the findings regarding medium-level complexity achieving optimal accuracy are noteworthy.

Weaknesses:
- The observation that complexity affects training is not novel and is widely accepted in the machine learning community.
- The complexity and difficulty metrics lack robust justification, and the paper does not adequately explore other challenging compositional splits or alternative measures of data complexity.
- The phenomenological focus on dataset characteristics neglects underlying mechanisms related to model capacity and representation learning.

### Suggestions for Improvement
We recommend that the authors improve the justification for their focus on specific datasets and the complexity metric used. Additionally, consider exploring other measurements of data complexity, such as compound divergence and local structures, to enhance the robustness of their findings. It would be beneficial to clarify the differences between "improving compositional understanding" and "preventing surface memorization" and to address how regularization techniques might influence generalization. Lastly, we suggest investigating the potential of combining tokenizers in the AugZero data augmentation procedure to exploit additional combinatorial factors.