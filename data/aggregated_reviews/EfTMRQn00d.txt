ID: EfTMRQn00d
Title: STREAMER: Streaming Representation Learning and Event Segmentation in a Hierarchical Manner
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 4, 5, 4, 6, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents STREAMER, a self-supervised architecture for hierarchical representation learning and segmentation of streaming perceptual inputs. The model employs layer-by-layer training to adapt to input complexity, aiming to predict future events while facilitating information flow across levels. By detecting prediction error peaks, it constructs an event hierarchy that supports bottom-up processing. The model is fully self-supervised and demonstrates promising results in temporal event segmentation and retrieval tasks, particularly on the Epic-Kitchen dataset.

### Strengths and Weaknesses
Strengths:
- The methodology is well-articulated and easy to follow, supported by effective visualizations.
- The innovative use of global context enhances event segmentation, and the self-supervised learning pipeline reduces annotation efforts.
- Experimental results on the Epic-Kitchen dataset are promising, showcasing the model's potential.

Weaknesses:
- Terminology is inconsistent, leading to confusion (e.g., event model vs. representation).
- The justification for using a streaming approach is insufficiently elaborated.
- Limited evaluation is conducted, with results primarily on the EPIC-KITCHEN dataset and minimal comparisons to prior work, hindering the assessment of the method's effectiveness.

### Suggestions for Improvement
We recommend that the authors improve the clarity of terminology to avoid confusion. Additionally, elaborating on the motivation for the streaming approach would strengthen the paper. Expanding the evaluation to include comparisons with more prior work and diverse datasets, such as exocentric video datasets, would provide a more comprehensive validation of the proposed method. Furthermore, we suggest including more experimental results regarding the Hierarchical Gradient Normalization to enhance the soundness of the findings. Lastly, addressing the computational cost of the proposed method would be beneficial.