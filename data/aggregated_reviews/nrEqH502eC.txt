ID: nrEqH502eC
Title: BLEnD: A Benchmark for LLMs on Everyday Knowledge in Diverse Cultures and Languages
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 7, 7, 4, 8, 7, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the BLEND benchmark, designed to evaluate large language models' (LLMs) cultural knowledge across diverse cultures and languages, comprising 52.6k question-answer pairs from 16 countries/regions in 13 languages, including low-resource languages. The authors conduct extensive evaluations of 16 LLMs, revealing significant performance gaps between high-resource and low-resource cultures. The study highlights that models perform better in local languages for mid-to-high-resource cultures but in English for low-resource cultures.

### Strengths and Weaknesses
Strengths:
1. The introduction of the BLEND benchmark addresses a critical gap in evaluating LLMs' cultural knowledge.
2. The dataset includes a wide range of cultures and languages, particularly low-resource ones.
3. The methodology for data collection and evaluation is well-structured and documented, enhancing the credibility of the findings.

Weaknesses:
1. The small number of annotators may introduce bias and limit the cultural diversity captured in the benchmark.
2. The benchmark lacks empirical depth, with limited analysis beyond basic accuracy metrics and no ablation studies.
3. The simplicity of questions may reduce the dataset's overall richness in assessing cultural knowledge.

### Suggestions for Improvement
We recommend that the authors improve the empirical analysis by including more in-depth data analysis and ablation studies to complement the main results. Additionally, we suggest conducting more experiments on open-sourced models, such as Llama, and cultural-specific models like MaLA-500 and TAIWAN-LLM. It would also be beneficial to explore factors influencing LLMs' cultural understanding, such as the scale of the model and the training corpus. Furthermore, addressing potential translation errors and ensuring culturally appropriate questions would enhance the dataset's relevance and effectiveness.