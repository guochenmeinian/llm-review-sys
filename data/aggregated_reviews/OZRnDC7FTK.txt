ID: OZRnDC7FTK
Title: Exploring Neural Scaling Law and Data Pruning Methods For Node Classification on Large-scale Graphs
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an exploration of data pruning methods for node classification tasks using graph neural networks (GNNs) and investigates the neural scaling law in GNNs. The authors develop a pruning technique that effectively removes training nodes while maintaining test accuracy. The paper includes a benchmarking section that provides valuable insights into data pruning for node classification.

### Strengths and Weaknesses
Strengths:
1. The paper addresses a clearly articulated problem in graph data pruning, an area less explored compared to image and language models.
2. The benchmarking section is well-executed, offering interesting insights into data pruning for node classification tasks.
3. The proposed algorithm demonstrates excellent results, validating its effectiveness in saving computational time on large graph datasets.

Weaknesses:
1. Some experimental settings are unclear, particularly regarding the use of semi-supervised settings and the removal of training nodes and adjacent edges.
2. Figure 1 lacks uncertainty representation from random node selection; each data point should have at least ten repetitions for robust statistics.
3. The paper relies on a single type of graph from the OBGN family, limiting the generalizability of conclusions to other graph types.
4. The connection between the proposed method and prior discussions is unclear, and limitations of the method, such as its applicability only under transductive settings, are not adequately addressed.
5. The paper is notation-heavy, making it difficult to follow; a notation table is recommended.

### Suggestions for Improvement
We recommend that the authors improve clarity by explicitly detailing experimental settings, particularly regarding semi-supervised settings and the handling of training nodes. Additionally, the authors should include uncertainty measures in Figure 1 and conduct more extensive experiments across diverse datasets to enhance the generalizability of their conclusions. To justify the pruning method's necessity, we suggest that the authors report training times with and without pruning. Furthermore, clarifying the connection between the proposed method and the retention of hard samples in the training set would strengthen the paper. Lastly, we advise the authors to provide a notation table and ensure all formulas are numbered for better readability.