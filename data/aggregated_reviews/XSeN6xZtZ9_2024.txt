ID: XSeN6xZtZ9
Title: Large Language Model Benchmarks Do Not Test Reliability
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 7, 6, 3
Original Confidences: 5, 4, 4

Aggregated Review:
### Key Points
This paper presents the construction of platinum benchmarks, which are intended to ensure that a reliable and performant model achieves 100% accuracy. The authors address a significant issue in LLM reliability, emphasizing the need for improved benchmarking practices. They conduct experiments on ten existing benchmarks, meticulously cleaning them to eliminate ambiguities and errors, and provide detailed methodologies for this process. The introduction of platinum benchmarks is a novel approach that challenges current practices in AI benchmarking.

### Strengths and Weaknesses
Strengths:  
- The research quality is commendable, highlighting a critical oversight in current benchmarking practices.  
- The paper is well-organized and accessible, with clear explanations of the platinum benchmarks and their significance.  
- The methodology for cleaning datasets enhances reproducibility and addresses the reliability of LLMs in real-world applications.  

Weaknesses:  
- The scope of the benchmarks is limited, potentially affecting the generalizability of the findings.  
- The paper does not sufficiently explore the reasons behind model failures on simple tasks, missing an opportunity to identify common error patterns.  
- The term "reliability" is questioned, as the paper does not address aspects such as robustness to prompt variations or biases in model outputs.  

### Suggestions for Improvement
We recommend that the authors clarify the selection criteria used in relabeling subsets of benchmarks. Additionally, please summarize the performance of the cleaned benchmarks versus the original ones, particularly explaining the significance of the -81% difference noted in Table 4. Address the issue of prompt brittleness in examples categorized as Ambiguous. Furthermore, we suggest that the authors delve deeper into the underlying causes of model failures and consider expanding the range of cleaned benchmarks to enhance the generalizability of their findings. Lastly, please correct any errors, such as "Table XXX (row X)," to improve clarity.