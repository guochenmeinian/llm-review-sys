ID: OJximyClit
Title: Enhancing Zero-Shot Vision Models by Label-Free Prompt Distribution Learning and Bias Correcting
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 7, 7, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Frolic, a method designed to enhance the zero-shot performance of vision-language models like CLIP. The authors propose three strategies: label-free prompt distribution learning, adaptive calibration, and bias correction, which collectively address key challenges in improving model performance across various downstream tasks. Experimental results across multiple datasets demonstrate the method's effectiveness.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and easy to follow.
- The method effectively addresses label bias in pre-trained models, enhancing robustness and accuracy in zero-shot predictions.
- The approach is training-free and does not require hyper-parameters, making it applicable in real-world scenarios.
- Comprehensive ablation experiments and diverse downstream tasks are included for evaluation.

Weaknesses:
- The paper's use of a uniform prior assumes balanced class distributions, which may not hold true in real-world scenarios.
- There is a lack of clarity regarding the validation dataset's use in experiments.
- The method's reliance on pseudo-labels from CLIP raises questions about its influence on final results.
- The computational intensity of calculating second-order moments and covariance matrices is a concern.
- Comparisons with other vision-language models and prompt distribution methods are insufficient.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the limitations of their method, particularly regarding the assumptions made about class distribution and the availability of testing data. Additionally, the authors should clarify how the proposed method compares with existing methods in few-shot settings and provide insights into the influence of prompt distribution learning on performance. It would also be beneficial to include results from stronger models like ViT-L and ViT-L@336, and to evaluate the method on all benchmark datasets, including CIFAR10/100 and RESISC. Lastly, addressing the computational concerns related to second-order moment calculations would enhance the paper's robustness.