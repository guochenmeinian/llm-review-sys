ID: mTAbl8kUzq
Title: LiteVAE: Lightweight and Efficient Variational Autoencoders for Latent Diffusion Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 5, 6, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 2, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents LiteVAE, an efficient modification to latent diffusion models (LDMs) that integrates a 2D wavelet transform into the encoding structure. The authors propose a feature aggregating model (UNet-based architecture) to fuse multiscale wavelet coefficients into a unified latent code, subsequently using a decoder to generate images. The modifications, including self-modulated convolution and additional loss functions, lead to a significant reduction in computational cost without compromising reconstruction quality. Experimental results demonstrate that LiteVAE models outperform standard VAEs based on various performance metrics.

### Strengths and Weaknesses
Strengths:
1. The integration of multi-scale VAE and discrete wavelet transform effectively reduces computational costs while enhancing reconstruction performance.
2. The paper is well-organized, providing sufficient background and relevant figures that improve readability.
3. Claims are supported by comprehensive experimental results and ablation studies, demonstrating the significance of the work.

Weaknesses:
1. The paper lacks detailed information about the decoder, which limits the perceived innovation of the work. The authors should clarify whether a lite version of the decoder exists and how it interacts with the encoder during inference.
2. There is insufficient validation of the proposed structure within known latent diffusion models, which raises questions about its effectiveness in modern applications.
3. The paper does not include an ablation study on the structure modules, nor does it provide visual comparisons between LiteVAE and standard VAE.
4. The limitations section is inadequately addressed, and the checklist format does not fully meet requirements.

### Suggestions for Improvement
We recommend that the authors improve the discussion surrounding the decoder, including its structure and training relationship with the encoder. Additionally, the authors should validate their approach against established latent diffusion models and include an ablation study on the proposed structure modules. We suggest enhancing visual comparisons between LiteVAE and standard VAE to substantiate claims of effectiveness. Furthermore, the authors should provide a more comprehensive limitations section and ensure that the checklist format adheres to the specified requirements. Lastly, we encourage the authors to release detailed implementation information regarding wavelet feature extraction to facilitate reproducibility.