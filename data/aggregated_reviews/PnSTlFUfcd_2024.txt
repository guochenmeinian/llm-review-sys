ID: PnSTlFUfcd
Title: Shielding Regular Safety Properties in Reinforcement Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 7, 7, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, 5, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an online shielding approach for safe reinforcement learning (RL) that does not require prior knowledge of environment dynamics. It utilizes finite-horizon model checking with learned approximations of the environment dynamics, focusing on RL with regular safety properties expressed as a PCTL formula. The authors propose a framework that dynamically identifies unsafe actions and deploys a safe backup policy when necessary. Additionally, the paper introduces a hybrid theoretical and experimental approach to safe RL, addressing limitations of existing methods that rely on smooth and continuous transition dynamics. The authors highlight that their method can handle hybrid dynamics and discontinuous jump dynamics, prevalent in environments like Mujoco and Safety Gym. They utilize Approximate Model-based Shielding (AMBS) as a backbone for their deep RL experiments, demonstrating its effectiveness in high-dimensional, partially observable environments. Key contributions include defining a constrained RL problem based on regular safety properties, presenting model checking algorithms for verifying finite-horizon satisfaction probability, and developing sample complexity results for statistical model checking procedures.

### Strengths and Weaknesses
Strengths:  
The paper is well-written and clearly presents its problem statement, effectively comparing it against various related settings. The integration of shielding from temporal logic specifications with a CMDP formulation is particularly interesting, allowing for general specifications beyond just invariant properties. The authors demonstrate the generality of their work concerning levels of model knowledge. The paper rigorously proves technical details while also providing adequate experimental settings to test the proposed approach. The use of AMBS shows promise in effectively managing safety in complex environments, and the authors clarify the limitations of existing methods, particularly in handling hybrid and discontinuous dynamics.

Weaknesses:  
The primary weakness is the lack of experiments in more complex models and safety specifications, particularly where safety and optimality conflict. Additionally, the motivation for using a CMDP framework for safe RL is insufficiently justified. The guarantees appear to hold primarily in tabular settings, raising concerns about their applicability in more complex environments. Assumptions regarding model access and the implications of learned models on safety guarantees are also unclear. Furthermore, the approach may struggle with learning a smooth and continuous stochastic differential equation (SDE) from discrete and discontinuous dynamics, and the exploration strategy may limit the ability to achieve optimal policies, as not all state-action pairs are explored sufficiently.

### Suggestions for Improvement
We recommend that the authors improve the experimental evaluation by including more complex models and safety specifications to better illustrate the trade-offs between safety and optimality. Additionally, the authors should clarify the motivation for using a CMDP framework and provide a more detailed discussion on the implications of learned models, particularly regarding Assumptions 5.2 and 5.3. It would also be beneficial to address how the guarantees apply when using approximated models, such as Dreamer, and to ensure that the limitations of the approach are clearly articulated in the paper. We suggest improving the exploration strategy to ensure that all safety-critical state-action pairs are accurately represented in the model. Furthermore, we encourage the authors to include the observed trends from the color gridworld experiments in the revised version of the paper to provide clearer insights into the model's performance. Finally, we recommend elaborating on the implications of dropping the assumption of known MDP topology, particularly regarding the initialization of visit counts and the use of Hoeffding's bounds.