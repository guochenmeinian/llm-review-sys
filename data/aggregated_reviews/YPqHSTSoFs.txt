ID: YPqHSTSoFs
Title: Cross-model Control: Improving Multiple Large Language Models in One-time Training
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 6, 5, 8, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Cross-model Control (CMC), a novel method designed to enhance multiple large language models (LLMs) in a single training session by utilizing a portable tiny language model. The authors propose a token mapping strategy called prefix match with minimal edit distance (PM-MinED) to adapt the tiny model to various vocabularies. Extensive experiments demonstrate CMC's effectiveness in instruction tuning and unlearning tasks, showcasing significant improvements over existing methods and highlighting its potential for cost-effective optimization of LLMs.

### Strengths and Weaknesses
Strengths:  
- The method is innovative and addresses a significant challenge in optimizing multiple LLMs simultaneously, which is particularly beneficial for users with limited resources.  
- The experimental validation shows substantial improvements, and the authors provide source code for reproducibility.  
- CMC demonstrates strong generalization and robustness, effectively mitigating overfitting and underfitting phenomena.  

Weaknesses:  
- The effectiveness of CMC relies on the assumption of similar logit shifts across models, which may not hold for models with divergent architectures or training data.  
- The paper lacks detailed discussions on the computational challenges and potential biases introduced by the PM-MinED strategy.  
- There is insufficient error analysis, particularly regarding cases where CMC underperforms compared to other methods like LoRA.  

### Suggestions for Improvement
We recommend that the authors improve the discussion on the computational efficiency and scalability of the PM-MinED strategy, particularly for larger-scale applications. Additionally, we suggest including a detailed error analysis to identify scenarios where CMC may underperform, as well as clarifying how to handle tokens not present in the delta model's vocabulary during inference. Finally, we encourage the authors to explicitly state the underlying assumptions regarding vocabulary coverage in the methods section.