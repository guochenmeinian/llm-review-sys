ID: 6lx34fpanw
Title: Improving Generalization in Federated Learning with Model-Data Mutual Information Regularization: A Posterior Inference Approach
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 6, 7, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 4, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Federated Learning model, **FedMDMI**, that supports Bayesian inference by introducing a regularization constraint on model-data mutual information to mitigate bias from local client data. The authors demonstrate that MCMC inference with this regularization can be implemented via stochastic gradient Langevin dynamics and provide a generalization bound. The approach aims to address training failures in heterogeneous federated learning setups by combining Bayesian posterior inference with mutual information regularization. Additionally, the paper offers a detailed analysis of the performance and convergence behavior of **FedMDMI**, showing that it requires fewer communication rounds for convergence compared to **FedPA** and **FedEP**. The complexity analysis indicates that **FedMDMI** has lower computational and memory requirements per communication round than **FedEP**.

### Strengths and Weaknesses
Strengths:
- The exploration of information-theoretical modeling in federated learning is valuable and underrepresented.
- The authors justify most design decisions effectively, and the theoretical derivations are detailed and clear.
- Extensive experiments are conducted, showing competitive performance and uncertainty calibration.
- The paper offers thorough theoretical and empirical analyses of convergence rates, showcasing the advantages of **FedMDMI** over competing methods.
- The authors effectively address the complexities associated with different methods, particularly in terms of time and memory requirements.
- The inclusion of additional baselines and supplementary experiments is a positive step towards enhancing the manuscript's quality.

Weaknesses:
- The writing can be convoluted, making it difficult to follow; the relevance of some theoretical analyses is unclear. Introducing Algorithm 1 earlier in the text would enhance clarity.
- The proposed method's computational complexity is higher than point estimates, and experimental results do not show significant performance improvements over baselines like **FedEP**. A comparison of computational costs is necessary.
- Evaluations are limited to small models, which may not reflect the method's performance in larger architectures. Testing on more complex models like ResNets is recommended.
- The use of the Dirichlet distribution for simulating class imbalance may not adequately represent natural data heterogeneity; utilizing datasets from TensorFlow Federated and LEAF would provide a more realistic evaluation.
- The improvements in performance and calibration results, while notable, appear marginal compared to existing methods.
- The discussion on the comparison between MCMC and variational methods lacks depth and could benefit from further elaboration.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing, particularly by introducing Algorithm 1 earlier in the main text. Additionally, a detailed comparison of computational costs and performance across all baselines should be included to better understand the proposed method's advantages. Evaluating **FedMDMI** on larger models, such as ResNets, would provide a more comprehensive assessment of its scalability. Furthermore, we suggest using heterogeneous datasets from TensorFlow Federated and LEAF to ensure the method is tested under realistic conditions. Lastly, we recommend enhancing the discussion section by elaborating on the comparison between MCMC and variational methods to better contextualize their work within the broader literature. Including variances and error bars in tables and plots, as well as time and memory complexity details in the supplementary material, will also enhance the clarity and comprehensiveness of the final manuscript.