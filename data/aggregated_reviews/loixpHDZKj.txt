ID: loixpHDZKj
Title: Robust Learning for Smoothed Online Convex Optimization with Feedback Delay
Conference: NeurIPS
Year: 2023
Number of Reviews: 20
Original Ratings: 6, 6, 5, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 2, 2, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on Smoothed Online Convex Optimization (SOCO) problems, focusing on minimizing a combination of per-round hitting costs and switching costs, particularly under conditions of feedback delay and multi-step nonlinear switching costs. The authors propose the Robustness-Constrained Learning (RCL) algorithm, which integrates machine learning (ML) predictions with expert methods to enhance performance. They provide a worst-case analysis and establish robustness guarantees, demonstrating the algorithm's effectiveness through a case study in battery management.

### Strengths and Weaknesses
Strengths:
1. The generality of the studied setting allows for the incorporation of popular neural networks.
2. The worst-case theoretical analysis appears novel and the proof is correct.
3. The experiments, although in the appendix, are well-conducted with detailed descriptions and careful analyses.
4. The paper is mostly well-written and the analysis is concise.

Weaknesses:
1. Certain terms, such as "multi-step nonlinear memory," are introduced without sufficient explanation, which may confuse readers.
2. Key notations, like $\text{cost}(x_{1:T})$ and $\text{Rob}_{\lambda} \left(\tilde{x}_{1:T}\right)$, lack clarity.
3. The reliance on known switching costs and smoothness constants may limit applicability.
4. The design of reservation costs may be overly technical, and the optimization complexity discussion is insufficient.

### Suggestions for Improvement
We recommend that the authors improve the clarity of technical terms and notations introduced in the paper, particularly "multi-step nonlinear memory" and the meanings of $\text{cost}(x_{1:T})$ and $\text{Rob}_{\lambda} \left(\tilde{x}_{1:T}\right)$. Additionally, we suggest including a discussion on the optimization complexity of the constrained convex problem to enhance understanding of practical implications. Furthermore, presenting experimental results in the main body of the paper would strengthen the claims made about RCL's performance. Lastly, addressing the potential conservativeness of the reservation cost design could provide deeper insights into the algorithm's applicability.