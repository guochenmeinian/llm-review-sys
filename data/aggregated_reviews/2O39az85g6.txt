ID: 2O39az85g6
Title: Exploring Context-Aware Evaluation Metrics for Machine Translation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Cont-COMET, a context-aware machine translation metric that builds on the COMET framework by incorporating previous and following sentence context. The authors experiment with context selection methods to identify the most relevant sentences, using data from WMT metrics shared tasks. The results indicate some improvements in system-level evaluations compared to the original COMET-21 metric.

### Strengths and Weaknesses
Strengths:
- The authors provide a thorough analysis of contextual information's impact on machine translation evaluation through reasonable experiments.
- The context selection module enhances the utilization of information within the constraints of pretrained language model encoders.
- A high-quality corpus for automatic metric training has been compiled from publicly available sources.

Weaknesses:
- The improvements over COMET are marginal and lack statistical significance testing, raising questions about their robustness.
- The assumption that similar sentences provide the most relevant context may not hold, as useful context often contains information not present in the current sentence.
- The method lacks innovation, and the impact of context selection appears small, inconsistent with earlier hypotheses.
- There is no language-wise breakdown of results, which is a significant oversight.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their results by explicitly stating that the results in Table 1 pertain to untrained COMET with additional context sentences. Additionally, conducting statistical significance tests would strengthen the claims regarding improvements. The authors should also provide a breakdown of results by language pair and consider including comparisons with other context-sensitive evaluation methods. Furthermore, exploring variable numbers of context sentences based on similarity thresholds could enhance the method's effectiveness. Lastly, a brief introduction to the COMET framework would provide necessary context for readers.