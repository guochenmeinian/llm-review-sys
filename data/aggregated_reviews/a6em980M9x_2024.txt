ID: a6em980M9x
Title: Amortized Fourier Neural Operators
Conference: NeurIPS
Year: 2024
Number of Reviews: 42
Original Ratings: 5, 7, 5, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Amortized Fourier Neural Operator (AM-FNO), which addresses the high-frequency truncation issue in Fourier Neural Operators (FNOs) by utilizing an amortized neural parameterization of the kernel function. This approach accommodates a variable number of frequency modes while maintaining a fixed number of parameters. The authors propose two implementations of AM-FNO: one based on Kolmogorov-Arnold Networks (KAN) and the other using Multi-Layer Perceptrons (MLPs) with orthogonal embedding functions. The paper includes extensive empirical evaluations demonstrating significant performance improvements across diverse PDE benchmarks. Additionally, the authors highlight the advantages of their architecture in terms of memory usage and training speed, particularly in high-dimensional contexts, asserting that AM-FNO outperforms existing models like AFNO. Experimental results show that AM-FNO processes a larger number of modes with only a minor increase in training time and memory usage, outperforming Geo-FNO on the 3D Plasticity benchmark.

### Strengths and Weaknesses
Strengths:
1. The novel approach effectively addresses the trade-off between model complexity and high-frequency representation in FNOs.
2. A solid theoretical foundation is provided, including a theorem on the approximation properties of orthogonal basis functions.
3. Comprehensive experiments cover multiple PDE benchmarks, enhancing the claims of generalization ability.
4. Significant performance improvements, with up to a 35% average reduction in relative error, are reported across various PDE types.
5. The authors provide a clear comparison of their method against existing models, demonstrating its effectiveness in reducing memory usage and improving training speed.
6. The paper is well-written with clear descriptions of methods and solid theoretical analysis.
7. The authors are responsive to reviewer feedback and willing to incorporate additional experiments and clarifications.

Weaknesses:
1. Baselines were inadequately tuned, raising questions about the fairness of comparisons and the extent of AM-FNO's improvements.
2. The paper lacks a discussion on scalability to higher-dimensional problems.
3. There is insufficient analysis of computational efficiency regarding training time and inference speed compared to baseline methods.
4. Each experiment was conducted only once, which may lead to statistical fluctuations; averaging over multiple runs is necessary for validation.
5. The motivation for the proposed method lacks empirical evidence, particularly regarding the limitations of MLPs in capturing complex, non-linear functions.
6. The complexity introduced by FFT may undermine the benefits claimed by the authors, raising concerns about the overall efficiency of the proposed approach.
7. There are inconsistencies in reported results and datasets, particularly regarding the comparison with DeepONet and Geo-FNO.
8. The role of orthogonal basis functions is not convincingly motivated, and the justification provided is ambiguous.

### Suggestions for Improvement
We recommend that the authors improve the robustness of their experimental results by conducting multiple runs for each experiment and reporting standard deviations, particularly for complex datasets like NS-2D and CFD-2D. Additionally, please clarify the validation dataset usage and provide a clear explanation to avoid overfitting concerns. We suggest including a more comprehensive discussion on the scalability of AM-FNO to higher-dimensional PDEs and a detailed analysis of computational efficiency compared to baseline methods. Furthermore, we encourage the authors to elaborate on the motivation for using orthogonal basis functions and to consider discussing related methods like AFNO to strengthen the paper's context. It would also be beneficial to include a more thorough analysis of the performance of AM-FNO compared to AFNO across all datasets, as well as ablation studies to clarify the efficiency of both methods. Lastly, addressing the undefined symbols and terms, enhancing the description of the "Factorization trick for high-dimensional PDEs," and improving the clarity of the abstract and introduction by emphasizing that the major benefit of AM-FNO arises from MLP parameterization rather than solely from using full frequency modes would improve the overall clarity and impact of the paper.