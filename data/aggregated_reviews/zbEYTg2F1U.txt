ID: zbEYTg2F1U
Title: ASL Citizen: A Community-Sourced Dataset for Advancing Isolated Sign Language Recognition
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 6, 6, 8, 9, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
We present the ASL Citizen dataset for Isolated Sign Language Recognition (ISLR), comprising 83,399 videos of 2,731 distinct signs from 52 signers in various environments. This dataset aims to facilitate dictionary retrieval for American Sign Language (ASL) by enabling users to demonstrate signs for matching entries. Experimental results show that training machine learning classifiers on this dataset significantly enhances the accuracy of dictionary retrieval tasks. We acknowledge the potential of continuous sign language translation for DHH users and propose that ASL Citizen could be improved by integrating continuous sign language data and a knowledge base of sign language grammar. Our dictionary task is crucial due to the lack of functional sign language dictionaries, emphasizing the need for ASL-to-English or ASL-to-ASL dictionaries.

### Strengths and Weaknesses
The strengths of our work include the creation of the largest ASL dataset for ISLR, which is four times larger than existing datasets, and the involvement of the Deaf community in the data collection process, ensuring ethical standards and data quality. Our dataset is also the first publicly available crowdsourced sign language dataset, addressing the critical barrier of data scarcity in sign language modeling. However, we note limitations such as the focus on isolated signs, which may not address practical applications of continuous sign recognition and translation. Additionally, the dataset lacks diversity in racial representation and only includes results from two baseline models. We must ensure that our future work includes comprehensive baselining results rather than deferring this to later stages, and we need to clarify that our use of models that generalize well does not imply the exclusive use of simple models.

### Suggestions for Improvement
We suggest performing baselining on more models and similar datasets for a comprehensive comparison. Revising the dataset paper to include sufficient baselining results will validate the dataset's importance. Incorporating visual explainability methods, such as GradCam, could enhance understanding of model focus on facial and hand gestures. We recommend clarifying our claims regarding classifier performance, emphasizing competitive performance rather than state-of-the-art accuracy. Furthermore, we should update our related work section to reflect recent advances in ISLR and separate limitations into a distinct subsection for clarity. Lastly, we should consider the frequency of use for sign dictionaries among deaf users to better understand their practical applications and clarify the dataset's potential benefits for Continuous Sign Language Recognition (CSLR) and Sign Language Translation (SLT) tasks.