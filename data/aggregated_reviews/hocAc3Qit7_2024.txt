ID: hocAc3Qit7
Title: Flexible mapping of abstract domains by grid cells via self-supervised extraction and projection of generalized velocity signals
Conference: NeurIPS
Year: 2024
Number of Reviews: 24
Original Ratings: 4, 8, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to dimensionality reduction based on velocity in latent space, inspired by entorhinal grid cell activity. The authors propose a self-supervised learning (SSL) framework that incorporates a "loop-closure" constraint to create a metric map of the latent space. They argue that their method effectively extracts velocities from high-dimensional datasets constructed to lie on low-dimensional manifolds, outperforming traditional algorithms like PCA, which struggle with datasets that are intrinsically two-dimensional. The authors clarify that their model assumes unique states in abstract cognitive spaces and detail their loss functions, which include next-state prediction, loop closure, isotropy, and shortcut losses, emphasizing their roles in refining velocity extraction. The experimental results indicate that this method captures relationships across various domains effectively, particularly in big data applications involving time series and video data.

### Strengths and Weaknesses
Strengths:
- The paper addresses an important problem relevant to both neuroscience and machine learning.
- The proposed method demonstrates effective dimensionality reduction by leveraging velocity extraction from high-dimensional data.
- The writing and visualizations are clear, with impressive experimental results relative to baselines.
- The authors provide a thorough explanation of their loss functions and their contributions to model performance.
- The work is well-explained, thorough, and correct, addressing significant challenges in data analysis.

Weaknesses:
- The framing of the work in relation to previous models is confrontational and misleading, suggesting a fundamental difference rather than a useful addition.
- Claims regarding the independence of learned velocity signals from stimuli are questionable, as the model does not transfer across different stimuli sets.
- The novelty of predictions made in the paper is overstated, as similar predictions have been made by existing models.
- Some reviewers question the necessity of the model, suggesting that the predictions regarding cell-cell correlations may be intuitive rather than groundbreaking.
- The requirement for the latent code to be a linear function of true velocities lacks justification and clarity.
- Limitations regarding the biological plausibility and naturalistic data collection processes are not adequately discussed.
- Some reviewers remain unconvinced by the arguments presented, particularly regarding the necessity of the proposed method over existing models.

### Suggestions for Improvement
We recommend that the authors improve the framing of their work to acknowledge its role as an addition to existing cognitive mapping models rather than a fundamentally different approach. Clarifying the independence of learned velocity signals from stimuli and addressing the concerns regarding the linearity assumption in the latent code would enhance the paper's rigor. Additionally, we suggest that the authors provide a more thorough discussion of limitations, particularly regarding biological plausibility and the implications of using specially constructed datasets. We recommend improving the clarity of the discussion surrounding "cell-cell relationships" to make it more accessible to a broader audience and explicitly addressing how their predictions could be falsified, particularly regarding the integration of velocities into grid cell models. Furthermore, we encourage the authors to elaborate on the biological plausibility of their model in future work to enhance its relevance to neuroscience. Lastly, we recommend including a more detailed explanation of the necessity of multiple loss functions in the context of their model's performance and providing more explicit examples of the method's application in nonlinear domains to alleviate skepticism about its versatility.