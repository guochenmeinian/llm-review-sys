ID: OvPnc5kVsb
Title: Importance-aware Co-teaching for Offline Model-based Optimization
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 7, 6, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel model-based optimization method that integrates ensemble-based ideas and meta-learning to address the out-of-distribution issue in offline model-based optimization. The authors introduce three proxy models that generate pseudo-labels for each other, functioning as co-teachers to enhance training stability. The method employs a meta-learning framework to adjust sample importance weights, focusing on confident samples to improve performance. Experimental results demonstrate the method's effectiveness across both continuous and discrete tasks.

### Strengths and Weaknesses
Strengths:
1. The proposed method is well-motivated and technically sound, addressing a significant challenge in offline model-based optimization.
2. The paper is well-written, making complex ideas accessible to readers.
3. Extensive experiments and ablation studies validate the effectiveness of the proposed method.

Weaknesses:
1. The lack of detailed mathematical explanations for the method's effectiveness limits understanding; an analysis based on experiments would enhance clarity.
2. The method appears to draw heavily from prior work, particularly BDI, necessitating a more explicit comparison to clarify differences and similarities.
3. Some experimental results show marginal gains with high variance, raising concerns about the robustness of the findings.

### Suggestions for Improvement
We recommend that the authors improve the mathematical explanation of their method's effectiveness, potentially including experimental analyses to support their claims. Additionally, we suggest providing a more explicit comparison with BDI to clarify the contributions of the proposed method. It would also be beneficial to conduct statistical tests, such as p-tests, to strengthen the claims made from the experimental results. Lastly, consider expanding the discussion on the per-sample weighting mechanism and its convergence properties to enhance understanding.