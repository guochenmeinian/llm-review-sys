ID: 8bExkmfLCr
Title: Block Coordinate Descent Methods for Optimization under J-Orthogonality Constraints with Applications
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 6, 4, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the JOBCD (J-Orthogonal Block Coordinate Descent) algorithm, a novel method for optimization problems under J-orthogonality constraints, featuring two variants: GS-JOBCD (Gauss-Seidel strategy) and VR-J-JOBCD (Jacobi strategy with variance reduction). The authors provide theoretical analyses that establish the algorithms' complexity and convergence, alongside extensive experiments demonstrating JOBCD's superior performance compared to existing methods. Additionally, the paper discusses the closed-form solution for the orthogonal tangent space, questioning the assertion that compactness of the orthogonality constraint directly leads to this solution. The authors clarify that the Riemannian gradient is derived from the first-order optimality condition of an optimization problem, but they do not utilize the Riemannian gradient in their JOBCD algorithm, relying instead on the Euclidean gradient for practical implementation.

### Strengths and Weaknesses
Strengths:  
- Originality: JOBCD introduces a novel approach to J-orthogonality constraints, showcasing flexibility with GS-JOBCD and VR-J-JOBCD.  
- Quality: Comprehensive complexity and convergence analyses are provided, with extensive experiments validating performance on both real-world and synthetic data.  
- Clarity: The paper is logically structured, facilitating understanding.  
- The authors provide a clear explanation of the derivation of the Riemannian gradient and its theoretical implications, effectively distinguishing between theoretical and practical applications.

Weaknesses:  
- Some proofs in Section 4 are challenging to follow.  
- The novelty of the paper may be insufficient, as the row-based approach is similar to that in reference [51].  
- Numerical results indicate that the proposed method fails to return feasible solutions for certain instances.  
- The assertion regarding the closed-form solution linked to compactness is challenged, indicating potential confusion or misinterpretation.  
- The decision to avoid solving the optimization problem for projecting the Euclidean gradient may limit the completeness of the analysis.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the proofs in Section 4 to enhance readability. Additionally, the authors should explicitly highlight the novelty of their algorithm in comparison to reference [51] and clarify the differences in implementation for solving J-orthogonality problems versus orthogonality constraints. Furthermore, we suggest providing more details on the dataset selection process in the numerical experiments and addressing the feasibility issues observed in specific instances. We also recommend improving the clarity of the relationship between the compactness of the orthogonality constraint and the closed-form solution. Lastly, consider providing a more detailed explanation of why the projection metric was not utilized, as this could enhance the understanding of the methodology employed in the JOBCD algorithm.