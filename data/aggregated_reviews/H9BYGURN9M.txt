ID: H9BYGURN9M
Title: A LLM-based Controllable, Scalable, Human-Involved User Simulator Framework for Conversational Recommender Systems
Conference: ACM
Year: 2024
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a controllable framework for LLM-based user simulators aimed at enhancing conversational recommendation systems (CRSs). The authors propose a modular architecture that allows for flexible user simulations, addressing issues such as data leakage and the need for personalized recommendations. The evaluation of the proposed simulator is conducted through quantitative analyses on two datasets and qualitative assessments of user interactions, showing promising initial results.

### Strengths and Weaknesses
Strengths:
- The paper effectively identifies the critical issue of data leakage in existing user simulators, contributing valuable insights for improving CRS evaluations.
- The modular design of the simulator enhances control and scalability, incorporating realistic user characteristics that improve personalization.

Weaknesses:
- The paper breaks the anonymity constraint by including a GitHub link to an author's homepage, warranting rejection in the current review round.
- Clarity issues exist in the introduction regarding the limitations of prior LLM-based simulators, and the contribution of the plugin manager is not sufficiently explained.
- There is a lack of a thorough discussion of related works, making it difficult to establish the novelty of the proposed approach.
- The absence of ablation studies prevents a clear understanding of the impact of specific modules on the experimental results.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the introduction by explicitly detailing the limitations of existing LLM-based user simulators and how the plugin manager addresses these issues. Additionally, a comprehensive review of related works should be included to better position the contribution within the broader context of user simulation research. The authors should also consider conducting ablation studies to clarify the contributions of specific modules to the overall performance of the simulator. Furthermore, justifications for design decisions in plugins, such as the threshold used in the User Preference Summary Plugin, should be provided, along with a detailed description of how decisions are made by the agent.