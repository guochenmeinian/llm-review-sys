ID: TbPv0qFnHO
Title: Beyond Euclidean: Dual-Space Representation Learning for Weakly Supervised Video Violence Detection
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 7, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a pioneering approach called Dual-Space Representation Learning (DSRL) for weakly supervised video violence detection. The framework integrates the Hyperbolic Energy-constrained Graph Convolutional Network (HE-GCN) and the Dual-Space Interaction (DSI) module to enhance feature integration and capture event hierarchies. The method demonstrates state-of-the-art performance on the XD-Violence dataset and shows good effectiveness on the UCF-Crime dataset, addressing the challenges of ambiguous violence detection.

### Strengths and Weaknesses
Strengths:
- The authors propose a novel combination of Euclidean and hyperbolic geometries, effectively addressing ambiguous violence scenarios.
- The presentation is well-organized, and the technical correctness of the proposed method is validated through experiments on two datasets.
- The HE-GCN and DSI modules are well-motivated, with sufficient ablation study results supporting their effectiveness.

Weaknesses:
- Some components, like the cross-graph attention mechanism, lack innovation and are commonly found in prior works.
- The paper does not address the computational complexity or parameters of the DSRL model, which is crucial for real-time applications.
- The Layer-Sensitive Hyperbolic Association Degree (LSHAD) contains multiple hyperparameters without sufficient explanation for their design choices, and the Preliminaries section may be too complex for a broader audience.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the computational complexity and parameters of the DSRL model to ensure its efficiency in practical applications. Additionally, please clarify the relationship between HDE and LSHAD in detail and revise Figure 2 to indicate that the method applies to both unimodal and multimodal inputs. We also suggest simplifying the Preliminaries section for better accessibility and addressing minor writing issues, such as standardizing the use of "Figure" and correcting symbol display errors. Finally, providing inference visualizations of the ablation modules would enhance the manuscript's convincingness.