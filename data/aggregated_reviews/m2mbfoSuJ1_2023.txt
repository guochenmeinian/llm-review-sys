ID: m2mbfoSuJ1
Title: A Comprehensive Study on Text-attributed Graphs: Benchmarking and Rethinking
Conference: NeurIPS
Year: 2023
Number of Reviews: 26
Original Ratings: 6, 6, 8, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive benchmark for text-attributed graphs (TAGs) using eight large-scale datasets and various Graph Neural Network (GNN) models. The authors propose the ogbn-arxiv-TA dataset, which enhances node embeddings and addresses noise issues compared to the original ogbn-arxiv dataset. The benchmark also incorporates the ogbn-papers100M dataset and includes social network datasets, Cresci-2015 and TwiBot-20, for social bot detection. The authors conduct extensive experiments, revealing interesting findings about the co-training of GNNs and Pre-trained Language Models (PLMs) and demonstrating the effectiveness of topological pre-training methods. The paper provides detailed information on data collection, statistics, and the classification of node attributes, contributing significantly to the research community.

### Strengths and Weaknesses
**Strengths:**
1. The benchmarks are larger in scale than traditional datasets, featuring millions of nodes and edges.
2. The datasets are comprehensive, including raw text and enhancing the modeling of semantic information.
3. The paper effectively highlights the importance of text attribute modeling in graph datasets and addresses real-world applications, such as recommender systems.
4. The authors provide thorough experimental results, showcasing the efficiency of the topological pre-training paradigm over traditional co-training methods.
5. The manuscript includes detailed discussions on the impact of node attributes on performance and clarifies the classification hierarchy in datasets.

**Weaknesses:**
1. The datasets are limited to two primary domains (academic and e-commerce), which may restrict generalization.
2. The GNNs and LMs utilized are somewhat trivial, lacking diversity in model selection.
3. The findings, particularly regarding the performance of the co-training framework, lack sufficient explanation and detail.
4. The connection to previous work could be more thoroughly discussed, especially regarding the differences between the datasets.
5. Some sections lack clear cross-referencing to appendices, making it difficult for readers to locate additional details.
6. Code documentation is insufficient, with unclear instructions on how to run benchmarks.

### Suggestions for Improvement
1. We recommend that the authors consider incorporating existing large-scale text-attributed graphs, such as ogbn-papers100M, to enhance the benchmark's relevance.
2. The authors should improve the discussion on the differences between the ogbn-arxiv and ogbn-arxiv-TA datasets to clarify their contributions.
3. We suggest expanding the benchmark to include datasets from more diverse domains beyond academic and e-commerce.
4. To enhance the explanation of the co-training framework's performance, we recommend providing a more detailed analysis of the computational complexities and trade-offs involved in the co-training process.
5. We recommend that the authors improve cross-referencing throughout the manuscript to guide readers more effectively to the relevant appendix sections.
6. Additionally, please enhance the code documentation by specifying scripts and providing a clear directory structure for easier navigation.
7. We suggest consolidating the results from Tables 2, 3, and 4 into a single comprehensive table to facilitate comparisons and ensure clarity in metrics and terminology used throughout the paper.
8. Lastly, ensure that all figures are fully accessible, including color considerations for print-friendly formats, and improve the consistency of symbols used throughout the paper, particularly in the appendix.