ID: TCkshxuQ7u
Title: The Impacts of Data, Ordering, and Intrinsic Dimensionality on Recall in Hierarchical Navigable Small Worlds
Conference: ACM
Year: 2024
Number of Reviews: 5
Original Ratings: 2, 0, 0, 1, -1
Original Confidences: 4, 3, 2, 4, 4

Aggregated Review:
### Key Points
This paper presents an experimental analysis of the Hierarchical Navigable Small Worlds (HNSW) algorithm, focusing on the impact of vector space dimensionality and the order of vector insertion on recall performance. The authors verify their hypothesis that populating the HNSW index in descending local intrinsic dimensionality yields better results than random insertion, using both synthetic datasets and contemporary retrieval benchmarks. The study also includes a proprietary dataset and examines the performance of HNSW across various scenarios.

### Strengths and Weaknesses
Strengths:
- The paper offers valuable insights into the performance of HNSW, particularly regarding the significance of data insertion order and intrinsic dimensionality.
- It employs a clear organizational structure and thorough experimental justification, making it accessible and informative.
- The authors creatively utilize synthetic data to control intrinsic dimensionality, enhancing the experimental rigor.

Weaknesses:
- The evaluation is limited to HNSW and does not include other ANN algorithms, which diminishes the broader applicability of the findings.
- Recall@10 is deemed too shallow for a first-stage retriever, and deeper cuts should be assessed for a more comprehensive evaluation.
- The complexity of estimating local intrinsic dimensionality is not addressed in terms of its impact on indexing time.
- The paper lacks exploration of additional real-world datasets beyond product image retrieval, which may limit its applicability.

### Suggestions for Improvement
We recommend that the authors improve the clarity of table and figure titles to better convey the data presented. Additionally, the authors should consider evaluating other ANN algorithms alongside HNSW to strengthen their findings. A more systematic approach to exploring the effects of different neural network architectures (e.g., Transformer vs. CNNs vs. RNN) on ranking performance is advisable. Furthermore, we suggest assessing recall at deeper cuts (e.g., 100, 1000) to provide a more robust evaluation. The authors should also clarify the computational impact of local intrinsic dimensionality estimation on indexing time. Finally, including a discussion on retrieval times and a justification for the choice of average recall metric over standard metrics would enhance the methodological foundation of the study.