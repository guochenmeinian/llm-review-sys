ID: A6EquH0enk
Title: Effective Bayesian Heteroscedastic Regression with Deep Neural Networks
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 6, 6, 7, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for modeling heteroscedastic observation noise using Bayesian Neural Networks (BNNs) by employing natural gradients and a Laplace approximation to handle epistemic uncertainty. The authors propose a closed-form posterior predictive likelihood approximation and evaluate their approach across various experiments, including UCI and a new image dataset. The paper aims to address shortcomings in prior variance modeling techniques.

### Strengths and Weaknesses
Strengths:
- The paper tackles a well-defined problem, identifies weaknesses in existing methods, and proposes a principled solution.
- It is well-written and accessible to readers.
- The experimental setups encompass a diverse range of domains, demonstrating the method's applicability.

Weaknesses:
- The proposed adaptations, such as switching to natural parameters and using Laplace approximations, are largely incremental and drawn from prior work.
- Section 5.2 appears as an afterthought, lacking sufficient detail in both setup and evaluation of results.
- The experiments are limited to regression tasks, which may restrict the paper's broader relevance.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Section 5.2 by providing a more detailed setup description and a thorough evaluation of results. Additionally, consider expanding the scope of experiments beyond regression to include other tasks, possibly by incorporating uncertainty-baseline benchmarks. We suggest including a related work section to contextualize the contributions within the current state of the art, particularly regarding the use of natural parameters and aleatoric uncertainty. Furthermore, we encourage the authors to clarify technical terms introduced in the introduction and improve the logical flow for better reader comprehension. Lastly, addressing the computational cost and runtime of the proposed method compared to rivals would enhance the discussion of limitations.