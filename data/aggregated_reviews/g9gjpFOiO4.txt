ID: g9gjpFOiO4
Title: Rethinking Semi-Supervised Medical Image Segmentation: A Variance-Reduction Perspective
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 7, 7, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ARCO, a novel semi-supervised contrastive learning framework that employs Stratified Group (SG) and Stratified-Antithetic Group (SAG) sampling strategies to enhance representation learning in medical image segmentation tasks with limited labeled data. The authors provide theoretical evidence demonstrating the variance-reduction properties of these sampling techniques, which improve training stability and performance across multiple datasets. Comprehensive experiments validate the effectiveness of ARCO, showing significant performance improvements compared to existing methods. The SG sampling method significantly enhances representation quality for pixel/voxel-level contrastive learning, with the authors demonstrating SG's superiority over naïve sampling across various datasets. Although the SAG method does not outperform SG in most experiments—except in the SUN RGB-D benchmark under a 50-label setting—it offers comparable performance with a reduced sample size, confirming that SAG can halve sample sizes compared to SG while largely preserving SG's variance reduction property.

### Strengths and Weaknesses
Strengths:
- The focus on variance reduction guarantees for pixel-level training is a notable contribution.
- The theoretical analyses supporting unbiasedness and variance reduction techniques can have important applications in self-supervised learning.
- Extensive experimental evaluations across eight benchmark datasets demonstrate strong performance improvements.
- The clarity of motivations and the method's empirical validation provide valuable insights into medical image segmentation.
- The SG sampling method shows notable improvements in representation quality for contrastive learning.
- The authors effectively demonstrate SG's superiority over naïve sampling across multiple datasets.
- The authors are responsive to reviewer feedback and have made positive revisions to the manuscript.

Weaknesses:
- Claims regarding model robustness are made without sufficient evidence, leading to potential misinterpretations.
- The assumptions in Theorem 3.2 regarding variance reduction need clarification, particularly in scenarios with minimal class differences.
- The aggregation functions' computational expense on dense pixel grids requires further explanation.
- Important methodological details are relegated to the Appendix, which detracts from the paper's clarity.
- The literature overview lacks discussion on self-supervised representation learning, which could enhance the paper's context.
- The SAG method's performance does not exceed that of SG in most contexts, which may limit its perceived value.
- Further clarification on the SAG method's advantages could enhance understanding and application.

### Suggestions for Improvement
We recommend that the authors improve the clarity of claims regarding model robustness by providing empirical evidence to support these assertions. Additionally, the authors should clarify the assumptions in Theorem 3.2 to address potential concerns about variance reduction in challenging scenarios. It would be beneficial to elaborate on the computational aspects of aggregation functions and to integrate key methodological details into the main text rather than the Appendix. Furthermore, we suggest including a discussion on self-supervised representation learning to better contextualize the contributions of this work. Lastly, we recommend improving the discussion surrounding the SAG method to clarify its advantages and potential applications, providing additional insights into the specific contexts where SAG may be beneficial.