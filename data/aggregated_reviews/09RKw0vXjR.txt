ID: 09RKw0vXjR
Title: Fast Iterative Hard Thresholding Methods with Pruning Gradient Computations
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 7, 5, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method to accelerate iterative hard thresholding (IHT) for sparse linear regression by pruning unnecessary computations in the gradient updates. The authors propose maintaining upper and lower bounds for each entry of the OLS parameter vector, which allows for the identification of elements that do not need to be computed, thereby reducing the overall computational cost while ensuring the same results as traditional IHT.

### Strengths and Weaknesses
Strengths:  
- The problem is well stated and relevant, with a novel approach to reducing computational costs per iteration.  
- The method is technically sound and well described, with good empirical performance demonstrating significant speedup.  
- The paper is generally well written and enjoyable to read.  

Weaknesses:  
- The rationale behind the pruning strategy is unclear, and the literature review is insufficient, making it difficult to understand the gap this work addresses.  
- Some definitions and lemmas are unnecessary or improperly categorized, and the presentation is occasionally long-winded.  
- The proposed method's applicability is limited to specific scenarios, and comparisons with other efficient algorithms are lacking.  

### Suggestions for Improvement
We recommend that the authors improve the clarity of the pruning strategy and provide a more comprehensive literature review, potentially moving Section 4 to the beginning of the paper. Additionally, consider elaborating on the rationale behind technical definitions and results, and reassess the necessity of certain lemmas. The authors should also include comparisons with other algorithms like coordinate descent and address the limitations of their method more explicitly. Finally, enhancing the presentation by avoiding redundancy and ensuring consistency in notation would be beneficial.