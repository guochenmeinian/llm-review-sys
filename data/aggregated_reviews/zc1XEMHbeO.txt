ID: zc1XEMHbeO
Title: Reembedding and Reweighting are Needed for Tail Item Sequential Recommendation
Conference: ACM
Year: 2024
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method to enhance sequential recommendation systems, particularly for tail items, by addressing performance challenges linked to biases in standard cross-entropy loss and the dominance of pre-trained knowledge from large language models (LLMs) and large vision models (LVMs). The authors propose a framework, RÂ²Rec, which combines a reweighting function and a reembedding operation initialized with a Gaussian distribution to optimize tail items during training. Extensive experiments across three datasets demonstrate that the proposed method significantly improves tail item performance compared to fourteen baselines.

### Strengths and Weaknesses
Strengths:
1. The paper is well-organized and clearly written.
2. Comprehensive experimental comparisons validate the effectiveness of the proposed method.
3. The focus on tail-item recommendations is a significant contribution, promoting diversity in personalized recommendations.

Weaknesses:
1. The paper lacks comparisons with LLM-based recommendation methods.
2. The explanation of the transfer tax issue is insufficiently detailed.
3. The novelty of the reembedding method is questionable, as it appears simplistic compared to recent techniques.
4. There is limited analysis regarding the impact of hyperparameters and the computational complexity of the approach.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the explanation regarding the transfer tax issue and its implications on tail-item recommendations. Additionally, a detailed analysis of how the optimization impacts the proportion of long-tail items in the final recommendations should be included. We suggest conducting comparisons with LLM-based methods and exploring alternative approaches, such as a mixed representation of VLM embeddings and reinitialized embeddings, to enhance the motivation for utilizing VLMs. Furthermore, a sensitivity analysis of hyperparameters beyond the temperature factor would provide valuable insights into their influence on model performance. Lastly, we encourage the authors to clarify the mechanics of the proposed methods, particularly in relation to the equations presented, to strengthen the technical rigor of the paper.