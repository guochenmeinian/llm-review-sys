ID: vW52xJF9ZA
Title: A Quasi-Wasserstein Loss for Learning Graph Neural Networks
Conference: ACM
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a *Quasi-Wasserstein (QW) loss* designed to model instances where node labels are not independent and identically distributed (i.i.d.), drawing from optimal transport theory. The authors motivate this new loss function effectively and provide a comprehensive set of experiments demonstrating its advantages over traditional loss functions, particularly in graph neural networks (GNNs).

### Strengths and Weaknesses
Strengths:
- The relaxation of the flow matrix constraint to a Bregman divergence-based regularizer enhances accessibility for practitioners.
- The experiments are thorough, comparing traditional node-level loss with the class-based QW loss across various GNN architectures, including GCN and GraphSAGE.
- The paper is mathematically sound and well-justified.

Weaknesses:
- The readability of Table 2 could be improved by replacing (2) in the Method column with "CE" for cross-entropy.
- The authors should document the differences in the number of trainable parameters between QW and cross-entropy across algorithms and datasets, as over-parameterization may influence results.
- The QW loss's computational demands, particularly for Algorithm 3, raise scalability concerns, especially for large graphs.
- Limited improvement was observed in homophilic graphs, which warrants further explanation.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Table 2 by using "CE" for cross-entropy. Additionally, please include a comparative analysis of the number of trainable parameters for QW and cross-entropy in the experiments. It would also be beneficial to provide a comparative analysis between Algorithm 1 and Algorithm 2 regarding node classification accuracy, possibly in an appendix. Furthermore, addressing the scalability of the QW loss on large graphs and offering practical recommendations to mitigate overfitting risks would enhance the paper's contributions. Lastly, insights into the limited improvements observed in homophilic graphs would clarify the applicability of the QW loss.