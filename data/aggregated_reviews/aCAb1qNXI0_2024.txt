ID: aCAb1qNXI0
Title: Hierarchical Federated Learning with Multi-Timescale Gradient Correction
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 6, 6, 6, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a multi-timescale gradient correction (MTGC) methodology aimed at addressing multi-timescale model drift in hierarchical federated learning (HFL). The authors propose distinct control variables to correct client gradients towards group gradients and group gradients towards global gradients. The paper includes theoretical convergence analysis in non-convex settings and empirical demonstrations of the algorithm's stability against multi-level non-i.i.d. data.

### Strengths and Weaknesses
Strengths:
- The idea of correcting gradients is interesting and the proposed MTGC algorithm is simple and easy to implement.
- The theoretical analysis provides a solid foundation, demonstrating linear speedup in local iterations, group aggregations, and clients.
- The convergence bound is robust against data heterogeneity, and the writing is clear and well-structured.

Weaknesses:
- The model is primarily tested on small datasets, raising questions about its performance on larger datasets.
- There is a lack of comparisons with clustered federated learning, which could provide valuable context.
- The experiments focus mainly on image classification, neglecting other tasks like natural language processing and various distribution shifts.
- The paper does not adequately analyze how model drift affects generalization performance or the impact of hierarchical communication levels on federated learning.

### Suggestions for Improvement
We recommend that the authors improve the experimental section by including comparisons of additional computational and communication costs associated with MTGC. It would be beneficial to conduct experiments on larger datasets and various types of tasks to enhance generalizability. We also suggest including an ablation study to assess the performance of the model with only one of the corrections. Furthermore, providing insights into the practical implications of the theoretical results and addressing the empirical effects of model drift on generalization performance would strengthen the paper. Lastly, consider incorporating the discussions from the rebuttal into the main body of the manuscript for clarity.