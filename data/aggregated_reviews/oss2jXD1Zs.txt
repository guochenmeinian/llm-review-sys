ID: oss2jXD1Zs
Title: Linear Time Algorithms for k-means with Multi-Swap Local Search
Conference: NeurIPS
Year: 2023
Number of Reviews: 7
Original Ratings: 7, 6, 6, 6, -1, -1, -1
Original Confidences: 3, 5, 3, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a multi-swap local search algorithm for the k-means clustering problem, aiming for a linear running time in relation to dataset size while achieving a better approximation ratio than existing single-swap strategies. The authors propose a sampling-based method to enhance the efficiency of updating clustering costs during swaps. Their algorithm reportedly achieves an approximation factor of 50+\(\epsilon\) and is validated through extensive empirical experiments demonstrating its practical performance.

### Strengths and Weaknesses
Strengths:  
1) The paper introduces a first linear time local search algorithm utilizing the multi-swap strategy, combining a smaller approximation ratio with linear run-time.  
2) The organization is clear, the mathematical proofs are detailed and accessible, and the experimental section is thorough.  
3) The use of sampling techniques in multi-swap local search appears to be novel and effective.

Weaknesses:  
1) There remains a significant gap between the lower bound of 9 for local search and the proven upper bounds.  
2) The improvement in experimental results is marginal, often less than 5%.  
3) The technical presentation is complex, making it difficult to follow, and there are instances of imprecise statements and notation throughout the paper.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the technical sections by simplifying notation and ensuring precise statements. Additionally, it would be beneficial to include comparisons with the single-swap heuristic from reference [9] in both theoretical and experimental contexts. We suggest conducting experiments for larger values of \(k\) to better assess the algorithm's performance across varying dataset sizes. Finally, addressing the limitations of the work explicitly in the paper would enhance its overall impact.