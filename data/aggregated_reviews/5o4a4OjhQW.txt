ID: 5o4a4OjhQW
Title: What Comes Next? Evaluating Uncertainty in Neural Text Generators Against Human Production Variability
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for quantifying the uncertainty of natural language generation (NLG) systems, comparing their variability to that of human outputs across various tasks. The authors find that models overestimate variability in open-ended tasks while underestimating it in constrained tasks. They also analyze the impact of decoding strategies on this variability. The study aims to enhance understanding of uncertainty in NLG and proposes a new measurement of production variability.

### Strengths and Weaknesses
Strengths:
- The topic is timely and underexplored, potentially sparking further interest in NLG uncertainty.
- The definition of production variability offers a novel measurement for assessing NLG diversity.
- The paper is well-written and accessible.

Weaknesses:
- The selection of NLG models lacks justification, raising concerns about the reliability of results.
- Divergence metrics differ between sections, which may affect conclusions.
- The terms "uncertainty" and "fitness" may mislead readers and reduce clarity.

### Suggestions for Improvement
We recommend that the authors improve the justification for their choice of NLG models across tasks and consider evaluating the same model across different tasks for consistency. Additionally, we suggest clarifying the relationship between cross-variability and divergence metrics used in sections 6.1 and 6.2. The authors should also address the misleading terminology regarding uncertainty and fitness to enhance readability. Furthermore, we advise incorporating a more formal introduction of the Wasserstein 1 Distance in the main text and ensuring that the reproducibility of the work is clearly stated, including the availability of code for further research.