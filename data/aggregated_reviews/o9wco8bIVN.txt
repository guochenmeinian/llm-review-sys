ID: o9wco8bIVN
Title: Unsupervised Grammatical Error Correction Rivaling Supervised Methods
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an unsupervised method for grammatical error correction (GEC) based on the Break-It-Fix-It (BIFI) method. The authors propose enhancements to both the 'fixer' and 'critic' components within the BIFI framework, introducing a simple data augmentation method using masked language models (MLM) and heuristic rules for the fixer. For the critic, they select high-confidence samples from the fixer's predictions and employ techniques such as masked data augmentation and self-knowledge distillation to improve performance. The results indicate that their unsupervised method significantly outperforms previous methods and enhances model performance in supervised settings.

### Strengths and Weaknesses
Strengths:
- Achieves state-of-the-art (SoTA) performance on English and Chinese benchmarks.
- Clear writing and reasonable analyses supporting the motivation for each component.
- Introduces effective synthetic data generation techniques that enhance the existing LM-Critic framework.

Weaknesses:
- The method appears to be a straightforward extension of the LM-Critic work, lacking significant novelty.
- Heavy reliance on a large backbone model (Flan-T5-11B) and extensive multi-task pretraining, with only modest improvements in supervised settings.
- Concerns about scalability and robustness, particularly regarding the empirical observation of error patterns and their applicability to low-resource languages.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their contributions by exploring more innovative approaches beyond the existing LM-Critic framework. Additionally, conducting experiments under low-resource settings and with smaller backbone models would validate the effectiveness of their methods. We also suggest providing performance metrics for different model sizes in Table 1 and clarifying the intuition behind soft labeling in formula (2). Finally, addressing the concerns regarding the vulnerability of the generation method to non-representative validation data would enhance the robustness of the proposed system.