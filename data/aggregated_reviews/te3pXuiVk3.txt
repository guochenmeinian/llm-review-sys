ID: te3pXuiVk3
Title: MemeCap: A Dataset for Captioning and Interpreting Memes
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the task of "meme captioning" and introduces a new dataset called MemeCap, which includes meme images, literal captions, visual metaphors, and meme captions. The authors conduct extensive experiments with state-of-the-art Vision and Language (VL) models to assess their performance on this task. The dataset comprises 6.3K memes, and the authors demonstrate the limitations of current models in understanding memes.

### Strengths and Weaknesses
Strengths:  
- The paper introduces an innovative dataset that is valuable for advancing humorous understanding in large models.  
- It provides both automatic and human evaluations for the meme captioning task, enhancing the robustness of the findings.  
- The experimentation is thorough, showcasing the performance of various state-of-the-art models.

Weaknesses:  
- The paper fails to cite a related ACL 2023 paper, which is a significant oversight in scholarly practice.  
- Only the MiniGPT4 model is tested under a fine-tuning setting, while other models like Flamingo and Llama lack this analysis.  
- The dataset's quality analysis is limited, with only a small number of memes used in evaluations, raising concerns about the robustness of the findings.  
- The overlap between the tasks of meme captioning and visual metaphor is not sufficiently addressed, which diminishes the novelty of the work.

### Suggestions for Improvement
We recommend that the authors improve the citation practices by including the relevant ACL 2023 paper to acknowledge related work. Additionally, we suggest that the authors provide full-training settings for all models tested to enhance the comprehensiveness of their analysis. It would also be beneficial to conduct a more thorough quality analysis of the dataset, considering the small sample sizes used in evaluations. Finally, we encourage the authors to clarify the distinctions between meme captioning and visual metaphor tasks to strengthen the justification for their proposed work.