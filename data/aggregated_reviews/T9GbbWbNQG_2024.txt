ID: T9GbbWbNQG
Title: Layer-Adaptive State Pruning for Deep State Space Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 6, 5, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 2, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel pruning method for Deep State Space Models (DSSM) called Layer-Adaptive $\mathcal{H}_{\infty}$ State pruning (LAST). The authors formulate output distortion post-pruning and establish that state importance correlates with the $H_{\inf}$ norm, which serves as the pruning criterion. The method employs greedy optimization to prune entire subsystems while maintaining the integrity of remaining components, demonstrating improved performance over Uniform $\mathcal{H}_{\infty}$ and Global $\mathcal{H}_{\infty}$ methods across various tasks.

### Strengths and Weaknesses
Strengths:  
1. The introduction of pruning techniques in DSSMs is innovative and aligns with the model's structure.  
2. Extensive experiments across 10 tasks validate the robustness and effectiveness of the proposed methods.  

Weaknesses:  
1. The comparison of the proposed method is limited to Uniform and Global $\mathcal{H}_{\infty}$ methods; additional comparisons with more diverse pruning techniques, such as magnitude pruning, are necessary for a comprehensive evaluation.  
2. The paper lacks statistical evidence demonstrating the impact of state dimension on computational cost, which could enhance understanding of its significance.

### Suggestions for Improvement
We recommend that the authors improve the comparative analysis by including additional weight pruning methods to provide a fairer assessment of the proposed approach. Furthermore, we suggest incorporating statistics that illustrate the importance of state dimension and discussing related works that address state dimension reduction beyond pruning methods. This would enrich the context and relevance of the research findings.