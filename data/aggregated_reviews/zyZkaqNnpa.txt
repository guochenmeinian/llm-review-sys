ID: zyZkaqNnpa
Title: Donâ€™t blame Dataset Shift! Shortcut Learning due to Gradients and Cross Entropy
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 6, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a theoretical and empirical analysis of shortcut learning in machine learning models, particularly in linear perception tasks. The authors demonstrate that the inductive bias of default empirical risk minimization (ERM) maximizes margins, leading to a preference for shortcut features over stable ones. To counteract this, they propose a uniform margin approach through a novel loss function, MARG-CTRL, which effectively mitigates shortcut learning across various vision and language tasks without requiring annotations of shortcut features.

### Strengths and Weaknesses
Strengths:
- The paper provides a thorough theoretical analysis of shortcut learning, addressing an important issue in machine learning.
- The proposed MARG-CTRL loss function shows effective results in mitigating shortcut learning across multiple tasks.
- The writing is clear and the experiments are well-conducted, supporting the authors' claims.

Weaknesses:
- The theoretical framework has limited applicability due to its reliance on linear models, raising questions about its generalizability to deep learning contexts.
- The performance of MARG-CTRL in scenarios where shortcut and stable features are highly correlated remains unclear.
- The experimental datasets are somewhat limited, and the informal statement of Theorem 1 lacks clarity regarding the regime of \(n\) and its interactions with other quantities.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Theorem 1 by explicitly stating the regime of \(n\) and how it interacts with other quantities. Additionally, we suggest conducting experiments that explore the performance of MARG-CTRL in cases where shortcut features and stable features are highly correlated. Expanding the range of experimental datasets could also enhance the robustness of the findings. Furthermore, providing a more detailed discussion on the implications of dimensionality and the connection between the linear model and neural network training would strengthen the theoretical insights.