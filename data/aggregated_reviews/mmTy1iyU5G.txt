ID: mmTy1iyU5G
Title: Optimizing Solution-Samplers for Combinatorial Problems: The Landscape of Policy-Gradient Method
Conference: NeurIPS
Year: 2023
Number of Reviews: 7
Original Ratings: 10, 6, 7, 7, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a theoretical framework for analyzing the effectiveness of deep models trained by gradient-based methods as solution generators for combinatorial optimization problems. The authors investigate the properties of complete, compressed, and efficiently optimizable solution generators, addressing challenges such as minimizers at infinity and vanishing gradients through entropy regularization and a fast/slow mixture generation scheme. The paper also provides a theoretical analysis of policy-gradient methods, defining three desirable properties for generating approximately optimal solutions, and proving the existence of a method that satisfies these properties. The implications of these findings are discussed in relation to various combinatorial problems, including TSP.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written, clearly presenting its insights and justifying design choices, making it accessible even to non-expert readers.
2. It provides a positive answer to the existence of effective solution generators for combinatorial tasks, supported by theoretical foundations and empirical evidence.
3. The proposed methods, including entropy regularization and fast/slow mixing, are well-motivated and theoretically justified.

Weaknesses:
1. The empirical studies are limited in scale, primarily focusing on small instances, which raises questions about the practical applicability of the proposed framework.
2. The model of computation is not well-defined, leading to mathematical ambiguities that need clarification.
3. The authors do not explore how to learn the feature mappings for solutions and instances, which limits the practical implementation of their framework.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the model of computation by explicitly defining it and ensuring consistency in their assumptions and statements. Additionally, conducting experiments on larger combinatorial problems would strengthen the empirical validation of their methods. The authors should also consider discussing a broader range of related work beyond [BPL+16] to provide a more comprehensive context for their contributions. Finally, addressing how to learn the feature mappings and exploring the scalability of their methods to larger instances would enhance the practical implications of their framework.