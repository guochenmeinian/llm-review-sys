ID: VdvdRfwTtk
Title: Background Summarization of Event Timelines
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel task of background summarization from event timelines, aiming to provide essential context for understanding updates on events. The authors introduce a dataset created by merging existing timeline datasets, supplemented with background summaries annotated by humans. Additionally, they propose a new evaluation metric, the Background Utility Score (BUS), to assess the effectiveness of these background summaries in answering reader questions.

### Strengths and Weaknesses
Strengths:  
- The introduction of the background news summarization task is innovative and relevant, potentially attracting interest in NLP and temporal information analysis.  
- The dataset created serves as a valuable benchmark for future research in this area.  
- The experimental evaluation is rigorous, demonstrating the complexity of the task and the performance of state-of-the-art models.  

Weaknesses:  
- The BUS metric may introduce bias due to its reliance on questions generated by GPT-3.5, which could affect the evaluation's reliability.  
- The choice of maximum length for model evaluation lacks sufficient justification, potentially obscuring fair comparisons.  
- Clarity is needed in Section 4 regarding the use of Named Entity Recognition (NER) for question generation, as its role is not well articulated.  

### Suggestions for Improvement
We recommend that the authors improve the BUS metric by addressing the potential bias from using automatically generated questions. Consider implementing predefined questions to ensure consistency and relevance in evaluations. Additionally, provide a clearer justification for the maximum length of 3696 for GPT-3.5 and its impact on performance comparisons. Clarify the rationale behind the choice of a 3/3/8 split ratio for the dataset, as this is atypical in NLP tasks. Lastly, enhance the explanation of how NER contributes to question generation in Section 4 to improve clarity.