ID: 3yW6F0bUhC
Title: List-aware Reranking-Truncation Joint Model for Search and Retrieval-augmented Generation
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents GenRT, a joint model designed for reranking and truncation in list-aware retrieval systems. The model employs an encoder-decoder architecture, where the encoder captures global list-level features and the decoder generates a reranked list while making truncation decisions. The authors introduce a local backward window for dynamic reranking and propose specific losses for training. Extensive experiments on LTR datasets and retrieval-augmented LLMs demonstrate the model's effectiveness.

### Strengths and Weaknesses
Strengths:
- The paper is mostly easy to read and well-structured.
- Extensive experiments validate the proposed methods.
- The integration of reranking and truncation is innovative and supported by experimental results.

Weaknesses:
- The joint training approach is somewhat incremental, as similar concepts have been explored in LeCut, with differences primarily on the model side.
- The TDCG reward/metric lacks grounding in user studies or prior research, raising concerns about its validity, especially regarding the selection of gamma.
- The improvement in information retrieval datasets appears moderate, and the application of truncation to LLM QA tasks seems to negatively impact performance.

### Suggestions for Improvement
We recommend that the authors improve the justification for using TDCG as an evaluation metric and clarify how it penalizes irrelevant documents. Additionally, it would be beneficial to include a detailed comparison of GenRT's latency and complexity against existing baseline methods to address potential concerns about real-time application efficiency. We also suggest elaborating on the actual impact of observed improvements in experimental results, particularly for small gains, and including the TDCG of optimal truncation for a deeper understanding of truncation performance. Furthermore, clarifying the meaning of symbols used in equations and providing additional details on document embeddings and position embedding would enhance the paper's clarity.