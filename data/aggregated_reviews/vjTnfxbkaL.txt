ID: vjTnfxbkaL
Title: Hierarchical Enhancement Framework for Aspect-based Argument Mining
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Hierarchical Enhancement Framework (HEF) for the Aspect-Based Argument Mining (ABAM) task, introducing four modules, including the Semantic and Syntactic Fusion (SSF) component, the Batch-level Heterogeneous Graph Attention Network (BHGAT), and the Span Mask Interactive Attention (SMIA) component. The authors claim that their approach effectively addresses key challenges in ABAM and demonstrates significant performance improvements over existing methods through extensive experiments.

### Strengths and Weaknesses
Strengths:
- The hierarchical enhancement framework is innovative and well-motivated.
- The paper is well-written and organized, providing clear descriptions of its contributions.
- Experimental results indicate that the proposed method significantly outperforms state-of-the-art baselines.

Weaknesses:
- The SSF component lacks novelty, as its purpose of bridging long-distance dependencies has been previously explored.
- The overall framework figure is unclear and does not adequately illustrate the key component modules.
- The paper does not sufficiently explain how the proposed components address the three key challenges of ABAM.
- There are discrepancies between equations and model structure diagrams, and some symbols lack clear definitions.

### Suggestions for Improvement
We recommend that the authors improve the clarity and precision of the writing, particularly in sections where technical details are presented. Additionally, the authors should enhance the comparison by including more state-of-the-art ABAM methods and ensuring that baseline models are relevant to the ABAM task. We suggest that the authors clarify the relationship between the proposed components and the challenges they address. Furthermore, we encourage the authors to provide additional experiments to evaluate the effectiveness of the SMIA component and to ensure that equations align with the model structure diagrams. Finally, we advise the authors to include a related work section to contextualize their contributions within existing literature.