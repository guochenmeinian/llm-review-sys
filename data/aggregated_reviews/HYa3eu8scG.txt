ID: HYa3eu8scG
Title: Training for Stable Explanation for Free
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 5, 7, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 2, 2, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel metric for assessing the stability of explanations in machine learning models, termed R2ET (Robust Ranking Explanation via Thickness). The authors propose this method to efficiently train models for generating stable explanations, demonstrating its effectiveness across various data modalities and model architectures. The experiments indicate that R2ET achieves superior stability against stealthy attacks and generalizes well across different explanation methods. Additionally, the paper focuses on top-k thickness and R2ET optimization, clarifying that both metrics do not consider the influence of rankings within the top-k features or the non-top-k features. The authors highlight that pairwise thickness measures explanation robustness by capturing surrounding gaps, and that R2ET optimizes bounds rather than the thickness itself. They also acknowledge the importance of selecting an appropriate value for k, noting that it should reflect the problem being solved rather than merely the complexity of explanations.

### Strengths and Weaknesses
Strengths:  
1. The introduction of a new metric that aligns more closely with human perception than existing $\ell_p$ distance measures is compelling.  
2. The theoretical grounding and extensive empirical validation provide a high degree of confidence in the results.  
3. The paper is well-organized and clearly written.  
4. The clear distinction between top-k thickness and R2ET optimization enhances understanding of their relationship.  
5. The proposal for a potential generalization of R2ET to accommodate more fine-grained explanation robustness could broaden its applicability.  

Weaknesses:  
1. The discussion of explanation robustness is primarily focused on adversarial robustness, neglecting other factors like distributional shifts. A discussion on the relationship between the proposed method and these factors would be beneficial.  
2. The focus on small-scale datasets, such as MNIST, raises concerns about the R2ET method's limitations when applied to real-world, large-scale datasets. An evaluation of scalability is needed.  
3. The motivation for using ranking robustness over $\ell_p$ metrics is questioned, as it may not adequately justify the approach. Additionally, the claim regarding an arms race in $\ell_p$ robustness lacks sufficient evidence.  
4. The methodology's reliance on a fixed k may lead to issues in scenarios where the number of important features varies across instances.  
5. The authors do not fully address how to effectively manage the selection of k in diverse contexts.  

### Suggestions for Improvement
We recommend that the authors improve the discussion on the relationship between explanation robustness and other factors, such as distributional shifts, to enhance the paper's depth. Additionally, addressing the limitations of R2ET in real-world applications and providing an evaluation of its scalability would strengthen the contribution. It would also be beneficial to clarify the motivation for using ranking robustness and provide toy experiments to illustrate the advantages of their approach compared to gradient-based explanations. Furthermore, we suggest that the authors improve the discussion on the selection of k, particularly in cases where the number of important features may not be uniform across instances. Providing a more detailed strategy for adapting k based on specific problem requirements would enhance the robustness of the methodology. Lastly, we encourage the authors to explore further the implications of generalizing R2ET with metrics like average precision@k (AP@k) and discounted cumulative gain (DCG) to better integrate relative rankings among features.