ID: 5l5bhYexYO
Title: Reinforcement Learning Gradients as Vitamin for Online Finetuning Decision Transformers
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 6, 6, 7, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for online fine-tuning of decision transformers (DT) by integrating TD3 gradients to enhance performance, particularly in scenarios with low-quality offline data. The authors theoretically analyze the limitations of existing approaches and empirically validate their method across various environments, including Adroit, Antmaze, and Mujoco, demonstrating competitive results.

### Strengths and Weaknesses
Strengths:
- The work addresses a significant issue in fine-tuning decision transformers, which is crucial for leveraging pre-trained models effectively.
- The proposed method shows strong empirical performance, supported by a comprehensive set of benchmarks and theoretical analysis.
- The paper is well-written, with clear figures and extensive experiments that enhance the understanding of DT methods.

Weaknesses:
- The empirical results exhibit noise, necessitating a more rigorous approach to statistical significance, particularly regarding overlapping results in figures and tables.
- The baselines considered are not sufficiently robust, and the TD3 baseline often collapses after fine-tuning, suggesting a need for stronger comparisons.
- Some notations and the clarity of TD3 gradients in the policy update are confusing, requiring better definitions and explanations.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the statistical significance in their results, particularly by adopting the recommended practices from Agarwal et al. to provide a clearer picture. Additionally, please consider introducing stronger baselines, such as TD3+BC+Transformer and TD3+RvS, to isolate the contributions of architecture and objective improvements. It would also be beneficial to clarify the notations used in the paper and provide detailed explanations of the TD3 gradients in the context of policy updates. Lastly, we suggest discussing the potential impact of alternative exploration strategies during the fine-tuning phase, as well as addressing the computational costs associated with using transformers compared to MLPs.