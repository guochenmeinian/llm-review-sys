ID: xgTV6rmH6n
Title: Efficient Bayesian Learning Curve Extrapolation using Prior-Data Fitted Networks
Conference: NeurIPS
Year: 2023
Number of Reviews: 6
Original Ratings: 7, 5, 6, 7, -1, -1
Original Confidences: 3, 3, 2, 4, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for learning curve extrapolation using prior-data fitted networks (PFNs) to predict model performance over time based on earlier observations. The authors demonstrate that their approach significantly outperforms the MCMC-based method by Dunham et al. (2015) in both predictive accuracy and computational efficiency. The proposed LC-PFN algorithm minimizes cross-entropy loss and is evaluated across various datasets, showing promising results.

### Strengths and Weaknesses
Strengths:  
- The paper addresses an important and underexplored task in the AutoML literature.  
- The authors conduct extensive evaluations across diverse experiments, supporting their claims effectively.  
- The manuscript is well-written, with a clear presentation of the method and results.  
- The implementation of the model is comprehensive, although it requires clarity for replicability.  
- The application of PFNs to this field is novel, yielding significant results that should interest the community.  

Weaknesses:  
- The introduction of the PFN model is insufficiently detailed, requiring a more thorough discussion in the main text or appendix.  
- Key training details and hyperparameters are inadequately explained, necessitating clarification of terms like `nb_data`, `emsize`, and `nlayers`.  
- The novelty of the work primarily lies in its application, which may be seen as a limitation.  
- Some tables, such as Table 3, lack error bars, and there are minor presentation issues in figures and tables.

### Suggestions for Improvement
We recommend that the authors improve the discussion of the PFN model in the main text or appendix to enhance understanding. Additionally, please provide a detailed explanation of training details and hyperparameters, including definitions for terms like `nb_data`, `emsize`, and `nlayers`. To strengthen the novelty of the work, consider comparing against a broader range of previous methods beyond just MCMC. Furthermore, we suggest adding error bars to Table 1 and Table 3, and addressing the minor presentation issues identified in the figures and tables.