ID: 4UReW4Ez6s
Title: Provably Optimal Memory Capacity for  Modern Hopfield Models:   Transformer-Compatible   Dense Associative Memories as Spherical Codes
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 6, 7, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a theoretical analysis of memory capacity in Modern Hopfield Models (MHMs) and Kernelized Hopfield Models (KHMs), proposing a method to optimize kernel versions by mapping memories onto well-separated values on a sphere in feature space. The authors address four fundamental problems related to memory capacity, optimal separation functions, algorithm efficiency, and theoretical connections between memory gaps and optimal capacity. The work establishes that the optimal memory capacity is strongly dependent on the projection function, maximizing the angle between memory pairs.

### Strengths and Weaknesses
Strengths:  
* Originality: The proposed method is simple yet non-trivial, potentially enhancing memory performance across various models.  
* Clarity: The submission is well-organized and clearly written.  
* Contribution: The paper effectively answers its core questions and provides a robust associative memory framework applicable to other MHNs.

Weaknesses:  
* Quality: The main justification for the algorithm relies on a lower bound that lacks tightness, undermining support for minimizing memory overlap.  
* Quality: The claim of improved memory capacity is not numerically validated; results are qualitative and based on toy problems.  
* Significance: The practical importance of results is limited to practitioners, necessitating stronger empirical validation of the algorithm's effectiveness.

### Suggestions for Improvement
We recommend that the authors improve the empirical validation of their algorithm by conducting numerical experiments that compare memory capacity against baseline models, such as plain-vanilla dense MHM or [Wu et al. 2024a]. Additionally, clarifying the contributions of the lower bound on memory capacity and its dependence on the embedding parameters would strengthen the theoretical foundation. Addressing the questions regarding the tightness of the lower bound and the assumptions in Definitions 2.7 and 2.8 would enhance the clarity and rigor of the analysis. Finally, including more practical experiments on tasks like multiple instance learning and retrieval would provide a clearer context for the algorithm's applicability.