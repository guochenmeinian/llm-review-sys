ID: Ra6gfR3XuI
Title: Understanding the Role of Input Token Characters in Language Models: How Does Information Loss Affect Performance?
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates whether pre-trained language models (PLMs) can function effectively with missing characters in input tokens. The authors pre-train various PLMs by retaining one, two, or three characters from different positions in the tokens and subsequently fine-tune these models on GLUE and SuperGLUE with similar character restrictions. The findings indicate that PLMs can perform well on downstream tasks even with minimal character retention. Probing experiments suggest that significant linguistic information is still encoded in the hidden representations despite character loss.

### Strengths and Weaknesses
Strengths:
- The paper addresses a novel and relevant question in NLP regarding the character requirements for language comprehension.
- The methodology is robust, and the experiments yield interesting insights into the performance of PLMs with partial character inputs.
- The paper is well-written and presents clear takeaways.

Weaknesses:
- Certain sections, particularly Section 6.2, are unclear, with phrases like "cut all words to keep the threshold" causing confusion.
- The results may not advance our understanding of current PLMs significantly, as they do not directly relate to how PLMs trained on full tokens would handle character-dropped inputs.
- The probing experiment results may lack surprise due to the retention of critical syntactic and semantic information in short words.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Section 6.2, particularly the phrase "cut all words to keep the threshold." Additionally, conducting a fine-tuning experiment on a full token model with character-dropped inputs would clarify the relationship between character retention and comprehension. A more detailed analysis of the probing experiment error patterns is necessary to assess whether accuracy is higher for sentences with intact verbs and pronouns. Lastly, we suggest including the majority baseline for the probing experiments and citing each dataset in GLUE and SuperGLUE in Section 4.5.