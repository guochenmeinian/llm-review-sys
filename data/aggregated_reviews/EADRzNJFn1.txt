ID: EADRzNJFn1
Title: TGB 2.0: A Benchmark for Learning on Temporal Knowledge Graphs and Heterogeneous Graphs
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 7, 5, 7, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Temporal Graph Benchmark 2.0 (TGB 2.0), a comprehensive framework for evaluating predictive models on Temporal Knowledge Graphs (TKGs) and Temporal Heterogeneous Graphs (THGs). TGB 2.0 enhances the existing benchmark by introducing eight new datasets across five domains, significantly larger than prior datasets, which facilitates robust evaluations. The authors provide insights from extensive experiments, emphasizing the importance of edge-type information, the competitiveness of simple heuristic baselines, and the scalability challenges faced by current methods on larger datasets.

### Strengths and Weaknesses
Strengths:
- The introduction of TGB 2.0 addresses critical gaps in the evaluation of temporal graphs, providing a robust framework that can significantly advance the field.
- The standardized evaluation pipeline and large datasets are valuable resources for researchers, enabling comprehensive and comparative studies.
- The methodological rigor and extensive experimentation demonstrate a high level of research quality.

Weaknesses:
- The framework's complexity may limit accessibility for some researchers, particularly those with limited computational resources.
- The paper lacks detailed discussion on the dataset construction process and the standardization of data formats.
- Limited experimental analysis could benefit from additional metrics and broader methodological comparisons.

### Suggestions for Improvement
We recommend that the authors improve the discussion on dataset construction, including details on data cleaning, format standardization, and the construction pipeline to enhance reproducibility. Additionally, we suggest expanding the experimental evaluations to include more comprehensive metrics and comparisons beyond link prediction, as well as addressing the scalability of methods tested on the largest datasets. Furthermore, we encourage the authors to discuss important related works to contextualize their contributions more effectively.