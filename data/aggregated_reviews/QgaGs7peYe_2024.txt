ID: QgaGs7peYe
Title: Predicting Future Actions of Reinforcement Learning Agents
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 5, 7, 4, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates methods for predicting future actions and events of reinforcement learning (RL) agents during deployment, comparing explicitly planning, implicitly planning, and non-planning agents. The authors utilize an inner state approach, leveraging the agent's internal computations, and a simulation-based approach using a learned world model. Results from the Sokoban environment indicate that plans from explicitly planning agents are more informative for prediction than other inner states.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant and practical problem in RL deploymentâ€”predicting future agent behavior.
- The proposed method is well-motivated, with a clear analysis of its ideas.
- The structure and presentation of the paper are clear and well-organized.
- The study offers originality by investigating how the type of agent influences its predictive capabilities.

Weaknesses:
- The rationale behind the choices in different methods is unclear.
- The results plot standard deviation instead of standard errors for confidence intervals.
- The evaluation criteria for predicting the event of reaching the blue tile may be trivial due to the uniform probability of tile placement.
- There is a lack of clarity regarding the potential divergence between simulated and real trajectories over time.
- The paper does not adequately define the categorization of planning agents or provide a hypothesis for the observed results.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their rationale behind the chosen methods and provide a more detailed explanation of the categorization of planning agents. Additionally, we suggest that the authors consider using top-K rollouts for MuZero to enhance information richness and explore the use of multiple or earlier layers for IMPALA. To strengthen the evaluation, we advise revising the criteria for predicting the blue tile event and addressing the potential data leakage from rollouts used as additional information. Finally, we encourage the authors to clarify the definitions and implications of their proposed taxonomy and ensure that the presentation of results includes standard errors for confidence intervals.