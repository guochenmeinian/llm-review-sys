ID: eVrmcOvJV4
Title: Inferring the Future by Imagining the Past
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 4, 8, 8, 5, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 2, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an efficient Monte Carlo algorithm for inferring an agent's goal state from a single observed state. The authors improve upon previous methods by sampling paths through the current state, separating the past and future trajectories, and employing incremental A-star search for planning. The algorithm demonstrates significant computational efficiency, converging faster than traditional rejection sampling methods, and is validated against human judgments across various environments, including grid worlds and a word-blocks game.

### Strengths and Weaknesses
Strengths:
- The problem of inferring goals from a single snapshot is compelling, addressing a major limitation of existing methods that rely on full trajectory contexts.
- The paper is clearly written and easy to understand, with a strong emphasis on the efficiency of the proposed method.
- The results align well with human judgments, enhancing the plausibility of the algorithm's inferences.
- The sampling strategy shows notable sample efficiency, achieving near convergence with only 10 samples.

Weaknesses:
- Key quantities such as states, actions, and goals are not clearly defined, leaving ambiguity regarding their continuity or discreteness.
- The algorithm appears somewhat ad-hoc, combining various techniques without a cohesive theoretical framework.
- The contribution may not be substantial enough for a NeurIPS submission, as the conceptual advancements over prior work are limited.
- The absence of a colorbar in Table 1 obscures the interpretation of the plotted results.

### Suggestions for Improvement
We recommend that the authors improve the clarity of key definitions, particularly regarding the nature of states, actions, and goals, and formally define the MDP and its components. Additionally, we suggest that the authors provide a clearer indication of the specific quantity computed by the algorithm (p(x | g)). To strengthen the theoretical foundation, we encourage the authors to include a complexity analysis of the sampling process in relation to the state space size and the number of starting/goal states. Furthermore, we recommend addressing the potential applicability of the algorithm in continuous domains and clarifying the role of A-star search within the proposed method. Lastly, we advise toning down the narrative style to enhance the delivery of key messages.