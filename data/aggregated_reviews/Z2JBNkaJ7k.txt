ID: Z2JBNkaJ7k
Title: CiteBench: A Benchmark for Scientific Citation Text Generation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents CITEBENCH, a comprehensive benchmark for citation text generation that unifies four structurally different datasets. The authors provide an evaluation and analysis kit for both quantitative and qualitative assessments, including a novel measure of discursive behavior based on KL divergence. The work includes a thorough set of baselines and suggestions for future research directions, addressing key questions in the field such as dataset unification and evaluation methodologies.

### Strengths and Weaknesses
Strengths:
- The paper is insightful, well-organized, and clearly written, making it easy to follow.
- It introduces a clever formalization of the citation text generation task, facilitating the unification of existing resources and standardization of evaluation.
- The experiments are solid, with comprehensive analysis and justification of methodologies, including performance evaluations on indirect supervision and out-of-distribution settings.

Weaknesses:
- There is a lack of validation to check if the Scicite or CORWA labeling reflects human labeling.
- The clarity of task-specific modifications when integrating different benchmarks is insufficiently addressed.
- The novelty of the problem formulation is questioned, as it does not significantly differ from existing citation generation tasks.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding how the four existing benchmarks were populated to fit the new task formulation. Additionally, we suggest conducting automatic validation to check the KL divergence between samples with gold labels to ensure the accuracy of the labeling. It would also be beneficial to provide a more comprehensive discussion of existing studies rather than merely listing them, and to clarify the distinctions between this work and previous citation generation tasks.