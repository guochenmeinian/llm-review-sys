ID: gdzxWGGxWE
Title: How do Minimum-Norm Shallow Denoisers Look in Function Space?
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 6, 7, 5, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the properties of one-layer networks in the context of denoising problems, specifically computing a closed-form solution for a neural network (NN) trained offline with regularization. The authors demonstrate that this NN outperforms the eMMSE estimator in terms of generalization in low-noise scenarios and in one-dimensional cases. They extend their findings to multivariate cases, showing that the network's output remains within a lower-dimensional subspace when training data points are confined to it, and they derive closed-form solutions for specific configurations.

### Strengths and Weaknesses
Strengths:
- The paper is clearly written, with well-explained theoretical results that enhance readability.
- The theorems presented appear novel and provide valuable insights into the behavior of simple networks in denoising tasks.
- A comprehensive analysis of the univariate case is provided, along with insights into higher-dimensional scenarios, supported by numerical illustrations.

Weaknesses:
- The study is restricted to low noise levels, and the authors do not address how the removal of assumption 1 might affect the results shown in figure 1.
- There is a lack of empirical illustrations or theoretical development regarding the behavior of the NN as noise levels increase.
- The novelty of the theoretical findings is questioned, particularly regarding the characterization of networks minimizing representation costs, which may overlap with existing literature.

### Suggestions for Improvement
We recommend that the authors improve the empirical evaluation of their model's performance in real-world denoising applications, particularly in higher-dimensional settings. Additionally, it would be beneficial for the authors to illustrate the effects of increasing noise levels on the NN's performance compared to the eMMSE. Providing bounds on the noise level $\sigma$ for which theorem 1 is valid, along with MSE curves that highlight the differences between NN and eMMSE across various noise levels, would also strengthen the paper. Finally, clarifying how their work extends previous characterizations of minimal representation cost solutions would enhance the contribution's clarity and impact.