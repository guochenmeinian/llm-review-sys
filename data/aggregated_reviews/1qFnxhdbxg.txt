ID: 1qFnxhdbxg
Title: Energy Discrepancies: A Score-Independent Loss for Energy-Based Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 7, 7, 7, 6, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 2, 4, 2, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel loss function called Energy Discrepancy (ED) for training energy-based models, which does not rely on score functions or MCMC samples. The authors demonstrate that optimizing ED yields the appropriate energy function and establish connections between ED, score matching, and contrastive divergence. The efficacy of ED is validated through extensive numerical experiments on both synthetic and real-world datasets, showing superior performance in density estimation, image reconstruction, and out-of-distribution detection compared to existing methods.

### Strengths and Weaknesses
Strengths:
1. Theoretical derivation of ED is rigorous and well-justified.
2. Extensive numerical experiments validate the proposed method's effectiveness.
3. The paper is generally well-written and organized, making it accessible.
4. The proposed algorithm is straightforward to implement.

Weaknesses:
1. The importance of the w-stabilization term in numerical experiments is unclear; its effectiveness with small values of w needs clarification.
2. There is a lack of empirical results on training EBMs directly on the data space using the proposed loss.
3. The paper does not explore comparisons with GAN-based models or other kernels beyond Gaussian for perturbing distributions.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the w-stabilization procedure, particularly regarding its generalizability beyond the Gaussian case. Additionally, we suggest including experiments in discrete settings and providing comparisons with GAN-based models. The authors should address the questions raised regarding the performance of ED in relation to other methods and clarify the definition of Wasserstein distance in Theorem 2 for broader accessibility.