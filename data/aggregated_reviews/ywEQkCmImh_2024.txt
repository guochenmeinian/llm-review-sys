ID: ywEQkCmImh
Title: Towards Multi-Domain Learning for Generalizable Video Anomaly Detection
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 5, 5, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new task called Multi-Domain Learning Video Anomaly Detection (MDVAD), aimed at developing a general Video Anomaly Detection (VAD) model across various domains. The authors identify abnormal conflict as a significant challenge and establish a new benchmark, alongside a baseline framework that includes multi-head mechanisms and an Abnormal Conflict (AC) Classifier. Extensive experiments demonstrate the effectiveness of the proposed methods in alleviating abnormal conflicts.

### Strengths and Weaknesses
Strengths:
1. The introduction of the MDVAD task is innovative and addresses the limitations of single-domain VAD models.
2. The establishment of a new benchmark and evaluation protocols enhances the assessment of multi-domain learning in VAD.
3. The proposed framework effectively tackles the issues of abnormal conflict and scene discrepancy, showcasing robust experimental results.

Weaknesses:
1. The proposed AC Classifier's ability to address abnormal conflict needs further clarification, particularly regarding the rationale behind the label determination in Eq. (6).
2. There is a lack of comparative experiments with additional baselines beyond MIL, Null-MIL, and NullAng-MIL, which limits the assessment of the proposed methods' effectiveness.
3. The complexity of the multi-head framework may hinder flexibility during domain changes, and the theoretical basis for some methods requires deeper exploration and validation.

### Suggestions for Improvement
We recommend that the authors improve the clarity of how the AC Classifier addresses the abnormal conflict problem, particularly by providing a more detailed explanation of the label determination process in Eq. (6). Additionally, we suggest including results from more comparative experiments with a broader range of baselines to strengthen the evaluation of the proposed methods. Lastly, we encourage the authors to enhance the manuscript's clarity by thoroughly checking the writing and providing detailed descriptions of the experimental setup and training procedures.