ID: 3qHlPqzjM1
Title: Projection Regret: Reducing Background Bias for Novelty Detection via Diffusion Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 5, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Projection Regret (PR), a method for novelty detection that addresses background bias in out-of-distribution (OOD) samples using diffusion models. PR computes the perceptual distance between a test image and its recursive diffusion-based projection, aiming to reduce the influence of non-semantic background information. The authors claim that their method outperforms existing techniques in novelty detection, particularly in datasets like CIFAR-10 and CIFAR-100. Additionally, the paper introduces a novel method for OOD detection that demonstrates significant acceleration (8.7x) compared to the second-best baseline, LMD. The authors assert that their method shows improved performance when tested on datasets with similar background information and clarify that OOD detection and industrial anomaly detection (IAD) have been researched separately. They also mention that their method has been effectively scaled to larger datasets like LSUN.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and easy to understand.
2. The problem of background bias in novelty detection is significant and well-motivated.
3. Experimental results indicate that PR outperforms state-of-the-art methods.
4. The proposed method exhibits significant computational efficiency compared to existing methods.
5. The authors have conducted additional experiments to address reviewer concerns, demonstrating improved performance on datasets with shared background information.

Weaknesses:
1. The projection method may not effectively differentiate between near-OOD samples with similar backgrounds, potentially complicating detection.
2. The design and hyperparameter tuning process is crucial for results, yet details on sensitivity analysis across various ID/OOD pairs are lacking.
3. The computational efficiency of the algorithm raises concerns, with insufficient comparison or explanation provided, particularly in larger-scale datasets.
4. The evaluation primarily focuses on standard datasets, lacking results on larger-scale benchmarks like ImageNet, which would enhance practical relevance.
5. Some reviewers question the appropriateness of the evaluated datasets and the relevance of comparisons against IAD datasets.

### Suggestions for Improvement
1. We recommend that the authors improve the evaluation by incorporating additional metrics such as precision-recall curves or F1 scores for a more comprehensive assessment of PR's performance.
2. It would be beneficial to test PR on real-world datasets, such as medical imaging or self-driving car data, to demonstrate its applicability in practical scenarios.
3. We suggest providing detailed information about the computational efficiency of PR, including time complexity and scalability, to help potential users assess its suitability for their specific use cases.
4. Conducting a robustness analysis against various types of noise and distortions would further validate PR's effectiveness under challenging conditions.
5. We encourage the authors to explore and discuss the origins of background bias in more depth, as well as to compare their method against datasets known for strong background biases to strengthen their claims.
6. We recommend that the authors improve clarity regarding the choice of evaluated datasets and address why they believe these datasets are not biased toward the background.
7. Additionally, we suggest that the authors provide further justification for the relevance of their method in the context of IAD datasets, given that baseline methods have not been tested on such datasets.
8. Lastly, we encourage the authors to continue demonstrating the efficiency of their method across various ensemble sizes to alleviate concerns about computational cost.