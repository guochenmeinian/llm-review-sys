ID: dYKXU5AGs5
Title: Understanding and Scaling Collaborative Filtering Optimization from the Perspective of Matrix Rank
Conference: ACM
Year: 2024
Number of Reviews: 3
Original Ratings: -1, -1, -1
Original Confidences: -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to collaborative filtering (CF) by introducing stable rank regularization as a cost-efficient alternative to traditional negative sampling methods. The authors focus on the relationships between negative sampling, matrix rank, and CF performance, providing both empirical and theoretical insights into how stable rank can enhance the training of recommendation systems. The work demonstrates that the singular values of embedding tables are intrinsically linked to CF loss functions, and it proposes a warm-start strategy that regularizes the stable rank of user and item embeddings, promoting higher-quality embeddings during early training phases.

### Strengths and Weaknesses
Strengths:
1. The evolution of stable rank during training is discussed, revealing its relationship with the final recommendation effect.
2. The theoretical analysis is sound and well-supported by empirical results.
3. The paper addresses scalability challenges in CF, offering significant innovation through stable rank regularization.

Weaknesses:
1. The experiments lack a stable rank trajectory using stable rank regularization, and the NDCG@20 score for stable rank regularization is not included, which is crucial for assessing its effectiveness.
2. The analysis of the method's applicability to complex deep learning models is insufficient.
3. Extensive textual explanations may hinder quick comprehension of core concepts, and the paper contains spelling mistakes and minor language issues.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their explanations by adding more visual aids to illustrate how stable rank regularization works. Additionally, the authors should expand their analysis to provide a more comprehensive comparison with other methods, particularly regarding SSM. It would be beneficial to conduct further tests on complex deep learning models to validate the method's applicability. We also suggest proofreading the paper carefully to correct spelling errors and minor language issues. Finally, including a section discussing potential limitations and challenges of the proposed approach would enhance the paper's depth.