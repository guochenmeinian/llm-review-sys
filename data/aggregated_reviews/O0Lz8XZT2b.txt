ID: O0Lz8XZT2b
Title: A U-turn on Double Descent: Rethinking Parameter Counting in Statistical Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 7, 9, 7, 7, 7, 7, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 2, 3, 3, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis of the double descent phenomenon in traditional machine learning models, specifically random forests, boosting, and linear regression using random Fourier features. The authors propose that the apparent double descent behavior is influenced by a two-dimensional parameter space, where one dimension reflects the complexity of individual models and the other represents the statistical power of ensembles. By employing a more nuanced measure of effective parameters, the authors demonstrate that the double descent behavior can be reinterpreted as U-shaped and L-shaped curves, depending on the model. Additionally, they explore the behavior of smoothers and argue that a more appropriate parameter counting method eliminates the double descent phenomenon.

### Strengths and Weaknesses
Strengths:
- The novel decomposition of parameter count into two dimensions is important and impactful within the studied models.
- The empirical analysis is robust, and the theoretical insights, particularly for linear regression, are well-founded.
- The clarity and structure of the writing are commendable, enhancing the overall presentation.

Weaknesses:
- The section explaining double descent through alternative parameter counting lacks novelty, as acknowledged by the authors, and is limited to smoothers, which restricts its broader applicability.
- The authors do not adequately explain the significant drop in effective parameter count with increased ensembles or exceeding features, which could strengthen the paper.
- The heuristic explanation for performance improvement with increased features lacks clarity and does not convincingly connect feature quality to test performance.
- There is insufficient discussion on the asymmetry between the two parameter count dimensions, particularly regarding their differing curve shapes.

### Suggestions for Improvement
We recommend that the authors improve the novelty of the second part of the paper by providing a clearer justification for the effective parameter count's relevance beyond smoothers. Additionally, it would be beneficial to include an explanation of why the effective parameter count decreases with more ensembles or exceeding features. We suggest enhancing the discussion on the relationship between feature quality and test performance to clarify the underlying mechanisms. Furthermore, addressing the asymmetry between the two parameter dimensions in a more generalizable manner would strengthen the paper's conclusions. Lastly, we encourage the authors to contextualize their findings with existing literature, particularly regarding ridge regression and its connections to their analysis.