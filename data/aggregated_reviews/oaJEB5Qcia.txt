ID: oaJEB5Qcia
Title: FGPrompt: Fine-grained Goal Prompting for Image-goal Navigation
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 5, 7, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents FGPrompt, which conditions the goal image embedding on the observation to enhance goal-relevant visual cues in image-goal navigation. The authors propose two fusion strategies: Mid Fusion by FiLM and Early Fusion through concatenation of input and goal images. The method achieves state-of-the-art results on the Gibson dataset. Additionally, FGPrompt explores three goal prompting techniques: keypoint matching, FiLM layers, and channel concatenation, with the latter two showing strong performance. The experiments confirm significant improvements over existing methods while using smaller model sizes.

### Strengths and Weaknesses
Strengths:
- The fusion strategies effectively capture goal-relevant information, leading to substantial performance gains over prior methods.
- The paper includes clear illustrations and qualitative examples that enhance understanding.
- The simple design of the early fusion method allows for high-resolution spatial reasoning in ImageNav tasks.

Weaknesses:
- The novelty of the proposed methods is somewhat unclear, particularly regarding the Mid Fusion technique, which appears to closely follow existing methodologies.
- The focus on a single task type limits the generalizability of the results, as the methods have not been tested across diverse tasks.
- The complexity of the narrative surrounding the various fusion techniques may detract from the clarity of the paper.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the novelty of their contributions, particularly in distinguishing the proposed methods from existing techniques. Additionally, consider applying the methods to other task types, such as visual rearrangement, to demonstrate broader applicability. We suggest making the Mid Fusion technique a baseline for comparison and focusing more on the early fusion technique. Furthermore, it would be beneficial to tone down claims regarding the early fusion mechanism to reflect that various concatenation methods were explored. Lastly, addressing the limitations of the FGPrompt technique in scenarios where camera parameters differ would enhance the paper's robustness.