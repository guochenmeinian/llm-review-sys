ID: Lc8gemv97Y
Title: Dealing with Synthetic Data Contamination in Online Continual Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 7, 7, 5, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates the impact of AI-generated images on online continual learning (CL) models, introducing a novel method called Entropy Selection with Real-synthetic similarity Maximization (ESRM) to address synthetic data contamination. ESRM employs entropy-based sample selection and a contrastive learning approach to enhance CL model robustness against synthetic data degradation. The authors provide experimental analysis and propose a new loss function to prioritize high-entropy samples, supported by extensive ablation studies.

### Strengths and Weaknesses
Strengths:
- The authors clearly articulate the problem, methodology, and results, enhancing accessibility for a broad readership.
- The paper identifies the significant challenge of synthetic data contamination in online continual learning, offering a pioneering approach with substantial implications for the ML community.
- ESRM demonstrates creativity by combining entropy selection and contrastive learning to mitigate the negative effects of synthetic data.
- The paper is technically clear, well-written, and underpinned by robust experimental validation.

Weaknesses:
- The evaluation of synthetic data is limited to a narrow set of generative models, primarily focusing on image classification datasets; broader task inclusion, especially text-to-images and text-to-text, is needed.
- The method for generating synthetic datasets relies on simple prompts; incorporating more complex prompts using large language models could better reflect real-world scenarios.
- The reliance on entropy as a distinguishing metric for real versus synthetic data may not be universally applicable, necessitating further exploration of its effectiveness across different domains.
- Limited discussion on the computational efficiency and scalability of the method, particularly for large-scale datasets or high contamination ratios, could hinder practical applications.

### Suggestions for Improvement
We recommend that the authors expand the evaluation to include a wider variety of generative models and tasks beyond image classification. Additionally, incorporating more complex prompts for synthetic data generation could enhance realism. The authors should also explore the applicability of the entropy metric across different domains and provide a more thorough discussion on the computational efficiency and scalability of their method, especially under high contamination ratios.