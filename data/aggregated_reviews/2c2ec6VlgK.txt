ID: 2c2ec6VlgK
Title: Unlearning Incentivizes Learning under Privacy Risk
Conference: ACM
Year: 2024
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into the economic impact of machine unlearning on user behavior and platform profitability, focusing on scenarios with and without data deletion requests. The authors model user behavior through training effort and privacy sensitivity, defining utility functions for both users and platforms. They formulate an optimization problem to maximize platform profit and derive theorems based on their findings, which indicate that enabling unlearning can enhance profitability under certain conditions. A questionnaire survey supports the notion that machine unlearning increases user willingness to participate in federated learning.

### Strengths and Weaknesses
Strengths:
1. The paper explores significant questions regarding user participation and contract design in federated learning, providing valuable insights.
2. The mathematical modeling and theoretical support are well-articulated, complemented by empirical data from the questionnaire survey.
3. Numerical experiments yield interesting results, particularly highlighting the influence of privacy sensitivity on platform profitability.

Weaknesses:
1. The discussion of related works is insufficient, lacking a thorough analysis of existing incentive mechanisms in federated learning, which is crucial for contextualizing the research.
2. The experimental section relies solely on parameter-based simulations, which may not convincingly represent real-world scenarios; validation with real datasets is recommended.
3. The research scope is inconsistently defined, oscillating between "machine learning" and "federated learning," which could confuse readers. A clearer definition of the specific scenario would enhance focus.

### Suggestions for Improvement
We recommend that the authors improve the literature review by incorporating a comprehensive analysis of existing studies on incentive mechanisms in federated learning. Additionally, the authors should validate their findings with real datasets or realistic federated learning scenarios to strengthen the experimental section. Clarifying the research scope by consistently using "federated learning" and explicitly defining the scenario under discussion would enhance the paper's precision. Furthermore, we suggest shortening or relocating Section 3.1 to improve relevance to the main results, and addressing the clarity of Theorem 1 and the formula errors noted in the reviews.