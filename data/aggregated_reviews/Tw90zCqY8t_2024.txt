ID: Tw90zCqY8t
Title: Understanding Memorization using Representation Similarity Analysis and Model Stitching
Conference: NeurIPS
Year: 2024
Number of Reviews: 4
Original Ratings: 7, 6, 9, 6
Original Confidences: 4, 4, 4, 4

Aggregated Review:
### Key Points
This paper investigates the dynamics of memorization in deep neural networks (DNNs) using Centered Kernel Alignment (CKA) and model stitching techniques. The authors train ResNet-18 on CIFAR-10 with varying degrees of label noise and analyze the convergence and similarity of layer representations. Findings reveal that early layers extract generalizable features, while memorization appears localized to deeper layers. The research challenges traditional views by suggesting that fixing early layers can mitigate memorization without significantly compromising model accuracy.

### Strengths and Weaknesses
Strengths:
- The paper presents interesting findings, demonstrating that early layers are less impacted by memorization than deeper layers and showing how representation similarity evolves during training.
- The innovative use of CKA and model stitching provides experimental support for conclusions about functional similarities between noisy and noise-free networks.
- The thorough experiments on CIFAR-10, backed by multiple checkpoints and extensive layer-wise analysis, effectively address gaps in the literature regarding the distribution of memorization across layers.

Weaknesses:
- The novelty of the findings is somewhat limited, as similar studies on memorization from a representation similarity perspective exist. A clearer discussion contrasting these findings with previous work would enhance the paper.
- The analysis appears specific to the random labels setting, raising questions about the generalizability of the results to more realistic scenarios.
- The scope of the dataset (CIFAR-10) is narrow, and extending experiments to more complex datasets or different architectures would improve generalization.
- The paper lacks clear definitions for key concepts such as memorization and generalization, which are crucial for reader comprehension.

### Suggestions for Improvement
We recommend that the authors improve the discussion by contrasting their findings with specific previous studies to highlight novelty. Additionally, exploring the applicability of their findings beyond the random labels setting would strengthen the paper. It would be beneficial to compare models trained with different levels of random label noise at a more fine-grained example level, potentially using similarity metrics based on data attribution (e.g., ModelDiff or Influence embeddings) to analyze how model predictions differ functionally. Furthermore, providing clearer definitions for key concepts and expanding the dataset and architecture choices would enhance the paper's impact. Lastly, addressing minor typos and inconsistencies in figure labeling would improve clarity.