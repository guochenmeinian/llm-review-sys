ID: a2Yg9Za6Rb
Title: Students Parrot Their Teachers: Membership Inference on Model Distillation
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 8, 8, 6, 8, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into the effectiveness of model distillation in safeguarding the privacy of training data, specifically through membership inference attacks (MIA). The authors demonstrate that distillation provides limited privacy protection, even when the distilled models have not directly encountered the teacher's data. They extend the LiRA attack to the distillation context and highlight critical factors such as data duplication and teacher set poisoning that influence privacy risks.

### Strengths and Weaknesses
Strengths:
- The paper addresses an important and timely problem regarding privacy in machine learning.
- It is well-organized and easy to read, with effective visualizations that enhance understanding.
- The experimental results are sound and support the paper's claims.

Weaknesses:
- The clarity of the attack details, particularly in Section 5, is lacking, making it difficult for readers to grasp the methodology fully.
- There is insufficient detail regarding the experimental setup, which raises questions about reproducibility and the utility of the models.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the assumptions and information available to the attacker in the proposed attacks. Additionally, providing more detail on how the student dataset was chosen for the End-to-End LiRA experiments would enhance reproducibility. Clarifying the link between student examples and teacher examples in Section 5, along with additional illustrations, would significantly aid reader comprehension. Furthermore, addressing the potential effectiveness of Differential Privacy as a mitigation strategy against MIAs would enrich the discussion.