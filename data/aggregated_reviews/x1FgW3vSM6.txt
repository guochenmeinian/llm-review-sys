ID: x1FgW3vSM6
Title: Flag Aggregator: Scalable Distributed Training under Failures and Augmented Losses using Convex Optimization
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 5, 3, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 1, 4, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Flag Aggregator (FA), a method for robust gradient aggregation in data-parallel training, formulated as a Maximum Likelihood Estimation (MLE) procedure using Beta densities. The authors analyze FA theoretically through convex optimization techniques and empirically demonstrate its effectiveness against Byzantine failures in image classification tasks, particularly with ResNet-18 on CIFAR10 using a 4-GPU cluster.

### Strengths and Weaknesses
Strengths:
- The proposed MLE-based estimation procedure for aggregation is simple and incorporates novel regularization functions.
- The authors provide code for reproducibility.
- The paper is well-written and easy to follow.

Weaknesses:
- The marginal improvement in wall-clock time may be attributed to heavy SVD overhead.
- The evaluation is limited to only two small models (ResNet18 and a 2-layer CNN) and image classification tasks (CIFAR10 and MNIST), lacking benchmarks with larger models like RNNs or GPT2 and other tasks such as language modeling.
- The 4-GPU cluster setup is outdated for assessing scalability in distributed training.
- The theoretical clarity is lacking, particularly regarding the optimization problem and the assumptions made.
- There are no convergence guarantees provided for the proposed method.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the theoretical components, particularly by clearly defining terms and concepts such as the optimization problem and the Flag/Grassmanian manifold. Additionally, the authors should provide convergence guarantees for their method, as this is crucial for establishing robustness against Byzantine workers. We suggest simulating a wider variety of Byzantine attacks and including advanced defenses like NNM and Bucketing in the experimental section to better assess the significance of FA's contributions. Finally, addressing the computational overhead and exploring methods from randomized linear algebra to reduce per-iteration time would enhance the practicality of the proposed approach.