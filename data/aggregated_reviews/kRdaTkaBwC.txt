ID: kRdaTkaBwC
Title: Inferring Hybrid Neural Fluid Fields from Videos
Conference: NeurIPS
Year: 2023
Number of Reviews: 22
Original Ratings: 6, 7, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 5, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach for recovering the density and velocity fields of inviscid fluids from sparse multiview videos. The authors propose a model that incorporates physics-based losses to ensure a divergence-free velocity field, addressing visual ambiguities in fluid velocity. Additionally, the model features a hybrid neural velocity representation, combining a base neural velocity field with a vortex particle-based model to capture vortical flow details. The method aims to enhance the visual understanding of fluids, particularly in applications involving smoke, fog, and gas.

### Strengths and Weaknesses
Strengths:  
- The integration of physics-based losses into the volume rendering framework is a rational approach to tackle visual ambiguities in fluid data.  
- The hybrid representation of velocity fields showcases originality, effectively recovering vortical flow details.  
- The results demonstrate improved accuracy in reconstruction, particularly illustrated in Figure 8.

Weaknesses:  
- The novelty of incorporating physical constraints is diminished by similar approaches in prior works, such as those by Chu et al. (2022) and Baieri et al. (2023).  
- The requirement for constant emitting radiance limits applicability in real-world scenarios with spatially-varying lighting.  
- The paper lacks sufficient experimental results, particularly regarding the recovery of fluid density and comparisons with more advanced neural rendering techniques.

### Suggestions for Improvement
We recommend that the authors improve the novelty aspect by explicitly acknowledging related works, such as NeuroFluid and PAC-NeRF, and clarifying how their approach differs. Additionally, the authors should evaluate the proposed method across a broader range of fluid scenarios, including laminar and turbulent flows, to demonstrate generalization capabilities. It would also be beneficial to compare reconstruction results with and without the constant radiance constraint to assess its impact. Furthermore, incorporating more advanced neural rendering techniques in comparisons and providing quantitative results regarding velocity field reconstruction against ground truth would strengthen the validation of the method. Lastly, the authors should clarify the implementation details of the loss functions and the performance differences between the hybrid velocity representation and high-frequency position embedding.