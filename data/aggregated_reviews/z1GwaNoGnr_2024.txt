ID: z1GwaNoGnr
Title: XMask3D: Cross-modal Mask Reasoning for Open Vocabulary 3D Semantic Segmentation
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 5, 5, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents XMask3D, a framework for open vocabulary 3D semantic segmentation that integrates a denoising UNet from a pre-trained diffusion model to generate geometry-aware segmentation masks based on learnable implicit 3D embeddings. The authors propose a cross-modal mask reasoning approach that aligns 3D features with 2D-text embeddings, utilizing techniques such as 3D-to-2D mask generation and 2D-to-3D mask regularization. The method aims to enhance the open vocabulary capacity of 3D features by producing coherent segmentation results.

### Strengths and Weaknesses
Strengths:
1. The motivation for the research is clear, and the proposed method is intuitive, with experiments validating its contributions.
2. The idea of merging 2D capabilities with 3D features is novel, and the method outperforms reported models like OpenScene.

Weaknesses:
1. The organization of the paper could be improved, particularly the flow between sections 3.1 and 3.2, which may confuse readers regarding the key contributions.
2. The evaluation is limited to indoor datasets, and comparisons with state-of-the-art methods like OV3D are lacking.

### Suggestions for Improvement
We recommend that the authors improve the organization of the paper to enhance clarity, particularly in sections 3.1 and 3.2. Additionally, please provide further clarification on how mask-level alignment can address traditional technique limitations and discuss the implications of concatenating texts with fused features. It would be beneficial to compare your method with OV3D and expand on the limitations, including technical challenges and failure cases. We also suggest including results on ScanNet++ and providing visual evidence of 2D and 3D masks in Figure 3. Lastly, please clarify the robustness of the Implicit 3D Captioner and the generalization capabilities of the text-to-image diffusion model across datasets.