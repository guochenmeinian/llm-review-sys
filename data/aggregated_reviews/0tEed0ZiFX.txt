ID: 0tEed0ZiFX
Title: Learning Semantic Role Labeling from Compatible Label Sequences
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper explores the joint output of PropBank (PB) and VerbNet (VN) labels for semantic role labeling (SRL) using a joint CRF model. The authors demonstrate that their approach outperforms a multi-task baseline, particularly on the out-of-domain Brown test set. Additionally, they investigate semi-supervised learning with PB-only data and the application of SemLink constraints during decoding to prevent conflicting argument labels. The results indicate that the proposed method achieves state-of-the-art performance, especially when gold standard PB labels are used.

### Strengths and Weaknesses
Strengths:
- The direction of the research is significant for unifying semantic resources.
- The paper is well-written, with comprehensive experiments and thorough analysis.
- The proposed approach facilitates mutual transformation between SRL data annotated under different standards.

Weaknesses:
- The experiments are limited to scenarios with abundant joint data, lacking exploration of low-resource cases.
- The performance improvements are marginal, and the writing could be clearer, particularly regarding SEMLINK and certain technical concepts.
- The reliance on gold predicate positions and attributes limits the model's practical applicability.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by providing more illustrative examples and better explanations of SEMLINK and related concepts. Additionally, exploring scenarios with less joint data and analyzing the impact of predicate frequency on performance would strengthen the paper. Finally, including standard deviation scores in the experimental results would enhance the statistical rigor of the findings.