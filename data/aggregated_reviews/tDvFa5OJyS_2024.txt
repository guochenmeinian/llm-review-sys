ID: tDvFa5OJyS
Title: Computation-Aware Gaussian Processes: Model Selection And Linear-Time Inference
Conference: NeurIPS
Year: 2024
Number of Reviews: 18
Original Ratings: 7, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an extension of the IterGP method by Wenger et al. (2022), focusing on computational uncertainty in Gaussian process regression models. The authors propose a new evidence lower bound (ELBO) for model selection and hyperparameter tuning, utilizing a sparse action matrix. They compare their approach against established methods like SVGP and SGPR across various datasets, demonstrating that IterGP-Opt achieves competitive performance. Additionally, the authors explore computation-aware methods in Gaussian processes, showing that the marginal variance decreases monotonically with increasing computational budget, leading to improved posterior precision. They clarify the interpretation of figures and equations, particularly regarding the behavior of SGPR and the implications of their experimental results, while addressing the calibration of confidence intervals and the memory complexities associated with different models.

### Strengths and Weaknesses
Strengths:  
- The work introduces a novel method for model selection and linear-time inference, contributing significantly to the Gaussian process community.  
- The exposition is clear, and the methodology is well-structured, making the paper accessible and enjoyable to read.  
- The authors provide a clear explanation of the monotonic behavior of marginal variance and precision.  
- They address reviewer concerns comprehensively, enhancing the clarity of figures and equations.  
- The inclusion of additional experiments comparing CGGP and IterGP-CG strengthens the paper's contributions.  

Weaknesses:  
- The evaluation of sparse variational methods raises concerns, particularly regarding GPyTorch's implementation, which may lead to instabilities.  
- Some figures, particularly Figure 2, lack clarity regarding the plotted data and its implications.  
- The paper lacks proper citations for datasets and does not adequately motivate the discussion on information gain.  
- The choice of optimizer and its impact on results could be better justified, as some reviewers noted discrepancies in performance metrics.  
- There is confusion regarding the status of IterGP-CG, which is presented as novel but is referenced as existing elsewhere.  
- The experimental comparisons with exact GPs are insufficient, particularly given the claims made about IterGP's performance.  
- The presentation of results for IterGP-CG could benefit from explicit comparisons to previous methods.  

### Suggestions for Improvement
We recommend that the authors improve the evaluation of sparse variational methods by addressing the numerical stability issues in GPyTorch, potentially by switching to float64 and full Cholesky decomposition. Additionally, consider using a second-order optimizer like L-BFGS-B for SGPR to enhance performance comparisons. We suggest improving the clarity of Figure 2 by providing a more detailed explanation of the plotted data and its significance. Clarifying the status of IterGP-CG in the paper is essential, as is ensuring proper citations for datasets. We also recommend a more thorough exploration of the relationship between ELBOs and hyperparameters in comparison to exact GPs, especially on smaller datasets. Furthermore, it would be beneficial to clarify the choice of optimizer and its parameters, ensuring that the rationale behind these decisions is well articulated in the manuscript. Lastly, including ELBOs/LML estimates alongside predictive metrics could provide a more comprehensive understanding of model performance.