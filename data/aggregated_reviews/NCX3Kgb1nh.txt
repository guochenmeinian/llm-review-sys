ID: NCX3Kgb1nh
Title: Multivariate Stochastic Dominance via Optimal Transport and Applications to Models Benchmarking
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 6, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 2, 1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework for estimating the degree of stochastic dominance between two multivariate distributions, inspired by the univariate case. The authors introduce a definition of near-stochastic dominance linked to optimal transport and enhance estimation through entropic regularization. Experimental results indicate that their metric correlates well with a "ground-truth" ranking in LLM evaluations, demonstrating its practical relevance.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and effectively connects its findings to prior research in univariate stochastic dominance and regularization methods.
- The proposed methods are timely and relevant, particularly for evaluating LLMs across multiple metrics.
- The application of the framework to both financial and LLM domains showcases its versatility.

Weaknesses:
- The experiments section lacks clarity, particularly regarding the approaches tested and the rationale behind the ground-truth ranking.
- Some parts of the writing are unclear, making the technical content harder to digest.
- The paper does not present Type I and II error rates for the hypothesis testing methodology, and the implications of increasing dimensions and sample sizes on these errors are unexplored.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the experiments section by providing detailed explanations of the various approaches tested and the reasoning behind the ground-truth ranking. Additionally, we suggest that the authors include Type I and II error rates in their results and investigate how these errors change with increasing sample size \(N\) and dimensionality \(d\). Furthermore, we encourage the authors to refine their writing throughout the paper to enhance readability, particularly in sections identified as unclear. Lastly, providing guidance on hyperparameter tuning and discussing the computational complexity of the proposed methods would strengthen the paper.