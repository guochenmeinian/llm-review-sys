ID: 3J5hvO5UaW
Title: Optimal Classification under Performative Distribution Shift
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 6, 5, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 4, 2, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the performative learning problem, aiming to minimize performative risk, defined as $PR(\theta) := \underset{\theta}{\mathbb{E}}[\ell(Z; \theta)]$, where $Z \sim \underset{\theta}{\mathbb{P}}$. The authors model the performative effect of model parameters $\theta$ as a pushforward measure under a differentiable, invertible mapping. Key results include a new expression for the performative gradient, the convexity of performative risk under specific assumptions, and a min-max reformulation connecting performative risk to adversarially robust classification. The paper also explores the implications of a shift operator on the performative effect, demonstrating scalability and a connection to robustness and regularization.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written, presenting assumptions and main theorems clearly, making it easy to follow.
2. It introduces a novel modeling approach for performative shifts as a pushforward measure, which appears innovative and flexible.
3. The proposed estimator for the performative gradient shows lower variance, enhancing practical utility, particularly in linear shift scenarios.

Weaknesses:
1. The generality of the performative effect is limited, as the paper does not adequately address how to identify or estimate the transformation function $\varphi_\theta$.
2. The reliance on linear shift assumptions may restrict the applicability of the findings, with unclear benefits in non-linear scenarios.
3. Some definitions and notations, such as "performative effect" and the "pound" symbol, lack clarity and formal definition, which could hinder understanding.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by explicitly defining the term "performative effect" in the introduction. Additionally, on Page 3, the authors should define the "pound" symbol and specify the density $p(\cdot)$ that $\mathbb{P}$ admits. In the Experiments section, we suggest clearly defining the "Reparametrization-based Performative Gradient (RPPerfGD)" algorithm and its relation to the gradient in Equation 3. Furthermore, we encourage the authors to explore a broader range of $\varphi_\theta$ in synthetic experiments to validate scalability and address the limitations of the linear shift assumption. Lastly, we recommend providing a more nuanced discussion regarding the practicality of knowing $\varphi$ versus $p_\theta$.