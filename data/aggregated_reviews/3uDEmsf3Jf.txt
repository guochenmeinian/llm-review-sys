ID: 3uDEmsf3Jf
Title: OASIS: Conditional Distribution Shaping for Offline Safe Reinforcement Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 6, 7, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 2, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the OASIS method, which addresses the safe dataset mismatch (SDM) problem in offline safe reinforcement learning (RL) by using a conditional diffusion model to reshape dataset distributions. The authors propose generating high-reward and safe samples to enhance offline safe RL algorithms. The paper includes extensive empirical evaluations across various safe RL tasks and datasets, demonstrating the effectiveness of the proposed approach.

### Strengths and Weaknesses
Strengths:
- The paper is well motivated, addressing the critical issue of biased data in offline safe RL, and the use of diffusion-based data generation is both intuitive and novel.
- Comprehensive empirical evaluations and ablation studies effectively illustrate the significance of the SDM problem and the proposed solution's effectiveness.
- Theoretical analysis provides guarantees regarding the approach's performance.
- The organization and clarity of the writing enhance comprehension.

Weaknesses:
- Some technical and experimental details are confusing, particularly regarding assumptions and dataset handling.
- Assumptions 1 and 2 appear idealized, as $\epsilon_{score}$ and $\epsilon_{inv}$ cannot be directly calculated or estimated, necessitating further discussion to justify these assumptions.
- The potential of directly excluding mismatched data from training datasets is not explored; a comparison between this approach and the proposed method would be beneficial.
- The computational heaviness of diffusion models may slow down data generation and training processes.
- Hyperparameter selection, such as the number of denoising steps, significantly impacts results, leading to inconsistencies.

### Suggestions for Improvement
We recommend that the authors improve clarity by providing more detailed explanations of the technical and experimental aspects, particularly regarding the assumptions made. Additionally, discussing the performance implications of directly excluding mismatched data from training datasets would enhance the paper's depth. We suggest conducting a study on hyperparameter changes to better understand the balance between conservative and risky actions in the proposed method. Finally, addressing the computational efficiency of the diffusion models and their impact on training time would strengthen the paper.