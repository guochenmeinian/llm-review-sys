ID: NNUMvNDknD
Title: Deep activity propagation via weight initialization in spiking neural networks
Conference: NeurIPS
Year: 2024
Number of Reviews: 2
Original Ratings: 7, 4
Original Confidences: 4, 5

Aggregated Review:
### Key Points
This paper presents a new weight initialization method for spiking neural networks (SNNs) that addresses the challenges of information loss during training due to the binary nature of spikes. The authors propose a method that regulates initialized weights based on the probability of neuron firing, which is shown to improve information propagation in deep SNNs compared to traditional artificial neural network (ANN) initialization methods. The experimental results indicate that the proposed method allows for efficient information propagation with reduced loss, particularly in deep SNNs with multiple time steps.

### Strengths and Weaknesses
Strengths:
- The proposed weight initialization method is innovative and tailored to the unique characteristics of SNNs, potentially enhancing their training and application.
- Experimental results demonstrate the effectiveness of the method in mitigating information loss in deep SNNs.

Weaknesses:
- The manuscript lacks a clear motivation for the proposed method and does not sufficiently compare it with existing SNN initialization techniques.
- The results section is underdeveloped, with insufficient detail on experimental settings and performance comparisons.
- The theoretical derivation does not address variations in input distribution, and the implications of using a threshold of 1 are not justified.

### Suggestions for Improvement
We recommend that the authors improve the clarity and depth of the results section by providing detailed settings for the SNNs used in experiments, including time steps and the calculation of P(u > Î¸). Additionally, please explain the rationale behind choosing T=3 and discuss the performance in conventional cases. We suggest adding tables to summarize performance metrics for clearer comparisons, particularly in the MNIST experiments.

Furthermore, we encourage the authors to elaborate on the theoretical implications of their approach, especially regarding the extension to multiple time steps and the biological plausibility of their model. It would be beneficial to include comparisons with other existing SNN initialization methods to substantiate the advantages of the proposed method. Lastly, we advise addressing minor issues such as improving the readability of figures and ensuring consistent labeling throughout the manuscript.