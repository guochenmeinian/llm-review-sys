ID: A68W11vA8o
Title: Skill-Based Few-Shot Selection for In-Context Learning
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a prompting-based rewriting method, "SKILL-KNN," aimed at enhancing few-shot in-context sample selection for semantic parsing tasks. The authors propose a skill-based selection method that utilizes the capabilities of large language models (LLMs) to generate skill-based representations from limited annotated instances. The method is designed to alleviate LLMsâ€™ sensitivities to the order of in-context samples and is supported by experimental results demonstrating its effectiveness compared to existing methods.

### Strengths and Weaknesses
Strengths:
- The proposed solutions for few-shot in-context sample selection are interesting and well-analyzed.
- The writing is clear, and the introduction is detailed.
- The method does not require training or fine-tuning, making it adaptable to changing example banks.

Weaknesses:
- The use of the "Database Schema" column in Table 1 is unclear.
- The motivation behind the two variants in sample similarity measurement lacks clarity, and the experimental scenarios where one variant outperforms the other are not well-explained.
- The reliance on manually annotated skill-based representations may hinder transferability to other domains.
- Some terminology may confuse the audience, such as the distinction between embedding models and skill-based representations.

### Suggestions for Improvement
We recommend that the authors clarify the purpose of the "Database Schema" column in Table 1. Additionally, we suggest providing more detailed explanations regarding the number of times the demonstration order should be altered for generating candidates and conducting ablation studies. The authors should also elucidate the motivation for the two variants in sample similarity measurement and present experimental analysis to highlight their comparative advantages. Furthermore, we encourage the authors to address the potential biases of their embedding methods and discuss the cognitive load involved in generating skill-based representations from manually annotated demonstrations. Finally, incorporating additional discussions or experiments from the rebuttal phase would strengthen the original work.