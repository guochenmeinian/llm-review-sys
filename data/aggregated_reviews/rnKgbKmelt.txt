ID: rnKgbKmelt
Title: AdaPlanner: Adaptive Planning from Feedback with Language Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 7, 6, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents AdaPlanner, a closed-loop LLM planner designed for adaptive planning in text-based sequential decision-making tasks. The authors propose that AdaPlanner refines its plans based on environmental feedback, leveraging code-style prompts and a skill-discovery mechanism. The method demonstrates superior performance compared to existing approaches, achieving state-of-the-art results in environments like ALFWorld and MiniWoB++. 

### Strengths and Weaknesses
Strengths:
- The authors empirically demonstrate strong results regarding sample efficiency and performance.
- Numerous ablation studies clarify the contributions of various model components.
- The approach is conceptually straightforward and well-articulated.

Weaknesses:
- The evaluation section inadequately addresses baseline comparisons, making it difficult to discern differences between AdaPlanner and existing methods.
- The term ‘hallucination’ is frequently used without definition.
- The discussion on in- and out-of-plan refiners lacks early intuitive examples.
- DEPS is a relevant baseline that is not sufficiently explored.
- The significant contributions of code-style prompts and skill prompts to AdaPlanner's success warrant further exploration in existing methods.
- The importance of prompting the LLM to correct syntax errors is not sufficiently ablated.

### Suggestions for Improvement
We recommend that the authors improve the evaluation section by providing clearer comparisons with baselines and incorporating relevant Appendix descriptions. Defining the term ‘hallucination’ early in the paper would enhance clarity. Additionally, including more intuitive examples for in- and out-of-plan refiners earlier in the text would be beneficial. We suggest that the authors analyze DEPS in more depth and consider applying code-style prompts to existing approaches for comparative analysis. Furthermore, including an ablation study on the significance of syntax error correction would provide valuable insights.