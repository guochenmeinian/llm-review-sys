ID: QIBpzaDCAv
Title: Lossy Image Compression with Conditional Diffusion Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 6, 6, 5, 5, 5, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 4, 5, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel architecture for lossy image compression using conditional diffusion models, integrating an encoder that maps images into contextual latent variables and a decoder that employs a conditional diffusion model. The authors introduce a perceptual loss to balance distortion, rate, and perceptual quality, allowing for flexible adjustments through parameter tuning. Extensive experiments are conducted to analyze the influence of parameters on performance and to compare results with existing methods.

### Strengths and Weaknesses
Strengths:
1. The architecture leveraging conditional diffusion models is innovative, demonstrating effective reverse processing in a limited number of steps.
2. Comprehensive experiments are performed, comparing sixteen metrics and examining the effects of parameters like ρ, γ, and decoding steps on performance.
3. Results indicate that the method effectively manages the tradeoff between distortion, rate, and perceptual quality, achieving competitive performance across various metrics.

Weaknesses:
1. Implementation details are insufficiently clarified, particularly regarding the "17 steps" in the reverse process, which could enhance understanding of encoding and decoding costs.
2. Additional qualitative and quantitative results, including diverse image resolutions and styles, would strengthen claims about performance and practicality.
3. Specifics on diffusion model parameters, such as total steps and schedule type, are lacking, which are crucial for understanding decoding steps.
4. Formula (7) appears to only represent the case of γ=0, suggesting the need for additional random noise when γ>0.

### Suggestions for Improvement
We recommend that the authors improve the clarity of implementation details, particularly regarding the "17 steps" of the reverse process, and consider including visual representations of each step to illustrate texture reconstruction. More qualitative and quantitative results should be provided to substantiate the method's performance across various image styles and resolutions. Additionally, the authors should specify diffusion model parameters, including total steps and schedule type, to enhance reproducibility. Finally, we suggest revisiting Formula (7) to account for the inclusion of random noise when γ>0, ensuring a comprehensive understanding of the model's behavior.