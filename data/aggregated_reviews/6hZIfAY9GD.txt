ID: 6hZIfAY9GD
Title: Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias
Conference: NeurIPS
Year: 2023
Number of Reviews: 18
Original Ratings: 7, 6, 7, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the use of large language models (LLMs) as training data generators, specifically focusing on the impact of diversely attributed prompts on data generation. The authors propose that these attributed prompts can reduce bias and enhance diversity in generated datasets compared to simple class-conditional prompts. Empirical results across multiple datasets demonstrate that attributed prompts lead to improved model performance and sample efficiency. The authors discuss the selection of attributes, emphasizing the need for diversity and bias reduction while acknowledging dataset-specific considerations. They propose a balanced number of attributes to enhance dataset diversity without overwhelming combinations. The paper also clarifies the use of BERT series models for classification and the rationale behind not using LLM in-context learning for high-cardinality tasks. Additional experiments with T5-Large and LLaMA-2 models demonstrate the effectiveness of their approach. Furthermore, the authors introduce a baseline, *MetaPrompt*, which optimizes input prompts using an LLM, showing that while it improves performance, it does not address the limited diversity issue in training data generation, leading to *AttrPrompt* outperforming it by an average of 5.65% across four datasets.

### Strengths and Weaknesses
Strengths:
- The paper applies the LLM-as-training-data-generator paradigm to high-cardinality datasets, marking a novel contribution to multi-label classification tasks.
- The incorporation of attributes into prompts is a novel approach that enhances data generation.
- The authors provide substantial evidence of high agreement among human raters for attribute selection, indicating reliability.
- Comprehensive empirical studies provide insights into the performance and efficiency of attributed prompts, and the inclusion of new baselines and performance comparisons strengthens the empirical foundation of the study.

Weaknesses:
- The findings are primarily based on classification datasets with limited model scales, potentially limiting generalizability to larger models and other task types.
- The reliance on BERT series models may limit the exploration of more recent state-of-the-art LLMs.
- The evaluation primarily focuses on ChatGPT, which may not fully represent the method's efficacy across different models.
- There is insufficient focus on bias mitigation strategies for synthetic datasets generated by simple prompts, and the potential for human bias in attribute selection remains a concern, despite efforts to mitigate it.
- Despite improvements, the paper does not fully address the diversity issue in training data generation, which remains a significant challenge.

### Suggestions for Improvement
We recommend that the authors improve the integration of the accompanying code into standard APIs to enhance usability. Additionally, optimizing the attribute configuration for better downstream performance would be beneficial. It would also be advantageous to conduct more comprehensive experiments using a wider variety of LLMs, including state-of-the-art models like LLaMA or GPT, and to demonstrate the efficacy of their method on additional LLMs beyond ChatGPT. Furthermore, we suggest conducting a data quality analysis independent of downstream task performance, incorporating more diverse metrics, and exploring various prompting techniques while adding more baselines in the evaluation section to enhance the robustness of their findings. Lastly, addressing the documentation issues, such as the non-functional appendix links, and providing a more comprehensive discussion on the limited diversity issue in training data generation could strengthen the manuscript.