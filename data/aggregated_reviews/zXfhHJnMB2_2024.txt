ID: zXfhHJnMB2
Title: Neural Conditional Probability for Uncertainty Quantification
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 7, 7, 7, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 1, 3, 2, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Neural Conditional Probability (NCP), a novel operator-theoretic approach for learning conditional probability distributions. The authors provide extensive theoretical results supporting the optimization consistency and statistical accuracy of NCP, which can extract conditional density and compute statistical measures like conditional mean, variance, moments, and CDF post-training. Experiments on conditional density estimation datasets demonstrate NCP's efficacy. However, the empirical evaluations are limited to low-dimensional toy problems, raising concerns about the method's applicability to more complex datasets.

### Strengths and Weaknesses
Strengths:
- The paper is mathematically solid and well-organized, with a rigorous mathematical derivation and sound motivation for the proposed method.
- NCP addresses a fundamental problem in statistical learning and introduces an effective, simplistic approach that outperforms more complex baselines.
- The introduction is accessible and well-motivated, and the theoretical analysis on statistical properties is thorough.

Weaknesses:
- The motivation for the NCP method is unclear, particularly in its contrast with existing approaches. Key concepts, such as the utility of learning the conditional expectation operator, are not well-explained.
- Empirical evaluations are limited to synthetic data, which does not adequately demonstrate the method's potential in real-world applications. The Related Work section fails to embed the current paper within the research landscape, lacking precise comparisons with referenced methods.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation for NCP by elaborating on its differences from existing methods and providing intuitive explanations alongside theoretical analysis. Additionally, we suggest enhancing the empirical evaluations to include high-dimensional tasks that cannot be solved by state-of-the-art methods, thereby addressing the limitations of the current experiments. A dedicated **Limitations** section in the conclusion would also provide a compact overview for readers. Furthermore, please fix the citations throughout the manuscript and consider adding a summary of the main properties of operators and their SVD decompositions to improve readability.