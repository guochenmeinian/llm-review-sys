ID: JV8Ff0lgVV
Title: DIFUSCO: Graph-based Diffusion Solvers for Combinatorial Optimization
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 7, 8, 6, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DIFUSCO, a novel graph-based diffusion model designed for solving NP-complete combinatorial optimization problems. The authors propose two variants of the model: one utilizing continuous Gaussian noise and another employing discrete Bernoulli noise. Extensive experiments on the Traveling Salesman Problem (TSP) and Maximal Independent Set (MIS) demonstrate that the discrete diffusion model significantly outperforms the continuous variant, achieving state-of-the-art results in terms of accuracy and scalability. The methodology involves generating a probability distribution over the solution space and training the model in a supervised manner to maximize the likelihood of high-quality solutions.

### Strengths and Weaknesses
Strengths:
- Novelty: The introduction of a graph-based diffusion model for NP-complete problems represents a significant advancement in the field.
- Performance: DIFUSCO outperforms existing state-of-the-art methods on TSP and MIS, showcasing good scalability and generalization across problem sizes.
- Thorough Experiments: Comprehensive experiments validate the model's performance and robustness across different configurations.

Weaknesses:
- Limited Scope: The focus on TSP and MIS raises questions about the model's effectiveness on other NP-complete problems.
- Dependency on Post-Processing: The model's performance heavily relies on 2-opt local search post-processing, complicating the assessment of its standalone effectiveness.
- Complexity: The intricate nature of the model and its components may hinder practical implementation and understanding.
- Lack of Generalizability: The model's performance on various graph types, particularly ER graphs, is underexplored.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the model's performance across a broader range of NP-complete problems to establish its generalizability. Additionally, we suggest providing more detailed insights into the model's performance without post-processing to clarify its inherent capabilities. Addressing the dependency on external solvers for generating training instances could enhance the model's applicability. Furthermore, we encourage the authors to elaborate on the inductive bias of their architecture concerning ER graphs and explore potential modifications to improve performance in this context. Lastly, a more thorough analysis of hyperparameter sensitivity would be beneficial for practitioners.