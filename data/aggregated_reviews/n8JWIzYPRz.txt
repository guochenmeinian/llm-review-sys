ID: n8JWIzYPRz
Title: Environment-Aware Dynamic Graph Learning for Out-of-Distribution Generalization
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 4, 7, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents EAGLE, a framework aimed at enhancing out-of-distribution (OOD) generalization in dynamic graphs by modeling complex environments and identifying spatio-temporal invariant patterns. EAGLE incorporates an environment-aware model, an environment instantiation mechanism, and an invariant pattern recognition mechanism. The authors claim that EAGLE outperforms existing methods across various dynamic graph datasets, marking a novel approach to OOD generalization from an environment learning perspective. Additionally, the authors introduce a warm-up mechanism for selecting the hyperparameter $K$, which reflects the number of underlying environments in dynamic graphs. They argue that tuning $K$ on the validation set during the first 10 epochs is effective, as empirical results show that model performance stabilizes and aligns with final results. While the warm-up mechanism enhances training efficiency, it is noted that this is not the primary contribution of the paper.

### Strengths and Weaknesses
Strengths:  
1. The problem addressed is significant, focusing on OOD generalization in dynamic graphs.  
2. The authors conducted extensive experiments, demonstrating the effectiveness of their approach.  
3. The Environment “Modeling-Inferring-Discriminating-Generalizing” paradigm is innovative and technically sound.  
4. The paper is well-organized, with clear derivations and proofs supporting the proposed method.  
5. The empirical results effectively demonstrate the relationship between $K$ and model performance, validating the warm-up mechanism's effectiveness.  
6. The authors show a willingness to improve their methodology based on reviewer feedback.

Weaknesses:  
1. The definition of 'environment' is unclear, particularly regarding its correlation with time and its determination as a dataset feature or hyperparameter.  
2. The notation used is confusing, hindering comprehension of theoretical proofs.  
3. There is insufficient explanation of Propositions 1 and 2, which could benefit from more context.  
4. Several statements in the paper are inaccurate or overly broad, lacking acknowledgment of existing literature.  
5. The computational complexity of the proposed method is not adequately discussed.  
6. The warm-up mechanism for selecting $K$ is not fully convincing, as its impact on model performance remains significant but underexplored.  
7. The authors do not consider the warm-up mechanism a main contribution, which may undermine its perceived importance.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the definition of 'environment', particularly its relationship with time and the dataset. Additionally, the authors should clarify whether the environment number $K$ is a hyperparameter or derived from the dataset. We suggest revising the notation for better readability and providing more detailed explanations for Propositions 1 and 2. Furthermore, we encourage the authors to correct any inaccuracies in their claims and to include a discussion on computational complexity in the main text. We also recommend that the authors improve the mechanism for selecting the appropriate $K$ for different datasets to enhance the robustness of their approach. Further exploration of advanced methods for determining $K$ could strengthen the paper's contributions.