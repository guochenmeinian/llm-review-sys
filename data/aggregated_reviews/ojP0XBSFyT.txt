ID: ojP0XBSFyT
Title: Identifying and Addressing Delusions for Target-Directed Decision Making
Conference: NeurIPS
Year: 2024
Number of Reviews: 4
Original Ratings: 10, 4, 7, 2
Original Confidences: 4, 4, 3, 3

Aggregated Review:
### Key Points
This paper presents a study on delusions in target-directed reinforcement learning (RL) agents, where agents hold false beliefs about targets leading to undesirable behaviors, particularly in out-of-distribution (OOD) scenarios. The authors propose strategies to mitigate these delusions, focusing on the roles of generator and estimator components, and utilize hindsight relabeling techniques to enhance training. Empirical validation shows significant reductions in delusional behaviors and improvements in OOD generalization.

### Strengths and Weaknesses
Strengths:
1. The paper systematically identifies and addresses delusional behaviors in target-directed RL agents, providing a structured framework for analysis.
2. Empirical results demonstrate significant improvements in OOD generalization performance, underscoring the practical impact of the proposed approach.
3. A solid theoretical foundation links psychological concepts of delusions to RL, offering a unique perspective on false beliefs in agents.
4. The introduction of hybrid strategies combining different hindsight relabeling techniques presents a flexible approach to balancing generator and estimator needs.
5. The focus on OOD generalization is highly relevant, addressing a major challenge in deploying RL agents in real-world scenarios.
6. The proposed strategies, such as "generate" and "pertask," are broadly applicable across various RL methods and environments.
7. The paper is well-written with a clear problem definition.

Weaknesses:
1. The complexity of implementing hybrid strategies may introduce computational overhead, potentially limiting feasibility for large-scale or real-time applications.
2. There is a lack of detailed analysis regarding the computational costs associated with the proposed strategies.
3. The effectiveness of the "generate" strategy is heavily reliant on the generator's quality, which could diminish benefits if non-viable targets are produced.
4. The choice of a simple toy environment (SSM) limits the compelling nature of the findings, as the problem may not be as challenging in more complex settings.
5. The paper lacks baselines from previous target-directed RL studies, and the similarity of experimental environments raises questions about the method's effectiveness in more complex scenarios.
6. The paper exceeds the specified page limits, which is unfair to other authors adhering to guidelines.

### Suggestions for Improvement
We recommend that the authors improve the analysis of computational costs associated with the proposed strategies to provide clearer insights into their feasibility. Additionally, we encourage the authors to explore more complex environments beyond the toy problem of SSM to validate their methods in challenging scenarios. Furthermore, including baselines from previous target-directed RL work would strengthen the paper's contributions. Lastly, the authors should adhere to the specified page limits to ensure fairness in the submission process.