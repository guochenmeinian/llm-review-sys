ID: HlIAoCHDWW
Title: Learning in the Presence of Low-dimensional Structure: A Spiked Random Matrix Perspective
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 6, 6, 6, 5, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an exploration of high-dimensional regression using a theoretical approach, focusing on a single-index model where the output depends on a one-dimensional projection of the input in a specific direction, $\mu$. The authors investigate spiked covariance data with Gaussian input, examining kernel methods and one hidden-layer neural networks in an asymptotic framework where dimension $d$, sample size $n$, and variance of the spike approach infinity. The key theoretical findings suggest that neural networks efficiently learn high-degree components when low-degree components are present, while kernel methods struggle under similar conditions. These results are supported by numerical simulations, indicating strong agreement with the theory.

### Strengths and Weaknesses
Strengths:
- The manuscript is well-articulated, providing transparent results and insights into the limitations of neural networks and kernel methods.
- The paper is clear and easy to follow, with strong technical contributions and rigorous theoretical results.

Weaknesses:
- The authors should justify why the considered model is superior to previous models and identify datasets that exhibit a single-index model with spiked covariance data.
- There is a lack of comparison regarding the novelty of the analyses compared to related works, particularly [GMMM20].
- The appendix contains numerous typos and inaccuracies, raising questions about the originality and accuracy of the proofs.

### Suggestions for Improvement
We recommend that the authors improve the justification for the single-index model and provide examples of datasets that fit this model. Additionally, clarify the novelty of the analyses compared to [GMMM20], particularly regarding the challenges of the single-index case versus multi-index scenarios. To enhance clarity, we suggest addressing the numerous typos and inaccuracies in the appendix and ensuring the originality of the proof techniques. Furthermore, consider including experiments with plain GD/SGD to explore the implications of the findings in a broader context.