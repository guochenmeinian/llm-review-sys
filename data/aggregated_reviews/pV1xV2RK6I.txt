ID: pV1xV2RK6I
Title: ToolQA: A Dataset for LLM Question Answering with External Tools
Conference: NeurIPS
Year: 2023
Number of Reviews: 21
Original Ratings: 6, 9, 7, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ToolQA, a dataset designed to evaluate the external tool use capabilities of large language models (LLMs) in answering questions. The authors clarify that "external tool use" involves LLMs accessing external APIs for information beyond their pre-trained knowledge, thereby enhancing both memorization and reasoning. ToolQA includes 13 specialized tools and employs a semi-automated process for generating diverse and challenging questions through human-LLM collaboration. Experimental results indicate that tool-augmented LLMs, such as ReAct and Chameleon, outperform standard models like ChatGPT, which struggles with low success rates on the benchmark. However, the dataset has been critiqued for limited question diversity and natural language applicability.

### Strengths and Weaknesses
**Strengths:**
- The study addresses a significant gap in evaluating LLMs' tool-use capabilities and provides a scalable and automated dataset creation process.
- ToolQA's design minimizes overlap with LLMs' pre-training data, enhancing the accuracy of evaluations.
- The dataset is curated from real-world data, ensuring relevance and practical application, and incorporates complex questions to challenge LLMs' reasoning abilities.
- Detailed performance analysis reveals the effectiveness of the dataset as a challenging benchmark for LLMs.

**Weaknesses:**
- The evaluation lacks a formal description of the normalization process for ground-truth answers and model predictions, which is crucial for success rate calculations.
- The diversity of questions in the dataset is perceived as insufficient, lacking natural language representation and variety in templates.
- All tested methods rely on black-box product APIs, raising concerns about reproducibility and transparency in findings.
- The justification for the diversity and challenge of questions generated by ChatGPT lacks convincing evidence, and the reliance on closed APIs for baselines may lead to reproducibility issues due to changing behaviors over time.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the normalization process for evaluation metrics, as this is essential for the reliability of success rates. Additionally, we suggest formalizing the normalization methods used for ground-truth answers and model predictions in the paper or supplementary material. To enhance the study's impact and accessibility for the research community, we recommend incorporating at least one or two open-sourced LLMs as baselines. Expanding the variety of tools and introducing more complex reasoning challenges in ToolQA would further strengthen the dataset. We also encourage the authors to improve the diversity of questions by incorporating a wider range of natural language queries and templates. Lastly, we recommend exploring the integration of real-world, up-to-date external data sources to increase the dataset's relevance and challenge LLMs' interaction with dynamic information.