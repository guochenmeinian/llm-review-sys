ID: 61YYSy078Z
Title: ECLipsE: Efficient Compositional Lipschitz Constant Estimation for Deep Neural Networks
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 6, 6, 6, 7, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents two novel algorithms, ECLipsE and ECLipsE-Fast, for estimating the Lipschitz constant of feedforward neural networks. The authors build upon the LipSDP framework, proposing a decomposition of the large matrix verification problem into smaller subproblems, which enhances computational efficiency. The algorithms demonstrate significant reductions in computation time while maintaining competitive accuracy compared to existing methods. Theoretical analyses support the validity of the proposed methods, and extensive experiments validate their performance on neural networks trained on MNIST.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, clearly articulating the motivation and significance of the research problem.
- The decomposition theory and the proposed algorithms are novel, providing a significant improvement in efficiency over existing methods.
- The experimental results show a steep reduction in computation time while yielding Lipschitz bounds comparable to state-of-the-art approaches.

Weaknesses:
- The theoretical results in Section 3.3 lack a clear summary of the main results and guarantees, which would enhance clarity regarding the provably correct upper bounds.
- The comparison with existing literature is limited, primarily focusing on SDP methods, which restricts the contextual understanding of the contributions.
- The approach is restricted to feedforward neural networks, limiting its applicability to other architectures like convolutional networks.
- Some parts of the methodology could be better organized for improved clarity and understanding.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the theoretical results in Section 3.3 by providing a concise summary of the main results and guarantees. Additionally, a broader comparison with other methods aimed at improving the scalability of LipSDP would enhance the contextual relevance of the work. We suggest including experiments with trained networks to demonstrate the algorithms' performance in more realistic scenarios. Furthermore, addressing the limitations regarding network width and providing a clearer organization of the methodology would benefit the overall presentation of the paper.