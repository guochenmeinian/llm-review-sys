ID: nuLtpgr9l5
Title: Disfluent Cues for Enhanced Speech Understanding in Large Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an exploration of the effect of disfluent input on a Q&A task using various models (ALBERT, BERT-QA, T5-QA, GPT-3.5, and GPT-4). The authors utilize the DISFL dataset, annotating disfluencies into seven categories, including D-repairs, A-repairs, and E-repairs. The results indicate that while models adapt well to A and E disfluencies, they struggle with D-repairs, even with extensive fine-tuning. The authors argue for training models on disfluent input to enhance robustness. However, the paper lacks a clear discussion on how model interpretation of disfluencies compares to human understanding and is limited to English.

### Strengths and Weaknesses
Strengths:
- The paper evaluates the robustness of language models to disfluent input in a Q&A context, making a significant contribution by identifying model sensitivity to different disfluency types.
- It introduces a new tagging system for the DISFL-QA dataset, providing a fine-grained analysis of disfluencies.

Weaknesses:
- The paper relies on synthetic disfluencies, which may not accurately represent natural speech patterns.
- It lacks a thorough discussion on the alignment of model interpretation of disfluencies with human understanding.
- The results are primarily presented in figures, making it difficult to extract exact F-score values.
- The authors did not anonymize their paper as required during submission.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the training/testing scheme and specify which experiments involve full training versus fine-tuning. Additionally, integrating zero-shot results for T5 in Figure 1 would facilitate comparisons. The authors should enhance the accessibility of figures for color-blind readers by using distinct markers and line types. It is also crucial to provide a detailed explanation of statistical tests used and to include references for claims regarding disfluencies in existing literature. Finally, we suggest incorporating natural disfluencies from datasets like CallHome or Switchboard to enhance the generalizability of findings.