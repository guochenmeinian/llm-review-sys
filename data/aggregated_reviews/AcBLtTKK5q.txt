ID: AcBLtTKK5q
Title: Jailbreaking Large Language Models Against Moderation Guardrails via Cipher Characters
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 8, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents JAMBench, a benchmark designed to evaluate OpenAI's moderation guardrails using 160 manually crafted questions across categories such as hate, sexual content, violence, and self-harm, categorized by severity. The authors propose JAM (Jailbreak Against Moderation), a method utilizing cipher characters to bypass these guardrails by manipulating harm scores. The study demonstrates JAM's effectiveness across various large language models (LLMs) and suggests potential countermeasures to enhance moderation strategies, aiming to improve the safety of LLM applications.

### Strengths and Weaknesses
Strengths:  
1. The paper addresses an important issue, revealing that even with moderation defenses, LLMs can still be exploited, which is critical for enhancing the safety of closed-source models like ChatGPT.  
2. The proposed methods for jailbreak and defense are reasonable.  
3. The experimental results are solid and promising.  
4. The writing quality of the paper is commendable.  

Weaknesses:  
1. The necessity and rationale behind the construction of JAMBench are questionable, as it relies solely on manually annotated test samples, which may not adequately reflect the diversity needed for effective evaluation.  
2. The optimization of cipher characters requires careful consideration of training and test samples to ensure generalization, as the authors need to demonstrate that improvements are due to the optimized cipher characters rather than other factors.  
3. The perplexity of JAM is significantly higher than many baselines, making it more susceptible to perplexity filters.  

### Suggestions for Improvement
We recommend that the authors improve the justification for JAMBench's construction by exploring the necessity of using existing benchmark datasets to identify data that triggers moderation guardrails. Additionally, the authors should consider a broader range of moderation guardrail methods to enhance the robustness of their findings. Finally, we suggest verifying the generalization of the optimization process by ensuring that training and test samples are distinct, thereby strengthening the validity of their results.