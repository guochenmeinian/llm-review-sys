ID: 2ep5PXEZiw
Title: Foundation Model is Efficient Multimodal Multitask Model Selector
Conference: NeurIPS
Year: 2023
Number of Reviews: 20
Original Ratings: 6, 5, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Efficient Multi-task Model Selector (EMMS), which utilizes large-scale foundation models to convert diverse label formats into unified noisy label embeddings. The authors propose a method to estimate the transferability of pre-trained neural networks on multi-modal tasks without fine-tuning, employing weighted linear regression and an alternating minimization algorithm. The experiments demonstrate EMMS's effectiveness and efficiency across five downstream tasks and 24 datasets, achieving significant performance gains and speedups compared to existing methods.

### Strengths and Weaknesses
Strengths:
1. The motivation for addressing a unified representation of diverse label formats is clearly articulated and validated, showcasing the use of foundation models effectively.
2. The paper provides comprehensive derivations and experiments, offering strong evidence for the validity of the proposed model.
3. The proposed method is intuitive, with clear algorithms, and extensive experimentation demonstrates superior performance in estimating transferability.

Weaknesses:
1. The paper lacks a complete demo in the code repository, providing only a short Python file.
2. There is ambiguity regarding the performance variability of EMMS compared to LogME, particularly in instances where EMMS is faster in some cases and slower in others.
3. The effect of the F-label on transferability assessment is unclear, as EMMS and EMMS(one) show identical performance in some instances.
4. The choice of evaluation metric, weighted Kendall's Ï„_w, may not effectively capture the actual performance differences, focusing instead on relative orders.

### Suggestions for Improvement
We recommend that the authors improve the code repository by including a complete demo to facilitate reproducibility. Additionally, clarifying the reasons behind the performance variability of EMMS compared to LogME would enhance understanding. The authors should also address the ambiguity surrounding the F-label's impact on transferability assessment and consider providing a broader array of foundational models for F-label evaluation. Lastly, we suggest exploring alternative evaluation metrics that could directly estimate actual performance rather than relying solely on relative rankings.