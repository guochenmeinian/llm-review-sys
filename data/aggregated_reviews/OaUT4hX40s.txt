ID: OaUT4hX40s
Title: The Gain from Ordering in Online Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 7, 5, 6, 6, -1, -1, -1, -1
Original Confidences: 4, 1, 2, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on self-directed online learning, focusing on the problem of ordering examples to minimize regret. The authors analyze realizable linear regression and ReLU regression under square loss, specifically assessing the ratio between the best achievable regret with random order and that with a self-directed order, termed as the 'Gain'. The main contributions include demonstrating that no polynomial time algorithm can achieve a Gain of order $d^{-1/\log\log^c d}$ under adversarial conditions, while a computationally efficient algorithm can achieve a Gain of order $1/\log d$ when examples are uniformly sampled. Additionally, absolute lower bounds for computationally efficient Gains are established for both Linear and ReLU regression.

### Strengths and Weaknesses
Strengths:  
The paper's primary strength lies in its unique presentation of hardness results regarding the efficiently achievable Gain in self-directed online learning, marking it as a pioneering work in this area. The reduction used in the proofs is intriguing and may be applicable to other learning theoretical problems. The incorporation of geometric concepts to establish the Gain in random examples is also noteworthy.

Weaknesses:  
The significance of the results is questionable from a learning theoretical perspective, as efficient algorithms for linear regression already exist. The complexity of the Gain, being a ratio of ratios, complicates its interpretation. Furthermore, clarity could be improved in Section 4 by directly stating the results for the worst-case $w^*$ rather than as a remark. The reliance on spherical data for algorithm design may limit practical applicability, and the absence of experimental results or code diminishes the paper's impact.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Section 4 by explicitly stating the results for the worst-case $w^*$. Additionally, addressing the applicability of the algorithms under the spherical data assumption in more practical scenarios would enhance the paper's relevance. Including experimental results or code for the proposed algorithms would provide valuable insights into their performance. Lastly, we suggest improving the proof sketches in the final version by adding more detail to enhance understanding.