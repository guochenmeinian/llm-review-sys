ID: Zlm7F7g9FK
Title: NLI4CT: Multi-Evidence Natural Language Inference for Clinical Trial Reports
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel binary biomedical NLI benchmark, NLI4CT, focusing on clinical trial reports (CTRs) related to breast cancer. It introduces an evidence retrieval task to support predicted relations (entailment or contradiction) and divides each CTR into four sections, with expert-written hypotheses. The authors provide a corpus of 2400 expert-annotated instances and several baselines for model evaluation, highlighting the limitations of existing NLI models, particularly in numerical reasoning.

### Strengths and Weaknesses
Strengths:
- The paper proposes a valuable NLI dataset and evidence selection task, enhancing transparency and explainability in predictions.
- It is well-structured and easy to follow, with ample examples and detailed explanations.
- The NLI4CT resource allows for fine-grained analysis, addressing challenges in biomedical NLI and numerical reasoning.
- Public access to the corpus, leaderboard, and code fosters collaboration and future research.

Weaknesses:
- The paper lacks performance evaluations of recent biomedical models, such as PubMedBERT and BioLinkBERT.
- The corpus compilation and annotation process is inadequately described, raising concerns about potential biases and limitations.
- The evaluation does not include an interventional study to verify the models' understanding of causal structures.
- The dataset contains fewer instances than other published biomedical NLI datasets.

### Suggestions for Improvement
We recommend that the authors improve the description of the corpus compilation and annotation process, addressing potential biases and limitations. Additionally, the authors should include performance evaluations of recent best-performing biomedical models, such as PubMedBERT and BioLinkBERT. It would also be beneficial to conduct an interventional study to verify if the models learn the underlying causal structures of the tasks. Lastly, we suggest including references to similar resources on CTR in other languages to enhance the literature review.