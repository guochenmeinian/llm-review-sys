ID: xutrKezbPF
Title: CIFD: Controlled Information Flow to Enhance Knowledge Distillation
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 5, 5, 5, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel knowledge distillation method, CIFD, based on Shannonâ€™s Rate-Distortion theory and the Information Bottleneck Principle (IBP). The authors propose two modules: Rate-Distortion Modules (RDM) for the teacher and Information Bottleneck Module (IBM) for the student, aiming to replace traditional Teacher Assistants (TAs) and improve performance across various datasets. The effectiveness of the method is demonstrated through extensive experiments.

### Strengths and Weaknesses
Strengths:
1. The paper is well-organized and easy to understand.
2. The proposed method shows effectiveness not only for traditional CNNs but also for modern CLIP models.
3. The introduction of multiple RDMs is more efficient in terms of parameter quantity compared to independent Assistant models.

Weaknesses:
1. The motivation for TA distillation lacks convincing justification; the proposed RDM and IBM can be seen as similar to existing adapter methods.
2. There are discrepancies in baseline performance between reported tables and the original text, raising concerns about fairness in comparisons.
3. The selection of hyperparameter R varies significantly across datasets, complicating parameter tuning and potentially increasing computational costs.
4. The paper does not adequately address the implications of including the IBM module during validation, which may skew performance comparisons.

### Suggestions for Improvement
We recommend that the authors improve the motivation and explanation for TA distillation to clarify its novelty. Additionally, we suggest including comparisons with recent state-of-the-art methods such as MLKD, CTKD, and LSKD to strengthen the paper's contribution. It would also be beneficial to clarify the formula representation in Eq. 5 and ensure that the hyperparameter R is discussed in more detail, particularly its impact on performance across different datasets. Finally, we encourage the authors to move the discussion of IBP and MIM back to the main paper and provide more systematic experiments to validate the efficacy of CIFD under varying teacher-student parameter scales.