ID: m1YYAQjO3w
Title: AgentDojo: A Dynamic Environment to Evaluate Prompt Injection Attacks and Defenses for LLM Agents
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 7, 6, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents AgentGym, a dynamic test suite designed to benchmark the performance of LLM agents in real-world scenarios, including tasks like navigating banking websites and managing calendars. The authors analyze adversarial prompt injection attacks and defenses within AgentGym, providing insights into the effectiveness of these attacks on various LLMs. The framework is notable for its extensibility, allowing for the incorporation of new tasks and defenses as research evolves.

### Strengths and Weaknesses
Strengths:
- AgentGym is a valuable contribution, offering an agentic benchmark to assess LLM efficacy in task completion and security against prompt injection attacks.
- The framework's extensibility facilitates the addition of new tasks and defenses, promoting ongoing research.
- The focus on multi-turn tool-calling highlights necessary improvements for LLMs to function effectively as agents.
- The evaluation includes a comprehensive set of tasks and security test cases, enhancing the understanding of LLM vulnerabilities.

Weaknesses:
- The overall framework and implemented attacks/defenses are somewhat simplistic, lacking more challenging attacks that achieve higher attack success rates.
- There is insufficient clarity on how LLMs interact with tool functions, which complicates the integration of new models into AgentGym.
- The setup of injection tasks may lead to confusion, as they appear indistinguishable from user tasks, raising questions about their legitimacy.
- The paper lacks detailed descriptions of the environments and tools used, which would aid in understanding the evaluation results.

### Suggestions for Improvement
We recommend that the authors improve the complexity of the attacks and defenses implemented in AgentGym to include more challenging scenarios. Additionally, providing a clearer explanation of how LLMs interact with tool functions and environments would enhance the framework's usability. We suggest clarifying the distinction between user tasks and injection tasks to avoid confusion regarding their legitimacy. Furthermore, including detailed descriptions of the environments and tools would help contextualize the evaluation results. Lastly, we encourage the authors to narrow the scope in the title to better reflect the focus on prompt injection attacks.