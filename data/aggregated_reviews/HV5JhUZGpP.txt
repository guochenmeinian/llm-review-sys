ID: HV5JhUZGpP
Title: BeanCounter: A low-toxicity, large-scale, and open dataset of business-oriented text
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 8, 6, -1
Original Confidences: 4, 5, -1

Aggregated Review:
### Key Points
This paper presents a large dataset of over 100 billion tokens derived from public business data, specifically EDGAR filings, which is significantly larger than previous datasets. The authors provide analyses on the dataset's composition, including the sources of tokens and demographic and toxicity content. They propose two main use cases: as a domain-specific resource for pre-training models and as a means to reduce bias and toxicity in models. The authors demonstrate the dataset's utility through pre-training two models, showing improved performance on business-related tasks and reduced toxicity.

### Strengths and Weaknesses
Strengths:
- The dataset is substantial and well-suited for pre-training, with a detailed cleaning and deduplication pipeline.
- Basic analyses reveal a lower prevalence of toxic data compared to standard datasets.
- The demonstrated improvements in model performance on business tasks and reductions in bias and toxicity are noteworthy.

Weaknesses:
- The analysis of potential downsides, particularly regarding alignment problems and manipulation in business communication, is insufficiently addressed.
- The experimental coverage is limited, with only two models tested, which may not fully validate the dataset's benefits.
- Some analyses, such as the impact of continued pre-training on safety scores, lack thorough exploration.

### Suggestions for Improvement
We recommend that the authors improve their analysis by including more examples in the appendix, particularly of the most toxic data in the dataset and comparisons with other datasets like C4. Additionally, we suggest including actual average toxicity scores in the appendix for clarity. The authors should also conduct further studies with larger models to better understand the dataset's performance and toxicity reduction capabilities. It is crucial to analyze the reasons behind the observed changes in safety scores after pre-training, ensuring that the dataset's limitations are clearly articulated. Finally, we advise pairing the analysis in Section 4.2 with standard LLM benchmarks to assess the broader utility of BeanCounter in reducing toxicity without compromising performance on other tasks.