ID: WRd9LCbvxN
Title: General Articulated Objects Manipulation in Real Images via Part-Aware Diffusion Process
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 4, 4, 7, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 5, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for manipulating articulated objects in 2D images using a 2D-3D-2D approach with a diffusion model. The authors propose an Abstract 3D Model to represent articulated objects and dynamic feature maps to transfer seen regions while generating novel areas. The method shows effectiveness in image editing and 3D articulated object understanding through thorough experiments, including qualitative and quantitative evaluations.

### Strengths and Weaknesses
Strengths:
- The method is well-motivated, leveraging 3D priors for articulated object manipulation.
- The design of the Abstract 3D Model is a practical solution for representing articulated objects without fine-grained 3D meshes.
- The dynamic feature maps intuitively ensure consistency between input and generated images.
- The training-free pipeline allows for easy generalization to novel categories and different object types.

Weaknesses:
- The limited application of the approach is a major concern, as the process of building Abstract 3D Models from 2D images may hinder generalization.
- The heuristic nature of the model for obtaining 3D information lacks detail, particularly in part-level understanding and structural information.
- The manipulation generation lacks clarity, especially regarding how to handle 'decreasing' manipulations.
- The generated shadows in output images are under-analyzed, and the consistency of opened objects appearing empty raises questions.

### Suggestions for Improvement
We recommend that the authors improve the clarity of how to construct an Abstract 3D Model, particularly addressing the concerns regarding the ambiguity of 2D information and the effectiveness of prototype matching. Additionally, we suggest providing a detailed analysis of how the method can extend to more object categories and manipulation types, including the potential need for abstract models in Blender. It would also be beneficial to include a discussion on the implications of edited images for robotic manipulation learning, as well as a more thorough examination of shadow generation in the output images.