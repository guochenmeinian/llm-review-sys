ID: YkBDJWerKg
Title: STEVE-1: A Generative Model for Text-to-Behavior in Minecraft
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 5, 6, 7, 8, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 3, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents STEVE-1, a generative pretraining method for developing an instruction-following agent in Minecraft by fine-tuning the VPT agent. It trains an image-goal-conditioned policy and utilizes the foundation model MineCLIP to map language instructions into the image-goal space. The authors claim that STEVE-1 can solve nearly any short-horizon open-ended text and visual task in Minecraft, while also acknowledging its ability to robustly complete 12 of 13 tasks in their evaluation suite. The paper employs techniques such as unCLIP, hindsight relabeling, and MineCLIP to learn goal-reaching behavior from a large dataset in a self-supervised manner. The authors plan to discuss differences in goal-conditioning architectures and relevant results compared to related work in the final version.

### Strengths and Weaknesses
Strengths:
- The paper explores the feasibility of using foundation models like MineCLIP and VPT for decision-making problems, providing a preliminary conclusion.
- The unCLIP approach for instruction-following decision-making is interesting.
- The use of classifier-free guidance to enhance instruction sensitivity is reasonable.
- The authors effectively highlight the innovative techniques employed in STEVE-1, which enhance open-world control.
- The paper is well-written and accessible, with a demonstrated willingness to improve clarity and precision in claims regarding the agent's capabilities.
- The proposed solutions for improving long-horizon task performance are well-articulated and grounded in experimental findings.

Weaknesses:
- The claim that "STEVE-1 can follow nearly any short-horizon task" is overstated, as testing revealed the agent's inability to differentiate between specific targets or follow instructions accurately.
- The initial vague statements about STEVE-1's capabilities may mislead readers regarding its performance.
- There is a lack of generalization experiments on unseen text instructions, which is crucial for demonstrating the method's efficacy in open-ended tasks.
- Concerns remain regarding the agent's ability to handle long-horizon tasks, which the authors acknowledge but do not fully resolve.
- The evaluation metric, MineCLIP, is insufficient for measuring task correspondence, as it fails to distinguish between similar trajectories effectively.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their performance claims by providing specific examples of tasks STEVE-1 can robustly accomplish, potentially including a detailed table summarizing the tasks along with the necessary prompts and preconditions for better transparency. Additionally, we strongly recommend incorporating generalization experiments on unseen text instructions to validate the method's effectiveness. To enhance the evaluation, consider integrating a success-rate-based confusion matrix to replace the current MineCLIP evaluation metric. Furthermore, we suggest expanding the limitations section to include a thorough analysis of the bottlenecks in solving long-term tasks, particularly addressing the constraints of packed hindsight relabeling. Lastly, addressing the scalability of the approach to more complex, long-horizon tasks and exploring proposed avenues for enhancing long-horizon performance, such as scaling, finetuning with RL, and utilizing LLMs or VLMs, would strengthen the paper's contributions.