ID: ryqwV6rrAi
Title: Can We Statically Locate Knowledge in Large Language Models? Financial Domain and Toxicity Reduction Case Studies
Conference: EMNLP/2024/Workshop/BlackBoxNLP
Year: 2024
Number of Reviews: 3
Original Ratings: -1, -1, -1
Original Confidences: 4, 4, 3

Aggregated Review:
### Key Points
This paper presents a novel method for statically identifying where specific knowledge is stored within the parameters of large language models (LLMs). The authors leverage the idea that model parameters can be interpreted as embeddings in the same embedding space, allowing them to locate relevant parameters by searching for those most similar to a query representing the desired knowledge, without requiring forward or backward passes. The method was evaluated across various tasks, model architectures, and ablation strategies, demonstrating effectiveness in identifying parameters related to financial information and reducing toxic language generation.

### Strengths and Weaknesses
Strengths:
- The static knowledge localization method marks a significant shift from traditional dynamic analysis techniques reliant on input-based evaluations.
- The ability to locate and potentially modify specific knowledge within LLMs offers considerable practical value for content creation and bias reduction.
- The extensive evaluation across multiple tasks and model families (GPT-2, OPT, Bloom) showcases the method's robustness.
- The experimental setup is exhaustive, addressing various research questions and demonstrating downstream applications, such as toxicity reduction.

Weaknesses:
- The focus on the financial domain and toxicity raises questions about the generalizability of the method to other domains and tasks.
- Results are mixed for tasks beyond CEO name prediction, with less pronounced differences in targeted versus controlled ablations for tickers and directors.
- Some analysis sections are difficult to follow, particularly regarding layer-wise distributions and specific task ablations, which could benefit from clearer explanations.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their findings by conducting experiments across a broader range of domains and tasks. Additionally, clarifying the reasoning behind the selection of the financial domain and toxicity for experimentation would enhance the paper's context. We suggest editing sections of the analysis to improve clarity, particularly around complex topics such as layer-wise distributions and ablations. It would also be beneficial to mention the utility of MLP layers earlier in the paper to set reader expectations. Lastly, addressing the clarity of figures and legends, as well as ensuring consistent terminology throughout, would strengthen the overall presentation.