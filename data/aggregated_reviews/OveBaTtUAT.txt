ID: OveBaTtUAT
Title: Towards Unbounded Machine Unlearning
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 5, 5, 6, 8, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 5, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper studies machine unlearning from an empirical perspective, proposing a scalable unlearning method, SCRUB, based on knowledge distillation. The authors evaluate SCRUB's performance across various metrics and applications, including removing biases, resolving confusion, and protecting user privacy. They highlight that previous state-of-the-art methods often fail to achieve good performance across all tasks due to their focus on single criteria. The paper also employs the latest LiRA membership inference attack accuracy as a metric for user privacy applications and includes comprehensive empirical evaluations to validate SCRUB's superior performance.

### Strengths and Weaknesses
Strengths:  
- The paper identifies three practical applications for unlearning algorithms, emphasizing the need for diverse evaluation metrics.
- SCRUB's teacher-student model formulation offers high scalability, effectively managing large forget sets without the computational complexity of sequential unlearning processes.
- The empirical evaluation supports SCRUB's performance, and the inclusion of full code and documentation enhances reproducibility.

Weaknesses:  
- The contribution may appear incremental, as the use of knowledge distillation and MIA accuracy metrics are not novel. Clarification on the necessity of adapting LiRA for unlearning would enhance understanding.
- Concerns exist regarding SCRUB's performance with small forget sets amidst large training datasets, potentially leading to unstable training outcomes.
- The paper lacks sufficient technical details in the main body, deferring crucial information to the appendix, which complicates evaluation of the contributions.

### Suggestions for Improvement
- We recommend that the authors clarify the necessity of adapting LiRA for unlearning, specifically addressing whether this adaptation significantly increases attack accuracy or presents technical challenges.
- The authors should investigate and discuss SCRUB's performance when unlearning small portions of a large training set, as this scenario is common in practice.
- We suggest that the authors enhance the main text with more technical details regarding the alternating step algorithm and validation set construction to improve clarity and evaluation.
- The authors could consider including additional experiments on larger datasets and addressing sequential unlearning to provide a more comprehensive evaluation of SCRUB's capabilities.