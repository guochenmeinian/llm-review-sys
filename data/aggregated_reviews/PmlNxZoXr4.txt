ID: PmlNxZoXr4
Title: Neural Processes with Stability
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 7, 5, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to training neural processes that enhances their algorithmic stability, which is beneficial for generalization in a frequentist context. The authors provide theoretical foundations for their method and demonstrate its effectiveness through comparisons with existing training techniques, showing improved performance across various tasks. The focus is on addressing algorithmic instability in the presence of noisy context points by utilizing hard predictable subsets as additional training datasets. Additionally, the paper compares training and testing times between CNP and SCNP across various tasks, indicating that while SCNP requires additional training time due to the stable strategy, the overall increase is acceptable. The testing times for both models are similar, demonstrating that the stable version retains the rapid inference capability of neural processes. The authors also report on Bayesian optimization experiments using data generated by Matern-GP, showing that SANP outperforms ANP and is competitive with BANP, despite some variability in results.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and effectively communicates its ideas.
- The proposed method shows consistent improvements in performance across diverse tasks.
- The introduction of theoretical findings regarding stable solutions is original and interesting.
- The paper provides a clear comparison of training and testing times, highlighting the efficiency of the stable version of NP.
- The experimental results demonstrate that SANP consistently outperforms ANP and shows competitive performance against BANP across different data types.

Weaknesses:
- The importance of stability is not sufficiently argued, leaving its critical role in generalization unclear.
- The choice of baseline models is outdated; newer methods like Convolutional Neural Processes should be included.
- The experimental tasks are overly simplistic, lacking complexity to convincingly demonstrate the proposed model's superiority.
- Limitations, particularly regarding computational costs and runtime comparisons with regular NPs, are inadequately addressed.
- The performance of SANP is noted to be slightly worse than BANP in specific visualized examples, raising concerns about stability and consistency in results.
- The authors acknowledge that the results may vary based on the data selected for visualization, which could affect the perceived reliability of the findings.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the importance of stability in neural processes to clarify its role in generalization. Additionally, consider incorporating more state-of-the-art methods, such as Convolutional Neural Processes, as baselines for comparison. The authors should also explore more complex tasks, such as Bayesian Optimization and the Predator-Prey task, to better showcase the model's applicability. Furthermore, a more thorough discussion of the computational costs associated with the proposed method compared to regular NPs is necessary, including a detailed analysis of runtime and potential trade-offs. We also recommend improving the stability of SANP's performance to ensure it consistently outperforms BANP across all datasets. Incorporating a broader range of data in the visualizations would provide a more comprehensive assessment of SANP's capabilities. Lastly, please ensure that all extra experiments and discussions are thoroughly integrated into the updated manuscript as per reviewer feedback.