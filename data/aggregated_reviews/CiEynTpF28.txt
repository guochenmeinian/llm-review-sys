ID: CiEynTpF28
Title: Distributional Reinforcement Learning with Regularized Wasserstein Loss
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 5, 5, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Sinkhorn Distributional Reinforcement Learning (SinkhornDRL), a novel algorithm that utilizes Sinkhorn divergence, a regularized Wasserstein loss, to enhance the estimation of return distributions in reinforcement learning. The authors provide theoretical guarantees on the convergence of SinkhornDRL and demonstrate its empirical effectiveness across 55 Atari games and various multi-dimensional reward settings. The algorithm aims to address the limitations of existing methods, particularly those based on quantile regression, by improving stability and capturing the geometric characteristics of return distributions.

### Strengths and Weaknesses
Strengths:
- The algorithm is clearly articulated and comprehensible.
- The authors conduct a thorough theoretical analysis and provide extensive empirical results, demonstrating superior performance in complex games.
- The paper effectively reviews relevant literature and presents a well-motivated approach to using Sinkhorn divergence.

Weaknesses:
- The benefits of Sinkhorn divergence remain unclear, with a lack of intuitive explanations for its selection over other methods.
- The theoretical contributions may not be sufficiently novel, as convergence results are only shown under limiting conditions.
- The presentation is dense, with some figures and text being difficult to read, and certain technical details are lacking in the algorithms.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the benefits of using Sinkhorn divergence by providing more intuitive explanations. Specifically, addressing the questions regarding the accuracy of using samples versus pre-specified statistics, the alignment of regularization with the max entropy principle, and the vagueness of the term "smoother" would enhance understanding. Additionally, we suggest that the authors clarify the novelty of their theoretical results by providing general convergence results for any epsilon value. To improve readability, consider simplifying the text and figures, and potentially moving technical details of Algorithm 1 to an appendix. Lastly, revising Figure 2 to avoid misleading visual representations of performance ratios would be beneficial.