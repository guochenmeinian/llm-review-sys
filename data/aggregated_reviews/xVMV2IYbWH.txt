ID: xVMV2IYbWH
Title: An Adaptive Prompt Generation Framework for Task-oriented Dialogue System
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an adaptive prompt-generation framework aimed at enhancing task-oriented dialogue systems using Large Language Models (LLMs). The authors propose a trainable slot generator (TSG) to produce domain and slot information from the belief state, which is then utilized by an adaptive prompt generator (APG) to create prompts for LLMs. The framework was evaluated on the MultiWOZ 2.0 dataset, demonstrating superior performance compared to existing methods like SOLOIST and ChatGPT.

### Strengths and Weaknesses
Strengths:
- The innovative approach of combining static and dynamic prompt generation for task-oriented dialogue.
- Experimental results indicate that the proposed framework outperforms prior baselines in dialogue evaluation metrics.
- The TSG enhances slot prediction accuracy and the APG reduces LLM hallucination.

Weaknesses:
- The TSG's validation is limited to the SOLOIST model, raising concerns about generalizability to other domains.
- The comparison with outdated baselines lacks fairness, and results on generation metrics are not provided.
- Key claims are insufficiently supported, particularly regarding the necessity of belief states in LLMs for task-oriented dialogue.

### Suggestions for Improvement
We recommend that the authors improve the validation of the TSG by comparing it with more recent models and providing a thorough analysis of its performance across various tasks. Additionally, we suggest including generation metrics such as BLEU and METEOR to substantiate the results. The authors should also conduct ablation studies to explore the effects of static versus dynamic prompts and clarify the structure and necessity of the belief state in their framework.