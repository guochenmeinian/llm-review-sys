ID: tScBQRNgjk
Title: ForecastPFN: Synthetically-Trained Zero-Shot Forecasting
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 6, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ForecastPFG, a zero-shot forecasting method trained exclusively on synthetic datasets and evaluated across several real-world datasets. The authors propose that this approach is particularly beneficial in scenarios with limited data. The methodology involves a transformer architecture that allows for predictions at arbitrary future time steps, leveraging a synthetic data generation model that incorporates diverse time series patterns. Additionally, the paper evaluates various forecasting models, including ForecastPFN, under different training and time budget settings, indicating that ForecastPFN often outperforms other models, especially in low training budget scenarios. The authors provide empirical results comparing models based on metrics like MSE and parameter counts, while addressing concerns about the fairness of comparisons in low train time settings.

### Strengths and Weaknesses
Strengths:
1. The manuscript is well-written and logically organized, making it easy to follow.
2. The innovative concept of training a foundational model solely on synthetic data addresses forecasting accuracy in data-sparse scenarios and has positive environmental implications.
3. The extensive experiments conducted demonstrate the model's performance against state-of-the-art methods, with detailed empirical results including MSE wins and ranks.

Weaknesses:
1. Claims regarding the superiority of ForecastPFN over existing methods are exaggerated, as experiments are conducted under severely constrained conditions.
2. The paper lacks clarity on the choice of multiplicative decomposition for the model and its implications.
3. The reliance on plots for results presentation makes it difficult for readers to extract meaningful information; tables are recommended for clarity.
4. There are concerns regarding the low train time setting, particularly its distinction from out-of-distribution cases.
5. The reporting of FLOPs alone is deemed insufficient; results should also include wall clock times for better understanding.

### Suggestions for Improvement
We recommend that the authors improve the clarity of sections where repetition occurs, specifically in rows 71-74, 83-85, and 23-24, by adding more details. Additionally, the authors should discuss the relationship between zero-shot forecasting, transfer learning, and global models more thoroughly, referencing recent works such as Januschowski et al. (2020) and others. 

Clarification is needed regarding the choice of multiplicative decomposition in rows 102-104 and its impact on results. The authors should also address the terminology used for the test set in rows 109-110, suggesting alternative names to avoid confusion. 

The authors should consider the implications of the prior distribution choice on real dataset results and provide motivation for using the Weibull distribution for noise in row 144. Furthermore, the authors should clarify the definition of "train budget" and "time budget" in Section 4, ensuring consistency throughout the paper.

We recommend including actual MSE scores alongside the number of wins/rankings to provide a clearer comparison of model performance. The addition of simple baselines, such as naive forecasts and historical means, would enhance the robustness of the comparisons made. Lastly, we suggest that the authors include key results in tabular form and adjust the scale of plots for better readability. We also encourage the authors to improve the clarity of the distinction between low train time and out-of-distribution cases, potentially by incorporating methods like AdaRNN. Additionally, we suggest that the authors update the paper with more extensive empirical results, including both wall clock times and FLOPs for a comprehensive comparison, and move the additional tables into the main paper to enhance accessibility and clarity.