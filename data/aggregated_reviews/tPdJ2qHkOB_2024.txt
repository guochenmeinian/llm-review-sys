ID: tPdJ2qHkOB
Title: Toward Self-Improvement of LLMs via Imagination, Searching, and Criticizing
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 5, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ALPHALLM, an imagination-searching-criticizing framework aimed at enhancing the capabilities of large language models (LLMs) through a self-improvement loop that integrates Monte Carlo Tree Search (MCTS) and LLMs. The authors propose eta-MCTS as a decoding method to reduce the search space. Experimental results indicate that ALPHALLM significantly improves LLMs' reasoning abilities, achieving notable performance on benchmarks like GSM8K and MATH.

### Strengths and Weaknesses
Strengths:
1. The innovative application of tree search for self-improvement is commendable, and the authors effectively identify key challenges.
2. Experimental results demonstrate a clear enhancement in LLM reasoning capabilities.

Weaknesses:
1. Clarity issues persist in several sections, particularly regarding data synthesizing and the implementation of option-level MCTS.
2. The reliability of the proposed evaluation methods (value function, PRM, ORM) for obtaining feedback is not adequately discussed.
3. The writing lacks precision, and the ablation studies are insufficient to validate the impact of various components in the pipeline.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing, particularly in sections discussing data synthesizing and the implementation of option-level MCTS. Including examples, especially for synthesized data, would enhance understanding. Additionally, we suggest that the authors conduct more comprehensive ablation studies, including comparisons with other heuristic search methods and detailed analyses of how different components influence performance. Finally, providing the codebase would facilitate verification and reproducibility of the results.