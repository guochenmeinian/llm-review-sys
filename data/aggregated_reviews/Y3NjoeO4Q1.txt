ID: Y3NjoeO4Q1
Title: Detection Based Part-level Articulated Object Reconstruction from Single RGBD Image
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 6, 5, 6, 6, 8, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method for reconstructing multiple articulated objects from a single RGB-D image, focusing on part-level shape, pose, joint parameters, and part-instance association. The authors propose an effective detect-and-group strategy that utilizes part-level representations for detection, reconstruction, and parameter prediction. Additionally, they introduce an oversampling and fusion strategy during inference to enhance detection performance, along with anisotropic size normalization and a refinement module to improve reconstruction quality and part pose/motion prediction.

### Strengths and Weaknesses
Strengths:
- The task of reconstructing articulated objects is novel and valuable for robotics applications.
- The use of part-level representations and the detect-then-group strategy is intuitive and effective for diverse structures.
- The end-to-end method builds on 3DETR, incorporating part-level detection and pose/motion prediction, with an instance-loss aiding in grouping.
- Experimental settings allow for meaningful comparisons with previous work, demonstrating the method's effectiveness.

Weaknesses:
- The paper lacks novel viewpoints on reconstructed shapes, with visualizations limited to the input RGBD viewpoint, hindering comprehensive understanding.
- The statistics in Table 2 regarding instance numbers are unclear, particularly concerning the SAPIEN dataset.
- Evaluation methods do not account for the real-world prevalence of closed movable parts, suggesting a need for separate evaluations based on motion states.
- There is a lack of statistics on the number of articulated objects in input images, which would aid in understanding part-instance association performance.
- Quantitative improvements with metrics like QO, PF, and kIoU are not substantial, and qualitative results are needed for further insights.

### Suggestions for Improvement
We recommend that the authors improve the visualizations of reconstructed shapes to provide clearer insights into the improvements achieved. Clarifying the statistics in Table 2 and providing a rationale for the instance numbers would enhance understanding. Additionally, we suggest conducting separate evaluations based on the motion states of parts to reflect real-world scenarios more accurately. Including statistics on the number of articulated objects in input images would also be beneficial. Finally, we encourage the authors to present qualitative results alongside quantitative metrics to better demonstrate the effectiveness of the proposed modules.