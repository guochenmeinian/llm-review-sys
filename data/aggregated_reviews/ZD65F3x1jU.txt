ID: ZD65F3x1jU
Title: On Learning Latent Models with Multi-Instance Weak Supervision
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 7, 6, 5, 6, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 2, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on multi-instance partial label learning (PLL), where weak supervision is provided through an unknown transition function $\sigma$. The authors establish necessary and sufficient conditions for learnability, particularly focusing on M-ambiguity. They demonstrate that under a known transition function, a stronger condition of 1-ambiguity can yield faster learning rates. The paper also explores learning multiple classifiers with shared label spaces and provides results for single classifiers under unknown transition functions. Empirical evaluations support the theoretical findings.

### Strengths and Weaknesses
Strengths:
- The paper offers comprehensive theoretical results across various problem setups, addressing known and unknown transition functions and single/multiple classifiers.
- It provides rigorous theoretical analysis with intuitive assumptions and relevant experiments that validate the theoretical claims.

Weaknesses:
- Scalability issues are evident, as performance drops significantly in seemingly simple tasks, raising concerns about the broader applicability of the PLL setting.
- The discussion surrounding Definition 5 lacks depth, particularly regarding the implications of the unknown transition function.

### Suggestions for Improvement
We recommend that the authors improve the discussion on scalability issues, clarifying whether they stem from the chosen neuro-symbolic methods, the PLL setting, or both. Additionally, we suggest expanding the analysis of Definition 5 to provide a more thorough exploration of the implications of the unknown transition function. Finally, consider providing a clearer connection between the theoretical results and practical applications to enhance the relevance of the findings.