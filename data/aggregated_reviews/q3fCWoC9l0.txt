ID: q3fCWoC9l0
Title: Efficient Data Subset Selection to Generalize Training Across Models: Transductive and Inductive Networks
Conference: NeurIPS
Year: 2023
Number of Reviews: 21
Original Ratings: 9, 6, 6, 5, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 2, 3, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method, SUBSELNET, for subset selection in neural network training, utilizing a graph neural network (GNN) and transformer architectures to create a model-agnostic approach. The authors aim to address the challenge that subset selections for one architecture do not generalize to others by proposing an end-to-end training method that leverages multiple architectures to select a generalizable subset. The approach emphasizes optimizing a probability distribution over samples to minimize loss while promoting diversity. Additionally, the authors provide extensive ablation studies indicating that the GNN+Transformer blocks yield superior results across six diverse datasets, demonstrating the method's robustness and generalizability.

### Strengths and Weaknesses
Strengths:  
- The method addresses a significant practical problem in subset selection that generalizes across architectures, enhancing its versatility.  
- The paper is well-written, with clear explanations of the method's components and robust empirical results that substantiate the method's superiority over existing baselines.  
- Extensive ablation studies support the effectiveness of the GNN+Transformer architecture, showcasing strong empirical evidence of its efficacy.  
- The authors are responsive to reviewer feedback and committed to improving the paper.

Weaknesses:  
- The complexity of the method may hinder community adoption, and there is a lack of justification for the proposed methods, particularly regarding whether the transformer effectively captures the mapping between models and data or merely overfits to training samples.  
- The reliance on the NAS-Bench-101 dataset, which contains similar CNN architectures, raises concerns about the method's applicability to other architectures, such as Residual Networks (ResNets).  
- The analysis of the selected data subsets compared to other methods is insufficient, and the experiments are limited to smaller datasets, which may not reflect real-world scenarios.  
- Some results are currently relegated to supplementary materials, which may hinder readability and accessibility, and the paper's presentation suffers from poor structure and unclear figures.

### Suggestions for Improvement
We recommend that the authors improve the notation and formatting of the paper to enhance clarity, possibly relegating complex details about GNNs to an appendix. We suggest improving the theoretical justification for their methods by conducting additional analyses to confirm the transformer's ability to capture necessary mappings without overfitting. Furthermore, it would be beneficial to test the proposed method on a broader range of architectures beyond those in the NAS-Bench-101 dataset to provide evidence of its efficacy across diverse scenarios. We encourage the authors to bring results from supplementary materials into the main text, particularly those on Selection-via-Proxy and RHO-Loss, and to include more complex datasets, such as ImageNet, to strengthen empirical validation. Additionally, addressing the potential overlap of selected subsets across architectures and providing a more thorough analysis of the model approximator's effectiveness would be beneficial. Lastly, we suggest highlighting the ablation study in Table 2 more prominently and clarifying the computational costs associated with the pre-processing steps to improve the paper's impact.