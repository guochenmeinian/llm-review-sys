ID: fuD0h4R1IL
Title: Time-MMD: Multi-Domain Multimodal Dataset for Time Series Analysis
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 6, 7, 8, 6, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 5, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Time-MMD, the first benchmark dataset for multi-modal multi-domain time series forecasting, encompassing nine primary data domains. The authors propose MM_TSFib, a new library for multi-modal time series forecasting, demonstrating significant performance improvements over unimodal scenarios. The paper aims to support the emerging research domain of "LLM for time series."

### Strengths and Weaknesses
Strengths:
1. The paper is clearly written and easy to follow.
2. The dataset and library are significant contributions to the research community.
3. Time-MMD addresses deficiencies in existing multimodal time series datasets, providing a rich data source.
4. The innovative method for textual data screening and alignment improves data quality.
5. The MM-TSFlib framework facilitates multimodal applications in time series prediction.

Weaknesses:
1. Some claims appear exaggerated, particularly regarding the title's focus on "time series analysis" rather than "time series forecasting."
2. The dataset lacks multilingual support, limiting its applicability.
3. The alignment of time series and text data is unclear, particularly regarding frequency differences and relevance.
4. The documentation is insufficient, lacking example usages and detailed explanations.
5. The experimental results do not serve as a comprehensive benchmark for multi-modal time series modeling.

### Suggestions for Improvement
We recommend that the authors improve clarity by addressing misleading statements, particularly regarding the title and claims about the dataset's capabilities. The authors should include essential statistics in Table 1, such as the number of samples and features. We suggest clarifying the alignment process between time series and text data, ensuring that the collected text data is relevant. Additionally, the authors should enhance the documentation to include more detailed instructions and examples for using the library and datasets. Finally, we encourage the authors to explore the integration of multilingual textual data and alternative methods for combining textual and numerical information beyond merely fine-tuning the projection layer.