ID: 5EHI2FGf1D
Title: Unsupervised Binary Code Translation with Application to Code Clone Detection and Vulnerability Discovery
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an approach to retargeting deep neural networks for binary analysis across different instruction set architectures (ISAs). The authors develop cross-architectural instruction embeddings (CAIEs) that abstract commonalities between high-resource ISAs like x86 and lower-resource ISAs such as ARM and PPC. The technique translates binaries from low-resource ISAs to high-resource ISAs, facilitating downstream tasks like functional similarity comparison and vulnerability detection. The authors provide metrics such as accuracy and F-1 scores to evaluate their method.

### Strengths and Weaknesses
Strengths:
- The paper addresses an important problem in binary analysis, particularly the challenges posed by low-resource ISAs.
- The conceptual framework for translating binaries and the creation of a novel dataset for evaluation are significant contributions.

Weaknesses:
- The paper lacks comparisons against baseline models, particularly in the functionality similarity comparison task.
- The methodology for functionality similarity comparison is questionable, relying on cosine similarity without sufficient dynamic analysis.
- The vulnerability discovery methodology is limited, focusing on single vulnerabilities and raising concerns about ecological validity.
- There is substantial overlap with a recently accepted paper at Usenix 2023, leading to questions about the novelty of the current submission.
- The evaluation is limited to x86 and ARM, neglecting other ISAs like PPC.

### Suggestions for Improvement
We recommend that the authors improve their paper by including comparisons against baseline models for both downstream evaluations. It is crucial to provide a more detailed analysis of the results, particularly in Section 5.2, to clarify the model's convergence and performance across different settings. Additionally, the authors should elaborate on the definition of code similarity to account for functions that perform the same task but have different names. It is essential to highlight how their approach differs from existing intermediate representation-based methods and to discuss the model's scalability and adaptability to new coding styles. Finally, we suggest adding an introduction or overview before the first sub-sections in Sections 2 and 4 to enhance clarity.