ID: hV52oj0Sik
Title: A Hierarchical Training Paradigm for Antibody Structure-sequence Co-design
Conference: NeurIPS
Year: 2023
Number of Reviews: 19
Original Ratings: 6, 5, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a hierarchical training paradigm (HTP) aimed at addressing the antibody co-design problem by utilizing geometric neural networks and large-scale protein language models. The authors propose a structured approach with four training stages to leverage evolutionary information from diverse protein sequences and binding structures. Additionally, the paper provides a comprehensive analysis of sequence similarity within the SAbDab training set, utilizing **pairwise2** from **Biopython** despite its speed limitations. The authors compute sequence similarity across all CDR sequences and follow the DiffAb methodology for dataset splitting, integrating **MMseqs2** for clustering. They also discuss the implications of using pre-trained protein language models (PLMs) like ESM-2, highlighting potential benefits and concerns regarding data leakage in sequence generation tasks.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and presents a clear methodology, making it easy to follow.
2. The integration of multi-modal data from various domains offers a novel perspective on improving antibody sequence-structure co-design.
3. Extensive experiments demonstrate that HTP significantly outperforms previous methods.
4. The authors effectively compute and present sequence similarity data, providing transparency through accessible plots and scripts.
5. The methodology is grounded in established frameworks like DiffAb, ensuring robustness in dataset handling.
6. The discussion on PLMs reflects a nuanced understanding of their role in protein design and the importance of avoiding data leakage.

Weaknesses:
1. The code is currently unavailable, limiting reproducibility.
2. Reported baseline results are inconsistent with original papers, raising concerns about fairness in comparisons.
3. The study lacks a comparison with the state-of-the-art method dyMEAN, which has a higher AAR for CDR-H3.
4. Some results are confusing, particularly the performance discrepancies between fix-backbone design and co-design tasks.
5. There are concerns regarding the evaluation of models using PLMs, particularly the risk of data leakage affecting results.
6. The small size of the test set may lead to low statistical significance in the findings.
7. The evaluation process needs to be more stringent, especially for tasks involving data generation.

### Suggestions for Improvement
We recommend that the authors improve the transparency of their results by providing the code for reproducibility. Additionally, please ensure that baseline results are consistent with original papers to maintain fairness in comparisons. We suggest including a comparison with the state-of-the-art method dyMEAN to strengthen the evaluation. Furthermore, clarify the discrepancies in performance between fix-backbone design and co-design tasks, as this raises questions about the methodology. We also recommend improving the evaluation by retraining the model with a proper sequence similarity split for CDR-H1/H2/L1/L2/L3 individually and re-evaluating the AAR score. It would be beneficial to provide evidence that the favorable numerical results are not due to ESM-2 having seen the test set. Lastly, we encourage the authors to consider using antibody-specific PLMs for high-antibody-specificity tasks to enhance their approach.