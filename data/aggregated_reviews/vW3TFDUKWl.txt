ID: vW3TFDUKWl
Title: Mitigating Backdoor Poisoning Attacks through the Lens of Spurious Correlation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a defense method against backdoor attacks in NLP models by leveraging spurious correlations between triggers and their target labels. The authors propose a technique that sanitizes the training dataset by calculating suspicious correlations using lexical and syntactic features, demonstrating effectiveness against various types of backdoor triggers. The experiments indicate that their method outperforms existing baseline defense technologies.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and clear, making it accessible to readers.
- The approach of linking backdoor attacks to spurious correlations is novel in the text domain.
- Thorough experiments validate the proposed defense's performance against multiple attack types.

Weaknesses:
- The defense method's effectiveness is contingent on knowledge of the attack methods, which may not be realistic.
- The reliance on specific feature extraction techniques raises questions about the generalizability of the defense.
- Some methodological choices, such as the use of "eyeball detection" for threshold selection, lack rigorous justification.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the selection of attack methods and discuss the implications of their defense's dependency on feature extraction. Additionally, we suggest providing an ablation study on the hyperparameter selection, particularly the threshold used in the defense method, to illustrate its impact on performance. A more comprehensive discussion on the generalization of the defense against various backdoor attacks, including those not explicitly covered, would strengthen the paper's conclusions.