ID: lpFDhC91Oj
Title: Black-Box Forgetting
Conference: NeurIPS
Year: 2024
Number of Reviews: 19
Original Ratings: 5, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for selective memorization in classification models under a black-box setup, addressing the "black-box forgetting" problem. The authors propose a technique that combines cross-entropy minimization for memorized classes and entropy maximization for unmemorized classes, utilizing a black-box optimization algorithm, CMA-ES. Additionally, the authors introduce latent context sharing (LCS) to enhance parameter efficiency and scalability in forgetting tasks, asserting that machine unlearning differs from black-box forgetting and emphasizing the need for distinct evaluation metrics. The evaluation focuses on the method's selective memorization capability and includes responses to various reviewer queries regarding experimental settings, assumptions, and implications for future research.

### Strengths and Weaknesses
Strengths:
- The exploration of "black-box forgetting" is crucial and previously unexplored, with a timely and straightforward approach.
- The design of the proposed method is logical and easy to follow.
- The authors provide satisfactory responses to most reviewer questions, demonstrating a thorough understanding of the topic.
- The experimental results, particularly on ImageNet-30, show promising performance and low standard deviation, reinforcing the validity of their conclusions.
- The discussion on the relationship between shared and unique latent contexts is insightful and has potential implications for future research.

Weaknesses:
1. Lack of novelty: The method resembles a variant of BBT, and further analysis on efficiency and qualitative results is needed to substantiate claims of originality. The learning objective is also common, making it difficult to assert its uniqueness.
2. Inappropriate validation setup: The study lacks comparisons with existing selective memorization and unlearning methods, which are necessary for validating the proposed method's effectiveness. Additionally, the validation is limited to three natural object recognition datasets, necessitating broader testing across diverse image domains.
3. The assumption regarding unique and shared latent contexts lacks robust justification, raising concerns about its validity prior to experimental support.
4. The connection between LCS and the black-box forgetting problem is perceived as weak, with some reviewers questioning the necessity of the proposed method.
5. Some reviewers express skepticism about the empirical basis for the claims regarding LCS's design for forgetting.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their claims by providing analyses on efficiency and qualitative results to contrast with BBT. Additionally, comparisons with existing unlearning objectives should be included to validate the proposed method. Expanding the validation to include a wider range of image domains will strengthen the conclusions drawn from the experiments. Furthermore, we suggest that the authors improve the justification for the assumption of unique and shared latent contexts by providing more detailed theoretical or empirical support in the final version. Clarifying the connection between LCS and the black-box forgetting problem could strengthen the paper's argument. Enhancing the discussion on evaluation metrics to better address the transition from specific samples to class-level forgetting will ensure that the proposed metrics effectively measure the intended outcomes. Finally, incorporating insights from reviewer feedback regarding dataset complexity and the implications of results obtained during the rebuttal could further enrich the manuscript.