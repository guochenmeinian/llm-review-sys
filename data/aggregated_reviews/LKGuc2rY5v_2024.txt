ID: LKGuc2rY5v
Title: Efficient and Sharp Off-Policy Evaluation in Robust Markov Decision Processes
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 6, 6, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a statistical theory for off-policy evaluation (OPE) under transition kernel shifts in Markov decision processes (MDPs), addressing the challenge of evaluating policies when the environment dynamics may change. The authors propose new algorithms and sharp estimators for robust policy value estimation, demonstrating that their method is semiparametrically efficient with a $\sqrt{n}$-rate of estimation, even under biased nuisance function estimates. The theoretical framework is supported by numerical simulations that validate the efficiency of the proposed estimators. Additionally, the paper explores risk-sensitive reinforcement learning, specifically focusing on iterated CVaR and worst path methodologies, proposing novel approaches that build upon existing literature, including quantile regression techniques and robust reinforcement learning frameworks.

### Strengths and Weaknesses
Strengths:
- The focus on policy evaluation under transition kernel shifts addresses a significant and realistic problem in reinforcement learning.
- The paper provides a credible statistical theory with strong guarantees for the proposed estimators, supported by solid theoretical analysis and well-defined theorems.
- The numerical results align with theoretical expectations, showcasing the proposed estimator's superior performance.
- The authors effectively address reviewer concerns and demonstrate a commitment to clarity in their responses, positively influencing reviewer scores.

Weaknesses:
- The paper is primarily theoretical, making it difficult to assess the practical applicability of the proposed methods, especially since numerical simulations are limited to simplified synthetic environments.
- There is a lack of discussion regarding related work on OPE under partially observable MDPs (POMDPs), which could provide valuable context.
- The notation is overly complex and may confuse readers, particularly those unfamiliar with the topic, as no examples or demonstrations are provided.

### Suggestions for Improvement
We recommend that the authors improve the practical evaluation of their estimation framework by including more comprehensive numerical simulations in realistic environments. Additionally, a discussion of the relationship between their work and existing literature on OPE under POMDPs would enhance the paper's context. To aid reader comprehension, we suggest simplifying the notation and including illustrative examples or demonstrations. Finally, clarifying the assumptions made in the theoretical framework and justifying the perturbation model would strengthen the paper's contributions.