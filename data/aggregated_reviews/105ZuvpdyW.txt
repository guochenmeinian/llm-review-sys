ID: 105ZuvpdyW
Title: SegVol: Universal and Interactive Volumetric Medical Image Segmentation
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 8, 7, 8, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents SegVol, a 3D foundation segmentation model designed for universal and interactive volumetric medical image segmentation, capable of handling over 200 anatomical categories. The authors propose a zoom-out-zoom-in mechanism for efficient and precise segmentation, supported by extensive training on 90K unlabeled and 6K labeled CT volumes. The model integrates spatial and semantic prompts, demonstrating superior performance compared to other SAM-like interactive segmentation methods.

### Strengths and Weaknesses
Strengths:
- The integration of spatial and semantic prompts is innovative and yields promising results.
- The paper is well-structured and clearly written, with high-quality figures that enhance understanding.
- The method achieves state-of-the-art results against SAM-like interactive segmentation methods.

Weaknesses:
- The training dataset is imbalanced, which may affect performance; further analysis and validation are needed.
- The segmentation effect on unseen anatomical categories is unclear; relevant experiments should be provided.
- Details regarding the model's complexity, number of parameters, and running speed are lacking, necessitating a comparison with existing state-of-the-art methods.
- Clarity issues exist regarding the training algorithm and hyperparameters, which are not sufficiently detailed in the main text.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the training algorithm by including a descriptive paragraph or diagram in the appendix. Additionally, the authors should provide further analysis on the impact of the imbalanced training dataset and conduct experiments on the segmentation of unseen anatomical categories. It would be beneficial to include a comparison of the model's complexity, number of parameters, and running speed with existing state-of-the-art methods. Lastly, unifying the reference format and addressing the clarity of the hyperparameter details would enhance the overall presentation.