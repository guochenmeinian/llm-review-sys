ID: pxscU6TidP
Title: AutoPlan: Automatic Planning of Interactive Decision-Making Tasks With Large Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents AutoPlan, a demonstration-free method for generating and iteratively improving plans for decision-making tasks using an LLM. The method is evaluated in the ALFWorld and HotpotQA domains, showing improved performance over a zero-shot ReAct baseline. The authors also analyze inference costs and conduct ablations to assess the impact of batch size on performance. The paper includes qualitative analyses of failures in ALFWorld and demonstrates results using GPT-4.

### Strengths and Weaknesses
Strengths:
- The paper provides a detailed qualitative analysis of failures in the ALFWorld domain, enhancing understanding of method performance.
- Ablation studies clarify the effect of batch size and the reflection step on performance.
- The proposed method combines elements of ReAct and Reflection effectively.

Weaknesses:
- The prompts contain ungrammatical English, potentially affecting experimental results.
- The paper lacks evaluation against strong baselines like InnerMonologue and Reflexion, which could provide a more comprehensive comparison.
- The method does not significantly outperform a 2-shot ReAct baseline, raising questions about the impact of AutoPlan.
- The human evaluation methodology for HotpotQA is not adequately detailed, and the authors conducted this evaluation themselves.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their writing, particularly regarding whether the optimization process is online or offline. Additionally, the authors should compare AutoPlan against strong baselines without in-context examples to establish a fair comparison. It would be beneficial to clarify the differences between the reflection component in AutoPlan and similar mechanisms in existing works. We also suggest including a comparison of total costs, encompassing both plan optimization and inference, to provide a more complete analysis. Finally, the authors should detail their evaluation methodology for HotpotQA and consider validating AutoPlan in more domains to justify its training costs.