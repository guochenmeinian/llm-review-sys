ID: hc9GkYw9kR
Title: LORA-MOO: Learning Ordinal Relations and Angles for Expensive Many-Objective Optimization
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the LORA-MOO framework, a surrogate-assisted evolutionary many-objective optimization algorithm that utilizes an ordinal-regression-based surrogate for convergence and m-1 surrogates for diversity modeling. The empirical study demonstrates its effectiveness, showing that LORA-MOO outperforms baseline algorithms on various benchmarks, including a new real-world NAS experiment with various network architectures and eight objectives, achieving a mean HV value of 0.5776 over 30 independent runs. The authors provide a detailed time complexity analysis of LORA-MOO, indicating that the overall training complexity is \(O(n^3)\) and prediction complexity is \(O(n^2*N)\), highlighting that increasing the number of objectives has limited impact on LORA-MOO's time cost compared to other optimization algorithms. However, the paper lacks clarity on the novelty of its contributions, particularly in distinguishing LORA-MOO from existing methods.

### Strengths and Weaknesses
Strengths:
- The problem addressed is significant and relevant.
- The paper is well-written, with clear technical details and motivations.
- The empirical results indicate that LORA-MOO improves the IGD metric compared to benchmarks.
- The experimental results show LORA-MOO's superior performance in a real-world context.
- The time complexity analysis is thorough, providing insights into the algorithm's efficiency relative to other methods.

Weaknesses:
- Major:
  1. The paper is repetitive in certain sections (Lines 113-116).
  2. The initial dataset size of 11D-1 is overly specific (Line 121).
  3. The algorithm descriptions are too detailed for NeurIPS, more suited for EC journals (Lines 121-134).
  4. The selection criteria are overly simplistic.
  5. The meaning of LORA-MOO is unclear.
  6. Comparisons with some HV-based MOBO methods are missing and inaccurately justified.
- Minor:
  - Numerous grammatical errors throughout the paper.
  - The ablation studies do not convincingly demonstrate the necessity of all components, as they focus primarily on parameters rather than component contributions.
  - The distinction between time complexity and runtime analysis is not adequately addressed, leading to confusion regarding the terminology used.

### Suggestions for Improvement
We recommend that the authors improve the clarity and conciseness of the manuscript by addressing the repetitive content and overly specific details. The authors should also clarify the meaning of LORA-MOO and provide a more comprehensive comparison with state-of-the-art methods, including HV-based MOBO methods. Additionally, we suggest conducting ablation studies that explicitly demonstrate the necessity of each component through component replacement rather than parameter adjustments. The authors should refine their terminology to avoid confusion between time complexity and runtime analysis, ensuring that their analysis aligns with standard definitions in the literature. Finally, we encourage the authors to expand the empirical study to include more real-world applications and ensure that the presentation of results is clear and informative, potentially considering submission to a more suitable venue like TEC.