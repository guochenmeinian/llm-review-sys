ID: V8GHCGYLkf
Title: Temporally Disentangled Representation Learning under Unknown Nonstationarity
Conference: NeurIPS
Year: 2023
Number of Reviews: 22
Original Ratings: 7, 6, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Nonstationary Temporal Disentangled Causal Representation Learning (NTDC), addressing the identification of latent representations from sequential data that are stationary within contexts but non-stationary between them. The authors propose a method that identifies time-delayed latent causal variables without relying on observed auxiliary variables, formulating the problem as a discrete Markov process and establishing the identifiability of latent independent components. The experimental results on synthetic and real-world datasets demonstrate the method's effectiveness in recovering latent variables.

### Strengths and Weaknesses
Strengths:
- The paper features impressive experimental results, particularly on simulated data and the MoSeq dataset analyzing mouse behavior.
- The graphical model effectively abstracts time series data, providing a more interpretable model of underlying system behavior, supported by identifiability results.

Weaknesses:
- The assumptions in Theorem 2 are unintuitive, potentially limiting the theorem's practical utility for practitioners who may struggle to assess their validity in real data.
- The writing quality is inconsistent, with some sections requiring proofreading and clearer terminology definitions, particularly regarding jargon like "domain indices."
- The evaluation lacks comparisons with established sequential disentanglement baselines, particularly on real-world data, where only one method is used for comparison.

### Suggestions for Improvement
We recommend that the authors improve the clarity of assumptions in Theorem 2 by providing more intuitive conditions or examples of distributions where these assumptions hold or fail. Additionally, enhancing the writing quality through proofreading and clearer definitions of technical terms would benefit the presentation. We also suggest including comparisons with other relevant sequential disentanglement methods, such as SKD and C-DSVAE, to strengthen the evaluation section.