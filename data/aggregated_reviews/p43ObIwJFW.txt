ID: p43ObIwJFW
Title: Learning to Solve Quadratic Unconstrained Binary Optimization in a Classification Way
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 5, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Value Classification Model (VCM), a neural solver for the Quadratic Unconstrained Binary Optimization (QUBO) problem. VCM employs a Depth Value Network (DVN) and a Value Classification Network (VCN) to efficiently generate solutions without optimal labels, achieving near-optimal solutions in milliseconds. The model captures value features effectively by leveraging the symmetry of the problem's matrix, thus reducing computational overhead compared to traditional deep reinforcement learning (DRL) methods.

### Strengths and Weaknesses
Strengths:
- The introduction of the DVN, which effectively captures valuable features without the performance degradation seen in traditional GCN models.
- VCM demonstrates impressive computational efficiency and quality of solutions, achieving near-optimal results rapidly.
- The model's ability to generalize across various instance sizes without retraining showcases its robustness and adaptability.

Weaknesses:
- The scalability and adaptability of the model to larger datasets or different types of QUBO instances remain unvalidated.
- The paper lacks detailed comparisons with existing state-of-the-art models specifically designed for hypergraph networks, which could clarify the model's relative performance.
- There is a need for a more thorough examination of the proposed approach against advanced methods and practical problems, such as MaxCut or Maximum Independent Set.

### Suggestions for Improvement
We recommend that the authors improve the paper by including a comparison with the state-of-the-art PI-GNN model from Schuetz et al. [1] to validate the performance of VCM against relevant baselines. Additionally, the authors should consider discussing the implications of using local optima generated by the greedy flip algorithm as labels for supervised learning compared to unsupervised methods. It is also crucial to conduct ablation studies comparing these approaches. Finally, we suggest that the authors explore the adaptation of their framework to constrained optimization problems, which are prevalent in practical applications.