ID: ZMn2SPUgkU
Title: VERIFIED: A Video Corpus Moment Retrieval Benchmark for Fine-Grained Video Understanding
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 7, 4, 7, 8, -1, -1, -1
Original Confidences: 3, 4, 3, 3, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel benchmark and annotation pipeline for fine-grained Video Corpus Moment Retrieval (VCMR), introducing VERIFIED, which utilizes LLMs and LMMs to generate detailed static and dynamic captions. The authors evaluate reconstructed datasets against baseline VCMR models, highlighting the limitations of existing models in handling fine-grained datasets. The paper emphasizes the importance of detailed textual descriptions for effective video moment retrieval.

### Strengths and Weaknesses
Strengths:
1. The annotation pipeline effectively rebuilds fine-grained VCMR datasets using LLMs and LMMs, incorporating a noise evaluator to mitigate hallucinations.
2. The introduction of a challenging VCMR benchmark that focuses on fine-grained video features is expected to be valuable to the community.
3. The implementation details of the pipeline are well-documented, enhancing reproducibility.

Weaknesses:
1. The reliability of the evaluation model is questionable, lacking direct hallucination analysis or human spot-checking.
2. The evaluation of dynamic enhanced captions is absent, and the analysis of benchmarking results is overly general, limiting insights into model performance improvement.
3. The experimental section lacks depth, failing to discuss the benchmark's challenges for current models or provide qualitative analysis and visualization of test samples.

### Suggestions for Improvement
We recommend that the authors improve the evaluation model's reliability by incorporating direct hallucination analysis or human spot-checking. Additionally, the authors should include evaluations for dynamic enhanced captions and provide a more detailed analysis of benchmarking results to elucidate the reasons behind model performance limitations. We also suggest conducting ablation studies to clarify the contributions of each component in the pipeline and generating visualizations for test samples to better illustrate the fine-grained capabilities of the benchmark. Lastly, simplifying the mathematical notations in the methods section would enhance clarity.