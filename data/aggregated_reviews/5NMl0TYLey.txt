ID: 5NMl0TYLey
Title: InfoCL: Alleviating Catastrophic Forgetting in Continual Text Classification from An Information Theoretic Perspective
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a continual learning method for text classification in a class-incremental setting, proposing InfoCL, which employs fast-slow and current-past contrastive learning to enhance representation learning and mitigate representation corruption. The authors provide a thorough analysis and demonstrate competitive performance across four classification tasks (fewrel, tacred, maven, and hwu64).

### Strengths and Weaknesses
Strengths:
- The method is well-motivated, with solid analysis and competitive experimental results.
- The information theoretic perspective is insightful and adds depth to the study.
- The paper is well-organized, and the methodology is relatively clear, particularly the focus on representation bias.

Weaknesses:
- The scope of experiments is limited to only four tasks, necessitating additional validation across more classification tasks.
- Clarity in writing needs improvement, particularly regarding the rationale behind the fast-slow method and its implementation; pseudo-code could enhance understanding.
- Some relevant works on contrastive learning have not been adequately discussed, which could provide context for the proposed method.
- Lack of provided code and computational resource details hinders reproducibility.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing, especially in explaining the motivation for the fast-slow contrastive learning approach and how to implement it, potentially by including pseudo-code. Additionally, we suggest discussing related works such as Co2L and CLASSIC to contextualize their contributions better. To enhance reproducibility, the authors should provide code and detailed information about the computational resources required for their method. Finally, we encourage the authors to expand their experimental validation to include more classification tasks to substantiate the generalizability of their approach.