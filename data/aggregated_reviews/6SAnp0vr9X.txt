ID: 6SAnp0vr9X
Title: Scale-invariant Optimal Sampling for Rare-events Data and Sparse Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 6, 7, 8, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on learning a sparse model under rare events and scale-invariance, proposing an optimal subsampling function to address scale-invariance in a Lasso-regularized model. The authors provide experimental results demonstrating the effectiveness of their subsampling scheme. The scale-invariant optimal subsampling function aims to improve parameter estimation and variable selection in the context of rare-events data, minimizing prediction error regardless of scaling transformations applied to inactive features.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and provides clear explanations of the methodology and implications.
- It introduces a novel scale-invariant optimal subsampling function that addresses inactive features in rare-events data, enhancing parameter estimation and variable selection.
- The theoretical foundation is robust, with discussions on assumptions and proofs supporting the method.
- Empirical evidence shows significant improvements in prediction error minimization and estimation efficiency.

Weaknesses:
- The problem setting appears very specific, lacking motivation for the simultaneous consideration of rare events, sparse models, and scale-invariance.
- The theoretical results lack discussion on proof strategies or novel techniques, leaving the technical challenges and their resolutions unexplored.
- The MSCL estimator is not defined in the paper, complicating comparisons made in section 4.
- Questions remain regarding the significance of minimizing $tr(M_{w(A)})$ and the implications of scaling transformations on inactive features.

### Suggestions for Improvement
We recommend that the authors improve the motivation for the specific problem setting by discussing its broader relevance. Additionally, we suggest including a discussion on proof strategies and the technical challenges encountered in developing the theoretical results. The authors should define the MSCL estimator clearly in the paper to facilitate understanding of the comparisons made. Furthermore, we encourage the authors to elaborate on the significance of minimizing $tr(M_{w(A)})$ and clarify the implications of scaling transformations on inactive features.