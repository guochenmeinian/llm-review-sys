ID: gsi9lJ3994
Title: NVFi: Neural Velocity Fields for 3D Physics Learning from Dynamic Videos
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 4, 7, 6, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 5, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an algorithm for dynamic view synthesis using multi-view video data, introducing a keyframe dynamic field and an interframe velocity field to represent motion, geometry, and color information. The authors propose a new representation that disentangles appearance and geometry from velocity, enabling applications such as future frame extrapolation and dynamic motion transfer. Additionally, two novel synthetic datasets are introduced to support the algorithm's validation. The method is evaluated primarily on synthetic datasets and the NVIDIA Dynamic Scene dataset, with the authors arguing that their approach captures complex dynamics, despite challenges with chaotic motions in datasets like DyNeRF. They acknowledge the limitations of the Nerfies dataset for their model due to its lack of temporal information and plan to include a discussion of the related work "Temporal-MPI" in future revisions.

### Strengths and Weaknesses
Strengths:
- The introduction of two novel datasets for dynamic object and indoor scenarios addresses existing limitations in available datasets for view synthesis.
- The method is well-motivated, intuitive, and easy to follow, with impressive results and applications, particularly in 3D semantic field segmentation.
- The authors have conducted extensive experiments, including evaluations on real-world datasets, demonstrating improved performance in future frame extrapolation.
- The method shows promise in capturing meaningful physical dynamics, particularly in controlled environments.
- Additional ablation studies provide insights into the impact of keyframes and training settings on performance.
- The paper is well-written, with a coherent structure and comprehensive experiments that support its claims.

Weaknesses:
- The concept of learning a canonical field and deformation field has been extensively discussed in prior literature, raising questions about the novelty of the proposed approach.
- The proposed datasets show minimal distinctions from existing datasets like the Nvidia dataset and Nerfie dataset.
- The algorithm struggles with chaotic motions, leading to static frame predictions rather than meaningful extrapolations.
- The reliance on synthetic datasets raises concerns about the generalizability of the results to more complex real-world scenarios.
- The method's performance is limited in intricate situations, such as uniform motion between frames.
- The paper lacks a detailed discussion of limitations, particularly regarding the absence of real-world data validation and the method's performance with monocular videos or sparse views.

### Suggestions for Improvement
We recommend that the authors improve the discussion of limitations, particularly addressing the lack of real-world data validation and the method's performance with monocular videos. Additionally, we suggest providing a clearer explanation of the losses and PINN used in the paper, as well as enhancing the precision of Algorithm 1. It would also be beneficial to explore the effect of keyframe selection and the number of cameras in the analysis, as these factors are crucial in dynamic scenes. We further recommend that the authors improve the evaluation of their method by testing on a broader range of real-world datasets to enhance generalizability. Addressing the challenges posed by chaotic motions in datasets like DyNeRF could strengthen their approach. We also suggest that the authors consider incorporating insights from the "Temporal-MPI" paper more thoroughly, particularly regarding interpolation techniques. Lastly, further exploration of the model's performance in scenarios with uniform motion could provide valuable insights into its robustness.