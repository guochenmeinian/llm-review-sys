ID: XHPonJtLvR
Title: Towards Energy-efficient Federated Learning via INT8-based Training on Mobile DSPs
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new energy-efficient federated learning (FL) framework called Q-FedUpdate, which enables INT8-based training on mobile DSP chips. The framework maintains a global FP32 model while aggregating small model updates, integrating efficient batch quantization with CPU cooperation. Q-FedUpdate aims to reduce power consumption during on-device training and accelerate model convergence without sacrificing precision. The authors highlight the significance of addressing high energy consumption in cross-device FL, particularly for mobile devices.

### Strengths and Weaknesses
Strengths:
1. The paper addresses a timely and important challenge of energy consumption in edge devices participating in FL.
2. It is well-structured and easy to follow, providing sufficient background on FL and quantization.
3. Comprehensive experiments demonstrate the effectiveness of the proposed method.

Weaknesses:
1. The claim of being the first work on model quantization in FL is inaccurate; comparisons with existing works are needed.
2. The novelty of aggregating local updates instead of local models is limited and has been widely adopted in prior communication works.
3. The meaning of the pipelining approach is unclear, and its impact on energy consumption versus training speed needs further clarification.
4. The effectiveness of Q-FedUpdate on complex datasets beyond CIFAR-10, CIFAR-100, and FEMNIST is uncertain, as is its adaptability to various mobile DSP architectures.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the relevance of the paper to the conference, particularly in relation to existing literature on model quantization in FL. Additionally, the authors should clarify the pipelining mechanism's role in energy efficiency and provide more detail on how energy consumption is measured during different phases. It would be beneficial to explore Q-FedUpdate's performance with complex datasets and its compatibility with existing optimizers and schedulers in FL. Finally, the authors should address potential challenges in deploying Q-FedUpdate across diverse mobile devices and elaborate on its applicability to other accelerators like TPU and FPGA.