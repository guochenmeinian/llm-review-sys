ID: y2J5dAqcJW
Title: Measuring Steerability in Large Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 2
Original Ratings: 8, 4
Original Confidences: 4, 3

Aggregated Review:
### Key Points
This paper presents the concept of steerability in large language models (LLMs), emphasizing the need for models that can be guided to generate outputs aligned with specific user objectives. The authors propose a quantitative, goal-oriented definition of steerability based on sensitivity and directionality. They introduce an empirical probe to measure steerability through text rewriting tasks, revealing that even advanced models like GPT-3.5, GPT-4, Llama3, and Mistral exhibit limitations in steerability, often deviating from user instructions. The study attributes these limitations to side effects where changes in one aspect lead to unintended shifts in others.

### Strengths and Weaknesses
Strengths:  
- The paper offers a novel and practical definition of steerability.  
- It establishes a robust evaluation framework for comparing steerability across different LLM models, setting a benchmark for future research.  
- The analysis of side effects when steering LLMs is insightful and relevant to the broader context of LLM usage.  
- The comparison of models from various architectures provides a nuanced understanding of steerability.

Weaknesses:  
- The methodology, particularly the 'goal space' concept, lacks clarity, making it difficult to understand how input and output texts are represented.  
- The comparison of the proposed methodology with existing steerability methods is insufficiently motivated.  
- The narrow scope of steerability evaluation (text rephrasing) necessitates additional context on its practical importance.  
- The "Defining Steerability" section could benefit from clearer organization, particularly regarding the description of space z.  
- The necessity of a value of 1 for steerability is unclear and warrants evaluation.  
- The explanation of "overshooting" and angle sizes needs expansion for better clarity.  
- The overlapping histograms of steerability metrics complicate the interpretation of results.  
- The conclusion regarding LLMs' steerability requires stronger support from existing literature.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the 'goal space' concept, detailing how input and output texts are represented. Additionally, the authors should provide a more robust motivation for their methodology in comparison to existing methods. Expanding the introduction to include the practical significance of steerability would enhance context. We suggest reorganizing the "Defining Steerability" section for better comprehension and evaluating the rationale behind the necessity of a value of 1 for steerability. Clarifying the descriptions of "overshooting" and angle sizes, as well as addressing the overlapping histograms in the results, would improve the paper's clarity. Finally, we advise the authors to substantiate their conclusion about LLMs' steerability with a more comprehensive evaluation against existing literature.