ID: 2I821Dypa2
Title: Model Editing as a Robust and Denoised variant of DPO: A Case Study on Toxicity
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 9, 7, 6
Original Confidences: 3, 4, 3

Aggregated Review:
### Key Points
This paper presents ProFS, a novel model alignment method aimed at enhancing the safety of large language models (LLMs) by reducing toxicity without extensive preference data for training. ProFS identifies and projects out harmful subspaces within model parameters, offering a sample-efficient and noise-robust alternative to Direct Preference Optimization (DPO). The method employs factor analysis to detect toxic subspaces and applies a projection filter to mitigate toxicity during model inference. The paper provides strong theoretical validation and empirical results demonstrating ProFS's effectiveness across multiple models and datasets.

### Strengths and Weaknesses
Strengths:
- ProFS achieves significant toxicity reduction with fewer data samples compared to DPO, showcasing high efficiency.
- The method exhibits superior robustness to noisy data, which is crucial for real-world applications, reducing susceptibility to mislabeled training data.
- The paper includes extensive experiments comparing ProFS with DPO, consistently showing improved toxicity reduction and robustness.

Weaknesses:
- There is a potential risk of overfitting to non-toxic data by focusing too strongly on eliminating toxicity, warranting further evaluation.
- The effectiveness of ProFS on a wider range of tasks and model architectures is not demonstrated, limiting its broader significance.
- The assumption of a low-dimensional toxicity subspace in MLP layers is not thoroughly investigated, and the relationship between the proposed method and attention-based toxic identification requires better explanation.

### Suggestions for Improvement
We recommend that the authors improve the evaluation of ProFS by demonstrating its effectiveness across a broader range of tasks and model architectures to enhance its significance. Additionally, the authors should investigate how to identify the low-dimensional structure of the toxicity subspace in MLP layers. A clearer explanation of the relationship between the MLP-based method and attention-based toxic identification, along with comparative experiments, would strengthen the paper. Finally, we suggest comparing ProFS with other alignment methods beyond DPO to provide a more comprehensive analysis.