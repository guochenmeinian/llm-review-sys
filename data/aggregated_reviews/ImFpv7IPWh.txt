ID: ImFpv7IPWh
Title: Information Bottleneck of Quantum Neural Networks
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 3, 7, 4
Original Confidences: 4, 4, 3

Aggregated Review:
### Key Points
This paper presents an investigation into the expressiveness of quantum neural networks (QNNs) through the lens of the information bottleneck, comparing it with classical neural networks (DNNs). The authors conduct numerical experiments on synthetic data to support their claim that QNNs exhibit greater expressiveness than classical counterparts. However, the review identifies significant flaws in the methodology, particularly regarding the treatment of quantum representations and the assumptions made about quantum and classical information.

### Strengths and Weaknesses
Strengths:  
- The approach of applying the information bottleneck concept to compare QNNs and DNNs is novel and intriguing.  
- The numerical simulations suggest that QNNs can learn more expressive representations than DNNs.

Weaknesses:  
- The representation of quantum states as classical information is flawed, neglecting the need for tomography and the implications of Holevo's theorem.  
- The authors incorrectly assert that quantum entropies can be substituted with classical ones in certain contexts.  
- The writing contains numerous typographical and grammatical errors, detracting from clarity.  
- The analysis is limited to a single dataset and does not adequately represent the behavior of QNNs under various noise models.  
- Critical technical details are missing, hindering reproducibility and validation of results.

### Suggestions for Improvement
We recommend that the authors improve the treatment of quantum representations by acknowledging the necessity of tomography for extracting classical information from quantum states. Additionally, the authors should clarify their claims regarding quantum and classical entropies, ensuring accurate distinctions are made. To enhance the manuscript's clarity, we suggest running it through automated grammar-checking tools to address typographical errors. 

Incorporating additional noise models, such as depolarizing noise and thermal relaxation, would provide a more realistic assessment of QNN performance. We also recommend including data re-uploading in the QNN to strengthen the expressivity claims. Providing anonymized source code would significantly improve reproducibility. Furthermore, the authors should include essential technical details, such as data dimensionality and model parameters, to enhance the clarity and utility of the work. Finally, we advise against making speculative claims about the presence of barren plateaus without rigorous theoretical substantiation.