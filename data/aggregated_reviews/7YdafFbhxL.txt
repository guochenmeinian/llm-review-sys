ID: 7YdafFbhxL
Title: Provably and Practically Efficient Adversarial Imitation Learning with General Function Approximation
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 5, 6, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method for adversarial imitation learning (AIL) called Optimization-Based AIL (OPT-AIL), which operates under general function approximation. The authors propose an algorithm that achieves polynomial expert sample complexity and interaction complexity, marking it as the first efficient AIL method in this context. The paper includes both theoretical guarantees and empirical validation, demonstrating that OPT-AIL outperforms existing state-of-the-art deep AIL methods.

### Strengths and Weaknesses
Strengths:
- The introduction of OPT-AIL addresses both theoretical and practical limitations of existing AIL methods.
- The paper provides solid theoretical results and empirical validation, showcasing the effectiveness of the proposed algorithm.
- The error decomposition presented offers a new perspective on understanding AIL.

Weaknesses:
- The complexity measure and core ideas of the algorithm are not entirely novel, relying on existing works like GEC and optimism-based methods.
- The practical implementation lacks innovation, as the use of a no-regret algorithm for reward updates is not new.
- There are numerous typographical errors throughout the paper, which detract from its clarity.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by correcting the identified typographical errors. Additionally, we suggest that the authors elaborate on the theoretical difficulties and novelties associated with applying existing ideas to AIL. It would also be beneficial to include comparisons with state-of-the-art algorithms such as FILTER and HyPER in the experimental results to strengthen the claims of superiority. Furthermore, we encourage the authors to clarify the implementation of neural networks within the architecture and provide more detailed discussions on the error measures mentioned.