ID: DIeZu6nqvo
Title: EgoTracks: A Long-term Egocentric Visual Object Tracking Dataset
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 6, 7, 8, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents EgoTracks, a long-term egocentric visual object tracking dataset derived from Ego4D, which emphasizes the re-detection challenges posed by target object occlusions and large camera motions. The authors propose a modified version of the STARK tracker, named EgoSTARK, tailored for the unique properties of egocentric videos. The dataset features extensive annotations and long video sequences, making it a significant contribution to the field of visual object tracking. Additionally, the authors provide a comprehensive analysis of long-term tracking challenges in egocentric video, particularly focusing on re-detection issues. They propose several future research directions, including the development of stronger features for object association, leveraging spatial signals from camera trajectories, and creating global, multi-view object representations. The authors also clarify the role of third-person spatiotemporal priors, indicating that while useful, they may not generalize well to egocentric contexts. Furthermore, they highlight the performance of their EgoSTARK model on other datasets, demonstrating its utility for large-scale pre-training.

### Strengths and Weaknesses
Strengths:  
- The dataset is a valuable resource for the community, being significantly larger and more challenging than existing datasets.  
- The authors provide comprehensive experimental results that highlight the performance of various deep trackers on EgoTracks, demonstrating the dataset's difficulty.  
- The paper identifies key challenges in long-term tracking and proposes actionable future research directions.  
- The authors provide empirical evidence supporting the need for improved feature embeddings and multi-view representations.  
- The revision includes additional experiments that validate the effectiveness of the EgoSTARK model on other datasets.  
- The paper is well-written, with clear comparisons to prior work and insightful analyses.

Weaknesses:  
- The evaluation of many trackers lacks re-detection algorithms, which are crucial for high performance on the dataset.  
- Some figures and tables require clearer captions and explanations to enhance reader understanding.  
- The evaluation metrics primarily focus on short-term tracking, which may not adequately reflect long-term tracking performance.  
- The clarity of figure and table captions requires improvement to enhance reader understanding.  
- The discussion on re-detection capabilities could be more explicitly differentiated from other evaluation considerations.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by including more tracking-by-detection algorithms to assess re-detection performance effectively. Additionally, we suggest refining figure and table captions to provide meaningful conclusions, particularly regarding which trackers perform well and why. The authors should also consider developing metrics that better reflect long-term tracking success, such as the successful re-detection rate. Furthermore, clarifying the oracle settings in Table 4 and providing more detailed statistics on the objects being tracked would enhance the dataset's usability. We encourage the authors to include a more detailed discussion of the re-detection capabilities of various baselines in relation to other evaluation metrics. Lastly, we encourage a deeper discussion of future work in the camera-ready version, as this would benefit the community in following the dataset and developing new methods.