ID: WCxfj3PsWb
Title: Multi-level Adaptive Contrastive Learning for Knowledge Internalization in Dialogue Generation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Multi-level Adaptive Contrastive Learning (MACL) framework aimed at addressing knowledge regurgitation in knowledge-grounded dialogue generation. The authors identify the issue of models duplicating knowledge segments without true comprehension, leading to dull responses. MACL introduces both token-level and sequence-level contrastive learning to penalize degeneration behaviors, achieving state-of-the-art results on the WoW dataset, with significant improvements in knowledge utilization and content quality.

### Strengths and Weaknesses
Strengths:
- The paper effectively identifies the critical problem of knowledge regurgitation in dialogue generation and proposes a novel solution through MACL.
- The dual approach of token-level and sequence-level contrastive learning offers a comprehensive strategy to mitigate degeneration behaviors.
- Thorough evaluations against multiple baselines demonstrate the effectiveness of the proposed method, supported by both automated and human metrics.

Weaknesses:
- Clarity issues exist in Section 4, particularly regarding the explanation of token-level contrastive learning and the integration of TFL into the loss function.
- The reliance on a single dataset (WoW) raises concerns about the generalizability of the findings, and the absence of knowledge-grounded dialogue baselines limits the robustness of comparisons.
- Implementation details are insufficient, which may hinder reproducibility, and the treatment of knowledge selection and response generation as independent processes may overlook their interdependence.

### Suggestions for Improvement
We recommend that the authors improve clarity in Section 4, particularly regarding the definitions and roles of Î²(y_c) and TFL in the loss function. Additionally, we suggest incorporating experiments on additional datasets to validate the generalizability of the findings and including knowledge-grounded dialogue baselines to strengthen the comparative analysis. Providing more detailed implementation information, including architecture and hyperparameters, would enhance reproducibility. Lastly, we encourage the authors to explore the relationship between knowledge selection and response generation more thoroughly, potentially demonstrating the effects of training on predicted knowledge rather than solely on golden knowledge.