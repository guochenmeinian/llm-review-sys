ID: TutGINeJzZ
Title: A Huber Loss Minimization Approach to Mean Estimation under User-level Differential Privacy
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 5, 6, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a user-level differentially private mechanism for mean estimation that utilizes Huber loss minimization. The authors demonstrate that their approach is robust to heavy-tailed distributions and effectively addresses data imbalance among users. The method is theoretically and empirically evaluated, showing advantages over existing estimators.

### Strengths and Weaknesses
Strengths:
- The construction of smooth sensitivity and its analysis in both balanced and imbalanced user settings is novel.
- The proposed method is well-analyzed, providing both error upper bounds and empirical evaluations.
- The writing is clear, and the arguments are well-structured.

Weaknesses:
- The convergence results (Theorem 5) may not apply to generic $w_i$'s, and the use of $m_i \land m_c$ is unclear. The authors should clarify the implications for federated learning scenarios.
- A detailed analytical comparison with WME is needed, extending beyond Section G.
- The definition of robustness should be clarified, including its relation to heavy-tailed data and outliers.
- The inequality in (10) appears to have a typo, and $\lambda$ in Theorem 4 requires a definition.
- Figures are too small, hindering result verification, and the meaning of the gray line in Figure 2(b) is unclear.
- The authors should explain the choice of Huber loss and whether their method includes innovations beyond its basic application.
- The assumption that the algorithm requires the sample size of each local user to determine the Huber loss parameter $T$ is a strong one.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the convergence results in Theorem 5 and provide a more detailed analytical comparison with WME. Additionally, the authors should explicitly define robustness and outliers, clarify the implications of the inequality in (10), and define $\lambda$ in Theorem 4. The figures should be enlarged for better readability, and the authors should clarify the meaning of the gray line in Figure 2(b). Furthermore, the authors should elaborate on their choice of Huber loss and discuss any potential innovations in their method. Lastly, addressing the strong assumption regarding the sample size of local users would strengthen the paper.