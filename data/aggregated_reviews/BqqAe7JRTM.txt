ID: BqqAe7JRTM
Title: Dynamic Security Analysis of JavaScript: Are We There Yet?
Conference: ACM
Year: 2024
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a systematic evaluation of JavaScript dynamic analysis tools, focusing on compatibility, transparency, coverage, and performance. The authors analyze eight tools, including Project Foxhound and PanoptiChrome, ultimately narrowing the evaluation to six due to usability issues. The study reveals that many tools struggle with modern web compatibility and highlights Project Foxhound's superior performance across all criteria, making it the only viable option for practical use.

### Strengths and Weaknesses
Strengths:
- Practical Methodology: The use of real-world websites provides realistic insights into tool effectiveness.
- Comprehensive Analysis: The evaluation covers multiple aspects of tool performance, including syntactic compatibility and performance overhead.
- Detailed Performance Metrics: Specific performance measurements are provided, explaining overhead levels across tools.
- Clear Comparative Analysis: The paper effectively contrasts browser-based and language-based tools, detailing their advantages and limitations.

Weaknesses:
- Lack of Improvement Discussion: The authors do not provide specific suggestions for enhancing existing tools based on their findings.
- Methodological Clarity: Some methodological choices lack clear justification, and the contributions of the paper are not well articulated.
- Limited Tool Evaluation: The final number of evaluated tools is unclear, and the selection criteria for discarded tools are not sufficiently detailed.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the contributions section to explicitly outline the paper's key contributions. Additionally, we suggest clarifying the rationale behind the insight regarding code rewriting tools in Section 2.1. It would be beneficial to specify the final number of evaluated tools and provide details on the discarded tools' reasons. Including a precise version of automation libraries that are considered modern would enhance the methodology's clarity. Furthermore, we encourage the authors to discuss the sustainability of results, particularly regarding browser modification tools, and to consider including a broader range of dynamic analysis tools to strengthen the study's generalizability.