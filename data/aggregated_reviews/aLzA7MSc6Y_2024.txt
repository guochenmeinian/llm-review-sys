ID: aLzA7MSc6Y
Title: Symmetric Linear Bandits with Hidden Symmetry
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 7, 3, 7, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis of symmetric linear bandits with hidden symmetry, focusing on high-dimensional settings where the reward function remains invariant under unknown group actions. The authors establish an impossibility result indicating that knowledge of the symmetry group alone does not improve algorithm performance. They introduce a cardinality condition under which a new algorithm, EMC (Explore Models then Commit), achieves a regret bound of \(O(d_0^{1/3} T^{2/3})\) when the partition is known to belong to a sub-exponential set, and an improved bound of \(O(d_0 \sqrt{T})\) under the assumption of well-separated models. The paper emphasizes theoretical contributions, including proofs and regret analysis, while lacking empirical validation. Additionally, the authors propose investigating whether greedy algorithms can approximate solutions to optimization problems, specifically addressing equation (5), although they acknowledge that this is complex and beyond the current scope of the paper.

### Strengths and Weaknesses
Strengths:
- Originality in formulating the problem of symmetric linear bandits with hidden symmetry, extending the sparse linear bandit framework.
- Rigorous technical analysis with well-structured proofs and a comprehensive theoretical framework.
- Clear articulation of problem motivation and significance, with potential implications for reinforcement learning and online optimization.
- Engagement with reviewer feedback and willingness to explore additional methods, such as greedy algorithms, in future work.

Weaknesses:
- Limited empirical validation, with no experimental results or simulations to support the theoretical claims.
- Complexity of key concepts, particularly the equivalence between sparsity and interval partitions, which could benefit from more intuitive explanations.
- Lack of practical applicability discussion, including how the proposed algorithms could be implemented in real-world scenarios.
- Insufficient exploration of the computational complexity of the algorithms, particularly the EMC algorithm.
- The necessity of knowing the set \(\mathcal{Q}_{d,\le d_0}\) as input, which raises questions about adaptivity and practical implementation.
- The response does not adequately address concerns regarding computational limitations, particularly the complexity of testing all models in the set \(\mathcal{Q}_{d,\le d_0}\) without an efficient approximation scheme.

### Suggestions for Improvement
We recommend that the authors improve the paper by including empirical results, even on synthetic datasets, to illustrate the performance of the EMC algorithm and its comparison with existing methods. Additionally, we suggest providing more intuitive explanations or concrete examples for complex concepts, particularly the connection between interval partitions and sparsity. A detailed discussion on the practical implications of the proposed algorithms, including how to obtain the input set \(\mathcal{Q}_{d,\le d_0}\) in real-world scenarios, would enhance the paper's relevance. Furthermore, addressing the computational complexity of the proposed algorithms and exploring potential adaptations for varying problem complexities would strengthen the work. Lastly, we recommend that the authors improve their discussion on computational limitations by demonstrating that if equation (5) is solved approximately (e.g., via greedy search), the optimal \(\theta\) found in the next step would not yield significantly worse performance, ensuring that the regret remains similarly bounded. Consider providing a strategy to reduce the size of the set \(\mathcal{Q}_{d,\le d_0}\) to alleviate the prohibitive complexity of \(O(d^{d_0})\).