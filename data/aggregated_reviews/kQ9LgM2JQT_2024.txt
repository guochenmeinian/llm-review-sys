ID: kQ9LgM2JQT
Title: QGFN: Controllable Greediness with Action Values
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 5, 7, 4, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents "QGFN: Controllable Greediness with Action Values," which enhances Generative Flow Networks (GFNs) by integrating action-value estimates (Q-values) to manage the sampling policy's greediness. The authors propose three variants—p-greedy, p-quantile, and p-of-max—aimed at balancing high-reward sample generation with diversity. Comprehensive experiments demonstrate that QGFN significantly improves high-utility sample generation while maintaining diversity across tasks like molecule generation and RNA design. Additionally, the paper analyzes GFlowNet training on the QM9 environment, emphasizing the importance of reporting average metrics and their implications for model evaluation. The authors propose a method for hyperparameter selection, questioning its effectiveness compared to standard sampling methods, and highlight the need for clarity in the presentation of results and comparisons to baselines.

### Strengths and Weaknesses
Strengths:
- **Innovative Approach**: The introduction of Q-values to control sampling greediness in GFNs is a novel solution to the challenge of balancing high-reward sample generation with diversity.
- **Comprehensive Evaluation**: The paper includes thorough experiments across various tasks, providing strong empirical evidence for QGFN's effectiveness.
- **Well-Developed Motivation**: The paper is well-written, with a clear motivation and discussion of design choices for incorporating Q-value estimation.
- The authors provide additional experiments and clarifications that enhance the understanding of their methodology.
- The improved figures in the rebuttal PDF demonstrate a better presentation of results.

Weaknesses:
- **Lack of Guidance on QGFN Variants**: The paper does not provide a method for selecting among the QGFN variants, which perform differently in varying environments.
- **Insufficient Complexity in Evaluation**: The performance of QGFN on more complex environments, such as graph combinatorial optimization problems, remains unaddressed.
- **Missing Recent Works**: The paper overlooks recent studies that address sampling high-reward candidates with diversity.
- **Insufficient Description of Q-Network Training**: The training process for the Q-network lacks clarity, making it difficult to understand the learning objectives.
- **Theoretical Guarantees**: There is a lack of theoretical analysis regarding the reliability of QGFN, particularly in cases where Q is not accurately trained.
- Some critical aspects, such as fair comparisons to baselines and clarity of presentation, remain inadequately addressed.
- The results do not convincingly support the proposed benefits of hyperparameter selection over direct sampling.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the selection process for QGFN variants, particularly in environments with varying action spaces. Additionally, we suggest including evaluations on more complex tasks, such as graph combinatorial optimization problems, to better assess QGFN's performance. The authors should also incorporate recent works related to sampling high-reward candidates to enhance the paper's relevance. Furthermore, we encourage the authors to provide a more detailed description of the Q-network training process and include a theoretical analysis to establish the reliability of QGFN under various conditions. We also recommend that the authors improve the clarity of their results by ensuring that comparisons to baselines are more explicitly addressed. Providing a reference for the use of 0.7 in training GFlowNet on QM9 would enhance the paper's credibility. Finally, we suggest that the authors clarify the effectiveness of their hyperparameter selection method in relation to standard sampling approaches, particularly in terms of computational cost versus sample quality.