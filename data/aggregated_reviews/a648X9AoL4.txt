ID: a648X9AoL4
Title: Large Language Model Guided Tree-of-Thought
Conference: NeurIPS
Year: 2023
Number of Reviews: 7
Original Ratings: 3, 3, 2, 4, 4, -1, -1
Original Confidences: 5, 4, 4, 4, 4, -1, -1

Aggregated Review:
### Key Points
This paper presents the Tree-of-Thought (ToT) framework, aimed at enhancing the problem-solving capabilities of large language models (LLMs) through a backtracking approach in a tree-like structure. The authors propose an architecture that includes a checker module, memory module, ToT controller, and prompter agent, evaluated on Sudoku puzzles of varying sizes. The results indicate that ToT significantly improves performance compared to LLMs without this augmentation.

### Strengths and Weaknesses
Strengths:
1. The motivation for transitioning from linear reasoning to a tree-like structure is well-founded, addressing a significant limitation of autoregressive LLMs.
2. The proposed method is technically sound, with empirical results demonstrating effectiveness, particularly on more challenging Sudoku puzzles.
3. The introduction clearly identifies limitations of LLMs in complex problem-solving, setting a relevant context for the proposed approach.

Weaknesses:
1. The evaluation is limited to a single task (Sudoku) and lacks sufficient experimental data, raising questions about the generalizability of the method.
2. The paper does not adequately test the various components of the ToT framework, such as the policy-gradient training mentioned, leaving the contributions unclear.
3. There is a mismatch between the described method and the experimental implementation, particularly regarding the use of a rule-based controller instead of a trained policy network.
4. The paper fails to situate itself within existing literature, neglecting relevant prior work that could provide context and comparison.

### Suggestions for Improvement
We recommend that the authors improve the breadth of their evaluations by testing the ToT framework on a wider range of tasks beyond Sudoku, including other NP problems. Additionally, we suggest conducting ablation studies to clarify the contributions of each component of the ToT architecture, particularly the checker and memory modules. It would be beneficial to provide more detailed descriptions of the experimental setup, including the number of puzzles tested and the computational costs involved. We also encourage the authors to clarify the implementation details of the ToT controller and memory module, ensuring that the methodology aligns with the theoretical framework presented. Finally, we advise the authors to enhance the literature review to include relevant works that could strengthen the paper's contributions.