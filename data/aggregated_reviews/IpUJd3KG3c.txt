ID: IpUJd3KG3c
Title: Improving the Privacy and Practicality of Objective Perturbation for Differentially Private Linear Learners
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 3, 7, 5, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 2, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new privacy analysis for the objective perturbation method in learning differentially private linear models, utilizing gradient clipping akin to DP-SGD. The analysis demonstrates competitive performance relative to DP-SGD, particularly in hyperparameter tuning. The authors extend the AMP framework to accommodate losses with unbounded gradients and provide tighter bounds for RÃ©nyi differential privacy (RDP) and approximate differential privacy. Additionally, the paper compares Objective Perturbation (ObjPert) with DP-SGD, emphasizing that while ObjPert may not dominate DP-SGD, it achieves comparable performance and should be considered a strong baseline. The authors clarify that they used the RDP bound (Theorem 3.1) for ObjPert in their experiments to align with the best hyperparameter tuning tools available, which are based on RDP. They argue that the empirical performance of ObjPert is hindered by the lack of modern analysis compared to DP-SGD, which benefits from recent advancements in privacy accounting.

### Strengths and Weaknesses
Strengths:
- The problem addressed is significant and has potential practical implications.
- The RDP analysis and the extension of AMP are notable contributions, enhancing the understanding of objective perturbation.
- The authors provide a clear rationale for using RDP in their experiments, aligning with state-of-the-art hyperparameter tuning methods.
- The paper addresses a significant gap in the analysis of ObjPert, offering modern privacy accounting that enhances its comparability to DP-SGD.
- The paper is well-structured and presents a compelling narrative on the relevance of objective perturbation.

Weaknesses:
- The presentation is poor, with vague sentences, undefined terms, and confusing notation, leading to several mathematical inaccuracies.
- The empirical evaluation is limited, relying on only two toy datasets, and does not consistently outperform DP-SGD.
- The choice of datasets is deemed inappropriate for the claims made, and the experimental evaluation lacks breadth and depth.
- The comparison methodology has been criticized for potentially being unfair, as it contrasts a loose upper bound for ObjPert with a tighter bound for DP-SGD.
- The discussion on computational efficiency lacks depth and fails to adequately contextualize the results against existing literature.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the presentation by defining all technical terms and ensuring consistent notation throughout the paper. Specifically, elaborate on the claim regarding the PLRV being "almost" Gaussian and clarify the meaning of "weakly" differentiable functions. Additionally, we suggest expanding the empirical evaluation to include more realistic datasets and varying batch sizes, as well as providing a more detailed discussion of the significance of the results in relation to existing analyses of DP-SGD. We also recommend that the authors improve their experimental evaluations by running tests on more suitable datasets for the camera-ready version, should the paper be accepted. Furthermore, we suggest explicitly reporting results under both Method 1 and Method 2 to clarify the privacy guarantees of ObjPert in comparison to DP-SGD. Finally, we encourage the authors to address the limitations of their method and provide a closed-form expression for the required value of $\sigma$ for achieving specific privacy guarantees.