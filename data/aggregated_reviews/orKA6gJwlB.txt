ID: orKA6gJwlB
Title: Probabilistic predictions with Fourier neural operators
Conference: NeurIPS
Year: 2024
Number of Reviews: 2
Original Ratings: 6, 7
Original Confidences: 3, 4

Aggregated Review:
### Key Points
This paper presents a novel approach that enhances Fourier Neural Operators (FNO) to generate probabilistic predictions for dynamical systems, leveraging strictly proper scoring rules for well-calibrated predictive distributions. The authors propose the Probabilistic Fourier Neural Operator, which demonstrates improved uncertainty representation, particularly in complex scenarios like the Kuramoto-Sivashinsky equation and weather forecasting. However, the critique of Monte Carlo Dropout (MCDropout) highlights its limitations as a variational approximation, noting that it may not accurately capture the true posterior distribution of neural network weights.

### Strengths and Weaknesses
Strengths:
- The combination of Fourier neural operators with probabilistic predictions is a fresh approach, particularly for uncertainty quantification in dynamical systems.
- The paper's use of proper scoring rules and generalizations over separable Hilbert spaces adds mathematical rigor and credibility to the method.

Weaknesses:
- The requirement for an additional training step and increased computational power due to multiple samples for loss calculation is noted, but the authors do not analyze the trade-off between computational cost and performance in depth.
- Experimental results indicate lower test performance on the 2-meter surface temperature prediction task compared to the validation set, suggesting potential out-of-distribution generalization issues that warrant further discussion or additional experiments.
- The mathematical density of the paper may hinder accessibility for a broader audience; more intuitive explanations or visualizations could enhance understanding.
- To improve reproducibility, the authors should provide the source code used for the experiments.

### Suggestions for Improvement
We recommend that the authors improve the analysis of the trade-off between computational cost and performance associated with the additional training step. Additionally, addressing the out-of-distribution generalization issues through further experiments or discussions would strengthen the paper. To enhance accessibility, consider adding more intuitive explanations or visualizations. Finally, providing the source code used for the experiments would significantly improve reproducibility.