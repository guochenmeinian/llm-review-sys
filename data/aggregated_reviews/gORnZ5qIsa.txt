ID: gORnZ5qIsa
Title: Interpretable factorization of clinical questionnaires to identify latent factors of psychopathology
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 6, 3, 3, 4, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new technique for extracting latent factors from psychological questionnaires using a matrix factorization approach. The method enhances previous techniques by accommodating flexible inputs, such as missing values and confounding variables, while ensuring interpretability of outputs. The authors formulate the method as an optimization problem and provide an algorithm to solve it, including automatic determination of latent factors. Extensive experiments demonstrate its effectiveness across various datasets.

### Strengths and Weaknesses
Strengths:
1. The paper effectively formalizes psychological models as a solvable optimization problem, showcasing better characteristics than competing methods.
2. The experiments are diverse, validating the method's utility in both synthetic and real-world scenarios.
3. Extensive comparisons with existing techniques in psychology are provided.
4. A Python implementation of the algorithm is made available.

Weaknesses:
1. Many figures are too small; moving some to an appendix could enhance clarity.
2. The novelty of the proposed method is questionable, as it closely resembles l1-constrained Non-Negative Matrix Factorization (NMF).
3. The manuscript can be difficult to follow, particularly in explaining the interpretability of the factorization.
4. The comparison is limited to linear factorization methods, neglecting potential advantages of deep learning approaches.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the manuscript, particularly in explaining the intuition behind the ICQF regularization method and its selection. Additionally, addressing the scaling complexity of the optimization problem concerning the number of participants and questions would enhance understanding. We suggest including a brief justification for the choice of NeurIPS as a venue and conducting a user study to quantitatively support claims of interpretability. Finally, expanding the comparison to include deep neural network methods, such as autoencoders, could provide a more comprehensive evaluation of the proposed method's advantages.