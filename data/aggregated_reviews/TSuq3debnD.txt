ID: TSuq3debnD
Title: Scalarization for Multi-Task and Multi-Domain Learning at Scale
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 6, 7, 6, 3, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis of scalarization in multi-task and multi-domain learning (MTL/MDL), focusing on the selection of weights for task losses. The authors conduct extensive experiments to explore the effects of model size, gradient conflict, and scalarization weight variations, proposing the use of population-based training (PBT) for efficient weight tuning. Key findings include that scalarization is more effective with larger model capacities, uniform scalarization is rarely optimal, and gradient conflict does not predict generalization performance.

### Strengths and Weaknesses
Strengths:
- The paper provides a comprehensive set of experiments to understand the dynamics of scalarization in MTL/MDL.
- It proposes actionable methods by leveraging existing population-based hyperparameter optimization techniques for weight tuning.
- The writing is clear, and the experimental methodology is described in sufficient detail for reproducibility.

Weaknesses:
- The writing lacks logical flow in some sections, with insights presented in a condensed manner that can be difficult to follow.
- The empirical nature of the study raises questions about the generalizability of the findings due to insufficient conceptual analysis.
- Some conclusions drawn from experiments involving only two tasks may not hold in larger task settings, and the methodology may unfairly compare single-task and multi-task hyperparameters.

### Suggestions for Improvement
We recommend that the authors improve the organization of the writing to enhance logical flow, particularly in sections where multiple insights are presented together. Additionally, we suggest incorporating a more robust conceptual analysis to support the empirical findings, addressing how conflicting gradients influence training outcomes. Clarifying the methodology for selecting optimal scalarization weights, especially regarding grid search and the implications of using single-task hyperparameters for multi-task settings, would strengthen the paper. Lastly, including comparisons with more baselines, such as random scalarization and other existing methods, would provide a clearer context for the proposed approach.