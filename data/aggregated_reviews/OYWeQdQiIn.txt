ID: OYWeQdQiIn
Title: Identifying Conspiracy Theories News based on Event Relation Graph
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a model for identifying conspiracy theories in news articles by constructing an event relation graph that captures events and their relationships, such as coreference, causality, temporal, and subevent. The authors propose a joint learning framework that integrates this graph with a Longformer LLM, resulting in an event-aware language model. The model is evaluated using the LOCO conspiracy theory dataset and shows significant performance improvements over a vanilla Longformer and ChatGPT, particularly in distinguishing between conspiracy and benign articles.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant contemporary issue: the detection of conspiracy theories in news media.
- It employs a well-justified NLP pipeline and achieves state-of-the-art results on a human-annotated dataset.
- The evaluation includes both random and media source splitting, providing a realistic assessment of the model's capabilities.

Weaknesses:
- There is insufficient evidence that the model effectively reasons about event graphs, with concerns about the rigor of the authors' claims regarding rationality.
- The baseline comparisons are perceived as weak, and the necessity of hard labels in the model is questioned.
- The reproducibility of results could be improved, and the paper lacks clarity in some methodological steps.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Section 3.2 regarding the event-aware language model and its necessity. Additionally, it would be beneficial to include stronger baselines from previous studies on short texts to better demonstrate the proposed method's superiority. We suggest exploring the use of soft labels instead of hard labels to capture richer information, and consider collapsing coreferential events into single nodes to enhance graph efficiency. Lastly, providing more detail on the training parameters and dependencies would strengthen reproducibility.