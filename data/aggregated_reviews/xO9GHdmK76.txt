ID: xO9GHdmK76
Title: Infinite-Dimensional Feature Interaction
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 6, 7, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel architecture, InfiNet, which enhances neural network performance by enabling infinite-dimensional feature interactions using the Radial Basis Function (RBF) kernel. The authors argue that traditional methods are limited to finite dimensions and propose their approach as a solution, providing empirical results across standard vision tasks. The work aims to generalize feature-feature interactions and compares the proposed method to self-attention mechanisms.

### Strengths and Weaknesses
Strengths:
- The idea of generalizing feature interactions via kernels is novel and shows promising empirical performance.
- The paper is well-organized and presents extensive experiments demonstrating the effectiveness of InfiNet across various tasks.

Weaknesses:
- There is no theoretical justification for the claim that increasing the dimension of feature interactions leads to better generalization.
- The empirical performance improvements are marginal, with some results worse than competing methods.
- The paper lacks a thorough exploration of the connections between kernel methods and existing literature, particularly regarding random features and neural networks.

### Suggestions for Improvement
We recommend that the authors improve the theoretical foundation of their claims regarding generalization and dimensionality. Additionally, we suggest including comparisons with language tasks to broaden the applicability of the proposed method. Clarifying the notation used in the paper, particularly for operations like element-wise multiplication, would enhance understanding. We also advise the authors to provide clearer explanations of the model architecture, possibly through pseudocode, and to include matrix/tensor shapes in the relevant sections. Finally, releasing the code would significantly aid reproducibility and transparency.