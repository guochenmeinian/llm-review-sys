ID: woRFmNJiLp
Title: Alignment at Pre-training! Towards Native Alignment for Arabic LLMs
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 3, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents two methods aimed at enhancing large language model (LLM) alignment and performance. The first method, termed "native alignment," focuses on improving Arabic LLMs during pre-training through a three-step process: pre-training data duplication, alignment rewriting, and model training. The authors claim that this method addresses issues related to formatting, fairness, and unsafe content in pre-training data, demonstrating improvements in safety and helpfulness through experiments. The second method, called REALIGN, reformats existing instructional data to enhance its quality for improved mathematical performance, distinguishing itself from native alignment by focusing on data rephrasing at the pre-training stage rather than during supervised fine-tuning. The authors argue that REALIGN is more aligned with format alignment, while native alignment emphasizes value alignment to mitigate harmfulness and biases in data.

### Strengths and Weaknesses
Strengths:
- The paper introduces innovative approaches to LLM alignment and instructional data quality enhancement.
- The writing is clear and well-organized, making complex concepts accessible.

Weaknesses:
- There is a lack of comparison with existing post-alignment methods for the native alignment approach, raising questions about its effectiveness.
- The analysis of potential trade-offs, particularly regarding the impact of rewriting on the understanding of Arabic dialects and the risk of inheriting hallucinations from LLMs, is insufficient.
- Experiment details are unclear, especially concerning the evaluation dataset, which is in English while the method focuses on Arabic data.
- The paper lacks a discussion of the metrics used to evaluate qualitative aspects such as 'trustworthiness' and 'knowledge,' relying on existing evaluation pipelines without thorough analysis.

### Suggestions for Improvement
We recommend that the authors improve the paper by including comparisons with existing post-alignment methods to strengthen their claims regarding native alignment. Additionally, more analyses should be conducted to explore the potential trade-offs of their method, particularly concerning the preservation of Arabic dialects and the risk of data hallucinations. Clarification on the experimental details is necessary, especially regarding the evaluation dataset's translation process. Furthermore, the authors should explicitly state whether they continued training the LLaMA 3 model or initialized a new model from scratch. For the REALIGN method, we encourage the authors to include a discussion of the metrics used to measure 'trustworthiness' and 'knowledge,' as these qualitative metrics are crucial for understanding the effectiveness of their approach. Lastly, we suggest that the authors re-evaluate the terminology used in relation to alignment, considering the distinctions between their method and existing frameworks.