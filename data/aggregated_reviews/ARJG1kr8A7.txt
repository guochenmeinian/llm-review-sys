ID: ARJG1kr8A7
Title: GPT is becoming a Turing machine: Here are some ways to program it
Conference: NeurIPS
Year: 2023
Number of Reviews: 22
Original Ratings: 4, 6, 7, 4, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method called Iterations by Regimenting Self-Attention (IRSA) to prompt GPT-3 for executing iterative programs. The authors propose three techniques: 1) providing detailed step-by-step examples of state transitions, 2) using fragments of state transitions, and 3) skipping attention on intermediate states. The results indicate that IRSA significantly improves performance on tasks requiring iterative behavior, such as sorting arrays and solving logical puzzles. The authors also discuss the potential applications of IRSA in educational contexts and the implications for evaluating large language models (LLMs). Additionally, the paper emphasizes the role of IRSA in algorithm execution rather than discovery and acknowledges the challenges of automating IRSA prompts while focusing on the design and effectiveness of manual constructions. The authors clarify the relationship between IRSA and Chain-of-Thought (CoT) prompting, noting that IRSA achieves a high level of accuracy in algorithm execution.

### Strengths and Weaknesses
Strengths:
- The authors introduce a novel approach to prompting LLMs that focuses on accurately following procedural rules, which is a distinct direction compared to existing methods.
- The proposed techniques, particularly fragmented prompting and skip attention, are original and effective, leading to state-of-the-art results on loop-involving tasks.
- The approach is efficient, reducing computational costs by only showing the most recent state to the LLM.
- The paper is well-written and clearly presented, with commendable figures and tables, and the authors are responsive to reviewer feedback.

Weaknesses:
- The motivation for the work is insufficiently articulated, leaving unclear why LLMs should be preferred over traditional programming methods for executing iterative behavior.
- The reliance on manual prompt construction limits scalability and practical application.
- The paper lacks a self-contained presentation, with numerous references to appendices that are not well-written or readable, making it difficult to follow.
- There is a need for clearer definitions and explanations of IRSA and its relationship with CoT prompting, and the absence of comprehensive baselines and experiments limits the contextualization of results.
- Some reviewers express uncertainty about the feasibility of proposed revisions, suggesting that significant changes may be needed for publication.

### Suggestions for Improvement
We recommend that the authors improve the motivation section to clarify the advantages of using LLMs for executing programs over traditional programming methods. Additionally, the authors should explore the possibility of automating the prompt construction process to enhance scalability. To improve clarity, we suggest restructuring the explanation of IRSA to provide a more intuitive flow, possibly by framing it in relation to existing frameworks like Chain-of-Thought (CoT). Furthermore, we encourage the authors to include a more thorough comparison with chain-of-thought reasoning and to address the limitations of their approach, particularly regarding the complexities involved in applying IRSA to larger state spaces and the conditions under which LLMs may fail to execute programs accurately. Lastly, we recommend integrating more detailed examples into the main text to reduce reliance on the appendix and including a more comprehensive set of baselines and experiments to effectively contextualize their results.