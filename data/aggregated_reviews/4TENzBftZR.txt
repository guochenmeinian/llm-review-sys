ID: 4TENzBftZR
Title: iVideoGPT: Interactive VideoGPTs are Scalable World Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 6, 7, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on planning and prediction using video world models, proposing a GPT-style transformer world model that integrates action and reward information into its context and prediction pipeline. The model employs a novel tokenization technique based on VQGAN and operates in pixel-observation space, which is a novel approach not widely explored in existing literature. The authors evaluate the model across three applications: video prediction, planning, and model-based reinforcement learning, while conducting ablations on model and tokenizer scalability. Additionally, the paper discusses the need for a tokenizer that enables seamless action embedding and efficient encoding, which is crucial for building the world model.

### Strengths and Weaknesses
Strengths:
- The problem of studying dyna-style video algorithms with foundational models is compelling and merits investigation.
- The paper is well-written, with clear language and a logical flow, making it easy to follow.
- The treatment of related work is thorough, citing 120 references, and effectively situating the work within the literature.
- The experimental section is extensive and demonstrates the potential benefits of pretraining, providing valuable insights into the model's capabilities.

Weaknesses:
- Some broad claims lack supporting evidence, such as the assertion that the model can acquire "broad world knowledge."
- The motivation for the model's interactivity and scalability is unclear, with insufficient evidence provided to support these claims.
- The experimental results appear weak, with the model underperforming in many tasks and lacking robust comparisons against stronger baselines.
- The arguments regarding scalability and interactivity are underdeveloped, and there is a disconnect between the claims about scalability and the downstream performance analysis.
- The introduction of the tokenizer lacks a clear connection to the world model's objectives.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their claims, particularly regarding "broad world knowledge," by providing precise definitions and supporting evidence. Additionally, the authors should clarify what is meant by the model being "interactive" and provide evidence to substantiate claims of scalability compared to existing models like Dreamer. We suggest including quantitative comparisons of computational efficiency, particularly regarding training and inference times for different tokenizers. Furthermore, we encourage the authors to enhance the experimental validation by demonstrating the correlation between scalability and downstream performance, as well as the necessity of the novel tokenization technique. We also recommend that the authors improve the focus of the paper on pixel-observation spaces and the single-model approach for downstream learning, rather than emphasizing interactivity. Adjusting the title to reflect pixel-observation spaces would enhance clarity. Additionally, we suggest rewriting the tokenizer section to better connect its purpose to the world model's objectives. Lastly, we advise including additional Dreamer experiments and a comparison with existing scalable models to strengthen the claims regarding scalability and to address the disconnect between scalability claims and downstream performance analysis in the experiments section.