ID: DcOivrmH8C
Title: Mitigating Forgetting in Adapting Pre-trained Language Models to Text Processing Tasks via Consistency Alignment
Conference: ACM
Year: 2024
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a dual-model framework called Consistency Alignment (CoAi) to mitigate catastrophic forgetting in pre-trained language models (PLMs) during fine-tuning. CoAi constructs an auxiliary model that simulates the distribution of pre-training knowledge, aligning its predictions with those of the task-specific model to balance pre-training and task-specific knowledge. The effectiveness of CoAi is validated through extensive experiments across various natural language processing tasks, demonstrating significant performance improvements.

### Strengths and Weaknesses
Strengths:
1. The CoAi framework introduces an innovative approach to dual-model learning, effectively addressing catastrophic forgetting.
2. The paper is well-structured and clearly written, making it accessible.
3. Extensive experimental validation shows CoAi's superiority over existing methods in multiple tasks.

Weaknesses:
1. Some technical details may be complex for non-expert readers, potentially hindering understanding.
2. The framework shares similarities with existing methods in continuous learning and knowledge distillation, which are not adequately discussed.
3. The implementation details, particularly regarding mathematical theorems and formulas, lack clarity.
4. The paper does not explore knowledge-intensive tasks or larger models, limiting its applicability.

### Suggestions for Improvement
We recommend that the authors improve the clarity of technical explanations to accommodate a broader audience. Additionally, the authors should explicitly discuss the similarities between CoAi and existing methods in continuous learning and knowledge distillation. We suggest enhancing the description of the model's implementation, particularly the mathematical formulations, to provide clearer insights. Furthermore, we encourage the authors to explore experiments on knowledge-intensive tasks and larger models, such as T5-3B or GPT variants, to assess scalability and performance comprehensively. Lastly, including comparisons with recent continual learning methods would strengthen the paper's contributions.