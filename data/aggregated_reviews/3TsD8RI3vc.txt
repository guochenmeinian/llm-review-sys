ID: 3TsD8RI3vc
Title: Preconditioned Crank-Nicolson Algorithms for Wide Bayesian Neural Networks
Conference: NeurIPS
Year: 2024
Number of Reviews: 2
Original Ratings: 7, 7
Original Confidences: 1, 3

Aggregated Review:
### Key Points
This paper presents a new sampling algorithm for Bayesian Neural Networks, utilizing a reparameterization with the Crank-Nicolson sampling algorithm to achieve better acceptance rates in high dimensions. The authors propose that their theoretical findings indicate improved acceptance rates and efficiency with wider Bayesian Neural Networks, supported by numerical experiments on CIFAR-10. The paper is well-written, with complexity primarily in the appendix, and the theoretical and experimental data warrant further investigation.

### Strengths and Weaknesses
Strengths:  
- The paper introduces a novel sampling algorithm that shows promise for Bayesian Neural Networks.  
- The theoretical findings are compelling, particularly regarding the relationship between network width and algorithm efficiency.  
- The writing is clear and accessible, facilitating understanding of complex concepts.  

Weaknesses:  
- The experimental work is limited and requires expansion to validate the algorithm as a viable alternative.  
- There is a lack of comparison with more sophisticated sampling algorithms.  
- The experimental section does not scale adequately with deeper networks or more challenging tasks, nor does it evaluate the downstream impact on posterior distribution quality.

### Suggestions for Improvement
We recommend that the authors improve the experimental section by:  
1) Comparing their sampling algorithm with more sophisticated alternatives.  
2) Scaling up experiments to include deeper networks and more challenging real-world tasks.  
3) Evaluating the downstream effects of the new parameterization, sampling, and higher acceptance rates on the quality of the posterior distribution, particularly in high dimensions.