ID: 0hq1SCYftX
Title: Privacy-Preserving and Fairness-Aware Federated Learning for Critical Infrastructure Protection and Resilience
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel serverless approach to federated learning (FL) aimed at enhancing privacy and fairness. The authors propose a framework that integrates Multi-Party Computation (MPC) and Differential Privacy (DP) to secure gradient aggregation while adding noise to local gradients. However, the process of updating the global model post-local pruning and the aggregation of heterogeneous models remains unclear. The authors claim improved privacy protection through pruning, but this is primarily attributed to differential privacy, which does not significantly differ from existing methods. The experiments lack comparisons with contemporary heterogeneous DFL aggregation mechanisms, and the background information does not adequately connect to the work's application in industrial control equipment.

### Strengths and Weaknesses
Strengths:
1) The paper is well-structured and easy to follow.
2) Comprehensive experiments demonstrate the effectiveness of the proposed method.

Weaknesses:
1) The process for updating the global model after local pruning is ambiguous.
2) The requirement for clients to select a proportion of updates for aggregation increases communication overhead.
3) The motivation for the proposed design is unclear, particularly regarding its necessity for web applications.
4) The specific value of the loss threshold LRR is unspecified, and the datasets' distribution (iid or non-iid) is not clarified.
5) The evaluation lacks a detailed performance analysis, particularly regarding latency and the impact of user churn.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the model update process after local pruning and provide a detailed explanation of how heterogeneous models are aggregated. Additionally, we suggest that the authors clarify the rationale for using both MPC and DP, highlighting their complementary roles in enhancing privacy. An analysis of the computational cost of the proposed approach compared to traditional FL plus MPC methods should be included to enrich the evaluation. Furthermore, we encourage the authors to provide specific values for the loss threshold LRR and clarify the datasets' distribution characteristics. Finally, a more thorough performance evaluation, including latency and the effects of user churn, would strengthen the paper's contributions.