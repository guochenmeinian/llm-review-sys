ID: BbIxB4xnbq
Title: LANCE: Stress-testing Visual Models by Generating Language-guided Counterfactual Images
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 7, 5, 6, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 2, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for stress-testing visual classifiers by generating counterfactual images through a four-step process: 1) taking an image input; 2) obtaining its caption via a captioning model (BLIP-2); 3) perturbing the caption using ChatGPT and fine-tuned LLAMA; and 4) generating new images based on the perturbed captions using text inversion of Stable Diffusion. The authors demonstrate that various models, such as ResNet-50 and ViT-B, perform significantly worse on the generated ImageNet dataset compared to the original, revealing model biases.

### Strengths and Weaknesses
Strengths:
1. The paper targets a novel direction in stress-testing visual models, crucial for real-world applications.
2. The proposed method is technically sound, producing realistic images from the pipeline.
3. Experiments conducted on the realistic ImageNet dataset enhance the practical value of the method.
4. The paper is well-written and easy to understand.

Weaknesses:
1. The absence of a baseline makes it difficult to justify the method's effectiveness; a human study validating the label accuracy of generated images is necessary.
2. Similar existing works are not adequately discussed, particularly regarding their similarities and differences.
3. The generated images may not accurately reflect model errors, as changes in captions can lead to unexpected model predictions.
4. The limitations of using language for representation, such as orientation and lighting, are acknowledged but require further exploration.

### Suggestions for Improvement
We recommend that the authors improve the paper by including a baseline for comparison to substantiate the effectiveness of their method. A human study validating the label accuracy of generated images is essential. Additionally, we suggest that the authors discuss existing works more thoroughly to clarify the distinctions between their approach and similar studies. Furthermore, the authors should address the potential discrepancies in model predictions due to caption changes and explore the limitations of language representation in greater detail.