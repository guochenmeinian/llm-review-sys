ID: 0Lr9HQijA1
Title: Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 7, 7, 6, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework for imprecise label learning (ILL), which unifies various configurations of imprecise labels, including partial label learning, semi-supervised learning, and noisy label learning, using an expectation-maximization (EM) approach. The authors demonstrate that their method adapts well across different learning setups and outperforms existing methods in various settings.

### Strengths and Weaknesses
Strengths:
- The unification of different imprecise label learning settings is both interesting and instructive, reducing the need for separate solutions.
- The paper is well-written, with clear language and a comprehensive appendix that provides detailed derivations and information.
- The framework shows promising performance across individual and mixed settings, demonstrating scalability on larger datasets.

Weaknesses:
- The main text lacks certain details, making it less straightforward to follow, particularly in section 3.2.
- The novelty of the approach is questionable, as the use of ground-truth labels or Bayes label distribution as latent variables is common in variational inference.
- The implementation of EM may increase computation time, and more related works should be discussed to highlight the novelty of the technique.
- The paper does not adequately explain why the EM framework optimizes the variational lower bound or its advantages.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the main text by including more details, particularly in section 3.2, to enhance comprehension. Additionally, the authors should discuss more related works to better position their contributions within the existing literature and clarify the novelty of their approach. An explanation of the advantages of using the EM framework to optimize the variational lower bound should also be included. Finally, addressing the computational efficiency of the EM implementation through theoretical or empirical analyses would strengthen the paper.