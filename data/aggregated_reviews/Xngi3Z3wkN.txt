ID: Xngi3Z3wkN
Title: Protein-Nucleic Acid Complex Modeling with Frame Averaging Transformer
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 7, 4, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for predicting contacts between proteins and aptamers using frame averaging transformers. The authors showcase their approach through contact prediction and unsupervised aptamer screening, demonstrating improvements over several baselines. They also compare their method to RoseTTAFoldNA, which appears to outperform their approach.

### Strengths and Weaknesses
Strengths:
- The application of frame averaging is innovative and promising for the problem at hand.
- The presentation is clear, and the paper is well-written.
- The addressed problem of aptamer screening is significant and relevant.
- The authors conduct comparisons with a variety of architectures.

Weaknesses:
- The comparison with pre-trained structure prediction methods, particularly in section 4.4, is underdeveloped, leading to confusion regarding Figure 3 and its implications.
- The novelty of the proposed architecture is limited, as it primarily combines existing concepts without substantial innovation.
- The low F1 score for contact map prediction raises concerns about the model's effectiveness.

### Suggestions for Improvement
We recommend that the authors improve section 4.4 by expanding the discussion on Figure 3 and Table 5 to clarify their relationship. Additionally, please confirm whether the times in Table 6 include MSA search for Rosetta and consider optimizing the MSA search for unchanged proteins. We also suggest exploring the application of the proposed method to other screening tasks and conducting more experiments on general tasks, such as protein-protein docking, to further validate the architecture's effectiveness. Lastly, providing more intuition on the module structures and addressing the efficiency of FAFormer compared to other equivariant neural networks would enhance the clarity and impact of the paper.