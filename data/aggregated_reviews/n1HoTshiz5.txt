ID: n1HoTshiz5
Title: UNIDEC : Unified Dual Encoder and Classifier Training for Extreme Multi-Label Classification
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents UniDEC, a unified framework for Extreme Multi-Label Classification (XMC) that integrates dual encoder and classifier training. The authors propose a novel "pick-some-labels" (PSL) reduction to compute loss over subsets of labels, significantly reducing computational costs and enabling training on large datasets with millions of labels using a single GPU. UniDEC achieves state-of-the-art performance across multiple public XMC datasets, demonstrating both efficiency and effectiveness.

### Strengths and Weaknesses
Strengths:
1. Achieves state-of-the-art results with up to 16× computational savings, enhancing accessibility for resource-constrained settings.
2. Comprehensive benchmarking across six diverse datasets, covering both short and long text.
3. Detailed insights from ablation studies highlight the contributions of individual components.
4. Well-structured and clear descriptions of methodology and experimental setup.

Weaknesses:
1. The methodology section is laden with mathematical symbols, which may hinder readability.
2. The presentation could be improved, such as using vector graphics for figures.
3. Limited discussion on the model’s computational overhead and theoretical limitations of the symmetric loss formulation.
4. The clustering-based batching strategy may introduce dependency on dataset-specific characteristics without thorough analysis.

### Suggestions for Improvement
We recommend that the authors improve the readability of the methodology section by reducing the number of mathematical symbols and enhancing the clarity of explanations, particularly in the ablation studies. Additionally, we suggest that the authors provide vector graphics for figures and address the missing labels for equations. It would be beneficial to include a more detailed discussion on the model’s computational overhead and the potential limitations of the symmetric loss formulation. Lastly, exploring the integration of external knowledge sources or pre-trained LLMs into the UniDEC framework could enhance its applicability.