ID: KQ25VgEvOJ
Title: Fairness Continual Learning Approach to Semantic Scene Understanding in Open-World Environments
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 6, 6, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Fairness Continual Learning approach to tackle the continual semantic segmentation problem. It introduces a fairness objective based on class distributions to mitigate bias towards majority classes and proposes a Prototypical Contrastive Clustering loss to address catastrophic forgetting and background shift issues. Additionally, a conditional structural consistency loss is introduced to ensure the coherence of segmentation predictions. The method achieves state-of-the-art results on standard benchmarks such as ADE20K, Cityscapes, and Pascal VOC.

### Strengths and Weaknesses
Strengths:
1. The analysis of class distribution effects leading to the learning objectives is novel.
2. Strong performance improvements are demonstrated across multiple standard benchmarks.
3. The paper effectively identifies and addresses fairness issues in continual segmentation systems, contributing significantly to the field.

Weaknesses:
1. The title may mislead, as the method is not suitable for unsupervised settings.
2. Mathematical derivations, particularly in equations 5, 12, and 13, lack rigor and require further clarification.
3. The calculation of the fairness objective \(L_{class}\) during training is unclear, and the final integrated training objective is not specified.
4. The ablation study indicates that the fairness improvement is minor, suggesting a need for better measurement of fairness, particularly regarding rare and dominant classes.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the title to accurately reflect the method's applicability. Additionally, we suggest providing more rigorous mathematical explanations for equations 5, 12, and 13, either in the main paper or supplementary materials. Clarifying how the fairness objective \(L_{class}\) is computed during training and detailing the final integrated training loss, including any balance weights between losses, is essential. Furthermore, we encourage the authors to enhance the ablation study by analyzing the contributions of the fairness loss separately for majority and minority classes across multiple datasets. Finally, addressing the organization of the method section to clarify the final loss function and its components would improve the paper's overall presentation.