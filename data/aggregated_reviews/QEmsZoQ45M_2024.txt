ID: QEmsZoQ45M
Title: Local Linearity: the Key for No-regret Reinforcement Learning in Continuous MDPs
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 5, 6, 5, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents two novel classes of MDPs in the function approximation setting: Mildly Smooth MDPs, where the Bellman optimality operator outputs smooth functions of degree $\nu$, and Locally Linearizable MDPs, characterized by a state-action feature mapping into $\mathbb{R}^d$ and a finite partition of the state-action space that allows for a linear Q function approximator within each partition. The authors propose an online algorithm, CINDERELLA, which achieves sublinear regret for Locally Linearizable MDPs and derives a sublinear regret bound for Mildly Smooth MDPs. 

### Strengths and Weaknesses
Strengths:  
- The work introduces a new class of continuous state-action MDPs where sublinear regret is achievable, representing the most general class that avoids lower bounds exponential in $H$.
- The paper is well-crafted, clearly articulating its contributions and situating them within existing literature.

Weaknesses:  
- The regret bound exhibits exponential factors in $d$, and the sublinearity in $K$ is considered weak given the generality of the results.
- CINDERELLA is computationally inefficient, and the technical details may obscure the practical implications of the findings.
- The novelty of the results may not be compelling to experts, as the decomposition of "smooth" MDPs into local linear ones is not particularly surprising.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the structural assumptions in Definition 1, as it currently lacks specificity regarding linearizability. Additionally, we suggest elaborating on the algorithmic differences between Eleanor and CINDERELLA, as the current discussion is limited and somewhat hidden. Furthermore, we encourage the authors to provide concrete examples of Mildly Smooth MDPs that are not Strongly Smooth to enhance understanding of their contributions. Lastly, clarifying how the regret bound scales with $K$ and addressing the gap between their bound and the information-theoretic lower bound would strengthen the paper.