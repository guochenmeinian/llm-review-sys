ID: jKzLukkKZO
Title: Learning to Control the Smoothness of GCN Features
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 5, 5, 5, 6, 4, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the impact of activation functions, specifically ReLU and leaky ReLU, on the smoothness of node features in Graph Convolutional Networks (GCNs). The authors propose a Smoothness Control Term (SCT) to modulate feature smoothness, aiming to enhance node classification in both homophilic and heterophilic graphs. Theoretical insights are provided, demonstrating how adjustments to input projections can achieve desired normalized smoothness levels. Empirical results validate the effectiveness of SCT across various GCN-style models.

### Strengths and Weaknesses
Strengths:
- The paper introduces a novel approach to controlling the smoothness of GCN features, significantly extending existing methods.
- A robust theoretical framework supports the proposed methods, with extensive experiments validating the claims and enhancing reproducibility.
- The paper is well-structured, providing a comprehensive review of related work and situating its contributions within the broader context of graph neural networks.

Weaknesses:
- The paper's readability is hindered by the removal of white space and the condensation of mathematical content, making it visually challenging.
- The complexity of mathematical formulations may alienate readers unfamiliar with advanced geometry and spectral graph theory; more intuitive examples are needed.
- The empirical results lack comprehensive baseline comparisons with state-of-the-art methods, and the performance improvements from SCT are often marginal.
- The analysis primarily focuses on GCNs, leaving the applicability of the proposed method to other GNN architectures unclear.
- The discussion on computational efficiency and the overhead introduced by SCT is insufficient.

### Suggestions for Improvement
We recommend that the authors improve the paper's visual presentation by avoiding excessive condensation of mathematical content and clearly distinguishing main contributions from supplementary material. Simplifying complex mathematical explanations and providing intuitive examples would enhance accessibility for a broader audience. Additionally, we suggest expanding the empirical evaluation to include comparisons with more state-of-the-art GCN and GNN models, as well as incorporating diverse real-world datasets to demonstrate practical relevance. A deeper analysis of performance degradation in deeper models, beyond the mention of vanishing gradients, would provide valuable insights. Finally, a more detailed discussion on the computational overhead associated with SCT, including trade-offs between accuracy and efficiency, would strengthen the paper.