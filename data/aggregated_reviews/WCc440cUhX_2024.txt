ID: WCc440cUhX
Title: Understanding Transformers via N-Gram Statistics
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 6, 5, 7, -1, -1, -1, -1
Original Confidences: 4, 3, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on how transformer-based large language models (LLMs) utilize context for next-token prediction by approximating these predictions with N-gram-based statistical rules. The authors propose a method to describe transformer predictions using simple N-gram rules and investigate their effectiveness. Key findings include a novel method for detecting overfitting without a holdout set, insights into the transition from simple to complex statistical rules during training, a criterion for aligning transformer predictions with N-gram rules, and an understanding of how well transformers can be approximated by increasingly complex N-gram rulesets. Experiments conducted on the TinyStories dataset and validated on Wikipedia data provide insights into the statistical nature of LLM behavior.

### Strengths and Weaknesses
Strengths:
- The proposed method for detecting overfitting without a holdout set is innovative and relevant for optimization applications.
- The paper includes visualizations and concrete examples that enhance understanding.
- Although focused on specific datasets, the methods and insights could be applicable to other domains.

Weaknesses:
- The study offers descriptive approximations without delving into the underlying reasons for the effectiveness of certain rules, lacking a deeper understanding of transformer behavior.
- The impact of fine-tuning on different datasets is not adequately explored, which may affect the proposed methods' effectiveness.
- The analysis primarily considers context lengths of up to seven tokens, potentially overlooking the long-range dependencies that transformers can manage.
- The evaluation methodology raises concerns, particularly regarding the small dataset size and the implications for the model-variance trade-off.

### Suggestions for Improvement
We recommend that the authors improve the depth of their analysis by providing explanations for why certain N-gram rules are effective, moving beyond mere descriptive approximations. Additionally, the authors should explore how fine-tuning on various datasets influences the proposed methods. To enhance the robustness of their findings, we suggest conducting experiments with larger and more diverse datasets, as well as considering additional evaluation metrics that capture other aspects of model performance and approximation quality. Furthermore, clarifying the computational complexity associated with selecting optimal N-gram rules and addressing the potential limitations of their methods in dynamic environments would strengthen the paper.