ID: 0uARg5G04K
Title: The Adversarial Consistency of Surrogate Risks for Binary Classification
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 8, 7, 6, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a necessary and sufficient condition for a loss function to be adversarially consistent, extending previous literature that focused on restricted hypothesis spaces or negative results. The condition, $C_\phi^*(1/2) < \phi(0)$, is straightforward to verify and applies even to nonconvex loss functions. The authors utilize strong duality and complementary slackness results to connect adversarial surrogate loss minimization with optimal coupling between benign and adversarial distributions. Additionally, the paper discusses the $\rho$-margin loss as a suitable surrogate loss that meets the proposed condition.

### Strengths and Weaknesses
Strengths:
- The paper provides a general condition for adversarially consistent losses, offering new insights that may aid in designing loss functions for adversarial training.
- The applicability of the condition to nonconvex losses is significant, as previous theories primarily addressed convex losses.
- The theoretical analysis is thorough, and the presentation is clear up to section 3.

Weaknesses:
- The presentation becomes less clear in section 4, with some notations introduced before their definitions.
- The $\rho$-margin loss, while theoretically sound, is non-differentiable and challenging to implement in practice.
- Some sections contain minor typographical errors and could benefit from additional clarity regarding propositions and definitions.

### Suggestions for Improvement
We recommend that the authors improve the clarity of section 4 by refining the presentation and possibly removing redundant proofs, such as that of Proposition 2, which mirrors existing work. Additionally, incorporating figures to illustrate the differences in consistency properties between adversarial and regular cases would enhance understanding. It would also be beneficial to include empirical experiments demonstrating the advantages of adversarially consistent surrogate losses on datasets like MNIST. Finally, addressing the comments regarding the introduction and the definitions of terms would further clarify the paper's contributions.