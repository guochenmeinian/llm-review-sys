ID: tJwyg9Zg9G
Title: Parallel-mentoring for Offline Model-based Optimization
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 7, 5, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 2, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel offline model-based optimization (MBO) framework that integrates a fine-tuning strategy for ensemble proxy models. The authors propose a "voting" strategy where models are fine-tuned using binary cross-entropy (BCE) loss based on the majority order of two (near) inputs, allowing the proxy models to mentor each other. Additionally, the paper addresses the out-of-distribution problem by introducing a parallel-mentoring approach with a voting-based pairwise supervision module and an adaptive soft-labeling module. The experimental results demonstrate significant performance improvements across various tasks.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and easy to follow.
- Extensive evaluation of experimental results shows good performance compared to prior offline MBO methods.
- The exploration of fine-tuning strategies for ensemble models is relatively under-explored in offline MBO literature, addressing an important problem.
- The proposed method effectively mitigates inaccuracies in proxy models and demonstrates technical robustness.

Weaknesses:
- Hyperparameter selection is a primary concern, with many additional hyperparameters introduced, such as learning rates and variance $\delta^2$. The analysis of these hyperparameters is insufficient, particularly regarding their determination in offline MBO.
- The fine-tuning strategy may lead to inaccuracies in training points, as it lacks the original regression objective.
- The research question and significance of the out-of-distribution problem are poorly defined, lacking experimental evidence to support the effectiveness of the tri-mentoring approach.
- The algorithm's complexity introduces numerous degrees of freedom, potentially limiting its practicality.

### Suggestions for Improvement
We recommend that the authors improve the analysis of hyperparameters, particularly $\delta^2$ and fine-tuning learning rates, and provide guidance on their determination in offline MBO. Additionally, the authors should clarify how the fine-tuning process is conducted, specifically whether models are fine-tuned sequentially. Addressing the definition and significance of the out-of-distribution problem, along with providing experimental evidence for the tri-mentoring approach, would strengthen the manuscript. Simplifying the algorithm to reduce complexity and enhancing the discussion on ensemble techniques in related domains would also improve the paper's quality.