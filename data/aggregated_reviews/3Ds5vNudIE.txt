ID: 3Ds5vNudIE
Title: LLM Circuit Analyses Are Consistent Across Training and Scale
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 5, 7, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis of internal circuits in language models, specifically the Pythia model suite, and attention heads, focusing on their development during pre-training across various model sizes and their roles in model performance. The study investigates four tasks: indirect object identification (IOI), subject-verb agreement, greater-than, and gendered pronouns. Key findings indicate that circuits emerge at similar token counts across different model sizes, with individual components changing functionality while maintaining overall algorithmic stability. The authors employ techniques such as edge attribution patching and Jaccard similarity graphs to identify circuit components and evaluate their dynamics, emphasizing the importance of specific heads in contributing to model performance.

### Strengths and Weaknesses
Strengths:
- The investigation into circuit dynamics during pre-training is novel and relevant for mechanistic interpretability.
- The use of diverse analysis techniques, including path patching, edge attribution patching, and Jaccard similarity graphs, supports systematic testing of hypotheses and enhances understanding of load balancing and fluctuations in circuit performance.
- The identification of general motifs, such as "load balancing," provides insights that could inform future research.
- The clarification of the methodology in Section 4.2 strengthens the argument regarding the testing of circuit assumptions.

Weaknesses:
- The analysis is limited to a small number of simple tasks, raising questions about the generalizability of findings to more complex tasks.
- Some training dynamics, such as the implications of load balancing, are not explored in sufficient detail.
- The methods introduced are not scalable to large datasets of auto-discovered circuits, limiting broader applicability.
- There is a concern regarding the assumptions made in the experiments, particularly in Section 4.2, which may undermine the validity of the conclusions drawn.
- The metrics used to evaluate head performance may not fully capture task relevance, potentially leading to misinterpretations of head significance.

### Suggestions for Improvement
We recommend that the authors improve the clarity of circuit component definitions, explicitly stating whether they involve MLPs and attention heads. Additionally, we suggest that the authors enhance the scalability of their analysis by developing standardized tests for identifying attention heads across various circuits. Including a graph showing Jaccard similarity over time would help visualize circuit stability. Clarification on the circuit discovery algorithm's application at early checkpoints is necessary, as is a discussion on the relationship between circuit size and model scale. We encourage the authors to address the assumptions made in Section 4.2 more explicitly to strengthen the validity of their conclusions. Lastly, we suggest integrating weighted metrics that account for task relevance in their evaluation of head performance, enhancing the clarity of their findings and addressing the potential implications of their findings on the Quanta hypothesis while considering relevant literature on fine-tuning impacts.