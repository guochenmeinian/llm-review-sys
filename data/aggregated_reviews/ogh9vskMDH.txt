ID: ogh9vskMDH
Title: Open-Ended Instructable Embodied Agents with Memory-Augmented Large Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents HELPER, an embodied agent that utilizes LLMs for planning, error correction, and user personalization in instruction-following tasks within the TEACh environment. HELPER processes language descriptions of observations to generate API-level symbolic programs and retrieves relevant past language-program pairs for feedback incorporation. Experimental results demonstrate that HELPER significantly outperforms previous state-of-the-art methods by 1.4x on task success and 2.54x on goal-condition success.

### Strengths and Weaknesses
Strengths:
- HELPER is highly applicable to robotics and addresses common issues such as error correction and user personalization without relying on hardcoded solutions or extensive human engineering.
- The paper reports compelling quantitative results on the TEACh benchmark, showcasing substantial improvements over prior methods.
- The experiments include a comprehensive set of baselines and ablation studies, providing insights into HELPERâ€™s components.

Weaknesses:
- The organization of the paper is suboptimal, lacking a unifying problem statement or example to clarify the multiple issues HELPER addresses.
- The term "visuomotor" is overclaimed, as HELPER primarily outputs high-level API actions, which may limit its applicability to certain tasks that require more complex actions.
- Evaluations are confined to the TEACh benchmark, with no exploration of HELPER's applicability to other domains like navigation.

### Suggestions for Improvement
We recommend that the authors improve the overall organization of the paper by providing a unifying problem statement or example that motivates the various issues HELPER addresses. Additionally, we suggest clarifying the use of the term "visuomotor" to accurately reflect HELPER's capabilities and limitations. To enhance the generalizability of HELPER, we encourage the authors to conduct evaluations on other relevant datasets, such as CVDN. Furthermore, we advise providing clearer descriptions of the modules, including their inputs and outputs, and detailing how user feedback is collected and utilized. Finally, we recommend breaking down Figure 2 into several figures for better clarity and focus.