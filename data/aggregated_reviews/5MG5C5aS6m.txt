ID: 5MG5C5aS6m
Title: Global Optimality in Bivariate Gradient-based DAG Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 5
Original Ratings: 8, 7, 5, 5, -1
Original Confidences: 3, 3, 1, 3, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to non-convex optimization problems related to learning the structure of Directed Acyclic Graphs (DAGs) through a homotopy-based optimization scheme. The authors propose a method that iteratively decreases the penalty coefficient, ensuring global convergence to the minimum, regardless of initialization. The study highlights the non-benign nature of the optimization landscape, indicating that naive implementations may lead to poor local minima. The theoretical results are primarily established for the case of two nodes in the DAG.

### Strengths and Weaknesses
Strengths:
- The work is original and provides a significant contribution to the field of DAG learning.
- The reduction from a combinatorial problem to a non-convex optimization problem is particularly commendable.
- The clarity of writing and the structured presentation enhance the paper's readability.
- The proof strategy is intuitive, and the proposed method could have broader applications beyond the current study.

Weaknesses:
- The results are limited to the case of two nodes, which restricts the applicability of the findings to more complex scenarios.
- There is a lack of discussion on how the approach would scale or behave with an increasing number of variables or in nonlinear settings.
- Some derivations and notations lack clarity, which may hinder understanding.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their explanations, particularly regarding Equation (2), "homotopy," and the bounding of $a$. Additionally, please elaborate on the difficulties mentioned in Remark 2 and provide more details in the caption of Figure 2. It would be beneficial to explore whether similar results hold for higher values of $d$ and to include numerical studies on larger-scale problems. Finally, consider discussing how the insights from the theoretical results could be applied to practical algorithms and the implications of non-linear functions on the optimization landscape.