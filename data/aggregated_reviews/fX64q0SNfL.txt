ID: fX64q0SNfL
Title: Sample based Explanations via Generalized Representers
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 5, 4, 7, 5, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a unifying framework for sample-based explanation methods through generalized representers, approximating nonlinear predictive functions using a surrogate from the Reproducing Kernel Hilbert Space (RKHS). The authors propose a necessary and sufficient explanation function $\phi$, which can be decomposed into global and local components, satisfying several axioms. The framework encompasses existing methods like TracInCP and influence functions as specific instances, and introduces a new strategy to alleviate the computational burden of TracInCP. Empirical results from experiments on CNN models with CIFAR10 and MNIST demonstrate the impact of different alpha coefficients and kernel functions. Additionally, the authors conduct an axiomatic analysis of influence measures, revealing that effective measures can be expressed as a coefficient multiplied by a continuous and positive definite kernel function.

### Strengths and Weaknesses
Strengths:  
1. The unification of existing sample-based explanation approaches is elegant, original, and novel.  
2. The paper is clear and self-contained, effectively presenting complex ideas.  

Weaknesses:  
1. Code availability is lacking, hindering reproducibility of the analysis.  
2. The theoretical insights drawn from the framework are limited, primarily focusing on alpha/kernel function choices.  
3. The experimental analysis relies on small and simple neural networks, which may not adequately demonstrate the framework's capabilities. Comparisons with TracInCP should utilize the same experimental settings as the original paper, such as employing a ResNet architecture.  
4. Insufficient discussion regarding the validity of the axioms, particularly in relation to existing metrics like Data Shapley.

### Suggestions for Improvement
We recommend that the authors improve the paper by releasing the code to enhance reproducibility. Additionally, the authors should expand the discussion on the significance of their theoretical insights beyond alpha/kernel function choices. It would be beneficial to conduct experiments using larger and more complex neural networks, such as ResNet, to validate the framework's applicability. We also suggest addressing the validity of the axioms in greater detail, particularly comparing them with those used in Data Shapley. Furthermore, consider revising the presentation by summarizing sample-based explanation strategies in a table format to clarify the differences in alpha and kernel function choices. Lastly, we encourage the authors to elaborate on the distinctions between TracInCP and their proposed strategy.