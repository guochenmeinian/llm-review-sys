ID: bjvRVA2ihO
Title: How to Data in Datathons
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 6, 7, 7, 6, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 2, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a five-part framework for assessing datasets used in datathons, focusing on dimensions such as appropriateness, readiness, reliability, sensitivity, and sufficiency. The authors analyze ten datathon datasets through this framework and provide recommendations for effective data preparation in future datathons. They emphasize the importance of pre-hackathon organization and preparation, drawing from their extensive experience in organizing datathons. The framework serves as a broad guide for participants and organizers, acknowledging the complexity of transitioning data stages and highlighting the unique challenges of data preparation for datathons compared to traditional research projects. The authors integrate existing literature and frameworks, consolidating established data quality criteria while introducing a new sensitivity dimension. They clarify the relationship between data documentation and assessment, particularly in the context of datathons.

### Strengths and Weaknesses
Strengths:
- The literature review is comprehensive and well-articulated, covering a broad range of relevant fields.
- The framework is actionable and grounded in real-world insights from the authors' experiences with Data Study Groups (DSGs).
- The paper includes detailed analyses of ten datathon use cases, offering practical guidelines for event organizers.
- The framework provides a structured approach to data assessment in datathons, addressing a gap in the literature.
- The authors effectively clarify the unique aspects of datathon data preparation compared to traditional research.
- The integration of case studies illustrates the practical application of the framework.

Weaknesses:
- The recommendations in Section 6 are minimal and lack context within the five-part framework, missing actionable insights for organizing datathons.
- The paper does not adequately address ethical considerations related to data use in datathons, leaving a significant gap in the framework.
- The distinction between "insufficient" and "developing" in the sufficiency criteria is unclear, and the assessment matrix lacks clarity on its application.
- The paper lacks specific actionable recommendations for data transitions, which could limit its practical utility.
- The discussion on ethics and privacy is insufficiently detailed, potentially overlooking critical considerations in data handling.
- The relationship between data documentation and assessment requires further elaboration to enhance clarity.

### Suggestions for Improvement
We recommend that the authors improve the recommendations in Section 6 by providing more actionable insights contextualized within the five-part framework, such as specific steps for assessing data sufficiency and readiness. Additionally, we encourage the authors to include a detailed discussion on the unique challenges of preparing data for datathons compared to regular datasets, as well as to clarify the mapping process of challenges to the framework. It would also be beneficial to enhance the ethical considerations section, addressing data protection and ethical guidelines comprehensively. Furthermore, we suggest improving the specificity of actionable insights regarding data transitions, perhaps by including more concrete examples or guidelines. Lastly, we encourage the authors to provide a more explicit discussion on the relationship between data documentation and assessment, particularly under the "readiness" dimension, to clarify its importance in the datathon context.