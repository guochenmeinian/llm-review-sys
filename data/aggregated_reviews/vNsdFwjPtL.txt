ID: vNsdFwjPtL
Title: Suggesting Variable Order for Cylindrical Algebraic Decomposition via Reinforcement Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 5, 6, 7, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method for suggesting variable order in Cylindrical Algebraic Decomposition (CAD) using Reinforcement Learning (RL) and Graph Neural Networks (GNN). The authors propose two variants: GRL-SVO(UP) with projection and GRL-SVO(NUP) without projection. The objective is to minimize the number of cells generated by the mathematical procedure, which is influenced by variable ordering. The authors utilize a graph representation of the polynomial set, where the action is variable permutation and the reward is the reduction in cell count. The experimental results indicate that the UP method outperforms existing methods.

### Strengths and Weaknesses
Strengths:
- The application of RL to optimize variable ordering in CAD is innovative and well-executed.
- The method demonstrates strong empirical performance and generalization across variable sets.
- The paper is well-structured, with clear explanations and a comprehensive literature review.

Weaknesses:
- The paper lacks ablation studies to assess the impact of different components, particularly the GNN's role.
- The novelty primarily lies in the problem setup rather than in the RL methodology itself.
- The interpretability of the model is limited, and there is a potential risk of overfitting due to the use of large neural networks on small datasets.

### Suggestions for Improvement
We recommend that the authors improve the interpretability of their model by conducting ablation studies to identify the importance of the 14 human-crafted features in the graph embedding matrix. Additionally, the authors should empirically evaluate the performance of simpler neural networks, such as MLPs, to assess overfitting risks. We suggest exploring various GNN architectures (e.g., GAT, GATv2, GraphSage) to enhance the robustness of their findings. Furthermore, the authors should clarify the role of polynomial coefficients in their graph representation and provide more analysis on the normalization factor “M” and its effects on performance and training stability.