ID: SKY1ScUTwA
Title: The Intelligible and Effective Graph Neural Additive Network
Conference: NeurIPS
Year: 2024
Number of Reviews: 18
Original Ratings: 5, 5, 4, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Graph Neural Additive Network (GNAN), which integrates Generalized Additive Models (GAMs) with Graph Neural Networks (GNNs) to enhance interpretability. GNAN aims to provide clear visualizations of feature effects and relationships within graph structures, achieving performance comparable to traditional GNNs. The authors propose that GNAN's design allows for a transparent decision-making process, making it suitable for applications requiring both accuracy and interpretability.

### Strengths and Weaknesses
Strengths:
- The paper introduces a novel approach by extending GAMs to graph neural networks, demonstrating comparable performance to mainstream GNNs.
- Extensive experiments validate the interpretability of GNAN through visualizations.

Weaknesses:
- The interpretability claims are not thoroughly tested; visualizations may be biased without an ablation study or comparison to true underlying data.
- The model's empirical performance does not consistently outperform baselines across datasets, raising questions about its effectiveness.
- The formulas and methods section is inadequately presented, and the computational cost of calculating shortest paths in large datasets is a concern.

### Suggestions for Improvement
We recommend that the authors improve the interpretability testing by conducting an ablation study with simulated feature effects to validate visualizations. Additionally, the authors should clarify the hyperparameter tuning process and ensure that architectures for GNAN and comparison models are consistent. To enhance the presentation, we suggest refining the formulas and methods section for clarity. Finally, addressing the scalability issues for large graphs and feature spaces through preprocessing strategies would strengthen the paper's contributions.