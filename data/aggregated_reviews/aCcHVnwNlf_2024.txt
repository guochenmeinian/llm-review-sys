ID: aCcHVnwNlf
Title: On Differentially Private Subspace Estimation in a Distribution-Free Setting
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 6, 7, 7, 7, -1, -1
Original Confidences: 3, 3, 3, 4, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on private subspace learning, addressing the challenge of high costs in private data analysis due to the curse of dimensionality. The authors propose measures based on multiplicative singular-value gaps to quantify dataset "easiness" for private subspace estimation. They derive new bounds and an implementable algorithm that can estimate subspaces with a number of points independent of the dimension, demonstrating improved performance in high-dimensional settings. The work also explores private PCA under the assumption of multiplicative decay in singular values, extending prior research and providing upper and lower bounds on sample complexity.

### Strengths and Weaknesses
Strengths:
1. The problem is well-motivated, with both upper and lower bounds provided.
2. The writing is clear, and the literature review is relatively comprehensive.
3. The removal of the Gaussianity assumption allows for broader applicability.
4. The proposed measure of dataset "easiness" is intuitive and practically relevant.

Weaknesses:
1. There are significant gaps between the upper and lower bounds.
2. Some parameters, such as $\lambda$, are vaguely described, hindering understanding.
3. The presentation could be improved, particularly in explaining gamma-easiness and the lower-bounds overview.

### Suggestions for Improvement
We recommend that the authors improve the clarity of parameter definitions, particularly for $\lambda$, to enhance understanding of its significance in the sample complexity bounds. Additionally, we suggest that the authors address the gaps between upper and lower bounds to strengthen their results. Improving the presentation of gamma-easiness early in the paper and making the lower-bounds overview more modular could also enhance readability. Finally, the authors should consider refining their upper bounds to achieve better dependence on $k$.