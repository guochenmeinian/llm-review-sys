ID: bxDok3uaK6
Title: Long-Range Feedback Spiking Network Captures Dynamic and Static Representations of the Visual Cortex under Movie Stimuli
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 7, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a long-range feedback spiking network (LoRaFB-SNet) designed to mimic neuronal and synaptic behavior in the brain's cortical regions. The authors propose a Time-Series Representational Similarity Analysis (TSRSA) framework to evaluate the similarity between the model's representations and those of the mouse visual cortex. The model demonstrates the highest representational similarity compared to existing baselines, suggesting that feedback connections and spiking mechanisms enhance performance by allowing for the extraction of temporal features. Additionally, the authors introduce a novel model, LoRaFB-CNet, which incorporates spiking mechanisms and long-range feedback connections to improve representational similarity to the visual cortex when processing movie stimuli. They report that LoRaFB-CNet achieves 63.3% and 45.9% of the neural ceilings for two movies, indicating effective neural representation capture, and discuss the influence of the entire movie on neural responses to clips.

### Strengths and Weaknesses
Strengths:  
- The paper effectively motivates the analysis of dynamic and static representations of visual stimuli, emphasizing the biological significance of feedback connections.  
- The introduction of TSRSA as an analytical tool is particularly noteworthy and contributes to understanding neural model representations.  
- The introduction of spiking mechanisms in deep neural networks is a pioneering effort that contributes to computational neuroscience.  
- The model demonstrates improved representational similarity scores compared to existing models, particularly for longer movie stimuli.  
- The authors provide detailed comparisons of their model's performance against neural ceilings and other models, showcasing its effectiveness.

Weaknesses:  
- The model architecture lacks novelty, as previous studies have highlighted the importance of long-range feedback in spiking neural networks (SNNs).  
- The explanation of TSRSA is overly textual and could benefit from a more mathematical approach.  
- The paper's baseline comparisons are limited, and further exploration of state-of-the-art vision models would enhance insights.  
- The discussion on spiking mechanisms is insufficient, particularly regarding their impact on model performance compared to non-spiking models like CORnet.  
- The absolute representational similarity scores are relatively low, raising concerns about the model's robustness.  
- The choice of the Pearson correlation coefficient for similarity measurement may overlook nonlinear relationships that the Spearman coefficient could capture.  
- The dataset size is limited, which may affect the generalizability of the results.

### Suggestions for Improvement
We recommend that the authors improve the clarity and depth of the discussion surrounding the benefits of spiking mechanisms, particularly how they enhance model performance over non-spiking alternatives. Providing more comprehensive comparisons with CORnet and other relevant models would strengthen the analysis. We suggest expanding the baseline comparisons to include state-of-the-art vision models such as VLMs and Video-LMs. Additionally, the authors should clarify the influence of the pretraining task on model performance and consider exploring the impact of local recurrent connections, which could provide valuable insights into the model's functionality. To enhance robustness, we recommend validating the model on larger and more diverse datasets, such as chronic 2-photon imaging datasets and electrophysiological datasets. Furthermore, it would be beneficial to clarify the rationale behind the choice of the Pearson correlation coefficient and consider incorporating the Spearman coefficient in future analyses to capture potential nonlinear relationships. Finally, addressing the limitations related to local recurrences in the model could provide a more comprehensive understanding of brain-like information processing.