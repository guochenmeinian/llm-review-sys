ID: j6kJSS9O6I
Title: Agent Planning with World Knowledge Model
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 6, 7, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a parametric World Knowledge Model (WKM) aimed at enhancing agent planning by integrating global task knowledge and dynamic state knowledge. The model synthesizes knowledge from expert and sampled trajectories, addressing limitations of traditional LLMs, such as hallucinations and invalid actions. The authors effectively explore world knowledge training and have addressed previous concerns raised by reviewers, leading to a clearer understanding of the topic. Experimental results demonstrate improved performance on complex tasks using state-of-the-art LLMs like Mistral-7B and Gemma-7B, showcasing the model's effectiveness in real-world simulated environments.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and presents a novel approach to enhancing planning in LLMs.
- Promising results are achieved using smaller models that typically struggle with planning tasks.
- The integration of a world knowledge model is a reasonable enhancement for task-specific knowledge.
- The authors' rebuttal has successfully clarified key aspects of world knowledge training, leading to an improved understanding of the work.

Weaknesses:
- Clarity is needed regarding hyperparameters, such as the tuning process for WKM and the structure of the retriever.
- The importance of WKM training for common-sense tasks versus pure planning tasks remains unclear.
- The computational overhead of using WKM for inference and the comparison of beam search time with ReAct are not addressed.
- The distinction between state knowledge and thoughts/reflections is ambiguous, and examples provided may not clearly represent world knowledge.
- The feasibility of merging WKM and agent training into a single model is not explored.
- The applicability of the method in an online setting, where the knowledge base updates dynamically, is questioned.
- No specific weaknesses were noted in the reviews.

### Suggestions for Improvement
We recommend that the authors improve clarity on hyperparameters and settings, specifically regarding the tuning process for WKM and the task split. Additionally, the authors should investigate the significance of WKM training for various task types and provide insights into the computational overhead associated with WKM inference. Clarifying the definitions of state knowledge versus thoughts and ensuring that examples accurately reflect world knowledge would enhance understanding. We also suggest exploring the possibility of integrating WKM with agent training and discussing the method's application in an online context. Furthermore, we encourage the authors to incorporate the feedback received to enhance clarity and depth further.