ID: 67N3FWoDtU
Title: Chronicling Germany: An Annotated Historical Newspaper Dataset
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 4, 4, 5, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 5, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Chronicling Germany dataset, which comprises 581 annotated pages of historical German newspapers from 1852 to 1924, along with a processing pipeline for layout detection and OCR. The dataset addresses the lack of layout information in historical German newspapers and includes detailed annotations for text recognition and reading order tasks. Baseline results for the pipeline are reported, validating its effectiveness on both in-domain and out-of-domain test data. Additionally, the authors evaluate a pipeline for text detection in historical newspapers, utilizing a U-Net for baseline detection and comparing it with a Yolo v8 model. They aim to enhance performance on fraktur letters by aligning their annotations with established datasets, reporting improvements in object-level recall and F1 scores after fine-tuning an OCR transformer, indicating a slight performance edge over the original LSTM-based OCR.

### Strengths and Weaknesses
Strengths:
- The dataset fills a significant gap in resources for historical German newspapers, allowing for the study of social perspectives and cultural values.
- High-quality annotations provide detailed layout information crucial for accurate OCR and text processing.
- The public availability of the dataset and code promotes reproducibility and further research.
- The authors provide a comprehensive evaluation of their pipeline, including detailed performance metrics such as Levenshtein distance and object-level recall.
- The integration of datasets and alignment with existing corpus enhances the potential for future research.

Weaknesses:
- The dataset's limited temporal and geographical scope raises concerns about its representativeness and generalization ability.
- The paper lacks comprehensive benchmark experiments and performance analysis using existing models, affecting its reliability.
- Clarity issues exist in the experimental setup and results sections, making it difficult to follow the methodology.
- The lack of annotated ground-truth text boxes complicates the fine-tuning process for the pipeline.
- Some reviewer responses indicate that certain explanations could have been more thorough, particularly regarding specific concerns.

### Suggestions for Improvement
We recommend that the authors improve the dataset's temporal and geographical diversity by extending the annotated dataset to include a wider range of newspapers and publication years. This should include a significant increase in the out-of-distribution test set sampled uniformly across the timeline from 1852 to 1924.

We suggest conducting more comprehensive benchmark experiments, including performance evaluations of state-of-the-art methods on this dataset, to provide a clearer perspective on its applicability.

We recommend enhancing the clarity of the experimental setup and results sections, particularly by detailing the number of images used for training and testing the OCR model, and ensuring that the test data is truly held out.

We encourage the authors to elaborate on the choice of metrics for OCR assessment and to provide more detailed documentation on the annotation process to facilitate replication by other researchers.

We advise addressing potential ethical concerns related to the dataset's content, particularly regarding personal information and cultural sensitivity.

Additionally, we recommend that the authors improve the comprehensiveness of their responses to reviewer concerns, particularly in areas where clarity is lacking. Addressing the annotation issue for ground-truth text boxes would facilitate better fine-tuning of the proposed pipeline.