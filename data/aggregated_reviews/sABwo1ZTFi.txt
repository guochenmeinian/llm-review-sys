ID: sABwo1ZTFi
Title: Generalizablity of Memorization Neural Network
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 7, 7, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive study of the generalization capabilities of memorization networks, particularly focusing on networks that achieve optimal memorization capacity with O(sqrt(N)) parameters for N samples. The authors propose a memorization algorithm based on the construction by Vardi et al. and demonstrate that memorization with a fixed width or limited parameters fails to generalize effectively. They provide upper and lower bounds for the communication complexity of learning with a memorization algorithm and introduce an efficient memorization algorithm.

### Strengths and Weaknesses
Strengths:
- The research direction is novel and highlights the unclear generalization capabilities of efficient memorization results.
- The paper is well-presented, making it easy to follow, with sufficient proof intuitions.
- Section 5 effectively illustrates the limitations of efficient memorization results, while Section 6 offers extensive sample complexity bounds connecting memorization network size to required sample numbers.

Weaknesses:
- The proof for Proposition 3.8 is missing, and the probabilistic nature of constructions in [54,48] is unclear.
- The proof of Theorem 5.3 is ambiguous, as it constructs a distribution D dependent on the training set D_tr, which may not support the theorem's claim.
- The comparison between interpolation and memorization learning lacks clarity regarding when interpolation results provide generalization bounds for memorization learning.
- The significance of theoretical results is diminished due to the absence of estimates for $N_\mathcal{D}$ and $S_\mathcal{D}$.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Proposition 3.8 by including the proof and addressing the probabilistic nature of the constructions. Additionally, the authors should revise the proof of Theorem 5.3 to ensure it accurately reflects the existence of a distribution D independent of D_tr. Clarifying the relationship between interpolation and memorization learning would enhance the paper's contribution. Furthermore, providing estimates for $N_\mathcal{D}$ and $S_\mathcal{D}$, even for simple examples, would strengthen the significance of the theoretical results. Lastly, addressing minor writing issues and typos throughout the paper would improve overall readability.