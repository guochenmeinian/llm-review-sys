ID: GzlDKZlwie
Title: Functional Renyi Differential Privacy for Generative Modeling
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 7, 5, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel variant of differential privacy called functional RDP (f-RDP), which extends the concept of RÃ©nyi differential privacy (RDP) to functional outputs. The authors propose definitions and theorems for f-RDP, including composition, post-processing, and the application of the subsampled Gaussian mechanism. They demonstrate the utility of f-RDP in training private generative models, showing improvements in image quality at strong privacy levels ($\epsilon=0.2$) across several datasets. The work aims to bridge the gap between traditional differential privacy and functional outputs, particularly in infinite-dimensional spaces.

### Strengths and Weaknesses
Strengths:
1. The theoretical contributions are solid, with several important properties of f-RDP established.
2. The application of f-RDP to real-world generative models is promising, demonstrating improved performance while maintaining privacy.
3. The overall presentation of the paper is generally good, with a clear structure and flow.

Weaknesses:
1. The originality of the work is questionable, as it primarily combines existing concepts of RDP and f-DP without exploring new properties.
2. The paper lacks detailed explanations of key mathematical concepts, which may hinder accessibility for readers outside the differential privacy community.
3. Quantitative results are presented without statistical uncertainty, limiting the robustness of the findings.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by providing more detailed explanations of complex concepts such as functionals, Borel sets, and Gaussian processes to enhance accessibility for a broader audience. Additionally, the authors should quantify the improvement in $\epsilon$ when using f-RDP compared to existing f-DP analysis and provide error bars for the results in Tables 1 and 3 to address concerns about statistical uncertainty. We also encourage the authors to explore alternative evaluation metrics beyond FID, considering the criticisms of its use in the literature, and to clarify the relationship between their proposed f-RDP and traditional RDP. Lastly, we suggest a more thorough discussion of the broader impacts of their work, particularly regarding fairness in private model training.