ID: MKjGklW9TP
Title: ClusterPrompt: Cluster Semantic Enhanced Prompt Learning for New Intent Discovery
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a semi-supervised method for new intent discovery in user utterances, introducing Cluster Semantic Enhanced Prompt Learning (CsePL). The authors recognize limitations in previous works, such as in-domain over-fitting and low-quality intent clusters, and propose a two-level contrastive learning approach with label semantic alignment to learn intent cluster representations. Extensive experiments on datasets like BANKING77, CLINC150, and StackOverflow demonstrate the method's effectiveness.

### Strengths and Weaknesses
Strengths:  
1. The paper addresses an important problem in discovering new intents, enhancing dialogue system capabilities.  
2. Extensive experiments validate the proposed method's superiority over several baselines.  
3. The use of contrastive learning and label semantic alignment is innovative and well-discussed.  

Weaknesses:  
1. The motivation and novelty of the paper are unclear, particularly regarding the relationship between the proposed methods and the limitations of previous studies.  
2. The effectiveness of the method's components is difficult to assess due to their complexity.  
3. Some experimental results, such as the NMI metric, show underperformance compared to existing methods like USNID.  

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation behind the study and explicitly connect the proposed methods to the identified limitations. Additionally, the authors should provide a more detailed analysis of the effectiveness of each component of the method. Clarifying the augmented version mentioned in line 283 and addressing the concerns regarding the sequence of soft prompts and the use of a pre-trained backbone in PID would strengthen the paper. Finally, summarizing the total loss function in stages 1 and 2, including how to balance the losses, would enhance understanding.