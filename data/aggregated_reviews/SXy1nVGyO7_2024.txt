ID: SXy1nVGyO7
Title: On the Identifiability of Hybrid Deep Generative Models: Meta-Learning as a Solution
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 7, 5, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a thorough assessment of the identifiability of both neural and physics components in hybrid deep generative models (hybrid-DGMs) and proposes a novel meta-learning approach to formulate these models. The authors demonstrate the model's performance against other hybrid-DGMs and ground truth across three established physics examples.

### Strengths and Weaknesses
Strengths:  
- The paper is the first theoretical study addressing the identifiability of hybrid-DGMs.  
- The motivation for analyzing identifiability is clearly stated, and the potential connection to nonlinear ICAs is intriguing.  
- The method is technically sound, with meta-learning applied in a novel context.  
- Experiments are conducted with reasonable synthetic datasets and adequate baseline methods.  

Weaknesses:  
- There are possible limitations regarding the applicability of meta-learning specifics.  
- The motivation for identifying the data-driven part lacks clarity, as it primarily focuses on approximation accuracy rather than interpretability.  
- The theoretical contribution appears to be borrowed from existing literature without significant revisions, limiting its significance.  
- The writing quality needs improvement, particularly in notation definitions and clarity.  
- Minor issues include typos and missing references, as well as an incomplete appendix.  

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation for identifying the data-driven components, emphasizing their interpretability. Additionally, we suggest enhancing the theoretical contribution by revising the discussions to reflect the unique aspects of hybrid-DGMs. The authors should also address the writing quality, particularly in defining notations and correcting typos. Furthermore, we encourage the authors to conduct a detailed hyperparameter performance study and explore the potential benefits of using the Wasserstein distance instead of KL divergence for improved identifiability. Lastly, providing examples with more parameters to identify in complex models would strengthen the proof-of-concept results.