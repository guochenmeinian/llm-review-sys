ID: vkEYzLIdLX
Title: Dolphin: A Challenging and Diverse Benchmark for Arabic NLG
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive benchmark for Arabic natural language generation (NLG) consisting of 40 datasets across 13 tasks, primarily utilizing publicly available datasets while also introducing new datasets for context switching and dialogue response generation. The authors evaluate multilingual models on this benchmark, providing baselines and a leaderboard featuring an aggregate metric called the Dolphin score. The benchmark is promoted as a significant resource for advancing research in Arabic NLG.

### Strengths and Weaknesses
Strengths:
- The benchmark is well-constructed, offering a clear comparison to existing benchmarks and addressing strengths and weaknesses in prior works.
- It enhances reproducibility in Arabic NLG research and emphasizes public access and diversity.
- The paper is organized and presents a thorough analysis of results, making it suitable for a high-impact conference.

Weaknesses:
- The design principles are similar to those in the ARGEN benchmark, raising concerns about originality.
- The evaluation discussion does not adequately address the unique signatures of the Dolphin benchmark, such as diversity and inclusivity.
- The section on "Model Computational Costs" lacks meaningful content.

### Suggestions for Improvement
We recommend that the authors improve the discussion of model evaluation to explicitly consider the unique aspects of the Dolphin benchmark. Additionally, we suggest providing more detailed support for minor claims and ensuring that all parameter settings are clearly specified to enhance reproducibility. Lastly, we encourage the authors to clarify the distinctions between Dolphin and ARGEN to address concerns regarding originality.