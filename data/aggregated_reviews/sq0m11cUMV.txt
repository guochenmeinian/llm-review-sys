ID: sq0m11cUMV
Title: Belief Projection-Based Reinforcement Learning for Environments with Delayed Feedback
Conference: NeurIPS
Year: 2023
Number of Reviews: 19
Original Ratings: 6, 7, 7, 4, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 3, 1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a solution to the delayed feedback problem in reinforcement learning (RL), specifically addressing fixed timestep delays through the introduction of Belief Projection Based Q-Learning (BPQL). The authors argue that BPQL effectively represents augmented state-based Q-values without the exponential growth in state space typically associated with longer delays. The paper provides a theoretical foundation for BPQL and demonstrates its effectiveness through empirical evaluations on the MuJoCo benchmark, where it outperforms naive and augmented approaches in continuous control tasks. Additionally, the authors explore the impact of additional actions on the augmented state space in delayed environments, asserting that their belief projection method stabilizes convergence in Q-learning. They emphasize the importance of including the last d actions in the policy input for decision-making in such environments. The authors also propose to include new experimental results in discrete settings to further support their findings.

### Strengths and Weaknesses
Strengths:
- The approach is technically novel, applying belief-based machine learning to a significant issue in real-world applications, particularly in robotics.
- The mathematical reasoning is sound, with clear assumptions stated regarding the constant delayed MDP.
- The empirical results demonstrate the significant impact of additional actions on Q-function convergence, and the evaluation on MuJoCo is thorough, showing impressive performance improvements over existing methods.
- The authors provide a clear connection between their approach and existing literature on POMDPs.
- The commitment to open-sourcing their code will benefit the RL and robot learning communities.

Weaknesses:
- The paper lacks a discussion on belief-state architectures, which could provide relevant context to the proposed method.
- The novelty claim compared to existing work, particularly Agarwal & Aggarwal (2021), is unclear, especially regarding the continuous control aspect.
- The motivation for using belief-based projection is insufficiently explained, and the presentation of theoretical concepts may be too complex for a broader audience.
- The theoretical contributions are perceived as lacking clarity, making it difficult for some reviewers to grasp their significance.
- The transition from linear projection to sampling-based implementation is not sufficiently clear, leading to confusion regarding the role of augmented states in Q-function updates.
- The evaluation is limited to four relatively simple MuJoCo benchmarks, and there is a lack of clarity on the choice of baselines and their parameterization.
- There is a lack of clarity on how the new results will be integrated into the existing paper.

### Suggestions for Improvement
We recommend that the authors improve the discussion on belief-state architectures to provide context for their approach. Additionally, clarifying the novelty of BPQL compared to Agarwal & Aggarwal (2021) and providing direct comparisons with established discrete solutions would strengthen the paper. We suggest enhancing the motivation for belief-based projection and simplifying the presentation of theoretical concepts to improve accessibility. Improving the clarity of the theoretical section by providing a more comprehensive explanation of the belief projection method and its implications would also be beneficial. An outline summarizing the solution before the detailed derivations in Section 4 would enhance reader comprehension. Furthermore, clarifying the notation regarding the parameterized beta Q-values to avoid confusion with standard neural network parameters, addressing the minor typo in Equation (7), and ensuring that the integration of new experimental results into the paper is clearly articulated will improve the overall precision and coherence of the manuscript. Lastly, we encourage the authors to ensure that the open-sourced code is accessible and well-documented for the community's benefit.