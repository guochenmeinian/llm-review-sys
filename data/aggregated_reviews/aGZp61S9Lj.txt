ID: aGZp61S9Lj
Title: Enhancing Adaptive History Reserving by Spiking Convolutional Block Attention Module in Recurrent Neural Networks
Conference: NeurIPS
Year: 2023
Number of Reviews: 6
Original Ratings: 7, 7, 3, 7, -1, -1
Original Confidences: 5, 5, 5, 5, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel spiking recurrent neural network model, SRNN-SCBAM, which integrates a spiking convolutional block attention mechanism. The primary aim is to effectively incorporate historical information into the spatial and temporal characteristics of spatiotemporal patterns, enhancing memory retrieval and reducing redundant historical data. The model's efficacy is validated through experiments on DVS128-Gesture datasets, demonstrating improved accuracy and efficient memory utilization compared to other models.

### Strengths and Weaknesses
Strengths:  
1. The practical issue of adaptive memory in spiking recurrent neural networks is effectively addressed.  
2. The learning algorithm for recurrent SNNs is straightforward and comprehensible.  
3. The proposed model is simple yet effective, with clear motivation and experimental evaluations on multiple neuromorphic datasets.  

Weaknesses:  
1. The writing quality needs significant improvement; some sections are difficult to follow.  
2. More ablation studies are required to clarify the influence of different gates in Table 1, and the potential for adaptive parameters to enhance performance should be explored.  
3. The paper lacks detailed explanations of certain parameter settings and experimental results, particularly regarding the network structure and the impact of specific parameters like alpha in Equation (7).  
4. There is a need for additional visualization of experimental results, especially for the CIFAR10-DVS dataset.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing to enhance readability and comprehension. Additionally, the authors should provide more ablation studies regarding the different gates in Table 1 and explore the potential of adaptive parameters for performance enhancement. It is crucial to include detailed explanations of parameter settings, particularly the time constant mentioned in section 2.4, and to supplement the experimental results with appropriate visualizations, especially for the CIFAR10-DVS dataset.