ID: a34bgvner1
Title: Benchmark Probing: Investigating Data Leakage in Large Language Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 2
Original Ratings: 5, 6
Original Confidences: 4, 4

Aggregated Review:
### Key Points
This paper studies the detection of data contamination in large language models (LLMs) by proposing methods that do not require access to the training dataset. The authors introduce two tasks: predicting critical keywords and predicting incorrect options in multiple-choice questions. They report exact match accuracy for the first task and ROUGE and BLEURT scores for the second.

### Strengths and Weaknesses
Strengths:
- The Question-multichoice setting is a novel approach for evaluating data contamination, allowing for the creation of various new research variants.
- The findings indicate that GPT-3.5-turbo and GPT-4 show over 52% exact match with incorrect options in multiple-choice test questions.

Weaknesses:
- The paper's relevance to the workshop on backdoor research is questionable.
- The evaluation in the Question-based setting lacks convincing justification for how correct completions indicate prior exposure to the questions.
- Section 3.5 is unclear, as it does not adequately assess the relationship between TS-guessing and task performance due to the limited number of models evaluated.
- There is insufficient interpretation of the accuracy scores, raising concerns about whether predictions are merely logical choices.
- The paper lacks comparison with existing methods, such as reference [5], which proposes a similar technique but predicts all text rather than just critical keywords.
- The quality of writing requires improvement, with specific sentences lacking clarity.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Section 3.5 by providing a more detailed explanation of the relationship between TS-guessing and task performance, potentially using different models with varying TS-guessing scores. Additionally, we suggest that the authors clarify how to interpret the accuracy scores and establish a threshold for significance. A comparative analysis with existing methods, particularly reference [5], should be included to highlight the differences in ranking induced by their proposed scores. Finally, we urge the authors to enhance the overall quality of writing for better comprehension.