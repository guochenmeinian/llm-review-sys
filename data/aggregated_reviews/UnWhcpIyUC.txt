ID: UnWhcpIyUC
Title: Me, Myself, and AI: The Situational Awareness Dataset (SAD) for LLMs
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 8, 7, 4, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a benchmark on situational awareness in large language models (LLMs), introducing the Situational Awareness Datasets (SAD), which includes 16 tasks across three categories: self-knowledge, inferences, and action selection. The authors benchmark various LLMs, revealing that chat-fine-tuned models generally outperform base models, with Claude-3-opus achieving the highest performance at around 50%, still below the upper baseline of 90%. The results indicate that the benchmark measures different capabilities than those assessed by MMLU, as performance is not well-correlated with MMLU scores.

### Strengths and Weaknesses
Strengths:
- The benchmark is meticulously crafted, featuring three levels of abilities and over 13,000 questions, making it comprehensive.
- The paper is well-written, clear, and presents its conclusions accessibly.
- The evaluation of situational awareness is original and significant for LLM research.

Weaknesses:
- The complexity of tasks could be improved to better assess situational awareness in more challenging contexts.
- The paper lacks empirical evidence linking SAD scores to real-world effectiveness, raising questions about the practical value of assessing situational awareness.
- There is insufficient discussion on the psychological theory underpinning the evaluation process.

### Suggestions for Improvement
We recommend that the authors improve the complexity of the tasks considered, as many current models may only demonstrate situational awareness in controlled settings. Expanding on SAD-Inferences and SAD-Actions with more complex tasks would be beneficial for future work. Additionally, we suggest providing more details on the selection of original data for the benchmark and consulting psychological literature to support the evaluation process. Lastly, addressing the potential societal and ethical impacts of the study would strengthen the paper, and we recommend including a discussion on the implications of using model-generated prompts in the SAD-Influence dataset.