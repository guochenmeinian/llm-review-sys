ID: LH94zPv8cu
Title: Warped Diffusion: Solving Video Inverse Problems with Image Diffusion Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 6, 6, 5, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to video inverse problems using image diffusion models, termed warped diffusion. The authors propose a continuous function space perspective that incorporates a Gaussian process-based noise-warping technique and an equivariance self-guidance method to enhance temporal consistency in generated videos. The effectiveness of warped diffusion is validated through experiments on video super-resolution and inpainting, demonstrating superior performance with latent diffusion models like SDXL.

### Strengths and Weaknesses
Strengths:
1. The proposed method is well-motivated with well-constructed formulations.
2. The paper is well-written and presented in a structured manner, with coherent content and helpful illustrations.
3. The visualization results are impressive, and the extensive experiments support the claims made.

Weaknesses:
1. The GP Noise Warping performs worse than "How I Warped Your Noise" in terms of warping error, with core performance improvements stemming from the equivariance self-guidance.
2. The equivariance self-guidance is inefficient, making the overall process more time-consuming despite being more efficient than "How I Warped Your Noise."
3. The inpainted regions in video examples remain static, raising questions about the method's ability to handle dynamic content.

### Suggestions for Improvement
We recommend that the authors improve the explanation and illustration of how the self-guidance equivariance works, as the current Figure 2 lacks clarity. Additionally, we suggest including the complete inference time for processing an entire video to provide a comprehensive understanding of the method's efficiency. More video results should be provided to demonstrate the capabilities and limitations of the proposed method in various scenarios. Lastly, we encourage the authors to address the static nature of inpainted regions and clarify how the method can handle moving objects in video inpainting.