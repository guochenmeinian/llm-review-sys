ID: 4d8dO5sAeM
Title: Benchmarking Robustness of Adaptation Methods on Pre-trained Vision-Language Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 27
Original Ratings: 4, 6, 5, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 5, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive evaluation of the robustness of adaptation models on pretrained vision-language (VL) models, focusing on natural robustness against various corruptions, including noise, blurring, weather conditions for images, and typos and character modifications for text. The authors benchmark 11 adaptation methods across 4 datasets, revealing that adaptation methods are more sensitive to text corruptions than visual ones. They utilize a semantic preserving mechanism to maintain the original meaning of corrupted texts and conduct extensive experiments, including 48 new experiments on the VQA-RAD dataset. The findings indicate that adapters can outperform full fine-tuning in certain contexts. The authors acknowledge the limitations of their evaluation benchmark, primarily focusing on image-text models, and recognize the need for further exploration of adversarial corruptions.

### Strengths and Weaknesses
Strengths:
1. The paper is well-structured, easy to follow, and presents a novel benchmark for robustness in VL adaptation tasks.
2. The authors have conducted extensive experiments, providing a detailed analysis of robustness across various adaptation methods and corruption types.
3. The clarity of the paper has improved based on reviewer feedback, particularly in the organization of figures and the introduction of corruption sources.
4. The incorporation of common corruption methods is well-grounded in existing robustness research, and the study maintains consistency in conclusions across different severity levels of perturbations.

Weaknesses:
1. The evaluation benchmark is limited to image-text models, potentially overstating the contribution and raising questions about the generalizability of the findings.
2. The novelty of the corruption methods is insufficient, as many are directly adopted from existing sources, and the paper lacks new evaluation metrics tailored to the specific task of analyzing adaptation methods.
3. The study lacks a human evaluation component, which could enhance the quality of the benchmark, and the focus on natural robustness limits the exploration of adversarial robustness.
4. The statistical significance of results and the evaluation of data quality and transferability remain underexplored, which could strengthen the findings.

### Suggestions for Improvement
We recommend that the authors improve the scope of their evaluation by including additional architectures beyond CLIP-BART to ensure more robust conclusions. It would be beneficial to propose new, distinct corruption methods for both text and images to enhance the novelty of the benchmark. Additionally, we suggest incorporating a performance comparison of learning efficiency alongside robustness evaluations. To provide a more comprehensive analysis, the authors should examine the effects of training sample corruption on clean accuracy and robustness, and consider including an evaluation of data quality and transferability. Finally, including advanced adversarial attack methods and conducting a human study to ensure that the corrupted samples are understandable and meaningful would broaden the scope of robustness analysis and enhance the paper's value.