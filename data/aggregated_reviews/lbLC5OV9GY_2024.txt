ID: lbLC5OV9GY
Title: VISA: Variational Inference with Sequential Sample-Average Approximations
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 5, 6, 6, 4, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for approximate inference in expensive-to-evaluate models where gradients may not be available, utilizing a trust-region optimization approach with deterministic surrogate objectives. The authors introduce a new method called VISA (Variational Inference Using Sequential Sample-Average Approximations), which is based on importance-weighted forward-KL variational inference, allowing for the reuse of model evaluations across multiple gradient steps. The method shows promising results in terms of computational efficiency and approximation accuracy compared to existing approaches.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and organized, making complex concepts accessible.
2. VISA effectively minimizes model evaluations, achieving significant computational efficiency.
3. The experiments provide robust evidence of faster convergence with fewer model evaluations compared to existing methods.

Weaknesses:
1. The choice of trust regions based on Effective Sample Size (ESS) lacks formal theoretical justification.
2. The analysis of the parameter alpha appears experimental, with no clear method for selection, raising concerns about the sensitivity of performance to this choice.
3. The paper does not adequately discuss the robustness of VISA across various optimization methods beyond L-BFGS.
4. The proposed method is sensitive to learning rates and tuning parameters, making it difficult to assess its advantages over other methods.
5. The relevance of the applications considered seems limited, as only synthetic experiments are presented without real-world examples.

### Suggestions for Improvement
We recommend that the authors improve the theoretical justification for the choice of trust regions based on ESS. Additionally, the authors should provide a clearer methodology for selecting the parameter alpha and discuss the implications of this choice on performance. We suggest including an analysis of how VISA performs with various optimization techniques, including classical stochastic gradient descent (SGD) and adaptive methods like RMSProp and Adam. Furthermore, we encourage the authors to incorporate real-world applications to enhance the relevance of their work and to clarify the effects of inconsistencies between approximate samples and the variational distribution during optimization.