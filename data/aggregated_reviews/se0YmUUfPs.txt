ID: se0YmUUfPs
Title: Manipulating the Perceived Personality Traits of Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study that investigates the ability of large language models (LLMs) to generate text consistent with specific personality traits, as defined by the Big Five personality assessment. The authors propose two datasets: one derived from human personality descriptions and another from Reddit discussions. The analysis explores how contextual prompts can manipulate the perceived personality traits of language models.

### Strengths and Weaknesses
Strengths:
- The analysis is thorough, with sound methods and significant findings that contribute to understanding personality estimation from text.
- The paper is well-organized, and the experiments are detailed, exploring various contextual data.
- The curated datasets are valuable for the research community.

Weaknesses:
- The choice of models, specifically BERT and GPT2, is outdated, raising concerns about the relevance of results to more recent models like GPT3.5.
- The generalizability of findings to other computational models is uncertain, and the experimental design lacks justification regarding biases introduced by prompts.
- Quality control on the Reddit dataset is questionable, and the paper does not address potential toxic content adequately.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the introduction by defining "context" more explicitly. Additionally, we suggest that the authors clarify the concept of "measured personality" and its relationship to generated text. To enhance the robustness of the study, we advise using more recent models, such as GPT3.5, to validate the findings. Furthermore, we recommend conducting a qualitative analysis of a random sample from the Reddit dataset to assess potential toxic language and ensure the relevance of discussions to personality traits. Lastly, we encourage the authors to establish general guidelines for their findings that are invariant to specific model types.