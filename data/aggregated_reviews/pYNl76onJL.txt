ID: pYNl76onJL
Title: VidProM: A Million-scale Real Prompt-Gallery Dataset for Text-to-Video Diffusion Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 9, 6, 9, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 5, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents VidProM, a novel large-scale dataset for text-to-video generation, comprising 1.67 million text-to-video prompts from real users and 6.69 million videos generated by four state-of-the-art diffusion models. The authors propose that VidProM serves as a foundational model for text-to-video generation, enhancing accuracy and contextual relevance. The dataset is structured to facilitate various research areas, including efficient video generation and video copy detection.

### Strengths and Weaknesses
Strengths:
- The motivation for creating a large text-to-video dataset is well-founded and clearly articulated.
- The quality of prompts in VidProM is superior, consisting of complete sentences that convey meaning effectively.
- The paper is well-organized, clearly written, and provides a comprehensive analysis of the dataset compared to DiffusionDB.

Weaknesses:
- The GitHub repository is nearly empty, lacking scalable dataloaders such as torch.dataloader and webdataset.
- The dataset's videos are limited to 3.0 seconds or shorter, which may restrict its applicability.
- There is a need for a comparison between synthetic and real-world data distributions, as well as an ablation study to evaluate the generated data's effectiveness.

### Suggestions for Improvement
We recommend that the authors improve the GitHub repository by including scalable dataloaders, such as torch.dataloader and webdataset, to encourage further research. Additionally, the authors should conduct a comparison between the distribution of synthetic data and real-world data, as well as perform more ablation studies to verify the efficiency of the generated data. It would also be beneficial to specify the duration of the videos in VidProM more precisely and to describe in detail the compositional relationship of the videos produced by the four SOTA generation models. Finally, investigating whether longer prompts yield better results could provide valuable insights into prompt length effectiveness in text-to-video generation.