ID: rLx2eDYcMK
Title: VivesDebate-Speech: A Corpus of Spoken Argumentation to Leverage Audio Features for Argument Mining
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents VivesDebate-Speech, which enhances the VivesDebate corpus by incorporating spoken argumentation to leverage audio features for argument mining tasks. The authors demonstrate that including audio features improves predictive performance and provides a significant resource for the research community, offering over 12 hours of spoken argumentationâ€”doubling the size of existing audio-based corpora. The paper emphasizes the importance of integrating audio information into argumentation processes and establishes a baseline for future research.

### Strengths and Weaknesses
Strengths:  
- The creation of a comprehensive and versatile corpus of spoken argumentation is a valuable resource for audio-based argument mining research.  
- The paper is well-written and clearly articulates the advantages of integrating audio features into argumentation tasks.  
- It presents an interesting experiment set despite space limitations.

Weaknesses:  
- The resource description lacks detail, such as the number of speakers, segment lengths, speaker identity annotations, and handling of incorrect alignments.  
- The experiments do not provide comprehensive results, particularly regarding the classification systems used, and there is insufficient discussion on the accuracy metric versus F1 score.  
- The rationale for not including a classifier that utilizes both text and audio features is unclear.

### Suggestions for Improvement
We recommend that the authors improve the resource description by including details about the number of speakers, segment lengths, speaker identity annotations, and the handling of incorrect alignments. Additionally, we suggest providing a succinct explanation for the decision to focus on F1 score over accuracy and clarifying the omission of a classifier that combines both text and audio inputs. Lastly, a more in-depth description of the classifiers used in the experiments would enhance the paper's clarity and reproducibility.