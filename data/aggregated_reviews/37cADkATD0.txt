ID: 37cADkATD0
Title: Explore to Generalize in Zero-Shot RL
Conference: NeurIPS
Year: 2023
Number of Reviews: 18
Original Ratings: 4, 7, 7, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an algorithm named ExpGen that selectively exhibits maximum entropy exploration behavior at test time by measuring epistemic uncertainty through an ensemble of policies. The authors propose formulating entropy as an intrinsic reward, using a trajectory of states to approximate state distribution entropy. Additionally, the paper evaluates the k-NN neighbor size and the use of L0 versus L2 norms in the context of MaxEnt exploration policies within the ProcGen benchmark. The authors suggest that a fixed neighbor size of k=1 across all environments balances performance and prevents over-tuning, although they acknowledge that environment-specific tuning could enhance results. Experimental results indicate that ExpGen achieves the highest scores in two of the five ProcGen environments tested, specifically Maze and Heist, and that both L0 and L2 norms yield similar performance, with a slight advantage for L0 in certain tests. The results also show that the ExpGen+IDAAC variant establishes a new state-of-the-art on ProcGen, outperforming previous benchmarks.

### Strengths and Weaknesses
Strengths:
- The paper introduces a novel framework that effectively combines switching strategies based on epistemic uncertainty with maximum entropy policies, addressing performance gaps between training and testing phases.
- The introduction and related work sections are well-written, providing a solid context for the proposed method.
- The empirical investigation is interesting and well-executed, demonstrating a thorough evaluation of different neighbor sizes and norms, which provides valuable insights into their impact on performance.
- The authors effectively address reviewer concerns with additional experiments and clarifications, enhancing the paper's rigor.

Weaknesses:
- Some logical parts are unclear, and the paper contains typos and mistakes.
- The experimental results present counterarguments against the motivation for using a general framework over those based on inductive biases, such as IDAAC, which is mentioned but not experimentally validated.
- There are memory and computational inefficiencies due to the need for training and inferring from an ensemble of policies.
- The empirical studies lack clarity on why and how ExpGen works, with insufficient ablation studies on the algorithm's components.
- The choice of a single k value may limit performance optimization for specific environments.
- Some reviewers expressed hesitance regarding the clarity and quality of figures and overall presentation in the final version.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their logic and address typographical errors. Additionally, conducting experiments that combine IDAAC with ExpGen could provide valuable insights into their complementary strengths. To enhance the empirical studies, we suggest including detailed ablation analyses of the algorithm's components. 

We also recommend clarifying the evaluation protocol for the main experiments and ensuring that all methods, including baselines, undergo proper hyperparameter tuning. Furthermore, addressing the computational burden of training ensembles and providing a clearer justification for the choice of the L0 norm over the L2 norm in the context of k-NN would strengthen the paper. We suggest that the authors include environment-specific tuning for the neighbor size k in the final version to potentially enhance performance across all tasks. Lastly, improving the clarity and presentation of tables and figures for better readability is essential.