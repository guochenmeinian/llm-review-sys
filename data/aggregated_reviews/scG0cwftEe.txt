ID: scG0cwftEe
Title: Unleashing the Full Potential of Product Quantization for Large-Scale Image Retrieval
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 5, 7, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a deep product quantization (PQ) method for approximate nearest neighbor (ANN) search, aimed at mitigating performance degradation when short codes are used on large-scale datasets with numerous categories. The authors propose a method that learns discriminative PQ subvectors using CosFace loss with pseudo-ground truth labels derived from mean vectors of all classes. Experiments on Glint360K and ImageNet datasets demonstrate that the proposed method achieves competitive or superior performance compared to existing ANN methods.

### Strengths and Weaknesses
Strengths:
1. The paper is well-organized and provides clear introductions to its concepts.
2. It effectively addresses the performance decline associated with short PQ codes through extensive experiments.
3. The proposed method is novel and practical, showing significant improvements in large-scale image retrieval.

Weaknesses:
1. Several ambiguities exist in the experimental details, raising concerns about the fairness of evaluations.
2. The novelty of the proposed method is questioned, as it resembles existing deep product quantization techniques.
3. The method's reliance on predefined PQ class labels and the complexity introduced by combining two branches may affect its performance and training time.

### Suggestions for Improvement
We recommend that the authors improve clarity in the experimental setup, particularly regarding the use of datasets and evaluation protocols, to address ambiguities noted in A1-A6. Additionally, we suggest conducting further evaluations to analyze performance gaps across varying class numbers and comparing the proposed method against straightforward combinations of feature extraction and supervised quantization. It would also be beneficial to provide visual retrieval samples of Top-K for clarity. Lastly, we encourage the authors to discuss the limitations of their method, particularly concerning dataset distribution shifts and the applicability to non-visual tasks.