ID: qkhpbRNSSE
Title: ProofNet: Autoformalizing and Formally Proving Undergraduate-Level Mathematics
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 4, 5, 5, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the ProofNet dataset, comprising 371 triplets of formal statements, natural language statements, and natural language proofs sourced from Putnam competitions and undergraduate mathematics textbooks, formalized in Lean 3. The dataset supports various tasks, including autoformalization and theorem proving, and the authors evaluate baseline models alongside their own model, ProofGPT, using metrics such as Typecheck rate and BLEU. The authors also introduce methods like prompt retrieval and distilled backtranslation to enhance performance.

### Strengths and Weaknesses
Strengths include the dataset's accessibility, the relevance of the problem space, and the potential utility of ProofGPT, which has been open-sourced. The paper is clearly written and presents a reasonable baseline analysis. However, weaknesses arise from the dataset's limited size, which may not significantly impact the autoformalization landscape, and the restricted domain of collected data, lacking diversity in proof styles and problem difficulty. Additionally, the qualitative analysis provided is deemed insufficiently informative.

### Suggestions for Improvement
We recommend that the authors improve the dataset's size to enhance its utility for theorem proving and autoformalization tasks. A more comprehensive discussion on the breakdown of problem difficulty and a clearer explanation of the Proof-Pile dataset's relationship to ProofNet are necessary. We suggest refining the metrics used for evaluation, as compile rate may yield misleading results, and consider alternative measures like comparing ASTs. Expanding the qualitative analysis and providing a visual breakdown of ProofNet by topic or skill would also be beneficial. Lastly, addressing licensing issues more thoroughly and providing code for model reproduction would strengthen the submission.