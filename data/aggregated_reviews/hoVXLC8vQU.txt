ID: hoVXLC8vQU
Title: Convergence of $\text{log}(1/\epsilon)$ for Gradient-Based Algorithms in Zero-Sum Games without the Condition Number: A Smoothed Analysis
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 6, 7, 6, 6, 6, -1, -1, -1, -1, -1
Original Confidences: 1, 1, 3, 3, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents smoothed analysis results for four gradient-based algorithms—OGDA, OMWU, EGDA, and IterSmooth—applied to two-player zero-sum games with a noise-injected payoff matrix. The authors demonstrate that the linear convergence rate \(O(\log(1/\epsilon))\) for OGDA, EGDA, and IterSmooth holds with high probability, relying on a specific error bound related to the noise. The work provides a theoretical justification for the performance of these algorithms in practice, showing that their smoothed complexity is polynomial in \(\log(1/e)\).

### Strengths and Weaknesses
Strengths:  
- The paper introduces novel techniques that analyze the reliability of existing gradient-based algorithms, focusing on geometric characteristics rather than condition numbers, which is significant for the field.  
- It provides meaningful insights into the performance of state-of-the-art algorithms in machine learning applications, particularly in zero-sum games.

Weaknesses:  
- The writing is often unclear, with theorems and technical results presented before being adequately defined, leading to confusion, particularly regarding the definition of matrix \(Q\) and the introduction of vectors \(b\), \(c\), and value \(d\).  
- The paper lacks sufficient comparison with existing literature on smoothed analysis, which could enhance its contribution. Additionally, the emphasis on convergence in terms of Euclidean distance over duality gap may detract from its novelty.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing by defining key terms and concepts, such as the matrix \(Q\), more explicitly before discussing them. Additionally, we suggest that the authors provide a more thorough comparison with existing literature on smoothed analysis to better contextualize their contributions. It would also be beneficial to emphasize Theorem 1.4 in the abstract and title, as it encapsulates the main message of the paper. Finally, including an example where the constant \(\kappa\) depends exponentially on \(m,n\) could enhance understanding.