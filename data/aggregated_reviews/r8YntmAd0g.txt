ID: r8YntmAd0g
Title: DOPPLER: Differentially Private Optimizers with Low-pass Filter for Privacy Noise Reduction
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 7, 6, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to augment DP-SGD by applying a low-pass filter to the noisy gradients, positing that true gradients are low-frequency signals while noise is high-frequency. The authors provide a theoretical convergence analysis indicating that the filter can enhance the signal-to-noise ratio, leading to improved convergence rates under optimal hyperparameter selection. Empirical results demonstrate that the filtered DP-SGD consistently outperforms its unfiltered counterpart across various datasets and models.

### Strengths and Weaknesses
Strengths:
- The investigation of DP-SGD from a frequency domain perspective is innovative and theoretically justified.
- The proposed low-pass filter effectively enhances performance without altering privacy guarantees, making it easy to implement across different DP-SGD variants.
- The paper is well-written, with clear communication of the main ideas and significant empirical results supporting the proposed method.

Weaknesses:
- Key signal processing concepts are introduced too briefly, hindering comprehension for readers unfamiliar with the field; an appendix with detailed explanations is recommended.
- The methodology for computing privacy bounds and the specifics of the subsampling method are not clearly articulated, leading to ambiguity in the experimental setup.
- The paper lacks detailed error analysis in experiments, and the assumptions regarding autocorrelation require further justification.

### Suggestions for Improvement
We recommend that the authors improve clarity by adding a section in the appendix that thoroughly explains the signal processing concepts used. Additionally, please clarify the methodology for computing privacy bounds and specify the subsampling method in the experiments to eliminate ambiguity. Including error bars in the experimental results would enhance the robustness of the findings, as would providing final accuracy metrics in a comparative table. We also suggest a more detailed investigation into the autocorrelation assumption, including empirical evidence and potential toy problems to validate the theoretical claims. Finally, consider exploring the tuning of filter coefficients in conjunction with learning rates to optimize performance further.