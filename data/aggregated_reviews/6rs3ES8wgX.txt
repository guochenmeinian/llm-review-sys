ID: 6rs3ES8wgX
Title: Predictive Relevance Uncertainty for Recommendation Systems
Conference: ACM
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an innovative approach to uncertainty estimation in Click-through Rate (CTR) models for recommendation systems, introducing Predictive Relevance Uncertainty (PRU) to capture unique predictive uncertainties not addressed by traditional models. The authors evaluate PRU's effectiveness across three tasks using various datasets, demonstrating its potential to enhance the robustness and reliability of recommendation systems.

### Strengths and Weaknesses
Strengths:
1. The focus on uncertainty estimation in recommendation systems is a significant and relevant research question.
2. The authors provide a thorough evaluation of state-of-the-art methods and analyze issues like overlap and class imbalance in recommendation datasets.
3. The proposed PRU approach effectively defines and quantifies uncertainty, showing promising results in improving CTR predictions.

Weaknesses:
1. The introduction lacks sufficient literature support for the role of uncertainty estimates in recommendation systems.
2. Visualization methods in Figure 2 are not clearly described, impacting clarity and reproducibility.
3. The use of simulated datasets raises questions about the applicability of findings to real-world scenarios.
4. The experimental section relies on a limited range of older backbone models, which may not comprehensively validate the PRU approach.
5. The paper is difficult to follow, with unclear explanations of figures and insufficient detail on data preprocessing and splitting.

### Suggestions for Improvement
We recommend that the authors improve the introduction by providing references to existing literature on uncertainty estimates in recommendation systems to contextualize their study. Additionally, the authors should elaborate on the methods used for visualizations in Figure 2 to enhance clarity. Justifying the choice of simulated datasets or incorporating real data would strengthen the applicability of their findings. Expanding the range of tested backbone models beyond DeepFM and Wide&Deep could provide a more comprehensive validation of PRU. Furthermore, the authors should clarify the preprocessing and data splitting methods used in their experiments, as well as optimize hyperparameters to ensure the reliability of their results. Lastly, addressing the clarity of figures and the rationale behind dataset choices would improve the overall readability and rigor of the paper.