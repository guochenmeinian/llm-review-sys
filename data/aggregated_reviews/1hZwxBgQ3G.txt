ID: 1hZwxBgQ3G
Title: Find What You Want: Learning Demand-conditioned Object Attribute Space for Demand-driven Navigation
Conference: NeurIPS
Year: 2023
Number of Reviews: 21
Original Ratings: 7, 5, 5, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Demand-driven Navigation (DDN), a novel task where an agent navigates to find an object that satisfies a user's demand, leveraging textual instructions instead of predefined object categories. The authors propose a method that extracts textual attribute features from a large language model and aligns them with visual features using Contrastive Language-Image Pre-training (CLIP). The DDN task is characterized by a broader range of object categories (109) compared to previous methods (22 for VTN and 6-21 for ZSON), which increases task complexity due to the many-to-many object-instruction mapping. Experiments conducted on the ProcThor dataset demonstrate that the proposed method significantly improves navigation performance compared to baseline methods. The authors utilize GPT-3 and CLIP to generate language-grounding mappings for learning demand-conditioned object attributes.

### Strengths and Weaknesses
Strengths:
1. The motivation for DDN is compelling, addressing real-world navigation challenges by allowing agents to fulfill human demands rather than merely locating specific objects.
2. The proposed attribute module effectively extracts object attributes, enhancing the agent's understanding of common sense knowledge.
3. The integration of GPT-3 and CLIP demonstrates a novel approach to aligning visual and textual information.
4. The experimental design is robust, with multiple trials showing statistical significance and clear performance improvements over baselines.
5. Responses to reviewer concerns have improved the overall perception of the paper.

Weaknesses:
1. The requirement that agents only search for objects present in the scene is questionable and may impact the definition of "navigation failure."
2. The method currently addresses only one demand at a time, limiting its applicability to scenarios with multiple simultaneous demands.
3. There remains an outstanding concern regarding potential statistical biases in the data, particularly about whether specific objects are always present to satisfy demands.
4. The motivation for the DDN task could be further clarified, especially regarding user expectations for specific object retrieval.
5. The evaluation could benefit from additional benchmark datasets beyond AI2Thor, such as the Habitat Challenge on ObjectNav.
6. The introduction is overly lengthy, making it tedious to read, and could be trimmed for clarity.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the task definition by addressing how often demanded objects may not be present in the scene and whether the task can accommodate multiple demands simultaneously. Additionally, we suggest including more benchmark datasets to strengthen the evaluation and conducting ablation studies to clarify the contributions of various components in the proposed method. We also recommend improving the clarity of the motivation behind the DDN task by providing more concrete examples that illustrate user expectations, such as prioritizing specific objects when they are present in a scene. Addressing the potential statistical biases in the data more thoroughly would strengthen the paper, and incorporating a discussion on how future work could consider human preferences for particular objects in the limitations section would enhance the paper's depth. Finally, we advise trimming the introduction to enhance readability and focus on essential motivations.