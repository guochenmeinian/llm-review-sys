ID: 3YkeHuT1o6
Title: A Swiss Army Knife for Heterogeneous Federated Learning: Flexible Coupling via Trace Norm
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 7, 6, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a federated multi-task learning framework called FedSAK, which addresses the challenges of data, model, and task heterogeneity in federated learning. The authors propose an innovative approach that integrates tensor trace paradigms to facilitate knowledge transfer among client models in heterogeneous environments. The framework is supported by theoretical guarantees and empirical evidence demonstrating its effectiveness.

### Strengths and Weaknesses
Strengths:  
1. The paper is easy to understand, making it accessible to readers with varying levels of expertise.  
2. The authors have made significant strides in addressing various forms of heterogeneity, which is a major highlight of the research.  
3. The provision of convergence guarantees and generalization bounds enhances the reliability and practical applicability of the FedSAK framework.  
4. The framework exhibits strong adaptability and generalization capabilities, as evidenced by superior performance on real-world datasets.  
5. The authors provide reproducible code, facilitating further research.

Weaknesses:  
1. The assumptions of Lipschitz continuous gradient and bounded variance are stringent, lacking sufficient justification or empirical verification.  
2. Some technical details require clarification, particularly regarding which model layers need to be shared in heterogeneous setups.  
3. The experimental results indicate only marginal gains compared to FedProto, and the reasons for FedMTL's faster convergence rate remain unclear.  
4. The computational complexity of the tensor trace norm raises concerns about scalability to larger models.  
5. The paper does not adequately emphasize the contributions of the trace norm or provide relevant ablation experiments to confirm the algorithm's effectiveness.

### Suggestions for Improvement
We recommend that the authors improve the justification for the stringent assumptions regarding Lipschitz continuity and variance by providing empirical evidence. Additionally, clarifying the specific model layers that should be shared in heterogeneous scenarios would enhance understanding. The authors should also address the marginal gains observed in experimental results and explain the faster convergence rate of FedMTL. To address scalability concerns, we suggest exploring methods to reduce computational complexity associated with tensor trace norm calculations. Finally, we encourage the authors to conduct ablation studies to better highlight the contributions of the trace norm and clarify the relationship between task and model heterogeneity.