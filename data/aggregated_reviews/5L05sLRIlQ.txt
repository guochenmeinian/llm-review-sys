ID: 5L05sLRIlQ
Title: VastTrack: Vast Category Visual Object Tracking
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 7, 7, 7, -1, -1, -1, -1
Original Confidences: 5, 4, 5, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents VastTrack, a new large benchmark for visual tracking that includes 2,115 object categories and 50,610 videos, totaling 4.2 million frames. It aims to enhance the development of visual tracking algorithms by providing extensive evaluations of 25 representative trackers. The dataset features rich annotations, including bounding boxes and over 50,000 linguistic descriptions, facilitating both vision-only and vision-language tracking research.

### Strengths and Weaknesses
Strengths:
- VastTrack significantly expands the number of object categories compared to existing benchmarks like GOT-10k and LaSOT.
- The dataset is the largest and most diverse in terms of video sequences and targets.
- It includes both standard bounding box annotations and rich linguistic specifications.
- The authors ensure precise annotations through a multi-round manual labeling process.

Weaknesses:
- The focus on short-term tracking may limit its applicability, as long-term tracking is more challenging and practical.
- The average video length of 83 frames at 6 fps is notably lower than typical video sequences, potentially impacting analysis.
- The performance improvement from retraining on VastTrack is not substantial, suggesting that existing trackers can handle unseen classes effectively.

### Suggestions for Improvement
We recommend that the authors improve the dataset by conducting additional experiments to demonstrate VastTrack's advantages, such as tracking performance on other datasets and addressing the challenges of the testing set. It would be beneficial to evaluate more recent language-based trackers in the retraining experiments. Additionally, we suggest clarifying the category names in the supplementary material and ensuring that the TNL2K dataset is included in comparisons. Lastly, the authors should provide more details on the data collection and annotation processes, as well as a maintenance plan for the dataset.