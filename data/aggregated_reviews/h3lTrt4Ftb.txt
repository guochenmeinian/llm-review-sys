ID: h3lTrt4Ftb
Title: Large language models implicitly learn to straighten neural sentence trajectories to construct a predictive representation of natural language.
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 6, 7, 5, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates the hypothesis that autoregressive language models, particularly the GPT family, learn to "straighten" the internal trajectory of word sequences to enhance next-word prediction. The authors define curvature based on the angle between consecutive word embeddings and demonstrate that trained models exhibit decreased curvature across layers, with larger models showing more pronounced straightening. The study also finds correlations between curvature and sentence surprisal.

### Strengths and Weaknesses
Strengths:  
- The paper introduces a clear and intuitive curvature metric to support the trajectory straightening hypothesis, backed by various well-executed experiments.  
- It raises significant questions regarding model interpretability and performance, appealing to the NeurIPS audience.  

Weaknesses:  
- The manuscript lacks clarity on the importance of the straightening hypothesis and its implications for broader machine learning or neuroscience communities.  
- Several critical points remain unclear, such as the dataset's language, the models' training status, and the definition of "untrained model."  
- The paper does not adequately address potential confounding factors or provide sufficient background on related work in geometric interpretability.

### Suggestions for Improvement
We recommend that the authors improve clarity regarding the dataset, including the language used and the rationale for selecting short sentences. It is essential to specify whether models were retrained or fine-tuned and to clarify the meaning of "untrained model." We suggest defining surprisal and relating it to perplexity/NLL, as well as discussing the decoding strategy's impact on measurements. Additionally, the authors should consider providing more intuition for the significance of straightening and its connection to broader interpretability goals. Finally, addressing the clarity of figures and captions, as well as ensuring that the writing is concise and free of typos, will enhance the manuscript's overall quality.