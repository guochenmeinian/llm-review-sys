ID: 7v88Fh6iSM
Title: Learning Diffusion Priors from Observations by Expectation Maximization
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 7, 5, 4, 5, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 5, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for learning diffusion models from incomplete and noisy observations, modeled as \( p(y) = \int p(y|x) q(x) dx \). The authors introduce a parametric version, \( p^\theta(y) = \int p(y|x) q^\theta(x) dx \), and aim to learn it by minimizing the KL divergence \( KL(p||p^\theta) \) using the Expectation-Maximization (EM) algorithm. The algorithm iteratively learns a diffusion model, but the E-step requires sampling from the posterior diffusion \( q^\theta(x|y) \), which is intractable. The authors propose an approximation method involving moment projection and conjugate gradient methods for matrix inversion. Additionally, the paper presents preliminary quantitative results for linear inverse problems, introducing two additional baselines (TMPD and DiffPIR) alongside existing methods. The authors evaluate performance using three standard image quality metrics (LPIPS, PSNR, and SSIM), averaging results over 100 FFHQ observations, and find that MMPS consistently outperforms all baselines. The review notes that PSNR and SSIM tend to favor smooth samples, while LPIPS is more aligned with perceptually detailed samples.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and presents an original methodology that effectively utilizes the EM algorithm for iterative learning of diffusion models.
- MMPS demonstrates superior performance across all evaluated metrics compared to the baselines.
- The inclusion of multiple baselines (TMPD and DiffPIR) enhances the robustness of the comparison.
- The experimental setting is diverse, including a toy example, and demonstrates the advantages of the proposed method.
- The use of three standard metrics provides a comprehensive evaluation of image quality.

Weaknesses:
- The experimental comparisons for the posterior sampling algorithm are limited, lacking comparisons with methods like DPS, DDRM, or CoPaint, raising concerns about the proposed sampler's superiority.
- There are potential identifiability issues in the framework, where the learned model may not accurately reconstruct clean data.
- The paper lacks clarity in presenting the algorithm, with insufficient detail on the training method and the role of the prior on the matrix \( A \).
- PSNR and SSIM may not adequately represent perceptual quality, potentially skewing the evaluation of methods favoring smoothness.
- The reliance on a single dataset (FFHQ) may limit the generalizability of the findings.

### Suggestions for Improvement
We recommend that the authors improve the experimental comparisons by including a broader range of methods such as DPS, DDRM, and CoPaint to substantiate claims of superiority. Additionally, the authors should address the identifiability concerns by clarifying how the model avoids learning incomplete data representations. We suggest enhancing the clarity of the algorithm presentation by providing a step-by-step demonstration in the main body and elaborating on the prior's role in the matrix \( A \). Furthermore, we recommend improving the evaluation by incorporating additional datasets to enhance the generalizability of the results. Lastly, consider addressing the limitations of PSNR and SSIM by providing a more detailed analysis of perceptual quality, possibly including user studies or alternative metrics that better capture perceptual differences in image quality.