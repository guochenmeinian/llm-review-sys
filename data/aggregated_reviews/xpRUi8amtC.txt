ID: xpRUi8amtC
Title: Scene Graph Generation with Role-Playing Large Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 6, 6, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 5, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents SDSGG, a novel open vocabulary scene graph generation (OVSGG) algorithm that utilizes the reasoning capabilities of a large language model (LLM) to enhance the determination of object relations in scenes. The authors propose prompting the LLM with multiple persona prompts to expand simple relational predicates into detailed visual descriptions, which augment the classification process. Additionally, a mutual visual adapter is introduced to better capture interactions between subjects and objects. Experimental results demonstrate the effectiveness of these designs.

### Strengths and Weaknesses
Strengths:  
1. The incorporation of an LLM to augment predicate labels for scene graph generation is a novel approach, providing valuable insights for future research.  
2. Experimental results (Tables 1-2) show significant improvements over previous methods.  
3. Extensive ablation studies on various design elements enhance the credibility of the findings.  

Weaknesses:  
1. Key details regarding the construction of LLM prompts are missing, particularly how "{scene content to be discussed}" is generated. The examples provided lack clarity on granularity and scalability.  
2. Additional discussions and experiments are needed to justify design choices, such as the use of CLIP for possible coexistence descriptions and the implications of removing this component from the inference pipeline.  
3. The computational complexity of the proposed framework, which involves multiple stages, raises concerns about its practicality for real-time applications.  
4. The description in Sec 3.1 is confusing due to inconsistent terminology and naming conventions, which could hinder reader comprehension.  

### Suggestions for Improvement
We recommend that the authors improve the clarity of how prompts are constructed, including the generation process and the scalability of these prompts. Additionally, we suggest providing further discussions and experiments to justify design choices, particularly regarding the use of CLIP and the impact of removing "possible coexistence" descriptions. To address computational complexity, consider optimizing the multi-step process for real-time applications. Lastly, we advise rewriting Sec 3.1 for better clarity and consistency in terminology.