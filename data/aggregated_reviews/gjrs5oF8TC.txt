ID: gjrs5oF8TC
Title: INVITE: a Testbed of Automatically Generated Invalid Questions to Evaluate Large Language Models for Hallucinations
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents INVITE, a framework for automatically generating invalid questions to evaluate large language models (LLMs) for hallucinations. The authors propose a method to create these questions by distorting valid facts, using the 100 most frequent DBpedia predicates and specific templates. The study evaluates several state-of-the-art LLMs against a generated test set, revealing a high rate of hallucination (â‰¥72.9%). The paper also highlights the lack of correlation between automatic and human evaluations.

### Strengths and Weaknesses
Strengths:  
1. The research addresses a significant issue regarding LLMs' susceptibility to hallucinations, emphasizing the need for improved reliability.  
2. A diverse range of LLMs is tested, strengthening the claims made.  
3. The clarity and accessibility of the paper enhance its appeal to a broad audience.  
4. The methodology is reproducible, adding credibility to the findings.  

Weaknesses:  
1. The dataset release status is unclear, which could hinder quick experimentation.  
2. There is a poor correlation between automatic and human evaluations, raising concerns about the dataset's utility.  
3. The question generation approach is simplistic, relying on fixed templates and limited diversity, which may introduce bias.  
4. The evaluation does not include larger LLMs like GPT-3.5 or GPT-4, which could provide more insights.  
5. The use of generic automatic evaluation metrics does not specifically address hallucination evaluation.

### Suggestions for Improvement
We recommend that the authors clarify the status of the dataset release to facilitate quicker experimentation. Additionally, we suggest exploring better automatic metrics, such as NLI-based metrics, to improve correlation with human evaluations. To enhance the diversity of the generated test set, we encourage the authors to utilize multiple templates for each question category. Finally, we recommend conducting experiments on larger LLMs, such as GPT-3.5 or GPT-4, to gain deeper insights into the hallucination problem.