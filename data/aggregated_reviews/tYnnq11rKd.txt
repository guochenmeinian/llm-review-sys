ID: tYnnq11rKd
Title: Dealing with Noisy Data in Federated Learning: An Incentive Mechanism with Flexible Pricing
Conference: ACM
Year: 2024
Number of Reviews: 3
Original Ratings: -1, -1, -1
Original Confidences: -1, -1, -1

Aggregated Review:
### Key Points
This paper presents FPIN, a framework designed to address noisy data in federated learning through noise detection, client selection, and dynamic pricing. The authors propose an innovative pricing mechanism to incentivize client participation and reduce noise. Additionally, the manuscript analyzes the convergence behavior in federated learning under noisy gradients, focusing on sublinear convergence rates. The theoretical foundation is robust, relying on sound assumptions and providing rigorous bounds on model parameters. The work contributes significantly to the literature by addressing gradient noise, client heterogeneity, and time-varying learning rates.

### Strengths and Weaknesses
Strengths:
- The experimental results and theoretical analysis strongly support the framework's effectiveness.
- The analysis of convergence is thorough and mathematically sound, particularly regarding the impact of non-IID data.
- The manuscript is well-structured, with clear derivations and a realistic approach to learning rates.

Weaknesses:
- The datasets used for evaluation are relatively small and lack diversity, limiting generalizability.
- The computational costs of the proposed method are not clearly analyzed.
- Some transitions in the proof require further clarification, and certain terms are introduced without sufficient explanation.
- The practical implications of the theoretical results are not adequately discussed, and the notation could be streamlined for better readability.
- The method's reliance on model discrepancy and cross-entropy loss may not accurately reflect noise levels in heterogeneous settings.

### Suggestions for Improvement
We recommend that the authors improve the diversity of datasets used for testing, potentially including text data, to demonstrate generalizability across different domains. Additionally, a clearer analysis of the computational overhead in real-world scenarios, particularly for devices with limited resources, would enhance the paper. We suggest providing more practical insights or simulations to illustrate how the convergence bounds behave in real-world federated learning systems, especially under varying client participation and data heterogeneity. Furthermore, clarifying the role of constants in the proofs and discussing alternative learning rate schedules would strengthen the analysis. Lastly, guidance on how clients can effectively clean their data would add value to the proposed incentive mechanism.