ID: u6Xv3FuF8N
Title: Flocks of Stochastic Parrots: Differentially Private Prompt Learning for Large Language Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 6, 7, 7, 5, 5, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, 5, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on privacy preservation in prompt learning for large language models (LLMs), focusing on the vulnerability of prompting data to membership inference attacks (MIAs). The authors propose two methods: PromptDPSGD, which adapts the DPSGD algorithm for soft prompt learning, and PromptPATE, which utilizes teacher-student knowledge transfer for discrete prompt learning. The evaluation demonstrates that both methods effectively protect prompt privacy while maintaining reasonable model performance under specific privacy budgets.

### Strengths and Weaknesses
Strengths:
- The paper is well-motivated, addressing the underexplored privacy concerns in prompted LLMs and validating these concerns through a membership inference analysis.
- It is organized and clearly presented, with a comprehensive literature review and systematic experiments on real-world LLMs, showcasing the applicability of the proposed methods.
- The consideration of both soft and discrete prompt learning settings is pragmatic, given the limitations of accessing gradients in popular LLM APIs.

Weaknesses:
- The membership inference attack relies on model logits, which may not be available in many commercial models, limiting the generalizability of the findings.
- PromptPATE is initially presented without clarifying its specific applicability to few-shot classification tasks, raising questions about its effectiveness in other contexts, such as free-form text generation.
- The novelty of PromptDPSGD and PromptPATE is questioned, as they appear to be straightforward adaptations of existing methods without significant innovation.
- The paper does not address the potential for attackers to extract instructional information from prompts, which is increasingly relevant in the context of instruction-tuned models.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by explicitly stating early on that it focuses on the restricted classification setting, which would help readers understand the specific problem being addressed. Additionally, we suggest that the authors discuss the novelty of PromptDPSGD and PromptPATE in relation to existing work to better highlight their contributions. It would also be beneficial to explore the generalizability of these methods to free-form text generation tasks and address potential privacy risks associated with instructional information extraction.