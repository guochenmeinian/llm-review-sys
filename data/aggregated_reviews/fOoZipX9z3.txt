ID: fOoZipX9z3
Title: Grounding Visual Illusions in Language: Do Vision-Language Models Perceive Illusions Like Humans?
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into whether Vision-and-Language models (VLMs) are susceptible to visual illusions, finding that they are to a limited extent. The authors construct a new visual illusion dataset, GVIL, encompassing five types of visual illusions, and evaluate four state-of-the-art VLMs through various probing tasks. The study aims to deepen the understanding of VLM behavior in visual question-answering scenarios.

### Strengths and Weaknesses
Strengths:
- The introduction of a visual illusion dataset for VLMs is a significant contribution.
- The research question is compelling, and the experiments are well-executed.
- The paper is well-written, clear, and presents comprehensive analyses of VLM behavior.

Weaknesses:
- The dataset size is limited, raising concerns about the reliability of the findings.
- A significant portion of VLM outputs is marked as N/A, indicating limitations in their foundational capabilities.
- The absence of statistical tests undermines the robustness of the conclusions, particularly given the high N/A rate.

### Suggestions for Improvement
We recommend that the authors expand the dataset size to enhance the reliability of their evaluation findings. Additionally, we suggest conducting statistical tests to validate the conclusions drawn from the results, particularly in light of the substantial N/A responses. Furthermore, we encourage the authors to analyze the underlying reasons for the observed behaviors of the VLMs to provide deeper insights into their performance.