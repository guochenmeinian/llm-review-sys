ID: 3UeAN1zicJ
Title: Scenario-independent Uncertainty Estimation for LLM-based Question Answering via Factor Analysis
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method to estimate uncertainty from LLMs that is agnostic to the specific uncertainty estimation method, utilizing a factor analysis model to analyze contributions from common semantics and scenario-specific noise. The authors propose a framework that enhances unsupervised uncertainty estimation by isolating semantic information and removing scenario-related noise, demonstrating its effectiveness through evaluations on standard QA benchmark datasets.

### Strengths and Weaknesses
Strengths:  
- The methodology is well-developed and addresses a timely problem in NLP, specifically hallucination detection in LLMs.  
- The framework allows for flexibility by supporting various LLMs and uncertainty estimation methods.  
- The paper is well-written, with clear representation and thorough experimental descriptions.

Weaknesses:  
- The paper lacks a discussion on the basic assumption that uncertainty remains unchanged across varying scenarios, which diminishes its practical value.  
- The reliance on AUROC as the sole evaluation metric is concerning; additional metrics such as Accuracy, Precision, Recall, or F-score should be included.  
- The evaluation relies on a DeBERTa-based NLI model for assessing LLM-generated responses, which raises questions about the choice of evaluator.  
- The heavy emphasis on scenario independence may not be suitable, as the results indicate minimal impact from scenario-centric rephrasing.

### Suggestions for Improvement
We recommend that the authors improve the discussion surrounding the assumption of unchanged uncertainty across scenarios to enhance the practical relevance of their work. Additionally, please implement comparisons to clarify why this method outperforms others, particularly emphasizing the suitability of factor analysis in this context. We suggest including human evaluation or AI annotation to verify the semantic retention of synthesized paraphrases. Furthermore, we encourage the authors to report additional evaluation metrics beyond AUROC, such as classification accuracy and true positive rates for hallucination detection, to provide a more comprehensive performance assessment. Lastly, consider using a powerful LLM as the evaluator for alignment assessments instead of a DeBERTa-based model.