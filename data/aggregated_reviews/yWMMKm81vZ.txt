ID: yWMMKm81vZ
Title: SeafloorAI: A Large-scale Vision-Language Dataset for Seafloor Geological Survey
Conference: NeurIPS
Year: 2024
Number of Reviews: 19
Original Ratings: 7, 8, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents two new multimodal multitask datasets, SeafloorAI (vision) and SeafloorGenAI (vision-language), aimed at seafloor mapping and understanding. The datasets comprise 700K sonar images, 827K segmentation masks, 696K general language descriptions, and 7M question-answer pairs, derived from publicly available USGS and NOAA data. The authors develop a standardization framework to harmonize diverse data sources and emphasize collaboration with marine scientists to ensure the datasets' relevance for oceanographic applications. The datasets are significant for their size, diversity, and potential to support various tasks in marine science, addressing gaps in existing datasets and enhancing marine scientists' interaction with data for analysis and discovery.

### Strengths and Weaknesses
Strengths:
- The datasets are the largest public collection of sonar images for marine science, ensuring diversity across multiple geographical regions.
- They are constructed with care, featuring multiple modalities and potential applications in oceanography.
- The dataset represents a substantial effort, harmonizing data from 62 surveys across 9 regions, and includes collaboration with domain experts for annotation.
- The paper is well-written, with clear explanations and a logical flow, effectively addressing the importance of the datasets.
- The authors have effectively addressed reviewer feedback and made constructive updates, such as including modeling codes and improving accessibility through a Zenodo link.

Weaknesses:
- The geographic coverage is limited to nearshore regions of the US, omitting significant areas like the Gulf of Mexico and other oceans.
- The validation process for the 7M question-answer pairs generated by GPT-4 is unclear, raising concerns about their reliability.
- The language annotations rely heavily on GPT-4-generated descriptions, with only 50 scenes directly annotated by experts, raising concerns about their utility and accuracy.
- Access to the dataset during the review process was hindered by permission issues with the Zenodo link.
- The paper primarily focuses on data processing, lacking a thorough discussion of benchmark modeling.
- Some reviewers noted a delay in responses, which could impact the review process.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the validation of the question-answer pairs generated for the SeafloorGenAI dataset, explicitly confirming the extent of human validation. Additionally, we suggest expanding the geographic coverage of the dataset to include more diverse marine environments, such as the Gulf of Mexico and other oceanic regions, to enhance its applicability. Furthermore, we encourage the authors to ensure that the dataset is accessible for review and examination, addressing any permission issues with the Zenodo link. We also recommend that the authors improve the paper's structure by transferring some details of data preparation to the Supplementary Material, allowing for a more comprehensive discussion of modeling approaches and preliminary results in the main text. The abstract should clearly differentiate between SeafloorAI and SeafloorGenAI, and the authors should explicitly discuss the geographic diversity of the dataset, addressing its representativeness for global regions. Clarifying the terminology between "geographic layers" and "geological features" is also necessary. Additionally, the authors should provide clarity on how varying resolutions of rasterized data are integrated and discuss potential biases in model application due to the dataset's geographic limitations. Finally, we suggest including a more detailed evaluation of the language annotations' accuracy and coherence based on expert feedback, and improving the timeliness of their responses to reviewer feedback to facilitate a smoother review process.