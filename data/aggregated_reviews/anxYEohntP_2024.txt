ID: anxYEohntP
Title: Exploring Prosocial Irrationality for LLM Agents: A Social Cognition View
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 5, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the CogMir framework, which investigates the potential for Large Language Model (LLM) agents to exhibit prosocial behavior through irrational decision-making, paralleling human cognitive biases. The framework leverages the hallucination properties of LLMs to simulate and assess social intelligence across various cognitive biases. Experimental results indicate a high consistency in irrational and prosocial decision-making between LLM agents and humans under uncertain conditions.

### Strengths and Weaknesses
Strengths:  
1. Innovative Framework: The CogMir framework offers a novel approach to studying social intelligence in LLMs by reflecting human cognitive biases.  
2. Comprehensive Evaluation: The paper evaluates multiple cognitive biases, such as Herd Effect and Confirmation Bias, providing valuable insights.  
3. Interdisciplinary Approach: The integration of social sciences and evolutionary psychology enriches the study's context.  

Weaknesses:  
1. The rationale for using hallucinations to mirror cognitive biases requires further explanation.  
2. There is a lack of clarity on how hallucinations can be manipulated.  
3. The choice to use entirely new datasets raises questions about the inadequacy of existing datasets.  
4. The conclusion lacks engagement and interest.  
5. The treatment of LLMs' wrong beliefs as cognitive biases due to external influences is not substantiated by experiments.  

### Suggestions for Improvement
We recommend that the authors improve the explanation of why hallucinations are utilized to mirror human cognitive biases and clarify how they can be manipulated. Additionally, the authors should justify the use of new datasets and consider incorporating existing ones. We suggest enhancing the conclusion to make it more compelling. Furthermore, the authors should provide experiments that demonstrate how external influences affect LLMs' beliefs, and consider designing scenarios that better reflect daily communication for evaluating the rumor chain effect. Lastly, clearer organization of module names and consistency in terminology throughout the paper would enhance readability.