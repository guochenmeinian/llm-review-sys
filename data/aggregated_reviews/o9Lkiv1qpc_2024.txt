ID: o9Lkiv1qpc
Title: Identifying and Solving Conditional Image Leakage in Image-to-Video Diffusion Model
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 5, 6, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into the problem of "conditional image leakage" in image-to-video (I2V) generation, where existing models overly depend on the conditional image, leading to static outputs. The authors propose two strategies: an inference-time strategy that initiates the reverse diffusion process earlier and a training-time strategy that employs a time-dependent noise distribution to reduce reliance on the conditional image at larger timesteps. The results indicate improvements in video generation quality.

### Strengths and Weaknesses
Strengths:
1. The identification of conditional image leakage is a significant contribution to the field.
2. The proposed methods are well-motivated and show clear empirical improvements in video generation metrics.
3. The paper is well-organized, facilitating reader comprehension.

Weaknesses:
1. The claim regarding the trade-off between conditional image reliance and motion diversity lacks depth; the proposed techniques may merely fine-tune motion diversity rather than fundamentally address the issue.
2. The explanation of conditional image leakage is not fully convincing, as some existing models still produce diverse motion.
3. The experiments lack clarity and do not include necessary ablation studies, particularly regarding the training strategy and the evaluation of user studies.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the experiments by including detailed ablation studies, especially for the 'M' in Proposition 1 and the training strategy variables. Additionally, we suggest providing a more thorough discussion of existing works related to noise initialization and motion control to contextualize their contributions better. Clarifying the evaluation metrics used in user studies and addressing the realism of generated videos would also enhance the paper's robustness. Lastly, we encourage the authors to elaborate on the selection of hyperparameters for the time-dependent noise distribution to provide clearer insights into their methodology.