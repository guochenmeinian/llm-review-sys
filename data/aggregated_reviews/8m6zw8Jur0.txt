ID: 8m6zw8Jur0
Title: Image2Struct: Benchmarking Structure Extraction for Vision-Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 7, 7, 6, -1, -1, -1
Original Confidences: 3, 4, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Image2Struct benchmark, an evaluation protocol for models translating images into structured information, specifically focusing on generating compilable code from screenshots of webpages, music sheets, and LaTeX documents. The authors propose a round-trip evaluation setup that continuously scrapes fresh data, mitigating data leakage issues. The benchmark evaluates recent VLMs, revealing significant performance gaps across various tasks.

### Strengths and Weaknesses
Strengths:
- The paper demonstrates a deep understanding of the evaluation landscape for VLMs, addressing issues like data leakage and distribution shifts.
- The engineering of the pipeline, including on-the-fly compilation and screenshotting, is impressive.
- The benchmark's transparency and potential for continuous updates enhance its relevance and usability for the research community.

Weaknesses:
- Concerns exist regarding the correctness of the evaluation strategy, particularly the reliance on image similarity metrics to reflect textual differences.
- The paper lacks a comprehensive literature survey, missing important related works that could contextualize its contributions.
- Clarity issues arise around specific metrics, such as the EMD and EMS, which require further explanation and justification.

### Suggestions for Improvement
We recommend that the authors improve the clarity and justification of the image similarity metrics used, particularly addressing concerns about their effectiveness in reflecting textual differences. Additionally, a more thorough literature survey should be included to contextualize the benchmark within existing research. We suggest incorporating human correlation studies to validate the metrics and consider hand-annotating model outputs to provide clearer performance evaluations. Lastly, clarifying the definitions and methodologies for metrics like Block-EMD and EMS will enhance the paper's overall rigor.