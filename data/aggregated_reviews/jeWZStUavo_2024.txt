ID: jeWZStUavo
Title: Reinforcement Learning Policy as Macro Regulator Rather than Macro Placer
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 5, 7, 7, 5, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 4, 5, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents MaskRegulate, a method that employs reinforcement learning (RL) for refining macro placements in chip design, rather than starting from scratch. The authors introduce a regularity metric to enhance reward generation and validate their approach through experiments on the ICCAD 2015 benchmark, demonstrating significant improvements in power, performance, and area (PPA) metrics compared to existing methods.

### Strengths and Weaknesses
Strengths:
- The paper effectively addresses the challenge of RL application in chip placement by reformulating the problem to focus on refinement, allowing for better utilization of state information and reward signals.
- The introduction of regularity as a metric is a notable contribution, enhancing the relevance of the results to industry standards.
- Comprehensive experiments using a commercial EDA tool validate the proposed method's effectiveness, with solid performance improvements over competitive baselines.

Weaknesses:
- The overall presentation requires clarity, particularly in figure labels and explanations, with specific issues noted in Figure 3(a).
- Several technical aspects, such as the action space of the new MDP and the calculation of the WireMask feature map, are inadequately described.
- The paper lacks a discussion on how the proposed regularity differs from similar concepts in existing literature and does not sufficiently justify the necessity of using RL over other methods.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper's presentation, particularly by enhancing figure labels and explanations to prevent misinterpretation. Specifically, Figure 3(a) should be revised for better clarity. Additionally, we suggest providing a more detailed description of the action space in the MDP, including the termination function and the calculation of the WireMask feature map. To strengthen the paper, consider discussing how the proposed regularity metric differs from existing works and elaborating on the advantages of using RL in this context. Finally, including training convergence graphs for both ChipFormer and MaskRegulate would enhance the quality of the work.