ID: 7Ye12RLZ4P
Title: Asynchronous Perception Machine for Efficient  Test Time Training
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 6, 7, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel test-time training method called the Asynchronous Perception Machine (APM), which utilizes knowledge distillation from pretrained networks like CLIP. The main contributions include robust accuracy in classifying corrupted images and computational efficiency, requiring fewer FLOPs than existing models. APM processes image patches asymmetrically, learning semantically-aware features and demonstrating competitive performance on out-of-distribution image classification tasks. The model also utilizes a trigger column $T$ to generate location-aware columns $T_{ij}$ for sequential querying in a multi-layer perceptron (MLP), predicting location-specific features $f_{ij}=MLP(T_{ij})$ through a forward pass with positional encodings $p_{ij}$. The authors have committed to refining the paper's writing for improved reader engagement.

### Strengths and Weaknesses
Strengths:
- The method is innovative, being the first practical approach to exploit object part hierarchies as proposed in the GLOM paper.
- The paper effectively recovers dense pixel-level features using only a global CLS token for supervision, which has broader implications for representation learning.
- Comprehensive experiments are conducted, comparing APM against various baselines and demonstrating strong performance across multiple benchmarks.
- The authors have addressed most technical concerns raised by reviewers, enhancing clarity regarding the folding/unfolding and distillation processes.
- The paper shows promise in its innovative approach to location-specific feature decoding, drawing parallels with existing models like neural fields.

Weaknesses:
- The paper lacks sufficient references to related works, citing fewer than five relevant studies despite the existence of over 50 pertinent papers on test-time adaptation.
- There is inadequate comparison to state-of-the-art methods, with outdated references to TTT-MAE and insufficient acknowledgment of more recent advancements.
- The proposed method is not explained in sufficient detail, particularly regarding the Vision Encoder and the folding/unfolding processes.
- Misleading information is present in the tables, and the ablation study lacks relevance, focusing only on clean datasets rather than corrupted images.
- The writing is unclear and disorganized, leading to confusion about the method's details and implications.
- There remains a lack of clarity in certain technical details and phrasing of claims, which could hinder reader understanding.

### Suggestions for Improvement
We recommend that the authors improve the related works section by citing and discussing key papers in test-time adaptation to provide context for their contributions. Additionally, the authors should enhance the clarity and organization of the manuscript, ensuring that all technical details, such as the folding/unfolding processes and the role of the Vision Encoder, are thoroughly explained. We also suggest correcting misleading information in the tables and expanding the ablation study to include relevant datasets that reflect the method's intended application. Furthermore, refining the phrasing of claims regarding inspirations and analogies will clarify the authors' intentions. Finally, the authors should clarify any unsubstantiated claims and ensure that all analogies used are scientifically grounded and relevant to the proposed method.