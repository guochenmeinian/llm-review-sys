ID: jWL2GhQw5D
Title: More than Votes? Voting and Language based Partisanship in the US Supreme Court
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis of partisanship in Supreme Court justices' oral arguments, proposing a model that predicts party affiliation based on their spoken language. The authors aim to address two main research questions: whether a justice's speech indicates their political affiliation and how well these oral arguments correlate with other measures of partisanship. The study utilizes a BERT-based classification model to derive insights into partisan language, correlating language-based ideology scores with established voting patterns.

### Strengths and Weaknesses
Strengths:
- The paper provides a novel approach by using speech-based measures of partisanship rather than relying solely on voting records.
- It features well-documented data preparation and model training procedures, ensuring methodological clarity.
- The temporal analysis of language partisanship offers valuable insights into the evolution of justices' language over time.

Weaknesses:
- The findings may be somewhat expected, as the topic of linguistic differences in political ideologies has been extensively studied.
- The paper lacks a thorough examination of the temporal dimension in linguistic features, which could affect the accuracy of the classification model.
- There is insufficient analysis of the linguistic features that indicate partisanship, which could enhance the interpretability of the model.

### Suggestions for Improvement
We recommend that the authors improve the clarity of how they derive "a partisanship score from our predicted party affiliation probabilities," particularly regarding the model's predictions per speaker per year. Additionally, addressing how the model accounts for varying text volumes per speaker would strengthen the analysis. We suggest incorporating insights into interesting linguistic patterns from the model, as simpler text regressions offer clearer interpretations. Furthermore, a deeper exploration of the linguistic evolution within each party could enhance the robustness of the findings. Finally, we encourage the authors to benchmark their model against more established models in the field, such as LegalBERT or Longformer, to contextualize their contributions more effectively.