ID: ZknHnDDxng
Title: VidChapters-7M: Video Chapters at Scale
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 5, 7, 7, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 5, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents VidChapters-7M, a large-scale dataset comprising 817K user-chaptered videos and 6.8M user-annotated chapters, created by scraping user-annotated chapters from YouTube. The authors propose benchmarks for video paragraph generation, video captioning, and grounded video captioning, demonstrating the dataset's potential to enhance performance in these tasks as well as in conventional dense video captioning tasks. The authors also explore the video chapter generation task with practical applications and provide extensive evaluations, showcasing the significance of their dataset's scale through transfer results to dense video captioning. The clarity of the paper, the sound construction of the dataset, and the adequacy of its documentation are highlighted.

### Strengths and Weaknesses
Strengths:  
- The exploration of video chapter generation for long videos is a valuable contribution, addressing a largely overlooked area.  
- The dataset is large-scale and well-constructed, providing ASR and chapter-level annotations that serve as a significant resource for the research community.  
- Extensive evaluations are provided, demonstrating the dataset's significance and effectiveness in improving performance.  
- The paper is clear and well-structured, with sufficient documentation.

Weaknesses:  
- The problem of long video captioning is not entirely new; thus, the authors should clarify the unique aspects of their dataset compared to existing ones.  
- The quality of chapter title annotations raises concerns, particularly regarding their informativeness and relevance to the corresponding video content.  
- The section on ASR extraction lacks detailed examples, and the authors should provide clearer explanations of the workflow and the generation of accurate word-level timestamps.  
- No specific weaknesses were noted in the reviews regarding the clarity and structure of the paper.

### Suggestions for Improvement
We recommend that the authors improve the explanation of the specific challenges involved in video chapter generation, rather than just highlighting differences from existing benchmarks. Additionally, the authors should address the quality of chapter title annotations more thoroughly, potentially including a quantitative assessment of their relevance to video content. We also suggest providing detailed examples in the ASR extraction section to enhance clarity. Furthermore, the authors should consider constructing more fine-grained datasets based on VidChapters-7M and include methods for de-noising and de-biasing the collected data. Lastly, we recommend that the authors provide a multi-lingual video caption baseline and benchmark to enhance the dataset's applicability across different languages.