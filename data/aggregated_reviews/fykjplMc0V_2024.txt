ID: fykjplMc0V
Title: ReFT: Representation Finetuning for Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 7, 9, 6, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Representation Finetuning (ReFT), a novel approach for fine-tuning language models that focuses on learning interventions directly on model representations rather than model weights. The authors compare ReFT to Parameter Efficient Finetuning (PEFT) methods, demonstrating that ReFT achieves similar performance with significantly fewer parameters. The paper introduces Low-rank Linear Subspace ReFT, showing its effectiveness across various models and datasets.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, with clear main ideas and a novel contribution to the field of representation intervention.
- Extensive empirical validation across multiple language models and datasets supports the method's practical applicability.
- The proposed method requires fewer parameters than existing methods like LoRA while maintaining comparable performance, particularly excelling in commonsense reasoning tasks.
- The authors provide thorough documentation and an open-sourced package for reproducing their results.

Weaknesses:
- The paper lacks comparisons to existing representation-editing baselines, which could enhance understanding of ReFT's performance relative to other methods.
- Some aspects of the presentation are unclear, including inconsistent variable names and a need for clearer definitions of terms like dropout.
- Hyperparameter tuning appears complex, and the authors should address how robust their hyperparameters are across different models and tasks.
- Performance decreases on certain tasks limit the method's applicability, necessitating broader evaluation across diverse datasets.

### Suggestions for Improvement
We recommend that the authors improve the paper by including comparisons of ReFT and DiReFT to existing representation-editing methods to clarify performance differences. Additionally, we suggest clarifying the notation used in the paper, particularly regarding variable names and dropout definitions. It would be beneficial to provide baseline generations in Appendix I for better interpretation of results. Furthermore, we encourage the authors to explore the robustness of hyperparameters across different models and tasks, and to clarify practical recommendations for using ReFT, including scenarios where it may be preferable to PEFT methods.