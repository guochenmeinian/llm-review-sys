ID: KEH6Cqjdw2
Title: Legally Enforceable Hate Speech Detection for Public Forums
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a dataset for hate speech detection, annotated by legal experts based on enforceable legal definitions. The authors aim to address the inconsistencies in hate speech definitions across various datasets, which complicate legal enforcement of classifier outputs. The dataset includes samples from existing datasets, relabeled according to federal laws, and evaluates various large language models (LLMs) for classification quality, serving as a benchmark for future research.

### Strengths and Weaknesses
Strengths:
- The dataset is a significant contribution, providing a reliable benchmark for evaluating classifiers against legally enforceable definitions.
- The paper offers a comprehensive analysis of LLM performance in detecting legally defined hate speech.
- High-quality writing and detailed presentation enhance the clarity of the research.

Weaknesses:
- The annotation strategy lacks clarity, raising potential ethical concerns regarding annotator rewards and motivations.
- The paper may not sufficiently address how the dataset will remain relevant as hate speech definitions evolve over time.
- There is a need for a more detailed discussion on the differences between original and relabeled definitions, as well as the degree of annotator agreement.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the annotation strategy, including details on how annotators are compensated or recognized for their contributions. Additionally, we suggest discussing the long-term maintenance of the dataset to ensure its relevance over time. The authors should provide a more thorough comparison of the original and relabeled definitions of hate speech and clarify the degree of annotator agreement. Finally, including the missing descriptions in Table 8 and for WizardLM would enhance the paper's clarity.