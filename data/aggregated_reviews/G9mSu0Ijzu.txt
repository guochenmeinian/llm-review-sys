ID: G9mSu0Ijzu
Title: The Art of Asking: Prompting Large Language Models for Serendipity Recommendations
Conference: ACM
Year: 2024
Number of Reviews: 5
Original Ratings: 1, 0, 0, 1, -1
Original Confidences: 4, 3, 4, 4, 5

Aggregated Review:
### Key Points
This paper presents SerenPrompt, which integrates discrete, continuous, and hybrid prompting techniques for applying large language models (LLMs) to serendipitous recommendations. The authors propose a novel computational approach to assess serendipity without manual annotation, achieving state-of-the-art results in this domain. The experimental setup is rigorous, validating the proposed methods against existing models.

### Strengths and Weaknesses
Strengths:
- SerenPrompt effectively combines various prompting techniques, enhancing the precision of serendipity recommendations.
- The integration of serendipity into the prompting process is a notable contribution, potentially leading to more personalized user experiences.
- The paper is well-organized, with a clear definition of serendipity and extensive experiments demonstrating the effectiveness of the proposed methods.

Weaknesses:
- The paper primarily tests SerenPrompt on large models (>10 billion parameters), raising questions about scalability and performance on smaller models.
- The heavy use of technical jargon could hinder readability.
- There is insufficient discussion on the computational costs and practical implications of deploying LLM-based systems in real-world scenarios.
- The generalizability of findings to other recommendation types and potential ethical issues related to serendipity recommendations are not adequately addressed.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Figure 1 and provide explanations for notations used. Clarifying the relationship between Demo users and the current user in the Demonstration Set $D$ is essential, as is detailing the average input length of discrete prompts. We suggest separating unexpectedness and relevance in Discrete Style 2: Indirect to enhance the understanding of LLM performance in these areas. Additionally, the authors should include total FLOPs for pre-training and fine-tuning, and compare inference times with baseline models, particularly SerenEnhance. We encourage the authors to explore the potential of using smaller models and to provide insights into how model scalability affects performance. Lastly, addressing the implications of user-item interaction histories and discussing ethical considerations would strengthen the paper.