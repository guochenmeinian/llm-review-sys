ID: jUdZCcoOu3
Title: RAPHAEL: Text-to-Image Generation via Large Mixture of Diffusion Paths
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 5, 7, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents RAPHEL, a large model for text-to-image generation based on the latent diffusion model (LDM) framework. RAPHEL incorporates mixture-of-experts (MoE) layers for spatial and temporal refinement, enhancing text and image fidelity. Trained on LAION-5B and internal datasets, it achieves state-of-the-art performance with a zero-shot FID score of 6.61 on COCO. The authors propose two novel contributions: spatial MoEs that process attended features from text tokens and edge-supervised learning for attention weights. Qualitative results indicate significant improvements over existing models. Additionally, the paper contributes valuable insights regarding model reproducibility, accessibility, and performance, although concerns about these aspects remain relevant in the broader context of generative models.

### Strengths and Weaknesses
Strengths:
- The paper is well-structured and clearly written, making it easy to follow.
- RAPHEL achieves state-of-the-art FID scores and qualitative results compared to other models like Stable Diffusion and DALLE2.
- The incorporation of MoEs for refining spatial and temporal details is intuitive and effectively demonstrated through ablation studies.
- The authors effectively addressed technical questions and concerns raised during the review process, with the rebuttal providing extensive details that enhanced understanding.

Weaknesses:
- The large-scale nature of the model, requiring 1000 A100 GPUs and extensive training time, limits reproducibility for most researchers.
- Ongoing concerns about reproducibility, model accessibility, and performance are not fully resolved.
- The technical novelties are somewhat limited and primarily applicable to the specific text-to-image task, with existing works showing similar ideas.
- Several technical details remain unclear, including the workings of time-MoE and the impact of internal data on performance.
- The reliance on comparisons with other works, such as Imagen, does not adequately address the specific concerns raised.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the technical details, particularly regarding the time-MoE mechanism and its role during inference. Additionally, providing more information about the internal dataset, including its size and characteristics, would enhance understanding. The authors should also clarify the ablation study methodology, specifying training conditions for each experiment. A more thorough discussion of limitations, including potential issues with edge map supervision and the implications of binarizing attention maps, would strengthen the paper. Furthermore, incorporating the detailed explanations provided in the rebuttal into the final version and addressing the broader concerns regarding reproducibility and model accessibility would enhance the paper's impact and relevance. Finally, addressing the notation inconsistencies and improving the writing quality by defining variables clearly would benefit the overall presentation.