ID: ymBG2xs9Zf
Title: Model-Based Control with Sparse Neural Dynamics
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 5, 5, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for pruning neural networks with ReLU activation functions during training, aimed at learning control system dynamics. The authors propose using mixed integer programming techniques to derive optimal control policies, demonstrating effectiveness through comparisons with a sampling-based optimizer on robotic manipulation tasks. The framework combines deep neural network pruning with mixed integer programming for model-based control, showcasing improvements in performance over strong baselines. Additionally, the authors achieve superior closed-loop control performance on tasks such as Object Sorting, Object Pushing, Cartpole, and Reacher using highly sparsified neural dynamics models. They demonstrate that their method outperforms prior works utilizing full dynamics models, particularly in terms of RMSE and performance metrics illustrated through box plots. The authors emphasize the generic applicability of their method to various dynamics models, including feed-forward and graph-neural networks, and showcase competitive performance across a range of tasks involving both rigid and deformable objects.

### Strengths and Weaknesses
Strengths:
- The integration of deep neural network pruning and mixed integer programming into model-based control is a novel approach.
- The technique for sparsifying the neural network by removing non-linearities aligns well with the goals of using a mixed integer programming solver.
- Experimental results provide strong evidence of the method's effectiveness in both simulation and real-world applications.
- The approach demonstrates superior closed-loop control performance across multiple tasks.
- The inclusion of additional simulation results strengthens the paper and highlights the method's advantages in scenarios with ample computation time for control inputs.
- The paper is well-structured and clearly written, with detailed descriptions of the sparsity induction methods.
- The discussion of limitations is appreciated and adds depth to the paper.

Weaknesses:
- The paper lacks a discussion on computational complexity and computation time, which is crucial given the NP-hard nature of mixed integer programming.
- There is insufficient clarity on the performance gains presented in the results, particularly in relation to the significance of improvements shown in Figure 5.
- Key comparisons to prior model-based reinforcement learning approaches are missing, limiting the evaluation's comprehensiveness.
- The experiments do not address the generalizability of findings to different model-based control frameworks or the feasibility of using image observations.
- The performance on the Rope Manipulation task is comparable to MPPI, indicating a limitation in the model's predictive capabilities.
- There are concerns regarding the experimental significance and the extension of the method to more complex domains.

### Suggestions for Improvement
We recommend that the authors improve the discussion on computational complexity, providing a clear specification of what constitutes a "sufficient" number of neurons in relation to the prediction horizon. Additionally, a complexity-performance trade-off comparison should be included to enhance the evaluation's usefulness. We suggest conducting more comprehensive comparisons with other model-based reinforcement learning methods, such as PETS and Dreamer, to strengthen the experimental validation. Furthermore, a discussion on the applicability of the proposed method to image-based observations would be beneficial. We also recommend including the accumulated rewards and standard deviation, as suggested in previous papers, and indicating that the method excels in scenarios where there is a comparatively large time for the computation of control inputs. Lastly, we encourage the authors to explore co-optimization of the model sparsification procedure with control synthesis to enhance performance further.