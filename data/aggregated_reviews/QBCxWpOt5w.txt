ID: QBCxWpOt5w
Title: Iteration Head: A Mechanistic Study of Chain-of-Thought
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 7, 6, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an algorithm called the "iteration-head" that enables autoregressive transformers to implement iterative functions, potentially linked to the chain of thought (CoT) reasoning capabilities of language models. The authors empirically demonstrate that simple two-layer transformers can learn the iteration-head algorithm when trained on iterative tasks. They propose a theoretical circuit for copying information and introduce a new metric, "attention peakiness," to measure the similarity of attention patterns to those predicted by the theoretical circuit.

### Strengths and Weaknesses
Strengths:
- The paper addresses a relevant topic concerning the mechanisms underlying CoT capabilities in transformers.
- It is well-written and studies a controlled setting, allowing for easy replication of results.
- The empirical findings support the theoretical intuition, particularly the use of transfer fine-tuning to validate the role of the MLP as $F$ in the iteration-head algorithm.

Weaknesses:
- The empirical evidence is limited to small models, while CoT prompting is more effective in larger models, necessitating an analysis of the iteration-head algorithm's replication in larger architectures.
- The implementation of the iteration-head algorithm is shown to vary across multiple heads/layers, indicating that the current description is incomplete. A discussion on how a distributed implementation might function would enhance the argument for its general applicability in pretrained transformers.
- The paper lacks a detailed comparison with existing mechanisms like the induction head, which would clarify the necessity of the iteration head for CoT reasoning.

### Suggestions for Improvement
We recommend that the authors improve the analysis by including an investigation of whether the iteration-head algorithm can be replicated in larger models, as these models benefit more from CoT prompting. Additionally, we suggest providing a discussion contrasting the iteration head with the induction head to clarify the unique contributions of the proposed algorithm. To strengthen the evidence for the mechanisms at play, we encourage the authors to incorporate weights-based analysis or activation patching, moving beyond reliance on attention patterns alone. Finally, we advise revising the abstract and introduction to clearly state that the study focuses on toy models and tasks, as this is crucial for understanding the paper's scope.