ID: Cib0JSAVwW
Title: Language-Agnostic Bias Detection in Language Models with Bias Probing
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents LABDet, a language-agnostic method for measuring social bias in pretrained language models, specifically focusing on nationality bias. The authors mitigate the sensitivity of prior methods by training a sentiment classifier on neutral-sentiment minimal pairs and analyzing sentiment score differences. They demonstrate their approach on a dataset for nationality, exploring correlations with sentiment in training data and assessing variability across multiple languages.

### Strengths and Weaknesses
Strengths:
- The method is simple yet effective and generalizable to any language with existing pretrained models.
- The paper is well-structured and clearly written, providing sufficient support for its claims.
- It uncovers biases consistent with political science expectations, contributing to the understanding of bias in language models.

Weaknesses:
- The scope is somewhat limited, focusing solely on nationality bias without exploring other types of bias.
- The evaluation is somewhat anecdotal; while it aligns with political science findings, a more rigorous assessment involving domain experts could enhance reliability.
- Implementation details, particularly regarding the training of multilingual classifiers, are lacking.

### Suggestions for Improvement
We recommend that the authors improve the scope of their evaluation by exploring additional tasks or datasets beyond sentiment classification. Additionally, providing more implementation details on the training of classifiers for multilingual models would strengthen the paper. It would also be beneficial to address the potential bias introduced by training solely on positive and negative samples, and consider including expert evaluations of detected biases for enhanced credibility.