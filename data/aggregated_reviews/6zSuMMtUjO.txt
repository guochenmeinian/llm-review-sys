ID: 6zSuMMtUjO
Title: IntenDD: A Unified Contrastive Learning Approach for Intent Detection and Discovery
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents INTENDD, a unified contrastive learning approach for intent detection and discovery in task-oriented dialogue systems. The authors propose (1) a shared utterance encoding backbone for intent classification and discovery, (2) an unsupervised contrastive learning strategy for representation learning, and (3) a two-step post-processing setup using Modified Adsorption (MAD) for intent classification. The study reports performance improvements over various baselines across multiple benchmark datasets.

### Strengths and Weaknesses
Strengths:
- The novel unified approach effectively addresses intent detection (multi-class and multi-label) and discovery (unsupervised and semi-supervised).
- The two-step post-processing method demonstrates performance improvements, validating the proposed model's efficacy.
- Extensive experiments across diverse datasets enhance the paper's contribution to the research community.

Weaknesses:
- Key details remain unclear, such as the total loss function for each task and the formal definition of final predictions for intent classification and discovery.
- The construction of the graph structure in the transductive learning setting lacks comprehensive discussion, which may hinder reproducibility.
- The method requires corpus-specific representation learning, deviating from a unified training approach applicable across multiple tasks and datasets.

### Suggestions for Improvement
We recommend that the authors improve clarity by summarizing the total loss function for each stage/task and defining the final predictions for intent classification and discovery formally. Additionally, a comprehensive discussion on the graph structure construction in the transductive learning setting is necessary to facilitate replication. The authors should also consider evaluating the model on other datasets, such as MixSNIPS and FSPS, to substantiate claims of significant improvements. Furthermore, we suggest visualizing the model architecture to enhance understanding of the complex design and connections between components. Lastly, addressing the computational complexity of graph construction and providing detailed statistical analyses would strengthen the paper.