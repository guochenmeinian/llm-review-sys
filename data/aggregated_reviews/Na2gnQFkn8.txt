ID: Na2gnQFkn8
Title: A SARS-CoV-2 Interaction Dataset and VHH Sequence Corpus for Antibody Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 6, 7, 8, 6, -1
Original Confidences: 4, 4, 4, 3, -1

Aggregated Review:
### Key Points
This paper presents two datasets: AVIDa-SARS-CoV-2, a detailed interaction dataset for analyzing antibody interactions with SARS-CoV-2 variants, and VHHCorpus-2M, a large sequence corpus for developing advanced antibody language models like VHHBERT. The datasets facilitate the training and evaluation of models aimed at predicting and generating high-affinity antibody sequences. The authors benchmark various protein and antibody language models, demonstrating that pre-training with VHHCorpus-2M improves F1 scores for binding predictions.

### Strengths and Weaknesses
Strengths:
- The datasets address a critical need in therapeutic antibody research, providing high-quality, specific data that enhances the development of antibody models.
- The resources are relevant to both COVID-19 research and broader fields of virology and immunology, promoting advancements in computational biology.
- The paper is well-structured and clearly written, with thorough documentation ensuring effective use by other researchers.
- The experimental dataset of approximately 77,000 sequences is significant for the immunotherapy community.

Weaknesses:
- The focus on VHHs may limit the dataset's applicability to certain research fields, reducing its significance from a broader machine learning perspective.
- The benchmarking analysis is somewhat underwhelming, lacking insights and conclusions, and the model selection process is not adequately justified.
- Limited description of the VHHCorpus-2M collection process raises questions about its curation and comparison to existing repertoires.

### Suggestions for Improvement
We recommend that the authors improve the manuscript by incorporating data on interactions with other coronaviruses to enhance model robustness and generalizability. Additionally, providing more structural information about VHHs would aid in understanding their mechanisms. We suggest conducting more extensive benchmarking against existing datasets and models, including evaluation or training curves to highlight differences. Clarifying the rationale behind model selection for benchmarking and addressing the out-of-distribution generalization task in the binary prediction setup would strengthen the analysis. Lastly, enhancing the clarity of figures, particularly Figure 2c, and including a diagram to illustrate the modeling choices for finetuning experiments would improve reader comprehension.