ID: X64IJvdftR
Title: Certified Robustness for Deep Equilibrium Models via Serialized Random Smoothing
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 7, 7, 7, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method for achieving certified robustness in Deep Equilibrium Models (DEQs) through Serialized Randomized Smoothing (SRS). The authors address the high computational costs associated with existing random smoothing methods by leveraging historical information from previous inputs, thereby enhancing efficiency without sacrificing certified accuracy. The paper includes theoretical proofs for the method's correctness and demonstrates significant performance improvements through extensive experiments on large-scale datasets.

### Strengths and Weaknesses
Strengths:
1. The paper effectively fills a gap in the literature by providing a scalable solution for certified robustness in DEQs across various datasets and network structures.
2. The proposed method significantly reduces computational time, making certification feasible for larger models and datasets, supported by extensive empirical evaluations.
3. The writing is clear and well-structured, facilitating reader comprehension.

Weaknesses:
1. The conceptual novelty may be limited since randomized smoothing is a well-established technique.
2. It remains unclear whether the certified robust accuracy of DEQs matches or exceeds that of existing results on feed-forward networks using standard random smoothing.
3. The method's applicability is restricted to DEQs, which may limit its broader impact compared to more widely used architectures.

### Suggestions for Improvement
We recommend that the authors improve their evaluation by reporting the average certified radius (ACR) alongside the discretized certified radius curve. Additionally, the authors should consider including performance comparisons of SRS against advanced training techniques like SmoothAdv and CATRS to demonstrate the universality of their approach. We advise the authors to clarify the dependency introduced by the SRS sampling in their proof and potentially revise it. Furthermore, elaborating on the initialization strategy for parallelization could enhance the method's efficiency. Lastly, a more substantial discussion on limitations and broader societal impacts would strengthen the paper's contribution.