ID: 1N5Ia3KLX8
Title: Closed Boundary Learning for Classification Tasks with the Universum Class
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a closed-boundary classification method aimed at distinguishing the Universum class from interest classes in classification tasks. The authors propose leveraging closed decision boundaries with a rule-based probability estimation strategy to classify these classes. The experiments conducted on the proposed COOLU method demonstrate comprehensive improvements over benchmarks such as BS, A-GCN, TaMM, AC-MIMLLN, SpanNER, and SCAPT, achieving approximately a 1% enhancement in F1/accuracy measures across NER, relation extraction, and sentiment analysis tasks.

### Strengths and Weaknesses
Strengths:  
- The proposed approach is novel and addresses an important problem in classification tasks.  
- The paper is well-written and clearly elaborates on its research questions and arguments.  
- The method shows previously overlooked connections between the Universum class and misclassification of samples, enhancing understanding in this area.  

Weaknesses:  
- Clarity issues persist regarding the framework's operation, particularly the lack of pseudocode or schema.  
- The GMM's suitability as a module is questionable, given its constraints on dimensionality.  
- The experimental design lacks comprehensive comparisons with state-of-the-art OOD detection methods and does not specify statistical tests used.  
- The mapping between threshold values, data scale, task types, and performance remains unclear.  

### Suggestions for Improvement
We recommend that the authors improve the clarity of the framework by including pseudocode or a schema to illustrate its operation. Additionally, the authors should consider incorporating traditional supervised classification methods and more state-of-the-art OOD detection methods in their baselines. We suggest providing a detailed explanation of the mapping between threshold values and performance metrics, as well as clarifying the statistical tests employed in the experiments. Finally, including ablation studies to assess the impact of N-pair loss pretraining and a more detailed experimental setting with case studies and visualizations would enhance the paper's rigor.