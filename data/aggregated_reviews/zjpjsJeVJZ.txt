ID: zjpjsJeVJZ
Title: Comparing Apples to Oranges: Learning Similarity Functions for Data Produced by Different Distributions
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 4, 7, 8, 2, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on PAC-learnable algorithms for estimating an intra-group similarity function, where intra-group similarities are predefined metrics and inter-group similarities adhere to the triangle inequality. The authors propose two algorithms, Naive and Cluster, and provide PAC-learning guarantees regarding their sample complexity. The clustering algorithm employs a representative subset of samples to enhance query efficiency. Empirical experiments validate the algorithms' performance against established benchmarks. Additionally, the authors critique the assumptions made in the analysis of error probabilities and learnability in machine learning algorithms, arguing that Theorem 2.3 is incorrectly stated. They emphasize that no algorithm can guarantee an error probability of \( O(\max(p_\ell(\epsilon, \delta), p_{\ell'}(\epsilon, \delta)) - \epsilon) \) in general, highlighting the limitations of assuming compact spaces and the implications of sampling the entire support of a distribution. Their proof technique, which constructs pathogenic instances to demonstrate learning hardness, is noted as a classical method in theoretical computer science.

### Strengths and Weaknesses
Strengths:
- The "simple learning algorithm" is effective and offers strong guarantees (Theorem 2.1).
- Utilizing $k$ centers from each group's samples as representatives is a logical enhancement.
- The experiments are robust, particularly the challenging similarity function based on the "married" feature, and benchmark algorithms are fairly compared.
- The authors provide a clear argument against the assumptions made in the critique, emphasizing the generality of their bounds.
- They effectively illustrate the importance of hard examples in understanding learnability and error bounds.

Weaknesses:
- The initial description of the simple algorithm is missing before Theorem 2.1, which could confuse readers.
- The presentation could benefit from reduced motivational content in the introduction and more detailed explanations in the main text, including proof sketches.
- The exploration of the "no free lunch" theorem is insufficient, particularly regarding the applicability of the framework when the maximum of {p_l, p_l'} is large.
- The critique of the upper bound relies on assumptions that may not hold in all scenarios, potentially oversimplifying the problem.
- The authors' proof is described as weak due to the level of control over input distributions, which may not reflect real-world complexities.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the initial algorithm description prior to Theorem 2.1. Additionally, we suggest enhancing the presentation by minimizing introductory motivation and providing more detailed proof sketches in the main text. To address the limitations of the "no free lunch" theorem, we encourage the authors to analyze their datasets to clarify how often the conditions for applicability are met. Furthermore, we recommend that the authors improve the clarity of their arguments regarding the implications of their assumptions, particularly in relation to compact spaces and realistic scenarios. Addressing the perceived weaknesses in their proof by providing a more robust justification for the construction of pathogenic instances could strengthen their position. Finally, we suggest that the authors consider including a discussion on the implications of their findings for learnability measures, such as VC dimension, to enhance the relevance of their work.