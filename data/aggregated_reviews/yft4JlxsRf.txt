ID: yft4JlxsRf
Title: A generative model of the hippocampal formation trained with theta driven local learning rules
Conference: NeurIPS
Year: 2023
Number of Reviews: 20
Original Ratings: 7, 4, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 1, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a model that integrates learning schemes from Bredenberg et al. (2021) to representation learning and path integration in the medial entorhinal cortex (MEC) and hippocampus (HPC). The authors propose a generative system that learns latent state representations and generates sensory predictions for spatial and nonspatial tasks, incorporating an oscillatory 'gating' signal related to theta oscillations. The MEC model demonstrates the ability to learn a ring attractor for path integration based solely on motion cues, generalizing to new environments without altering recurrent synaptic weights. The model employs biologically plausible learning rules and extends the MESH architecture with Hebbian-like algorithms. However, concerns are raised regarding the novelty of the computational aspects and the implementation of theta modulation in relation to observed neural phenomena.

### Strengths and Weaknesses
Strengths:  
- The paper successfully connects local, biophysically-motivated synaptic plasticity to representation learning objectives, marking a significant advancement over previous models.  
- The model innovatively couples neural dynamics with a theta oscillator, improving the scheduling of neuron activity and plasticity.  
- The clarity and logical presentation of the paper are commendable, with detailed responses to reviewer questions enhancing understanding of the model's mechanisms.  
- The model's ability to learn and adapt to new environments even with fixed weights is a notable strength.

Weaknesses:  
- The primary weaknesses stem from a lack of additional analyses, particularly the absence of tests in more complex environments, which raises concerns about scalability and the ability to develop grid-like or place cell responses.  
- The architecture is not entirely novel, as similar multi-compartment neuron models have been previously described, questioning the uniqueness of the authors' contributions.  
- There is insufficient analysis of the computations performed by the generative model, especially regarding the ring attractor's functionality and the increasing error in path integration beyond certain distances.  
- The inclusion of network predictions prior to learning is lacking, which could clarify the effectiveness of the learning process.  
- The paper lacks sufficient clarity in motivating the novelty of the model architecture and its applicability across different tasks, particularly in relation to theta oscillations and their biological relevance.

### Suggestions for Improvement
We recommend that the authors improve their analysis by testing the learning algorithm in more complex environments, such as two-dimensional spaces, to evaluate its scalability and ability to develop grid-like or place cell responses. Additionally, we suggest discussing testable predictions in more detail, particularly regarding the convergence of learning phases in nondeterministic systems. It would be beneficial to clarify the significance of attractor formation and provide more insights into why the proposed model uniquely captures hippocampal dynamics. We also recommend improving the clarity of the computations performed by the generative model, particularly regarding the ring attractor's role, and addressing the increasing error in path integration beyond 20 cm. Expanding the model's application to a 2D navigation task would significantly strengthen its contribution. Finally, conducting more thorough ablation studies on the theta oscillator and neuron compartments would provide deeper insights into their respective roles in learning, and splitting section 2.2 into two subsections could enhance the manuscript's structure.