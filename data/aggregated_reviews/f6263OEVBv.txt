ID: f6263OEVBv
Title: miniCTX: Neural Theorem Proving with (Long-)Contexts
Conference: NeurIPS
Year: 2024
Number of Reviews: 4
Original Ratings: 6, 8, 6, 7
Original Confidences: 3, 5, 3, 4

Aggregated Review:
### Key Points
This paper presents the miniCTX dataset and NTP-TOOLKIT, contributing significantly to context-dependent theorem proving. The experiments indicate that context enhances model performance, particularly through file-tuning. However, the explanations for key results, especially the comparison between miniCTX and miniF2F, require more depth. The paper's structure could be improved for better readability, and the broader implications of the work should be explored more thoroughly.

### Strengths and Weaknesses
Strengths:  
- The introduction of miniCTX as a dataset addresses a critical gap in evaluating models' abilities to handle complex contexts, making it a valuable tool for future research.  
- The development of NTP-TOOLKIT facilitates reproducibility and simplifies extending the benchmark, adding practical value.  
- The experimental setup is well-structured, effectively comparing different approaches and demonstrating the importance of context in theorem proving.  

Weaknesses:  
- The comparison between miniCTX and miniF2F lacks a clear explanation of the differing performance of file-tuning, necessitating a more detailed analysis.  
- The paper does not sufficiently explore broader implications, such as applications in mathematical education or AI-driven discovery.  
- Certain sections could benefit from improved clarity and cohesion, particularly around experimental results, to enhance readability.  
- The paper primarily offers qualitative comparisons; more quantitative comparisons across datasets would strengthen the empirical foundation of the claims.

### Suggestions for Improvement
We recommend that the authors improve the explanation of results, particularly regarding the performance differences between miniCTX and miniF2F, to provide clearer insights into the influencing factors. We suggest expanding the discussion to include broader implications of the work, such as potential applications in other domains. We encourage the authors to enhance the clarity and flow of the paper by refining transitions between key concepts and providing more detailed explanations. Additionally, we advise including more quantitative comparisons to strengthen the empirical evidence supporting the claims made in the paper.