ID: dDqNhoNHFo
Title: Amortized Decision-Aware Bayesian Experimental Design
Conference: NeurIPS
Year: 2024
Number of Reviews: 2
Original Ratings: 6, 4
Original Confidences: 3, 4

Aggregated Review:
### Key Points
This paper presents an innovative approach to Bayesian Experimental Design (BED) called Amortized Decision-Aware BED, which integrates decision-making objectives directly into the experiment design process to maximize downstream decision utility. The authors propose a Transformer Neural Decision Process (TNDP) architecture to predict experimental designs that optimize a non-myopic, discounted cumulative Decision Utility Gain (DUG), contributing a novel perspective to the literature.

### Strengths and Weaknesses
Strengths:
- The paper introduces a clean and novel setup that directly considers downstream decision-making utility, marking a significant contribution.
- The decision-aware framing extends Bayesian decision theory effectively, with the concept of DUG well justified.
- The TNDP architecture creatively addresses the complexity of traditional lookahead optimization methods.

Weaknesses:
- The proposed method shows only marginal improvements over baseline methods, lacking statistically significant enhancements that would support its practical relevance.
- Experimental comparisons are inadequate, particularly lacking direct comparisons with similarly motivated lookahead acquisition functions like the Knowledge Gradient (KG).
- The paper does not sufficiently discuss how pretraining data could be utilized by GP-based baselines through transfer learning or task-specific priors.
- The decision problem addressed appears overly simplistic, raising doubts about the method's advantages over standard Bayesian Optimization (BO) techniques.
- The experiments lack diversity, as they primarily focus on variations of Hyperparameter Optimization (HPO), limiting the generalizability of the findings.
- There is no reported training time for the TNDP model, leaving a critical aspect of its practical applicability unaddressed.

### Suggestions for Improvement
We recommend that the authors improve the empirical validation by providing more substantial comparisons with relevant lookahead acquisition functions, such as the Knowledge Gradient (KG), to strengthen the claims of practical relevance. Additionally, the authors should explore the potential for leveraging pretraining data in GP-based baselines and clarify how the decision-aware approach diverges from standard BO methods. Expanding the diversity of experimental tasks beyond HPO problems would enhance the generalizability of the proposed method. Finally, including details on the training time for the TNDP model would address an important factor in its practical applicability.