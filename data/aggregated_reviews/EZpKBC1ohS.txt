ID: EZpKBC1ohS
Title: Kernel PCA for Out-of-Distribution Detection
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 6, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for out-of-distribution (OOD) detection using Kernel Principal Component Analysis (KPCA) applied to the penultimate features of a neural network. The authors propose two kernels, a cosine kernel and a cosine-Gaussian kernel, motivated by previous nearest-neighbor-based detection approaches. The study demonstrates that both kernels outperform baseline methods in image-based OOD detection while achieving efficient inference with O(1) time and memory complexity through the use of Random Fourier Features (RFF). Additionally, the authors emphasize the transition from PCA to KPCA to effectively capture informative principal components of in-distribution (InD) features, arguing that linear transformations via PCA are inadequate for distinguishing InD from OOD features. By employing KPCA with appropriate non-linear kernels, the authors show improved separability and reconstruction error differentiation between InD and OOD features, evaluated against state-of-the-art (SOTA) techniques, demonstrating superior performance and efficiency.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and easy to understand, providing clear motivation and explanations of methods.
- The introduction of a kernel perspective in OOD detection is a significant contribution, addressing a gap in the literature.
- The simplicity and effectiveness of the proposed method are commendable.
- Extensive experimental evaluations demonstrate strong performance and efficiency compared to recent SOTA methods, with detailed ablation studies and sensitivity analyses providing comprehensive insights into the method's effectiveness.

Weaknesses:
- Section 2 lacks clarity on whether the RFF approximation applies to both kernels and requires elaboration on the approximation details.
- The dimensionality of the penultimate layer features and the number of random Fourier features selected should be highlighted, as RFF approximation demands a high number of features for medium to high-dimensional problems.
- The computational complexity of RFF is not discussed adequately.
- Some results in Table 1 may be perceived as underwhelming, despite outperforming KNN and other baselines.
- The relationship between the proposed method and boosting schemes could be more clearly articulated.
- The necessity of Proposition 2 for implementing CoP and CoRP is unclear and needs clarification.
- The rationale for using two kernels is not clearly stated at the beginning of the paper.

### Suggestions for Improvement
We recommend that the authors improve clarity in Section 2 regarding the use of RFF for both kernels and provide detailed explanations of the kernel approximations. It is essential to specify the dimensionality of the penultimate features and the number of random Fourier features selected in the experiments. Additionally, the authors should discuss the computational complexity of RFF in detail and consider consolidating Sections 2.2 and 3.1 into a "background" section. Clarifying the role of Proposition 2 in the implementation of CoP and CoRP is also necessary. We suggest improving the clarity regarding the motivation for transitioning from PCA to KPCA, specifically highlighting the advantages of low-dimensional subspaces and non-linear kernels. Furthermore, we recommend providing a more explicit explanation of the boosting scheme's role in the detection method and its comparison with other techniques. Finally, consider adding more comparisons with diverse methods and kernel designs to further validate the proposed approach.