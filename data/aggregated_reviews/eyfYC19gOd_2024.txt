ID: eyfYC19gOd
Title: Grid4D: 4D Decomposed Hash Encoding for High-Fidelity Dynamic Gaussian Splatting
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 6, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Grid4D, a novel representation for dynamic scene rendering that utilizes Hash Encoding to model the Deformation Field. The authors decompose 4D encoding into four 3D encodings to mitigate losses associated with low-rank tensor assumptions and introduce an attention module to separate spatial and temporal features. To enhance the smoothness of delta predictions for the deformation field, a smooth loss is incorporated. Experimental results on synthetic and real-world datasets demonstrate significant quality improvements over prior state-of-the-art methods, along with notable FPS enhancements compared to Deformable-GS.

### Strengths and Weaknesses
Strengths:
- The authors exhibit a profound understanding of Deformable-based Gaussian splatting, addressing the smoothness of the deformation field effectively.
- The design of the deformation network and the experiments with strong baselines are compelling, and the inclusion of ablation studies is appreciated.
- The novel attention mechanism and smooth training strategy contribute positively to feature aggregation and rendering quality.

Weaknesses:
- The paper lacks comprehensive comparisons with SC-GS, which currently achieves state-of-the-art rendering quality.
- The results on datasets like D-NeRF and HyperNeRF are questioned due to potential inaccuracies in camera poses and the selection of hyperparameters.
- The complexity of the architecture may hinder generalizability and complicate implementation.
- The paper does not convincingly demonstrate temporal smoothness and coherence, which are critical for a 4D method.

### Suggestions for Improvement
We recommend that the authors improve the comparison with SC-GS to provide a clearer understanding of their model's performance. Additionally, please include complete results on the Neu3D dataset and all relevant metrics, such as average training time and rendering speed. It would be beneficial to adopt the NeRF-DS dataset with more accurate camera poses for real-world scene comparisons. Furthermore, exploring the model's performance on more complex motions, such as non-rigid or large deformations, could enhance the robustness of the findings. Lastly, we suggest including temporal coherence metrics and supplementary videos to substantiate claims regarding the model's performance.