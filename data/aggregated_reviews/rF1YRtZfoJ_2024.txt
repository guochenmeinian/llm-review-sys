ID: rF1YRtZfoJ
Title: CLAP4CLIP: Continual Learning with Probabilistic Finetuning for Vision-Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 8, 4, 3, 5, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method for continual learning (CL) called CLAP (Continual LeArning with Probabilistic finetuning) applied to the CLIP model. The authors propose a probabilistic fine-tuning approach that utilizes task-specific adapters and visual-guided attention (VGA) modules to address catastrophic forgetting while enhancing model adaptation to new tasks. The method is evaluated across multiple datasets, demonstrating improved performance over traditional deterministic fine-tuning methods and showcasing effective uncertainty estimation.

### Strengths and Weaknesses
Strengths:
1. **Originality and Significance:** The integration of probabilistic fine-tuning with CLIP is innovative and addresses catastrophic forgetting effectively.
2. **Quality and Clarity:** The paper is well-written, with clear methodological explanations and thorough experimental setups.
3. **Technical Soundness:** Comprehensive experiments across various datasets convincingly demonstrate the effectiveness of CLAP4CLIP, particularly in achieving positive backward transfer.

Weaknesses:
1. **Presentation Issues:** Figure 1 lacks clarity and should be larger for better readability. Improved visualizations would enhance the understanding of the proposed method's complexities.
2. **Reference Order and Citations:** The references are incorrectly ordered, which may confuse readers. Reference [36] should also be included in the related works section for better context.
3. **Redundant Replay Strategies:** The reliance on replay strategies may underutilize CLIP's capabilities, and the paper does not clarify whether the VGA module is updated during incremental tasks, which is critical for performance.
4. **Computational Efficiency:** The method's multiple components may introduce significant computational overhead, and the paper lacks a detailed discussion on computational costs compared to baselines.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Figure 1 and enhance visualizations to better convey the method's complexities. Additionally, please ensure the correct ordering of references and include Reference [36] in the related works section. Address the necessity of the replay strategy and clarify the update strategy for the VGA module during incremental tasks. Furthermore, we suggest providing a detailed analysis of the computational requirements of your method compared to existing baselines to strengthen the paper's arguments regarding efficiency.