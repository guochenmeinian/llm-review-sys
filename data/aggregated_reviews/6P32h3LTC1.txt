ID: 6P32h3LTC1
Title: A Multi-Modal Multilingual Benchmark for Document Image Classification
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents two new datasets, MULTIEURLEX-DOC and WIKI-DOC, aimed at advancing multilingual document image classification. The MULTIEURLEX-DOC dataset includes multi-label legal documents in 23 European languages, while WIKI-DOC comprises multi-class Wikipedia articles in 9 languages, including Arabic, Chinese, and Japanese. The authors evaluate several multilingual Document AI models, revealing limitations in cross-lingual transfer, particularly between distant languages, and highlighting performance gaps between image-only models like Donut and more effective models. The datasets facilitate a more comprehensive analysis of multilingual Document AI models, addressing existing gaps in evaluation.

### Strengths and Weaknesses
Strengths:
- The introduction of two valuable multilingual datasets enhances the evaluation of document image classification models.
- Extensive empirical analysis and benchmarking of state-of-the-art models provide insights into their capabilities and limitations in multilingual contexts.
- The paper compares uni-modal and multi-modal models, demonstrating the struggles of image-only models in certain scenarios.
- The authors open-source the code and datasets, promoting reproducible research.

Weaknesses:
- Insufficient details regarding the datasets, including label semantics and distribution, hinder a full understanding of their strengths and limitations.
- The methodology for curating the datasets lacks clarity, raising questions about the novelty of the datasets.
- The writing, particularly in result analysis, is confusing and requires refinement.
- The influence of varying sample sizes in the MULTIEURLEX-DOC dataset is not adequately discussed.

### Suggestions for Improvement
We recommend that the authors improve the clarity and depth of the dataset descriptions, including label semantics and distribution, to better illustrate their strengths and limitations. Additionally, we suggest providing a more detailed discussion on the methodology used for curating the datasets to justify their novelty. The authors should also clarify the potential advantages and disadvantages of converting texts to PDFs and then to images, as this may impact model performance. Furthermore, refining the writing in the result analysis and addressing the influence of sample size variations in the MULTIEURLEX-DOC dataset would enhance the paper's overall clarity and impact.