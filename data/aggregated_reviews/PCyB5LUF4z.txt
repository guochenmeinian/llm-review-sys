ID: PCyB5LUF4z
Title: Learning to Follow Object-Centric Image Editing Instructions Faithfully
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for enhancing text-guided image editing by improving the quality of paired data through recent advancements in segmentation, chain-of-thought prompting, and visual question answering (VQA). The authors propose fine-tuning models with additional supervision signals, such as bounding boxes and segmentation masks, and curate a test set with both in-domain and out-of-domain examples. Experiments indicate that the enhanced dataset and fine-tuning strategies improve evaluation scores.

### Strengths and Weaknesses
Strengths:
- The proposed pipeline effectively utilizes recent advancements in computer vision and NLP, potentially increasing the quality of existing datasets.
- The evaluation using TIFA scores and human assessments demonstrates the impact of the proposed dataset.
- The paper is well-written and presents superior performance in both quantitative and qualitative results compared to baseline methods.

Weaknesses:
- The paper lacks clarity on how supervision signals (bounding boxes and segmentation masks) are utilized in fine-tuning, particularly in Section 3.
- There is confusion regarding the treatment of fine-tuned data in experiments, especially in Figure 8.
- The motivation behind the data cleaning steps is not convincingly justified, and the reliability of using GPT for instruction feasibility is questionable.
- Presentation issues, such as missing labels in figures, hinder understanding.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Section 3 by providing detailed explanations on how supervision signals are integrated into the fine-tuning process. Additionally, please clarify the data used in Figure 8 for the Instructpix2pix baseline. We suggest adding a comparative analysis with relevant datasets or methods, such as MetaCLUE, to strengthen the discussion. Furthermore, addressing the presentation issues, particularly the labeling of figures, will enhance the paper's comprehensibility. Lastly, we encourage the authors to justify the motivation behind the cleaning steps and the reliability of using GPT for assessing instruction feasibility.