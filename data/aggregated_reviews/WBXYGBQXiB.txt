ID: WBXYGBQXiB
Title: NCDL:  A Framework for Deep Learning on non-Cartesian Lattices
Conference: NeurIPS
Year: 2023
Number of Reviews: 6
Original Ratings: 8, 5, 8, 4, -1, -1
Original Confidences: 4, 3, 4, 3, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework and software library for computing convolutions on non-Cartesian lattices, arguing that such representations can be more beneficial than Cartesian grids for certain data types, particularly in image processing. The authors propose a new data structure called lattice tensor and emphasize the efficiency of their software, which leverages existing PyTorch implementations. They include experimental results demonstrating the performance of their method compared to existing software for hexagonal lattices.

### Strengths and Weaknesses
Strengths:  
- The contribution is novel, addressing an under-explored area in deep learning on lattices, likely to impact future research significantly.  
- The theoretical framework is strong, particularly regarding up and down sampling on non-uniform grids.  
- The software package is well-structured, documented, and includes a full test suite, indicating high quality.  

Weaknesses:  
- The paper is short and could benefit from expanded discussions, particularly on derivatives and numerical stability.  
- The experimental results are limited, focusing on a single dataset and lacking comparisons with other non-Cartesian models, such as GNNs.  
- The motivation for using hexagonal grids for images is unclear, and potential applications are not well articulated.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the computation of derivatives, including details on numerical stability and whether backward passes were handled natively by PyTorch. Additionally, we suggest including comparisons with other non-Cartesian models, such as GNNs, and expanding the experimental section to include more datasets and metrics, such as L2, PSNR, FID, and perceptual distance. Furthermore, constructing a table outlining typical use cases for non-Cartesian representations would clarify their potential applications and impact.