ID: iRIj0OvFG1
Title: Intuitive Multilingual Audio-Visual Speech Recognition with a Single-Trained Model
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach for multilingual audio-visual speech recognition (AVSR) by developing a single model trained on a multilingual dataset. The authors propose a framework that distinguishes languages and recognizes speech effectively across multiple languages. Key contributions include the introduction of an audio-visual guiding linguistic representation extractor, addressing language imbalance with a weighted objective function, and validating the model on the MuAViC dataset, which contains 1200 hours of audio-visual data in 9 languages. The results indicate an average 11% WER reduction in clean environments and 13% in noisy environments compared to previous models.

### Strengths and Weaknesses
Strengths:
- The innovative fine-tuning of a pre-trained audio-visual representation model with language prompts enhances multilingual recognition.
- The model shows robustness in low-resource languages and performs well in both clean and noisy environments.
- The weighted objective function effectively addresses language imbalance, improving performance for low-resource languages.
- Comprehensive experiments on a challenging dataset provide a solid evaluation of the model's capabilities.
- The approach has the potential to reduce the reliance on language-specific models, benefiting the NLP community.

Weaknesses:
- The lack of an in-depth ablation study raises questions about the effectiveness of prompt fine-tuning and hyperparameter sensitivity.
- The absence of results for scenarios with unknown languages during inference limits practical applicability.
- The paper does not provide specific details on the dataset's language distribution, which is crucial for understanding performance impacts.
- The focus on the MuAViC dataset may limit generalization; exploring other datasets could enhance validation.
- Clarity issues and inconsistencies in baseline comparisons detract from the paper's overall rigor.

### Suggestions for Improvement
We recommend that the authors improve clarity by addressing errors and ambiguities in the text, particularly regarding the prompt component and baseline comparisons. It would be beneficial to include an in-depth ablation study to evaluate the impact of prompt fine-tuning and to provide results for scenarios where the language is unknown during inference. Additionally, the authors should clarify the dataset's language distribution and consider integrating recent advancements in multimodal learning. Expanding the evaluation to include comparisons with a broader range of existing methods and datasets would strengthen the findings and generalizability of the proposed model.