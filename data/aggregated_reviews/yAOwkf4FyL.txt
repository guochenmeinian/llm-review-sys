ID: yAOwkf4FyL
Title: Operation-Level Early Stopping for Robustifying Differentiable NAS
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 5, 4, 6, 7, 3, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 4, 4, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the robustness issue of DARTS, focusing on overfitting as a key factor contributing to the dominance of skip connections. The authors propose an operation-level early stopping (OLES) strategy that utilizes gradient matching scores to mitigate this issue. The approach has been evaluated across various search spaces, yielding results comparable to state-of-the-art methods.

### Strengths and Weaknesses
Strengths:
- The concept of using gradient direction similarity between training and validation batches is sound.
- Extensive experiments across multiple search spaces and benchmarks demonstrate the effectiveness of the proposed method.
- The clarity of presentation and the comprehensive analysis of the skip connection issue are commendable.

Weaknesses:
- The novelty of the early stopping approach is diminished due to its similarity to the metric used in GM-NAS.
- Results on the DARTS S1-S4 space are absent, limiting the evaluation scope.
- Some discussions on overfitting lack clarity, particularly regarding the correlation between architecture parameters and validation loss.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the discussion surrounding the gradient matching method, providing a more detailed comparison with existing approaches. Additionally, addressing the absence of results on DARTS S1-S4 would strengthen the evaluation. The authors should also clarify the assumptions regarding overfitting and provide a more rigorous analysis of the correlation metrics used. Finally, it would be beneficial to discuss how the OLES method could be adapted for other scenarios beyond differentiable architecture search.