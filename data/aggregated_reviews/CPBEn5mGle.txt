ID: CPBEn5mGle
Title: CQE: A Comprehensive Quantity Extractor
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new method called CQE for extracting mentions of quantity, unit, and concept in textual documents, utilizing 61 syntax-based rules and a BERT-based classifier trained with examples generated by ChatGPT. The authors propose NewsQuant, a manually annotated corpus for quantity, unit, and concept mentions, where quantities and units are normalized. CQE is compared to three other quantity extractors and GPT-3, demonstrating superior performance on NewsQuant.

### Strengths and Weaknesses
Strengths:  
- The extraction of quantities, units, and entities is a challenging problem with significant applications, and this paper contributes a novel solution.  
- The method outperforms four state-of-the-art approaches, and the experiments are detailed and well-documented.  
- The introduction of a new benchmark dataset enhances the field's resources.  

Weaknesses:  
- The definitions of "concept" and "change" are vague, leading to potential issues in manual annotation and method evaluation.  
- The use of post-processing for output normalization may introduce biases, making comparisons with other methods unfair.  
- The paper lacks visual representation of the proposed methodology, which could aid understanding.

### Suggestions for Improvement
We recommend that the authors improve the formal definitions of "concept" and "change" to enhance clarity and robustness in evaluation. Additionally, the authors should provide a thorough explanation of the post-processing steps used for output normalization to ensure fair comparisons. It would also be beneficial to include a visual representation of the methodology to aid reader comprehension.