ID: Gqou8PRgWq
Title: SHED: Shapley-Based Automated Dataset Refinement for Instruction Fine-Tuning
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 3, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a data selection framework for instruction tuning using Shapley values, structured in three steps: clustering target samples, evaluating clusters with Shapley scores, and resampling based on these scores. The authors validate their approach on two instruction tuning benchmarks, achieving favorable results against several baselines. The proposed method, SHED, aims to create smaller, high-quality datasets from larger datasets without human intervention, demonstrating strong transferability across various large language models (LLMs).

### Strengths and Weaknesses
Strengths:
- The paper is clearly written and well-structured, making it easy to read.
- The problem addressed is critical, as high-quality data is essential for fine-tuning LLMs.
- Extensive experiments cover multiple datasets and fine-tuning tasks, showing improved performance compared to other methods.

Weaknesses:
- The use of the costly Shapley approach raises questions about its actual benefits, as final data selection relies on resampling without considering combinatorial effects between clusters.
- The paper does not include recent works in instruction mining as baselines, limiting the comparison scope.
- The computational overhead of the proposed method is not benchmarked, and its claim of suitability for any objective lacks validation.
- The reliance on clustering may reduce data diversity, potentially overlooking rare but important samples.
- The novelty and contribution of the paper are questioned, particularly in light of similar existing methods like TS-DSHAPLEY.

### Suggestions for Improvement
We recommend that the authors improve the justification for using the Shapley approach by demonstrating its benefits over simpler methods, such as conducting a grid search over sampling ratios. Additionally, the authors should include recent works in instruction mining as baselines to strengthen their comparisons. It is crucial to benchmark the computational overhead of SHED and validate its claims regarding suitability for various objectives. The authors should also address the potential reduction in data diversity due to clustering and discuss the limitations of their method more thoroughly. Finally, expanding the scope of the paper to include broader applications beyond instruction mining could enhance its impact.