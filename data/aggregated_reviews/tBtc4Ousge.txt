ID: tBtc4Ousge
Title: Intervention-Based Alignment of Code Search with Execution Feedback
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an approach called CIRL that addresses the problem of distinguishing functionally correct code from incorrect code in code retrieval. The authors propose using iterative perturbations of subtrees within Abstract Syntax Trees (ASTs) to create hard negative examples, employing a reinforcement learning (RL) framework to facilitate this process. Experimental results on three Python code datasets demonstrate the effectiveness of these code interventions, showing improvements in Mean Reciprocal Rank (MRR) over multiple baselines.

### Strengths and Weaknesses
Strengths:
- The approach provides an intuitive and well-motivated improvement over previous methods, with potential implications for various code-related tasks.
- The proposed method is novel, particularly in its use of structural perturbations rather than lexical changes.
- The evaluation is comprehensive, covering multiple benchmarks and providing detailed implementation information in the Appendix.

Weaknesses:
- The method is evaluated solely on Python data using one code search model (GraphCodeBERT), and the complexity of implementation for other languages is not discussed.
- The experiments involving LLMs lack thoroughness, with concerns regarding the structure and clarity of prompts used.
- The justification for employing an RL-based approach is unclear, and the paper does not empirically validate the necessity of this framework.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation for functional correctness in code search and provide a more robust justification for the use of the RL framework. Additionally, we suggest evaluating the proposed method on other programming languages and code search models to demonstrate its generalizability. Furthermore, the authors should address the weaknesses identified in the LLM experiments, ensuring that prompts are correctly formatted and structured. Lastly, we encourage the authors to compare their augmentation methods with existing works to contextualize their contributions better.