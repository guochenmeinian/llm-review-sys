ID: p3LSDQ0bxt
Title: GRE Score: Generative Risk Evaluation for Large Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 7, 6, 5
Original Confidences: 4, 4, 5

Aggregated Review:
### Key Points
This paper presents an attack-independent evaluation metric, the GRE score, aimed at quantifying the robustness of large language models (LLMs) in an attack-agnostic manner. The GRE score encompasses safety, privacy, robustness, ethics, and fairness, and demonstrates high correlations with RTA metrics under red teaming attacks while maintaining lower computational costs. The framework involves generating synthetic samples through risk-specific prompts, processing them with an LLM, and computing the GRE score based on the responses.

### Strengths and Weaknesses
Strengths:
- The paper is well written, with clear motivation and presentation of ideas.
- The computation-friendly evaluation is significant.
- The theoretical guarantee for the local GRE score as a robustness certificate is provided.

Weaknesses:
- The motivation for selecting TAP as the red-teaming attack is unclear, and the evaluation could be strengthened by considering other adaptable attack methods like GCG and AutoDAN.
- The alignment of the GRE score with human evaluation or GPT-4 evaluation is not sufficiently addressed, as the use of a Longformer and a PLM classifier may not be convincing enough.
- The stability of the GRE score calculation, particularly regarding the variance using different random seeds, needs analysis, and practical parameters should be determinative for reproducing the evaluation score.
- The limited number of risk-specific prompts raises concerns about the generalization of findings and the ability to accurately quantify the overall robustness of LLMs.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation for choosing TAP as the red-teaming attack and consider evaluating additional attack methods like GCG and AutoDAN. Additionally, the authors should address how the GRE score aligns with human evaluations or GPT-4 evaluations to enhance credibility. An analysis of the stability of GRE scores, including the variance across different random seeds, is necessary, and the authors should ensure that practical parameters are determinative for reproducibility. Finally, expanding the number of risk-specific prompts used in the evaluation could strengthen the generalizability of the findings.