ID: lCiqPxcyC0
Title: Replicable Uniformity Testing
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 7, 8, 4, 5, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on replicable uniformity testing, focusing on the minimum number of samples required to distinguish whether a distribution \( p \) is uniform or \( \varepsilon \) far from it in total variation (TV) distance. The authors propose an algorithm that requires \(\tilde{\Theta}(\sqrt{n}/(\varepsilon^2\rho) + 1/(\varepsilon^2\rho^2))\) samples, achieving a significant improvement over previous work by only incurring a \(1/\rho\) blow-up in sample complexity compared to non-replicable algorithms. The paper also provides a matching lower bound for symmetric algorithms, emphasizing that replicability does not necessitate an increase in sample complexity relative to the ambient dimension.

### Strengths and Weaknesses
Strengths:  
The work addresses a relevant problem in uniformity testing and presents an interesting sample complexity result that has not been previously explored in the context of replicability. The technical contribution is substantial, with the upper bound achieved through a modification of existing algorithms and a careful concentration argument.

Weaknesses:  
The discussion preceding the main result lacks clarity regarding the \(1/(\varepsilon^2\rho^2)\) additive term in the sample complexity, which could be better highlighted. Additionally, there is confusion about the appearance of the \(\tilde{O}(1/(\varepsilon^2\rho^2))\) term in the upper bound, as the proof sketch does not adequately address its role in the general case.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the discussion prior to the main result by explicitly mentioning the \(1/(\varepsilon^2\rho^2)\) additive term in the sample complexity, potentially including this in the abstract. Additionally, please elaborate on how the \(\tilde{O}(1/(\varepsilon^2\rho^2))\) term is derived and its significance, particularly in the context of the proof sketch. Furthermore, we suggest providing a high-level intuitive explanation for the inverse-linear dependency on \(\rho\) when \(n\) is large, as the current overview may be too technical for readers.