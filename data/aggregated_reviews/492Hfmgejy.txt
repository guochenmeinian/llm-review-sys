ID: 492Hfmgejy
Title: Lightweight Vision Transformer with Bidirectional Interaction
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 6, 6, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new lightweight vision transformer structure called FAT, utilizing a fully adaptive self-attention mechanism to model local and global information through bidirectional interactions. The authors propose a fine-grained downsampling strategy to enhance the self-attention mechanism for improved global perception. The experiments cover image classification, object detection, and semantic segmentation, demonstrating the method's effectiveness across various benchmarks.

### Strengths and Weaknesses
Strengths:  
- The paper is well-written and easy to understand.  
- The proposed method shows significant improvements through bidirectional interaction, validated by comprehensive ablation studies.  
- Experimental results indicate that FAT-B0 and B1 achieve remarkable throughput and accuracy, providing insights for future low-latency models.  

Weaknesses:  
- The novelty is limited, as many components like the conv stem and conditional positional encoding are not new, with the primary innovation being bidirectional interaction, which lacks a clear justification related to human visual perception.  
- The scaling behavior of the method shows limited improvement in larger models, and there is insufficient comparison of inference times across different hardware.  
- The experimental comparisons are inconsistent, with cherry-picked baselines that undermine the credibility of the results. Additionally, the efficacy of the proposed bidirectional interactions is not convincingly demonstrated.

### Suggestions for Improvement
We recommend that the authors improve the novelty of the paper by clearly distinguishing their method from existing works, particularly MixFormer, and providing a more robust justification for the proposed bidirectional interaction. It is essential to include a discussion on the scaling behavior of the model and to present comparisons of inference times across various hardware setups. Furthermore, we suggest that the authors ensure consistent baseline comparisons and consider replacing the fusion method in FAT with established techniques for fair evaluation. Lastly, including plots to illustrate training stability would enhance the paper's rigor.