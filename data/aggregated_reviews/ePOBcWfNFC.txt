ID: ePOBcWfNFC
Title: Disentangled Unsupervised Skill Discovery for Efficient Hierarchical Reinforcement Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 5, 5, 7, 4, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DUSDi, a method for learning disentangled skills through unsupervised interactions, which allows for efficient chaining of skills via hierarchical reinforcement learning. The authors propose a mutual-information-based objective to ensure skill disentanglement and utilize value factorization to optimize the process. Empirical results demonstrate the method's superiority over existing unsupervised skill discovery techniques.

### Strengths and Weaknesses
Strengths:  
- The algorithm design, based on factored MDP, is well motivated, and the empirical study shows that DUSDi consistently outperforms other methods.  
- The paper is well-written, with extensive empirical results highlighting advantages over baselines.  
- The simplicity of the approach and the clarity of presentation enhance its accessibility.  

Weaknesses:  
- The algorithmic contribution is not significant compared to other MI-based unsupervised skill discovery methods.  
- The key objective design lacks theoretical support, as Eq. (4) does not constitute a lower bound of the real objective.  
- The assumption of a discrete skill space limits generalization to continuous spaces, and there is insufficient visualization of learned skill embeddings.  
- The empirical evaluation is limited, as standard benchmarks (e.g., D4RL) are not utilized, raising questions about performance in complex environments.  
- The approach may not perform well in POMDPs or high-dimensional environments, and the benefits of disentanglement in real-world scenarios are not convincingly demonstrated.  

### Suggestions for Improvement
We recommend that the authors improve the theoretical support for the objective design and consider maintaining a lower bound. Additionally, providing visualizations of the learned skill embeddings would clarify how different skills affect specific factors of the state space. The authors should also address the limitations of the empirical evaluation by including results on standard benchmarks and discussing the implications of omitting proprioceptive states from the MI optimization. Finally, including a readme file in the submitted code folder detailing how to reproduce the paper's results would enhance reproducibility.