ID: rwcLHjtUmn
Title: A Suite of Generative Tasks for Multi-Level Multimodal Webpage Understanding
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the WikiWeb2M dataset, comprising 2 million webpages, aimed at advancing multimodal webpage understanding. The dataset retains complete web content, facilitating generative modeling tasks such as page description generation, section summarization, and contextual image captioning. The authors propose a novel attention mechanism, Prefix Global, which selects relevant image and text content as global tokens to improve context handling. Experimental results indicate that WikiWeb2M annotations enhance task performance compared to prior datasets, supported by comprehensive analyses of sequence length, input features, and model size.

### Strengths and Weaknesses
Strengths:  
- The paper is well-written and organized, making it easy to follow.  
- WikiWeb2M is a valuable resource for multimodal webpage understanding, combining image-caption pairs and long text articles.  
- The Prefix Global method is well-motivated, reducing computational complexity while maintaining performance.  
- Extensive experiments, including ablation studies and efficiency analyses, demonstrate the utility of the dataset and proposed method.  

Weaknesses:  
- The novelty of the proposed tasks is questioned, as they primarily focus on multimodal summarization or captioning.  
- The contribution of structural metadata signaling is unclear.  
- Other evaluation metrics reflecting human preference and multimodal evaluation are not reported.  
- The dataset parsing process may contain noise, which should be addressed.  

### Suggestions for Improvement
We recommend that the authors improve the clarity of the contribution of structural metadata in different tasks. Additionally, we suggest exploring the performance of LLMs with vision input on the proposed dataset. It would also be beneficial to report additional evaluation metrics, particularly those that reflect human preference and multimodal evaluation. Lastly, addressing potential noise in the dataset parsing process and discussing its types would enhance the paper's robustness.