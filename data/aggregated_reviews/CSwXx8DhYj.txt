ID: CSwXx8DhYj
Title: Communication Hierarchy-aware Graph Engine for Distributed Model Training
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents TuComm, a framework designed to manage communication for graph processing on high-performance computers (HPC). TuComm addresses the complex communication hierarchy in HPC, noting that high-level communication incurs longer delays than low-level communication. By merging messages within the same communication domain before sending them to the target domain, TuComm aims to enhance processing speed and reduce communication costs. Empirical results indicate that TuComm outperforms baseline methods in metrics such as GTEPS and communication time.

### Strengths and Weaknesses
Strengths:  
- The complex communication hierarchy of high-performance computers is clearly explained.  
- Empirical results demonstrate that TuComm outperforms baseline methods, showcasing impressive performance gains.  
- The paper tackles a significant problem in distributed graph computation and employs robust evaluation methods, including the Graph 500 benchmark.

Weaknesses:  
- The design is overly simplistic, primarily involving message merging, and the implementation appears straightforward.  
- The connection between the motivation (high-level latency) and the solution (message merging) is unclear, raising questions about the rationale behind merging as a means to reduce communication delay.  
- The writing quality requires significant improvement to meet top conference standards, with issues such as inconsistent logic between subsections and insufficient reflection of input in pseudocode.  
- The paper does not adequately address load balancing between computations or discuss potential trade-offs in memory usage, energy consumption, or fault tolerance.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the connection between the motivation and the proposed solution, specifically addressing how merging messages reduces communication delays. Additionally, we suggest enhancing the writing quality to ensure consistency and clarity throughout the paper. The authors should also consider incorporating a more formal discussion of the hierarchy-aware message aggregation mechanism and address the lack of load balancing mechanisms in their approach. Finally, discussing potential trade-offs related to memory usage, energy consumption, and fault tolerance would strengthen the paper's contributions.