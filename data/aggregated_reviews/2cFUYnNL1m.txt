ID: 2cFUYnNL1m
Title: Weight Diffusion for Future: Learn to Generalize in Non-Stationary Environments
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 5, 7, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Weight Diffusion (W-Diff), a framework addressing evolving domain generalization (EDG) in non-stationary environments. The authors propose using a conditional diffusion model in the parameter space to learn the evolving patterns of classifiers during domain-incremental training. The method employs an ensemble of classifiers tailored to the target domain for robust predictions, demonstrating effectiveness across various datasets.

### Strengths and Weaknesses
Strengths:
- The evolving domain generalization is an important area of research.
- The manuscript is well-structured, with clear explanations of the methodology.
- The introduction of model weight generation through diffusion models is innovative.
- The framework shows strong performance in generalizing to unseen domains across diverse datasets.

Weaknesses:
- The novelty of the approach is unclear, as similar ideas have been previously discussed without proper citation.
- Performance improvements across datasets appear marginal.
- The experiments are limited to small networks, raising questions about scalability.
- There is a lack of ablation studies and comparisons with other generative models, such as Variational Autoencoders (VAEs).
- The framework assumes knowledge of future datasets during inference, which may not be realistic.

### Suggestions for Improvement
We recommend that the authors improve the discussion of related work, particularly citing and addressing previous studies on diffusion models. Additionally, we suggest conducting more extensive ablation studies to explore alternative approaches, such as leveraging past classifiers for ensemble predictions. Clarifying the computational complexity of the diffusion model and its implications for larger datasets is essential. Finally, including a notation table in the appendix and proofreading for grammatical errors would enhance the manuscript's clarity and presentation.