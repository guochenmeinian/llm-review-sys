ID: UQTGlkr30Y
Title: Towards Consistent Language Models Using Controlled Prompting and Decoding
Conference: AAAI
Year: 2023
Number of Reviews: 3
Original Ratings: 7, 6, 5
Original Confidences: 4, 4, 3

Aggregated Review:
### Key Points
This paper presents an exploration of approaches to minimize inconsistencies in large language model (LLM) generated texts without fine-tuning. The authors discuss methods for representing semantic and lexical constraints and enforcing these during text generation. Experiments on the CommonGen dataset demonstrate the benefits of combining prompt engineering and constrained decoding techniques to meet specified requirements.

### Strengths and Weaknesses
Strengths:
1. The paper addresses a meaningful research question regarding the inconsistencies in LLM outputs.
2. It includes solid experiments with detailed results, particularly insightful ablation studies on the CommonGen dataset.
3. The discussion on enforcing semantic and lexical constraints without fine-tuning is interesting.

Weaknesses:
1. The literature review is missing key papers, such as Synchromesh, Format5, and DataVinci.
2. The paper lacks originality, presenting an amalgamation of existing techniques without introducing new ideas.
3. The contributions are not clearly articulated in Sections 2, 3, and 4.
4. The experiments do not adequately cover the ideas discussed, particularly regarding semantic constraints or output sequence repair.
5. Only LLaMA-2-7B is used in experiments, limiting the scope of the findings.

### Suggestions for Improvement
We recommend that the authors improve the literature review by including key papers like Synchromesh, Format5, and DataVinci. Additionally, we suggest that the authors clarify their contributions in Sections 2, 3, and 4. To enhance the experimental section, we recommend including more backbone models beyond LLaMA-2-7B and providing concrete examples for Declarative Constraints. Furthermore, we encourage the authors to present more examples of success and failure cases for different techniques, as this is crucial for an analysis paper. Lastly, addressing the formatting issues, such as the "Related Works TODO," is necessary for clarity.