ID: 7cnMLZvTy9
Title: Certification of Distributional Individual Fairness
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 6, 6, 7, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on certifying individual fairness (IF) in supervised learning, focusing on distributional individual fairness (DIF) in neural networks. The authors propose a novel convex relation of IF constraints that reduces computational costs and adapt methodologies from adversarial robustness to provide upper and lower bounds for IF on empirical samples and distributions within a $\gamma$-Wasserstein ball. The contributions include certifying DIF and using these bounds as regularizers in training to debias neural networks, supported by extensive experimental validation.

### Strengths and Weaknesses
Strengths:
- The paper is technically sound and addresses an important problem in individual fairness.
- The extensive experiments validate the effectiveness of the proposed methods, demonstrating significant improvements in DIF with modest accuracy degradation.

Weaknesses:
- The relationship between individual fairness and distributional fairness is not clearly articulated, leading to potential misunderstandings.
- Key observations and the novelty of the approach are not sufficiently highlighted, particularly regarding the efficiency of the methods.
- Some sections, particularly Section 5, are dense and could benefit from clearer explanations and additional theorem statements to clarify theoretical contributions.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the relationship between individual fairness and distributional fairness to avoid potential misunderstandings. Additionally, the authors should explicitly highlight the key observations and novelty of their approach, particularly regarding the efficiency of their methods. It would be beneficial to provide a brief explanation of the efficiency of the methods used, rather than relegating this information to the appendix. Furthermore, we suggest enhancing the discussion in Section 5, particularly around the optimization procedure and the final guarantees, to aid reader comprehension. Lastly, revising Figure 1 for clarity and ensuring that the definitions in the context of empirical samples align with the expectations stated in the paper would strengthen the presentation.