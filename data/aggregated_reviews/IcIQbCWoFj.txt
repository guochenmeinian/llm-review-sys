ID: IcIQbCWoFj
Title: Stochastic Approximation Approaches to Group Distributionally Robust Optimization
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 7, 5, 4, 8, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a near-optimal optimization algorithm for the group distributionally robust optimization (GDRO) problem, leveraging stochastic mirror descent (SMD) techniques. The authors propose an algorithm that achieves optimal sample complexity while also addressing scenarios with varying sample budgets across distributions. A weighted GDRO formulation is introduced, along with convergence analysis. The paper emphasizes the practical relevance of GDRO in machine learning applications.

### Strengths and Weaknesses
Strengths:
- The results are clearly presented, and the proof is fluent, warranting acceptance.
- The clever application of SMD and online learning techniques achieves near-optimal sample complexity and reduces per-iteration sample costs, which is significant for storage considerations.
- The introduction of a weighted GDRO formulation is of research interest.

Weaknesses:
- The absence of numerical studies to validate the convergence rate of the proposed algorithm is a significant drawback.
- The novelty of the second algorithm compared to existing works, particularly Soma et al. (2022), is unclear, raising questions about its originality.
- Mini-batch sizes in the proposed algorithms can be excessively large, and the contribution in the uniform-sample-budget setting appears limited due to extra logarithmic factors.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their contributions, particularly in distinguishing their work from Soma et al. (2022). Explicitly highlighting the unique features of Theorem 3 and Algorithm 3 would enhance the perceived originality. Additionally, we suggest incorporating numerical experiments to validate the performance of the proposed algorithms, as empirical evidence is crucial for practical relevance. Finally, addressing the concerns regarding mini-batch sizes and the necessity of reducing per-iteration sample counts would strengthen the paper's practical implications.