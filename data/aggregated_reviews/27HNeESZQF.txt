ID: 27HNeESZQF
Title: PromptARA: Improving Deep Representation in Hybrid Automatic Readability Assessment with Prompt and Orthogonal Projection
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a hybrid automatic readability assessment (ARA) model that utilizes prompts and an orthogonal projection layer to enhance deep feature representations and linguistic features. The authors conducted extensive experiments on four English and two Chinese datasets, demonstrating the model's effectiveness in improving readability assessment.

### Strengths and Weaknesses
Strengths:
1. The paper effectively demonstrates the contribution of deep feature representations and explicit syntactic information to readability assessment.
2. It provides sufficient technical details regarding the transformation process.
3. The inclusion of multiple datasets in both Chinese and English enhances the study's robustness.
4. Extensive computational experiments validate the effectiveness of the proposed framework.

Weaknesses:
1. The function of fusion through orthogonal layers is unclear; the authors need to provide examples or experimental results to show that this processing effectively removes redundant information.
2. There are grammatical issues throughout the paper, often involving missing determiners.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the orthogonal projection layer's functionality by providing examples or experimental results demonstrating its effectiveness in removing redundancy. Additionally, we suggest proofreading the paper to address grammatical issues. To strengthen the novelty claims regarding prompts and orthogonal projection layers, the authors should conduct a more comprehensive ablation study and provide detailed descriptions of their prompt engineering process, including how prompts are integrated into the model. Furthermore, comparisons with traditional readability formula-based methods and fine-tuned results for BERT-FP-LBL across all datasets should be included for a more thorough evaluation.