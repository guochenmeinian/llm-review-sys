ID: satH8Evs2y
Title: Beware of Road Markings: A New Adversarial Patch Attack to Monocular Depth Estimation
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 5, 6, 6, 6, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Adversarial Road Marking (AdvRM) attack, a novel adversarial patch method targeting monocular depth estimation (MDE) models for autonomous driving. The authors demonstrate that MDE models heavily depend on road regions for depth prediction, allowing AdvRM to deploy patches disguised as ordinary road markings, thus affecting depth predictions for obstacles. Experimental results validate the effectiveness, stealthiness, and robustness of AdvRM across various MDE models in both simulated and real-world scenarios. Additionally, the authors conduct a comprehensive analysis of the vulnerabilities in MDE models, particularly focusing on the impact of road features on depth predictions. They reveal that while advanced models like Midas and DeAny mitigate the effects of adversarial attacks, they do not completely eliminate vulnerabilities, as evidenced by substantial prediction errors that could lead to collisions. The authors also explore the practicality of white-box versus black-box methods, acknowledging the limitations of white-box methods while proposing extensions to black-box scenarios.

### Strengths and Weaknesses
Strengths:
- The paper is the first to produce obstacle-independent adversarial patches, demonstrating robust performance against both CNN and ViT-based models.
- Comprehensive experiments yield good quantitative results, convincingly demonstrating the reliance of MDE models on road features and providing clear evidence of the effectiveness of road patches.
- The analysis of advanced models like Midas and DeAny highlights their vulnerabilities, contributing to the understanding of depth estimation security.
- The method is simple yet effective, leveraging saliency maps to identify optimal patch locations on roads.
- The authors acknowledge the limitations of their methods and propose future directions for research, enhancing the paper's depth.

Weaknesses:
- The robustness analysis lacks evaluation under random noise and blurriness, common in real-world scenarios.
- The reliance on knowledge of target models limits the applicability of the approach.
- There is no comparison to existing attacks or evaluation of defenses against AdvRM, which would provide valuable context for its effectiveness.
- Building patches are shown to be ineffective, which may limit the generalizability of the findings.
- The transferability of both AdvRM and the referenced model is limited, indicating potential weaknesses in their applicability across different scenarios.

### Suggestions for Improvement
We recommend that the authors improve the robustness analysis by evaluating performance under random noise and blurriness. Additionally, the authors should include comparisons to existing patch attacks to contextualize AdvRM's effectiveness and evaluate potential defenses against it. Clarifying the problem formulation in Section 3.2 and providing more details on the saliency-driven analysis in Section 4.2 would enhance the paper's clarity. We also suggest that the authors improve the discussion on the implications of the limited transferability observed in their experiments and further explore the reasons behind the vulnerabilities of MDE models to enhance the theoretical support for their findings. Lastly, providing more detailed insights into the practical applications of their white-box and black-box methods would better inform future research directions.