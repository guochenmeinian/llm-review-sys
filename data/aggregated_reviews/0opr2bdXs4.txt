ID: 0opr2bdXs4
Title: From Trojan Horses to Castle Walls: Unveiling Bilateral Backdoor Effects in Diffusion Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 2
Original Ratings: 6, 5
Original Confidences: 5, 3

Aggregated Review:
### Key Points
This paper presents a relaxed threat model for backdoor attacks on diffusion models (DM), focusing on data poisoning attacks. The authors propose methods to poison the training dataset by injecting trigger patterns into training images or misaligning the image-text dataset. The paper provides insights into both attack and defense mechanisms involving backdoored DMs, demonstrating that such models can generate images with specific trigger patterns or misalignments with text prompts. The authors categorize the outcomes of backdooring DMs into four groups: poisoned generation + misaligned image-text (G1), poisoned generation only (G2), misaligned image-text (G3), and normal generation (G4), supported by empirical results indicating the feasibility of these attacks.

### Strengths and Weaknesses
Strengths:
- The paper relaxes the assumptions of threat models for backdoor attacks on DMs.
- It effectively demonstrates the backdoor attack's efficacy through trigger injection and image-text misalignment.
- The authors provide a novel perspective on the differences between attacking DMs and traditional image classification models.
- The categorization of outcomes from backdooring DMs is insightful.
- Empirical results validate the feasibility of generating misaligned text-image pairs and poisoned images.

Weaknesses:
- The defense strategy using backdoored DMs is counter-intuitive, relying on the assumption that defenders can predict the type of incoming attack, which is unrealistic.
- The rationale for employing backdoor DMs in defense is unclear, as clean DMs enhance robustness by generating artifacts.
- The claim that BadNet-like attacks are more practical than existing methods lacks clarity, as both require control over model training and distribution.
- The paper lacks significant technical contributions, primarily reusing BadNet techniques without addressing new challenges.
- There is insufficient comparison with existing Trojan methods in DMs, and some findings overlap with previously discussed concepts, such as adversarial training.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their defense strategy, addressing the unrealistic assumptions regarding the predictability of attacks. Additionally, we suggest providing a stronger rationale for the use of backdoor DMs in defense, highlighting their advantages over clean DMs. The authors should clarify the practicality of BadNet-like attacks compared to existing methods and enhance the technical contribution by addressing new challenges. Finally, we encourage the authors to include a comparative analysis with existing Trojan techniques in DMs to strengthen their findings.