ID: bf0MdFlz1i
Title: Optimistic Verifiable Training by Controlling Hardware Nondeterminism
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 6, 6, 7, -1, -1, -1, -1
Original Confidences: 3, 3, 1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to achieving identical results in model training across different GPU types through shared rounding decisions. The authors propose a verifiable training scheme utilizing a Merkle tree for efficient model weight comparison between a trainer and an auditor. They demonstrate the scalability of their method with experiments on ResNet-50 and GPT-2 across three NVIDIA GPU architectures (A40, Titan XP, RTX 2080 Ti). Additionally, they introduce techniques to reduce storage costs via efficient encoding of rounding logs and an adaptive threshold mechanism. Comparisons with existing methods indicate that their approach is both storage and time-efficient.

### Strengths and Weaknesses
Strengths:
- The paper introduces a method for achieving identical training results across different GPU types, enhancing reproducibility in machine learning. The verifiable training scheme adds trust and transparency, making it suitable for sensitive applications. The proposed storage cost reduction methods address practical resource usage concerns, representing a significant contribution.
- Experiments with foundation models across multiple GPU architectures demonstrate the robustness and practicality of the approach. Thorough comparisons with existing methods highlight the improved efficiency, reinforcing the case for adoption.

Weaknesses:
- The implementation of the verifiable training method is based entirely on PyTorch version 1.13.1, raising concerns about compatibility with newer versions, such as 2.3.1. This could affect the validity of claims regarding perfect training replication if others attempt to implement the method on updated frameworks.
- The authors assume certain metrics from baselines due to unavailability of specific information, which may compromise the fairness of comparisons and the validity of reported improvements in different scenarios.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the relationship and differences between their work and that of Teutsch & Reitwie√üner (2019) to emphasize their novelty. Additionally, we suggest that the authors add results from experiments conducted with PyTorch 2.3.1 to demonstrate the framework-agnostic nature of their method. Finally, we encourage the authors to elaborate on the motivation behind the existence of a trusted third party in their auditing process to strengthen the justification of their scenario.