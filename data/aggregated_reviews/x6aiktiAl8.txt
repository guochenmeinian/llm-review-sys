ID: x6aiktiAl8
Title: Compressing and Debiasing Vision-Language Pre-Trained Models for Visual Question Answering
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the first joint study on compressing and debiasing vision-language pre-trained models (VLPs) for visual question answering (VQA). The authors investigate whether a VLP can be compressed to reduce costs while improving out-of-distribution (OOD) accuracy by identifying sparse and robust subnetworks. Through systematic analysis involving various VLPs, compression methods, training strategies, and datasets, the authors demonstrate that sparse VLP subnetworks can match the performance of full debiased models and outperform state-of-the-art debiasing techniques on OOD datasets with fewer parameters.

### Strengths and Weaknesses
Strengths:
1. The paper addresses critical challenges in VLPs, including reliance on biases and inefficiencies in computation and memory.
2. The systematic analysis provides new insights into the training pipeline, compression techniques, and sparsity assignment.
3. The proposed joint compression-debiasing approach yields promising results and could influence other NLP domains.

Weaknesses:
1. The use of out-of-distribution (OOD) data during model development diverges from standard practices, potentially confounding results regarding true OOD generalization abilities.
2. The novelty of the contributions is limited as existing compression and debiasing methods are directly adopted from previous work.
3. The experiments are restricted to the LXMERT model, raising questions about the applicability of results to other VLP models.
4. There are formatting issues and typographical errors present in the manuscript.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their contributions, particularly in distinguishing their work from existing methods. Additionally, the authors should consider expanding their experiments to include newer VLP models to validate the generalizability of their findings. It is crucial to address the use of OOD data during model development, aligning with standard practices in OOD generalization literature. Finally, we suggest correcting formatting issues and typographical errors throughout the manuscript to enhance readability.