ID: uAOFSQEE4G
Title: Supernotes: Driving Consensus in Crowd-Sourced Fact-Checking
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework for creating Supernotes, which utilizes AI-generated consensus comments to enhance agreement among users in crowd-sourced fact-checking systems. Supernotes synthesize existing community comments and generate candidate comments using large language models (LLMs), filtering them through a scoring model trained on historical community ratings. Experimental results indicate that Supernotes are perceived as more helpful than existing community comments and outperform LLM-generated summaries across dimensions such as quality, clarity, coverage, context, and argumentation.

### Strengths and Weaknesses
Strengths:
1. Supernotes effectively leverage LLMs for generating diverse candidate comments and employ a robust scoring model to filter for helpfulness, addressing consensus challenges in existing systems.
2. The framework comprises candidate generation and scoring components, utilizing a "virtual jury" to assess candidate comments against effective fact-checking principles.
3. User experiments demonstrate that Supernotes excel in providing essential context, high-quality information, and clear language, while minimizing external information interference.
4. The Personalized Helpfulness Model (PHM) enhances evaluation accuracy by predicting ratings based on content and rater characteristics.

Weaknesses:
1. The framework's reliance on existing community comments may lead to delayed responses to real-time misinformation.
2. The experimental design, conducted via external surveys, may not fully replicate actual user experiences.
3. Insufficient focus on the principle alignment module raises questions about its contribution, and the survey's participant details are lacking, impacting reproducibility.
4. The evaluation does not adequately explain the context of the X posts used, raising concerns about potential cherry-picking of posts.

### Suggestions for Improvement
We recommend that the authors improve the description of the principle alignment module and clarify its role within the framework. Additionally, providing more detailed information about the survey participants and their training would enhance reproducibility. It would be beneficial to include context for the X posts used in experiments to avoid cherry-picking concerns. We suggest comparing Supernotes' performance against plain LLM prompting to assess its effectiveness further. Lastly, considering the integration of external reliable sources during annotation generation could enhance context and comprehensiveness.