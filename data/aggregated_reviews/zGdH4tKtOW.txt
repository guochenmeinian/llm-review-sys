ID: zGdH4tKtOW
Title: Optimal Treatment Regimes for Proximal Causal Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 5, 7, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new optimal individual treatment regime (ITR) within the proximal causal inference framework, which circumvents the strong assumption of no unmeasured confounding. The authors propose that the effect of unmeasured confounders flows exclusively through proxy variables, defined via outcome-inducing and treatment-inducing confounding bridges. The proposed ITR is defined with respect to a more flexible function class, incorporating known confounders \(X\), treatment-inducing confounding proxies \(Z\), and outcome-inducing confounding proxies \(W\). The authors identify the value function for this broader class of ITRs and demonstrate its superiority over narrower classes. Additionally, the paper introduces a novel approach to ensuring the consistency of a conditional value function, distinct from the marginal value consistency addressed by Qi et al. (2023, JASA), imposing an \(L_{\infty}\) convergence assumption to achieve this consistency. The authors acknowledge the complexity of deriving convergence rates and finite sample error bounds and express intent to discuss limitations and future work in the revision. A qualitative analysis illustrates the differences in performance between their proposed method and existing estimators, particularly in the context of patients with lung cancer.

### Strengths and Weaknesses
Strengths:  
- The proposed ITR extends existing methods by using a function \(\pi(x)\) that selectively chooses between two existing ITRs based on known confounders \(x\).  
- The authors introduce a simple plugin estimator for the proposed ITR, with simulation studies indicating that it is either superior or comparable to existing ITRs.  
- The manuscript is well-written and provides a thorough review of prior work, clearly articulating how their work builds upon it.  
- The authors have made significant improvements in addressing reviewer concerns, particularly regarding the qualitative analysis and hyperparameter tuning.  
- The paper demonstrates a clear understanding of the implications of the \(L_{\infty}\) assumption and its role in proving consistency.

Weaknesses:  
- The extension of the ITR function class appears incremental, and the authors should demonstrate that this is the best approach by showing that more complex function classes would be unidentifiable without stronger assumptions.  
- The improvement in mean value from the proposed ITR is significant only in one simulation scenario, with unclear performance in others; further explanation is needed.  
- The real-data analysis lacks calculated values for the estimated ITR, hindering performance comparison against existing ITRs.  
- The limited number of treatment-inducing and outcome-inducing confounding proxies in simulations and real data analysis does not reflect the practical appeal of the proximal causal inference framework, which suggests using many proxies.  
- The model class remains somewhat limited, and the authors have yet to fully address the implications of using different evaluation methods for comparisons.  
- The consistency results achieved may not be as robust as those in Qi et al. (2023) without the \(L_{\infty}\) assumption.

### Suggestions for Improvement
We recommend that the authors improve the theoretical guarantees by deriving convergence rates and finite-sample error bounds, avoiding reliance on \(L_\infty\) convergence assumptions. Additionally, the authors should clarify how value estimates are derived in the real data analysis and consider qualitative assessments of the proposed method's performance against existing literature. Expanding empirical comparisons to include more baselines and varying sample sizes would strengthen the findings. Furthermore, we suggest that the authors explore more sophisticated estimators for \(d_z\), \(d_w\), and \(\delta\) and discuss hyperparameter tuning for all functional classes. We also recommend improving the explanation of the \(L_{\infty}\) assumption in contrast to previous work and exploring the possibility of achieving similar consistency results with an \(L_2\) assumption. Additionally, the authors should compare their proposed method to \(\hat d_{z \cup w}\) rather than solely to \(\hat d_w\), and acknowledge the limitations of evaluating methods with different assumptions in the value table for real data analysis. To enhance the impact of the work, we encourage the authors to emphasize comparative baselines against existing methods, uncertainty estimation, and provide clear guidance for applied researchers on identifying the appropriate proximal regime. Finally, we suggest adding a "Discussion" section that summarizes results and addresses limitations, including the assumptions made in the proposed method.