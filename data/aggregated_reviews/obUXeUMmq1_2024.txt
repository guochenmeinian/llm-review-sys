ID: obUXeUMmq1
Title: Understanding Representation of Deep Equilibrium Models from Neural Collapse Perspective
Conference: NeurIPS
Year: 2024
Number of Reviews: 18
Original Ratings: 5, 6, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis of Deep Equilibrium Models (DEQ) through the lens of Neural Collapse (NC), demonstrating that DEQ exhibits NC under balanced conditions and maintains advantages in imbalanced settings. The authors compare DEQ's theoretical properties with standard neural networks (NN) using a layer-peeled model and provide experimental results on CIFAR-10 and CIFAR-100, showing DEQ's superior performance in various scenarios.

### Strengths and Weaknesses
Strengths:  
- The paper offers a novel perspective on the advantages of DEQ over standard NN, supported by solid theoretical analysis and experimental validation.  
- It effectively demonstrates DEQ's performance in handling imbalanced datasets, enhancing the credibility of its findings.  
- The introduction of the Neural Collapse phenomenon provides valuable insights into deep representations in implicit neural networks.

Weaknesses:  
- Major presentation issues, including notation errors and unclear formulations, hinder the clarity of results.  
- The experimental setup lacks validation of the authors' claims regarding DEQ's lower loss compared to explicit layers, particularly the absence of cross-entropy loss illustrations.  
- The reliance on a single random seed for experiments limits the robustness of performance measures.  
- The contribution of the paper may be perceived as marginal compared to existing techniques for mitigating minority collapse, such as sample reweighting.

### Suggestions for Improvement
We recommend that the authors improve the presentation by addressing the notation and formulation errors, particularly in Eq (1), NC1, and Theorem 3.1. Additionally, we suggest validating the claim about DEQ's lower loss by including cross-entropy loss comparisons in the experiments. To enhance the robustness of the findings, we encourage the authors to conduct experiments using multiple random seeds and to compare DEQ with standard techniques like sample reweighting. Furthermore, providing a more comprehensive evaluation across various architectures beyond ResNet-18 would strengthen the contribution of the paper.