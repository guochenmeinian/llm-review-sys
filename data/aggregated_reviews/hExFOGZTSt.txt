ID: hExFOGZTSt
Title: Creating a Public Repository for Joining Private Data
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 7, 7, 7, 7, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 1, 2, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a scenario where a data owner aims to publish a private view of their dataset, allowing others to evaluate join aggregations against it. The authors propose the SumOverJoin problem, where a high-dimensional sparse vector is published to enable others to estimate the inner product with their own vectors. The paper explores optimization settings to find vectors that approximately optimize a loss function, demonstrating applicability to models like logistic regression with privacy guarantees. Additionally, it addresses the challenge of computing functions of joined datasets while ensuring differential privacy through a non-interactive sketching method.

### Strengths and Weaknesses
Strengths:
- The paper clearly defines the problem and effectively combines sketches with noise for a solution.
- The algorithm is straightforward to implement and shows strong experimental performance.
- The technical proof of optimization query accuracy reflects the authors' skill.

Weaknesses:
- The scenario may be perceived as narrow, with alternative approaches failing due to the non-interactive requirement.
- The novelty of the core contribution is debatable, as prior work exists on sketches with differential privacy noise.
- Presentation issues exist, such as unclear phrasing and the need for more precise definitions regarding objectives and guarantees.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their presentation, particularly in phrases like "we can view the sketch as a function accepting as query an entire dataset" and "we are not trying to compress a stream." It would be beneficial to clarify that the goal is to take an input with n non-zeros over a domain of size D, aiming for a size proportional to n but sublinear in D. Additionally, the authors should discuss the implications if D were small and provide more precise language regarding "secure hash functions should give the same guarantees." 

We also suggest that the authors define the correctness and privacy properties of their system more formally, particularly concerning the potential for false positive matches in joins. Lastly, it would be informative to compare their results with other baselines, such as Label DP, to contextualize their findings within the broader landscape of privacy-preserving data analysis.