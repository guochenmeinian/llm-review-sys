ID: 0T8xRFrScB
Title: Benchmarking Counterfactual Image Generation
Conference: NeurIPS
Year: 2024
Number of Reviews: 18
Original Ratings: 8, 7, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a benchmark for comparing counterfactual image generation methods, utilizing a structural causal model to guide image manipulation. It is noted as the first benchmark of its kind, providing significant contributions to the field. The authors propose a framework that evaluates various generative models, including hierarchical VAEs, conditional GANs, and others, across dimensions such as composition, effectiveness, realism, and minimality. The results indicate that hierarchical VAEs outperform other models in these evaluations.

### Strengths and Weaknesses
Strengths:
- The paper addresses a critical research gap and is well-written, making it easy to follow.
- The experimental setup is robust, with extensive benchmarking across multiple datasets and methods, leading to valuable conclusions regarding the performance of HVAE.
- The proposed benchmark and source code are well-crafted and relevant to the community.

Weaknesses:
- The study suffers from low image resolution, which may hinder the assessment of generated images.
- The exclusion of recent generative paradigms, particularly denoising diffusion models, limits the framework's applicability.
- The paper primarily focuses on "true causal counterfactual methods," neglecting other semantic image editing methods, which could provide a broader context for the findings.

### Suggestions for Improvement
We recommend that the authors improve the discussion surrounding the metrics, particularly justifying their relevance and definitions. The authors should consider moving some results to the appendix to allocate more space for this critical discussion. Additionally, addressing the limitations of low-resolution images and the absence of diffusion models is essential; including experiments with these models could significantly enhance the paper's contributions. A detailed explanation of the challenges associated with benchmarking diffusion models and the feasibility of including non-causal methods would also be beneficial. Finally, clarifying the difficulties encountered with scaling to higher-resolution datasets would provide valuable context for the study's limitations.