ID: rq4UfmpRA9
Title: Democratizing Reasoning Ability: Tailored Learning from Large Language Model
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework that distills reasoning abilities from larger language models (LLMs) to smaller models through a multi-round learning procedure. The authors propose using incorrect reasoning chains from the student model to iteratively refine the reasoning chains generated by LLMs, supplemented by a ‘self-reflection’ objective that allows the model to learn from its own errors. Experimental results demonstrate the effectiveness of this approach across various datasets in math and commonsense reasoning tasks.

### Strengths and Weaknesses
Strengths:
- The incorporation of feedback from the student LM into knowledge distillation is novel and enhances interaction between teacher and student models.
- The experiments are comprehensive, featuring multiple datasets and competitive baselines, with insightful ablation studies that validate the proposed method's efficacy.
- The paper is well-structured and effectively communicates its ideas and results.

Weaknesses:
- The evaluation of generated rationales relies solely on the correctness of final answers, which may not accurately reflect the quality of the rationales.
- The paper lacks a discussion on the legality and copyright implications of using outputs from closed-source models for fine-tuning open-source models.
- There is no human evaluation to verify the enhanced reasoning ability of the smaller LMs.

### Suggestions for Improvement
We recommend that the authors improve the evaluation criteria for generated rationales by incorporating sanity checks to filter out inconsistent rationale-label pairs. Additionally, the authors should consider conducting human evaluations to substantiate claims of enhanced reasoning abilities. It would also be beneficial to include comparisons with manually labeled reasoning chains to assess the proposed method's effectiveness. Furthermore, clarifying how Equation 2 facilitates accurate rationale generation and exploring the potential of using different subsets of training data in each round could enhance the study. Lastly, addressing the legality and copyright aspects more thoroughly would strengthen the paper.