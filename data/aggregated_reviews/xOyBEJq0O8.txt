ID: xOyBEJq0O8
Title: GATITOS: Using a New Multilingual Lexicon for Low-resource Machine Translation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into the use of bilingual lexica for data augmentation in machine translation (MT), specifically focusing on low-resource languages. The authors propose several approaches to augment data using bilingual lexica and evaluate their effectiveness across 200 translation models trained on extensive web-crawl data. Key findings indicate that the impact of lexical data augmentation is most significant in unsupervised MT, that the approaches exhibit high complementarity, and that the quality of bilingual lexica is more crucial than their size. Additionally, a high-quality bilingual lexicon covering 184 low-resource languages is released alongside the paper.

### Strengths and Weaknesses
Strengths:
- The paper addresses a relevant problem and is supported by extensive analyses and experiments across multiple language pairs.
- Findings are particularly valuable for unsupervised MT, which could be emphasized further.
- The structured discussion, including takeaway messages at the end of each section, enhances clarity.
- The release of the dataset is a significant contribution to research in low-resource languages.

Weaknesses:
- The introduction emphasizes the impact of data augmentation on supervised and self-supervised training but lacks in-depth discussion on this aspect.
- The reliance on in-house data limits the reproducibility of results, raising concerns about the ability of other researchers to validate findings.
- The overall message is somewhat confusing, as the paper shifts focus from bilingual lexica's impact on supervised methods to unsupervised MT without clear justification.
- The paper's structure could be improved for clarity, and some sections contain excessive material that could be developed into a separate paper.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the impact of data augmentation methods on supervised and self-supervised training to align with the introduction's emphasis. Additionally, please clarify the rationale for using in-house data and consider conducting preliminary studies with publicly available datasets to enhance reproducibility. We suggest focusing the paper more directly on unsupervised MT to streamline the overall message. Furthermore, we recommend restructuring the paper by moving Sections 3, 4, and 5 after Section 6 for better flow. Lastly, please address the clarity issues in writing and ensure that all abbreviations are introduced before use.