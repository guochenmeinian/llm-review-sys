ID: Wjp1AYB8lH
Title: Large Language Models as Commonsense Knowledge for Large-Scale Task Planning
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 7, 7, 4, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach that utilizes large language models (LLMs) as both a commonsense world model and a heuristic policy within the Monte Carlo Tree Search (MCTS) framework for household planning tasks, specifically object rearrangements. The authors demonstrate that their method significantly outperforms traditional search algorithms and LLMs used solely as policies. Additionally, the authors propose a methodology that employs LLMs to provide a prior that effectively narrows down the belief space for search in large domains, addressing challenges posed by large belief states. They acknowledge the limitations of PUCT in scaling to larger belief spaces and clarify that object relationships are used to initialize the world's belief, balancing efficiency and accuracy, with beliefs updated as the agent navigates and receives new observations. The evaluation includes various task complexities and an insightful ablation study, highlighting the effectiveness of integrating LLMs into the planning process.

### Strengths and Weaknesses
Strengths:
- The innovative use of LLMs as a world model rather than just a policy model is compelling and addresses the complexity of planning tasks effectively.
- The authors provide a clear contribution by using LLMs to narrow the belief space, which is a significant aspect of their work.
- Experimental results show significant improvements over baseline models, including a variant of MCTS without a commonsense world model and a supervised GPT-2 model.
- The thorough ablation study provides valuable insights into the contributions of different components of the proposed methodology.
- The trade-off between efficiency and accuracy in initializing beliefs is well-articulated and supported by experimental results.

Weaknesses:
- The evaluation is limited to object rearrangement tasks within a single domain (VirtualHome), raising questions about generalizability to more complex environments.
- The methodology may not adequately scale to larger belief states, and the lack of additional experiments in this area is a concern.
- The paper lacks a detailed explanation of how frequently the LLM is utilized as a world model during the MCTS process, which could enhance clarity.
- The response to reviewer comments could be perceived as defensive rather than constructive.
- The absence of a limitations section and consideration of broader societal impacts is noted, which are important for a generation model like LLMs.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their methodology by providing a more organized description of how the LLM is used throughout the MCTS process, potentially with a running example. Additionally, including more diverse baselines that feature specialized designs for task planning, such as SayCan and Zero-Shot Planner, would strengthen the evaluation. Expanding the scope of experiments to include more complex tasks with varied object relationships would also be beneficial. We suggest conducting and including additional experiments with larger belief states to address the primary concerns raised and positively influence the evaluation of the paper. Finally, we recommend adding a limitations section to address potential shortcomings and societal impacts associated with the use of LLMs in this context, and making the code available for review prior to the final submission to enhance transparency and facilitate further evaluation.