ID: gHCFduRo7o
Title: Selective Explanations
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 4, 7, 5, 4, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel framework for explaining black box models through a selective explainer that unifies amortized and complex explanation methods. The selective explainer identifies when to use cheaper, lower-quality explanations versus more costly, higher-quality ones, depending on user needs. The authors claim that their method improves explanation quality while reducing computational costs, validated through experiments on benchmark datasets.

### Strengths and Weaknesses
Strengths:
- The paper addresses an interesting problem of combining inexpensive and expensive explanations.
- The theoretical analysis appears sound, with rigorous mathematical formulations.
- The method shows practical impact by significantly reducing computational costs while maintaining or improving explanation quality.

Weaknesses:
- The methodology relies on unexamined assumptions, particularly that less stable explanations are inherently low-quality, which requires further discussion.
- The terminology is misleading, as the paper equates expensive explanations with high quality without actual comparisons.
- The experimental evaluation is limited to quantitative measures; a user study would enhance understanding of explanation quality from a human perspective.
- Relevant related work on uncertainty quantification is not adequately addressed.

### Suggestions for Improvement
We recommend that the authors improve the discussion surrounding the assumption that less stable explanations are low-quality, including how this relates to the correctness of ML predictions. Additionally, we suggest clarifying the terminology used, replacing "high-quality" with "expensive-to-obtain" throughout the paper. To strengthen the evaluation, we encourage the authors to include a user study to assess the quality of explanations from a human perspective. Lastly, we advise incorporating relevant literature on uncertainty quantification to provide a more comprehensive context for the proposed method.