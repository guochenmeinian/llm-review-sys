ID: iv2sTQtbst
Title: Patch Diffusion: Faster and More Data-Efficient Training of Diffusion Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 5, 6, 6, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents PatchDiffusion, a novel framework aimed at addressing scalability challenges in diffusion models by employing a patch-wise training approach. The authors propose training a denoising network on image patches instead of full images, utilizing progressive or stochastic scheduling techniques to generate patches at the target resolution. Experimental results indicate that PatchDiffusion enhances sample quality and reduces training time, demonstrating its potential as a resource-efficient solution for diffusion training methods.

### Strengths and Weaknesses
Strengths:
- The paper effectively tackles significant computational costs associated with training diffusion models, proposing PatchDiffusion as a flexible solution compatible with various diffusion model pipelines.
- The approach enhances generation quality and offers additional benefits beyond reduced computational costs, particularly in scenarios with limited datasets.
- The method is well-organized, with clear motivation and proper ablation studies validating different model components.

Weaknesses:
- Limited experiments and missing important baselines hinder the assessment of performance, particularly as PatchDiffusion shows worse FID scores compared to state-of-the-art methods.
- The writing quality requires improvement, especially in comparing this work with baselines and presenting trade-offs between generation quality and computational costs.
- The algorithm's reliance on a U-Net backbone may limit its efficiency; exploring alternatives like ViT could yield better results.

### Suggestions for Improvement
We recommend that the authors improve the writing quality to better highlight comparisons with baseline methods and include a figure illustrating the trade-off between FID and FLOPs. Additionally, considering a more efficient backbone, such as ViT, could enhance performance, and including comparisons with DiT or U-ViT would strengthen the paper. We suggest conducting an ablation study on different spatial conditioning methods to analyze their effectiveness in the diffusion setting. Furthermore, exploring the potential of generating variable-size images could further demonstrate the framework's benefits. Lastly, addressing the theoretical proof of convergence for patch-wise score matching and conducting experiments on high-resolution image synthesis would provide valuable insights.