ID: CsCRTvEZg1
Title: MISCA: A Joint Model for Multiple Intent Detection and Slot Filling with Intent-Slot Co-Attention
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel framework, MISCA, aimed at enhancing the joint process of multi-intent detection and slot filling tasks. The authors propose an intent-slot co-attention mechanism and a hierarchical label attention mechanism to address issues such as the uncertainty from preliminary intent and slot predictions and the limitations of token-level intent voting. The framework achieves state-of-the-art results on two benchmarks, MixATIS and MixSNIPS.

### Strengths and Weaknesses
Strengths:  
- The motivation for the research is clear, and the experiments are extensive, demonstrating good performance.  
- The architecture is well-elaborated, and the paper is generally easy to read.  
- The proposed framework achieves state-of-the-art results on two datasets.

Weaknesses:  
- The improvement over existing models is marginal, particularly on the MixSNIPS dataset, with only a 0.2% increase.  
- The label attention mechanism appears limited to datasets with hierarchical labels, lacking evidence for its effectiveness in capturing "coarse-grained" label information.  
- The presentation of the co-attention mechanism in Figure 2 and Section 3.3 lacks clarity.  
- The paper exhibits limited technical novelty compared to prior works, and the averaging of accuracies across datasets seems unfounded.  
- The analysis of model validity is weak, and the overall accuracy as a primary comparison metric may not be appropriate.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the co-attention mechanism illustration in Figure 2 and Section 3.3. Additionally, the authors should provide evidence that the label attention mechanism effectively captures coarse-grained label information. It would be beneficial to clarify the purpose of concatenating character-level word embeddings in the Task-shared encoder section. We also suggest adding experiments with MISCA + BERT to strengthen the evaluation, as the current experiments with PLM are limited. Finally, the authors should enhance the analysis of the model's validity and consider addressing the limitations discussed in the paper more thoroughly.