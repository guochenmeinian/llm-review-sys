ID: X9Fga52OOv
Title: FreeLong: Training-Free Long Video Generation with SpectralBlend Temporal Attention
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 5, 5, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents FreeLong, a training-free method for generating extended videos (up to 128 frames) using pre-trained short video (16 frames) diffusion models. The authors propose the SpectralBlend Temporal Attention (SB-TA) mechanism, which fuses low-frequency global video features with high-frequency local features to enhance consistency and fidelity in long video generation. Experimental results indicate that FreeLong outperforms existing methods in video fidelity and temporal consistency.

### Strengths and Weaknesses
Strengths:
1. The research problem is significant, and the paper is well-written and easy to follow.
2. The proposed SB-TA mechanism effectively mitigates high-frequency component degradation, ensuring high-fidelity video outputs.
3. The method supports multi-prompt generation, demonstrating coherent visual continuity and smooth transitions.

Weaknesses:
1. The method can only generate videos up to 128 frames, which does not constitute true long video generation.
2. The related work section lacks clarity for readers unfamiliar with the field, presenting a vague overview of various models.
3. The analysis and experiments are limited to two base models, raising concerns about the generalizability of the proposed method.
4. Inference time comparisons should include both single-pass and multi-pass temporal attention from previous methods to clearly demonstrate advantages.

### Suggestions for Improvement
We recommend that the authors improve the related work section to provide a clearer outline of the research field for readers unfamiliar with it. Additionally, we suggest that the authors validate their method on longer videos, such as generating 1-minute videos, to demonstrate its effectiveness in true long video generation. It would also be beneficial to include comparisons with a broader range of models beyond LaVie and VideoCrafter. Finally, we encourage the authors to conduct a more extensive user study to validate the consistency and quality of the generated videos.