ID: LIsJHQHi4z
Title: Variational Weighting for Kernel Density Ratios
Conference: NeurIPS
Year: 2023
Number of Reviews: 7
Original Ratings: 7, 6, 6, 5, -1, -1, -1
Original Confidences: 3, 2, 2, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an optimized weight function for kernel density estimations (KDE) that reduces bias and enhances estimates of prediction posteriors and information-theoretic measures. The weight function is derived using multidimensional calculus of variations and incorporates first derivatives to mitigate bias from second derivatives. Experiments validate the effective bias reduction achieved with a Gaussian density model, demonstrating that this reduction is independent of model accuracy, thus addressing the traditional bias-variance trade-off. The method consistently improves kernel density estimation despite computational overhead and does not impact the asymptotic convergence rate.

### Strengths and Weaknesses
Strengths:
- The paper introduces a novel approach to KDE that effectively reduces bias and variance, maintaining flexibility in estimation.
- It is well-written, with a solid theoretical foundation and detailed empirical analysis demonstrating improved performance.
- The problem addressed is significant for the machine learning community, and the proposed method is theoretically sound and accessible.

Weaknesses:
- The paper lacks some mathematical rigor and clarity in presentation, with suggestions for structural improvements.
- The computational expense of the proposed method raises questions about performance comparisons with other methods.
- Some minor details need clarification, such as the explanation of symbols and the integration process in equations.

### Suggestions for Improvement
We recommend that the authors improve the paper's structure by adopting a proposition-based approach to enhance clarity and logic flow. Derivations that do not contribute immediately to the main argument should be moved to supplementary material. Additionally, please clarify the causes of underestimation and overestimation in convex and concave regions, and consider including complete representations in figures for better understanding. It would also be beneficial to define all symbols before use and ensure that the assumptions regarding the kernel are clearly stated. Lastly, we suggest improving the quality of figures and using vectorial images for better clarity.