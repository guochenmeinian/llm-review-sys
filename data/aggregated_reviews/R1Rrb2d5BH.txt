ID: R1Rrb2d5BH
Title: EZ-HOI: VLM Adaptation via Guided Prompt Learning for Zero-Shot HOI Detection
Conference: NeurIPS
Year: 2024
Number of Reviews: 20
Original Ratings: 7, 5, 4, 6, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 5, 5, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents EZ-HOI, a framework for zero-shot Human-Object Interaction (HOI) detection that employs prompt learning to enhance the generalizability of Vision-Language Models (VLMs) by integrating guidance from Large Language Models (LLMs). The authors propose the Unseen-class Text Prompt Learning (UTPL) module, which utilizes learnable visual and textual prompts to improve performance on unseen classes, achieving state-of-the-art results with fewer trainable parameters compared to existing methods.

### Strengths and Weaknesses
Strengths:
1. The work is innovative, well-written, and features clear diagrams.
2. The proposed learnable prompts scheme and UTPL module are novel and effectively address the zero-shot HOI detection challenge.
3. The method achieves significant performance improvements while maintaining parameter efficiency.

Weaknesses:
1. The qualitative results, particularly in Figure 4, do not convincingly illustrate the claim that "MaPLe tends to predict seen classes with high confidence scores."
2. The reliance on LLM-generated information raises concerns about potential inaccuracies; the authors should clarify whether they filtered this information to prevent negative impacts on HOI detection.
3. The method's prompt design lacks specificity regarding task configurations, making it difficult to justify its necessity.
4. The performance on unseen classes is reportedly worse than CLIP4HOI, raising questions about the effectiveness of the proposed approach.
5. The paper does not adequately discuss related works that utilize LLMs for new class descriptions, which could provide valuable context.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Figure 4 to better support their claims regarding confidence scores. Additionally, the authors should address the potential inaccuracies of LLM-generated information and detail their filtering process. It would be beneficial to provide a more structured and intuitive explanation of the proposed methodology, particularly regarding the prompt design and its task-specific configurations. We also suggest including experimental results without the pre-definition of all HOI classes during training to allow for a fairer comparison with previous work. Lastly, expanding the discussion on related LLM-based works and providing more visual results could enhance the paper's impact.