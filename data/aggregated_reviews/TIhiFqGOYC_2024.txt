ID: TIhiFqGOYC
Title: Meaningful Learning: Enhancing Abstract Reasoning in Large Language Models via Generic Fact Guidance
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 6, 3, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel framework aimed at enhancing the abstract reasoning capabilities of large language models (LLMs) through a method called "Meaningful Learning" (MeanLearn). It introduces the AbsR dataset, which incorporates generic facts and guided explanations to help LLMs apply these facts in reasoning tasks. The authors identify a significant gap between general and abstract reasoning performance in LLMs and propose their structured approach to bridge this gap, demonstrating improvements across various benchmarks.

### Strengths and Weaknesses
Strengths:
- The introduction of the AbsR dataset and the MeanLearn framework provides a useful resource for studying abstract reasoning in LLMs.
- Empirical evidence from comprehensive experimental results and ablation studies validates the effectiveness of the proposed method, showing improvements in both general and abstract reasoning capabilities.

Weaknesses:
- The paper is poorly organized, with experimental results scattered across sections, making it difficult to follow.
- The methodology lacks sufficient detail, particularly regarding the model's implementation and the use of evaluation metrics like perplexity and AbsAcc.
- Limited comparisons to more recent reasoning techniques and advanced LLMs raise questions about the broader applicability of the findings.

### Suggestions for Improvement
We recommend that the authors improve the organization of the paper by consolidating experimental results and providing a clearer structure. Additionally, the methodology section should be expanded to include more details about the model and its implementation. It would be beneficial to compare MeanLearn with more recent reasoning techniques and advanced models like LLaMA-3 and GPT-4 to better assess its effectiveness. Clarifying the evaluation metrics used, particularly the justification for using perplexity and the definition of AbsAcc, would enhance the paper's rigor. Lastly, updating the related work section to include recent advancements in abstract reasoning would provide a more comprehensive context for the research.