ID: CdSRFn1fVe
Title: Smooth, exact rotational symmetrization for deep learning on point clouds
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 4, 6, 5, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 2, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for integrating rotational symmetries with translational and permutation symmetries in neural networks for point cloud data, particularly focusing on molecular data. The authors propose adding rotational augmentations during training and evaluating the neural network on an ensemble of coordinate systems at test time. Additionally, the paper introduces a posteriori rotational equivariant protocol applicable to existing 3D models, ensuring rotational equivariance while preserving permutation equivariance and expressiveness. The Point Edge Transformer architecture achieves state-of-the-art performance on several benchmarks, demonstrating that exact equivariance is not always essential for certain learning tasks.

### Strengths and Weaknesses
Strengths:
- The incorporation of rotational symmetries into neural networks for atomic data is significant, potentially reducing data requirements and enhancing generalization.
- The innovative approach of using an ensemble of coordinate systems is commendable.
- The proposed protocol allows for the utilization of non-equivariant 3D models, broadening its applicability across various tasks.
- The experimental analysis effectively demonstrates that non-intrinsically equivariant models can outperform their counterparts in atomic applications.

Weaknesses:
- The paper lacks clarity regarding the typical number of coordinate systems and the necessity of using \(y_s\), which increases inference runtime without clear performance benefits.
- The presentation is convoluted, with important details relegated to the appendix, making it difficult to appreciate the contributions.
- There is insufficient discussion on competing methods using rotational augmentations and the performance of state-of-the-art methods on specific datasets.
- The proposed equivariant protocol incurs increased computational requirements and may be sensitive to noise, raising concerns about its robustness.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the presentation by integrating critical details from the appendix into the main text and providing a precise definition of the problem. Additionally, the authors should elaborate on the necessity of \(y_s\) and clarify the computational implications of their method. It would be beneficial to include a comparison of their model with other equivariant models in tasks where equivariance is crucial. Furthermore, we suggest conducting experiments to validate the robustness of the proposed method against noise and exploring its scalability in large point cloud applications. Lastly, addressing the lack of related work on geometric deep learning, particularly group equivariant CNNs, would enhance the paper's context and relevance.