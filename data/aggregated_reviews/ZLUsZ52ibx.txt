ID: ZLUsZ52ibx
Title: Review of Language Models for Survival Analysis
Conference: AAAI
Year: 2024
Number of Reviews: 3
Original Ratings: 5, 6, 7
Original Confidences: 4, 3, 3

Aggregated Review:
### Key Points
This paper presents an exploration of leveraging Large Language Models (LLMs) for survival analysis in medical prognostic and diagnostic applications. The authors propose a comprehensive approach that incorporates embedding, fine-tuning, and prompting strategies, while emphasizing the importance of cross-validation techniques for assessing generalizability across medical institutions. The work addresses the significant challenge of censoring in survival analysis and aims to develop evidence-based recommendations for effectively estimating patient survival outcomes.

### Strengths and Weaknesses
Strengths:
- Comprehensive Approach: The paper provides a thorough overview of LLMs for survival analysis, covering various methodologies and adaptations.
- Practical Contributions: The open-source implementation facilitates experimentation and comparison of different LLM strategies.
- Addressing a Crucial Challenge: The work tackles the challenge of censoring in survival analysis, proposing methods to improve modeling under such conditions.

Weaknesses:
- Lack of Detail: Descriptions of many works lack clarity, making it difficult to draw conclusions.
- Fragmented Recommendations: The recommendation section appears disorganized and could benefit from summarization in the conclusion.
- Brittle Literature Search: The search strategy is inadequate, as it includes titles that do not meet the criteria, suggesting a need for a more robust approach.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the descriptions of prior works to facilitate better conclusions. Additionally, we suggest reorganizing the recommendation section to enhance coherence and summarizing it in the conclusion. The authors should also refine the literature search strategy to ensure it is more robust and consider providing a more descriptive title that indicates this is a review. Furthermore, clarification is needed regarding the findings in the "Fine-tuning: Adjusting LLMs for the task - Limitations" section, the strengths of prompting methods, and the reference to multiple risk scores. Lastly, we encourage the authors to provide updates on the current state of the GitHub implementation and its usability, along with any results from the methods implemented thus far.