ID: gAQCx61chN
Title: SOL: Sampling-based Optimal Linear bounding of arbitrary scalar functions
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 7, 6, 7, 4, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 5, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for upper and lower bounding scalar functions within convex sets using linear functions, particularly applicable to neural networks with general activation functions. The authors propose a sampling-based approach called SOL, which efficiently computes tight linear bounds for Lipschitz continuous functions. The evaluation indicates that SOL achieves comparable performance to the state-of-the-art method LinSyn while requiring significantly less computational time. Additionally, the paper evaluates the SOL method against LinSyn for robustness certification on neural networks, focusing on certification rates and runtimes across various perturbation radii. The results show that SOL achieves comparable or superior certification rates to LinSyn, especially as the perturbation scale increases. The authors also discuss the saturation dynamics of certification rates as the perturbation parameter $\varepsilon$ approaches zero, suggesting that saturation occurs at different thresholds depending on the perturbation scale.

### Strengths and Weaknesses
Strengths:
1. The proposed method is versatile, functioning with various activation functions, unlike existing robust verifiers limited to popular functions like ReLU and Sigmoid.
2. SOL demonstrates similar performance to LinSyn but with reduced computational demands, enhancing efficiency in verification tasks.
3. The evaluation provides clear comparisons between SOL and LinSyn, demonstrating SOL's efficiency in achieving tighter bounds with reduced runtimes.
4. The analysis of saturation dynamics offers valuable insights into the behavior of certification rates across perturbation scales.

Weaknesses:
1. The experimental section lacks depth, as the proposed method does not significantly improve the "fraction of properties certified" compared to LinSyn, suggesting it may merely be a more efficient implementation.
2. The analysis of robustness verification is limited, with insufficient variation in robustness radius and a lack of detailed model descriptions, which hinders the assessment of the method's effectiveness across different architectures.
3. The reliance on non-robust models for evaluation raises questions about the practical applicability of the results, as certified results may not be useful for such models.
4. The claim regarding SOL's performance being unaffected by model geometry lacks supporting evidence and may require further clarification.

### Suggestions for Improvement
We recommend that the authors improve the experimental section by providing a more comprehensive analysis of the "fraction of properties certified" and including comparisons with networks where optimal bounds are known. Additionally, it would be beneficial to explore varying robustness radii to assess the impact on runtime and certification rates. Clarifying the training methods used for the models in Table 1 and including upper bounds on the "fraction of properties certified" would also enhance the robustness of the findings. Furthermore, we suggest that the authors improve the robustness of their evaluation by including additional experiments using robustly trained models to demonstrate the efficiency and efficacy of the proposed method more convincingly. Including the upper bound on the certification rate, defined as the fraction of inputs for which attack algorithms fail to find an attack, would provide a clearer understanding of SOL's performance. Finally, we suggest that the authors provide supporting evidence for the claim that SOL's relative performance is not affected by model geometry, as this would strengthen the paper's arguments.