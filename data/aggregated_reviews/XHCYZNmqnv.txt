ID: XHCYZNmqnv
Title: Detecting Brittle Decisions for Free: Leveraging Margin Consistency in Deep Robust Classifiers
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 5, 7, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for efficiently detecting vulnerable inputs to robust deep classifiers by utilizing the concept of margin consistency, which connects input-space margin and logit margin. The authors define a model as margin consistent if there is a monotonic relationship between input margin and logit margin, allowing for the detection of non-robust samples. Additionally, the authors propose a method for estimating adversarial robustness using logit margins, which is particularly beneficial in scenarios where heavy adversarial attacks or formal verification methods are impractical. The authors outline two applications: estimating empirical robust accuracy from a small dataset subset and real-time identification of vulnerable samples in margin-consistent models without performing actual attacks. The experiments demonstrate that many robust models exhibit high margin consistency, validated through Kendall Tau correlation, and indicate that logit margins can effectively flag non-robust samples, although the method's effectiveness in real-world deployment scenarios remains uncertain.

### Strengths and Weaknesses
Strengths:  
- The paper addresses a significant problem in detecting vulnerable inputs efficiently using logit margin as a proxy for input margin.  
- The development of margin consistency and its application in detecting non-robust inputs is a novel contribution.  
- The method provides a lightweight approach for estimating robust accuracy, which is valuable for large datasets and real-time applications.  
- The experimental section is extensive, exploring various models and metrics, with clear writing and sound mathematical formulation.  
- Empirical results demonstrate the potential of logit margins to identify non-robust samples effectively.

Weaknesses:  
- The correlation observation is not robust enough, as the relationship between input and output margins is not surprising given existing knowledge about Lipschitz networks.  
- The authors do not explore adaptive attacks, leaving uncertainty about the correlation's validity under adversarial conditions.  
- The proof of Theorem 1 lacks precision and clarity, and the rationale for using logit margin over feature-space margin is not fully justified.  
- The method's applicability to adversarial inputs is limited, as it is primarily validated on clean examples.  
- The current results are preliminary, and there is a lack of comprehensive studies across multiple models.

### Suggestions for Improvement
We recommend that the authors improve the theoretical robustness of their findings by providing a more formal analysis of the equidistant assumption in Equation (3) and clarifying the meaning of "values" in Line 640. Additionally, we suggest including experiments with non-adversarially robust models to illustrate the limitations of margin consistency. An exploration of adaptive attacks is crucial; we urge the authors to investigate how such attacks might exploit the proposed method's vulnerabilities. Furthermore, we recommend improving the discussion on the method's limitations regarding its vulnerability to adversarial inputs and the implications of adaptive attacks. Including results on adversarial inputs in the paper's appendices would enhance the understanding of the method's robustness. We also suggest incorporating the applications of estimating robust accuracy using logit margins as motivation in the introduction. Lastly, consider exploring modifications to existing attack algorithms, such as PGD and AutoAttack, to increase output margins, as suggested in the reviews.