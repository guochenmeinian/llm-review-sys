ID: 1FVmMlifl7
Title: How a Student becomes a Teacher: learning and forgetting through Spectral methods
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 7, 7, 6, 6, 5, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 2, 1, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel technique for identifying an invariant subnetwork in a student model that reflects the characteristics of a teacher network, focusing on computing neurons, path distribution, and topological attributes. The authors analyze the performance of a spectral parameterization/regularization scheme in a teacher-student framework, demonstrating that it leads to significant sparsity in the student network while maintaining predictive performance. The results suggest a stable "computational core" within the student network that mirrors the teacher's complexity.

### Strengths and Weaknesses
Strengths:
- The manuscript is well-structured and presents a relevant research topic.
- The authors developed a novel technique for identifying invariant characteristics in student models.
- The paper is generally well-written and accessible, with interesting results regarding sparsity and the computational core.

Weaknesses:
- The empirical experiments are limited, relying on a single synthetic dataset, which raises concerns about the generalizability of the findings.
- There is insufficient reference to related work, and no baselines are considered for comparison.
- Some sections, particularly the path analysis, lack clarity and could confuse readers.

### Suggestions for Improvement
We recommend that the authors improve the empirical evaluation by incorporating multiple datasets, including different synthetic parameterizations and publicly available datasets, to strengthen the results. Additionally, we suggest that the authors provide a more detailed discussion of related work, referencing key literature on model distillation and pruning, such as the works by Liang et al. (2021), Elizondo and Fiesler (1997), and Gou et al. (2021). The authors should also acknowledge the limitations of their research and discuss how these limitations might impact the results, offering insights on addressing them in future work. Furthermore, we encourage the authors to clarify the path analysis section and enhance the clarity of specific terms and phrases throughout the manuscript.