ID: SoM3vngOH5
Title: Tree of Attacks: Jailbreaking Black-Box LLMs Automatically
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 7, 5, 6, 7, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents TAP (Tree of Attacks with Pruning), an automated method for generating jailbreak prompts to exploit vulnerabilities in LLMs. TAP employs a tree-of-thought reasoning approach to iteratively refine and prune candidate prompts, significantly reducing the number of queries needed to successfully jailbreak models like GPT-4. The method enhances the PAIR attack by incorporating branching and pruning techniques, achieving higher effectiveness with fewer queries.

### Strengths and Weaknesses
Strengths:
- TAP optimizes the search for effective jailbreak prompts through tree-of-thought reasoning combined with pruning, requiring fewer queries.
- The method demonstrates effectiveness across multiple LLMs and attack scenarios, successfully jailbreaking most state-of-the-art models for over 70%.
- The attack is strong, using fewer queries than previous work, and the thorough evaluation includes transfer performance and effectiveness against defenses like LLaMA Guard.

Weaknesses:
- The jailbreak evaluation method raises concerns, as LLM autograders for jailbreak success have been shown to be problematic, and skepticism exists regarding the reported 88% success rate against GPT-40.
- TAP's ability to discover novel jailbreaks appears limited, with initialization and prompting playing a significant role.
- The dependence on a powerful evaluator LLM significantly affects performance, with reduced effectiveness when using less capable evaluators.
- The paper's format requires refinement, particularly in Tables 1, 2, and 3, and there are redundancies in content that could be streamlined.

### Suggestions for Improvement
We recommend that the authors improve the evaluation method by addressing the concerns regarding LLM autograders and clarifying the calibration of the judge model. It would be beneficial to include a discussion on the limitations of the jailbreak evaluation method and provide quantitative or qualitative analysis of TAP's ability to find novel jailbreaks. Additionally, we suggest refining the paper's format to eliminate redundancy, particularly by merging overlapping sections, and clarifying the choice of evaluator LLMs to enhance the robustness of the findings. Finally, including evaluations with Llama-3 and Gemma-2 in the final version would strengthen the paper's contributions.