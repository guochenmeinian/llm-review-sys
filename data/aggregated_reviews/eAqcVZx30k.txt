ID: eAqcVZx30k
Title: Is the MMI Criterion Necessary for Interpretability? Degenerating Non-causal Features to Plain Noise for Self-Rationalization
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 6, 7, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to rationalization, focusing on finding explainable support for predictions made by black-box models. The authors propose shifting the focus from extracted rationalization features to residuals, arguing that this change helps suppress spurious features by rendering them indistinguishable from noise. A KL divergence-based criterion is introduced, and empirical results on two datasets—BeerAdvocate and HotelReview—demonstrate the proposed approach's superior performance over existing rationalization methods. Additionally, the paper introduces the MRD (maximizing the remaining discrepancy) criterion, which minimizes the negative KL divergence of label distributions given the input with and without the rational part, achieving promising results across six datasets.

### Strengths and Weaknesses
Strengths:
- Novel formulation for extracting rationalization features.
- Clear and comprehensive presentation, making the paper easy to understand.
- Significant empirical gains on multiple datasets, supporting the proposed methods.
- Open-sourced code promotes transparency and further research.

Weaknesses:
- Insufficient reasoning in Sections 4.1 and 4.2 regarding mutual information and divergence behavior.
- The BeerAdvocate dataset appears to have been retracted, and the HotelReview dataset lacks extensive published results.
- The scope of experiments is narrow, lacking generalization across different data types.
- Inconsistencies in results across tables and insufficient analysis of encoder performance.

### Suggestions for Improvement
We recommend that the authors improve the theoretical exposition in Sections 4.1 and 4.2 to clarify the relationship between mutual information and divergence behavior. Additionally, please address the retraction of the BeerAdvocate dataset and provide references for the HotelReview dataset. To enhance the generalizability of the findings, we suggest conducting experiments on diverse data types, such as images or speech. Furthermore, including a comparison with LLMs as a baseline would help contextualize the proposed method's performance. Lastly, we recommend bolding and underlining the best and second-best results in all tables for consistency and clarity, and providing explanations for the metrics used in the results.