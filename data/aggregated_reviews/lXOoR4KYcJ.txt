ID: lXOoR4KYcJ
Title: Entropy-based Training Methods for Scalable Neural Implicit Samplers
Conference: NeurIPS
Year: 2023
Number of Reviews: 18
Original Ratings: 5, 6, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on learning implicit samplers where the score function is unavailable, making explicit computation of KL or Fisher divergence impossible. The authors propose an alternating procedure to learn a surrogate score for the implicit sampler and minimize divergence with respect to the target. They establish an equivalence between Fisher divergence training and a min-max approach to minimizing Stein's discrepancy, demonstrating the method's effectiveness on standard benchmarks. Additionally, the paper compares neural samplers with MCMC samplers, emphasizing the computational efficiency of the neural sampler, which operates at a computational cost of $\mathcal{O}(n)$ and requires only a single forward pass to generate samples. The authors categorize target distributions into "analytic" and "neural," detailing the computational costs associated with each and providing empirical evidence that neural samplers outperform MCMC samplers in both speed and sample quality across various target types.

### Strengths and Weaknesses
Strengths:  
The article introduces an original application of score-matching methods to implicit samplers, providing a well-motivated and novel procedure with significant general applicability. The sampling application is relevant to a broad audience, and the writing is clear, requiring minimal changes for clarity. The authors effectively demonstrate the computational efficiency of neural samplers compared to MCMC samplers, supported by clear empirical data. The distinction between "analytic" and "neural" targets is well-articulated, enhancing the understanding of the computational challenges involved.

Weaknesses:  
The evaluation of the method focuses solely on sampling accuracy without considering the total cost, including training, which may render comparisons with HMC and SGLD unfair. The paper lacks a thorough comparison with related works that warp target distributions, which could strengthen its competitiveness. Additionally, the empirical evaluation is the weakest aspect, with missing baselines and insufficient details on tuning parameters for competing methods. There is a lack of quantification regarding the training time of the neural samplers, raising concerns about overall efficiency when considering the training phase. Furthermore, the potential computational burden of the Laplacian in high-dimensional spaces is not fully addressed, leaving some ambiguity regarding its impact on performance.

### Suggestions for Improvement
We recommend that the authors improve the empirical evaluation by including comparisons with relevant sampling literature to enhance soundness. Specifically, addressing the performance of HMC and SGLD in terms of total cost would provide a fairer assessment. Clarifying the confusing paragraph on performance and explaining how the FID is mimicked would also strengthen the paper. Furthermore, we suggest including a specific reference when introducing the neural implicit sampler and verifying all citations for accuracy. We also recommend improving the clarity of the training time quantification for neural samplers, as this is crucial for evaluating their overall efficiency. Additionally, addressing the computational challenges associated with the Laplacian in high-dimensional spaces more thoroughly would strengthen the paper's arguments. Finally, we encourage the authors to make their code repository publicly available if the paper is accepted.