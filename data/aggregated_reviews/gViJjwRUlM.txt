ID: gViJjwRUlM
Title: Retrospective for the Dynamic Sensorium Competition for predicting large-scale mouse primary visual cortex activity from videos
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 7, 8, 7, -1, -1, -1, -1
Original Confidences: 4, 4, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a synthesis of results from the 2023 SENSORIUM competition at NeurIPS, aimed at identifying state-of-the-art dynamic models for the mouse visual system. The authors discuss the architectural decisions of the top three winners and the significance of the challenge in advancing machine learning models that predict neural activity in response to dynamic visual stimuli. The dataset is well-documented and designed to require generalization across held-out and out-of-distribution videos.

### Strengths and Weaknesses
Strengths:  
The authors effectively document an impactful challenge that fosters new approaches in neurobiology, with strong baselines reflecting state-of-the-art models. The competition produced novel methods for analyzing neural activity, particularly through diverse architectural approaches, including ViT-based and CNN models.

Weaknesses:  
The analysis primarily emphasizes architectural differences, neglecting the importance of hyperparameter tuning and data processing, which may also significantly influence results. The varying formats of reporting across methods hinder direct comparisons, leaving questions about the completeness of hyperparameter searches and other engineering strategies.

### Suggestions for Improvement
We recommend that the authors improve the depth of comparison across methods by including more detailed discussions on hyperparameter tuning and data processing strategies. Standardizing the reporting format across competitors would enhance clarity and comparability, allowing for a better understanding of the contributions of different design decisions. Additionally, we suggest that the authors provide more insight into how the winning models might inform future research directions in neural decoding.