ID: Ma0993KZlq
Title: Active Classification with Few Queries under Misspecification
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 7, 7, 7, 7, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on active learning of halfspaces under persistent Massart noise, introducing a new query model called "threshold statistical queries" (TSQ). The authors propose an algorithm that achieves polynomial time learning with $O((d \log(1/\varepsilon)^3)$ TSQs, without requiring structural assumptions on the feature distribution. The work demonstrates that while TSQs enable learning under Massart noise, they are insufficient for adversarial noise scenarios. The paper also discusses the implications of these findings in the context of agnostic learning.

### Strengths and Weaknesses
Strengths:
- The paper addresses a relevant theoretical problem in active learning, providing interesting results regarding the efficiency of the TSQ model under Massart noise.
- The TSQ model is a novel extension of existing query types, and the techniques employed for both upper and lower bounds are non-trivial and innovative.
- The writing is clear, with a comprehensive review of related work and a solid discussion on algorithm design.

Weaknesses:
- The label complexity bound in Theorem 1.4 is cubic in both d and log(1/Îµ), and it would be beneficial to explore potential improvements.
- The manuscript lacks a proper conclusion and an overall discussion section on limitations, which could enhance its completeness.
- Some presentation aspects, particularly in algorithm design, could be improved for clarity.

### Suggestions for Improvement
We recommend that the authors improve the conclusion section to provide a more comprehensive summary of the findings. Additionally, including an overall discussion on limitations would enhance the manuscript's depth. We suggest that the authors clarify the intuitive introduction of the algorithm design in section 2, particularly how the strong learning algorithm is constructed from the weak learning algorithm. Furthermore, a frank discussion on the practical execution of TSQs, considering their computational demands, would strengthen the contribution.