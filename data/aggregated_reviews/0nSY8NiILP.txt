ID: 0nSY8NiILP
Title: Tight Bounds for Learning RUMs from Small Slates
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 8, 7, 5, 4, -1, -1, -1, -1
Original Confidences: 3, 4, 2, 2, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper studies the learning of Random Utility Models (RUMs), defined as probability distributions over permutations of a set of elements. The authors focus on learning RUMs given slates of size at most \( k \), establishing that access to winning distributions of slates of size \( O(k) \) is both necessary and sufficient for learning. They present two algorithms: a proper algorithm that constructs a RUM in time \( n^{O(n)} \) and an improper algorithm that runs in time \( n^{O(\sqrt{n})} \), improving the previous best running time for approximating the winning distribution of the full slate. The authors also explore fractional versions of the \( k \)-deck and trace reconstruction problems, leveraging their techniques to derive new results.

### Strengths and Weaknesses
Strengths:  
The paper addresses a significant problem in learning RUMs with a clear formulation and provides a complete solution, identifying the necessary slate size as \( k = O(\sqrt{n}) \). The connections made to existing results in Boolean function approximation are innovative and enhance understanding. The applications to fractional versions of classical problems are noteworthy and could attract interest from researchers in those areas.

Weaknesses:  
The paper's reliance on exponentially large slates for learning RUMs raises practical concerns, as the required query complexity may not be feasible in real-world applications. The introduction could benefit from more context and motivation, and comparisons to prior work, particularly by Chierichetti et al., are insufficiently elaborated. Additionally, the writing quality could be improved, with some technical terms needing clearer definitions.

### Suggestions for Improvement
We recommend that the authors improve the introduction by providing more context and motivation for the problem of learning RUMs. It would also be beneficial to elaborate on how their work compares to prior studies, particularly those by Chierichetti et al. We suggest including additional references related to variations of the \( k \)-deck and trace reconstruction problems to enhance the literature review. Furthermore, we encourage the authors to explore the possibility of developing algorithms that require fewer slates or that can operate effectively in practical scenarios. Lastly, we recommend rigorously demonstrating that the algorithm in Theorem 5 can run with \( 2^{O(n)} \) slates instead of \( n^{O(n)} \) to clarify its practical implications.