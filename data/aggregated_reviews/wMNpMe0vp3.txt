ID: wMNpMe0vp3
Title: A Closer Look at the Robustness of Contrastive Language-Image Pre-Training (CLIP)
Conference: NeurIPS
Year: 2023
Number of Reviews: 19
Original Ratings: 6, 4, 5, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive study of various CLIP models, focusing on their robustness to visual factors, out-of-distribution (OOD) detection, and calibrated uncertainty estimations. The authors analyze 53 CLIP models trained on diverse datasets and architectures, alongside 32 models fine-tuned on ImageNet. The findings reveal that while CLIP models generally exhibit robustness, they are not uniformly superior; for instance, they are less robust than supervised models under certain conditions. The authors highlight the importance of training distribution and other factors in evaluating CLIP's robustness, particularly in OOD detection. They also note that model architecture does not significantly impact performance trends. However, the reviewers express concerns regarding the lack of a central argument, insufficient novelty, and shallow analysis of results, noting that the paper appears to replicate findings from previous studies without providing new insights or actionable conclusions.

### Strengths and Weaknesses
Strengths:
- The paper conducts extensive experiments across multiple models and datasets, providing valuable insights for practical applications.
- The authors propose a focus on safety-driven objectives beyond mere classification accuracy, acknowledging the role of training distribution and other factors in CLIP's robustness.
- The authors provide a thorough response to reviewer feedback, indicating a willingness to improve clarity and accuracy, and plan to enhance visual representations of data.

Weaknesses:
- The paper lacks a clear central argument, appearing more as a collection of experiments rather than a focused analysis.
- Some experimental observations require further support and interpretation, particularly regarding the influence of training data on model performance.
- The novelty of the findings is questioned, as similar studies have been conducted previously, necessitating a more thorough literature review and positioning.
- The analysis of results is deemed shallow, with insufficient depth in discussing the implications of findings, and some statements regarding OOD detection contributions are ambiguous or incorrect.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their central argument and provide deeper interpretations of their findings, particularly regarding the influence of training data on robustness and OOD detection. Additionally, addressing the limitations of their study more explicitly and discussing the implications of their findings in the context of existing literature would enhance the paper's contribution. We suggest including evaluations of image-text retrieval to strengthen the paper's claims about CLIP's capabilities. Furthermore, please clarify the influence of model architecture and contrastive loss on OOD detection, and revise claims about OOD detection contributions to ensure they are supported by new benchmark results. Lastly, we encourage the authors to enhance the depth of analysis and interpretation of results to provide actionable insights, rather than reiterating well-known observations.