ID: Tb7np0MInj
Title: Fast Trainable Projection for Robust Fine-tuning
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 5, 5, 5, 5, 6, -1, -1, -1
Original Confidences: 5, 2, 4, 5, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Fast Trainable Projection (FTP), a novel fine-tuning algorithm designed to enhance the robustness and efficiency of pre-trained models. FTP achieves a 35% speedup compared to prior methods, particularly TPGM, by optimizing layer-wise constraints using the last training batch rather than validation data. The authors provide a theoretical framework based on Lipschitz continuity to explain the robustness of FTP, supported by extensive experiments across various vision tasks.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and presents a clear methodology.
- The proposed FTP algorithm is easy to implement, with provided pseudo code.
- The theoretical analysis is appreciated, and the experimental results demonstrate strong performance across multiple datasets and tasks.

Weaknesses:
- The novelty of FTP is limited, appearing as a direct extension of TPGM, with insufficient justification for its superior performance.
- The ablation study lacks depth, particularly regarding ProjUpdate and Gradient Annealing.
- The method's applicability is primarily confined to vision tasks, raising questions about its effectiveness in other domains like natural language processing.
- The theoretical contributions may be seen as trivial, oversimplifying the complexities of model robustness.

### Suggestions for Improvement
We recommend that the authors improve the novelty aspect by providing a clearer distinction between FTP and TPGM, including a detailed explanation of why FTP achieves better performance. Additionally, we suggest enhancing the ablation study to evaluate the contributions of ProjUpdate and Gradient Annealing more thoroughly. Expanding experiments to include other application areas, such as natural language processing, would also strengthen the paper's impact. Finally, we advise reconsidering the theoretical analysis to ensure it adds substantial value to the understanding of FTP's robustness.