ID: 49IQ5pP0PU
Title: Logic-Aware Knowledge Graph Reasoning for Structural Sparsity under Large Language Model Supervision
Conference: ACM
Year: 2024
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel KG reasoning approach called LoLLM, which integrates Logical Tuning Embedding and Structural Embedding to incorporate logic from large language models (LLMs) into knowledge graph (KG) inference. The authors propose that LoLLM addresses the challenges of sparsity in KGs by providing link prediction and explanations in the form of Horn rules. The experimental evaluation indicates that LoLLM outperforms traditional KG embedding methods and LM-augmented approaches across multiple benchmark datasets.

### Strengths and Weaknesses
Strengths:
- The motivation for the research is well-articulated.
- The writing is clear and logically structured.
- The innovation of integrating logical rules with structural embeddings is noteworthy.
- The experimental results validate the effectiveness of the proposed method.

Weaknesses:
- The overall idea can be confusing, particularly regarding the reliance on LLM-generated similarities without specifying the exact LLM used.
- Performance improvements are not statistically significant, and the comparative experiments are insufficiently conducted.
- The method section lacks comprehensive descriptions, and some settings may be questionable.
- The notion of sparsity is inadequately discussed, raising questions about LoLLM's specific advantages over other approaches.

### Suggestions for Improvement
We recommend that the authors improve clarity by explicitly defining terms such as "reasoning path" and "similarity" and providing a more thorough discussion on the implications of sparsity in KGs. Additionally, we suggest including statistical significance analyses of performance improvements and conducting more comprehensive ablation studies for each component. The authors should clarify the rationale behind using GCN for structural information extraction and consider including traditional datasets like WN18RR in their experiments. Furthermore, we encourage the authors to provide a prompt template for generating textual descriptions of reasoning paths and to address the theoretical underpinnings of the GPT scoring framework to ensure its reliability. Lastly, a detailed comparison with existing logic-based approaches, such as AnyBURL and AMIE, would enhance the positioning of LoLLM within the state-of-the-art.