ID: l974YvnzU5
Title: Investigating LLM Memorization: Bridging Trojan Detection and Training Data Extraction
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 6, 6, 4
Original Confidences: 4, 3, 4

Aggregated Review:
### Key Points
This paper presents a novel technique for measuring memorization in Large Language Models (LLMs) using Mutual Information (MI). The authors introduce a Memorization Score (MS) to identify memorized input-response pairs, aiming to detect both benign and malicious memorization. The approach is validated on two tasks: Trojan Detection using the *llm-pretrain-apr2024* IARPA challenge dataset and Training Data Extraction utilizing the *lm-extraction-benchmark*. 

### Strengths and Weaknesses
Strengths:
- The use of Mutual Information to measure memorization in LLMs is innovative and provides a fresh perspective on model auditing.
- The technique's application to both Trojan detection and training data extraction showcases its versatility and practical relevance.
- The method is grounded in information theory, providing a solid theoretical basis for the proposed Memorization Score.
- The method outperforms baselines in both tasks, indicating its effectiveness.

Weaknesses:
- The paper compares the proposed method against only a few baselines, which may not fully represent the state-of-the-art.
- Some steps in the methodology, particularly the heuristic search for Trojan triggers, lack clarity, hindering reproducibility.
- There is a lack of analysis regarding the sensitivity of the Memorization Score to various parameters.
- A clear threat model for Trojan detection is missing, and the implementation details could be better explained.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the heuristic search for Trojan triggers by providing more detailed explanations and possibly including figures to illustrate the process. Additionally, we suggest that the authors explore combining the Memorization Score with zlib or high-conf for improved results in training data extraction. Testing the methods on different datasets could also provide further insights. Furthermore, a clear threat model for Trojan detection should be included to enhance the robustness of the study.