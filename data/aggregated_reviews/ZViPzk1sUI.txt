ID: ZViPzk1sUI
Title: Structured Semidefinite Programming for Recovering Structured Preconditioners
Conference: NeurIPS
Year: 2023
Number of Reviews: 7
Original Ratings: 6, 8, 3, 7, -1, -1, -1
Original Confidences: 3, 3, 1, 3, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a general preconditioning framework called matrix-dictionary recovery, which utilizes the matrix multiplicative weights update method to address two classes of problems: (1) diagonal preconditioning (outer and inner scaling) with nearly linear time approximation algorithms, and (2) algorithms for graph-structured matrix families, including perturbed Laplacian solvers and recovery of structured matrices like M-matrices and Laplacian matrices. The authors develop a general-purpose solver for the matrix-dictionary recovery problem, significantly improving upon existing methods.

### Strengths and Weaknesses
Strengths:  
- The proposed algorithm for diagonal preconditioners (Theorem 1 and Theorem 2) enhances existing methods by $\text{poly}(d)$ factors when $\kappa_o^\star (\mathbf{K})$ and $\kappa_i^\star (\mathbf{A})$ are small.  
- The framework for solving graph-structured matrices (Theorem 3, 4, and 5) achieves $\widetilde{O}(n^2)$ running time, outperforming state-of-the-art methods with $O(n^\omega)$ complexity.  
- The paper is well-written and comprehensible, making complex concepts accessible.  

Weaknesses:  
- The diagonal preconditioning algorithms improve existing methods by a factor of $\text{poly}(d)$ at the cost of $(\kappa^\star)^{1.5}$, which is applicable primarily when $\kappa^\star$ is small and $\kappa$ is large.  
- The graph-structured matrix algorithms, while achieving $\widetilde{O}(n^2)$ time complexity, are primarily effective for dense inputs, whereas practical scenarios often involve sparse inputs.  
- Section 5 is positioned at the end of the manuscript; presenting comparisons with existing work in the Introduction would clarify contributions and advantages.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the practical implications of their algorithms, particularly regarding implementation feasibility. Additionally, we suggest that the authors address the potential for further optimization of their algorithms for sparse inputs. It would also be beneficial to include a comparison with existing methods in the Introduction to enhance clarity regarding the contributions of this work. Finally, providing proof sketches or hints for the theorems would strengthen the manuscript's credibility and accessibility.