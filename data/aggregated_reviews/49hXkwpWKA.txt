ID: 49hXkwpWKA
Title: AHA: Human-Assisted Out-of-Distribution Generalization and Detection
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 7, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel framework, AHA (Adaptive Human-Assisted OOD learning), designed to enhance out-of-distribution (OOD) generalization and detection by leveraging human-assisted labeling within a maximum disambiguation region. The authors report significant improvements over state-of-the-art methods using only a few hundred human annotations, demonstrating the framework's efficacy through extensive experiments on datasets like CIFAR and PACS.

### Strengths and Weaknesses
Strengths:
- The AHA framework creatively addresses the critical challenges of OOD generalization and detection.
- Extensive experimental results validate the approach, showcasing robust performance across various datasets.
- The strategic incorporation of human feedback maximizes model performance within limited labeling budgets.
- The paper articulates its contributions clearly, particularly the novel labeling strategy and the transformation of the problem into a noisy binary search.

Weaknesses:
- The scalability of the AHA framework with larger and more complex datasets remains unclear.
- The reliance on human annotations may limit applicability in scenarios where such resources are scarce or costly.
- The paper lacks a discussion on the generalizability of findings beyond the tested datasets.
- Computational complexity and runtime performance of the AHA algorithm on large datasets are not addressed.
- Potential biases introduced by human labeling in OOD detection are not considered.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the scalability of the AHA framework with larger datasets and clarify how it handles class imbalance in OOD detection. Additionally, addressing the potential biases in human labeling and providing details on the computational efficiency of the AHA algorithm for large-scale applications would strengthen the paper. We suggest including evaluations on high-resolution datasets, such as ImageNet, to enhance the robustness of the experimental results. Finally, a clearer distinction between active learning and the proposed Human-Assisted Learning would benefit the readers' understanding.