ID: txPdKZrrZF
Title: Fed-FA: Theoretically Modeling Client Data Divergence for Federated Language Backdoor Defense
Conference: NeurIPS
Year: 2023
Number of Reviews: 22
Original Ratings: 7, 5, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel Federated F-Divergence-Based Aggregation (Fed-FA) algorithm aimed at enhancing defenses against backdoor attacks in federated learning for NLP tasks. The authors propose using the f-divergence indicator to estimate data divergences among clients, allowing for the identification and exclusion of suspicious clients. Experimental results indicate that Fed-FA outperforms existing parameter-distance-based methods and demonstrates robustness against adaptive attacks.

### Strengths and Weaknesses
Strengths:
- The paper addresses a critical issue regarding the robustness of federated learning systems against backdoor attacks.
- The Fed-FA algorithm is both novel and theoretically grounded, effectively detecting and removing suspicious clients.
- Comprehensive evaluations, including ablation studies, validate the effectiveness of Fed-FA across various conditions.
- The theoretical analysis supports the advantages of using f-divergence over traditional distance-based measures.

Weaknesses:
- The assumption of independent and identically distributed (IID) data across clients limits the applicability of the method in real-world scenarios.
- The performance of Fed-FA in non-IID cases is less satisfactory compared to IID cases.
- The paper lacks comparisons with state-of-the-art defense algorithms outside the parameter-distance-based category.
- The writing clarity and presentation require improvement, particularly in explaining the unique challenges of defending against backdoor attacks in federated learning.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing to better articulate the unique challenges of backdoor attacks in federated learning. Additionally, the authors should provide further insight into the performance of the f-divergence indicator compared to other divergence measures and elaborate on potential real-world applications of Fed-FA. It would be beneficial to include comparisons with other state-of-the-art defenses, particularly those not based on parameter-distance, and to address the scalability of the approach with an increasing number of clients. Finally, the authors should discuss the computational overhead introduced by the proposed method and analyze the rate of false positives in their defense mechanism.