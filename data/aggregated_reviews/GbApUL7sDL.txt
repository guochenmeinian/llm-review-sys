ID: GbApUL7sDL
Title: Do “English” Named Entity Recognizers Work Well on Global Englishes?
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new dataset for Named Entity Recognition (NER) that encompasses English varieties from regions outside the US and UK. The authors argue that existing NER datasets are predominantly US- and UK-centric, leading to suboptimal performance on English from other global contexts. The dataset comprises 1,075 articles with 674,000 tokens, categorized into regions such as Asia, Africa, Latin America, the Middle East, and Indigenous Commonwealth. The authors demonstrate that models trained on traditional datasets (CoNLL-03 and OntoNotes) perform poorly on this new dataset, while combining training data from both sources enhances performance across all English varieties.

### Strengths and Weaknesses
Strengths:
- The paper identifies a significant gap in NLP regarding non-standard English dialects and provides a novel dataset to address this issue.
- It offers a clear and well-structured presentation, with promising experimental results and insightful error analysis.
- The introduction of a comprehensive ablation analysis highlights the impact of English variants on NER performance.

Weaknesses:
- Critical details about the data annotation process, including the number of annotators and inter-annotator agreement, are lacking.
- The paper does not provide sufficient statistical information about the dataset or discuss ethical considerations related to its collection.
- The analysis primarily focuses on qualitative insights, with a need for more quantitative data to support the findings.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the data annotation process by including details such as the number of annotators per region, their native language proficiency, and measures of inter-annotator agreement. Additionally, we suggest incorporating statistical breakdowns of the dataset across train/dev/test splits and within each region. The authors should also address potential unseen entity issues and domain shifts that may affect model performance, as highlighted in the reviews. Lastly, we encourage a more thorough exploration of strategies for managing English variations beyond the conventional combined training approach.