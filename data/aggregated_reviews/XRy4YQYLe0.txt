ID: XRy4YQYLe0
Title: Aleatoric and Epistemic Discrimination: Fundamental Limits of Fairness Interventions
Conference: NeurIPS
Year: 2023
Number of Reviews: 18
Original Ratings: 4, 6, 7, 4, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 3, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework for understanding discrimination in machine learning by distinguishing between aleatoric (inherent to data distribution) and epistemic (due to modeling choices) discrimination. The authors propose an upper bound on the Fairness Pareto frontier using Blackwell's results, demonstrating its empirical validity across multiple datasets and fairness interventions. The manuscript emphasizes that aleatoric discrimination cannot be mitigated by algorithms, while epistemic discrimination can be reduced through fairness measures. Additionally, the paper explores aleatoric and epistemic uncertainty in the context of fair classification, specifically through the lens of the Bayes optimal classifier and its fair counterpart, FairFront. Aleatoric uncertainty is defined as the irreducible uncertainty inherent in the data distribution, while epistemic uncertainty arises from limited sample size and missing features.

### Strengths and Weaknesses
Strengths:
- The manuscript introduces a novel distinction between aleatoric and epistemic discrimination, enhancing the understanding of bias mitigation limitations.
- It provides the first characterization of an upper bound on the Fairness Pareto frontier, applicable to multi-class and multi-attribute settings.
- The authors offer a clear mathematical framework for differentiating between aleatoric and epistemic discrimination.
- The writing is clear, and the theoretical contributions are well-supported by experiments.
- The discussion on the implications of distribution shifts and their relation to fairness is insightful and relevant.

Weaknesses:
- The terms "epistemic" and "aleatoric" discrimination may lead to confusion and should be reconsidered, as they do not align well with established definitions in uncertainty literature.
- The connection between aleatoric and epistemic uncertainty appears underdeveloped and somewhat handwavy, lacking a solid formal link.
- The paper lacks comprehensive experiments beyond missing data, neglecting other sources of data variability, such as latent noise in measurements.
- The examples provided may not encompass all potential sources of aleatoric uncertainty.
- The presentation is dense, making it difficult to follow; an illustrative example would aid in understanding key concepts.
- The manuscript does not adequately address the implications of approximating the function g, which could limit its applicability to more complex domains.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the manuscript by providing an illustrative example to help build intuition around the theoretical results, particularly Theorem 1. Additionally, we suggest that the authors be more explicit about the limitations of their work, particularly regarding the upper bound characterization and the narrow lens of fairness they adopt. It would be beneficial to clarify the implications of approximating g and its impact on the applicability of the method to complex data types. We also recommend improving the clarity of the relationship between aleatoric and epistemic uncertainty by providing a more formal mathematical linkage, potentially through a parametric equation that incorporates FairFront. Furthermore, we suggest expanding the discussion on the various sources of aleatoric discrimination beyond missing features to include other factors like measurement noise. Finally, we encourage the authors to refine the framing of their critique regarding the use of standard datasets, possibly by including experiments with more complex datasets to better illustrate their points.