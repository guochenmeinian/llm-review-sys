ID: zLU21oQjD5
Title: DART-Math: Difficulty-Aware Rejection Tuning for Mathematical Problem-Solving
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 4, 4, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Difficulty-Aware Rejection Tuning (DART), a method aimed at enhancing the mathematical problem-solving capabilities of large language models (LLMs) by addressing the bias towards easier queries in traditional datasets. The authors propose a rejection sampling technique that allocates more trials to difficult queries, utilizing two strategies, Uniform and Prop2Diff, to ensure balanced representation. The authors claim that models fine-tuned on datasets generated through DART outperform those trained on traditional datasets, with a reported average improvement of 3-4%. Additionally, the paper includes a detailed response to reviewer concerns, featuring new experiments that support the claims made. The authors clarify that the 83.1% coverage from ToRA is not exceptionally high and provide elaborately designed experiments to explain the differences in sampling strategies between ToRA and DART.

### Strengths and Weaknesses
Strengths:
- The DART method effectively mitigates bias towards easier queries, representing a significant contribution to the field.
- The paper provides a thorough analysis of existing dataset biases and explains how DART addresses these issues.
- The authors plan to publicly release their datasets and models, contributing valuable resources to the research community.
- The experiments demonstrate solid improvements over traditional rejection methods.
- The authors have effectively addressed most reviewer concerns and provided additional experiments to support their claims.

Weaknesses:
- The proposed sampling technique is seen as trivial and incremental compared to previous methods, lacking significant innovation.
- The success of DART is contingent on the models' ability to generate correct responses for difficult queries, which may not always be feasible.
- The quality of generated responses for difficult queries is not adequately analyzed, raising concerns about their utility in training.
- The reliance on extensive sampling for difficult queries may pose scalability issues, particularly for large datasets or models with limited computational resources.
- The performance of fine-tuned models using the proposed method is comparable to or worse than the original model, raising questions about the effectiveness of the approach.
- Conducting additional experiments within the limited rebuttal period poses challenges.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their proposed sampling techniques by providing a more detailed comparison with existing methods, particularly addressing the differences with approaches like ToRA. Additionally, we suggest that the authors conduct a thorough analysis of the quality of responses generated for difficult queries to ensure they contribute positively to the training process. Clarifying the hyperparameter tuning process for baseline models and providing a more detailed analysis of topic-wise performance could also enhance the paper's rigor. Furthermore, we recommend that the authors improve clarity on the significance of the 83.1% coverage and ensure that the differences in sampling strategies are thoroughly explained to enhance understanding. Finally, addressing the potential scalability issues of the DART method in practical applications would strengthen the overall contribution of the work.