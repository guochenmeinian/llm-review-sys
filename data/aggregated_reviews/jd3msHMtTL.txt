ID: jd3msHMtTL
Title: Small coresets via negative dependence: DPPs, linear statistics, and concentration
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 6, 8, 6, 7, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 3, 2, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the use of Determinantal Point Processes (DPPs) for constructing coresets in machine learning tasks. The authors demonstrate that DPPs can outperform independently drawn coresets due to linear statistics and better concentration properties. The paper proves concentration inequalities for linear statistics of samples from a DPP, showing that a coreset sampled from a DPP achieves a loss that approaches the full dataset loss faster than uniform sampling. The superiority of DPP samples is illustrated through applications in k-means on toy and MNIST data.

### Strengths and Weaknesses
Strengths:
- The topic of coreset problems is essential in machine learning.
- The paper provides technically solid theoretical results and proper justification for previously observed empirical results.
- It includes a compact introduction to coresets, making it accessible to those unfamiliar with the topic.
- The results generalize beyond the coreset problem and apply to non-symmetric kernels.

Weaknesses:
- The writing can be improved; the numerous theorems and remarks may confuse the main contributions, and some theorems lack explanations regarding their conclusions and applications.
- There is a lack of discussion on coreset literature, such as relevant works by Cohen-Addad et al. (2022) and Huang et al.
- The markers in figures are of different sizes without clear explanations of what they represent.
- The comparison to related work could be more detailed, particularly regarding how it differs from the present results.
- The "stratified" baseline appears stronger than both the uniform and DPP samplers, suggesting that other heuristical methods may be preferable in large-scale applications.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their writing by providing more explanations for the theorems and their implications. Additionally, a more thorough discussion of existing coreset literature would enhance the paper's context. Clarifying the significance of marker sizes in figures and providing a more detailed comparison to related work would also be beneficial. We suggest including a side-by-side comparison of sample complexity with previous works in a tabular format to better illustrate contributions. Finally, we encourage the authors to explore experimental results with various kernel choices, including non-symmetric ones, to strengthen their findings.