ID: yjWVd8Fhqt
Title: OBJECT 3DIT: Language-guided 3D-aware Image Editing
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 6, 5, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on object-centric image editing, focusing on a dataset curated from Objaverse and a diffusion-based model named 3DIT. The dataset comprises 400K examples designed for language-guided 3D-aware image editing, allowing for 3D manipulation of objects. The authors claim that 3DIT outperforms baseline models in both quantitative and qualitative evaluations. The paper also emphasizes the importance of 3D understanding in image editing tasks.

### Strengths and Weaknesses
Strengths:
- The dataset curation using 3D simulation is a significant contribution, ensuring 3D correctness and utility for future research.
- The proposed method demonstrates strong performance compared to baselines, with well-structured experiments and clear presentation.
- The paper effectively shows that the model preserves 3D properties during editing, including shadows and object localization.

Weaknesses:
- The realism of the generated dataset is limited, particularly due to single directional lighting and a restricted size range of objects.
- The model's design primarily follows a 2D approach, leading to issues with maintaining object identity and realistic shadowing during transformations.
- The performance of the proposed model is questioned, with concerns about the quality of edited images and the need for more challenging test data.

### Suggestions for Improvement
We recommend that the authors improve the realism of the dataset by incorporating multiple light sources and a broader range of object sizes. Additionally, we suggest conducting a systematic analysis of failure cases to better understand the limitations of the model. It would also be beneficial to provide a clearer explanation of the training pipeline and the role of the Zero-1-to-3 method in achieving 3D awareness. Lastly, including comparisons with more robust baselines, such as monocular depth estimation models, would strengthen the evaluation of the proposed method.