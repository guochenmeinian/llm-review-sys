ID: RN5KLywTll
Title: What's "up" with vision-language models? Investigating their struggle with spatial reasoning
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an examination of spatial relationships in Vision and Language Models (VLMs), focusing on their understanding of common English prepositions through experiments with three datasets: COCO, GQA, and a novel dataset, RealCLEVR. The authors evaluate 18 pre-trained models, revealing a significant lack of spatial understanding, with most models performing no better than random guessing. The contributions include a new dataset for studying spatial relationships, a comprehensive evaluation of existing models, and insights into the limitations of current approaches.

### Strengths and Weaknesses
Strengths:
- The introduction of a novel dataset that effectively mitigates biases in data distribution.
- A comprehensive evaluation of various VLM architectures, providing valuable insights into their performance.
- Clear writing and detailed experimental descriptions enhance the presentation of findings.

Weaknesses:
- Insufficient explanation of the methodology for collecting human judgments, including details about annotators and their recruitment.
- The paper does not adequately differentiate its contributions from existing literature on spatial understanding, lacking acknowledgment of prior work.
- Limited insightful discussion regarding the implications of results, particularly concerning model capabilities with spatial prepositions.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the methodology section by detailing how human judgments were collected, including information about annotators and their instructions. Additionally, we suggest that the authors provide a more thorough literature review to clearly distinguish their contributions from previous studies, particularly those by Zhang et al. (NAACL2022), Mirzaee et al. (NAACL2021), and Singh et al. (ArXiv 2022). Furthermore, we encourage the authors to enhance the discussion of their results, particularly regarding the implications of model performance on spatial reasoning tasks. Lastly, consider renaming the dataset RealCLEVR to avoid potential confusion with the original CLEVR dataset.