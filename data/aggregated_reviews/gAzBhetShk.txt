ID: gAzBhetShk
Title: Exploring Chain of Thought Style Prompting for Text-to-SQL
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an exploration of enhancing the multi-step reasoning ability of LLMs in text-to-SQL parsing through CoT and least-to-most prompting methods. The authors introduce a new CoT-style prompting method called QDecomp, along with its variant QDecomp+InterCOL, which aims to address error propagation issues associated with existing methods. Empirical evidence supports the improved accuracy of the proposed question decomposition prompting method, and the experimental section provides a thorough analysis of various prompting strategies.

### Strengths and Weaknesses
Strengths:  
- The paper offers significant insights into CoT-style prompting within text-to-SQL parsing, revealing that error propagation is common and iterative prompting may be unnecessary.  
- The proposed question decomposition method shows improved accuracy compared to CoT and least-to-most prompting strategies.  
- The experiments on in-context examples' number, format, and selection strategy are beneficial for future prompting strategy designs.  
- The authors effectively address concerns regarding statistical significance and the impact of different choices in their rebuttal.

Weaknesses:  
- There is a notable performance disparity between the proposed methods and fine-tuned or other LLM-based methods, lacking a detailed comparative analysis.  
- The experimental results exhibit fluctuations, raising concerns about the validity and robustness of the method.  
- The applicability of the proposed methods to datasets beyond the one used is unclear, and the inconsistent impacts of InterCOL need further clarification.

### Suggestions for Improvement
We recommend that the authors improve the comparative analysis by including detailed performance metrics against fine-tuned and other LLM-based methods to elucidate performance differentials. Additionally, we suggest conducting further experiments to validate the robustness of the proposed methods across various datasets and to clarify the inconsistent effects of InterCOL by presenting results focused solely on its performance.