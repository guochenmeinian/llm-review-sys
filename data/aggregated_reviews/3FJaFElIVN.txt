ID: 3FJaFElIVN
Title: GLIME: General, Stable and Local LIME Explanation
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 7, 7, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents GLIME, a new explanation method that generalizes LIME to provide more stable and locally faithful explanations for machine learning models. The authors identify that small sample weights in LIME lead to instability and poor local fidelity, proposing GLIME as a solution with a novel sampling scheme that ensures faster convergence. The paper includes a theoretical analysis and empirical results demonstrating GLIME's advantages over LIME.

### Strengths and Weaknesses
Strengths:
1. The method GLIME is clearly articulated, with strong justification for its development as a successor to LIME, focusing on stability and local fidelity.
2. The rigorous theoretical analysis supports the claims made, and the overall presentation is clear and easy to follow.
3. The paper addresses a significant problem in model-agnostic explanations, potentially establishing GLIME as a standard replacement for LIME.

Weaknesses:
1. The focus on comparing GLIME to LIME limits the exploration of other explanation methods, which could enhance understanding of GLIME's place in the broader research landscape.
2. The empirical evaluation is restricted to the ImageNet dataset, lacking results from additional benchmark datasets.
3. Some theoretical properties of GLIME are not empirically verified, such as the claimed faster convergence compared to LIME.
4. Presentation issues in figures, such as unclear legends and overwhelming inline-math, detract from clarity.

### Suggestions for Improvement
We recommend that the authors improve the discussion on GLIME's shortcomings and outline future work to reinforce the contribution. Additionally, expanding the empirical evaluation to include multiple datasets would strengthen the findings. We suggest providing empirical evidence for theoretical claims, such as convergence speed, and enhancing the clarity of figures by unifying color schemes and addressing presentation issues. Finally, we encourage the authors to explore the human interpretability of GLIME's explanations compared to LIME, as this aspect is crucial for the practical application of model explanations.