ID: Apq6corvfZ
Title: Instance-Optimal Private Density Estimation in the Wasserstein Distance
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 7, 3, 8, 5, -1
Original Confidences: 3, 3, 4, 3, -1

Aggregated Review:
### Key Points
This paper presents a study on differentially private density estimation using the Wasserstein distance, focusing on a non-parametric approach that does not assume a specific distribution. The authors propose algorithms that achieve instance-optimal error, meaning they perform well within a small "neighborhood" around any given input. They explore various definitions of "neighborhood" for distribution estimation in both $\mathbb{R}$ and $\mathbb{R}^2$, extending their algorithm to arbitrary metric spaces with some performance trade-offs. The main contribution is the introduction of instance optimality, which is compared against existing literature.

### Strengths and Weaknesses
Strengths:
- The instance optimal algorithms can significantly outperform traditional methods on specific inputs, and proving their instance optimality is a notable achievement.
- The introduction of instance optimality is a strong conceptual contribution, as it allows for competitive performance against algorithms with prior knowledge of the distribution.
- The writing is clear and well-structured, making the problem well-motivated and easy to follow.

Weaknesses:
- The multiplicative factors in the instance optimality guarantee can be large, raising concerns about their tightness.
- The results appear weak for higher dimensions, and the choice of $n' = n/\text{polylog}(n)$ seems arbitrary.
- The reference estimator's performance evaluation against both the actual and worst-case distributions weakens its effectiveness.

### Suggestions for Improvement
We recommend that the authors improve the tightness of the multiplicative factors in their instance optimality guarantees and provide lower bounds to justify their dependence. Clarifying the conditions under which the approximation factors are derived would also strengthen the paper. Additionally, addressing the performance evaluation of the reference estimator to ensure it does not overly weaken the results would enhance the robustness of the findings. Lastly, including all constants in the algorithms would facilitate practical implementation and understanding.