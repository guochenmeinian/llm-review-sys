ID: lrSrJZZCle
Title: CODA: A Correlation-Oriented Disentanglement and Augmentation Modeling Scheme for Better Resisting Subpopulation Shifts
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 7, 7, 7, -1, -1, -1, -1
Original Confidences: 4, 3, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents CODA (Correlation-Oriented Disentanglement and Augmentation), a framework designed to address subpopulation shifts caused by spurious correlations and group imbalance. The authors propose a correlation-oriented disentanglement method that separates spurious from invariant features using a bi-branch encoder architecture. Additionally, the framework includes a sample augmentation technique that generates synthetic samples through mixing disentangled features, supported by extensive experiments on datasets like ColoredMNIST and CelebA, demonstrating improvements in worst-group accuracy.

### Strengths and Weaknesses
Strengths:  
1. The approach utilizes spurious attributes constructively, transforming them from impediments to useful components.  
2. The disentanglement objective is theoretically motivated and avoids complex density estimation.  
3. The experiments are comprehensive, covering multiple datasets and varying subpopulation shifts.  
4. The method is compatible with existing robust classification techniques such as ERM, RWG, and GDRO.  

Weaknesses:  
1. The reliance on pre-identified spurious attributes may necessitate costly labeling.  
2. Increased computational costs during training due to data augmentation processes.  
3. Limited theoretical analysis of the proposed method.  
4. The qualitative results do not convincingly support the disentanglement, particularly in the CelebA dataset.  
5. The average accuracies in experimental results sometimes do not surpass baseline models, raising questions about the method's effectiveness.

### Suggestions for Improvement
We recommend that the authors improve the theoretical understanding of the disentanglement process, elaborating on how CODA ensures the learned representations are truly disentangled. Additionally, evaluating datasets with more complex spurious information, such as the Waterbird dataset, would strengthen the paper. The authors should also discuss the limitations of binary classification in the latent space concerning transfer learning ability and provide a detailed explanation for the observed performance discrepancies in average accuracies compared to baseline models. Furthermore, quantifying the computational overhead during training compared to standard procedures would be beneficial.