ID: TwrnhZfD6a
Title: Test Where Decisions Matter: Importance-driven Testing for Deep Reinforcement Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 7, 5, 6, 4, 6, -1, -1
Original Confidences: 5, 3, 4, 4, 3, -1, -1

Aggregated Review:
### Key Points
This paper presents a model-based method for testing the safety properties of Deep Reinforcement Learning (DRL) by computing a ranking of state importance across the entire state space, effectively dividing it into safe and unsafe regions. The authors propose an importance-driven framework that enhances testing scalability by focusing on cases with higher importance ranks. The method provides formal verification guarantees and is evaluated across various examples, demonstrating its ability to discover unsafe policy behavior with minimal testing effort.

### Strengths and Weaknesses
Strengths:
- The paper introduces a novel method for ranking state importance, aiding the testing procedure.
- The use of optimistic and pessimistic safety estimates offers a range of expected outcomes.
- The framework is well-structured, and the experiments clearly illustrate its effectiveness.

Weaknesses:
- Some technical details, such as the safety formula $\phi$ and the calculation of $\mathbb{P}_{\mathcal{M}^\pi, \phi}$, require clearer explanation.
- The framework relies on several human-defined thresholds, which need better justification regarding their determination and sensitivity.
- The approach assumes a correct model of the MDP, which may limit its applicability to real-world tasks.

### Suggestions for Improvement
We recommend that the authors improve the clarity of technical details, particularly regarding the formal guarantees provided by IMT, such as probabilistic certification. Additionally, the authors should discuss how human-defined thresholds are determined and their impact on testing results. It would be beneficial to explore the applicability of the framework to continuous state and action spaces and to include comparisons with state-of-the-art DRL testing methods, such as MDPFuzz and STARLA, to better position their contributions within the existing literature. Finally, including experiments on abstract or learned models of the environment would significantly strengthen the paper's impact and utility.