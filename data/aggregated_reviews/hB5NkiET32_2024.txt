ID: hB5NkiET32
Title: Detecting Bugs with Substantial Monetary Consequences by LLM and Rule-based Reasoning
Conference: NeurIPS
Year: 2024
Number of Reviews: 20
Original Ratings: 7, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ABAUDITOR, a hybrid system that combines large language models (LLMs) and rule-based reasoning to detect accounting bugs in smart contracts, particularly in DeFi projects. The authors argue that these bugs can lead to substantial monetary losses, citing that accounting bugs caused $50M in damages in 2024 alone. The system annotates source code to identify relevant parameters and global variables, then applies rule-based reasoning to validate potential vulnerabilities. It achieves a recall of 90.5% on known accounting bugs and reduces false positive rates by 54.5% through a feedback loop for iterative self-reflection. The authors address several critical questions raised by reviewers, including false positives, code snippets, baseline comparisons, and the sensitivity of results to variable names, emphasizing the pressing need for automatic detection of these complex and specific bugs.

### Strengths and Weaknesses
Strengths:
- The methodology effectively combines LLMs and logical reasoning, addressing weaknesses in both approaches.
- The empirical results demonstrate high recall and precision on real-world smart contracts.
- The authors provide a clear rationale for the importance of detecting accounting bugs in DeFi projects, supported by relevant statistics on financial losses.
- The system is computationally inexpensive and does not require manual code annotation, enhancing its usability.
- The authors have conducted new experiments to address reviewer concerns and included these results in their response.

Weaknesses:
- The approach's generalizability is not clearly established, with limited evaluation on new bugs and only six true positive detections.
- The system lacks comparisons with existing bug detection tools, limiting the assessment of its effectiveness.
- The reliance on GPT-3.5-Turbo instead of LLMs specifically trained on code, such as Code Llama or CodeBERT, raises concerns about annotation accuracy.
- The paper has been criticized for its narrow focus on accounting bugs and the use of weaker models in comparisons with baselines.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their approach by providing a more comprehensive evaluation that includes comparisons with existing static analysis and fuzzing techniques. Additionally, the authors should consider utilizing LLMs trained specifically on code to enhance annotation accuracy. Clarifying the derivation of the 119 rules and addressing the scalability of the technique across various programming languages would also strengthen the paper. We suggest that the authors broaden the scope of their study by considering a wider range of smart contract vulnerabilities beyond accounting bugs. Finally, enhancing the comparison with stronger baseline models would strengthen the validity of their findings. Providing more detailed insights into the manual evaluation process and the sensitivity of the LLM's variable annotations to code syntax would also be beneficial.