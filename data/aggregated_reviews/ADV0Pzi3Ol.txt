ID: ADV0Pzi3Ol
Title: Beyond Accuracy: Ensuring Correct Predictions With Correct Rationales
Conference: NeurIPS
Year: 2024
Number of Reviews: 19
Original Ratings: 7, 4, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method termed dual-correct predictions, aimed at training models to make accurate predictions based on correct rationales, thereby enhancing their safety for deployment. The authors introduce a unique dataset containing structured rationales that delineate reasoning processes for visual recognition tasks. The method is evaluated through experiments demonstrating superior performance in prediction accuracy and rationale correctness compared to state-of-the-art models. Furthermore, the paper provides a comprehensive evaluation of the rationale dataset generated by GPT-4, supported by both human and machine assessments. The evaluation metrics included Factual Consistency, Comprehensiveness, and Visual Disentanglement, with results indicating a high degree of alignment between human and machine evaluations, achieving scores of 4.61 or higher across all metrics.

### Strengths and Weaknesses
Strengths:
1. The authors constructed a new fine-grained rationale ontology dataset, offering innovative solutions for generating faithful explanations.
2. The dual-correct method proposed enhances model effectiveness.
3. The rationale dataset is potentially beneficial for future research in rationale methods for ImageNet.
4. Extensive experiments across various tasks, including image classification and retrieval, showcase the method's robustness.
5. The paper provides robust evidence of the rationale dataset's quality through both human and machine evaluations, achieving high average scores across multiple metrics.
6. The strong correlation (Pearson coefficient of 0.82) between machine and human evaluations supports the reliability of the automatic evaluation method.

Weaknesses:
1. Equation 4 lacks sufficient explanation, particularly regarding the correct rationale.
2. An algorithm flowchart to illustrate the training and inference process is absent.
3. The dataset generation method is limited to ImageNet, raising questions about generalizability to other domains.
4. The reliance on GPT-4 for generating gold-label rationales is questionable, given the potential for spurious correlations.
5. Clarity issues exist in the rationale-informed optimization section, and the paper contains typos and incomplete sentences.
6. The reliance on graduate students as human evaluators may introduce bias, as their expertise may not fully represent a broader audience's perspective.
7. The evaluation sample size, while adequate, could be expanded to enhance the robustness of the findings.

### Suggestions for Improvement
We recommend that the authors improve the explanation of Equation 4 to clarify its relationship with the correct rationale. Additionally, including an algorithm flowchart would enhance understanding of the training and inference processes. To address the generalizability concerns, we suggest conducting experiments across other domains and models beyond vision transformers. The authors should also provide a more thorough discussion on the validity of GPT-4 generated rationales and consider incorporating related work from the NLP literature on rationale development. Furthermore, we recommend improving the diversity of human evaluators by including participants with varying levels of expertise to mitigate potential bias. Lastly, we encourage the authors to refine the clarity of the writing, correct typographical errors throughout the paper, and consider increasing the sample size of the evaluation groups to further validate the findings and enhance the generalizability of the results.