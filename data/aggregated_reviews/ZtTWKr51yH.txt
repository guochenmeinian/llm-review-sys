ID: ZtTWKr51yH
Title: Constrained Adaptive Attack: Effective Adversarial Attack Against Deep Neural Networks for Tabular Data
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 5, 7, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents two novel adversarial attack methods, Constrained Adaptive Projected Gradient Descent (CAPGD) and Constrained Adaptive Attack (CAA), targeting deep learning models for tabular data. CAPGD enhances the constrained PGD attack by incorporating adaptive mechanisms, while CAA combines CAPGD with the Multi-Objective Evolutionary Adversarial Attack (MOEVA). The authors demonstrate the effectiveness of these attacks across various datasets and models, showing significant improvements in success rates and computational efficiency.

### Strengths and Weaknesses
Strengths:
- The problem addressed is significant and underexplored compared to adversarial attacks in computer vision and natural language processing.
- The paper is well-structured and presents a comprehensive empirical evaluation, showcasing the superiority of the proposed methods.
- The motivation and rationale behind the algorithms are clearly articulated.

Weaknesses:
- Many techniques and terms used in the methods are not original to this paper, limiting its novelty.
- The description of CAPGD lacks clarity regarding the repair operator's role in ensuring constraint satisfaction.
- The analysis of results is superficial; specific failures of the attacks on certain datasets are not adequately discussed.
- A limitations section is missing, which should summarize the constraints and challenges faced by the proposed methods.
- There are typographical errors and inconsistencies in notation that detract from the paper's clarity.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the CAPGD description by elaborating on the repair operator's role in ensuring constraint satisfaction. Additionally, we suggest enhancing the depth of the results analysis by discussing specific failures and their causes, particularly regarding the CTU dataset. It would be beneficial to include a dedicated limitations section summarizing the constraints of the proposed attacks. Finally, we encourage the authors to correct the identified typographical errors and inconsistencies to improve the paper's overall readability.