ID: uViw1lr2mZ
Title: Understanding Variational Autoencoders with Intrinsic Dimension and Information Imbalance
Conference: NeurIPS
Year: 2024
Number of Reviews: 2
Original Ratings: 6, 7
Original Confidences: 3, 2

Aggregated Review:
### Key Points
This paper analyzes the behaviors of intrinsic dimension, information imbalance, and KL divergence. The authors propose an exploration of hidden VAE representations through geometric properties, building on two previous works with different architectures. The metrics employed are thoroughly explained, and the claims are supported by experiments, although the results are largely empirical.

### Strengths and Weaknesses
Strengths:  
1. The interplays of the measures presented are interesting and may open avenues for new research.  
2. The paper is well written, with clear implementation details for reproducibility, and adequately cites previous works.  
3. The approach, while not entirely novel, offers a new perspective on VAEs that could enhance understanding of the architecture.

Weaknesses:  
1. The results are primarily empirical, and the inclusion of theoretical results would strengthen the paper.  
2. The reliability of the intrinsic dimension estimator used is questionable, particularly in high dimensions.  
3. The choice of geometric properties (II and ID) lacks sufficient justification.  
4. The discussion of limitations is inadequate, and experiments on the MNIST dataset are insufficient; testing on different datasets is recommended.

### Suggestions for Improvement
We recommend that the authors improve the theoretical foundation of their results and provide a more robust justification for the choice of geometric properties. Additionally, addressing the limitations of the work and conducting experiments on different datasets would enhance the validation of their methods.