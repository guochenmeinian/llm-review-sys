ID: xT3i5GS3zU
Title: GSLB: The Graph Structure Learning Benchmark
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 7, 6, 6, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
The paper presents GSLB, a benchmark for graph structure learning (GSL) methods, analyzing 19 datasets across various tasks, including node classification and graph classification. It evaluates the robustness of GSL methods against perturbations and discusses scalability issues. Key contributions include a high-level abstraction of GSL algorithms, exploration of method sensitivity to label counts, and a unified API for fair comparisons. Additionally, the work integrates various self-supervised GSL methods, including SLAPS, STABLE, HES-GSL, and a newly added GSR algorithm. Experimental results are provided for both Topology Refinement (TR) and Topology Inference (TI) scenarios, with detailed performance metrics for multiple datasets. The authors have refined their experimental descriptions and included additional analyses regarding model performance, efficiency, and space consumption. The relationship between model performance and dataset characteristics, such as homophily, is explored, revealing that performance is not always positively correlated with homophily.

### Strengths and Weaknesses
**Strengths:**
1. Comprehensive examination of GSL methods across multiple tasks, including heterogeneous node classification.
2. Robustness analysis of GSL methods adds significant value.
3. Well-organized paper with clear documentation in the GSLB repository.
4. Extensive experiments provide insights into effectiveness, robustness, and complexity.
5. Clear presentation of performance metrics across various datasets and scenarios.
6. Acknowledgment of the need for additional analyses and improvements in the paper.

**Weaknesses:**
1. Limited analysis on design choices and performance metrics.
2. Some datasets are unreachable, and hyperlinks are broken.
3. The paper lacks sufficient insights into differentiating GSL methodologies and their performance across tasks.
4. Lack of inclusion of all evaluated GSL algorithms in Table 4.
5. Insufficient elaboration on the relationship between model performance and dataset characteristics.
6. Inconsistencies in experimental settings across different tables, which may confuse readers.

### Suggestions for Improvement
The authors should perform additional analyses on the design choices mentioned in Table 1, such as identifying which structure modeling techniques and regularizations are most effective. They should also provide justifications for the choice of metrics and encoders, and ensure all datasets are accessible. More implementation details for algorithms like GAT_{knn} and LP should be included. Additionally, the authors should elaborate on the performance of GSL algorithms in relation to heterogeneous Graph Attention Networks and clarify the observations in Table 10 regarding suitable algorithms for specific tasks. Addressing scalability issues with larger datasets, such as ogbn-products, would strengthen the analysis. Furthermore, the authors should improve the clarity and consistency of experimental settings by explicitly explaining discrepancies between tables, particularly regarding the inclusion of STABLE and HES-GSL. Including link prediction tasks in their evaluations would also enhance the analysis, as this is a significant aspect of analyzing graph structures. Finally, providing more detailed analyses of design choices and their impacts on performance would benefit practitioners applying GSL to their own problems.