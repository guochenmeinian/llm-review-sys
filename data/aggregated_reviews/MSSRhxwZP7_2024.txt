ID: MSSRhxwZP7
Title: Learning Disentangled Representations for Perceptual Point Cloud Quality Assessment via Mutual Information Minimization
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 4, 6, 7, 6, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel no-reference quality assessment model for point-cloud data, leveraging a disentangled representation learning strategy to differentiate between content-aware and distortion-aware information. The authors conduct comprehensive experiments across multiple public databases, demonstrating that their method achieves optimal or suboptimal results in most metrics. The ablation study confirms the necessity of each design component.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, with a clear formulation of the approach.
- The proposed framework is novel, and the methodology is well-motivated, particularly the masked auto-encoding strategy.
- The mathematical derivations are detailed and easy to follow, enhancing the understanding of the approach.

Weaknesses:
- The presentation is lacking; many terms are introduced without adequate explanation, and figures, particularly Fig 2 and Fig 5, are poorly designed or contain flaws.
- The idea of separating quality assessment into content-aware and distortion-aware aspects is common in existing literature, and a review of related metrics for 2D data would strengthen the paper.
- There is insufficient discussion on computational complexity, the impact of the number of viewpoints on quality score prediction, and the pretraining details of the content-aware encoder.
- The use of a clean/reference image as a constraint in the masked auto-encoding stage raises concerns about its implications for quality assessment.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the presentation by thoroughly explaining all introduced terms and ensuring that figures are well-designed and free of errors. Additionally, the authors should review related quality assessment metrics for 2D data to highlight differences in implementation. It would be beneficial to include a discussion on computational complexity and the effects of viewpoint numbers on quality predictions. Clarifying the pretraining details of the content-aware encoder and addressing the implications of using a clean image as a constraint in the masked auto-encoding stage would also enhance the paper's rigor. Lastly, making the code publicly available would facilitate collaboration and sharing of this work.