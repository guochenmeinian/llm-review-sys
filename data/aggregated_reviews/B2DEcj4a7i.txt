ID: B2DEcj4a7i
Title: Counterfactually Comparing Abstaining Classifiers
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 4, 6, 7, 5, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for estimating the counterfactual performance of abstaining classifiers, addressing what would occur if they did not abstain. The authors frame this as a missing data problem using causal inference tools, providing estimators for the relevant quantity and proving identifiability under standard conditions. They demonstrate the method's effectiveness through semi-synthetic experiments, showing that the estimator yields good confidence intervals.

### Strengths and Weaknesses
Strengths:
- The paper is clearly presented and technically sound.
- The connection between abstaining classifiers and missing data problems is novel and interesting.
- The application of the missing at random assumption is insightful.
- Experimental results are clear and demonstrate the practical effectiveness of the method.

Weaknesses:
- The motivation for the problem appears unrealistic, with contrived examples that do not convincingly justify the need for the proposed API structure.
- While the connection to causality and missing data is novel, there is a lack of additional novel insights specific to the abstaining classifier problem.
- The counterfactual score is unidentifiable if abstentions are deterministic, limiting its applicability.
- Related works on abstention are not adequately discussed.

### Suggestions for Improvement
We recommend that the authors improve the motivation section by providing more realistic examples that clearly illustrate the relevance of their approach. Additionally, we suggest clarifying how the proposed metric is preferred over simply evaluating the accuracy of selected versus non-selected labels. It would also be beneficial to discuss related works on abstention more thoroughly. Lastly, addressing the lack of other baselines in the experiments could strengthen the paper's contributions.