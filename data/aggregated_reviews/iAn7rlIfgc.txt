ID: iAn7rlIfgc
Title: Explainable and Efficient Editing for Large Language Models
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ECE (Explainable and effiCient model Editing), a novel approach for model editing in large language models (LLMs). The authors propose improvements to the two stages of knowledge editing, addressing limitations of current paradigms by incorporating explainability and enabling batch optimization to reduce computational overhead. The method shows performance gains and speedup in experiments.

### Strengths and Weaknesses
Strengths:
- ECE is more personalized and focused than previous approaches.
- The method addresses critical topics in model editing, such as explainability and efficiency.
- Experimental results demonstrate performance improvements.

Weaknesses:
- The top half of Figure 1 is difficult to understand due to similar colors.
- Figure 7 features a two-column image with a single-column caption.
- The task output in the case study raises questions about optimization with multiple tokens versus a single label.
- The outputs of the model strictly containing labels do not address cases with synonyms.
- ECE's efficiency claims in Table 2 may overlook the time taken for separate forward passes.
- The meaning of "104.87.94s" in Table 2 is unclear.
- The comparison with state-of-the-art models is limited, and some models used are outdated.
- There is a lack of theoretical grounding for the superiority of explainability-driven approaches.
- No code or data is provided for reproducing experiments, and related work is relegated to the appendix.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Figure 1 by using more distinct colors. Additionally, they should ensure that captions correspond to the figures accurately, as seen in Figure 7. To address the confusion regarding task outputs, we suggest clarifying how to optimize model parameters when outputs contain multiple tokens. The authors should also consider including cases where outputs contain synonyms for labels. We recommend providing a more detailed explanation of the time metrics in Table 2 and clarifying the meaning of "104.87.94s." Furthermore, conducting more experiments on larger models (>=13B) and presenting additional case studies on explainability in the main content would enhance the paper. Finally, we urge the authors to include related work in the main text and provide code and data for reproducibility.