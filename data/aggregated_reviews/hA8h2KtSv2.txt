ID: hA8h2KtSv2
Title: Stop Uploading Test Data in Plain Text: Practical Strategies for Mitigating Data Contamination by Evaluation Benchmarks
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a critical examination of data leakage and contamination in closed-source task data, particularly concerning the training of large language models on web-crawled data. The authors propose three countermeasures to address the issue and highlight the importance of this problem as model technologies evolve. They emphasize the need for encryption of test data and caution against evaluating models through APIs without explicit training exclusion options.

### Strengths and Weaknesses
Strengths:  
- The paper addresses a highly relevant issue in the context of large language models and data contamination, making it timely for discussion at major conferences like EMNLP.  
- It provides a thorough review of existing solutions, identifies their inadequacies, and proposes novel approaches.  
- The writing is clear and accessible, enhancing the paper's readability.  

Weaknesses:  
- The work lacks a clear task abstraction or problem definition, and it does not include mathematical expressions or model training details.  
- There is no theoretical or practical validation to support the authors' claims.  
- The proposed solutions, while relevant, are not groundbreaking and may require further refinement.

### Suggestions for Improvement
We recommend that the authors improve the task abstraction and problem definition by incorporating mathematical expressions and model training details. Additionally, we suggest providing theoretical or practical validation for the proposed solutions to strengthen their claims. Addressing the questions raised, such as the implications of encryption on usability and the potential for obfuscation techniques, could enhance the paper's depth. Finally, considering the ethical implications of relying on closed models and the reproducibility challenges associated with data contamination would further enrich the discussion.