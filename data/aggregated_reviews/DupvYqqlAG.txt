ID: DupvYqqlAG
Title: Spectral Learning of Shared Dynamics Between Generalized-Linear Processes
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 5, 7, 7, 5, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new linear dynamical system model designed to capture the interaction between two time series by explicitly modeling their shared and private dynamics. The authors incorporate generalized linear models into their observation framework to accommodate various time series types encountered in neuroscience. They extend standard covariance-based subspace system identification to learn the model parameters and compare their approach against existing baselines using two experimental datasets and a simulation study. Furthermore, the authors distinguish between primary and secondary time series based on their bio-physical interpretations, particularly in the context of neural dynamics and behavior. They propose that the designation of primary/secondary time series reflects a direction of causality, highlighting scenarios such as unidirectional and bidirectional interactions, although they acknowledge that their current model formulation does not accommodate simultaneous bidirectional communication.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, with ideas presented in a clear and logical progression.
- The authors identify a significant gap in the literature regarding the modeling of multiple time series with shared and private dynamics.
- The proposed dynamical system allows for analytical estimation of parameters and shows improved predictive capabilities for one time series based on another.
- The core derivations and empirical results are solid, demonstrating the method's effectiveness in identifying shared dynamics.
- The authors effectively clarify their assumptions and the reasoning behind the primary/secondary designation.
- The discussion of bio-physical interpretations adds depth to the model's applicability in neural dynamics.

Weaknesses:
- The proof regarding the decomposition of matrices into the block form structure is incomplete, requiring a rigorous mathematical justification for the general case.
- Claims about the model's applicability to any generalized-linear process are overstated, as moment conversion equations are only provided for specific distributions.
- The multi-step nature of the algorithm may introduce computational overhead and potential numerical stability issues.
- The model's assumptions regarding the structure of the A matrix and the designation of primary and secondary time series may limit its generalizability and interpretability.
- The current model formulation lacks the capability to handle bidirectional communication simultaneously, which limits its generalizability.

### Suggestions for Improvement
We recommend that the authors improve the proof of the claim regarding the decomposition of matrices into the block form structure by providing a rigorous mathematical proof applicable to the general case. If this cannot be achieved, we suggest modifying the manuscript to clarify that the block diagonal structure is an assumption of the model. Additionally, we ask the authors to tone down their claims about the model's applicability to generalized-linear processes or provide general moment conversion equations for arbitrary exponential family distributions. Furthermore, we encourage the authors to address potential numerical stability concerns associated with the multi-stage algorithm and to discuss the implications of their assumptions regarding the primary and secondary time series more explicitly, considering the potential restrictions on the model's applicability. Lastly, we recommend that the authors explore the possibility of modeling both communication directions simultaneously to enhance the model's applicability and robustness.