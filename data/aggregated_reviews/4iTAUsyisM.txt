ID: 4iTAUsyisM
Title: Data-Dependent Bounds for Online Portfolio Selection Without Lipschitzness and Smoothness
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 7, 6, 7, 6, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 4, 2, 2, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into the online portfolio selection (OPS) problem, focusing on achieving adaptive regret bounds, specifically gradient-variation and small-loss bounds, without the classical no-junk bond assumption. The authors propose a novel optimistic Follow The Regularized Leader (FTRL) algorithm utilizing a self-concordant regularizer, which circumvents the need for Lipschitzness and smoothness assumptions by establishing local norm analogues. The paper introduces three data-dependent bounds: small-loss, gradual-variation, and a second-order bound, which are significant contributions to the field.

### Strengths and Weaknesses
Strengths:
- The paper effectively addresses the OPS problem, providing a comprehensive exploration of data-dependent bounds that are novel and significant.
- The proposed optimistic FTRL algorithm is innovative, facilitating the application of local-norm techniques.
- The writing is clear and well-structured, making complex concepts accessible.

Weaknesses:
- The paper lacks clarity in the application of Theorem 3.2 to the OPS problem, particularly regarding the conditions necessary for its application.
- There are several typos and unclear notations that detract from the technical presentation.
- The relationship between the two data-dependent bounds requires further elaboration, as does the computational efficiency compared to existing algorithms.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the application of Theorem 3.2 by explicitly stating the necessary conditions and mapping the OPS problem to Algorithm 1 more clearly. Additionally, addressing the unclear notations and typos throughout the paper will enhance its technical presentation. We suggest that the authors elaborate on the efficiency of their proposed algorithms in comparison to existing methods, particularly in terms of computational trade-offs, and consider providing a numerical example to illustrate these points. Lastly, we encourage the authors to clarify the implications of their findings regarding the relationship between the gradual-variation and small-loss bounds.