ID: bCW6kFz8fh
Title: FreqMAE: Frequency-Aware Masked Autoencoder for Multi-Modal IoT Sensing
Conference: ACM
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents FreqMAE, a self-supervised learning framework utilizing masked autoencoders for multi-modal IoT signals. The authors propose a method that distinguishes different frequency regions while leveraging cross-modal correlations, aiming to improve performance over recent state-of-the-art baselines. Key contributions include a Temporal-Shifting Transformer for time-frequency signal processing, a factorized multimodal fusion mechanism, and a hierarchically weighted loss function prioritizing significant frequency components and high Signal-to-Noise Ratio samples. The framework is evaluated on various sensor datasets, demonstrating its potential to reduce labeling needs and enhance resilience against domain shifts.

### Strengths and Weaknesses
Strengths:
1. The paper provides a clear explanation of the intuitions and reasoning behind the design choices of FreqMAE.
2. The methodology is grounded in strong mathematical foundations.
3. Comprehensive evaluations on multiple datasets show clear advantages over recent state-of-the-art baselines.
4. The paper is self-contained, offering relevant explanations within the draft.
5. Evaluation on Raspberry Pi 3 illustrates how local attention reduces computational overload on constrained devices.

Weaknesses:
1. The core idea is not novel, as similar approaches have been explored extensively, such as using wavelet transforms with contrastive loss.
2. The paper lacks clarity in certain areas, particularly regarding the private and shared concepts, which require more detailed motivation.
3. Insufficient comparisons with reference [68] hinder a comprehensive understanding of the paper's uniqueness.
4. The writing style is awkward in places, indicating a need for professional editing to enhance clarity.
5. The novelty is somewhat limited, primarily combining existing techniques like MAE, Transformer, and multi-modal fusion.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the private and shared concepts to enhance overall understanding. Additionally, expanding the discussion and comparison with reference [68] would help highlight the paper's uniqueness in the context of similar ideas. We suggest professional editing to address writing style issues and improve clarity, ensuring a smoother reading experience. Furthermore, clarifying terms such as "factorization" would enhance reader understanding and avoid potential misinterpretations. Lastly, the authors should provide insights into how their method compares to existing deep learning techniques for HAR and explore the effects of noise on data performance.