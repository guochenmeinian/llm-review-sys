ID: ZrNRBmOzwE
Title: Data Portraits: Recording Foundation Model Training Data
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 7, 7, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the concept of Data Portraits, a documentation artifact based on membership inferences, aimed at recording training data. The authors propose a specific implementation using Bloom filters to document datasets like The Pile and The Stack, enabling the identification of test set leakage and model plagiarism. The method produces concise summaries of large datasets, facilitating the detection of specific content while being efficient and low-latency. Additionally, the authors advocate for community adoption of these documentation artifacts, emphasizing the need for a minimal and lightweight solution for indexing and membership testing. They argue for the necessity of post-hoc example search capabilities in large language model (LLM) data curation and suggest that Data Portraits should be released alongside new models.

### Strengths and Weaknesses
Strengths:
- Clear motivation for Data Portraits, relevant to current ML research trends.
- Effective application of existing data sketching methods to LLM datasets.
- Low-latency method requiring minimal storage, supporting matching and indexing.
- Well-structured paper with practical applications and a live demo.
- Recognized as a significant contribution to data-centric technology, moving beyond merely presenting a new dataset.
- Viability illustrated through a web interface and new experimental results.
- Grounded in existing community standards, promoting broader adoption of documentation practices.

Weaknesses:
- Limited to Bloom filters without consideration of modern variants.
- Lack of novelty in using Bloom filters for dataset documentation.
- Sensitivity to query strings, requiring long, exact matches for effective membership testing.
- Lack of a publicly available codebase for reproducibility, raising concerns about practical application.
- Insufficient clarity regarding the limitations and intended use of Data Portraits, which could hinder community engagement.
- Potential inconsistency between analyses in Section 4.3 and Section 4.4, which may confuse readers.

### Suggestions for Improvement
We recommend that the authors improve their analysis by comparing their method with modern Bloom filter variants, such as Partitioned Learned Bloom Filters. Additionally, conducting experiments with synthetic datasets to evaluate compression ratios and search speeds across different methods would provide valuable insights. We suggest that the authors ablate the choices of Data Portrait parameters, particularly the impact of different strides on false positive rates and efficiency. Furthermore, we recommend improving the clarity of the documentation associated with their codebase to facilitate community use and addressing the limitations of Data Portraits in the paper to enhance understanding of their applicability. We also suggest reorganizing Section 4 to explicitly describe the distinct aspects of the method's application, thereby clarifying the relationship between the analyses presented in Sections 4.3 and 4.4. Lastly, exploring the release of their method as both a web interface and an easy-to-use library could significantly enhance accessibility and reproducibility.