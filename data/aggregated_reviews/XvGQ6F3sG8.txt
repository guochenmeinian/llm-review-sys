ID: XvGQ6F3sG8
Title: Self-supervised Graph Neural Networks via Low-Rank Decomposition
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 7, 7, 7, 6, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to self-supervised learning in graph neural networks (GNNs) by addressing the limitations of propagation-based encoders, specifically their inability to capture local properties and handle heterophilic networks. The authors propose low-rank decomposition-based GNNs, utilizing low-rank matrix and tensor decompositions to enhance representation learning. They also introduce a tensor-based formulation to incorporate long-distance information from similar ego-networks. Experimental results demonstrate the effectiveness and robustness of the proposed methods against noise, particularly in heterophilic settings.

### Strengths and Weaknesses
Strengths:
- The paper offers a fresh perspective on GNN encoders for self-supervised learning, effectively addressing critical issues associated with propagation-based methods.
- The low-rank decomposition approach successfully captures local structure and enhances performance on heterophilic networks.
- The incorporation of long-distance information is well-executed, improving relationships between original and similar ego-networks.
- Empirical results validate the proposed methods, showcasing their superiority and robustness.

Weaknesses:
- The rationale for how low-rank decomposition-based GNNs preserve local information is not clearly articulated.
- The distinctions between homophilic and heterophilic networks require further clarification.
- The potential for enhancing the model's performance in semi-supervised tasks using node labels is not explored.
- The relationship between the proposed method and existing self-supervised GNNs lacks clarity, particularly regarding the absence of an objective function.
- The presentation contains some unclear descriptions and typographical errors, which detract from the overall clarity.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the explanation regarding how low-rank decomposition preserves local information. Additionally, please clarify the differences between homophilic and heterophilic networks. To enhance the model's applicability, we suggest exploring how the proposed method can be improved in semi-supervised tasks by utilizing node labels. It would also be beneficial to establish a clearer connection between the proposed method and existing self-supervised GNNs, particularly in terms of the objective function. Finally, we advise revising the presentation to address unclear descriptions and correct typographical errors.