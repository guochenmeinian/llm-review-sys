ID: CluDBdRhUp
Title: Probing Representations for Document-level Event Extraction
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach using probing classifiers to analyze embeddings in document-level information extraction (IE) tasks. The authors propose eight probing tasks across three categories: surface, semantic, and event levels. They compare four models on the MUC dataset, examining correlations between probing task accuracies and target task performance. The findings indicate that probing task accuracies evolve during IE task training compared to the untrained BERT-base model. Additionally, the authors explore different encoder constructions, including aggregation methods and layer variations.

### Strengths and Weaknesses
Strengths:
- The introduction of probing tasks for document-level IE is innovative and provides valuable insights.
- The probing tasks are intuitive and the write-up is concise and easy to follow.
- The paper offers empirical results that contribute to understanding event knowledge in pre-trained LLMs.

Weaknesses:
- The empirical results are mixed, making it difficult to draw clear conclusions about explainability.
- The observations are dataset-specific (MUC), raising questions about generalizability.
- The results lack clarity and interpretation in some areas, and the novelty of the work is questioned.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the results and their interpretations to enhance understanding. Additionally, we suggest adding average sentence and document lengths, along with their distributions, to provide context for the findings. It would be beneficial to bucketize the test set by lengths for analysis. Furthermore, we encourage the authors to elaborate on the differences between GTT and BERT, including this discussion in the paper or appendix. Lastly, strengthening the generalizability of the findings beyond the MUC dataset would significantly enhance the paper's impact.