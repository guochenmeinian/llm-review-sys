ID: c4ElkpA0kh
Title: Efficient $\Phi$-Regret Minimization with Low-Degree Swap Deviations in Extensive-Form Games
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 6, 5, 6, -1, -1, -1, -1
Original Confidences: 1, 4, 1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents advancements in the research direction of linear-swap regret in extensive-form games, extending it to low-degree swaps and connecting it to general swap regret. The authors introduce k-mediator deviations, which relate to low-degree polynomials and depth-k decision trees on n>>k variables. A significant finding is that allowing a player to output a probability distribution over strategies is sufficient for computing an approximate fixed point of the deviations in expectation. The main results include algorithms achieving at most $\\epsilon$ average $\\Phi$-regret in $N^{O(k)}/\\epsilon^2$ rounds for various settings, including depth-k deviations and polynomial degree-k deviations.

### Strengths and Weaknesses
Strengths:
- The results effectively bridge the gap between linear swap and arbitrary swap regret.
- The technical contributions highlight the advantages of probabilistic strategies, demonstrating that a fixed point in expectation suffices for optimization.

Weaknesses:
- The results may deteriorate for large $k$, suggesting a "bottom-up" bridging of the gap.
- The presentation lacks clarity, making it difficult to evaluate the significance and novelty of the results. Key motivations and relationships between results are not well articulated.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the presentation, particularly by elaborating on the relationship between their results and previous works. Including a table that compares convergence rates, computational complexities, and required regimes of $\varepsilon$ would enhance understanding. Additionally, we suggest discussing the implications of using k-mediator deviations in relation to low-degree polynomials, as the convergence rate appears to worsen. Clarifying the distinction between mixed strategies and probability distributions over strategies is also essential. Finally, incorporating examples or applications to elucidate the learning protocol would greatly benefit readers unfamiliar with the topic.