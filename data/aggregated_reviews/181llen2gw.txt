ID: 181llen2gw
Title: A Unified Debiasing Approach for Vision-Language Models across Modalities and Tasks
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 6, 6, 7, -1, -1, -1, -1
Original Confidences: 4, 3, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for debiasing Vision-Language Models (VLMs) called Selective Feature Imputation for Debiasing (SFID), which integrates feature pruning and low confidence imputation to effectively reduce biases. The authors propose that this method can be applied across various layers of image and text encoders/decoders and is suitable for multiple downstream tasks, including image generation, zero-shot classification, text-to-image retrieval, and image captioning.

### Strengths and Weaknesses
Strengths:
- The goal of debiasing VLMs is timely and relevant to the NeurIPS community.
- The proposed approach is effective, lightweight, and easy to apply, eliminating the need for costly retraining.
- SFID demonstrates efficacy in mitigating bias across four downstream tasks and does not require extensive hyperparameter tuning.

Weaknesses:
- The writing contains minor grammatical errors and could benefit from additional editing.
- The structure of section 3 is confusing, mixing background material with experimental setup details.
- The experimental results lack confidence intervals, which should be calculated even for deterministic methods.
- The comparison with only two other debiasing approaches limits the evaluation of the proposed method's novelty.
- The method primarily focuses on gender bias, neglecting other complex biases such as race or age.
- The limitations of using Random Forest for feature importance are not adequately addressed.

### Suggestions for Improvement
We recommend that the authors improve the writing quality by addressing grammatical errors and restructuring section 3 to separate background information from experimental details. Additionally, the authors should include confidence intervals in their results, particularly for the text-to-image generation experiment, and broaden the comparison to include more existing debiasing methods, especially Chuang et al.'s approach. A more comprehensive discussion of limitations should be added, focusing on fundamental issues beyond experimental performance, such as the assumption of access to a labeled validation set for bias attributes. Lastly, we suggest exploring how identified features correlate with social biases, potentially using visualization tools.