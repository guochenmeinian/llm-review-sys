ID: zzOOqD6R1b
Title: Stress-Testing Capability Elicitation With Password-Locked Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 8, 7, 5, 5, -1, -1
Original Confidences: 4, 3, 3, 4, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on eliciting hidden capabilities from language models (LLMs) through fine-tuning, specifically using a password-locked model setup. The authors investigate whether fine-tuning and reinforcement learning (RL) can unlock capabilities that are otherwise concealed unless a password is provided in the prompt. The findings indicate that with sufficiently high-quality demonstrations, fine-tuning and RL can effectively elicit these capabilities, while poor demonstrations are insufficient.

### Strengths and Weaknesses
Strengths:  
- The paper addresses a significant concern in safety research regarding capability elicitation, with the password-locking scenario providing a novel framework for study.  
- The experimental methodology is robust, exploring various fine-tuning and RL approaches, and the results are presented clearly.  
- The framing of the problem is compelling, drawing parallels to backdoor detection while introducing unique constraints.

Weaknesses:  
- The technical contributions are somewhat limited, as password-locking may not accurately model more complex threat scenarios.  
- The motivation for studying password-locked models could be clearer, and the reliance on prior work for experimental design explanations detracts from the paper's originality.  
- Alternative elicitation methods, such as prompt optimization and few-shot prompting, are not adequately explored.  
- The nomenclature used throughout the paper can be confusing, and the connection to neural backdoors needs further clarification.

### Suggestions for Improvement
We recommend that the authors improve the motivation for using password-locked models and clarify their relevance to real-world scenarios. Additionally, the authors should explore alternative elicitation techniques, such as prompt optimization and few-shot prompting, to provide a more comprehensive analysis. It would also be beneficial to simplify the nomenclature for better clarity and to explicitly address the applicability of backdoor removal methods in this context. Lastly, we suggest including a straightforward baseline for capability elicitation that does not involve modifying model weights.