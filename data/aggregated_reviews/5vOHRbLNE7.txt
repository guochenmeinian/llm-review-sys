ID: 5vOHRbLNE7
Title: HierarchicalContrast: A Coarse-to-Fine Contrastive Learning Framework for Cross-Domain Zero-Shot Slot Filling
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a hierarchical contrastive learning method aimed at addressing the domain shift problem in cross-domain zero-shot slot filling. The authors propose using Gaussian embeddings to enhance the representation of token features and conduct extensive experiments demonstrating state-of-the-art performance. The paper also identifies the issue of poor generalizability in existing methods for unseen target domains and introduces innovations such as token-level contrastive learning alongside entity-level contrastive learning.

### Strengths and Weaknesses
Strengths:
- The proposed framework achieves state-of-the-art performance and includes comprehensive ablation studies that convincingly discuss the impact of various components.
- The introduction clearly outlines the problem and different paradigms of zero-shot slot filling, making it accessible to non-experts.
- The innovative idea of incorporating token-level contrastive learning is well-explained and supported by strong experimental results.

Weaknesses:
- The method section lacks clarity, with several descriptions being difficult to follow, particularly regarding loss computation and entity-level representations.
- The presentation is somewhat rough, with important results relegated to the appendix and tables/figures being too small for clear interpretation.
- There is a lack of MRC-based slot filling baselines and missing citations for borrowed concepts, which undermines the paper's rigor.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the method section, particularly in explaining how to compute loss and obtain entity-level representations. Additionally, we suggest reorganizing the paper's structure to integrate key results into the main text rather than the appendix. The authors should also ensure that all relevant citations are included, particularly for the contrastive loss methodology. Finally, resizing tables and figures for better visibility and revising long sentences for clarity would enhance the overall presentation.