ID: deXcOn4ScH
Title: Hi-fi functional priors by learning activations
Conference: NeurIPS
Year: 2024
Number of Reviews: 2
Original Ratings: 7, 6
Original Confidences: 3, 3

Aggregated Review:
### Key Points
This paper presents a novel approach to learning activation functions by minimizing a loss function between the GP probability and the NN probability. However, it lacks a discussion on how this approach compares to prior works that integrate domain knowledge, such as Dylan Sam et al.'s Bayesian Neural Networks with Domain Knowledge Priors. Additionally, the paper does not address how this approach scales with respect to the size of the input space.

### Strengths and Weaknesses
Strengths:
1. The paper is well organized, and the presentation is good.
2. The theoretical contribution of this paper is sufficient, which is a bright spot.

Weaknesses:
1. If more experimental results in the appendix can be added to the main text, the experimental part will be more complete.
2. The summary of the full text seems to be missing at the end of the paper.
3. The investigation of previous studies in the relevant work section is insufficient.

### Suggestions for Improvement
We recommend that the authors improve the discussion on how their approach compares to prior works that integrate domain knowledge. Additionally, the authors should address the scalability of their approach concerning the size of the input space. To enhance the completeness of the experimental section, we suggest incorporating more experimental results from the appendix into the main text. Finally, we advise the authors to include a summary of the full text at the end and to conduct a more thorough investigation of previous studies in the relevant work section.