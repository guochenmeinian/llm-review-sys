ID: 2ioRi2uwLR
Title: Neuro-symbolic Learning Yielding Logical Constraints
Conference: NeurIPS
Year: 2023
Number of Reviews: 7
Original Ratings: 7, 7, 7, 5, -1, -1, -1
Original Confidences: 3, 3, 1, 3, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel neurosymbolic approach that integrates neural network training, symbol grounding, and logical constraint synthesis, utilizing cardinality constraints and a DC penalty for constraint relaxation. The authors derive an efficient training algorithm through multiple minimization steps and demonstrate that their method outperforms state-of-the-art models, including SATNET and L1R32H4, on challenging tasks. The paper includes proofs of convergence and optimality, although it lacks a clear evaluation of the interpretability of the learned logical constraints.

### Strengths and Weaknesses
Strengths:
- The paper addresses the complex problem of simultaneously learning rules and perceptions, achieving strong performance on difficult tasks.
- The methodology introduces original components, such as the DC relaxation loss and cardinality constraints, enhancing the numerical learning framework.
- The theoretical aspects are well-supported by proofs in the appendix, and the results show significant improvements over existing neurosymbolic approaches.

Weaknesses:
- The presentation is hindered by technical complexities that obscure the high-level understanding of the method, including reliance on various optimization techniques and numerous hyperparameters.
- The introduction of the hyperparameter alpha complicates computations without clear justification for its necessity.
- The paper lacks a limitations section, and the evaluation of the interpretability of the learned constraints is insufficient.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the presentation by including more high-level figures to illustrate the logical constraints and their enforcement. Additionally, we suggest that the authors discuss the limitations of the cardinality-based logical constraints in the main paper rather than relegating this to the appendix. It would also be beneficial to evaluate the interpretability of the learned constraints and address the questions regarding the SMT solver's role, the use of cross-entropy for the $\ell_1$ loss, and the justification for the hyperparameter alpha. Lastly, we encourage the authors to clarify the choice of tasks and their applicability to different domains.