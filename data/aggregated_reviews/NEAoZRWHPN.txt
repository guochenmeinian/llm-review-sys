ID: NEAoZRWHPN
Title: Large Language Models for Constrained-Based Causal Discovery
Conference: AAAI
Year: 2023
Number of Reviews: 4
Original Ratings: 2, 1, 3, -1
Original Confidences: 2, 3, 2, 3

Aggregated Review:
### Key Points
This paper presents an exploration of using large language models (LLMs) as conditional independence (CI) testers, proposing an alternative to traditional expert knowledge. The authors integrate their LLM-based CI tester within the PC algorithm to construct causal graphs from various datasets, demonstrating that this approach can yield reasonable performance under certain conditions.

### Strengths and Weaknesses
Strengths:
- The paper sufficiently discusses all relevant related work.
- The authors effectively describe their method and enhance its robustness through hypothesis testing.
- Empirical evidence supports the viability of the proposed approach under appropriate circumstances.
- The application of the method to real-world scenarios is both interesting and significant.

Weaknesses:
- There is a lack of comparison with classical methods like PC and GES in the empirical evaluation, which would enhance the paper's quality.
- Minor inaccuracies in the description of the output graph and the characterization of state-of-the-art methods in causal discovery.
- The methodology lacks formalization, particularly regarding the computation of p-values, which hampers the interpretation of results.

### Suggestions for Improvement
We recommend that the authors improve the formalization of their methodology, particularly by clarifying how the p-value is computed and considering a Bayesian framework for their hypothesis test. Additionally, we suggest including comparisons with classical methods such as PC and GES to strengthen the empirical evaluation. Addressing the robustness and reliability of the causal graphs derived from LLMs is crucial; exploring the use of soft constraints rather than hard constraints could enhance the reliability of the causal discovery algorithm. Furthermore, a discussion on the variability of results based on different prompts and LLMs, as well as the potential benefits of fine-tuning, would provide valuable insights. Lastly, we encourage the authors to explore the performance of their approach across different domains to identify where LLMs may be most effective.