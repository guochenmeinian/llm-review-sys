ID: IEH9YsR5Ty
Title: mAggretriever: A Simple yet Effective Approach to Zero-Shot Multilingual Dense Retrieval
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents mAggretriever, an extension of Aggretriever for multilingual retrieval, proposing two computationally efficient strategies: target-language prediction and self prediction. These methods aim to alleviate the computational cost associated with large multilingual vocabulary spaces. Experiments demonstrate that mAggretriever outperforms existing state-of-the-art multilingual dense retrieval models, achieving competitive results while reducing training and inference costs.

### Strengths and Weaknesses
Strengths:
- The proposed method is straightforward and enhances both efficiency and effectiveness in multilingual retrieval.
- Extensive and thorough experimental methodology, providing valuable insights and discussions.
- The study extends Aggretriever's scope from monolingual to multilingual scenarios, which is a significant contribution.

Weaknesses:
- The motivation for the Aggretriever-like design appears limited to specific approaches requiring lexical representation.
- Comparisons are not entirely fair, focusing solely on Aggretriever-based methods, neglecting other models like mDPR/mContriever that do not face similar efficiency challenges.
- Results on the MS-MARCO dataset are not particularly high, potentially due to the absence of mined hard negatives.
- Some notations are undefined, leading to confusion, and certain assumptions made in the paper may not hold in real-world scenarios.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the self prediction section, particularly regarding whether it employs a bag-of-words representation without learned term weighting. Additionally, we suggest providing insights into the observed performance gap in recall and including a comprehensive comparison of computation cost and inference latency with baselines such as mContriever and mDPR, specifically focusing on GPU usage and retrieval latency. Finally, we advise clarifying abbreviations like "tg" (target) and "wp" (word piece) to enhance reader understanding.