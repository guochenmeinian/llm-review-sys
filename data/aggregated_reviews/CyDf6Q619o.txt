ID: CyDf6Q619o
Title: Enabling Unsupervised Neural Machine Translation with Word-level Visual Representations
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, 3

Aggregated Review:
### Key Points
This paper presents a novel multi-modal unsupervised neural machine translation (UNMT) method that utilizes word-level images to enhance translation accuracy and reduce lexical confusion. The authors propose an image fusion technique within the Transformerâ€™s embedding layer and compile a dataset of 300K images for experimentation. Additionally, they introduce a visible matrix to strengthen the relationship between images and words.

### Strengths and Weaknesses
Strengths:
- The paper addresses the significant issue of lexical confusion in UNMT and offers a straightforward solution using word-level images.
- It features a comprehensive experimental setup, demonstrating consistent improvements over text-only and multimodal baselines.
- The large-scale word-image dataset can facilitate further multimodal NLP research.

Weaknesses:
- The comparison with baselines is unfair, as the authors utilize high-quality pre-trained models while baselines do not. The self-collected images also differ from those used in other studies.
- There is a lack of an ablation study to clarify the role of word-level images, and the results of random image selection raise questions about the methodology.
- The reliance on search engine results introduces potential biases, and the selection criteria for images lack justification.
- The paper does not adequately explore the impact of image quantity and quality on translation outcomes or compare its method with other relevant approaches.

### Suggestions for Improvement
We recommend that the authors improve the justification for their image selection process and clarify how they handle noisy or irrelevant images. Additionally, conducting an ablation study to demonstrate the specific contributions of word-level images would strengthen their claims. The authors should also consider addressing ethical concerns related to image sourcing and explore the scalability of their approach to different words and contexts. Finally, a more thorough comparison with existing methods that utilize word-level images could provide valuable insights into the advantages and limitations of their approach.