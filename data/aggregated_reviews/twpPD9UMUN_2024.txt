ID: twpPD9UMUN
Title: Look, Listen, and Answer: Overcoming Biases for Audio-Visual Question Answering
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 8, 5, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents significant contributions to the field of Audio-Visual Question Answering (AVQA) by introducing the MUSIC-AVQA-R dataset and associated evaluation metrics, which are essential for assessing AVQA models' reasoning capabilities and generalization. The authors propose a novel AVQA architecture that employs the multifaceted cycle collaborative debiasing (MCCD) strategy to address training biases, marking a systematic approach to bias mitigation in AVQA tasks. Extensive experiments on both MUSIC-AVQA and MUSIC-AVQA-R demonstrate the effectiveness of the proposed architecture and debiasing strategy, revealing limitations in existing multimodal QA methods regarding generalization.

### Strengths and Weaknesses
Strengths:
- The introduction of the MUSIC-AVQA-R dataset allows for fine-grained evaluations and encourages community engagement in enhancing model robustness through debiasing strategies.
- The proposed MCCD strategy effectively addresses biases in AVQA tasks from both model evaluation and design perspectives.
- Extensive experiments provide robust evidence supporting the architecture and MCCD strategy's effectiveness, as shown in the results of Tables 1, 2, and 3.
- The authors evaluate 13 multimodal QA methods, highlighting their limited generalization capabilities.

Weaknesses:
- The dataset's evaluation metrics could be improved to assess how well models predict within the rephrased question group, suggesting a need for more fine-grained evaluation metrics.
- The single-word answers in MUSIC-AVQA-R may not reflect real-world scenarios, necessitating a discussion on how to generate more realistic multi-word answers.
- There is a lack of detailed bias type categorization in the dataset, raising questions about how to address this limitation.
- Concerns regarding the dataset's quality and the need for a clearer demonstration of distribution differences between training and testing sets.
- The novelty of the proposed solution is questioned, as existing methods for mitigating modality bias in VQA have been established, and the authors should clarify the theoretical basis for their approach.

### Suggestions for Improvement
We recommend that the authors improve the evaluation metrics to allow for a more nuanced assessment of model performance on the rephrased question group. Additionally, consider generating multi-word answers to align better with real-world scenarios. We suggest providing a more detailed categorization of bias types within the dataset to enhance its utility. Furthermore, the authors should clarify the distribution differences between the training and testing sets to validate the dataset's robustness. Lastly, we encourage the authors to elaborate on the theoretical foundations of their proposed method and compare it with existing debiasing strategies to establish its novelty and effectiveness.