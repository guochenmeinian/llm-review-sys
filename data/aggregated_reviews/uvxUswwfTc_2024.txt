ID: uvxUswwfTc
Title: Retention Score: Quantifying Jailbreak Risks for Vision Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 2
Original Ratings: 7, 7
Original Confidences: 3, 4

Aggregated Review:
### Key Points
The authors propose a Retention Score to evaluate jailbreak risks in vision-language models, utilizing diffusion models to generate additional samples and measure toxicity margins for robustness assessment. This method offers a faster evaluation compared to traditional adversarial attacks. The authors introduce a multimodal framework, *RetentionScore*, which provides a conditional robustness certificate against jailbreak attempts from both visual and textual inputs.

### Strengths and Weaknesses
Strengths:
- The topic is highly relevant given the widespread use of large language models.
- The authors provide a detailed explanation of their experiments.
- The work explores both image and text attacks, broadening the scope of robustness evaluation.

Weaknesses:
- Some writing and presentation aspects are difficult to follow, particularly the premature introduction of terms like "Retention-I" and "Retention-T" before their explanations. The emphasis on time efficiency is also brief, with a small illustrative figure.
- The paper does not address a critical assumption regarding the model's inherent toxicity, raising questions about the applicability of the ASR in demonstrating robustness.
- The Retention Score results require further discussion, as discrepancies in scores and ASR values raise concerns about the metric's reliability.
- The claim that optimization-based attacks are impractical lacks sufficient evidence, and the computational intensity of the pipeline is not adequately justified.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their writing by defining terms like "Retention-I" and "Retention-T" earlier in the paper. Additionally, a more comprehensive discussion on time efficiency and a larger figure illustrating this aspect would enhance understanding. The authors should address the assumption of model toxicity and clarify how the ASR can demonstrate robustness in such cases. Furthermore, a detailed analysis of the Retention Score results is necessary to establish its reliability. Lastly, we suggest providing evidence to support the claim regarding optimization-based attacks and clarifying the computational requirements for generating RetentionScores and robustness certificates.