ID: 9lGJrkqJUw
Title: Score-based 3D molecule generation with neural fields
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 6, 7, 7, 7, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the FuncMol model for molecular generation, leveraging continuous space neural fields and joint training of a molecular neural field with modulation codes. The model employs a neural empirical Bayes technique for generating new molecular structures during inference. Performance is evaluated against established neural baseline models on the GEOM-DRUGS dataset and the CREMP dataset for macrocyclic peptides, demonstrating competitive results and fast sampling capabilities.

### Strengths and Weaknesses
Strengths:
- The use of continuous space neural fields for molecular generation is a novel and unexplored approach.
- The model's training on both the GEOM and CREMP datasets contributes significantly to the peptide generation domain.
- The representation of 3D molecular structures as atom occupancy fields enhances expressivity and scalability.

Weaknesses:
- The experimental analysis is incomplete, lacking several baselines and thorough ablation studies to justify hyperparameter selections.
- The model does not outperform existing methods like VoxMol and GeoLDM in many metrics, indicating potential trade-offs between generative ability and representation quality.
- The approach shows issues with generating unique molecules, raising concerns about overfitting and the effectiveness of the modulation code space.

### Suggestions for Improvement
We recommend that the authors improve the experimental analysis by including additional baselines, such as MolDiff and RINGER, to provide a more comprehensive evaluation of the model's performance. It is crucial to conduct thorough ablation studies to justify hyperparameter choices and explore the model's limitations in depth. We also suggest extending the analysis to include conditional generation scenarios, such as conformation generation and pocket-conditioned generation, to demonstrate adaptability. Furthermore, clarification on the methods used to address the lack of SE(3) equivariance and the impact of different discretization steps on model performance and computational speed would be valuable. Lastly, we encourage the authors to provide quantitative results for the CREMP dataset to substantiate claims of scalability.