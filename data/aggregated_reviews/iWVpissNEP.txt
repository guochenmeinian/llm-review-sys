ID: iWVpissNEP
Title: Towards Building More Robust NER datasets: An Empirical Study on NER Dataset Bias from a Dataset Difficulty View
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a thorough analysis of dataset bias in named entity recognition (NER), introducing V-information for measuring individual and dataset difficulty and context-entity information margin (CEIM) for assessing difficulty differences between entity- and context-level instances. The authors find that lexical information of entities is easier to learn than contextual information, leading to shortcut learning by models. They propose methods to reduce this learning difficulty by adjusting the training data, which improves baseline model performance in robustness tests on NER benchmark datasets.

### Strengths and Weaknesses
Strengths:
- The analysis methods, V-information and CEIM, are novel in the NER field and technically sound.
- The study is well-supported by relevant literature and comprehensive experiments, providing interesting results, particularly on out-of-domain test sets.
- The paper offers potential solutions to de-bias NER datasets, demonstrating effectiveness through experimental results.

Weaknesses:
- The presentation quality requires improvement, with numerous typos and grammatical errors throughout the manuscript.
- The novelty of the conclusions is limited, as they align closely with existing findings in the field.
- Some terms and concepts are not clearly defined, leading to potential confusion regarding the paper's contributions.

### Suggestions for Improvement
We recommend that the authors improve the presentation quality by thoroughly reviewing and revising the manuscript to correct typos and grammatical errors. Specifically, clarify terms such as "data bias" and "entity-context distribution" to enhance understanding. Additionally, consider addressing the second type of error ("ambiguous entity") discussed in Figure 1 and ensure that all figures and tables are appropriately sized for readability. Finally, we suggest incorporating newer datasets like FewNerd to strengthen the relevance of the experiments and exploring the performance of the proposed data augmentation methods with larger instance counts to assess potential diminishing returns.