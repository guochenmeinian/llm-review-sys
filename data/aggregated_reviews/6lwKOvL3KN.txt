ID: 6lwKOvL3KN
Title: Adaptive Visual Scene Understanding: Incremental Scene Graph Generation
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 3, 6, 6, -1, -1, -1
Original Confidences: 4, 4, 3, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new task, Continual Scene Graph Generation (CSEGG), requiring scene graph generation (SGG) models to adaptively recognize new objects and relationships. It introduces a benchmark with three learning regimes: relationship incremental, scene incremental, and relationship generalization. The authors propose a learning method called Replays via Analysis by Synthesis (RAS), which utilizes textual triplets to synthesize new images for model training. Performance evaluations indicate effectiveness, although the significance of CSEGG compared to existing methods is questioned.

### Strengths and Weaknesses
Strengths:
1. The paper is clear and easy to understand.
2. The effectiveness of key components has been verified.
3. The scenarios and benchmark experiments using both transformer-based and CNN-based backbones are exhaustive, with RAS outperforming baselines in two scenarios.

Weaknesses:
1. The significance of CSEGG is limited; training for new categories is unstable due to data, hyperparameters, and hardware requirements. The advantages of CSEGG over open-vocabulary SGG and zero-shot SGG are unclear.
2. RAS relies on predictions from the previous SGG model, risking error propagation; using a generative model with fine-grained control signals is recommended.
3. The two-stage SGG baseline is outdated; incorporating the latest models like PE-Net is suggested.
4. The model is evaluated solely on VG, necessitating more experiments for generality, including cross-domain evaluations.
5. The presentation is difficult to follow, and formal mathematical definitions of methods are missing.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the presentation and provide formal mathematical definitions for the methods, particularly how the RAS framework integrates with existing SGG backbones. Additionally, we suggest including evaluations on more diverse datasets to enhance the generality of the findings. Addressing the stability of training processes for new categories and clarifying the advantages of CSEGG over existing methods would strengthen the paper. Finally, consider exploring dynamic scene graph generation to broaden the applicability of the proposed framework.