ID: VgLBPLvHuK
Title: Revisiting Source Context in Nearest Neighbor Machine Translation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates the role of source context in kNN-MT, arguing that it is an important yet under-explored area. The authors propose methods to incorporate source context into various kNN-MT components: retrieval, calibration, and interpolation. Specifically, they create an auxiliary datastore based on source similarity, modify the distance function to include source-side distance, and compute \(\lambda\) adaptively based on source similarity. The results indicate improvements over strong baselines, with only marginal increases in inference speed and memory requirements.

### Strengths and Weaknesses
Strengths:
- The use of source context in kNN-MT is well-motivated and shows promising results.
- The method is comprehensive, benefiting multiple kNN-MT components, as indicated by ablation studies.
- The paper is well-structured and clearly written, facilitating understanding.

Weaknesses:
- Important evaluation details are missing, such as the SacreBLEU signature, which raises questions about the fairness of baseline comparisons.
- Some methodological details are unclear, including how certain distances are calculated and how hyperparameters are optimized.
- The training datasets used are limited, raising concerns about the generalizability of the results.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their evaluation by including the SacreBLEU signature and ensuring that reported scores match those in original papers. Additionally, please clarify how the distance \(d(r,r^j)\) is calculated and provide details on how the lightweight module for hyperparameter \(\mu\) is optimized. It would also be beneficial to specify the hyperparameter search process for \(k\) and \(T\), and to include statistical significance testing for BLEU score improvements. Furthermore, consider using more competitive baselines and providing a clearer description of the datasets used, including their translation directions and languages. Lastly, including a measure of variation in BLEU scores would enhance the understanding of the significance of reported improvements.