ID: 2CJUQe6IoR
Title: MultiVENT: Multilingual Videos of Events and Aligned Natural Text
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 5, 6, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents MultiVENT, a new multilingual, multimodal dataset for video retrieval, consisting of 2,396 videos covering 260 current events in five languages (Arabic, Chinese, English, Korean, Russian). The authors propose a method utilizing CLIP as a baseline for video retrieval on this dataset, which aims to address the lack of multilingual video datasets and provides a unique perspective on content evolution over time. While MultiVENT has fewer videos than some benchmarks, the average video length is significantly longer, providing substantial content for fine-tuning existing models. The authors discuss the feasibility of scaling the dataset by utilizing YouTube for video retrieval and translation software for multilingual expansion. Additionally, they have added a "Limitations and Ethical Considerations" section to address potential societal impacts and data biases.

### Strengths and Weaknesses
Strengths:  
- The dataset is the first large-scale multilingual video retrieval dataset spanning five languages and includes diverse video types beyond news broadcasts.  
- MultiVENT offers a substantial amount of content with longer average video lengths compared to similar datasets.  
- The authors adopt CLIP effectively for multilingual, event-centric video retrieval.  
- The dataset is structured to allow for easy scaling in both video quantity and language diversity.  
- The methods and experiments are clearly presented, making them easy to follow.  
- The literature review is comprehensive and motivates the proposed work well.  
- The authors have addressed ethical considerations and limitations in the revised paper, enhancing its comprehensiveness.  
- The paper is well-written, with great clarity and flow.

Weaknesses:  
- The dataset may lack sufficient video quantity, raising concerns about its robustness.  
- The research motivation and unique aspects of the dataset need further clarification.  
- The related works section lacks depth and could benefit from a broader review of existing literature.  
- The dataset's source diversity is limited, primarily relying on YouTube and Twitter, which may introduce bias.  
- The distinction between MultiCLIP and CLIP could be clearer, and there is a lack of experiments with certain models like MPLUG-2.  
- The documentation lacks detail, particularly regarding the evaluation of video-text associations and the characteristics of visual content.

### Suggestions for Improvement
We recommend that the authors improve the dataset by providing audio information and developing more tasks using the proposed dataset. Additionally, the authors should compare more methods on MultiVENT, including experiments with MPLUG-2, and utilize OCR to extract text within the videos to enhance retrieval. Clarifying the definition of "event" in the context of the dataset and detailing the process for confirming video-text associations would strengthen the paper. We also suggest that the authors address ethical considerations more thoroughly, particularly regarding the recruitment and role of local annotators. Furthermore, we recommend improving the diversity of video sources to mitigate potential biases in the dataset and providing a clearer distinction between MultiCLIP and CLIP in the manuscript. Lastly, expanding the related works section to provide a more comprehensive overview of relevant literature and including more experiments with models like MPLUG-2 would enhance the overall quality of the work.