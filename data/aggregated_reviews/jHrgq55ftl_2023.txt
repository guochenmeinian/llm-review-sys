ID: jHrgq55ftl
Title: SAMRS: Scaling-up Remote Sensing Segmentation Dataset with Segment Anything Model
Conference: NeurIPS
Year: 2023
Number of Reviews: 28
Original Ratings: 6, 8, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to generating masks for semantic segmentation in remote sensing imagery by utilizing the Segment Anything Model (SAM) to create a new dataset, SAMRS, which aggregates labels from four existing datasets. The authors conduct pre-training experiments with SAMRS, benchmarking its performance against other pre-training strategies. Additionally, the authors employ a human-in-the-loop approach using the HRSC2016 dataset for label quality control, evaluating various prompts for segmentation across multiple datasets, including DOTA, DIOR, and FAIR1M. The paper also evaluates the effectiveness of SAMRS and the Segmentation Enhancement Pipeline (SEP) across various models and pre-training strategies, demonstrating that SEP can enhance model performance, particularly in convolutional and vision transformer networks.

### Strengths and Weaknesses
**Strengths:**
- The methodology automates the translation of existing dataset labels into detailed segmentation labels, enhancing the utility of remote sensing datasets.
- The authors provide a thorough quantitative analysis of the SAMRS dataset and include detailed experimental results, contributing valuable insights into the quality of the generated segmentation masks.
- The paper is well-structured and clearly written, making it accessible to the broader research community.
- The authors acknowledge and address potential biases and limitations in the dataset creation process, enhancing the credibility of their findings.

**Weaknesses:**
- The dataset's reliance on existing datasets designed for object detection limits its original purpose, which warrants further discussion.
- There is an imbalance in instance distribution within the dataset, which could affect the understanding of instances.
- The authors do not adequately address the quality of the automatically generated labels, lacking a human-in-the-loop approach that could enhance reliability.
- There is insufficient discussion regarding the quality of automatically generated labels, particularly in relation to the size of the test set.
- Concerns remain regarding the reliability of the SAMRS dataset as a benchmark due to the quality of generated segmentation masks, which may not meet the high accuracy standards required for remote sensing segmentation tasks.

### Suggestions for Improvement
We recommend that the authors improve the discussion surrounding the limitations of using existing datasets for segmentation, particularly regarding the original intent of these datasets. Additionally, clarify the rationale for selecting the specific datasets included in SAMRS and the choice of Potsdam for fine-tuning evaluations. It would be beneficial to provide more extensive qualitative analyses of label quality and to explore the performance of SAMRS in comparison to other pre-training strategies, such as BEiT, ViT-Adapter, and InternImage. Furthermore, we suggest that the authors provide a more thorough motivation for the selection of datasets, clarifying why certain datasets were chosen over others. We encourage the authors to improve the clarity of how the SAMRS dataset can be utilized as a benchmark for related researchers and to justify the mIoU scores presented, emphasizing the implications of these results on the dataset's reliability for training and evaluation purposes. Finally, consider including manual ground truth annotations to assist in evaluating the quality of the pseudo ground truths generated by SAM.