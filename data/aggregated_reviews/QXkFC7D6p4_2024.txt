ID: QXkFC7D6p4
Title: FedGTST: Boosting Global Transferability of Federated Models via Statistics Tuning
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 6, 6, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents FedGTST, a novel approach to enhance transferability in federated learning (FL) by leveraging cross-client statistics. The authors conduct a thorough theoretical analysis, identifying the cross-client averaged Jacobian norm and its variance as critical factors influencing transferability. FedGTST effectively controls these elements to improve transferability while minimizing communication overhead and preventing privacy leakage by only transmitting scalar values. The method demonstrates promising results across various benchmark datasets.

### Strengths and Weaknesses
Strengths:
1. The paper is well-structured and clearly written.
2. The proposed method is effective, with thorough experimental validation.
3. The theoretical analysis is robust and connects well with the method's design.
4. The algorithm is communication-efficient, addressing a crucial requirement in federated settings.

Weaknesses:
1. The benchmark datasets used are relatively simple; more complex datasets like PACS or DomainNet would strengthen the experimental results.
2. The method's effectiveness when optimizing feature extractors during FL is unclear.
3. The applicability of the proposed method in scenarios with multiple source domains is not addressed.
4. The variance of the cross-client Jacobian may inherently promote good transferability in IID settings, necessitating comparisons with advanced FL algorithms that handle data heterogeneity.
5. The theoretical analysis lacks intuitive explanations regarding the impact of norm inflation on transferability.
6. Certain assumptions in the analysis, such as using one local step and Gradient Descent instead of Stochastic Gradient Descent, may be impractical.

### Suggestions for Improvement
We recommend that the authors improve the experimental validation by including more complex benchmark datasets to enhance the credibility of their results. Additionally, the authors should clarify the effectiveness of the proposed method when feature extractors are optimized during FL and explore its applicability in settings with multiple source domains. It would be beneficial to provide detailed insights into why inflating norms aids transferability and to address the implications of relaxing the assumptions regarding local steps and optimization methods. Finally, we suggest correcting typographical errors and enhancing the clarity of the experimental setup to facilitate better understanding and reproducibility.