ID: f39Q3JyoIi
Title: Collaborative Alignment of NLP Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 5, 6, 6, 6, 6, -1, -1, -1, -1
Original Confidences: 5, 3, 1, 4, 1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework called CoDev for collaborative NLP development, enabling multiple users to align models with their beliefs. The authors propose a dual-model approach, utilizing a global model that integrates original data with user-defined concepts and local models for each concept. The framework guides a large language model to generate instances where local and global models disagree, facilitating user annotation to improve model alignment. Experiments demonstrate that CoDev outperforms baseline models like AdaTest across various tasks.

### Strengths and Weaknesses
Strengths:
- The paper addresses an important issue in NLP model alignment with user values.
- The approach of using GPT-3 as a global model and Roberta-large as a local model is novel.
- The framework is well-structured and easy to understand, with effective experimental results.
- The inclusion of real-world user interactions enhances the relevance of the findings.

Weaknesses:
- The assumption that disagreement can be resolved through repeated user labeling overlooks the possibility of multiple acceptable answers.
- The experimental setup lacks clarity, making reproducibility difficult for other researchers.
- The paper does not adequately address the subjective nature of labeling tasks, which weakens the argument for the proposed framework.
- Some results lack statistical significance, and the focus on simpler tasks limits the generalizability of the findings.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the experimental setup to facilitate reproducibility. Additionally, the authors should address the assumption of a single ground truth in user labeling and consider discussing the implications of multiple acceptable answers. It would be beneficial to include a broader range of datasets to test the framework's generalizability. Furthermore, the authors should provide more detailed explanations of the local and global models, including the prompts used for GPT-3, and clarify how they handle user disagreements during the labeling process. Lastly, we suggest that the authors enhance the discussion on the subjective nature of labeling tasks and the potential conflicts between user-defined concepts.