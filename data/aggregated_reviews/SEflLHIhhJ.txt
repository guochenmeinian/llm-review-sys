ID: SEflLHIhhJ
Title: Stepping on the Edge: Curvature Aware Learning Rate Tuners
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 5, 7, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel learning rate tuning method, Curvature Dynamics Aware Tuning (CDAT), which leverages insights from sharpness dynamics to optimize learning rates in deep learning. The authors analyze the behavior of classical learning rate tuners, such as line search and quadratically greedy methods, highlighting their limitations, particularly in the context of deep learning. The paper argues that these methods often fail to maintain optimal performance due to their inability to adapt to the progressive sharpening of sharpness dynamics towards the Edge of Stability (EoS). The proposed CDAT method aims to address these issues by incorporating the alignment of the gradient with the Hessian and is shown to outperform constant learning rate schedules in the full-batch setting. However, the authors also explore CDAT's performance limitations in stochastic settings and suggest that measuring curvature less frequently may be viable, supported by preliminary results with exponential moving average (EMA) methods. They note discrepancies in early-stage learning rates compared to Adam and the impact of learning rate tuners on sharpness dynamics.

### Strengths and Weaknesses
Strengths:  
1. The paper introduces a novel perspective on the interplay between sharpness dynamics and learning rate scheduling, which is a significant contribution to the field.  
2. The structure and clarity of the paper are commendable, providing a well-organized flow between empirical evidence and theoretical models.  
3. The CDAT tuner captures interesting properties of sharpness and learning rate interactions, showing promise in full-batch scenarios.  
4. The authors provide a detailed analysis of CDAT's performance and its implications for optimizer design.  
5. The integration of EMA in evaluating curvature shows promise for stabilizing learning dynamics.  
6. The work challenges existing views on sharpness dynamics and learning rate selection, presenting a novel perspective.

Weaknesses:  
1. CDAT has practical limitations, particularly in mini-batch settings, where it does not consistently outperform constant learning rates and requires additional hyperparameter tuning.  
2. The performance of CDAT is sensitive to the choice of the scaling factor $\sigma$, which raises concerns about its robustness across different tasks.  
3. The theoretical foundation for CDAT, particularly regarding the use of the largest Hessian eigenvalue, is questioned, especially in the context of stochastic gradient descent and adaptive optimizers like Adam.  
4. CDAT's performance in stochastic settings is lower than expected, which limits its significance as a state-of-the-art optimizer.  
5. The dependence of sharpness on individual mini-batches has not been thoroughly tested, leaving questions about the impact of stochastic noise.

### Suggestions for Improvement
We recommend that the authors improve the theoretical grounding of CDAT by addressing the discrepancies in sharpness measures for stochastic settings and adaptive optimizers. Additionally, the authors should conduct further experiments to validate the performance of CDAT across various mini-batch sizes and learning rate schedules, particularly comparing it with established methods like warmup and cosine schedules. It would also be beneficial to provide a more detailed analysis of the sensitivity of CDAT to the choice of $\sigma$ and explore potential strategies to mitigate this issue, such as using an exponential moving average for edge estimation. Finally, we suggest that the authors investigate how sharpness varies at the mini-batch level to better understand the effects of stochastic noise on curvature throughout training, and clarifying the reparametrization in relation to existing literature would enhance the paper's rigor and comprehensibility.