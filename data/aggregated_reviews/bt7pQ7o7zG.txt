ID: bt7pQ7o7zG
Title: Chatting Makes Perfect: Chat-based Image Retrieval
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 5, 4, 4, 5, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a chat-based image retrieval system that engages users in dialogue to clarify their search intent and retrieve desired images from a large corpus. The authors propose a framework utilizing Large Language Models (LLMs) to generate follow-up questions based on an initial image description, achieving a success rate of over 78% after five dialogue rounds. The evaluation includes comparisons against strong baselines and suggests protocols for ongoing assessment using a Visual Dialog model.

### Strengths and Weaknesses
Strengths:  
- The paper addresses an interesting and under-explored problem, proposing a novel setup that enhances traditional text-image retrieval tasks.  
- The framework is practically valuable for clarifying user search intent and is well-evaluated using existing datasets.  
- The submission is well-written and includes clear visual aids that enhance understanding.

Weaknesses:  
- The paper lacks a comprehensive comparison with classical text-image retrieval methods, which raises questions about the necessity of the dialogue component.  
- Clarity issues exist, particularly regarding the type of dialogue needed for effective retrieval and the motivation behind using dialogue in this context.  
- The experiments are limited to instruction-tuned LLMs and the VisDial dataset, necessitating justification for this choice and exploration of alternative methods.

### Suggestions for Improvement
We recommend that the authors improve clarity by elaborating on the types of dialogue necessary for effective image retrieval and the rationale for using dialogue in this context. Additionally, we suggest including comparisons with classical text-image retrieval methods to validate the proposed approach and demonstrate its advantages. Addressing the questions regarding the evaluation data, the unanswered setup, and the potential for using other methods beyond BLIP2 will also strengthen the paper.