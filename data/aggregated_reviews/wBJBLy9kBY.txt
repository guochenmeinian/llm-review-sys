ID: wBJBLy9kBY
Title: Ambient Diffusion: Learning Clean Distributions from Corrupted Data
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 6, 7, 6, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 4, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a diffusion-based framework that learns to recover clean data from corrupted samples without requiring access to clean training data. The authors introduce a corruption matrix $A$ and propose a method to sample a further corruption matrix $\tilde{A}$, enabling the model to predict existing pixels effectively. Empirical results demonstrate that this approach achieves better performance than traditional methods trained on clean data, particularly in handling higher levels of corruption.

### Strengths and Weaknesses
Strengths:
- The authors propose the first diffusion-based method capable of restoring data from corruption without clean data training.
- The method can utilize existing diffusion samplers with minimal modifications.
- Theoretically, the model is guaranteed to recover clean data under certain rank assumptions.
- It addresses memorization issues in diffusion models by incorporating corruption schemes.

Weaknesses:
- The paper lacks clarity on the specifics of $\tilde{A}$ during inference and whether the same $\delta$ is used in training.
- Implementation details are insufficient, particularly regarding the dependency of $h_\theta(\tilde{A}, \tilde{A}x_t, t)$ on $\tilde{A}$.
- The focus is solely on random masking corruption, neglecting other linear corruption types, raising questions about robustness against different corruptions.
- There is no comparison with AmbientGAN in Table 1, which is a significant baseline.
- The theoretical justification for approximations in equations 3.3 and 3.4 is unclear.

### Suggestions for Improvement
We recommend that the authors improve the exposition on the sampling process, specifically clarifying the nature of $\tilde{A}$ used during inference and whether it is fixed or resampled at each step. Additionally, providing a detailed explanation of the implementation of $h_\theta(\tilde{A}, \tilde{A}x_t, t)$ would enhance understanding. The authors should consider analyzing the method's robustness against various corruption types beyond random masking and include comparisons with AmbientGAN in their results. Furthermore, we suggest revising the theoretical sections to clarify the justifications for the approximations made in equations 3.3 and 3.4, ensuring that the reasoning is well-articulated and connected to the overall methodology.