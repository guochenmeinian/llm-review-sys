ID: i0OmcF14Kf
Title: State-space models with layer-wise nonlinearity are universal approximators with exponential decaying memory
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 6, 6, 8, 5, 6, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 4, 2, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a constructive proof that state-space models (SSMs) are universal approximators of sequence-to-sequence mappings, demonstrating that SSMs, including empirically S4, suffer from exponentially decaying memory akin to standard RNNs. The authors analyze properties of SSMs, including their ability to approximate element-wise functions and temporal convolutions, and validate theoretical results with numerical simulations.

### Strengths and Weaknesses
Strengths:  
- The paper provides the first constructive proof of universality for SSMs, which is significant for understanding their capabilities.  
- It includes a thorough background section and clear writing, making complex concepts more accessible.  
- The use of the Kolmogorov-Arnold theorem and Volterra series is noteworthy and adds depth to the analysis.  

Weaknesses:  
- The writing quality is poor, with numerous grammatical errors and typos, necessitating comprehensive proofreading.  
- The universality proof does not encompass S4 models, which limits its practical applicability.  
- The section on the curse of memory is difficult to follow and requires clearer exposition.  
- The paper lacks a rigorous connection to linear RNNs, which could enhance the theoretical framework.  
- The figures need improvement in clarity, and some lack error bars or details on experimental conditions.

### Suggestions for Improvement
We recommend that the authors improve the overall writing quality by conducting a thorough proofreading to eliminate grammatical errors and typos. Additionally, consider including S4 in the universality proof to enhance its relevance. The section discussing the curse of memory should be rewritten for clarity, with a proper introduction to memory functions. We also suggest defining all variables clearly to aid reader comprehension. Furthermore, providing rates of memory decay and discussing the implications of each proposition would enhance the paper's impact. Lastly, improving the presentation of figures and including error bars or details on experimental conditions would strengthen the results.