ID: 7VNvM9SnRE
Title: Optimal, Efficient and Practical Algorithms for Assortment Optimization
Conference: NeurIPS
Year: 2024
Number of Reviews: 25
Original Ratings: 6, 7, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 3, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Adaptive Optimal Assortment (AOA) problem, also known as Utility Maximization with Subset Choices, which aims to identify the optimal profit-maximizing subset of items using the Plackett-Luce (PL) choice model. The authors propose a new algorithm, AOA-RB, which is claimed to be practical, efficient, and optimal, avoiding the need for repeated sampling of the same subset or the assumption of a strongest default item. The algorithm is enhanced with adaptive pivots, improving performance further. The theoretical analysis introduces a novel "Rank-Breaking" parameter estimation technique, providing regret guarantees for both the Top-m and Wtd-Top-m objectives. Additionally, the authors present an algorithm that improves upon existing models in the context of the Multinomial Logit (MNL) framework, particularly addressing limitations regarding regret bounds and the treatment of "no choice" scenarios. The authors argue that their algorithm, AOA-RBPL-Adaptive, achieves significantly better regret bounds under relaxed assumptions compared to prior models. Empirical validation supports the theoretical claims, showcasing the algorithm's effectiveness in practical settings.

### Strengths and Weaknesses
Strengths:
- Clear presentation and motivation of the problem.
- The algorithm's relaxation of previous assumptions is well-articulated, making it easy to follow.
- The adaptive pivot extension significantly enhances performance.
- Novel concentration lemmas and regret guarantees, particularly Theorem 6, are noteworthy contributions.
- The authors provide a robust theoretical foundation, demonstrating improved regret bounds under relaxed assumptions.
- The paper addresses significant limitations in existing algorithms, particularly regarding the treatment of "no choice" scenarios and the estimation of parameters.
- The introduction of a valid and tight upper confidence bound (UCB) contributes to improved regret guarantees.

Weaknesses:
- Some claims lack citations, and certain references are misapplied, affecting the credibility of the arguments.
- Limitations of the PL model and potential extensions to other models are inadequately discussed.
- The computational complexity of the $argmax_{S\subseteq [K], |S|\leq m}$ optimization is not addressed.
- Experiments are limited to synthetic data, lacking real-world applicability, and only one baseline is compared.
- Some reviewers question the validity of the experimental setups and the choice of parameters, suggesting that the synthetic experiments may not convincingly reflect real-world scenarios.
- There are concerns regarding the clarity of the presentation and the intuition behind certain algorithmic choices, particularly the UCB estimates.

### Suggestions for Improvement
We recommend that the authors improve the citation consistency, ensuring that broader literature is referenced appropriately. Additionally, the authors should clarify the limitations of the PL model in the problem statement and discuss how their approach could be extended to other models. It would be beneficial to elaborate on the intuition behind the AOA-RB algorithm and the UCB estimates to enhance understanding. We suggest including experiments with real-world data and comparing against multiple baselines mentioned in Table 1 to strengthen the empirical validation of the algorithm. Lastly, we advise revising the title to specify "online assortment optimization" to accurately reflect the paper's focus and consider providing more detailed justifications for their experimental choices.