ID: BJ1vOqh3hJ
Title: Retaining Beneficial Information from Detrimental Data for Neural Network Repair
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 5, 8, 8, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method to identify and repair corrupted data in training sets to enhance model performance. The approach consists of two stages: detecting corrupted examples using a loss difference computation and repairing them through an energy-based model. The authors demonstrate the effectiveness of their method through experiments on MNIST and CIFAR-10 datasets, showing improvements over existing techniques in handling various types of noise.

### Strengths and Weaknesses
Strengths:
- The problem addressed is highly relevant, and the proposed solution is interesting.
- The methodology is well-designed, with a clear motivation and sound theoretical foundation.
- Experimental results indicate significant improvements over baseline methods.

Weaknesses:
- The claim of using "real-world datasets" is misleading, as the corruption cases were simulated, and the datasets are relatively small. The inclusion of larger datasets like ImageNet could enhance the study.
- The paper lacks clarity in describing the alignment process, which is crucial for the proposed framework.
- The experimental setup does not adequately justify the proportions of corrupted samples used, and the results may not reflect real-world scenarios.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the alignment process in Section 1, particularly Lines 64 to 80, by providing detailed descriptions of how it works and its outcomes. Additionally, we suggest including a comparison against methods based on the Shapley value to strengthen the experimental evaluation. It would also be beneficial to explore the impact of varying the size of the clean reserved dataset on identification performance and to conduct experiments on more challenging datasets, such as CIFAR-100 or CIFAR-10N, to assess the robustness of the proposed method.