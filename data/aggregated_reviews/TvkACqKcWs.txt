ID: TvkACqKcWs
Title: On the alignment of LM language generation and human language comprehension
Conference: EMNLP/2024/Workshop/BlackBoxNLP
Year: 2024
Number of Reviews: 3
Original Ratings: -1, -1, -1
Original Confidences: 2, 4, 3

Aggregated Review:
### Key Points
This paper investigates the alignment between generative models and human reading comprehension through eye movement data, focusing on the effects of various decoding strategies on surprisal and entropy. The authors propose that different LLMs and decoding strategies influence human reading behavior, with findings indicating that certain strategies align better with comprehension stages. The study employs regression analyses typical in psycholinguistic modeling to assess reading times of machine-generated text stimuli.

### Strengths and Weaknesses
Strengths:
1. The study presents a novel approach by evaluating human-LM alignment using metrics on LM-generated texts rather than human-written stimuli.
2. The regression modeling protocols are solid, and results are visualized clearly, contributing to insights into different stages of human comprehension.

Weaknesses:
1. The paper may not be suitable for BlackboxNLP, as it resembles cognitive modeling work more than typical NLP studies. Its accessibility to readers unfamiliar with psycholinguistic modeling is questionable.
2. The data does not convincingly support the conclusion that different LLMs and decoding strategies yield differential fits of surprisal/entropy to reading measures, as confidence intervals overlap significantly.
3. Important experimental details are missing, such as the specifics of Bolliger et al.'s (2024) dataset, including the number of passages generated and subjects recruited.
4. The definition of transition scores is unclear, raising questions about their calculation.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by focusing on either the four different language models or the decoding strategies, rather than both. Additionally, a more detailed description of the dataset, including the number of passages, their lengths, genres, and the number of observations collected, should be provided. To strengthen the evidence for their conclusions, the authors should explicitly test whether a "by-LLM" random slope on surprisal/entropy significantly improves regression model fits. Furthermore, we suggest clarifying the definition of transition scores and ensuring that all figures have improved readability through larger font sizes. Lastly, the authors should address the statistical analyses performed for multiple comparisons and clarify which models were compared in their claims about processing efforts.