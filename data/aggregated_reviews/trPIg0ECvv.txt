ID: trPIg0ECvv
Title: Learning Disentangled Representation for Multi-Modal Time-Series Sensing Signals
Conference: ACM
Year: 2024
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Multi-modal Temporal Disentanglement (MATE) model, which effectively disentangles modality-shared and modality-specific latent variables in multi-modal time-series data. The authors propose a general disentangled representation learning framework with identifiability guarantees, addressing the limitations of traditional orthogonal approaches by modeling dependencies between latent variables. The paper includes rigorous theoretical results and experiments on 12 datasets, demonstrating the model's effectiveness in real-world scenarios.

### Strengths and Weaknesses
Strengths:
1. The MATE model advances the understanding of modality relationships by modeling latent variables as dependent, enhancing its applicability to complex datasets.
2. The theoretical results provide significant contributions to the identifiability of the learned representations, ensuring reliability.
3. The experimental evaluation covers a diverse set of datasets, showcasing strong performance, particularly in classification tasks.

Weaknesses:
1. The paper suffers from excessive use of equations, which may hinder readability; moving some equations to an appendix could improve clarity.
2. There is a lack of explicit connection between Sections 4 and 5, making it difficult to understand how the theoretical analysis informs the framework design.
3. Formatting inconsistencies and unclear symbols detract from clarity, and the titles of Tables 1 and 2 do not adequately explain the values presented.
4. The novelty of the work is questioned, as it appears to apply existing variational disentanglement methods to multi-modal time series without significant innovation.
5. The assumption that the mixing function is reversible may not hold in real-world scenarios, raising concerns about the model's applicability.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by reorganizing the Introduction to clearly articulate the motivation behind the dependence of latent variables. Additionally, consider providing a summary table for complex symbols to enhance understanding. It would be beneficial to include a discussion on the scalability of the model to more than two modalities and to validate the assumptions made in Section 5.2 with empirical evidence. Furthermore, we suggest that the authors include comparisons with more recent time series representation learning methods in their experiments and explore the model's performance on various downstream tasks beyond classification. Lastly, addressing formatting inconsistencies and providing source code would enhance the manuscript's overall quality.