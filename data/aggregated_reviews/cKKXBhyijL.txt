ID: cKKXBhyijL
Title: No-Regret Bandit Exploration based on Soft Tree Ensemble Model
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 5, 7, 5, 5, -1, -1, -1
Original Confidences: 3, 3, 4, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a stochastic bandit algorithm, ST-UCB, based on the soft-tree ensemble model for reward estimation and regret minimization. The authors propose that ST-UCB achieves lower cumulative regrets compared to traditional algorithms based on ReLU neural networks, under certain assumptions. The study also explores the theoretical connection between soft and hard trees and introduces the Tree Neutral Tangent Kernel (TNTK) for soft tree models, providing theoretical guarantees and a regret bound for the ST-UCB algorithm.

### Strengths and Weaknesses
Strengths:  
1. The research extends neural bandit theory to non-neural network models, enhancing the applicability of stochastic bandit algorithms and offering new regret minimization algorithms for tree-based models.  
2. The paper includes a proof of theory, an in-depth analysis of the soft tree ensemble model, and empirical results demonstrating the performance of the ST-UCB algorithm.  
3. The introduction of TNTK and its theoretical properties represents a significant contribution, supported by solid theories and comprehensive empirical studies.

Weaknesses:  
1. The conditions under which ST-UCB achieves regret-free performance may be challenging to satisfy in practical applications.  
2. The presentation of TNTK lacks clarity, with missing definitions and derivation steps that require better structuring.  
3. Some sections are unclear, such as the first paragraph of the introduction and the explanation of effective dimension, which need refinement.  
4. There are minor errors in notation and citation formats that detract from the overall presentation.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the presentation, particularly in defining and deriving TNTK, and ensure that the introduction clearly connects various combinations of users and items to unobserved actions. Additionally, we suggest providing a concrete dependency on T for the lower bound on M in Theorem 3.2 to clarify how the confidence bound depends on time. The authors should also address the minor errors noted, such as the missing gradient operators and citation format corrections. Finally, exploring the applicability of the algorithm under a wider range of conditions and discussing the efficiency of the soft-tree model in relation to its computational demands would enhance the paper's contribution.