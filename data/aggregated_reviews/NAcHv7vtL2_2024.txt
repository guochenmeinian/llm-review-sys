ID: NAcHv7vtL2
Title: Scaling laws for learning with real and surrogate data
Conference: NeurIPS
Year: 2024
Number of Reviews: 21
Original Ratings: 6, 4, 9, 3, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a weighted empirical risk minimization (ERM) approach to enhance generalization by integrating surrogate data into training, demonstrating that this can reduce test error even when the surrogate data is unrelated to the original dataset. The authors derive a scaling law that predicts the optimal weighting scheme and the amount of surrogate data to use, supported by theoretical analysis and empirical validation across various statistical models and tasks. Additionally, the authors emphasize the importance of proper weighting and the implications of different loss functions, proposing to enhance the discussion on classification loss with empirical comparisons and mathematical results for under-parametrized settings. They also plan to address the practical use of scaling laws and provide visual aids to illustrate the effects of adding surrogate data on model performance.

### Strengths and Weaknesses
Strengths:
- The theoretical analysis of weighted ERM on generalization is robust and insightful, particularly the connection to the Stein paradox.
- The scaling law is well-supported by diverse empirical results, enhancing the paper's credibility.
- The authors demonstrate a clear understanding of the complexities involved in using surrogate data and regularization.
- Proposed changes include empirical comparisons and visual aids that enhance the practical applicability of the findings.
- The mathematical rigor in analyzing the effects of finite surrogate sample sizes is commendable.
- The paper is generally well-written, with a clear introduction and problem formulation.

Weaknesses:
- The discussion on related works is insufficient, particularly regarding data augmentation and distributionally robust optimization, which could provide a broader context for the findings.
- The theoretical framework is primarily focused on squared loss functions, while most empirical results are on classification tasks, creating a disconnect that needs addressing.
- Some notations are unclear or undefined, which may hinder understanding for readers unfamiliar with the concepts.
- The distinction between regularization and surrogate data could be further clarified, as the subtle differences may confuse readers.
- The current presentation may not fully address the nuances of how different data mixing strategies impact model performance.

### Suggestions for Improvement
We recommend that the authors improve the literature review by providing a comprehensive discussion of related works, particularly in the context of data augmentation and distributionally robust optimization. Additionally, the authors should clarify the role of the regularizer and analyze its sensitivity to parameters, as this is crucial for understanding the results. We also suggest extending the theoretical analysis to include more common loss functions beyond squared loss to broaden applicability. Furthermore, addressing the unclear notations and ensuring consistency in terminology throughout the paper will enhance clarity. We recommend improving the clarity of the distinctions between regularization and surrogate data, particularly in terms of their effects on model parameters and performance. Additionally, enhancing the discussion around the equivalence of weighted ERM and vanilla ERM, especially in practical scenarios with limited original examples, would be beneficial. Providing more detailed examples or case studies could further elucidate these concepts for the readers. Lastly, we encourage the authors to provide more intuitive explanations for complex results, particularly in Theorem 3, to aid reader comprehension.