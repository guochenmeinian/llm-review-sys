ID: YiRX7nQ77Q
Title: Anytime Model Selection in Linear Bandits
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 6, 6, 8, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 2, 4, 2, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents AlExp, a novel algorithm designed for online model selection in bandit optimization. The algorithm operates by randomly selecting a learner (linear bandit regret minimizer) each round, allowing the chosen learner to propose optimal actions while balancing exploration and exploitation. The authors provide theoretical guarantees and empirical validation, comparing their approach with existing literature. Additionally, the paper discusses an anytime exponential weighting algorithm based on Lasso reward estimates, which does not require knowledge of the horizon or an initial exploratory stage.

### Strengths and Weaknesses
Strengths:
- The paper includes a comprehensive literature review and a thorough comparison of the proposed approach with existing methods.
- The algorithm's routine is straightforward and well-commented, enhancing understandability.
- The approach shows theoretical and empirical improvements in certain dependencies, such as the number of learners.
- The analysis introduces technical novelty and effectively addresses the problem of missing regret data.

Weaknesses:
- Some parts of the presentation lack clarity, making it challenging to grasp the theoretical quantities involved.
- There is insufficient discussion on the computational aspects of the proposed approach, particularly regarding the expensive numerical computations as the number of learners increases.
- The algorithm relies on knowledge of theoretical quantities (e.g., expected values), which could be addressed through a Monte Carlo sampling procedure, but the convergence of estimators and computational implications need clarification.
- The dimensionality of the proposed model may lead to high complexity, and the algorithm's runtime is heavily dependent on the efficiency of the sparse regression model.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the presentation, particularly in explaining the theoretical quantities involved, to facilitate a more intuitive understanding. Additionally, we suggest including a more detailed discussion on the computational limitations of the approach, specifically the solving complexity of the optimizations involved. It would be beneficial to provide insights into the convergence speed of estimators when using Monte Carlo sampling and to consider potential corrections to the algorithm for estimation errors. Furthermore, highlighting real-world applications of the model selection problem and conducting real-data experiments could enhance the practical relevance of the findings. Lastly, we advise correcting the missing label on the vertical axis in Figure 3 for better interpretability.