ID: 3MW44iNdrD
Title: FairQueue: Rethinking Prompt Learning for Fair Text-to-Image Generation
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 5, 7, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 1, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an examination of the prompt learning method in fair text-to-image (T2I) generation, focusing on its impact on image quality. The authors identify that aligning prompt embeddings with reference image embeddings introduces noise from unrelated concepts, degrading image quality. They analyze the T2I model's denoising subnetwork and introduce novel prompt switching analyses (I2H and H2I) along with new quantitative metrics for cross-attention map characterization. Their findings indicate abnormalities in early denoising steps that affect global structure synthesis. The authors propose two solutions: Prompt Queuing (PQ), which applies base prompts initially and ITI-GEN prompts later, and Attention Amplification (AA), which balances quality and fairness. Extensive experiments demonstrate that the specific combination of PQ and AA, referred to as FairQueue, enhances image quality while maintaining fairness and diversity, outperforming other configurations in both quality and fairness metrics.

### Strengths and Weaknesses
Strengths:
1. The paper provides an in-depth examination of the denoising subnetwork within the T2I model, allowing for a granular understanding of how learned prompts influence image generation.
2. The cross-attention maps reveal specific patterns and irregularities, highlighting misalignment in attention distribution that disrupts coherent global structure formation.
3. Extensive experimental results show the superiority of FairQueue over ITI-GEN in terms of fairness, image quality, and semantic preservation.
4. The comprehensive analysis of various combinations of PQ and AA clearly demonstrates why FairQueue is superior, supported by quantitative results indicating a balance between high sample quality and fairness.

Weaknesses:
1. The proposed innovations, Prompt Queuing and Attention Amplification, may be seen as incremental rather than groundbreaking, lacking a strong theoretical basis for their superiority.
2. The explanation of how FairQueue addresses identified issues is insufficient, particularly regarding the effectiveness of base prompts in early denoising steps.
3. The transition to ITI-GEN prompts requires clearer justification, especially in terms of enhancing tSA expression.
4. The mechanism of Attention Amplification needs a more detailed explanation, including the rationale behind scaling factors.
5. The paper lacks detailed descriptions of experimental settings and parameters, which could hinder reproducibility.
6. The argument for why the combination of PQ and AA is superior to other configurations could be more detailed, lacking deeper analysis to strengthen the argument.

### Suggestions for Improvement
We recommend that the authors improve the explanation of why the base prompt T is more effective in forming global structures during early denoising steps, possibly by providing theoretical analysis and specific experimental results. Additionally, the authors should clarify how switching to ITI-GEN prompts enhances tSA expression without compromising overall image quality. A more detailed explanation of the Attention Amplification mechanism, including mathematical derivations or experimental data, would strengthen the argument. We also suggest including more comprehensive experimental results, particularly comparisons between using only the base prompt, only ITI-GEN prompts, and the FairQueue method, to demonstrate how FairQueue effectively addresses the identified issues. Lastly, we recommend consolidating the analyses of PQ and AA into a single section to enhance the overall coherence of the argument, along with a thorough analysis of the computational complexity and resource requirements for implementing FairQueue to assess its feasibility in real-world applications.