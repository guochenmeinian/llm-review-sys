ID: y2FPllMQVg
Title: Decision-margin consistency: a principled metric for human and machine performance alignment
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 5, 5, 8
Original Confidences: 4, 3, 3

Aggregated Review:
### Key Points
This paper presents a method for estimating classification performance alignment between humans and machines, focusing on decision-margin consistency as a measure for human-human and human-machine alignment. The authors motivate their approach by highlighting the high variability within subjects when solving the same task multiple times, suggesting that averaging over trials could mitigate this noise, although they indicate that over 300 trials would be necessary for reliable results. They introduce two new metrics, *decision margin* and *decision margin index*, to estimate decision margins for networks and humans, respectively. The results suggest that human-human alignment is higher than machine-machine alignment, challenging prevailing assumptions in the alignment community. The authors emphasize the importance of including multiple trials in user studies to reduce noise.

### Strengths and Weaknesses
Strengths:
- Well-written and easy to follow.
- Clear motivation for the study.
- Intriguing results that challenge existing beliefs.
- Chapter 5 offers valuable reflections on factors influencing alignment.
- The main takeaway regarding the relevance of averaging responses is significant.

Weaknesses:
- The sample size is insufficient for accurate estimates, with only 45 participants when 300 are needed.
- The accuracy of humans and models is not provided, raising questions about the validity of the results, particularly regarding low accuracies in Figure 2.
- Error consistency is not adequately introduced or described, appearing only in the results.
- The reliability of the introduced metrics as measures of alignment is uncertain.

### Suggestions for Improvement
We recommend that the authors extend the background to provide a more comprehensive overview of existing alignment measures, clarifying the novelty of their approach. A larger user study is essential to obtain reliable results. Additionally, the authors should address the simplifying assumptions regarding noise and response bias, as these could lead to inaccurate alignment estimates. It would also be beneficial to present evidence at the single-subject and single-trial levels, potentially incorporating physiological measures or fitting dynamical systems to responses. Finally, we suggest revising section titles for clarity, detailing confidence interval calculations, and correcting minor errors in the manuscript.