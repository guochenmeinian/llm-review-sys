ID: ZBi4ijmOzs
Title: End-to-End Single-Channel Speaker-Turn Aware Conversational Speech Translation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 7
Original Ratings: -1, -1, -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an end-to-end speech translation system designed for multi-talker conversations, utilizing a multitask training framework that integrates automatic speech recognition (ASR), speech translation, and speaker turn detection. The authors propose a model that employs task tokens for managing overlapping speech segments and speaker turns, demonstrating its effectiveness through extensive experiments on datasets like Fisher and CALLHOME.

### Strengths and Weaknesses
Strengths:  
- The paper addresses a relevant and challenging problem in conversational speech translation, showcasing a novel approach with comprehensive experimental results that support its claims.  
- The introduction of specific tokens for speaker turns and cross-talk detection enhances the model's performance, as evidenced by the experimental findings.  
- The writing is generally clear, and the study is thorough, with a strong motivation and technical soundness.

Weaknesses:  
- The explanation of multi-turn handling is vague and lacks clarity, particularly regarding the implementation of auxiliary tasks and the generation of labels.  
- Some experimental details, such as the performance of the SL and TL tokens and the evaluation of overlapping speech, are not adequately addressed.  
- The paper does not sufficiently motivate certain design choices, such as the use of a single cross-talk tag, and lacks a discussion of the implications of its findings compared to state-of-the-art models.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the multi-turn handling section by explicitly detailing the implementation of auxiliary tasks and how labels are generated, possibly including a figure for better illustration. Additionally, please clarify the meaning of "speech act" in Table 1 and provide essential statistics like the speech overlap ratio. In Section 4.1, clearly state whether the chunking procedure is applied during both training and testing. We also suggest evaluating the performance of different speech overlaps and estimating diarization performance with DER values. Lastly, please ensure that the bold fonts in Tables 5 and 6 accurately reflect the best performance and consider enriching the baseline models with more recent state-of-the-art models beyond Whisper.