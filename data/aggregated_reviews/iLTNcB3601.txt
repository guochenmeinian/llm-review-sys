ID: iLTNcB3601
Title: Improving End-to-End Speech Processing by Efficient Text Data Utilization with Latent Synthesis
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework for enhancing speech tasks by leveraging unpaired textual data, aiming to improve the modeling capability of speech recognition and spoken language understanding. The authors propose a latent synthesizer that generates continuous latent features from text, facilitating cross-modal knowledge transfer from linguistic to acoustic representations. Experimental results demonstrate substantial improvements in performance over baselines, achieving state-of-the-art results on smaller models and datasets.

### Strengths and Weaknesses
Strengths:  
- The approach is novel and effectively utilizes unpaired data, showing positive impacts across multiple downstream tasks.  
- The latent synthesizer designs are tailored for text-to-speech representation simulation, and the empirical results are promising.  
- The paper is well-written and clearly presented, with reproducible results.

Weaknesses:  
- The ASR experiments are limited to the Librispeech dataset, which may not comprehensively reflect ASR performance due to its clean read speech nature and the absence of more competitive models.  
- There is a lack of comparison with semi-supervised baselines that utilize text data, limiting the evaluation of the proposed method's effectiveness.  
- The investigation into the efficacy of external language model fusion is insufficient, and the applicability of the proposed method may be restricted by the domains of training data used.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by including comparisons with data augmentation methods utilizing discrete acoustic units, such as SpeechUT, to strengthen their claims. Additionally, conducting experiments on more challenging datasets beyond Librispeech would provide a more comprehensive assessment of ASR performance. Clarifying the relative effectiveness of the proposed method compared to shallow fusion and exploring domain transferability with out-of-domain datasets would also enhance the study's robustness. Finally, we suggest incorporating relevant references to improve the literature coverage, particularly regarding acoustic-to-linguistic cross-modal training and recent trends like SpeechGPT models.