ID: bzuQtVDxv0
Title: Splatter a Video: Video Gaussian Representation  for Versatile Processing
Conference: NeurIPS
Year: 2024
Number of Reviews: 26
Original Ratings: 7, 6, 6, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Video Gaussian Representation (VGR) that utilizes 3D Gaussian primitives to model dynamic scenes in monocular videos, transforming videos into a pseudo-3D representation space. The authors propose leveraging 2D priors, such as depth and optical flow, to regularize the learning of video Gaussians, aiming to enhance various video processing tasks including dense tracking, geometry editing, and novel view synthesis. They emphasize that their approach does not focus on 3D real-world reconstruction but rather on improving video processing capabilities. The method addresses challenges related to monocular video data and camera modeling by employing a fixed orthographic camera model and a modified EWA projection. The authors claim significant performance improvements over existing methods like CoDeF and RoDynRF, particularly in tracking, novel view synthesis, spatial-aware editing, and segmentation.

### Strengths and Weaknesses
Strengths:
1. The integration of 3D Gaussian splatting for video representation is ambitious and supports multiple downstream tasks.
2. The proposed method demonstrates significant performance gains in video processing tasks, outperforming existing approaches in various metrics.
3. The paper is well-structured and generally easy to follow, with clear visual illustrations.
4. The use of a pseudo-3D representation allows for better handling of complex motions and occlusions.
5. The supplemental video effectively demonstrates the proposed method's capabilities across various tasks.

Weaknesses:
1. The novelty of the approach is questioned, as it largely extends existing methods without significant technical contributions.
2. The evaluation is primarily qualitative, with limited quantitative results, particularly concerning downstream tasks.
3. The initial submission appeared rushed, lacking comprehensive experimental results and raising concerns about the validity of the claims made regarding the method's capabilities.
4. The optimization procedure lacks clarity, and the method's performance on diverse video scenarios remains unvalidated.
5. The model's sensitivity to hyperparameters and the potential overestimation of required Gaussians are concerns.
6. The method struggles with significant camera movements and complex scenarios, indicating limitations in robustness.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the optimization procedure, detailing how video frames are processed and how Gaussian attributes are initialized. Additionally, we suggest expanding the quantitative evaluation to include established benchmarks for tasks like dense tracking and providing a more comprehensive comparison with related works, particularly those employing 4D Gaussian methods. Addressing the overestimation of Gaussians by considering different feature frequencies and refining the model's robustness to hyperparameter changes would also enhance the paper. Furthermore, we recommend improving the clarity of the significance of their results and explicitly outlining the insights gained regarding 3D representations. Integrating additional quantitative results from the rebuttal into the main paper would strengthen the submission. Lastly, we suggest providing more visualizations to illustrate the impact of depth loss on performance, particularly in occluded areas, and improving experimental validation by including a broader range of video scenarios to better demonstrate the robustness of their pseudo-3D representation.