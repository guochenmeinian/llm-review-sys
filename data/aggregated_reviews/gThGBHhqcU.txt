ID: gThGBHhqcU
Title: Rethinking Conditional Diffusion Sampling with Progressive Guidance
Conference: NeurIPS
Year: 2023
Number of Reviews: 35
Original Ratings: 7, 5, 6, 5, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a generalized classifier guidance method for diffusion models, termed Progressive Guidance (PROG), which addresses significant issues such as diversity suppression and adversarial effects inherent in vanilla classifier guidance. The authors demonstrate that PROG, which incorporates information from multiple relevant classes and modifies guidance over time, achieves state-of-the-art results in certain experimental settings. The authors argue that their approach is simple and effective, with comprehensive rebuttals addressing concerns regarding novelty and emphasizing the potential for extending PROG to text-to-image synthesis, despite some skepticism about its applicability.

### Strengths and Weaknesses
Strengths:
1. The paper is well-motivated, addressing significant challenges in classifier guidance.
2. The proposed method is simple, effective, and intuitively aligned with its motivations, offering an interesting entropy perspective.
3. The writing is clear, with good flow and detailed explanations that enhance understanding.
4. Experiments are comprehensive, validating the method's advantages over vanilla classifier guidance and achieving new state-of-the-art results.
5. Multiple reviewers confirm that the authors have satisfactorily addressed novelty concerns, enhancing the paper's credibility.
6. The inclusion of empirical design choices and sensitivity analyses adds value to the community.
7. Code availability is a positive aspect.

Weaknesses:
1. Results on CIFAR-10 are less impressive compared to ImageNet, raising questions about potential reasons.
2. The degree of information is based on ChatGPT-generated descriptions; the prompts and their impacts are unclear.
3. Some clarity issues remain, particularly regarding the entropy perspective and the meaning of superscripts in tables.
4. Minor writing issues exist, such as unclear figure captions and missing definitions.
5. The necessity of pre-trained noise-aware classifiers for PROG is seen as a limitation, potentially complicating its application.
6. Some reviewers express concerns about the alignment of FID scores with existing methods, particularly CFG, suggesting that PROG may not perform as well.
7. There are calls for further clarification on the differences in diffusion paths and properties between classifier guidance and classifier-free guidance.
8. The paper lacks a thorough discussion of limitations, which should be elaborated for better insight.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the entropy perspective and provide a more logical derivation in the main text. Additionally, please clarify the meaning of superscripts in tables and ensure all figure captions are fully informative. Addressing the minor writing issues noted will enhance the overall presentation. We suggest improving the clarity of the FID score comparisons with existing methods, particularly addressing discrepancies with the GLIDE paper. Conducting a user study to validate whether PROG enhances image quality and diversity more effectively than CFG would be beneficial. Furthermore, refining arguments regarding the computational costs associated with training noise-aware classifiers and the extendability of PROG to text-to-image synthesis would strengthen the paper. Lastly, providing deeper insights into the differences in diffusion paths and properties between classifier guidance and classifier-free guidance would enhance understanding of the proposed method's applicability and performance.