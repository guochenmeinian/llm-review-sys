ID: kKtalvwqBZ
Title: Benchmarking Structural Inference Methods for Interacting Dynamical Systems with Synthetic Data
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 6, 9, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a benchmark for structural inference methods applied to complex dynamical systems, evaluating 13 methods across various disciplines using synthetic data that simulates real-world scenarios. The authors develop the Dataset for Structural Inference (DoSI), which includes diverse interaction graphs and dynamical functions. Key findings indicate that deep learning methods excel with multi-dimensional data, while classical statistical and information theory-based approaches demonstrate notable accuracy and robustness. The study aims to guide researchers in selecting appropriate methods and stimulate further innovation in structural inference methodologies.

### Strengths and Weaknesses
Strengths:
- The paper addresses an important research problem in inferring network structures from time series data.
- It offers a comprehensive evaluation framework that includes both traditional and deep learning-based approaches, assessing effectiveness, scalability, and robustness.
- The methodology is robust, with thorough documentation and detailed results analysis provided in the main text and supplementary materials.

Weaknesses:
- The benchmarking process is computationally intensive, making it challenging for a broader audience to understand and reproduce.
- The results on real-world datasets appear unconvincing, raising concerns about the dataset quality and its impact on method performance.
- Some explanations of results require further clarification, particularly regarding the performance of deep learning methods on multi-dimensional datasets.

### Suggestions for Improvement
We recommend that the authors improve the dataset quality evaluation and provide more details on dataset generation. Additionally, adding datasets from different simulations could enhance the robustness of the findings. To strengthen the evaluation, further validation on diverse real-world datasets is necessary, as this would enhance the study's generalizability and applicability. Lastly, clarifying the explanations regarding the performance of deep learning methods on multi-dimensional datasets would improve the paper's clarity.