ID: 8DKrruapZ5
Title: Boosting Prompt-Based Self-Training With Mapping-Free Automatic Verbalizer for Multi-Class Classification
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a prompt-based fine-tuning method for multi-class text classification, specifically addressing scenarios with four or more classes. The authors propose a mapping-free automatic verbalizer (MAV) that enhances a previous self-training method, SFLM (Chen et al., 2021), by adding two learnable fully-connected layers to the MLM head of RoBERTa. Experimental results indicate the method's effectiveness in few-shot settings across five datasets, with K set to 16. The paper includes analyses demonstrating the proposed method's superiority over comparison methods.

### Strengths and Weaknesses
Strengths:
- The proposed method effectively addresses the challenges of manual verbalizer creation and the computational cost of searching for optimal label words.
- The paper is well-structured, providing sufficient detail on the experimental setup to ensure reproducibility.
- Strong empirical results support the authors' claims, particularly in few-shot scenarios without requiring manual label names.

Weaknesses:
- The experiments are limited to a single pre-trained language model, RoBERTa-base, and a fixed few-shot setting (K=16), raising concerns about generalizability.
- The argument that the method can be applied to any multi-class dataset is contradicted by the filtering of minor classes in the experiments, limiting its applicability.
- The narrative lacks focus on the unique contributions of the work, particularly regarding the interaction of the verbalizer with self-training.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their findings by evaluating the proposed method on larger language models, such as RoBERTa-large (355M parameters), and varying the value of K. Additionally, conducting experiments on the entire dataset without filtering would better assess the method's applicability to multi-class datasets. Clarifying the experimental settings and the rationale behind the choice of freezing the MLM head versus the entire encoder would enhance the paper's clarity. Finally, providing more details on the "Multi Label Words Mapping" step and the differences in masking strategies would strengthen the methodology section.