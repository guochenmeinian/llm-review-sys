ID: noPuQXVx8Y
Title: Exploring the Sensitivity of LLMs' Decision-Making Capabilities: Insights from Prompt Variations and Hyperparameters
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into the performance of large pretrained language models (LPLMs) on a Horizon decision-making task, focusing on how variations in prompts and temperature settings affect their decision-making capabilities. The authors claim that their results show LPLMs can exhibit human-like exploration-exploitation trade-offs with appropriate prompting. They emphasize the importance of considering prompt modification and hyperparameter variation in studies of LPLM performance.

### Strengths and Weaknesses
Strengths:  
- The paper is concise, well-written, and highlights a significant point regarding the influence of prompting and hyperparameter variation on LPLM performance.  
- It explores an interesting intersection of language modeling and human psychology, demonstrating that LLMs can achieve superhuman performance in minimizing regret on the Horizon task.  
- Comprehensive experiments are conducted, providing sufficient support for the claims made.

Weaknesses:  
- The study only examines one task from Binz and Schulz (2023), limiting its scope; additional tasks could provide a more robust analysis.  
- There are major methodological concerns, including insufficient details on the experimental design, such as the number of trials and reasoning behind temperature choices.  
- The paper lacks necessary citations for key claims and contains multiple grammatical errors and confusing language, particularly in the description of the Horizon task and Figure 3.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their experimental design by providing details such as the number of trials and justifications for the chosen temperature settings. Additionally, addressing the limitations of only studying one task from Binz and Schulz (2023) and considering other tasks would strengthen the paper. We suggest including a discussion on the broader implications of prompt engineering and its impact on LPLM performance. Furthermore, we encourage the authors to refine the language throughout the paper to enhance readability and precision, particularly in the description of the Horizon task and in correcting grammatical errors.