ID: MzM99vV5Rx
Title: IQA-EVAL: Automatic Evaluation of Human-Model Interactive Question Answering
Conference: NeurIPS
Year: 2024
Number of Reviews: 22
Original Ratings: 5, 5, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents IQA-EVAL, an automated evaluation framework for Interactive Question Answering (IQA) systems utilizing large language models (LLMs). The authors propose LLM-based Evaluation Agents (LEAs) to simulate human interactions with IQA models and evaluate these interactions, incorporating persona assignments to represent diverse user groups. The framework reportedly achieves high correlation with human evaluations, addressing the need for efficient evaluation methods in complex question-answering tasks.

### Strengths and Weaknesses
Strengths:
- Proposes a fully automated framework for evaluating interactive QA systems, enhancing efficiency.
- Incorporates persona assignments to LEAs for nuanced simulations of user interactions.
- Demonstrates strong correlation with human judgments, indicating reliability.

Weaknesses:
- Limited novelty, as the use of LLMs as evaluators is common in existing research.
- The interaction scenarios considered lack diversity, failing to reflect real-world user behaviors adequately.
- The evaluation dataset consists solely of multiple-choice questions, which may not effectively simulate genuine multi-turn conversations.

### Suggestions for Improvement
We recommend that the authors improve the diversity of interaction scenarios to better reflect real-world user behaviors. Additionally, we suggest incorporating more diverse interaction patterns, such as clarification questions and ambiguous queries, to enhance the evaluation results. The authors should also provide a more robust justification for claims regarding the alignment of ChatGPTâ€™s assessments with human evaluations, as well as address the potential biases introduced by using LLMs for evaluation. Finally, we encourage the authors to analyze the verification process for personas more thoroughly to ensure that performance differences are reflective of actual characteristics.