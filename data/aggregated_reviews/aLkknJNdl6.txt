ID: aLkknJNdl6
Title: Towards Low-Resource Automatic Program Repair with Meta-Learning and Pretrained Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, 4

Aggregated Review:
### Key Points
This paper presents a meta-learning framework, Meta-APR, for automatic program repair (APR) targeting low-resource error types. It utilizes the Reptile algorithm, first meta-training on high-resource bug-fix pairs and then fine-tuning on low-resource error types across various sample sizes. The authors curate datasets from three benchmarks and demonstrate that Meta-APR outperforms existing methods, including ChatGPT, in low-resource settings. The study highlights the challenges of imbalanced error type distributions in APR and the effectiveness of meta-learning in addressing these challenges.

### Strengths and Weaknesses
Strengths:
- The paper innovatively addresses low-resource APR, providing useful datasets for future research.
- The application of the Reptile algorithm for fine-tuning LLMs is a clever approach, demonstrating advantages over traditional methods.
- Comprehensive experiments and analyses are conducted, including comparisons with ChatGPT, showcasing the proposed method's effectiveness.

Weaknesses:
- The artificial limitation of data points creates an unrealistic low-resource scenario, which may not reflect real-world conditions.
- The improvements over multi-task transfer learning are minor, raising questions about the method's efficacy for larger sample sizes.
- The clarity of the meta-training algorithm and baseline comparisons is insufficient, leading to potential confusion.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the meta-training algorithm, particularly the Reptile process, to enhance understanding of its contributions. Additionally, we suggest providing more detailed explanations of the baselines, including transfer-learning and multi-task learning. The authors should consider testing their method in more realistic settings without artificially limiting data and include performance metrics beyond Exact Match, such as Error Removal results. Finally, clarifying figure captions and presentation issues will enhance the overall readability of the paper.