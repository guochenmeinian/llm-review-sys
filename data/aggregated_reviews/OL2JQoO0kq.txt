ID: OL2JQoO0kq
Title: Quilt-1M: One Million Image-Text Pairs for Histopathology
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 8, 9, 8, 10, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents QUILT-1M, a large-scale multimodal dataset consisting of one million image-text pairs for histopathology, curated from diverse sources including YouTube, Twitter, and research papers. The authors detail the automated processes employed for dataset creation, including the use of large language models and automatic speech recognition. They introduce QUILTNET, a modified CLIP model fine-tuned on this dataset, and validate its performance across various downstream tasks. The authors propose that QUILT offers superior data quality compared to other datasets, as evidenced by performance comparisons with models trained on OpenPath. They acknowledge the need for further evaluation of data quality through pretraining on various datasets and recognize limitations, including the potential for improved dataset quality through human refinement and the possibility that alternative models could yield better results. The paper discusses technical limitations, ethical considerations, and potential biases associated with the dataset.

### Strengths and Weaknesses
Strengths:
- The dataset's innovative collection method integrates various advanced techniques, enhancing its comprehensiveness.
- The size and richness of the dataset, including multiple descriptions per image, represent a significant contribution to the field.
- The dataset is largely reproducible and sourced from credible medical experts, ensuring a level of accuracy.
- The authors provide a detailed methodology for dataset creation and extensive evaluations demonstrating the model's performance.
- The authors have made efforts to address ethical concerns regarding data privacy and have implemented measures to protect sensitive information.
- The release of multiple QuiltNet models allows accessibility for researchers with limited resources.

Weaknesses:
- The final QUILT and QUILT-1M datasets are not fully accessible, raising concerns about findability and reproducibility.
- The authors do not specify the license for the datasets, nor do they clarify the expertise of YouTube narrators, which affects the reliability of textual descriptions.
- There is a lack of clarity regarding the differences between QUILT and QUILT-1M, and the specific pre-trained models used.
- The dataset's limited size and the choice of text prompts may contribute to underperformance in specific tasks, such as BACH.
- The authors have not conducted extensive ablation studies due to computational constraints, limiting insights into dataset utility in low-resource environments.
- Some discrepancies in reported dataset sizes and the absence of human verification for all image-text pairs raise concerns about data quality.

### Suggestions for Improvement
We recommend that the authors improve the accessibility of the QUILT and QUILT-1M datasets by hosting them on a more user-friendly platform than Google Drive, such as HuggingFace or Zenodo, which would enhance findability and allow for programmatic downloads. Additionally, please clarify the licensing information for the datasets in the manuscript. We urge the authors to conduct an ablation study to evaluate the impact of different data sources on model performance. It would also be beneficial to provide more details on the expertise of the YouTube narrators and the specific models used in the dataset creation process. Furthermore, we recommend that the authors improve the evaluation of data quality by pretraining the same network on QUILT(-1M) versus other datasets and measuring performance on a fixed test set. We suggest acknowledging further limitations, including the potential benefits of human refinement and the exploration of alternative models like BEIT or VILT. To enhance dataset diversity, we encourage the authors to expedite the expansion of QUILT(-1M) to include multi-lingual captions and various data modalities. Finally, we advise the authors to conduct ablation studies to better understand the impact of dataset size and composition on model performance.