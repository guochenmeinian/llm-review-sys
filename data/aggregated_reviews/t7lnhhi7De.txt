ID: t7lnhhi7De
Title: Joint Bayesian Inference of Graphical Structure and Parameters with a Single Generative Flow Network
Conference: NeurIPS
Year: 2023
Number of Reviews: 18
Original Ratings: 6, 5, 6, 5, 8, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 2, 4, 2, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an extension of Generative Flow Networks (GFlowNets) for Bayesian structure learning, focusing on jointly modeling the structure and parameters of Bayesian networks. The authors propose a two-stage method that constructs a directed acyclic graph (DAG) and selects parameters associated with its nodes. The theoretical framework includes a new reward function and subtrajectory balance conditions to ensure the desired distribution is achieved. Additionally, the authors address the need for approximating the joint posterior over the structure of Bayesian networks and the parameters of their conditional probability distributions (CPDs). They emphasize the standard assumptions of modularity and independence of posteriors for computational efficiency, while also acknowledging concerns regarding practical applications to real-world data and potential correlations in marginal posteriors. The method is evaluated against synthetic problems and gene regulatory networks, showing competitive performance compared to existing methods.

### Strengths and Weaknesses
Strengths:
1. The paper addresses the significant problem of structure learning in Bayesian networks, providing a thorough literature review and well-written content.
2. The theoretical framework is robust, offering a deep understanding of the problem and deriving necessary conditions for the proposed method.
3. The authors provide a clear focus on structure learning within Bayesian networks, addressing a less studied area.
4. Experimental results demonstrate promising performance on both synthetic and real-world datasets.

Weaknesses:
1. The core theory, particularly equation (6), presents measure-theoretic issues that need clarification, especially regarding the convergence of the proposed method.
2. The manuscript lacks sufficient practical implementation details and comprehensibility, making it difficult for readers to grasp the architecture and training process.
3. The lack of provided code limits the reproducibility of the reported results.
4. There is a perceived absence of experimental evidence demonstrating the method's effectiveness on real-world data.
5. The strong assumptions of modularity and independence of posteriors are seen as a significant weakness that requires more thorough discussion.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the theoretical framework, particularly addressing the measure-theoretic concerns related to equation (6) and its implications for convergence. Additionally, we suggest providing more detailed explanations of the architecture and implementation to enhance understanding. Including a simple educational example could further aid in illustrating the framework. We also encourage the authors to submit code to facilitate reproducibility and consider expanding the discussion on limitations, particularly regarding the scalability of their method. Furthermore, the authors should provide a more in-depth discussion of the implications of the modularity assumption and address the potential correlations in marginal posteriors more explicitly. Lastly, it would be beneficial to include experimental evidence demonstrating the method's performance on real-world datasets to substantiate their claims.