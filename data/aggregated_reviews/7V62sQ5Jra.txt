ID: 7V62sQ5Jra
Title: Prediction-Powered Ranking of Large Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 6, 6, 7, 6, -1
Original Confidences: 3, 3, 3, 4, -1

Aggregated Review:
### Key Points
This paper presents a study on uncertainty estimation in the ranking of large language models (LLMs), focusing on how to rank LLMs based on response quality using a combination of human and model-generated pairwise comparisons. The authors propose a prediction powered inference (PPI) framework to construct rank sets for each candidate LLM, demonstrating that this approach can yield reasonable trade-offs between rank set size and accuracy compared to an oracle method using only human data. The experiments utilize data from the Chatbot Arena platform.

### Strengths and Weaknesses
Strengths:
- The application of PPI for constructing rank sets from pairwise comparisons is timely and relevant.
- The framework is clearly explained, making the paper easy to follow.
- The empirical evaluation is thorough, showcasing desired behaviors of the proposed approach.

Weaknesses:
- The paper primarily applies PPI without substantial novelty or technical depth, limiting its contribution.
- The rank sets are at the dataset level, raising questions about their practical utility.
- The reliance on a single dataset for experiments reduces generalizability.
- The evaluation metrics proposed are not standard, and the absence of true rankings diminishes empirical validity.
- Concerns about potential bias in human pairwise comparisons and the self-recognition problem in LLMs are inadequately addressed.

### Suggestions for Improvement
We recommend that the authors improve the depth of their theoretical contributions to enhance novelty. Additionally, testing the framework on multiple benchmarks, such as MT-bench or AlpacaEval, would help address concerns regarding selection bias and generalization. The authors should also consider incorporating standard ranking metrics like precision/recall @ k, RBO, MAP, or NDCG to strengthen their evaluation. Clarifying the implications of the self-recognition problem in LLMs and exploring error propagation in rank sets from erroneous human comparisons would add valuable insights. Lastly, revisiting the claims regarding coverage guarantees and providing further evidence to support the approximation of baseline intersection probability would bolster the paper's claims.