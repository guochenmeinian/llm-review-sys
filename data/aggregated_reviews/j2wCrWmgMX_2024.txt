ID: j2wCrWmgMX
Title: Kernel Language Entropy: Fine-grained Uncertainty Quantification for LLMs from Semantic Similarities
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 7, 7, 6, 4, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 2, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method called Kernel Language Entropy (KLE) for uncertainty estimation in both white- and black-box LLMs. KLE utilizes positive semidefinite unit trace kernels to encode semantic similarities of LLM outputs and quantifies uncertainty through von Neumann entropy. The method accounts for pairwise semantic dependencies, offering finer uncertainty estimates compared to previous hard clustering approaches. The authors theoretically prove that KLE generalizes the existing semantic entropy method and empirically demonstrate its superior performance across various natural language generation datasets and LLM architectures.

### Strengths and Weaknesses
Strengths:
1. The authors propose Kernel Language Entropy, a novel method for uncertainty quantification in natural language generation.
2. The authors provide effective design choices, such as graph kernels and weight functions.
3. The empirical evaluation against baseline methods across multiple tasks and LLMs (up to 70B parameters) shows state-of-the-art results.

Weaknesses:
1. The motivation for choosing the kernel approach is unclear, despite being illustrated in Fig 1.
2. The method's performance appears dependent on the number of sampling times, raising concerns about efficiency.
3. The paper's structure complicates comprehension, with inconsistent use of subsections and unclear definitions, particularly regarding kernel choices and their implications.
4. The empirical results show modest gains over baselines, questioning the strength of the claims made.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation for using kernels in their approach. Additionally, addressing the computational cost associated with iterative sampling is crucial; exploring performance with fewer samples could enhance applicability. We suggest restructuring the paper for better coherence, particularly in Section 3, by clearly delineating definitions and ensuring consistent use of subsections. Clarifying the criteria for kernel selection and discussing the significance of weighting factors in the proposed kernels would also strengthen the manuscript. Finally, we encourage the authors to provide more robust evidence supporting their claims, particularly regarding the performance gains and the reliability of the intermediate models used in their experimental setup.