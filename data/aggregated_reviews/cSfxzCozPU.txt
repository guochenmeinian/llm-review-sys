ID: cSfxzCozPU
Title: Distributional regression: CRPS-error bounds for model fitting, model selection and convex aggregation
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 5, 4, 6, 6, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on distributional regression, focusing on estimating the conditional distribution of a response variable given predictors. The authors propose minimizing the risk function using the Continuous Rank Probability Score (CRPS) and provide theoretical guarantees for model fitting, selection, and aggregation. The work includes concentration bounds for the empirical risk minimization (ERM) estimator and explores error bounds for the predictive distribution.

### Strengths and Weaknesses
Strengths:
- Comprehensive Approach: The use of distributional regression offers a holistic view by modeling the entire conditional distribution, providing deeper insights than traditional methods.
- Theoretical Contributions: The authors present a robust theoretical framework, including error bounds for the predictive distribution, enhancing the reliability of predictions.
- Clear Presentation: The paper is well-structured and clearly written, with rigorous proofs and organized notations.

Weaknesses:
- Typos and Clarity: The text contains typos and several mathematical symbols or abbreviations are used without prior definition, affecting readability.
- Limited Technical Contribution: The proving techniques are standard, and the paper lacks new algorithm proposals or insights for algorithm design.
- Insufficient Experimental Validation: The experimental section does not adequately utilize the theoretical guarantees, and the results lack clarity and sensitivity analysis. The experiments do not sufficiently validate the theoretical bounds.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the text by correcting typos and defining all mathematical symbols and abbreviations upon first use. Additionally, the authors should enhance the technical contribution by proposing new algorithms or providing insights for algorithm design. We suggest that the authors conduct more comprehensive experiments that better align with the theoretical results, including sensitivity analyses and validation across diverse datasets. Finally, a detailed complexity analysis should be included to clarify the computational cost of the proposed method relative to existing techniques.