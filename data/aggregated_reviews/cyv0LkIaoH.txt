ID: cyv0LkIaoH
Title: Self-Consuming Generative Models with Curated Data Provably Optimize Human Preferences
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 7, 6, 6, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates the properties of self-consuming loops in generative models and presents a theoretical framework addressing the support of probability distributions in reinforcement learning. The authors focus on the effects of data curation on iterative retraining performance in generative models, exploring how various strategies—such as using only synthetic data, mixing real data, or employing human-preference curated samples—impact model performance. They clarify that their theory accommodates scenarios where the support of \( p_{t+1} \) is included in that of \( p_t \), contingent on the assumption that the reward is bounded over the support of \( p_0 \). The study highlights the significance of addressing data contamination issues in generative models, particularly in the context of human-curated data, and discusses implications of infinite capacity and training data regimes that prevent generalization errors. Additionally, the authors propose an extension to their model to account for data accumulation in web-scaled datasets, suggesting that this does not hinder the collapse of the model to maximal reward regions.

### Strengths and Weaknesses
Strengths:
- The work is highly original, addressing novel problems regarding the impact of human-curated synthetic data on self-consuming generative models and providing a clear theoretical foundation for claims about probability distribution supports.
- The authors clearly motivate the problem and provide significant contributions to burgeoning areas of research, with empirical experiments supporting their theoretical claims.
- They acknowledge and address potential limitations in their assumptions, demonstrating a willingness to refine their work based on feedback.
- The proposed extension to incorporate data accumulation enhances the relevance of their model.

Weaknesses:
- The presentation of theorem statements and key assumptions needs improvement for clarity and contextualization, particularly regarding the assumptions and key notations.
- Some theoretical results are derived from previous works, which may limit the perceived novelty of the contributions.
- The initial presentation of key assumptions and conditions was not sufficiently clear, potentially leading to confusion.
- The writing quality requires enhancement, with certain mathematical notations introduced without adequate explanation and missing literature references.
- The omission of concurrent work in the field may limit the contextualization of their findings.

### Suggestions for Improvement
We recommend that the authors improve the clarity of theorem statements by summarizing assumptions and key notations directly within each theorem, similar to the structure used in Bertrand et al.'s work. Additionally, we suggest providing a more thorough contextualization of the results relative to existing literature, particularly distinguishing between iterative fine-tuning and retraining from scratch. The authors should also consider extending their theoretical analysis to account for heterogeneous human preferences and explore the implications of using realistic datasets, such as LAION and Stable Diffusion, in their experiments. Furthermore, we encourage the authors to clarify the contributions of Section 2.2.1 and ensure that all mathematical notations are adequately explained. Finally, we recommend that the authors explicitly highlight the infinite capacity and training data regimes in the manuscript and incorporate a discussion of concurrent work to better situate their contributions within the existing literature.