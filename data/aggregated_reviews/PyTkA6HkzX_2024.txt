ID: PyTkA6HkzX
Title: Controlling Counterfactual Harm in Decision Support Systems Based on Prediction Sets
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 6, 5, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework for decision support systems that utilize prediction sets to assist humans in multi-class classification tasks. The authors define "counterfactual harm" as the scenario where the model's intervention leads to incorrect predictions that a human would have made correctly without assistance. They introduce counterfactual and interventional monotonicity assumptions to identify this harm and propose methods to control it using conformal risk control. The paper validates its theoretical findings through experiments on human subject studies, revealing a trade-off between post-intervention accuracy and counterfactual harm. Additionally, the authors emphasize the importance of counterfactual harm in high-stakes domains and propose that their approach leverages specific monotonicity assumptions to identify counterfactual harm directly from observational data, contrasting it with existing methods that do not utilize these assumptions. They also clarify their notation, aligning it with Peters et al. and addressing potential confusion with Pearl's notation.

### Strengths and Weaknesses
Strengths:  
- The formulation of counterfactual harm is significant and provides a theoretical foundation for understanding risks in decision support systems.  
- The authors demonstrate that counterfactual harm can be practically managed through conformal risk control, supported by empirical validation.  
- The writing is generally clear, making complex concepts accessible.  
- The authors provide a clear rationale for their focus on harm-controlling sets and their relevance in decision support systems.  
- They acknowledge and plan to clarify the differences in notation, which enhances the paper's accessibility.  

Weaknesses:  
- The causal inference notation is inadequate, particularly in Definition 1, which undermines the clarity of the proposed definitions.  
- The paper lacks practical examples illustrating the applicability of prediction sets in real-world scenarios, especially in complex domains like healthcare.  
- The experimental section is weak, lacking comparisons with state-of-the-art conformal prediction algorithms regarding conformal accuracy, prediction set size, and counterfactual harm.  
- There is insufficient comparison with other established conformal predictors, which is essential for validating the proposed approach.  
- The paper lacks concrete examples or illustrations demonstrating how their harm-controlling sets address problems not covered by existing methods.  

### Suggestions for Improvement
We recommend that the authors improve the causal inference notation, particularly in Definition 1, to ensure clarity and correctness. A side-by-side comparison of their definition with that of Richens et al. should be included, utilizing a unified notation. Additionally, the authors should provide practical examples of decision support systems based on prediction sets to justify their approach. We suggest enhancing the experimental section by comparing their methods with state-of-the-art conformal prediction algorithms, such as APS and RAPS, to evaluate performance metrics comprehensively. Finally, including a simple example or illustration that demonstrates how the harm-controlling sets can solve a problem not addressed by existing methods would strengthen the paper's contributions. Addressing the trade-off between counterfactual harm and conformal accuracy in more detail would also enhance the overall impact of the work.