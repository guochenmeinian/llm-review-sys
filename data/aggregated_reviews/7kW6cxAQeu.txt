ID: 7kW6cxAQeu
Title: IvRA: A Framework to Enhance Attention-Based Explanations for Language Models with Interpretability-Driven Training
Conference: EMNLP/2024/Workshop/BlackBoxNLP
Year: 2024
Number of Reviews: 2
Original Ratings: -1, -1
Original Confidences: 3, 3

Aggregated Review:
### Key Points
This paper presents the IvRA attention module, which is integrated into a language model (LM) optimized for four interpretability measures: simulatability, comprehensiveness, sufficiency, and consistency. The authors demonstrate through experiments across three LMs and various tasks that IvRA improves performance compared to standard attention and other extractive explainability methods like LIME and IG. Notably, the optimization for consistency negatively impacts performance, while sufficiency and simulatability have minimal effects.

### Strengths and Weaknesses
Strengths:  
- The paper is thoughtful, well-written, and features a comprehensive set of experiments.  
- The IvRA module is practically useful for researchers seeking explanations that meet specific interpretability measures.  
- The ablation studies provide valuable guidance for selecting optimization measures.  
- The methodology is well-founded, addressing significant concerns in interpretability research, and aligns with recent studies.  
- Extensive results illustrate the conflicts among different XAI paradigms, with reasonable explanations provided.  
- Criterion-aligned attention scores prove useful and competitive with typical post-hoc methods, often surpassing them in efficiency.  

Weaknesses:  
- A philosophical question arises regarding whether the four measures are definitions of interpretability or merely indicators, which warrants discussion.  
- Suggestions for improvement in figure clarity and mathematical formalization are noted.

### Suggestions for Improvement
We recommend that the authors improve the discussion surrounding the philosophical implications of the four interpretability measures, specifically addressing Goodhart's law. Additionally, we suggest polishing the figures and enhancing the explanations of the mathematical formalization, particularly ensuring that all variables in figures are clearly labeled and that the depiction of $t^k_i$ is formatted consistently with equations.