ID: iCNoSVJl2y
Title: CCIM: Cross-modal Cross-lingual Interactive Image Translation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an interactive decoding method for Text Image Machine Translation (TIMT), enabling the synchronous generation of source and target sentences. The authors propose a novel architecture utilizing cross-lingual and cross-modal attention mechanisms, demonstrating that their method, CCIM, outperforms existing cascaded baselines and previous TIMT models on a recent benchmark.

### Strengths and Weaknesses
Strengths:
- The proposed method achieves promising results and demonstrates effectiveness against existing methods.
- The writing is clear and well-illustrated with figures, making the methodology easy to follow.

Weaknesses:
- The novelty of the approach is limited, as it directly applies interactive attention techniques previously used in speech translation and multilingual NMT.
- Essential technical details, particularly regarding the interactive decoder and the challenges of word reordering and differing sentence lengths, are not adequately described.
- More related work should be introduced, and further analysis, such as visualization of attention mechanisms, is needed.

### Suggestions for Improvement
We recommend that the authors improve the description of the essential parts of the method, particularly in Section 2.2 regarding the loss functions and the interactive decoding strategy. Additionally, we suggest that the authors conduct more analyses, including visualizations of the attention mechanisms, to enhance understanding of their contributions. Furthermore, exploring the wait-k decoding policy in interactive decoding, as suggested in previous works, could provide additional insights.