ID: 168NLzTpw8
Title: Unleashing Region Understanding in Intermediate Layers for MLLM-based Referring Expression Generation
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 6, 5, 4, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for Referring Expression Generation (REG) using Multi-modal Large Language Models (MLLMs), focusing on the trade-off between detailed descriptions and accurate targeting, which often leads to hallucinations. The authors propose a training-free "unleash-then-eliminate" approach that utilizes intermediate layers of MLLMs and employs a cycle-consistency-based decoding strategy to mitigate hallucinations. Extensive experiments on the RefCOCOg and PHD benchmarks demonstrate that this method outperforms existing techniques in both semantic and hallucination-related metrics.

### Strengths and Weaknesses
Strengths:
1. The observation that intermediate layers of MLLMs can contain more descriptive information than the final layer is insightful.
2. The writing is clear and logical, making the methodologies comprehensible.
3. Experimental results convincingly show the proposed method's superiority over existing approaches.

Weaknesses:
1. The method's reliance on multiple layers for inference leads to low efficiency and increased computational demands.
2. The ablation study lacks depth, particularly regarding the impact of subset size and quality on performance and the use of cycle-consistency-based candidate ranking across the entire dataset.
3. The writing is at times disorganized, and some terms and notations are not clearly defined, which may confuse readers.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing, particularly in the introduction and related work sections, to enhance readability. Additionally, we suggest conducting a more thorough ablation study to explore the effects of subset size and quality on performance and to clarify the role of different RES models in the proposed method. Furthermore, providing explicit definitions for terms and notations, such as Q, H, and W, would significantly aid comprehension.