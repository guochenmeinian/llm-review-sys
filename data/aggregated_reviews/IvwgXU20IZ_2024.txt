ID: IvwgXU20IZ
Title: Monkey See, Model Knew: Large Language Models accurately Predict Human AND Macaque Visual Brain Activity
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 10, 3, 6
Original Confidences: 5, 4, 3

Aggregated Review:
### Key Points
This paper investigates the role of language in shaping visual representations in both humans and non-human primates, specifically rhesus macaques, who lack formal language. The authors propose that language models (LMs) can predict brain activity in both species, suggesting that this predictive power reflects an underlying statistical structure of the world rather than a direct influence of language on visual processing. The study builds on previous research comparing neural representations in AI systems and human brains, emphasizing the need for further exploration of language model predictivity across different species.

### Strengths and Weaknesses
Strengths:
1. The premise of examining whether non-language species like macaques exhibit representations aligning with LMs is intriguing.
2. The experimental results are statistically robust.

Weaknesses:
1. The paper's argument is convoluted, leaving the main goal unclearâ€”whether it aims to determine if language shapes vision or if representational alignment indicates a common underlying structure.
2. The abstract mentions "underlying statistical structure" but fails to elaborate on its implications for representational analysis.
3. There is a lack of discussion regarding the specific models used, as the paper does not clarify which architectures or types of LMs are being referenced.
4. The experimental setup for LMs is vague, particularly regarding the prompts and instructions provided.
5. Limited references to existing beliefs or hypotheses in the field hinder clarity; a related work section would enhance understanding.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their main argument by explicitly stating whether the work aims to assess the influence of language on vision or to highlight representational alignment. Additionally, we suggest that the authors elaborate on the concept of "underlying statistical structure" and its relevance to their findings. It would be beneficial to include a detailed discussion of the specific models used, including their architectures and training types. Clarifying the experimental setup for LMs, including prompts and instructions, is essential. Finally, we encourage the authors to incorporate a related work section to contextualize their claims within existing literature.