ID: k6iyUfwdI9
Title: To Believe or Not to Believe Your LLM: Iterative Prompting for Estimating Epistemic Uncertainty
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 5, 3, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for uncertainty quantification in large language models (LLMs), focusing on distinguishing between epistemic and aleatoric uncertainty through iterative prompting. The authors propose an information-theoretic metric to quantify epistemic uncertainty and validate their approach with experiments on datasets like TriviaQA and AmbigQA. The method aims to enhance the understanding of model behavior in multi-label queries, particularly in identifying high epistemic uncertainty scenarios.

### Strengths and Weaknesses
Strengths:
1. The topic is significant and relevant, addressing critical challenges in uncertainty quantification.
2. The proposed iterative prompting strategy is practical and straightforward to implement.
3. The theoretical framework for understanding epistemic and aleatoric uncertainty is well-defined.

Weaknesses:
1. The writing lacks clarity and formality, making it difficult to grasp the insights and principles.
2. The evaluation protocol is unclear, with missing definitions and explanations for key terms and figures.
3. Limited application scope, as the method primarily addresses multi-label queries and does not adequately consider single-label scenarios.
4. The paper does not sufficiently discuss limitations, particularly regarding the assumptions made in the methodology.

### Suggestions for Improvement
We recommend that the authors improve the clarity and formality of the writing to enhance understanding. Specifically, please clarify the evaluation protocol and ensure that all figures have properly labeled axes. Additionally, we suggest addressing the limitations of the approach, particularly concerning Assumption 4.1 and its implications for context dependence. It would also be beneficial to include a broader range of datasets and models to validate the effectiveness of the proposed method across different scenarios. Lastly, consider revising the title to be more descriptive, such as “Iterative Prompting for Estimating Epistemic Uncertainty.”