ID: LxRmdXf72k
Title: Learning 1D Causal Visual Representation with De-focus Attention Networks
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 7, 4, 6, 4, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 2, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an improvement to existing 1D causal models for visual inputs, addressing the "over-focus" issue where models concentrate on a few tokens rather than capturing comprehensive image information. The authors propose the De-focus Attention Networks (DANs), which utilize learnable bandpass filters and strategies such as large drop path rates and an auxiliary loss on globally pooled features to enhance attention diversity and model optimization. Experimental results demonstrate that the proposed approach achieves performance comparable to 2D non-causal models across various tasks, including image classification and multi-modal understanding.

### Strengths and Weaknesses
Strengths:
1. The identification of the over-focus issue in 1D causal visual modeling provides a valuable foundation for this work.
2. The introduction of the De-focus Attention strategy, incorporating learnable bandpass filters, is a reasonable and innovative approach.
3. Extensive experiments validate the effectiveness of the proposed methods across multiple visual understanding benchmarks.

Weaknesses:
1. The paper lacks discussion on the generalization capabilities of the De-focus network in comparison to 2D non-causal architectures, particularly regarding resolution variations.
2. Some viewpoints, such as the causal reasoning abilities of standard Transformers without causal attention masks, are unclear and require further clarification.
3. The evaluation of the proposed method is inconsistent, with missing comparisons for different model sizes and tasks, particularly in cross-modal retrieval.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the generalization of the De-focus network, particularly in scenarios involving different resolutions. Additionally, we suggest providing clearer explanations regarding the causal reasoning capabilities of existing models and the rationale behind the positioning of learnable decay and learnable RoPE in the attention mechanism. It would be beneficial to include comparisons with large spatial dropout or randomly dropping masked image tokens to substantiate the advantages of the Large Drop Path Rate. Furthermore, we advise the authors to enhance the evaluation by including performance metrics related to model FLOPs and latency, and to ensure comprehensive comparisons across various model sizes and tasks in their experimental results.