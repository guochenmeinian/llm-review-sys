ID: 0n92zm014A
Title: Self-ICL: Zero-Shot In-Context Learning with Self-Generated Demonstrations
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Self-ICL, a method for zero-shot in-context learning (ICL) that utilizes pseudo-inputs as contextual examples. The authors propose generating pseudo-inputs and predicting pseudo-labels for these inputs via zero-shot prompting, using these pairs as demonstrations for test inputs. The effectiveness of Self-ICL is demonstrated on the BIG-Bench Hard tasks, showing superiority over zero-shot baselines and performance comparable to real demonstrations.

### Strengths and Weaknesses
Strengths:  
- The methodology is sensible and addresses a relevant problem in extending ICL to a strictly zero-shot setup.  
- The paper is well-written and easy to follow, with thorough experiments and convincing dataset choices.  
- Self-ICL achieves state-of-the-art performance in some tasks without requiring external data.  

Weaknesses:  
- The novelty of using pseudo-inputs as in-context examples is questionable, and the paper lacks an in-depth analysis of the impact of different types of pseudo-inputs.  
- The method requires more prompting of the LLM, which may increase user burden and computational costs compared to existing methods like AutoCoT.  
- Generalizability is unclear, as the evaluation is limited to InstructGPT without testing on other models or datasets.

### Suggestions for Improvement
We recommend that the authors clarify the practical significance of their strictly zero-shot setup compared to existing methods, particularly in terms of user burden and computational efficiency. Additionally, the authors should analyze the effectiveness of various types of pseudo-inputs and develop methods for filtering low-quality examples. To enhance generalizability, we suggest evaluating Self-ICL on other models such as LLaMA, Falcon, and Flan-T5, and including comparisons with previous approaches in benchmarking tables. Finally, we encourage the authors to discuss the limitations of their approach, particularly regarding the risks of using incorrect few-shot examples generated by the LLM.