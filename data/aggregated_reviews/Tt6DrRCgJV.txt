ID: Tt6DrRCgJV
Title: GIMLET: A Unified Graph-Text Model for Instruction-Based Molecule Zero-Shot Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 7, 6, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents GIMLET, a unified graph-text model designed for instruction-based molecule zero-shot learning. It utilizes natural language instructions and a novel relative position embedding to enhance the interaction between graph and text data. The authors demonstrate GIMLET's effectiveness through experiments on various downstream tasks, showcasing its potential in molecule-related applications.

### Strengths and Weaknesses
Strengths:
- GIMLET introduces a novel approach by treating graph nodes and instruction tokens as input tokens, which alleviates structural information loss.
- The authors provide a comprehensive dataset for pretraining, which is a valuable resource for the research community.
- Empirical results indicate strong performance in zero-shot learning compared to several baselines, including GNNs and other models.
- The paper is well-written and includes detailed appendices that enhance understanding.

Weaknesses:
- The paper lacks detailed training information, such as total iterations and hyper-parameters, which are crucial for reproducibility.
- The computational requirements for training GIMLET from scratch with a large dataset are not addressed, raising concerns about feasibility.
- The input model's clarity is insufficient; a sample input-output pair would enhance understanding.
- The paper does not include a limitations section or discuss potential social impacts, which is necessary for ethical considerations.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the training details by including total iterations and hyper-parameters. Additionally, the authors should address the computational requirements for training GIMLET to provide a clearer picture of its feasibility. Including a sample input-output pair in the appendix would enhance the model's clarity. We also suggest adding a limitations section and a discussion on potential social impacts to address ethical considerations adequately.