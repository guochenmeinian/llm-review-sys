ID: 4L9g1jUDtO
Title: Generalization in the Face of Adaptivity: A Bayesian Perspective
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 7, 7, 6, 5, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper explores adaptive data analysis, focusing on the issue of overfitting when a single dataset is used for multiple queries. The authors propose that adding noise to query outputs can mitigate this bias, with differential privacy (DP) being a common approach. However, DP's worst-case nature necessitates noise scaling based on extreme datasets rather than typical ones. The paper's contributions include: 1) establishing that posterior accuracy correlates with the Bayes factor; 2) introducing pairwise concentration as a new stability measure that avoids DP's worst-case requirements; and 3) demonstrating that noise can be scaled with the standard deviation of each query, improving upon previous work by Feldman and Steinke (FS 18) in terms of probability guarantees and handling unbounded ranges.

### Strengths and Weaknesses
Strengths:
- The authors provide a refined analysis of scaling noise to the standard deviation of queries, demonstrating that error bounds hold with high probability and extend to unbounded subgaussian queries.
- The introduction of pairwise concentration offers a novel perspective that may have broader applications in adaptive data analysis.
- The paper presents several new tools and measures for assessing dissimilarity between distributions, enhancing the analytical framework.

Weaknesses:
- The definition and application of pairwise concentration are complex, and a simpler interface could enhance its applicability.
- The algorithm currently only addresses linear queries, limiting its generalizability compared to DP techniques that accommodate low-sensitivity queries.
- The paper lacks empirical evaluations to substantiate its theoretical claims, particularly in demonstrating the impact on preventing overfitting.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the pairwise concentration definition and its application in Theorem 4.5 by explicitly stating that it only requires bounding datasets differing by one point. Additionally, consider simplifying the conditions regarding $\xi$ and $\epsilon$ to enhance usability. We also suggest exploring the possibility of estimating query standard deviations dynamically, similar to FS 18, to broaden the algorithm's applicability. Finally, conducting empirical evaluations, such as toy regression experiments, would strengthen the paper's claims regarding overfitting prevention.