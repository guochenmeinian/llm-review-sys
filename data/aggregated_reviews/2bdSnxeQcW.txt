ID: 2bdSnxeQcW
Title: Exclusively Penalized Q-learning for Offline Reinforcement Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 5, 7, 8, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates the issue of mitigating unnecessary conservatism in offline reinforcement learning (RL) value functions, specifically through the introduction of an exclusive penalty term $P_\tau=f_\tau^{\pi,\hat{\beta}}(s) \left(\dfrac{\pi}{\hat{\beta}}-1\right)$. The authors propose a *Prioritized Dataset* (PD) trick to reduce bias and derive the final optimization objective for their EPQ approach. Experimental results on D4RL datasets demonstrate that EPQ outperforms existing methods.

### Strengths and Weaknesses
Strengths:
- The authors focus on value-based offline RL methods, presenting a novel weighting method to address over-conservatism in CQL, which is a significant contribution.
- The paper is well-presented, featuring illustrative toy examples and comparisons against strong baselines, aiding reader comprehension.
- Experimental results are comprehensive, showing EPQ's strong performance across various datasets.

Weaknesses:
- EPQ introduces multiple hyperparameters, requiring manual tuning for new datasets, which may hinder practical application.
- The ablation study is insufficient, with evaluations limited to a single environment, necessitating broader testing to assess hyperparameter sensitivity and the impact of the PD trick.
- The relationship between the proposed penalty term $P_\tau$ and existing methods like RND is unclear, raising questions about its advantages.

### Suggestions for Improvement
We recommend that the authors improve the ablation study by evaluating EPQ across a wider range of datasets to thoroughly examine hyperparameter sensitivity and the effects of the PD trick. Additionally, we suggest clarifying the advantages of the penalty term $P_\tau$ over RND and exploring direct optimization of Equation 3 with tuning of $\alpha$. Furthermore, enhancing the accessibility of figures, particularly Figures 1 and 2, would improve presentation. Lastly, addressing the formatting issues and ensuring confidence intervals for baseline methods in results would strengthen the paper.