ID: HNH1ykRjXf
Title: Online Feature Updates Improve Online (Generalized) Label Shift Adaptation
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 5, 6, 3, 5, -1, -1, -1, -1, 7, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, 3, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for addressing online label shift (OLS) adaptation, where label distributions change over time without access to true labels during testing. The authors propose Online Label Shift adaptation with Online Feature Updates (OLS-OFU), which enhances feature representations using self-supervised learning (SSL) during test time. The method aims to maintain online regret convergence while improving predictive performance. Theoretical analysis and extensive experiments demonstrate the effectiveness of OLS-OFU across various datasets and scenarios. Additionally, the paper includes an ablation study comparing the performance of OLS-OFU with its variant OLS-OFU-difforder, utilizing the CIFAR-10 dataset with rotation degree prediction as the SSL and a sinusoidal shift pattern. Results indicate that when the batch size $\tau=1$, the difference in performance between the two algorithms is significant, and even with a larger batch size $\tau=100$, applying Principle 1 leads to non-negligible improvements in performance.

### Strengths and Weaknesses
Strengths:
- The paper effectively describes the mathematical framework for OLS adaptation and provides a comprehensive exploration of the proposed method.
- The integration of SSL techniques into OLS methods shows strong empirical performance and theoretical guarantees, ensuring general applicability.
- Experimental results indicate significant improvements in classification accuracy, validating the proposed approach.
- The empirical evidence provided through the ablation study effectively supports the relevance of Principle 1 in practical scenarios.
- The detailed performance metrics across different settings enhance the robustness of the findings.

Weaknesses:
- The motivation for the proposed method lacks clarity, relying on the intuitive notion of improving feature extractors without sufficient theoretical or empirical justification.
- The novelty of the method appears limited, as it combines existing OLS and SSL approaches without clear differentiation from prior work.
- The requirement for storing historical data raises data privacy concerns, and the experiments primarily utilize simulated datasets, limiting practical applicability.
- The paper suffers from structural issues, with insufficient introduction to related OLS methods and an overly brief conclusion.
- The initial observation of no difference at $\tau=100$ may require clearer explanation to avoid potential misinterpretation of results.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation behind their approach, providing more robust theoretical or empirical support for the benefits of enhancing feature extractors specifically for label shift scenarios. Additionally, the authors should clarify the novelty of their contributions compared to existing literature on OLS and SSL. It would be beneficial to address data privacy concerns by exploring alternatives to storing historical data, such as data augmentation techniques. Furthermore, we suggest improving the clarity of the explanation regarding the performance results at $\tau=100$ to ensure that the implications of Principle 1 are fully understood. Finally, we recommend restructuring the paper to provide a more balanced introduction to related OLS methods and a more comprehensive analysis of experimental results, including a detailed conclusion.