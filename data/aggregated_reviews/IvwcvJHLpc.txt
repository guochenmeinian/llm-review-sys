ID: IvwcvJHLpc
Title: IdealGPT: Iteratively Decomposing Vision and Language Reasoning via Large Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents IdealGPT, a zero-shot framework for open-domain visual question-answering (VQA) tasks that utilizes large language models (LLMs) to iteratively decompose visual-language reasoning. The framework consists of three components: a Questioner, an Answerer, and a Reasoner, which work together to refine answers based on sub-questions. IdealGPT demonstrates superior performance on challenging VL reasoning tasks, outperforming existing models like GPT-4 by significant margins.

### Strengths and Weaknesses
Strengths:  
- The framework is novel, easy to reproduce, and provides a clear understanding of the reasoning process by breaking down questions into manageable parts.  
- IdealGPT shows strong generalizability across various tasks and achieves state-of-the-art results in zero-shot settings.  
- The method is well-structured and clearly articulated, making it accessible for further research.

Weaknesses:  
- The performance is heavily reliant on the capabilities of the Answerer (VLM), which may limit generalizability.  
- The framework requires multiple iterations, potentially increasing latency and computational costs.  
- The prompts for LLMs are manually designed, complicating the optimization process and introducing risks of biases and hallucinations.

### Suggestions for Improvement
We recommend that the authors improve the exploration of how different VLMs affect performance and include essential baselines, such as VQG and Co-VQA, to strengthen their comparative analysis. Additionally, we suggest that the authors provide more evaluation datasets to demonstrate the generalizability of IdealGPT across various tasks. Addressing the potential biases and hallucination issues associated with using ChatGPT as the Questioner and Reasoner would also enhance the robustness of the framework. Finally, considering automatic prompt generation or optimization techniques could further improve performance without relying solely on manually designed prompts.