ID: i5PoejmWoC
Title: Causal language modeling can elicit search and reasoning capabilities on logic puzzles
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 8, 5, 5, 7, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on solving Sudoku puzzles using causal language models (Transformers), achieving a 94.21% accuracy rate. The authors propose that these models can develop human-like reasoning capabilities through structured training data and probing analyses. They demonstrate that appropriate training data, which breaks down the problem, is essential for the model's success. The study evaluates various input representations and highlights the importance of the order in which cells are filled.

### Strengths and Weaknesses
Strengths:
- The problem definition, model description, and experimental setup are clear and accessible.
- The introduction of a Sudoku puzzle dataset with steps to solve the puzzles is a valuable contribution.
- The probing analysis effectively tracks the candidate set of cell values.

Weaknesses:
- The selection of puzzles solvable by a simple solver simplifies the problem, limiting the model's demonstrated capabilities in planning and reasoning.
- The paper lacks comparisons to traditional Sudoku-solving algorithms, which is necessary for assessing advancements meaningfully.
- There is insufficient discussion on computational efficiency and costs associated with different methodologies.
- The probing methodology is questionable, as it does not adequately examine intermediate representations or the model's internal reasoning processes.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the filtering of the dataset, emphasizing that the model may only learn from 'Easy Sudoku' puzzles. Additionally, the authors should provide comparisons to traditional Sudoku-solving algorithms to better contextualize their results. A more detailed error analysis is necessary to understand the model's failure modes. We suggest that the authors clarify the polynomial time claim and mention the 42M parameter GPT-2 architecture earlier in the paper. Finally, exploring the model's performance against puzzle difficulty ratings and its generalization to other reasoning tasks would enhance the paper's impact.