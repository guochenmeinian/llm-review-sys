ID: LOH6qzI7T6
Title: Semantic Density: Uncertainty Quantification for Large Language Models through Confidence Measurement in Semantic Space
Conference: NeurIPS
Year: 2024
Number of Reviews: 21
Original Ratings: 5, 5, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel framework for quantifying uncertainty in large language models (LLMs) through the concept of "Semantic Density" (SD), which measures uncertainty from a probability distribution perspective in semantic space. The authors demonstrate that SD can be applied to any pre-trained LLM without additional training and show its effectiveness through experiments on various state-of-the-art LLMs and benchmarks, indicating that SD outperforms existing methods in accuracy and robustness. Additionally, the paper provides a comprehensive evaluation of various language models across multiple datasets, including CoQA, TriviaQA, SciQ, and NQ, using metrics such as Rouge-L and AUROC. The authors propose a modified version of semantic entropy and semantic density to assess uncertainty in language generation tasks, with results indicating that these methods consistently outperform traditional approaches across different models and tasks.

### Strengths and Weaknesses
Strengths:
- The introduction of Semantic Density as a method for quantifying uncertainty in LLM responses is innovative.
- The framework is well-structured, with clear theoretical foundations and implementation details.
- The empirical results demonstrate that SD performs well across multiple datasets and models.
- The paper provides detailed experimental results across multiple datasets, demonstrating the effectiveness of the proposed methods.
- The inclusion of an ablation study enhances the understanding of how different parameters affect model performance.

Weaknesses:
- The theoretical grounding of Semantic Density in uncertainty quantification theory is insufficient, as it is presented as an ad-hoc solution rather than a robust theoretical framework.
- The experimental setup relies on a fixed Rouge-L threshold of 0.3, which may not adequately assess performance given the short responses typical of the datasets used.
- The literature review lacks comprehensiveness, omitting recent and relevant works that could enhance the discussion.
- The theoretical foundation of the proposed methods lacks robustness, particularly in the context of uncertainty quantification.
- The presentation of results could be improved; the extensive tables may benefit from a more concise representation, such as line plots.

### Suggestions for Improvement
We recommend that the authors improve the theoretical foundation of Semantic Density by grounding it more firmly in established uncertainty quantification theory. Additionally, consider using multiple thresholds for Rouge-L to better evaluate the performance of uncertainty metrics, as a fixed threshold may not be sufficient. It would also be beneficial to expand the literature review to include recent methods such as Kernel Language Entropy and to discuss their relevance. Furthermore, we suggest providing more details on prompt construction in Section 3.2 and exploring the applicability of SD to other types of tasks beyond question-answering. Lastly, we recommend summarizing the extensive results in a line plot format to enhance clarity and accessibility for readers, and conducting an ablation study on the sensitivity of hyperparameters used in the diverse beam search sampling strategy to provide valuable insights into the robustness of the method.