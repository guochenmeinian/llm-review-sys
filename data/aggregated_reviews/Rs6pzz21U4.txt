ID: Rs6pzz21U4
Title: A Partially-Supervised Reinforcement Learning Framework for Visual Active Search
Conference: NeurIPS
Year: 2023
Number of Reviews: 7
Original Ratings: 5, 6, 6, 5, -1, -1, -1
Original Confidences: 3, 4, 4, 2, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel Partially Supervised Reinforcement Learning (PSVAS) framework for visual active search in geospatial images. The authors propose integrating visual supervised signals and a meta-learning approach to enhance adaptability to varying test cases and support multiple queries. Experimental results indicate that the proposed method significantly outperforms both baseline approaches and previous RL-based methods on the xView and DOTA benchmarks.

### Strengths and Weaknesses
Strengths:
- The proposed method is intuitive and technically sound, effectively utilizing target-location labels as additional supervision.
- The motivation for test-time and multi-query adaptation is well-justified.
- A variety of datasets and settings substantiate the superior performance of the proposed method.
- The manuscript is well-written, enhancing clarity and comprehension.

Weaknesses:
- The addition of supervised loss appears more as an engineering extension rather than a novel contribution.
- The method is limited to two benchmarks; testing on traditional vision benchmarks would enhance its contribution.
- More ablation studies are needed to deepen understanding, particularly regarding hyper-parameters and module interactions.
- The binary classification loss used could be improved by integrating a more fine-grained supervised loss, such as detection or segmentation loss.
- The lack of clarity in the paragraph from lines 128 to 140 needs restructuring for better logical consistency.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the section from lines 128 to 140 to enhance logical consistency. Additionally, conducting more ablation studies, particularly on the balancing factor between RL and BCE loss, would provide valuable insights. Testing the method on traditional vision benchmarks and discussing its applicability across different datasets would significantly strengthen the paper. Finally, we suggest considering the integration of a more fine-grained supervised loss to potentially enhance overall performance.