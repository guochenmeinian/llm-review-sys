ID: iF7MnXnxRw
Title: Understanding the Differences in Foundation Models: Attention, State  Space Models, and Recurrent Neural Networks
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 6, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Dynamical Systems Framework (DSF) for analyzing and comparing various sequence models, including linear attention, State Space Models (SSMs), and Recurrent Neural Networks (RNNs). The DSF reformulates these models into a common dynamical systems representation, facilitating principled comparisons and generating insights into their similarities and differences. The authors aim to explore the role of state expansion and propose improvements to RNN architectures based on insights from SSMs, supported by empirical results on the multi-query associative recall (MQAR) task and the WikiText-103 dataset.

### Strengths and Weaknesses
Strengths:
- The paper provides a novel unified perspective on different foundation model architectures, enabling new theoretical insights.
- It includes sound theoretical analysis with supporting lemmas and proofs.
- The empirical validation on MQAR and WikiText-103 grounds the theoretical contributions in practical results.
- The paper is well-written and organized, making it accessible to researchers without extensive background knowledge.

Weaknesses:
- The originality of the DSF is diminished by prior discussions of its components in existing literature.
- The empirical evaluation is limited to two tasks, which may not generalize well to other contexts.
- The theoretical insights are somewhat straightforward and do not fully explore implications for training or inference efficiency.
- Some claims, particularly around Lemma 2, lack sufficient qualification and could mislead readers regarding expressivity.

### Suggestions for Improvement
We recommend that the authors improve the introduction to provide a high-level overview of the DSF and its significance, making it more accessible to a broader audience. Additionally, we suggest incorporating discussions of alternative data modalities beyond language to enhance the insights drawn from the DSF. It would also be beneficial to address the theoretical novelty by acknowledging existing studies that have explored similar comparisons. Furthermore, we encourage the authors to include more diverse empirical evaluations and to clarify the implications of their findings for practical applications in model selection and architecture design.