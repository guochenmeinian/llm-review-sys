ID: 1gUUznQgVC
Title: SAC$^3$: Reliable Hallucination Detection in Black-Box Language Models via Semantic-aware Cross-check Consistency
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method called SAC^3, aimed at detecting hallucinations in LLMs through a novel approach that includes question paraphrasing and cross-model checking. The authors propose generating semantically equivalent questions and verifying the consistency of answers across these variants and different models. The method shows significant performance improvements over existing self-consistency approaches on multiple datasets. Additionally, the paper identifies two types of hallucinations: question-level and model-level, and introduces a weighted hallucination score for detection.

### Strengths and Weaknesses
Strengths:
- The proposed method demonstrates superior performance compared to traditional self-consistency methods, particularly in classification QA tasks.
- The authors conduct thorough analyses, showcasing the efficacy of their approach on the gpt-3.5-turbo model.
- The paper is well-written and presents a valuable contribution to the field of hallucination detection.

Weaknesses:
- The method is computationally expensive due to multiple API calls for paraphrasing, response sampling, and consistency checking.
- Evaluation is limited to synthesized datasets and the gpt-3.5-turbo model, raising concerns about the generalizability of results.
- The improvement in generation QA tasks is less pronounced, and the authors do not adequately discuss this in the experimental section.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by testing their method on real outputs from LLMs and additional models, including open-source options, to better assess its efficacy. Additionally, the authors should address the computational costs associated with their method and explore its applicability to various LLMs. Clarifying the criteria for determining answer consistency, particularly regarding the treatment of explanations, would also enhance the paper's rigor.