ID: 9Oi3YxIBSa
Title: Loss Decoupling for Task-Agnostic Continual Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 6, 5, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates the stability-plasticity tradeoff in a task-agnostic continual learning (CL) setting by introducing loss decoupling (LODE). LODE separates the learning objectives for new tasks into two components: new/old class distinction and new class distinction, allowing for different weights to be assigned to each. The authors evaluate the proposed method through experiments on CIFAR10, CIFAR100, and TinyImageNet, demonstrating its effectiveness in improving the stability-plasticity tradeoff compared to existing methods.

### Strengths and Weaknesses
Strengths:
- The proposed idea of LODE is simple yet innovative, likely to attract attention within the CL community.
- The paper is well-written, with clear presentation and thorough experimental design, including detailed comparisons in both offline and online settings.
- Experimental results indicate that LODE outperforms state-of-the-art methods, enhancing the practical applicability of continual learning algorithms.

Weaknesses:
- The experiments are limited to ResNet18; including larger models for evaluation would be beneficial.
- The paper lacks a description of the learning rate used across methods, raising questions about consistency and optimization.
- The reliance on heuristic weight selection in LODE is a concern, as it is sensitive to these choices and lacks justification.
- The focus on task-agnostic problems limits the exploration of LODE's applicability to other continual learning scenarios.

### Suggestions for Improvement
We recommend that the authors improve the paper by including evaluations with larger models to enhance the robustness of their findings. Additionally, a detailed description of the learning rate and its determination process should be provided to clarify its impact on the results. Incorporating TSNE visualizations could validate the assumptions made regarding the model's performance. Furthermore, we suggest exploring the application of LODE in exemplar-free settings and comparing it with other loss decoupling methods to strengthen its novelty. Lastly, addressing the weight selection process through a more principled optimization approach could enhance the overall quality of the paper.