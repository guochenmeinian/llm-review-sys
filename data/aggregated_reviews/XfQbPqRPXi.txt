ID: XfQbPqRPXi
Title: Towards Better Evaluation of GNN Expressiveness with BREC Dataset
Conference: NeurIPS
Year: 2023
Number of Reviews: 25
Original Ratings: 6, 8, 7, 8, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 5, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the BREC dataset, a benchmark for evaluating the expressiveness of graph neural networks (GNNs) through 800 non-isomorphic graphs categorized into Basic Graphs, Regular Graphs, Extension Graphs, and CFI Graphs. The authors propose a new evaluation method called RPC, which assesses the performance of 23 models on BREC, demonstrating its utility in distinguishing expressiveness among GNN architectures. The dataset is curated to include graphs with known hardness properties, enhancing the empirical analysis of GNN expressiveness. The authors argue that previous datasets inadequately assess whether theoretically powerful models achieve their expressiveness in practice, and BREC addresses issues of difficulty, granularity, and scale, providing a more comprehensive framework for expressiveness analysis.

### Strengths and Weaknesses
Strengths:  
1. The BREC dataset is diverse and well-constructed, addressing gaps in existing literature regarding expressiveness analysis.  
2. The paper provides a comprehensive evaluation of multiple models, contributing significantly to the GNN community.  
3. The contrastive task introduced allows for a clearer assessment of model performance without the complications of multiclass predictions.  
4. The dataset's design considers critical factors such as difficulty and granularity, enhancing its utility for researchers.  
5. The integration of the dataset into standard APIs, such as PyTorch Geometric, enhances usability.

Weaknesses:  
1. The practical value of graph expressiveness is not clearly discussed, raising questions about its relevance in real-world applications.  
2. The dataset's size, while larger than previous synthetic datasets, may still be perceived as insufficient for robust generalization insights, with only 400 pairs derived from 29 different graphs.  
3. Some sections of the paper suffer from language issues and lack clarity, particularly regarding the theoretical underpinnings of the evaluation metrics and the reporting of dataset size.  
4. The dataset primarily focuses on structural information, which may limit its applicability in broader contexts.  
5. The code's accessibility for quick testing may pose challenges for some users, despite efforts to distribute it via standard APIs.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the practical implications of graph expressiveness, specifically how it translates to real-world applications and generalization capabilities. Additionally, clarifying the novelty of the BREC dataset compared to existing datasets would enhance its contribution. We suggest providing more detailed explanations of the evaluation metrics and enhancing the theoretical analysis of the new evaluation metric presented in Equation 1, possibly by contrasting it with alternative measures like centered kernel alignment. Furthermore, we recommend improving the clarity of the dataset size reporting by consistently distinguishing between the total number of graphs and the number of pairs. Consider adding more contextual examples to illustrate how the graph types relate to real-world applications, such as molecular or social network graphs. Finally, addressing language and clarity issues throughout the paper, along with providing clearer documentation and examples for users, will improve its accessibility and readability.