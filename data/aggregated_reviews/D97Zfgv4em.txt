ID: D97Zfgv4em
Title: MeaeQ: Mount Model Extraction Attacks with Efficient Queries
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new algorithm for model extraction, which aims to train a student model to mimic a teacher model without access to the original training data, instead querying the teacher model API for labels. The proposed method enhances query efficiency through a two-step process: data filtering using a natural language inference classifier and data clustering to select representative examples for querying. Experiments demonstrate the algorithm's effectiveness across various tasks, showing improvements over random sampling and active learning.

### Strengths and Weaknesses
Strengths:
- The paper addresses a relevant issue in the context of large language models and black-box APIs.
- It introduces a straightforward and intuitive algorithm for query-efficient model extraction.
- The experimental results indicate strong performance improvements and include informative ablation studies.

Weaknesses:
- The focus on BERT fine-tuning is outdated compared to current state-of-the-art language models.
- The strict query budget (<1K queries) lacks justification, especially given the low cost of API access.
- The filtering process's effectiveness is unclear, and examples of filtered data would enhance understanding.
- The paper does not discuss potential defenses against model extraction.

### Suggestions for Improvement
We recommend that the authors improve the timeliness of the paper by applying their methods to instruction tuning settings and comparing sample efficiency with techniques like self-instruct. Additionally, justifying the strict query budgets with cost estimates from different APIs is critical. Providing examples of the filtered data would clarify the filtering process, and a discussion on possible defenses against model extraction would be beneficial. Finally, expanding experiments to include larger language models and a broader range of tasks would enhance the paper's relevance and applicability.