ID: UaJErAOssN
Title: State Space Models on Temporal Graphs: A First-Principles Study
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 6, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an approach for processing discrete-time temporal graphs through an extension of state-space models (SSMs). The authors propose a generalization of the HIPPO framework for graph-structured data, termed GHIPPO, which outlines how the state of different nodes should be updated over time to compress the evolution of node features. The experimental evaluation demonstrates that the SSM-based solution, GraphSSM, outperforms various methods on multiple datasets, including DBLP-3, Brain, Reddit, DBLP-10, arXiv, and Tmall.

### Strengths and Weaknesses
Strengths:  
- The paper is well-written and presents an interesting research direction, highlighting the application of SSMs to graph-structured data.  
- The experimental evaluation appears robust, with GraphSSM outperforming prior approaches across different datasets.  

Weaknesses:  
- The proposed approach may struggle with heterophilic graphs due to the smoothness in node state imposed in equation (3), which may not serve as an effective regularizer in such contexts.  
- The methodology is limited to discrete-time temporal graphs, necessitating further work to extend it to continuous-time settings.  
- The exposition is occasionally unclear, with specific issues including typos and vague explanations that could confuse readers.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the exposition by addressing the following points:  
1) Correct the typo in line 67 by replacing “features the dynamics” with “the features dynamics.”  
2) Refactor lines 74 to 77 for better clarity.  
3) Replace “recurrence model” with “recurrent model” in line 105.  
4) Include efficient transformer architectures in Table 1 to provide a complete picture of transformer capabilities.  
5) Highlight the limitation of the smoothness in node state for heterophilic graphs in the paper.  
6) Clarify the statement in lines 180-181 regarding the piecewise vector solution.  
7) Provide a clearer explanation of how nodes' memories are parameterized as polynomials in lines 184-185.  
8) Correct the performance statement regarding GraphSSM with S5 in lines 335-336.  
9) Fix the typo in line 339 by addressing the “and” at the beginning of the sentence.  
Additionally, we recommend that the authors conduct experiments swapping the proposed SSM module with RNN or transformer architectures to evaluate the performance impact of using SSMs versus alternative methods.