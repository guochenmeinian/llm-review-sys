ID: TGC7HNf6nK
Title: Lever LM: Configuring In-Context Sequence to Lever Large Vision Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 5, 8, 8, 3, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Lever-LM, a small language model designed to configure effective in-context demonstrations (ICD) for enhancing the in-context learning (ICL) performance of large vision-language models (LVLMs). The authors construct a dataset of effective ICD sequences to train Lever-LM, which generates new ICD configurations for novel queries in vision-language tasks. Experimental results on image captioning and visual question answering (VQA) tasks show that Lever-LM outperforms strong baselines and effectively captures statistical patterns in ICD sequences.

### Strengths and Weaknesses
Strengths:
- The paper introduces an innovative method using Lever-LM for ICD configuration, demonstrating effectiveness in image captioning and VQA.
- A comprehensive range of ablation studies provides valuable insights into various factors affecting Lever-LM's performance.
- The model's structure, utilizing only two layers of Transformer Decoder, enhances efficiency in generating ICD sequences.

Weaknesses:
- The approach requires training a small model for ICD selection, which raises concerns about generalization to other models and tasks beyond VQA and captioning.
- Zero-shot performance comparisons are lacking, and the extrapolation from 2-shot training to higher shots may limit performance gains.
- The experiments do not convincingly demonstrate the model's performance across a broader range of benchmarks and models, particularly in the context of multimodal learning.

### Suggestions for Improvement
We recommend that the authors improve generalization by demonstrating Lever-LM's effectiveness on additional models (e.g., Qwen-VL, InternLM-XComposer2, IDEFICS2, GPT4) and tasks beyond VQA and captioning. Additionally, we suggest including zero-shot performance metrics in Tables 1, 2, and 3 for reference. To enhance the robustness of the findings, we encourage the authors to evaluate Lever-LM against traditional ICD ranking methods and explore its performance in LLMs to showcase versatility. Finally, we advise conducting further experiments with more benchmarks, such as M-ICL, MM-Vet, and SEED-Bench, to assess the generalization capability of their approach.