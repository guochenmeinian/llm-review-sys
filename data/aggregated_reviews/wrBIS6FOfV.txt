ID: wrBIS6FOfV
Title: MoqaGPT : Zero-Shot Multi-modal Open-domain Question Answering with Large Language Model
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel framework, MoqaGPT, for zero-shot multimodal open-domain question answering (QA), employing a divide-and-conquer strategy to extract and fuse answers from multiple modalities. The authors conduct extensive experiments, demonstrating impressive performance improvements over existing retrieval and question-answering methods. The approach is well-structured, easy to follow, and shows promising results on datasets such as MMCoQA and MultiModalQA.

### Strengths and Weaknesses
Strengths:
- The proposed method demonstrates strong performance and addresses a challenging problem in multimodal QA.
- The paper is well-written and easy to follow, with a clear presentation of the experimental results.
- The framework is simple and effective, making it applicable in real-world scenarios.

Weaknesses:
- The novelty of the approach may be limited, as similar pipelines exist in related tasks.
- The ablation studies are incomplete, primarily focusing on the ChatGPT family, which raises concerns about data contamination and reproducibility.
- The paper lacks error case analysis, which is crucial given the instability of LLM outputs.

### Suggestions for Improvement
We recommend that the authors improve the ablation studies by including results from a broader range of open-sourced models for reasoning, as suggested in https://openreview.net/forum?id=wrBIS6FOfV&noteId=bPutO2Ja6P. Additionally, it would be beneficial to incorporate error case categories in the experiments to provide a more comprehensive evaluation of the model's performance. Furthermore, addressing the differences in performance across datasets and including more baseline comparisons would strengthen the overall findings.