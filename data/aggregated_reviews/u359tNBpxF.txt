ID: u359tNBpxF
Title: Robust Data Valuation with Weighted Banzhaf Values
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 6, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an extension of Banzhaf values to weighted Banzhaf values aimed at enhancing data ranking robustness under Kronecker noise. The authors demonstrate that minimizing worst-case entropy leads to the most robust parameters within this framework. They propose a noise model that perturbs the utility function \( v \) for subsets of players/data in a correlated manner based on their overlap, utilizing a product form of noise, \( \tilde v(A) = v(A) + \prod_{i\in A} \epsilon_i \prod_{j\not\in A} \bar\epsilon_j \), which relies on a \( 2\times 2 \) covariance matrix \( \Sigma \) instead of the impractically large \( 2^n \times 2^n \) matrix \( \Lambda \). The authors validate their findings through experiments on noisy label detection and data ranking across multiple datasets, supporting the adaptive phenomenon where no single value dominates across experimental settings.

### Strengths and Weaknesses
Strengths:
- The paper introduces a novel approach by applying Kronecker noise for learning semi-values, which is original and relevant for noisy datasets.
- The proposed noise model is innovative and succinct, effectively addressing the challenge of correlated perturbations.
- Extensive experiments validate the theoretical claims, showcasing the effectiveness of weighted Banzhaf values in achieving consistent data ranking.
- Empirical validation of the theory through differential entropy criteria enhances the robustness of the findings.

Weaknesses:
- The definition of robustness and the assumptions underlying the work are inadequately explained, particularly in Section 3.2.
- The focus on simple models and limited datasets raises concerns about the applicability of the proposed method in more complex, real-world scenarios.
- The justification for the Kronecker noise model and the chosen measure of robustness lacks clarity and intuition.
- The theory for cardinality-based noise levels remains unexplored, presenting a gap in the current research.
- The potential bias introduced by using \( \tilde v(A) = v(A) + \prod_{i\in A} \epsilon_i \) against larger sets is a concern that needs further clarification.

### Suggestions for Improvement
We recommend that the authors improve the introduction by providing a clearer definition of robustness, ideally referencing the Data Banzhaf paper for context. A formal definition should follow to enhance understanding. 

Additionally, the authors should clarify the relationship between weighted Banzhaf values and concepts in cooperative game theory literature, such as binomial semivalues and null player exclusion. 

In the experimental section, it would be beneficial to explore the performance of Beta Shapley values and provide insights on the time complexity and runtime for weighted Banzhaf value calculations. 

We suggest that the authors address the limitations of the Kronecker noise model in relation to real-world data noise and consider discussing alternative noise models. 

Furthermore, we recommend improving the exploration of the theory for cardinality-based noise levels, as it presents an interesting future direction. 

Lastly, minor typographical errors should be corrected, and the presentation of figures should be improved for clarity.