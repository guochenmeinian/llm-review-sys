ID: AfzbDw6DSp
Title: Understanding Transformer Reasoning Capabilities via Graph Algorithms
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 6, 7, 7, -1, -1
Original Confidences: 3, 4, 4, -1, -1

Aggregated Review:
### Key Points
This paper investigates the algorithmic reasoning capabilities of transformers on graph problems, introducing a novel hierarchy that categorizes tasks based on the scaling regimes of transformers. The authors relate transformers to the massively parallel computing model (MPC) and validate their theoretical analysis through experiments on the GraphQA benchmark. The study emphasizes the representational power of transformers in executing graph algorithms and provides insights into their depth, width, and token requirements.

### Strengths and Weaknesses
Strengths:
- The paper offers a novel hierarchy that categorizes graph problems according to the scale of transformers needed, enhancing understanding of their algorithmic reasoning capabilities.
- The motivation is strong, and the empirical study is well-designed, tightly linking theoretical results to practical tasks in GraphQA.
- The clarity of presentation, particularly the “Theoretical interpretation” sections, aids in contextualizing empirical findings.

Weaknesses:
- The theoretical results are based on specific assumptions and parameter scaling regimes, limiting generalizability to real-world scenarios.
- There is ambiguity in empirical results regarding GNNs and transformers, particularly concerning the use of positional encodings.
- The experimental settings, particularly with small graphs (5 to 20 nodes), create a significant gap between theory and practice, necessitating further empirical evaluation on larger graphs.
- The lack of standard deviation reporting due to runtime costs raises concerns about the variance of results.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their theoretical results by addressing the assumptions made and providing guidance for practical applications. Additionally, we suggest clarifying the distinctions between expressivity and inductive bias in GNNs and comparing both GNNs with and without node identifiers. To enhance empirical validation, we encourage the authors to conduct experiments on larger graphs and consider limiting the parameter count of transformers. Finally, we recommend providing standard deviation for the smaller models to better understand the variance in results.