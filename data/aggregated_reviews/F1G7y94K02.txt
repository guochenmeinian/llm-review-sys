ID: F1G7y94K02
Title: Dissecting Recall of Factual Associations in Auto-Regressive Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on how transformer-based language models retrieve information for subject-relation queries. The authors designed methods to analyze the effects of blocking updates in specific components, revealing that information flows through critical points and that attribute information is gradually built up in the representation at the last subject position. The work also explores the retrieval of factual information and suggests further research directions in knowledge localization and model editing.

### Strengths and Weaknesses
Strengths:  
- The paper is well-written and easy to understand, presenting interesting findings that enhance the understanding of transformer-based models.  
- The experiments are comprehensive, providing valuable insights into the prediction mechanisms for subject-relation queries.  
- The use of figures effectively illustrates complex concepts and results.  
- The study contributes to the evolving domain of internal representations in transformer models, proposing a novel automatic approximation of subject-attribute relatedness.

Weaknesses:  
- The focus on subject-relation queries limits the applicability of the proposed methods to other tasks where key query words are not predetermined.  
- The paper is seen as a technical stepping stone, with some reviewers expressing concerns about the generalizability of the findings to more complex NLP tasks.  
- Reproducibility issues arise due to insufficient detail on data and parameter settings, making it challenging for others to replicate the results.  
- There are minor grammatical errors, such as the incorrect term "Attributes Rate" instead of "Attribute Rate."

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their findings by discussing how their methods might apply to other NLP tasks beyond subject-relation queries. Additionally, we suggest providing more detailed descriptions of the experimental setup and data to enhance reproducibility. Clarifying the relationship between their findings and potential dependencies on training tasks or model size would also strengthen the paper. Finally, addressing the identified grammatical errors will improve the overall presentation.