ID: XSCYxDp3yE
Title: A Bayesian Approach To Analysing Training Data Attribution In Deep Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 5, 4, 7, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Bayesian perspective on Training Data Attribution (TDA), focusing on the stochasticity in estimating model parameters with and without specific training examples. The authors conduct experiments using various TDA methods on subsampled versions of MNIST and CIFAR10, revealing that TDA estimates often exhibit high variance due to noise from model initialization and batch composition. They explore the variance in TDA scores based on the original leave-one-out (LOO) definition and how various TDA approximation methods capture this variability. The authors address the impact of training set size on TDA scores, noting that increased size leads to greater variability up to a point, after which scores tend to decrease. They also discuss the relationship between model complexity and TDA score variability, asserting that more complex models exhibit larger variability. The authors clarify their use of a 1-sample Studentâ€™s t-test and the non-IID nature of their samples, emphasizing their stratified sampling approach.

### Strengths and Weaknesses
Strengths:  
- The paper is well-written and communicates its ideas clearly, with helpful figures.  
- It addresses an important practical problem and provides relevant recommendations.  
- The experimental setup is sensible, and the analysis of experiments is strong.  
- The paper effectively addresses the relationship between training set size and TDA score variability, providing empirical data to support claims.  
- The authors demonstrate a clear understanding of the theoretical implications of their damping term and its connection to Bayesian learning frameworks.  
- The discussion on model complexity and its effect on TDA score variability is well-articulated and supported by data.  

Weaknesses:  
- The theoretical treatment of the subject is limited, reducing its value to the community.  
- Conclusions are drawn from experiments with relatively small samples, lacking broader applicability.  
- The presentation of the statistical test (Equation 11) is confusing, making it difficult to interpret results.  
- The paper does not adequately discuss solutions or paths toward addressing the TDA problem.  
- The paper lacks a thorough examination of alternative approaches to training, such as continuing from optimized checkpoints or freezing model parameters.  
- There is insufficient discussion regarding the potential sources of noise in the training process and their impact on TDA scores.  
- The authors do not adequately address the limitations of comparing TDA methods to LOO retraining, particularly as neural network sizes increase.  

### Suggestions for Improvement
We recommend that the authors improve the theoretical analysis of TDA methods, particularly how a Bayesian perspective might affect their validity. This could include a discussion on the implications of treating model parameters as random variables and how this affects the application of the implicit function theorem used to derive influence. Additionally, we suggest conducting experiments on larger datasets to strengthen the claims made and considering downstream tasks for TDA, such as mislabel identification, to evaluate the relevance of TDA variability. We also recommend that the authors improve the discussion on alternative training approaches, specifically addressing the implications of continuing from optimized checkpoints and freezing parameters. Furthermore, we suggest providing a more comprehensive analysis of the sources of noise in their experiments and how these may affect their findings. Finally, we encourage the authors to clarify the limitations of their comparisons between TDA methods and LOO retraining, particularly in the context of larger neural networks, to strengthen their argument. Clarifying the statistical test setup and addressing the confusion around Equation 11 would also enhance the paper's clarity.