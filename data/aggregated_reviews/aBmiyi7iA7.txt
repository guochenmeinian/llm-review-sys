ID: aBmiyi7iA7
Title: Hamiltonian Monte Carlo on ReLU Neural Networks is Inefficient
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 6, 4, 6, 4, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 2, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis of the Hamiltonian Monte Carlo (HMC) algorithm applied to Bayesian neural networks (BNNs) with ReLU activation functions. The authors theoretically demonstrate that HMC, despite its piecewise linear structure, accumulates error due to non-differentiability, making it less efficient compared to HMC applied to networks with smooth activation functions like sigmoid. The efficiency is evaluated based on acceptance rates and step sizes, revealing significant local error rates in practice.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and structured, providing a clear narrative and thorough theoretical analysis, including correctness results and optimal acceptance rates.
- It highlights the inefficiency of HMC for ReLU-based networks, drawing attention to a previously overlooked issue in the machine learning community.

Weaknesses:
- The term "inefficient" lacks clarity; it implies absolute inefficiency rather than relative inefficiency compared to sigmoid networks. The paper does not define a threshold for inefficiency.
- Empirical evaluations are limited to a single toy dataset, which undermines the generalizability of the findings. The reliance on only sigmoid, ReLU, and LeakyReLU activation functions is insufficient, as they perform similarly.
- The theoretical contributions do not significantly advance existing error estimation results for HMC, and the presentation lacks discussion on the loss landscape of neural networks, which is relevant to the topic.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the term "inefficient" by specifying the context of inefficiency and providing a threshold for sampling rates. Expanding the empirical evaluation to include multiple datasets, particularly high-dimensional ones like MNIST, would strengthen the findings. Additionally, comparing ReLU with other activation functions, such as Swish, could enhance the empirical analysis. The authors should also clarify the efficiency calculations presented in the figures and ensure that accuracy or log-likelihood metrics are included in the experiments to provide a more comprehensive assessment of the sampling performance. Finally, a clearer discussion of the loss landscape and its implications for HMC would enhance the paper's relevance and depth.