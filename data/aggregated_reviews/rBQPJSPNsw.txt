ID: rBQPJSPNsw
Title: Language decoding from human brain activity via contrastive learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 4
Original Ratings: 4, 3, 4, 6
Original Confidences: 4, 4, 3, 3

Aggregated Review:
### Key Points
This paper presents a contrastive learning approach to decode sentences from fMRI brain activity by mapping neural recordings and text embeddings into a shared representational space. The authors report promising results, with top-1 accuracy of up to 49.2% and top-10 accuracy of up to 84%. However, the method lacks significant novelty, appearing as a modification of the contrastive learning framework CLIP without adequate citation or acknowledgment of foundational contributions. The experimental evaluation is limited to three subjects, lacking comparative analysis with previous work or baseline methods, which raises concerns about generalizability and robustness. Additionally, the reliance on a retrieval module restricts the model's ability to generalize beyond the training dataset.

### Strengths and Weaknesses
Strengths:
- The paper is easy to understand, with a logical structure and detailed methodology.
- Results indicate some useful learning, with Pearson correlation maps showing higher correlation among language-related cortical areas.
- The evaluation metrics are appropriate for the task, and the methodology section is well-detailed.

Weaknesses:
- The novelty of the approach is limited, closely resembling existing methods like BrainCLIP without sufficient differentiation.
- The small sample size of three subjects limits generalizability and raises concerns about overfitting.
- The paper lacks rigorous comparisons with state-of-the-art methods and does not adequately explore different language models or fMRI preprocessing techniques.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their work by clearly differentiating their approach from existing frameworks like CLIP and BrainCLIP, including appropriate citations. The authors should expand their experimental evaluation to include a larger and more diverse sample size, as well as comparative analyses with baseline methods to assess the true impact of their approach. Additionally, we suggest that the authors allocate more space to the Results section to include analyses that interpret the learned representation spaces, such as dimensionality reduction and clustering of cosine similarity matrices, rather than focusing excessively on methodological details.