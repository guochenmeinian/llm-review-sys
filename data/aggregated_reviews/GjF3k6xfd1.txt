ID: GjF3k6xfd1
Title: Toward Effective Digraph Representation Learning: A Magnetic Adaptive Propagation based Approach
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents MAP and MAP++ to enhance digraph representation learning by addressing limitations in existing magnetic Laplacian-based digraph neural networks (MagDGs). The authors derive insights regarding optimal settings for q-parameterized magnetic Laplacians and provide a theoretical framework, empirical investigations, and experimental results across 12 datasets, demonstrating the methods' scalability, flexibility, and predictive performance.

### Strengths and Weaknesses
Strengths:
- The introduction and background sections effectively contextualize digraph neural networks and magnetic Laplacians for readers.
- Empirical studies are well-presented, offering insights into the challenges of coarse-grained propagation.
- The proposed methods are simple yet effective, addressing both homophilic and heterophilic graph structures.

Weaknesses:
- Some mathematical notations lack adequate explanation, potentially confusing readers unfamiliar with spectral graph theory.
- A high-level summary of the main steps for MAP and MAP++ should be included in the main text for clarity.
- The performance of the proposed methods on real-world applications is not explored in detail.
- Discrepancies in baseline performance values compared to prior works raise concerns about the proposed methods' efficacy.
- The paper lacks robustness analysis under perturbations or deletions.

### Suggestions for Improvement
We recommend that the authors improve the clarity of mathematical notations and provide adequate explanations for terms introduced. Additionally, including a high-level summary of MAP and MAP++ in the main text would enhance understanding. The authors should explore the performance of their methods on real-world applications and conduct a thorough analysis of computational costs. We also suggest addressing discrepancies in baseline performance values and providing a robustness analysis under different perturbations. Lastly, the authors should consider restructuring the paper to enhance readability and ensure that experimental details are more prominently featured.