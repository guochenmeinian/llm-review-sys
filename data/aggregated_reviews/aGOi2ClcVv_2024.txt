ID: aGOi2ClcVv
Title: Token Highlighter: Inspecting and Mitigating Jailbreak Prompts for Large Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 6, 6, 7
Original Confidences: 3, 4, 4

Aggregated Review:
### Key Points
This paper presents a new defense method called "Token highlighter," which reduces the importance of tokens likely to elicit affirmative responses from large language models (LLMs). The authors demonstrate through extensive evaluations that this approach achieves a maximum Alpaca win rate while maintaining a low attack success rate (ASR). The proposed algorithm identifies jailbreak prompts and mitigates their effects, showing a promising tradeoff between accuracy and robustness under the assumption that attackers aim for affirmative responses.

### Strengths and Weaknesses
Strengths:
- The method is simple, conceptually solid, and inexpensive, performing well in the AlpacaEval vs ASR plot.
- The writing is clear, and the proposed algorithm is easy to follow.

Weaknesses:
- The assumption that successful jailbreaks rely solely on affirmative responses may not hold for all datasets, necessitating broader evaluation beyond the Alpaca win rate.
- The algorithm's performance against more advanced adaptive attacks, such as those involving role-play, remains uncertain.
- Backpropagation through the entire model is costly for large models and frequent queries, making the algorithm challenging to scale.
- Evaluation is limited to two models, which may not provide robust results; a more diverse set of models, particularly those with different pre-training pipelines, is needed.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by including a more diverse set of models to enhance robustness, particularly those with different pre-training pipelines. An analysis of the relationship between the proposed method's performance and model scale would also be beneficial. Additionally, we suggest conducting an analysis on the effectiveness of various model affirmations, including the number of tokens required and the sensitivity of the method to affirmation selection. It would be interesting to explore how the model deteriorates with this method, possibly by sorting benign requests based on preference reduction compared to the baseline. Lastly, we encourage the authors to investigate alternative evaluation methods beyond AlpacaEval with MT-Bench, particularly in domains requiring reasoning, such as science and math, and consider multiple-choice question answering evaluations.