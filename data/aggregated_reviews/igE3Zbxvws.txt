ID: igE3Zbxvws
Title: Maximum Independent Set: Self-Training through Dynamic Programming
Conference: NeurIPS
Year: 2023
Number of Reviews: 24
Original Ratings: 6, 6, 6, 7, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 1, 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for solving the maximum independent set (MIS) problem using a dynamic programming framework combined with graph neural networks (GNNs). The authors propose a randomized divide-and-conquer approach, utilizing a graph comparator function parameterized by a GNN to recursively determine the larger MIS between two graphs. The method aims to efficiently generate training data through self-training, addressing the NP-hard nature of the problem. The authors argue that their dynamic programming framework is appropriate for the task and incorporates domain knowledge. Experimental results demonstrate that the proposed CMP method achieves competitive results compared to existing deep-learning-based methods, greedy heuristics, and other approaches, particularly highlighting performance on various datasets, including SPECIAL, Twitter, and Collab.

### Strengths and Weaknesses
Strengths:
- The paper introduces an innovative approach to the MIS problem using GNNs in a self-training manner.
- The method effectively reduces the cost of training data generation for NP-hard problems.
- The clarity of notations and presentation is commendable, making the approach easy to follow.
- The authors effectively address reviewer comments and provide additional analyses that clarify their methodology and results.
- The experimental results indicate interesting performance gaps, particularly in the context of the greedy heuristic.
- The paper introduces novel elements in data annotation for MIS.

Weaknesses:
- The distinction between dynamic programming and recursive algorithms is not clearly articulated, potentially leading to misunderstandings.
- The paper lacks a detailed explanation of the consistency of the graph comparator function, which is crucial for the method's reliability.
- There is insufficient discussion on the computational complexity, particularly regarding the scalability of the proposed method to larger graphs.
- Some reviewers express skepticism regarding the novelty of the method, suggesting it does not significantly exceed existing approaches.
- There are concerns about the explainability of the model, particularly regarding the embeddings of nodes and their decision-making processes.
- The performance of the learned comparator does not consistently exceed that of the greedy baseline on real-world datasets.
- The empirical evaluation does not adequately justify the choice of benchmark datasets, raising concerns about their real-world relevance.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by explicitly distinguishing between dynamic programming and recursive algorithms. Additionally, providing a more detailed explanation of the consistency of the graph comparator function would enhance the method's credibility. It is essential to include a thorough discussion of the computational complexity and scalability of the proposed approach, especially in relation to larger graphs. We suggest that the authors improve the explainability of their model by hashing compatible and incompatible nodes to enhance the clarity of decision-making processes. Furthermore, we recommend that the authors provide more detailed explanations of the greedy baseline results and clarify the relationship between the learned comparator and the greedy heuristic. It would also be beneficial to include further analyses on the consistency of the learned comparator across all datasets, particularly in relation to the SPECIAL dataset. Finally, we suggest that the authors justify the choice of benchmark datasets used in the experiments to ensure their relevance to real-world applications.