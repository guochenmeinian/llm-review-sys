ID: WVQ4Clw1VD
Title: MedTrinity-25M: A Large-scale Multimodal Dataset with Multigranular Annotations for Medicine
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 6, 5, 6, -1, -1, -1, -1
Original Confidences: 4, 4, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents MedTrinity-25M, a large-scale multimodal medical dataset comprising over 25 million images annotated for 65 diseases, featuring both global textual information and detailed local annotations such as bounding boxes and segmentation masks. The authors propose an automated annotation pipeline that enhances scalability by generating detailed visual and textual annotations without requiring pre-existing text-image pairs, utilizing domain-specific models for ROI identification and multimodal large language models (MLLMs) for annotation generation. The dataset supports various multimodal and vision-centric tasks, laying the groundwork for future foundational models in the medical field.

### Strengths and Weaknesses
Strengths:
- Comprehensive and high-quality dataset with multigranular annotations.
- Introduction of ROI as a new modality is important and interesting.
- Development of an automated pipeline for multimodal data generation without relying on paired text descriptions.

Weaknesses:
- The paper's format has several issues, such as inconsistent styles between sections.
- Results of model training on the MedTrinity-25M dataset are not included in the main paper, which is necessary for evaluating its practical relevance.

### Suggestions for Improvement
We recommend that the authors improve the paper's format to ensure consistency across all sections. Additionally, it is crucial to include the results of model training on the proposed MedTrinity-25M dataset within the main paper to demonstrate its practical relevance. Furthermore, we suggest conducting expert validation of the dataset and addressing how the ROI will be utilized in cases where global information is more pertinent for certain diseases. Lastly, benchmarking state-of-the-art (SOTA) MLLMs on this dataset could enhance its utility, despite the workload involved.