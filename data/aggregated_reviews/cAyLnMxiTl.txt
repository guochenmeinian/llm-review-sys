ID: cAyLnMxiTl
Title: Enhancing Motion Deblurring in High-Speed Scenes with Spike Streams
Conference: NeurIPS
Year: 2023
Number of Reviews: 20
Original Ratings: 5, 4, 5, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel motion deblurring method that integrates RGB images and binary spike streams, utilizing a content-aware motion magnitude attention module and a transposed cross-modal attention fusion module. The authors introduce two synthetic datasets for training and evaluation, demonstrating that their method achieves state-of-the-art performance on these datasets. Additionally, the authors propose using auxiliary inputs such as grayscale images, LBP texture maps, and Canny edge maps to enhance the deblurring process. They address various concerns, including experimental settings, qualitative comparisons, the effectiveness of the CAMMA branch, and the visualization of motion magnitude masks, providing additional experiments and clarifications in response to feedback.

### Strengths and Weaknesses
Strengths:
- The paper proposes the first spike-based motion deblurring model, leveraging transformers.
- The authors claim the ability to reconstruct sub-frame sharp images at any timestamp, which is a significant advantage.
- The datasets introduced could provide valuable resources for future research.
- The proposed method outperforms state-of-the-art techniques on the synthetic datasets.
- The authors effectively demonstrate the utility of texture information in the deblurring process through toy experiments.
- Additional ablation experiments clarify the effectiveness of the CAMMA branch and its incremental gains.
- The authors have addressed concerns regarding experimental settings and provided visualizations of motion magnitude masks.

Weaknesses:
- The evaluation primarily relies on synthetic data, with limited real-world testing, raising concerns about the synchronization of spike and RGB cameras.
- The main loss function is unclear, particularly regarding the separation of similar terms.
- The motivation for using spike streams over event-based methods is inadequately justified, and previous works in this area are not sufficiently acknowledged.
- The experimental results lack robustness, with comparisons favoring the proposed method without fair baseline evaluations.
- Some aspects of the initial response remain arguable, indicating potential gaps in clarity or justification.
- The qualitative comparison with REFID was not initially included, which may affect the comprehensiveness of the results.
- The writing contains several typos and could benefit from improved clarity and structure.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by including more real-world data and addressing the synchronization challenges between spike and RGB cameras. Additionally, we suggest clarifying the main loss function and providing a more detailed justification for the choice of spike streams over event-based methods. A more thorough and fair comparison with existing event-based techniques is necessary, along with additional ablation studies to validate design choices. We also encourage the authors to enhance the clarity of their arguments in response to remaining concerns, particularly regarding the justification of their methods. Lastly, please ensure that the updated comparisons and new results are incorporated into the paper to enhance its utility for the community, along with revising the methodology section and correcting typographical errors.