ID: erorKQYQ7P
Title: Co$^2$PT: Mitigating Bias in Pre-trained Language Models through Counterfactual Contrastive Prompt Tuning
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method called Co2PT (Counterfactual Contrastive Prompt Tuning) aimed at mitigating gender bias in pre-trained language models (PLMs) during downstream tasks through prompt tuning. The authors propose integrating a counterfactual contrastive loss while keeping PLM parameters frozen, which enhances efficiency and effectiveness. The method is evaluated on three bias benchmarks: Bias-STS-B, Bias-NLI, and Bias-in-Bios, demonstrating superior performance compared to existing methods. The authors also provide extensive ablation studies to support their claims.

### Strengths and Weaknesses
Strengths:
- The proposed method is efficient and effective, with clear experimental validation across multiple datasets.
- The paper is well-written, providing detailed explanations of the methodology and experimental setup.
- The authors conducted thorough ablation studies, demonstrating the significance of their approach.

Weaknesses:
- Some core ideas, such as debiasing during adaptation, are not novel and have been explored in prior works.
- The choice of baselines is questionable; comparisons with stronger debiasing methods are lacking, which raises concerns about the claimed superiority of the proposed method.
- The specific role of prompts in the debiasing process lacks clarity, and the paper does not sufficiently address the potential impact of counterfactual pairs on model performance.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their contributions by clearly differentiating their method from existing works, particularly in the context of debiasing during adaptation. Additionally, we suggest including comparisons with stronger debiasing baselines, such as ADELE-TA, and exploring the applicability of the counterfactual contrastive loss to other parameter-efficient methods like adapter tuning. Furthermore, we encourage the authors to clarify the role of prompts in their method and provide more detailed explanations regarding the implementation of counterfactual pairs. Lastly, we recommend conducting experiments to evaluate the method's effectiveness across different bias dimensions beyond gender, potentially using synthetic data for comprehensive analysis.