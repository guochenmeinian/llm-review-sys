ID: HShs7q1Njh
Title: LLM Processes: Numerical Predictive Distributions Conditioned on Natural Language
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 6, 9, 7, -1, -1, -1
Original Confidences: 3, 4, 3, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an innovative approach to using large language models (LLMs) for numerical predictions by proposing LLM Processes, which apply LLMs to tasks like density estimation and multivariate time series forecasting. The authors employ techniques such as binning for continuous inputs and introduce a terminal special token (<t>). Their experiments demonstrate that LLMP achieves superior performance compared to baselines like LLMTime and Gaussian Processes (GPs) with RBF kernels across various forecasting tasks, including the integration of textual information alongside numerical inputs.

### Strengths and Weaknesses
Strengths:
- The empirical results show that the proposed approach improves over LLMTime and GPs across multiple univariate and multivariate forecasting tasks.
- The paper includes ablation studies that support specific choices for input formatting and scaling.
- The problem statement is innovative, and the extensive empirical results investigate different failure modes and compare performance to traditional methods.

Weaknesses:
- Some evaluation aspects are unclear, particularly regarding the takeaways from Figure 9 and the interpretation of the results.
- The runtime performance of the method is not discussed, leaving questions about how it scales with longer sequences of input-output pairs.
- The experimental results lack direct comparisons to previous works, particularly regarding cited studies.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the evaluation by explicitly detailing the axes in Figure 9 and providing a clearer interpretation of the results. Additionally, we suggest including runtime analysis to address concerns about performance as input sequences grow. Furthermore, the authors should enhance the organization of the experimental results to clearly differentiate between training and prompting paradigms and include side-by-side comparisons with results from related works to highlight their contributions more effectively.