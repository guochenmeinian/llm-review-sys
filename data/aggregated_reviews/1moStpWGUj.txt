ID: 1moStpWGUj
Title: Energy Guided Diffusion for Generating Neurally Exciting Images
Conference: NeurIPS
Year: 2023
Number of Reviews: 23
Original Ratings: 6, 5, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to predicting neural responses in the V4 area of the macaque visual cortex by employing an attention readout mechanism integrated into a convolutional neural network (CNN). The authors introduce a method called Energy Guided Diffusion (EGG), which utilizes Bayesian diffusion techniques to generate most exciting inputs (MEI) from neural responses. Their results indicate that the attention-based model outperforms state-of-the-art methods in predicting neuronal activity, while EGG demonstrates faster performance and better generalization compared to traditional gradient ascent methods. Additionally, the authors conduct a comparative analysis of the Attention model and a Gaussian model in generating MEIs, hypothesizing that the Attention model exhibits less natural image bias. They compute Centered Kernel Alignment (CKA) to assess the similarity of neural encodings across different architectures, finding high similarity within architectures and moderate similarity across them.

### Strengths and Weaknesses
Strengths:
- The integration of attention mechanisms into the encoding network is biologically motivated and shows improved performance in predicting neuronal responses.
- The incorporation of an attention module into the model's final layer captures stimulus-dependent changes effectively.
- The use of diffusion models for generating MEI is innovative and has not been previously attempted in this context.
- The replication of MEIs for selected neurons across different models validates the MEI technique for interpreting neural tuning.
- The CKA results demonstrate a robust understanding of neural encoding similarities across architectures.
- The paper is well-structured, with clear experimental design and sufficient detail for reproducibility.

Weaknesses:
- The authors overstate the novelty of the energy guidance method (EGG) without adequately citing prior work in computer vision that employs similar techniques.
- The paper lacks clarity on which specific changes in the attention readout model contribute to improved predictivity, complicating the interpretation of results.
- The experimental setups lack consistency, particularly in the optimization methods used across different experiments, raising questions about the fairness of comparisons.
- There is no experimental evidence demonstrating that the learned attention readout effectively captures shifts in receptive field locations.
- The term “natural” used to describe generated images is misleading, as the images do not appear natural and are influenced by the diffusion model's learned distribution.
- The claim regarding MEIs being more “concentrated” lacks quantification, reducing the strength of the assertion.
- The reliance on a norm constraint in the energy function has been criticized as introducing an additional prior that may weaken the validity of the method.
- The absence of neurophysiological verification experiments raises concerns about biases in model responses.
- The normalization approach is viewed as a potential flaw, as it may not accurately represent sampling from the joint distribution.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their contributions by including additional citations to relevant prior work in computer vision that addresses similar methodologies. Additionally, the authors should consider providing more consistent experimental setups, such as using the same optimization method across all experiments. To enhance the evaluation of their results, we suggest incorporating quantitative metrics like SSIM, PSNR, or FID to substantiate claims about the quality of MEI and MENI outputs. Furthermore, we recommend that the authors improve the clarity of which model changes lead to performance enhancements, particularly in Figure 2. Conducting experiments to demonstrate that the attention readout learns to adjust receptive field locations would also be beneficial. The authors should reconsider the terminology used to describe generated images, potentially removing references to “natural” images to avoid misleading interpretations. Quantifying the concentration of MEIs would strengthen the discussion. We encourage the authors to improve the discussion on the norm constraint, explicitly acknowledging it as a potential limitation in the text. Additionally, consider incorporating a more sound proof to ensure bounded responses of the encoder, such as using observed min and max values of neuron responses. Lastly, clarifying the implications of the normalization approach and its impact on the validity of the method, potentially exploring alternatives that do not rely on hand-crafted constraints, would enhance the paper's rigor.