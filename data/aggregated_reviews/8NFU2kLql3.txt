ID: 8NFU2kLql3
Title: HANSEN: Human and AI Spoken Text Benchmark for Authorship Analysis
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the HANSEN benchmark, the largest dataset for authorship analysis on spoken texts, combining human and AI-generated datasets. The authors propose a comprehensive evaluation of state-of-the-art models for Authorship Attribution and Author Verification tasks, as well as Human vs. AI spoken text detection. The contributions include curating and preprocessing 17 existing human spoken datasets, generating over 20K samples from three LLMs (ChatGPT, PaLM2, and Vicuna), and conducting extensive evaluations of traditional authorship analysis methods.

### Strengths and Weaknesses
Strengths:
- The paper is well organized and clearly written, with a valuable literature review.
- The HANSEN benchmark introduces novel tasks and diverse datasets, enhancing accessibility for authorship analysis.
- The experiments demonstrate the performance of baseline and state-of-the-art methods on spoken text tasks, revealing significant research gaps.

Weaknesses:
- The necessity of using AI-generated datasets for the benchmark is unclear, particularly regarding the similarity to human text.
- The quality assessment process for LLM-generated data and curation of existing datasets lacks clarity.
- There is insufficient discussion on distribution rights for curated datasets, raising ethical concerns.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the quality assessment process for LLM-generated data and the curation of existing datasets in the main text. Additionally, addressing the ethical implications of their dataset release and providing detailed information on distribution rights and licenses for the curated datasets is essential. Furthermore, we suggest that the authors clarify whether the experiments were conducted multiple times to enhance the reliability of their findings. Lastly, consider introducing character n-gram models earlier in the paper and revising Table 8 for accessibility by avoiding color coding.