ID: 99rOAM7Jfm
Title: Noise-Aware Differentially Private Regression via Meta-Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 6, 7, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a meta-learning Gaussian differential privacy (DP) algorithm, referred to as DPConvCNP, which modifies the SetConv procedure by incorporating a functional DP mechanism. The authors propose a method that uses a noisy encoder during training and meta-testing, aiming to generalize from context datasets to sensitive target datasets. The paper claims to extend Gaussian DP to functional outputs, demonstrating effectiveness through experiments on synthetic and real datasets.

### Strengths and Weaknesses
Strengths:
1. Theoretically extends Gaussian DP to functional outputs, potentially paving the way for future research.
2. Empirical experiments are extensive, covering both synthetic and real tasks with comparisons to existing methods.
3. The paper is well-organized, with clear figures and illustrations.

Weaknesses:
1. The notation and presentation are not always clear, leading to confusion regarding the method's correctness and the privacy guarantees.
2. The experimental datasets are simplistic and do not reflect the complexity of typical public datasets in fields like images and NLP.
3. The necessity of adding noise during the test stage is questioned, as it may not be optimal and could complicate privacy budget management.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the notation and presentation, particularly in the privacy proof section, to ensure that the sensitivity calculations are comprehensible. Additionally, we suggest including more challenging experiments that reflect real-world scenarios, such as those involving images and text, to validate the method's effectiveness. It would also be beneficial to justify the choice of privacy hyperparameters and discuss the implications of noise addition during the test stage. Finally, we encourage the authors to provide a detailed explanation of how simulated data is generated and its assumptions regarding public statistics to enhance transparency.