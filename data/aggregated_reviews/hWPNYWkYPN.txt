ID: hWPNYWkYPN
Title: A new perspective on building efficient and expressive 3D equivariant graph neural networks
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 8, 7, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis of the expressive power of equivariant graph neural networks (GNNs) from a 3D isomorphism perspective, proposing three types of isomorphism in 3D space: Tree Isometric, Triangular Isometric, and Subgraph Isometric. The authors define geometric Weisfeiler-Lehman (WL) tests and enhance the expressive power of equivariant GNNs by incorporating mutual 3D substructures and introducing an SE(3)-invariant encoder. The theoretical analysis demonstrates that simple aggregation of local messages cannot approximate global interactions, leading to the enhancement of the model's expressive power through a frame transition matrix. Experimental results validate the effectiveness of the proposed model on scalar and vector properties of molecules on QM9.

### Strengths and Weaknesses
Strengths:
- The paper is the first to analyze the expressive power of equivariant neural networks from the 3D isomorphism perspective, potentially inspiring future research.
- The incorporation of mutual 3D substructures into 3D GNNs enhances their expressive power, supported by experimental validation.
- A novel frame transition matrix is proposed to reduce computational costs while expressing global geometric information.

Weaknesses:
- The notation is confusing, with inconsistencies in definitions (e.g., the use of h and f) that burden comprehension.
- The analysis appears to build on prior work, raising questions about the ability to incorporate mutual 3D substructures into other GNN architectures.
- The paper lacks discussion on analyzing the expressive power of 3D GNNs from the attention mechanism perspective, despite recent relevant literature.

### Suggestions for Improvement
We recommend that the authors improve the clarity of notation and definitions to alleviate confusion, possibly by providing a guideline at the end of the introduction. Additionally, the authors should address how their methods can be generalized to incorporate mutual 3D substructures into other 3D GNNs. We also suggest including a discussion on the expressive power of 3D GNNs from the attention mechanism perspective, as this could enhance the paper's relevance in light of recent studies. Finally, improving the organization and readability of the manuscript will facilitate better understanding of the proposed framework and its contributions.