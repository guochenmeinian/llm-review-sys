ID: 6gzPSMUAz2
Title: MATES: Model-Aware Data Selection for Efficient Pretraining with Data Influence Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 5, 5, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents MATES, a method termed "model-aware data selection with data influence models," aimed at optimizing data selection for large language model (LLM) pre-training. MATES dynamically adapts to the evolving data preferences during pre-training by utilizing a small data influence model, which reduces the computational cost of influence score calculations. Experiments conducted on the C4 dataset with Pythia models validate that MATES outperforms random and existing static data selection methods.

### Strengths and Weaknesses
Strengths:
- The paper highlights the changing influence of data throughout the training process, emphasizing the need for adaptive data selection methods.
- The use of the Gumbel-Top-k algorithm effectively balances data quality and diversity, mitigating the independent influence assumption of training data.
- Extensive experiments validate the method's effectiveness, demonstrating improved performance over static baselines.

Weaknesses:
- There is a notable gap between the motivation for data selection and the experimental design, particularly regarding the necessity of data selection for pre-training versus full training.
- The significance of results in Table 1 is questionable, as only a few tasks show improvements beyond one standard error, suggesting p-values may exceed 0.05.
- Critical implementation details are lacking, leading to confusion in the presentation.
- The paper primarily compares MATES to static baselines, with limited exploration of other dynamic data pruning methods.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the experimental design by addressing the necessity of data selection for pre-training versus full training. Additionally, the authors should provide results and computational costs for pre-training the entire C4 dataset to substantiate the need for MATES. Clarifying the significance of results in Table 1 and including more robust comparisons with dynamic data pruning methods would strengthen the paper. Furthermore, we suggest that the authors enhance the implementation details to improve clarity and address the computational overhead associated with maintaining the data influence model.