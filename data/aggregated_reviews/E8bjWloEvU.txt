ID: E8bjWloEvU
Title: When Large Vision Language Models Meet Multimodal Sequential Recommendation: An Empirical Study
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an evaluation of five strategies for integrating Large Vision Language Models (LVLMs) in multimodal sequential recommendation tasks. The authors introduce MSRBench, a benchmark designed to assess these integration strategies, and the Amazon Review Plus dataset, which includes image descriptions from the Amazon Review dataset. The findings indicate that using LVLMs as rerankers significantly enhances recommendation performance.

### Strengths and Weaknesses
Strengths:
- The work investigates the integration of proprietary LVLMs in multimodal sequential recommendation, a topic that has not been thoroughly explored before.
- The experimental design is detailed, with well-motivated choices and extensive baseline model descriptions.
- The paper is well-written and easy to follow, providing a clear framework for analyzing LVLM roles.

Weaknesses:
- The proprietary nature of the chosen LVLMs limits reproducibility, as results may not be replicable if the models become unavailable.
- The analysis of results, particularly for RQ1, lacks depth, and the experiments on image input modes are limited to a single dataset and model, affecting generalizability.
- The necessity of multimodality in sequential recommendation tasks is questionable, as results suggest that text-only models may suffice.

### Suggestions for Improvement
We recommend that the authors improve the discussion surrounding the results for RQ1 to provide deeper insights into the performance differences observed. Additionally, the authors should consider conducting experiments with open-source LVLMs and report their findings, even if the models perform poorly, to inform future research. To enhance the generalizability of their results, we suggest expanding the experimental design to include multiple datasets and models. Finally, the authors should clarify the necessity of using multimodal data in sequential recommendations and address potential limitations in processing concatenated images.