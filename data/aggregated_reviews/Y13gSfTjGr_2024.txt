ID: Y13gSfTjGr
Title: Scaling Laws and Compute-Optimal Training Beyond Fixed Training Durations
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 5, 9, 8, -1, -1, -1
Original Confidences: 4, 5, 5, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an empirical study on the use of constant learning rates (plus a short cooldown) as an alternative to cosine schedules for training large language models (LLMs). The authors demonstrate that: 
- Constant LR with cooldown roughly matches the performance of cosine schedules (Figures 3, 4).
- Stochastic Weight Averaging (SWA) of a long schedule nearly matches the performance of shorter schedules given the same number of steps (Figure 8).
- Chinchilla-type scaling laws can be derived using constant LR schedules with cooldowns, resulting in significant compute savings (Figure 10).

### Strengths and Weaknesses
Strengths:
- The potential impact of using constant LR instead of cosine is substantial.
- The paper is well-written and presents clear experiments and results.

Weaknesses:
- The experimental setup lacks clarity, which could be easily rectified in an updated version.
- The exact degree of match between constant LR and cosine schedules, particularly for longer training durations, remains unclear.
- The results on SWA and constant LR appear almost orthogonal.
- The study does not achieve higher performance, limiting its relevance primarily to scaling studies for well-funded labs.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the experimental setup by including a dedicated subsection. Additionally, we suggest addressing the discrepancy between Figures 3 and 4 regarding the performance of constant LR versus cosine. The authors should also clarify the SWA methodology, specifically how evaluations are conducted over the last 500 steps. Furthermore, we encourage the authors to explore the application of their proposed method in continued pre-training scenarios, discussing whether it is more effective to continue from checkpoints before or after cooldown. Lastly, expanding the scale of experiments to larger models, such as 3B or 7B, would enhance the validation of the proposed method.