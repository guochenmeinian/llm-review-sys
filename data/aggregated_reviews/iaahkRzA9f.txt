ID: iaahkRzA9f
Title: Map It Anywhere: Empowering BEV Map Prediction using Large-scale Public Datasets
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 7, 6, 6, -1, -1, -1
Original Confidences: 3, 3, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents MIA, a framework designed to enhance bird's eye view (BEV) mapping for ground robot navigation by automating the collection of a large dataset comprising 1.2 million pairs of first-person view (FPV) and BEV images. The authors propose a pipeline that facilitates dataset creation, which shows significant performance improvements over previous state-of-the-art approaches. The work builds upon OrienterNet but lacks a detailed comparison with it, which could clarify the differences and broaden the audience's understanding.

### Strengths and Weaknesses
Strengths:
- The pipeline automates the dataset creation process, allowing for a large-scale collection of diverse geographical contexts.
- The methodology demonstrates marked improvements in BEV map prediction performance, establishing a benchmark for future research.

Weaknesses:
- The dataset is skewed towards locations in the US, lacking diversity from other countries, which limits generalization.
- The focus on static maps may not adequately address dynamic classes, limiting applicability in real-world scenarios with moving objects.
- The manuscript lacks clarity on the raw data from Mapillary and the geospatial filtering process, as well as a detailed comparison with related work.

### Suggestions for Improvement
We recommend that the authors improve the diversity of locations included in the dataset by incorporating data from various countries, such as those in the EU and Asia, to enhance the robustness of the pipeline. Additionally, the authors should provide more details on the raw data format from Mapillary, clarify the sources of camera poses, and elaborate on the geospatial filtering process. A more thorough discussion on the potential applications of the BEV mapping technique, including cross-view localization and online map retrieval, would also strengthen the manuscript. Finally, a detailed comparison with OrienterNet is necessary to highlight the distinctions and relevance of this work.