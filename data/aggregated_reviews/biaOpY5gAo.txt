ID: biaOpY5gAo
Title: Stack More Layers Differently: High-Rank Training Through Low-Rank Updates
Conference: NeurIPS
Year: 2023
Number of Reviews: 7
Original Ratings: 4, 3, 5, 5, -1, -1, -1
Original Confidences: 5, 3, 3, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ReLoRA, a novel approach for training large-scale neural networks using low-rank updates to enhance the rank of a high-rank network (â‰¤350M parameters). The authors propose a method that incorporates a full-rank training warm start, followed by a merge-and-reinit strategy, and a jagged learning rate scheduler. The efficiency of ReLoRA is claimed to improve with larger networks, suggesting its potential for training multi-billion-parameter models. However, the definition of "pre-training" remains ambiguous, and the experimental setup lacks clarity regarding resource utilization and performance metrics.

### Strengths and Weaknesses
Strengths:
- The proposed method is innovative, utilizing a clever technique to artificially increase the rank of LoRA.
- The rationale behind the approach is reasonable, and the introduction is well-written.
- The paper includes a sophisticated design for the ablation study, and reproducibility is supported by released code and hyperparameter settings.

Weaknesses:
- The writing quality is poor, with many notations unexplained and significant details omitted, making it difficult to fully grasp the proposed method.
- The experimental section is insufficient, lacking comprehensive comparisons and analyses, particularly regarding downstream tasks and the performance of ReLoRA against established baselines.
- The motivation for the method is not convincingly articulated, and the claims regarding rank guarantees are inadequately supported.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing by thoroughly explaining all notations and providing a detailed, line-by-line explanation of the algorithm. Additionally, we suggest that the authors conduct experiments comparing ReLoRA for both pre-training and fine-tuning against full training with LoRA, as this will clarify the expressibility trade-offs. It is also essential to include analyses on downstream tasks like GLUE/super-GLUE and to provide a formal definition of "Control" along with its performance metrics. Finally, the authors should discuss the selection of rank \( r \) and include training time for each model in the experimental results to better contextualize the benefits of ReLoRA.