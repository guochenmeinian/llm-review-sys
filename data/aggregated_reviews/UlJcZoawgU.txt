ID: UlJcZoawgU
Title: Extending the Design Space of Graph Neural Networks by Rethinking Folklore Weisfeiler-Lehman
Conference: NeurIPS
Year: 2023
Number of Reviews: 26
Original Ratings: 7, 4, 6, 3, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 2, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an extension to the $k$-FWL isomorphism test algorithms called $(k,t)$-FWL+, which combines two modifications to the original $k$-FWL: the $(k,t)$-FWL, which colors $k$ tuples and aggregates multi-sets of size $n^t$ tuples to enhance expressivity, and the $k$-FWL+, which modifies tuple neighborhoods to equivariant sets, potentially reducing time complexity. The authors claim to establish an expressiveness hierarchy with a fixed space complexity of \(O(n^k)\) for any \(k \geq 2\) and demonstrate a strict hierarchy in solving the isomorphism problem with increasing $t$. They provide a practical neural instantiation that achieves state-of-the-art results on benchmarks, particularly highlighting the performance of the (2,2)-FWL+ algorithm on the ZINC dataset. However, reviewers express skepticism about the significance of the quadratic space perspective and the novelty of the contributions, suggesting that some results may be trivial or minor modifications of existing literature.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and effectively highlights the limitations of the $k$-WL hierarchy, contributing to the design of more expressive GNNs.
- It introduces a general framework that unifies several recent approaches, providing a canonical design space for GNNs.
- The construction of the $(k,t)$-FWL hierarchy shifts memory complexity to runtime complexity in a fixed $k$ scenario.
- Extensive experimental evaluation shows the proposed method achieves state-of-the-art performance on standard datasets such as ZINC.

Weaknesses:
- The discussion of the "no free lunch" principle is insufficiently addressed in the main text, as it is relegated to the appendix.
- An ablation study comparing the performance of various hierarchy variants on substructure counting benchmarks is lacking, which would enhance the paper's intuition.
- The novelty of the quadratic space perspective is questioned, with reviewers noting that it does not provide significant insights into WL learning on graphs.
- The clarity of the paper is lacking, making it difficult to discern the novel contributions over existing subgraph-enhanced GNNs.
- Results on the QM9 dataset raise questions regarding consistency with other implementations, and the contribution regarding the existence of a WL-hierarchy solving Graph Isomorphism with bounded space is deemed insufficient.

### Suggestions for Improvement
We recommend that the authors improve the discussion of the "no free lunch" principle by integrating it into the main body of the paper rather than the appendix. Additionally, conducting an ablation study to evaluate the expressiveness of different hierarchy variants on substructure counting benchmarks would significantly enhance the paper's clarity and completeness. We suggest restructuring the paper to better highlight the novel contributions of the (2,2)-FWL+ algorithm, rather than focusing predominantly on the quadratic space perspective. Furthermore, please clarify the discrepancies in the QM9 dataset results and provide runtime comparisons of your GNN training against other approaches to demonstrate scalability. Lastly, enhancing the discussion on how this work differentiates itself from the extensive literature on subgraph-enhanced GNNs, along with providing more intuitive explanations and figures, would strengthen the paper's impact.