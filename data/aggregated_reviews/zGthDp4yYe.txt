ID: zGthDp4yYe
Title: Real3D-AD: A Dataset of Point Cloud Anomaly Detection
Conference: NeurIPS
Year: 2023
Number of Reviews: 26
Original Ratings: 9, 6, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
We introduce Real3D-AD, a point cloud dataset designed for 3D anomaly detection, featuring 12 object classes with high-resolution scans. The dataset includes 4 training samples and approximately 100 test samples (50 normal and 50 anomalous) per class. Our work provides a comprehensive account of the dataset generation, annotation methods, and a systematic benchmark for evaluating anomaly detection methods. We also propose a novel registration-based method that outperforms existing approaches. The dataset consists of toys from manufacturing lines, with anomalies that are artificial yet representative, primarily focusing on incompleteness and redundancy. We acknowledge the challenges posed by transparent objects in point cloud anomaly detection. Additionally, we recognize the importance of addressing data shift issues in 3D anomaly detection methods, particularly concerning the limitations of single-view test samples.

### Strengths and Weaknesses
**Strengths:**
- Real3D-AD is a significant contribution to the field, being the first dataset that captures full 3D point clouds from multiple views, addressing the limitations of previous RGB-D datasets.
- The dataset is meticulously created, ensuring high quality and diversity, which can drive advancements in 3D anomaly detection.
- Our benchmark and evaluation toolkit facilitate fair assessments of future research.
- The manuscript is praised for its comprehensive approach, clear demonstrations, and systematic benchmarking.
- We effectively addressed many concerns raised by reviewers, leading to improved clarity and understanding of the methodology.

**Weaknesses:**
- The dataset primarily consists of rigid object forms, limiting the complexity of anomalies to missing or additional parts.
- The training set's small size (only 4 samples) poses challenges for methods requiring extensive training data, which should be explicitly stated.
- Test samples are scanned from a single viewpoint, potentially introducing data shifts that could affect model performance and evaluation metrics.
- The few-shot nature of the dataset may affect the performance of evaluated methods, akin to a few-shot problem.
- Some technical aspects, such as the combination of features and the labeling of missing points, were initially unclear and required further clarification.

### Suggestions for Improvement
We suggest clarifying the description of the dataset, particularly regarding the single-view scanning of test samples and the implications for evaluation metrics. Additionally, we recommend expanding the dataset to include a wider variety of object types commonly encountered in daily life to enhance its applicability. Addressing the disparity in point cloud numbers between training and testing samples in discussions would also be beneficial. We plan to clarify the few-shot nature of the dataset in the introduction to better contextualize the performance of evaluated methods. Furthermore, we suggest enhancing the explanation of how single-view test samples impact evaluation metrics and addressing the potential data shift problem more explicitly. We also recommend providing clearer definitions and calculations for metrics mentioned in the manuscript, particularly regarding the labeling of missing parts in point clouds. Finally, we should ensure that the terminology used throughout the paper is consistent and clear, particularly regarding the distinction between "point clouds" and "points," and articulate the limitations and potential negative impacts of the dataset in the supplementary material.