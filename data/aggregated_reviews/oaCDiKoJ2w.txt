ID: oaCDiKoJ2w
Title: Follow-ups Also Matter: Improving Contextual Bandits via Post-serving Contexts
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 8, 6, 6, 7, 7, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, 2, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel variant of linear contextual bandits that incorporates post-serving contexts, which are revealed after the learner selects an arm. The authors propose an algorithm, poLinUCB, based on LinUCB, which creates confidence sets for both the post-serving context and the reward function parameters. The regret bound is characterized by terms dependent on the complexity of the function and the dimension. The paper includes theoretical analysis supported by simulations on synthetic and real-world datasets, demonstrating the effectiveness of poLinUCB.

### Strengths and Weaknesses
Strengths:
- The model introduces a well-motivated post-serving context, enhancing the learner's information.
- The algorithm is simple and elegantly designed, with a thorough discussion of the implications of uncertainty in the post-serving context.
- The introduction of a novel elliptical potential lemma is technically interesting and accommodates slower learning rates.
- The paper is well-written, clearly articulating key ideas and contributions.

Weaknesses:
- The focus on upper bounds may overlook the potential for lower bounds analysis.
- The result in Observation 1 appears limited to linear bandit algorithms, which may lead to an unfair comparison due to model misspecification.
- The paper lacks a conclusion section and a thorough discussion of limitations and assumptions, particularly regarding real-world applicability.
- The experimental evaluation is somewhat limited, lacking diversity in datasets and scenarios.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the potential for lower bounds analysis to complement the upper bounds presented. Clarifying the limitations of the results in Observation 1 regarding linear bandit algorithms would strengthen the paper. Additionally, including a conclusion section and expanding the experimental evaluation to cover more datasets and scenarios would enhance the overall impact. Finally, providing more details on the implementation, computational complexity, and the sensitivity of hyperparameters would be beneficial for practical applications.