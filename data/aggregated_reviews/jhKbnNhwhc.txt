ID: jhKbnNhwhc
Title: Passage-specific Prompt Tuning for Passage Reranking in Question Answering with Large Language Models
Conference: ACM
Year: 2024
Number of Reviews: 3
Original Ratings: 2, -1, 1
Original Confidences: 4, 5, 5

Aggregated Review:
### Key Points
This paper presents a novel approach called Passage-specific Prompt Tuning (PSPT) aimed at enhancing passage reranking in open-domain question-answering tasks. By utilizing learnable soft prompts, the method achieves significant improvements with minimal parameter tuning, sometimes as low as ~0.001%. The authors conduct extensive experiments across three datasets, demonstrating PSPT's effectiveness compared to baseline retrievers.

### Strengths and Weaknesses
Strengths:
1) The method is highly parameter-efficient, achieving notable performance improvements with minimal tuning.
2) Comprehensive ablation studies provide clarity on the method's effectiveness.
3) Experimental results are robust, covering a variety of datasets.
4) Open-source plans indicate potential for widespread adaptation and use.

Weaknesses:
1) The experiments are confined to three smaller-scale wiki-based QA datasets; broader datasets like MS MARCO and BEIR would enhance validation.
2) The absence of critical baselines, such as Doc2query-T5 and RankLLaMA, limits situating the work within the existing literature.
3) The term Ret.Train is mentioned but not explained in the text, leaving ambiguity regarding its filtering process.
4) There is a lack of exploration regarding train set/test set leakage.
5) The paper does not compare PSPT with full fine-tuning, leaving questions about the impact of full fine-tuning on performance.

### Suggestions for Improvement
We recommend that the authors improve the clarity around the negative document discussions in Section 3 and provide a comparison between P(q|d+) and P(q|d-). In Section 4.2/Appendix A.4, please clarify whether the naive in-batch negative is akin to a random negative or if negative mining strategies were employed. Additionally, we suggest elaborating on the setting of LoRAâ€™s r=1 in Section 4.2 and providing analysis on e2 and e3 regarding re-ranking effectiveness. Finally, we encourage the authors to include a broader range of datasets and additional baselines to better situate their work within the current landscape of reranking methods.