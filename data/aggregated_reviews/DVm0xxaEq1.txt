ID: DVm0xxaEq1
Title: AiluRus: A Scalable ViT Framework for Dense Prediction
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 4, 6, 4, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a spatial-aware density-based clustering algorithm aimed at accelerating Vision Transformers (ViTs) for dense prediction tasks, particularly semantic segmentation. The authors propose an adaptive resolution strategy that merges tokens based on their importance, significantly reducing the number of tokens processed while maintaining performance. The method is evaluated across three datasets, demonstrating notable improvements in inference speed, with up to 48% acceleration in frames per second (FPS) for certain configurations.

### Strengths and Weaknesses
Strengths:
- The paper addresses a well-known issue of computational expense in ViTs by introducing a novel approach to token reduction.
- It is well-written and easy to understand, with clear motivation and technical details.
- The experiments yield strong qualitative and quantitative results, outperforming the Expedite method, especially in shallow layers.

Weaknesses:
- The novelty of merging tokens is limited, as similar ideas have been explored in prior works (e.g., STViT, PaCa-ViT).
- Comparisons are primarily made with Expedite, neglecting other efficient ViTs that could provide a broader context.
- The visualization in Figure 2 lacks clarity, as it misrepresents group assignments, and the manuscript contains numerous typographical errors.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Figure 2 by exploring alternative visualizations, such as scaling values or changing colors. Additionally, including results for ViT-B in Table 1 would enhance the informativeness of the data presented. To strengthen the paper, we suggest providing a more detailed analysis of why the proposed method outperforms existing methods, particularly in terms of the performance improvements observed with 900 clusters in Table 2. Lastly, addressing the reconstruction error between the reconstructed and original feature maps could further validate the proposed method's effectiveness.