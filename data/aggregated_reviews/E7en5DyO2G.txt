ID: E7en5DyO2G
Title: Bayesian Online Natural Gradient (BONG)
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 7, 6, 4, 7, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework for variational online learning, characterized by three components: (1) implicit or explicit regularization, (2) the type of approximation for the expected gradient and Hessian, and (3) the geometry of the gradient (natural vs. standard). The authors propose a method that employs implicit regularization, linearization of the Hessian, and natural gradient, which is shown to perform best in their case study. Additionally, they explore sequential Bayesian inference using variational inference (VI), suggesting the removal of the regularizing KL term and performing a single natural gradient step based solely on the expected log-likelihood.

### Strengths and Weaknesses
Strengths:  
The paper is a valuable contribution, unifying various methods in variational online learning and providing a thorough comparison of approximation techniques. The detailed experiments support the proposed methods, and the motivation involving conjugacy is well-articulated. The clear presentation and exhaustive related work enhance understanding of the proposed algorithms.

Weaknesses:  
The theoretical motivation is weak, with overly restrictive assumptions in Proposition 4.1. The claimed novelty regarding the removal of the KL term and the one-step natural gradient descent has been previously explored in the literature, raising concerns about the originality of the contribution. Additionally, the empirical evaluation is limited to the MNIST dataset, which may not adequately demonstrate the proposed algorithm's superiority.

### Suggestions for Improvement
We recommend that the authors improve the theoretical framework by relaxing the assumptions in Proposition 4.1 and providing a more robust justification for their contributions. A more exhaustive case study would strengthen the work, and less essential comments could be relegated to the appendix. Furthermore, we suggest expanding the empirical evaluation beyond the MNIST dataset to better validate the performance of the proposed methods. Lastly, we encourage the authors to emphasize the underlying ideas rather than the specific update rule, which has been previously discussed in the literature.