ID: BEiqNQZIky
Title: Efficiently Learning Significant Fourier Feature Pairs for Statistical Independence Testing
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 8, 4, 5, -1, -1, -1
Original Confidences: 3, 3, 3, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method to extend RFF with parametric transforms of Fourier features for shift invariant kernels, following the approach of Gretton et al. (2007). The proposed $\text{HSIC}_\omega$ statistic converges in distribution to a Gaussian under the null hypothesis, with linear time estimates for the first two moments necessary for HSIC. The authors aim to integrate modern learning methods into the HSIC framework while managing quadratic complexity. The work includes concentration bounds, moment estimators, and upper bounds for optimization convergence and Type II error.

### Strengths and Weaknesses
Strengths:  
- The potential for the work to become seminal in conditional independence testing for large-scale data is noted.  
- The incorporation of modern learning methods into the HSIC framework is a significant improvement.  
- The theoretical support includes concentration bounds and linear time estimators, which are non-trivial.  

Weaknesses:  
- The method is limited to translation invariant kernels, which is a common but notable restriction.  
- The necessity of splitting the dataset to avoid selective inference is a drawback.  
- The method may inherit limitations from HSIC, such as the need for empirical approximation of the null distribution.  
- Several explanations lack clarity, particularly regarding the purpose of criterion J, the introduction of $c_\alpha$, and definitions of Type I error and test power.  
- The resemblance of derivations in sections 4.2 and 4.3 to previous work weakens the perceived novelty.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the methodology in the introduction to facilitate reader understanding. Additionally, we suggest providing a detailed description of the objective J, Type I error, and test power used in the paper. It would be beneficial to explicitly discuss the limitations regarding the translation invariant kernels and dataset splitting. We also encourage the authors to cite relevant work more thoroughly and consider postponing detailed derivations to the appendix to enhance the presentation. Lastly, empirical comparisons with similar methodologies should be included to substantiate claims of novelty and contribution.