ID: cDXtscWCKC
Title: SleepFM: Multi-modal Representation Learning for Sleep across ECG, EEG and Respiratory Signals
Conference: AAAI
Year: 2024
Number of Reviews: 4
Original Ratings: 5, 9, 8, 7
Original Confidences: 4, 4, 5, 4

Aggregated Review:
### Key Points
This paper presents SleepFM, a foundational model for sleep analysis utilizing large-scale polysomnography (PSG) data, including EEG, ECG, and respiratory signals. The authors propose a novel application of contrastive learning for training the model, demonstrating its efficacy in downstream tasks such as sleep stage classification and apnea detection. While the results indicate superior performance compared to traditional CNN methods, the evaluation of the foundational model's capabilities remains insufficient.

### Strengths and Weaknesses
Strengths:
- The introduction of a large-scale multi-sensory dataset for training a foundational model is well-curated and positively impacts downstream task performance.
- The motivation for using contrastive learning with multiple time-series data types is clearly articulated and grounded in prior work.
- The methodology for pre-training, fine-tuning, and evaluation is well-defined, reducing data contamination risks.
- The comparison between pairwise contrastive learning and leave-one-out contrastive learning is relevant and insightful.
- The k-shot analysis effectively demonstrates the contextual information's impact on downstream performance.

Weaknesses:
- The claim of a "multi-modal" model is questionable, as the model primarily operates on paired multi-variate time-series data, which are similarly encoded.
- The lack of experimental comparisons with other recent statistical and deep learning methods limits understanding of the model's performance.

### Suggestions for Improvement
We recommend that the authors improve the evaluation of the foundational model by explicitly highlighting the tested properties and limitations, particularly regarding generalization to unseen datasets. Additionally, the authors should include comparisons with established methods for the proposed downstream tasks to strengthen their claims. Clarifying the utility of a foundational model for sleep analysis by identifying existing methods' shortcomings and delineating specific research questions would enhance the paper's motivation. Furthermore, we suggest providing more detailed implementation descriptions of the contrastive learning method and exploring the effects of omitting one modality to justify the need for joint modeling. Lastly, the authors should consider citing prior works related to leave-one-out contrastive learning to acknowledge its established presence in the literature.