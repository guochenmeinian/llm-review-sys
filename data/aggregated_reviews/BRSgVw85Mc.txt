ID: BRSgVw85Mc
Title: Optimal privacy guarantees for a relaxed threat model: Addressing sub-optimal adversaries in differentially private machine learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 7, 7, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a notion of privacy termed Detection Resilience (DR), which quantifies the success of a membership inference adversary in a relaxed threat model where the adversary lacks access to the target example. The authors provide theoretical results characterizing the optimal adversary under this model, demonstrating that for common privacy mechanisms, the problem reduces to one-sided hypothesis testing. The paper includes expressions for numerically computing trade-off curves for Laplace, Gaussian, and Subsampled Gaussian mechanisms and visualizes the differences between these curves in the relaxed model and f-privacy using synthetic setups.

### Strengths and Weaknesses
Strengths:  
- The paper is a significant step towards actionable provable privacy guarantees in differential privacy (DP), addressing the pessimistic nature of existing guarantees and enabling reduced noise during private training while maintaining reasonable privacy assurances.  
- The theoretical results are well-formed, and the paper is well-written and well-cited.

Weaknesses:  
- The threat model does not correspond to relevant privacy threats, as it assumes the adversary does not know the challenge example, which is not reflective of practical membership inference attacks.  
- The paper lacks results with DP-SGD, making it difficult to assess the utility gains of the proposed relaxation in real-world applications.  
- Many results appear straightforward and intuitive, with some contributions lacking depth, particularly regarding the concept of "lambda-Detection Resilience."

### Suggestions for Improvement
We recommend that the authors improve the motivation for the threat model to clarify its relevance to practical scenarios, particularly in relation to offline membership inference attacks. Additionally, we suggest including evaluations with DP-SGD to better gauge the utility of the proposed approach in real-world settings. The authors should also consider analyzing more complex privacy mechanisms beyond the additive ones currently discussed. Furthermore, we advise refining the contributions paragraph for clarity and ensuring that the title accurately reflects the scope of the work to avoid overclaims.