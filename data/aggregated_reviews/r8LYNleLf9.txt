ID: r8LYNleLf9
Title: TexQ: Zero-shot Network Quantization with Texture Feature Distribution Calibration
Conference: NeurIPS
Year: 2023
Number of Reviews: 20
Original Ratings: 6, 7, 5, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 2, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents TexQ, a novel zero-shot quantization (ZSQ) method that retains texture feature distributions in synthetic samples, achieving state-of-the-art results in ultra-low bit width quantization. The authors propose a texture feature energy distribution calibration method and introduce a mixup knowledge distillation module to enhance the diversity of synthetic samples. The effectiveness of TexQ is demonstrated through extensive experiments on ResNet and MobileNet architectures across CIFAR and ImageNet datasets. Additionally, the paper analyzes incompatibility issues in quantization tasks, particularly in the W2A4 case, where the goals of different methods diverge significantly. The authors provide results showing that methods like Qimera and IntraQ, while effective for ZSQ distillation, struggle with post-training quantization (PTQ) due to their reliance on diversified samples, leading to poor performance. They also identify gaps in distillation-based ZSQ, emphasizing the need for further exploration in distillation modes and image feature extraction.

### Strengths and Weaknesses
Strengths:
- The viewpoint on the importance of texture features in quantization is compelling and well-articulated.
- The experimental results show promising performance, particularly in ultra-low bit quantization scenarios.
- The paper is well-organized, with meaningful discussions in Section 5.1 that enhance its credibility.
- The authors effectively highlight the incompatibility between different quantization methods and their respective goals.
- The detailed analysis of the performance of various methods provides valuable insights into the challenges faced in quantization tasks.

Weaknesses:
- The writing quality is inconsistent, leading to confusion in several sections, such as the unclear statement in Line 171.
- The rationale for using calibration centers in synthetic sample generation is inadequately discussed.
- The principles behind calibration set generation and synthetic sample generation lack clarity, necessitating an ablation study to justify the need for synthetic samples.
- The introduction of "LAWS texture feature energy" is not sufficiently clear, and the numerous artifact weighting coefficients may require further justification through sensitivity analysis.
- The paper does not sufficiently address why calibration samples outperform synthetic samples in certain scenarios, leaving some questions unanswered.
- The explanation regarding the loss of calibration information when synthetic samples are used could be clearer.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their writing, particularly in sections that are currently confusing, such as the statement in Line 171. Additionally, the authors should provide a more thorough discussion on the necessity of calibration centers in synthetic sample generation. An ablation study comparing performance with and without synthetic samples would strengthen their argument. Furthermore, we suggest enhancing the explanation of the "LAWS texture feature energy" concept and conducting a sensitivity analysis on the artifact weighting coefficients to validate their choices. The authors should also improve the clarity of their analysis regarding the performance differences between calibration and synthetic samples, specifically providing a more detailed explanation of how the removal of calibration samples affects the performance of synthetic samples. Addressing the reasons behind the superior performance of calibration samples over synthetic samples in more depth would further strengthen the paper's arguments. Lastly, the authors should consider validating their method on a wider range of architectures, including ResNet-50 and Transformer structures, to demonstrate generalizability.