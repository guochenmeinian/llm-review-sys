ID: APAaTfU21K
Title: Solving the Rubikâ€™s Cube in a Human-like Manner with Assisted Reinforcement Learning (ARL)
Conference: AAAI
Year: 2024
Number of Reviews: 3
Original Ratings: 4, 4, 4
Original Confidences: 5, 4, 3

Aggregated Review:
### Key Points
This paper presents a study on human-AI collaboration in solving the Rubik's Cube, focusing on enhancing assisted reinforcement learning (ARL) by learning reward functions from human trajectories through inverse reinforcement learning (IRL). The authors demonstrate that their system can closely mimic human behavior using a dataset of 10,000 human solving sequences. However, the paper's relevance to mathematical discovery and neural models is unclear, and it lacks algorithmic contributions, making it challenging to assess its significance for the workshop.

### Strengths and Weaknesses
Strengths:
- The implementation of an agent that solves Rubik's Cubes using DQN is commendable.
- The collection of an extensive dataset based on various human solvers is a notable contribution.

Weaknesses:
- The paper lacks ablations on design decisions and evaluations of key claims regarding interpretability, human alignment, and trust.
- There is no comparison with baseline methods optimizing for the shortest solving sequence, such as DeepCubeA.
- Numerous citations are missing, and the narrative lacks coherence, making it difficult to understand how individual components contribute to the overall goal.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the abstract, particularly in sentences like "We demonstrate assisted reinforcement learning, ...". In the related work section, please add explanations and citations for CFOP, the intersection of AI and human problem-solving, and the usefulness of visualizations in human-centered AI. Additionally, clarify the "assisted" aspect of ARL and how it incorporates human intuition. Provide details on the training setup, including the history length in observations and how invalid moves are handled. 

In the IRL approach, clarify the differences in gym environments and provide quantitative analysis to demonstrate that the policy solves the cube in a human-like manner. Consider making the dataset public for future work. In the conclusion, elucidate how the 3D cube model benefits human users and the insights gained from the learned reward function. Lastly, ensure minor corrections, such as placing captions below tables and addressing typographical errors.