ID: 0tEjORCGFD
Title: Collaborative Score Distillation for Consistent Visual Editing
Conference: NeurIPS
Year: 2023
Number of Reviews: 20
Original Ratings: 4, 5, 6, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method called Collaborative Score Distillation (CSD) for consistent visual synthesis and manipulation using a pre-trained pix2pix diffusion model. The authors propose a generalization of the SDS loss to a CSD loss, utilizing Stein variational gradient descent (SVGD), enabling joint distillation of multiple samples from a text-to-image diffusion model. The CSD loss is applicable to various visual editing scenarios, including panorama images, videos, and 3D scenes, and can facilitate text-to-3D generation. The authors formulate the manipulation of these modalities as a multi-particle variational inference problem, interpreting complex visuals as a set of images that maintain modality-specific consistency. They demonstrate that their adaptation generalizes SDS rather than merely addressing its limitations and indicate that improving baseline noise estimation can enhance editing quality.

### Strengths and Weaknesses
Strengths:
- The authors provide results for diverse visual editing applications, showcasing the method's flexibility.
- The approach addresses a novel problem in visual editing across various modalities.
- The formulation as a multi-particle variational inference problem is innovative.
- The use of SVGD for diffusion models is a significant contribution.
- The paper is well-structured and flows smoothly, making it accessible for newcomers.
- Extensive experiments demonstrate the effectiveness of the proposed method, particularly in panorama image, video, and 3D scene editing.

Weaknesses:
- The paper lacks reproducibility due to missing details, such as the selection process for parameter N and the final parameter theta.
- There is insufficient information on aggregating multiple views/frames/crops and explicit classifier-free guidance weights, particularly in 3D generation.
- The rationale for the additional epsilon in equations 8 and 9 is unclear, and the ablation study does not justify the choices made.
- The related work section is lacking, particularly regarding methods beyond DreamFusion, and a more extensive comparison to SDS is needed.
- The paper does not address limitations of SDS, such as mode collapse, which may limit its applicability.
- Figures are overcrowded, particularly Figure 1, which could be clearer if the generated panorama matched the text description.
- Some previous responses may have caused confusion regarding the paper's objectives.

### Suggestions for Improvement
We recommend that the authors improve the reproducibility of their work by providing detailed explanations for parameter selection, particularly for N and theta. Additionally, the authors should clarify the aggregation process for multiple views/frames/crops and specify the classifier-free guidance weights used in their experiments. We suggest that the authors justify the inclusion of epsilon in their equations and expand the ablation study to cover all alternatives. The related work section should be enriched with comparisons to other methods beyond DreamFusion, and a more thorough comparison with SDS should be included. Furthermore, we recommend that the authors improve clarity in their responses to avoid confusion regarding their objectives, specifically distinguishing their work from merely addressing SDS limitations. Finally, we advise revising Figure 1 for clarity, ensuring that the generated panorama corresponds to the text description.