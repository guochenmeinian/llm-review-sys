ID: 7v0UyO0B6q
Title: Online Posterior Sampling with a Diffusion Prior
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 7, 5, 6, 6, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 2, 2, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents novel posterior sampling approximations for contextual bandits utilizing diffusion model priors, aiming to address instability and divergence issues associated with Gaussian priors. The authors propose an algorithm that employs the Laplace approximation, demonstrating asymptotic consistency and effectiveness through empirical evaluations on synthetic and real datasets. The work extends Thompson sampling from K-armed bandits to a broader contextual bandit framework.

### Strengths and Weaknesses
Strengths:  
- The paper introduces a well-motivated approach to enhance existing algorithms by using diffusion model priors, which improves stability and efficiency.  
- The theoretical results, including asymptotic consistency, are convincingly supported by proofs and empirical results.  
- The writing is clear, providing extensive context and making the material accessible to a broad audience.  

Weaknesses:  
- The paper lacks novelty, as the proofs appear standard and similar to those based on Gaussian priors.  
- There are concerns regarding the clarity of certain mathematical statements, particularly the use of "$\approx$" without formal definition.  
- The experimental section lacks depth in discussing the computational demands of the proposed method compared to benchmarks.  
- The discussion on limitations is insufficient, and the paper could benefit from a more explicit examination of tuning parameters and their implications.

### Suggestions for Improvement
We recommend that the authors improve the precision of Theorem statements by replacing "$\approx$" with "=" and clearly stating the assumptions underlying the approximations. Additionally, a discussion on the computational implications of DiffTS relative to its benchmarks, possibly including a figure that reports regret versus time, would enhance the paper. We also suggest that the authors provide a more detailed comparison with related works, particularly Hsieh et al. [22], to clarify the unique contributions of their approach. Finally, a more thorough discussion of the limitations and tuning parameters would strengthen the overall presentation and applicability of the proposed methods.