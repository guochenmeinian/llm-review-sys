ID: iytcEQ5I5v
Title: SDOH-NLI: a Dataset for Inferring Social Determinants of Health from Clinical Notes
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the SDOH-NLI dataset, aimed at enhancing the extraction of Social and Behavioral Determinants of Health (SDOH) from clinical notes through a natural language inference (NLI) framework. The dataset is publicly available and formulated with binary textual entailment labels assigned by human raters. The authors evaluate various state-of-the-art models on this dataset, providing insights into their performance and the challenges posed by the dataset's structure.

### Strengths and Weaknesses
Strengths:
- The creation of the SDOH-NLI dataset addresses the critical issue of extracting SDOH from clinical notes, potentially improving healthcare equity.
- The innovative approach of framing SDOH extraction as an NLI task could advance NLP methods in this domain.
- The paper is well-written and presents a comprehensive evaluation of baseline models.

Weaknesses:
- The dataset suffers from significant data imbalance and redundancy, with a high repetition of premises and hypotheses, which may lead to models relying on statistical patterns rather than deeper understanding.
- There is insufficient detail regarding the annotation guidelines, data collection processes, and how privacy and regulatory constraints were managed.
- The reliance on human raters for binary labels raises concerns about potential bias and the quality of the dataset.

### Suggestions for Improvement
We recommend that the authors improve the dataset's usability by addressing the issues of imbalance and redundancy, possibly by diversifying the examples or restructuring the dataset. Additionally, we urge the authors to provide more detailed descriptions of the annotation guidelines and data collection methods, as well as a discussion on how privacy and regulatory concerns were navigated. Clarifying the fine-tuning process for retrieval models and addressing the potential biases introduced by human raters would also strengthen the paper.