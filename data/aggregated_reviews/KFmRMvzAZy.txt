ID: KFmRMvzAZy
Title: Rethinking LLM Memorization through the Lens of Adversarial Compression
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 7, 5, 7, 6, 4, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 4, 3, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel metric for assessing memorization in LLMs called Adversarial Compression Ratio (ACR). ACR is defined as the ratio between the length of the generation needed to test memorization and the length of the shortest prompt that can elicit such a generation. The authors argue that traditional definitions of memorization may be inadequate and propose ACR as a more effective measure. They validate ACR through experiments, demonstrating its utility in detecting memorized content even after unlearning attempts.

### Strengths and Weaknesses
Strengths:
1. The authors propose an innovative metric that significantly contributes to the field of LLM memorization.
2. The validation of ACR against existing unlearning methods is compelling and prompts further inquiry into model memorization.
3. The paper is well-organized, clearly written, and includes effective visual aids, making it accessible to readers.
4. A comprehensive literature review underscores the importance of the proposed metric.

Weaknesses:
1. Some concepts require further clarification, particularly the justification for the adversarial perspective in the compression argument and the threshold parameter $\tau(y)$.
2. The efficiency of Algorithm 1 lacks analysis, and the potential bias of ACR towards longer sequences may affect its evaluation of concise knowledge.
3. The introduction of the MINIPROMPT algorithm is brief, and a more detailed explanation of the Greedy Coordinate Gradient (GCG) algorithm would enhance reader comprehension.
4. The method does not account for paraphrases, which could lead to false positives in memorization detection.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the justification for the adversarial view in the compression argument and provide more analysis on the threshold parameter $\tau(y)$. Additionally, conducting an efficiency analysis on Algorithm 1 would strengthen the paper. We suggest expanding the introduction of the MINIPROMPT algorithm and including a brief overview of GCG for better accessibility. Finally, addressing the issue of paraphrases in the context of memorization detection would enhance the robustness of the proposed metric.