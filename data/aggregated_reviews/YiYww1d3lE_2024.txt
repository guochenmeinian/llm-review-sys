ID: YiYww1d3lE
Title: AWT: Transferring Vision-Language Models via Augmentation, Weighting, and Transportation
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 7, 7, 6, 4, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an adaptation framework, AWT, aimed at enhancing vision-language models (VLMs) through augmentations of visual images and textual class names. The authors propose a method that dynamically weights these augmentations based on prediction entropy and employs optimal transport to measure the semantic correlation between the augmented sets. The experimental results indicate strong performance across various tasks, including zero-shot and few-shot classification, as well as out-of-distribution generalization.

### Strengths and Weaknesses
Strengths:
- The paper is well-illustrated, organized, and easy to follow.
- AWT is a novel and effective framework that improves VLM performance without incurring additional training costs.
- The use of a single set of hyper-parameters across all datasets distinguishes this method in low-shot adaptation, achieving state-of-the-art results.

Weaknesses:
- The performance-efficiency trade-off under few-shot settings is not adequately explored, particularly in comparison to zero-shot settings.
- There is insufficient detail on how hyper-parameters were chosen, which could enhance the understanding of the results.
- The rationale for selecting flipping as an image augmentation strategy is unclear, given that random cropping already captures fine-grained matching.
- The paper lacks a comparison with weighted averaging based on prediction entropy, which would clarify the importance of optimal transport.
- The related work section is limited and should include recent methods like CLIP-Adapter and TIP-Adapter, as well as a discussion of their differences from AWT.

### Suggestions for Improvement
We recommend that the authors improve the analysis of performance under few-shot settings to strengthen the significance of their findings. Additionally, providing more detailed explanations regarding hyper-parameter selection would enhance clarity. The authors should also justify the choice of flipping as an augmentation strategy and consider incorporating more sophisticated augmentation techniques. A comparison with weighted averaging methods should be included to better illustrate the advantages of their approach. Finally, expanding the related work section to include recent adaptations and clarifying the distinctions between these works and AWT would provide a more comprehensive context for their contributions.