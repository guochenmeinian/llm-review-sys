ID: QyxE3W9Yni
Title: Faster Differentially Private Top-$k$ Selection: A Joint Exponential Mechanism with Pruning
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 6, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a compute and memory efficient implementation of the differentially private top-$k$ algorithm proposed by Gillenwater et al. (2022), utilizing the exponential mechanism across all index sequences of length $k$. The authors improve the time complexity from $O(d k \log k + d \log d)$ and space complexity from $O(dk)$ to $\widetilde{O}(d + k^2)$, where $\widetilde{O}$ omits log factors. Experimental comparisons demonstrate that this method achieves comparable utility to Gillenwater et al. (2022) while offering 1-2 orders of magnitude faster running time.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, particularly in its motivation and introduction.
- It contributes a clear enhancement to an existing state-of-the-art method, achieving better empirical performance in some cases.

Weaknesses:
- The contribution appears narrow, primarily focused on reducing memory consumption and compute time without surpassing the speed of the baseline method "CDP Peel" by Rogers et al. (2019), which often outperforms in utility. 
- The paper lacks clarity on the broader applicability of this implementation, particularly in distinguishing when this method is preferable to CDP Peel.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the practical scenarios where this implementation is necessary, particularly in online settings, and clarify whether the speed is sufficient for such applications. Additionally, addressing the comparative advantages of this method over CDP Peel would enhance the paper's relevance. We also suggest including a more detailed supplementary section on the Joint Exponential Mechanism to provide necessary background, as well as incorporating $\epsilon$ in the running time for better clarity in comparisons. Minor corrections should also be made, such as fixing "the its" and "lose function," and providing definitions for terms like $s$ in Equation 4.