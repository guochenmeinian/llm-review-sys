ID: 7gIhLGqyph
Title: Are Structural Concepts Universal in Transformer Language Models? Towards Interpretable Cross-Lingual Generalization
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates the encoding of structural concepts in pre-trained language models (LMs) and their alignment across languages using POS tags and grammatical relations. The authors demonstrate that structural concepts are implicitly aligned through vanilla pre-training and propose a meta-learning-based approach to enhance explicit alignments. The analysis extends to in-context learning, showing that alignment with demonstration examples yields further improvements.

### Strengths and Weaknesses
Strengths:
- The paper is well-structured and easy to follow.
- It provides a comprehensive analysis of cross-lingual alignments of structural concepts in pre-trained LMs, potentially inspiring future research.
- The proposed meta-learning method is data-efficient and competitive with state-of-the-art results, particularly for low-resource languages.

Weaknesses:
- The analysis is limited to two types of syntactic structures, lacking exploration of semantic concepts and their impact on downstream tasks.
- Only two pre-trained LMs (mBERT and LLaMA) are analyzed, raising concerns about the generalizability of findings.
- Some experimental comparisons are not fair, with discrepancies in training data across models.

### Suggestions for Improvement
We recommend that the authors improve the analysis by including additional types of syntactic and semantic structures to enrich the findings. Expanding the range of pre-trained LMs analyzed would also strengthen the generalizability of the results. Additionally, clarifying the meta-learning setting and addressing the inconsistencies in the results, such as those in Figure 1, would enhance the paper's rigor. Lastly, exploring the correlations between alignability and language distances could provide valuable insights.