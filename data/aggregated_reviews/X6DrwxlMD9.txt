ID: X6DrwxlMD9
Title: Evaluating Dependencies in Fact Editing for Language Models: Specificity and Implication Awareness
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an evaluation protocol for knowledge editing in LLMs, focusing on the dependency between facts and their logical implications. The authors propose a semi-supervised online learning process that includes initial fine-tuning, retrieval of relational facts, validation of generation errors, and re-use of corrected facts for further fine-tuning. The experiments demonstrate that existing methods struggle with logical dependencies during knowledge editing.

### Strengths and Weaknesses
Strengths:  
- The proposed task and dataset are novel and likely impactful for future research in knowledge editing.  
- The experiments and analysis are comprehensive, providing a detailed assessment of the proposed methodology.

Weaknesses:  
- The experiments reveal that existing knowledge editing methods are sensitive to surface forms and have limited performance in inferring implications.  
- There is insufficient detail regarding the quality of the annotators' work and how disagreements among them are handled.  
- The paper lacks a clear justification for the importance of the proposed task and benchmark, and it does not address potential downsides of iterative fine-tuning, such as catastrophic forgetting.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by providing a more thorough explanation of the significance of knowledge editing and the implications of their approach. Additionally, we suggest including details about the annotation process, such as how disagreements among annotators are resolved and the consistency of their evaluations. An illustrative diagram of the annotation process would also enhance reader understanding. Finally, addressing the potential downsides of iterative fine-tuning, particularly regarding the impact on multi-task learning capabilities, would strengthen the paper.