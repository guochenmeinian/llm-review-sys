ID: GTYaYNsFyv
Title: ChatGPT-Powered Hierarchical Comparisons for Image Classification
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 5, 6, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a hierarchical approach for enhancing the classification performance of a vision-language model (CLIP) by utilizing descriptions generated from a large-language model (GPT-4). Unlike previous methods that extract direct class descriptions, the authors propose a multi-layered strategy that iteratively refines class descriptions through clustering similar classes. The experimental results demonstrate that the proposed model consistently outperforms CLIP and the direct descriptions from prior work, achieving state-of-the-art performance across various datasets.

### Strengths and Weaknesses
Strengths:
- The multi-stage classification process allows for a focus on easier separations before addressing finer distinctions, enhancing interpretability as it reveals which descriptions contribute to high classification scores.
- The framework's flexibility enables its application to new versions of large-language models and vision-language models.
- The method exhibits high interpretability by mirroring human cognitive organization of visual and linguistic concepts, improving the understanding of the classification process.

Weaknesses:
- The performance gap between the proposed model and previous methods is minimal, with average accuracy gains below 1%, raising concerns about overstated contributions and increased computational costs due to more text-image comparisons.
- Limited analysis of hyperparameters, such as the impact of the factor $\lambda$ and the number of clusters $N$, is provided, which could affect the model's performance.
- The absence of diverse domain datasets in evaluations limits the generalizability of the proposed method.
- The definition of the tolerance score $\tau$ is unnecessary if it is not utilized in experiments, and its impact should be clarified if included.

### Suggestions for Improvement
We recommend that the authors improve the analysis of hyperparameters, particularly the impact of $\lambda$, $N$, and the threshold $l$, to provide a clearer understanding of their effects on model performance. Additionally, including datasets from diverse domains would enhance the validation of the proposed method's robustness. We suggest discussing the potential use of recent open-source LLMs like LLaMA, Alpaca, and Vicuna for generating descriptions to broaden the evaluation scope. Furthermore, we advise that the authors clarify the role of $\tau$ in the manuscript and consider omitting it if it does not contribute positively to the results. Lastly, we encourage the authors to incorporate the quantitative and qualitative analyses from the rebuttal into the main paper to enrich the insights into the model's functioning.