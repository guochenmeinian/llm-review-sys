ID: LNKGWaRtlE
Title: Ecologically Valid Explanations for Label Variation in NLI
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the LIVENLI dataset, which contains 1,415 ecologically valid explanations for 122 MNLI items, to explore human label variation in natural language inference (NLI). The authors analyze both label variation and within-label variation, revealing that annotators sometimes select the same label for different reasons, indicating the importance of explanations in label interpretation. The paper also investigates the use of LLMs to predict and explain label variation, emphasizing the necessity for diverse explanations to mimic human decision-making.

### Strengths and Weaknesses
Strengths:
- The introduction of the LIVENLI dataset fills a significant gap in the field and serves as a valuable resource for future research.
- The authors provide thorough human annotation and analysis, identifying Questions Under Discussion (QUDs) as a key factor in label variation, which adds depth to existing taxonomies.
- The exploration of human label variation is a novel contribution that can lead to more sophisticated approaches in NLI tasks.

Weaknesses:
- The paper lacks focus, treating label variation and within-label variation as distinct problems without sufficient depth in analysis.
- The dataset's small size may limit its effectiveness in providing comprehensive insights into label variation across diverse contexts.
- The evaluation is restricted to GPT-3, omitting other state-of-the-art models like GPT-4, which could broaden the understanding of AI's capabilities in this area.

### Suggestions for Improvement
We recommend that the authors improve the focus of the paper by thoroughly analyzing either label variation or within-label variation, rather than treating them as separate issues. If the emphasis is on label variation, more discussion on the NLI task's complexities and potential mistakes in the dataset's labels is necessary. Conversely, if focusing on within-label variation, the authors should present hypotheses about model mechanisms and analyses to support these claims. Additionally, expanding the dataset to include more non-NLI examples would enhance its applicability. Finally, we suggest clarifying the methodology regarding the use of text-davinci-003 for multilabel classification and providing prompts in the appendix for reproducibility.