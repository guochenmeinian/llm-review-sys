ID: 0NMzBwqaAJ
Title: Not All Tokens Are What You Need for Pretraining
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 7, 7, 9, -1, -1
Original Confidences: 4, 4, 4, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis of token-level training dynamics in continued pretraining, identifying four loss patterns: persistent low loss, persistent high loss, increasing loss, and decreasing loss. The authors propose Selective Language Modeling (SLM), which trains on a subset of input tokens selected based on the "excess loss" computed from a high-quality reference model. The model trained using SLM, Rho, demonstrates strong performance on math and other benchmarks compared to standard continual pretraining models.

### Strengths and Weaknesses
Strengths:  
- The identification of four token-level loss categories is novel and well-analyzed, providing a solid foundation for the proposed method.  
- The strategy of selecting a subset of tokens for training is clever and effective, yielding strong results, particularly on math benchmarks.  
- The analysis is comprehensive, with insightful comparisons between token losses and downstream performance for selected and unselected tokens.  

Weaknesses:  
- Concerns about training time and cost arise from claims of "10x faster"/"5x faster" in Figure 1, which do not account for the pre-scoring cost of each token. The efficiency claims need clearer explanations, as the data efficiency is well-supported, but broader efficiency claims lack substantiation.  
- The title and abstract imply a broader application of the method than is supported, as the focus is primarily on continued pretraining and math datasets.  
- The reference model should be included in results tables to clarify if Rho outperforms it.  
- The method's hard selection cutoffs may be overly rigid; weighting examples by "excess loss" could enhance performance, which the authors mention as a future direction.  

### Suggestions for Improvement
We recommend that the authors improve the clarity of efficiency claims by measuring and reporting the cost of pre-scoring tokens. Additionally, the title and abstract should be revised to accurately reflect the focus on continued pretraining and math tasks. Including the reference model in results tables would provide necessary context for evaluating Rho's performance. We also suggest exploring a weighting approach for token selection based on "excess loss" to potentially enhance results. Finally, providing example sets of tokens and clearer interpretations of loss categories would strengthen the paper's motivation and findings.