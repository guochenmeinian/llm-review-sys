ID: jdCMwF06c6
Title: LT-Defense: Searching-free Backdoor Defense via Exploiting the Long-tailed Effect
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 4, 4, 6, -1, -1, -1, -1
Original Confidences: 4, 4, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents LT-Defense, a search-free backdoor defense method for detecting backdoored models in language processing. It leverages the long-tailed effect induced by poisoned datasets, which shifts decision boundaries towards target labels. LT-Defense utilizes a small set of clean samples and two metrics to identify backdoor-related features, offering test-time backdoor freezing and attack target prediction. Extensive experiments validate the method's effectiveness across various backdoor attacks and models.

### Strengths and Weaknesses
Strengths:
- The approach is original, utilizing the long-tailed property of backdoored models, which is both simple and effective.
- The experiments are well-designed, demonstrating superior performance and efficiency compared to baseline methods.
- The method does not require trigger searches, significantly reducing the time cost of backdoor defense.

Weaknesses:
- The presentation of the problem and method lacks clarity, with undefined terms and incorrect mathematical notations, such as in equation (1).
- The design choices and hyperparameter selections are inadequately explained, lacking general guidelines for their settings.
- There is insufficient comparison with existing methods for task-related backdoor detection, limiting the demonstration of LT-Defense's advantages.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the problem and method presentation, particularly by defining all terms and correcting mathematical notations. Additionally, the authors should provide a more detailed explanation of the design choices and hyperparameter settings, including the rationale behind specific values. It would also be beneficial to include comparisons with existing methods for task-related backdoor detection to better highlight the advantages of LT-Defense. Furthermore, testing the method against implicit attacks that do not target fixed tokens, such as sentiment manipulation, would strengthen the evaluation of its robustness.