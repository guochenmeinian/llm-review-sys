ID: P3v3x7HnV0
Title: QueST: Self-Supervised Skill Abstractions for Learning Continuous Control
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 4, 6, 5, 7, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel framework for learning generalizable skills from demonstration data using a quantized discrete latent variable model. The authors propose a method that encodes actions into a latent space and decodes them to predict temporal sequences of actions. The approach employs causal encoders and decoders, differing from traditional methods that condition states and actions as inputs. The method is validated on LIBERO and Meta-World environments, demonstrating improved performance over existing approaches. The authors also conduct extensive ablation studies to analyze the impact of various design choices.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, providing a clear explanation of the proposed framework.
- The experimental evaluations on LIBERO and Meta-World are robust, showing significant performance improvements compared to several recent baselines.
- The use of causal encoders/decoders for latent abstraction is an interesting contribution.
- The methodology leverages the structure of robotic manipulation tasks effectively.

Weaknesses:
- The originality of the work is somewhat limited, as it closely resembles existing methods like VQ-BeT and PRISE without sufficient differentiation.
- The analysis of the learned latent representations is insufficient; it should clarify what the latent variables are capturing regarding temporal abstractions.
- There is a lack of real-world robotic experiments, which raises concerns about the practical applicability of the proposed method.
- The paper does not adequately address inference latency or provide error bars in key figures, which could undermine the robustness of the findings.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the differences between their method and similar approaches like VQ-BeT and PRISE, possibly including a comparative table. Additionally, the authors should include a detailed analysis of the learned latent variables to verify their claim about capturing skill abstractions. We suggest conducting real-world robotic experiments to validate the method's applicability beyond simulation. Furthermore, addressing latency considerations and providing error bars in figures would enhance the robustness of the results. Lastly, clarifying the tuning of hyperparameters for both the proposed method and the baselines in the main body of the paper is essential for transparency.