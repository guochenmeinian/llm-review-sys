ID: TEpRn67828
Title: Uniform Convergence with Square-Root Lipschitz Loss
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 7, 6, 4, 7, 4, -1, -1, -1, -1
Original Confidences: 1, 3, 3, 3, 2, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents uniform convergence results for empirical risk minimization with a square-root Lipschitz loss function, assuming the covariate vector \(x\) follows a \(d\)-dimensional multivariate normal distribution. The authors derive bounds on the population risk in relation to empirical risk, incorporating the Lipschitz constant, complexity measures, and sample size. This result is applied to various problems, including phase retrieval, ReLU regression, and matrix sensing, while also demonstrating that Gaussian universality does not universally apply in this context.

### Strengths and Weaknesses
Strengths:
1. The paper builds upon and generalizes existing literature, establishing a significant result and applying it to relevant problems.
2. It provides clear and rigorous presentation, making complex concepts accessible.
3. The extension to square-root Lipschitz losses offers valuable insights, particularly in the context of optimistic rates.

Weaknesses:
1. The notion of "consistency" is mentioned but lacks a thorough explanation, which may hinder understanding for readers outside the field.
2. Assumption (C) requires further clarification regarding its necessity and expected applicability.
3. The proof technique is not entirely novel, relying on prior works, and the focus remains on Gaussian data, limiting broader applicability.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the term "consistency" and its relation to traditional statistical concepts. Additionally, further explanation of Assumption (C) is necessary to justify its inclusion. We suggest discussing the implications of the Gaussian feature assumption and exploring potential extensions to non-Gaussian settings. Furthermore, providing a detailed discussion of the ten distinct terms in the bound of equation (10) would enhance comprehension. Lastly, we encourage the authors to include comparisons with existing results to better highlight their contributions.