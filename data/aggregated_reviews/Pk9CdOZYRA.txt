ID: Pk9CdOZYRA
Title: Optimal Preconditioning and Fisher Adaptive Langevin Sampling
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 6, 7, 7, 8, -1, -1, -1, -1
Original Confidences: 5, 5, 4, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an optimal preconditioning for Langevin diffusion by maximizing the expected squared jumped distance, identifying the optimal preconditioning as an inverse Fisher information covariance matrix. The authors apply this to the Metropolis adjusted Langevin algorithm (MALA) and derive an efficient adaptive MCMC scheme that learns the preconditioning from gradient history during execution. Experiments demonstrate that the proposed algorithm outperforms standard methods, particularly in Gaussian target distributions.

### Strengths and Weaknesses
Strengths:  
- The innovative use of the inverse Fisher information covariance matrix as a preconditioner for MALA is a novel contribution.  
- The adaptive learning of preconditioning from gradient history is a valuable idea.  
- Experimental results indicate the algorithm's promise and effectiveness.

Weaknesses:  
- The paper lacks theoretical justification for the empirical findings, raising concerns about the method's universality and optimal applicability.  
- The computation of the inverse Fisher information may be complex, necessitating a computational complexity analysis.  
- There is no theoretical support for convergence speed in non-Gaussian settings, and additional numerical examples for such distributions are needed.  
- The main text's claims regarding the Rao-Blackwellized version's superiority are not substantiated by the numerics in Appendix E, which may be misleading.  
- Numerous grammatical errors and awkward phrasings detract from the overall presentation.

### Suggestions for Improvement
We recommend that the authors improve the theoretical justification for the proposed method, particularly regarding its applicability to non-Gaussian distributions. Additionally, a computational complexity analysis of the inverse Fisher information computation should be included. We suggest providing numerical examples for mixed Gaussian or non-log concave distributions to test the algorithm's performance. Furthermore, a clearer comparison with related methods, such as the Newtonâ€“Langevin diffusion, should be included. Lastly, we advise a thorough proofreading to address grammatical errors and enhance clarity.