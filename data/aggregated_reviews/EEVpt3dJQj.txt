ID: EEVpt3dJQj
Title: Auditing Fairness by Betting
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 8, 6, 8, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a safe anytime-valid inference (SAVI) testing procedure for auditing classifier and regression model fairness, proposing group-conditioned fairness as a test of equality of means under specified conditions. The authors introduce a technique for sequential testing that accommodates repeated testing, finite or infinite time horizons, batched testing, and importance-weighted testing, providing expected stopping times for their procedure. The work also explores continuous monitoring of fairness in deployed models, addressing distribution shifts and leveraging recent advancements in game-theoretic statistics.

### Strengths and Weaknesses
Strengths:
- The paper is well-structured and clearly written, providing all necessary information for understanding its contributions.
- It offers practical considerations such as time horizon, batched testing, and importance weighting, making the method simple to implement.
- The originality of continuous fairness monitoring in real-world systems is a significant contribution, supported by rigorous theoretical reasoning and empirical analysis.

Weaknesses:
- The main limitation is the lack of immediate applicability to scenarios where equality of means is too strict, as the authors do not explore testing for absolute differences below a specified epsilon value.
- The experiments are limited to only two datasets and one model (Random Forest), which restricts the robustness of the findings. The paper could benefit from exploring various fairness methods and models.

### Suggestions for Improvement
We recommend that the authors improve the paper by addressing the limitations related to extending the methodology to settings where equality of means may be too strict. Specifically, incorporating a discussion on testing for absolute differences in means would enhance the applicability of the framework. Additionally, we suggest including more datasets and exploring the effects of different fairness methods, such as in-processing, post-processing, and preprocessing approaches, to provide a more comprehensive understanding of the proposed methods. Finally, we encourage the authors to clarify how their framework could adapt to individual fairness scenarios, particularly in cases of non-deterministic outputs.