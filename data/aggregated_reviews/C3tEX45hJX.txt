ID: C3tEX45hJX
Title: Diffusion Spectral Representation for Reinforcement Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 6, 6, 6, 7, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 2, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Diff-Rep, a novel method that integrates diffusion models into reinforcement learning (RL) to learn representations of value functions while mitigating the high inference costs associated with traditional diffusion sampling. The authors demonstrate that spectral representations can be learned using a diffusion-like loss function, allowing for efficient online policy optimization. Evaluations on Gym-MuJoCo locomotion tasks and partially observable MDP tasks reveal that Diff-Rep achieves superior performance compared to existing methods, particularly in POMDP settings.

### Strengths and Weaknesses
Strengths:
- The integration of diffusion models into the LV-Rep framework is innovative and provides a fresh perspective on diffusion-based RL methods.
- Empirical results indicate that Diff-Rep outperforms competitive baselines across various continuous control tasks and shows reduced wall time compared to PolyGRAD.
- The writing is generally clear and easy to follow, with a solid motivation stemming from the LV-Rep framework.

Weaknesses:
- In the MDP setting, Diff-Rep only shows significant advantages in specific tasks, such as HalfCheetah, while performing similarly or worse than LV-Rep and PolyGRAD in others. A clearer explanation for this discrepancy is needed.
- The theoretical analysis is limited; more formal characterizations or guarantees on the representation power, such as error bounds on the Q-function approximation, would strengthen the contributions.
- The paper contains several grammatical errors and unclear statements that detract from its overall clarity.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their exposition, particularly by addressing grammatical issues and providing clearer definitions for key terms and concepts. Additionally, we suggest including a runtime comparison between Diff-Rep and LV-Rep, as well as plots illustrating the accuracy of the estimated Q-function using the proposed representation. To enhance the theoretical foundation, we encourage the authors to provide formal characterizations of the representation power and discuss potential limitations in practical applications. Finally, a discussion on the representation quality, possibly through experiments on toy latent-state MDPs, would further enrich the paper.