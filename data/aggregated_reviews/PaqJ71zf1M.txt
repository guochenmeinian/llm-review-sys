ID: PaqJ71zf1M
Title: Continuous Contrastive Learning for Long-Tailed Semi-Supervised Recognition
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 7, 6, 7, 7, -1
Original Confidences: 5, 2, 5, 4, -1

Aggregated Review:
### Key Points
This paper presents a novel method to address the long-tail problem in semi-supervised learning by leveraging continuous contrastive learning on both labeled and unlabeled samples to enhance model performance, particularly for minority classes. The authors propose a probabilistic framework that unifies recent approaches in long-tail learning and introduces a continuous contrastive learning method based on reliable and smoothed pseudo-labels to mitigate confirmation bias and improve representation quality. The experiments demonstrate the effectiveness of the proposed method across various datasets.

### Strengths and Weaknesses
Strengths:
- Novelty: The integration of contrastive learning with unlabeled samples is relatively unexplored in existing literature.
- Technical Soundness: The theoretical formulation and unified framework of existing long-tail learning methods are well-explained and logically sound.
- Comprehensive Experiments: The experiments cover various imbalanced and labeled ratios on CIFAR-10-LT and CIFAR-100-LT datasets, showing statistically significant improvements over baseline methods.
- Clarity: The paper is well-structured and clearly written, with effective illustrations of results.

Weaknesses:
- It is unclear how selecting pseudo-labels using energy score ensures better model calibration (line 189).
- The authors should explicitly discuss how the proposed method addresses the unlabeled data for diverse label distributions and why other methods do not.
- The interpretation of the statement regarding model outputs and representation learning (lines 33-34) needs clarification.
- An analysis of the relationship between reliable and smoothed pseudo-labels is necessary, as well as a comparison of time and space complexity with other methods.
- The training time of the proposed method is not reported, and a comparison with ACR is suggested.

### Suggestions for Improvement
We recommend that the authors improve the clarity of how selecting pseudo-labels using energy score contributes to model calibration. Additionally, the authors should explicitly discuss the handling of diverse label distributions in unlabeled data and clarify the interpretation of the statement regarding model outputs. An analysis of the relationship between reliable and smoothed pseudo-labels should be included, along with a comparison of time and space complexity with existing methods. Finally, we suggest reporting the training time of the proposed method and comparing it with ACR.