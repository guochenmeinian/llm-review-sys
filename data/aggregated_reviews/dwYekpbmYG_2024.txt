ID: dwYekpbmYG
Title: Free Lunch in Pathology Foundation Model: Task-specific Model Adaptation with Concept-Guided Feature Enhancement
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 5, 8, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an approach to enhance image features from Vision-Language Models (VLM) for downstream tasks in histopathology by aligning them with task-specific text prompts. The authors propose two modules: the Concept-guided Information Bottleneck (CIB) module, which retains relevant features while eliminating irrelevant ones, and the Concept-Feature Interference (CFI) module, which creates task-specific features. Additionally, the paper introduces a novel method for integrating domain knowledge into whole slide image (WSI) classification using large language models (LLMs) and retrieval-based LLMs. The authors demonstrate that CATE-MIL outperforms ABMIL across various datasets, particularly in distinguishing site-specific features and enhancing model generalization. Results from cancer subtyping tasks and WSI classification experiments provide solid evidence of the proposed methods' effectiveness.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, clearly presenting key ideas and methodologies.
- The experiments are well-structured, providing solid evidence of the proposed methods' effectiveness and discussing limitations.
- The innovative use of textual prompts to create task anchors and the predictive information maximization (PIM) objective are noteworthy contributions.
- The integration of domain-specific knowledge into WSI classification is innovative and has the potential to advance computational pathology.
- Experimental results indicate that CATE-MIL consistently outperforms ABMIL, particularly in terms of generalization and site-specific feature handling.
- The authors have addressed reviewer concerns by conducting additional experiments and clarifying technical aspects of their methodology.

Weaknesses:
- The approach's applicability is limited by assumptions regarding patch-level alignment, which can be noisy and inappropriate for tasks requiring aggregation across patches.
- The reliance on the quality of text prompts and the pre-trained VLM raises concerns about generalizability, particularly for complex tasks lacking robust descriptions.
- The performance of CATE is questioned due to its dependence on the quality of concept anchors and the unclear contributions of the alignment step versus patch filtering.
- The complexity of the model may lead to overfitting, and the relationship between parameters in CATE-MIL and ABMIL is not entirely clear.
- The alignment of patches to tasks is dependent on the quality of the VLM and the prompts used, which may introduce noise into the process.
- Some reviewers feel that the addressed concerns were not comprehensive enough to warrant a higher rating.

### Suggestions for Improvement
We recommend that the authors improve the alignment of slide-level representations with task concepts instead of patch-level representations to address the limitations associated with noisy patch alignment. Additionally, we suggest exploring more principled methods for generating expert-designed prompts to enhance the robustness of the approach. Clarifying the experimental settings, particularly regarding the choice of in-domain and out-of-domain sites, would also strengthen the paper. Furthermore, we recommend improving the clarity regarding the term "bottleneck" in the context of feature dimensions to avoid misunderstandings. It would be beneficial to explore tasks such as survival and biomarker prediction, where reliable features are not yet established, and to leverage LLMs to generate descriptive prompts for morphological features. Finally, we suggest including the results of additional experiments and clarifications in the revised manuscript to strengthen the overall presentation of the work.