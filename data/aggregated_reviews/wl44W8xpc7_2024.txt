ID: wl44W8xpc7
Title: Learning Infinitesimal Generators of Continuous Symmetries from Data
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 5, 6, 6, -1, -1, -1
Original Confidences: 3, 4, 3, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for data-driven symmetry discovery using neural ODEs to parameterize symmetries as elements of a one-parameter group. The authors demonstrate that by learning the parameters of these neural ODEs, they can recover ground truth symmetries in image classification and PDE tasks. The validity score, a critical component of the method, measures the extent to which transformed data remains symmetric to the input, utilizing cosine similarity for images and numerical errors for PDEs. The method is tested on CIFAR10 and various PDEs, showing competitive results and the ability to learn both affine and non-affine symmetries.

### Strengths and Weaknesses
Strengths:  
- The paper addresses an important problem in machine learning and physical sciences, potentially improving generalization in low-data regimes.  
- The methodology allows for the recovery of symmetries from non-affine transformations without requiring predefined group structures.  
- The execution of the proposed method is well-implemented, yielding competitive results in experiments.

Weaknesses:  
- The reliance on the validity score is a significant limitation, as it is crucial for determining the learned symmetries and may not be universally applicable.  
- There is insufficient empirical validation of the validity score, particularly for image tasks, raising concerns about its robustness.  
- The paper lacks comparisons with other methods, particularly those using MLPs, which could strengthen the argument for using neural ODEs.

### Suggestions for Improvement
We recommend that the authors improve the clarity and robustness of the validity score, explicitly acknowledging its limitations and the assumptions required in domains beyond PDEs. Additionally, we suggest including a direct comparison with MLP-based methods to empirically support the necessity of employing neural ODEs. The authors should also provide a more detailed discussion on the types of groups that can be learned, including continuous and differentiable groups, and consider including additional empirical evidence across various datasets to bolster their claims. Finally, enhancing the exposition of group theory concepts and experimental details would make the work more accessible to a broader audience.