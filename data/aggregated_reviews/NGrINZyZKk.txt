ID: NGrINZyZKk
Title: UniAudio 1.5: Large Language Model-Driven Audio Codec is A Few-Shot Audio Task Learner
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 5, 6, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 2, 5, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents LLM-Codec, a novel audio codec model that integrates with existing frozen LLMs, such as LLAMA-2, to perform few-shot in-context learning for tasks including speech emotion classification and text-to-speech synthesis. The model encodes raw audio waveforms into a latent space, utilizing a multi-layer alignment design where shallow layers capture semantic information and deeper layers focus on fine-grained details. Four losses—semantic loss, consistency loss, reconstruction loss, and discriminator loss—are employed to align features with the LLM's pretrained embedding space. Experiments validate the module's effectiveness in audio understanding and TTS tasks.

### Strengths and Weaknesses
Strengths:
1. The paper proposes an innovative plug-in module for LLMs that allows for few-shot learning in audio tasks without requiring LLM training or fine-tuning, maintaining efficiency with only 160M parameters.
2. The tasks addressed encompass both audio understanding and text-to-speech synthesis, showcasing flexibility within the constraints of in-context learning.
3. The manuscript is mostly well-written, with a clear presentation of the motivation and proposed method.

Weaknesses:
1. The simplicity of the tasks raises concerns about the model's performance in more complex scenarios, particularly as the number of classes increases or when handling more intricate TTS scripts.
2. The accuracy of random guessing in the 2-way speech emotion classification task is unexpectedly low at 40%, and the reported 59% accuracy for binary classification is insufficient, prompting questions about what improvements are needed.
3. The experimental setup lacks clarity, particularly regarding the evaluation metrics and the results presented in Tables 1, 3, and 4, which require further explanation.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the experimental setup and results, particularly by providing additional demonstrations of the main experimental findings to enhance readability. It is crucial to address the low accuracy rates in the classification tasks and clarify the evaluation metrics used. Additionally, the authors should compare their approach with BLIP-like methods to elucidate the advantages of their pipeline. Finally, we suggest that the authors expand their discussion on the theoretical connections between their codec-based method and embedding injection-based approaches, as well as address the grammatical and formatting issues throughout the manuscript.