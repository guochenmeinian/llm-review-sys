ID: qv5UZJTNda
Title: Multimodal Deep Learning Model Unveils Behavioral Dynamics of V1 Activity in Freely Moving Mice
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 8, 5, 7, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 3, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a multimodal neural network designed to predict the activity of V1 neurons in freely moving mice, utilizing approximately one-hour-long electrophysiological recordings alongside visual scenes and behavioral variables. The architecture comprises two modules: one for visual feature extraction and another for encoding behavioral variables, with outputs combined and processed through a recurrent unit (GRU) to account for temporal dynamics. The model achieves state-of-the-art performance, surpassing previous benchmarks, and is analyzed through maximal-activating stimuli and saliency analysis to elucidate the effects of individual behavioral variables on neural activity.

### Strengths and Weaknesses
Strengths:
- The paper is clearly written and addresses an important problem regarding the integration of behavioral variables in predicting V1 activity.
- The proposed model demonstrates a significant improvement over prior state-of-the-art models.
- The incorporation of behavioral data provides valuable insights into neuronal computations.

Weaknesses:
- The dataset is relatively small, limiting the ability to draw quantitative conclusions from the diversity of maximal-activating stimuli (MEIs).
- The paper lacks a discussion on limitations and does not explore the mechanistic implications of the findings.
- The related work section is limited and could benefit from a broader context of computational models in mouse visual activity.

### Suggestions for Improvement
We recommend that the authors improve the dataset size to include a calcium dataset with thousands of neurons to enhance the robustness of their conclusions. Additionally, we suggest expanding the discussion on the mechanistic understanding of V1 functions and the anatomical inputs related to behavioral variables. It would also be beneficial to enhance the related work section to include more comprehensive information about other relevant computational models. Lastly, we encourage the authors to provide more details about the visual stimuli and recording setup in the Methods section, and to clarify their openness to sharing models and code for reproducibility.