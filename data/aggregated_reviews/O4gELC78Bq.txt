ID: O4gELC78Bq
Title: Towards Detecting Contextual Real-Time Toxicity for In-Game Chat
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ToxBuster, a BERT-based model designed for detecting toxicity in game chat. The authors incorporate chat history and metadata, testing their model on four datasetsâ€”two they constructed (R6S and FH) and two existing ones (DOTA 2 and CC). ToxBuster outperforms three baseline models across all datasets and shows promising transferability within the gaming domain. The authors conduct thorough analyses, including class-wise evaluations and error analysis, demonstrating ToxBuster's effectiveness in flagging toxic players.

### Strengths and Weaknesses
Strengths:
- ToxBuster outperforms baseline models across four datasets.
- Strong results in transferability and adaptability.
- Comprehensive evaluations, including class-wise performance and error analysis.

Weaknesses:
- Method additions beyond BERT_Base are relatively simple and do not significantly improve performance for two datasets.
- Performance varies greatly across toxicity classes, with some classes showing F1 scores below 30.
- The novelty of the work is limited, lacking clear differentiation from existing models.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their innovations and explicitly discuss how their approach differs from existing toxicity detection methods. Additionally, the authors should provide more detailed descriptions of the chat speaker segmentation embeddings and their integration into the model. Further ablation studies could help elucidate the effects of chat history and metadata on performance, particularly for datasets where improvements are minimal. Finally, we suggest exploring the potential of large language models (LLMs) in similar contexts to assess their effectiveness in toxicity detection.