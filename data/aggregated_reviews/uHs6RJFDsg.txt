ID: uHs6RJFDsg
Title: MoVA: Adapting Mixture of Vision Experts to Multimodal Context
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 7, 5, 4, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents MoVA, a multimodal large language model (MLLM) that adaptively routes and fuses task-specific vision experts using a coarse-to-fine mechanism. The authors leverage the tool-use capabilities of LLMs to select appropriate experts and enhance visual representations through the MoV-Adapter module. Experimental results demonstrate the method's effectiveness across various benchmarks.

### Strengths and Weaknesses
Strengths:
1. The paper introduces a new perspective on enhancing multi-task reasoning in MLLMs based on the differing perceptual abilities of various encoders.
2. The writing is fluent and accessible.
3. Extensive experiments validate the proposed approach's effectiveness.

Weaknesses:
1. The number of components listed does not align with the serial numbers provided.
2. The inference process is resource-intensive, involving two rounds of LLM inference and two Base Encoders, which may hinder practical applications due to increased inference time and GPU memory usage.
3. Concerns about novelty arise, as the method appears similar to the adapter+agent approach by Wang et al. [1]. Clarification on the differences and advantages of MoVA is needed.
4. The experiments utilize different SFT data across models, raising fairness issues in comparisons.
5. The complexity of the inference structure may introduce error propagation, questioning the necessity of the two-step routing design.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the number of components in line 102 to ensure consistency. Additionally, addressing the significant inference time and GPU memory usage is crucial for practical applications. We suggest that the authors clarify the novelty of their approach compared to existing methods, particularly the adapter+agent approach. Furthermore, we recommend aligning the SFT data used across different models for fairer comparisons and considering a more efficient routing strategy to mitigate the complexity and potential error propagation in the current framework.