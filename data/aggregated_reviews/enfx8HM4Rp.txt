ID: enfx8HM4Rp
Title: Train Once and Explain Everywhere: Pre-training Interpretable Graph Neural Networks
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 8, 6, 5, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel pre-training method for interpretable graph neural networks (GNNs), addressing the challenge of generalization across diverse datasets. The authors propose a pre-training framework utilizing a labeled synthetic graph dataset, which includes ground truth explanations, enabling the model to capture common structural knowledge. The introduction of a structure pattern learning module and a hypergraph refining module enhances the model's performance. The extensive experiments demonstrate significant improvements over state-of-the-art (SOTA) methods in both node and graph classification tasks, validating the model's generalization capabilities.

### Strengths and Weaknesses
Strengths:
- The paper is the first to propose a pre-training interpretable GNN model, which is both novel and practically significant, achieving substantial performance improvements.
- The integration of a structure pattern learning module and a hypergraph refining module allows for a comprehensive capture of structural patterns and edge interactions.
- Extensive experiments on various datasets convincingly demonstrate the model's performance, with publicly available code.
- The manuscript is well-written, logically organized, and easy to follow.

Weaknesses:
- The construction of synthetic graphs with ground truth labels is not adequately explained, raising concerns about its impact on model performance.
- The necessity of Theorem 1 and 2 is unclear; the authors should clarify their importance in preserving graph pattern information for interpretable GNNs.
- The implementation details of comparing pi-GNN with pi-GNN-DFT, which fine-tunes directly on downstream datasets, are insufficiently explained.
- The dependency between test tasks and the synthetic pre-training dataset is not well investigated, which is critical for real-world applications.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the synthetic graph dataset construction process, providing more details on how to create effective datasets. Additionally, the authors should clarify the rationale behind Theorem 1 and 2, emphasizing their significance for interpretable GNNs. We suggest including a more detailed explanation of the implementation of pi-GNN-DFT. Furthermore, we encourage the authors to evaluate the impact of different pre-training datasets on various test tasks, ensuring that some tasks include motifs not fully covered in the pre-training phase. Lastly, incorporating graph semi-supervised learning methods as baselines would enhance the comparative analysis of the proposed model.