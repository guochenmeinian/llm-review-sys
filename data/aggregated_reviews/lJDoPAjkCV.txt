ID: lJDoPAjkCV
Title: Gold-YOLO: Efficient Object Detector via Gather-and-Distribute Mechanism
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 6, 6, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Gather-and-Distribute (GD) mechanism for efficient information exchange in YOLOs, enhancing multi-level feature fusion and integrating global information into higher levels. The GD-YOLO architectures demonstrate competitive results against existing YOLO models, particularly with a pre-training method using MAE on ImageNet 1K, which improves convergence speed and accuracy. The GD-YOLO-N variant achieves a notable 39.9% Average Precision on the COCO val2017 dataset with 1030 FPS on a T4 GPU, surpassing YOLOv6-3.0-N.

### Strengths and Weaknesses
Strengths:
- The proposed GD mechanism effectively replaces the traditional FPN structure, improving information fusion without significantly increasing latency.
- The paper is well-organized and presents a comprehensive comparison with existing YOLO models.
- The ablation studies validate the effectiveness of the proposed module.

Weaknesses:
- The motivation for the GD mechanism lacks clarity, particularly regarding its advantages over traditional FPN.
- The trade-off between accuracy and latency is similar to that of YOLOv8, raising questions about the fairness of comparisons with YOLOv6.
- The structural design is confusing, especially regarding where to inject information, and the novelty of the GD mechanism is limited compared to existing technologies.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation for the GD mechanism and explicitly outline its advantages over traditional FPN. Additionally, a more comprehensive comparison with YOLOv8 would provide a fairer assessment of latency and accuracy trade-offs. The authors should also clarify the rationale behind their structural design choices and consider discussing related works like Topformer. Furthermore, restructuring the related work section to better represent multi-scale features and enhancing the experimental setup to include more datasets would strengthen the paper's contributions. Lastly, we suggest removing the section on "Masked image modeling pre-training" to maintain focus on multi-scale features.