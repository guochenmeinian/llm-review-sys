ID: b6e1wV03hy
Title: Retrieval-Augmented Few-shot Text Classification
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on retrieval-augmented few-shot classification, addressing data scarcity and the vanishing gradient problem. The authors propose an Expectation Maximization-based Loss (EM-L) algorithm that retrieves optimal training data and updates parameters by maximizing log-likelihood, alongside a Ranking-based Loss (R-L) that minimizes the discrepancy between the retriever and classifier. Comprehensive empirical studies validate the effectiveness of these techniques, particularly in data-scarce environments.

### Strengths and Weaknesses
Strengths:
- The paper tackles a significant problem in NLP, making it relevant for researchers and practitioners.
- The proposed algorithms effectively address limitations of existing methods.
- The writing is clear, and the experiments are thorough, yielding promising results.

Weaknesses:
- Some aspects remain unclear, such as the rationale for not combining EM-L and R-L.
- Formula notations are inconsistent and could be improved for clarity.
- The training time evaluation is insufficient, and implementation details for the functions f_retr and f_cls are lacking.

### Suggestions for Improvement
We recommend that the authors improve the clarity of formula notations, ensuring all symbols are explained upon first use. Additionally, we suggest providing comprehensive training time results rather than relegating them to the Limitations section. The authors should also clarify the relationship between the functions f_retr and f_cls, and consider including a framework figure to enhance understanding. Lastly, addressing the organization of the article and ensuring all references are cited appropriately would strengthen the paper.