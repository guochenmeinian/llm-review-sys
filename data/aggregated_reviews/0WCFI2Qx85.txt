ID: 0WCFI2Qx85
Title: ScaleKD: Strong Vision Transformers Could Be Excellent Teachers
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 6, 6, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel knowledge distillation method called ScaleKD, which utilizes well-pretrained vision transformer (ViT) models as teachers for various student model architectures. The authors propose a cross-attention projector to align student features with the teacher's, complemented by a dual-view feature mimicking module and a teacher parameter perception module to enhance knowledge transfer. Extensive experiments validate the effectiveness of ScaleKD across different tasks and model types.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and structured, making the proposed method easy to follow.
- The novelty of using ViTs as teachers for CNNs is significant, and the experimental results demonstrate improvements over previous knowledge distillation methods.
- The extensive experiments provide solid validation for the proposed methodology.

Weaknesses:
- The motivation for using a ViT teacher for training CNN students requires further justification, particularly in light of existing research that questions the efficacy of stronger teacher models.
- The complexity of the proposed method, consisting of three components, may hinder clarity.
- The related work section lacks a thorough discussion comparing ScaleKD's components with existing techniques, which is essential for establishing originality.
- The connection between the dual-view feature mimicking and teacher parameter perception modules is unclear, particularly regarding their effectiveness in addressing model scale and knowledge density differences.

### Suggestions for Improvement
We recommend that the authors improve the motivation section by providing a clearer justification for the necessity of adapting a ViT teacher for CNN students, including comparisons with CNN teachers. Additionally, we suggest enhancing the related work section to better contextualize ScaleKD within existing literature. The authors should clarify the connections between the dual-view feature mimicking and teacher parameter perception modules, particularly how they address the challenges of model scale and knowledge density. Finally, we encourage the authors to elaborate on the effects of scaling teacher models and consider including more diverse CNN backbones in their experiments to support their claims.