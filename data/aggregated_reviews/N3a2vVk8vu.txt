ID: N3a2vVk8vu
Title: Hierarchical Prompting Assists Large Language Model on Web Navigation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach called Actor-Summarizer-Hierarchical (ASH) prompt for Web Navigation, emphasizing the importance of filtering irrelevant information from web observations before inputting them into Language Models (LLMs). The ASH prompt comprises two components: the SUMMARIZER prompt, which eliminates irrelevant details, and the ACTOR prompt, which predicts the next step. ASH achieves a task success rate surpassing the previous state-of-the-art prompting mechanism by 6.2%. The manuscript also proposes the Hierarchical Hint Assistant for optimizing LLMs in web navigation tasks, verified through experiments on the Webshop dataset.

### Strengths and Weaknesses
Strengths:  
- The SUMMARIZER prompt effectively filters irrelevant information, demonstrating promising results in web navigation.  
- The proposed methods are clear and structured, contributing to the optimization of LLMs in complex interaction scenarios.  

Weaknesses:  
- The paper lacks specific details on how the SUMMARIZER effectively eliminates irrelevant information and does not define what qualifies as irrelevant.  
- There is insufficient comparison with baseline models like REACT, limiting the understanding of ASH's advantages.  
- The evaluation is not comprehensive, lacking transparency regarding the experimental setup and relying on a single dataset.  
- The experiments are limited, with no verification on current representative LLMs or ablation studies.

### Suggestions for Improvement
We recommend that the authors improve the clarity of how the SUMMARIZER works and define the criteria for irrelevant information. Additionally, providing comprehensive details about the baseline models for comparison, such as REACT, would enhance the paper's rigor. We suggest expanding the evaluation to include multiple datasets and varying the number of In-Context Examples. Testing the proposed method on the text-davinci-003-based model and modifying prompts in baseline methods to include an equivalent to the summarizer would also be beneficial.