ID: SthlUe5xDP
Title: Topological Parallax: A Geometric Specification for Deep Perception Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 7, 5, 8, 7, 7, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 1, 3, 2, 4, 2, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework for analyzing the validity of deep classification models by comparing their multi-scale geometric features with those of the training dataset using topological data analysis (TDA). The authors propose a method based on persistence diagrams to detect and characterize topological features, addressing the challenge of conducting this analysis in the implicit space of deep models. They introduce distance estimate algorithms for comparing the implicit space with ambient Euclidean distances to assess geometric feature matching. The paper demonstrates the framework's application on a single dataset and discusses its potential as an objective function for training more accurate networks. Additionally, the authors utilize the Rips complex constructed from both training and test sets, although the effectiveness of this method in identifying false negatives/positives outside the convex hull remains uncertain. The inclusion of the teapot experiment is noted as a step toward relevance for the image domain, but further experiments are needed to assess the method's effectiveness compared to existing measures of model generalization.

### Strengths and Weaknesses
Strengths:
- The paper poses a significant question regarding the fidelity of deep perception models to dataset characteristics and proposes a theoretical framework for geometric matching.
- It provides a novel perspective by utilizing TDA to express geometric relationships between models and datasets, contributing valuable insights into overfitting and generalization in neural networks.
- The framework includes extensive derivations and proofs, along with a practical computational method validated on concrete examples.
- The idea of applying TDA to model evaluation is innovative and could lead to future advancements.
- The addition of the teapot experiment aligns better with the interests of the target audience.

Weaknesses:
- The paper is theoretical and lacks clarity, making it difficult to read and understand. Key concepts and definitions are not adequately motivated or interpreted, leading to confusion.
- The empirical evaluation is limited to one dataset, and the authors do not explore the applicability of their method to more intuitive datasets or generative models.
- There are numerous undefined terms and symbols, which hinder comprehension, particularly for readers unfamiliar with TDA.
- The paper lacks comparisons to existing methods, making it difficult to evaluate the proposed method's effectiveness.
- There is a need for clearer explanations and definitions of notation to enhance readability.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by providing a notation table and defining crucial concepts such as \( \rho_K(Y) \) and the bi-filtered persistence module explicitly. Additionally, we suggest including more figures and tables to summarize notations and illustrate ideas, particularly for complex sections like perturbation lemmas and local simplicial matching. 

To enhance the empirical evaluation, we encourage the authors to test their framework on more intuitive datasets, such as MNIST or CIFAR, and to compare multiple models, including decision trees and various neural network architectures. Furthermore, we recommend discussing how the proposed framework applies to generative models, as well as addressing the computational complexity of the method. 

We also suggest that the authors include more diverse experiments, such as a small 2D circle at random locations, to better address extrapolation outside the convex hull and to demonstrate the method's ability to distinguish between well-trained and overfitted models. Finally, positioning Section 6 in context with examples from Section 8 could help clarify the theoretical framework's relevance.