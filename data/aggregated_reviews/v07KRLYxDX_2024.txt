ID: v07KRLYxDX
Title: Achieving Domain-Independent Certified Robustness via Knowledge Continuity
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 7, 7, 5, 7, -1, -1, -1
Original Confidences: 2, 3, 3, 2, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel definition of "continuity": knowledge continuity, which measures the continuity of a model concerning its hidden representations rather than its inputs. The authors propose that knowledge continuity can certify adversarial robustness across various domain modalities and provide theorems supporting this new definition. They demonstrate that knowledge continuity can imply Lipschitz continuity and does not compromise the universal approximation property of neural networks. The authors also illustrate applications of knowledge continuity in enhancing robustness.

### Strengths and Weaknesses
Strengths:
- The novel definition of continuity is applicable in discrete domains, such as natural language.
- The authors provide solid and interesting theoretical support for knowledge continuity.
- Practical applications are included to demonstrate the effectiveness of the new definition.

Weaknesses:
- There are several typos, including a suggestion to delete "with respect to a function $f$" in Line 193 and to correct $P_X[A]$ to $P_{X\times Y}[A]$ in Line 218.
- The implementation of knowledge continuity lacks clarity, particularly regarding the accuracy of the approximation in Algorithm 1 and its effect on training speed.
- The paper does not provide a certification algorithm for computing certified accuracy with knowledge continuity, which is necessary given the non-deterministic nature of the framework.
- The experiments are limited to discrete text domains, and there is a lack of analysis on larger models and their performance under out-of-distribution conditions.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the implementation details for knowledge continuity, particularly regarding Algorithm 1 and its approximation accuracy. Additionally, the authors should conduct experiments across various modalities and larger models to validate the generalizability of their approach. It would also be beneficial to include a certification algorithm to compute certified accuracy with knowledge continuity. Finally, we suggest reorganizing the paper to present empirical results more clearly, as many details are currently deferred to the appendix.