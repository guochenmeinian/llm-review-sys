ID: ai6kjD6cyX
Title: Event Causality Extraction via Implicit Cause-Effect Interactions
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper studies Event Causality Extraction (ECE) by formulating it in a generative paradigm. The authors aim to enhance model performance through two strategies: 1) improving the interaction between cause-effect events, and 2) leveraging semantic information from event types or arguments. The proposed methods include knowledge distillation to transfer information from teacher models to a student model, and Optimal Transport to facilitate knowledge transfer. The paper presents a novel ICE framework that models implicit cause-effect interactions using privileged information and teacher-student learning, supported by extensive experiments demonstrating performance advantages.

### Strengths and Weaknesses
Strengths:
- The problem is well-motivated, addressing a significant NLP task.
- The proposed ICE framework is novel and effectively captures intra- and inter-event interactions.
- Comprehensive experiments show clear improvements, particularly in low-resource scenarios, with well-explained methodology.
- The writing is clear and the experimental setup is strong.

Weaknesses:
- The term "Implicit" in the title is not adequately defined, leading to confusion.
- The effect of different hyper-parameters is under-explored, and the performance gain may stem from careful tuning of BART.
- The paper lacks detailed descriptions of the template-guided extraction process and how templates are obtained, making the method hard to understand.
- The results should reflect score variance from multiple experiments with different seeds.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the term "Implicit" in the title and provide a clear definition within the paper. Additionally, please explain the simultaneous use of MSE and KL in the distillation process. It would be beneficial to include original model performances of the teacher and student models for comparison. We suggest exploring the impact of hyper-parameters more thoroughly and ensuring that the results reflect variance from multiple experimental seeds. Lastly, we encourage the authors to provide detailed examples of the data flow and a comprehensive description of the template extraction process to enhance understanding.