ID: YsYKv95jy9
Title: Deep Fractional Fourier Transform
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 8, 7, 8, 5, 8, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 5, 5, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Fractional Fourier Transform (FRFT) as a novel approach to provide unified spatial-frequency perspectives for deep learning applications. The authors propose a basic operator, Multi-order Fractional Fourier Convolution (MFRFC), and evaluate its effectiveness across various computer vision tasks, including object detection, image classification, and low-level image processing tasks such as denoising and dehazing.

### Strengths and Weaknesses
Strengths:
1. The paper demonstrates high novelty by introducing FRFT into deep learning, addressing a less explored area.
2. It achieves a fast implementation of FRFT, which is crucial for its integration into deep learning pipelines.
3. The effectiveness of the MFRFC operator is validated through comprehensive experiments across multiple tasks.
4. The writing is clear and the experimental settings are well-defined.

Weaknesses:
1. The related work section lacks comprehensiveness, failing to discuss recent applications of FRFT in image super-resolution.
2. The design rationale for the MFRFC operator is insufficiently explained, particularly regarding the optimality of using three paths and the potential for more.
3. The performance of the MFRFC operator with only a fractional branch compared to other configurations is not evaluated.
4. The paper does not adequately compare the proposed methods with recent state-of-the-art algorithms, particularly in denoising tasks.

### Suggestions for Improvement
We recommend that the authors improve the related work section to include a broader discussion of FRFT applications, particularly in image super-resolution. Additionally, the authors should provide a clearer explanation of the MFRFC operator's design and its performance implications with varying path configurations. It would be beneficial to include comparisons with state-of-the-art methods in the experimental results, especially for denoising tasks. Lastly, addressing the computational cost and speed comparisons between the original and fast implementations of FRFT would enhance the paper's contributions.