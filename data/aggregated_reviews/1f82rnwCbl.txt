ID: 1f82rnwCbl
Title: Learning to Discuss Strategically: A Case Study on One Night Ultimate Werewolf
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 7, 8, 6, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into the game "One Night Ultimate Werewolf" (ONUW) to enhance the discussion capabilities of language agents using reinforcement learning (RL). The authors analyze Perfect Bayesian Equilibria in both discussion and non-discussion scenarios, demonstrating the significance of discussion tactics in influencing players' beliefs and utilities. They propose a framework that employs RL to instruct an LLM agent, showing its ability to recognize and approximate equilibria across various ONUW settings.

### Strengths and Weaknesses
Strengths:
1. The paper introduces ONUW as a benchmark for evaluating LLM agents' deduction abilities and provides a clear problem formulation.
2. The authors conduct thorough theoretical analyses, proving the importance of discussion in influencing beliefs and establishing a solid foundation for their proposed method.
3. The integration of RL policy into LLM agents for strategic communication is innovative, with empirical results demonstrating its efficacy.
4. The theoretical analysis and experimental design are robust, making complex content accessible to readers.

Weaknesses:
1. The paper is limited to the ONUW game, and the transferability of the proposed algorithms to other games or environments is not demonstrated.
2. There are no examples of discussions between LLM players, and the absence of provided code limits assessment of the generated discussions' quality.
3. The model's reliance on predefined categories (Honest/Deceptive and Evidence/Accusation/Defense) constrains its ability to discover alternative strategies.
4. The experiments focus solely on LLMs, lacking human evaluations that could capture the game's social dynamics.

### Suggestions for Improvement
We recommend that the authors improve the transferability of their algorithms by demonstrating their applicability to other games or environments. Additionally, including examples of discussions between LLM players and providing the code would enhance the assessment of generated discussions. To address the limitations of predefined categories, we suggest exploring methods for dynamic tactic generation based on real-time gameplay feedback. Finally, incorporating human evaluations would provide insights into the AI's ability to mimic human-like strategic discussions and enhance the overall robustness of the findings.