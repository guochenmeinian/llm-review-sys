ID: 9EYS2EEqFq
Title: CAR: Conceptualization-Augmented Reasoner for Zero-Shot Commonsense Question Answering
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method for constructing synthetic data aimed at zero-shot commonsense question answering (QA) by leveraging commonsense knowledge bases (CSKB). The authors propose a strategy that involves conceptualizing knowledge triples to enhance the generation of synthetic QA pairs, thereby reducing false negatives. Their experiments demonstrate that training models like RoBERTa and DeBERTa on the newly generated synthetic data leads to significant performance improvements across five commonsense QA benchmarks.

### Strengths and Weaknesses
Strengths:  
1. The proposed method is intuitive and effectively addresses the challenge of false negatives in synthetic data by abstracting higher-level concepts from knowledge triples.  
2. The results indicate substantial performance gains when using the new synthetic data for training, showcasing the method's effectiveness across multiple tasks.  
3. The paper is well-organized and presents extensive experimental results that support its claims.

Weaknesses:  
1. The generalizability of the method to other knowledge graphs remains uncertain, particularly since the conceptualization relies on the AbstractATOMIC dataset.  
2. Some experimental details lack clarity, such as the number of annotators in human evaluations and the potential unfairness in diversity metrics due to random sampling.  
3. The novelty of the method is questioned, as it heavily relies on prior work for conceptualization and synthesizing QA methods, which may dilute its contribution.

### Suggestions for Improvement
We recommend that the authors improve the clarity of experimental details, particularly regarding the human evaluation process and the sampling methodology used for diversity metrics. Additionally, exploring alternatives to the AbstractATOMIC dataset for conceptualization could enhance the generalizability of the method. It would also be beneficial to define key terms such as event, instance, and concept more clearly within the paper. Lastly, we suggest investigating the impact of training set size on model performance by downsampling the augmented data to match the original ATOMIC size.