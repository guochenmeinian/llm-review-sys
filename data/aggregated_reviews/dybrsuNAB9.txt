ID: dybrsuNAB9
Title: GMSF: Global Matching Scene Flow
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 7, 5, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents GMSF, a transformer-based method for scene flow estimation from point clouds, utilizing a hybrid local-global-cross transformer architecture. The authors propose a single-scale one-shot global matching approach, achieving state-of-the-art performance on multiple benchmarks, including FlyingThings3D and KITTI Scene Flow datasets. Extensive experiments demonstrate the effectiveness of the proposed method, which leverages cross- and self-attention mechanisms for dense feature matching.

### Strengths and Weaknesses
Strengths:
1. The proposed GMSF achieves state-of-the-art results on multiple scene flow estimation benchmarks.
2. The architecture is straightforward and effectively produces discriminative per-point features.
3. The clarity of the narrative and the description of the architecture and attention modules are commendable.

Weaknesses:
1. Some related studies have been neglected; comparisons with previous works such as [cite1] and discussions on [cite2-3] are necessary.
2. The paper lacks sufficient ablation studies, particularly regarding the KNN parameters and the impact of varying the λ parameter.
3. The motivation behind certain equations, such as Eq. (11), is unclear and requires further clarification.
4. The computational cost, including FLOPs, GPU memory, and run-time comparisons with recent methods, is not adequately addressed.
5. The tokenization process appears overly complex, and experiments should be conducted to evaluate GMSF with only PT as the tokenization method.
6. The paper does not sufficiently discuss the novelty of the approach in the context of existing literature on attention mechanisms.

### Suggestions for Improvement
We recommend that the authors improve the literature review by including and discussing related studies such as [cite1], [cite2], and [cite3]. Additionally, please clarify the inconsistencies in the compared methods in Tables 2 and 3. We suggest conducting a more comprehensive ablation study, particularly focusing on the KNN parameters and the λ parameter's impact on performance. Furthermore, we advise including a detailed analysis of the computational costs associated with GMSF, including FLOPs and memory usage, to better contextualize its efficiency compared to existing methods. Lastly, we encourage the authors to simplify the tokenization process and report results using only PT, as this may enhance the model's efficiency.