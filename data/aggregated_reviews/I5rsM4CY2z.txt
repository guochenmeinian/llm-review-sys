ID: I5rsM4CY2z
Title: Deductive Verification of Chain-of-Thought Reasoning
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 6, 5, 3, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Natural Programs, a novel framework designed to enhance the trustworthiness of reasoning in Language Models (LLMs) by breaking down reasoning processes into explicit steps. Each step lists premises that support conclusions, allowing for local verification of reasoning chains. The authors benchmark their approach against existing methods, demonstrating improvements in accuracy across several datasets, particularly in mathematical reasoning tasks. Additionally, the paper includes a comparative analysis of Natural Program and NLProofS, highlighting their differing approaches to proof search and reasoning. The authors propose that Natural Program's flexibility in extracting initial premises through in-context learning enhances its adaptability to various natural language reasoning tasks and allows for the integration of commonsense knowledge in reasoning steps, which is not limited to explicitly listed premises. They clarify the relationship between their verification approach and the accuracy of reasoning chains, explaining that while verification improves reasoning reliability, it may inadvertently reduce final answer accuracy due to the removal of correct-answer chains.

### Strengths and Weaknesses
Strengths:
- The framework effectively incorporates a deductive reasoning approach, enhancing explainability in LLMs.
- Natural Program's use of in-context learning allows for greater flexibility in reasoning tasks.
- The paper is well-structured, with clear examples illustrating the main concepts.
- The approach effectively identifies and explains invalid reasoning steps, enhancing understanding of reasoning errors.
- Compatibility with abstract reasoning tasks and the ability to incorporate commonsense knowledge are notable advantages.
- The observation that using minimal premises aids in self-verification is insightful and contributes to the overall motivation of the work.

Weaknesses:
- The novelty of Natural Programs is questioned due to similarities with prior work, particularly the NLProofS framework.
- The empirical results could be strengthened with additional experiments and comparisons to a broader range of benchmarks.
- The method's marginal performance gains raise concerns about its practical utility, particularly regarding verification accuracy and the cost of API calls.
- The verification process may filter out a significant number of correct reasoning chains, impacting final answer accuracy.
- The complexity of intertwining reasoning-step dependencies presents challenges in extracting premises for individual reasoning steps.

### Suggestions for Improvement
We recommend that the authors improve the empirical validation by including more diverse benchmarks and conducting additional experiments, particularly with advanced models like GPT-4. It would also be beneficial to clarify the differences between Natural Programs and related works, such as NLProofS, to better highlight the unique contributions of this paper. Additionally, we suggest expanding the qualitative analysis of the verification process to elucidate the design choices made and their impact on performance. We encourage the authors to improve clarity regarding the impact of their verification approach on final answer accuracy, particularly in relation to the GSM8K dataset. Furthermore, we suggest exploring methods to enhance the filtering of incorrect reasoning chains without disproportionately affecting correct-answer chains. Finally, investigating the potential integration of techniques from ROSCOE and ReCEval to bolster the accuracy of their approach would be beneficial. Addressing the cost implications of the proposed method in a dedicated limitations section would enhance the paper's comprehensiveness.