ID: yg4Tt2QeU7
Title: Bag of Tricks: Benchmarking of Jailbreak Attacks on LLMs
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 6, 6, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a comprehensive study on jailbreak attacks on Large Language Models (LLMs), addressing the lack of adequate examination of multiple factors influencing these attacks. The authors conduct an extensive ablation study, investigating the impact of various factors such as model size, fine-tuning, safety prompts, and attacker capabilities on the success rate of jailbreak attacks. The experiments encompass seven representative jailbreak attacks against six defense methods across two widely used datasets, totaling approximately 320 experiments. The findings provide valuable insights into LLM vulnerabilities and the efficacy of current defense strategies.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and organized, with clear presentation of results supported by extensive experimentation.
- The benchmark includes a substantial number of attack and defense methods, enhancing the evaluation of factors affecting jailbreak attacks.
- The provided code facilitates reproducibility of experimental results and is well documented.

Weaknesses:
- The experiments are solely conducted on Llama-based models, raising concerns about the generalizability of the findings to other LLM architectures.
- The code lacks important defense methods, as it only includes SmoothLLM despite claims of verifying six mainstream techniques, necessitating clarification on this discrepancy.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their findings by including experiments on non-Llama LLMs. Additionally, the authors need to clarify the ratio of training to test data in their code to ensure the accuracy of experimental results. It is essential to include the missing defense methods in the code to enhance its reliability and completeness. Furthermore, to better fit the paper within the benchmark track, the authors should provide a way for other researchers to run the benchmark code on their models and defenses. Finally, we suggest adding more examples to support the claim that fine-tuning makes jailbreaking easier, as the current reliance on the Vicuna example is insufficient.