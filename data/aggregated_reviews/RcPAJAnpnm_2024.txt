ID: RcPAJAnpnm
Title: Incremental Learning of Retrievable Skills For Efficient Continual Task Adaptation
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 5, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents IsCiL, a method for continual imitation learning that enables an agent to adapt to new tasks through imitation. IsCiL employs prototype-based skill incremental learning, gradually building a repository of skill prototypes for task adaptation. Evaluated in environments like Franka-Kitchen and Meta-World, IsCiL demonstrates superior performance compared to previous continual imitation learning methods. The method also addresses knowledge sharing limitations and incorporates task unlearning for privacy concerns.

### Strengths and Weaknesses
Strengths:
- The paper tackles the significant problem of continual imitation learning effectively.
- It introduces a novel prototype-based skill retrieval mechanism that shows improvements in task adaptation and unlearning capabilities.
- The experimental results are well-presented and demonstrate the method's efficacy across various benchmarks.

Weaknesses:
- The contribution appears incremental, as concepts like prototype-based skill learning and parameter-efficient adaptation have been previously explored.
- Key terms such as skill prototype and skill adaptor are not adequately defined, leading to confusion about their generation and usage.
- The assumption of access to subgoals raises concerns about the practicality of the method, as these subgoals heavily influence skill prototype generation.
- The retrieval and adaptation processes may increase inference time and resource demands, which are not thoroughly analyzed.

### Suggestions for Improvement
We recommend that the authors improve the clarity of key concepts such as skill prototypes and adaptors, including how they are generated and utilized. Additionally, addressing the assumption of subgoal access and its implications on practical applications would strengthen the paper. We suggest including a detailed analysis of the computational overheads and scalability issues related to maintaining a prototype-based memory. Furthermore, we encourage the authors to evaluate IsCiL on more challenging benchmarks, such as LIBERO, and to provide training curves to illustrate performance intuitively. Lastly, clarifying the experimental settings and addressing the potential inefficiencies in skill updates would enhance the overall understanding of the method.