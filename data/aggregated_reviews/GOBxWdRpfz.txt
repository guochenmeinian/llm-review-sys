ID: GOBxWdRpfz
Title: Re-ViLM: Retrieval-Augmented Visual Language Model for Zero and Few-Shot Image Captioning
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Retrieval-augmented Visual Language Model called "Re-ViLM," designed to enhance image captioning performance by leveraging external databases of image-text pairs. The authors propose improvements such as storing specific knowledge in an external database and interleaving image and text data. While the model shows better results across various settings, including zero-shot and few-shot learning, the benefits of retrieval integration are not convincingly demonstrated.

### Strengths and Weaknesses
Strengths:
- The use of existing public datasets for creating a pre-training and evaluation dataset facilitates contextual learning.
- Re-ViLM outperforms baselines on multiple downstream tasks, supported by ablation studies.

Weaknesses:
- The novelty of the proposed method is limited, primarily following existing structures with minor enhancements.
- The paper lacks a discussion on limitations and does not adequately demonstrate the effectiveness of retrieval integration.
- Inference time and memory comparisons are absent, and the benefit of retrieval is not clearly established.

### Suggestions for Improvement
We recommend that the authors improve the demonstration of the benefits of incorporating retrieval into captioning, particularly by providing a baseline that evaluates retrieved captions directly. Additionally, including more examples of retrieved captions alongside generated results would enhance clarity. Reporting the inference time and memory requirements for the retrieval process is essential, as is the performance of the method without retrieval. Finally, addressing the potential overlap between the retrieval database and test set would strengthen the validity of the 0-shot setting.