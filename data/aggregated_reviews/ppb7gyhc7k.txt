ID: ppb7gyhc7k
Title: Learning Retrieval Augmentation for Personalized Dialogue Generation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method called Learning Retrieval Augmentation for Personalized Dialogue Generation (LAPDOG) aimed at enhancing personalized dialogue generation by leveraging external story documents. The authors propose a model that integrates a retriever and generator, trained jointly to improve the generation of persona-specific dialogues without relying on annotated datasets. The approach includes a retrieval candidate augmentation during training to ensure diversity and addresses challenges in personalized dialogue generation.

### Strengths and Weaknesses
Strengths:  
1. The authors provide a reasonable analysis of the challenges in personalized dialogue generation and effectively address these through their well-designed method.  
2. The paper is clearly structured and well-written, facilitating easy comprehension of its contributions.  
3. The commitment to open-sourcing the code and pre-trained model is commendable.  
4. The introduction of a differentiable probability distribution technique is a notable contribution that addresses the non-differentiable metric issue.

Weaknesses:  
1. The experiments lack competitiveness due to the use of insufficiently robust baselines, which diminishes the credibility of comparative results.  
2. The model architecture, particularly the ROC story selection, requires more detailed discussion.  
3. The related work section does not adequately address recent developments in large language models (LLMs).  
4. Minor formatting issues, including punctuation and bold font inconsistencies, need correction.

### Suggestions for Improvement
We recommend that the authors improve the experimental design by incorporating more competitive baselines, including traditional knowledge dialogue methods, to strengthen the comparative analysis. Additionally, we suggest providing a more detailed discussion of the model architecture, particularly the ROC story selection process. The related work section should be expanded to include relevant literature on LLMs. Lastly, we advise conducting a thorough review to rectify the identified formatting and punctuation issues.