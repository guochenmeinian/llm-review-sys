ID: R9gR9MPuD5
Title: InterpBench: Semi-Synthetic Transformers for Evaluating Mechanistic Interpretability Techniques
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 5, 5, 7, 7, -1, -1, -1
Original Confidences: 3, 2, 4, 3, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents InterpBench, a benchmark comprising 17 small transformer models trained on algorithmic tasks to realistically mimic ground-truth circuits. The authors introduce Strict Interchange Intervention Training (SIIT), an extended causal intervention training method that incorporates a loss term to minimize the impact of irrelevant nodes on downstream task performance. The benchmark aims to facilitate the comparison and advancement of causal circuit discovery techniques within the Mechanistic Interpretability field.

### Strengths and Weaknesses
Strengths:
- The work provides a novel benchmark that enhances the objectivity of evaluating mechanistic interpretability methods.
- SIIT effectively generates transformers that implement known circuits, improving realism compared to previous benchmarks like Tracr.
- The paper is well-written and accessible for informed readers.

Weaknesses:
- The models are small and limited to one algorithmic circuit each, which may not reflect the complexity of larger, real-world models.
- The experimental results lack thorough explanations, particularly regarding the evaluation of SIIT and its comparison with other methods.
- Certain formatting and clarity issues, such as inconsistencies in task counts and minor typos, detract from the overall presentation.

### Suggestions for Improvement
We recommend that the authors improve the clarity of experimental details, specifically regarding the sensitivity of SIIT and IIT hyperparameters, and provide comprehensive documentation on the selected loss weights and their significance. Additionally, the authors should clarify the source and details of the synthetic tasks generated by GPT-4, including the RASP programs used. Expanding the benchmark to include more circuits and addressing other aspects of mechanistic interpretability beyond attention routes would enhance its applicability and relevance.