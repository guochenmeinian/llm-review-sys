ID: 41vXNjZbIn
Title: Improving Input-label Mapping with Demonstration Replay for In-context Learning
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel in-context learning (ICL) method called Repeated Demonstration with Sliding Causal Attention (RdSca), aimed at overcoming the structural limitations of causal language models (CLMs). The authors propose duplicating later demonstrations and applying sliding window attention to enhance the contextualization of demonstrations. The effectiveness of this approach is validated through experiments on traditional text classification datasets, demonstrating improvements in input-label mapping ability across various model scales.

### Strengths and Weaknesses
Strengths:
1. The motivation to address the limitations of CLMs in ICL is clear and thought-provoking.
2. The proposed techniques are simple, intuitive, and easy to implement.
3. The experiments provide sufficient support for the claims made, showing significant improvements on benchmark datasets.

Weaknesses:
1. The use of repeated demonstrations increases sequence length, which raises efficiency concerns.
2. The 4-shots RdSca ICL does not outperform regular 7-shots, suggesting that traditional ICL methods may still be preferable within the same computational budget.
3. The selected benchmarks are considered outdated, necessitating validation on more contemporary datasets like MMLU/BigBench.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the efficiency of the RdSca ICL method, particularly through a detailed analysis of its memory and time costs compared to regular ICL methods. Additionally, we suggest validating the proposed approach on more modern benchmarks such as MMLU/BigBench to enhance the paper's credibility. Providing more detailed experimental specifics in the appendix, including standard deviations, would also be beneficial. Lastly, reducing redundancy in the content and enhancing the analytical depth of the experimental results would significantly improve the paper's overall quality.