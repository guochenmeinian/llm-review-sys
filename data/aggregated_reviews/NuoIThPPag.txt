ID: NuoIThPPag
Title: Label-Only Model Inversion Attacks via Knowledge Transfer
Conference: NeurIPS
Year: 2023
Number of Reviews: 18
Original Ratings: 6, 5, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel label-only model inversion attack (MIA) that addresses a challenging scenario where the adversary only has access to hard label predictions of the target model. The authors utilize a surrogate model trained with a modified ACGAN to generate characteristic samples from the target model's training data. They demonstrate that the surrogate model can replicate the target model's scoring behavior for both easy and hard-to-classify samples. Extensive user studies and additional experiments show that the proposed method outperforms the state-of-the-art method, BREP-MI, by over 15% across various benchmarks. The evaluation includes multiple metrics, such as user preference, structural similarity (SSIM), KNN distance, and feature distance, consistently highlighting the superior performance of the proposed method.

### Strengths and Weaknesses
Strengths:
- The paper introduces a challenging label-only MIA scenario, representing a significant advancement in model inversion techniques.
- The proposed method shows substantial improvements in label-only MI attack performance compared to BREP-MI, with comprehensive empirical validation through 50 experiments across four datasets.
- The analysis comparing the training behaviors of the target and surrogate models is insightful, and the inclusion of user studies indicates a strong preference for the authors' approach.

Weaknesses:
- The evaluation relies on outdated models and small image sizes (64x64), limiting the generalizability of the findings; higher resolution images (e.g., 256x256) and more recent architectures should be considered.
- The paper lacks a detailed comparison with GAMIN and does not sufficiently clarify the limitations of the attack.
- Some experimental details are not self-contained, requiring readers to refer to external sources for context, and the selection process for qualitative samples is unclear.
- The focus on attack accuracy and feature distance may overlook other relevant metrics, such as transferable adversarial examples or CLIP zero-shot predictions, which could provide a more comprehensive evaluation.
- The overall writing quality needs improvement for better readability and clarity.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by incorporating larger models and higher resolution images to enhance the robustness of their findings. Additionally, we suggest that the authors include a detailed comparison with GAMIN, particularly focusing on the differences in training objectives and the limitations of label-only attacks. Exploring alternative metrics beyond attack accuracy and feature distance, such as CLIP zero-shot predictions or face verification distances, would enrich the analysis. Clarifying the selection criteria for qualitative samples and including unfiltered results in an appendix would strengthen the evaluation. Lastly, enhancing the writing quality for fluency and coherence is essential for better communication of the concepts presented.