ID: vU1SiBb57j
Title: Learning Multimodal Behaviors from Scratch with Diffusion Policy Gradient
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 6, 7, 5, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DDiffPG, a method for online reinforcement learning that incorporates multi-modal behavior discovery. DDiffPG consists of a novel policy improvement technique aimed at stabilizing the diffusion policy by cloning target actions, and a mode discovery mechanism that trains mode-specific and intrinsic Q functions. The authors demonstrate through experiments that DDiffPG achieves performance comparable to baseline methods while effectively producing multi-modal behaviors, thus mitigating mode collapse.

### Strengths and Weaknesses
Strengths:
- The introduction of a diffusion policy for multi-modal behaviors in online RL is innovative and addresses a previously unexplored area.
- The method is well-motivated, and the visualizations of multimodal behaviors enhance understanding and illustrate practical utility.
- The paper demonstrates that DDiffPG outperforms several classic baselines, showcasing the potential of diffusion policy in online RL.

Weaknesses:
- The presentation is difficult to follow, and improvements are needed.
- The theoretical derivation of the policy improvement objective is absent, leaving unclear how it maximizes expected return.
- Some claims, such as DDiffPG's ability to overcome local minimum issues, lack sufficient empirical support and may be overstated.
- The proposed diffusion training objective appears handcrafted and may require extensive tuning, limiting broader applicability.
- The absence of provided code raises concerns about reproducibility.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the presentation to enhance readability. Additionally, we suggest including a formal theoretical derivation of the policy improvement objective to clarify its expected return maximization. The authors should moderate their claims regarding overcoming local minima and provide more empirical evidence to support such assertions. To strengthen the paper, we encourage the authors to conduct more robust ablation studies to isolate the contributions of various components of DDiffPG. Finally, we urge the authors to provide the code to facilitate reproducibility and further validation of their results.