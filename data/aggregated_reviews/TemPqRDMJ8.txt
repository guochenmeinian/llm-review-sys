ID: TemPqRDMJ8
Title: SOUL: Towards Sentiment and Opinion Understanding of Language
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel task called Sentiment and Opinion Understanding of Language (SOUL), which encompasses review comprehension and justification generation. The authors annotate a dataset based on the Yelp and IMDb review corpora, consisting of 15,028 statements. Experimental results indicate that SOUL is a challenging task, particularly in justifying sentiment labels, with GPT-4 performing comparably to human evaluators in assessing generated justifications.

### Strengths and Weaknesses
Strengths:
1. The introduction of the SOUL task addresses limitations in traditional sentiment analysis, particularly in detecting indirect sentiment expressions like irony.
2. The justification generation aspect enhances AI model reliability by requiring models to explain their sentiment decisions.
3. The evaluation method using GPT prompting demonstrates validity when compared to human evaluation.
4. The paper is well-written and organized.

Weaknesses:
1. The paper lacks a novel method for addressing the SOUL task and primarily focuses on small language models (Roberta and Flan-T5), neglecting state-of-the-art Machine Reading Comprehension (MRC) methods.
2. Results for the Justification Generation task are inconsistent, particularly regarding ChatGPT's performance.
3. The annotation criteria are ambiguous, and there is no Inter Annotator Agreement reported, which raises concerns about data quality.
4. The paper reports an "overall accuracy" metric without clarity on its measurement and relies on non-human metrics like BLEU, ROUGE, and BERTScore, which may not be suitable for evaluating justification tasks.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the Justification Generation task results, ensuring consistency with reported metrics. Additionally, the authors should provide a novel method for the SOUL task and evaluate state-of-the-art MRC methods to enhance the robustness of their findings. We suggest including an error analysis to identify challenges faced by small and large language models in the SOUL task. Furthermore, the authors should clarify the criteria for annotation, provide examples for the "not-given" label, and ensure that the "overall accuracy" metric is clearly defined. Lastly, we advise using human judgment for evaluating generated justifications instead of relying solely on non-human metrics.