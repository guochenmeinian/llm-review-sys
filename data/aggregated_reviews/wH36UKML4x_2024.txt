ID: wH36UKML4x
Title: Trained Models Tell Us How to Make Them Robust to Spurious Correlation without Group Annotation
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method called Environment-based Validation and Loss-based Sampling (EVaLS) to tackle subpopulation generalization and spurious correlations when group labels are unavailable. Building on the Last Layer Retraining (DFR) method, EVaLS partitions the validation set into two parts: $D^{LL}$ for loss-based sampling and $D^{MS}$ for environment inference. The authors provide theoretical insights and empirical results that demonstrate the effectiveness of EVaLS in improving model robustness against spurious correlations. Additionally, the paper evaluates the EVaLS and EVaLS-GL methods, focusing on their performance against spurious correlation benchmarks across various datasets, including Waterbirds, CelebA, UrbanCars, and Dominoes-CMF. The authors clarify that their methods outperform those of SELF in most cases, particularly in datasets with class imbalance, while also addressing the limitations of environment-based validation and the specific methodologies employed.

### Strengths and Weaknesses
Strengths:
* The paper is well-structured and clearly presented, facilitating comprehension.
* The proposed method is straightforward yet effective, addressing a challenging area in subgroup generalization without group annotations.
* The authors include theoretical analysis to support their claims.
* The authors provide comprehensive comparisons of their methods against existing benchmarks, demonstrating superior performance in several datasets.
* Clear explanations regarding the limitations of previous methods and the rationale behind their proposed approaches enhance the paper's clarity.

Weaknesses:
* The novelty of the proposed method is limited, as it combines multiple existing methods (DFR, EIIL) and primarily contributes through loss-based sampling, which has been extensively explored in the noisy label literature.
* The paper does not adequately discuss recent methods requiring no group annotations, such as SELF, BAM, and BPA, particularly in relation to loss-based versus class-based schemes.
* Additional analyses are needed to clarify the characteristics of selected loss-based samples, such as the percentage of minority versus majority samples at varying thresholds.
* The experimental results lack polish and comprehensive comparisons, particularly for datasets like UrbanCars and MultiNLI, and an ablation study is missing to elucidate how the proposed approach ensures data balancing.
* The comparison of results across different group settings (4 vs. 16 groups) may lead to misleading conclusions regarding the effectiveness of EVaLS-GL on the CivilComments dataset.
* There is a need for more explicit discussion on the experimental setup to ensure clarity and fairness in comparisons.

### Suggestions for Improvement
We recommend that the authors improve the discussion of the novelty and contribution of EVaLS by explicitly comparing it to recent methods like SELF and BAM, highlighting both strengths and limitations. Additionally, we suggest including more analyses to provide insights into the characteristics of loss-based samples, such as the percentage of minority and majority samples at different thresholds. Furthermore, we encourage the authors to enhance the clarity of their experimental results by including more comprehensive comparisons and conducting an ablation study to better understand the effectiveness of their approach. We also recommend that the authors improve the clarity of the experimental setup in the revised version, particularly regarding the group settings used for the CivilComments dataset, and incorporate a more detailed discussion on the implications of using different groupings to avoid potential confusion and ensure fair comparisons across methods. Lastly, providing pseudocode for the loss-based sampling implementation would improve the presentation and clarity of the method.