ID: cqfE9eYMdP
Title: Neural Krylov Iteration for Accelerating Linear System Solving
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 5, 6, 8, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method, NeurKItt, which integrates neural network techniques with Krylov subspace methods to accelerate the solution of linear systems derived from partial differential equations (PDEs). The authors propose predicting invariant subspaces associated with the matrices defining these linear systems, significantly reducing the number of iterations required for convergence. The method is validated on linear systems from PDEs, achieving notable speedups in computation time.

### Strengths and Weaknesses
Strengths:  
1. The originality of the approach, combining neural networks with Krylov subspace methods, enhances the efficiency of traditional methods.  
2. The manuscript effectively addresses critical issues of computational inefficiency and instability in high-dimensional linear systems, making it relevant for both academic and practical applications.  
3. The method demonstrates significant reductions in GMRES iterations and wall-clock time, particularly impressive given the sparsity of the matrices involved.  

Weaknesses:  
1. The presentation lacks clarity, particularly in describing how the Fourier Neural Operator (FNO) is implemented to learn the invariant subspace, with vague sections that require more precise explanations.  
2. There are several typographical errors and unclear statements throughout the manuscript, such as the abrupt termination of sentences and incorrect terminology.  
3. The method's reliance on training Neural Operators for each individual problem increases overall time, despite improved convergence speed.  

### Suggestions for Improvement
We recommend that the authors improve the clarity of the methodology by providing a detailed description of how the FNO is applied to learn the invariant subspace, ideally in the main body of the paper. Additionally, a thorough spell-check should be conducted to address typographical errors. The authors should also clarify the implications of using preconditioners on the predicted subspace and discuss the potential for optimizing the approximated subspace in future work.