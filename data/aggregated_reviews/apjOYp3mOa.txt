ID: apjOYp3mOa
Title: LICO: Explainable Models with Language-Image COnsistency
Conference: NeurIPS
Year: 2023
Number of Reviews: 18
Original Ratings: 6, 5, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents LICO, a model that aligns visual encoders with language features using a frozen text encoder and a trainable image encoder. It employs manifold matching loss and optimal transport loss to enhance the alignment between image features and prompt tokens, demonstrating improvements over existing interpretation methods. The authors conduct thorough experiments across multiple datasets, indicating that LICO enhances classification performance and interpretability. Additionally, the paper evaluates LICO on Vision Transformers (ViTs), addressing concerns raised by reviewers regarding its interpretability and classification performance. The authors provide additional experimental results, including Table R3, which demonstrates LICO's advantages over previous interpretation methods.

### Strengths and Weaknesses
Strengths:
1. The paper introduces a novel approach that utilizes semantic knowledge from large language models to improve feature representation in image classification.
2. Comprehensive experiments validate the effectiveness of the proposed method across various datasets.
3. The manuscript is well-organized and clearly articulated.
4. The authors have effectively addressed initial concerns regarding LICO's evaluation on ViTs, enhancing the clarity and quality of the paper.
5. Additional experimental results contribute to the robustness of the findings.

Weaknesses:
1. The model's reliance on large language models raises concerns about whether it genuinely enhances existing visual interpretation methods, as the improved interpretations pertain to a modified model rather than the original.
2. Several technical issues remain unaddressed, including the transport cost in optimal transport, the initialization of learnable prompts, and the lack of introduction for certain perturbation-based explanation methods.
3. The comparison with baseline methods may be unfair due to the trainable image encoder and pretrained text encoder, which could skew results.
4. The authors' requests for feedback and reconsideration of ratings may come across as overly reliant on reviewer approval.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the relationship between LICO and existing visual interpretation methods, ensuring that the distinction between model enhancement and interpretation is well-defined. Additionally, addressing the technical questions raised, such as the transport cost in optimal transport and the initialization of learnable prompts, would strengthen the paper. We also suggest including more comprehensive evaluations on complex images and discussing the implications of using different architectures, particularly transformer-based models, to broaden the scope of the research. Furthermore, we recommend minimizing requests for rating reconsideration and focusing on the technical contributions of their work to enhance the clarity of their communication.