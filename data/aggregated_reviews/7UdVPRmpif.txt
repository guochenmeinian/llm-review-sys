ID: 7UdVPRmpif
Title: On student-teacher deviations in distillation: does it pay to disobey?
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 7, 7, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a detailed analysis of the discrepancies between the predictions of student and teacher models in knowledge distillation. The authors propose that the student network often exaggerates the teacher's confidence levels, leading to improved performance despite deviations from the teacher's soft-labels. They argue that knowledge distillation amplifies the inductive bias of gradient descent, which can result in faster convergence along significant data eigendirections. The study bridges theoretical insights with empirical evidence, enhancing the understanding of knowledge distillation dynamics.

### Strengths and Weaknesses
Strengths:
- The authors conduct a high-quality analysis with targeted experiments, thoroughly demonstrating key observations, such as the student's underfitting of challenging points (S1).
- The theoretical framework in Section 4 is presented clearly and is easy to follow (S2).
- The experimental results, particularly in Fig. 3(a), reveal interesting insights about student confidence on mislabeled data (S3).
- The paper is well-structured, with a coherent introduction and comprehensive experimental evaluation, enhancing the understanding of knowledge distillation behavior.

Weaknesses:
- Some confidence scatter-plots in the appendix are less interpretable than those in the main text (W1).
- The impact of training length on confidence distribution remains unexplored, despite its relevance to distillation performance (W2).
- The authors' claim regarding distillation's negative impact on ImageNet contradicts findings from prior work, raising questions about the discrepancies (W3).
- The theoretical model is simplistic, primarily applicable to linear models and infinitesimal learning rates, with unclear implications for neural networks (W4).

### Suggestions for Improvement
We recommend that the authors improve the clarity of the confidence scatter-plots in the appendix to enhance interpretability. Additionally, exploring the impact of training length on confidence distribution could provide valuable insights. The authors should address the discrepancies between their findings and those of prior works, particularly regarding ImageNet, to clarify their conclusions. Lastly, we suggest expanding the theoretical framework to better explain its applicability to non-linear models and classification problems, potentially incorporating discussions on the relevance of lower eigendirections in the context of implicit bias.