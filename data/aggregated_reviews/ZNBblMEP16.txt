ID: ZNBblMEP16
Title: Depth-discriminative Metric Learning for Monocular 3D Object Detection
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 8, 6, 7, 7, 6, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 4, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel metric learning scheme aimed at enhancing depth-discriminative feature extraction for monocular 3D object detection. The authors propose a quasi-isometric loss and an auxiliary head for object-wise depth estimation, which collectively improve depth quality without increasing inference time or model size. Extensive experiments on the KITTI and Waymo datasets validate the effectiveness of the proposed method across various baseline models.

### Strengths and Weaknesses
Strengths:
- The application of metric learning to improve depth estimation is theoretically sound and demonstrates good generalization potential.
- Extensive experiments on KITTI and Waymo datasets show significant performance improvements across multiple baseline models.
- The paper is well-organized and presents complex mathematical concepts clearly, making it accessible to readers.

Weaknesses:
- The claim of being the first to apply metric learning to monocular 3D object detection is inaccurate, as prior work has explored this area.
- The experiments primarily utilize the CenterNet model, lacking validation on other popular detection pipelines like the BEV paradigm.
- There is a need for performance evaluation on the nuScenes dataset to further demonstrate the method's generalization ability.
- The efficiency of the proposed method during training is questioned due to the computational complexity associated with calculating relative distances among numerous objects.

### Suggestions for Improvement
We recommend that the authors modify or remove the claim regarding being the first to apply metric learning in this context. Additionally, we suggest validating the proposed method on a wider range of detection pipelines beyond CenterNet, including the BEV paradigm. Evaluating performance on the nuScenes dataset would further substantiate the generalization capability of the method. Furthermore, addressing the computational efficiency during training and clarifying the use of the object-wise depth prediction head during inference would enhance the paper's robustness. Lastly, providing guidelines for hyper-parameter selection and discussing the limitations of the proposed method would be beneficial.