ID: Nh5dp6Uuvx
Title: Improving neural network representations using human similarity judgments
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 7, 6, 6, 7, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 5, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new objective function at the representation level, proposing the gLocal transform to align the global structure of neural network representations with human similarity judgments while preserving local structure. The authors introduce three main losses: (1) naive transform, which maximizes alignment with human similarity judgments; (2) global transform, which regularizes the transformed representation toward the original; and (3) gLocal transform, which combines global alignment with local contrastive loss. The authors demonstrate that gLocal transform enhances performance in few-shot learning and anomaly detection tasks, while the naive transform does not yield improvements.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and clear, with a logical flow.
- The method is original, effectively combining components of the losses.
- Extensive experiments validate the approach across multiple datasets and tasks.

Weaknesses:
- Results show only marginal improvements over baseline methods.
- The choice of the LCKA representation similarity measure lacks clear motivation.
- The paper does not explore transfer learning beyond few-shot learning and anomaly detection.
- Quantification of t-SNE and PCA plots is absent, which could lead to misleading conclusions.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation behind the choice of LCKA as the representation similarity measure. Additionally, the authors should consider including comparisons with general baselines in few-shot learning experiments to provide a more comprehensive evaluation. Testing the representations on transfer learning tasks, such as ImageNet linear probing, would also strengthen the findings. Furthermore, we suggest quantifying the t-SNE and PCA plots, possibly through Pearson correlation, to enhance the analysis of representation changes. Lastly, incorporating qualitative assessments, such as adversarial attacks, could provide deeper insights into the robustness of the aligned representations.