ID: aou5yrBqKy
Title: TabPedia: Towards Comprehensive Visual Table Understanding with Concept Synergy
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 7, 7, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents TabPedia, a novel large vision-language model aimed at comprehensive visual table understanding (VTU) within a unified framework. It addresses modal isolation and task exclusivity through a concept synergy mechanism that treats diverse VTU tasks and multi-source visual embeddings as interconnected concepts. The framework integrates table detection (TD), table structure recognition (TSR), table querying (TQ), and table question answering (TQA) with the capabilities of large language models (LLMs). Extensive experiments validate TabPedia's effectiveness, and a new benchmark, ComTQA, is established, featuring approximately 9,000 high-quality question-answer pairs. The authors also emphasize their proactive approach in responding to reviewer comments, expressing gratitude for the feedback and a willingness to address any remaining concerns to enhance the evaluation of their work.

### Strengths and Weaknesses
Strengths:
- The paper introduces a unified approach that effectively combines table perception and comprehension tasks, achieving impressive performance across various VTU tasks.
- An efficient table detection strategy is proposed, eliminating the need for complex non-maximum suppression algorithms, which inspires new solutions for detection-related tasks.
- The ComTQA benchmark addresses limitations of previous datasets by including more complex question types, enhancing its suitability for community development.
- The authors demonstrate a proactive approach in addressing reviewer feedback and show appreciation for constructive criticism.

Weaknesses:
- The outputs for different objects in object detection tasks are unordered, and the authors need to clarify how TabPedia reconciles this with the serialized outputs of LLMs.
- Detailed descriptions of instruction design for each table task are lacking, particularly in line 187.
- The representation of table structure with five object classes requires further explanation to clarify the relationships among them.
- The ComTQA benchmark lacks detailed statistical information, such as average question and answer lengths.
- The Broader Impact section is not comprehensive enough, requiring deeper discussions on the techniques' extensibility to other areas and challenges in multilingual scenarios.
- The initial manuscript may have contained confusing elements that led to misunderstandings, indicating a need for clearer communication.

### Suggestions for Improvement
We recommend that the authors improve the clarity of how TabPedia addresses the mismatch between unordered outputs in object detection and the serialized outputs of LLMs. Additionally, please provide more detailed descriptions of the instruction design for each task, as well as a clearer explanation of the relationships among the five object classes used in table structure representation. Furthermore, we suggest including detailed statistical information about the ComTQA benchmark, such as average question and answer lengths. Lastly, we encourage the authors to expand the Broader Impact section to include discussions on the potential for extending the techniques to other areas and the challenges of visual table understanding in multilingual contexts. Improving clarity in the manuscript will also help prevent confusion and misunderstandings.