ID: pwKkNSuuEs
Title: Abstracted Shapes as Tokens - A Generalizable and Interpretable Model for Time-series Classification
Conference: NeurIPS
Year: 2024
Number of Reviews: 22
Original Ratings: 4, 7, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents VQShape, an interpretable model for time-series classification that utilizes vector quantization to create a codebook of abstracted shapes. The authors propose that these shapes serve as interpretable tokens, allowing for dataset-agnostic representation learning. The model is evaluated against various benchmarks, demonstrating comparable performance to existing methods while emphasizing interpretability. Additionally, the authors explore the generalization capabilities of VQShape in zero-shot learning scenarios. Furthermore, the paper discusses a method for learning shapelets in time-series classification through a self-supervised pre-training process, predicting attributes such as offset, scale, relative starting position, and relative length, which are then quantized into a specific format. The authors argue that the Transformer architecture is suitable for extracting features from time-series data, despite concerns regarding its ability to capture local information.

### Strengths and Weaknesses
Strengths:
- The introduction of VQShape is innovative, linking abstracted shapes to latent space features for time-series modeling.
- The paper is well-structured, clearly articulating motivations, methodology, and findings.
- Experimental results indicate the effectiveness of the approach compared to baselines, with clear ablations demonstrating model component efficacy.
- The authors have engaged constructively with reviewer feedback, leading to an improved understanding of their methodology.
- The paper presents an interesting approach to learning shapelets, which may inspire further research in the field.

Weaknesses:
- The experimental results lack convincing comparisons, with limited baseline models and insufficient statistical significance to support claims of superiority over methods like MOMENT.
- Clarity issues persist in mathematical notation and figure captions, hindering comprehensibility.
- The model's inductive bias and its implications are not adequately discussed, particularly regarding the representation of time series through shapelets.
- The choice of benchmarking datasets is limited to UEA datasets, lacking broader comparison with UCR datasets.
- The comparison against supervised methods is primarily with forecasting models rather than classification-specific methods.
- Concerns remain regarding the model's ability to learn high-frequency information and the diversity of the learned shapelets.

### Suggestions for Improvement
We recommend that the authors improve the clarity of mathematical notation, particularly by introducing $l_{\text{min}}$ in Section 3.1 and providing formulas for $t_k$ and $l_k$ to enhance understanding. Additionally, the authors should include standard deviation information in Tab. 1 to better assess result significance. We suggest expanding the discussion on the inductive bias of VQShape, particularly how it influences the model's interpretability and performance. Furthermore, the authors should consider benchmarking against a broader range of datasets, including the UCR repository and more challenging real-world datasets, to strengthen their comparative analysis. It would also be beneficial to compare their method against classification-specific baselines rather than primarily forecasting methods. Lastly, enhancing figure captions to provide necessary context would improve overall comprehensibility, and providing experimental results that demonstrate the model's handling of high-frequency information and address the diversity of the learned shapelets more thoroughly would be advantageous.