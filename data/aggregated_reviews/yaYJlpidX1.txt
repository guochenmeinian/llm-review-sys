ID: yaYJlpidX1
Title: Metalearning to Continually Learn In Context
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 5, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for Automated Continual Learning (ACL) using self-referential weight matrices (SRWM) to meta-learn in-context continual learning algorithms. It identifies the emergence of in-context catastrophic forgetting and evaluates the performance of the proposed method across various tasks, primarily focusing on two-task and five-task settings. The authors propose a novel loss function that optimizes for both forward and backward transfer, demonstrating improvements over existing meta-learning baselines in image classification tasks like Split-MNIST and Mini-ImageNet.

### Strengths and Weaknesses
Strengths:
- The paper is clearly written and easy to follow.
- It introduces the original idea of Automated Continual Learning and identifies "in-context" catastrophic forgetting.
- The approach shows positive results in preventing catastrophic forgetting without using replay, outperforming existing baselines in simpler settings.

Weaknesses:
- The concept of in-context learning is not clearly explained, and the focus on only two-task and five-task settings limits the applicability of the findings.
- The method's scalability is questioned due to the increasing number of loss function terms with more tasks, which could hinder practical applications.
- Performance is comparatively poor against pre-trained transformer models, raising concerns about the added value of the proposed method.
- The paper primarily focuses on image classification tasks, lacking exploration in other domains such as language modeling or multimodal tasks.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the in-context learning concept and expand the experimental settings to include a wider range of task configurations, such as three-task and four-task settings. Additionally, addressing the scalability of the loss function terms and providing a more detailed comparison with replay buffer-based methods would strengthen the paper. Including experiments on language modeling tasks could also enhance the generality of the proposed method. Finally, a discussion on the computational and memory costs associated with the approach would be beneficial for practitioners.