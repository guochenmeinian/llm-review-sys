ID: tn9Dldam9L
Title: Add and Thin: Diffusion for Temporal Point Processes
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 7, 6, 5, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel probabilistic diffusion model for temporal point processes (TPPs) called ADD-THIN, which effectively addresses the continuous and discrete nature of point processes while directly modeling entire event sequences. The authors propose a framework that utilizes the Add-Thin approach, which is immune to the accumulation of errors associated with traditional autoregressive methods. The model demonstrates competitive performance in density estimation and superior forecasting capabilities on both synthetic and real-world datasets.

### Strengths and Weaknesses
Strengths:
- The originality of the work is notable, as it represents the first attempt to integrate diffusion models with TPPs, providing a promising avenue for future research.
- The formulation leverages the properties of thinning and superposition, and the empirical results indicate strong performance, particularly in forecasting tasks.
- The paper is generally well-presented, with a sound methodological approach.

Weaknesses:
- The writing and notation are often confusing, making it difficult for readers to grasp the concepts. Specific sections, such as the distinction between sets A, B, C, D, E, and F, require clearer explanations.
- There are inaccuracies and unreferenced claims throughout the paper, which undermine its credibility.
- The experimental evaluation lacks rigor, with some datasets deemed inappropriate benchmarks for neural TPPs.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing and notation, particularly in distinguishing between sets A, B, C, D, E, and F, potentially by including a figure or clearer captions. Additionally, we suggest providing more detailed explanations for the model's design choices, such as the use of positional encoding and the rationale behind the mixture of Gaussians for modeling conditional intensity. Addressing the potential limitations of using a neural network to approximate missing information about $\mathbf{t}^{(0)}$ is also essential. Lastly, a more in-depth discussion of the computational trade-offs and the efficiency of sampling routines would enhance the paper's contribution.