ID: LvAy07mCxU
Title: The Surprising Ineffectiveness of Pre-Trained Visual Representations for Model-Based Reinforcement Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 5, 6, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the application of pre-trained visual representations (PVRs) to enhance sample efficiency in model-based reinforcement learning (MBRL). The authors evaluate various PVRs across two model-based algorithms, DreamerV3 and TD-MPC2, on nine continuous control tasks from the DeepMind Control Suite and ManiSkill2. The findings reveal that using PVRs does not improve performance and often yields diminishing returns compared to training representations from scratch. The study also examines the impact of PVRs in out-of-distribution (OOD) scenarios, concluding that they do not enhance performance in these settings.

### Strengths and Weaknesses
Strengths:
- The paper addresses a novel area of research by exploring PVRs in MBRL, which has been relatively underexplored.
- It provides a comprehensive evaluation of multiple pre-trained models, revealing that learning representations from scratch often outperforms PVRs.
- The experiments are well-structured, and the paper is clearly written, making it accessible for readers.

Weaknesses:
- The study is limited to frozen PVRs, without back-propagation of gradients to pre-trained weights, which may restrict the potential benefits of PVRs.
- The focus on continuous control tasks limits the generalizability of the findings; exploring discrete action domains could provide additional insights.
- The paper does not adequately investigate the reasons behind the limited benefits of PVRs for MBRL compared to model-free RL.

### Suggestions for Improvement
We recommend that the authors improve their study by experimenting with fine-tuning the PVRs during training instead of using frozen representations. Additionally, investigating the reconstruction of image observations from frozen PVRs could provide insights into recovering image information. The authors should also consider analyzing representations from different layers of the PVRs, as the utility of these representations may vary significantly. Furthermore, clarifying the policy used for generating data during pre-training would enhance the understanding of the PVRs' effectiveness. Lastly, expanding the experimental scope to include more diverse environments and tasks would strengthen the conclusions drawn from the study.