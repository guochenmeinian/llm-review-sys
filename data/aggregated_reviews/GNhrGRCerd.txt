ID: GNhrGRCerd
Title: Trap-MID: Trapdoor-based Defense against Model Inversion Attacks
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 6, 5, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Trap-MID, a novel defense method against model inversion attacks and membership inference attacks, which integrates trapdoors into the model to mislead attackers into extracting trapdoor triggers instead of private data. The authors provide theoretical insights into the effectiveness and invisibility of these trapdoors and validate their approach through empirical experiments, demonstrating superior performance against various MI attacks without requiring additional data or significant computational overhead. The paper highlights Trap-MID's effectiveness in reducing attack accuracy under specific configurations and compares it favorably to existing defenses like NegLS, particularly in metrics such as FaceNet distance.

### Strengths and Weaknesses
Strengths:
- The paper creatively applies trapdoor injection techniques to defend against model inversion attacks, filling a gap in existing defense strategies.
- The theoretical analysis establishes definitions for trapdoor effectiveness and visibility, providing a solid foundation for the proposed defense.
- Comprehensive experiments demonstrate the generalizability and robustness of Trap-MID across various MI attacks and DNN architectures.
- Trap-MID demonstrates superior performance in FaceNet distance and ranks well in other metrics against existing defenses.
- The authors provide thorough rebuttals and additional experimental results that clarify previous concerns.
- The paper is well-structured, with clear explanations and effective illustrations of key concepts and findings.

Weaknesses:
- The evaluation is limited to low-resolution settings (64x64), which may not reflect practical applications; testing in high-resolution settings is necessary.
- The effectiveness of Trap-MID against practical MI setups, particularly PPA attacks and high-resolution images, appears limited.
- The reliance on specific evaluation metrics, such as attack accuracy and FID score, is insufficient for assessing privacy leakage; additional metrics like FaceNet should be considered.
- There are inconsistencies between visualization results and quantitative metrics, leading to potential confusion regarding the performance of Trap-MID compared to NegLS.
- The method's computational expense due to multiple optimization processes may hinder its practicality for large-scale applications.
- The assumption of white-box attackers and the lack of exploration against black-box and label-only attacks limit the scope of the evaluation.
- The paper does not adequately analyze the trade-off between trapdoor effectiveness and invisibility, which is crucial for understanding practical implications.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by including tests against black-box and label-only attacks, particularly the label-only BREP-MI attack, to provide a more comprehensive perspective. Additionally, we suggest evaluating Trap-MID in high-resolution settings and comparing it with baseline defenses like PPA or MIRROR. To enhance the assessment of privacy leakage, we encourage the authors to incorporate additional metrics, such as FaceNet, to evaluate identity similarity. Furthermore, we advise improving the clarity of the relationship between visualization results and quantitative metrics to resolve perceived inconsistencies. Addressing the computational efficiency of the method and exploring more stable trigger designs could improve its practicality. Lastly, we recommend a more thorough analysis of the trade-offs between privacy and utility, particularly concerning the impact of different trapdoor loss weights.