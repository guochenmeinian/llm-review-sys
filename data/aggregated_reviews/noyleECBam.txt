ID: noyleECBam
Title: Marginal Density Ratio for Off-Policy Evaluation in Contextual Bandits
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 5, 7, 7, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel off-policy evaluation (OPE) estimator called the Marginal Ratio (MR) estimator, which addresses the high variance issues associated with conventional methods like Inverse Probability Weighting (IPW) and Doubly Robust (DR) by focusing on the shift in the marginal distribution of rewards rather than actions. The MR estimator is shown to achieve lower variance compared to IPW and DR when the important weights are known, and it is theoretically analyzed alongside existing methods. The authors provide extensive experimental results demonstrating the MR estimator's superior performance in various scenarios. Additionally, the paper introduces a methodology for off-policy evaluation using importance sampling, emphasizing the estimation of marginal distributions of rewards and simplifying the estimation process through scalar to scalar regression for marginal ratios, contrasting with traditional importance sampling methods.

### Strengths and Weaknesses
Strengths:
- The paper tackles a relevant problem in OPE and is well-written, making it easy to follow.
- The proposed MR estimator effectively reduces variance compared to conventional methods and is supported by comprehensive experimental results.
- The connection between the MR estimator and existing methods like MIPS is clearly articulated, showcasing its potential advantages.
- The authors provide clear distinctions between their methodology and existing literature, particularly [Kallus & Zhou, 18].
- The approach simplifies the estimation of marginal ratios, making it more accessible for practical applications.
- Reviewers appreciate the authors' responsiveness to questions and the promise of additional experiments.

Weaknesses:
- The stability of the MR estimator may be compromised in cases where the target and behavior policies differ significantly, leading to high variance in the estimation of weights.
- The reliance on estimating marginal reward distributions, which are often unknown, raises questions about the practical advantages of MR over DM.
- The experimental design could be improved by comparing MR with estimated weights against IPS, DR, and MIPS using true weights, particularly in industry applications where these are known.
- The paper does not adequately discuss the relevance of reference [26], which is significant to the topic.
- Some reviewers express concerns about potential issues arising from sparsely observed actions and the implications of Dirac delta target policies.

### Suggestions for Improvement
We recommend that the authors improve the experimental design by including comparisons of the MR estimator with estimated weights against IPS, DR, and MIPS using their true weights. Additionally, we suggest providing further analysis on the accuracy of the regression problem in cases where $\rho(x,a)$ exhibits high variance. It would also be beneficial to discuss the applicability of the Self-Normalization trick to the MR estimator and to explore the potential for extending MR to a doubly-robust version. Furthermore, we recommend improving the discussion surrounding the differences between their work and reference [26], as it is crucial for contextualizing their contributions. Addressing the potential variance issues related to sparsely observed actions, similar to those in [Kallus & Zhou, 18], would enhance the robustness of their methodology. Including a comprehensive discussion of these points in either the main paper or the appendix would be beneficial.