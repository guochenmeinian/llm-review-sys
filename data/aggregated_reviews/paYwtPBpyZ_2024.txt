ID: paYwtPBpyZ
Title: Sequence-Augmented SE(3)-Flow Matching For Conditional Protein Generation
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 6, 5, 7, 6, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents FOLDFLOW++, a sequence-conditioned SE(3)-equivariant flow matching model designed for protein structure generation. It builds upon the previous FOLDFLOW model by incorporating a protein language model for sequence encoding, a multi-modal fusion trunk for integrating structure and sequence representations, and a geometric transformer-based decoder. The model demonstrates substantial improvements over state-of-the-art methods in designability, diversity, and novelty, excelling in various conditional design tasks.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and presents a carefully designed model that shows significant potential in protein generative modeling.
- It achieves state-of-the-art performance on multiple protein-related generation tasks, including unconditional generation and motif scaffolding.
- A detailed ablation study is included, examining architectural components and flow matching schedules.

Weaknesses:
- The technical novelty is somewhat limited, as many core components are derived from previous works.
- The model architecture closely resembles earlier models, making it unclear which specific elements contribute to the observed improvements.
- Some important baselines related to molecular dynamics may be missing, and the paper lacks insightful discussions on certain comparisons.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the novelty of their contributions, particularly in distinguishing FOLDFLOW++ from previous models like MultiFlow. Additionally, including visualizations of generated structures for the motif scaffolding task and benchmarking against models like AlphaFold2 would enhance the paper's depth. Clarifying the implementation of the loss function and addressing questions regarding the masking process during training would also strengthen the submission.