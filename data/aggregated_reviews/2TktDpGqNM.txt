ID: 2TktDpGqNM
Title: Overcoming Common Flaws in the Evaluation of Selective Classification Systems
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 7, 6, 8, 7, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 5, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new metric, AUGRC, for evaluating classifiers within the Selective Classification framework, which allows for the rejection of low-confidence predictions. The authors propose five requirements for multi-threshold metrics in Selective Classification and demonstrate that AUGRC satisfies these requirements, leading to different rankings of Confidence Scoring Functions across multiple datasets. The empirical results indicate that AUGRC provides valuable insights into the performance of selective classifiers compared to existing metrics.

### Strengths and Weaknesses
Strengths:
- The authors address a significant issue in the evaluation of abstaining classifiers and contribute a well-motivated metric.
- The theoretical foundations and empirical analyses are sound, and the paper is well-written and clear.
- The provision of code enhances reproducibility.

Weaknesses:
- The empirical evaluation lacks clarity in certain areas, such as contradictory statements regarding the performance of classifiers and the absence of corrections for multiple testing.
- The interpretability of AUGRC is not straightforward, and the paper relies heavily on acronyms, which may hinder readability.
- There is limited discussion on future work and no explicit limitations section, leaving questions about computational time and the applicability of AUGRC in various contexts.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the empirical evaluation by addressing contradictory statements and ensuring corrections for multiple testing are specified. Additionally, we suggest enhancing the interpretability of AUGRC by providing clearer explanations in the text. To improve readability, consider reducing reliance on acronyms. Lastly, we advise including a limitations section to discuss potential computational costs and the applicability of AUGRC in different scenarios, as well as incorporating recent state-of-the-art methods in the evaluation.