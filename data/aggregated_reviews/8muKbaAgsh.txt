ID: 8muKbaAgsh
Title: Towards Stable Backdoor Purification through Feature Shift Tuning
Conference: NeurIPS
Year: 2023
Number of Reviews: 19
Original Ratings: 7, 5, 7, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the limitations of fine-tuning and linear probing as defenses against backdoor attacks, particularly at low poisoning rates, where feature entanglement occurs. The authors propose a novel method called Feature Shift Tuning (FST) to effectively decouple clean and backdoor features, demonstrating its efficacy through extensive experiments across various backdoor attacks.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and easy to follow, with no typographical errors.
2. The experiments convincingly demonstrate the failures of previous methods in low poisoning rate scenarios and validate the proposed approach.
3. The proposed methods are intuitively reasonable and derived systematically from pre-experimental observations.
4. FST shows significant improvements in both robustness and clean accuracy compared to initial methods.

Weaknesses:
1. The implementation of the proposed methods is not publicly available, limiting reproducibility.
2. The effectiveness of the constraint term C in equation (1) requires further discussion in an ablation study.
3. The generalizability of the findings across different model architectures and datasets is not sufficiently demonstrated.
4. The paper lacks a thorough exploration of the impact of varying poisoning rates on the victim model.

### Suggestions for Improvement
We recommend that the authors improve the accessibility of their implementation by making it publicly available. Additionally, we suggest including a detailed ablation study to discuss the effectiveness of the constraint term C. The authors should also provide more insights into the generalizability of their findings across different model architectures and datasets. Furthermore, we encourage the authors to explore the effects of higher poisoning rates and include results against a broader range of attacks, such as BadNets and WaNet, to strengthen their analysis.