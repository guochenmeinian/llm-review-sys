ID: Fanbig8DR9
Title: Euclidean distance compression via deep random features
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 6, 4, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on constructing sketches of point sets using random maps $\varphi_l$ into the discrete cube $N^{-\frac{1}{2}}\{-1,1\}^N$, aiming to estimate squared Euclidean distances. The authors motivate the choice of maps based on properties of functions $f$ and $g$, providing detailed proofs for bounding sketch errors. The paper identifies limitations of $\varphi_l$, noting an additive error of $\epsilon\|x - y\|^{2-2^{1-l}}$, suggesting that for $\|x - y\| > 1$, $\varphi_l$ with $l > 1$ may not be optimal. Experiments with simulated data illustrate the performance of $l = 1$ and $l = 2$ for nearest neighbor searches, leading to conditions for their use.

### Strengths and Weaknesses
Strengths:
- The sketching algorithm efficiently stores data as bits on the discrete cube $\{-1,1\}^N$, saving space compared to traditional methods using doubles or floats.
- The approach of applying $\varphi^D$ repeatedly and finding an appropriate inverse to recover Euclidean distances is innovative.
- The paper is clear in its motivation for random projection and sketching, with thorough proofs explaining each step for w.h.p. error bounds.

Weaknesses:
- The one-layer map $\varphi_l$ appears to derive from existing sign random projections, limiting the novelty primarily to the $l$-layer maps for $l \geq 2$.
- Experimental results indicate that the two-layer map only outperforms the one-layer map in niche cases where $\|x - y\| \leq 0.06$, raising concerns about its practical utility.
- Replicating experiments, particularly in Figure 3, is challenging due to data preprocessing requirements and ambiguity regarding the nearest neighbors post-projection.
- The increased computation time for the second layer map raises questions about the trade-off between error reduction and efficiency.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the one-layer map by referencing sign random projections to clarify its origins. Additionally, it would be beneficial to provide more context on the practical implications of the two-layer map's performance, particularly addressing potential false positives. We suggest enhancing the clarity of experimental replication instructions and specifying whether true nearest neighbors refer to original or projected data. Furthermore, consider revising Figure 1 to plot $\epsilon$s within the unit circle for clearer comparisons between one-layer and two-layer maps. Lastly, including a conclusion or discussion section summarizing key ideas from Section 1 would strengthen the paper's coherence.