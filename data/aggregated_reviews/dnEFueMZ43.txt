ID: dnEFueMZ43
Title: Efficient Multi-Task Reinforcement Learning via Selective Behavior Sharing
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 5, 4, 5, 4, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 2, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Q-switch Mixture of Policies (QMP) method for identifying and incorporating shareable behaviors in multi-task reinforcement learning (MTRL). The authors propose that each task maintains an independent policy network, utilizing learned Q-functions to evaluate and select actions from other tasks during exploration. Experimental validation is conducted across various manipulation and navigation tasks, demonstrating improved sample efficiency and performance.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written, with a clear motivation for behavior sharing in MTRL.
2. The analysis is comprehensive, validating the effectiveness of behavior identification and incorporation, suggesting that combining behavior sharing with parameter sharing can enhance sample efficiency.

Weaknesses:
1. The experimental environments are overly simplified, lacking complexity. Testing in more challenging environments, such as the meta-world with tasks like insert peg and pick & place, would strengthen the results.
2. The assumption that tasks differ only in reward functions is limiting; a broader approach considering diverse transition functions and state spaces is necessary.
3. The proposed method does not significantly outperform baseline methods, raising questions about its relative effectiveness.

### Suggestions for Improvement
We recommend that the authors improve the experimental design by testing the framework in more complex environments to enhance the credibility of the results. Additionally, addressing the assumption regarding task similarity and exploring how to measure it would strengthen the theoretical foundation. Clarifying the notation and formulation throughout the paper, particularly in the problem formulation section, is essential for improving technical soundness. Finally, providing a pseudo-code for the algorithm and additional graphs to illustrate key phenomena would enhance clarity and understanding.