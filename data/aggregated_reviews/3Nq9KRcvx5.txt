ID: 3Nq9KRcvx5
Title: DiNeR: A Large Realistic Dataset for Evaluating Compositional Generalization
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel large-scale dataset, DiNeR, for compositional generalization, consisting of 3,000 dishes and 228,000 recipes. The dataset requires understanding diverse combinations of ingredients, actions, and flavors, with the task focused on predicting dish names from recipe instructions. The authors propose compositional prompting and leverage continual pretraining, demonstrating that their method outperforms T5 and GPT-3.5 on the TMCD split. The experimental results indicate that the dataset serves as a valuable resource for evaluating compositional generalization.

### Strengths and Weaknesses
Strengths:
- The proposed dataset is a significant contribution to the field of compositional generalization.
- The experimental setup includes strong baseline methods, and results show the difficulty of compositional splits compared to iid.
- The paper is clear, well-written, and presents a valuable categorization of tasks with increasing complexity.

Weaknesses:
- The f1 evaluation metric may not be well-suited for all categories, particularly the AddOne category, where it rewards easy classifications.
- Some useful statistics for the dataset, such as compound frequency and co-occurrence, are missing.
- The dataset's multilingual aspect is unclear, raising questions about the validity of findings across languages.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the dataset's language specification, ideally including a statement in the introduction or abstract that it is in Chinese. Additionally, we suggest adding a comprehensive related work section to contextualize the dataset within existing literature on compositional generalization. The authors should also clarify the role of human involvement in dataset preparation and provide more detailed statistics regarding the dataset. Finally, reconsidering the use of the f1 metric in favor of exact match evaluation could enhance the robustness of the experimental results.