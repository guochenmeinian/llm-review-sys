ID: dyZ8GJZjtX
Title: Multi-Head Mixture-of-Experts
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 4, 5, 4, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Multi-Head Mixture-of-Experts (MH-MoE), a novel routing strategy that enhances expert activation by splitting input tokens into multiple sub-tokens for expert routing. The authors conduct extensive experiments across various pre-training tasks and parameter scales (300M to 7B), demonstrating the effectiveness of the MH-MoE approach.

### Strengths and Weaknesses
Strengths:
1. The paper addresses an important research problem, focusing on improving expert utilization in MoE models.
2. Comprehensive experiments across different tasks and model sizes validate the proposed method.
3. The paper is well-written and includes helpful visualizations, such as Figure 1, which clarify the model's functionality.

Weaknesses:
1. Concerns regarding the end-to-end training and inference throughput due to the complexity of the routing process.
2. The experimental settings are limited, particularly the reliance on the X-MoE model, which may affect the generalizability of results.
3. Lack of computational scaling experiments on activated experts limits the understanding of the method's performance.
4. The paper does not adequately discuss limitations or provide comparisons with recent state-of-the-art MoE models.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by addressing the concerns regarding end-to-end throughput and the potential slowdown due to fine-grained routing decisions. Additionally, we suggest conducting computational scaling experiments to enhance the credibility of the findings. It would also be beneficial to include comparisons with recent state-of-the-art MoE models to provide a clearer context for the proposed method's performance. Finally, we urge the authors to reflect on the limitations of their approach and discuss potential scenarios where the method may underperform.