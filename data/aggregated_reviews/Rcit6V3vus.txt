ID: Rcit6V3vus
Title: GenS: Generalizable Neural Surface Reconstruction from Multi-View Images
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 6, 7, 6, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 3, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for neural implicit surface reconstruction from multi-view images, emphasizing generalizability without per-scene overfitting. The authors propose a multi-view feature volume constructed from a multi-scale FPN network, utilizing this feature to enforce view-consistency and geometry smoothness during training. The method achieves state-of-the-art results on the DTU dataset with fine-tuning. Additionally, the paper introduces novel multi-scale feature-metric consistency and view contrast losses, which enhance reconstruction quality, particularly in poorly visible regions.

### Strengths and Weaknesses
Strengths:
- The proposed approach targeting generalizable neural surface representation is innovative and technically sound.
- The inclusion of novel losses contributes to achieving state-of-the-art results both qualitatively and quantitatively.
- Writing is generally clear, and the results demonstrate reasonable quality.

Weaknesses:
- The method appears to be a direct extension of SparseNeuS, lacking significant novelty as it does not address key challenges in combining existing techniques. 
- The experiments are limited, with quantitative results only reported on the DTU dataset, and comparisons to recent efficient methods are missing.
- Grammar and sentence structure require improvement for clarity, and the reconstruction results without fine-tuning are not sufficiently compelling.

### Suggestions for Improvement
We recommend that the authors improve the novelty discussion by explicitly addressing the challenges faced when integrating existing techniques. Additionally, we suggest conducting more comprehensive experiments, including comparisons with recent methods like VolRecon and MVSNet, and providing numerical ablation studies on the proposed losses. It would be beneficial to include standard deviations in Table 1 and bold the best-performing model in each column. Furthermore, clarifying the annealing factor's role in batch-wise training and addressing the handling of occlusions in the multi-view feature consistency loss would enhance the paper's rigor. Lastly, polishing the grammar and sentence structure is essential for improving overall presentation.