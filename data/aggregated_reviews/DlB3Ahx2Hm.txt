ID: DlB3Ahx2Hm
Title: Rethinking Adversarial Attacks as Protection Against Diffusion-based Mimicry
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 5, 6, 6
Original Confidences: 3, 4, 3

Aggregated Review:
### Key Points
This paper presents a significant exploration of adversarial machine learning by focusing on pixel-space diffusion models (PDMs), which have been largely overlooked compared to latent diffusion models (LDMs). The authors argue that existing adversarial attack methods primarily target LDMs, neglecting the robustness of PDMs. Through comprehensive experiments, they demonstrate the ineffectiveness of common adversarial attacks against PDMs and introduce a purification method, PDM-Pure, which utilizes the strengths of PDMs to mitigate adversarial perturbations. This timely investigation raises critical questions regarding the current state of adversarial defenses for diffusion models.

### Strengths and Weaknesses
Strengths:
- The paper effectively identifies a crucial research gap regarding adversarial attacks on PDMs, making the problem statement relevant and plausible.
- Strong empirical results and thorough comparisons between LDMs and PDMs are presented.
- The introduction of PDM-Pure shows promise in achieving good purification results.

Weaknesses:
- The paper lacks novelty, as the use of PDMs for removing adversarial perturbations has been previously explored.
- There is insufficient theoretical depth, particularly in explaining the robustness of PDMs and the claim regarding LDMsâ€™ vulnerability due to their encoder.
- Limited exploration of new attack methods for PDMs and insufficient discussion on practical scalability and real-world implementation.

### Suggestions for Improvement
We recommend that the authors improve the theoretical analysis by providing deeper insights and proofs to support the claims regarding the robustness of PDMs. Additionally, we suggest including results with $\epsilon=8/255$ to demonstrate the effectiveness of PDM-Pure under more imperceptible conditions. Incorporating recent works such as MetaCloak and SimAC into the empirical evaluation would strengthen the claims about the robustness of LDMs and broaden the scope of the study. Finally, enhancing the clarity of technical terms and methods would improve the overall comprehensibility of the paper.