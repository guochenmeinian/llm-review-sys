ID: O97BzlN9Wh
Title: GDeR: Safeguarding Efficiency, Balancing, and Robustness via Prototypical Graph Pruning
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 8, 6, 7, -1, -1, -1, -1
Original Confidences: 4, 3, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method for graph neural network training called Graph De-Redundancy (GDeR), which aims to enhance efficiency, balance, and robustness during the training process. It utilizes trainable prototypes to create a hyperspherical embedding space, maintaining a balanced subset of training data. The experiments indicate that GDeR can achieve or exceed the performance of full datasets with significantly fewer samples, demonstrating up to a 2.81Ã— speedup and outperforming existing pruning methods. However, the generalizability of the approach beyond graph datasets remains uncertain.

### Strengths and Weaknesses
Strengths:
1. The proposed training debugging concept addresses critical challenges in training large-scale models, particularly in the context of imbalanced and noisy datasets.
2. The paper is well-written and engaging, with clear experimental tables and diagrams that enhance understanding.
3. GDeR represents a novel approach to dataset pruning in graph learning, supported by sound theoretical explanations.

Weaknesses:
1. The applicability of the method to domains outside graph training is questionable, and further elaboration is needed on its generalizability.
2. The introduction of prototypes may slow down training speed due to increased computational complexity, necessitating a discussion on complexity analysis and numerical comparisons.
3. The authors should report results at high sparsity levels and compare GDeR with established techniques for data imbalance, such as Focal Loss and Dynamic Sampling.
4. The initialization of prototypes and the impact of loss weight adjustments on model output require clarification.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the generalizability of GDeR to other data domains, particularly in computer vision and natural language processing. Additionally, the authors should provide a complexity analysis and numerical comparisons to quantify the computational burden introduced by the prototypes. Reporting results at high sparsity levels and including comparisons with established data imbalance techniques in Section 4.3 would strengthen the paper. Clarifying the initialization of prototypes and the effects of varying loss weights on model output is also essential.