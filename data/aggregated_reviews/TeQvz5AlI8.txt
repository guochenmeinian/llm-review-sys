ID: TeQvz5AlI8
Title: DAT: Improving Adversarial Robustness via Generative Amplitude Mix-up in Frequency Domain
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 6, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework for generating improved adversarial examples for adversarial training, motivated by the differential influence of amplitude and phase in adversarial examples. The authors propose Dual Adversarial Training (DAT), which enhances the resilience of deep neural networks against adversarial attacks by utilizing generative amplitude mix-up in the frequency domain. The effectiveness of the proposed approach is validated through experiments across multiple datasets and architectures.

### Strengths and Weaknesses
Strengths:  
1. The motivation illustrated in the figures is clear and solid.  
2. The experimental results consistently demonstrate the effectiveness of the proposed method.  
3. The paper is well-organized and easy to follow.  
4. Comprehensive experiments are conducted on various datasets with different architectures.

Weaknesses:  
1. The proposed framework is complex, containing multiple modules that may complicate implementation.  
2. Some descriptions are unclear, and certain details are missing.  
3. The experiments primarily focus on decision space attacks, lacking tests against feature space attacks, which could better demonstrate the method's effectiveness.  
4. The types of models used in experiments are limited, primarily based on ResNet architecture, which may not adequately showcase the method's generalizability.  
5. The comparison with existing data augmentation-based approaches is insufficient, as only a few weak baselines are considered.

### Suggestions for Improvement
We recommend that the authors improve clarity in their descriptions and provide additional details where necessary. Specifically, we suggest including results against feature space attacks to better validate the method's robustness. Additionally, the authors should consider incorporating a wider variety of models, such as Inception_v3 and ViT, to demonstrate the generalizability of their approach. Furthermore, we advise expanding the comparison with other data augmentation-based methods, such as DAJAT, and ensuring that clean accuracy metrics are included in the results for a more comprehensive evaluation of the accuracy-robustness trade-off.