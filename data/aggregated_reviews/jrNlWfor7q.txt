ID: jrNlWfor7q
Title: Kronecker-Factored Approximate Curvature for Physics-Informed Neural Networks
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 7, 6, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a KFAC approximation for second-order optimization of physics-informed neural network (PINN) losses, addressing optimization challenges associated with PINNs. The authors propose using forward mode automatic differentiation for various derivatives of the PDE, which corresponds to a forward pass with additional inputs and weight sharing. They tie this approach to KFAC approximations for weight-sharing architectures. While the combination of these ideas is novel in the context of PINN optimization, the experimental evaluation is limited to training loss curves for two PDEs (heat and Poisson equations) based on a single run without error bars.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, with a concise introduction and clear explanations of the problem and approach.
- The technical derivations and notation are precise, with no apparent mistakes.
- The insight of viewing derivatives as forward propagation with weight sharing linked to KFAC approximations is commendable.

Weaknesses:
- The notation, while rigorous, can be overwhelming, making it difficult to parse simple expressions. Simplifying some parts could enhance clarity without sacrificing precision.
- The experimental rigor is lacking; only single-run training loss curves are presented, with no error bars, making it unclear if KFAC leads to overfitting compared to other optimizers. Additional visualizations or multiple runs would provide more informative insights.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their notation to facilitate reader comprehension, possibly by simplifying expressions and removing unnecessary layer indices. Additionally, conducting multiple runs to average out noise and including error bars in the experimental results would strengthen the evaluation. We suggest incorporating visualizations that illustrate failure cases of SGD and how KFAC addresses these issues, as well as exploring more challenging PDE settings to assess the robustness of their method. Furthermore, addressing the limitations regarding the computational complexity of the algorithm and providing an open-source implementation would enhance the paper's contribution.