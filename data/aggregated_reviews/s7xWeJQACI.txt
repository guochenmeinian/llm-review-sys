ID: s7xWeJQACI
Title: Donâ€™t Stop Pretraining? Make Prompt-based Fine-tuning Powerful Learner
Conference: NeurIPS
Year: 2023
Number of Reviews: 7
Original Ratings: 7, 6, 7, 5, 5, -1, -1
Original Confidences: 5, 4, 3, 4, 4, -1, -1

Aggregated Review:
### Key Points
This paper presents a new approach to pre-training language models called Prompt-based Continued Pre-training (PCP), which combines instruction tuning with conventional continued pre-training. The authors argue that PCP enhances performance on various natural language processing tasks, particularly in scenarios where traditional continued pre-training methods, such as TAPT, are ineffective, especially for sentence-pair tasks. The proposed method utilizes pseudo-labels generated from unlabeled data to construct a prompt-based pre-training corpus, demonstrating significant improvements over baseline methods.

### Strengths and Weaknesses
Strengths:
- The paper provides a clear comparison between PCP and conventional continued pre-training, supported by strong evidence from benchmark datasets.
- The proposed method is technically simple yet effective, challenging previous assumptions about TAPT's efficacy.
- The writing is generally clear, and the experimental results validate the effectiveness of the proposed approach.

Weaknesses:
- The reasons behind TAPT's poor performance on sentence-pair tasks remain unclear, necessitating further investigation.
- The distinction between the benefits of prompt alignment and data augmentation through pseudo-labels is ambiguous, requiring additional ablation studies.
- The paper lacks thorough analysis regarding the factors contributing to the success of the proposed method, particularly in relation to the significance of labels in continued fine-tuning.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper's presentation, particularly in Figure 2 and overall flow. Additionally, more ablation studies are needed to elucidate why TAPT struggles with sentence-pair tasks and to differentiate the effects of template alignment versus data augmentation from pseudo-labels. Providing concrete examples of the methodology applied to real data instances would also enhance understanding. Finally, exploring the impact of pseudo-labels on masked language modeling predictions could strengthen the analysis of the proposed method's effectiveness.