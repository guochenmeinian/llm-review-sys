ID: Y1rOWS2Z4i
Title: Long-Horizon Planning for Multi-Agent Robots in Partially Observable Environments
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 6, 6, 5, 8, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 2, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Long-Horizon Planner for Multi-Agent Robotics (LLaMAR), a cognitive architecture that utilizes Language Models (LMs) for planning tasks in partially observable environments. LLaMAR employs a plan-act-correct-verify framework, facilitating real-time self-correction and task verification without dependence on oracles or simulators. The system's effectiveness is validated through the MAP-THOR benchmark, demonstrating a 30% higher success rate than other state-of-the-art LM-based multi-agent planners. The architecture comprises four modules: Planner, Actor, Corrector, and Verifier, designed to manage task decomposition and execution. Additionally, the paper outlines a scalable pipeline that transitions effectively from single-agent to multi-agent settings, demonstrating generalizability without needing to differentiate between the two. The architecture integrates a planner and verifier to manage high-level subtasks, while the actor and corrector modules execute actions based on memory and environmental state, addressing challenges inherent in multi-agent environments, such as task allocation, non-stationarity, and computational complexity.

### Strengths and Weaknesses
Strengths:  
1. The modular design allows for efficient task management and error correction.  
2. Real-time self-correction reduces reliance on perfect environmental knowledge.  
3. Experimental results indicate a significantly higher success rate compared to existing LM-based planners.  
4. The architecture's flexibility in handling task allocation and environmental changes enhances long-term planning.  
5. The approach effectively mitigates computational complexity by avoiding exhaustive action sequence generation.  

Weaknesses:  
1. Scaling to real-world applications remains a significant concern.  
2. The use of multiple LM-based modules increases computational and time costs.  
3. The paper lacks a thorough exploration of multi-agent interactions and task allocation.  
4. The exploration strategy appears ad-hoc and domain-specific.  
5. The framework's reliance on multiple components may introduce unnecessary complexity.  
6. The paper does not explore the implications of asynchrony or decentralization in planning, which could present additional challenges.

### Suggestions for Improvement
We recommend that the authors improve the justification for the order of the components in the plan-act-correct-verify pipeline, as the rationale for their sequence is not clearly articulated. Additionally, we suggest conducting a comparison between single-agent and multi-agent systems to demonstrate the advantages of the multi-agent approach. More in-depth analyses of failure cases should be included to identify the causes of performance gaps. Furthermore, clarifying the details of the MAP-THOR benchmark, including the number of training and evaluation episodes, would enhance the paper's transparency. Lastly, we encourage the authors to explore strategies for optimizing computational overhead, consider integrating traditional perception tools to enhance the reliability of the verifier module, and improve the exploration of asynchrony and decentralization in their planning approach, as this represents a significant area for future research.