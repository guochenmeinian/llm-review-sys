ID: fu5tWxAtZ3
Title: BOTS: Batch Bayesian Optimization of Extended Thompson Sampling for Severely Episode-Limited RL Settings
Conference: NeurIPS
Year: 2024
Number of Reviews: 4
Original Ratings: 8, 5, 6, 6
Original Confidences: 4, 4, 2, 3

Aggregated Review:
### Key Points
This paper presents a novel extension of Thompson sampling (TS) for contextual bandit problems, specifically addressing challenges in episode-limited reinforcement learning (RL) settings. The authors introduce a state-action utility function that incorporates action bias terms, optimized through batch Bayesian optimization (BO) to enhance expected returns. The methodology demonstrates significant performance improvements over traditional TS and other baseline methods, particularly in optimizing adaptive health interventions. The use of an adaptive intervention simulation environment adds credibility to the findings, showcasing the method's practical relevance and contribution to the bias-variance trade-off in contextual bandit methods.

### Strengths and Weaknesses
Strengths:
- The integration of batch Bayesian optimization to learn action bias terms is a novel and effective enhancement to Thompson sampling.
- The empirical results demonstrate significant improvements in performance across various settings, supporting the method's applicability in resource-constrained environments.
- The paper provides clear notations and comprehensive experimental comparisons, lending strong credibility to the findings.

Weaknesses:
- The theoretical guarantees on the performance of the proposed method (BOTS) are unclear.
- Certain sections contain undefined terms or references to external literature without adequate explanation, which may hinder understanding.
- The rationale behind the positive impact of the action bias term remains ambiguous, and there is a lack of exploration regarding its sensitivity and potential counterexamples in different scenarios.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the assumptions underlying their method, particularly by clearly stating the contextual bandits problem and distinguishing between environmental terms and those introduced by their algorithm. Additionally, addressing the computational complexity and overhead associated with the BOTS method would enhance its practical applicability. The authors should also explore the sensitivity of key parameters in their experiments and consider validating their method in a broader range of environments. Finally, providing open-source code would facilitate further research and application of their findings.