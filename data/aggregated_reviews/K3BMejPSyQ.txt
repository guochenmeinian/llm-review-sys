ID: K3BMejPSyQ
Title: Two-timescale Derivative Free Optimization for Performative Prediction with Markovian Data
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 5, 5, 7, 5, 6, -1, -1, -1, -1, -1
Original Confidences: 2, 4, 4, 3, 2, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a derivative-free two-timescale optimization algorithm for the performative prediction problem, where the data distribution evolves according to a controlled Markov chain. The authors demonstrate that their method achieves a sample complexity of \(O(\epsilon^{-3})\) for finding a point with a squared gradient norm at most \(\epsilon\). The work addresses the challenges of optimizing non-convex objectives in this context and provides theoretical derivations and experimental results to support their claims.

### Strengths and Weaknesses
Strengths:
1. The paper is generally well-written, with a clear motivation for tackling the targeted problem.
2. The theoretical derivation is well-presented, and the convergence rate appears reasonable.
3. The authors conduct various experiments to examine the proposed method, which is an important contribution given the limited existing results in this area.

Weaknesses:
1. The experiments are primarily conducted on toy examples, raising questions about the method's efficacy in more challenging task settings and its performance compared to other strategies.
2. The algorithm converges to a stationary point rather than an approximate minimizer of the performative risk, which is a weaker result than previous works.
3. Assumption 3.2, which is crucial for the theoretical analysis, may limit the applicability of the algorithm to popular loss functions like squared loss.
4. The paper lacks a presented lower bound for the problem, leaving the practicality of the presented rates unclear.

### Suggestions for Improvement
We recommend that the authors improve the experimental validation by applying their method to more complex, real-world scenarios to demonstrate its robustness. Additionally, clarifying the limitations of the proposed method, particularly regarding computational costs and the implications of Assumption 3.2, would enhance the paper's transparency. It would also be beneficial to explicitly state the differences between their approach and prior works, particularly in relation to the controlled Markov chain model. Finally, addressing the lack of a lower bound for the problem would strengthen the theoretical foundation of the paper.