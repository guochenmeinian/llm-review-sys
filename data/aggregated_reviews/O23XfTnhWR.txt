ID: O23XfTnhWR
Title: Graphcode: Learning from multiparameter persistent homology using graph neural networks
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 4, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents graphcodes, biparametric persistence summaries that are efficient to compute but not topologically invariant. The authors provide a C++ library for calculating graphcodes, structured as layered graphs where vertices represent points in persistence diagrams from bifiltration "horizontal slices," and edges are induced by inclusion maps between homology groups across vertical slices. The authors propose using graphcodes as effective representations of data topology for graph neural networks, facilitating the learning of topological features through deep learning. Empirical tests show that graphcodes excel in shape and binary classification tasks but do not surpass state-of-the-art methods in graph classification.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant problem in applied topological data analysis by developing topological summaries that are user-friendly and suitable for machine learning tasks.
- The originality of the approach lies in integrating multiparameter persistent homology with machine learning, presenting a novel method for extracting topological information.
- The quality of the writing is commendable, with clear illustrations aiding comprehension, although the theoretical aspects may challenge non-experts.

Weaknesses:
- The primary weakness is that graphcodes are not topological invariants and depend on the choice of basis, which may hinder their effectiveness in neural networks that require equivariance and invariance.
- The discussion on graph classification is perceived as unfair, lacking critical analysis of performance compared to other methods, and the experimental setup details are insufficiently described.
- There are concerns regarding the clarity of certain notations and the need for additional literature references to strengthen the theoretical foundation.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the sensitivity of graphcodes to the choice of basis, including experiments that assess this impact. A more critical analysis of the graph classification results is necessary, particularly in comparing accuracies with other methods and providing detailed descriptions of the experimental setups. Additionally, we suggest clarifying the notation used for persistence diagrams and addressing the identified typos. Including references to relevant literature, such as the Mapper paper and works analyzing expressivity in topology for graph learning, would enhance the literature review. Finally, we encourage the authors to explore the potential for parallelizing computations and extending the method to n-parameter persistent homology.