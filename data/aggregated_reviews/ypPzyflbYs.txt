ID: ypPzyflbYs
Title: Neural Concept Binder
Conference: NeurIPS
Year: 2024
Number of Reviews: 18
Original Ratings: 5, 4, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to unsupervised concept learning through the Neural Concept Binder (NCB), which integrates continuous and discrete encodings. NCB allows for human inspection and revision of learned concepts, demonstrating that its discrete encodings are as expressive as continuous ones. The authors introduce a new dataset, CLEVER-Sudoku, suitable for neuro-symbolic benchmarking, and show that NCB can be integrated with symbolic and sub-symbolic modules.

### Strengths and Weaknesses
Strengths:
- **Novelty**: The approach is innovative in concept learning, particularly the ability to revise concepts, enhancing human-computer interaction.
- **New Resource**: CLEVER-Sudoku is a valuable addition to the neuro-symbolic literature.

Weaknesses:
- **Method Presentation**: The explanation of block-slot encodings is insufficiently detailed, necessitating a background section on slot attention and SysBinder for clarity. Figure 2 is confusing, lacking clarity on discrete concept representation. The workings of $\texttt{enc}_l^j$ and the revision operations are unclear.
- **Experimental Evaluation**: NCB is only compared to SysBinder, lacking benchmarks against standard unsupervised approaches like SENN, BotCL, and ACE. Testing on real-world datasets, such as CUB or CELEBA, is also missing.
- **Related Work**: Important literature on unsupervised concept learning is not adequately reviewed, and recent combinations of continuous and discrete representations in supervised learning are overlooked.
- **Unclear Sentences**: Some sentences mislead regarding the inference process, and terminology used for inspections could align better with established literature.

### Suggestions for Improvement
We recommend that the authors improve the method presentation by providing a detailed background section on slot attention and SysBinder. Clarifying Figure 2 with color coding and specific references to parts of the model would enhance understanding. Additionally, we suggest expanding the experimental evaluation to include comparisons with standard unsupervised concept-based approaches and testing on real-world datasets. The authors should also ensure that the related work section comprehensively covers significant literature in the field. Lastly, we advise using well-known terms for inspection methods to avoid confusion.