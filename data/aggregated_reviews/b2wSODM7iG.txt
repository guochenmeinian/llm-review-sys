ID: b2wSODM7iG
Title: LightSpeed: Light and Fast Neural Light Fields on Mobile Devices
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 6, 6, 5, 8, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 2, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents LightSpeed, a method for real-time rendering on mobile devices using a novel 4D light-slab representation for learning neural light fields. The authors propose a divide-and-conquer strategy to enhance the representation's capability for 360-degree objects, while also integrating a super-resolution network to improve rendering quality. The method shows promising results in terms of rendering quality and efficiency compared to existing techniques, particularly on mobile platforms.

### Strengths and Weaknesses
Strengths:
- The use of the light-slab representation is innovative and offers a compact and efficient ray representation.
- The method demonstrates improved rendering quality and speed, achieving competitive performance on mobile devices.
- The paper includes extensive evaluations across various benchmark datasets, providing a clear presentation of results.

Weaknesses:
- The results for unbounded scenes are inferior to state-of-the-art methods, with noticeable artifacts such as blurriness.
- The claims regarding the novelty of the light-slab parameterization overlook existing literature that has explored similar approaches.
- The experimental results lack sufficient detail, particularly regarding comparisons with other methods and the performance at higher resolutions.

### Suggestions for Improvement
We recommend that the authors improve the discussion of existing literature on light-slab parameterization to accurately contextualize their contributions. Additionally, a more thorough analysis of the results, especially for unbounded scenes, should be included to address the observed quality issues. It would also be beneficial to provide comparisons of rendering quality when directly generating full-resolution images without the super-resolution network. Lastly, we suggest including a live demonstration video to substantiate claims of real-time rendering capabilities on mobile devices.