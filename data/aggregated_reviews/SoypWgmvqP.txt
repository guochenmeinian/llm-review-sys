ID: SoypWgmvqP
Title: Detecting Propaganda Techniques in Code-Switched Social Media Text
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 7
Original Ratings: -1, -1, -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel corpus for propaganda identification at the span level in code-switched Urdu-English text. The authors propose a new task focused on detecting propaganda techniques in this bilingual context, providing a detailed annotation methodology and experiments with various model configurations. The study highlights the inadequacy of translating Roman Urdu and emphasizes the need for direct multilingual approaches.

### Strengths and Weaknesses
Strengths:
- The annotation methodology is rigorous, improving upon previous datasets that faced significant noise.
- The paper addresses a significant gap in propaganda research for low-resource languages, particularly in a code-switched format.
- The results are clearly presented, showcasing the effectiveness of different models.

Weaknesses:
- The claim of introducing a new task is contested, as propaganda technique identification remains the core focus.
- The experimental setup does not adequately demonstrate the contribution of code-switched words, with results lacking depth for various models.
- Ethical concerns regarding the recruitment and consent of annotators are not sufficiently addressed.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their claims regarding the novelty of the task and provide a more thorough discussion of the experimental results for all models, not just the highest scoring ones. Additionally, we suggest including a reference defining "code-switching" in the introduction and a brief discussion of the topics covered in the dataset. It is also crucial to clarify the ethical considerations surrounding the annotation process, including how annotators were selected and compensated. Finally, addressing the questions raised about the dataset's construction and the impact of code-switched words on classification would enhance the paper's contributions.