ID: GeFFYOCkvS
Title: Multilingual Coarse Political Stance Classification of Media. The Editorial Line of a ChatGPT and Bard Newspaper
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the results of political stance classification experiments aimed at identifying political bias in ChatGPT. The authors utilize a multilingual corpus of newspaper articles, tagged through distant supervision, to train a binary political stance classifier that achieves 95% accuracy on a held-out test set. The classifier is then applied to ChatGPT-generated articles on politically divisive topics, revealing a consistent left political bias across all languages. The research addresses a timely issue in diagnosing bias in large language models (LLMs), particularly ChatGPT.

### Strengths and Weaknesses
Strengths:
- The research question is compelling and relevant.
- The methodology is appropriate, utilizing a valuable multilingual newspaper corpus.
- The paper is well-written and organized, with a clear analysis of political bias in ChatGPT's output.

Weaknesses:
- The study reproduces a known result regarding left political bias in LLMs using a "coarse" methodology, raising questions about the necessity of this observation.
- The decision to filter by divisive topics introduces an unacknowledged bias, as the choice of topics may skew the results.
- Clarity issues exist in the paper, with gaps in the evaluation and methodological details, making it difficult to understand and reproduce the results.

### Suggestions for Improvement
We recommend that the authors improve clarity by addressing the simplification of binary left/right political stance, particularly in the context of long-form texts. Additionally, the authors should provide further explanation of the heuristics used for data cleanliness and clarify the impact of topic selection on bias. We suggest integrating a more straightforward filtering method based on source categories instead of LDA, and ensuring that all parameters and preprocessing steps are clearly documented to enhance reproducibility. Lastly, addressing the linguistic properties of ChatGPT-generated articles and their potential influence on classifier outcomes would strengthen the analysis.