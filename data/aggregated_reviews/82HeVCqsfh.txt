ID: 82HeVCqsfh
Title: Expanding Small-Scale Datasets with Guided Imagination
Conference: NeurIPS
Year: 2023
Number of Reviews: 20
Original Ratings: 7, 5, 4, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 2, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Guided Imagination Framework (GIF) aimed at expanding small-scale datasets by generating new labeled samples using pre-trained generative models like DALL-E2 and Stable Diffusion. The framework emphasizes two criteria: (i) class-maintained information boosting and (ii) sample diversity promotion. The authors argue that their approach is significant in automatic dataset expansion, particularly in small-data scenarios, despite the concept not being entirely novel. They provide empirical evidence demonstrating the effectiveness of their method compared to existing augmentation techniques, particularly in model fine-tuning scenarios. Extensive experimental evaluations show substantial improvements in model performance across various tasks, highlighting the potential of GIF to enhance accuracy in image classification tasks.

### Strengths and Weaknesses
Strengths:
- The paper addresses the significant challenge of generating reliable supplementary training data, distinguishing itself from traditional data augmentation methods by producing unique content.
- The integration of latent features with generative models is innovative, ensuring class consistency while enhancing sample diversity.
- The proposed method shows notable performance improvements in small-data scenarios, particularly in fine-tuning settings.
- Extensive experiments validate the proposed method's effectiveness, showcasing improvements in model generalization and performance.

Weaknesses:
- Some experimental results, particularly for the Stanford Cars dataset, raise concerns about the efficacy of the augmented data, as alternative methods achieve superior results without additional data.
- The novelty of the work is questioned due to the existence of similar studies on dataset expansion.
- The exclusive use of ResNet-50 as the backbone architecture may introduce bias; exploring multiple architectures would strengthen the findings.
- There is a lack of comprehensive time cost comparisons with other models, and conflicting claims regarding the training setups of dataset expansion methods and CLIP-related baselines may lead to biased comparisons.
- Concerns about the safety and quality of generated images remain unaddressed without experimental evidence.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the experimental setup by providing detailed explanations of how baseline models like DALL-E2, SD, and MAE are implemented and optimized. Additionally, it would be beneficial to explore the performance of GIF across various backbone architectures to establish its robustness. A comprehensive discussion on the time requirements for the generating-training procedure is essential for assessing practicality. We also suggest including a detailed comparison of time costs for various models to enhance the analysis. Furthermore, we encourage the authors to provide experimental assessments of the safety and quality of the generated images to substantiate their claims regarding the benign nature of their synthetic data. Lastly, we recommend expanding the literature review to include relevant works on text-driven dataset generation and ensuring that all references cited in the main paper are accurately reflected in the bibliography, along with a discussion on the limitations and broader impacts of the work, including potential risks like mode collapse and exacerbating biases.