ID: z37ki6nqAY
Title: Online List Labeling with Predictions
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 8, 8, 7, 6, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel learning-augmented algorithm for the classic Online List Labeling problem, where n orderable items arrive sequentially and must be maintained in sorted order within an array of size c*n. The authors propose a data structure that incorporates predictions of the final rank of each item, achieving an amortized cost of O(f(eta)), where f(n) is the cost of a classic data structure used as a black box. The algorithm's performance is analyzed under various prediction error models, including Gaussian distributions, and shows significant cost improvements over traditional methods. The authors also provide empirical results demonstrating approximately 50% cost reductions compared to classic data structures.

### Strengths and Weaknesses
Strengths:
1. The main algorithm is nontrivial yet simple, with a clear central idea.
2. The analysis of performance under Gaussian prediction errors is a valuable addition.
3. The use of existing classic data structures in a black-box manner facilitates implementation and leverages optimized solutions.
4. The authors provide a matching lower bound for deterministic algorithms.
5. The paper is well-written and easy to follow.

Weaknesses:
1. The practical relevance of the studied problem is uncertain, though it remains theoretically appealing.
2. The experiments are primarily proof-of-concept, utilizing datasets adapted from unrelated benchmarks.

### Suggestions for Improvement
We recommend that the authors improve the experimental evaluation by conducting tests in an online learning context rather than a batch learning fashion, predicting the rank of item i based on its relative rank among the previous i-1 items. Additionally, we suggest clarifying the claim regarding the uniqueness of their analysis of prediction errors, as it may not accurately reflect existing literature. Furthermore, we encourage the authors to refine the terminology used in the paper to avoid potential misunderstandings, such as replacing "optimal" with "tight up to a constant factor" and ensuring precise definitions of terms like "actual LLA." Lastly, addressing the implications of average L1 prediction error in their analysis could enhance the robustness of their findings.