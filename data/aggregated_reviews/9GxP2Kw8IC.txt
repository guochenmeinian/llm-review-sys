ID: 9GxP2Kw8IC
Title: Synthesize, if you do not have: Effective Synthetic Dataset Creation Strategies for Self-Supervised Opinion Summarization in E-commerce
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents methods for generating synthetic training datasets aimed at enhancing both generic and aspect-based review summarization. For aspect-based summarization, the authors utilize a two-level clustering method on SentenceBERT representations to map fine-grained aspects to more general ones, creating triplets of reviews, aspects, and pseudo-summaries. For generic summarization, reviews similar to others based on ROUGE and cosine similarity are selected as pseudo-summaries. A BART-based model is trained on these datasets, achieving superior performance in ROUGE and faithfulness metrics compared to several baselines.

### Strengths and Weaknesses
Strengths:
- The paper introduces a novel approach to synthetic data creation for aspect-based summarization.
- It demonstrates high performance with a relatively simple model, achieving state-of-the-art results across various metrics.
- The human evaluation using best-worst scaling supports the effectiveness of the proposed methods.

Weaknesses:
- The paper lacks clarity on several technical aspects, including the definition of "human-specified aspects" and the motivation behind faithfulness issues in existing datasets.
- There are numerous hyperparameters introduced, which may limit generalizability.
- Important baseline comparisons, particularly with Coop, are missing, and the discussion on language model-based methods is insufficient.
- Presentation issues, including ambiguous terminology and unclear diagrams, hinder understanding.

### Suggestions for Improvement
We recommend that the authors improve clarity by explicitly defining terms such as "human-specified aspects" and "D" early in the paper. Additionally, we suggest including a detailed explanation of the clustering algorithm and thresholds for aspect granularity in an appendix. The authors should also provide a more thorough analysis of the results, explaining the reasons behind observed outcomes, and include comparisons with the Coop baseline to strengthen their claims. Furthermore, addressing the potential limitations of hyperparameters and discussing the relevance of synthetic data creation in the context of recent advancements in language models would enhance the paper's contributions. Lastly, we advise revising the presentation for better clarity and coherence, particularly in diagrams and terminology.