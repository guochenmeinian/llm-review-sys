ID: I2gVmVRgNk
Title: Towards Understanding Evolving Patterns in Sequential Data
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 6, 8, 8, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 4, 5, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel metric, Evolving Rate (EvoRate), utilizing mutual information (MI) to quantify evolving patterns in sequential data. The authors propose an advanced version, EvoRate$_W$, which employs optimal transport (OT) to establish correspondences between data points across different timestamps, facilitating MI estimation without direct correspondences. The effectiveness of these methods is validated through experiments on various tasks, including time-series forecasting and video prediction, demonstrating superior performance compared to state-of-the-art baselines.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant gap in the understanding and measurement of evolving patterns in sequential data, providing a quantitative measure through EvoRate and EvoRate$_W$.
- The use of optimal transport to resolve non-correspondence issues in temporal data is innovative and enhances the applicability of the proposed methods.
- The technical contributions are sound, with clear motivation and well-presented analyses supporting the effectiveness of EvoRate.

Weaknesses:
- The experimental details regarding the cost function for optimal transport, parameters, and neural architecture are insufficiently detailed, which may hinder reproducibility.
- Concerns about the scalability of the methods as dimensionality increases are raised, particularly regarding the time and resources required for training auto-encoders.
- The paper lacks extensive real-world datasets in its experiments, and the true MI values for high-dimensional data are challenging to obtain, raising questions about the accuracy of EvoRate in such contexts.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the experimental details, particularly regarding the cost function of optimal transport and the neural architecture used. Additionally, addressing the scalability concerns by discussing the computational implications of dimensionality reduction in training auto-encoders would strengthen the paper. We suggest including a pseudocode table to clarify the algorithms and considering the application of EvoRate to NLP datasets to broaden its applicability. Finally, a more robust discussion on the convergence of the function $f$ in Remark 2, given the absence of joint distribution, would enhance the theoretical foundation of the work.