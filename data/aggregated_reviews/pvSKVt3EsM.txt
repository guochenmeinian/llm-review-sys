ID: pvSKVt3EsM
Title: Flow-Attention-based Spatio-Temporal Aggregation Network for 3D Mask Detection
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 6, 3, 7, 3, 5, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 5, 1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework called FASTEN (Flow-Attention-based Spatio-Temporal Aggregation Network) for 3D mask presentation attack detection. FASTEN aims to address the limitations of existing methods, such as sensitivity to noise and high computational overhead, by focusing on fine-grained details in large movements and capturing splicing traces of 3D masks using fewer frames. The architecture includes three key modules: a facial optical flow network for inter-frame flow information, flow attention for frame significance, and spatio-temporal aggregation for combining spatial and temporal features. Extensive experiments demonstrate that FASTEN outperforms six competing methods in both intra-dataset and cross-dataset evaluations.

### Strengths and Weaknesses
Strengths:
1. FASTEN shows good performance compared to existing methods, validated through extensive experiments on publicly available datasets.
2. The framework's deployment on mobile devices highlights its practicality for real-world applications.
3. The model's requirement of only five frames for detection enhances computational efficiency.

Weaknesses:
1. The novelty of the proposed method is limited, as many components are derived from existing work.
2. The experiments lack sufficient exploration of real-world scenarios and comparisons with recent algorithms.
3. The method's focus on large movements raises questions about its performance with minimal motion.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their approach by exploring alternative architectures beyond MobileNetV3 and incorporating comparisons with recent vision transformer-based methods. Additionally, we suggest that the authors provide more extensive discussions on the model's performance in real-world scenarios and clarify the implications of using only five frames for capturing facial changes. It would also be beneficial to include a detailed analysis of the computational efficiency, including Flops and Params, and to address the latency of responses in real-time applications.