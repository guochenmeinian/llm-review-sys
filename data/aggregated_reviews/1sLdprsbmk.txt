ID: 1sLdprsbmk
Title: Can Models Learn Skill Composition from Examples?
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 6, 7, 5, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper studies the ability of large language models (LLMs) to learn compositional generalization through finetuning with a dataset that includes skill composition examples. The authors conclude that such finetuning enables models to develop a "meta-skill" for generalizing to more complex tasks. They find that training samples with higher-order skill compositions are particularly effective in eliciting this meta-skill. The paper is well-structured and presents findings that could inspire innovative applications in LLM finetuning.

### Strengths and Weaknesses
Strengths:
- The paper introduces a dataset with diverse skill examples for analyzing skill composition.
- Results indicate that finetuning enhances not only knowledge acquisition but also the ability to compose skills, potentially leading to novel applications.
- The method, while simple, effectively improves model performance on skill composition, with observations on "skill-richer" data being particularly useful for practical applications.

Weaknesses:
- Trends and comparisons in results are difficult to discern; visualizations could enhance clarity.
- The tasks in the Skill-Mix benchmark may appear artificial and challenging for evaluation.
- The reliance on automatic grading by GPT-4 raises concerns about accuracy and warrants further justification.
- The experimental pipeline lacks novelty and overlaps significantly with prior work, with insufficient exploration of alternative evaluation methods.
- Strong claims regarding the acquisition of a meta-skill require additional experimental support or theoretical justification.

### Suggestions for Improvement
We recommend that the authors improve the clarity of results by incorporating visualizations to better illustrate trends. Additionally, we suggest providing more justification for the use of GPT-4 as a grader, including a discussion on its accuracy. The authors should consider exploring a wider range of evaluation methods to strengthen their claims about compositional generalization. Furthermore, we encourage the authors to support their assertions regarding meta-skill acquisition with more experimental results or theoretical backing. Lastly, addressing the potential inflation of scores in the Skill-Mix dataset and including stronger baselines could enhance the robustness of their findings.