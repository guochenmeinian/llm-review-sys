ID: dpdbbN7AKr
Title: Large-Scale Distributed Learning via Private On-Device LSH
Conference: NeurIPS
Year: 2023
Number of Reviews: 4
Original Ratings: 7, 5, 3, -1
Original Confidences: 5, 3, 4, -1

Aggregated Review:
### Key Points
This paper presents a novel framework for on-device locality-sensitive hashing (LSH) that enhances computational efficiency, memory constraints, and privacy concerns. The authors introduce a new family of hash functions, PGhash, allowing independent hash table generation on each device, which supports personalized and private LSH analysis. The work also proposes a more efficient hashing scheme by performing low-dimensional projections and utilizing a smaller Gaussian matrix, demonstrating that cosine distance on the projected data preserves LSH properties.

### Strengths and Weaknesses
Strengths:
- The proposed PGhash family is innovative, addressing computational and memory challenges in distributed settings.
- The authors claim to have proven several statistical and sensitivity properties of PGhash, ensuring the framework's reliability, supported by competitive experimental results.
- The paper is well-written, with a clear theoretical formulation and presentation.

Weaknesses:
- Concerns about the novelty of the approach, particularly regarding the design of the projection matrix B, which may not be original.
- Lack of discussion on the parameter 'c' and its impact on performance.
- Theoretical soundness issues, particularly with Theorem 1 and the structured matrix B, which may undermine theoretical guarantees.
- Experimental results do not demonstrate convergence, raising questions about the accuracy trade-offs in multi-device settings.

### Suggestions for Improvement
We recommend that the authors improve the clarity and originality of the design of matrix B, providing detailed proofs to support its theoretical claims. Additionally, a discussion on the implications of the parameter 'c' on performance should be included. The authors should also address the theoretical soundness of their theorems, particularly Theorem 1, and ensure that the experiments illustrate convergence to better assess accuracy loss. Finally, we suggest providing further analysis on why PGhash performs worse with an increasing number of devices in multi-device settings.