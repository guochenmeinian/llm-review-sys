ID: ZJ2ONmSgCS
Title: DiffHammer: Rethinking the Robustness of Diffusion-Based Adversarial Purification
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 4, 6, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel attack evaluation framework for diffusion-based purification methods, termed the 1 + N evaluation, which integrates expectation maximization (E-M) based attacks and N-time evaluation. The authors argue that this approach effectively assesses the worst-case robustness of stochasticity-based defenses. Additionally, the paper introduces DiffHammer, an advanced evaluation framework that identifies vulnerabilities in purification clusters more effectively than traditional methods, demonstrating superior performance in identifying adversarial samples.

### Strengths and Weaknesses
Strengths:  
1. The paper is well-structured and clearly organized, with effective illustrations.  
2. The introduction of the N-time evaluation and the E-M based attack framework is novel and contributes to the field.  
3. The theoretical foundation is comprehensive, supported by detailed proofs and extensive experimental validation.

Weaknesses:  
1. The advantages of N-time evaluation are not particularly impressive and may seem intuitive, raising questions about the innovation.  
2. The proposed setting significantly increases attack costs, and if N is large, many stochasticity-based defenses may be compromised, making it impractical.  
3. Results cannot be directly compared with other methods; absolute robustness should be reported alongside ASR in Table 1 for better comparability.  
4. The experimental results are limited to CIFAR-10; additional datasets, especially ImageNet, should be included for a more robust evaluation.  
5. The clarity of the attack analysis in the E-M framework is lacking, with several definitions and assumptions needing more rigorous explanation.

### Suggestions for Improvement
We recommend that the authors improve the clarity of definitions, particularly regarding the term "cluster" and the Gaussian assumptions in the attack framework. Additionally, we suggest providing a more rigorous justification for the choice of baselines in the experiments and including newer methods for comparison. The authors should also enhance the presentation by adding labels to figures and clarifying the calculations of specific results. Finally, incorporating more diverse datasets, particularly high-resolution ones like ImageNet, would strengthen the empirical findings and overall robustness of the evaluation framework.