ID: WLZX3et7VT
Title: Active Retrieval Augmented Generation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach called Forward-Looking Active Retrieval Augmented generation (FLARE) aimed at reducing hallucination in long-form text generation. The authors propose an active retrieval method that generates a temporary next sentence and checks for low-probability tokens, allowing for iterative retrieval and regeneration of sentences. FLARE is applicable to existing language models during inference without additional training and demonstrates effectiveness across four QA datasets (MultihopQA, StrategyQA, ASQA, WikiAsp), although it shows limited gains on Wizard of Wikipedia and ELI5.

### Strengths and Weaknesses
Strengths:
- The proposed FLARE approach effectively determines when and what to retrieve during the generation process, enhancing performance across multiple QA tasks.
- The authors provide thorough experimental analysis, demonstrating the method's effectiveness and clarity in presentation.

Weaknesses:
- The similarity of FLARE with Toolformer raises concerns about novelty, and the second approach may lack depth as it appears straightforward.
- The paper does not report on the efficiency and latency of the proposed method, which involves multiple iterative retrievals.
- Comparisons are limited to simple baselines, particularly on certain datasets, and there is insufficient exploration of existing literature.

### Suggestions for Improvement
We recommend that the authors improve the novelty discussion by addressing the similarities with Toolformer and exploring existing literature more comprehensively. Additionally, please report the latency and efficiency of your approach compared to baselines. Clarify the threshold values (\beta and \theta) used for different tasks and provide empirical evidence supporting the claim that past information is not useful for predicting future tokens. Lastly, consider using a consistent model for query generation to mitigate risks associated with external models like ChatGPT.