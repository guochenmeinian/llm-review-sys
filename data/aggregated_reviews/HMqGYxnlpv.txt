ID: HMqGYxnlpv
Title: A Simple Yet Effective Strategy to Robustify the Meta Learning Paradigm
Conference: NeurIPS
Year: 2023
Number of Reviews: 18
Original Ratings: 5, 6, 5, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a robustification framework for meta-learning that addresses the gap in fast adaptation by utilizing expected tail risk. The authors propose a two-stage optimization strategy that enhances robustness against task distributions and mitigates worst-case performance, validated through various benchmark tasks. The framework is positioned as a distributional optimization problem, with a focus on conditional value at risk (CVaR) to filter poorly performing tasks.

### Strengths and Weaknesses
Strengths:
- The paper effectively motivates the need for distributionally robust optimization and introduces a novel formulation for the robustness problem in meta-learning.
- It provides a clear illustration of how the proposed optimization method can enhance existing meta-learning approaches.
- The organization and visual structure of the paper are commendable, with well-defined sections.

Weaknesses:
- The selection of the confidence level α is inadequately justified, particularly regarding its range and implications for tail risk.
- The contribution appears incremental to TR-MAML, lacking detailed exposition in the main text about the probabilistic approach and its implications.
- The authors rely on existing datasets without introducing new ones, limiting the exploration of the framework's applicability in more challenging scenarios.
- Certain technical aspects, such as the optimization objective's behavior as α approaches 1.0, require further elaboration in the main text.
- The empirical claims are weakened by the limited number of runs in experiments, raising questions about the reliability of results.

### Suggestions for Improvement
We recommend that the authors improve the justification for the confidence level α, particularly its implications for tail risk. It would be beneficial to provide more detailed discussions in the main text regarding the probabilistic approach and its contributions, rather than relegating them to the appendices. Introducing new datasets or conducting experiments in more challenging settings, such as reinforcement learning tasks, would enhance the robustness of the findings. Additionally, expanding the discussion on the performance degradation phenomenon as α approaches 1.0 in the main text is necessary. Finally, we suggest including pseudocode in the main text for better accessibility and clarity.