ID: ajzFrKT3U7
Title: Leveraging Structured Information for Explainable Multi-hop Question Answering and Reasoning
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method to enhance multi-hop question answering (QA) by leveraging structured information, specifically semantic graphs, to improve the reasoning capabilities of large language models (LLMs). The authors propose a novel framework that integrates these graphs into the prompting process, resulting in higher-quality reasoning chains and improved task performance. The main contributions include the introduction of semantic graphs, the demonstration of their effectiveness in generating grounded explanations, and empirical results supporting the claims.

### Strengths and Weaknesses
Strengths:
- The motivation for the research is clear, focusing on the importance of structured information in enhancing model reasoning.
- The paper is well-written, and the claims are strongly supported by empirical evidence and human evaluations.
- The approach demonstrates a straightforward yet efficient method for integrating data into LLMs, leading to improved performance in multi-hop reasoning tasks.

Weaknesses:
- The evaluation lacks rigor, with experiments conducted on only two datasets containing a limited number of questions, raising concerns about the reliability of the conclusions.
- The performance improvement is marginal, questioning the computational cost of processing lengthy prompts for such gains.
- The paper does not adequately address the effectiveness of the extracted information in enhancing the LLM's information extraction capabilities.

### Suggestions for Improvement
We recommend that the authors improve the evaluation rigor by expanding the dataset size and including more comprehensive human evaluations. Additionally, testing the LLM's information extraction capability on benchmarks such as NER or relation extraction would provide valuable insights. Clarifying the specific variant of GPT-3.5 used in the experiments is essential, as different models exhibit varying performance characteristics. Furthermore, we suggest conducting experiments to analyze the role of semantic relations in the graphs and evaluating the generated semantic graphs themselves. Addressing these points will strengthen the paper's contributions and applicability in real-world scenarios.