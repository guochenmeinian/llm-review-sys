ID: kTtK65vKvD
Title: ODGEN: Domain-specific Object Detection Data Generation with Diffusion Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 20
Original Ratings: 6, 6, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents ODGEN, a method for controllable image generation from bounding boxes and text prompts, aimed at training object detectors. The authors propose fine-tuning diffusion models on both entire images and cropped foreground regions to mitigate concept bleeding. By utilizing text and image lists as inputs for ControlNet, the method generates high-quality images, outperforming state-of-the-art techniques across seven datasets in terms of FID score. Additionally, object detectors trained on these generated images demonstrate improved performance.

### Strengths and Weaknesses
Strengths:
- The proposed method is simple yet effective, making it accessible for practitioners and researchers.
- The paper is well-structured and clearly written, with a solid motivation and comprehensive related work.
- Experimental results validate the method's high performance, showing better FID scores and improved object detector performance.

Weaknesses:
- The absence of an ablation study to confirm the effectiveness of fine-tuning with both cropped and entire images is concerning.
- Comparisons with other methods, particularly regarding corrupted label filtering, are insufficient for fair evaluation.
- Limited analysis on the impact of using only 200 real images for training raises questions about the method's scalability.
- A quantitative evaluation of how concept bleeding is addressed is lacking.

### Suggestions for Improvement
We recommend that the authors improve the paper by including an ablation study to validate the contribution of fine-tuning with both cropped and entire images. Additionally, provide comparisons of ODGEN with other methods both with and without corrupted label filtering for a fair assessment. It would also be beneficial to explore the performance of the proposed method and others when trained with a larger number of real images. Finally, a quantitative evaluation of concept bleeding should be included to substantiate claims made in the paper.