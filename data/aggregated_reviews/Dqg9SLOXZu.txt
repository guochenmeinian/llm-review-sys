ID: Dqg9SLOXZu
Title: Multi-Source Probing for Open-Domain Conversational Understanding
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a Multi-Source Probing (MSP) method to evaluate the dialogue comprehension abilities of open-domain dialogue models. The authors conduct probing experiments across seven tasks, demonstrating that these models can encode semantic information in their intermediate hidden states and exhibit varying conversational understanding capabilities. The findings advocate for a comprehensive evaluation and design of open-domain dialogue models.

### Strengths and Weaknesses
Strengths:  
- The writing is clear and easy to understand.  
- Extensive experiments across multiple tasks and settings provide a robust evaluation framework.  
- The paper introduces an innovative MSP technique and presents enlightening empirical discoveries regarding dialogue comprehension.

Weaknesses:  
- The necessity of a multi-source attention mechanism is unclear, raising questions about its effectiveness compared to a singular attention approach.  
- The probing model may learn shortcuts due to an increasing number of trainable parameters, potentially skewing results.  
- The descriptions of the MSP and Prompt Based methods lack clarity, particularly regarding soft tokens and prompt templates.  
- Some conclusions drawn from the experiments are not surprising, and more in-depth probing experiments are needed.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the MSP and Prompt Based methods by defining soft tokens and prompt templates explicitly. Additionally, consider conducting an experiment that maintains decoder tunability in prompt-based probing to ensure a fair comparison. We suggest exploring more in-depth probing experiments, such as analyzing dialogue discourse relations, to derive novel insights. Finally, please provide implementation details regarding the verbalizer and clarify the rationale behind the multi-source attention mechanism.