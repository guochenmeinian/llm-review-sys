ID: fYfliutfHX
Title: Learning predictable and robust neural representations by straightening image sequences
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 7, 6, 7, -1, -1
Original Confidences: 4, 4, 4, -1, -1

Aggregated Review:
### Key Points
This paper presents a self-supervised learning (SSL) objective that aims to "straighten" representation trajectories in latent space, maximizing cosine similarity of consecutive deltas of representations. To prevent collapse, the authors suggest using two regularization losses: one that pushes the variance of each representation dimension to one and another that decorrelates the representation dimensions. The objective is evaluated on simple synthetic datasets, demonstrating that it learns interesting representations, as evidenced by readout accuracy and robustness to noise and adversarial attacks.

### Strengths and Weaknesses
Strengths:
- Originality: The work is original in its application and simpler than existing methods, with connections to neuroscience.
- Quality: The analysis and breadth of existing experiments are solid, providing multiple angles to inspect learned representations.
- Clarity: The paper is well-written, with clear language and effective figures.

Weaknesses:
- Scope of experiments: The experimental validation is limited to synthetic datasets like MNIST and CIFAR-10, which restricts the generalizability of results. The authors should explore larger, naturalistic datasets to assess the model's performance on complex transformations.
- Novelty claim: The paper does not sufficiently differentiate its objective function from similar concepts explored in prior works.
- Qualitative assessment: The paper lacks a qualitative analysis of the robustness of different training networks against adversarial images.

### Suggestions for Improvement
We recommend that the authors improve the scope of their experiments by including larger, naturalistic datasets to better demonstrate the applicability of their method. Additionally, the authors should clarify how their approach differentiates from existing methods that utilize linear predictors or phase-pooling for straightening. A qualitative assessment of the robustness of perceptually straightened networks against adversarial images would also enhance the paper's contributions. Lastly, we suggest revising the presentation of figures, particularly by using legends instead of colored labels for clarity.