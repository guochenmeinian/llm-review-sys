ID: gQUDsNE3Lh
Title: HARE: Explainable Hate Speech Detection with Step-by-Step Reasoning
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a hate speech detection framework called HARE, which utilizes large language models (LLMs) to enhance the understanding and explanation of hate speech. The authors identify gaps in existing annotation schemes and propose using LLM-generated free-text rationales with Chain-of-Thought (CoT) prompts to address these gaps. Experimental results on SBIC and ImplicitHate benchmarks indicate that HARE outperforms baseline models and improves explanation quality.

### Strengths and Weaknesses
Strengths:
- The authors effectively address critical reasoning gaps in hate speech annotation schemes using LLM-generated rationales.
- Experimental results demonstrate consistent performance improvements over baselines trained on human annotations.
- The paper introduces two forms of CoT-augmentations (Fr-HARE and Co-HARE) to enhance generalizability.

Weaknesses:
- The effectiveness of HARE with language models other than Flan-T5 remains unvalidated.
- Key methodological details are missing, making it difficult to assess the paper's contributions fully.
- There is a lack of error analysis, which is essential for understanding the model's performance and limitations.
- Concerns exist regarding the potential propagation of bias through generated rationales, necessitating a qualitative analysis.

### Suggestions for Improvement
We recommend that the authors improve the experimental validation of HARE with various language models beyond Flan-T5. Additionally, it is crucial to include key methodological details that are currently referenced but not elaborated upon. We suggest conducting a thorough error analysis to clarify where the model succeeds and fails. Furthermore, we urge the authors to perform a qualitative analysis of the generated rationales to ensure they do not propagate bias and to evaluate these outputs with experts in hate speech contexts. Incorporating the new experiments reported in the rebuttal, such as those using GPT-2 and T5, would also enhance the paper's contributions.