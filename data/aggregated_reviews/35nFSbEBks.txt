ID: 35nFSbEBks
Title: Equivariant Spatio-Temporal Attentive Graph Networks to Simulate Physical Dynamics
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 7, 6, 6, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an E(3)-invariant temporal attention scheme within the E(3)-equivariant GNN framework, addressing the non-Markovian dynamics in physical systems by treating it as a spatio-temporal prediction task. The authors propose Equivariant Graph Neural Networks (GNNs) that incorporate a novel feature extraction method based on Fourier Transform, alongside spatial and temporal modules to enhance prediction accuracy. The experiments demonstrate that the proposed method outperforms existing approaches across various datasets.

### Strengths and Weaknesses
Strengths:  
- The identification of the Markov limitation in previous methods is well-founded, and the approach to address non-Markovian dynamics is significant.  
- The preservation of equivariant properties while extracting spatio-temporal features is effectively demonstrated, supported by theoretical evidence.  
- The architecture is novel and shows substantial performance improvements, particularly on the molecular dataset, with clear and easy-to-follow presentation.  

Weaknesses:  
- The paper lacks clarity regarding how the Equivariant Discrete Fourier Transform (EDFT) enhances prediction accuracy, necessitating further explanation.  
- There is a need for additional experiments, particularly in long-term recurrent forecasting, to better understand the model's capabilities.  
- The manuscript does not adequately address the limitations of the proposed method, particularly regarding the complexity introduced by the attention module for higher-order temporal relationships.  
- Several related works are overlooked, which could strengthen the literature review and claims made in the paper.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the EDFT's role in enhancing prediction accuracy by providing a more detailed explanation of its underlying mechanisms. Additionally, conducting further experiments on long-term recurrent forecasting would enhance the understanding of the model's capabilities. We also suggest that the authors acknowledge the limitations related to the complexity introduced by the attention module and analyze potential remedies for this overhead. Furthermore, a more thorough literature review should be conducted to include relevant works such as LoCS and EqMotion, and the authors should consider comparing their model against more powerful baselines beyond STGCN to substantiate their claims.