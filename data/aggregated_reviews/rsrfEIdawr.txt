ID: rsrfEIdawr
Title: DÃ¤RF: Boosting Radiance Fields from Sparse Input Views with Monocular Depth Adaptation
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 6, 5, 6, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method to enhance few-shot NeRF reconstruction by leveraging monocular depth estimation (MDE) networks as a prior for both seen and unseen viewpoints. The authors propose two main technical contributions: applying a mono depth constraint to unseen views and implementing a per-patch un-distortion of monocular depth, rather than a per-image approach. The experiments demonstrate improvements in rendered novel views and depths, particularly on datasets like Scannet and Tanks and Temples.

### Strengths and Weaknesses
Strengths:
1. The motivation for addressing distortions in monocular depth estimation is compelling, as the global scale and shift approximation is insufficient.
2. The paper effectively shows that monocular depth networks can yield reasonable depth maps from noisy NeRF renderings, enhancing NeRF optimization.
3. The proposed patch-wise scale-shift fitting reduces the impact of erroneous depth differences, and the method achieves state-of-the-art results on real-world datasets.

Weaknesses:
1. The definition of few-shot learning based solely on the number of images is problematic; it should consider view-angle and scene coverage.
2. The paper lacks clarity on how few-shot views cover evaluated scenes and the number of patches used in training, raising questions about the modeling of patch-wise scale/shift.
3. There are several unclear elements in the figures and writing, including undefined symbols and vague explanations of methodologies.

### Suggestions for Improvement
We recommend that the authors improve the definition of few-shot learning to incorporate view-angle and scene coverage. Additionally, providing a top-view visualization of camera positions and orientations would clarify how few-shot views cover evaluated scenes. The authors should also specify the number of patches used in training and clarify the relationship between patch-wise and image-wise scale/shift modeling. Furthermore, enhancing the clarity of figure captions and addressing the undefined symbols would strengthen the paper's presentation. Lastly, a more thorough discussion of the limitations and failure cases should be included in the main text rather than relegated to supplementary material.