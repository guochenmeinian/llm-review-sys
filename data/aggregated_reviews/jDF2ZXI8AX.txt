ID: jDF2ZXI8AX
Title: MV2Cyl: Reconstructing 3D Extrusion Cylinders from Multi-View Images
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 7, 5, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents MV2Cyl, a novel method for reconstructing 3D objects using a sketch-extrude paradigm, leveraging multi-view images and a learnable radiance field. The authors train a 2D prior model on labeled datasets to predict semantic labels, extrusion cylinders, and curves, which are essential for 3D shape processing. The model predicts pseudo-ground-truth for a radiance field model, which is then used to extract surfaces and curves in 3D space. Additionally, the authors propose using a pretrained DeepCAD model to enhance their multi-view image encoder's learning of the latent space. Experimental results indicate that MV2Cyl outperforms selected baselines, demonstrating improved real-world applicability and the potential for extending the approach to other tasks, such as B-Rep modeling.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and easy to follow, with effective justifications for each component.
- The ablation study clearly demonstrates the significance of each part of the method.
- The prior model's training on extensive datasets like ABC represents a substantial contribution, potentially serving as a foundational model for future CAD extraction.
- The independence of the prior and inference models allows for adaptability to new models in the literature, facilitating scalability.
- The practical application of the model is illustrated through a demo in the Appendix, reinforcing its societal impact.
- The authors effectively addressed most reviewer concerns and clarified their methodology.
- The proposed method shows promise for extending to other integrated 2D-to-3D reconstruction tasks.
- The rebuttal provided insights into the handling of NeRF models and the potential for future improvements.

Weaknesses:
- The encoding of inputs as latent vectors in Point2Cyl, ExtrudeNet, and SECAD-Net could be adapted to handle multi-view images, supporting the paper's claims.
- Section 3.4 lacks clarity; a visualization could enhance understanding.
- The reference to TensorRF raises questions about the specific 3D model used, with ambiguity regarding whether a standard NeRF or NeuS was employed.
- The prediction of normals could be leveraged to derive output shapes using algorithms like ball-pivoting or Poisson surface reconstruction.
- The method's focus on a specific problem in computer graphics may limit its broader applicability, and the lack of quantitative evaluation on real-world data is a concern.
- The pretrained model link does not include the point cloud encoder, limiting the authors' ability to train during the rebuttal period.
- Concerns remain regarding the handling and portability of using two NeRF models for the task.

### Suggestions for Improvement
We recommend that the authors improve Section 3.4 by introducing a simple visualization to aid comprehension. Additionally, we propose renaming "existence field" to "density field" for clarity, and "attribute field" to "semantic field" to avoid misinterpretation. It would be beneficial to explicitly state that $L_\text{existence}$ applies to both curve and attribute fields to eliminate ambiguities. Furthermore, we suggest including examples or visualizations in the Appendix to clarify the limitations regarding binary operations across primitives. Lastly, a discussion on the shapes the proposed approach struggles with, along with a figure showcasing these failures, would enhance the paper's completeness. We also recommend that the authors utilize the pretrained DeepCAD model and train their own multi-view image encoder to learn the latent space of the pretrained CAD sequence autoencoder. Addressing the handling and portability issues related to the two NeRF models in more detail would enhance clarity, and exploring techniques for bridging domain gaps and using realistic textures in training data could further improve the quality of results.