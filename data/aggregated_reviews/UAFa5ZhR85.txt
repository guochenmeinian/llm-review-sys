ID: UAFa5ZhR85
Title: Unsupervised Graph Neural Architecture Search with Disentangled Self-Supervision
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 4, 8, 7, 6, 7, -1, -1, -1, -1
Original Confidences: 5, 4, 5, 4, 5, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method called Disentangled Self-supervised Graph Neural Architecture Search (DSGAS) aimed at unsupervised graph neural architecture search. The authors propose a disentangled graph super-network that learns to discover optimal architectures by capturing latent graph factors without labeled data. Extensive experiments on 11 real-world datasets demonstrate that the DSGAS model achieves state-of-the-art performance compared to several baseline methods.

### Strengths and Weaknesses
Strengths:
- The paper addresses an important and underexplored problem in graph neural architecture search, particularly in scenarios lacking supervised labels.
- The DSGAS model introduces a novel approach leveraging latent graph factors through self-supervised learning, enhancing understanding and performance.
- The extensive experimental evaluation shows the model's effectiveness across various datasets.

Weaknesses:
- The necessity of designing disentangled architectures is unclear, and the motivation for this approach is not well justified. The distinction between the proposed method and existing baselines that use a single latent factor for architecture design needs clarification.
- The experiments lack sufficient comparisons with existing unsupervised methods, as they primarily compare against supervised methods.
- Additional details regarding the implementation of the DSGAS model, such as the construction of the super-network, would enhance clarity.
- The framework diagram is too small and difficult to read, and some typographical errors need correction.

### Suggestions for Improvement
We recommend that the authors improve the justification for the necessity of disentangled architectures and clarify how their method differs from existing baselines. Additionally, conducting fair comparisons with existing unsupervised methods would strengthen the evaluation. We suggest providing more implementation details about the super-network construction in the main paper. Furthermore, enlarging the framework diagram and correcting typographical errors will enhance the overall presentation.