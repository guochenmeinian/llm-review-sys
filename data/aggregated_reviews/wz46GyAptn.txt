ID: wz46GyAptn
Title: CTR-Driven Advertising Image Generation with Multimodal Large Language Models
Conference: ACM
Year: 2024
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for generating advertising images optimized for Click-Through Rate (CTR) using Multimodal Large Language Models (MLLMs). The authors propose a two-stage approach that involves pre-training MLLMs on a large-scale e-commerce multimodal dataset and fine-tuning them with a novel reward model through Reinforcement Learning (RL). The method incorporates a product-centric preference optimization strategy to ensure that the generated backgrounds align with product characteristics. Experimental results indicate that the proposed approach achieves state-of-the-art performance on both online and offline metrics.

### Strengths and Weaknesses
Strengths:
- The focus on optimizing advertising image generation for CTR is a novel and impactful approach, addressing a critical performance metric in e-commerce.
- The integration of Reinforcement Learning with MLLMs effectively enhances the alignment between generated content and user preferences.
- Strong experimental results support the effectiveness of the proposed method, demonstrating its applicability in real-world scenarios.

Weaknesses:
- Specific details about the large-scale dataset are insufficiently discussed, limiting understanding of its applicability across diverse advertising scenarios.
- The model's applicability to domains outside e-commerce, such as service advertisements, remains unclear.
- The design of the reward model for CTR fine-tuning lacks extensive explanation, hindering transparency regarding how it reflects user preferences.
- The proprietary nature of the dataset creation process raises concerns about reproducibility and further research progress.

### Suggestions for Improvement
We recommend that the authors improve the transparency of the dataset by providing more detailed information about its creation and whether it will be publicly released. Additionally, a clearer breakdown of the reward model's design and its differentiation between positive and negative samples would enhance understanding. The authors should also consider evaluating the method across various MLLMs to demonstrate generalizability and provide a comparison table of results from alternative image generation methods. Lastly, clarifying the specific instructions used in implementation and addressing the necessity and effectiveness of masking in the model would strengthen the paper's contributions.