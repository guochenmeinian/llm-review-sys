ID: xz8j3r3oUA
Title: Color Equivariant Convolutional Networks
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 5, 6, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 2, 5, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to color-equivariant convolutional neural networks (CE-CNNs) that achieves hue equivariance by applying discrete hue rotations to convolution filters. The authors demonstrate the effectiveness of their method through experiments on synthetic datasets and common object recognition benchmarks, showing marginal improvements on in-distribution data and significant gains when test data is subjected to hue shifts. The paper addresses an important yet underexplored area regarding color representation in neural networks.

### Strengths and Weaknesses
Strengths:
- The study tackles an interesting and underinvestigated question about color representation in neural networks.
- The paper is well-written, with clear motivation and thorough experimentation.
- The method achieves performance improvements without increasing the number of trainable parameters.
- The originality of the approach, particularly in achieving color equivariance through hue transformations, is noteworthy.

Weaknesses:
- The focus on hue shifts limits the scope of the paper; other photometric transformations are not considered.
- The experiments are primarily limited to object recognition tasks, lacking exploration of other applications such as unsupervised domain adaptation.
- The authors do not compare their method against robust baseline models, which raises questions about the claimed robustness to test-time corruptions.
- The mathematical definition of hue equivariance is not precise, and the implications of using a discrete subgroup for transformations are not thoroughly discussed.

### Suggestions for Improvement
We recommend that the authors improve the scope of their study by considering additional photometric transformations beyond hue shifts and exploring other tasks such as detection or segmentation. It would be beneficial to include comparisons with robust baseline models to substantiate claims regarding robustness. Additionally, clarifying the mathematical definition of hue equivariance and addressing the limitations related to illumination changes would strengthen the paper. We also suggest conducting ablation studies to analyze the impact of the number of hue rotations and the effects of color jitter augmentation during training. Finally, expanding discussions on the implications of color equivariance for algorithmic fairness and interpretability would add value to the manuscript.