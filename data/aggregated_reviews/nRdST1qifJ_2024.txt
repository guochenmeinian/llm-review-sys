ID: nRdST1qifJ
Title: Fight Back Against Jailbreaking via Prompt Adversarial Tuning
Conference: NeurIPS
Year: 2024
Number of Reviews: 19
Original Ratings: 4, 5, 4, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new defense mechanism called Prompt Adversarial Tuning (PAT) aimed at protecting large language models (LLMs) from jailbreak attacks. PAT optimizes a defensive prompt control attached to user inputs, combining adversarial and benign prompts to enhance model robustness. The method reportedly reduces the success rate of advanced attacks to nearly zero while maintaining performance on benign tasks. However, concerns arise regarding the simplicity of the optimization idea, its generalization against adaptive attacks, and the robustness of experimental results due to the use of prefix-based methods for calculating attack success rates (ASR). The authors express gratitude for the reviewer's time and effort, indicating a willingness to address any remaining concerns and provide additional explanations as needed.

### Strengths and Weaknesses
Strengths:
1. PAT introduces an innovative system-level defense mechanism that does not alter the LLM itself.
2. The method shows good transferability across various models, demonstrating versatility.
3. It preserves model performance on benign tasks while effectively defending against malicious prompts.
4. The authors demonstrate a proactive approach by inviting further discussion and clarification, showing their commitment to improving the manuscript.

Weaknesses:
1. The optimization process incurs computational overhead and is time-consuming due to greedy sampling.
2. There are doubts about PAT's generalization, particularly against adaptive and real-world attacks.
3. The robustness of experimental results is questionable, especially with prefix-based ASR calculations that may lead to false judgments.
4. The evaluation lacks comprehensive coverage of attack and defense baselines, particularly in closed-source models.
5. The review lacks specific feedback on the content of the manuscript, making it difficult to assess the strengths and weaknesses of the research itself.

### Suggestions for Improvement
We recommend that the authors improve the clarity of experimental settings by specifying the number of training and testing datasets used. Additionally, the authors should expand their evaluation to include a broader range of attack and defense methods, such as SmoothLLM and RPO, and consider testing on more general capabilities beyond MT-bench, including math and reasoning tasks. Furthermore, we suggest the authors provide a detailed discussion on the potential effectiveness of PAT against unseen jailbreak attacks and clarify the implications of the adversarial prompt's position in relation to the optimized defense prefix. Finally, we recommend that the authors incorporate specific feedback from reviewers to address any outstanding concerns more effectively.