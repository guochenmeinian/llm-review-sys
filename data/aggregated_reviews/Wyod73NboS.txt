ID: Wyod73NboS
Title: Are Language Models Worse than Humans at Following Prompts? It's Complicated
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper conducts a follow-up study on the work by Webson and Pavlick (2022), investigating human performance on datasets constructed similarly to those used by W&P. The authors find that one of W&Pâ€™s assumptions regarding human behavior does not hold, highlighting the need for empirical validation of human performance in model comparisons. The study reveals that while both humans and models perform well with irrelevant instructions, humans adhere to misleading instructions more faithfully than models. 

### Strengths and Weaknesses
Strengths:
- The paper presents an interesting research question and conducts comprehensive human studies that illustrate its points.
- It provides empirical evidence that challenges previous assumptions about human behavior in response to misleading prompts, emphasizing the importance of rigorous validation.

Weaknesses:
- The scope of the findings is limited, primarily focusing on the NLI task with fewer than 200 examples, which may not generalize to other NLP tasks.
- The analysis and discussion of results are not sufficiently informative, and the claims made about human behavior lack depth and clarity.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their findings by evaluating additional NLP tasks beyond NLI. Additionally, we suggest providing a clearer rationale for the significance of their claims regarding human behavior, particularly in the context of misleading prompts. More examples and a detailed discussion of the experimental results would enhance the clarity and impact of the paper.