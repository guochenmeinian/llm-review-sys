ID: hcXDbbzgoh
Title: Taylor TD-learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 7, 6, 5, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 2, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an algorithm called Taylor TD, which enhances model-based reinforcement learning by utilizing a Taylor series expansion to analytically estimate the expected TD update over a distribution of nearby state-action pairs, thereby reducing variance compared to standard Monte Carlo TD updates. The authors provide theoretical analysis demonstrating that Taylor TD updates exhibit lower variance and stability with linear function approximation. Empirical results indicate that the proposed TaTD3 algorithm performs competitively against model-free and model-based baselines on MuJoCo benchmarks.

### Strengths and Weaknesses
Strengths:
- The core idea of using Taylor expansions for expected TD updates is novel and theoretically motivated, contributing to variance reduction.
- The method maintains convergence guarantees of TD-learning under linear function approximation, which is a significant theoretical advancement.
- The empirical results are strong, with meaningful comparisons to baseline algorithms and additional variance analysis.

Weaknesses:
- Performance improvements of Taylor TD3 are marginal in most environments, raising concerns about its effectiveness across tasks.
- Some derivations and loss functions are unclear, necessitating further clarification.
- The presentation could benefit from clearer explanations of computational demands and the significance of results currently relegated to the appendix.

### Suggestions for Improvement
We recommend that the authors improve clarity regarding the loss function used for model learning, as well as the derivation of the update equations. Specifically, please specify the objective or loss function used to optimize model parameters in Algorithm 1. Additionally, we suggest including a discussion on why the performance gains of Taylor TD3 are limited in certain environments, as this could provide valuable insights. Furthermore, we encourage the authors to move key results from the appendix to the main body of the paper to enhance accessibility and understanding. Lastly, consider modifying the terminology from "MC TD update" to "sampled TD update" to avoid confusion with traditional Monte Carlo estimates.