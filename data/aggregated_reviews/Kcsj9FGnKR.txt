ID: Kcsj9FGnKR
Title: DiffuLT: Diffusion for Long-tail Recognition Without External Knowledge
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 4, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel pipeline for long-tail recognition using a diffusion model to generate data for tail classes, addressing the long-tail distribution problem. The authors emphasize the importance of approximately-in-distribution (AID) samples in enhancing classifier performance and propose an L_AID loss to guide the diffusion model in generating richer AID samples. Experiments on CIFAR 10-LT, CIFAR 100-LT, and ImageNet-LT demonstrate significant performance improvements.

### Strengths and Weaknesses
Strengths:
1. The paper is clearly organized and well-written.
2. Experimental results are promising, showing improvements over baseline methods.
3. The exploration of dataset composition, including ID, AID, and OOD, is insightful and well-analyzed.

Weaknesses:
1. The innovation is limited, as the method primarily involves a reconstruction loss similar to existing studies.
2. The claim of generalizability in real-world applications is questionable, given that performance improvements may stem from identical training and test data distributions.
3. The rationale behind Equation 4 and the definition of AID need clarification, particularly regarding the impact of potential modifications.
4. The performance of combining ID and AID in Table 6 is not adequately explained.
5. The authors should provide ablation studies for Nt and further clarify the baseline setups in Tables 1, 2, and 3.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Equation 4 and justify the definition of AID samples. Additionally, addressing the performance discrepancies in Table 6 and providing ablation studies for Nt would strengthen the paper. Clarifying the baseline setups in Tables 1, 2, and 3 is also essential. Finally, including real-world long-tailed datasets in experiments would enhance the robustness of the findings.