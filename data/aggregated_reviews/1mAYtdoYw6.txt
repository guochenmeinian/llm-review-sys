ID: 1mAYtdoYw6
Title: Laplacian Canonization: A Minimalist Approach to Sign and Basis Invariant Spectral Embedding
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 7, 7, 5, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 2, 2, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Laplacian Canonization (LC), a method designed to ensure sign and basis invariance in spectral embeddings for graph neural networks (GNNs). The authors propose the Minimal Axis Projection (MAP) algorithm, which canonizes eigenvectors during preprocessing, thereby enhancing computational efficiency. The paper includes theoretical analyses and experimental results demonstrating MAP's effectiveness on various graph classification benchmarks, showing improved performance and reduced runtime compared to existing methods. While MAP achieves comparable accuracy to existing models, its efficiency is highlighted as a significant advantage. However, the current experiments do not adequately demonstrate the impact of basis ambiguity on performance, particularly in real-world datasets.

### Strengths and Weaknesses
Strengths:
- Originality: The approach of Laplacian canonization is novel and addresses significant issues in GNN literature.
- Quality: The method is both simple and efficient, with experiments indicating performance gains when paired with multiple architectures. The ablation study effectively highlights the contributions of different components.
- Clarity: The paper is well-written, with clear definitions and a logical structure. The MAP method shows commendable efficiency, as evidenced by the results in Table 6, and the synthetic dataset experiments indicate that MAP can effectively handle basis ambiguity, achieving an accuracy of 84% in graph isomorphic testing.

Weaknesses:
- The experimental results show only modest improvements over BasisNet, with the primary contribution being reduced runtime. The authors should clarify the decision to exclude certain results from the BasisNet paper.
- The theoretical guarantees provided are seen as marginal, and the limitations of not all eigenvectors being canonizable should be discussed more thoroughly.
- Questions remain regarding the distribution of uncanonizable eigenvectors and the implications of using low-frequency eigenvectors.
- The presentation, especially in the introduction, lacks clarity and does not adequately address the limitations of MAP's performance relative to existing methods. Current experiments do not sufficiently highlight real-world applications where basis ambiguity significantly impacts performance.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the limitations of their approach, particularly regarding the 90% canonizable rate and its implications. Additionally, the authors should provide a clearer justification for the exclusion of BasisNet results and explore the distribution of uncanonizable eigenvectors in their datasets. It would also be beneficial to include the useful toy illustrations from the appendix in the main paper and to address the performance discrepancies observed when varying the number of eigenvectors used in MAP. Furthermore, the authors should improve the presentation of their findings by clearly stating that MAP achieves comparable performance to existing methods while emphasizing its efficiency. Specifically, the authors should include reservations about the claims of superiority over methods like SignNet, detailing that basis ambiguity is less influential in real-world datasets. Lastly, we suggest that the authors find real-world datasets where basis ambiguity matters, as this would strengthen their argument for MAP's advantages, and they should not downplay the importance of basis ambiguity, as it is a key selling point of their method.