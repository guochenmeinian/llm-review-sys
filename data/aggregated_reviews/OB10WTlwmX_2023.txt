ID: OB10WTlwmX
Title: Evaluating and Improving Tool-Augmented Computation-Intensive Math Reasoning
Conference: NeurIPS
Year: 2023
Number of Reviews: 30
Original Ratings: 4, 7, 7, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an evaluation and enhancement of tool-augmented computation-intensive math reasoning using large language models (LLMs) through the introduction of a new dataset, CARP (Computation-Intensive ARithmetic Problems), which consists of 4,886 algebra problems with formal annotations of intermediate steps. The authors propose a novel evaluation metric, Intermediate Reasoning Accuracy (IRA), alongside new metrics, ExpAcc and Fail@where, to diagnose errors in the reasoning process. They demonstrate that chain-of-thought (CoT) prompting significantly improves LLMs' math reasoning performance and introduce DELI (Deliberation with Exemplar-based Learning and Interface), a method that deliberates reasoning steps with a tool interface. DELI shows superior performance compared to existing methods, particularly in handling computation-intensive tasks, and is flexible enough to incorporate various tools, demonstrating its generalizability across different tasks.

### Strengths and Weaknesses
Strengths:  
1. The CARP dataset includes detailed annotations for intermediate reasoning steps, facilitating the evaluation of LLMs' accuracy in math problem-solving.  
2. The introduction of the IRA, ExpAcc, and Fail@where metrics provides new ways to assess intermediate reasoning accuracy and error diagnosis in LLMs.  
3. Experimental results indicate that CoT prompting enhances LLMs' performance in math reasoning tasks.  
4. DELI effectively combines reasoning deliberation with tool manipulation, showing promising results in improving LLMs' accuracy and outperforming other methods across various models.  
5. The paper includes empirical analyses and experiments that validate the proposed methods and address reviewer concerns.

Weaknesses:  
1. The motivation behind measuring tool manipulation ability is unclear, and the dataset's contribution to quantifying this performance is questionable.  
2. The benchmark lacks comprehensiveness, considering only three tools and focusing solely on math reasoning, which limits its applicability and may be perceived as monotonous compared to contemporary works.  
3. The paper does not address the potential for multiple solution paths in algebra problems, raising concerns about the validity of conclusions drawn regarding LLMs' error patterns.  
4. The computational cost of DELI may be significantly higher than baseline methods, and its novelty compared to existing frameworks like ReAct is not well established.  
5. Limited experimental details are provided, particularly regarding the annotation process and the LLMs used, and the terminology, such as "Deliberation," may be unclear to some readers.

### Suggestions for Improvement
1. We recommend that the authors clarify the motivation for measuring tool manipulation ability and explicitly state how the CARP dataset contributes to this goal.  
2. To enhance the benchmark's comprehensiveness, consider including a wider variety of tools and expanding the evaluation to include diverse domains beyond math reasoning.  
3. We suggest addressing the possibility of multiple solution paths in algebra problems to validate the conclusions regarding LLMs' early-stage errors.  
4. The authors should provide a detailed discussion on the computational overhead associated with DELI and compare it to self-consistency as a baseline.  
5. We encourage the authors to elaborate on the annotation process and clarify the relationship between CARP and DELI to strengthen the paper's coherence.  
6. Additionally, a clearer explanation of the term "Deliberation" would enhance reader comprehension, and a candid discussion on the additional inference overhead associated with DELI, along with comparisons to ReAct and other multi-pass methods, would be beneficial.