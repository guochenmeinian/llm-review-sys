ID: cmQj1FdsOJ
Title: Evaluating the Knowledge Base Completion Potential of GPT
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an experiment for knowledge base (KB) completion using GPT-3, focusing on predicting 41 relations from Petroni et al. (2019). The authors evaluate various promptings, including a few-shot prompting to elicit ‘don’t know’ responses, and conduct both automatic and manual evaluations, yielding interesting results. The study emphasizes extending KBs by addressing non-popular statements, which contrasts with previous research. The paper is well-written and provides a timely analysis of GPT-3's capabilities in KB completion.

### Strengths and Weaknesses
Strengths:
- The paper is easy to understand and well-structured.
- It addresses a relevant topic by exploring the use of large language models for KB expansion.
- The findings may interest a broader community and contribute to the understanding of LLMs in knowledge-related tasks.

Weaknesses:
- Some methodological choices lack sufficient motivation and explanation.
- The results require further testing or clarification, particularly regarding the lowest scores for certain relations.
- There is a need for experiments with other LLMs more similar to GPT-3 than Bert-Large, and the influence of pre-training documents on results is not adequately explored.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their methodological choices and provide more detailed explanations for their results, especially for the lowest scores observed. Additionally, we suggest conducting experiments with smaller versions of GPT-3 and exploring the impact of pre-training documents on the outcomes. It would also be beneficial to clarify how GPT-3 can be prompted to achieve high precision results and whether a threshold needs to be defined for each relation in the knowledge graph.