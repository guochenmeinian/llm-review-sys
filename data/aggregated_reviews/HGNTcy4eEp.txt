ID: HGNTcy4eEp
Title: Learning Group Actions on Latent Representations
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 7, 4, 5, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 2, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for learning group actions in latent space using autoencoders, arguing that this approach allows for modeling a broader range of real-world scenarios without requiring specific layers. The authors emphasize the importance of cycle consistency in the decoder output, demonstrating their method's effectiveness through experiments on various image datasets, including 2D and 3D rotations, and image contrast transformations.

### Strengths and Weaknesses
Strengths:  
- The problem addressed is significant, as limited work has focused on group actions in latent representations, which is crucial in the context of generative AI.  
- Results are impressive, showing that the method performs comparably or better than prior work on data group actions, indicating invariance to the level of group action.  
- The ablation study provides valuable insights into the contributions of different components to model performance.

Weaknesses:  
- The novelty of the approach is somewhat limited, as operations in latent space are not uncommon in other tasks.  
- The explanation of the framework in section 3.3 lacks clarity, particularly regarding the rationale for applying attention operations to skip connections.  
- There is insufficient analysis of the latent space, making it difficult to ascertain the extent to which improved metrics are due to the modeled group action versus the neural network architecture.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the explanation regarding the initialization of the transformation matrix \( g \) in the latent space, particularly in relation to Figure 2. Additionally, we suggest including experiments that visualize the latent space to demonstrate the disentanglement of invariant and varying parts, such as swapping these parts between latent vectors. Furthermore, providing qualitative comparisons in the ablation study would enhance the credibility of the results, particularly regarding the impact of the LPIPS loss on image rendering.