ID: MhbiD5FVPF
Title: People Make Better Edits: Measuring the Efficacy of LLM-Generated Counterfactually Augmented Data for Harmful Language Detection
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the automatic generation of Counterfactually Augmented Data (CAD) using pretrained language models such as ChatGPT, Flan-T5, and PolyJuice. The authors analyze various data creation strategies and their effectiveness in training a RoBERTa classifier for harmful language detection, measuring both in-domain and out-domain generalization. The findings indicate that while human-written CADs outperform automated ones, ChatGPT-generated data is competitive. The paper emphasizes the importance of manual validation due to the inadequacies of current language models in generating effective counterfactuals.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant issue in NLPâ€”reducing reliance on spurious correlations in harmful language detection.
- It provides a thorough experimental study and analysis of multiple counterfactual data augmentation methods.
- The results are well-reported, and the paper is clearly written.

Weaknesses:
- The experimental design lacks justification and clarity, particularly regarding the choice of classifiers and the handling of data sampling.
- There is no human validation of the generated data, which raises concerns about the quality of the augmentation.
- Statistical significance tests are absent, and the paper does not adequately address the implications of using ChatGPT outputs due to commercial restrictions.

### Suggestions for Improvement
We recommend that the authors improve the experimental design by providing justifications for their choices and clarifying data sampling methods. It would be beneficial to include human validation for a subset of the generated examples to assess quality. Additionally, conducting statistical significance tests on the results would strengthen the findings. We suggest exploring the use of newer base models, such as LLAMA or fine-tuned Flan-T5, to evaluate the generalizability of the results. Lastly, addressing the commercial restrictions on using ChatGPT outputs in the discussion would enhance the paper's applicability.