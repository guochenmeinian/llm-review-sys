ID: FZW7Ctyjm3
Title: Enhancing Large Vision Language Models with Self-Training on Image Comprehension
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 6, 4, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents STIC (Self-Training on Image Comprehension), a method aimed at acquiring high-quality fine-tuning data for large vision language models (LVLMs) with minimal human effort. STIC consists of two stages: image comprehension self-training and description-infused fine-tuning. The LVLM generates descriptions from images and corrupted images, treating these as preferred and dis-preferred responses, respectively. The base LVLM is trained using directed preference optimization (DPO) on this generated preference data, followed by fine-tuning on instruction-following data. Experimental results indicate that STIC outperforms existing methods across various benchmarks.

### Strengths and Weaknesses
Strengths:
- The manuscript is well-written and accessible, with helpful preliminaries and figures.
- The paper includes diverse analyses and discussions in its experimental section.
- The proposed method shows significant performance improvements across multiple benchmarks, achieving an average accuracy gain of 3.8%.

Weaknesses:
- The soundness of the manuscript is limited; for instance, the effectiveness of description-infused fine-tuning is not validated, and much of the performance gain is attributed to the prompting method (DaR), which is not part of STIC.
- The investigation of existing self-training algorithms is narrow, focusing primarily on recent self-improvement systems, which raises questions about STIC's technical contributions relative to established semi-supervised learning research.
- The experiments utilize a relatively small dataset of unlabeled images (6k and 12k), and the optimal data quantity for maximizing performance has not been thoroughly explored.

### Suggestions for Improvement
We recommend that the authors improve the validation of the effectiveness of description-infused fine-tuning and clarify the contributions of each stage to performance improvement. Additionally, we suggest expanding the discussion on the design principles behind the prompt sets used for generating preferred and dis-preferred responses. The authors should also explore the scalability of STIC with different datasets and model sizes, as well as provide detailed explanations of the DaR prompting method earlier in the paper. Finally, we encourage the authors to investigate the impact of using a larger and more diverse set of unlabeled images on the performance of STIC.