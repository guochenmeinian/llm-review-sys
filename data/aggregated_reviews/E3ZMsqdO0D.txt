ID: E3ZMsqdO0D
Title: Zero-Shot Event-Intensity Asymmetric Stereo via Visual Prompting from Image Domain
Conference: NeurIPS
Year: 2024
Number of Reviews: 17
Original Ratings: 5, 6, 6, 6, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a zero-shot framework called ZEST for event-intensity asymmetric stereo matching, utilizing a representation alignment module to bridge the gap between frame and event representations. The authors propose a monocular cue-guided disparity refinement method to enhance robustness in textureless regions. A detailed analysis of the refinement module's performance in edge and textureless areas demonstrates significant improvements in endpoint error (EPE) metrics. The effectiveness of ZEST is validated through comprehensive experiments on the DSEC dataset, showing superior performance compared to existing methods. The authors also provide a comparative analysis of the refinement module's computational cost, indicating that a balance between accuracy and efficiency can be achieved by adjusting iteration counts. They acknowledge the need for baseline comparisons across various datasets, which is hindered by large data sizes and preprocessing requirements.

### Strengths and Weaknesses
Strengths:
1. The visual prompting technique creatively addresses the modality alignment challenge, allowing the use of off-the-shelf stereo models without additional training.
2. The experimental evaluation is comprehensive, demonstrating clear improvements over existing methods and validating the approach through ablation studies.
3. The paper is well-structured and clearly explains the methodology, providing sufficient details for reproducibility.
4. The analysis of EPE improvements in different areas is thorough and insightful, showcasing a clear understanding of computational efficiency and scalability suitable for real-time applications.

Weaknesses:
1. The experimental evaluation is limited to the DSEC dataset, raising concerns about the generalizability of the results; additional benchmarks would strengthen the findings.
2. The computational efficiency and resource requirements of the proposed method are not adequately analyzed, which is crucial for real-time applications.
3. The monocular disparity refinement module's marginal gains and computational overhead are not fully justified, and its optimization details should be included in the main body of the paper.
4. The challenges in conducting baseline comparisons due to data size and format compatibility are noted, and fine-tuning large models poses significant challenges that the authors plan to address in future work.

### Suggestions for Improvement
We recommend that the authors improve the analysis of the computational efficiency and resource requirements of the ZEST framework, particularly regarding the monocular cue-guided disparity refinement module. Additionally, we suggest including results from other datasets, such as MVSEC, to enhance the evaluation of the method's generalization capabilities. Furthermore, we encourage the authors to provide a detailed justification for the monocular refinement module's marginal gains and to include its optimization details in the main text rather than the appendix. We also recommend that the authors provide a more detailed breakdown of the refinement module's performance across various scenarios and highlight the ZEST framework's potential for future advancements in monocular depth estimation and frame stereo matching. Exploring sparse stereo matching networks and incorporating spatially varying scales with a strong regularization term should also be considered for future work.