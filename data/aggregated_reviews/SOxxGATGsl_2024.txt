ID: SOxxGATGsl
Title: Efficient Algorithms for Lipschitz Bandits
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 2, 6, 6, 4, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents two algorithms for Lipschitz bandit problems, focusing on regret minimization with memory constraints. The authors propose the Memory Bounded Uniform Discretization (MBUD) and Memory Bounded Adaptive Discretization (MBAD) algorithms, achieving nearly optimal regret while improving time complexity to \(O(T)\) and memory complexity to \(O(1)\). The algorithms utilize a tree-like embedding of the state space and pairwise comparisons. The paper also claims to match upper bounds with lower bounds from previous work while maintaining linear time complexity.

### Strengths and Weaknesses
Strengths:  
1. The algorithms achieve nearly optimal regret bounds while reducing time and memory complexity.  
2. Both proposed algorithms are non-trivial, novel, and interesting.  
3. The contribution is useful in practice, particularly in the Lipschitz bandit setting.

Weaknesses:  
1. The paper suffers from clarity issues, making it difficult to understand the algorithms and verify claims. Specific definitions and notations are often ambiguous or poorly presented.  
2. The novelty of the contributions is questionable, as many ideas appear to be modifications of existing methods.  
3. The experimental validation is limited to small 1-dimensional datasets, lacking broader applicability.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their definitions and notations throughout the paper, particularly in section 2.2, to avoid ambiguity. It would be beneficial to include illustrations or additional explanations to enhance the understanding of the algorithms. We suggest providing a more explicit comparison with previous work to clarify what aspects of the algorithms are novel. Additionally, expanding the experimental validation to include higher-dimensional datasets and real-world applications would strengthen the paper's contributions.