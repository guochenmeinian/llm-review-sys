ID: nJKfNiEBvq
Title: Learning the Latent Causal Structure for Modeling Label Noise
Conference: NeurIPS
Year: 2024
Number of Reviews: 22
Original Ratings: 5, 3, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an approach to learning with noisy labels by addressing the limitations of traditional noise-labeled learning methods that rely on noise transition matrices. The authors propose learning the latent causal structure governing the generative process of noisy data to estimate these matrices more effectively. They identify critical oversights in existing generative methods, such as the assumption that an instance directly causes noisy labels and the independence of latent variables. A novel structural causal model is constructed, integrating semi-supervised learning techniques and masks to select essential causal factors for generating instances and noisy labels. The approach reportedly achieves state-of-the-art results on both synthetic and real-world datasets, with notable accuracy improvements over existing methods.

### Strengths and Weaknesses
Strengths:
1. The assumption of dependency relationships among latent variables in the structural causal model is novel and convincingly analyzed.
2. The theoretical analysis of the identifiability of latent variables is reasonable.
3. The proposed causal model effectively captures latent relationships, enhancing the realism of the noise generation process.
4. The experimental design is comprehensive, demonstrating the effectiveness of the proposed methods across various benchmarks, particularly on complex datasets.

Weaknesses:
1. The structural causal model's labeling process is flawed; it inaccurately posits that the clean label is the sole cause of the noisy label, failing to account for instance-dependent noise.
2. The reliance on the small-loss criterion and clean samples in the CSGN method is problematic.
3. Some reviewers express skepticism regarding the utility of the proposed method, citing a lack of significant performance improvement over baselines.
4. The experimental section lacks ablation studies, and the baselines used are outdated, missing recent methods like NPC and SOP.
5. Concerns are raised about the reproducibility of baseline results, with some methods performing worse than expected.
6. The motivation for learning the latent causal structure is not convincingly articulated, and the computational cost is high.
7. The empirical validation of the learned latent causal structure remains insufficient for some reviewers.

### Suggestions for Improvement
We recommend that the authors improve the structural causal model by clarifying the causal relationships, particularly addressing why the clean label is considered the cause of latent noise variables. Additionally, the authors should provide model performance metrics without using semi-supervised learning and include ablation studies to substantiate the effectiveness of their approach. Updating the experimental baselines to include more recent methods and providing a clearer motivation for the latent causal structure would enhance the paper's contribution. Furthermore, we recommend improving the empirical findings to demonstrate the optimization of the learned latent causal structure more convincingly, clarifying the reproducibility of baseline results, and addressing the performance gaps noted by reviewers. It may also be beneficial to provide further justification for the utility of the proposed method beyond performance metrics, perhaps by discussing its applicability in various real-world scenarios. Finally, addressing the computational limitations and clarifying the differences between classifiers in the warmup step would strengthen the overall presentation.