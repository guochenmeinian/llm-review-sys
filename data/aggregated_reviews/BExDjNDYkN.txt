ID: BExDjNDYkN
Title: HyP-NeRF: Learning Improved NeRF Priors using a HyperNetwork
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 4, 5, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents HyP-NeRF, a framework utilizing hypernetworks to learn category-level NeRF priors through conditioning on latent codes. The authors propose a novel approach that estimates multi-resolution hash encodings and network weights, addressing the generalization challenges faced by NeRF models. The framework shows significant performance improvements in downstream tasks, including single-view novel view generation and text-to-NeRF applications. Additionally, the paper provides a detailed analysis of the rendering process for NeRF, specifically focusing on the Denoise and Finetune steps, with a breakdown of rendering times for PixelNeRF, CodeNeRF, and HyP-NeRF. The authors note that while denoising yields marginal differences, the fine-tuning process shows significant improvements, particularly on the SRN car dataset due to its lower geometric diversity. They also acknowledge the need to better position their model within existing literature and to provide more comprehensive comparisons with current methods.

### Strengths and Weaknesses
Strengths:
- The authors introduce a novel method for conditioning network weights and multi-resolution hash encodings via hypernetworks, facilitating the sharing of prior knowledge among NeRF instances.
- HyP-NeRF effectively reduces overfitting by enabling the training of a single model for objects within the same category.
- The framework demonstrates versatility in various downstream tasks, showcasing its potential for broader applications.
- The authors provide a clear breakdown of rendering times, demonstrating the efficiency of HyP-NeRF.
- The analysis of the impact of denoising and fine-tuning on performance is well-articulated, particularly regarding dataset characteristics.

Weaknesses:
- The paper lacks sufficient discussion on the hypernetwork's ability to disentangle geometry and color, particularly in single-view reconstruction scenarios.
- Comparative analysis with a wider range of baselines and datasets is insufficient, limiting the credibility of performance claims.
- The computational cost of the hypernetwork and its impact on performance are not adequately addressed, raising concerns about efficiency.
- Readability issues and unclear statements regarding the hypernetwork's functionality and the denoising process detract from the overall clarity.
- The authors need to better contextualize their model within the existing literature.
- There is a lack of detailed comparisons with other methods, which could strengthen the paper's contributions.

### Suggestions for Improvement
We recommend that the authors improve the discussion on the hypernetwork's ability to disentangle geometry and color, particularly by providing evidence of category geometry and color clustering. Additionally, we suggest conducting more experiments with diverse baselines, such as Vision-NeRF and NeRFDiff, to validate HyP-NeRFâ€™s performance across different datasets. It would be beneficial to include ablation studies to explore the effectiveness of latent codes in capturing object shape and color. Furthermore, we encourage the authors to provide a detailed analysis of the computational costs associated with the hypernetwork, including the number of parameters and FLOPS, to clarify its efficiency compared to existing models. Lastly, we recommend that the authors improve the positioning of their model in the literature by providing a more thorough discussion of existing methods and including more detailed comparisons with these methods to enhance the paper's impact and clarity. Addressing readability issues and clarifying ambiguous statements will also enhance the paper's overall quality.