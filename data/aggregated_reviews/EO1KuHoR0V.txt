ID: EO1KuHoR0V
Title: AUDIT: Audio Editing by Following Instructions with Latent Diffusion Models
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 8, 4, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents AUDIT, an instruction-guided audio editing model based on latent diffusion models, trained on triplet data consisting of an instruction, input audio, and output audio. The model aims to modify only the necessary audio segments while preserving others, achieving state-of-the-art results across various editing tasks such as adding, dropping, replacement, inpainting, and super-resolution. The authors propose a framework for general-purpose text-based neural audio editing, which could serve as a foundation for future advancements in audio editing capabilities.

### Strengths and Weaknesses
Strengths:  
- AUDIT represents a significant advancement in audio editing by utilizing human text instructions, which is a relatively unexplored area in audio generation.  
- The data construction strategy, which involves paired text-audio data and refining instructions using templates and LLM, enhances the quality of instruction datasets.  
- The model outperforms several baselines, including SDEdit and its variants, in various editing tasks.

Weaknesses:  
- The claim of being “the first audio editing model based on human instructions” is misleading; it could be rephrased to reflect that it is the first to perform semantic audio editing from text-based prompts.  
- The evaluation of super-resolution lacks comparison with recent task-specific models, raising doubts about the advantages of using text prompts over dedicated models.  
- The paper does not clearly define the baseline models in Table 7, and the experimental study lacks reproducibility and comprehensive metrics compared to ground truth data.  
- The model's performance on real data and its robustness outside the training distribution remain unclear.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their claims regarding the novelty of their model by rephrasing the statement about being the first audio editing model based on human instructions. Additionally, the authors should provide a comparison of super-resolution results with recent task-specific models to substantiate their claims. Clarifying the baseline models in Table 7 and ensuring that the experimental study is reproducible by including comprehensive metrics compared to ground truth data would enhance the paper's rigor. Furthermore, we suggest conducting an ablation analysis for each component of the model and exploring its performance on out-of-domain data to assess robustness.