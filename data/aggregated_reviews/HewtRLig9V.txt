ID: HewtRLig9V
Title: Cabbage Sweeter than Cake? Analysing the Potential of Large Language Models for Learning Conceptual Spaces
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates whether large language models (LLMs) can recover taste properties of objects alongside their physical qualities. The authors find that GPT-3 and GPT-4 can reproduce human ratings on these properties with varying accuracy, although they perform worse than supervised baselines. The study also explores the encoding of conceptual spaces, particularly in the taste domain, and introduces a new dataset. The authors employ various prompting techniques to rank objects and report correlations with human judgments, with fine-tuned RoBERTa performing the best.

### Strengths and Weaknesses
Strengths:
- The paper demonstrates the capability of LLMs to learn semantic properties of objects.
- It provides valuable insights into which properties are easier or harder to learn, such as the difficulty of encoding bitterness compared to sweetness.
- The methodology for prompting models is rigorous, utilizing probabilities of completions and pairwise comparisons.
- The exploration of conceptual spaces is a novel and interesting direction.

Weaknesses:
- The findings may not convince skeptics of LLMs' ability to learn semantics.
- The authors do not clarify why LLMs succeed where smaller models fail.
- The experimental design raises concerns about the interpretation of results as evidence of conceptual space encoding.
- Some results, such as those in Table 1, lack adequate error analysis, and Table 2 is unclear.

### Suggestions for Improvement
We recommend that the authors improve the theoretical framing regarding conceptual spaces, ensuring clarity on how LLMs' representations relate to sensory primitives. To substantiate claims about the representations, consider using relational similarity analysis (RSA) to measure geometrical similarities between LLM spaces and conceptual spaces. Additionally, we suggest conducting a thorough error analysis for surprising results in Table 1 and clarifying the metrics in Table 2. Finally, we encourage the authors to verify the consistency of responses from GPT models and assess the quality of generated data in their baselines.