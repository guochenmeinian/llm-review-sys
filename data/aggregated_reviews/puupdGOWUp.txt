ID: puupdGOWUp
Title: GraphPatcher: Mitigating Degree Bias for Graph Neural Networks via Test-time Augmentation
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 5, 6, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents GraphPatcher, a test-time augmentation framework aimed at mitigating degree bias in Graph Neural Networks (GNNs). The authors identify that existing methods often degrade performance for high-degree nodes while attempting to enhance low-degree nodes. GraphPatcher introduces virtual nodes during testing to progressively improve low-degree nodes without sacrificing performance on high-degree nodes. The method is model-agnostic and demonstrates significant improvements across various benchmark datasets.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, facilitating reader comprehension of core ideas and detailed explanations.
- The motivation for GraphPatcher is robust, aiming to enhance overall performance without trade-offs.
- Empirical evaluations show statistically significant improvements, with a clear correlation between the number of patched virtual nodes and performance enhancements.

Weaknesses:
- The theoretical analysis, while logically sound, lacks relevance to the community's primary concern of reducing generalization risk in GNNs, potentially diminishing its perceived contribution.
- Experiments could be more comprehensive; including visually informative figures/tables and evaluating on heterophilic graphs would enhance clarity and depth. Additionally, assessing the efficiency of GraphPatcher is crucial due to its computational overhead.
- Concerns arise regarding the training time for GraphPatcher in a node-parallel manner, as well as the performance drop for high-degree nodes observed in certain datasets.

### Suggestions for Improvement
We recommend that the authors improve the theoretical analysis to better connect with the community's concerns regarding generalization risk. Additionally, enhancing the comprehensiveness of experiments by including more visually informative figures/tables and conducting evaluations on heterophilic graphs would provide a clearer understanding of GraphPatcher's effectiveness. It is also essential to evaluate the efficiency of GraphPatcher, considering the additional computational costs involved. Finally, addressing the training time and performance discrepancies in high-degree nodes would strengthen the paper's contributions.