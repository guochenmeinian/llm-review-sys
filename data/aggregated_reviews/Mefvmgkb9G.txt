ID: Mefvmgkb9G
Title: CAPSTONE: Curriculum Sampling for Dense Retrieval with Document Expansion
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the limitations of the dual-encoder architecture in dense retrieval systems, proposing CAPSTONE, which enhances document representation by expanding it with a real query. The authors introduce a novel curriculum sampling strategy to mitigate exploration bias during training by progressively introducing pseudo queries that improve the relevance between generated and real queries. The paper builds on the dual-cross-encoder architecture from Li et al. (2022) and aims to enable the document encoder to learn complex relations between queries and documents while maintaining reasonable inference times. Experimental results on datasets like MS MARCO and BEIR demonstrate the effectiveness of the proposed method.

### Strengths and Weaknesses
Strengths:
- The paper proposes an intuitive document expansion method that generates document-related queries.
- Experimental results indicate the proposed method effectively alleviates exploration bias and improves upon baseline training procedures.
- The approach is well-articulated, and the results show effectiveness over multiple datasets.

Weaknesses:
- The query generation process lacks clarity, and the authors do not provide sufficient detail on how synthetic queries are constructed.
- There are concerns regarding the statistical significance of results, particularly in comparison to the coCondenser baseline.
- The argument about retrieval time and the impact of generating multiple queries on latency is unclear.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the query generation process by providing more detailed explanations and examples in the main text rather than deferring to the appendix. Additionally, addressing the statistical significance of results, especially in relation to coCondenser, would strengthen the evaluation. The authors should clarify the implications of generating multiple queries on retrieval latency and ensure that the ROUGE implementation used is correctly noted, as discrepancies have been reported in recent literature. Finally, providing qualitative examples of synthetic queries across different relevance levels would enhance understanding of the curriculum learning process.