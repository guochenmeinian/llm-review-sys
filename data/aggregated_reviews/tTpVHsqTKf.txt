ID: tTpVHsqTKf
Title: SyncVIS: Synchronized Video Instance Segmentation
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 5, 5, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents SyncVIS, a method for video instance segmentation (VIS) that addresses the challenges of asynchronous designs by proposing synchronized modeling of frame and video queries. The authors introduce a synchronized embedding optimization strategy to enhance performance in long-range video analysis, achieving state-of-the-art results across multiple benchmarks, including YouTube-VIS 2019, 2021, 2022, and OVIS. The paper includes thorough ablation studies to validate the proposed method.

### Strengths and Weaknesses
Strengths:
- The paper is generally clear and well-structured, with comprehensive explanations and detailed analyses of prior research.
- SyncVIS demonstrates impressive performance improvements across various VIS benchmarks.
- The proposed architecture is intuitive and versatile, applicable to multiple existing VIS frameworks.

Weaknesses:
- The novelty of synchronized embedding optimization is limited, and comparisons with methods like DVIS++ and TCOVIS are lacking.
- The analysis primarily focuses on early works, with insufficient examination of the baselines used.
- Implementation details, such as training steps and compute resources, are inadequately reported, despite affirmative responses in the checklist.

### Suggestions for Improvement
We recommend that the authors improve the novelty aspect of synchronized embedding optimization by providing more comparative analysis with existing methods like DVIS++ and TCOVIS. Additionally, the authors should include more implementation details, such as specific training steps and the type of GPU used, to enhance transparency. Conducting an ablation study on different values of $N_{k}$ and clarifying how the method ensures that video queries learn motion information would also strengthen the paper. Lastly, we suggest including qualitative results to illustrate the improvements SyncVIS offers over base models trained in an asynchronous manner.