ID: 5TTV5IZnLL
Title: Variational Inference with Gaussian Score Matching
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 3, 7, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method for black-box variational inference (BBVI) based on score matching, termed Gaussian Score Matching VI (GSM-VI). The authors propose an iterative procedure that updates the variational approximation by matching the gradients of the log-densities of the approximation and the target distribution. The method is shown to converge significantly faster than traditional approaches, particularly for Gaussian target distributions, while also demonstrating limitations when the target deviates from Gaussianity. Additionally, the authors compare GSM-VI against Natural Gradient Descent Variational Inference (NGD-VI) using Stein's Lemma for estimating the expected Hessian. They acknowledge that while NGD-VI can be competitive with proper tuning, it is sensitive to parameter adjustments and does not scale well with increasing dimensions due to singular Hessian approximations. Empirical results indicate that GSM-VI consistently outperforms NGD-VI, particularly in higher dimensions.

### Strengths and Weaknesses
Strengths:
- The proposed method is original and offers a clear and effective approach to variational inference, particularly in the Gaussian case.
- The paper is well-structured and easy to follow, with a clear communication of ideas and results.
- Empirical evaluations indicate that GSM-VI outperforms BBVI and NGD-VI in terms of convergence speed and efficiency across various datasets.
- The authors provide a detailed code implementation that allows for reproducibility of experiments.
- The paper introduces novel ideas and demonstrates that GSM-VI can outperform NGD-VI in various scenarios, especially with larger dimensions.

Weaknesses:
- The analysis is primarily focused on Gaussian variational approximations, lacking exploration of other approximation methods or a deeper theoretical framework.
- The paper does not adequately address the oscillatory behavior observed in experiments, nor does it provide a comprehensive explanation for the empirical results.
- Important related works on natural gradient methods are not discussed, which could provide context for the performance of GSM-VI.
- The choice of using VOGN for estimating the expected Hessian is criticized as suboptimal, as it yields biased estimates.
- The empirical performance claims of GSM-VI compared to strong baselines are considered overstated, requiring more precise articulation.

### Suggestions for Improvement
We recommend that the authors improve the theoretical analysis of the method, particularly in settings where the target distribution cannot be perfectly approximated. It would be beneficial to explore convergence conditions and clarify the criteria fulfilled by the learned approximation. Additionally, we suggest including comparisons with relevant methods, such as those based on natural gradients, to contextualize the performance of GSM-VI. Addressing the oscillatory behavior in the experiments and providing explanations for the empirical results would enhance the paper's robustness. We also recommend improving the experiment section by including results from NGD-VI, both from their implementation and the gmmvi package, to provide a comprehensive comparison. Furthermore, we suggest that the authors make their claims regarding empirical performance more precise, ensuring that limitations are well-discussed. Lastly, it would be beneficial to explore the impact of different batch sizes on performance, as larger batch sizes may enhance stability and efficiency.