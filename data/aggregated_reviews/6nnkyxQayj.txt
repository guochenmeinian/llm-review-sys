ID: 6nnkyxQayj
Title: On the Feasibility of Simple Transformer for Dynamic Graph Modeling
Conference: ACM
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel strategy for tokenizing dynamic graphs tailored for Transformer-based architectures, introducing a method called SimpleDyG. The proposed approach effectively captures temporal evolution patterns and outperforms existing representation learning methods for dynamic graphs without requiring complex architectures or heavy computation. The authors reconceptualize dynamic graphs as sequence modeling challenges and support their methodology with experiments across various datasets.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, with clear explanations and illustrative figures that enhance comprehension.
- SimpleDyG is a straightforward yet effective approach that utilizes the self-attention mechanism of Transformers to address long-range dependencies in dynamic graphs.

Weaknesses:
- The proposed method only supports incremental settings and lacks the capability to handle link deletions.
- The experimental evaluation is insufficient, with a need for more datasets and missing important dynamic GNN baselines.
- The authors should clarify the rationale behind the Hepth dataset's characterization as an inductive scenario and provide insights into the temporal characteristics of the datasets used.

### Suggestions for Improvement
We recommend that the authors improve the model by enabling support for link deletion operations. Additionally, the authors should conduct a time complexity analysis and include corresponding time efficiency experiments. It would be beneficial to add more recent baselines and perform ablation studies to strengthen the experimental evaluation. Furthermore, clarifying the superscript in Equation (8) and addressing the typo regarding Figure 3.1 would enhance the paper's clarity. Lastly, providing detailed statistics about the temporal patterns in each dataset would offer deeper insights into the model's performance under varying temporal dynamics.