ID: c3OZBJpN7M
Title: FedGMKD: An Efficient Prototype Federated Learning Framework through Knowledge Distillation and Discrepancy-Aware Aggregation
Conference: NeurIPS
Year: 2024
Number of Reviews: 21
Original Ratings: 6, 8, 3, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents FedGMKD, a federated learning framework that addresses data heterogeneity through the integration of Cluster Knowledge Fusion (CKF) and Differential Aggregation Technique (DAT). CKF utilizes Gaussian Mixture Model (GMM) clustering to generate prototype features and soft predictions, enabling effective local model training without public datasets. DAT optimizes the aggregation process by considering distinct feature distributions, enhancing both efficiency and performance. Comprehensive experiments on benchmark datasets (SVHN, CIFAR-10, and CIFAR-100) demonstrate that FedGMKD achieves superior results in personalized and global model accuracy compared to traditional federated learning methods. Additionally, the authors discuss the issue of data distribution heterogeneity in Federated Learning (FL), particularly focusing on the use of LDA distributions. They clarify that many cited works do not utilize LDA distributions or differ significantly in their experimental settings compared to their approach, emphasizing the importance of client participation ratios and selection methods. Their results reportedly outperform those of referenced studies when all clients participate, even with fewer epochs.

### Strengths and Weaknesses
Strengths:
- The innovative integration of CKF and DAT effectively addresses data heterogeneity in federated learning.
- The use of GMM clustering for prototype features marks a significant advancement in handling diverse data distributions without public datasets.
- The theoretical analysis provides strong mathematical guarantees for convergence and performance, enhancing the framework's credibility.
- Extensive experimental evaluation shows that FedGMKD outperforms existing methods, underscoring its practical effectiveness.
- The authors provide a detailed analysis of the cited literature, clarifying misconceptions regarding the use of LDA versus Dirichlet distributions.
- They highlight the distinctiveness of their experimental setup and results, emphasizing the impact of parameters like client participation and epoch settings on model performance.

Weaknesses:
- The paper lacks comparisons against architectures like FjORD, which effectively handle model heterogeneity.
- The experiments primarily utilize a narrow range of hyperparameter settings, limiting the understanding of the framework's robustness.
- Insufficient justification is provided for choosing GMM over other clustering methods.
- The organization and presentation of the paper require improvement for clarity, and necessary citations in the convergence analysis are missing.
- The authors do not conduct direct comparisons with the referenced works due to constraints, which limits the validation of their claims.
- There is a lack of clarity on why specific comparisons with certain algorithms are prioritized over others that may also address data heterogeneity.

### Suggestions for Improvement
We recommend that the authors improve the comparison of FedGMKD against architectures like FjORD to better illustrate its advantages in handling model heterogeneity. Additionally, exploring a wider range of hyperparameters, such as α and β in the local loss function, would provide a more comprehensive understanding of the framework's robustness and sensitivity. The authors should also elaborate on the rationale for selecting GMM for obtaining prototype features over other clustering methods. Furthermore, we suggest that the authors consider conducting experiments under identical settings with the referenced works to substantiate their claims regarding performance. Lastly, enhancing the organization and clarity of the paper, improving the quality of figures, and ensuring proper citations in the convergence analysis will significantly strengthen the manuscript. Addressing the practical implications of their findings in real-world scenarios could also enhance the relevance of their research.