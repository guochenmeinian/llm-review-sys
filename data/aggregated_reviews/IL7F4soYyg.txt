ID: IL7F4soYyg
Title: CellPLM: Pre-training of Cell Language Model Beyond Single Cells
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 5, 5, 4, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel pre-training strategy, CellPLM, that treats cells as tokens and tissues as sentences, leveraging spatially-resolved transcriptomic data to encode cell-cell relations. The proposed model achieves state-of-the-art performance across various downstream tasks, including scRNA-seq denoising, SRT imputation, and perturbation prediction, outperforming state-of-the-art non-pretrained models. The authors introduce a Gaussian mixture prior to address data limitations and validate their approach through extensive experiments. Additionally, CellPLM's unique methodology, combined with a lightweight gene expression embedder, results in a training and inference throughput over ten times greater than other pretrained models.

### Strengths and Weaknesses
Strengths:
- The approach of using cells as tokens and tissues as sentences is biologically meaningful, reflecting the lack of sequential relationships among genes.
- Significant empirical results across multiple tasks confirm CellPLM's contributions and its innovative use of spatial information from SRT data enhances the model's input.
- Efficient computational performance, with a training time of only 20 seconds per epoch compared to over 3600 seconds for other models, demonstrates the model's practicality.
- The authors provide reproducibility through accessible code and present a well-organized and clear exposition of their methodology.

Weaknesses:
- Full fine-tuning is required for downstream tasks, which contradicts the premise of pre-trained models that should allow for easier adaptation by tuning only task-specific layers, raising concerns about resource requirements and performance attribution.
- The absence of comparisons between pre-trained and non-pre-trained models, as well as the performance of fine-tuning task-specific layers, limits the understanding of the pre-training's impact.
- Key tasks like cell-type classification, which are critical for benchmarking, are not evaluated, leaving a gap in the experimental validation.
- The statistical significance analysis could be enhanced by considering multiple testing corrections and alternative statistical tests.
- Limited benchmarking datasets for cell-type classification tasks.

### Suggestions for Improvement
We recommend that the authors improve clarity in the descriptions of the pre-training process and its technical details, as this is crucial for understanding cell-data characteristics and for reproducibility. Additionally, the authors should compare the performance of models with and without pre-training, as well as the effects of fine-tuning task-specific layers, to elucidate the benefits of their approach. We also suggest including cell-type classification in the evaluation to provide a more comprehensive benchmark of the proposed method's capabilities. Finally, we recommend enhancing the statistical analysis by incorporating multiple testing corrections, such as Bonferroni correction, and considering the use of ANOVA or the Kruskal-Wallis H test for performance comparisons. Furthermore, adding more datasets to benchmark the performance on cell-type classification tasks would be essential for evaluating the proposed method's capabilities.