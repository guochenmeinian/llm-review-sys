ID: i913TUOvTK
Title: Cinematic Mindscapes: High-quality Video Reconstruction from Brain Activity
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 6, 3, 6, 8, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method called MinD-Video for reconstructing high-quality videos from brain activity using continuous fMRI data. The authors propose a novel model that learns spatiotemporal information through masked brain modeling, multimodal contrastive learning with spatiotemporal attention, and co-training with an augmented Stable Diffusion model. The results are evaluated using semantic and pixel metrics at both video and frame levels.

### Strengths and Weaknesses
Strengths:
1. The approach innovatively combines self-supervised learning, contrastive alignment, and conditional video generation, demonstrating significant improvements over existing methods.
2. The authors provide both quantitative and qualitative results, including interpretable visualizations, which enhance the understanding of the model's performance.
3. The methodology offers interpretability, crucial for medical applications, and the experimental evaluation shows superior performance compared to previous works.

Weaknesses:
1. The novelty of the work is limited as it heavily relies on existing techniques, leading to a lack of a central focus in its technical contributions.
2. The generated videos often lack pixel-level controllability and show inconsistencies in style and semantics compared to ground truth, raising concerns about the reliability of the results.
3. The dataset used for training is limited to three subjects, which may affect the generalizability of the findings.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the manuscript by emphasizing the central contributions and addressing the limitations of novelty in their approach. Additionally, we suggest enhancing the ablation studies to better highlight the impact of various components of the model. It would also be beneficial to provide more detailed discussions on the failure cases of generated videos and to explore the potential for improving pixel-level controllability in future iterations. Finally, expanding the dataset to include more subjects could enhance the generalizability of the results.