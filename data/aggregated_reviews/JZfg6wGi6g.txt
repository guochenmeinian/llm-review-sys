ID: JZfg6wGi6g
Title: Scissorhands: Exploiting the Persistence of Importance Hypothesis for LLM KV Cache Compression at Test Time
Conference: NeurIPS
Year: 2023
Number of Reviews: 15
Original Ratings: 7, 7, 5, 3, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 3, 5, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for reducing the memory requirement of inference for large autoregressive language models by leveraging the Persistence of Importance Hypothesis. The authors propose retaining only 'pivotal tokens'—those with high attention scores—thereby compressing the KV cache size during inference by up to 5x. The empirical results indicate that this method does not significantly compromise model performance, although the evaluation lacks comprehensive benchmarks on generative datasets.

### Strengths and Weaknesses
Strengths:
- The paper addresses the critical issue of high memory costs associated with KV caches in autoregressive generative models.
- The observation of persistent attention patterns is original and provides new insights into self-attention mechanisms.
- The experimental validation is robust, demonstrating practical utility across different model scales and tasks.

Weaknesses:
- The exposition requires improvement, particularly in justifying claims about memory reduction and performance maintenance across various tasks.
- Insufficient baseline comparisons and evaluation on generative datasets raise concerns about the generalizability of results.
- Some design choices, such as the threshold for pivotal token selection, appear arbitrary and need further justification.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the exposition, particularly regarding the claims of memory reduction and performance maintenance. Specifically, provide detailed evaluations on generative datasets to substantiate the assertion of no loss in accuracy. Additionally, consider including more baseline comparisons, such as using multi-query attention (MQA) as a reference point. We suggest exploring alternative methods for pivotal token selection, such as adaptive thresholds or non-context-based selection, to enhance the robustness of the approach. Finally, addressing the potential limitations of the method through adversarial evaluations would provide a more comprehensive understanding of its performance boundaries.