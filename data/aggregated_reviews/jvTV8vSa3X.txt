ID: jvTV8vSa3X
Title: Text-guided 3D Human Generation from 2D Collections
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for generating 3D human body models from fashion descriptions, addressing challenges in previous studies such as unclear rendering and the need for multi-view videos. The authors propose a technique that utilizes 2D collections for training and enhances efficiency by extracting fashion semantics from text and integrating them with 3D rendering through cross-modal attention. The paper introduces a new task in vision-and-language research, demonstrating improved performance metrics and reduced inference time.

### Strengths and Weaknesses
Strengths:
- Achieves faster execution and high-quality 3D human model generation compared to conventional methods.
- Reduces inference time from over 100 seconds to less than one second, saving GPU memory and broadening accessibility.
- The proposed text-based control is effective, and the approach shows promise in motion generation.

Weaknesses:
- The automatic evaluation criteria may not adequately measure the quality of generated models, necessitating further discussion.
- The compositional 3D human rendering lacks identity information, potentially affecting robustness.
- The novelty of using cross-modal attention is questioned, as it is already prevalent in diffusion models.
- The writing quality, including mathematical notations, requires improvement for better readability.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the automatic evaluation criteria and discuss their effectiveness in measuring model quality. Additionally, addressing the lack of identity information in the compositional rendering could enhance robustness. We suggest providing a more detailed network architecture figure to aid understanding and revising mathematical notations for better readability. Finally, the authors should clarify the rationale for limiting text guidance to fashion descriptions, considering the relevance of image conditioning in this context.