ID: CswEebv5Hn
Title: Imitation Learning from Vague Feedback
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 6, 5, 9, 5, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 2, 5, 3, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to Imitation Learning (IL) from imperfect demonstrations characterized by vague pairwise comparisons, termed Vaguely Pairwise Imitation Learning (VPIL). The authors assume the availability of a competent annotator who may mislabel expert and non-expert samples. They propose two methods: one for scenarios with a known expert ratio and another for unknown ratios, utilizing risk rewriting and mixture proportion estimation. Additionally, the paper explores overestimation and underestimation methods in the context of expert ratio estimation using the BBE algorithm. The authors argue that while both methods can achieve high precision with large datasets, the overestimation method is significantly influenced by non-expert data when the expert ratio is low. The performance of these methods is evaluated through experiments on various Mujoco tasks, demonstrating superior results compared to standard and preference-based IL methods, supported by empirical results and theoretical insights.

### Strengths and Weaknesses
Strengths:
- Novel Approach: The paper introduces a unique method for estimating expert occupancy measures from imperfect preferences, addressing significant challenges in imitation learning.
- Theoretical Foundation: The proposed algorithms are backed by solid theoretical analyses and proofs, enhancing their credibility.
- Strong Experimental Results: The methods consistently outperform existing IL approaches across multiple Mujoco environments, showcasing their practical relevance.
- Transparency: The inclusion of full results and source code enhances the submission's transparency and robustness.
- Complementary Analyses: The empirical and theoretical analyses provide valuable insights into the algorithm's performance.

Weaknesses:
- Overestimation Concerns: The results in Figures 3a, b, and Appendix Figure 1a-h suggest potential overestimation issues, raising doubts about code implementation.
- Inconsistent Results: Table 1 presents inconsistencies, particularly with the HalfCheetah and Hopper tasks, which lack specific results.
- GAIL_expert Evaluation Issues: The evaluation of GAIL_expert is conducted separately for different alpha values, despite its independence from alpha, and the number of random seeds (5) may be insufficient.
- Unclear Advantages of COMPILER-E: The reasons for COMPILER-E's superior performance over COMPILER are not adequately explained.
- Limited Experiment Scope: The evaluation is confined to Mujoco environments, with no discussion on applicability to real-world tasks.
- Missing Hyperparameters: Key hyperparameters for baseline methods are not disclosed, affecting transparency.
- Proof Readability: The proofs are compact and difficult to follow, necessitating clearer explanations.
- Clarity Issues: The explanation of the "1-quantity" relationship and the inverse transposition of heatmaps lacks clarity, leading to potential confusion.
- Typos and Style Issues: The manuscript contains several typographical errors and redundancies that detract from clarity.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the proofs by providing additional steps and explanations to enhance readability. Addressing the suspected overestimation issues in the results and ensuring the accuracy of Table 1 is crucial. We suggest that the authors clarify the advantages of COMPILER-E over COMPILER and consider expanding the experimental scope to include real-world tasks. Increasing the number of seeds beyond 5 would enhance the reliability of their results, despite their justification for the current approach. Providing the code and detailed hyperparameters for baseline methods would enhance reproducibility. Additionally, we encourage the authors to include a limitations section discussing the assumptions made regarding the annotator's behavior and the potential biases in real-world scenarios. Finally, a thorough proofreading to correct typos and improve the overall writing style is essential.