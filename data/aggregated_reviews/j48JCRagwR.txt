ID: j48JCRagwR
Title: Improving Contrastive Learning of Sentence Embeddings with Focal InfoNCE
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel Focal-InfoNCE loss function aimed at enhancing SimCSE by emphasizing hard negative examples in unsupervised contrastive learning. The authors demonstrate that incorporating this loss improves performance across various semantic similarity tasks compared to existing baselines, including SimCSE. The method is compatible with multiple contrastive learning systems and does not require external semantic resources.

### Strengths and Weaknesses
Strengths:
- The approach is intuitive, with a simple modification leading to improved results.
- The paper addresses an important problem by enhancing a widely used model.
- There is good quantitative analysis on system performance and hyperparameter tuning.

Weaknesses:
- The reported performance improvements appear modest and lack statistical significance analysis.
- The authors did not conduct qualitative analysis, limiting insights into the practical implications of their method.
- The implementation's availability is unclear, which raises concerns about reproducibility.

### Suggestions for Improvement
We recommend that the authors improve their analysis by conducting statistical significance tests to confirm performance increases. Additionally, we suggest including qualitative analysis to provide insights into the types of negative pairs that Focal-InfoNCE identifies as hard. Clarifying whether the implementation will be publicly available is also essential for reproducibility. Lastly, addressing the presentation issues, such as consistent terminology and clearer graphical representations, would enhance the paper's clarity.