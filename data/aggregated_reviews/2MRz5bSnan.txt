ID: 2MRz5bSnan
Title: Permutation Decision Trees using Structural Impurity
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 2, 3, 2, 4, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 5, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the permutation decision trees method, utilizing Effort-To-Compress (ETC) as the impurity measure to model order dependencies in data instances. The authors extend this method to a variant of random forest, termed the permutation decision forest, and conduct experiments comparing its performance against traditional random forests. The paper aims to address datasets with temporal order, proposing that the permutation of data can yield diverse decision trees without the need for bagging.

### Strengths and Weaknesses
Strengths:
- The proposed structural impurity measure effectively captures order dependencies, as evidenced by examples in Table 1.
- The use of ETC as an impurity measure is innovative and potentially well-suited for temporal datasets, providing a new avenue for constructing diverse trees.

Weaknesses:
- The paper lacks clarity in defining its problem setup, particularly regarding its focus on time series data versus multi-class classification in an i.i.d. setting.
- Notation inconsistencies are present, with different symbols used for features across tables and figures.
- The experimental setup is unfair, with varying hyperparameters across datasets and a lack of statistical significance in results. The comparison between random forests and permutation decision forests is flawed, as the latter uses more trees.
- The experimental evaluation is weak, with insufficient metrics beyond F1-score and no comparison of single tree performances.
- A formal mathematical explanation of the ETC measure and its implications for the proposed methodology is missing, along with a dedicated related work section.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the problem setup, explicitly stating the types of tasks being addressed. Additionally, we suggest standardizing notation throughout the paper to avoid confusion. The experimental design should be revised to ensure fairness, with consistent hyperparameters and a broader range of evaluation metrics, including misclassification loss. We also encourage the authors to provide a formal mathematical characterization of the dependencies they claim to address and to include a thorough related work section to contextualize their contributions. Finally, a more robust experimental protocol, including cross-validation and multiple train/test splits, should be implemented to validate the proposed methods effectively.