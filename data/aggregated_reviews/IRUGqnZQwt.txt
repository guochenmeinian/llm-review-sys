ID: IRUGqnZQwt
Title: Diversifying language models for lesser-studied languages and language-usage contexts: A case of second language Korean
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on morpheme POS tagging and parsing for L2 Korean speakers, concluding that models trained on L2 data can outperform those trained on L1 data in the same domain. It also finds that cleaned training sets of L2 speakers yield better results than larger original datasets, and performance is not bidirectional when tested on unseen L2 data from different domains. The study emphasizes the importance of data quality and the specificities of L2 Korean compared to L1 Korean.

### Strengths and Weaknesses
Strengths:  
- The paper offers a complete and exhaustive experimental setup with extensive experiments and detailed discussions.  
- It provides in-depth data treatment, including analysis and cleaning, and the authors plan to share the cleaning script, facilitating future research.  
- The results challenge the assumption that more data always leads to better performance, which is significant for developing L2 Korean data.

Weaknesses:  
- The motivation for choosing L2 Korean remains unclear, lacking examples or statistics to illustrate the differences between L1 and L2 data.  
- There is a lack of clarity regarding evaluation metrics, making results difficult to interpret.  
- Some claims appear unsupported, and the framing of the paper does not consistently align with its content, leading to confusion about its primary focus.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation behind selecting L2 Korean for their study, possibly by including relevant examples or statistics. Additionally, we suggest expanding on the ethical implications of their contributions, particularly regarding how their work may ameliorate research biases. The authors should also clarify evaluation metrics, ensuring definitions are explicit and consistent throughout the paper. It would be beneficial to add a "Discussion" section to articulate how findings can be generalized to low-resourced languages. Lastly, we advise revising titles and section headings for better alignment with content and improving the overall presentation for clarity.