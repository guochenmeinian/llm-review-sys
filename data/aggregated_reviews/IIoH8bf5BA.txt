ID: IIoH8bf5BA
Title: Piecewise deterministic generative models
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 7, 7, 6, 7, 7, -1, -1, -1
Original Confidences: 4, 5, 4, 3, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel generative model based on piecewise deterministic Markov processes (PDMPs), diverging from traditional diffusion-based models. The authors propose using PDMPs, specifically the Zig-Zag process (ZZP), Bouncy Particle Sampler (BPS), and Randomized Hamiltonian Monte Carlo (RHMC), as forward processes. They demonstrate that time-reversed PDMPs retain the PDMP structure and derive a total variation bound between the learned and true data distributions. The authors introduce a ratio matching objective for training and provide initial empirical results on simple toy datasets. Additionally, the authors effectively address reviewers' questions through a comprehensive rebuttal, proposing additional figures that clarify key aspects of the research.

### Strengths and Weaknesses
Strengths:  
- The introduction of PDMPs as a new class of generative models is original and offers a fresh perspective on generative modeling.  
- The paper provides a comprehensive theoretical framework, including the characterization of time reversals and error bounds, which demonstrates a deep understanding of the subject.  
- Initial numerical simulations support the potential efficacy of the proposed models.  
- The authors have successfully incorporated feedback into their revised paper, enhancing clarity and addressing previous doubts. The rebuttal figures (1 and 2) are well-explained and significantly strengthen the paper.

Weaknesses:  
- The paper lacks sufficient characterization of potential drawbacks, particularly regarding the computational cost associated with training high-dimensional data.  
- There is limited exploration of real-world applications and comparisons with existing generative models, which diminishes the perceived significance of the proposed approach.  
- The presentation could be improved, as some sections contain dense technical language that may hinder reader comprehension.  
- No specific weaknesses were identified in the reviews of the rebuttal.

### Suggestions for Improvement
We recommend that the authors improve the characterization of the computational challenges associated with the proposed method, particularly regarding the ratio matching for high-dimensional data. Additional discussions on the practical implications of PDMPs compared to existing models would enhance the paper's significance. We suggest including more empirical validation on complex datasets to demonstrate the applicability of the proposed models in real-world scenarios. Furthermore, we encourage the authors to clarify the presentation by simplifying dense mathematical notation and providing intuitive explanations or visual aids. Lastly, including a step-by-step guide or pseudocode for the training procedures in the appendix would aid practitioners in applying the proposed methods. Additionally, we recommend that the authors improve the clarity of any remaining complex sections to further enhance understanding for all readers.