ID: W4pIBQ7bAI
Title: MediQ: Question-Asking LLMs and a Benchmark for Reliable Interactive Clinical Reasoning
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 6, 7, 5, 7, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the MEDIQ framework, designed to simulate clinical interactions between doctors and patients through two agents: an expert system that asks questions and a patient system that responds. The framework aims to enhance diagnosis by proactively collecting information and includes an abstaining module to determine when to stop the conversation. Extensive experiments validate its design, although the evaluation primarily relies on outputs from ChatGPT and similar LLMs.

### Strengths and Weaknesses
Strengths:
1. The novel design of the expert and patient modules facilitates realistic medical conversations.
2. The expert agent's proactive information collection supports diagnostic decisions.
3. The extensive experimental evaluation demonstrates the effectiveness of the framework's components.

Weaknesses:
1. The reliance on ChatGPT for key algorithm components, such as the abstention module, limits reproducibility and transparency in results.
2. The evaluation lacks human performance metrics, making it difficult to assess effectiveness in realistic scenarios.
3. The dataset's reliance on LLMs for crafting medical Q&A limits validation against real clinical conversations.

### Suggestions for Improvement
We recommend that the authors improve the explainability of the abstention and rationale generation modules to enhance transparency. Additionally, incorporating a medical conversation dataset for evaluation would provide a more realistic context for the proposed model's performance. We also suggest comparing the framework's performance against specialized medical Q&A LLMs, such as MedPalm2, to better contextualize its effectiveness. Finally, we encourage the authors to clarify the paper's goals regarding whether it aims to evaluate other approaches or present a new abstention module.