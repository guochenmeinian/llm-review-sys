ID: dIVb5C0QFf
Title: MetaAligner: Towards Generalizable Multi-Objective Alignment of Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 15
Original Ratings: 7, 6, 6, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents *MetaAligner*, a policy-agnostic and retraining-free approach for multi-objective alignment of language models. The framework consists of three stages: data reorganization from multi-objective datasets, supervised model training (including warming up on a downsampled dataset, fine-tuning for equal-preference alignment, and contrastive training), and inference using prompting for unseen objectives. The authors report significant improvements across three commonly-used datasets and claim generalizability to unseen objectives.

### Strengths and Weaknesses
Strengths:
- The originality of the three-stage framework of *MetaAligner*.
- The paper is well-written and organized, with reader-friendly figures and tables.
- It is the first policy-agnostic and retraining-free multi-objective alignment approach, supported by extensive experiments comparing *MetaAligner* with other baselines.

Weaknesses:
- The framework's complexity lacks an ablation study on its components, such as the impact of discarding the $D_e$ dataset.
- Comparisons in Table 3 may be unfair due to *MetaAligner* using significantly more parameters than some baselines.
- The method does not accommodate varying user preferences, as it aligns to multiple objectives without introducing weights.
- The reorganization process is trivial, and the SFT training is a common practice, making the contribution appear marginal.
- The *MetaAligner* model is not lightweight, complicating deployment.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the distinction between *MetaAligner* and Aligner, particularly in the introduction. Additionally, we suggest including a more streamlined version of Figure 2 for better comprehension. The authors should enhance the ablation study section by adding comparative experiments with Aligner and clarifying how the effective correction dataset is generated. Furthermore, we advise conducting direct performance comparisons with prompt engineering-based aligners to strengthen the argument for *MetaAligner*'s advantages. Lastly, addressing the complexity of the framework and the deployment challenges associated with the model size would significantly enhance the paper's impact.