ID: Mwj57TcHWX
Title: DiffTORI: Differentiable Trajectory Optimization for Deep Reinforcement and Imitation Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 6, 5, 8, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DiffTOP, a model-based approach to reinforcement learning (RL) and behavior cloning (BC) that utilizes differentiable trajectory optimization to learn a cost function and dynamics model. DiffTOP addresses the objective mismatch issue found in prior methods like TD-MPC and is evaluated on 15 model-based RL tasks and 35 imitation learning tasks with high-dimensional observations. The authors propose using a conditional variational autoencoder (CVAE) for learning multimodal policies in BC.

### Strengths and Weaknesses
Strengths:
- The broad applicability of DiffTOP across various RL and BC tasks, from simple continuous control to complex object manipulation, is commendable.
- The paper is well-structured and easy to understand, with thorough experimental comparisons against state-of-the-art methods.
- Extensive experiments and ablation studies demonstrate the effectiveness of DiffTOP in addressing the objective mismatch problem.

Weaknesses:
- The paper lacks contextualization within the existing literature, particularly regarding recent advancements like TD-MPC2, which also addresses the objective mismatch issue.
- The novelty of the approach is questionable, as the integration of TD-MPC and differentiable trajectory optimization is not particularly innovative.
- The trajectory optimization solver used does not support constraint optimization, which may limit its practical application.

### Suggestions for Improvement
We recommend that the authors improve the literature review to include a more comprehensive discussion of related works, particularly TD-MPC2, to clarify the unique contributions of DiffTOP. Additionally, we suggest that the authors provide a clearer distinction between their method and existing approaches in the introduction, possibly through a dedicated section or diagram. Justifying design choices and including comparisons with advanced baselines in experiments would also strengthen the paper. Finally, addressing the high computational cost of trajectory optimization at test time and exploring alternative solvers could enhance the method's practicality.