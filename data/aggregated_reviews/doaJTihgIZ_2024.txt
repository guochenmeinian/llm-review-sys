ID: doaJTihgIZ
Title: Dynamics of Supervised and Reinforcement Learning in the Non-Linear Perceptron
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 7, 7, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 2, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a derivation of equations for gradient flow in a non-linear finite-dimensional perceptron, assuming multinormal data distribution, a small learning rate, and binary classification tasks. The authors develop equations for both supervised and reinforcement learning rules, exploring the effects of noise on learning time, anisotropy in input distributions, and continual learning. They validate their findings using a preprocessed MNIST dataset, extending their analysis beyond toy datasets.

### Strengths and Weaknesses
Strengths:  
The paper addresses a significant open question regarding the learning dynamics of non-linear neural networks. The mathematical derivations are sound, and the writing is clear, complemented by well-designed figures that enhance understanding. The authors effectively demonstrate the insights gained from their derivations and extend their experiments beyond simplistic datasets.

Weaknesses:  
The assumptions made in the study are quite strong and may not reflect practical scenarios, potentially equating the learning dynamics to those of a linear model. The novelty of the results is difficult to assess due to a lack of references to closely related works, particularly the need for comparison with Refinetti [5]. Additionally, the introduction oversimplifies the related work landscape, neglecting more complex non-linear dynamics. The preprocessing of the MNIST dataset raises questions about its adherence to the multinormal assumption.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by elaborating on the strong assumptions made, particularly regarding the covariance of weights and the implications for practical applicability. A clearer distinction between their work and that of Refinetti [5] should be provided. We suggest expanding the related works section to include more relevant literature on non-linear learning dynamics. Additionally, a more detailed explanation of the preprocessing of the MNIST dataset is necessary to clarify its alignment with the multinormal assumption. Finally, addressing the questions posed regarding the continuum limit and the derivation of moment equations would enhance the paper's rigor and accessibility.