ID: Xa3dVaolKo
Title: Pure Message Passing Can Estimate Common Neighbor for Link Prediction
Conference: NeurIPS
Year: 2024
Number of Reviews: 19
Original Ratings: 5, 8, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Message Passing Link Predictor (MPLP), a model designed to enhance link prediction by utilizing pure message passing to estimate structural similarities between nodes. The authors argue that MPLP can effectively count common neighbors and develop quasi-orthogonal vectors for this purpose. They introduce an advanced version, MPLP+, which simplifies the estimation of shortest path neighborhoods through multiple rounds of message passing. The paper also includes a proof sketch demonstrating that MPLP is more expressive than NCN, particularly due to its ability to enable weighted node counting through the Norm Scaling technique. The authors analyze rook's graphs, showing that MPLP can encode non-adjacent node pairs differently based on their distinct norms, while NCN fails to differentiate due to identical representations generated by the GNN encoder. Empirical results indicate that MPLP(+) outperforms NCN across various datasets, supporting its effectiveness for link prediction tasks. Additionally, the paper analyzes the GPU memory consumption of the MPLP+ model compared to a typical 2-layer GCN model, reporting that MPLP+ consumes more memory during training but less during inference.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and clearly articulates the motivation and methodology.
2. It addresses an important problem in link prediction, balancing expressivity and efficiency.
3. The proposed models are extensively evaluated across diverse datasets, showing promising results.
4. The theoretical demonstration of MPLP's expressiveness compared to NCN is compelling.
5. The paper provides a detailed comparison of GPU memory usage between MPLP+ and GCN, highlighting the efficiency of MPLP+ during inference.
6. The authors engage in a thoughtful discussion regarding the performance of MPLP+ relative to BUDDY and NCN.

Weaknesses:
1. The authors do not sufficiently explain the significant performance gap between MPLP and BUDDY, despite their similar methodologies.
2. The novelty of the paper is diminished by the similarities between MPLP and existing methods like BUDDY.
3. Some benchmark datasets are missing, which could provide a more comprehensive evaluation.
4. The experimental evaluation lacks training time comparisons and additional metrics beyond HITS@50.
5. Concerns remain regarding the novelty of techniques like Norm Scaling and Shortcut Removal, which are not original contributions.
6. The estimation quality of walks in MPLP+ raises questions, particularly regarding high variance and its implications for performance.
7. Concerns exist regarding the correctness of the proof related to Pairwise Orthogonality, affecting confidence in the assessment of the paper.

### Suggestions for Improvement
We recommend that the authors improve the clarity regarding the performance discrepancies between MPLP and BUDDY, specifically addressing why MPLP outperforms BUDDY despite their methodological similarities. Additionally, include MPLP+ in the experiments in Appendix F.1 to provide a clearer comparison of estimation quality. It would also be beneficial to discuss the efficiency differences between MPLP+ and BUDDY more explicitly in the paper. Furthermore, we suggest including results from benchmark datasets such as Cora, Citeseer, and Pubmed, and reporting training times and additional evaluation metrics like accuracy and AUC-ROC. We also recommend that the authors improve the clarity regarding the contributions of Norm Scaling and Shortcut Removal, emphasizing their role without overstating their novelty. A more detailed analysis of the estimation quality of walks, including comparisons to existing methods, would address concerns about high variance and its impact on performance. Lastly, we encourage the authors to clarify the theoretical properties of positional encodings and their relationship to common neighbor estimation, as well as improve the clarity and rigor of the proof concerning Pairwise Orthogonality. Exploring more memory-efficient implementations, such as storing node signatures on CPU memory and loading them into GPU memory as needed, could enhance the overall efficiency of MPLP+.