ID: Dq023aV4Ih
Title: Hallucination Mitigation in Natural Language Generation from Large-Scale Open-Domain Knowledge Graphs
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new dataset, GraphNarrative, aimed at enhancing graph-to-text generation models. The authors collected Wikipedia sentences and mapped corresponding entities in Freebase, grounding knowledge triples to these sentences through lexical matching. The dataset notably contains fewer star graphs compared to prior datasets. To address misalignment between graphs and sentences, the authors propose a sentence trimming method based on dependency graphs to find the shortest paths covering all entities from paired Freebase triples. Experiments with BART and T5 models demonstrate that finetuning on trimmed sentences improves output quality and reduces hallucinations.

### Strengths and Weaknesses
Strengths:
- The proposed dataset is substantial, containing over 8 million graph-sentence pairs, and addresses limitations of existing datasets by including diverse narrations and complex graph structures.
- The paper is well-structured, with thorough theoretical concepts and experimental details, and effectively measures the prevalence of hallucination in graph-to-text models.
- The sentence trimming method shows promise in mitigating hallucination, supported by both automatic and human evaluations.

Weaknesses:
- Generalization of the dataset is inadequately studied; no zero-shot results are provided, despite the dataset's size and diversity.
- The necessity of the sentence trimming method is not convincingly established, as it may lead to grammatical errors and unnatural sentences.
- The comparison with recent related studies is insufficient, lacking discussions on datasets like DART and models proposed by Ma et al.

### Suggestions for Improvement
We recommend that the authors improve the generalization analysis of GraphNarrative by including zero-shot results. Additionally, the authors should clarify the necessity of the sentence trimming method, possibly by experimenting with different training data sizes and considering discarding misaligned sentences. A more comprehensive comparison with recent studies, particularly regarding the DART dataset and other relevant models, would strengthen the paper. Finally, providing evaluation results with larger models, such as GPT-3.5, could offer insights into the effectiveness of the proposed trimming method across various model architectures.