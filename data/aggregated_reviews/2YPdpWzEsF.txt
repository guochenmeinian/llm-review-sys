ID: 2YPdpWzEsF
Title: Visual Anchors Are Strong Information Aggregators For Multimodal Large Language Model
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 6, 5, 4, 6, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 5, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents AcFormer, a novel vision-language connector designed to enhance the efficiency and accuracy of multimodal models. The method identifies visual anchors within Vision Transformers and employs a progressive search algorithm to utilize these anchors for effective information aggregation. The authors validate AcFormer through extensive experiments, demonstrating significant reductions in computational costs while maintaining or improving performance compared to existing methods like Q-Former and Perceiver Resampler.

### Strengths and Weaknesses
Strengths:
- AcFormer achieves approximately 2.3/1.7 times faster pretraining speed while retaining overall performance.
- The extensive ablation results substantiate the effectiveness of AcFormer.
- The writing is clear, and the experimental setup is well-structured, aiding reader comprehension.

Weaknesses:
- The main advantage of AcFormer appears to be its efficiency; however, only training time is reported, which may not be the primary bottleneck for developing LLaVA-1.5. Reporting inference time per token is encouraged for a more comprehensive evaluation.
- The motivation behind the use of visual anchors is not sufficiently clear, as similar phenomena have been observed in recent studies. Additional experiments are needed to elucidate the emergence of visual anchors.
- AcFormer selects visual tokens without considering the actual question, potentially leading to harmful token reduction when the question does not pertain to the image's major subject.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the Anchor Selector algorithm's description and its justification within the main paper, rather than relegating it to the appendix. Providing pseudocode could enhance understanding. Additionally, we suggest reporting the inference time per token to better justify the efficiency claims of AcFormer. Further experiments should be conducted to explore the reasons behind the emergence of visual anchors and their impact on performance, particularly in relation to the actual questions posed.