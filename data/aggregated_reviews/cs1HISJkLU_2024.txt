ID: cs1HISJkLU
Title: A Versatile Diffusion Transformer with Mixture of Noise Levels for Audiovisual Generation
Conference: NeurIPS
Year: 2024
Number of Reviews: 24
Original Ratings: 5, 5, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel diffusion model, the Audiovisual Diffusion Transformer (AVDiT) with Mixture of Noise Levels (MoNL), designed for generating audiovisual data across various conditional distributions. The model employs variable noise levels across modalities and time segments, allowing it to learn multiple conditional distributions simultaneously, including cross-modal conditioning and temporal dynamics. The theoretical foundation of MoNL demonstrates a superior generalization bound compared to unimodal learning, with an improvement factor of \(O(\sqrt{n})\). The empirical results indicate that AVDiT with MoNL outperforms existing baselines on multiple datasets, including Monologues, AIST++, and Landscape, by enhancing connectivity between audio and video modalities and adapting its focus more effectively.

### Strengths and Weaknesses
Strengths:
- The concept of using variable noise levels is innovative and enhances the model's flexibility in learning conditional distributions.
- MoNL effectively enhances connectivity between audio and video modalities, demonstrating superior performance in multimodal tasks.
- The method shows strong empirical performance, particularly in audiovisual inpainting and continuation tasks.
- The theoretical background provided strengthens the understanding of the method's foundations and its empirical contributions.
- The manuscript is well-structured and easy to comprehend.

Weaknesses:
- The novelty of the methodology is somewhat limited, as similar concepts have been previously explored in the literature. The authors should provide more theoretical justification for their approach.
- The theoretical novelty of the work is perceived as limited, with a need for deeper theoretical insights into how MoNL boosts connectivity.
- The majority of experiments rely on internal datasets, raising concerns about reproducibility. The authors are encouraged to include ablation studies on publicly available datasets.
- There are concerns regarding the validation of the model on publicly available datasets due to resource constraints.
- Some technical details, such as the criteria for selecting noise levels and the comparison with other methods, lack thorough explanation.

### Suggestions for Improvement
We recommend that the authors improve the theoretical foundation of their approach by providing rigorous support for the claim that learning a single mixture is more beneficial than training separate models for each modality. Additionally, we suggest that the authors provide a more rigorous analysis of how MoNL contributes to connectivity between modalities. Conducting experiments on publicly available datasets would enhance reproducibility and generalizability, and prioritizing validation on these datasets would improve the credibility of the results. Clarifying the criteria for noise level selection and addressing the fairness of comparisons with other architectures would also strengthen the paper. Finally, including a Vanilla strategy in ablation studies could provide insights into the model's performance under varying noise conditions, and making trained models and code available would significantly support the research community and facilitate future work.