ID: yBd2UREDNL
Title: MixTEA: Semi-supervised Entity Alignment with Mixture Teaching
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new method for semi-supervised entity alignment called MixTEA, which utilizes a Teacher-Student architecture. The authors propose a novel approach that combines manually labeled mappings with probabilistic pseudo mappings to address the challenges of noisy pseudo mappings and uncertainty in pseudo mapping learning. The paper includes extensive experiments demonstrating the method's effectiveness and provides a detailed ablation study.

### Strengths and Weaknesses
Strengths:  
- The paper addresses a challenging problem in entity alignment and is well-motivated and clearly written.  
- It introduces innovative strategies such as bi-directional voting (BDV) and matching diversity-based rectification (MDR) to enhance pseudo mapping quality.  
- The experimental results are promising, and the paper includes a thorough comparison with existing methods.

Weaknesses:  
- The theoretical justification for the BDV strategy and MDR module is lacking, and their effectiveness is not clearly demonstrated.  
- The motivation for the proposed methods is insufficiently articulated, and some mathematical notations are inaccurate.  
- The experimental setup lacks clarity regarding the use of additional unlabeled data and hyperparameter tuning, and the absence of standard deviations for baseline comparisons raises concerns.

### Suggestions for Improvement
We recommend that the authors improve the theoretical explanation of the BDV and MDR components to clarify their effectiveness. Additionally, the authors should provide more detailed empirical analyses to attribute improvements specifically to their proposed methods rather than general enhancements. It would be beneficial to include examples or analyses that demonstrate the gradual improvement of pseudo mappings during training. Furthermore, enhancing the clarity of the experimental setup and addressing the inaccuracies in mathematical notation would strengthen the paper. Lastly, we suggest discussing threshold tuning methods in more depth, as well as ensuring that all important algorithm components are adequately represented in the figures.