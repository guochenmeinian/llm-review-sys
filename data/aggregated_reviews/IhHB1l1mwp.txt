ID: IhHB1l1mwp
Title: Seq2seq is All You Need for Coreference Resolution
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a supervised method for entity coreference resolution using pre-trained sequence-to-sequence models, eliminating the need for task-specific components. The authors demonstrate that their approach, which linearizes the target sequence and utilizes special tokens for entity boundaries and cluster identities, achieves state-of-the-art results across multiple datasets, including OntoNotes. They provide extensive ablation studies to analyze the impact of various design decisions on performance.

### Strengths and Weaknesses
Strengths:
- The proposed method achieves competitive performance, surpassing existing models on key datasets.
- The writing is clear, and the methodology is well-structured, making the paper easy to follow.
- The paper includes a solid ablation study that explores the effects of different modeling decisions.

Weaknesses:
- The paper lacks a comprehensive comparison with prior work, particularly Bohnet et al. (2023), which also achieved state-of-the-art results.
- The error analysis is limited and does not provide sufficient insight into model performance.
- Some claims are overly strong, particularly regarding the non-task-specific nature of the proposed method.

### Suggestions for Improvement
We recommend that the authors improve the comparison with Bohnet et al. (2023) to clarify the distinctions between task-specific and non-task-specific approaches. Additionally, we suggest enhancing the error analysis to better understand the performance gaps between different model sizes. It would be beneficial to include a discussion section that organizes hypotheses regarding the effectiveness of the seq2seq approach. Furthermore, we encourage the authors to provide supplemental code to support their claims and consider adding a system architecture diagram to clarify the methodology. Lastly, addressing the alignment of input and output sequences in the context of post-processing would add valuable insight.