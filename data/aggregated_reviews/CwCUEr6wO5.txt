ID: CwCUEr6wO5
Title: Plan-on-Graph: Self-Correcting Adaptive Planning of Large Language Model on Knowledge Graphs
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 6, 5, 5, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Plan-on-Graph (PoG), a self-correcting adaptive planning paradigm for Knowledge Graph-augmented Large Language Models (KG-LLMs). PoG employs three mechanisms: Guidance for query decomposition, Memory for storing historical retrieval information, and Reflection for evaluating exploration paths. Experiments on three datasets demonstrate PoG's effectiveness and efficiency, outperforming state-of-the-art methods.

### Strengths and Weaknesses
Strengths:
- The design of the memory component, particularly the Sub-Objective Status, effectively reminds the LLM of known information and exploration progress.
- The experimental results indicate significant improvements over existing methods.
- PoG is training-free, making it suitable as a plug-and-play solution for evolving LLMs.
- The paper is well-presented, with clear explanations and visual aids that enhance understanding.

Weaknesses:
- Self-correction is limited to the retrieval process; if sub-queries are poorly decomposed, the final answer may not be correct.
- PoG requires multiple interactions with the LLM, leading to latency issues, particularly for real-time question answering.
- The novelty of PoG is questioned, as it appears to be a trivial adaptation of existing methods like Graph of Thoughts (GoT).
- The paper lacks sufficient analysis on why PoG outperforms baseline models and does not adequately compare with other recent RAG methods.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the differences between PoG and GoT to address concerns about novelty. Additionally, the authors should provide more detailed analyses of PoG's performance, including the impact of exploration depth and the efficiency of reasoning with large knowledge graphs. It would be beneficial to discuss the applicability of PoG to smaller open-source models and explore potential strategies for enhancing their performance. Finally, we suggest including explicit implementation details to clarify how the proposed mechanisms are integrated into the LLM prompts.