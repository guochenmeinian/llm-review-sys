ID: vh9yEPLeyD
Title: Can We Leave Deepfake Data Behind in Training Deepfake Detector?
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 4, 5, 4, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 5, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel training strategy for deepfake detection that utilizes real, blendfake, and deepfake datasets. The authors propose an Oriented Progressive Regularizer (OPR) and a feature bridging module to enhance the model's ability to extract forgery information, thereby improving generalizability. The experimental results indicate that this method surpasses current state-of-the-art (SOTA) approaches.

### Strengths and Weaknesses
Strengths:  
- The proposed method categorizes forgery faces into distinct types, encouraging robust learning of representative features.  
- The paper provides a fresh perspective on deepfake detection and is mostly well-written, with clear arguments and extensive evaluations.  
- The experiments demonstrate the effectiveness of the proposed design.

Weaknesses:  
- The rationale for the progressive transition from real to blendfake to deepfake is unclear, and the necessity of continuity in these features is not justified.  
- The claim that blendfake data alone is sufficient for training deepfake detectors lacks universal applicability and should be toned down.  
- The choice of blendfake algorithms is insufficiently discussed, and the paper does not adequately address the impact of using outdated datasets.  
- The lack of detailed experimental validation for the unorganized latent-space distribution raises concerns about the method's robustness.

### Suggestions for Improvement
We recommend that the authors improve the explanation of the rationale behind the feature bridging and transition design to clarify the necessity of continuity in features. Additionally, the authors should provide empirical support for the claim regarding blendfake data sufficiency and consider incorporating more recent deepfake datasets, such as WildDeepfake and DeepForensics-1.0, in their evaluations. To enhance the progressive transition, we suggest extending it to include compression or adversarial artifacts. Furthermore, the authors should clarify the choice of blendfake algorithms and explore the potential benefits of using multiple mixing parameters for interpolation. Lastly, addressing the latent-space distribution with comprehensive experimental validation is crucial for demonstrating the robustness of the proposed method.