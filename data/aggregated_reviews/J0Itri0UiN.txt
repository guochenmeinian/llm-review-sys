ID: J0Itri0UiN
Title: Counterfactual Fairness by Combining Factual and Counterfactual Predictions
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 7, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on counterfactual fairness (CF) in machine learning predictions, establishing a theoretical framework for the best possible fair predictor in a model-agnostic manner. The authors characterize the excess risk of the optimal predictor under CF constraints and propose a post-preprocessing algorithm to achieve CF with arbitrary ML predictors. Comprehensive numerical studies validate the proposed algorithm's performance against various baselines.

### Strengths and Weaknesses
Strengths:
- The theoretical analyses are technically sound and comprehensive.
- The paper is well-written and easy to follow, with clear presentation of results.
- The authors demonstrate that access to ground truth counterfactuals allows for strong fairness and accuracy, as shown in Theorems 3.3 and 3.4.

Weaknesses:
- The authors acknowledge limitations regarding access to ground truth counterfactuals and the Bayes optimal predictor, which may affect practical applicability.
- The experiments primarily consider one observed feature, raising concerns about the framework's practicality and real-world significance.
- The paper lacks comparisons with additional existing methods in numerical experiments, such as those by Wang et al. and Chen et al.

### Suggestions for Improvement
We recommend that the authors improve the practical applicability of their algorithm by incorporating existing counterfactual estimation procedures into Algorithm 1. Additionally, including more existing methods in the numerical experiments for comparison, such as the post-processing method by Wang et al. and the pre-processing method by Chen et al., would provide a clearer performance gap analysis. Furthermore, we suggest that the authors clarify the intuition behind the objective function for counterfactual risk minimization, particularly regarding the necessity of the second term, and explore the implications of their results in a multi-class setting.