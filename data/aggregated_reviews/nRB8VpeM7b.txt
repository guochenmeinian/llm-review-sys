ID: nRB8VpeM7b
Title: Pushdown Layers: Encoding Recursive Structure in Transformer Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a modification of the transformer architecture, termed $\lambda$-layers, aimed at modeling recursive syntax through a shift-reduce parsing mechanism. The model utilizes syntactic supervision during training to extract unlabeled, binarized parse trees. It tracks a stack of constituents and determines the depth of each input token, which is then integrated into the attention layer. The authors compare their method against baseline transformers and other recent architectures, demonstrating that $\lambda$-layers generally outperform baseline transformers in learning recursive syntax and are competitive with existing syntactically-supervised models.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant research question regarding the effective modification of transformers for recursive syntax learning.
- Experimental results show $\lambda$-layers' superior data efficiency and performance across various tasks, including better generalization on the Dyck language and improved parsing on the BLLIP dataset.

Weaknesses:
- The description of the model lacks precision, with vague terminology and assumptions that may not be universally accepted.
- The conclusions drawn from attention pattern analyses are not entirely convincing, and there is a need for clearer explanations of the model's mechanics and the implications of its design choices.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the model description in Section 3 by defining vague terms such as "attachment decision" and "recursive state." Additionally, we suggest providing a more detailed explanation of the shift-reduce operations and the grammar used. It would be beneficial to clarify the requirement for gold or "silver" trees, emphasizing that the model cannot be trained on unannotated text. We also encourage the authors to enhance the analysis of attention behaviors, particularly regarding the impact of stack tape embeddings on attention scores. Finally, addressing the questions raised about the model's mechanics and providing more detailed experimental setups would strengthen the paper.