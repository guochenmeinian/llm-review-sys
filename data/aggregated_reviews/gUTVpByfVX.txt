ID: gUTVpByfVX
Title: Diffusion-TTA: Test-time Adaptation of Discriminative Models via Generative Feedback
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 7, 6, 7, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Diffusion-TTA, a test-time adaptation method that updates pretrained image classifiers using generative diffusion models to maximize image likelihood. The authors demonstrate improved classification accuracy across various datasets, including ImageNet, by leveraging the output probabilities of the classifier to condition the diffusion model. The method shows significant performance improvements across various distribution shifts, particularly with larger models like ConvNext-Large. The authors provide standardized results comparing their method to TENT and CoTTA, showcasing its effectiveness, especially in scenarios with static, unsupervised data. Additionally, the paper reports on semantic segmentation results and insights regarding the model's finetuning capabilities. However, the method's computational complexity is a concern, as it is 2-3 orders of magnitude slower than TENT, raising questions about its practical applicability.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant challenge in deep learning: test-time out-of-distribution generalization.
- The combination of generative and discriminative models is innovative, particularly the modulation of text conditioning in the diffusion model.
- The experimental evaluation is thorough, showcasing the effectiveness of the proposed method and including rigorous ablation studies.
- The authors effectively address reviewer concerns and provide new empirical results.
- The method shows promise for offline TTA, adapting well to distribution shifts.
- Inclusion of semantic segmentation results enhances understanding of the method.

Weaknesses:
- The experimental results are difficult to interpret, particularly in comparison to existing methods like TENT and COTTA, raising concerns about the method's empirical advantages.
- The computational intensity of the method is a limitation, with adaptation taking approximately 55 seconds per image, which may hinder practical applications.
- The clarity of the introduction and the discussion on the differences between generative and discriminative models could be improved.
- The argument distinguishing this work from Li et al. [22] lacks convincing detail, particularly regarding the method's efficiency and lightweight requirements.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the experimental results by ensuring that baseline models are comparable in architecture and reporting their performance on the same networks as Diffusion-TTA. Additionally, please include confidence intervals and alternative metrics such as top-k accuracy and f-score to provide a more comprehensive evaluation. 

We suggest addressing the concerns regarding the computational overhead by conducting a complexity analysis that compares the method's efficiency with simpler TTA methods. Furthermore, we encourage the authors to clarify the implications of their findings on the memorization capabilities of diffusion models and their generalization to out-of-distribution data.

We also recommend that the authors improve the clarity of their distinctions from Li et al. [22], particularly emphasizing the versatility of their approach and the joint adaptation of diffusion and classifier weights. Additionally, we suggest elaborating on the specific settings where their method could be effectively utilized, considering its computational demands. Finally, ensure that all figures and tables are clearly readable and well-referenced in the text, and that all new insights and results are included in the main manuscript or appendix for comprehensive understanding.