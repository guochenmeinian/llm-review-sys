ID: fXEi3LVflp
Title: Referring Human Pose and Mask Estimation In the Wild
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 6, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a new task called Referring Human Pose and Mask Estimation (R-HPM) and introduces the RefHuman dataset, which includes over 50K annotated instances for 2D keypoints, masks, and prompts (text, points, or scribbles). The authors propose a model named UniPHD to perform R-HPM, demonstrating its effectiveness through experiments on the RefHuman dataset and MSCOCO.

### Strengths and Weaknesses
Strengths:
1. The proposed R-HPM task is useful and complements existing human pose and mask estimation tasks, providing new insights.
2. The RefHuman dataset is large and well-annotated, supporting future research in R-HPM.
3. The UniPHD model shows promising performance in both the new task and traditional human pose estimation tasks.

Weaknesses:
1. The definitions of point and scribble prompts are unclear, requiring a formal definition rather than a textual description.
2. There is confusion regarding the experimental setup, particularly the use of MSCOCO images without reference annotations and the evaluation configurations.
3. The motivation for the referring approach is not clearly articulated, and the multimodal encoder's capacity may be insufficient.
4. The evaluation metric (AP) is not suitable for R-HPM, as it should focus on single-instance metrics like PCKh@0.5.
5. The paper lacks comparisons with existing referring-based methods, which would help establish a comprehensive benchmark.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the definitions for point and scribble prompts by providing formal definitions. Additionally, clarify the experimental setup, particularly the use of MSCOCO images and the evaluation configurations. The authors should articulate the motivation for the referring approach more clearly and consider enhancing the multimodal encoder's capacity. We suggest adopting a more suitable evaluation metric for R-HPM, such as PCKh@0.5, and including comparisons with existing referring-based methods to establish a comprehensive benchmark.