ID: OHtjMJABg0
Title: Aegis: Post-Training Attribute Unlearning in Federated Recommender Systems against Attribute Inference Attacks
Conference: ACM
Year: 2024
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Aegis, a post-training federated unlearning framework aimed at protecting user privacy by removing sensitive attributes from embeddings in recommender systems. The authors propose a method that employs mutual information and Gaussian modeling to balance privacy and recommendation quality, even without access to training data. Evaluations demonstrate that Aegis effectively safeguards privacy while maintaining high-quality recommendations.

### Strengths and Weaknesses
Strengths:
- The research addresses a significant problem of attribute information leakage in data privacy, particularly in federated learning contexts.
- The methodology, which utilizes mutual information, is innovative and well-explained.
- The experiments conducted are sufficient in quantity, although they require more analysis for clarity.

Weaknesses:
- The introduction lacks clarity in connecting current privacy protection methods to the proposed solution, leading to confusion.
- The notation in Equations 7 and 8 is inconsistent and may cause misunderstandings.
- The methodology section lacks a derivation for the KL divergence upper bound and does not adequately explain how the mutual information objective is achieved.
- The generality of the Aegis framework is not validated in the evaluation, limiting its perceived versatility.
- The visualizations in Figure 2 do not clearly demonstrate significant differences before and after unlearning, particularly regarding occupational distribution.
- The paper does not include a theoretical complexity analysis, which would enhance understanding of the framework's computational efficiency.
- Concerns are raised regarding the assumptions made about user privacy dynamics and the practicality of the post-training approach.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the introduction by better connecting current privacy protection methods to their proposed solution. Additionally, the authors should address the dynamic nature of privacy protection in the model and experimental sections. It is essential to review and correct the notation in Equations 7 and 8 for clarity and consistency. The authors should provide a detailed derivation for the KL divergence upper bound in the Private Attributes Information Loss section and explain how the mutual information objective is achieved in the Recommendation Knowledge Retention Loss section. To validate the generality of the Aegis framework, we suggest conducting additional experiments or comparisons. Furthermore, the authors should enhance Figure 2's visualizations to clearly show differences before and after unlearning and clarify what is being visualized. Lastly, including a theoretical complexity analysis would provide valuable insights into the computational efficiency of the proposed framework.