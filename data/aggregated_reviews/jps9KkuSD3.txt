ID: jps9KkuSD3
Title: Sequential Harmful Shift Detection Without Labels
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 5, 6, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 1, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for detecting harmful distribution shifts in machine learning models without requiring access to ground truth labels during production. The authors propose an error estimator model that predicts error scores, enabling the identification of drifts that could negatively impact model performance. The method is evaluated against various synthetic and real-world datasets, demonstrating comparable performance to traditional label-based methods while effectively controlling false positives. Additionally, the authors introduce a calibration step and statistical tools to establish a warning threshold with provable false alarm guarantees, clarifying that their normalization process does not violate the independence assumptions of Hoeffding's Inequality. They specify the models used for evaluations, including ResNet-50 for image data and a Random Forest regressor/classifier for tabular data.

### Strengths and Weaknesses
Strengths:
- The introduction of a label-free solution is significant for practical applications where labeled data is scarce.
- The method's ability to detect shifts without target labels is a notable contribution.
- The method is algorithm-agnostic, enhancing its applicability across different contexts.
- Clear differentiation from existing approaches like DDM and PHT enhances understanding of the proposed approach.
- Detailed mathematical derivations are provided, contributing to the theoretical foundation of the approach.
- The authors' commitment to clarifying model details and assumptions strengthens reproducibility.
- The rigorous evaluation on multiple datasets supports the robustness of the proposed method.

Weaknesses:
- The paper lacks a comprehensive discussion on related work concerning distribution shifts and continuous production environments, which could clarify the motivation behind the proposed method.
- The error prediction function is limited to detecting shifts involving covariate distributions, potentially reducing its effectiveness for shifts in P_{Y|X}.
- The experimental section only compares the proposed method with a baseline, neglecting other existing distribution shift detection algorithms.
- Some claims regarding traditional drift detection methods are unfounded and could mislead readers.
- Potential introduction of interdependencies through normalization may raise concerns regarding Hoeffding's Inequality.
- The initial characterization of the calibration set as a weakness could be misleading without proper context.

### Suggestions for Improvement
We recommend that the authors improve the introduction by including a section on related work that discusses distribution shifts and continuous production environments, particularly referencing the Out-of-Distribution (OOD) field's research on Dataset Shift. Additionally, the authors should clarify how their method differs from existing works, such as those by Ginsberg et al., and provide comparisons with other covariate shift detection methods in the experiments. Furthermore, we suggest addressing the limitations of the error prediction function and ensuring that all claims regarding traditional methods are substantiated to avoid misinformation. We also recommend improving the discussion on the independence assumptions of Hoeffding's Inequality, specifically addressing the normalization process's potential impact. It would be beneficial to clarify the distinction between performance-based drift detectors that require labels and those that do not in the introduction. Lastly, explicitly stating the models used for evaluations earlier in the paper and providing access to the experimental scripts would enhance reproducibility.