ID: rbw9xCU6Ci
Title: Adaptive Test-Time Personalization for Federated Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 14
Original Ratings: 5, 5, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Adaptive Test-time Personalization (ATP) algorithm within the federated learning framework, addressing the challenges of adaptive test-time personalization in the presence of multiple target domain distributions. The authors propose a method to automatically determine which modules to adapt and the extent of adaptation required. The paper claims to be the first to introduce test-time personalized federated learning (TTPFL), although this assertion is contested by prior works. The authors emphasize the significance of adapting different layers of deep neural networks (DNNs) based on label and domain non-IID conditions.

### Strengths and Weaknesses
Strengths:
1. The experiments in Section 3.2 effectively illustrate the challenges faced by existing test-time adaptation (TTA) methods in federated learning, providing valuable insights for future improvements.
2. The proposed method is straightforward to implement and demonstrates impressive performance in the conducted experiments.

Weaknesses:
1. The claim of being the first to propose TTPFL is questionable, as previous research has explored similar concepts.
2. The significance of the “supervised refinement” step is unclear, particularly regarding the use of labeled data, which may undermine the TTA's challenge.
3. The datasets utilized in the experiments are small-scale and synthetic; larger, real-world datasets would enhance the credibility of the findings.
4. The paper lacks a thorough comparison with established federated learning methods and does not adequately address the relationship between TTPFL and existing TTA frameworks.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their claims regarding the novelty of TTPFL and provide a more comprehensive discussion on how their work differs from prior studies. Additionally, we suggest including ablation studies to assess the importance of the “supervised refinement” step and conducting experiments on larger, real-world datasets to strengthen the validity of their results. It would also be beneficial to compare the proposed method against established federated learning baselines and clarify the unique challenges posed by test-time shifts in federated settings. Finally, we encourage the authors to explore the adaptability of their method across various model architectures beyond convolutional networks.