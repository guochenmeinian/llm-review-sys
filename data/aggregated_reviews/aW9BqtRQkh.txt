ID: aW9BqtRQkh
Title: Language Models Can Improve Event Prediction by Few-Shot Abductive Reasoning
Conference: NeurIPS
Year: 2023
Number of Reviews: 24
Original Ratings: 6, 6, 6, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework that integrates large language models (LLMs) with traditional event sequence models to enhance event prediction. The authors propose a three-step process: 1) an event sequence model predicts potential events and their timestamps, 2) an LLM reasons about these events to retrieve relevant historical events, and 3) a reranking model scores the event candidates based on the retrieved events. The framework is evaluated on two datasets, GDELT and Amazon Review, demonstrating that the LLM-based reranking approach outperforms the naive event sequence model. Additionally, the authors introduce a method for event-based reasoning in natural language processing (NLP) that leverages the abductive reasoning capabilities of LLMs to identify possible causes for given goals, without requiring explicit rules. This method is compared to classical logical reasoning techniques, particularly backward chaining, and is shown to be effective in handling a large number of event types.

### Strengths and Weaknesses
Strengths:
1. The study addresses the significant topic of leveraging LLMs for temporal modeling, which has broad applications, such as political event forecasting.
2. The integration of LLMs with event sequence modeling is innovative and addresses a significant challenge in NLP.
3. Experiments on two datasets show a clear advantage for the LLM-based reranking method.
4. The authors have effectively responded to reviewer concerns, leading to improved clarity and presentation in the paper.
5. New experimental results demonstrate the method's robustness and potential applications across various event types.

Weaknesses:
1. The paper lacks substantial justification for its experimental design, particularly focusing predominantly on event type prediction while providing limited discussion on timestamp prediction. The authors should consider using a dataset that facilitates more thorough discussions on this task.
2. The evaluation on GDELT is not end-to-end, as it assumes one or two ground-truth components from each triplet, potentially leading to discrepancies between evaluation and real-world applications.
3. Limitations exist regarding the number of event types that can be effectively handled due to prompt size constraints.
4. Clarifications regarding dataset specifics are needed, such as the number of historical events considered for each prediction.
5. Results indicate that performance worsens as M increases, suggesting that the LLM-based reranker may struggle with more candidates. The paper does not adequately clarify the implications of varying M on the results.
6. The framework's reliance on the event sequence model raises concerns, as its poor performance appears to be a bottleneck, questioning the overall contribution of the LLM integration.
7. The paper does not explore alternative methods for using LLMs in reranking, such as employing SentenceBERT or BM25 for event retrieval before scoring.
8. Some writing lacks clarity and self-containment, particularly in mathematical formulations that are introduced without references or clear explanations.

### Suggestions for Improvement
We recommend that the authors improve the justification for their experimental design by providing a more balanced focus on both event type and timestamp predictions, potentially using a dataset that better supports this analysis. Additionally, the authors should clarify the evaluation methodology to ensure it aligns with realistic applications, addressing the end-to-end nature of the GDELT evaluation.

Further, we suggest that the authors provide more detailed explanations of the datasets used, including the number of historical events considered for predictions. The authors should also clarify the implications of varying M on performance results and consider exploring alternative methods for LLM integration in reranking.

We encourage the authors to enhance the clarity of their writing, particularly in sections involving mathematical formulations, by providing appropriate references and clearer explanations of the notations used. Additionally, we recommend improving the clarity of their contributions in the Abstract and Introduction, emphasizing the significance of event sequence modeling and the role of LLMs. It would be beneficial to provide a technical overview of the framework at the beginning of Section 3 and to include a discussion on classical logical reasoning methods. Finally, the authors should justify their experimental design and clarify the details of their experiments, including the interpretation of results, and consider including qualitative results and a discussion of limitations and future work to provide a comprehensive view of the research.