ID: RLJ8t01p0u
Title: Exploring the Promise and Limits of Real-Time Recurrent Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 17
Original Ratings: 7, 7, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 5, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates Realtime Recurrent Learning (RTRL) as an alternative to Backpropagation Through Time (BPTT) for training recurrent neural networks, specifically proposing an elementwise-LSTM (eLSTM) to reduce time and space complexity. The authors conduct experiments on reinforcement learning tasks using IMPALA and R2D2, demonstrating that while RTRL can match the performance of BPTT with long truncation lengths, it shows significant advantages with shorter lengths. The paper emphasizes the potential of RTRL for long-term dependencies in complex tasks. Additionally, it presents a comparison between full RTRL and Truncated Backpropagation Through Time (TBPTT), highlighting the need for a direct evaluation of these methods beyond toy tasks. The authors propose using element-wise recurrence in their experiments and reveal that "full RTRL with element-wise recurrence" outperforms "SnAp-1 with a fully recurrent neural network."

### Strengths and Weaknesses
Strengths:
- The authors present a forward-looking idea that addresses the limitations of BPTT in capturing long-term dependencies, which is crucial for human-level decision-making.
- The paper is well-written and clearly outlines its contributions, with extensive empirical evaluations across various benchmarks.
- The proposed method is elegant and well-explained, showing promising results in specific scenarios.
- The paper addresses a significant gap in the RTRL literature by comparing full RTRL and TBPTT directly.
- Additional experiments with SnAp-1 provide valuable insights into the performance of different architectures.

Weaknesses:
- There is a lack of empirical data demonstrating the time and space efficiency of RTRL, which is critical for validating its advantages over BPTT.
- The paper does not adequately clarify the equivalence of BPTT and RTRL in traditional RL scenarios, particularly regarding the impact of truncation.
- The empirical evaluation could be strengthened by including a broader range of truncation lengths and additional baselines, such as comparisons with LSTM and GRU architectures.
- The reviewers note that the experimental setup does not align with the baseline comparisons, particularly regarding the use of LSTM/GRU.
- There is a lack of clarity regarding the relevance of the ProcGen environments, which the authors chose not to include in their experiments.

### Suggestions for Improvement
We recommend that the authors improve the empirical evaluation by providing data on the practical wall-clock time and GPU memory usage of RTRL compared to BPTT. Additionally, it would be beneficial to clarify the equivalence of BPTT and RTRL in traditional RL setups and to conduct a mini-study examining a wider range of truncation lengths. Including comparisons with LSTM and GRU, as well as other approximations of RTRL, would enhance the robustness of the findings. We also suggest that the authors improve the clarity of their experimental setup by explicitly comparing LSTM with SnAP-1 against the tasks considered. Finally, we recommend exploring the proposed method on more diverse tasks, such as language modeling and sequential image classification, to better assess its applicability.