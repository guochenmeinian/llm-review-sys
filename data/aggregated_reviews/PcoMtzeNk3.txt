ID: PcoMtzeNk3
Title: Dynamic Graph Unlearning: A General and Efficient Post-Processing Method via Gradient Transformation
Conference: ACM
Year: 2024
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for "unlearning" in dynamic graph neural networks (DGNNs), addressing privacy protection and AI governance regulations, particularly the "right to be forgotten" under GDPR. The authors propose a gradient transformation-based method for dynamic graph unlearning, allowing efficient parameter updates through post-processing without altering the model architecture. Evaluations on six real-world datasets demonstrate significant performance improvements over existing baselines. However, the paper lacks direct comparisons with methods like SISA and influence function-based approaches, and it only tests two DGNN models, omitting others commonly used in the field. Additionally, performance metrics such as memory usage and training time are not evaluated, and there is insufficient discussion on practical issues related to GDPR compliance and the method's applicability in web scenarios.

### Strengths and Weaknesses
Strengths:
- The paper innovatively formulates the problem of unlearning in dynamic graphs, providing a general and practical solution that is model-agnostic.
- The proposed method shows significant efficiency improvements, achieving unlearning with up to a 32.59x speed enhancement while maintaining model utility.
- The writing is clear and well-organized, with extensive experiments validating the method across multiple datasets.

Weaknesses:
- There is a limited discussion on privacy guarantees, and formal analysis of these guarantees is absent.
- The experiments do not cover a range of unlearning request sizes, and comparisons with existing unlearning methods are insufficient.
- The paper lacks clarity on the definitions of key terms and objectives, particularly regarding the distinction between dynamic and static graph unlearning.
- Methodological limitations of prior approaches are not accurately described, potentially undermining the rigor of the paper.
- The hyperparameter settings lack justification, and the paper does not adequately analyze suboptimal experimental results.

### Suggestions for Improvement
We recommend that the authors improve the discussion on privacy guarantees by providing formal analyses. It would be beneficial to include experiments that evaluate the method's performance with varying sizes of unlearning requests and to compare it with adapted versions of existing unlearning methods. The authors should clarify the definitions of "Dynamic Graph Unlearning" and its objectives to enhance reader understanding. Additionally, we suggest revisiting the description of prior methods' limitations to accurately reflect their applicability. The authors should provide detailed justifications for hyperparameter settings and analyze the reasons for any suboptimal results observed in experiments. Lastly, a more thorough discussion on the practical deployment challenges of the method, particularly in distributed environments, is warranted.