ID: T6IbERflun
Title: Correlating Variational Autoencoders Natively For Multi-View Imputation
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 7, 6, 7, -1, -1, -1
Original Confidences: 2, 3, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method utilizing Variational Autoencoders (VAEs) to generate data from two distinct views, such as medical scans from different conditions. The authors propose training two VAEs to correlate the latent space distributions between views, demonstrating improved reconstruction compared to uncorrelated VAEs. They also show the ability to impute a missing view based on the available one. However, the paper lacks a theoretical link to other alignment loss functions and does not sufficiently compare their model to those from different families.

### Strengths and Weaknesses
Strengths:  
- The method shows promise in improving reconstruction and imputation of multi-view data.  
- Good ablation comparisons are presented, contributing to the workshop.  
- The idea is clearly articulated, and some improvements in visuals and results have been made in response to reviewer feedback.  

Weaknesses:  
- The paper lacks sufficient results and visuals to demonstrate the effectiveness of the proposed method.  
- Experiments are limited to the MNIST dataset, which is not comprehensive enough for robust validation.  
- There is a need for a theoretical link to other alignment loss functions and comparisons to models from different families.

### Suggestions for Improvement
We recommend that the authors improve the theoretical framework by establishing a clearer link to other alignment loss functions, such as contrastive loss and Barlow twins. Additionally, we suggest conducting experiments on more complex datasets to validate the method's effectiveness beyond the MNIST dataset. It would also be beneficial to compare the proposed model with methods from different families to provide a broader context for its performance.