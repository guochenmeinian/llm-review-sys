ID: Ss7l98DVvD
Title: Wild-GS: Real-Time Novel View Synthesis from Unconstrained Photo Collections
Conference: NeurIPS
Year: 2024
Number of Reviews: 23
Original Ratings: 3, 6, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 5, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Wild-GS, a method that adapts 3D Gaussian Splatting for in-the-wild rendering by decomposing appearance into global features, local features via triplane representation, and intrinsic material attributes. The authors argue that their advanced appearance modeling pipeline leads to superior results in novel view synthesis compared to existing methods, including NeRF-W, Ha-NeRF, and CR-NeRF. They claim that Wild-GS achieves significant improvements in metrics such as PSNR, training time, and rendering speed, asserting that it is not merely incremental. The framework leverages a point cloud to condition splats, enhancing local variability reproduction.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and easy to understand.
2. Wild-GS proposes a novel hierarchical appearance decomposition method, achieving high-quality appearance transfer from arbitrary images.
3. The method demonstrates state-of-the-art performance on three in-the-wild datasets, including a 3 PSNR increase and a 200-fold reduction in training time compared to CR-NeRF.
4. The authors provide a comprehensive experimental analysis that serves as a foundation for future research in novel view synthesis.

Weaknesses:
1. **Lack of Novelty**: The task has been previously addressed in NeRF, and many contributions appear to be inherited from existing works. The authors do not directly compare with other concurrent methods due to the absence of released code.
2. **Confusion in Module Design**: The rationale for using triplane representation for local appearance is unclear, as continuous volume representations could suffice, and this approach may be limiting for large scenes.
3. **Overstated Claims**: Some claims regarding physical interactions and intrinsic features lack experimental validation, and the absence of ablation studies raises questions about their effectiveness.
4. The comparison metrics in Table 1 may be misleading, as the authors calculated PSNR, SSIM, and LPIPS using the whole image, while many existing methods use only half of the image, leading to potentially unfair comparisons.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their contributions by implementing a version on Scaffold-GS for a fair comparison. Additionally, clarifying the motivation behind using triplane representation over alternatives like hash encoding would strengthen the paper. We suggest including ablation experiments to demonstrate the effectiveness of local features and intrinsic properties. Furthermore, we recommend improving the clarity of their evaluation metrics by ensuring that comparisons with existing methods are made on a consistent basis, ideally using half-image calculations for fairness. Lastly, exploring alternative 3D representations and efficient 3D networks could enhance the robustness of Wild-GS, addressing the limitations of triplane representation in large scenes.