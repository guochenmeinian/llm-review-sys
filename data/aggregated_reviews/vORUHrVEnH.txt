ID: vORUHrVEnH
Title: Going Beyond Linear Mode Connectivity: The Layerwise Linear Feature Connectivity
Conference: NeurIPS
Year: 2023
Number of Reviews: 12
Original Ratings: 7, 5, 6, 8, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 3, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Layerwise Linear Feature Connectivity (LLFC), a stronger generalization of linear mode connectivity (LMC). LLFC asserts that the feature maps of every layer in two trained neural networks are linearly connected, whereas LMC only requires linear connectivity in parameter space. The authors demonstrate that LLFC often co-occurs with LMC and identify two conditions—weak additivity of ReLU and commutativity—that imply LLFC. They provide empirical evidence supporting these claims through various experiments involving spawning and permutation methods.

### Strengths and Weaknesses
Strengths:
- The introduction of LLFC extends the understanding of linear connectivity in neural networks, providing precise definitions and sufficient conditions.
- The empirical results are comprehensive and support the occurrence of LLFC, validating the identified conditions.
- The paper is well-written, with clear organization and insightful discussions on the relationship between LLFC and existing methods.

Weaknesses:
- The analysis is limited to ReLU activations, and extending weak additivity to other activation functions is not straightforward.
- The findings regarding LLFC implying LMC are somewhat obvious, as current alignment algorithms already optimize for LLFC.
- The experimental evidence lacks adequate baselines for comparison, particularly with non-LMC networks, which may exaggerate results.

### Suggestions for Improvement
We recommend that the authors improve the experimental validation of LLFC by testing on larger datasets beyond MNIST and CIFAR-10, such as ImageNet, to establish broader applicability. Additionally, we suggest including comparisons with non-LMC networks to provide clearer baselines for the reported results. It would also be beneficial to explore the implications of LLFC with different activation functions and clarify the relationship between early training epochs and the emergence of LMC. Finally, addressing the gaps between theoretical findings and empirical observations could strengthen the paper's contributions.