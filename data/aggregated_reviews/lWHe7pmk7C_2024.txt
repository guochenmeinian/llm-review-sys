ID: lWHe7pmk7C
Title: From Chaos to Clarity: 3DGS in the Dark
Conference: NeurIPS
Year: 2024
Number of Reviews: 16
Original Ratings: 5, 6, 6, 6, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a self-supervised learning framework for reconstructing HDR 3D Gaussian Splatting (3DGS) from noisy raw images. The authors propose a noise extractor and a noise-robust reconstruction loss to mitigate noise effects, enhancing reconstruction quality and inference speed, particularly in limited-view scenarios. Experimental results on the RawNeRF dataset demonstrate that the proposed method outperforms existing state-of-the-art techniques in rendering quality and speed. Additionally, the authors analyze color bias in the context of RawNeRF, attributing discrepancies to differences in the Image Signal Processors (ISPs) used for training views. They observe similar color biases across various viewing platforms and emphasize that while the ISPs for training views are not disclosed, they consistently use the same ISP for test views, which mitigates concerns about the validity of their results. The authors acknowledge some loss of detail in specific areas, such as the grass in Fig. R1, but argue that their method generally preserves detail effectively, as evidenced by superior PSNR, SSIM, and LPIPS metrics compared to HDR Scaffold-GS. They also highlight a significant increase in rendering FPS by removing artifacts.

### Strengths and Weaknesses
Strengths:
1. The paper introduces an intuitive noise decomposition and informative noise removal method.
2. It achieves better reconstruction and denoising performance compared to 3DGS.
3. The writing and presentation are clear and well-organized.
4. The authors provide a clear rationale for observed color biases, linking them to ISP discrepancies.
5. They demonstrate strong quantitative performance metrics (PSNR, SSIM, LPIPS) compared to existing methods.
6. The method shows a notable improvement in rendering FPS, indicating efficiency gains.

Weaknesses:
1. The innovation may not be sufficient for the conference, as the major contribution lies in the denoising aspect, which requires pre-training with additional data.
2. The performance improvement over baseline methods is marginal, with no significant synthesis quality enhancement compared to the original RawNeRF scores.
3. The method assumes clean pixel values remain consistent across different viewpoints, raising questions about handling non-Lambertian surfaces.
4. The impact of the $L_{cov}$ term in the $L_{nd}$ loss is unclear, necessitating further investigation.
5. Some details are lost in specific areas, such as the grass in Fig. R1, which may raise concerns about detail preservation.
6. The lack of access to training view ISPs limits the ability to fully replicate results.

### Suggestions for Improvement
We recommend that the authors improve the experimental evaluation by including comparisons with NeRF-based methods on RAW data, such as RawNeRF, to better assess the denoising capabilities of their approach. Additionally, providing more qualitative results and addressing the potential lack of evaluation in the RawNeRF dataset would strengthen the paper. Clarifying the role of the noise extractor and its pre-training requirements through ablation studies would also enhance the understanding of the proposed method's effectiveness. Furthermore, we suggest improving the clarity of explanations regarding the impact of ISP differences on color bias. Consider providing more detailed visual comparisons to address concerns about detail loss, particularly in areas like the grass in Fig. R1. Finally, exploring potential methods to obtain or simulate the training view ISPs could enhance the robustness of their findings.