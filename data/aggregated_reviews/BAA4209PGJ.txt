ID: BAA4209PGJ
Title: Set Learning for Generative Information Extraction
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to address order bias in Information Extraction (IE) frameworks using sequence-to-sequence (Seq2Seq) models. The authors propose a set learning method that incorporates multiple permutations of structured objects to approximate set probability, thereby mitigating order bias. Key contributions include highlighting the order bias issue, introducing a set learning approach compatible with existing frameworks, and validating the method through extensive experiments across various tasks and datasets.

### Strengths and Weaknesses
Strengths:
- The paper proposes a unique 'set learning' solution that effectively addresses order bias without requiring changes to existing model structures.
- The writing is well-motivated and clear, with extensive experiments conducted on nine datasets across four tasks, demonstrating the method's effectiveness.
- The analysis of the proposed method is detailed, and the experiments validate its applicability and robustness.

Weaknesses:
- The paper lacks a comparative analysis with existing methods for mitigating order bias, limiting the strength of its claims.
- The computational costs associated with permutation sampling may be high for longer texts with more entities and relations.
- The introduction's example does not clearly illustrate the order bias issue, and the innovativeness of the approach is perceived as somewhat lacking, as it only refines previously proposed methods.

### Suggestions for Improvement
We recommend that the authors improve the comparative analysis by including comparisons with existing order bias mitigation methods to strengthen their argument. Additionally, addressing the computational costs of permutation sampling for longer texts is essential. We suggest revising the introductory example to better demonstrate the order bias issue. Furthermore, providing additional experimental evidence to validate claims about the Uniform loss, SetRNN loss, and the proposed Set loss would enhance the paper's credibility.