ID: PEEqnXlSCk
Title: SDP4Bit: Toward 4-bit Communication Quantization in Sharded Data Parallelism for LLM Training
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 7, 5, 6, 6, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to reduce communication overhead in Sharded Data Parallelism (ShardedDP) for training large language models (LLMs) by proposing two key techniques: quantization on weight differences and two-level gradient smooth quantization. The authors demonstrate that their method compresses weights and gradients to nearly 4 bits without compromising training accuracy, achieving up to 4.08Ã— speedup on 128 GPUs. The paper includes theoretical guarantees of convergence and shows negligible impact on training loss for models with up to 6.7 billion parameters.

### Strengths and Weaknesses
Strengths:  
1. The proposed weight difference and two-level gradient quantization techniques effectively retain accuracy while significantly improving throughput compared to baseline approaches.  
2. The authors provide a comprehensive narrative with a new quantization algorithm, GPU kernel implementations, and detailed evaluations that clearly illustrate the benefits of their approach.  

Weaknesses:  
1. The connection between the convergence analysis and the quantization schemes is unclear, particularly regarding the classification of quantizers as biased or unbiased.  
2. Empirical analysis is primarily limited to older GPT models, raising concerns about the applicability to modern architectures.  
3. The paper lacks key ablation studies and practical analysis of communication volume based on the number of nodes, which would enhance understanding of the approach's effectiveness.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the connection between convergence analysis and quantization schemes, specifically addressing the classification of biased and unbiased compressors. Additionally, we suggest including empirical analysis on modern models to validate the approach's applicability. The authors should also provide more ablation studies on various design choices and practical analyses of communication volume based on the number of nodes. Furthermore, exploring asymmetric quantization and stochastic rounding could enhance accuracy and potentially eliminate the need for Hadamard smoothing. Finally, addressing the size of the Hadamard transform and its overhead in non-power-of-two scenarios would strengthen the paper.