ID: IFNbElsnCi
Title: Generating Summaries with Controllable Readability Levels
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a variant of the summarization task focused on generating summaries at specified readability levels. The authors propose three baseline methods—instruction-prompting, reinforcement learning (RL), and lookahead decoding (LA)—to control summary readability. The evaluation demonstrates that these methods effectively manage readability while analyzing trade-offs with specificity, abstraction, factuality, and informativeness.

### Strengths and Weaknesses
Strengths:
- The trade-off between readability and specificity is a valuable contribution to the summarization task.
- The proposed methods provide a solid foundation for future research in this area.
- Comprehensive evaluations, both automatic and human, validate the effectiveness of the RL and LA approaches.

Weaknesses:
- The comparison to GPT-3 is deemed unfair due to differing evaluation methods, raising concerns about performance differences.
- The motivation for lower readability levels is inadequately addressed.
- The novelty of the proposed methods is questioned, as prompting from LLMs and applying PPO are common techniques.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the motivation for lower readability levels, emphasizing its significance earlier in the paper. Additionally, we suggest making the comparison to GPT-3 more equitable or excluding it from the evaluation. It would be beneficial to include qualitative analyses to support the differences in summaries across readability levels. Lastly, we encourage the authors to provide more examples of generated summaries at various readability levels to enhance understanding.