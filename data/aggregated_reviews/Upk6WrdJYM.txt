ID: Upk6WrdJYM
Title: Efficient k-NN Search with Cross-Encoders using Adaptive Multi-Round CUR Decomposition
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents AdaCUR, an extension of AnnCUR, aimed at enhancing KNN search efficiency through adaptive anchor items during test-time. The authors propose that while anchor queries are fixed during offline indexing, anchor items can be dynamically adjusted based on the test query. AdaCUR demonstrates higher recall than AnnCUR using the same cross-encoder model, although the improvements are considered incremental. The paper lacks comparisons with more recent methods and does not adequately address real-world time costs associated with its approach.

### Strengths and Weaknesses
Strengths:  
- The CUR factorization provides a compelling perspective on accelerating cross-encoder approaches.  
- AdaCUR shows improved recall metrics compared to AnnCUR with the same model.  
- The method is well-motivated conceptually and empirically, enhancing understanding of AnnCUR.

Weaknesses:  
- The novelty of the approach is borderline, with significant concerns regarding the lack of comparison to recent literature.  
- The paper is not self-contained, requiring reference to the previous AnnCUR paper for clarity.  
- The analysis of latency and computational efficiency is misleading, as it does not consider parallelization of cross-encoder calls.

### Suggestions for Improvement
We recommend that the authors improve the paper by including experimental results comparing AdaCUR with more recent methods, as listed in the missing references. Additionally, clarify the reasons for the varying improvements in recall metrics at different values of k, particularly why AnnCUR performs worse than TF-IDF in certain figures. The introduction should be more self-contained, properly defining key concepts such as anchors and CUR. We suggest reorganizing the writing for clarity, particularly in sections 2.1 and 2.2, and rephrasing complex phrases for better understanding. Lastly, the latency analysis should be revised to accurately reflect the implications of parallelizing cross-encoder calls.