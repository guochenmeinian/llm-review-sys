ID: jcx5YIN3Sd
Title: That was the last straw, we need more: Are Translation Systems Sensitive to Disambiguating Context?
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents TIDE, a new dataset designed to evaluate the figurative language capabilities of machine translation (MT) systems. TIDE comprises 512 ambiguous idioms with disambiguating content for both figurative and literal interpretations. The authors analyze various MT systems and large language models (LLMs) using TIDE, focusing on models' preferences for literal versus figurative translations, sensitivity to disambiguating context, and the translation quality gap between figurative and literal sources. The findings indicate that LLMs outperform traditional MT models in context-aware translations but struggle in low-resource settings.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and introduces a valuable resource for studying figurative language translation.
- The experimental framework is clearly defined, incorporating both automatic and human evaluations across a diverse set of models and languages.
- The evaluation results effectively highlight the strengths and weaknesses of the models examined.

Weaknesses:
- The novelty of the dataset is questionable, as existing test sets for idiom translation were not adequately referenced.
- The potential utility of TIDE compared to larger datasets like MAGPIE is unclear.
- The corpus creation method, relying on GPT-generated examples, raises concerns about the dataset's diversity and potential biases.

### Suggestions for Improvement
We recommend that the authors improve the discussion of TIDE's novelty and relevance by clearly articulating how it complements existing datasets like MAGPIE. Additionally, consider addressing the limitations of using GPT-4 for corpus generation, as this may introduce biases favoring LLMs. Clarifying the version of NLLB used and the architecture of OPUS MT in the text would enhance reproducibility. Furthermore, specify when LMs and Google Translate APIs were accessed for translations and explain the significance of the gray bars in figures. Lastly, we suggest revising the phrasing regarding LLM capabilities to avoid implications of sudden emergence without supporting evidence.