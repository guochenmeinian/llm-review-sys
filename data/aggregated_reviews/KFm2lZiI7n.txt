ID: KFm2lZiI7n
Title: MeCo: Zero-Shot NAS with One Data and Single Forward Pass via Minimum Eigenvalue of Correlation
Conference: NeurIPS
Year: 2023
Number of Reviews: 23
Original Ratings: 5, 7, 6, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents MeCo, a novel zero-cost proxy for neural architecture search (NAS) that operates independently of data and labels, requiring only one data sample for a forward pass. The authors analyze the correlation between the Pearson matrix of feature maps and the network's training convergence rate, demonstrating MeCo's effectiveness across various NAS benchmarks, including NATS-Bench-TSS and NATS-Bench-SSS. Additionally, the paper introduces an optimization method, MeCo-opt, aimed at addressing the channel sensitivity issue of the original MeCo proxy. The authors demonstrate that MeCo-opt effectively resolves negative correlations observed in various benchmarks, including NASBench-301 and Transbench101, providing empirical evidence of improved performance metrics, particularly in high-resolution tasks like segmentation.

### Strengths and Weaknesses
Strengths:
1. The paper introduces a theoretically grounded zero-cost proxy, MeCo, which is quick due to its reliance on a single data sample and no backward pass.
2. MeCo achieves superior ranking correlation compared to existing methods on several benchmarks.
3. The introduction of MeCo-opt significantly mitigates the channel sensitivity problem, leading to improved correlation results across multiple benchmarks.
4. The paper includes new experimental results that validate the effectiveness of the optimization method, particularly in high-resolution vision tasks.
5. The writing is clear and well-structured, facilitating comprehension.

Weaknesses:
1. The performance gains of MeCo are marginal compared to other zero-cost methods, particularly on larger datasets like ImageNet, where results are lacking.
2. The correlation results exhibit variability across different search spaces, raising concerns about MeCo's robustness and generalizability.
3. Concerns remain regarding the ImageNet results, where the increase in FLOPS does not correspond to a substantial improvement in accuracy.
4. The applicability of MeCo is limited in scenarios where the number of channels exceeds the feature map dimensions, which may restrict its use in certain architectures.
5. The paper does not adequately address the implications of channel sensitivity on MeCo's performance, nor does it explore its application in transformer architectures or other NAS benchmarks.

### Suggestions for Improvement
We recommend that the authors improve the experimental evaluation by including results on larger datasets, such as ImageNet, and exploring additional NAS benchmarks beyond image classification, like TransNASBench. Furthermore, we suggest conducting a detailed analysis of the correlation variations observed in different search spaces and addressing the implications of channel sensitivity on MeCo's performance. It would also be beneficial to clarify the connection between MeCo and the generalization capacity of networks. Additionally, we recommend that the authors improve the clarity of the paper by clearly identifying the conditions under which MeCo should be applied, particularly emphasizing the dependence on channel dimensions. Demonstrating at least one high-resolution vision application, such as image super-resolution, would showcase the benefits of their approach. Addressing the hyperparameter selection for n in MeCo-opt with empirical guidelines would enhance the practical applicability of their method. Lastly, we encourage the authors to conduct further real-world experiments to substantiate the improvements in accuracy over existing proxies, particularly in tasks beyond NAS benchmarks.