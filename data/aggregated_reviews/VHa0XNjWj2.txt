ID: VHa0XNjWj2
Title: VLM4Bio: A Benchmark Dataset to Evaluate Pretrained Vision-Language Models for Trait Discovery from Biological Images
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 6, 7, 7, -1, -1, -1, -1
Original Confidences: 3, 3, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a dataset from the organismal biology domain, including species of fishes, birds, and butterflies, and covers five biologically relevant tasks. The authors evaluate the zero-shot effectiveness of pretrained vision-language models (VLMs), focusing on prompting and VLM hallucinations. They benchmark a total of 12 VLMs, including GPT-4V, GPT-4o, and Gemini. The dataset comprises 469K question-answer pairs and 30K images, aiming to assess the capabilities of VLMs in answering biological questions.

### Strengths and Weaknesses
Strengths:  
- The introduction of a relatively uncommon dataset and benchmark for animal species is commendable.  
- The extensive evaluation of various VLMs provides valuable insights into their performance on the proposed tasks.  
- The clarity of the writing enhances the accessibility of the research.

Weaknesses:  
- The dataset currently covers a limited number of organisms, which may restrict its impact on the community.  
- Some annotations are automatically generated, and certain questions posed are trivial.  
- The sampling methods for the dataset lack detail, and the classes in the Fish and Butterfly subsets could be more balanced.

### Suggestions for Improvement
We recommend that the authors improve the sampling methodology by considering random sampling after clustering features extracted with a pretrained model, such as DINOv2 or ImageNet pretrained ResNet, to ensure diversity and balance. Additionally, we suggest specifying the sampling process for the 10K images in the Fish subset and addressing the imbalance in classes for the Fish and Butterfly subsets. It would also be beneficial to include annotations for the bounding boxes in the Trait Grounding case to enhance clarity. Lastly, we encourage the authors to explore the impact of image resolution on VLM performance and to provide a description of the dataset's license in the documentation.