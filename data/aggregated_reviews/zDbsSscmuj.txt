ID: zDbsSscmuj
Title: Leveraging Pre-trained Large Language Models to Construct and Utilize World Models for Model-based Task Planning
Conference: NeurIPS
Year: 2023
Number of Reviews: 11
Original Ratings: 5, 6, 7, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 5, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to using GPT LLMs for constructing PDDL models from natural language descriptions and correcting them through feedback. The authors propose a two-stage process where LLMs translate descriptions into valid PDDL domains, which can then be used with classic planners or LLM planners to generate plans. Experiments conducted in synthetic domains demonstrate that GPT-4 constructs PDDL models with fewer errors, while classic PDDL planners outperform LLM planners on these models.

### Strengths and Weaknesses
Strengths:
- The exploration of LLMs for PDDL model construction is innovative and contributes to the field of AI planning.
- The paper includes experiments comparing LLM and classic planners, showing the latter's superior performance on LLM-generated PDDL models.
- The methodology is well-structured, and the detailed prompt descriptions enhance understanding of the LLM's functioning.

Weaknesses:
- The absence of a theoretical framework linking LLM token sequences to formal action description languages limits the evaluation of this approach's validity and applicability.
- The experimental methodology lacks systematic handling of metrics and underlying hypotheses, making it ad-hoc.
- The reliance on human feedback for error correction raises questions about the automation potential of the proposed method.

### Suggestions for Improvement
We recommend that the authors improve the theoretical framework to connect LLMs' underlying models with formal action description languages, enhancing the evaluation of their approach. Additionally, we suggest providing a systematic methodology for metrics and hypotheses in the experiments to guide future research. Clarifying the role of the user in generating PDDL domains and discussing the implications of human feedback on automation would strengthen the paper. Lastly, addressing the differences in performance between GPT-4 and GPT-3.5, as well as exploring the potential for fully automated error correction methods, would be beneficial.