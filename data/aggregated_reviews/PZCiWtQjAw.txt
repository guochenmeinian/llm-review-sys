ID: PZCiWtQjAw
Title: Continual Audio-Visual Sound Separation
Conference: NeurIPS
Year: 2024
Number of Reviews: 28
Original Ratings: 5, 6, 5, 7, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel continual audio-visual sound separation task, integrating continual learning with audio-visual sound separation. The authors propose ContAV-Sep, a framework that employs a Cross-modal Similarity Distillation Constraint (CrossSDC) to mitigate catastrophic forgetting while continuously separating new sound categories and maintaining the performance of previously learned categories. Experimental results on the MUSIC-21 dataset demonstrate that ContAV-Sep significantly outperforms existing continual learning baselines in standard sound separation metrics. Additionally, the authors conducted experiments on the VGGSound dataset, utilizing 100 diverse sound categories, and reported improved performance metrics compared to baseline methods, arguing that their approach significantly extends beyond existing works that typically utilize smaller subsets of audio-visual data.

### Strengths and Weaknesses
Strengths:
- The paper clearly identifies a novel and practical problem in audio-visual sound separation, addressing continual learning effectively.
- It proposes a well-defined framework, ContAV-Sep, with a CrossSDC to tackle catastrophic forgetting.
- Empirical results show significant performance improvements over strong baselines, supported by thorough analyses, including ablation studies.
- The authors demonstrate effective generalization to a larger dataset with a broader range of sound categories.
- The training speed and data processing capabilities of the authors are commendable.

Weaknesses:
- The mathematical expression of the CrossSDC lacks distinction from the Dual-Audio-Visual Similarity Constraint in prior work, raising concerns about its novelty.
- The technical contribution of the paper is perceived as low, with concerns about the significance of combining existing tasks to create a new one.
- The experimental validation is limited to the MUSIC-21 dataset, which restricts the assessment of the model's generalization ability to other datasets or real-world scenarios.
- The innovation of the proposed task is questioned, as it appears to stem from established methods in continual learning and audio-visual classification.
- The performance improvement of ContAV-Sep is not substantial in some instances, and the manuscript lacks thorough investigation of related continual learning techniques in sound processing.

### Suggestions for Improvement
We recommend that the authors improve the mathematical clarity of the CrossSDC to clearly differentiate it from existing methods. Additionally, we suggest conducting experiments on a broader range of datasets, such as VGGSound or Audioset, to provide a more comprehensive evaluation of the model's effectiveness. We also recommend refining the presentation, including increasing the font size in Figure 2 and ensuring that all symbols are clearly explained in the captions. Furthermore, we encourage the authors to improve the clarity of the technical contributions by explicitly addressing the significance of their novel task compared to existing methods. Providing a more detailed comparison of model capacities and training strategies used in related works would enhance the understanding of their approach's uniqueness. Lastly, exploring the potential for extending their method to other tasks, such as audio-visual segmentation, could further strengthen their contributions.