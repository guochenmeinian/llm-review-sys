ID: TnTDiCppx5
Title: Predict-then-Calibrate: A New Perspective of Robust Contextual LP
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 4, 7, 6, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a risk-sensitive variant of contextual linear optimization, utilizing VaR as the risk measure. The authors propose two heuristic approaches that approximate the minimization of VaR through robust optimization, specifying uncertainty sets based on regression models to predict conditional means and calibrating their sizes for coverage guarantees. The authors provide bounds on the probability of satisfying these guarantees and conduct computational experiments to evaluate their methods against baselines. Additionally, they briefly discuss a distributionally robust variant of contextual linear optimization, demonstrating convergence to an optimal policy. Furthermore, the authors introduce a "predict-then-calibrate" (PTC) approach aimed at enhancing flexibility in machine learning model selection while addressing uncertainty quantification. However, the PTC framework is not clearly articulated, leading to confusion. The paper critiques existing works, particularly Ohmori (2021) and Chenreddy et al. (2022), highlighting the need for a conditional guarantee in the context of the authors' optimization problem.

### Strengths and Weaknesses
Strengths:
- The problem of risk-sensitive contextual linear optimization is relevant and interesting.
- The proposed methods exhibit good performance, supported by reasonable experimental design.
- The paper is well-structured and clearly written, with strong algorithm analysis and empirical work.
- The proposed method offers additional flexibility in choosing prediction methods, and the justification for the two-step procedure is reasonable and promising.

Weaknesses:
- The motivation for the chosen form of the uncertainty set is unclear, requiring further explanation.
- The coverage guarantees do not align with the contextual problem's requirements, potentially underestimating risk in heteroskedastic settings.
- The theoretical guarantees are weak, as they could be satisfied by poorly chosen uncertainty sets.
- The PTC framework is not clearly defined, leading to ambiguity in its application.
- The connection between methods in different sections is poorly communicated, particularly in Section 4, which appears disconnected from the main content.
- The paper lacks a clear presentation of individual coverage guarantees, which are critical for the contextual optimization problem.
- There is inconsistency regarding whether values A and b are treated as random or constant.

### Suggestions for Improvement
We recommend that the authors improve the motivation for their modeling choices, particularly for the uncertainty set. The authors should redesign the method to ensure that the correct coverage guarantee, P(c ϵ U_α(z) | z) = α, is met. Additionally, the authors should strengthen the theoretical guarantees to demonstrate that their choice of uncertainty set satisfies more robust properties. We suggest that the authors improve the clarity of the PTC framework by providing a rigorous definition, explaining its applicability in various contexts, and demonstrating its benefits through theoretical results or broad experiments. Furthermore, we advise the authors to present the method for individual coverage guarantees more prominently, as this is essential for the optimization problem. We also suggest strengthening the connections between the methods discussed in different sections, particularly in Section 4, or considering its removal if a stronger linkage cannot be established. Lastly, the authors should clarify the treatment of values A and b as either random or constant throughout the methodology and provide empirical strategies for ensuring the validation set is correctly specified to enhance practical applicability.