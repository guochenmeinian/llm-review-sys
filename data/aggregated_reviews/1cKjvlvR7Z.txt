ID: 1cKjvlvR7Z
Title: Test-Time Self-Adaptive Small Language Models for Question Answering
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a “self-adaptive” technique for fine-tuning smaller language models (LMs) without labeled data, utilizing a novel sampling method based on Monte-Carlo dropout to generate multiple potential answers for unlabelled questions. The authors provide empirical evidence demonstrating that their sampling and filtration method outperforms previous approaches. The study investigates the capabilities of smaller self-adaptive LMs to solve downstream QA tasks, showing significant performance improvements and robustness across diverse prompts.

### Strengths and Weaknesses
Strengths:
- The proposed sampling methodology is novel and effectively increases answer diversity.
- Comprehensive experiments yield sound empirical results, demonstrating the effectiveness of the methods.
- The paper is well-written and easy to follow.

Weaknesses:
- A significant portion of the datasets used overlaps with the training set for the Flan-T5 models, which the authors do not adequately address, potentially mischaracterizing the study as semi-supervised.
- The contextualization of the work is insufficient, lacking discussion of related self-training literature.
- The reliability of the majority voting strategy for pseudo-label selection is questionable, given the lower reliability of smaller LMs compared to larger ones.
- The evaluation is limited to a single backbone model, raising concerns about generalizability.

### Suggestions for Improvement
We recommend that the authors improve the discussion regarding the implications of dataset overlap with the training set of Flan-T5 models to clarify the study's classification. Additionally, we suggest enhancing the contextualization of the work by incorporating discussions of relevant self-training literature. It is also crucial to address the reliability of the majority voting strategy for pseudo-label selection and to include comparisons with larger LMs to demonstrate the proposed method's effectiveness. Finally, we encourage the authors to evaluate their approach across multiple backbone models to assess generalizability.