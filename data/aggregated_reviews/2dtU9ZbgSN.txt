ID: 2dtU9ZbgSN
Title: Bilevel Coreset Selection in Continual Learning: A New Formulation and Algorithm
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 6, 5, 7, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to coreset selection in rehearsal-based continual learning, addressing limitations in existing methods related to scalability and computational efficiency. The authors propose a bilevel optimization framework that minimizes expected training error while learning a probability distribution over the dataset, incorporating a smoothed top-K regularizer. The effectiveness of this method is supported by extensive experiments demonstrating superior performance compared to existing techniques.

### Strengths and Weaknesses
Strengths:
- The approach is well-motivated and addresses the limitations of prior works effectively.
- The writing is clear and accessible, with comprehensive experimental results across various datasets.
- The inclusion of a new loss function and the use of a smoothed top-K regularizer enhance the optimization process.

Weaknesses:
- Further analysis of the top-K loss and its effects on the probability distribution would improve understanding.
- Comparisons with state-of-the-art non-coreset methods are lacking, which could provide valuable insights.
- The main illustration (Figure 1) could benefit from additional technical details or supplementary figures.
- The reliance on a proxy model may limit applicability in large-scale scenarios, and the computational cost of Hessian-vector products could pose challenges.

### Suggestions for Improvement
We recommend that the authors improve the analysis of the top-K loss to clarify its impact on the optimization process. Additionally, including comparisons with state-of-the-art non-coreset methods would enhance the paper's contribution. We suggest enriching Figure 1 with more technical information or adding supplementary figures for better clarity. Finally, addressing the computational efficiency of the proposed method, particularly in large-scale applications, would strengthen the overall impact of the work.