ID: SrQua0ATRZ
Title: Diffusion-Inspired Truncated Sampler for Text-Video Retrieval
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 6, 7, 4, 7, 4, -1, -1, -1, -1
Original Confidences: 4, 5, 4, 4, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Diffusion-Inspired Truncated Sampler (DITS), a novel method aimed at addressing the modality gap in text-video retrieval tasks. The authors leverage diffusion models to enhance the alignment between text and video embeddings within a joint embedding space. Extensive experiments on five benchmark datasets demonstrate DITS's state-of-the-art performance, showcasing its flexibility in adjusting retrieval scope and improving the structure of the CLIP embedding space.

### Strengths and Weaknesses
Strengths:
- The authors effectively investigate the use of diffusion models to bridge the text-video modality gap, identifying limitations in standard diffusion models for retrieval tasks.
- DITS achieves state-of-the-art performance across five datasets, supported by comprehensive experiments.
- The commitment to releasing the code will facilitate further research and application of the proposed method.

Weaknesses:
- Generalization ability is a concern, particularly regarding the optimal selection of timestamps for the truncated diffusion process, as too many timestamps may hinder generalization.
- Computational efficiency is a significant issue, as diffusion models typically demand substantial resources for training and inference.
- Some writing sections are confusing, particularly regarding the conditions for diffusion and the clarity of certain equations.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing, particularly in Section 3.2 and 3.3, to ensure consistency regarding the conditions for diffusion. Additionally, we suggest providing a comparison of inference times to better illustrate the computational efficiency of DITS relative to existing methods. Given the impact of timestamps on performance, could an automated method be devised to determine optimal time steps? Furthermore, we encourage the authors to analyze why unconditional diffusion outperforms text or video diffusion, as this counter-intuitive result warrants further exploration. Lastly, we recommend including a discussion on the additional computational resources required for the proposed method compared to non-diffusion methods.