ID: OETPPc15XG
Title: Whispering LLaMA: A Cross-Modal Generative Error Correction Framework for Speech Recognition
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a cross-modal technique for correcting speech recognition errors by integrating acoustic data from Whisper, a state-of-the-art ASR model, with LLaMA, a large language model (LLM). The authors propose a novel fusion mechanism that utilizes cross-attention tensors to enhance the LLM decoder for improved error correction. Experimental results indicate significant reductions in word error rate (WER) compared to traditional n-best selection methods.

### Strengths and Weaknesses
Strengths:
- The paper introduces a new and effective method for ASR-LLM integration, addressing a significant practical problem.
- Promising results are supported by thorough experimentation and detailed ablation studies.

Weaknesses:
- The use of whisper-tiny for evaluation may lead to overly optimistic results, as it is a smaller model not representative of real-world applications.
- Performance analysis discrepancies exist between reported results and tables, raising concerns about the validity of the findings.
- Reproducibility is questionable due to the complexity of the methods and potential data leakage issues.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by using larger Whisper models to provide a more realistic assessment of their method's effectiveness. Additionally, clarifying the purpose of the adapter A_L^i and considering the use of the LoRA adapter for fine-tuning LLMs would enhance the paper's rigor. Addressing the discrepancies in performance analysis and ensuring that evaluation sets are carefully selected to avoid data leakage will strengthen the study's conclusions. Finally, correcting minor grammatical errors and inconsistencies in tables will improve clarity.