ID: CfJiBuysQQ
Title: CLEVR-Implicit: A Diagnostic Dataset for Implicit Reasoning in Referring Expression Comprehension
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 5
Original Ratings: -1, -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the CLEVR-Implicit dataset aimed at addressing implicit reasoning in referring expression comprehension tasks. The authors propose a method to transform implicit text into explicit text (TIE), revealing that existing vision-language models (VLMs) struggle with aligning implicit text to objects in images. The study demonstrates that converting implicit text to explicit significantly enhances VLM performance on this task.

### Strengths and Weaknesses
Strengths:
- The paper identifies a critical issue in implicit text matching for vision-language learning and constructs a valuable dataset for this purpose.
- The proposed TIE method effectively improves model performance on implicit reasoning tasks.
- The organization and clarity of the paper facilitate understanding.

Weaknesses:
- The experiments primarily simplify the task by converting implicit descriptions to explicit ones, which undermines the original goal of understanding implicit descriptions.
- The dataset is synthetic and limited in diversity, lacking a broader exploration of realistic scenarios and attributes.
- There is insufficient engagement with relevant literature on referring expression generation, which could enhance the paper's depth and context.
- The paper does not adequately relate its findings to broader referring expression comprehension challenges or provide clear comparisons to existing models.

### Suggestions for Improvement
We recommend that the authors improve the experimental design to focus on learning from implicit descriptions without simplifying the task by making them explicit. Additionally, incorporating a more diverse dataset that includes realistic attributes would strengthen the findings. Engaging with the referring expression generation literature could provide valuable insights and enhance the paper's contributions. We also suggest clarifying the relationship between the proposed method and its applicability to other types of referring expressions, as well as addressing the limitations of using synthetic data in more complex domains. Lastly, improving the clarity of writing and addressing specific technical questions raised in the reviews would enhance the overall presentation.