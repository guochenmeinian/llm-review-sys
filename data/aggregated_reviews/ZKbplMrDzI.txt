ID: ZKbplMrDzI
Title: SDformer: Similarity-driven Discrete Transformer For Time Series Generation
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 7, 6, 6, 5, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 2, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents SDformer, a time series generation model utilizing a similarity-driven vector quantization technique for high-quality discrete token representations. The authors demonstrate the model's effectiveness through empirical results, showing it surpasses state-of-the-art methods across multiple metrics and datasets. The paper also addresses challenges related to inference time and quality improvement in time series generation.

### Strengths and Weaknesses
Strengths:
- The similarity-driven vector quantization approach is novel and effective for time series generation.
- Experimental results are compelling, showcasing significant improvements in generated time series quality and efficiency.
- The paper is well-written, with detailed analysis of experimental results.

Weaknesses:
- The description of the proposed method lacks detail, making it difficult to reproduce results.
- Limitations of the method are not well explained, and comparisons with other methods are insufficient.
- There are concerns regarding the choice of codebook size, the concept of code collapse, and the implementation details for random replacement.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the method description to enhance reproducibility. Additionally, the authors should provide a thorough discussion of the model's limitations and include comparisons with recent related work. It would also be beneficial to clarify how the codebook size K is chosen, elaborate on the implications of code collapse, and provide precise implementation details for random replacement, including the selection of hyperparameters. Furthermore, we suggest conducting more ablation studies regarding model size and code embedding size to strengthen the findings.