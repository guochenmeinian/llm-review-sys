ID: VXohja0vrQ
Title: MedCalc-Bench: Evaluating Large Language Models for Medical Calculations
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 8, 7, 8, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents MEDCALC-BENCH, a novel annotated dataset of 1,000 medical cases designed to evaluate the performance of large language models (LLMs) on equation-based and rule-based medical calculation tasks across seven topics. The dataset includes 55 tasks, with instances ranging from 40 to 327 cases, and was labeled by an unspecified number of medical professionals using publicly available sources that respect patient confidentiality. The authors provide baseline results and analyze error types to highlight the limitations of current LLMs in medical contexts.

### Strengths and Weaknesses
Strengths:  
- The dataset addresses a significant gap in evaluating LLMs for medical calculations, offering a comprehensive benchmark for multiple models.  
- It includes a manually curated collection of medical calculators and detailed evaluations of various LLMs, enhancing the understanding of their capabilities and limitations.  
- The paper is well-organized, clearly presented, and includes reproducible code, contributing valuable insights to the field.

Weaknesses:  
- The section on limitations is brief and lacks depth regarding potential improvements for the dataset and LLM capabilities.  
- There is insufficient information about the medical professionals involved in the labeling process and their agreement metrics.  
- Some sections, such as paragraphs 5.2 and 5.3, appear disjointed and could benefit from better integration or elaboration.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the medical professionals' assessment process, including details on their qualifications and interrater agreement metrics. Additionally, we suggest expanding the limitations section to discuss ways to enhance the dataset and improve LLM computational abilities. For reproducibility, consider conducting experiments with GPT APIs and setting the temperature to 0.0. Furthermore, please clarify how the evaluation of error types is realized by GPT-4 and whether the annotations in Figure 3 are made by humans or the model. Lastly, we advise adding legends to Table 1 and simplifying the data presentation in Tables 2 and 4 for better readability.