ID: dbRZyDxYlL
Title: Improving Speech Translation by Fusing Speech and Text
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework that utilizes pre-trained representations for speech and text embedding to learn a joint representation through various modality matching losses. The authors propose a model called Fuse-Speech-Text (FST) that is jointly trained for speech translation, machine translation, fused speech-text translation, and ASR, achieving notable improvements in BLEU scores on the MuST-C and GigaST datasets. The contributions include a hierarchical architecture for multi-modal input and the application of several losses for cross-modal alignment.

### Strengths and Weaknesses
Strengths:
- The motivation for the approach is clear, and the experimental section is thorough, demonstrating significant improvements over baselines.
- The model framework is well-defined, and the figures are intuitive and easy to understand.
- The strategy of using fused representations is straightforward and shows numerical improvements.

Weaknesses:
- The complexity of the proposed method, which combines multiple pre-trained modules and eight different losses, makes it difficult to ascertain the source of improvements and increases the number of hyper-parameters to tune.
- The writing lacks clarity in certain sections, particularly in the related work and the explanation of the model's objectives, which may confuse readers.
- The novelty of the approach is questioned due to similarities with existing works, and the presentation of results could be improved for better comparability.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing, particularly in the related work section, by discussing how their approach differs from existing models. Additionally, we suggest that the authors provide a more intuitive explanation of the contribution of each of the eight objectives in the framework, possibly through analysis of previous model outputs. To enhance comparability, we encourage the authors to include at least one data point from their in-house cascade model. Finally, we advise against using the acronym "FST" due to potential confusion with finite-state transducer terminology.