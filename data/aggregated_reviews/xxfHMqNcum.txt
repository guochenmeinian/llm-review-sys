ID: xxfHMqNcum
Title: Towards Hybrid-grained Feature Interaction Selection for Deep Sparse Network
Conference: NeurIPS
Year: 2023
Number of Reviews: 18
Original Ratings: 5, 4, 6, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a hybrid-grained feature interaction selection approach for deep sparse networks, targeting both feature field and feature value. The authors propose a decomposed selection space calculated on the fly, introducing the OptFeature algorithm for efficient selection of feature interactions. Experimental evaluations on three large real-world datasets demonstrate that the proposed approach achieves competitive accuracy and efficiency, suggesting its potential to enhance prediction tasks with high-dimensional sparse features.

### Strengths and Weaknesses
Strengths:
- The hybrid-grained approach extends traditional field-level selection, incorporating both field and value levels, which appears innovative.
- The experimental setup is robust, with repeated trials and detailed reporting of parameters, enhancing the reliability of results.
- Strong performance on benchmarks indicates the effectiveness of the proposed method.

Weaknesses:
- The novelty of the approach is not clearly established due to a lack of comprehensive review of related work in Feature Interaction Selection.
- The evaluation datasets are relatively small, which may not adequately demonstrate scalability and performance in real-world applications.
- Clarity issues arise from misleading figures and insufficient explanations regarding parameter selection and the relevance of certain sections.

### Suggestions for Improvement
We recommend that the authors improve the literature review in Section 2 to better highlight the novelty of their approach. Additionally, consider using larger-scale datasets to validate the scalability and performance of the proposed method. Clarifying the introduction to summarize the main contributions would enhance reader comprehension. Furthermore, we suggest addressing the clarity of figures, particularly Fig. 3, to accurately reflect performance differences, and providing confidence intervals for the experimental results to substantiate claims of significance. Lastly, ensure that the relevance of all sections, including Neural Architecture Search, is clearly justified.