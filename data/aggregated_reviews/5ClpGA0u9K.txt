ID: 5ClpGA0u9K
Title: Energy Rank Alignment: Using Preference Optimization to Search Chemical Space at Scale
Conference: NeurIPS
Year: 2024
Number of Reviews: 6
Original Ratings: 6, 6, 5, -1, -1, -1
Original Confidences: 4, 4, 3, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method called Energy Rank Alignment (ERA) for finetuning large language models (LLMs) aimed at molecular generation, paralleling Reinforcement Learning from Human Feedback (RLHF). The authors differentiate ERA from traditional RLHF methods like PPO and DPO by emphasizing its minimization objectives and reward function. The paper details the derivation of the ERA loss using KL divergence and provides a theoretical analysis of its properties. Experimental results demonstrate a distribution shift between models finetuned with ERA and those that were not, alongside a discussion of alignment settings related to IMDB movie reviews.

### Strengths and Weaknesses
Strengths:
- The proposed ERA method is innovative for designing property-conditioned molecules and aligns well with LLMs.
- The paper includes a thorough derivation of the ERA loss and a solid theoretical analysis.
- Experimental results generally support the efficacy of the ERA method in inducing a distribution shift.

Weaknesses:
- The discussion on related work regarding transformer models and LLMs using reinforcement learning is insufficient, lacking references to relevant studies.
- The absence of baseline evaluations for DPO and PPO limits the comparative analysis of ERA's performance.
- Additional details on experimental settings and methodologies are needed for clarity.

### Suggestions for Improvement
We recommend that the authors improve the discussion of related work by including references to studies on transformer models and reinforcement learning for molecular generation. Additionally, incorporating baseline evaluations of DPO and PPO would provide valuable context for ERA's performance. The authors should also clarify experimental settings, addressing questions such as the choice of optimization objectives, the handling of multiple properties, and the sampling of chemically invalid molecules. Furthermore, a discussion on the scalability of their method with larger models and higher compute budgets would enhance the paper's depth.