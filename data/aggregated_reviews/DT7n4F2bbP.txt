ID: DT7n4F2bbP
Title: Tensor-Based Synchronization and the Low-Rankness of the Block Trifocal Tensor
Conference: NeurIPS
Year: 2024
Number of Reviews: 5
Original Ratings: 7, 7, 4, 6, -1
Original Confidences: 4, 3, 4, 4, -1

Aggregated Review:
### Key Points
This paper presents a method for camera pose synchronization using trifocal tensors, focusing on estimating trifocal tensors from calibrated images and employing HOSVD for tensor projection. The authors propose an iterative algorithm for estimating scales and completing the block tensor, contributing to the understanding of multiple-view geometry. However, the practical application of the method is limited by runtime, accuracy, and input size constraints.

### Strengths and Weaknesses
Strengths:
- The paper introduces a strong theoretical framework for trifocal tensor synchronization and contributes significantly to multi-view geometry.
- The proposed algorithm is based on solid theory, demonstrating potential benefits in translation estimation accuracy.

Weaknesses:
- The experimental validation is weak, particularly with simple datasets like EPFL, where the method fails on easier sequences (CastleP19, CastleP30).
- The choice of baselines for comparison is inadequate, with outdated methods like LUD being used, and the rotation averaging method remains unclear.
- The method's performance is heavily reliant on calibration, limiting its applicability in uncalibrated scenarios.
- The computational efficiency is poor, with the method being significantly slower than existing alternatives.

### Suggestions for Improvement
We recommend that the authors improve the experimental validation by using more challenging datasets and providing a clearer comparison with state-of-the-art methods, including recent deep learning approaches. Additionally, consider employing rotation averaging techniques from the Theia library and alternative imputation methods like HOALS or TNNM to enhance robustness. Address the limitations of the method regarding noise sensitivity and scalability, and provide a sensitivity analysis to demonstrate performance under varying conditions. Lastly, we suggest including more visualizations to illustrate the results of camera synchronization and the accuracy of the imputed data, which would help clarify the practical impact of the proposed method.