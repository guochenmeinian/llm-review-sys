ID: PLbFid00aU
Title: The Impact of Geometric Complexity on Neural Collapse in Transfer Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 5, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into the relationship between geometric complexity (GC) and neural collapse (NC), proposing that GC serves as a robust metric that connects the flatness of the loss surface with NC. The authors derive theoretical bounds indicating that GC can control NC under certain assumptions and empirically demonstrate that factors affecting GC, such as learning rate and batch size, also influence NC. The study highlights that lower GC during pre-training correlates with improved transfer learning outcomes, particularly in few-shot tasks.

### Strengths and Weaknesses
Strengths:
- The paper offers a novel perspective by linking GC with NC, potentially unifying various strands of research in deep learning.
- The empirical evaluation is comprehensive, covering multiple datasets and architectures, and includes valuable ablation studies.
- The structure and clarity of the paper facilitate understanding, with well-presented figures and detailed experimental setups.

Weaknesses:
- The theoretical foundation is limited, relying on strong assumptions that may not hold in practical scenarios, such as the Poincar√© inequality.
- The empirical focus on image classification tasks raises questions about the generalizability of the findings to larger datasets or other domains.
- There is a lack of thorough comparison between GC and other complexity measures, making it difficult to assess its relative merits.
- The paper shows correlations between GC, NC, and transfer performance but does not establish causation, leaving alternative explanations unexplored.

### Suggestions for Improvement
We recommend that the authors improve the theoretical foundation by providing empirical evidence that the strong assumptions hold in realistic settings or by deriving results under weaker assumptions. Additionally, expanding the empirical evaluation to include a broader range of tasks and scales would enhance the generalizability of the findings. A more thorough comparison of GC with other complexity measures in the literature is necessary to clarify its unique contributions. Finally, we suggest conducting a rigorous causal analysis to explore the mechanisms by which GC influences NC and transfer learning, thereby adding depth to the analysis.