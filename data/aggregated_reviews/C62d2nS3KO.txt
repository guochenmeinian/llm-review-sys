ID: C62d2nS3KO
Title: Multistep Distillation of Diffusion Models via Moment Matching
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 6, 6, 6, 6, 7, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 5, 3, 3, 3, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method for distilling diffusion models into fewer sampling steps, leveraging moment matching to enhance efficiency. The authors propose a technique that distills many-step diffusion models into few-step models, achieving state-of-the-art results on the Imagenet dataset. The method incorporates conditioning on noisy data during expectation matching, distinguishing it from previous approaches. Experimental results validate the effectiveness of the proposed method, particularly with an 8-step model.

### Strengths and Weaknesses
Strengths:
1. The paper introduces a well-motivated and novel method for distilling diffusion models, achieving impressive results on standard benchmarks.
2. The moment matching formulation is theoretically sound and offers practical improvements, including conditioning on noisy input.
3. The experimental validation is comprehensive, demonstrating the superiority of the proposed method over existing models.

Weaknesses:
1. The Moment Matching Distillation section is overly mathematical and difficult to understand; the authors should improve clarity.
2. The experiments lack detailed ablation studies, particularly regarding the impact of different sampling steps and optimization setups.
3. The analysis of conditional sampling is unclear, and the authors need to address potential contradictions with existing literature.
4. Some notations and definitions require clarification for better coherence.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the Moment Matching Distillation section to enhance reader comprehension. Additionally, we suggest including more detailed ablation studies to elucidate the effectiveness of alternative formulations and sampling steps. The authors should also clarify the analysis of conditional sampling and address any contradictions with existing methods. Furthermore, providing theoretical explanations for observed performance variations with different step counts would strengthen the paper. Lastly, we encourage the authors to clarify notations and definitions to ensure consistency throughout the paper.