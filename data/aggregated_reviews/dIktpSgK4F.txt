ID: dIktpSgK4F
Title: Dissecting Query-Key Interaction in Vision Transformers
Conference: NeurIPS
Year: 2024
Number of Reviews: 14
Original Ratings: 3, 7, 7, 8, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis framework utilizing Singular Value Decomposition (SVD) to investigate query-key interactions in Vision Transformers (ViTs). The authors propose that early layers group similar tokens, while deeper layers contextualize dissimilar tokens, supported by empirical evidence across various ViT architectures. The findings reveal that the nature of interactions varies with layer depth, contributing to a deeper understanding of self-attention mechanisms.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and clearly motivated, presenting an innovative approach to analyzing query-key interactions.
- The theoretical justification for using SVD is robust, backed by solid empirical analysis.
- The findings provide valuable insights into the dynamics of self-attention in ViTs and have potential applications in other domains.

Weaknesses:
- The analysis primarily reaffirms known conclusions about attention mechanisms without introducing novel insights.
- The scope of analysis is limited to specific training objectives, lacking exploration of others like masked image modeling (MIM).
- Visualizations and figures are inadequately labeled and do not effectively relate to the claims made, diminishing clarity.

### Suggestions for Improvement
We recommend that the authors improve the clarity of figures by ensuring proper labeling, particularly for the x-axis. Additionally, a more thorough analysis of the behavior of deeper layers is necessary; for instance, testing the impact of overriding attention scores could enhance understanding. We suggest expanding the analysis to include various training objectives beyond those currently examined, such as MIM and JEPA, to provide a more comprehensive view of query-key interactions. Finally, visualizations should focus on specific images to illustrate how different layers and heads process visual information, thereby creating a coherent narrative around feature extraction.