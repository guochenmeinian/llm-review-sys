ID: kayoyzcsTa
Title: $\textit{Lost in Translation, Found in Spans}$: Identifying Claims in Multilingual Social Media
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on claim span identification across six languages, including English and several Indian languages. The authors propose a methodology to automatically construct a multilingual corpus of claims by matching manually written claims to their source sentences. They train various transformer-based models, including mBERT, mDeBERTa, and XLM-R, and explore different training approaches. The results indicate that multilingual models generally outperform monolingual models, although performance varies across languages. The authors also assess the performance of GPT models, finding that the best-performing GPT model does not surpass the best translation baseline.

### Strengths and Weaknesses
Strengths:
- The task is significant for enhancing access to fact claim verification, particularly in non-English languages.
- The paper is generally clear and proposes to release the dataset.
- A wide variety of baselines are compared, including both trained and pretrained models.
- The annotation approach is generalizable for constructing datasets in other languages.

Weaknesses:
- The automated annotation method may skew the dataset towards more easily identifiable claims, potentially excluding subtler claims.
- The results align with existing literature but lack specific evidence on the performance benefits of multilingual models for this task.
- The dataset is relatively small for non-English languages, raising concerns about quality verification.

### Suggestions for Improvement
We recommend that the authors improve the discussion on how the automated annotation approach may influence dataset composition, particularly regarding the inclusion of subtle claims. Additionally, we suggest that the authors provide concrete evidence of performance improvements when using multilingual models compared to English-trained models. It would also be beneficial to manually verify at least the test sets to ensure data quality, given the small size of the dataset. Finally, we encourage the authors to clarify the methodology for collecting post texts and to rephrase the confusing sentences in the abstract for better clarity.