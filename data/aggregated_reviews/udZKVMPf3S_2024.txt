ID: udZKVMPf3S
Title: Calibrating Reasoning in Language Models with Internal Consistency
Conference: NeurIPS
Year: 2024
Number of Reviews: 12
Original Ratings: 7, 6, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper investigates the correlation between CoT reasoning and internal representations in Transformer models, revealing inconsistencies between internal representations in different layers. The authors propose an internal consistency metric that, when integrated with self-consistency (SC+IC), enhances model predictions without incurring significant additional costs. The study includes extensive experiments across multiple datasets and model families, demonstrating that SC+IC outperforms SC and SC+$\Delta$. 

### Strengths and Weaknesses
Strengths:
- The correlation between internal representations and CoT reasoning is a novel topic, providing valuable insights for researchers in CoT prompting.
- The paper is logically structured, with solid experimental design that effectively correlates internal consistency with prediction correctness.
- Robust improvements of SC+IC over SC and SC+$\Delta$ are shown across various datasets and models.

Weaknesses:
- The improvement of SC+IC over SC is marginal (+1.2% on average), potentially due to the simplistic use of internal consistency as weights. Alternative weighting strategies, such as exponentiating internal consistency, could yield better results.
- Section 4.4 lacks clarity regarding the relationship between attention weights, top value vectors, and internal inconsistency; further elaboration on the probe vector is needed.
- Important details, such as those in Figure 6, are difficult to understand without consulting the Appendix; these should be reorganized in the main text.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Section 4.4 by providing a detailed explanation of how attention weights and top value vectors relate to internal inconsistency, as well as elaborating on the probe vector. Additionally, we suggest reorganizing critical details from the Appendix into the main paper for better accessibility. To enhance the performance of SC+IC, consider experimenting with alternative weighting strategies for internal consistency. Furthermore, addressing the motivation for measuring internal consistency against final predictions and exploring its applicability to non-binary answers would strengthen the paper.