ID: ndzErs0RfF
Title: Enhancing Complex Question Answering over Knowledge Graphs through Evidence Pattern Retrieval
Conference: ACM
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for improving question answering (QA) over knowledge graphs (KGs) by focusing on subgraph extraction. The authors introduce the EPR method, which extracts atomic patterns through dense retrieval, systematically enumerates combinations to generate candidate evidence patterns, and ranks them using a trained model. Experimental results indicate that EPR + NSM achieves the best performance on the CWQ dataset, although there remains a performance gap on WebQSP. The paper is well-written and includes detailed experiments demonstrating the effectiveness of the proposed method.

### Strengths and Weaknesses
Strengths:
- The focus on subgraph extraction is crucial for enhancing QA performance in two-stage IR-based KGQA systems.
- The proposed method provides a systematic approach to subgraph construction, expanding evidence paths and offering explainability.
- Extensive experiments validate the effectiveness of the subgraph construction method.

Weaknesses:
- Some subsections lack clarity and could benefit from clearer organization, such as distinguishing between different topics in Section 4.1.
- Certain technical details, particularly regarding the BERT-based models, are inadequately explained.
- The use of Freebase KG, which is smaller and older than Wikidata, raises concerns about scalability and the computational costs associated with dense encoder indexing.

### Suggestions for Improvement
We recommend that the authors improve the clarity of subsections, particularly in Section 4.1, by highlighting different topics. Additionally, the authors should provide clearer explanations of the technical details related to the BERT-based models. It would be beneficial to consider using a larger and more contemporary KG, such as Wikidata, to enhance the scalability of the method. Furthermore, addressing the questions raised regarding the initial evidence facts, sampling ratios, and the handling of relations in CVTs would strengthen the paper's contributions. Lastly, we suggest including a comparison with fine-tuned public LLM models to demonstrate the added value of the proposed QA methods.