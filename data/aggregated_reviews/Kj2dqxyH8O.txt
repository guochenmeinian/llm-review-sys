ID: Kj2dqxyH8O
Title: Model-Agnostic Social Network Refinement with Diffusion Models for Robust Social Recommendation
Conference: ACM
Year: 2024
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a model-agnostic social network refinement framework (ARD-SR) that utilizes diffusion models to enhance social recommendation systems by addressing noise and sparsity in social connections. The authors propose an adaptive module driven by user preferences to mitigate the impact of noise, and they provide a comprehensive analysis of the algorithm's time complexity, conducting experiments across various datasets to validate the effectiveness of their approach. The framework is designed to integrate seamlessly with different recommendation algorithms without necessitating significant structural changes.

### Strengths and Weaknesses
Strengths:
1. The paper is innovative in applying diffusion models to tackle noise and sparsity in social recommendation systems.
2. The curriculum learning strategy enhances the model's denoising capability.
3. Extensive experiments validate the efficacy of the proposed framework across multiple datasets and metrics.
4. The framework is well-structured and clearly presented.

Weaknesses:
1. The introduction lacks a clear distinction from recent approaches like RecDiff, which could emphasize the novelty of this work.
2. The datasets used are limited in scale, affecting the assessment of practical effectiveness.
3. The ablation study is incomplete, and the paper lacks case studies and error analysis.
4. There is insufficient discussion on hyperparameters, particularly the decay factor and noise bounds, and the paper does not provide the preprocessed datasets or code for reproducibility.

### Suggestions for Improvement
We recommend that the authors improve the introduction by clearly distinguishing their work from RecDiff to highlight its novelty. Additionally, providing experimental results on larger-scale datasets would enhance the practical relevance of the findings. The authors should clarify the encoders fr and fs used for final embeddings, as well as the rank in Equation (20). It would be beneficial to indicate the execution order of algorithm steps in Figure 1. Furthermore, a more thorough discussion on the decay factor and hyperparameters $\beta_{\text{min}}$ and $\beta_{\text{max}}$ is necessary, along with a comparison of runtime performance across varying data scales. Lastly, addressing minor formatting inconsistencies and spelling errors would improve the overall quality of the manuscript.