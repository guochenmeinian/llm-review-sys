ID: wUNPmdE273
Title: Transitivity Recovering Decompositions: Interpretable and Robust Fine-Grained Relationships
Conference: NeurIPS
Year: 2023
Number of Reviews: 7
Original Ratings: 6, 5, 7, -1, -1, -1, -1
Original Confidences: 3, 4, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for fine-grained representation learning through Transitivity Recovering Decompositions (TRD), which identifies interpretable graph representations of local-to-global relationships in fine-grained visual categorization (FGVC). The authors theoretically demonstrate the existence of semantically equivalent graphs and derive their information theoretic and topological properties. They conduct experiments to validate the effectiveness of TRD, achieving state-of-the-art performance across various FGVC benchmarks.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and easy to follow.
- The motivation for the research is strong, and the proposed technique is solid.
- TRD is theoretically and empirically validated, demonstrating consistent state-of-the-art performance on multiple datasets.

Weaknesses:
- The term "abstract" in relation to local-to-global relationships is not adequately explained.
- There is a lack of comprehensive literature review and comparison with relevant methods, raising concerns about the experimental setup and fairness of comparisons.
- The experimental results in Table 1 appear to be copied from the Relational Proxies paper, with differing experimental setups.
- The authors do not address the potential over-smoothing issue in deep GNNs, nor do they clarify the relationship between TRD and Relational Proxies.
- The introduction lacks a high-level overview of TRD, and the inference pipeline is not clearly described.

### Suggestions for Improvement
We recommend that the authors improve the explanation of the term "abstract" to enhance clarity. Additionally, a comprehensive literature review should be included to contextualize their work within existing methods. The authors should ensure that their experimental setup aligns with common practices in FGVC, such as resizing images to 448Ã—448, and provide detailed information about the pre-trained models used. To address concerns regarding over-smoothing, we suggest that the authors investigate the impact of the number of layers on model performance. Furthermore, including a clear overview of the TRD pipeline in the introduction and providing training and testing pseudo code would enhance the paper's clarity. Lastly, expanding the robustness analysis to include causal interventions would provide deeper insights into the interpretability of TRD.