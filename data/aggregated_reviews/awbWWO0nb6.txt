ID: awbWWO0nb6
Title: Characterization of Overfitting in Robust Multiclass Classification
Conference: NeurIPS
Year: 2023
Number of Reviews: 20
Original Ratings: 6, 5, 4, 7, 5, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 3, 2, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an analysis of robust overfitting in machine learning, focusing on the relationship between robust accuracy, the number of classes (m), the number of accuracy queries (k), and the size of the test dataset (n). The authors derive upper and lower bounds for robust overfitting bias in multiclass settings, extending previous works to an adversarial context. The authors also discuss theoretical results regarding the robustness of machine learning models in the context of fixed test sets, arguing that their findings have practical implications, particularly in benchmarking platforms like RobustBench. However, concerns remain about the practical significance of these results, especially regarding the reliance on a single test set and the strong assumption of uniformly distributed labels, which limits the generalizability of the theoretical contributions.

### Strengths and Weaknesses
Strengths:
- The paper demonstrates exceptional writing quality and clarity, with a well-structured introduction that effectively outlines its contributions.
- The theoretical results are presented with clear proofs, and the related works section acknowledges prior research while highlighting key distinctions.
- The paper addresses a challenging problem in machine learning and contributes to the theoretical understanding of robustness.
- The authors provide a clear rationale for their choice of setting and align their work with the broader scope of NeurIPS.

Weaknesses:
- The level of originality in the theoretical results is limited, as they extend previous works without significant new contributions.
- The reliance on the assumption of uniformly distributed labels limits the applicability of the theoretical results, as this condition is rarely met in practice.
- The practical impact of the theoretical findings remains unclear, as many machine learning practitioners do not depend on a single test set for evaluating methods.
- The paper lacks practical experiments and illustrations, which would enhance understanding and applicability.
- Several errors in notation and assumptions, such as the treatment of the perturbation radius (r) and the uniformity of labels, raise concerns about the clarity and realism of the results.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by addressing the following points:
- Provide a more detailed discussion of the implications and significance of the bounds presented, including their relationship to existing theories.
- Clarify the role of the perturbation set U and how varying the radius r affects the bounds.
- Include practical examples or numerical experiments to illustrate the theoretical results and their applicability.
- Correct the identified errors in notation, such as the division of n in Algorithm 2 and the bounds on |B_i|.
- Enhance the motivation and contextualization of the study to reach a broader audience, ensuring that the assumptions made are realistic and well-explained.
- Improve the practical relevance of the results by providing clearer connections between the theoretical findings and real-world applications in machine learning.
- Explore alternative assumptions regarding label distributions to enhance the generalizability of the theoretical contributions.