ID: OzjBohmLvE
Title: Achieving $\mathcal{O}(\epsilon^{-1.5})$ Complexity in Hessian/Jacobian-free Stochastic Bilevel Optimization
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 5, 5, 7, 6, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 2, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents faster first-order stochastic algorithms for bilevel optimization, leveraging the implementation of Hessian-vector products via finite differences of gradients. The authors propose a novel Hessian-free bilevel optimization algorithm called FdeHBO, which claims to improve upon the state-of-the-art F3SA in terms of iteration complexity. The paper includes convergence analysis and empirical results, demonstrating the effectiveness of the proposed methods.

### Strengths and Weaknesses
Strengths:  
- The study addresses an important problem in stochastic bilevel optimization, providing a complexity upper bound that improves upon previous works.  
- The proposed FdeHBO algorithm is novel and shows promising convergence rates, with well-organized presentation and convincing experimental results.  
- The investigation into Hessian-free approaches in the nonconvex-strongly-convex setting is significant and contributes to the theoretical landscape.

Weaknesses:  
- The claim of novelty is undermined by the well-known fact that Hessian-vector products can be approximated using finite differences, suggesting that the results may not be as innovative as presented.  
- The proof of Lemma 5 is incorrect, as it misapplies the mean value theorem, leading to potential flaws in the main theorem's proof.  
- The paper inconsistently uses multiple names for the same baseline algorithm, which could confuse readers.  
- The projection technique is limited, and the analysis does not adequately cover simpler SGD-type methods, which could hold practical significance.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their claims regarding novelty, particularly concerning the use of finite differences for Hessian-vector estimation. Additionally, we suggest revising the proof of Lemma 5 to correct the identified errors and ensure the validity of the main theorem. The authors should unify the naming conventions for the baseline algorithms to avoid confusion. Furthermore, we encourage the authors to explore generalizing the projection technique and to provide a more thorough analysis of simpler SGD-type methods. Lastly, a clearer explanation of the auxiliary projection's impact on convergence guarantees would enhance the paper's rigor.