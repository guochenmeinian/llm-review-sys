ID: oulcuR8Aub
Title: Med42 - Evaluating Fine-Tuning Strategies for Medical LLMs: Full-Parameter vs. Parameter-Efficient Approaches
Conference: AAAI
Year: 2024
Number of Reviews: 4
Original Ratings: 8, 6, 7, 7
Original Confidences: 3, 4, 4, 4

Aggregated Review:
### Key Points
This paper investigates the effectiveness of LoRA fine-tuning compared to full-parameter fine-tuning of LLMs in the healthcare domain, specifically using the 7B and 70B Llama-2 models. The authors evaluate performance against state-of-the-art models like GPT-4 and Med-PaLM-2, reporting results on various medical benchmarks. A decontamination pipeline is introduced to ensure a fair evaluation by removing common samples between training and testing splits.

### Strengths and Weaknesses
Strengths:
- The evaluation is comprehensive across multiple medical datasets, enabling in-depth analysis.
- The dataset compiled from open medical sources is comprehensive and suitable for clinical applications.
- The focus on data decontamination enhances the relevance of the results.
- The work is highly relevant to the venue's topic.
- The detailed description of hyperparameters supports reproducibility.

Weaknesses:
- The claim that parameter-efficient fine-tuning closely matches full-parameter fine-tuning is a known research artifact; the authors should emphasize their contributions regarding the training dataset and decontamination pipeline rather than focusing heavily on fine-tuning comparisons.
- The instruction tuning methodology requires more detailed description, either in the main paper or the appendix.
- The results are largely expected and consistent with prior studies, lacking novelty.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Table 1 by explicitly indicating which backbone corresponds to PE-FT and FP-FT, and including a column for llama7b. Additionally, detailing the computational resources required for both PE and FP fine-tuning, in terms of GPU hours and memory, would provide valuable insights into the resource intensity of each method. Furthermore, it would be beneficial to present performance results for LoRA applied only to attention layers, as this is a common approach. Lastly, please correct the typo in Table 1 where GPT-3.5 is mistakenly referred to as GPT-3.4.