ID: kKKzd8SaMy
Title: The Interpreter Understands Your Meaning: End-to-end Spoken Language Understanding Aided by Speech Translation
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to pretraining end-to-end spoken language understanding (SLU) models using speech translation (ST) for both intra and cross-lingual scenarios. The authors argue that ST captures high-level semantic information and long-term dependencies, outperforming traditional automatic speech recognition (ASR) methods. The paper includes experiments on five datasets, including two newly proposed ones, demonstrating that ST pretraining enhances performance across various benchmarks. Additionally, the authors emphasize the importance of preserving ST-pretrained knowledge through Bayesian regularization, particularly in low-resource settings.

### Strengths and Weaknesses
Strengths:
- The approach is well-motivated, effectively leveraging ST for SLU tasks, and is supported by strong empirical validation across multiple datasets.
- The paper provides valuable insights into the cross-lingual transfer capabilities of ST-pretrained models, especially in zero-shot scenarios.
- The commitment to open-sourcing code and models fosters community engagement and future research.

Weaknesses:
- The experimental results are limited to single datasets for each task, lacking broader generalizability.
- The paper lacks a comprehensive qualitative discussion on the strengths and weaknesses of the ST-pretraining approach, particularly in comparison to ASR-pretrained models.
- The organization and clarity of the presentation could be improved, as some sections contain redundant context and unclear comparisons.

### Suggestions for Improvement
We recommend that the authors improve the organization of the paper to enhance readability and clarity, particularly in the presentation of results. It would be beneficial to provide a more unified experimental setup across datasets to strengthen the validity of the findings. Additionally, we suggest including a detailed qualitative analysis comparing ST-pretrained models with ASR and acoustic pretrained models, highlighting specific examples of performance differences. Finally, we advise relocating detailed methodologies, such as L2-SP and EWC, to the appendix while presenting the results of speech summarization in the main article for better coherence.