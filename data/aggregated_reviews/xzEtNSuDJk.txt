ID: xzEtNSuDJk
Title: LIBERO: Benchmarking Knowledge Transfer for Lifelong Robot Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 16
Original Ratings: 6, 6, 7, 7, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
We present LIBERO, a lifelong learning benchmark comprising 130 language-conditioned robot manipulation tasks designed to assess distribution shifts in task goals, object types, and locations. The authors conduct extensive experiments and ablation studies to explore the impact of various factors on performance, including network architecture and lifelong learning algorithms. We agree that a more exhaustive evaluation of lifelong algorithms is necessary, acknowledging current limitations in task variety and environment design. The LIBERO framework generates tasks through a three-step process but faces challenges in defining task difficulty and generating diverse task descriptions. We recognize the need for clearer documentation on task creation and will enhance it to facilitate user engagement. Additionally, we observe unexpected performance in forward transfer tasks, which will be clarified in our language to better reflect the findings. We acknowledge the potential for curriculum learning and the exploration of reinforcement learning (RL) as future directions, while noting the challenges associated with defining dense reward functions.

### Strengths and Weaknesses
**Strengths:**
- The problem setup is novel and meaningful, addressing a gap in lifelong learning within language-conditioned robot manipulation.
- The benchmark includes a variety of realistic indoor scenes and household objects.
- Extensive experiments are performed to analyze critical performance factors.
- The framework is designed for accessibility and reproducibility, allowing future research to build upon it.
- Supporting documents ensure reproducibility, and the codebase is well-documented.
- The documentation is being improved to ensure clarity for users creating new tasks.
- The authors are open to exploring advanced methodologies, such as using LLMs for task description generation and incorporating RL.

**Weaknesses:**
- Key details about the simulator, task designs, action space, and data are lacking, hindering evaluation of the work's contribution.
- The benchmark primarily features pick-and-place and drawer-opening tasks, raising concerns about generalizability to other manipulation tasks.
- The limited number of human demonstrations (50 per task) may not suffice for learning effective policies, especially for long-horizon tasks.
- The current task set is limited to 10 tasks for LIBERO-100, which may not sufficiently cover the desired distribution shift factors.
- There is a lack of detailed statistics on human demonstrations and the task design process, which could hinder understanding of the benchmark's robustness.
- The reliance on behavioral cloning without exploring RL limits the potential insights that could be gained from comparing these approaches.

### Suggestions for Improvement
We suggest providing more information on the underlying simulator, including its speed for RL applications. Additional details on task design, action space, and observation space are necessary. We recommend expanding the number of tasks in LIBERO-100 to better examine various distribution shift factors and enhance the benchmark's challenge. We propose providing comprehensive details on the human demonstration data collection process, including total frames and their distribution across tasks. We also suggest exploring reinforcement learning algorithms alongside behavioral cloning to uncover new challenges and insights. A comparison table with other benchmarks would enhance understanding of LIBERO's contributions. Lastly, we should consider using LLMs or paraphrase models to diversify the language used in task descriptions, enhancing the framework's linguistic variety. Clarifying the pretraining experiments and addressing the unexpected negative impact of pretraining on downstream performance would strengthen the paper.