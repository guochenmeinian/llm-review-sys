ID: Mdd3f8Cui8
Title: Latent Feature Mining with Large Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 5, 3, 4, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a framework that utilizes large language models (LLMs) to augment observed features with inferred latent features, framing the task as a text-to-text propositional reasoning problem. The authors validate their method through a case study in the criminal justice system, demonstrating improved predictive performance. The approach is adaptable across various domains and shows promise in enhancing downstream tasks.

### Strengths and Weaknesses
Strengths:
- The paper is well-written with clear logic and descriptive diagrams.
- The methodology of using LLMs for latent feature inference is novel and shows significant performance improvements in predictive tasks, particularly in the criminal justice context.

Weaknesses:
- Concerns regarding the potential biases of LLMs in generating latent features, particularly related to sensitive attributes like race and gender, remain unaddressed.
- The paper lacks a thorough evaluation across multiple datasets and does not provide publicly available code for reproducibility.
- There is insufficient exploration of the generalizability of the method, particularly regarding which latent features are effectively constructed and which may be prone to bias.

### Suggestions for Improvement
We recommend that the authors improve their evaluation of the framework by conducting assessments on multiple datasets to establish generalizability. Additionally, we suggest including ablation studies to explore the impact of removing certain features on model performance. Addressing the potential biases in LLM outputs is crucial; thus, we encourage the authors to evaluate the latent features for bias against sensitive attributes. Furthermore, clarifying the rationale behind the selection of latent features and their relationship to causal inference would enhance the paper's robustness. Lastly, releasing the code for public access would facilitate further evaluation and validation of the proposed method.