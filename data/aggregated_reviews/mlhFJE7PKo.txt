ID: mlhFJE7PKo
Title: HEST-1k: A Dataset For Spatial Transcriptomics and Histology Image Analysis
Conference: NeurIPS
Year: 2024
Number of Reviews: 7
Original Ratings: 9, 7, 6, 8, -1, -1, -1
Original Confidences: 5, 4, 4, 4, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents HEST-1k, a dataset comprising 1108 paired spatial transcriptomic (ST) profiles and H&E stained whole slide images (WSI) along with their metadata. The dataset spans 131 public and internal cohorts, covering 25 organs, two species, and 320 cancer samples from 25 cancer types. The authors propose the HEST-library, a Python package for querying and assembling ST data, and demonstrate its potential through use cases such as benchmarking foundation models for histopathology, biomarker identification, and multimodal representation learning.

### Strengths and Weaknesses
Strengths:  
- **Diversity of Data**: The dataset includes a wide range of samples from various organs and cancer types, enhancing its utility for computational pathology.  
- **Comprehensive Dataset**: HEST-1k is well-assembled, providing a rich resource for multiple applications.  
- **Data Processing Tools**: The HEST-library facilitates integration and processing of ST data, addressing common issues like missing data and alignment mismatches.  
- **Benchmarking Framework**: HEST-Benchmark offers a robust framework for evaluating histopathology models on diverse tasks.  
- **Clarity**: The paper is clearly written, with well-documented methodologies and related work.

Weaknesses:  
- **Noise in ST Data**: The dataset acknowledges inherent noise and potential issues with data alignment and staining artifacts.  
- **Batch Effects**: Significant batch effects across samples and technologies were not quantified or mitigated, which could impact dataset quality.  
- **Fragmentation of Benchmarks**: Many benchmarks consist of data from fewer than five patients, raising concerns about statistical significance.  
- **Incomplete Documentation**: The project website is poorly designed, and links to the dataset and GitHub are missing in the abstract.

### Suggestions for Improvement
We recommend that the authors improve the dataset by applying some basic normalization and releasing it as separate subsets that can be programmatically requested through the developed package. This would enhance usability. Additionally, please clarify the use of discovery tasks and discuss opportunities for representation learning beyond fine-tuning existing models. Addressing batch effects and providing analysis on the theoretical performance upper bound would also strengthen the dataset's reliability. Finally, please reformat references to a conventional style and ensure that the project website is complete and user-friendly.