ID: OU1uqd1vyw
Title: CLUES: Collaborative Private-domain High-quality Data Selection for LLMs via Training Dynamics
Conference: NeurIPS
Year: 2024
Number of Reviews: 23
Original Ratings: 4, 4, 7, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel data quality control technique aimed at enhancing data quality in collaborative training settings, particularly for large language models (LLMs). The authors propose a method that scores training samples by tracing gradients of low-rank adapters, filtering out low-quality data locally, and adaptively merging model parameters. Evaluations on heterogeneous medical and multilingual datasets demonstrate that training on high-quality data selected by this method outperforms other data selection methods. The authors claim significant performance improvements and suggest that their approach offers a general, efficient means to identify high-quality data. Additionally, the paper incorporates global thresholds to effectively manage domain heterogeneity, addressing the interference of local models during merging. The authors justify the necessity of global thresholds by demonstrating that they minimize the validation loss of the global model, unlike local thresholds. Experiments conducted on the FiQA dataset validate the effectiveness of their approach in various data quality scenarios, showing significant improvements in model performance metrics such as precision, recall, and accuracy. Furthermore, the paper provides a comprehensive exploration of data selection methods in collaborative settings, specifically addressing low-quality data challenges, with refined notations, detailed pseudo-code, and extensive experimental results, including evaluations on a new financial dataset.

### Strengths and Weaknesses
Strengths:
- The use of training dynamics to score and filter data for collaborative fine-tuning is a commendable approach.
- The method provides a general pipeline applicable to various models without requiring task-specific adjustments.
- The authors provide a clear mathematical formulation for determining global thresholds, enhancing the technical rigor of their approach.
- Extensive experimental results demonstrate the effectiveness of their data selection methods, achieving over 99% accuracy in selecting high-quality data.
- The paper is well-structured and easy to follow, with clear diagrams that enhance understanding.

Weaknesses:
- The evaluation is limited to medical datasets, raising concerns about the generalizability of the proposed method; broader experiments across diverse domains are needed.
- The generation of 40% low-quality data may not reflect real-world scenarios; testing with varying proportions of low-quality data would be beneficial.
- The reliance on only 10 public samples as anchor data for calculating the global threshold raises questions about reliability; a more rigorous justification or experimentation with different numbers of anchor samples is necessary.
- The conclusion is based on limited observations from selected datasets, which may not fully represent broader applicability.
- Some reviewers noted a lack of clarity regarding the performance of alternative data evaluation methods, which performed poorly in comparison to the authors' approach.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their findings by conducting experiments on a wider range of datasets from different domains. Additionally, consider testing with varying proportions of low-quality data to assess the robustness of the method. Clarifying the choice of using only 10 anchor samples and providing a more rigorous justification or experimenting with different numbers of anchor samples would strengthen the method's credibility. Furthermore, we suggest including an analysis to explain the superior performance of the proposed method compared to the Oracle method, as this could enhance the overall argument. We also recommend improving the discussion on the necessity and implications of global thresholds, ensuring that the justification is clearly articulated. Additionally, further elaboration on the scalability of their per-sample gradient computation, particularly addressing how micro-batching impacts parallel processing and efficiency, would be beneficial. Lastly, expanding the discussion on the generalizability of the findings to other domains and ensuring that the implications of the results are well articulated could strengthen the overall contribution of the paper.