ID: ea4oxkiMP7
Title: EgoChoir: Capturing 3D Human-Object Interaction Regions from Egocentric Views
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 6, 6, 7, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 4, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an approach to estimate human-object interaction from egocentric videos by integrating head movement, 3D object meshes, and 2D video inputs. The authors propose a framework called EgoChoir, which utilizes modality-wise encoders to extract features and infer interaction concepts. The evaluation is conducted on the Ego-Exo4D and GINO datasets, with additional annotations for 3D human contact and object affordance.

### Strengths and Weaknesses
Strengths:
- The model's information flow is logically structured.
- Both quantitative and qualitative results provide significant insights into the method's performance.
- The paper introduces a novel framework that harmonizes multiple interaction clues, demonstrating effectiveness through comprehensive empirical evaluation.

Weaknesses:
- The contributions regarding novelty over related work, particularly LEMON, are unclear.
- A critical discussion of the model's performance is lacking, raising questions about specific results.
- The paper is verbose and difficult to read, obscuring the true contributions and motivations behind design choices.
- Important technical details and dataset statistics are missing, particularly regarding the new dataset's composition and the role of learnable tokens in gradient modulation.

### Suggestions for Improvement
We recommend that the authors improve clarity by tightening the writing and reducing verbosity, particularly in the abstract and introduction. Additionally, we suggest providing a more critical discussion of the model's performance, especially regarding the results depicted in figures. The authors should clarify the differences between their approach and LEMON, and better integrate Figures 1-3 with the text to highlight novelties. Furthermore, including statistical information about the dataset and elaborating on the application examples of the proposed method would enhance understanding. Lastly, addressing the clarity of the gradient modulation process and the meaning of "non-overlapping" in the training and test sets is essential.