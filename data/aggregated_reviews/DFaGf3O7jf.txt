ID: DFaGf3O7jf
Title: Propagating Knowledge Updates to LMs Through Distillation
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 7, 6, 5, 6, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for updating knowledge in language models (LMs) through context distillation, enabling LMs to make inferences based on newly injected entity knowledge. The authors propose a two-step process: first, generating a transfer set of continuations for a definition sentence using a language model; second, fine-tuning a student model to align its output distribution with that of a teacher model conditioned on the definition. The results demonstrate that this method outperforms several baselines in terms of knowledge updates and retention of existing knowledge.

### Strengths and Weaknesses
Strengths:
- The paper addresses a significant issue of knowledge injection and propagation, presenting a novel method that is well-motivated and effectively evaluated.
- The evaluation shows the method's superiority over standard fine-tuning and other knowledge editing techniques, with insightful analyses provided.

Weaknesses:
- The method lacks transparency regarding what it teaches the models and the underlying mechanics of its effectiveness, although some analysis in Section 7 begins to address this.
- Concerns arise regarding the reported performance improvements, particularly related to potential overlaps between the generated transfer set and evaluation set probe sentences, which were not adequately addressed.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their methodology by providing more detailed explanations of the model's learning process and the implications of the results. Additionally, it would be beneficial to report the overlap levels between the transfer set and evaluation set, as well as include a baseline that fine-tunes on the transfer set alone. We also suggest exploring the performance of the method on larger models and different types of knowledge updates beyond entity definitions to enhance generalizability. Finally, addressing the writing issues, such as clarifying terms like "Finetuning on definition (full)" and "Finetuning on definition (last only)," would improve the paper's readability.