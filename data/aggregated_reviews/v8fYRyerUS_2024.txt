ID: v8fYRyerUS
Title: Integrating Object Detection Modality into Visual Language Model for Enhanced Autonomous Driving Agent
Conference: NeurIPS
Year: 2024
Number of Reviews: 3
Original Ratings: 7, 8, 3
Original Confidences: 5, 2, 3

Aggregated Review:
### Key Points
This paper presents a method for integrating Vision Language Models (VLMs) with object detection for autonomous driving applications. The authors propose a YOLOS-based detection network that enhances object detection accuracy and introduces trainable ID-separators for multicamera processing, which is crucial for comprehensive environmental understanding. The paper evaluates its approach using metrics such as ChatGPT scores, BLEU scores, and CIDEr metrics, highlighting the interpretability and safety improvements of the model.

### Strengths and Weaknesses
Strengths:
- The novelty of the YOLOS-based detection network improves object detection accuracy.
- The introduction of trainable ID-separators enhances the system's capability to process inputs from multiple cameras.
- The paper effectively addresses the limitations of the vanilla adapter and combines detection with the Llama-Adapter architecture for better decision-making.

Weaknesses:
- The experiments are limited to a specific dataset, raising concerns about generalization to larger datasets and complex environments.
- Critical computational requirements for inference, such as VRAM and inference time per frame, are not discussed.
- The qualitative evaluation of the impact of camera ID separators on output text is lacking.
- The clarity of certain technical terms and concepts, such as ID-separators and loss functions, is insufficiently explained.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their findings by testing the model on larger and more diverse datasets. It is essential to include detailed computational requirements for inference to assess real-time applicability in autonomous driving. Additionally, providing a sample text prompt related to the autonomous driving scenario and the corresponding YOLOS detections would enhance clarity. We also suggest that the authors clarify the definition and function of ID-separators and include a discussion on the loss functions used in training the detection network. Lastly, the safety section should be strengthened with specific analyses and visualizations regarding safety concerns and performance under various conditions.