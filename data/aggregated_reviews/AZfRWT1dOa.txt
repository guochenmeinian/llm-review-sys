ID: AZfRWT1dOa
Title: Not All Demonstration Examples are Equally Beneficial: Reweighting Demonstration Examples for In-Context Learning
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a study on the weights of different demonstrations in in-context learning (ICL), proposing a method to evaluate and optimize these weights to enhance performance. The authors introduce a scoring mechanism, the masked self-prediction (MSP) score, and utilize beam search for weight selection. The findings indicate that reweighting demonstrations can significantly improve ICL performance across various datasets and model sizes.

### Strengths and Weaknesses
Strengths:
- The proposed method is straightforward and easy to implement.
- The MSP score serves as a robust metric for evaluating in-context learning performance.
- The weight-searching method shows consistent improvements across different datasets and model sizes.
- The paper identifies a novel issue in ICL, emphasizing the unequal treatment of demonstrations.

Weaknesses:
- The experiments primarily focus on text classification tasks, leaving the effectiveness on text generation tasks unclear.
- The method introduces additional inference costs when searching for weights.
- There is a lack of strong baselines, limiting the comparative analysis of the proposed method's effectiveness.

### Suggestions for Improvement
We recommend that the authors improve the paper by:
1. Clarifying the relationship between demonstration selection and the proposed method, particularly in the context of a true few-shot setting without held-out validation data.
2. Including stronger baselines, such as retrieval/ranking based on query similarity, to better validate the proposed method's effectiveness.
3. Analyzing the sensitivity of the proposed method to the order of demonstrations and discussing the implications for inference costs, especially in real-time applications.
4. Providing insights or preliminary thoughts on the application of the proposed method to generative tasks.