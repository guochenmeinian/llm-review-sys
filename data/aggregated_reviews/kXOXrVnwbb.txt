ID: kXOXrVnwbb
Title: DaTaSeg: Taming a Universal Multi-Dataset Multi-Task Segmentation Model
Conference: NeurIPS
Year: 2023
Number of Reviews: 9
Original Ratings: 5, 6, 4, 7, 6, -1, -1, -1, -1
Original Confidences: 5, 4, 5, 4, 5, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DaTaSeg, a universal multi-dataset multi-task segmentation model that employs shared representations and distinct merge operations for panoptic, semantic, and instance segmentation tasks. The model utilizes weak supervision for bounding box annotations and facilitates knowledge sharing across datasets using text embeddings. Experimental results demonstrate improved performance, particularly on smaller datasets, and the model supports open-vocabulary segmentation. The authors also plan to release a subset of the Objects365 dataset as a public benchmark.

### Strengths and Weaknesses
Strengths:
1. The paper is well-organized and easy to follow, enhancing reader comprehension.
2. Comprehensive experiments showcase state-of-the-art performance on multiple long-tailed recognition benchmarks, indicating the robustness of the proposed method.
3. The effective use of weak supervision for bounding box annotations makes the approach more accessible and applicable in real-world scenarios.

Weaknesses:
1. Limited novelty in contributions, as the main aspects have been explored in prior works, particularly regarding multi-dataset multi-task training and the use of text embeddings.
2. The ablation study lacks sufficient detail, particularly concerning the hyperparameters λ and μ in equations (4) and (5), which are crucial for model performance.
3. The results for weakly supervised instance segmentation appear underwhelming compared to state-of-the-art methods, raising questions about the upper-bound performance of the Objects365 instance segmentation.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their contributions by clearly distinguishing their work from existing literature, particularly in relation to models like X-Decoder and SAM. Additionally, we suggest conducting a more thorough ablation study that includes experiments on the impact of hyperparameters λ and μ on model performance. Furthermore, addressing the limitations of weakly supervised instance segmentation and providing comparisons with other state-of-the-art methods would strengthen the paper. Lastly, we encourage the authors to consider alternative sampling strategies in multi-dataset training to mitigate dataset imbalance issues.