ID: mAdGQ1Hh3L
Title: START: A Generalized State Space Model with Saliency-Driven Token-Aware Transformation
Conference: NeurIPS
Year: 2024
Number of Reviews: 11
Original Ratings: 5, 5, 6, 6, 5, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 3, 4, 3, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an investigation into the domain generalization problem, focusing on the Mamba architecture within state space models (SSMs). The authors analyze generalization risk using a theoretical framework based on the token-level maximum mean discrepancy. They identify that input-dependent matrices in SSMs can amplify domain-specific features, hindering generalization. To address this, the authors propose a saliency-based token-aware transformation (START) to selectively suppress these features in salient tokens. The paper includes experimental results demonstrating improved performance on domain generalization benchmarks.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written and provides a clear analysis of SSMs in computer vision, highlighting the issue of domain bias.
2. The introduction of saliency as a metric for token selection is innovative and relevant for mitigating performance gaps across domains.
3. The theoretical foundation and empirical results support the proposed methods, showing their effectiveness compared to baselines.

Weaknesses:
1. The analysis lacks clarity regarding the impact of the number of training sources on performance, particularly in relation to Equation (5).
2. The trade-off between mitigating domain-related information and potentially losing useful features is not adequately addressed.
3. The performance gains over existing methods, such as DGMamba, are marginal and may not be statistically significant.
4. There is insufficient exploration of how the proposed methods could be adapted for other architectures, such as CNNs or ViTs.
5. The writing in certain sections, particularly Propositions 1 and 2, could be more concise and directly related to the generalization ability of SSMs.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the conditions and assumptions underlying their analysis, particularly regarding the influence of the number of training sources on performance. Additionally, the authors should address the trade-off between suppressing domain-specific features and retaining useful information more thoroughly. It would be beneficial to provide a more comprehensive comparison with advanced salient feature identification methods to validate the effectiveness of START. Furthermore, we suggest that the authors clarify how their methods could be adapted for other architectures, such as CNNs or ViTs, and consider reporting computation costs like inference time. Lastly, revising the writing in Propositions 1 and 2 for conciseness and clarity would enhance the overall presentation.