ID: YGK9cd0bHz
Title: WiCE: Real-World Entailment for Claims in Wikipedia
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents WICE, a new fine-grained textual entailment dataset derived from natural claim and evidence pairs extracted from Wikipedia. It offers entailment judgments over sub-sentence units and a minimal subset of evidence sentences supporting each subclaim. The authors demonstrate that decomposing complex claims into subclaims enhances both annotation and entailment prediction. The dataset facilitates three entailment-related tasks: entailment classification, evidence retrieval, and non-supported token detection. The authors also introduce Claim-Split, which effectively splits claims into subclaims using GPT-3.5.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and presents a valuable contribution to the field of textual entailment recognition.
- The experiments conducted are solid and provide informative insights for researchers.
- The dataset's features, such as long premises and natural negative examples, enhance its realism and applicability.

Weaknesses:
- The contributions of the paper are not clearly articulated, particularly regarding the justification for not using GPT-3.5 directly for the three tasks.
- The sample size of 50 for human performance evaluation may be insufficient and requires justification.
- There are inconsistencies in the metrics used for entailment classification results that need clarification.
- Several descriptions lack detailed explanations or justifications, which could hinder understanding.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the paper by explicitly outlining the contributions and justifying the choice of methods, particularly regarding the use of GPT-3.5. Additionally, the authors should consider increasing the sample size for human performance evaluation and provide a rationale for the chosen sample size. We suggest clarifying the metrics used in the results and ensuring consistent terminology throughout the paper. Finally, we encourage the authors to elaborate on key research decisions and definitions to enhance the paper's comprehensibility.