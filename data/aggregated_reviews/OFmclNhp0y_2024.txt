ID: OFmclNhp0y
Title: Deterministic Uncertainty Propagation for Improved Model-Based Offline Reinforcement Learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 18
Original Ratings: 3, 6, 5, 7, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 2, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents MOMBO, a model-based policy optimization method for offline reinforcement learning that utilizes moment matching to propagate uncertainties deterministically through the Q-function, addressing the high variance associated with sampling-based uncertainty estimation. The authors argue that MOMBO achieves tighter upper bounds on value approximation compared to Monte Carlo sampling and demonstrates improved performance across various environments, particularly in terms of tighter penalty scores and faster convergence rates, as evidenced by their AUC results. They clarify the theoretical underpinnings of their method, referencing Theorems 1, 2, and 4.3, and emphasize the significance of addressing the variance issue in Monte Carlo estimators.

### Strengths and Weaknesses
Strengths:
- MOMBO is a more stable and sample-efficient approach, with experiments providing evidence that it applies less penalty than both MOPO and MOBILE, suggesting improved training efficiency.
- The theoretical analysis supports the superiority of moment matching over Monte Carlo sampling in terms of value approximation and effectively identifies and characterizes the problems associated with sampling-based approaches.

Weaknesses:
- The writing proficiency of the authors requires significant improvement, with unclear expressions and convoluted sentences.
- The novelty of MOMBO appears limited, as it seems to be a minor modification of existing methods like MOBILE, lacking strong empirical advantages.
- The manuscript's contribution statement is unclear, and the motivation for using a sampling-free approach is inadequately articulated.
- Concerns remain regarding the motivation behind the research and the authors' responses to specific questions posed by reviewers.
- The convergence rate of MOMBO is not consistently superior across all tasks, raising questions about its overall effectiveness compared to MOBILE.
- Experimental validation is insufficient, with a need for broader comparisons and more challenging tasks to demonstrate MOMBO's effectiveness.

### Suggestions for Improvement
We recommend that the authors improve their writing clarity by addressing long sentences, ambiguous pronouns, and adherence to academic conventions. Additionally, we suggest refining the contribution statement to clearly articulate the core innovations of their work and clarifying the motivation behind the research, specifically addressing whether high variance is the sole issue with Monte Carlo sampling and how their method uniquely resolves this. We recommend providing a more thorough analysis of the convergence rates across all tasks to substantiate claims of superiority over MOBILE, and conducting ablation studies to verify the method's effectiveness. Lastly, consider revising the presentation of results to better highlight the significance of low standard deviation in terms of training robustness and convergence.