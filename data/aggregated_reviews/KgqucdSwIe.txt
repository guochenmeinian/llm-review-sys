ID: KgqucdSwIe
Title: VoxDet: Voxel Learning for Novel Instance Detection
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 7, 7, 7, 6, 7, -1, -1, -1, -1, -1
Original Confidences: 3, 4, 3, 3, 3, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents VoxDet, a 3D geometry-aware framework designed for novel instance detection using multi-view templates. It comprises three main modules: the Template Voxel Aggregation (TVA) module, which converts multi-view 2D features into 3D voxel features; the open-world detection module; and the Query Voxel Matching (QVM) module, which aligns and compares query and template voxels. The authors also introduce the Open-World Instance Detection (OWID) dataset, enhancing existing datasets by addressing pose variations and occlusions. Experimental results demonstrate that VoxDet outperforms previous methods and 2D baselines across multiple benchmarks, including LineMod-Occlusion and YCB-video.

### Strengths and Weaknesses
Strengths:
- The paper provides sufficient context for understanding the method, making it accessible even to those not directly working in the field.
- VoxDet is the first to utilize explicit 3D knowledge in multi-view templates for open-world detection in household datasets.
- The OWID dataset effectively complements existing datasets by addressing typically overlooked areas, enhancing understanding of complex scenarios.
- Experimental results indicate that VoxDet achieves superior performance and faster inference speed compared to previous works.

Weaknesses:
- The training process requires known rotations for reference images, which may not be available in practice.
- Clarity issues arise in the writing and figures, making it difficult to follow the system's implementation and concepts.
- The manuscript lacks comparisons to more recent few-shot/one-shot detection methods and does not clarify the "R" and "R w/ sup" columns in Table 3.
- The paper does not adequately address the potential domain gap when deploying the model in real-world scenarios.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the writing and figures to enhance understanding of the system's implementation. Specifically, clearer explanations of the figures and the "R" and "R w/ sup" columns in Table 3 are necessary. Additionally, the authors should consider including comparisons to more recent few-shot/one-shot detection methods to strengthen their contributions. It would also be beneficial to clarify the requirement for posed images in the revised version, ensuring readers understand the scope of the work. Finally, providing examples of the OWID dataset renderings would help assess its quality and impact.