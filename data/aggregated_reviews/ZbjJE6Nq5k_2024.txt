ID: ZbjJE6Nq5k
Title: Normalization and effective learning rates in reinforcement learning
Conference: NeurIPS
Year: 2024
Number of Reviews: 10
Original Ratings: 6, 6, 7, 7, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method called Normalize-and-Project (NaP) aimed at enhancing optimization in deep reinforcement learning (DRL) by incorporating normalization layers and weight projection steps to maintain a consistent effective learning rate (ELR). The authors explore the dynamics of NaP, emphasizing its theoretical grounding and implications for effective learning rates. They discuss how the growth of parameter norms can lead to a decay in the ELR, which can be particularly detrimental in continual learning contexts. Through experiments across various domains, including reinforcement learning and supervised learning, the authors demonstrate that NaP improves performance and stability, revealing nuanced learning curves across different tasks.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, with clear figures and sufficient details for reproducibility.
- The proposed NaP method is relevant and shows good performance across diverse experiments.
- It provides novel insights into the effects of normalization layers on parameter norms and effective learning rates.
- The authors provide a rigorous theoretical foundation for NaP, referencing recent developments in the field.
- Empirical evaluations demonstrate that NaP can yield new insights into established problem settings in DRL.
- The paper addresses reviewer concerns with detailed clarifications and acknowledges the importance of learning rate schedules in reinforcement learning.

Weaknesses:
- The NaP method is closely related to existing optimization techniques that are not adequately discussed, lacking comparisons or discussions of similar methods.
- The experimental procedure could be more rigorous, with insufficient evaluation of individual components of the NaP method.
- Some mathematical notations and definitions are unclear, leading to potential confusion regarding their relationships and implications.
- Some theoretical claims regarding input plasticity and warm-starting effects require further clarification to avoid ambiguity.
- The absence of certain empirical results, such as per-task learning curves, limits the depth of the analysis presented.
- The interaction between normalization layers and optimization dynamics needs more exploration, particularly regarding the implications of removing these layers.

### Suggestions for Improvement
We recommend that the authors improve the discussion of related work by including comparisons with existing optimizers like LARS, LAMB, and others that address effective learning rates. Additionally, we suggest a more thorough evaluation of the individual effects of normalization and weight projection, possibly by including experiments that isolate these components. Clarifying the mathematical framework, particularly the definitions and relationships between symbols used throughout the paper, would enhance reader comprehension. We also recommend explicitly explaining how input plasticity subsumes the warm-starting effect, potentially referencing relevant literature separately. Including per-task learning curves in the supplementary material would enhance the empirical analysis. Furthermore, it would be beneficial to explore the role of normalization layers in signal propagation dynamics and include results that isolate their effects in future revisions. Finally, we encourage the authors to emphasize the surprising effectiveness of learning rate schedules in DRL, as this aspect appears to be underexplored in the literature.