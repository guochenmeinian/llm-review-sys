ID: HcqV2bPFKz
Title: Hierarchical Object-Aware Dual-Level Contrastive Learning for Domain Generalized Stereo Matching
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 6, 7, 5, 6, -1, -1, -1, -1
Original Confidences: 4, 3, 5, 4, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel framework for domain generalization in stereo matching, termed hierarchical object-aware dual-level contrastive learning (HODC). The authors propose a dual-level contrastive loss that matches object features across intra- and inter-scale regions, enhancing the robustness of feature extraction. Extensive experiments demonstrate the framework's superiority over existing domain generalization techniques across multiple datasets, confirming its effectiveness in achieving state-of-the-art performance.

### Strengths and Weaknesses
Strengths:  
- **State-of-the-art performance**: The proposal shows significant error reduction compared to various domain generalization frameworks and recent stereo architectures.  
- **Extensive experiments**: The authors conduct thorough ablation studies and qualitative analyses, providing convincing evidence of the method's effectiveness.  
- **Clear presentation**: The paper is well-structured and easy to follow, with logical progression and clear figures.

Weaknesses:  
- **Dependence on semantic labels**: Achieving state-of-the-art performance necessitates semantic labels, which may not be available for all datasets.  
- **Insufficient qualitative analysis**: The qualitative comparisons are limited, primarily relying on PSMNet, which may not fully illustrate the method's improvements.  
- **Lack of visualization**: The paper does not adequately visualize how the proposed strategy impacts learned feature representations.

### Suggestions for Improvement
We recommend that the authors improve the paper by demonstrating the effects of a state-of-the-art segmentation network to replace ground-truth labels, which could be done offline. Additionally, consider extending experiments using other recent stereo networks robust against domain shifts, such as RAFT-Stereo. Enhancing qualitative visualizations and evaluating performance on more challenging unseen domains, like the Booster and Spring datasets, would provide deeper insights into the method's effectiveness. Furthermore, including a mathematical definition or reference for the smooth L1 loss and reporting baseline results without the proposed additional losses in Table 3 would enhance clarity.