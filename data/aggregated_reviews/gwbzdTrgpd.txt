ID: gwbzdTrgpd
Title: HetGPT: Harnessing the Power of Prompt Tuning in Pre-Trained Heterogeneous Graph Neural Networks
Conference: ACM
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents HetGPT, a novel post-training prompting framework specifically designed for heterogeneous graphs. It addresses the misalignment between pretext tasks and downstream tasks in graph machine learning, particularly in scenarios with limited labeled nodes. HetGPT reformulates downstream tasks to align better with contrastive pretext tasks, integrating a virtual class prompt, a heterogeneous feature prompt, and a multi-view neighborhood aggregation mechanism. Extensive experiments on three benchmark datasets demonstrate that HetGPT enhances the performance of state-of-the-art heterogeneous graph neural networks (HGNNs) in semi-supervised node classification tasks.

### Strengths and Weaknesses
Strengths:  
- Innovative Approach for Heterogeneous Graphs: The integration of a virtual class prompt and a heterogeneous feature prompt is a novel contribution to heterogeneous graph neural networks.  
- Enhanced Performance: The framework shows improved performance over state-of-the-art HGNNs in semi-supervised node classification, validated through extensive experiments.  
- Clear and Coherent Writing: The paper articulates its motivation and concepts in an accessible manner, enhancing reader comprehension.  
- Well-structured Presentation: The adaptation of the “pre-train, prompt” paradigm to heterogeneous graphs is well-motivated and effectively presented.  

Weaknesses:  
- Limited Interpretation of Prompt-based Methods: The framework overlooks leveraging inherent knowledge encoded in graph data, focusing primarily on task alignment.  
- Task-Specific Evaluation: The method is primarily designed for node classification, raising questions about its generalizability to other tasks such as link prediction.  
- Lack of Statistical Significance Tests: The absence of statistical significance tests leaves unclear whether performance gaps are meaningful.  
- Unclear Performance Gains: The reasons behind performance gains in few-shot settings are not adequately explained, and the overlap in distributions raises concerns about statistical significance.  
- Potential Overextension: The paper attempts to cover multiple aspects, which may distract from its main objective of demonstrating prompt effectiveness in heterogeneous graphs.

### Suggestions for Improvement
We recommend that the authors improve the interpretation of prompt-based methods by incorporating a discussion on leveraging inherent knowledge in graph structures. Additionally, we suggest providing a case study that intuitively demonstrates the effectiveness of the virtual class prompt in HetGPT. To enhance the generalizability of the framework, we encourage the authors to evaluate its performance on tasks beyond node classification, such as link prediction, and to conduct statistical significance tests to validate their findings. Furthermore, we advise a more detailed analysis of the few-shot setting results, exploring the reasons behind performance stabilization with a small number of examples. Lastly, we recommend using graphs from different domains for transfer learning experiments to strengthen the robustness of the experimental setting.