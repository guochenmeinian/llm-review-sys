ID: 0EQ4z8n5rp
Title: Global Voices, Local Biases: Socio-Cultural Prejudices across Languages
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an expansion of the Word Embedding Association Test (WEAT) to 24 global south languages, focusing on Indian languages. The authors shift from static embeddings to contextualized representations in language models, analyzing translation behaviors and comparing machine translations with human translations. They introduce a bias sensitivity metric and investigate culturally-specific biases, including casteism and surname stereotypes in Indian languages. The study finds that contextualized embeddings express bias differently than static ones and that high-resourced languages show more consistent representation biases.

### Strengths and Weaknesses
Strengths:
- The paper makes multiple contributions, including the extension of WEAT to various languages and the introduction of new bias dimensions.
- It presents interesting and relevant results, particularly regarding India-specific biases and the human-centered analysis of biases.
- The empirical evaluation is extensive and mostly well-supported by data.

Weaknesses:
- The organization and clarity of the presentation need improvement, particularly in the introduction and methods sections, which can be vague and confusing.
- Some bias dimensions, such as ableism and toxicity, are characterized in ways that may not be intuitive.
- The validation of results is insufficient, relying heavily on anecdotal evidence from a single annotator in some cases.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the introduction by explicitly stating the languages and models tested and providing background on how WEAT functions. Additionally, we suggest that the authors clarify the rationale behind the chosen attribute-target pairs for bias dimensions. The authors should also enhance the validation of their findings by incorporating a broader range of perspectives beyond a single annotator. Finally, we encourage the authors to reorganize the results section to clearly distinguish between core findings and auxiliary discussions, and to ensure that figures are labeled with descriptive terms rather than acronyms.