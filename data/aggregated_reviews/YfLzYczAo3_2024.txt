ID: YfLzYczAo3
Title: CRONOS: Enhancing Deep Learning with Scalable GPU Accelerated Convex Neural Networks
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 5, 5, 5, 7, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel approach to optimizing two-layer ReLU networks by reformulating the problem as a convex optimization task. The authors introduce the ADMM algorithm for solving this constrained optimization and propose a Nystrom-preconditioned solver to enhance efficiency, resulting in the Cronos method. For deeper networks, they suggest an alternating minimization strategy, leading to Cronos-AM, which successfully applies convex neural network optimization to deep networks. The authors claim this is the first successful application of such methods to deep networks, demonstrating promising results on binary classification tasks.

### Strengths and Weaknesses
Strengths:
- The work represents a significant advancement in applying convex reformulation for optimizing deep networks, particularly for the final two layers using Cronos.
- The theoretical framework is robust and well-supported, with a practical implementation provided via JAX.
- Cronos shows competitive performance without the need for hyperparameter tuning, particularly in binary classification tasks.

Weaknesses:
- The reliance on D-adapted Adam for most layers raises questions about the true necessity of Cronos.
- The lack of comparison with D-adapted optimizers in key figures undermines claims regarding hyperparameter advantages.
- There is insufficient discussion on the empirical runtime of the algorithm, and the accuracy claims in figures appear questionable.

### Suggestions for Improvement
We recommend that the authors improve the clarity of their claims, particularly regarding the definition of their models and the notation used. It would be beneficial to include a table format for results in Figures 1 and 2 for easier interpretation. Additionally, we suggest providing performance comparisons of Cronos against existing methods across various datasets, including detailed runtime analyses. The authors should also clarify the experimental settings for Imagenet and NLP tasks, ensuring that the effects of different optimizers are decoupled. Finally, addressing the selection and impact of hyperparameters, particularly for the Nystrom PCG algorithm, would enhance the paper's rigor.