ID: 0M2m9GUTLN
Title: Fair Text Classification with Wasserstein Independence
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method to enhance fairness in text classification by minimizing the mutual information between task representations and sensitive attributes using Wasserstein distance. The authors demonstrate the effectiveness of their approach through experiments on two standard fairness benchmark datasets, reporting improvements in fairness metrics while maintaining competitive performance against state-of-the-art debiasing methods.

### Strengths and Weaknesses
Strengths:
- The paper addresses an important problem in group fairness and is well-written and easy to follow.
- The proposed method is well-motivated, leveraging Wasserstein distance, and is thoroughly evaluated across various settings.
- The authors provide source code for reproducibility, and the approach can function without observing protected attributes during training.

Weaknesses:
- The novelty is limited, as similar ideas have been proposed in prior work, which is neither cited nor compared in this paper.
- The choice to minimize mutual information using a lower-bound estimation is questioned, especially when an upper-bound estimation has been shown to be more plausible in related research.
- The experimental results raise concerns, particularly regarding leakage of sensitive attributes and the lack of clear conclusions drawn from the data.

### Suggestions for Improvement
We recommend that the authors improve the novelty of their work by incorporating and comparing with existing methods, particularly those that utilize upper-bound estimations for mutual information. Additionally, addressing the leakage results and providing a discussion on this behavior would strengthen the paper. Clarifying the applicability of their method in relation to existing baselines that do not require sensitive attributes at test time is also essential. Finally, including relevant baselines, especially those related to INLP, would enhance the comprehensiveness of the evaluation.