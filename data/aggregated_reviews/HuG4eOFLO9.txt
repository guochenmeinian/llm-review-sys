ID: HuG4eOFLO9
Title: Bullying10K: A Large-Scale Neuromorphic Dataset towards Privacy-Preserving Bullying Recognition
Conference: NeurIPS
Year: 2023
Number of Reviews: 19
Original Ratings: 6, 7, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 3, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents the Bullying10K dataset, which captures violent and non-violent behaviors using Dynamic Vision Sensors (DVS) to preserve privacy. The dataset consists of 10,000 event segments annotated with human body keypoints and serves as a baseline for evaluating violence-detecting classifiers. The authors propose three classification benchmarks: action recognition, temporal action localization, and pose estimation, with reasonable evaluation metrics. The dataset aims to bridge the gap in research that considers both privacy protection and violence recognition, highlighting the advantages of DVS technology in capturing motion characteristics while maintaining privacy. The authors also express gratitude for reviewer feedback and indicate that they have made modifications to enhance the paper's overall quality.

### Strengths and Weaknesses
Strengths:
- The dataset is substantial and designed to address privacy issues in sensitive action detection models.
- The innovative use of DVS technology allows for capturing complex actions while preserving privacy.
- The authors have conducted comparative experiments demonstrating the performance of DVS data against RGB data and other privacy-preserving techniques.
- The paper includes a clear definition of privacy and its implications, enhancing the rigor of the research.
- The authors demonstrate responsiveness to reviewer feedback, indicating a commitment to improving the paper's quality.

Weaknesses:
- The dataset's representativeness and diversity are limited, as it relies on student actors performing scripted actions, which may not accurately reflect real-world violent behaviors.
- The non-violent actions included are underrepresented, raising concerns about potential misclassification.
- There is insufficient discussion on the ethical implications, privacy risks, and societal impacts of the dataset and its applications.
- The dataset may not fully represent real-life action scenarios due to its construction method, which involves instructing participants to perform specific actions.
- Some reviewers remain unconvinced in several aspects, indicating that further improvements may still be necessary.

### Suggestions for Improvement
We recommend that the authors improve the dataset's representativeness by including a wider variety of non-violent and real-life actions beyond those that are commonly filmed, ensuring a more diverse set of actors. Additionally, a thorough cross-validation against reliable ground-truth data should be conducted to mitigate misclassification risks. The authors should provide a clearer definition of privacy preservation and discuss potential vulnerabilities in the DVS approach. Furthermore, we suggest enhancing the discussion on the societal impacts of the dataset and ensuring that informed consent from participants is adequately addressed. Clarity in the data collection process and the division of training, validation, and test sets should also be improved. Lastly, we recommend that the authors improve the clarity of their arguments and ensure that all reviewer concerns are thoroughly addressed in future revisions, seeking further feedback to solidify the paper's contributions and resolve any lingering doubts among reviewers.