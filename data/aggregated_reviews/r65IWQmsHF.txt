ID: r65IWQmsHF
Title: Understanding HTML with Large Language Models
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method to fine-tune pre-trained language models (LLMs) on raw HTML texts to enhance their understanding of webpages. It introduces a benchmark of three HTML understanding tasks, including one novel task, and evaluates various model architectures and sizes. The experimental results demonstrate the effectiveness of the proposed method, outperforming existing approaches.

### Strengths and Weaknesses
Strengths:
- The paper is well-written, clearly illustrating its motivation, framework, and results.
- It introduces a new benchmark for evaluating webpage understanding, which is a significant contribution.
- The extensive experiments and analyses support the effectiveness of the proposed method.

Weaknesses:
- The models used for training are relatively small, lacking the inclusion of larger models that exhibit emergent capabilities.
- The motivation for proposing the dataset for the Description Generation task is unclear.
- There is insufficient discussion on the connection between HTML understanding and web information extraction methodologies.

### Suggestions for Improvement
We recommend that the authors improve the justification for the selection of the three tasks for HTML understanding. Additionally, please provide a more detailed explanation of the dataset creation and pre-processing steps, particularly regarding the handling of various HTML tags. It would also be beneficial to include discussions on the performance of larger models, such as LLaMa or GPT-3/4, and their potential in zero- and few-shot settings. Finally, we suggest strengthening the justification for the choice of smaller models in the context of a "privacy-oriented on-device approach."