ID: 8fLatmFQgF
Title: Uniform-in-Time Wasserstein Stability Bounds for (Noisy) Stochastic Gradient Descent
Conference: NeurIPS
Year: 2023
Number of Reviews: 21
Original Ratings: 7, 6, 7, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 2, 3, 4, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents new stability bounds for Stochastic Gradient Descent (SGD), leveraging perturbation theory for Markov Chains and the ergodicity of SGD. It studies algorithmic stability to bound expected generalization error using Wasserstein stability, contrasting with standard uniform stability. The authors propose a three-step process to derive these bounds, addressing both strongly convex and non-convex cases with additive noise. Additionally, the paper introduces uniform in time stability bounds applicable across the optimization process. Furthermore, the authors analyze surrogate losses in optimization, addressing the challenges of using original cost functions for performance measurement. They propose that while surrogate losses can complicate the assessment of results, they may also provide valuable insights, particularly in cases where the original loss is non-smooth or non-convex. The authors acknowledge the need for clarity regarding the relationship between the surrogate loss \( f \) and the original loss \( \ell \).

### Strengths and Weaknesses
Strengths:
- The paper is well-written and presents complex proofs in an accessible manner.
- It establishes a novel connection between Markov Chain theory and learning algorithm generalization.
- The approach to derive stability bounds is innovative and may inspire future research.
- The analysis introduces novel insights into the use of surrogate losses and their implications for generalization bounds.
- The authors demonstrate a willingness to clarify and improve the presentation based on reviewer feedback.

Weaknesses:
- Some results recover rates from previous works but exhibit worse dependencies on other parameters.
- Certain assumptions and parameters are difficult to interpret, particularly Assumptions 3.1 and 3.3, which lack contextual examples.
- The complexity of the analysis in Section 3.3 raises questions about the practical implications of the derived bounds.
- The performance measurement relies on an unspecified surrogate loss, making it difficult to assess the results accurately.
- The paper may require readers to have advanced knowledge of the latest developments in the field to fully grasp the concepts presented.

### Suggestions for Improvement
We recommend that the authors improve the clarity of Assumptions 3.1 and 3.3 by providing contextual examples and intuitive explanations of their generality compared to strong convexity. Additionally, please simplify the notation and clarify the definitions of terms such as "algorithm" and "surrogate loss" to enhance reader comprehension. We also suggest discussing the implications of the additive noise on optimization performance more explicitly, particularly in relation to the trade-off between optimization and generalization error. Furthermore, we recommend improving the clarity of the relationship between \( f \) and \( \ell \) by including practical examples that illustrate their connection. We suggest incorporating an additional error term in the bounds to account for the deviation between the surrogate loss and the original loss, as indicated by the term:

$$ | \mathbb{E}_{\theta, x}[f(\theta, x) - \ell(\theta,x) ] | $$ 

This will enhance the understanding of the implications of using surrogate losses. Finally, we encourage the authors to provide a dedicated section discussing the implications of the \( K/M \) term and its relevance to sample size, as well as to clarify the asymptotic behavior of the analysis when parameters approach certain limits.