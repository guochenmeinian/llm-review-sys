ID: UE6CeRMnq3
Title: Frequency-aware Generative Models for Multivariate Time Series Imputation
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 5, 5, 6, 5, -1, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 4, 4, -1, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents Frequency-aware Generative Models for Multivariate Time Series Imputation (FGTI), which addresses missing data in multivariate time series by focusing on the often-overlooked residual term. The authors propose leveraging frequency-domain information through high-frequency and dominant-frequency filters to enhance the imputation of residual, trend, and seasonal components. A case study using the KDD dataset demonstrates that dominant-frequency information is crucial for the Trend and Seasonal terms, while high-frequency information primarily aids the Residual term. The method adapts to various missing data mechanisms (MCAR, MAR, MNAR) and outperforms conventional approaches across different scenarios, as evidenced by extensive experimental evaluations on three real-world datasets, including detailed results with RMSE and MAE metrics.

### Strengths and Weaknesses
Strengths:
1. The authors effectively utilize high-frequency and dominant-frequency features to improve time series imputation.
2. The introduction of time-domain and frequency-domain representation learning modules comprehensively captures relevant information.
3. Comprehensive experiments, including ablation studies, validate the method's effectiveness across various missing data patterns.
4. Clear presentation of results supports the claims of superior performance.

Weaknesses:
1. The formulation and writing require improvement, with several typographical errors needing correction.
2. The claim that the residual mainly consists of high-frequency components may overlook the presence of multiple scales of seasonality and trend features, potentially leading to noisy residuals.
3. The rationale for outperforming conventional methods in the presence of trend, seasonality, and missing patterns needs further clarification.
4. The method's use of frequency features as conditions for the diffusion model appears straightforward and may limit its contribution.
5. Some technical details, such as the architecture of projectors and the implications of masking strategies, could be more explicitly described.
6. The modeling of temporal dependency in the representation learning module may be insufficient, as only two attention layers are utilized without considering the time stamp.

### Suggestions for Improvement
We recommend that the authors improve the clarity and precision of the writing, addressing typographical errors. Additionally, the authors should provide a more robust justification for their claim regarding the residual components and clarify their rationale for outperforming conventional methods, particularly in relation to trend, seasonality, and missing patterns. We suggest incorporating comparisons with two significant time-series imputation methods that were omitted and conducting experiments that assess the effects of trend and seasonality components. Furthermore, please revise Equation (7) to replace $\text{Encoder}(\cdot)$ with $\text{Transformer}(\cdot)$ to enhance clarity regarding the capture of time information. We encourage the authors to clarify the purpose of Proposition 3.1, elaborate on the methodology for hyper-parameter selection in their experiments, and ensure that the discussion on masking ratios and patterns is comprehensive, as these factors significantly impact model performance. Lastly, detailed descriptions of the input and output projectors should be included in the main text to avoid ambiguities.