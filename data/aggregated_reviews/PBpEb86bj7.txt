ID: PBpEb86bj7
Title: ATMAN: Understanding Transformer Predictions Through Memory Efficient Attention Manipulation
Conference: NeurIPS
Year: 2023
Number of Reviews: 10
Original Ratings: 5, 6, 6, 7, 3, -1, -1, -1, -1, -1
Original Confidences: 4, 3, 4, 2, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents AtMan, a method that manipulates the attention mechanism of generative transformer models to provide explanations by perturbing raw attention scores rather than token inputs. The authors conduct extensive experiments across various modalities, claiming improved results compared to established baselines.

### Strengths and Weaknesses
Strengths:
1. AtMan introduces a novel approach to Explainable AI that does not require gradient calculations, allowing for evaluation of larger models on the same hardware.
2. The manipulation of attention scores is an interesting and innovative idea.
3. The authors perform a comprehensive evaluation of their method across different modalities, leveraging the universality of the Transformer architecture.

Weaknesses:
1. While the paper discusses memory extensively, inference speed is only mildly explored, with significant time increases for large sequence lengths.
2. The method requires setting new hyperparameters, $f$ and $\kappa$, without discussing their effects on sequence length or model architecture.
3. The masking of tokens by setting corresponding $H$ values to 0 does not effectively mask tokens, as explained in Appendix A5, and the choice of values for masking is not adequately explored.
4. The derivations involve numerous approximations, with insufficient justification for choices like Eq. (4) for token masking and the cosine similarity measure.

### Suggestions for Improvement
We recommend that the authors improve the exploration of inference speed, particularly for large sequence lengths, and provide a clearer analysis of the time costs associated with AtMan. Additionally, we suggest conducting experiments to evaluate the impact of different values for the hyperparameters $f$ and $\kappa$ on performance across various datasets. It would also be beneficial to clarify the rationale behind the choice of masking values and to explore alternative measures for token sensitivity, such as clustering tokens for evaluation. Finally, we encourage the authors to include discussions on the implications of their findings for societal impacts and to address the limitations of their method more comprehensively.