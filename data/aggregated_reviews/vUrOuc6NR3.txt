ID: vUrOuc6NR3
Title: DynaMo: In-Domain Dynamics Pretraining for Visuo-Motor Control
Conference: NeurIPS
Year: 2024
Number of Reviews: 9
Original Ratings: 6, 6, 6, 4, -1, -1, -1, -1, -1
Original Confidences: 4, 4, 4, 5, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents DynaMo, a self-supervised model for pre-training visual encoders in robot control, specifically for imitation learning. The authors propose a method that utilizes in-domain data from demonstrations to train a visual encoder alongside forward and inverse dynamics models. This approach aims to enhance the learning of latent actions and improve performance in downstream tasks.

### Strengths and Weaknesses
Strengths:
- The paper is well-written and easy to follow.
- It addresses the crucial problem of pre-training representations from limited in-domain data, which is vital for fine-grained control tasks in robotics.
- The experiments are extensive, including both simulation and real-world scenarios, demonstrating competitive performance against alternative self-supervised methods.

Weaknesses:
- The paper lacks citations of earlier research, giving the impression of novelty where established concepts exist, particularly regarding training on in-domain data and the use of forward and inverse models.
- The experimental design is criticized for being overly simplistic, particularly in real-world setups, which may not adequately challenge the proposed method.
- Comparisons with other models may be unfair due to differences in backbone architectures, and the rationale for not using available action data during training is insufficiently justified.

### Suggestions for Improvement
We recommend that the authors improve the experimental design by introducing spatial randomization in real-robot experiments to better reflect complex scenarios. Additionally, conducting more comprehensive comparisons with various backbone architectures, such as ViT and ResNet-50, would provide a fairer evaluation of DynaMo's performance. 

To strengthen the paper, we suggest that the authors clarify the reasoning behind not using ground truth action values in pre-training, especially when such data is available. Furthermore, including experiments that evaluate DynaMo's performance against masked pre-training methods on the same dataset and assessing its generalization to unseen tasks would enhance the robustness of the findings.