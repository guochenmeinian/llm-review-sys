ID: e3eIqCPCT9
Title: Learning to Rank Generation with Pairwise Partial Rewards
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method for enhancing credit assignment in text generation models using reinforcement learning (RL). The authors propose a reward-shaping technique that utilizes a prefix tree to assign partial rewards to incomplete sequences, specifically focusing on paraphrase generation. The method demonstrates substantial improvements over existing RL and contrastive learning algorithms, supported by comprehensive experimental analysis, including insights into beam search decoding.

### Strengths and Weaknesses
Strengths:
- The proposed reward-shaping technique is novel and effectively addresses the credit assignment problem.
- The motivation is clear, with strong quantitative support for the method's efficacy.
- The experiments are thorough, analyzing various algorithms and beam sizes.

Weaknesses:
- Evaluation relies solely on BERT-iBLEU, lacking human verification of output quality.
- The paper does not compare against other paraphrasing systems or explore summarization tasks.
- The organization and clarity of the paper could be improved, particularly in the presentation of figures and notations.

### Suggestions for Improvement
We recommend that the authors improve the evaluation by including human assessments of model outputs on a random subset. Additionally, consider comparing the proposed method with other paraphrasing systems and exploring its applicability to summarization tasks. We suggest reorganizing the paper for clarity, particularly by presenting Figure 4 earlier and refining the notations used throughout. Lastly, please ensure that the related work section is more comprehensive, addressing significant prior research on credit assignment and partial rewards.