ID: RqjQL08UFc
Title: Spectral Co-Distillation for Personalized Federated Learning
Conference: NeurIPS
Year: 2023
Number of Reviews: 13
Original Ratings: 7, 6, 5, 5, 4, 5, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 3, 4, 3, 4, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a personalized federated learning (PFL) method that utilizes a spectral co-distillation framework to address data heterogeneity. The authors propose a bi-directional knowledge distillation approach based on model spectrum information and introduce a wait-free local training protocol to enhance efficiency. Extensive experiments demonstrate that the proposed method outperforms existing PFL and conventional federated learning baselines across multiple datasets and architectures.

### Strengths and Weaknesses
Strengths:
1. The novel approach of using spectral information for measuring model similarities is promising and provides a principled solution for PFL.
2. The wait-free local training protocol significantly improves convergence time and can enhance the efficiency of PFL methods.
3. The paper is well-organized, clearly written, and presents strong experimental results.

Weaknesses:
1. The method appears to be a mathematically motivated heuristic, lacking theoretical guarantees or convergence analysis.
2. The reliance on spectral information may require additional computational resources, potentially increasing training time and costs.
3. The evaluation is limited to a small set of datasets and architectures, raising questions about generalizability.

### Suggestions for Improvement
We recommend that the authors improve the theoretical analysis by providing convergence guarantees or error bounds for their method, even in simplified scenarios. Additionally, clarifying the calculation process of the model spectrum and providing detailed explanations, possibly with examples, would enhance understanding. We suggest including a broader range of datasets and architectures in the experiments to assess generalizability and addressing the privacy and security implications of the proposed approach. Lastly, improving the clarity of the presentation, particularly regarding abbreviations and experimental settings, would strengthen the paper.