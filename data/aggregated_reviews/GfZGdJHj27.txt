ID: GfZGdJHj27
Title: Consistent Diffusion Models: Mitigating Sampling Drift by Learning to be Consistent
Conference: NeurIPS
Year: 2023
Number of Reviews: 8
Original Ratings: 5, 5, 7, 7, -1, -1, -1, -1
Original Confidences: 4, 2, 4, 3, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a novel method to enhance diffusion models by enforcing a Martingale Property (MP) during training, ensuring consistency in model predictions on self-generated data. The authors prove that if the learned denoiser satisfies MP, it leads to a corresponding diffusion process, and they introduce a new loss function to encourage this property. Empirical results demonstrate that incorporating this loss term improves image generation quality, particularly on CIFAR-10, AFHQ, and FFHQ datasets.

### Strengths and Weaknesses
Strengths:
* The paper addresses a significant issue of sampling drift in diffusion models with a well-motivated approach.
* The theoretical justification for the MP is clear, and the methodology is presented in an organized manner.
* Empirical results show slight improvements in FID scores, indicating the effectiveness of the proposed MP loss.

Weaknesses:
* The performance gain in FID scores is modest relative to the additional training cost.
* The main theorem's assumptions may not be practical in real-world training scenarios.
* The experiments are limited to only two datasets, and the benefits of the MP loss are not fully elucidated.

### Suggestions for Improvement
We recommend that the authors improve the clarity of the relationship between the Martingale Property and the consistency property from concurrent work [1]. Additionally, it would be beneficial to include results from longer training of the MDM without the DSM loss to extend the findings in Table 2. We suggest providing more comprehensive results on larger datasets to evaluate the performance of the proposed method. Furthermore, clarifying the differences between the terms in equations 3 and 4, as well as addressing the notation inconsistencies throughout the paper, would enhance readability. Lastly, we encourage the authors to explore additional evaluation metrics beyond FID to provide a more rounded assessment of their approach.