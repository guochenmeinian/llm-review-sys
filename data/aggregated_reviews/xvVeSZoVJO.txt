ID: xvVeSZoVJO
Title: RCDN: Towards Robust Camera-Insensitivity Collaborative Perception via Dynamic Feature-based 3D Neural Modeling
Conference: NeurIPS
Year: 2024
Number of Reviews: 13
Original Ratings: 6, 5, 5, 5, 5, -1, -1, -1, -1, -1, -1, -1, -1
Original Confidences: 3, 3, 2, 3, 3, -1, -1, -1, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents RCDN, a method designed to address challenges posed by failed camera perspectives while maintaining high collaborative performance with low calibration costs. The authors propose a robust camera-insensitivity collaborative perception framework utilizing a novel dynamic feature-based 3D neural modeling mechanism. To validate their approach, they introduce the OPV2V-N dataset, which demonstrates the model's effectiveness in various scenarios. The experiments indicate that RCDN significantly enhances performance compared to baseline methods.

### Strengths and Weaknesses
Strengths:  
1. The paper introduces an innovative approach to recover noisy camera perceptual information through collaborative neural rendering field representation, distinguishing between static and dynamic components.
2. The creation of the OPV2V-N dataset addresses the lack of comprehensive collaborative perception datasets under different camera noise scenarios.
3. The organization and clarity of the paper facilitate understanding.

Weaknesses:  
1. The paper lacks theoretical analysis of the proposed method and does not adequately explain the motivation behind each sub-module, such as the advantages of using Nerf for static and dynamic fields.
2. There is insufficient mathematical rigor in the analysis of equations, and details regarding network training parameters and learning rates are missing.
3. The evaluation is limited to the OPV2V-N dataset, which may lead to overfitting, and the experimental section appears incomplete.

### Suggestions for Improvement
We recommend that the authors improve the theoretical analysis of their method, providing clearer motivations for each sub-module, particularly regarding the use of Nerf. Additionally, a more rigorous mathematical analysis of the equations is necessary, along with detailed descriptions of the network configurations, including training parameters and learning rates. To enhance the generalizability of their findings, the authors should conduct evaluations on diverse datasets beyond OPV2V-N and consider adding random noise to existing datasets for further validation. Lastly, we suggest expanding the experimental section to include more comprehensive evaluations and addressing the real-time applicability of the proposed method.