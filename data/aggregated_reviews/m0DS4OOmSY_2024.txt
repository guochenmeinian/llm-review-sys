ID: m0DS4OOmSY
Title: Should We Really Edit Language Models? On the Evaluation of Edited Language Models
Conference: NeurIPS
Year: 2024
Number of Reviews: 8
Original Ratings: 5, 6, 6, -1, -1, -1, -1, -1
Original Confidences: 2, 4, 4, -1, -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents an evaluation of various model editing methods and their impact on the general capabilities of language models (LLMs). It investigates factors such as the number of edits, model scale, safety, and different aspects of model performance. The authors summarize key findings, including the observation that while a few edits have minimal impact, extensive edits can lead to significant degradation, including a "muting effect" where models produce empty outputs. The paper also emphasizes the need for more reliable editing techniques and provides a comprehensive empirical evaluation of model editing methods.

### Strengths and Weaknesses
Strengths:
1. The paper is well-written, precise, and easy to follow, with findings clearly summarized.
2. The empirical studies are solid and rigorous, offering reliable insights that can inform future research.
3. The evaluation includes a thorough literature review and addresses critical issues related to model safety.

Weaknesses:
1. The findings are primarily empirical observations rather than a systematic analysis, making it difficult to assess their academic contributions.
2. The paper lacks a deeper technical analysis of why certain methods lead to performance degradation or safety issues, particularly regarding the "muting effect."
3. The motivation for the necessity of model editing at scale is insufficiently addressed, raising questions about its practicality compared to fine-tuning or retrieval-augmented generation (RAG).

### Suggestions for Improvement
We recommend that the authors improve the theoretical framework by providing a systematic justification for their findings, potentially exploring the "Elasticity and Plasticity Trade-off" in greater depth. Additionally, we suggest that the authors conduct a deeper analysis of the mechanisms causing performance degradation, particularly regarding the "muting effect." Clarifying the necessity of model editing in the context of current practices, such as fine-tuning and RAG, would strengthen the paper's motivation. Finally, extending the scale of edits in experiments could provide further insights into performance trade-offs and the robustness of editing methods.