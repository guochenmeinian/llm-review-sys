ID: djmjglxOZ7
Title: Finding Support Examples for In-Context Learning
Conference: EMNLP/2023/Conference
Year: 2023
Number of Reviews: 4
Original Ratings: -1, -1, -1, -1
Original Confidences: -1, -1, -1, -1

Aggregated Review:
### Key Points
This paper presents a method called LENS (fiLter-thEN-Search) for selecting support examples to enhance in-context learning performance. The authors propose a two-stage approach: first, filtering the dataset using the InfoScore metric to identify informative examples, and second, employing a diversity-guided search to refine the selected examples. Extensive experiments demonstrate that LENS outperforms traditional coreset selection methods across eight datasets, highlighting its robustness to example ordering and the importance of ground truth labels.

### Strengths and Weaknesses
Strengths:
- The proposed LENS method is novel and effectively addresses the challenge of selecting support examples for in-context learning.
- The paper is well-organized, with clear descriptions of the methodology and extensive experimental results that validate the effectiveness of LENS.
- The analyses provide valuable insights into the characteristics of support examples, including their sensitivity to ordering and transferability across language models.

Weaknesses:
- The experiments are limited to GPT-2 models, raising concerns about generalizability to larger, instruction-tuned models.
- The static nature of example selection may restrict the method's performance, as dynamic selection could better utilize a larger example bank.
- The paper lacks a runtime comparison and does not adequately address recent state-of-the-art related work, which could serve as stronger baselines.

### Suggestions for Improvement
We recommend that the authors improve the generalizability of their findings by conducting experiments on additional language models, particularly larger ones such as GPT-3. Additionally, we suggest incorporating dynamic selection methods to enhance the example selection process. The authors should also include a runtime comparison to clarify the computational efficiency of their approach. Finally, we advise addressing the missing references to recent related work to strengthen the paper's context and relevance.