{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.4451238153469887,
  "eval_steps": 100,
  "global_step": 3000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.008152450830530929,
      "grad_norm": 0.3311692774295807,
      "learning_rate": 1.9951060358890702e-05,
      "loss": 1.8003,
      "step": 10
    },
    {
      "epoch": 0.016304901661061858,
      "grad_norm": 0.27713748812675476,
      "learning_rate": 1.989668297988037e-05,
      "loss": 1.8149,
      "step": 20
    },
    {
      "epoch": 0.024457352491592785,
      "grad_norm": 0.25232887268066406,
      "learning_rate": 1.984230560087004e-05,
      "loss": 1.8126,
      "step": 30
    },
    {
      "epoch": 0.032609803322123716,
      "grad_norm": 0.23682108521461487,
      "learning_rate": 1.978792822185971e-05,
      "loss": 1.7789,
      "step": 40
    },
    {
      "epoch": 0.040762254152654644,
      "grad_norm": 0.2789612114429474,
      "learning_rate": 1.9733550842849377e-05,
      "loss": 1.789,
      "step": 50
    },
    {
      "epoch": 0.04891470498318557,
      "grad_norm": 0.25721868872642517,
      "learning_rate": 1.9679173463839046e-05,
      "loss": 1.745,
      "step": 60
    },
    {
      "epoch": 0.0570671558137165,
      "grad_norm": 0.23930305242538452,
      "learning_rate": 1.962479608482871e-05,
      "loss": 1.6863,
      "step": 70
    },
    {
      "epoch": 0.06521960664424743,
      "grad_norm": 0.2657647728919983,
      "learning_rate": 1.957041870581838e-05,
      "loss": 1.7522,
      "step": 80
    },
    {
      "epoch": 0.07337205747477836,
      "grad_norm": 0.28104493021965027,
      "learning_rate": 1.951604132680805e-05,
      "loss": 1.7214,
      "step": 90
    },
    {
      "epoch": 0.08152450830530929,
      "grad_norm": 0.32312580943107605,
      "learning_rate": 1.9461663947797717e-05,
      "loss": 1.7491,
      "step": 100
    },
    {
      "epoch": 0.08152450830530929,
      "eval_loss": 1.7317801713943481,
      "eval_runtime": 628.1865,
      "eval_samples_per_second": 0.834,
      "eval_steps_per_second": 0.834,
      "step": 100
    },
    {
      "epoch": 0.08967695913584021,
      "grad_norm": 0.32267943024635315,
      "learning_rate": 1.9407286568787386e-05,
      "loss": 1.7006,
      "step": 110
    },
    {
      "epoch": 0.09782940996637114,
      "grad_norm": 0.2832651436328888,
      "learning_rate": 1.9352909189777054e-05,
      "loss": 1.6651,
      "step": 120
    },
    {
      "epoch": 0.10598186079690207,
      "grad_norm": 0.2602057158946991,
      "learning_rate": 1.9298531810766723e-05,
      "loss": 1.645,
      "step": 130
    },
    {
      "epoch": 0.114134311627433,
      "grad_norm": 0.4102191925048828,
      "learning_rate": 1.924415443175639e-05,
      "loss": 1.6349,
      "step": 140
    },
    {
      "epoch": 0.12228676245796392,
      "grad_norm": 0.3416495621204376,
      "learning_rate": 1.918977705274606e-05,
      "loss": 1.6655,
      "step": 150
    },
    {
      "epoch": 0.13043921328849487,
      "grad_norm": 0.31516605615615845,
      "learning_rate": 1.913539967373573e-05,
      "loss": 1.595,
      "step": 160
    },
    {
      "epoch": 0.1385916641190258,
      "grad_norm": 0.33010053634643555,
      "learning_rate": 1.9081022294725394e-05,
      "loss": 1.5914,
      "step": 170
    },
    {
      "epoch": 0.14674411494955672,
      "grad_norm": 0.3298036754131317,
      "learning_rate": 1.9026644915715063e-05,
      "loss": 1.6712,
      "step": 180
    },
    {
      "epoch": 0.15489656578008765,
      "grad_norm": 0.3616012632846832,
      "learning_rate": 1.8972267536704732e-05,
      "loss": 1.6086,
      "step": 190
    },
    {
      "epoch": 0.16304901661061857,
      "grad_norm": 0.3055187165737152,
      "learning_rate": 1.89178901576944e-05,
      "loss": 1.6406,
      "step": 200
    },
    {
      "epoch": 0.16304901661061857,
      "eval_loss": 1.6365959644317627,
      "eval_runtime": 628.0547,
      "eval_samples_per_second": 0.834,
      "eval_steps_per_second": 0.834,
      "step": 200
    },
    {
      "epoch": 0.1712014674411495,
      "grad_norm": 0.30562156438827515,
      "learning_rate": 1.886351277868407e-05,
      "loss": 1.6477,
      "step": 210
    },
    {
      "epoch": 0.17935391827168043,
      "grad_norm": 0.38296985626220703,
      "learning_rate": 1.8809135399673738e-05,
      "loss": 1.6002,
      "step": 220
    },
    {
      "epoch": 0.18750636910221136,
      "grad_norm": 0.4076945185661316,
      "learning_rate": 1.8754758020663407e-05,
      "loss": 1.6311,
      "step": 230
    },
    {
      "epoch": 0.19565881993274228,
      "grad_norm": 0.32245227694511414,
      "learning_rate": 1.8700380641653072e-05,
      "loss": 1.6603,
      "step": 240
    },
    {
      "epoch": 0.2038112707632732,
      "grad_norm": 0.33095529675483704,
      "learning_rate": 1.8646003262642744e-05,
      "loss": 1.6599,
      "step": 250
    },
    {
      "epoch": 0.21196372159380414,
      "grad_norm": 0.35560694336891174,
      "learning_rate": 1.8591625883632413e-05,
      "loss": 1.6199,
      "step": 260
    },
    {
      "epoch": 0.22011617242433507,
      "grad_norm": 0.40860337018966675,
      "learning_rate": 1.8537248504622078e-05,
      "loss": 1.6417,
      "step": 270
    },
    {
      "epoch": 0.228268623254866,
      "grad_norm": 0.4313002824783325,
      "learning_rate": 1.8482871125611747e-05,
      "loss": 1.6053,
      "step": 280
    },
    {
      "epoch": 0.23642107408539692,
      "grad_norm": 0.3679775297641754,
      "learning_rate": 1.8428493746601415e-05,
      "loss": 1.5531,
      "step": 290
    },
    {
      "epoch": 0.24457352491592785,
      "grad_norm": 0.37339580059051514,
      "learning_rate": 1.8374116367591084e-05,
      "loss": 1.6213,
      "step": 300
    },
    {
      "epoch": 0.24457352491592785,
      "eval_loss": 1.6195720434188843,
      "eval_runtime": 627.6767,
      "eval_samples_per_second": 0.835,
      "eval_steps_per_second": 0.835,
      "step": 300
    },
    {
      "epoch": 0.2527259757464588,
      "grad_norm": 0.33434033393859863,
      "learning_rate": 1.831973898858075e-05,
      "loss": 1.6365,
      "step": 310
    },
    {
      "epoch": 0.26087842657698973,
      "grad_norm": 0.35079243779182434,
      "learning_rate": 1.826536160957042e-05,
      "loss": 1.5941,
      "step": 320
    },
    {
      "epoch": 0.26903087740752063,
      "grad_norm": 0.39896517992019653,
      "learning_rate": 1.821098423056009e-05,
      "loss": 1.6409,
      "step": 330
    },
    {
      "epoch": 0.2771833282380516,
      "grad_norm": 0.36629223823547363,
      "learning_rate": 1.8156606851549755e-05,
      "loss": 1.5951,
      "step": 340
    },
    {
      "epoch": 0.2853357790685825,
      "grad_norm": 0.3795347511768341,
      "learning_rate": 1.8102229472539424e-05,
      "loss": 1.6051,
      "step": 350
    },
    {
      "epoch": 0.29348822989911344,
      "grad_norm": 0.3853951096534729,
      "learning_rate": 1.8047852093529093e-05,
      "loss": 1.5797,
      "step": 360
    },
    {
      "epoch": 0.30164068072964434,
      "grad_norm": 0.3793982267379761,
      "learning_rate": 1.799347471451876e-05,
      "loss": 1.6225,
      "step": 370
    },
    {
      "epoch": 0.3097931315601753,
      "grad_norm": 0.43265318870544434,
      "learning_rate": 1.793909733550843e-05,
      "loss": 1.6282,
      "step": 380
    },
    {
      "epoch": 0.3179455823907062,
      "grad_norm": 0.5481163859367371,
      "learning_rate": 1.78847199564981e-05,
      "loss": 1.6324,
      "step": 390
    },
    {
      "epoch": 0.32609803322123715,
      "grad_norm": 0.3657844662666321,
      "learning_rate": 1.7830342577487767e-05,
      "loss": 1.6452,
      "step": 400
    },
    {
      "epoch": 0.32609803322123715,
      "eval_loss": 1.6110070943832397,
      "eval_runtime": 628.4843,
      "eval_samples_per_second": 0.834,
      "eval_steps_per_second": 0.834,
      "step": 400
    },
    {
      "epoch": 0.33425048405176805,
      "grad_norm": 0.4074755012989044,
      "learning_rate": 1.7775965198477433e-05,
      "loss": 1.5794,
      "step": 410
    },
    {
      "epoch": 0.342402934882299,
      "grad_norm": 0.3376625180244446,
      "learning_rate": 1.7721587819467105e-05,
      "loss": 1.6235,
      "step": 420
    },
    {
      "epoch": 0.3505553857128299,
      "grad_norm": 0.3577468991279602,
      "learning_rate": 1.7667210440456773e-05,
      "loss": 1.6201,
      "step": 430
    },
    {
      "epoch": 0.35870783654336086,
      "grad_norm": 0.5349379777908325,
      "learning_rate": 1.761283306144644e-05,
      "loss": 1.6158,
      "step": 440
    },
    {
      "epoch": 0.36686028737389176,
      "grad_norm": 0.42377743124961853,
      "learning_rate": 1.7558455682436107e-05,
      "loss": 1.5782,
      "step": 450
    },
    {
      "epoch": 0.3750127382044227,
      "grad_norm": 0.3936997056007385,
      "learning_rate": 1.7504078303425776e-05,
      "loss": 1.6277,
      "step": 460
    },
    {
      "epoch": 0.3831651890349536,
      "grad_norm": 0.4345022141933441,
      "learning_rate": 1.7449700924415445e-05,
      "loss": 1.6062,
      "step": 470
    },
    {
      "epoch": 0.39131763986548457,
      "grad_norm": 0.4006388485431671,
      "learning_rate": 1.7395323545405113e-05,
      "loss": 1.6061,
      "step": 480
    },
    {
      "epoch": 0.39947009069601547,
      "grad_norm": 0.37755319476127625,
      "learning_rate": 1.7340946166394782e-05,
      "loss": 1.5988,
      "step": 490
    },
    {
      "epoch": 0.4076225415265464,
      "grad_norm": 0.4855238199234009,
      "learning_rate": 1.728656878738445e-05,
      "loss": 1.5961,
      "step": 500
    },
    {
      "epoch": 0.4076225415265464,
      "eval_loss": 1.6046533584594727,
      "eval_runtime": 628.4531,
      "eval_samples_per_second": 0.834,
      "eval_steps_per_second": 0.834,
      "step": 500
    },
    {
      "epoch": 0.4157749923570773,
      "grad_norm": 0.45019522309303284,
      "learning_rate": 1.7232191408374116e-05,
      "loss": 1.565,
      "step": 510
    },
    {
      "epoch": 0.4239274431876083,
      "grad_norm": 0.4030131697654724,
      "learning_rate": 1.7177814029363785e-05,
      "loss": 1.5737,
      "step": 520
    },
    {
      "epoch": 0.4320798940181392,
      "grad_norm": 0.4623696804046631,
      "learning_rate": 1.7123436650353453e-05,
      "loss": 1.5525,
      "step": 530
    },
    {
      "epoch": 0.44023234484867013,
      "grad_norm": 0.36460989713668823,
      "learning_rate": 1.7069059271343122e-05,
      "loss": 1.6171,
      "step": 540
    },
    {
      "epoch": 0.4483847956792011,
      "grad_norm": 0.4278542399406433,
      "learning_rate": 1.701468189233279e-05,
      "loss": 1.5307,
      "step": 550
    },
    {
      "epoch": 0.456537246509732,
      "grad_norm": 0.4029304087162018,
      "learning_rate": 1.696030451332246e-05,
      "loss": 1.5752,
      "step": 560
    },
    {
      "epoch": 0.46468969734026294,
      "grad_norm": 0.4095546305179596,
      "learning_rate": 1.6905927134312128e-05,
      "loss": 1.5711,
      "step": 570
    },
    {
      "epoch": 0.47284214817079384,
      "grad_norm": 0.37692487239837646,
      "learning_rate": 1.6851549755301793e-05,
      "loss": 1.5826,
      "step": 580
    },
    {
      "epoch": 0.4809945990013248,
      "grad_norm": 0.4119563102722168,
      "learning_rate": 1.6797172376291465e-05,
      "loss": 1.5687,
      "step": 590
    },
    {
      "epoch": 0.4891470498318557,
      "grad_norm": 0.3820366859436035,
      "learning_rate": 1.6742794997281134e-05,
      "loss": 1.5787,
      "step": 600
    },
    {
      "epoch": 0.4891470498318557,
      "eval_loss": 1.5992225408554077,
      "eval_runtime": 628.4377,
      "eval_samples_per_second": 0.834,
      "eval_steps_per_second": 0.834,
      "step": 600
    },
    {
      "epoch": 0.49729950066238665,
      "grad_norm": 0.38737305998802185,
      "learning_rate": 1.66884176182708e-05,
      "loss": 1.5735,
      "step": 610
    },
    {
      "epoch": 0.5054519514929176,
      "grad_norm": 0.45967617630958557,
      "learning_rate": 1.6634040239260468e-05,
      "loss": 1.6067,
      "step": 620
    },
    {
      "epoch": 0.5136044023234485,
      "grad_norm": 0.3652702867984772,
      "learning_rate": 1.6579662860250137e-05,
      "loss": 1.629,
      "step": 630
    },
    {
      "epoch": 0.5217568531539795,
      "grad_norm": 0.4427448809146881,
      "learning_rate": 1.6525285481239805e-05,
      "loss": 1.5753,
      "step": 640
    },
    {
      "epoch": 0.5299093039845103,
      "grad_norm": 0.5014920830726624,
      "learning_rate": 1.6470908102229474e-05,
      "loss": 1.5957,
      "step": 650
    },
    {
      "epoch": 0.5380617548150413,
      "grad_norm": 0.41629523038864136,
      "learning_rate": 1.6416530723219143e-05,
      "loss": 1.5994,
      "step": 660
    },
    {
      "epoch": 0.5462142056455722,
      "grad_norm": 0.38216716051101685,
      "learning_rate": 1.636215334420881e-05,
      "loss": 1.6099,
      "step": 670
    },
    {
      "epoch": 0.5543666564761032,
      "grad_norm": 0.4480958878993988,
      "learning_rate": 1.6307775965198477e-05,
      "loss": 1.646,
      "step": 680
    },
    {
      "epoch": 0.562519107306634,
      "grad_norm": 0.3951428532600403,
      "learning_rate": 1.625339858618815e-05,
      "loss": 1.5784,
      "step": 690
    },
    {
      "epoch": 0.570671558137165,
      "grad_norm": 0.46712470054626465,
      "learning_rate": 1.6199021207177817e-05,
      "loss": 1.614,
      "step": 700
    },
    {
      "epoch": 0.570671558137165,
      "eval_loss": 1.595380187034607,
      "eval_runtime": 627.2585,
      "eval_samples_per_second": 0.835,
      "eval_steps_per_second": 0.835,
      "step": 700
    },
    {
      "epoch": 0.5788240089676959,
      "grad_norm": 0.4101339876651764,
      "learning_rate": 1.6144643828167483e-05,
      "loss": 1.6174,
      "step": 710
    },
    {
      "epoch": 0.5869764597982269,
      "grad_norm": 0.434919536113739,
      "learning_rate": 1.609026644915715e-05,
      "loss": 1.585,
      "step": 720
    },
    {
      "epoch": 0.5951289106287577,
      "grad_norm": 0.4575454592704773,
      "learning_rate": 1.603588907014682e-05,
      "loss": 1.5743,
      "step": 730
    },
    {
      "epoch": 0.6032813614592887,
      "grad_norm": 0.5028732419013977,
      "learning_rate": 1.598151169113649e-05,
      "loss": 1.5981,
      "step": 740
    },
    {
      "epoch": 0.6114338122898196,
      "grad_norm": 0.38822460174560547,
      "learning_rate": 1.5927134312126157e-05,
      "loss": 1.6198,
      "step": 750
    },
    {
      "epoch": 0.6195862631203506,
      "grad_norm": 0.4123600125312805,
      "learning_rate": 1.5872756933115826e-05,
      "loss": 1.5925,
      "step": 760
    },
    {
      "epoch": 0.6277387139508814,
      "grad_norm": 0.47765082120895386,
      "learning_rate": 1.5818379554105495e-05,
      "loss": 1.5603,
      "step": 770
    },
    {
      "epoch": 0.6358911647814124,
      "grad_norm": 0.3991430401802063,
      "learning_rate": 1.576400217509516e-05,
      "loss": 1.6007,
      "step": 780
    },
    {
      "epoch": 0.6440436156119433,
      "grad_norm": 0.36612674593925476,
      "learning_rate": 1.570962479608483e-05,
      "loss": 1.5783,
      "step": 790
    },
    {
      "epoch": 0.6521960664424743,
      "grad_norm": 0.35402020812034607,
      "learning_rate": 1.5655247417074497e-05,
      "loss": 1.587,
      "step": 800
    },
    {
      "epoch": 0.6521960664424743,
      "eval_loss": 1.5929460525512695,
      "eval_runtime": 628.3044,
      "eval_samples_per_second": 0.834,
      "eval_steps_per_second": 0.834,
      "step": 800
    },
    {
      "epoch": 0.6603485172730051,
      "grad_norm": 0.4162622094154358,
      "learning_rate": 1.5600870038064166e-05,
      "loss": 1.5992,
      "step": 810
    },
    {
      "epoch": 0.6685009681035361,
      "grad_norm": 0.37367379665374756,
      "learning_rate": 1.5546492659053835e-05,
      "loss": 1.5621,
      "step": 820
    },
    {
      "epoch": 0.676653418934067,
      "grad_norm": 0.34456968307495117,
      "learning_rate": 1.5492115280043503e-05,
      "loss": 1.6155,
      "step": 830
    },
    {
      "epoch": 0.684805869764598,
      "grad_norm": 0.4961128234863281,
      "learning_rate": 1.5437737901033172e-05,
      "loss": 1.6211,
      "step": 840
    },
    {
      "epoch": 0.692958320595129,
      "grad_norm": 0.48865005373954773,
      "learning_rate": 1.5383360522022837e-05,
      "loss": 1.6197,
      "step": 850
    },
    {
      "epoch": 0.7011107714256598,
      "grad_norm": 0.41574233770370483,
      "learning_rate": 1.532898314301251e-05,
      "loss": 1.6044,
      "step": 860
    },
    {
      "epoch": 0.7092632222561908,
      "grad_norm": 0.4063962399959564,
      "learning_rate": 1.5274605764002178e-05,
      "loss": 1.5684,
      "step": 870
    },
    {
      "epoch": 0.7174156730867217,
      "grad_norm": 0.4620988070964813,
      "learning_rate": 1.5220228384991843e-05,
      "loss": 1.5805,
      "step": 880
    },
    {
      "epoch": 0.7255681239172527,
      "grad_norm": 0.4191127121448517,
      "learning_rate": 1.5165851005981514e-05,
      "loss": 1.5435,
      "step": 890
    },
    {
      "epoch": 0.7337205747477835,
      "grad_norm": 0.3828658163547516,
      "learning_rate": 1.511147362697118e-05,
      "loss": 1.551,
      "step": 900
    },
    {
      "epoch": 0.7337205747477835,
      "eval_loss": 1.590617299079895,
      "eval_runtime": 628.3171,
      "eval_samples_per_second": 0.834,
      "eval_steps_per_second": 0.834,
      "step": 900
    },
    {
      "epoch": 0.7418730255783145,
      "grad_norm": 0.3994990587234497,
      "learning_rate": 1.505709624796085e-05,
      "loss": 1.5659,
      "step": 910
    },
    {
      "epoch": 0.7500254764088454,
      "grad_norm": 0.3942956030368805,
      "learning_rate": 1.5002718868950518e-05,
      "loss": 1.6157,
      "step": 920
    },
    {
      "epoch": 0.7581779272393764,
      "grad_norm": 0.46907857060432434,
      "learning_rate": 1.4948341489940185e-05,
      "loss": 1.5875,
      "step": 930
    },
    {
      "epoch": 0.7663303780699072,
      "grad_norm": 0.4038463830947876,
      "learning_rate": 1.4893964110929855e-05,
      "loss": 1.6006,
      "step": 940
    },
    {
      "epoch": 0.7744828289004382,
      "grad_norm": 0.3846774399280548,
      "learning_rate": 1.4839586731919522e-05,
      "loss": 1.5179,
      "step": 950
    },
    {
      "epoch": 0.7826352797309691,
      "grad_norm": 0.49233120679855347,
      "learning_rate": 1.4785209352909191e-05,
      "loss": 1.6003,
      "step": 960
    },
    {
      "epoch": 0.7907877305615001,
      "grad_norm": 0.46612900495529175,
      "learning_rate": 1.473083197389886e-05,
      "loss": 1.6312,
      "step": 970
    },
    {
      "epoch": 0.7989401813920309,
      "grad_norm": 0.4363501965999603,
      "learning_rate": 1.4676454594888527e-05,
      "loss": 1.5759,
      "step": 980
    },
    {
      "epoch": 0.8070926322225619,
      "grad_norm": 0.40238139033317566,
      "learning_rate": 1.4622077215878197e-05,
      "loss": 1.5989,
      "step": 990
    },
    {
      "epoch": 0.8152450830530928,
      "grad_norm": 0.41700711846351624,
      "learning_rate": 1.4567699836867864e-05,
      "loss": 1.6201,
      "step": 1000
    },
    {
      "epoch": 0.8152450830530928,
      "eval_loss": 1.588518738746643,
      "eval_runtime": 629.4582,
      "eval_samples_per_second": 0.832,
      "eval_steps_per_second": 0.832,
      "step": 1000
    },
    {
      "epoch": 0.8233975338836238,
      "grad_norm": 0.4209458529949188,
      "learning_rate": 1.4513322457857533e-05,
      "loss": 1.5966,
      "step": 1010
    },
    {
      "epoch": 0.8315499847141546,
      "grad_norm": 0.4174433946609497,
      "learning_rate": 1.44589450788472e-05,
      "loss": 1.5465,
      "step": 1020
    },
    {
      "epoch": 0.8397024355446856,
      "grad_norm": 0.4152403473854065,
      "learning_rate": 1.4404567699836868e-05,
      "loss": 1.5786,
      "step": 1030
    },
    {
      "epoch": 0.8478548863752166,
      "grad_norm": 0.4695897698402405,
      "learning_rate": 1.4350190320826539e-05,
      "loss": 1.5905,
      "step": 1040
    },
    {
      "epoch": 0.8560073372057475,
      "grad_norm": 0.4303470253944397,
      "learning_rate": 1.4295812941816206e-05,
      "loss": 1.6085,
      "step": 1050
    },
    {
      "epoch": 0.8641597880362784,
      "grad_norm": 0.4628176987171173,
      "learning_rate": 1.4241435562805875e-05,
      "loss": 1.5912,
      "step": 1060
    },
    {
      "epoch": 0.8723122388668093,
      "grad_norm": 0.46263137459754944,
      "learning_rate": 1.4187058183795542e-05,
      "loss": 1.6131,
      "step": 1070
    },
    {
      "epoch": 0.8804646896973403,
      "grad_norm": 0.4725632965564728,
      "learning_rate": 1.413268080478521e-05,
      "loss": 1.6311,
      "step": 1080
    },
    {
      "epoch": 0.8886171405278712,
      "grad_norm": 0.3865177035331726,
      "learning_rate": 1.4078303425774879e-05,
      "loss": 1.5701,
      "step": 1090
    },
    {
      "epoch": 0.8967695913584022,
      "grad_norm": 0.4250967502593994,
      "learning_rate": 1.4023926046764546e-05,
      "loss": 1.5682,
      "step": 1100
    },
    {
      "epoch": 0.8967695913584022,
      "eval_loss": 1.5867369174957275,
      "eval_runtime": 628.6598,
      "eval_samples_per_second": 0.834,
      "eval_steps_per_second": 0.834,
      "step": 1100
    },
    {
      "epoch": 0.904922042188933,
      "grad_norm": 0.5138018727302551,
      "learning_rate": 1.3969548667754216e-05,
      "loss": 1.5485,
      "step": 1110
    },
    {
      "epoch": 0.913074493019464,
      "grad_norm": 0.3959486484527588,
      "learning_rate": 1.3915171288743883e-05,
      "loss": 1.6016,
      "step": 1120
    },
    {
      "epoch": 0.9212269438499949,
      "grad_norm": 0.4651067554950714,
      "learning_rate": 1.3860793909733552e-05,
      "loss": 1.5659,
      "step": 1130
    },
    {
      "epoch": 0.9293793946805259,
      "grad_norm": 0.4948703348636627,
      "learning_rate": 1.380641653072322e-05,
      "loss": 1.5511,
      "step": 1140
    },
    {
      "epoch": 0.9375318455110567,
      "grad_norm": 0.47498366236686707,
      "learning_rate": 1.3752039151712888e-05,
      "loss": 1.5989,
      "step": 1150
    },
    {
      "epoch": 0.9456842963415877,
      "grad_norm": 0.45440927147865295,
      "learning_rate": 1.3697661772702558e-05,
      "loss": 1.5848,
      "step": 1160
    },
    {
      "epoch": 0.9538367471721186,
      "grad_norm": 0.4234197437763214,
      "learning_rate": 1.3643284393692225e-05,
      "loss": 1.5844,
      "step": 1170
    },
    {
      "epoch": 0.9619891980026496,
      "grad_norm": 0.5256593823432922,
      "learning_rate": 1.3588907014681894e-05,
      "loss": 1.5797,
      "step": 1180
    },
    {
      "epoch": 0.9701416488331804,
      "grad_norm": 0.39645805954933167,
      "learning_rate": 1.3534529635671562e-05,
      "loss": 1.5818,
      "step": 1190
    },
    {
      "epoch": 0.9782940996637114,
      "grad_norm": 0.394193172454834,
      "learning_rate": 1.348015225666123e-05,
      "loss": 1.562,
      "step": 1200
    },
    {
      "epoch": 0.9782940996637114,
      "eval_loss": 1.5849674940109253,
      "eval_runtime": 628.0014,
      "eval_samples_per_second": 0.834,
      "eval_steps_per_second": 0.834,
      "step": 1200
    },
    {
      "epoch": 0.9864465504942423,
      "grad_norm": 0.40485328435897827,
      "learning_rate": 1.34257748776509e-05,
      "loss": 1.5576,
      "step": 1210
    },
    {
      "epoch": 0.9945990013247733,
      "grad_norm": 0.5124382972717285,
      "learning_rate": 1.3371397498640567e-05,
      "loss": 1.6234,
      "step": 1220
    },
    {
      "epoch": 1.0024457352491594,
      "grad_norm": 0.4467029869556427,
      "learning_rate": 1.3317020119630235e-05,
      "loss": 1.5953,
      "step": 1230
    },
    {
      "epoch": 1.0105981860796902,
      "grad_norm": 0.47513070702552795,
      "learning_rate": 1.3262642740619904e-05,
      "loss": 1.5771,
      "step": 1240
    },
    {
      "epoch": 1.018750636910221,
      "grad_norm": 0.3490251302719116,
      "learning_rate": 1.3208265361609571e-05,
      "loss": 1.6075,
      "step": 1250
    },
    {
      "epoch": 1.0269030877407521,
      "grad_norm": 0.44626715779304504,
      "learning_rate": 1.3153887982599241e-05,
      "loss": 1.607,
      "step": 1260
    },
    {
      "epoch": 1.035055538571283,
      "grad_norm": 0.45933398604393005,
      "learning_rate": 1.3099510603588908e-05,
      "loss": 1.6183,
      "step": 1270
    },
    {
      "epoch": 1.043207989401814,
      "grad_norm": 0.43072280287742615,
      "learning_rate": 1.3045133224578577e-05,
      "loss": 1.575,
      "step": 1280
    },
    {
      "epoch": 1.0513604402323449,
      "grad_norm": 0.3956737220287323,
      "learning_rate": 1.2990755845568244e-05,
      "loss": 1.5416,
      "step": 1290
    },
    {
      "epoch": 1.0595128910628757,
      "grad_norm": 0.4304109811782837,
      "learning_rate": 1.2936378466557913e-05,
      "loss": 1.542,
      "step": 1300
    },
    {
      "epoch": 1.0595128910628757,
      "eval_loss": 1.5836964845657349,
      "eval_runtime": 628.7839,
      "eval_samples_per_second": 0.833,
      "eval_steps_per_second": 0.833,
      "step": 1300
    },
    {
      "epoch": 1.0676653418934068,
      "grad_norm": 0.3857465386390686,
      "learning_rate": 1.2882001087547581e-05,
      "loss": 1.5484,
      "step": 1310
    },
    {
      "epoch": 1.0758177927239376,
      "grad_norm": 0.9742546677589417,
      "learning_rate": 1.2827623708537248e-05,
      "loss": 1.5963,
      "step": 1320
    },
    {
      "epoch": 1.0839702435544685,
      "grad_norm": 0.4662739634513855,
      "learning_rate": 1.2773246329526919e-05,
      "loss": 1.5578,
      "step": 1330
    },
    {
      "epoch": 1.0921226943849995,
      "grad_norm": 0.42711734771728516,
      "learning_rate": 1.2718868950516586e-05,
      "loss": 1.5756,
      "step": 1340
    },
    {
      "epoch": 1.1002751452155304,
      "grad_norm": 0.5390928387641907,
      "learning_rate": 1.2664491571506254e-05,
      "loss": 1.5466,
      "step": 1350
    },
    {
      "epoch": 1.1084275960460614,
      "grad_norm": 0.4222089946269989,
      "learning_rate": 1.2610114192495923e-05,
      "loss": 1.5945,
      "step": 1360
    },
    {
      "epoch": 1.1165800468765923,
      "grad_norm": 0.4180808961391449,
      "learning_rate": 1.255573681348559e-05,
      "loss": 1.5859,
      "step": 1370
    },
    {
      "epoch": 1.1247324977071231,
      "grad_norm": 0.4656865894794464,
      "learning_rate": 1.250135943447526e-05,
      "loss": 1.5645,
      "step": 1380
    },
    {
      "epoch": 1.1328849485376542,
      "grad_norm": 0.47740256786346436,
      "learning_rate": 1.2446982055464927e-05,
      "loss": 1.6348,
      "step": 1390
    },
    {
      "epoch": 1.141037399368185,
      "grad_norm": 0.5045738220214844,
      "learning_rate": 1.2392604676454596e-05,
      "loss": 1.5737,
      "step": 1400
    },
    {
      "epoch": 1.141037399368185,
      "eval_loss": 1.582592487335205,
      "eval_runtime": 626.4453,
      "eval_samples_per_second": 0.836,
      "eval_steps_per_second": 0.836,
      "step": 1400
    },
    {
      "epoch": 1.1491898501987161,
      "grad_norm": 0.39718371629714966,
      "learning_rate": 1.2338227297444265e-05,
      "loss": 1.5786,
      "step": 1410
    },
    {
      "epoch": 1.157342301029247,
      "grad_norm": 0.43058761954307556,
      "learning_rate": 1.2283849918433932e-05,
      "loss": 1.5739,
      "step": 1420
    },
    {
      "epoch": 1.1654947518597778,
      "grad_norm": 0.6034866571426392,
      "learning_rate": 1.2229472539423602e-05,
      "loss": 1.5612,
      "step": 1430
    },
    {
      "epoch": 1.1736472026903089,
      "grad_norm": 0.411866694688797,
      "learning_rate": 1.2175095160413269e-05,
      "loss": 1.5839,
      "step": 1440
    },
    {
      "epoch": 1.1817996535208397,
      "grad_norm": 0.5046722888946533,
      "learning_rate": 1.2120717781402938e-05,
      "loss": 1.5824,
      "step": 1450
    },
    {
      "epoch": 1.1899521043513706,
      "grad_norm": 0.4605434834957123,
      "learning_rate": 1.2066340402392606e-05,
      "loss": 1.5833,
      "step": 1460
    },
    {
      "epoch": 1.1981045551819016,
      "grad_norm": 0.40340811014175415,
      "learning_rate": 1.2011963023382273e-05,
      "loss": 1.5648,
      "step": 1470
    },
    {
      "epoch": 1.2062570060124325,
      "grad_norm": 0.44053396582603455,
      "learning_rate": 1.1957585644371944e-05,
      "loss": 1.549,
      "step": 1480
    },
    {
      "epoch": 1.2144094568429633,
      "grad_norm": 0.41683781147003174,
      "learning_rate": 1.190320826536161e-05,
      "loss": 1.5856,
      "step": 1490
    },
    {
      "epoch": 1.2225619076734944,
      "grad_norm": 0.49003928899765015,
      "learning_rate": 1.184883088635128e-05,
      "loss": 1.5691,
      "step": 1500
    },
    {
      "epoch": 1.2225619076734944,
      "eval_loss": 1.5814627408981323,
      "eval_runtime": 627.9469,
      "eval_samples_per_second": 0.834,
      "eval_steps_per_second": 0.834,
      "step": 1500
    },
    {
      "epoch": 1.2307143585040252,
      "grad_norm": 0.46324068307876587,
      "learning_rate": 1.1794453507340946e-05,
      "loss": 1.6028,
      "step": 1510
    },
    {
      "epoch": 1.2388668093345563,
      "grad_norm": 0.5170046091079712,
      "learning_rate": 1.1740076128330615e-05,
      "loss": 1.5506,
      "step": 1520
    },
    {
      "epoch": 1.2470192601650871,
      "grad_norm": 0.5930673480033875,
      "learning_rate": 1.1685698749320284e-05,
      "loss": 1.6334,
      "step": 1530
    },
    {
      "epoch": 1.2551717109956182,
      "grad_norm": 0.44316786527633667,
      "learning_rate": 1.163132137030995e-05,
      "loss": 1.6087,
      "step": 1540
    },
    {
      "epoch": 1.263324161826149,
      "grad_norm": 0.433112233877182,
      "learning_rate": 1.1576943991299621e-05,
      "loss": 1.621,
      "step": 1550
    },
    {
      "epoch": 1.2714766126566799,
      "grad_norm": 0.48237890005111694,
      "learning_rate": 1.1522566612289288e-05,
      "loss": 1.5545,
      "step": 1560
    },
    {
      "epoch": 1.279629063487211,
      "grad_norm": 0.3748369514942169,
      "learning_rate": 1.1468189233278957e-05,
      "loss": 1.5542,
      "step": 1570
    },
    {
      "epoch": 1.2877815143177418,
      "grad_norm": 0.5125359296798706,
      "learning_rate": 1.1413811854268625e-05,
      "loss": 1.5665,
      "step": 1580
    },
    {
      "epoch": 1.2959339651482726,
      "grad_norm": 0.4174591302871704,
      "learning_rate": 1.1359434475258292e-05,
      "loss": 1.561,
      "step": 1590
    },
    {
      "epoch": 1.3040864159788037,
      "grad_norm": 0.47518956661224365,
      "learning_rate": 1.1305057096247963e-05,
      "loss": 1.5186,
      "step": 1600
    },
    {
      "epoch": 1.3040864159788037,
      "eval_loss": 1.5804643630981445,
      "eval_runtime": 629.2763,
      "eval_samples_per_second": 0.833,
      "eval_steps_per_second": 0.833,
      "step": 1600
    },
    {
      "epoch": 1.3122388668093345,
      "grad_norm": 0.405939519405365,
      "learning_rate": 1.125067971723763e-05,
      "loss": 1.5669,
      "step": 1610
    },
    {
      "epoch": 1.3203913176398654,
      "grad_norm": 0.47731828689575195,
      "learning_rate": 1.1196302338227298e-05,
      "loss": 1.5616,
      "step": 1620
    },
    {
      "epoch": 1.3285437684703965,
      "grad_norm": 0.4865424931049347,
      "learning_rate": 1.1141924959216967e-05,
      "loss": 1.5723,
      "step": 1630
    },
    {
      "epoch": 1.3366962193009273,
      "grad_norm": 0.4471837282180786,
      "learning_rate": 1.1087547580206634e-05,
      "loss": 1.5558,
      "step": 1640
    },
    {
      "epoch": 1.3448486701314581,
      "grad_norm": 0.5128414630889893,
      "learning_rate": 1.1033170201196304e-05,
      "loss": 1.6165,
      "step": 1650
    },
    {
      "epoch": 1.3530011209619892,
      "grad_norm": 0.4598480463027954,
      "learning_rate": 1.0978792822185971e-05,
      "loss": 1.5233,
      "step": 1660
    },
    {
      "epoch": 1.36115357179252,
      "grad_norm": 0.39761096239089966,
      "learning_rate": 1.092441544317564e-05,
      "loss": 1.5248,
      "step": 1670
    },
    {
      "epoch": 1.3693060226230511,
      "grad_norm": 0.4692278802394867,
      "learning_rate": 1.0870038064165309e-05,
      "loss": 1.5302,
      "step": 1680
    },
    {
      "epoch": 1.377458473453582,
      "grad_norm": 0.4021396338939667,
      "learning_rate": 1.0815660685154976e-05,
      "loss": 1.5633,
      "step": 1690
    },
    {
      "epoch": 1.385610924284113,
      "grad_norm": 0.46550601720809937,
      "learning_rate": 1.0761283306144646e-05,
      "loss": 1.5999,
      "step": 1700
    },
    {
      "epoch": 1.385610924284113,
      "eval_loss": 1.5796884298324585,
      "eval_runtime": 630.4367,
      "eval_samples_per_second": 0.831,
      "eval_steps_per_second": 0.831,
      "step": 1700
    },
    {
      "epoch": 1.3937633751146439,
      "grad_norm": 0.4445372521877289,
      "learning_rate": 1.0706905927134313e-05,
      "loss": 1.5517,
      "step": 1710
    },
    {
      "epoch": 1.4019158259451747,
      "grad_norm": 0.5196864008903503,
      "learning_rate": 1.0652528548123982e-05,
      "loss": 1.5845,
      "step": 1720
    },
    {
      "epoch": 1.4100682767757058,
      "grad_norm": 0.4918241798877716,
      "learning_rate": 1.0598151169113649e-05,
      "loss": 1.6164,
      "step": 1730
    },
    {
      "epoch": 1.4182207276062366,
      "grad_norm": 0.4305378198623657,
      "learning_rate": 1.0543773790103317e-05,
      "loss": 1.5987,
      "step": 1740
    },
    {
      "epoch": 1.4263731784367675,
      "grad_norm": 0.41286876797676086,
      "learning_rate": 1.0489396411092986e-05,
      "loss": 1.5774,
      "step": 1750
    },
    {
      "epoch": 1.4345256292672985,
      "grad_norm": 0.4356973171234131,
      "learning_rate": 1.0435019032082653e-05,
      "loss": 1.5661,
      "step": 1760
    },
    {
      "epoch": 1.4426780800978294,
      "grad_norm": 0.42471036314964294,
      "learning_rate": 1.0380641653072323e-05,
      "loss": 1.5711,
      "step": 1770
    },
    {
      "epoch": 1.4508305309283602,
      "grad_norm": 0.39982175827026367,
      "learning_rate": 1.032626427406199e-05,
      "loss": 1.5892,
      "step": 1780
    },
    {
      "epoch": 1.4589829817588913,
      "grad_norm": 0.5070464611053467,
      "learning_rate": 1.0271886895051659e-05,
      "loss": 1.5763,
      "step": 1790
    },
    {
      "epoch": 1.4671354325894221,
      "grad_norm": 0.4313432574272156,
      "learning_rate": 1.0217509516041328e-05,
      "loss": 1.6123,
      "step": 1800
    },
    {
      "epoch": 1.4671354325894221,
      "eval_loss": 1.578995943069458,
      "eval_runtime": 629.4602,
      "eval_samples_per_second": 0.832,
      "eval_steps_per_second": 0.832,
      "step": 1800
    },
    {
      "epoch": 1.4752878834199532,
      "grad_norm": 0.43435195088386536,
      "learning_rate": 1.0163132137030995e-05,
      "loss": 1.5981,
      "step": 1810
    },
    {
      "epoch": 1.483440334250484,
      "grad_norm": 0.4341891407966614,
      "learning_rate": 1.0108754758020665e-05,
      "loss": 1.5808,
      "step": 1820
    },
    {
      "epoch": 1.4915927850810151,
      "grad_norm": 0.42315077781677246,
      "learning_rate": 1.0054377379010332e-05,
      "loss": 1.5474,
      "step": 1830
    },
    {
      "epoch": 1.499745235911546,
      "grad_norm": 0.454534113407135,
      "learning_rate": 1e-05,
      "loss": 1.5568,
      "step": 1840
    },
    {
      "epoch": 1.5078976867420768,
      "grad_norm": 0.4893239438533783,
      "learning_rate": 9.94562262098967e-06,
      "loss": 1.5722,
      "step": 1850
    },
    {
      "epoch": 1.5160501375726079,
      "grad_norm": 0.4834889769554138,
      "learning_rate": 9.891245241979336e-06,
      "loss": 1.5504,
      "step": 1860
    },
    {
      "epoch": 1.5242025884031387,
      "grad_norm": 0.44720569252967834,
      "learning_rate": 9.836867862969007e-06,
      "loss": 1.5916,
      "step": 1870
    },
    {
      "epoch": 1.5323550392336696,
      "grad_norm": 0.43025439977645874,
      "learning_rate": 9.782490483958674e-06,
      "loss": 1.575,
      "step": 1880
    },
    {
      "epoch": 1.5405074900642006,
      "grad_norm": 0.5002491474151611,
      "learning_rate": 9.728113104948343e-06,
      "loss": 1.5691,
      "step": 1890
    },
    {
      "epoch": 1.5486599408947315,
      "grad_norm": 0.4620574116706848,
      "learning_rate": 9.673735725938011e-06,
      "loss": 1.6148,
      "step": 1900
    },
    {
      "epoch": 1.5486599408947315,
      "eval_loss": 1.578127145767212,
      "eval_runtime": 626.7588,
      "eval_samples_per_second": 0.836,
      "eval_steps_per_second": 0.836,
      "step": 1900
    },
    {
      "epoch": 1.5568123917252623,
      "grad_norm": 0.48895710706710815,
      "learning_rate": 9.619358346927678e-06,
      "loss": 1.5388,
      "step": 1910
    },
    {
      "epoch": 1.5649648425557934,
      "grad_norm": 0.43487703800201416,
      "learning_rate": 9.564980967917347e-06,
      "loss": 1.5775,
      "step": 1920
    },
    {
      "epoch": 1.5731172933863242,
      "grad_norm": 0.42718687653541565,
      "learning_rate": 9.510603588907016e-06,
      "loss": 1.6176,
      "step": 1930
    },
    {
      "epoch": 1.581269744216855,
      "grad_norm": 0.5073007345199585,
      "learning_rate": 9.456226209896684e-06,
      "loss": 1.6149,
      "step": 1940
    },
    {
      "epoch": 1.5894221950473861,
      "grad_norm": 0.48630473017692566,
      "learning_rate": 9.401848830886353e-06,
      "loss": 1.5276,
      "step": 1950
    },
    {
      "epoch": 1.5975746458779172,
      "grad_norm": 0.4898337423801422,
      "learning_rate": 9.34747145187602e-06,
      "loss": 1.5932,
      "step": 1960
    },
    {
      "epoch": 1.6057270967084478,
      "grad_norm": 0.49005359411239624,
      "learning_rate": 9.293094072865689e-06,
      "loss": 1.5408,
      "step": 1970
    },
    {
      "epoch": 1.6138795475389789,
      "grad_norm": 0.4618704617023468,
      "learning_rate": 9.238716693855357e-06,
      "loss": 1.5676,
      "step": 1980
    },
    {
      "epoch": 1.62203199836951,
      "grad_norm": 0.46689558029174805,
      "learning_rate": 9.184339314845026e-06,
      "loss": 1.5549,
      "step": 1990
    },
    {
      "epoch": 1.6301844492000408,
      "grad_norm": 0.5081518888473511,
      "learning_rate": 9.129961935834693e-06,
      "loss": 1.5389,
      "step": 2000
    },
    {
      "epoch": 1.6301844492000408,
      "eval_loss": 1.5775007009506226,
      "eval_runtime": 627.1589,
      "eval_samples_per_second": 0.836,
      "eval_steps_per_second": 0.836,
      "step": 2000
    },
    {
      "epoch": 1.6383369000305716,
      "grad_norm": 0.6700371503829956,
      "learning_rate": 9.075584556824362e-06,
      "loss": 1.5968,
      "step": 2010
    },
    {
      "epoch": 1.6464893508611027,
      "grad_norm": 0.4585631191730499,
      "learning_rate": 9.02120717781403e-06,
      "loss": 1.6081,
      "step": 2020
    },
    {
      "epoch": 1.6546418016916336,
      "grad_norm": 0.47685202956199646,
      "learning_rate": 8.966829798803697e-06,
      "loss": 1.512,
      "step": 2030
    },
    {
      "epoch": 1.6627942525221644,
      "grad_norm": 0.41188278794288635,
      "learning_rate": 8.912452419793368e-06,
      "loss": 1.5719,
      "step": 2040
    },
    {
      "epoch": 1.6709467033526955,
      "grad_norm": 0.46074411273002625,
      "learning_rate": 8.858075040783035e-06,
      "loss": 1.5966,
      "step": 2050
    },
    {
      "epoch": 1.6790991541832263,
      "grad_norm": 0.41184481978416443,
      "learning_rate": 8.803697661772703e-06,
      "loss": 1.5842,
      "step": 2060
    },
    {
      "epoch": 1.6872516050137571,
      "grad_norm": 0.4629879891872406,
      "learning_rate": 8.749320282762372e-06,
      "loss": 1.5898,
      "step": 2070
    },
    {
      "epoch": 1.6954040558442882,
      "grad_norm": 0.47982296347618103,
      "learning_rate": 8.694942903752039e-06,
      "loss": 1.5609,
      "step": 2080
    },
    {
      "epoch": 1.7035565066748193,
      "grad_norm": 0.4701460003852844,
      "learning_rate": 8.64056552474171e-06,
      "loss": 1.5842,
      "step": 2090
    },
    {
      "epoch": 1.71170895750535,
      "grad_norm": 0.4030892252922058,
      "learning_rate": 8.586188145731376e-06,
      "loss": 1.5482,
      "step": 2100
    },
    {
      "epoch": 1.71170895750535,
      "eval_loss": 1.5768908262252808,
      "eval_runtime": 628.9683,
      "eval_samples_per_second": 0.833,
      "eval_steps_per_second": 0.833,
      "step": 2100
    },
    {
      "epoch": 1.719861408335881,
      "grad_norm": 0.5076884031295776,
      "learning_rate": 8.531810766721045e-06,
      "loss": 1.656,
      "step": 2110
    },
    {
      "epoch": 1.728013859166412,
      "grad_norm": 0.4121248722076416,
      "learning_rate": 8.477433387710714e-06,
      "loss": 1.5928,
      "step": 2120
    },
    {
      "epoch": 1.7361663099969429,
      "grad_norm": 0.43413859605789185,
      "learning_rate": 8.42305600870038e-06,
      "loss": 1.5771,
      "step": 2130
    },
    {
      "epoch": 1.7443187608274737,
      "grad_norm": 0.4762989282608032,
      "learning_rate": 8.36867862969005e-06,
      "loss": 1.6093,
      "step": 2140
    },
    {
      "epoch": 1.7524712116580048,
      "grad_norm": 0.5716801881790161,
      "learning_rate": 8.314301250679718e-06,
      "loss": 1.5932,
      "step": 2150
    },
    {
      "epoch": 1.7606236624885356,
      "grad_norm": 0.5607592463493347,
      "learning_rate": 8.259923871669387e-06,
      "loss": 1.5233,
      "step": 2160
    },
    {
      "epoch": 1.7687761133190665,
      "grad_norm": 0.4426048994064331,
      "learning_rate": 8.205546492659055e-06,
      "loss": 1.5719,
      "step": 2170
    },
    {
      "epoch": 1.7769285641495975,
      "grad_norm": 0.4552748501300812,
      "learning_rate": 8.151169113648722e-06,
      "loss": 1.5962,
      "step": 2180
    },
    {
      "epoch": 1.7850810149801284,
      "grad_norm": 0.5203737020492554,
      "learning_rate": 8.096791734638391e-06,
      "loss": 1.5538,
      "step": 2190
    },
    {
      "epoch": 1.7932334658106592,
      "grad_norm": 0.48024362325668335,
      "learning_rate": 8.04241435562806e-06,
      "loss": 1.5788,
      "step": 2200
    },
    {
      "epoch": 1.7932334658106592,
      "eval_loss": 1.5763064622879028,
      "eval_runtime": 627.5008,
      "eval_samples_per_second": 0.835,
      "eval_steps_per_second": 0.835,
      "step": 2200
    },
    {
      "epoch": 1.8013859166411903,
      "grad_norm": 0.4058772623538971,
      "learning_rate": 7.988036976617728e-06,
      "loss": 1.574,
      "step": 2210
    },
    {
      "epoch": 1.8095383674717211,
      "grad_norm": 0.4396074414253235,
      "learning_rate": 7.933659597607395e-06,
      "loss": 1.5752,
      "step": 2220
    },
    {
      "epoch": 1.817690818302252,
      "grad_norm": 0.4080843925476074,
      "learning_rate": 7.879282218597064e-06,
      "loss": 1.6033,
      "step": 2230
    },
    {
      "epoch": 1.825843269132783,
      "grad_norm": 0.3954201638698578,
      "learning_rate": 7.824904839586733e-06,
      "loss": 1.5647,
      "step": 2240
    },
    {
      "epoch": 1.8339957199633141,
      "grad_norm": 0.4609851539134979,
      "learning_rate": 7.770527460576401e-06,
      "loss": 1.5529,
      "step": 2250
    },
    {
      "epoch": 1.8421481707938447,
      "grad_norm": 0.3958445191383362,
      "learning_rate": 7.71615008156607e-06,
      "loss": 1.574,
      "step": 2260
    },
    {
      "epoch": 1.8503006216243758,
      "grad_norm": 0.5139660239219666,
      "learning_rate": 7.661772702555737e-06,
      "loss": 1.5272,
      "step": 2270
    },
    {
      "epoch": 1.8584530724549069,
      "grad_norm": 0.4816521406173706,
      "learning_rate": 7.607395323545406e-06,
      "loss": 1.5491,
      "step": 2280
    },
    {
      "epoch": 1.8666055232854377,
      "grad_norm": 0.47871488332748413,
      "learning_rate": 7.5530179445350735e-06,
      "loss": 1.6302,
      "step": 2290
    },
    {
      "epoch": 1.8747579741159686,
      "grad_norm": 0.4261458218097687,
      "learning_rate": 7.498640565524742e-06,
      "loss": 1.5917,
      "step": 2300
    },
    {
      "epoch": 1.8747579741159686,
      "eval_loss": 1.575818657875061,
      "eval_runtime": 626.6909,
      "eval_samples_per_second": 0.836,
      "eval_steps_per_second": 0.836,
      "step": 2300
    },
    {
      "epoch": 1.8829104249464996,
      "grad_norm": 0.4128953218460083,
      "learning_rate": 7.444263186514411e-06,
      "loss": 1.5908,
      "step": 2310
    },
    {
      "epoch": 1.8910628757770305,
      "grad_norm": 0.4055868685245514,
      "learning_rate": 7.3898858075040795e-06,
      "loss": 1.5795,
      "step": 2320
    },
    {
      "epoch": 1.8992153266075613,
      "grad_norm": 0.45305201411247253,
      "learning_rate": 7.335508428493747e-06,
      "loss": 1.5975,
      "step": 2330
    },
    {
      "epoch": 1.9073677774380924,
      "grad_norm": 0.450764000415802,
      "learning_rate": 7.281131049483415e-06,
      "loss": 1.6178,
      "step": 2340
    },
    {
      "epoch": 1.9155202282686232,
      "grad_norm": 0.4026702046394348,
      "learning_rate": 7.226753670473083e-06,
      "loss": 1.5606,
      "step": 2350
    },
    {
      "epoch": 1.923672679099154,
      "grad_norm": 0.5437828302383423,
      "learning_rate": 7.1723762914627525e-06,
      "loss": 1.6056,
      "step": 2360
    },
    {
      "epoch": 1.9318251299296851,
      "grad_norm": 0.5664982795715332,
      "learning_rate": 7.11799891245242e-06,
      "loss": 1.6135,
      "step": 2370
    },
    {
      "epoch": 1.9399775807602162,
      "grad_norm": 0.4198838472366333,
      "learning_rate": 7.063621533442089e-06,
      "loss": 1.5762,
      "step": 2380
    },
    {
      "epoch": 1.9481300315907468,
      "grad_norm": 0.44043463468551636,
      "learning_rate": 7.009244154431757e-06,
      "loss": 1.5669,
      "step": 2390
    },
    {
      "epoch": 1.956282482421278,
      "grad_norm": 0.5119584202766418,
      "learning_rate": 6.954866775421425e-06,
      "loss": 1.5807,
      "step": 2400
    },
    {
      "epoch": 1.956282482421278,
      "eval_loss": 1.5753415822982788,
      "eval_runtime": 630.3264,
      "eval_samples_per_second": 0.831,
      "eval_steps_per_second": 0.831,
      "step": 2400
    },
    {
      "epoch": 1.964434933251809,
      "grad_norm": 0.452528178691864,
      "learning_rate": 6.900489396411093e-06,
      "loss": 1.5574,
      "step": 2410
    },
    {
      "epoch": 1.9725873840823398,
      "grad_norm": 0.40641099214553833,
      "learning_rate": 6.846112017400762e-06,
      "loss": 1.5922,
      "step": 2420
    },
    {
      "epoch": 1.9807398349128706,
      "grad_norm": 0.4473434090614319,
      "learning_rate": 6.791734638390431e-06,
      "loss": 1.5671,
      "step": 2430
    },
    {
      "epoch": 1.9888922857434017,
      "grad_norm": 0.5546268820762634,
      "learning_rate": 6.7373572593800986e-06,
      "loss": 1.5734,
      "step": 2440
    },
    {
      "epoch": 1.9970447365739326,
      "grad_norm": 0.5243239998817444,
      "learning_rate": 6.682979880369766e-06,
      "loss": 1.5116,
      "step": 2450
    },
    {
      "epoch": 2.0048914704983187,
      "grad_norm": 0.5806818008422852,
      "learning_rate": 6.628602501359434e-06,
      "loss": 1.5003,
      "step": 2460
    },
    {
      "epoch": 2.0130439213288494,
      "grad_norm": 0.3940637409687042,
      "learning_rate": 6.574225122349104e-06,
      "loss": 1.6401,
      "step": 2470
    },
    {
      "epoch": 2.0211963721593804,
      "grad_norm": 0.46891096234321594,
      "learning_rate": 6.5198477433387716e-06,
      "loss": 1.5919,
      "step": 2480
    },
    {
      "epoch": 2.0293488229899115,
      "grad_norm": 0.444722443819046,
      "learning_rate": 6.46547036432844e-06,
      "loss": 1.5548,
      "step": 2490
    },
    {
      "epoch": 2.037501273820442,
      "grad_norm": 0.5083728432655334,
      "learning_rate": 6.411092985318108e-06,
      "loss": 1.5912,
      "step": 2500
    },
    {
      "epoch": 2.037501273820442,
      "eval_loss": 1.5749953985214233,
      "eval_runtime": 629.3037,
      "eval_samples_per_second": 0.833,
      "eval_steps_per_second": 0.833,
      "step": 2500
    },
    {
      "epoch": 2.045653724650973,
      "grad_norm": 0.4489590525627136,
      "learning_rate": 6.356715606307776e-06,
      "loss": 1.5991,
      "step": 2510
    },
    {
      "epoch": 2.0538061754815042,
      "grad_norm": 0.6014991998672485,
      "learning_rate": 6.302338227297445e-06,
      "loss": 1.5753,
      "step": 2520
    },
    {
      "epoch": 2.061958626312035,
      "grad_norm": 0.47446209192276,
      "learning_rate": 6.247960848287113e-06,
      "loss": 1.5864,
      "step": 2530
    },
    {
      "epoch": 2.070111077142566,
      "grad_norm": 0.45587649941444397,
      "learning_rate": 6.193583469276782e-06,
      "loss": 1.5578,
      "step": 2540
    },
    {
      "epoch": 2.078263527973097,
      "grad_norm": 0.4501432180404663,
      "learning_rate": 6.13920609026645e-06,
      "loss": 1.5698,
      "step": 2550
    },
    {
      "epoch": 2.086415978803628,
      "grad_norm": 0.5494632124900818,
      "learning_rate": 6.084828711256118e-06,
      "loss": 1.5484,
      "step": 2560
    },
    {
      "epoch": 2.0945684296341587,
      "grad_norm": 0.42702555656433105,
      "learning_rate": 6.030451332245785e-06,
      "loss": 1.5691,
      "step": 2570
    },
    {
      "epoch": 2.1027208804646897,
      "grad_norm": 0.4675261974334717,
      "learning_rate": 5.976073953235455e-06,
      "loss": 1.5799,
      "step": 2580
    },
    {
      "epoch": 2.110873331295221,
      "grad_norm": 0.5166953206062317,
      "learning_rate": 5.921696574225123e-06,
      "loss": 1.5719,
      "step": 2590
    },
    {
      "epoch": 2.1190257821257514,
      "grad_norm": 0.4850239157676697,
      "learning_rate": 5.8673191952147915e-06,
      "loss": 1.5354,
      "step": 2600
    },
    {
      "epoch": 2.1190257821257514,
      "eval_loss": 1.5746347904205322,
      "eval_runtime": 628.8896,
      "eval_samples_per_second": 0.833,
      "eval_steps_per_second": 0.833,
      "step": 2600
    },
    {
      "epoch": 2.1271782329562825,
      "grad_norm": 0.5642560124397278,
      "learning_rate": 5.812941816204459e-06,
      "loss": 1.6453,
      "step": 2610
    },
    {
      "epoch": 2.1353306837868136,
      "grad_norm": 0.6686995625495911,
      "learning_rate": 5.758564437194127e-06,
      "loss": 1.5234,
      "step": 2620
    },
    {
      "epoch": 2.143483134617344,
      "grad_norm": 0.4717545807361603,
      "learning_rate": 5.704187058183796e-06,
      "loss": 1.5524,
      "step": 2630
    },
    {
      "epoch": 2.1516355854478753,
      "grad_norm": 0.4818636178970337,
      "learning_rate": 5.6498096791734645e-06,
      "loss": 1.5608,
      "step": 2640
    },
    {
      "epoch": 2.1597880362784063,
      "grad_norm": 0.4864891767501831,
      "learning_rate": 5.595432300163133e-06,
      "loss": 1.568,
      "step": 2650
    },
    {
      "epoch": 2.167940487108937,
      "grad_norm": 0.43482479453086853,
      "learning_rate": 5.541054921152801e-06,
      "loss": 1.62,
      "step": 2660
    },
    {
      "epoch": 2.176092937939468,
      "grad_norm": 0.5423178672790527,
      "learning_rate": 5.486677542142469e-06,
      "loss": 1.5472,
      "step": 2670
    },
    {
      "epoch": 2.184245388769999,
      "grad_norm": 0.47047343850135803,
      "learning_rate": 5.432300163132137e-06,
      "loss": 1.5923,
      "step": 2680
    },
    {
      "epoch": 2.19239783960053,
      "grad_norm": 0.4534684121608734,
      "learning_rate": 5.377922784121806e-06,
      "loss": 1.5821,
      "step": 2690
    },
    {
      "epoch": 2.2005502904310608,
      "grad_norm": 0.4601859748363495,
      "learning_rate": 5.323545405111474e-06,
      "loss": 1.5564,
      "step": 2700
    },
    {
      "epoch": 2.2005502904310608,
      "eval_loss": 1.5742571353912354,
      "eval_runtime": 628.7444,
      "eval_samples_per_second": 0.833,
      "eval_steps_per_second": 0.833,
      "step": 2700
    },
    {
      "epoch": 2.208702741261592,
      "grad_norm": 0.46235111355781555,
      "learning_rate": 5.269168026101143e-06,
      "loss": 1.5455,
      "step": 2710
    },
    {
      "epoch": 2.216855192092123,
      "grad_norm": 0.470617413520813,
      "learning_rate": 5.2147906470908105e-06,
      "loss": 1.5278,
      "step": 2720
    },
    {
      "epoch": 2.2250076429226535,
      "grad_norm": 0.5316031575202942,
      "learning_rate": 5.160413268080478e-06,
      "loss": 1.5884,
      "step": 2730
    },
    {
      "epoch": 2.2331600937531846,
      "grad_norm": 0.5488737225532532,
      "learning_rate": 5.106035889070147e-06,
      "loss": 1.5472,
      "step": 2740
    },
    {
      "epoch": 2.2413125445837156,
      "grad_norm": 0.4848385453224182,
      "learning_rate": 5.051658510059816e-06,
      "loss": 1.5441,
      "step": 2750
    },
    {
      "epoch": 2.2494649954142463,
      "grad_norm": 0.46074938774108887,
      "learning_rate": 4.997281131049484e-06,
      "loss": 1.5986,
      "step": 2760
    },
    {
      "epoch": 2.2576174462447773,
      "grad_norm": 0.5823139548301697,
      "learning_rate": 4.942903752039152e-06,
      "loss": 1.588,
      "step": 2770
    },
    {
      "epoch": 2.2657698970753084,
      "grad_norm": 0.46078136563301086,
      "learning_rate": 4.88852637302882e-06,
      "loss": 1.5682,
      "step": 2780
    },
    {
      "epoch": 2.273922347905839,
      "grad_norm": 0.45343226194381714,
      "learning_rate": 4.834148994018489e-06,
      "loss": 1.5888,
      "step": 2790
    },
    {
      "epoch": 2.28207479873637,
      "grad_norm": 0.43895602226257324,
      "learning_rate": 4.7797716150081565e-06,
      "loss": 1.5874,
      "step": 2800
    },
    {
      "epoch": 2.28207479873637,
      "eval_loss": 1.5740087032318115,
      "eval_runtime": 628.4526,
      "eval_samples_per_second": 0.834,
      "eval_steps_per_second": 0.834,
      "step": 2800
    },
    {
      "epoch": 2.290227249566901,
      "grad_norm": 0.49466150999069214,
      "learning_rate": 4.725394235997825e-06,
      "loss": 1.5722,
      "step": 2810
    },
    {
      "epoch": 2.2983797003974322,
      "grad_norm": 0.46236515045166016,
      "learning_rate": 4.671016856987494e-06,
      "loss": 1.5561,
      "step": 2820
    },
    {
      "epoch": 2.306532151227963,
      "grad_norm": 0.5053916573524475,
      "learning_rate": 4.616639477977162e-06,
      "loss": 1.664,
      "step": 2830
    },
    {
      "epoch": 2.314684602058494,
      "grad_norm": 0.5937914848327637,
      "learning_rate": 4.56226209896683e-06,
      "loss": 1.598,
      "step": 2840
    },
    {
      "epoch": 2.3228370528890245,
      "grad_norm": 0.4269644021987915,
      "learning_rate": 4.507884719956498e-06,
      "loss": 1.6029,
      "step": 2850
    },
    {
      "epoch": 2.3309895037195556,
      "grad_norm": 0.5874468088150024,
      "learning_rate": 4.453507340946167e-06,
      "loss": 1.612,
      "step": 2860
    },
    {
      "epoch": 2.3391419545500867,
      "grad_norm": 0.656265139579773,
      "learning_rate": 4.3991299619358356e-06,
      "loss": 1.5907,
      "step": 2870
    },
    {
      "epoch": 2.3472944053806177,
      "grad_norm": 0.5433053374290466,
      "learning_rate": 4.344752582925503e-06,
      "loss": 1.5574,
      "step": 2880
    },
    {
      "epoch": 2.3554468562111484,
      "grad_norm": 0.534174382686615,
      "learning_rate": 4.290375203915171e-06,
      "loss": 1.5803,
      "step": 2890
    },
    {
      "epoch": 2.3635993070416794,
      "grad_norm": 0.48351776599884033,
      "learning_rate": 4.23599782490484e-06,
      "loss": 1.573,
      "step": 2900
    },
    {
      "epoch": 2.3635993070416794,
      "eval_loss": 1.5737483501434326,
      "eval_runtime": 628.4442,
      "eval_samples_per_second": 0.834,
      "eval_steps_per_second": 0.834,
      "step": 2900
    },
    {
      "epoch": 2.3717517578722105,
      "grad_norm": 0.4450860619544983,
      "learning_rate": 4.181620445894508e-06,
      "loss": 1.511,
      "step": 2910
    },
    {
      "epoch": 2.379904208702741,
      "grad_norm": 0.4661327004432678,
      "learning_rate": 4.127243066884176e-06,
      "loss": 1.5671,
      "step": 2920
    },
    {
      "epoch": 2.388056659533272,
      "grad_norm": 0.5694936513900757,
      "learning_rate": 4.072865687873845e-06,
      "loss": 1.5327,
      "step": 2930
    },
    {
      "epoch": 2.3962091103638032,
      "grad_norm": 0.4761938750743866,
      "learning_rate": 4.018488308863513e-06,
      "loss": 1.5757,
      "step": 2940
    },
    {
      "epoch": 2.404361561194334,
      "grad_norm": 0.4207357168197632,
      "learning_rate": 3.964110929853182e-06,
      "loss": 1.5871,
      "step": 2950
    },
    {
      "epoch": 2.412514012024865,
      "grad_norm": 0.4203931391239166,
      "learning_rate": 3.909733550842849e-06,
      "loss": 1.5957,
      "step": 2960
    },
    {
      "epoch": 2.420666462855396,
      "grad_norm": 0.47743695974349976,
      "learning_rate": 3.855356171832518e-06,
      "loss": 1.6385,
      "step": 2970
    },
    {
      "epoch": 2.4288189136859266,
      "grad_norm": 0.4753260910511017,
      "learning_rate": 3.8009787928221863e-06,
      "loss": 1.5694,
      "step": 2980
    },
    {
      "epoch": 2.4369713645164577,
      "grad_norm": 0.4718553125858307,
      "learning_rate": 3.7466014138118546e-06,
      "loss": 1.5617,
      "step": 2990
    },
    {
      "epoch": 2.4451238153469887,
      "grad_norm": 0.45786139369010925,
      "learning_rate": 3.6922240348015233e-06,
      "loss": 1.5555,
      "step": 3000
    },
    {
      "epoch": 2.4451238153469887,
      "eval_loss": 1.5735602378845215,
      "eval_runtime": 628.7562,
      "eval_samples_per_second": 0.833,
      "eval_steps_per_second": 0.833,
      "step": 3000
    }
  ],
  "logging_steps": 10,
  "max_steps": 3678,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8.854975171497296e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
