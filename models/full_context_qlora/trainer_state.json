{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.1197941038839496,
  "eval_steps": 100,
  "global_step": 1700,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.012478552487911403,
      "grad_norm": 0.3147985339164734,
      "learning_rate": 1.99250936329588e-05,
      "loss": 1.8483,
      "step": 10
    },
    {
      "epoch": 0.024957104975822805,
      "grad_norm": 0.26116031408309937,
      "learning_rate": 1.9841864336246363e-05,
      "loss": 1.8151,
      "step": 20
    },
    {
      "epoch": 0.03743565746373421,
      "grad_norm": 0.21668913960456848,
      "learning_rate": 1.9758635039533918e-05,
      "loss": 1.7614,
      "step": 30
    },
    {
      "epoch": 0.04991420995164561,
      "grad_norm": 0.22964096069335938,
      "learning_rate": 1.9675405742821472e-05,
      "loss": 1.7483,
      "step": 40
    },
    {
      "epoch": 0.06239276243955701,
      "grad_norm": 0.23517240583896637,
      "learning_rate": 1.9592176446109034e-05,
      "loss": 1.7685,
      "step": 50
    },
    {
      "epoch": 0.07487131492746842,
      "grad_norm": 0.21608954668045044,
      "learning_rate": 1.950894714939659e-05,
      "loss": 1.7684,
      "step": 60
    },
    {
      "epoch": 0.08734986741537981,
      "grad_norm": 0.22287830710411072,
      "learning_rate": 1.9425717852684147e-05,
      "loss": 1.7911,
      "step": 70
    },
    {
      "epoch": 0.09982841990329122,
      "grad_norm": 0.23340710997581482,
      "learning_rate": 1.9342488555971705e-05,
      "loss": 1.752,
      "step": 80
    },
    {
      "epoch": 0.11230697239120262,
      "grad_norm": 0.29059189558029175,
      "learning_rate": 1.925925925925926e-05,
      "loss": 1.7202,
      "step": 90
    },
    {
      "epoch": 0.12478552487911403,
      "grad_norm": 0.26038146018981934,
      "learning_rate": 1.9176029962546818e-05,
      "loss": 1.7146,
      "step": 100
    },
    {
      "epoch": 0.12478552487911403,
      "eval_loss": 1.7244702577590942,
      "eval_runtime": 745.8866,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 100
    },
    {
      "epoch": 0.13726407736702542,
      "grad_norm": 0.2841840982437134,
      "learning_rate": 1.9092800665834373e-05,
      "loss": 1.7297,
      "step": 110
    },
    {
      "epoch": 0.14974262985493683,
      "grad_norm": 0.28451818227767944,
      "learning_rate": 1.9009571369121934e-05,
      "loss": 1.7109,
      "step": 120
    },
    {
      "epoch": 0.16222118234284824,
      "grad_norm": 0.30177542567253113,
      "learning_rate": 1.892634207240949e-05,
      "loss": 1.6996,
      "step": 130
    },
    {
      "epoch": 0.17469973483075962,
      "grad_norm": 0.2568003535270691,
      "learning_rate": 1.8843112775697047e-05,
      "loss": 1.7091,
      "step": 140
    },
    {
      "epoch": 0.18717828731867103,
      "grad_norm": 0.2993435263633728,
      "learning_rate": 1.8759883478984606e-05,
      "loss": 1.7042,
      "step": 150
    },
    {
      "epoch": 0.19965683980658244,
      "grad_norm": 0.26141828298568726,
      "learning_rate": 1.867665418227216e-05,
      "loss": 1.6561,
      "step": 160
    },
    {
      "epoch": 0.21213539229449385,
      "grad_norm": 0.2754722833633423,
      "learning_rate": 1.859342488555972e-05,
      "loss": 1.6713,
      "step": 170
    },
    {
      "epoch": 0.22461394478240523,
      "grad_norm": 0.29068711400032043,
      "learning_rate": 1.8510195588847273e-05,
      "loss": 1.6349,
      "step": 180
    },
    {
      "epoch": 0.23709249727031664,
      "grad_norm": 0.31808891892433167,
      "learning_rate": 1.8426966292134835e-05,
      "loss": 1.6495,
      "step": 190
    },
    {
      "epoch": 0.24957104975822805,
      "grad_norm": 0.3254215121269226,
      "learning_rate": 1.834373699542239e-05,
      "loss": 1.6829,
      "step": 200
    },
    {
      "epoch": 0.24957104975822805,
      "eval_loss": 1.66189444065094,
      "eval_runtime": 746.0514,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 200
    },
    {
      "epoch": 0.26204960224613943,
      "grad_norm": 0.3006862998008728,
      "learning_rate": 1.8260507698709948e-05,
      "loss": 1.6521,
      "step": 210
    },
    {
      "epoch": 0.27452815473405084,
      "grad_norm": 0.287098228931427,
      "learning_rate": 1.8177278401997506e-05,
      "loss": 1.6874,
      "step": 220
    },
    {
      "epoch": 0.28700670722196225,
      "grad_norm": 0.3156284987926483,
      "learning_rate": 1.809404910528506e-05,
      "loss": 1.6486,
      "step": 230
    },
    {
      "epoch": 0.29948525970987366,
      "grad_norm": 0.2949230968952179,
      "learning_rate": 1.801081980857262e-05,
      "loss": 1.6408,
      "step": 240
    },
    {
      "epoch": 0.3119638121977851,
      "grad_norm": 0.28712204098701477,
      "learning_rate": 1.7927590511860177e-05,
      "loss": 1.6522,
      "step": 250
    },
    {
      "epoch": 0.3244423646856965,
      "grad_norm": 0.2953967750072479,
      "learning_rate": 1.7844361215147735e-05,
      "loss": 1.6104,
      "step": 260
    },
    {
      "epoch": 0.33692091717360784,
      "grad_norm": 0.29658210277557373,
      "learning_rate": 1.776113191843529e-05,
      "loss": 1.6529,
      "step": 270
    },
    {
      "epoch": 0.34939946966151925,
      "grad_norm": 0.2933609187602997,
      "learning_rate": 1.767790262172285e-05,
      "loss": 1.6044,
      "step": 280
    },
    {
      "epoch": 0.36187802214943066,
      "grad_norm": 0.29135167598724365,
      "learning_rate": 1.7594673325010407e-05,
      "loss": 1.6227,
      "step": 290
    },
    {
      "epoch": 0.37435657463734207,
      "grad_norm": 0.29941609501838684,
      "learning_rate": 1.751144402829796e-05,
      "loss": 1.6321,
      "step": 300
    },
    {
      "epoch": 0.37435657463734207,
      "eval_loss": 1.6496553421020508,
      "eval_runtime": 745.8142,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 300
    },
    {
      "epoch": 0.3868351271252535,
      "grad_norm": 0.2816488742828369,
      "learning_rate": 1.742821473158552e-05,
      "loss": 1.6665,
      "step": 310
    },
    {
      "epoch": 0.3993136796131649,
      "grad_norm": 0.30732232332229614,
      "learning_rate": 1.7344985434873078e-05,
      "loss": 1.6075,
      "step": 320
    },
    {
      "epoch": 0.4117922321010763,
      "grad_norm": 0.333055317401886,
      "learning_rate": 1.7261756138160636e-05,
      "loss": 1.6587,
      "step": 330
    },
    {
      "epoch": 0.4242707845889877,
      "grad_norm": 0.2994298040866852,
      "learning_rate": 1.717852684144819e-05,
      "loss": 1.6637,
      "step": 340
    },
    {
      "epoch": 0.43674933707689906,
      "grad_norm": 0.30892905592918396,
      "learning_rate": 1.709529754473575e-05,
      "loss": 1.6042,
      "step": 350
    },
    {
      "epoch": 0.44922788956481047,
      "grad_norm": 0.3129854202270508,
      "learning_rate": 1.7012068248023307e-05,
      "loss": 1.6627,
      "step": 360
    },
    {
      "epoch": 0.4617064420527219,
      "grad_norm": 0.31971505284309387,
      "learning_rate": 1.6928838951310862e-05,
      "loss": 1.6164,
      "step": 370
    },
    {
      "epoch": 0.4741849945406333,
      "grad_norm": 0.30975228548049927,
      "learning_rate": 1.684560965459842e-05,
      "loss": 1.6696,
      "step": 380
    },
    {
      "epoch": 0.4866635470285447,
      "grad_norm": 0.32334238290786743,
      "learning_rate": 1.6762380357885978e-05,
      "loss": 1.6316,
      "step": 390
    },
    {
      "epoch": 0.4991420995164561,
      "grad_norm": 0.35800114274024963,
      "learning_rate": 1.6679151061173536e-05,
      "loss": 1.6339,
      "step": 400
    },
    {
      "epoch": 0.4991420995164561,
      "eval_loss": 1.6423187255859375,
      "eval_runtime": 746.4552,
      "eval_samples_per_second": 0.451,
      "eval_steps_per_second": 0.451,
      "step": 400
    },
    {
      "epoch": 0.5116206520043675,
      "grad_norm": 0.35244783759117126,
      "learning_rate": 1.659592176446109e-05,
      "loss": 1.6485,
      "step": 410
    },
    {
      "epoch": 0.5240992044922789,
      "grad_norm": 0.33304929733276367,
      "learning_rate": 1.651269246774865e-05,
      "loss": 1.6013,
      "step": 420
    },
    {
      "epoch": 0.5365777569801903,
      "grad_norm": 0.3303681015968323,
      "learning_rate": 1.6429463171036208e-05,
      "loss": 1.6036,
      "step": 430
    },
    {
      "epoch": 0.5490563094681017,
      "grad_norm": 0.33582863211631775,
      "learning_rate": 1.6346233874323762e-05,
      "loss": 1.612,
      "step": 440
    },
    {
      "epoch": 0.5615348619560131,
      "grad_norm": 0.32314378023147583,
      "learning_rate": 1.626300457761132e-05,
      "loss": 1.6282,
      "step": 450
    },
    {
      "epoch": 0.5740134144439245,
      "grad_norm": 0.3374105393886566,
      "learning_rate": 1.617977528089888e-05,
      "loss": 1.6415,
      "step": 460
    },
    {
      "epoch": 0.5864919669318359,
      "grad_norm": 0.32177263498306274,
      "learning_rate": 1.6096545984186437e-05,
      "loss": 1.5977,
      "step": 470
    },
    {
      "epoch": 0.5989705194197473,
      "grad_norm": 0.32473424077033997,
      "learning_rate": 1.6013316687473992e-05,
      "loss": 1.599,
      "step": 480
    },
    {
      "epoch": 0.6114490719076587,
      "grad_norm": 0.38149118423461914,
      "learning_rate": 1.593008739076155e-05,
      "loss": 1.6377,
      "step": 490
    },
    {
      "epoch": 0.6239276243955701,
      "grad_norm": 0.31775200366973877,
      "learning_rate": 1.5846858094049108e-05,
      "loss": 1.669,
      "step": 500
    },
    {
      "epoch": 0.6239276243955701,
      "eval_loss": 1.6374092102050781,
      "eval_runtime": 746.2183,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 500
    },
    {
      "epoch": 0.6364061768834816,
      "grad_norm": 0.36361563205718994,
      "learning_rate": 1.5763628797336663e-05,
      "loss": 1.623,
      "step": 510
    },
    {
      "epoch": 0.648884729371393,
      "grad_norm": 0.3194529414176941,
      "learning_rate": 1.568039950062422e-05,
      "loss": 1.605,
      "step": 520
    },
    {
      "epoch": 0.6613632818593044,
      "grad_norm": 0.3753105401992798,
      "learning_rate": 1.559717020391178e-05,
      "loss": 1.6442,
      "step": 530
    },
    {
      "epoch": 0.6738418343472157,
      "grad_norm": 0.3416999578475952,
      "learning_rate": 1.5513940907199337e-05,
      "loss": 1.6186,
      "step": 540
    },
    {
      "epoch": 0.6863203868351271,
      "grad_norm": 0.33181849122047424,
      "learning_rate": 1.5430711610486892e-05,
      "loss": 1.5941,
      "step": 550
    },
    {
      "epoch": 0.6987989393230385,
      "grad_norm": 0.3380682170391083,
      "learning_rate": 1.534748231377445e-05,
      "loss": 1.6474,
      "step": 560
    },
    {
      "epoch": 0.7112774918109499,
      "grad_norm": 0.3318757712841034,
      "learning_rate": 1.526425301706201e-05,
      "loss": 1.6327,
      "step": 570
    },
    {
      "epoch": 0.7237560442988613,
      "grad_norm": 0.3294508755207062,
      "learning_rate": 1.5181023720349563e-05,
      "loss": 1.6196,
      "step": 580
    },
    {
      "epoch": 0.7362345967867727,
      "grad_norm": 0.35363492369651794,
      "learning_rate": 1.5097794423637122e-05,
      "loss": 1.6062,
      "step": 590
    },
    {
      "epoch": 0.7487131492746841,
      "grad_norm": 0.34357836842536926,
      "learning_rate": 1.5014565126924678e-05,
      "loss": 1.6434,
      "step": 600
    },
    {
      "epoch": 0.7487131492746841,
      "eval_loss": 1.6337748765945435,
      "eval_runtime": 746.4629,
      "eval_samples_per_second": 0.451,
      "eval_steps_per_second": 0.451,
      "step": 600
    },
    {
      "epoch": 0.7611917017625955,
      "grad_norm": 0.36358198523521423,
      "learning_rate": 1.4931335830212236e-05,
      "loss": 1.6244,
      "step": 610
    },
    {
      "epoch": 0.773670254250507,
      "grad_norm": 0.34423327445983887,
      "learning_rate": 1.4848106533499793e-05,
      "loss": 1.595,
      "step": 620
    },
    {
      "epoch": 0.7861488067384184,
      "grad_norm": 0.3319184184074402,
      "learning_rate": 1.476487723678735e-05,
      "loss": 1.6332,
      "step": 630
    },
    {
      "epoch": 0.7986273592263298,
      "grad_norm": 0.35647717118263245,
      "learning_rate": 1.4681647940074907e-05,
      "loss": 1.6467,
      "step": 640
    },
    {
      "epoch": 0.8111059117142412,
      "grad_norm": 0.36785203218460083,
      "learning_rate": 1.4598418643362464e-05,
      "loss": 1.6171,
      "step": 650
    },
    {
      "epoch": 0.8235844642021526,
      "grad_norm": 0.3487859070301056,
      "learning_rate": 1.4515189346650022e-05,
      "loss": 1.6357,
      "step": 660
    },
    {
      "epoch": 0.836063016690064,
      "grad_norm": 0.37454089522361755,
      "learning_rate": 1.4431960049937579e-05,
      "loss": 1.6355,
      "step": 670
    },
    {
      "epoch": 0.8485415691779754,
      "grad_norm": 0.33491721749305725,
      "learning_rate": 1.4348730753225137e-05,
      "loss": 1.6422,
      "step": 680
    },
    {
      "epoch": 0.8610201216658867,
      "grad_norm": 0.37103384733200073,
      "learning_rate": 1.4265501456512693e-05,
      "loss": 1.6305,
      "step": 690
    },
    {
      "epoch": 0.8734986741537981,
      "grad_norm": 0.36846020817756653,
      "learning_rate": 1.418227215980025e-05,
      "loss": 1.6328,
      "step": 700
    },
    {
      "epoch": 0.8734986741537981,
      "eval_loss": 1.6308505535125732,
      "eval_runtime": 746.1548,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 700
    },
    {
      "epoch": 0.8859772266417095,
      "grad_norm": 0.4032544493675232,
      "learning_rate": 1.4099042863087808e-05,
      "loss": 1.6007,
      "step": 710
    },
    {
      "epoch": 0.8984557791296209,
      "grad_norm": 0.4019668698310852,
      "learning_rate": 1.4015813566375364e-05,
      "loss": 1.6276,
      "step": 720
    },
    {
      "epoch": 0.9109343316175323,
      "grad_norm": 0.34175023436546326,
      "learning_rate": 1.3932584269662923e-05,
      "loss": 1.6233,
      "step": 730
    },
    {
      "epoch": 0.9234128841054438,
      "grad_norm": 0.3494705557823181,
      "learning_rate": 1.3849354972950479e-05,
      "loss": 1.637,
      "step": 740
    },
    {
      "epoch": 0.9358914365933552,
      "grad_norm": 0.3502333164215088,
      "learning_rate": 1.3766125676238037e-05,
      "loss": 1.5932,
      "step": 750
    },
    {
      "epoch": 0.9483699890812666,
      "grad_norm": 0.3558036983013153,
      "learning_rate": 1.3682896379525594e-05,
      "loss": 1.6256,
      "step": 760
    },
    {
      "epoch": 0.960848541569178,
      "grad_norm": 0.3654417097568512,
      "learning_rate": 1.359966708281315e-05,
      "loss": 1.582,
      "step": 770
    },
    {
      "epoch": 0.9733270940570894,
      "grad_norm": 0.3560602366924286,
      "learning_rate": 1.3516437786100708e-05,
      "loss": 1.6478,
      "step": 780
    },
    {
      "epoch": 0.9858056465450008,
      "grad_norm": 0.39214786887168884,
      "learning_rate": 1.3433208489388265e-05,
      "loss": 1.6801,
      "step": 790
    },
    {
      "epoch": 0.9982841990329122,
      "grad_norm": 0.3478713929653168,
      "learning_rate": 1.3349979192675823e-05,
      "loss": 1.61,
      "step": 800
    },
    {
      "epoch": 0.9982841990329122,
      "eval_loss": 1.6286646127700806,
      "eval_runtime": 746.4655,
      "eval_samples_per_second": 0.451,
      "eval_steps_per_second": 0.451,
      "step": 800
    },
    {
      "epoch": 1.0099828419903292,
      "grad_norm": 0.34891247749328613,
      "learning_rate": 1.326674989596338e-05,
      "loss": 1.5848,
      "step": 810
    },
    {
      "epoch": 1.0224613944782406,
      "grad_norm": 0.3558107018470764,
      "learning_rate": 1.3183520599250936e-05,
      "loss": 1.6033,
      "step": 820
    },
    {
      "epoch": 1.034939946966152,
      "grad_norm": 0.3407217264175415,
      "learning_rate": 1.3100291302538494e-05,
      "loss": 1.5866,
      "step": 830
    },
    {
      "epoch": 1.0474184994540634,
      "grad_norm": 0.3707372546195984,
      "learning_rate": 1.301706200582605e-05,
      "loss": 1.6628,
      "step": 840
    },
    {
      "epoch": 1.0598970519419748,
      "grad_norm": 0.37324637174606323,
      "learning_rate": 1.2933832709113609e-05,
      "loss": 1.663,
      "step": 850
    },
    {
      "epoch": 1.0723756044298862,
      "grad_norm": 0.37459951639175415,
      "learning_rate": 1.2850603412401165e-05,
      "loss": 1.6082,
      "step": 860
    },
    {
      "epoch": 1.0848541569177976,
      "grad_norm": 0.36105698347091675,
      "learning_rate": 1.2767374115688724e-05,
      "loss": 1.5405,
      "step": 870
    },
    {
      "epoch": 1.097332709405709,
      "grad_norm": 0.3359855115413666,
      "learning_rate": 1.268414481897628e-05,
      "loss": 1.6046,
      "step": 880
    },
    {
      "epoch": 1.1098112618936202,
      "grad_norm": 0.3493248224258423,
      "learning_rate": 1.2600915522263836e-05,
      "loss": 1.6081,
      "step": 890
    },
    {
      "epoch": 1.1222898143815319,
      "grad_norm": 0.3721296489238739,
      "learning_rate": 1.2517686225551395e-05,
      "loss": 1.6242,
      "step": 900
    },
    {
      "epoch": 1.1222898143815319,
      "eval_loss": 1.6267272233963013,
      "eval_runtime": 745.8553,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 900
    },
    {
      "epoch": 1.134768366869443,
      "grad_norm": 0.33801379799842834,
      "learning_rate": 1.2434456928838951e-05,
      "loss": 1.6241,
      "step": 910
    },
    {
      "epoch": 1.1472469193573545,
      "grad_norm": 0.3586273193359375,
      "learning_rate": 1.235122763212651e-05,
      "loss": 1.5986,
      "step": 920
    },
    {
      "epoch": 1.1597254718452659,
      "grad_norm": 0.343190461397171,
      "learning_rate": 1.2267998335414066e-05,
      "loss": 1.5659,
      "step": 930
    },
    {
      "epoch": 1.1722040243331773,
      "grad_norm": 0.3625870943069458,
      "learning_rate": 1.2184769038701626e-05,
      "loss": 1.6391,
      "step": 940
    },
    {
      "epoch": 1.1846825768210887,
      "grad_norm": 0.36213117837905884,
      "learning_rate": 1.210153974198918e-05,
      "loss": 1.5912,
      "step": 950
    },
    {
      "epoch": 1.197161129309,
      "grad_norm": 0.3641369938850403,
      "learning_rate": 1.2018310445276737e-05,
      "loss": 1.5862,
      "step": 960
    },
    {
      "epoch": 1.2096396817969115,
      "grad_norm": 0.37484830617904663,
      "learning_rate": 1.1935081148564295e-05,
      "loss": 1.6293,
      "step": 970
    },
    {
      "epoch": 1.222118234284823,
      "grad_norm": 0.3921659290790558,
      "learning_rate": 1.1851851851851852e-05,
      "loss": 1.623,
      "step": 980
    },
    {
      "epoch": 1.2345967867727343,
      "grad_norm": 0.355478972196579,
      "learning_rate": 1.176862255513941e-05,
      "loss": 1.6001,
      "step": 990
    },
    {
      "epoch": 1.2470753392606457,
      "grad_norm": 0.3552475869655609,
      "learning_rate": 1.1685393258426966e-05,
      "loss": 1.6265,
      "step": 1000
    },
    {
      "epoch": 1.2470753392606457,
      "eval_loss": 1.6251648664474487,
      "eval_runtime": 746.0421,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 1000
    },
    {
      "epoch": 1.2595538917485571,
      "grad_norm": 0.37729567289352417,
      "learning_rate": 1.1602163961714526e-05,
      "loss": 1.6299,
      "step": 1010
    },
    {
      "epoch": 1.2720324442364686,
      "grad_norm": 0.35307592153549194,
      "learning_rate": 1.1518934665002081e-05,
      "loss": 1.633,
      "step": 1020
    },
    {
      "epoch": 1.28451099672438,
      "grad_norm": 0.3584156632423401,
      "learning_rate": 1.1435705368289637e-05,
      "loss": 1.6203,
      "step": 1030
    },
    {
      "epoch": 1.2969895492122914,
      "grad_norm": 0.4069333076477051,
      "learning_rate": 1.1352476071577196e-05,
      "loss": 1.5698,
      "step": 1040
    },
    {
      "epoch": 1.3094681017002028,
      "grad_norm": 0.3474373519420624,
      "learning_rate": 1.1269246774864752e-05,
      "loss": 1.6164,
      "step": 1050
    },
    {
      "epoch": 1.3219466541881142,
      "grad_norm": 0.35756155848503113,
      "learning_rate": 1.1186017478152312e-05,
      "loss": 1.6318,
      "step": 1060
    },
    {
      "epoch": 1.3344252066760256,
      "grad_norm": 0.37782391905784607,
      "learning_rate": 1.1102788181439867e-05,
      "loss": 1.5895,
      "step": 1070
    },
    {
      "epoch": 1.346903759163937,
      "grad_norm": 0.3373231589794159,
      "learning_rate": 1.1019558884727427e-05,
      "loss": 1.6188,
      "step": 1080
    },
    {
      "epoch": 1.3593823116518484,
      "grad_norm": 0.4014514684677124,
      "learning_rate": 1.0936329588014981e-05,
      "loss": 1.6246,
      "step": 1090
    },
    {
      "epoch": 1.3718608641397598,
      "grad_norm": 0.357704758644104,
      "learning_rate": 1.0853100291302538e-05,
      "loss": 1.6202,
      "step": 1100
    },
    {
      "epoch": 1.3718608641397598,
      "eval_loss": 1.6238071918487549,
      "eval_runtime": 745.8404,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 1100
    },
    {
      "epoch": 1.3843394166276712,
      "grad_norm": 0.37670543789863586,
      "learning_rate": 1.0769870994590098e-05,
      "loss": 1.6144,
      "step": 1110
    },
    {
      "epoch": 1.3968179691155826,
      "grad_norm": 0.37045836448669434,
      "learning_rate": 1.0686641697877653e-05,
      "loss": 1.5794,
      "step": 1120
    },
    {
      "epoch": 1.409296521603494,
      "grad_norm": 0.3904931843280792,
      "learning_rate": 1.0603412401165212e-05,
      "loss": 1.5977,
      "step": 1130
    },
    {
      "epoch": 1.4217750740914055,
      "grad_norm": 0.3967387080192566,
      "learning_rate": 1.0520183104452767e-05,
      "loss": 1.5671,
      "step": 1140
    },
    {
      "epoch": 1.4342536265793169,
      "grad_norm": 0.37693941593170166,
      "learning_rate": 1.0436953807740327e-05,
      "loss": 1.6296,
      "step": 1150
    },
    {
      "epoch": 1.446732179067228,
      "grad_norm": 0.36507847905158997,
      "learning_rate": 1.0353724511027882e-05,
      "loss": 1.6016,
      "step": 1160
    },
    {
      "epoch": 1.4592107315551397,
      "grad_norm": 0.36338168382644653,
      "learning_rate": 1.0270495214315438e-05,
      "loss": 1.6565,
      "step": 1170
    },
    {
      "epoch": 1.4716892840430509,
      "grad_norm": 0.37242573499679565,
      "learning_rate": 1.0187265917602998e-05,
      "loss": 1.6265,
      "step": 1180
    },
    {
      "epoch": 1.4841678365309625,
      "grad_norm": 0.37010902166366577,
      "learning_rate": 1.0104036620890553e-05,
      "loss": 1.6034,
      "step": 1190
    },
    {
      "epoch": 1.4966463890188737,
      "grad_norm": 0.36610332131385803,
      "learning_rate": 1.0020807324178113e-05,
      "loss": 1.6265,
      "step": 1200
    },
    {
      "epoch": 1.4966463890188737,
      "eval_loss": 1.6225850582122803,
      "eval_runtime": 746.0245,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 1200
    },
    {
      "epoch": 1.5091249415067853,
      "grad_norm": 0.42151033878326416,
      "learning_rate": 9.937578027465668e-06,
      "loss": 1.6356,
      "step": 1210
    },
    {
      "epoch": 1.5216034939946965,
      "grad_norm": 0.37838026881217957,
      "learning_rate": 9.854348730753226e-06,
      "loss": 1.6012,
      "step": 1220
    },
    {
      "epoch": 1.5340820464826082,
      "grad_norm": 0.3729464113712311,
      "learning_rate": 9.771119434040784e-06,
      "loss": 1.6682,
      "step": 1230
    },
    {
      "epoch": 1.5465605989705193,
      "grad_norm": 0.3820635974407196,
      "learning_rate": 9.68789013732834e-06,
      "loss": 1.6296,
      "step": 1240
    },
    {
      "epoch": 1.559039151458431,
      "grad_norm": 0.414014995098114,
      "learning_rate": 9.604660840615899e-06,
      "loss": 1.6005,
      "step": 1250
    },
    {
      "epoch": 1.5715177039463422,
      "grad_norm": 0.35754695534706116,
      "learning_rate": 9.521431543903454e-06,
      "loss": 1.591,
      "step": 1260
    },
    {
      "epoch": 1.5839962564342538,
      "grad_norm": 0.3994999825954437,
      "learning_rate": 9.438202247191012e-06,
      "loss": 1.657,
      "step": 1270
    },
    {
      "epoch": 1.596474808922165,
      "grad_norm": 0.364341139793396,
      "learning_rate": 9.35497295047857e-06,
      "loss": 1.6861,
      "step": 1280
    },
    {
      "epoch": 1.6089533614100764,
      "grad_norm": 0.40613624453544617,
      "learning_rate": 9.271743653766126e-06,
      "loss": 1.5915,
      "step": 1290
    },
    {
      "epoch": 1.6214319138979878,
      "grad_norm": 0.35508477687835693,
      "learning_rate": 9.188514357053685e-06,
      "loss": 1.6165,
      "step": 1300
    },
    {
      "epoch": 1.6214319138979878,
      "eval_loss": 1.621435523033142,
      "eval_runtime": 746.4862,
      "eval_samples_per_second": 0.451,
      "eval_steps_per_second": 0.451,
      "step": 1300
    },
    {
      "epoch": 1.6339104663858992,
      "grad_norm": 0.3686458468437195,
      "learning_rate": 9.105285060341241e-06,
      "loss": 1.5913,
      "step": 1310
    },
    {
      "epoch": 1.6463890188738106,
      "grad_norm": 0.3861751854419708,
      "learning_rate": 9.022055763628798e-06,
      "loss": 1.6106,
      "step": 1320
    },
    {
      "epoch": 1.658867571361722,
      "grad_norm": 0.3504468500614166,
      "learning_rate": 8.938826466916356e-06,
      "loss": 1.6135,
      "step": 1330
    },
    {
      "epoch": 1.6713461238496334,
      "grad_norm": 0.3876728415489197,
      "learning_rate": 8.855597170203912e-06,
      "loss": 1.6016,
      "step": 1340
    },
    {
      "epoch": 1.6838246763375448,
      "grad_norm": 0.36027300357818604,
      "learning_rate": 8.77236787349147e-06,
      "loss": 1.6288,
      "step": 1350
    },
    {
      "epoch": 1.6963032288254563,
      "grad_norm": 0.39893966913223267,
      "learning_rate": 8.689138576779027e-06,
      "loss": 1.5814,
      "step": 1360
    },
    {
      "epoch": 1.7087817813133677,
      "grad_norm": 0.3781922161579132,
      "learning_rate": 8.605909280066585e-06,
      "loss": 1.6314,
      "step": 1370
    },
    {
      "epoch": 1.721260333801279,
      "grad_norm": 0.3688964545726776,
      "learning_rate": 8.522679983354142e-06,
      "loss": 1.6262,
      "step": 1380
    },
    {
      "epoch": 1.7337388862891905,
      "grad_norm": 0.37224116921424866,
      "learning_rate": 8.439450686641698e-06,
      "loss": 1.6195,
      "step": 1390
    },
    {
      "epoch": 1.746217438777102,
      "grad_norm": 0.42646318674087524,
      "learning_rate": 8.356221389929256e-06,
      "loss": 1.6593,
      "step": 1400
    },
    {
      "epoch": 1.746217438777102,
      "eval_loss": 1.6205925941467285,
      "eval_runtime": 745.6759,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 1400
    },
    {
      "epoch": 1.7586959912650133,
      "grad_norm": 0.38344046473503113,
      "learning_rate": 8.272992093216813e-06,
      "loss": 1.6103,
      "step": 1410
    },
    {
      "epoch": 1.7711745437529247,
      "grad_norm": 0.38875341415405273,
      "learning_rate": 8.189762796504371e-06,
      "loss": 1.6426,
      "step": 1420
    },
    {
      "epoch": 1.783653096240836,
      "grad_norm": 0.39454638957977295,
      "learning_rate": 8.106533499791927e-06,
      "loss": 1.6291,
      "step": 1430
    },
    {
      "epoch": 1.7961316487287475,
      "grad_norm": 0.3884683847427368,
      "learning_rate": 8.023304203079486e-06,
      "loss": 1.619,
      "step": 1440
    },
    {
      "epoch": 1.8086102012166587,
      "grad_norm": 0.382282555103302,
      "learning_rate": 7.940074906367042e-06,
      "loss": 1.6243,
      "step": 1450
    },
    {
      "epoch": 1.8210887537045704,
      "grad_norm": 0.3990756571292877,
      "learning_rate": 7.856845609654599e-06,
      "loss": 1.5855,
      "step": 1460
    },
    {
      "epoch": 1.8335673061924815,
      "grad_norm": 0.4014148712158203,
      "learning_rate": 7.773616312942157e-06,
      "loss": 1.6038,
      "step": 1470
    },
    {
      "epoch": 1.8460458586803932,
      "grad_norm": 0.3662790060043335,
      "learning_rate": 7.690387016229713e-06,
      "loss": 1.6114,
      "step": 1480
    },
    {
      "epoch": 1.8585244111683044,
      "grad_norm": 0.36482828855514526,
      "learning_rate": 7.6071577195172706e-06,
      "loss": 1.5879,
      "step": 1490
    },
    {
      "epoch": 1.871002963656216,
      "grad_norm": 0.3807674050331116,
      "learning_rate": 7.523928422804828e-06,
      "loss": 1.618,
      "step": 1500
    },
    {
      "epoch": 1.871002963656216,
      "eval_loss": 1.6197468042373657,
      "eval_runtime": 745.7152,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 1500
    },
    {
      "epoch": 1.8834815161441272,
      "grad_norm": 0.3605729639530182,
      "learning_rate": 7.440699126092385e-06,
      "loss": 1.6253,
      "step": 1510
    },
    {
      "epoch": 1.8959600686320388,
      "grad_norm": 0.36715325713157654,
      "learning_rate": 7.357469829379942e-06,
      "loss": 1.6089,
      "step": 1520
    },
    {
      "epoch": 1.90843862111995,
      "grad_norm": 0.4154967963695526,
      "learning_rate": 7.274240532667499e-06,
      "loss": 1.6103,
      "step": 1530
    },
    {
      "epoch": 1.9209171736078616,
      "grad_norm": 0.39539989829063416,
      "learning_rate": 7.191011235955056e-06,
      "loss": 1.6265,
      "step": 1540
    },
    {
      "epoch": 1.9333957260957728,
      "grad_norm": 0.3863082826137543,
      "learning_rate": 7.107781939242614e-06,
      "loss": 1.6036,
      "step": 1550
    },
    {
      "epoch": 1.9458742785836844,
      "grad_norm": 0.3818724751472473,
      "learning_rate": 7.024552642530171e-06,
      "loss": 1.5823,
      "step": 1560
    },
    {
      "epoch": 1.9583528310715956,
      "grad_norm": 0.3813151717185974,
      "learning_rate": 6.941323345817728e-06,
      "loss": 1.6105,
      "step": 1570
    },
    {
      "epoch": 1.970831383559507,
      "grad_norm": 0.3829282224178314,
      "learning_rate": 6.858094049105286e-06,
      "loss": 1.6317,
      "step": 1580
    },
    {
      "epoch": 1.9833099360474185,
      "grad_norm": 0.3944942057132721,
      "learning_rate": 6.774864752392842e-06,
      "loss": 1.6,
      "step": 1590
    },
    {
      "epoch": 1.9957884885353299,
      "grad_norm": 0.37618952989578247,
      "learning_rate": 6.6916354556803995e-06,
      "loss": 1.6093,
      "step": 1600
    },
    {
      "epoch": 1.9957884885353299,
      "eval_loss": 1.6191269159317017,
      "eval_runtime": 746.3016,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 1600
    },
    {
      "epoch": 2.0074871314927467,
      "grad_norm": 0.38876932859420776,
      "learning_rate": 6.608406158967957e-06,
      "loss": 1.66,
      "step": 1610
    },
    {
      "epoch": 2.0199656839806583,
      "grad_norm": 0.3817826509475708,
      "learning_rate": 6.525176862255514e-06,
      "loss": 1.5746,
      "step": 1620
    },
    {
      "epoch": 2.0324442364685695,
      "grad_norm": 0.36292117834091187,
      "learning_rate": 6.4419475655430715e-06,
      "loss": 1.5889,
      "step": 1630
    },
    {
      "epoch": 2.044922788956481,
      "grad_norm": 0.40853554010391235,
      "learning_rate": 6.358718268830629e-06,
      "loss": 1.6164,
      "step": 1640
    },
    {
      "epoch": 2.0574013414443924,
      "grad_norm": 0.3916262984275818,
      "learning_rate": 6.275488972118187e-06,
      "loss": 1.6015,
      "step": 1650
    },
    {
      "epoch": 2.069879893932304,
      "grad_norm": 0.426333487033844,
      "learning_rate": 6.192259675405743e-06,
      "loss": 1.6001,
      "step": 1660
    },
    {
      "epoch": 2.082358446420215,
      "grad_norm": 0.3823014497756958,
      "learning_rate": 6.1090303786933e-06,
      "loss": 1.5898,
      "step": 1670
    },
    {
      "epoch": 2.094836998908127,
      "grad_norm": 0.407762348651886,
      "learning_rate": 6.025801081980857e-06,
      "loss": 1.6248,
      "step": 1680
    },
    {
      "epoch": 2.107315551396038,
      "grad_norm": 0.3752041161060333,
      "learning_rate": 5.942571785268415e-06,
      "loss": 1.625,
      "step": 1690
    },
    {
      "epoch": 2.1197941038839496,
      "grad_norm": 0.3709266781806946,
      "learning_rate": 5.859342488555972e-06,
      "loss": 1.6081,
      "step": 1700
    },
    {
      "epoch": 2.1197941038839496,
      "eval_loss": 1.6186338663101196,
      "eval_runtime": 745.8683,
      "eval_samples_per_second": 0.452,
      "eval_steps_per_second": 0.452,
      "step": 1700
    }
  ],
  "logging_steps": 10,
  "max_steps": 2403,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.102012984147968e+19,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
